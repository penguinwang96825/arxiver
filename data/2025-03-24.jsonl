{"title": "A Survey of Large Language Model Agents for Question Answering", "abstract": "This paper surveys the development of large language model (LLM)-based agents\nfor question answering (QA). Traditional agents face significant limitations,\nincluding substantial data requirements and difficulty in generalizing to new\nenvironments. LLM-based agents address these challenges by leveraging LLMs as\ntheir core reasoning engine. These agents achieve superior QA results compared\nto traditional QA pipelines and naive LLM QA systems by enabling interaction\nwith external environments. We systematically review the design of LLM agents\nin the context of QA tasks, organizing our discussion across key stages:\nplanning, question understanding, information retrieval, and answer generation.\nAdditionally, this paper identifies ongoing challenges and explores future\nresearch directions to enhance the performance of LLM agent QA systems.", "published": "2025-03-24 23:39:44", "link": "http://arxiv.org/abs/2503.19213v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Towards Terminology Management Automation for Arabic", "abstract": "This paper presents a method and supporting tools for automation of\nterminology management for Arabic. The tools extract lists of parallel\nterminology matching terms in foreign languages to their Arabic counterparts\nfrom field specific texts. This has significant implications as it can be used\nto improve consistent translation and use of terms in specialized Arabic\nacademic books, and provides automated aid for enhancing cross lingual text\nprocessing. This automation of terminology management aims to reduce processing\ntime, and ensure use of consistent and correct terminology. The extraction\ntakes advantage of naturally occurring term translations. It considers several\ncandidate phrases of varying lengths that co-occur next to the foreign terms.\nThen it computes several similarity metrics, including lexicographic, phonetic,\nmorphological, and semantic ones to decide the problem. We experiment with\nheuristic, machine learning, and ML with post processing approaches. This paper\nreports on a novel curated dataset for the task, an existing expert reviewed\nindustry parallel corpora, and on the performance of the three approaches. The\nbest approach achieved 94.9% precision and 92.4% recall.", "published": "2025-03-24 23:35:00", "link": "http://arxiv.org/abs/2503.19211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overtrained Language Models Are Harder to Fine-Tune", "abstract": "Large language models are pre-trained on ever-growing token budgets under the\nassumption that better pre-training performance translates to improved\ndownstream models. In this work, we challenge this assumption and show that\nextended pre-training can make models harder to fine-tune, leading to degraded\nfinal performance. We term this phenomenon catastrophic overtraining. For\nexample, the instruction-tuned OLMo-1B model pre-trained on 3T tokens leads to\nover 2% worse performance on multiple standard LLM benchmarks than its 2.3T\ntoken counterpart. Through controlled experiments and theoretical analysis, we\nshow that catastrophic overtraining arises from a systematic increase in the\nbroad sensitivity of pre-trained parameters to modifications, including but not\nlimited to fine-tuning. Our findings call for a critical reassessment of\npre-training design that considers the downstream adaptability of the model.", "published": "2025-03-24 23:11:56", "link": "http://arxiv.org/abs/2503.19206v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Browsing Lost Unformed Recollections: A Benchmark for Tip-of-the-Tongue Search and Reasoning", "abstract": "We introduce Browsing Lost Unformed Recollections, a tip-of-the-tongue\nknown-item search and reasoning benchmark for general AI assistants. BLUR\nintroduces a set of 573 real-world validated questions that demand searching\nand reasoning across multi-modal and multilingual inputs, as well as proficient\ntool use, in order to excel on. Humans easily ace these questions (scoring on\naverage 98%), while the best-performing system scores around 56%. To facilitate\nprogress toward addressing this challenging and aspirational use case for\ngeneral AI assistants, we release 350 questions through a public leaderboard,\nretain the answers to 250 of them, and have the rest as a private test set.", "published": "2025-03-24 22:46:25", "link": "http://arxiv.org/abs/2503.19193v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Protein Structure-Function Relationship: A Kernel-PCA Approach for Reaction Coordinate Identification", "abstract": "In this study, we propose a Kernel-PCA model designed to capture\nstructure-function relationships in a protein. This model also enables ranking\nof reaction coordinates according to their impact on protein properties. By\nleveraging machine learning techniques, including Kernel and principal\ncomponent analysis (PCA), our model uncovers meaningful patterns in\nhigh-dimensional protein data obtained from molecular dynamics (MD)\nsimulations. The effectiveness of our model in accurately identifying reaction\ncoordinates has been demonstrated through its application to a G\nprotein-coupled receptor. Furthermore, this model utilizes a network-based\napproach to uncover correlations in the dynamic behavior of residues associated\nwith a specific protein property. These findings underscore the potential of\nour model as a powerful tool for protein structure-function analysis and\nvisualization.", "published": "2025-03-24 22:22:51", "link": "http://arxiv.org/abs/2503.19186v1", "categories": ["cs.CL", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Evaluating Bias in LLMs for Job-Resume Matching: Gender, Race, and Education", "abstract": "Large Language Models (LLMs) offer the potential to automate hiring by\nmatching job descriptions with candidate resumes, streamlining recruitment\nprocesses, and reducing operational costs. However, biases inherent in these\nmodels may lead to unfair hiring practices, reinforcing societal prejudices and\nundermining workplace diversity. This study examines the performance and\nfairness of LLMs in job-resume matching tasks within the English language and\nU.S. context. It evaluates how factors such as gender, race, and educational\nbackground influence model decisions, providing critical insights into the\nfairness and reliability of LLMs in HR applications. Our findings indicate that\nwhile recent models have reduced biases related to explicit attributes like\ngender and race, implicit biases concerning educational background remain\nsignificant. These results highlight the need for ongoing evaluation and the\ndevelopment of advanced bias mitigation strategies to ensure equitable hiring\npractices when using LLMs in industry settings.", "published": "2025-03-24 22:11:22", "link": "http://arxiv.org/abs/2503.19182v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Model Uncertainty Quantification with Attention Chain", "abstract": "Accurately quantifying a large language model's (LLM) predictive uncertainty\nis crucial for judging the reliability of its answers. While most existing\nresearch focuses on short, directly answerable questions with closed-form\noutputs (e.g., multiple-choice), involving intermediate reasoning steps in LLM\nresponses is increasingly important. This added complexity complicates\nuncertainty quantification (UQ) because the probabilities assigned to answer\ntokens are conditioned on a vast space of preceding reasoning tokens. Direct\nmarginalization is infeasible, and the dependency inflates probability\nestimates, causing overconfidence in UQ. To address this, we propose UQAC, an\nefficient method that narrows the reasoning space to a tractable size for\nmarginalization. UQAC iteratively constructs an \"attention chain\" of tokens\ndeemed \"semantically crucial\" to the final answer via a backtracking procedure.\nStarting from the answer tokens, it uses attention weights to identify the most\ninfluential predecessors, then iterates this process until reaching the input\ntokens. Similarity filtering and probability thresholding further refine the\nresulting chain, allowing us to approximate the marginal probabilities of the\nanswer tokens, which serve as the LLM's confidence. We validate UQAC on\nmultiple reasoning benchmarks with advanced open-source LLMs, demonstrating\nthat it consistently delivers reliable UQ estimates with high computational\nefficiency.", "published": "2025-03-24 21:43:47", "link": "http://arxiv.org/abs/2503.19168v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fundamental Safety-Capability Trade-offs in Fine-tuning Large Language Models", "abstract": "Fine-tuning Large Language Models (LLMs) on some task-specific datasets has\nbeen a primary use of LLMs. However, it has been empirically observed that this\napproach to enhancing capability inevitably compromises safety, a phenomenon\nalso known as the safety-capability trade-off in LLM fine-tuning. This paper\npresents a theoretical framework for understanding the interplay between safety\nand capability in two primary safety-aware LLM fine-tuning strategies,\nproviding new insights into the effects of data similarity, context overlap,\nand alignment loss landscape. Our theoretical results characterize the\nfundamental limits of the safety-capability trade-off in LLM fine-tuning, which\nare also validated by numerical experiments.", "published": "2025-03-24 20:41:57", "link": "http://arxiv.org/abs/2503.20807v1", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "MIRAGE: Multimodal Immersive Reasoning and Guided Exploration for Red-Team Jailbreak Attacks", "abstract": "While safety mechanisms have significantly progressed in filtering harmful\ntext inputs, MLLMs remain vulnerable to multimodal jailbreaks that exploit\ntheir cross-modal reasoning capabilities. We present MIRAGE, a novel multimodal\njailbreak framework that exploits narrative-driven context and role immersion\nto circumvent safety mechanisms in Multimodal Large Language Models (MLLMs). By\nsystematically decomposing the toxic query into environment, role, and action\ntriplets, MIRAGE constructs a multi-turn visual storytelling sequence of images\nand text using Stable Diffusion, guiding the target model through an engaging\ndetective narrative. This process progressively lowers the model's defences and\nsubtly guides its reasoning through structured contextual cues, ultimately\neliciting harmful responses. In extensive experiments on the selected datasets\nwith six mainstream MLLMs, MIRAGE achieves state-of-the-art performance,\nimproving attack success rates by up to 17.5% over the best baselines.\nMoreover, we demonstrate that role immersion and structured semantic\nreconstruction can activate inherent model biases, facilitating the model's\nspontaneous violation of ethical safeguards. These results highlight critical\nweaknesses in current multimodal safety mechanisms and underscore the urgent\nneed for more robust defences against cross-modal threats.", "published": "2025-03-24 20:38:42", "link": "http://arxiv.org/abs/2503.19134v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Overcoming Vocabulary Mismatch: Vocabulary-agnostic Teacher Guided Language Modeling", "abstract": "Using large teacher models to guide the training of smaller student models\nhas become the prevailing paradigm for efficient and effective learning.\nHowever, vocabulary mismatches between teacher and student language models pose\nsignificant challenges in language modeling, resulting in divergent token\nsequences and output distributions. To overcome these limitations, we propose\nVocabulary-agnostic Teacher Guided Language Modeling (VocAgnoLM), a novel\napproach that bridges the gap caused by vocabulary mismatch through two key\nmethods: (1) Token-level Lexical Alignment, which aligns token sequences across\nmismatched vocabularies, and (2) Teacher Guided Loss, which leverages the loss\nof teacher model to guide effective student training. We demonstrate its\neffectiveness in language modeling with 1B student model using various 7B\nteacher models with different vocabularies. Notably, with\nQwen2.5-Math-Instruct, a teacher model sharing only about 6% of its vocabulary\nwith TinyLlama, VocAgnoLM achieves a 46% performance improvement compared to\nnaive continual pretraining. Furthermore, we demonstrate that VocAgnoLM\nconsistently benefits from stronger teacher models, providing a robust solution\nto vocabulary mismatches in language modeling.", "published": "2025-03-24 20:19:31", "link": "http://arxiv.org/abs/2503.19123v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Where is this coming from? Making groundedness count in the evaluation of Document VQA models", "abstract": "Document Visual Question Answering (VQA) models have evolved at an impressive\nrate over the past few years, coming close to or matching human performance on\nsome benchmarks. We argue that common evaluation metrics used by popular\nbenchmarks do not account for the semantic and multimodal groundedness of a\nmodel's outputs. As a result, hallucinations and major semantic errors are\ntreated the same way as well-grounded outputs, and the evaluation scores do not\nreflect the reasoning capabilities of the model. In response, we propose a new\nevaluation methodology that accounts for the groundedness of predictions with\nregard to the semantic characteristics of the output as well as the multimodal\nplacement of the output within the input document. Our proposed methodology is\nparameterized in such a way that users can configure the score according to\ntheir preferences. We validate our scoring methodology using human judgment and\nshow its potential impact on existing popular leaderboards. Through extensive\nanalyses, we demonstrate that our proposed method produces scores that are a\nbetter indicator of a model's robustness and tends to give higher rewards to\nbetter-calibrated answers.", "published": "2025-03-24 20:14:46", "link": "http://arxiv.org/abs/2503.19120v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding and Improving Information Preservation in Prompt Compression for LLMs", "abstract": "Recent advancements in large language models (LLMs) have enabled their\nsuccessful application to a broad range of tasks. However, in\ninformation-intensive tasks, the prompt length can grow fast, leading to\nincreased computational requirements, performance degradation, and induced\nbiases from irrelevant or redundant information. Recently, various prompt\ncompression techniques have been introduced to optimize the trade-off between\nreducing input length and retaining performance. We propose a holistic\nevaluation framework that allows for in-depth analysis of prompt compression\nmethods. We focus on three key aspects, besides compression ratio: (i)\ndownstream task performance, (ii) grounding in the input context, and (iii)\ninformation preservation. Through this framework, we investigate\nstate-of-the-art soft and hard compression methods, showing that they struggle\nto preserve key details from the original prompt, limiting their performance on\ncomplex tasks. We demonstrate that modifying soft prompting methods to control\nbetter the granularity of the compressed information can significantly improve\ntheir effectiveness -- up to +23\\% in downstream task performance, more than +8\nBERTScore points in grounding, and 2.7x more entities preserved in compression.", "published": "2025-03-24 20:06:11", "link": "http://arxiv.org/abs/2503.19114v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Joint Prediction of Multiple Future Tokens", "abstract": "In this short report, we introduce joint multi-token prediction (JTP), a\nlightweight modification of standard next-token prediction designed to enrich\nhidden state representations by jointly predicting multiple future tokens.\nUnlike previous multi-token prediction approaches, JTP strategically employs\nteacher forcing of future-tokens through a carefully designed representation\nbottleneck, allowing the model to encode rich predictive information with\nminimal computational overhead during training. We show that the JTP approach\nachieves a short-horizon belief state representation, while popular\nalternatives for multi-token prediction fail to do so. We demonstrate the\neffectiveness of our method on the synthetic star graph navigation task from\nfrom Bachmann and Nagarajan [2024], highlighting a significant performance\nimprovement over existing methods. This manuscript presents promising\npreliminary results intended to stimulate further research.", "published": "2025-03-24 19:52:42", "link": "http://arxiv.org/abs/2503.21801v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Masks and Mimicry: Strategic Obfuscation and Impersonation Attacks on Authorship Verification", "abstract": "The increasing use of Artificial Intelligence (AI) technologies, such as\nLarge Language Models (LLMs) has led to nontrivial improvements in various\ntasks, including accurate authorship identification of documents. However,\nwhile LLMs improve such defense techniques, they also simultaneously provide a\nvehicle for malicious actors to launch new attack vectors. To combat this\nsecurity risk, we evaluate the adversarial robustness of authorship models\n(specifically an authorship verification model) to potent LLM-based attacks.\nThese attacks include untargeted methods - \\textit{authorship obfuscation} and\ntargeted methods - \\textit{authorship impersonation}. For both attacks, the\nobjective is to mask or mimic the writing style of an author while preserving\nthe original texts' semantics, respectively. Thus, we perturb an accurate\nauthorship verification model, and achieve maximum attack success rates of 92\\%\nand 78\\% for both obfuscation and impersonation attacks, respectively.", "published": "2025-03-24 19:36:22", "link": "http://arxiv.org/abs/2503.19099v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rankers, Judges, and Assistants: Towards Understanding the Interplay of LLMs in Information Retrieval Evaluation", "abstract": "Large language models (LLMs) are increasingly integral to information\nretrieval (IR), powering ranking, evaluation, and AI-assisted content creation.\nThis widespread adoption necessitates a critical examination of potential\nbiases arising from the interplay between these LLM-based components. This\npaper synthesizes existing research and presents novel experiment designs that\nexplore how LLM-based rankers and assistants influence LLM-based judges. We\nprovide the first empirical evidence of LLM judges exhibiting significant bias\ntowards LLM-based rankers. Furthermore, we observe limitations in LLM judges'\nability to discern subtle system performance differences. Contrary to some\nprevious findings, our preliminary study does not find evidence of bias against\nAI-generated content. These results highlight the need for a more holistic view\nof the LLM-driven information ecosystem. To this end, we offer initial\nguidelines and a research agenda to ensure the reliable use of LLMs in IR\nevaluation.", "published": "2025-03-24 19:24:40", "link": "http://arxiv.org/abs/2503.19092v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "LLM-Based Insight Extraction for Contact Center Analytics and Cost-Efficient Deployment", "abstract": "Large Language Models have transformed the Contact Center industry,\nmanifesting in enhanced self-service tools, streamlined administrative\nprocesses, and augmented agent productivity. This paper delineates our system\nthat automates call driver generation, which serves as the foundation for tasks\nsuch as topic modeling, incoming call classification, trend detection, and FAQ\ngeneration, delivering actionable insights for contact center agents and\nadministrators to consume. We present a cost-efficient LLM system design, with\n1) a comprehensive evaluation of proprietary, open-weight, and fine-tuned\nmodels and 2) cost-efficient strategies, and 3) the corresponding cost analysis\nwhen deployed in production environments.", "published": "2025-03-24 19:22:32", "link": "http://arxiv.org/abs/2503.19090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology Reports", "abstract": "Population-based cancer registries (PBCRs) face a significant bottleneck in\nmanually extracting data from unstructured pathology reports, a process crucial\nfor tasks like tumor group assignment, which can consume 900 person-hours for\napproximately 100,000 reports. To address this, we introduce ELM (Ensemble of\nLanguage Models), a novel ensemble-based approach leveraging both small\nlanguage models (SLMs) and large language models (LLMs). ELM utilizes six\nfine-tuned SLMs, where three SLMs use the top part of the pathology report and\nthree SLMs use the bottom part. This is done to maximize report coverage. ELM\nrequires five-out-of-six agreement for a tumor group classification.\nDisagreements are arbitrated by an LLM with a carefully curated prompt. Our\nevaluation across nineteen tumor groups demonstrates ELM achieves an average\nprecision and recall of 0.94, outperforming single-model and\nensemble-without-LLM approaches. Deployed at the British Columbia Cancer\nRegistry, ELM demonstrates how LLMs can be successfully applied in a PBCR\nsetting to achieve state-of-the-art results and significantly enhance\noperational efficiencies, saving hundreds of person-hours annually.", "published": "2025-03-24 19:21:53", "link": "http://arxiv.org/abs/2503.21800v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LookAhead Tuning: Safer Language Models via Partial Answer Previews", "abstract": "Fine-tuning enables large language models (LLMs) to adapt to specific\ndomains, but often undermines their previously established safety alignment. To\nmitigate the degradation of model safety during fine-tuning, we introduce\nLookAhead Tuning, which comprises two simple, low-resource, and effective\ndata-driven methods that modify training data by previewing partial answer\nprefixes. Both methods aim to preserve the model's inherent safety mechanisms\nby minimizing perturbations to initial token distributions. Comprehensive\nexperiments demonstrate that LookAhead Tuning effectively maintains model\nsafety without sacrificing robust performance on downstream tasks. Our findings\nposition LookAhead Tuning as a reliable and efficient solution for the safe and\neffective adaptation of LLMs. Code is released at\nhttps://github.com/zjunlp/LookAheadTuning.", "published": "2025-03-24 18:11:42", "link": "http://arxiv.org/abs/2503.19041v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Exploring Training and Inference Scaling Laws in Generative Retrieval", "abstract": "Generative retrieval has emerged as a novel paradigm that leverages large\nlanguage models (LLMs) to autoregressively generate document identifiers.\nAlthough promising, the mechanisms that underpin its performance and\nscalability remain largely unclear. We conduct a systematic investigation of\ntraining and inference scaling laws in generative retrieval, exploring how\nmodel size, training data scale, and inference-time compute jointly influence\nretrieval performance. To address the lack of suitable metrics, we propose a\nnovel evaluation measure inspired by contrastive entropy and generation loss,\nproviding a continuous performance signal that enables robust comparisons\nacross diverse generative retrieval methods. Our experiments show that\nn-gram-based methods demonstrate strong alignment with both training and\ninference scaling laws, especially when paired with larger LLMs. Furthermore,\nincreasing inference computation yields substantial performance gains,\nrevealing that generative retrieval can significantly benefit from higher\ncompute budgets at inference. Across these settings, LLaMA models consistently\noutperform T5 models, suggesting a particular advantage for larger decoder-only\nmodels in generative retrieval. Taken together, our findings underscore that\nmodel sizes, data availability, and inference computation interact to unlock\nthe full potential of generative retrieval, offering new insights for designing\nand optimizing future systems.", "published": "2025-03-24 17:59:03", "link": "http://arxiv.org/abs/2503.18941v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "xKV: Cross-Layer SVD for KV-Cache Compression", "abstract": "Large Language Models (LLMs) with long context windows enable powerful\napplications but come at the cost of high memory consumption to store the Key\nand Value states (KV-Cache). Recent studies attempted to merge KV-cache from\nmultiple layers into shared representations, yet these approaches either\nrequire expensive pretraining or rely on assumptions of high per-token cosine\nsimilarity across layers which generally does not hold in practice. We find\nthat the dominant singular vectors are remarkably well-aligned across multiple\nlayers of the KV-Cache. Exploiting this insight, we propose xKV, a simple\npost-training method that applies Singular Value Decomposition (SVD) on the\nKV-Cache of grouped layers. xKV consolidates the KV-Cache of multiple layers\ninto a shared low-rank subspace, significantly reducing KV-Cache sizes. Through\nextensive evaluations on the RULER long-context benchmark with widely-used LLMs\n(e.g., Llama-3.1 and Qwen2.5), xKV achieves up to 6.8x higher compression rates\nthan state-of-the-art inter-layer technique while improving accuracy by 2.7%.\nMoreover, xKV is compatible with the emerging Multi-Head Latent Attention (MLA)\n(e.g., DeepSeek-Coder-V2), yielding a notable 3x compression rates on coding\ntasks without performance degradation. These results highlight xKV's strong\ncapability and versatility in addressing memory bottlenecks for long-context\nLLM inference. Our code is publicly available at:\nhttps://github.com/abdelfattah-lab/xKV.", "published": "2025-03-24 17:06:37", "link": "http://arxiv.org/abs/2503.18893v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild", "abstract": "DeepSeek-R1 has shown that long chain-of-thought (CoT) reasoning can\nnaturally emerge through a simple reinforcement learning (RL) framework with\nrule-based rewards, where the training may directly start from the base\nmodels-a paradigm referred to as zero RL training. Most recent efforts to\nreproduce zero RL training have primarily focused on the Qwen2.5 model series,\nwhich may not be representative as we find the base models already exhibit\nstrong instruction-following and self-reflection abilities. In this work, we\ninvestigate zero RL training across 10 diverse base models, spanning different\nfamilies and sizes including LLama3-8B, Mistral-7B/24B, DeepSeek-Math-7B,\nQwen2.5-math-7B, and all Qwen2.5 models from 0.5B to 32B. Leveraging several\nkey design strategies-such as adjusting format reward and controlling query\ndifficulty-we achieve substantial improvements in both reasoning accuracy and\nresponse length across most settings. However, by carefully monitoring the\ntraining dynamics, we observe that different base models exhibit distinct\npatterns during training. For instance, the increased response length does not\nalways correlate with the emergence of certain cognitive behaviors such as\nverification (i.e., the \"aha moment\"). Notably, we observe the \"aha moment\" for\nthe first time in small models not from the Qwen family. We share the key\ndesigns that enable successful zero RL training, along with our findings and\npractices. To facilitate further research, we open-source the code, models, and\nanalysis tools.", "published": "2025-03-24 17:06:10", "link": "http://arxiv.org/abs/2503.18892v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration", "abstract": "Multi-agent systems (MAS) based on large language models (LLMs) have\ndemonstrated significant potential in collaborative problem-solving. However,\nthey still face substantial challenges of low communication efficiency and\nsuboptimal task performance, making the careful design of the agents'\ncommunication topologies particularly important. Inspired by the management\ntheory that roles in an efficient team are often dynamically adjusted, we\npropose AgentDropout, which identifies redundant agents and communication\nacross different communication rounds by optimizing the adjacency matrices of\nthe communication graphs and eliminates them to enhance both token efficiency\nand task performance. Compared to state-of-the-art methods, AgentDropout\nachieves an average reduction of 21.6% in prompt token consumption and 18.4% in\ncompletion token consumption, along with a performance improvement of 1.14 on\nthe tasks. Furthermore, the extended experiments demonstrate that AgentDropout\nachieves notable domain transferability and structure robustness, revealing its\nreliability and effectiveness. We release our code at\nhttps://github.com/wangzx1219/AgentDropout.", "published": "2025-03-24 17:04:55", "link": "http://arxiv.org/abs/2503.18891v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Toward building next-generation Geocoding systems: a systematic review", "abstract": "Geocoding systems are widely used in both scientific research for spatial\nanalysis and everyday life through location-based services. The quality of\ngeocoded data significantly impacts subsequent processes and applications,\nunderscoring the need for next-generation systems. In response to this demand,\nthis review first examines the evolving requirements for geocoding inputs and\noutputs across various scenarios these systems must address. It then provides a\ndetailed analysis of how to construct such systems by breaking them down into\nkey functional components and reviewing a broad spectrum of existing\napproaches, from traditional rule-based methods to advanced techniques in\ninformation retrieval, natural language processing, and large language models.\nFinally, we identify opportunities to improve next-generation geocoding systems\nin light of recent technological advances.", "published": "2025-03-24 17:00:13", "link": "http://arxiv.org/abs/2503.18888v1", "categories": ["cs.SE", "cs.CL", "cs.IR"], "primary_category": "cs.SE"}
{"title": "I Have Covered All the Bases Here: Interpreting Reasoning Features in Large Language Models via Sparse Autoencoders", "abstract": "Large Language Models (LLMs) have achieved remarkable success in natural\nlanguage processing. Recent advances have led to the developing of a new class\nof reasoning LLMs; for example, open-source DeepSeek-R1 has achieved\nstate-of-the-art performance by integrating deep thinking and complex\nreasoning. Despite these impressive capabilities, the internal reasoning\nmechanisms of such models remain unexplored. In this work, we employ Sparse\nAutoencoders (SAEs), a method to learn a sparse decomposition of latent\nrepresentations of a neural network into interpretable features, to identify\nfeatures that drive reasoning in the DeepSeek-R1 series of models. First, we\npropose an approach to extract candidate ''reasoning features'' from SAE\nrepresentations. We validate these features through empirical analysis and\ninterpretability methods, demonstrating their direct correlation with the\nmodel's reasoning abilities. Crucially, we demonstrate that steering these\nfeatures systematically enhances reasoning performance, offering the first\nmechanistic account of reasoning in LLMs. Code available at\nhttps://github.com/AIRI-Institute/SAE-Reasoning", "published": "2025-03-24 16:54:26", "link": "http://arxiv.org/abs/2503.18878v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning to Learn from Latent Thoughts", "abstract": "Compute scaling for language model (LM) pretraining has outpaced the growth\nof human-written texts, leading to concerns that data will become the\nbottleneck to LM scaling. To continue scaling pretraining in this\ndata-constrained regime, we propose that explicitly modeling and inferring the\nlatent thoughts that underlie the text generation process can significantly\nimprove pretraining data efficiency. Intuitively, our approach views web text\nas the compressed final outcome of a verbose human thought process and that the\nlatent thoughts contain important contextual knowledge and reasoning steps that\nare critical to data-efficient learning. We empirically demonstrate the\neffectiveness of our approach through data-constrained continued pretraining\nfor math. We first show that synthetic data approaches to inferring latent\nthoughts significantly improve data efficiency, outperforming training on the\nsame amount of raw data (5.7\\% $\\rightarrow$ 25.4\\% on MATH). Furthermore, we\ndemonstrate latent thought inference without a strong teacher, where an LM\nbootstraps its own performance by using an EM algorithm to iteratively improve\nthe capability of the trained LM and the quality of thought-augmented\npretraining data. We show that a 1B LM can bootstrap its performance across at\nleast three iterations and significantly outperform baselines trained on raw\ndata, with increasing gains from additional inference compute when performing\nthe E-step. The gains from inference scaling and EM iterations suggest new\nopportunities for scaling data-constrained pretraining.", "published": "2025-03-24 16:41:23", "link": "http://arxiv.org/abs/2503.18866v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "EconEvals: Benchmarks and Litmus Tests for LLM Agents in Unknown Environments", "abstract": "We develop benchmarks for LLM agents that act in, learn from, and strategize\nin unknown environments, the specifications of which the LLM agent must learn\nover time from deliberate exploration. Our benchmarks consist of\ndecision-making tasks derived from key problems in economics. To forestall\nsaturation, the benchmark tasks are synthetically generated with scalable\ndifficulty levels. Additionally, we propose litmus tests, a new kind of\nquantitative measure for LLMs and LLM agents. Unlike benchmarks, litmus tests\nquantify differences in character, values, and tendencies of LLMs and LLM\nagents, by considering their behavior when faced with tradeoffs (e.g.,\nefficiency versus equality) where there is no objectively right or wrong\nbehavior. Overall, our benchmarks and litmus tests assess the abilities and\ntendencies of LLM agents in tackling complex economic problems in diverse\nsettings spanning procurement, scheduling, task allocation, and pricing --\napplications that should grow in importance as such agents are further\nintegrated into the economy.", "published": "2025-03-24 16:06:04", "link": "http://arxiv.org/abs/2503.18825v1", "categories": ["cs.AI", "cs.CL", "cs.GT"], "primary_category": "cs.AI"}
{"title": "REALM: A Dataset of Real-World LLM Use Cases", "abstract": "Large Language Models, such as the GPT series, have driven significant\nindustrial applications, leading to economic and societal transformations.\nHowever, a comprehensive understanding of their real-world applications remains\nlimited. To address this, we introduce REALM, a dataset of over 94,000 LLM use\ncases collected from Reddit and news articles. REALM captures two key\ndimensions: the diverse applications of LLMs and the demographics of their\nusers. It categorizes LLM applications and explores how users' occupations\nrelate to the types of applications they use. By integrating real-world data,\nREALM offers insights into LLM adoption across different domains, providing a\nfoundation for future research on their evolving societal roles. A dedicated\ndashboard https://realm-e7682.web.app/ presents the data.", "published": "2025-03-24 15:39:25", "link": "http://arxiv.org/abs/2503.18792v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs Decoding with Low-Bit KV Cache", "abstract": "The growing adoption of long-context Large Language Models (LLMs) has\nintroduced significant memory and computational challenges in autoregressive\ndecoding due to the expanding Key-Value (KV) cache. KV cache quantization has\nemerged as a promising solution, with prior work showing that 4-bit or even\n2-bit quantization can maintain model accuracy while reducing memory costs.\nHowever, despite these benefits, preliminary implementations for the low-bit KV\ncache struggle to deliver the expected speedup due to quantization and\ndequantization overheads and the lack of Tensor Cores utilization. In this\nwork, we propose BitDecoding, a GPU-optimized framework that unlocks Tensor\nCores for efficient decoding with low-bit KV cache. Efficiently leveraging\nTensor Cores for low-bit KV cache is challenging due to the dynamic nature of\nKV cache generation at each decoding step. BitDecoding addresses these\nchallenges with a Tensor Cores-Centric BitFusion Scheme that ensures data\nlayout compatibility to enable high utilization of Tensor Cores. Additionally,\nBitDecoding incorporates a warp-efficient parallel decoding kernel and a\nfine-grained asynchronous pipeline, minimizing dequantization overhead and\nimproving computational efficiency. Experiments show that BitDecoding achieves\nup to 7.5x speedup on RTX 4090, 4.8x on A100, and 8.9x on H100, compared to\nFP16 FlashDecoding-v2. It also outperforms the state-of-the-art low-bit KV\ncache implementation (QServe) by up to 4.3x. On LLaMA-3.1-8B with a 128K\nsequence length, BitDecoding reduces single-batch decoding latency by 3x,\ndemonstrating its effectiveness in long-context generation scenarios. The code\nis available at https://github.com/DD-DuDa/BitDecoding.", "published": "2025-03-24 15:22:41", "link": "http://arxiv.org/abs/2503.18773v1", "categories": ["cs.AR", "cs.AI", "cs.CL", "cs.PF"], "primary_category": "cs.AR"}
{"title": "AlphaSpace: Enabling Robotic Actions through Semantic Tokenization and Symbolic Reasoning", "abstract": "This paper presents AlphaSpace, a novel methodology designed to enhance the\nspatial reasoning capabilities of language models for robotic manipulation in\n3D Cartesian space. AlphaSpace employs a hierarchical semantics-based\ntokenization strategy that encodes spatial information at both coarse and\nfine-grained levels. Our approach represents objects with their attributes,\npositions, and height information through structured tokens, enabling precise\nspatial reasoning without relying on traditional vision-based embeddings. This\napproach enables LLMs to accurately manipulate objects by positioning them at\nspecific (x, y, z) coordinates. Experimental results suggest that AlphaSpace\ndemonstrates promising potential for improving manipulation tasks, achieving a\ntotal accuracy of 66.67%, compared to 37.5% for GPT-4o and 29.17% for Claude\n3.5 Sonnet. These results demonstrate the potential of structured spatial\nencoding for manipulation tasks and warrant further exploration.", "published": "2025-03-24 15:16:51", "link": "http://arxiv.org/abs/2503.18769v2", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Synthetic Function Demonstrations Improve Generation in Low-Resource Programming Languages", "abstract": "A key consideration when training an LLM is whether the target language is\nmore or less resourced, whether this is English compared to Welsh, or Python\ncompared to Excel. Typical training data for programming languages consist of\nreal program demonstrations coupled with human-written comments. Here we\npresent novel approaches to the creation of such data for low resource\nprogramming languages. We generate fully-synthetic, textbook-quality\ndemonstrations of common library functions in an example domain of Excel\nformulas, using a teacher model. We then finetune an underperforming student\nmodel, and show improvement on 2 question-answering datasets recast into the\nExcel domain. We show advantages of finetuning over standard, off-the-shelf RAG\napproaches, which can offer only modest improvement due to the unfamiliar\ntarget domain.", "published": "2025-03-24 15:09:03", "link": "http://arxiv.org/abs/2503.18760v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Construction Identification and Disambiguation Using BERT: A Case Study of NPN", "abstract": "Construction Grammar hypothesizes that knowledge of a language consists\nchiefly of knowledge of form-meaning pairs (''constructions'') that include\nvocabulary, general grammar rules, and even idiosyncratic patterns. Recent work\nhas shown that transformer language models represent at least some\nconstructional patterns, including ones where the construction is rare overall.\nIn this work, we probe BERT's representation of the form and meaning of a minor\nconstruction of English, the NPN (noun-preposition-noun) construction --\nexhibited in such expressions as face to face and day to day -- which is known\nto be polysemous. We construct a benchmark dataset of semantically annotated\ncorpus instances (including distractors that superficially resemble the\nconstruction). With this dataset, we train and evaluate probing classifiers.\nThey achieve decent discrimination of the construction from distractors, as\nwell as sense disambiguation among true instances of the construction,\nrevealing that BERT embeddings carry indications of the construction's\nsemantics. Moreover, artificially permuting the word order of true construction\ninstances causes them to be rejected, indicating sensitivity to matters of\nform. We conclude that BERT does latently encode at least some knowledge of the\nNPN construction going beyond a surface syntactic pattern and lexical cues.", "published": "2025-03-24 14:59:39", "link": "http://arxiv.org/abs/2503.18751v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Predicting the Road Ahead: A Knowledge Graph based Foundation Model for Scene Understanding in Autonomous Driving", "abstract": "The autonomous driving field has seen remarkable advancements in various\ntopics, such as object recognition, trajectory prediction, and motion planning.\nHowever, current approaches face limitations in effectively comprehending the\ncomplex evolutions of driving scenes over time. This paper proposes FM4SU, a\nnovel methodology for training a symbolic foundation model (FM) for scene\nunderstanding in autonomous driving. It leverages knowledge graphs (KGs) to\ncapture sensory observation along with domain knowledge such as road topology,\ntraffic rules, or complex interactions between traffic participants. A bird's\neye view (BEV) symbolic representation is extracted from the KG for each\ndriving scene, including the spatio-temporal information among the objects\nacross the scenes. The BEV representation is serialized into a sequence of\ntokens and given to pre-trained language models (PLMs) for learning an inherent\nunderstanding of the co-occurrence among driving scene elements and generating\npredictions on the next scenes. We conducted a number of experiments using the\nnuScenes dataset and KG in various scenarios. The results demonstrate that\nfine-tuned models achieve significantly higher accuracy in all tasks. The\nfine-tuned T5 model achieved a next scene prediction accuracy of 86.7%. This\npaper concludes that FM4SU offers a promising foundation for developing more\ncomprehensive models for scene understanding in autonomous driving.", "published": "2025-03-24 14:38:25", "link": "http://arxiv.org/abs/2503.18730v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Acquisition of Discrete Grammatical Categories", "abstract": "This article presents experiments performed using a computational laboratory\nenvironment for language acquisition experiments. It implements a multi-agent\nsystem consisting of two agents: an adult language model and a daughter\nlanguage model that aims to learn the mother language. Crucially, the daughter\nagent does not have access to the internal knowledge of the mother language\nmodel but only to the language exemplars the mother agent generates. These\nexperiments illustrate how this system can be used to acquire abstract\ngrammatical knowledge. We demonstrate how statistical analyses of patterns in\nthe input data corresponding to grammatical categories yield discrete\ngrammatical rules. These rules are subsequently added to the grammatical\nknowledge of the daughter language model. To this end, hierarchical\nagglomerative cluster analysis was applied to the utterances consecutively\ngenerated by the mother language model. It is argued that this procedure can be\nused to acquire structures resembling grammatical categories proposed by\nlinguists for natural languages. Thus, it is established that non-trivial\ngrammatical knowledge has been acquired. Moreover, the parameter configuration\nof this computational laboratory environment determined using training data\ngenerated by the mother language model is validated in a second experiment with\na test set similarly resulting in the acquisition of non-trivial categories.", "published": "2025-03-24 14:15:08", "link": "http://arxiv.org/abs/2503.18702v1", "categories": ["cs.CL", "I.2.6; I.2.7; J.5"], "primary_category": "cs.CL"}
{"title": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models", "abstract": "Sarcasm detection, as a crucial research direction in the field of Natural\nLanguage Processing (NLP), has attracted widespread attention. Traditional\nsarcasm detection tasks have typically focused on single-modal approaches\n(e.g., text), but due to the implicit and subtle nature of sarcasm, such\nmethods often fail to yield satisfactory results. In recent years, researchers\nhave shifted the focus of sarcasm detection to multi-modal approaches. However,\neffectively leveraging multi-modal information to accurately identify sarcastic\ncontent remains a challenge that warrants further exploration. Leveraging the\npowerful integrated processing capabilities of Multi-Modal Large Language\nModels (MLLMs) for various information sources, we propose an innovative\nmulti-modal Commander-GPT framework. Inspired by military strategy, we first\ndecompose the sarcasm detection task into six distinct sub-tasks. A central\ncommander (decision-maker) then assigns the best-suited large language model to\naddress each specific sub-task. Ultimately, the detection results from each\nmodel are aggregated to identify sarcasm. We conducted extensive experiments on\nMMSD and MMSD 2.0, utilizing four multi-modal large language models and six\nprompting strategies. Our experiments demonstrate that our approach achieves\nstate-of-the-art performance, with a 19.3% improvement in F1 score, without\nnecessitating fine-tuning or ground-truth rationales.", "published": "2025-03-24 13:53:00", "link": "http://arxiv.org/abs/2503.18681v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ArchSeek: Retrieving Architectural Case Studies Using Vision-Language Models", "abstract": "Efficiently searching for relevant case studies is critical in architectural\ndesign, as designers rely on precedent examples to guide or inspire their\nongoing projects. However, traditional text-based search tools struggle to\ncapture the inherently visual and complex nature of architectural knowledge,\noften leading to time-consuming and imprecise exploration. This paper\nintroduces ArchSeek, an innovative case study search system with recommendation\ncapability, tailored for architecture design professionals. Powered by the\nvisual understanding capabilities from vision-language models and cross-modal\nembeddings, it enables text and image queries with fine-grained control, and\ninteraction-based design case recommendations. It offers architects a more\nefficient, personalized way to discover design inspirations, with potential\napplications across other visually driven design fields. The source code is\navailable at https://github.com/danruili/ArchSeek.", "published": "2025-03-24 13:50:23", "link": "http://arxiv.org/abs/2503.18680v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "abstract": "Agents built on LLMs are increasingly deployed across diverse domains,\nautomating complex decision-making and task execution. However, their autonomy\nintroduces safety risks, including security vulnerabilities, legal violations,\nand unintended harmful actions. Existing mitigation methods, such as\nmodel-based safeguards and early enforcement strategies, fall short in\nrobustness, interpretability, and adaptability. To address these challenges, we\npropose AgentSpec, a lightweight domain-specific language for specifying and\nenforcing runtime constraints on LLM agents. With AgentSpec, users define\nstructured rules that incorporate triggers, predicates, and enforcement\nmechanisms, ensuring agents operate within predefined safety boundaries. We\nimplement AgentSpec across multiple domains, including code execution, embodied\nagents, and autonomous driving, demonstrating its adaptability and\neffectiveness. Our evaluation shows that AgentSpec successfully prevents unsafe\nexecutions in over 90% of code agent cases, eliminates all hazardous actions in\nembodied agent tasks, and enforces 100% compliance by autonomous vehicles\n(AVs). Despite its strong safety guarantees, AgentSpec remains computationally\nlightweight, with overheads in milliseconds. By combining interpretability,\nmodularity, and efficiency, AgentSpec provides a practical and scalable\nsolution for enforcing LLM agent safety across diverse applications. We also\nautomate the generation of rules using LLMs and assess their effectiveness. Our\nevaluation shows that the rules generated by OpenAI o1 achieve a precision of\n95.56% and recall of 70.96% for embodied agents, successfully identifying\n87.26% of the risky code, and prevent AVs from breaking laws in 5 out of 8\nscenarios.", "published": "2025-03-24 13:31:48", "link": "http://arxiv.org/abs/2503.18666v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SE-GNN: Seed Expanded-Aware Graph Neural Network with Iterative Optimization for Semi-supervised Entity Alignment", "abstract": "Entity alignment aims to use pre-aligned seed pairs to find other equivalent\nentities from different knowledge graphs (KGs) and is widely used in graph\nfusion-related fields. However, as the scale of KGs increases, manually\nannotating pre-aligned seed pairs becomes difficult. Existing research utilizes\nentity embeddings obtained by aggregating single structural information to\nidentify potential seed pairs, thus reducing the reliance on pre-aligned seed\npairs. However, due to the structural heterogeneity of KGs, the quality of\npotential seed pairs obtained using only a single structural information is not\nideal. In addition, although existing research improves the quality of\npotential seed pairs through semi-supervised iteration, they underestimate the\nimpact of embedding distortion produced by noisy seed pairs on the alignment\neffect. In order to solve the above problems, we propose a seed expanded-aware\ngraph neural network with iterative optimization for semi-supervised entity\nalignment, named SE-GNN. First, we utilize the semantic attributes and\nstructural features of entities, combined with a conditional filtering\nmechanism, to obtain high-quality initial potential seed pairs. Next, we\ndesigned a local and global awareness mechanism. It introduces initial\npotential seed pairs and combines local and global information to obtain a more\ncomprehensive entity embedding representation, which alleviates the impact of\nKGs structural heterogeneity and lays the foundation for the optimization of\ninitial potential seed pairs. Then, we designed the threshold nearest neighbor\nembedding correction strategy. It combines the similarity threshold and the\nbidirectional nearest neighbor method as a filtering mechanism to select\niterative potential seed pairs and also uses an embedding correction strategy\nto eliminate the embedding distortion.", "published": "2025-03-24 13:28:49", "link": "http://arxiv.org/abs/2503.20801v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ZeroLM: Data-Free Transformer Architecture Search for Language Models", "abstract": "Neural architecture search (NAS) provides a systematic framework for\nautomating the design of neural network architectures, yet its widespread\nadoption is hindered by prohibitive computational requirements. Existing\nzero-cost proxy methods, while reducing search overhead, demonstrate inadequate\nperformance in architecture ranking tasks, particularly for Transformer-based\nmodels where they often underperform simple parameter counting metrics. Current\nautomated proxy discovery approaches suffer from extended search times,\nsusceptibility to data overfitting, and structural complexity. This paper\nintroduces a novel zero-cost proxy methodology that quantifies model capacity\nthrough efficient weight statistics computation while decomposing Transformer\narchitectures into functionally distinct sub-modules, thereby optimizing the\nbalance of their contributions to overall performance. Our comprehensive\nevaluation demonstrates the superiority of this approach, achieving a\nSpearman's rho of 0.76 and Kendall's tau of 0.53 on the FlexiBERT benchmark.\nThe proposed method exhibits exceptional computational efficiency while\nmaintaining robust performance across diverse NAS benchmark tasks, offering a\npractical solution for large-scale architecture search.", "published": "2025-03-24 13:11:22", "link": "http://arxiv.org/abs/2503.18646v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LANGALIGN: Enhancing Non-English Language Models via Cross-Lingual Embedding Alignment", "abstract": "While Large Language Models have gained attention, many service developers\nstill rely on embedding-based models due to practical constraints. In such\ncases, the quality of fine-tuning data directly impacts performance, and\nEnglish datasets are often used as seed data for training non-English models.\nIn this study, we propose LANGALIGN, which enhances target language processing\nby aligning English embedding vectors with those of the target language at the\ninterface between the language model and the task header. Experiments on\nKorean, Japanese, and Chinese demonstrate that LANGALIGN significantly improves\nperformance across all three languages. Additionally, we show that LANGALIGN\ncan be applied in reverse to convert target language data into a format that an\nEnglish-based model can process.", "published": "2025-03-24 12:02:26", "link": "http://arxiv.org/abs/2503.18603v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LinkAlign: Scalable Schema Linking for Real-World Large-Scale Multi-Database Text-to-SQL", "abstract": "Schema linking is a critical bottleneck in achieving human-level performance\nin Text-to-SQL tasks, particularly in real-world large-scale multi-database\nscenarios. Addressing schema linking faces two major challenges: (1) Database\nRetrieval: selecting the correct database from a large schema pool in\nmulti-database settings, while filtering out irrelevant ones. (2) Schema Item\nGrounding: accurately identifying the relevant tables and columns from within a\nlarge and redundant schema for SQL generation. To address this, we introduce\nLinkAlign, a novel framework that can effectively adapt existing baselines to\nreal-world environments by systematically addressing schema linking. Our\nframework comprises three key steps: multi-round semantic enhanced retrieval\nand irrelevant information isolation for Challenge 1, and schema extraction\nenhancement for Challenge 2. We evaluate our method performance of schema\nlinking on the SPIDER and BIRD benchmarks, and the ability to adapt existing\nText-to-SQL models to real-world environments on the SPIDER 2.0-lite benchmark.\nExperiments show that LinkAlign outperforms existing baselines in\nmulti-database settings, demonstrating its effectiveness and robustness. On the\nother hand, our method ranks highest among models excluding those using long\nchain-of-thought reasoning LLMs. This work bridges the gap between current\nresearch and real-world scenarios, providing a practical solution for robust\nand scalable schema linking. The codes are available at\nhttps://github.com/Satissss/LinkAlign.", "published": "2025-03-24 11:53:06", "link": "http://arxiv.org/abs/2503.18596v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ClinText-SP and RigoBERTa Clinical: a new set of open resources for Spanish Clinical NLP", "abstract": "We present a novel contribution to Spanish clinical natural language\nprocessing by introducing the largest publicly available clinical corpus,\nClinText-SP, along with a state-of-the-art clinical encoder language model,\nRigoBERTa Clinical. Our corpus was meticulously curated from diverse open\nsources, including clinical cases from medical journals and annotated corpora\nfrom shared tasks, providing a rich and diverse dataset that was previously\ndifficult to access. RigoBERTa Clinical, developed through domain-adaptive\npretraining on this comprehensive dataset, significantly outperforms existing\nmodels on multiple clinical NLP benchmarks. By publicly releasing both the\ndataset and the model, we aim to empower the research community with robust\nresources that can drive further advancements in clinical NLP and ultimately\ncontribute to improved healthcare applications.", "published": "2025-03-24 11:52:17", "link": "http://arxiv.org/abs/2503.18594v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dense Retrieval for Low Resource Languages -- the Case of Amharic Language", "abstract": "This paper reports some difficulties and some results when using dense\nretrievers on Amharic, one of the low-resource languages spoken by 120 millions\npopulations. The efforts put and difficulties faced by University Addis Ababa\ntoward Amharic Information Retrieval will be developed during the presentation.", "published": "2025-03-24 11:26:40", "link": "http://arxiv.org/abs/2503.18570v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Distil-xLSTM: Learning Attention Mechanisms through Recurrent Structures", "abstract": "The current era of Natural Language Processing (NLP) is dominated by\nTransformer models. However, novel architectures relying on recurrent\nmechanisms, such as xLSTM and Mamba, have been proposed as alternatives to\nattention-based models. Although computation is done differently than with the\nattention mechanism mechanism, these recurrent models yield good results and\nsometimes even outperform state-of-the-art attention-based models. In this\nwork, we propose Distil-xLSTM, an xLSTM-based Small Language Model (SLM)\ntrained by distilling knowledge from a Large Language Model (LLM) that shows\npromising results while being compute and scale efficient. Our Distil-xLSTM\nfocuses on approximating a transformer-based model attention parametrization\nusing its recurrent sequence mixing components and shows good results with\nminimal training.", "published": "2025-03-24 11:18:25", "link": "http://arxiv.org/abs/2503.18565v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Self-Reported Confidence of Large Language Models in Gastroenterology: Analysis of Commercial, Open-Source, and Quantized Models", "abstract": "This study evaluated self-reported response certainty across several large\nlanguage models (GPT, Claude, Llama, Phi, Mistral, Gemini, Gemma, and Qwen)\nusing 300 gastroenterology board-style questions. The highest-performing models\n(GPT-o1 preview, GPT-4o, and Claude-3.5-Sonnet) achieved Brier scores of\n0.15-0.2 and AUROC of 0.6. Although newer models demonstrated improved\nperformance, all exhibited a consistent tendency towards overconfidence.\nUncertainty estimation presents a significant challenge to the safe use of LLMs\nin healthcare. Keywords: Large Language Models; Confidence Elicitation;\nArtificial Intelligence; Gastroenterology; Uncertainty Quantification", "published": "2025-03-24 11:16:41", "link": "http://arxiv.org/abs/2503.18562v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Instruction-Aligned Visual Attention for Mitigating Hallucinations in Large Vision-Language Models", "abstract": "Despite the significant success of Large Vision-Language models(LVLMs), these\nmodels still suffer hallucinations when describing images, generating answers\nthat include non-existent objects. It is reported that these models tend to\nover-focus on certain irrelevant image tokens that do not contain critical\ninformation for answering the question and distort the output. To address this,\nwe propose an Instruction-Aligned Visual Attention(IAVA) approach, which\nidentifies irrelevant tokens by comparing changes in attention weights under\ntwo different instructions. By applying contrastive decoding, we dynamically\nadjust the logits generated from original image tokens and irrelevant image\ntokens, reducing the model's over-attention to irrelevant information. The\nexperimental results demonstrate that IAVA consistently outperforms existing\ndecoding techniques on benchmarks such as MME, POPE, and TextVQA in mitigating\nobject hallucinations. Our IAVA approach is available online at\nhttps://github.com/Lee-lab558/IAVA.", "published": "2025-03-24 11:09:06", "link": "http://arxiv.org/abs/2503.18556v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Natural Language Processing for Electronic Health Records in Scandinavian Languages: Norwegian, Swedish, and Danish", "abstract": "Background: Clinical natural language processing (NLP) refers to the use of\ncomputational methods for extracting, processing, and analyzing unstructured\nclinical text data, and holds a huge potential to transform healthcare in\nvarious clinical tasks. Objective: The study aims to perform a systematic\nreview to comprehensively assess and analyze the state-of-the-art NLP methods\nfor the mainland Scandinavian clinical text. Method: A literature search was\nconducted in various online databases including PubMed, ScienceDirect, Google\nScholar, ACM digital library, and IEEE Xplore between December 2022 and\nFebruary 2024. Further, relevant references to the included articles were also\nused to solidify our search. The final pool includes articles that conducted\nclinical NLP in the mainland Scandinavian languages and were published in\nEnglish between 2010 and 2024. Results: Out of the 113 articles, 18% (n=21)\nfocus on Norwegian clinical text, 64% (n=72) on Swedish, 10% (n=11) on Danish,\nand 8% (n=9) focus on more than one language. Generally, the review identified\npositive developments across the region despite some observable gaps and\ndisparities between the languages. There are substantial disparities in the\nlevel of adoption of transformer-based models. In essential tasks such as\nde-identification, there is significantly less research activity focusing on\nNorwegian and Danish compared to Swedish text. Further, the review identified a\nlow level of sharing resources such as data, experimentation code, pre-trained\nmodels, and rate of adaptation and transfer learning in the region. Conclusion:\nThe review presented a comprehensive assessment of the state-of-the-art\nClinical NLP for electronic health records (EHR) text in mainland Scandinavian\nlanguages and, highlighted the potential barriers and challenges that hinder\nthe rapid advancement of the field in the region.", "published": "2025-03-24 10:47:32", "link": "http://arxiv.org/abs/2503.18539v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SciClaims: An End-to-End Generative System for Biomedical Claim Analysis", "abstract": "Validating key claims in scientific literature, particularly in biomedical\nresearch, is essential for ensuring accuracy and advancing knowledge. This\nprocess is critical in sectors like the pharmaceutical industry, where rapid\nscientific progress requires automation and deep domain expertise. However,\ncurrent solutions have significant limitations. They lack end-to-end pipelines\nencompassing all claim extraction, evidence retrieval, and verification steps;\nrely on complex NLP and information retrieval pipelines prone to multiple\nfailure points; and often fail to provide clear, user-friendly justifications\nfor claim verification outcomes. To address these challenges, we introduce\nSciClaims, an advanced system powered by state-of-the-art large language models\n(LLMs) that seamlessly integrates the entire scientific claim analysis process.\nSciClaims outperforms previous approaches in both claim extraction and\nverification without requiring additional fine-tuning, setting a new benchmark\nfor automated scientific claim analysis.", "published": "2025-03-24 10:31:31", "link": "http://arxiv.org/abs/2503.18526v1", "categories": ["cs.CL", "cs.AI", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Autoregressive Language Models for Knowledge Base Population: A case study in the space mission domain", "abstract": "Knowledge base population KBP plays a crucial role in populating and\nmaintaining knowledge bases up-to-date in organizations by leveraging domain\ncorpora. Motivated by the increasingly large context windows supported by large\nlanguage models, we propose to fine-tune an autoregressive language model for\nend-toend KPB. Our case study involves the population of a space mission\nknowledge graph. To fine-tune the model we generate a dataset for end-to-end\nKBP tapping into existing domain resources. Our case study shows that\nfine-tuned language models of limited size can achieve competitive and even\nhigher accuracy than larger models in the KBP task. Smaller models specialized\nfor KBP offer affordable deployment and lower-cost inference. Moreover, KBP\nspecialist models do not require the ontology to be included in the prompt,\nallowing for more space in the context for additional input text or output\nserialization.", "published": "2025-03-24 09:58:44", "link": "http://arxiv.org/abs/2503.18502v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Verbal Process Supervision Elicits Better Coding Agents", "abstract": "The emergence of large language models and their applications as AI agents\nhave significantly advanced state-of-the-art code generation benchmarks,\ntransforming modern software engineering tasks. However, even with test-time\ncomputed reasoning models, these systems still struggle with complex software\nengineering challenges. This work introduces CURA, a code understanding and\nreasoning agent system enhanced with verbal process supervision (VPS),\nachieving a 3.65\\% improvement over baseline models on challenging benchmarks\nlike BigCodeBench. Furthermore, CURA, when paired with the o3-mini model and\nVPS techniques, attains state-of-the-art performance. This work represents a\nstep forward in integrating reasoning-driven architectures with LLM-based code\ngeneration, enabling agentic reasoning for language models to solve complex\nsoftware engineering tasks.", "published": "2025-03-24 09:48:59", "link": "http://arxiv.org/abs/2503.18494v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Safeguarding Mobile GUI Agent via Logic-based Action Verification", "abstract": "Large Foundation Models (LFMs) have unlocked new possibilities in\nhuman-computer interaction, particularly with the rise of mobile Graphical User\nInterface (GUI) Agents capable of interpreting GUIs. These agents promise to\nrevolutionize mobile computing by allowing users to automate complex mobile\ntasks through simple natural language instructions. However, the inherent\nprobabilistic nature of LFMs, coupled with the ambiguity and context-dependence\nof mobile tasks, makes LFM-based automation unreliable and prone to errors. To\naddress this critical challenge, we introduce VeriSafe Agent (VSA): a formal\nverification system that serves as a logically grounded safeguard for Mobile\nGUI Agents. VSA is designed to deterministically ensure that an agent's actions\nstrictly align with user intent before conducting an action. At its core, VSA\nintroduces a novel autoformalization technique that translates natural language\nuser instructions into a formally verifiable specification, expressed in our\ndomain-specific language (DSL). This enables runtime, rule-based verification,\nallowing VSA to detect and prevent erroneous actions executing an action,\neither by providing corrective feedback or halting unsafe behavior. To the best\nof our knowledge, VSA is the first attempt to bring the rigor of formal\nverification to GUI agent. effectively bridging the gap between LFM-driven\nautomation and formal software verification. We implement VSA using\noff-the-shelf LLM services (GPT-4o) and evaluate its performance on 300 user\ninstructions across 18 widely used mobile apps. The results demonstrate that\nVSA achieves 94.3%-98.33% accuracy in verifying agent actions, representing a\nsignificant 20.4%-25.6% improvement over existing LLM-based verification\nmethods, and consequently increases the GUI agent's task completion rate by\n90%-130%.", "published": "2025-03-24 09:46:05", "link": "http://arxiv.org/abs/2503.18492v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "MAGIC-VQA: Multimodal And Grounded Inference with Commonsense Knowledge for Visual Question Answering", "abstract": "Visual Question Answering (VQA) requires reasoning across visual and textual\nmodalities, yet Large Vision-Language Models (LVLMs) often lack integrated\ncommonsense knowledge, limiting their robustness in real-world scenarios. To\naddress this, we introduce MAGIC-VQA, a novel framework that enhances VQA by\nsystematically integrating commonsense knowledge with LVLMs. MAGIC-VQA employs\na three-stage process: (1) Explicit Knowledge Integration from external\nsources, (2) By-Type Post-Processing for contextual refinement, and (3)\nImplicit Knowledge Augmentation using a Graph Neural Network (GNN) for\nstructured reasoning. While GNNs bring greater depth to structured inference,\nthey enable superior relational inference beyond LVLMs. MAGIC-VQA bridges a key\ngap by unifying commonsensse knowledge with LVLM-driven reasoning, eliminating\nthe need for extensive pre-training or complex prompt tuning. Our framework\nachieves state-of-the-art performance on benchmark datasets, significantly\nimproving commonsense reasoning in VQA.", "published": "2025-03-24 09:45:26", "link": "http://arxiv.org/abs/2503.18491v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Whispering in Amharic: Fine-tuning Whisper for Low-resource Language", "abstract": "This work explores fine-tuning OpenAI's Whisper automatic speech recognition\n(ASR) model for Amharic, a low-resource language, to improve transcription\naccuracy. While the foundational Whisper model struggles with Amharic due to\nlimited representation in its training data, we fine-tune it using datasets\nlike Mozilla Common Voice, FLEURS, and the BDU-speech dataset. The\nbest-performing model, Whispersmall-am, significantly improves when finetuned\non a mix of existing FLEURS data and new, unseen Amharic datasets. Training\nsolely on new data leads to poor performance, but combining it with FLEURS data\nreinforces the model, enabling better specialization in Amharic. We also\ndemonstrate that normalizing Amharic homophones significantly enhances Word\nError Rate (WER) and Bilingual Evaluation Understudy (BLEU) scores. This study\nunderscores the importance of fine-tuning strategies and dataset composition\nfor improving ASR in low-resource languages, providing insights for future\nAmharic speech recognition research.", "published": "2025-03-24 09:39:41", "link": "http://arxiv.org/abs/2503.18485v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PM4Bench: A Parallel Multilingual Multi-Modal Multi-task Benchmark for Large Vision Language Model", "abstract": "Existing multilingual benchmarks for Large Vision Language Models (LVLMs)\nsuffer from limitations including language-specific content biases, disjointed\nmultimodal input formats, and a lack of safety evaluation. To address these\ngaps, we propose PM4Bench, the first Parallel Multilingual Multi-Modal\nMulti-task Benchmark for LVLMs. PM4Bench features a parallel corpus design\nacross 10 languages, enabling fair and accurate cross-lingual comparisons. It\nincludes the vision setting where text and queries are embedded in images,\nrequiring LVLMs to simultaneously \"see\", \"read\", and \"think\", aligning with\nreal-world applications. Additionally, PM\\textsuperscript{4}Bench incorporates\nsafety evaluations, addressing critical oversight in existing multilingual\nbenchmarks. Using PM4Bench, we evaluate 11 mainstream LVLMs, revealing\nsignificant cross-linguistic performance disparities, particularly in vision\nsettings, and identifying OCR capability as a key determinant of these\nimbalances. We will release PM4Bench at https://github.com/opendatalab/PM4Bench .", "published": "2025-03-24 09:38:37", "link": "http://arxiv.org/abs/2503.18484v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Global-Local Tree Search in VLMs for 3D Indoor Scene Generation", "abstract": "Large Vision-Language Models (VLMs), such as GPT-4, have achieved remarkable\nsuccess across various fields. However, there are few studies on 3D indoor\nscene generation with VLMs. This paper considers this task as a planning\nproblem subject to spatial and layout common sense constraints. To solve the\nproblem with a VLM, we propose a new global-local tree search algorithm.\nGlobally, the method places each object sequentially and explores multiple\nplacements during each placement process, where the problem space is\nrepresented as a tree. To reduce the depth of the tree, we decompose the scene\nstructure hierarchically, i.e. room level, region level, floor object level,\nand supported object level. The algorithm independently generates the floor\nobjects in different regions and supported objects placed on different floor\nobjects. Locally, we also decompose the sub-task, the placement of each object,\ninto multiple steps. The algorithm searches the tree of problem space. To\nleverage the VLM model to produce positions of objects, we discretize the\ntop-down view space as a dense grid and fill each cell with diverse emojis to\nmake to cells distinct. We prompt the VLM with the emoji grid and the VLM\nproduces a reasonable location for the object by describing the position with\nthe name of emojis. The quantitative and qualitative experimental results\nillustrate our approach generates more plausible 3D scenes than\nstate-of-the-art approaches. Our source code is available at\nhttps://github.com/dw-dengwei/TreeSearchGen .", "published": "2025-03-24 09:21:13", "link": "http://arxiv.org/abs/2503.18476v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Words as Bridges: Exploring Computational Support for Cross-Disciplinary Translation Work", "abstract": "Scholars often explore literature outside of their home community of study.\nThis exploration process is frequently hampered by field-specific jargon. Past\ncomputational work often focuses on supporting translation work by removing\njargon through simplification and summarization; here, we explore a different\napproach that preserves jargon as useful bridges to new conceptual spaces.\nSpecifically, we cast different scholarly domains as different language-using\ncommunities, and explore how to adapt techniques from unsupervised\ncross-lingual alignment of word embeddings to explore conceptual alignments\nbetween domain-specific word embedding spaces.We developed a prototype\ncross-domain search engine that uses aligned domain-specific embeddings to\nsupport conceptual exploration, and tested this prototype in two case studies.\nWe discuss qualitative insights into the promises and pitfalls of this approach\nto translation work, and suggest design insights for future interfaces that\nprovide computational support for cross-domain information seeking.", "published": "2025-03-24 09:19:29", "link": "http://arxiv.org/abs/2503.18471v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "StableGS: A Floater-Free Framework for 3D Gaussian Splatting", "abstract": "Recent years have witnessed remarkable success of 3D Gaussian Splatting\n(3DGS) in novel view synthesis, surpassing prior differentiable rendering\nmethods in both quality and efficiency. However, its training process suffers\nfrom coupled opacity-color optimization that frequently converges to local\nminima, producing floater artifacts that degrade visual fidelity. We present\nStableGS, a framework that eliminates floaters through cross-view depth\nconsistency constraints while introducing a dual-opacity GS model to decouple\ngeometry and material properties of translucent objects. To further enhance\nreconstruction quality in weakly-textured regions, we integrate DUSt3R depth\nestimation, significantly improving geometric stability. Our method\nfundamentally addresses 3DGS training instabilities, outperforming existing\nstate-of-the-art methods across open-source datasets.", "published": "2025-03-24 09:02:51", "link": "http://arxiv.org/abs/2503.18458v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "On the Perception Bottleneck of VLMs for Chart Understanding", "abstract": "Chart understanding requires models to effectively analyze and reason about\nnumerical data, textual elements, and complex visual components. Our\nobservations reveal that the perception capabilities of existing large\nvision-language models (LVLMs) constitute a critical bottleneck in this\nprocess. In this study, we delve into this perception bottleneck by decomposing\nit into two components: the vision encoder bottleneck, where the visual\nrepresentation may fail to encapsulate the correct information, and the\nextraction bottleneck, where the language model struggles to extract the\nnecessary information from the provided visual representations. Through\ncomprehensive experiments, we find that (1) the information embedded within\nvisual representations is substantially richer than what is typically captured\nby linear extractors, such as the widely used retrieval accuracy metric; (2)\nWhile instruction tuning effectively enhances the extraction capability of\nLVLMs, the vision encoder remains a critical bottleneck, demanding focused\nattention and improvement. Therefore, we further enhance the visual encoder to\nmitigate the vision encoder bottleneck under a contrastive learning framework.\nEmpirical results demonstrate that our approach significantly mitigates the\nperception bottleneck and improves the ability of LVLMs to comprehend charts.\nCode is publicly available at https://github.com/hkust-nlp/Vision4Chart.", "published": "2025-03-24 08:33:58", "link": "http://arxiv.org/abs/2503.18435v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Teaching LLMs for Step-Level Automatic Math Correction via Reinforcement Learning", "abstract": "Automatic math correction aims to check students' solutions to mathematical\nproblems via artificial intelligence technologies. Most existing studies focus\non judging the final answer at the problem level, while they ignore detailed\nfeedback on each step in a math problem-solving process, which requires\nabilities of semantic understanding and reasoning. In this paper, we propose a\nreinforcement learning (RL)-based method to boost large language model (LLM)\nfor step-level automatic math correction, named StepAMC. Particularly, we\nconvert the step-level automatic math correction within the text classification\ntask into an RL problem to enhance the reasoning capabilities of LLMs. Then, we\ndesign a space-constrained policy network to improve the stability of RL. Then,\nwe introduce a fine-grained reward network to convert the binary human feedback\ninto a continuous value. We conduct extensive experiments over two benchmark\ndatasets and the results show that our model outperforms the eleven strong\nbaselines.", "published": "2025-03-24 08:28:34", "link": "http://arxiv.org/abs/2503.18432v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Solving Situation Puzzles with Large Language Model and External Reformulation", "abstract": "In recent years, large language models (LLMs) have shown an impressive\nability to perform arithmetic and symbolic reasoning tasks. However, we found\nthat LLMs (e.g., ChatGPT) cannot perform well on reasoning that requires\nmultiple rounds of dialogue, especially when solving situation puzzles.\nSpecifically, LLMs intend to ask very detailed questions focusing on a specific\naspect or same/similar questions after several rounds of Q&As. To help LLMs get\nout of the above dilemma, we propose a novel external reformulation\nmethodology, where the situation puzzle will be reformulated after several\nrounds of Q&A or when the LLMs raise an incorrect guess. Experiments show\nsuperior performance (e.g., win rate, number of question/guess attempts) of our\nmethod than directly using LLMs for solving situation puzzles, highlighting the\npotential of strategic problem reformulation to enhance the reasoning\ncapabilities of LLMs in complex interactive scenarios.", "published": "2025-03-24 07:05:55", "link": "http://arxiv.org/abs/2503.18394v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "J&H: Evaluating the Robustness of Large Language Models Under Knowledge-Injection Attacks in Legal Domain", "abstract": "As the scale and capabilities of Large Language Models (LLMs) increase, their\napplications in knowledge-intensive fields such as legal domain have garnered\nwidespread attention. However, it remains doubtful whether these LLMs make\njudgments based on domain knowledge for reasoning. If LLMs base their judgments\nsolely on specific words or patterns, rather than on the underlying logic of\nthe language, the ''LLM-as-judges'' paradigm poses substantial risks in the\nreal-world applications. To address this question, we propose a method of legal\nknowledge injection attacks for robustness testing, thereby inferring whether\nLLMs have learned legal knowledge and reasoning logic. In this paper, we\npropose J&H: an evaluation framework for detecting the robustness of LLMs under\nknowledge injection attacks in the legal domain. The aim of the framework is to\nexplore whether LLMs perform deductive reasoning when accomplishing legal\ntasks. To further this aim, we have attacked each part of the reasoning logic\nunderlying these tasks (major premise, minor premise, and conclusion\ngeneration). We have collected mistakes that legal experts might make in\njudicial decisions in the real world, such as typos, legal synonyms, inaccurate\nexternal legal statutes retrieval. However, in real legal practice, legal\nexperts tend to overlook these mistakes and make judgments based on logic.\nHowever, when faced with these errors, LLMs are likely to be misled by\ntypographical errors and may not utilize logic in their judgments. We conducted\nknowledge injection attacks on existing general and domain-specific LLMs.\nCurrent LLMs are not robust against the attacks employed in our experiments. In\naddition we propose and compare several methods to enhance the knowledge\nrobustness of LLMs.", "published": "2025-03-24 05:42:05", "link": "http://arxiv.org/abs/2503.18360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Writing Manner Gap in Visual Instruction Tuning by Creating LLM-aligned Instructions", "abstract": "In the realm of Large Multi-modal Models (LMMs), the instruction quality\nduring the visual instruction tuning stage significantly influences the\nperformance of modality alignment. In this paper, we assess the instruction\nquality from a unique perspective termed \\textbf{Writing Manner}, which\nencompasses the selection of vocabulary, grammar and sentence structure to\nconvey specific semantics. We argue that there exists a substantial writing\nmanner gap between the visual instructions and the base Large Language Models\n(LLMs) within LMMs. This gap forces the pre-trained base LLMs to deviate from\ntheir original writing styles, leading to capability degradation of both base\nLLMs and LMMs. To bridge the writing manner gap while preserving the original\nsemantics, we propose directly leveraging the base LLM to align the writing\nmanner of soft-format visual instructions with that of the base LLM itself,\nresulting in novel LLM-aligned instructions. The manual writing manner\nevaluation results demonstrate that our approach successfully minimizes the\nwriting manner gap. By utilizing LLM-aligned instructions, the baseline models\nLLaVA-7B and QwenVL demonstrate enhanced resistance to hallucinations and\nnon-trivial comprehensive improvements across all $15$ visual and language\nbenchmarks.", "published": "2025-03-24 03:59:06", "link": "http://arxiv.org/abs/2503.18320v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Surgical Action Planning with Large Language Models", "abstract": "In robot-assisted minimally invasive surgery, we introduce the Surgical\nAction Planning (SAP) task, which generates future action plans from visual\ninputs to address the absence of intraoperative predictive planning in current\nintelligent applications. SAP shows great potential for enhancing\nintraoperative guidance and automating procedures. However, it faces challenges\nsuch as understanding instrument-action relationships and tracking surgical\nprogress. Large Language Models (LLMs) show promise in understanding surgical\nvideo content but remain underexplored for predictive decision-making in SAP,\nas they focus mainly on retrospective analysis. Challenges like data privacy,\ncomputational demands, and modality-specific constraints further highlight\nsignificant research gaps. To tackle these challenges, we introduce LLM-SAP, a\nLarge Language Models-based Surgical Action Planning framework that predicts\nfuture actions and generates text responses by interpreting natural language\nprompts of surgical goals. The text responses potentially support surgical\neducation, intraoperative decision-making, procedure documentation, and skill\nanalysis. LLM-SAP integrates two novel modules: the Near-History Focus Memory\nModule (NHF-MM) for modeling historical states and the prompts factory for\naction planning. We evaluate LLM-SAP on our constructed CholecT50-SAP dataset\nusing models like Qwen2.5 and Qwen2-VL, demonstrating its effectiveness in\nnext-action prediction. Pre-trained LLMs are tested in a zero-shot setting, and\nsupervised fine-tuning (SFT) with LoRA is implemented. Our experiments show\nthat Qwen2.5-72B-SFT surpasses Qwen2.5-72B with a 19.3% higher accuracy.", "published": "2025-03-24 03:02:04", "link": "http://arxiv.org/abs/2503.18296v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fact-checking AI-generated news reports: Can LLMs catch their own lies?", "abstract": "In this paper, we evaluate the ability of Large Language Models (LLMs) to\nassess the veracity of claims in ''news reports'' generated by themselves or\nother LLMs. Our goal is to determine whether LLMs can effectively fact-check\ntheir own content, using methods similar to those used to verify claims made by\nhumans. Our findings indicate that LLMs are more effective at assessing claims\nin national or international news stories than in local news stories, better at\nevaluating static information than dynamic information, and better at verifying\ntrue claims compared to false ones. We hypothesize that this disparity arises\nbecause the former types of claims are better represented in the training data.\nAdditionally, we find that incorporating retrieved results from a search engine\nin a Retrieval-Augmented Generation (RAG) setting significantly reduces the\nnumber of claims an LLM cannot assess. However, this approach also increases\nthe occurrence of incorrect assessments, partly due to irrelevant or\nlow-quality search results. This diagnostic study highlights the need for\nfuture research on fact-checking machine-generated reports to prioritize\nimproving the precision and relevance of retrieved information to better\nsupport fact-checking efforts. Furthermore, claims about dynamic events and\nlocal news may require human-in-the-loop fact-checking systems to ensure\naccuracy and reliability.", "published": "2025-03-24 02:32:02", "link": "http://arxiv.org/abs/2503.18293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When is dataset cartography ineffective? Using training dynamics does not improve robustness against Adversarial SQuAD", "abstract": "In this paper, I investigate the effectiveness of dataset cartography for\nextractive question answering on the SQuAD dataset. I begin by analyzing\nannotation artifacts in SQuAD and evaluate the impact of two adversarial\ndatasets, AddSent and AddOneSent, on an ELECTRA-small model. Using training\ndynamics, I partition SQuAD into easy-to-learn, ambiguous, and hard-to-learn\nsubsets. I then compare the performance of models trained on these subsets to\nthose trained on randomly selected samples of equal size. Results show that\ntraining on cartography-based subsets does not improve generalization to the\nSQuAD validation set or the AddSent adversarial set. While the hard-to-learn\nsubset yields a slightly higher F1 score on the AddOneSent dataset, the overall\ngains are limited. These findings suggest that dataset cartography provides\nlittle benefit for adversarial robustness in SQuAD-style QA tasks. I conclude\nby comparing these results to prior findings on SNLI and discuss possible\nreasons for the observed differences.", "published": "2025-03-24 02:24:18", "link": "http://arxiv.org/abs/2503.18290v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6; I.5.1"], "primary_category": "cs.CL"}
{"title": "Sun-Shine: A Large Language Model for Tibetan Culture", "abstract": "Tibetan, a minority language in China, features a highly intricate\ngrammatical structure, characterized by four verb tenses and a tense system\nwith frequent irregularities, contributing to its extensive inflectional\ndiversity. Recently, advances in Large Language Models (LLMs) have transformed\nthe paradigm in many domains. Despite the success in other fields, current LLMs\noften fall short in catering to the needs of domain experts like Tibetans, and\nthe potential of LLMs for Tibetan culture is under-explored. The intrinsic\nreasons are the immense and intricate nature of Tibetan culture as well as the\nnecessity for higher granularity and richness in knowledge. Simultaneously, the\ncomplexity and uniqueness of its grammatical structure, coupled with its status\nas a minority ethnic language, contribute to data scarcity, which remains a\nfundamental challenge. To alleviate these issues, we introduce Llama-Sunshine\n(Sun-Shine), the first large language model for Tibetan culture, which is\nexpert in various Tibetan language processing tasks. Sun-Shine incorporates\nstate-of-the-art model architectures optimized for Tibetan's linguistic\nfeatures. We also propose TIB-STC, a comprehensive dataset comprising diverse\nTibetan texts such as literature, religious scripts, news, and conversational\ndata, which is also the first large-scale dataset for Tibetan culture. Though\ncomprehensive experiments, Sun-Shine not only demonstrates a higher level of\nknowledge expertise for Tibetan culture but also gains preliminary embodied\nintelligence capabilities in Tibetan language processing tasks, like language\nmodeling, text classification, machine translation, and syntactic analysis.\nMoreover, it excels in low-resource scenarios, showcasing strong generalization\ncapabilities.", "published": "2025-03-24 02:17:41", "link": "http://arxiv.org/abs/2503.18288v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging Emotions and Architecture: Sentiment Analysis in Modern Distributed Systems", "abstract": "Sentiment analysis is a field within NLP that has gained importance because\nit is applied in various areas such as; social media surveillance, customer\nfeedback evaluation and market research. At the same time, distributed systems\nallow for effective processing of large amounts of data. Therefore, this paper\nexamines how sentiment analysis converges with distributed systems by\nconcentrating on different approaches, challenges and future investigations.\nFurthermore, we do an extensive experiment where we train sentiment analysis\nmodels using both single node configuration and distributed architecture to\nbring out the benefits and shortcomings of each method in terms of performance\nand accuracy.", "published": "2025-03-24 01:01:19", "link": "http://arxiv.org/abs/2503.18260v1", "categories": ["cs.CL", "cs.DC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Multi-Label Emotion Analysis and Corresponding Intensities for Ethiopian Languages", "abstract": "In this digital world, people freely express their emotions using different\nsocial media platforms. As a result, modeling and integrating\nemotion-understanding models are vital for various human-computer interaction\ntasks such as decision-making, product and customer feedback analysis,\npolitical promotions, marketing research, and social media monitoring. As users\nexpress different emotions simultaneously in a single instance, annotating\nemotions in a multilabel setting such as the EthioEmo (Belay et al., 2025)\ndataset effectively captures this dynamic. Additionally, incorporating\nintensity, or the degree of emotion, is crucial, as emotions can significantly\ndiffer in their expressive strength and impact. This intensity is significant\nfor assessing whether further action is necessary in decision-making processes,\nespecially concerning negative emotions in applications such as healthcare and\nmental health studies. To enhance the EthioEmo dataset, we include annotations\nfor the intensity of each labeled emotion. Furthermore, we evaluate various\nstate-of-the-art encoder-only Pretrained Language Models (PLMs) and\ndecoder-only Large Language Models (LLMs) to provide comprehensive\nbenchmarking.", "published": "2025-03-24 00:34:36", "link": "http://arxiv.org/abs/2503.18253v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PAD: Towards Efficient Data Generation for Transfer Learning Using Phrase Alignment", "abstract": "Transfer learning leverages the abundance of English data to address the\nscarcity of resources in modeling non-English languages, such as Korean. In\nthis study, we explore the potential of Phrase Aligned Data (PAD) from\nstandardized Statistical Machine Translation (SMT) to enhance the efficiency of\ntransfer learning. Through extensive experiments, we demonstrate that PAD\nsynergizes effectively with the syntactic characteristics of the Korean\nlanguage, mitigating the weaknesses of SMT and significantly improving model\nperformance. Moreover, we reveal that PAD complements traditional data\nconstruction methods and enhances their effectiveness when combined. This\ninnovative approach not only boosts model performance but also suggests a\ncost-efficient solution for resource-scarce languages.", "published": "2025-03-24 00:29:05", "link": "http://arxiv.org/abs/2503.18250v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AfroXLMR-Social: Adapting Pre-trained Language Models for African Languages Social Media Text", "abstract": "Pretrained Language Models (PLMs) built from various sources are the\nfoundation of today's NLP progress. Language representations learned by such\nmodels achieve strong performance across many tasks with datasets of varying\nsizes drawn from various sources. We explore a thorough analysis of domain and\ntask adaptive continual pretraining approaches for low-resource African\nlanguages and a promising result is shown for the evaluated tasks. We create\nAfriSocial, a corpus designed for domain adaptive finetuning that passes\nthrough quality pre-processing steps. Continual pretraining PLMs using\nAfriSocial as domain adaptive pretraining (DAPT) data, consistently improves\nperformance on fine-grained emotion classification task of 16 targeted\nlanguages from 1% to 28.27% macro F1 score. Likewise, using the task adaptive\npertaining (TAPT) approach, further finetuning with small unlabeled but similar\ntask data shows promising results. For example, unlabeled sentiment data\n(source) for fine-grained emotion classification task (target) improves the\nbase model results by an F1 score ranging from 0.55% to 15.11%. Combining the\ntwo methods, DAPT + TAPT, achieves also better results than base models. All\nthe resources will be available to improve low-resource NLP tasks, generally,\nas well as other similar domain tasks such as hate speech and sentiment tasks.", "published": "2025-03-24 00:06:33", "link": "http://arxiv.org/abs/2503.18247v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM Benchmarking with LLaMA2: Evaluating Code Development Performance Across Multiple Programming Languages", "abstract": "The rapid evolution of large language models (LLMs) has opened new\npossibilities for automating various tasks in software development. This paper\nevaluates the capabilities of the Llama 2-70B model in automating these tasks\nfor scientific applications written in commonly used programming languages.\nUsing representative test problems, we assess the model's capacity to generate\ncode, documentation, and unit tests, as well as its ability to translate\nexisting code between commonly used programming languages. Our comprehensive\nanalysis evaluates the compilation, runtime behavior, and correctness of the\ngenerated and translated code. Additionally, we assess the quality of\nautomatically generated code, documentation and unit tests. Our results\nindicate that while Llama 2-70B frequently generates syntactically correct and\nfunctional code for simpler numerical tasks, it encounters substantial\ndifficulties with more complex, parallelized, or distributed computations,\nrequiring considerable manual corrections. We identify key limitations and\nsuggest areas for future improvements to better leverage AI-driven automation\nin scientific computing workflows.", "published": "2025-03-24 23:46:14", "link": "http://arxiv.org/abs/2503.19217v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Continual Reinforcement Learning for HVAC Systems Control: Integrating Hypernetworks and Transfer Learning", "abstract": "Buildings with Heating, Ventilation, and Air Conditioning (HVAC) systems play\na crucial role in ensuring indoor comfort and efficiency. While traditionally\ngoverned by physics-based models, the emergence of big data has enabled\ndata-driven methods like Deep Reinforcement Learning (DRL). However,\nReinforcement Learning (RL)-based techniques often suffer from sample\ninefficiency and limited generalization, especially across varying HVAC\nsystems. We introduce a model-based reinforcement learning framework that uses\na Hypernetwork to continuously learn environment dynamics across tasks with\ndifferent action spaces. This enables efficient synthetic rollout generation\nand improved sample usage. Our approach demonstrates strong backward transfer\nin a continual learning setting after training on a second task, minimal\nfine-tuning on the first task allows rapid convergence within just 5 episodes\nand thus outperforming Model Free Reinforcement Learning (MFRL) and effectively\nmitigating catastrophic forgetting. These findings have significant\nimplications for reducing energy consumption and operational costs in building\nmanagement, thus supporting global sustainability goals.\n  Keywords: Deep Reinforcement Learning, HVAC Systems Control, Hypernetworks,\nTransfer and Continual Learning, Catastrophic Forgetting", "published": "2025-03-24 23:38:04", "link": "http://arxiv.org/abs/2503.19212v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "A Shared Low-Rank Adaptation Approach to Personalized RLHF", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a pivotal\ntechnique for aligning artificial intelligence systems with human values,\nachieving remarkable success in fine-tuning large language models. However,\nexisting RLHF frameworks often assume that human preferences are relatively\nhomogeneous and can be captured by a single, unified reward model. This\nassumption overlooks the inherent diversity and heterogeneity across\nindividuals, limiting the adaptability of RLHF to personalized scenarios and\nrisking misalignments that can diminish user satisfaction and trust in AI\nsystems. In this paper, we address these challenges by introducing Low-Rank\nAdaptation (LoRA) into the personalized RLHF framework. We apply LoRA in the\nthe aggregated parameter space of all personalized reward functions, thereby\nenabling efficient learning of personalized reward models from potentially\nlimited local datasets. Our approach exploits potential shared structures among\nthe local ground-truth reward models while allowing for individual adaptation,\nwithout relying on restrictive assumptions about shared representations as in\nprior works. We further establish sample complexity guarantees for our method.\nTheoretical analysis demonstrates the effectiveness of the proposed approach in\ncapturing both shared and individual-specific structures within heterogeneous\nhuman preferences, addressing the dual challenge of personalization\nrequirements and practical data constraints. Experimental results on real-world\ndatasets corroborate the efficiency of our algorithm in the personalized RLHF\nsetting.", "published": "2025-03-24 23:01:08", "link": "http://arxiv.org/abs/2503.19201v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Mining-Gym: A Configurable RL Benchmarking Environment for Truck Dispatch Scheduling", "abstract": "Mining process optimization particularly truck dispatch scheduling is a\ncritical factor in enhancing the efficiency of open pit mining operations\nHowever the dynamic and stochastic nature of mining environments characterized\nby uncertainties such as equipment failures truck maintenance and variable haul\ncycle times poses significant challenges for traditional optimization methods\nWhile Reinforcement Learning RL has shown promise in adaptive decision making\nfor mining logistics its practical deployment requires rigorous evaluation in\nrealistic and customizable simulation environments The lack of standardized\nbenchmarking environments limits fair algorithm comparisons reproducibility and\nthe real world applicability of RL based approaches in open pit mining settings\nTo address this challenge we introduce Mining Gym a configurable open source\nbenchmarking environment designed for training testing and comparing RL\nalgorithms in mining process optimization Built on Discrete Event Simulation\nDES and seamlessly integrated with the OpenAI Gym interface Mining Gym provides\na structured testbed that enables the direct application of advanced RL\nalgorithms from Stable Baselines The framework models key mining specific\nuncertainties such as equipment failures queue congestion and the stochasticity\nof mining processes ensuring a realistic and adaptive learning environment\nAdditionally Mining Gym features a graphical user interface GUI for intuitive\nmine site configuration a comprehensive data logging system a built in KPI\ndashboard and real time visual representation of the mine site These\ncapabilities facilitate standardized reproducible evaluations across multiple\nRL strategies and baseline heuristics", "published": "2025-03-24 22:48:20", "link": "http://arxiv.org/abs/2503.19195v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "SoK: How Robust is Audio Watermarking in Generative AI models?", "abstract": "Audio watermarking is increasingly used to verify the provenance of\nAI-generated content, enabling applications such as detecting AI-generated\nspeech, protecting music IP, and defending against voice cloning. To be\neffective, audio watermarks must resist removal attacks that distort signals to\nevade detection. While many schemes claim robustness, these claims are\ntypically tested in isolation and against a limited set of attacks. A\nsystematic evaluation against diverse removal attacks is lacking, hindering\npractical deployment. In this paper, we investigate whether recent watermarking\nschemes that claim robustness can withstand a broad range of removal attacks.\nFirst, we introduce a taxonomy covering 22 audio watermarking schemes. Next, we\nsummarize their underlying technologies and potential vulnerabilities. We then\npresent a large-scale empirical study to assess their robustness. To support\nthis, we build an evaluation framework encompassing 22 types of removal attacks\n(109 configurations) including signal-level, physical-level, and AI-induced\ndistortions. We reproduce 9 watermarking schemes using open-source code,\nidentify 8 new highly effective attacks, and highlight 11 key findings that\nexpose the fundamental limitations of these methods across 3 public datasets.\nOur results reveal that none of the surveyed schemes can withstand all tested\ndistortions. This evaluation offers a comprehensive view of how current\nwatermarking methods perform under real-world threats. Our demo and code are\navailable at https://sokaudiowm.github.io/.", "published": "2025-03-24 21:57:59", "link": "http://arxiv.org/abs/2503.19176v2", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "AssertionForge: Enhancing Formal Verification Assertion Generation with Structured Representation of Specifications and RTL", "abstract": "Generating SystemVerilog Assertions (SVAs) from natural language\nspecifications remains a major challenge in formal verification (FV) due to the\ninherent ambiguity and incompleteness of specifications. Existing LLM-based\napproaches, such as AssertLLM, focus on extracting information solely from\nspecification documents, often failing to capture essential internal signal\ninteractions and design details present in the RTL code, leading to incomplete\nor incorrect assertions. We propose a novel approach that constructs a\nKnowledge Graph (KG) from both specifications and RTL, using a\nhardware-specific schema with domain-specific entity and relation types. We\ncreate an initial KG from the specification and then systematically fuse it\nwith information extracted from the RTL code, resulting in a unified,\ncomprehensive KG. This combined representation enables a more thorough\nunderstanding of the design and allows for a multi-resolution context synthesis\nprocess which is designed to extract diverse verification contexts from the KG.\nExperiments on four designs demonstrate that our method significantly enhances\nSVA quality over prior methods. This structured representation not only\nimproves FV but also paves the way for future research in tasks like code\ngeneration and design understanding.", "published": "2025-03-24 21:53:37", "link": "http://arxiv.org/abs/2503.19174v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "PSO-UNet: Particle Swarm-Optimized U-Net Framework for Precise Multimodal Brain Tumor Segmentation", "abstract": "Medical image segmentation, particularly for brain tumor analysis, demands\nprecise and computationally efficient models due to the complexity of\nmultimodal MRI datasets and diverse tumor morphologies. This study introduces\nPSO-UNet, which integrates Particle Swarm Optimization (PSO) with the U-Net\narchitecture for dynamic hyperparameter optimization. Unlike traditional manual\ntuning or alternative optimization approaches, PSO effectively navigates\ncomplex hyperparameter search spaces, explicitly optimizing the number of\nfilters, kernel size, and learning rate. PSO-UNet substantially enhances\nsegmentation performance, achieving Dice Similarity Coefficients (DSC) of\n0.9578 and 0.9523 and Intersection over Union (IoU) scores of 0.9194 and 0.9097\non the BraTS 2021 and Figshare datasets, respectively. Moreover, the method\nreduces computational complexity significantly, utilizing only 7.8 million\nparameters and executing in approximately 906 seconds, markedly faster than\ncomparable U-Net-based frameworks. These outcomes underscore PSO-UNet's robust\ngeneralization capabilities across diverse MRI modalities and tumor\nclassifications, emphasizing its clinical potential and clear advantages over\nconventional hyperparameter tuning methods. Future research will explore hybrid\noptimization strategies and validate the framework against other bio-inspired\nalgorithms to enhance its robustness and scalability.", "published": "2025-03-24 21:14:08", "link": "http://arxiv.org/abs/2503.19152v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "68Q07", "I.4.6; I.2"], "primary_category": "eess.IV"}
{"title": "Information-Seeking Decision Strategies Mitigate Risk in Dynamic, Uncertain Environments", "abstract": "To survive in dynamic and uncertain environments, individuals must develop\neffective decision strategies that balance information gathering and decision\ncommitment. Models of such strategies often prioritize either optimizing\ntangible payoffs, like reward rate, or gathering information to support a\ndiversity of (possibly unknown) objectives. However, our understanding of the\nrelative merits of these two approaches remains incomplete, in part because\ndirect comparisons have been limited to idealized, static environments that\nlack the dynamic complexity of the real world. Here we compared the performance\nof normative reward- and information-seeking strategies in a dynamic foraging\ntask. Both strategies show similar transitions between exploratory and\nexploitative behaviors as environmental uncertainty changes. However, we find\nsubtle disparities in the actions they take, resulting in meaningful\nperformance differences: whereas reward-seeking strategies generate slightly\nmore reward on average, information-seeking strategies provide more consistent\nand predictable outcomes. Our findings support the adaptive value of\ninformation-seeking behaviors that can mitigate risk with minimal reward loss.", "published": "2025-03-24 19:55:41", "link": "http://arxiv.org/abs/2503.19107v1", "categories": ["cs.AI", "math.PR", "q-bio.NC"], "primary_category": "cs.AI"}
{"title": "Anomaly Detection Using Computer Vision: A Comparative Analysis of Class Distinction and Performance Metrics", "abstract": "This paper showcases an experimental study on anomaly detection using\ncomputer vision. The study focuses on class distinction and performance\nevaluation, combining OpenCV with deep learning techniques while employing a\nTensorFlow-based convolutional neural network for real-time face recognition\nand classification. The system effectively distinguishes among three classes:\nauthorized personnel (admin), intruders, and non-human entities. A\nMobileNetV2-based deep learning model is utilized to optimize real-time\nperformance, ensuring high computational efficiency without compromising\naccuracy. Extensive dataset preprocessing, including image augmentation and\nnormalization, enhances the models generalization capabilities. Our analysis\ndemonstrates classification accuracies of 90.20% for admin, 98.60% for\nintruders, and 75.80% for non-human detection, while maintaining an average\nprocessing rate of 30 frames per second. The study leverages transfer learning,\nbatch normalization, and Adam optimization to achieve stable and robust\nlearning, and a comparative analysis of class differentiation strategies\nhighlights the impact of feature extraction techniques and training\nmethodologies. The results indicate that advanced feature selection and data\naugmentation significantly enhance detection performance, particularly in\ndistinguishing human from non-human scenes. As an experimental study, this\nresearch provides critical insights into optimizing deep learning-based\nsurveillance systems for high-security environments and improving the accuracy\nand efficiency of real-time anomaly detection.", "published": "2025-03-24 19:36:47", "link": "http://arxiv.org/abs/2503.19100v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Case for \"Thick Evaluations\" of Cultural Representation in AI", "abstract": "Generative AI image models have been increasingly evaluated for their\n(in)ability to represent non-Western cultures. We argue that these evaluations\noperate through reductive ideals of representation, abstracted from how people\ndefine their own representation and neglecting the inherently interpretive and\ncontextual nature of cultural representation. In contrast to these 'thin'\nevaluations, we introduce the idea of 'thick evaluations': a more granular,\nsituated, and discursive measurement framework for evaluating representations\nof social worlds in AI images, steeped in communities' own understandings of\nrepresentation. We develop this evaluation framework through workshops in South\nAsia, by studying the 'thick' ways in which people interpret and assign meaning\nto images of their own cultures. We introduce practices for thicker evaluations\nof representation that expand the understanding of representation underpinning\nAI evaluations and by co-constructing metrics with communities, bringing\nmeasurement in line with the experiences of communities on the ground.", "published": "2025-03-24 19:01:14", "link": "http://arxiv.org/abs/2503.19075v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "HingeRLC-GAN: Combating Mode Collapse with Hinge Loss and RLC Regularization", "abstract": "Recent advances in Generative Adversarial Networks (GANs) have demonstrated\ntheir capability for producing high-quality images. However, a significant\nchallenge remains mode collapse, which occurs when the generator produces a\nlimited number of data patterns that do not reflect the diversity of the\ntraining dataset. This study addresses this issue by proposing a number of\narchitectural changes aimed at increasing the diversity and stability of GAN\nmodels. We start by improving the loss function with Wasserstein loss and\nGradient Penalty to better capture the full range of data variations. We also\ninvestigate various network architectures and conclude that ResNet\nsignificantly contributes to increased diversity. Building on these findings,\nwe introduce HingeRLC-GAN, a novel approach that combines RLC Regularization\nand the Hinge loss function. With a FID Score of 18 and a KID Score of 0.001,\nour approach outperforms existing methods by effectively balancing training\nstability and increased diversity.", "published": "2025-03-24 19:00:28", "link": "http://arxiv.org/abs/2503.19074v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Graph-Level Label-Only Membership Inference Attack against Graph Neural Networks", "abstract": "Graph neural networks (GNNs) are widely used for graph-structured data but\nare vulnerable to membership inference attacks (MIAs) in graph classification\ntasks, which determine if a graph was part of the training dataset, potentially\ncausing data leakage. Existing MIAs rely on prediction probability vectors, but\nthey become ineffective when only prediction labels are available. We propose a\nGraph-level Label-Only Membership Inference Attack (GLO-MIA), which is based on\nthe intuition that the target model's predictions on training data are more\nstable than those on testing data. GLO-MIA generates a set of perturbed graphs\nfor target graph by adding perturbations to its effective features and queries\nthe target model with the perturbed graphs to get their prediction labels,\nwhich are then used to calculate robustness score of the target graph. Finally,\nby comparing the robustness score with a predefined threshold, the membership\nof the target graph can be inferred correctly with high probability. Our\nevaluation on three datasets and four GNN models shows that GLO-MIA achieves an\nattack accuracy of up to 0.825, outperforming baseline work by 8.5% and closely\nmatching the performance of probability-based MIAs, even with only prediction\nlabels.", "published": "2025-03-24 18:55:02", "link": "http://arxiv.org/abs/2503.19070v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Minimum Volume Conformal Sets for Multivariate Regression", "abstract": "Conformal prediction provides a principled framework for constructing\npredictive sets with finite-sample validity. While much of the focus has been\non univariate response variables, existing multivariate methods either impose\nrigid geometric assumptions or rely on flexible but computationally expensive\napproaches that do not explicitly optimize prediction set volume. We propose an\noptimization-driven framework based on a novel loss function that directly\nlearns minimum-volume covering sets while ensuring valid coverage. This\nformulation naturally induces a new nonconformity score for conformal\nprediction, which adapts to the residual distribution and covariates. Our\napproach optimizes over prediction sets defined by arbitrary norm balls,\nincluding single and multi-norm formulations. Additionally, by jointly\noptimizing both the predictive model and predictive uncertainty, we obtain\nprediction sets that are tight, informative, and computationally efficient, as\ndemonstrated in our experiments on real-world datasets.", "published": "2025-03-24 18:54:22", "link": "http://arxiv.org/abs/2503.19068v1", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME", "stat.OT"], "primary_category": "stat.ML"}
{"title": "Mist: Efficient Distributed Training of Large Language Models via Memory-Parallelism Co-Optimization", "abstract": "Various parallelism, such as data, tensor, and pipeline parallelism, along\nwith memory optimizations like activation checkpointing, redundancy\nelimination, and offloading, have been proposed to accelerate distributed\ntraining for Large Language Models. To find the best combination of these\ntechniques, automatic distributed training systems are proposed. However,\nexisting systems only tune a subset of optimizations, due to the lack of\noverlap awareness, inability to navigate the vast search space, and ignoring\nthe inter-microbatch imbalance, leading to sub-optimal performance. To address\nthese shortcomings, we propose Mist, a memory, overlap, and imbalance-aware\nautomatic distributed training system that comprehensively co-optimizes all\nmemory footprint reduction techniques alongside parallelism. Mist is based on\nthree key ideas: (1) fine-grained overlap-centric scheduling, orchestrating\noptimizations in an overlapped manner, (2) symbolic-based performance analysis\nthat predicts runtime and memory usage using symbolic expressions for fast\ntuning, and (3) imbalance-aware hierarchical tuning, decoupling the process\ninto an inter-stage imbalance and overlap aware Mixed Integer Linear\nProgramming problem and an intra-stage Dual-Objective Constrained Optimization\nproblem, and connecting them through Pareto frontier sampling. Our evaluation\nresults show that Mist achieves an average of 1.28$\\times$ (up to 1.73$\\times$)\nand 1.27$\\times$ (up to 2.04$\\times$) speedup compared to state-of-the-art\nmanual system Megatron-LM and state-of-the-art automatic system Aceso,\nrespectively.", "published": "2025-03-24 18:21:08", "link": "http://arxiv.org/abs/2503.19050v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "Forecasting Labor Demand: Predicting JOLT Job Openings using Deep Learning Model", "abstract": "This thesis studies the effectiveness of Long Short Term Memory model in\nforecasting future Job Openings and Labor Turnover Survey data in the United\nStates. Drawing on multiple economic indicators from various sources, the data\nare fed directly into LSTM model to predict JOLT job openings in subsequent\nperiods. The performance of the LSTM model is compared with conventional\nautoregressive approaches, including ARIMA, SARIMA, and Holt-Winters. Findings\nsuggest that the LSTM model outperforms these traditional models in predicting\nJOLT job openings, as it not only captures the dependent variables trends but\nalso harmonized with key economic factors. These results highlight the\npotential of deep learning techniques in capturing complex temporal\ndependencies in economic data, offering valuable insights for policymakers and\nstakeholders in developing data-driven labor market strategies", "published": "2025-03-24 18:19:33", "link": "http://arxiv.org/abs/2503.19048v1", "categories": ["econ.EM", "cs.AI"], "primary_category": "econ.EM"}
{"title": "Evolutionary Policy Optimization", "abstract": "Despite its extreme sample inefficiency, on-policy reinforcement learning has\nbecome a fundamental tool in real-world applications. With recent advances in\nGPU-driven simulation, the ability to collect vast amounts of data for RL\ntraining has scaled exponentially. However, studies show that current on-policy\nmethods, such as PPO, fail to fully leverage the benefits of parallelized\nenvironments, leading to performance saturation beyond a certain scale. In\ncontrast, Evolutionary Algorithms (EAs) excel at increasing diversity through\nrandomization, making them a natural complement to RL. However, existing EvoRL\nmethods have struggled to gain widespread adoption due to their extreme sample\ninefficiency. To address these challenges, we introduce Evolutionary Policy\nOptimization (EPO), a novel policy gradient algorithm that combines the\nstrengths of EA and policy gradients. We show that EPO significantly improves\nperformance across diverse and challenging environments, demonstrating superior\nscalability with parallelized simulations.", "published": "2025-03-24 18:08:54", "link": "http://arxiv.org/abs/2503.19037v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Aether: Geometric-Aware Unified World Modeling", "abstract": "The integration of geometric reconstruction and generative modeling remains a\ncritical challenge in developing AI systems capable of human-like spatial\nreasoning. This paper proposes Aether, a unified framework that enables\ngeometry-aware reasoning in world models by jointly optimizing three core\ncapabilities: (1) 4D dynamic reconstruction, (2) action-conditioned video\nprediction, and (3) goal-conditioned visual planning. Through task-interleaved\nfeature learning, Aether achieves synergistic knowledge sharing across\nreconstruction, prediction, and planning objectives. Building upon video\ngeneration models, our framework demonstrates unprecedented synthetic-to-real\ngeneralization despite never observing real-world data during training.\nFurthermore, our approach achieves zero-shot generalization in both action\nfollowing and reconstruction tasks, thanks to its intrinsic geometric modeling.\nRemarkably, even without real-world data, its reconstruction performance is\ncomparable with or even better than that of domain-specific models.\nAdditionally, Aether employs camera trajectories as geometry-informed action\nspaces, enabling effective action-conditioned prediction and visual planning.\nWe hope our work inspires the community to explore new frontiers in\nphysically-reasonable world modeling and its applications.", "published": "2025-03-24 17:59:51", "link": "http://arxiv.org/abs/2503.18945v2", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Video-T1: Test-Time Scaling for Video Generation", "abstract": "With the scale capability of increasing training data, model size, and\ncomputational cost, video generation has achieved impressive results in digital\ncreation, enabling users to express creativity across various domains.\nRecently, researchers in Large Language Models (LLMs) have expanded the scaling\nto test-time, which can significantly improve LLM performance by using more\ninference-time computation. Instead of scaling up video foundation models\nthrough expensive training costs, we explore the power of Test-Time Scaling\n(TTS) in video generation, aiming to answer the question: if a video generation\nmodel is allowed to use non-trivial amount of inference-time compute, how much\ncan it improve generation quality given a challenging text prompt. In this\nwork, we reinterpret the test-time scaling of video generation as a searching\nproblem to sample better trajectories from Gaussian noise space to the target\nvideo distribution. Specifically, we build the search space with test-time\nverifiers to provide feedback and heuristic algorithms to guide searching\nprocess. Given a text prompt, we first explore an intuitive linear search\nstrategy by increasing noise candidates at inference time. As full-step\ndenoising all frames simultaneously requires heavy test-time computation costs,\nwe further design a more efficient TTS method for video generation called\nTree-of-Frames (ToF) that adaptively expands and prunes video branches in an\nautoregressive manner. Extensive experiments on text-conditioned video\ngeneration benchmarks demonstrate that increasing test-time compute\nconsistently leads to significant improvements in the quality of videos.\nProject page: https://liuff19.github.io/Video-T1", "published": "2025-03-24 17:59:04", "link": "http://arxiv.org/abs/2503.18942v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "AdaWorld: Learning Adaptable World Models with Latent Actions", "abstract": "World models aim to learn action-controlled prediction models and have proven\nessential for the development of intelligent agents. However, most existing\nworld models rely heavily on substantial action-labeled data and costly\ntraining, making it challenging to adapt to novel environments with\nheterogeneous actions through limited interactions. This limitation can hinder\ntheir applicability across broader domains. To overcome this challenge, we\npropose AdaWorld, an innovative world model learning approach that enables\nefficient adaptation. The key idea is to incorporate action information during\nthe pretraining of world models. This is achieved by extracting latent actions\nfrom videos in a self-supervised manner, capturing the most critical\ntransitions between frames. We then develop an autoregressive world model that\nconditions on these latent actions. This learning paradigm enables highly\nadaptable world models, facilitating efficient transfer and learning of new\nactions even with limited interactions and finetuning. Our comprehensive\nexperiments across multiple environments demonstrate that AdaWorld achieves\nsuperior performance in both simulation quality and visual planning.", "published": "2025-03-24 17:58:15", "link": "http://arxiv.org/abs/2503.18938v1", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Statistical Proof of Execution (SPEX)", "abstract": "Many real-world applications are increasingly incorporating automated\ndecision-making, driven by the widespread adoption of ML/AI inference for\nplanning and guidance. This study examines the growing need for verifiable\ncomputing in autonomous decision-making. We formalize the problem of verifiable\ncomputing and introduce a sampling-based protocol that is significantly faster,\nmore cost-effective, and simpler than existing methods. Furthermore, we tackle\nthe challenges posed by non-determinism, proposing a set of strategies to\neffectively manage common scenarios.", "published": "2025-03-24 17:13:25", "link": "http://arxiv.org/abs/2503.18899v1", "categories": ["cs.AI", "cs.CR"], "primary_category": "cs.AI"}
{"title": "Universally applicable and tunable graph-based coarse-graining for Machine learning force fields", "abstract": "Coarse-grained (CG) force field methods for molecular systems are a crucial\ntool to simulate large biological macromolecules and are therefore essential\nfor characterisations of biomolecular systems. While state-of-the-art deep\nlearning (DL)-based models for all-atom force fields have improved immensely\nover recent years, we observe and analyse significant limitations of the\ncurrently available approaches for DL-based CG simulations. In this work, we\npresent the first transferable DL-based CG force field approach (i.e., not\nspecific to only one narrowly defined system type) applicable to a wide range\nof biosystems. To achieve this, our CG algorithm does not rely on hard-coded\nrules and is tuned to output coarse-grained systems optimised for minimal\nstatistical noise in the ground truth CG forces, which results in significant\nimprovement of model training. Our force field model is also the first CG\nvariant that is based on the MACE architecture and is trained on a custom\ndataset created by a new approach based on the fragmentation of large\nbiosystems covering protein, RNA and lipid chemistry. We demonstrate that our\nmodel can be applied in molecular dynamics simulations to obtain stable and\nqualitatively accurate trajectories for a variety of systems, while also\ndiscussing cases for which we observe limited reliability.", "published": "2025-03-24 16:55:53", "link": "http://arxiv.org/abs/2504.01973v1", "categories": ["physics.chem-ph", "cs.AI"], "primary_category": "physics.chem-ph"}
{"title": "Bootstrapped Model Predictive Control", "abstract": "Model Predictive Control (MPC) has been demonstrated to be effective in\ncontinuous control tasks. When a world model and a value function are\navailable, planning a sequence of actions ahead of time leads to a better\npolicy. Existing methods typically obtain the value function and the\ncorresponding policy in a model-free manner. However, we find that such an\napproach struggles with complex tasks, resulting in poor policy learning and\ninaccurate value estimation. To address this problem, we leverage the strengths\nof MPC itself. In this work, we introduce Bootstrapped Model Predictive Control\n(BMPC), a novel algorithm that performs policy learning in a bootstrapped\nmanner. BMPC learns a network policy by imitating an MPC expert, and in turn,\nuses this policy to guide the MPC process. Combined with model-based\nTD-learning, our policy learning yields better value estimation and further\nboosts the efficiency of MPC. We also introduce a lazy reanalyze mechanism,\nwhich enables computationally efficient imitation learning. Our method achieves\nsuperior performance over prior works on diverse continuous control tasks. In\nparticular, on challenging high-dimensional locomotion tasks, BMPC\nsignificantly improves data efficiency while also enhancing asymptotic\nperformance and training stability, with comparable training time and smaller\nnetwork sizes. Code is available at https://github.com/wertyuilife2/bmpc.", "published": "2025-03-24 16:46:36", "link": "http://arxiv.org/abs/2503.18871v2", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Structuring Scientific Innovation: A Framework for Modeling and Discovering Impactful Knowledge Combinations", "abstract": "The emergence of large language models offers new possibilities for\nstructured exploration of scientific knowledge. Rather than viewing scientific\ndiscovery as isolated ideas or content, we propose a structured approach that\nemphasizes the role of method combinations in shaping disruptive insights.\nSpecifically, we investigate how knowledge unit--especially those tied to\nmethodological design--can be modeled and recombined to yield research\nbreakthroughs. Our proposed framework addresses two key challenges. First, we\nintroduce a contrastive learning-based mechanism to identify distinguishing\nfeatures of historically disruptive method combinations within problem-driven\ncontexts. Second, we propose a reasoning-guided Monte Carlo search algorithm\nthat leverages the chain-of-thought capability of LLMs to identify promising\nknowledge recombinations for new problem statements.Empirical studies across\nmultiple domains show that the framework is capable of modeling the structural\ndynamics of innovation and successfully highlights combinations with high\ndisruptive potential. This research provides a new path for computationally\nguided scientific ideation grounded in structured reasoning and historical data\nmodeling.", "published": "2025-03-24 16:41:17", "link": "http://arxiv.org/abs/2503.18865v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Exploring the Integration of Key-Value Attention Into Pure and Hybrid Transformers for Semantic Segmentation", "abstract": "While CNNs were long considered state of the art for image processing, the\nintroduction of Transformer architectures has challenged this position. While\nachieving excellent results in image classification and segmentation,\nTransformers remain inherently reliant on large training datasets and remain\ncomputationally expensive. A newly introduced Transformer derivative named KV\nTransformer shows promising results in synthetic, NLP, and image classification\ntasks, while reducing complexity and memory usage. This is especially conducive\nto use cases where local inference is required, such as medical screening\napplications. We endeavoured to further evaluate the merit of KV Transformers\non semantic segmentation tasks, specifically in the domain of medical imaging.\nBy directly comparing traditional and KV variants of the same base\narchitectures, we provide further insight into the practical tradeoffs of\nreduced model complexity. We observe a notable reduction in parameter count and\nmultiply accumulate operations, while achieving similar performance from most\nof the KV variant models when directly compared to their QKV implementation.", "published": "2025-03-24 16:38:31", "link": "http://arxiv.org/abs/2503.18862v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Role of AI Innovation, Clean Energy and Digital Economy towards Net Zero Emission in the United States: An ARDL Approach", "abstract": "The current paper investigates the influences of AI innovation, GDP growth,\nrenewable energy utilization, the digital economy, and industrialization on CO2\nemissions in the USA from 1990 to 2022, incorporating the ARDL methodology. The\noutcomes observe that AI innovation, renewable energy usage, and the digital\neconomy reduce CO2 emissions, while GDP expansion and industrialization\nintensify ecosystem damage. Unit root tests (ADF, PP, and DF-GLS) reveal\nheterogeneous integration levels amongst components, ensuring robustness in the\nARDL analysis. Complementary methods (FMOLS, DOLS, and CCR) validate the\nresults, enhancing their reliability. Pairwise Granger causality assessments\nidentify strong unidirectional connections within CO2 emissions and AI\ninnovation, as well as the digital economy, underscoring their significant\nroles in ecological sustainability. This research highlights the requirement\nfor strategic actions to nurture equitable growth, including advancements in AI\ntechnology, green energy adoption, and environmentally conscious industrial\ndevelopment, to improve environmental quality in the United States.", "published": "2025-03-24 16:32:24", "link": "http://arxiv.org/abs/2503.19933v1", "categories": ["econ.GN", "cs.AI", "cs.CY", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "MC-LLaVA: Multi-Concept Personalized Vision-Language Model", "abstract": "Current vision-language models (VLMs) show exceptional abilities across\ndiverse tasks, such as visual question answering. To enhance user experience,\nrecent studies investigate VLM personalization to understand user-provided\nconcepts. However, they mainly focus on single-concept personalization,\nneglecting the existence and interplay of multiple concepts, which limits\nreal-world applicability. This paper proposes the first multi-concept\npersonalization paradigm, MC-LLaVA. Specifically, MC-LLaVA employs a\nmulti-concept instruction tuning strategy, effectively integrating multiple\nconcepts in a single training step. To reduce the costs related to joint\ntraining, we propose a personalized textual prompt that uses visual token\ninformation to initialize concept tokens. Additionally, we introduce a\npersonalized visual prompt during inference, aggregating location confidence\nmaps for enhanced recognition and grounding capabilities. To advance\nmulti-concept personalization research, we further contribute a high-quality\ninstruction tuning dataset. We carefully collect images with multiple\ncharacters and objects from movies and manually generate question-answer\nsamples for multi-concept scenarios, featuring superior diversity.\nComprehensive qualitative and quantitative experiments demonstrate that\nMC-LLaVA can achieve impressive multi-concept personalized responses, paving\nthe way for VLMs to become better user-specific assistants. The code and\ndataset will be publicly available at https://github.com/arctanxarc/MC-LLaVA}.", "published": "2025-03-24 16:32:17", "link": "http://arxiv.org/abs/2503.18854v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Self-Organizing Graph Reasoning Evolves into a Critical State for Continuous Discovery Through Structural-Semantic Dynamics", "abstract": "We report fundamental insights into how agentic graph reasoning systems\nspontaneously evolve toward a critical state that sustains continuous semantic\ndiscovery. By rigorously analyzing structural (Von Neumann graph entropy) and\nsemantic (embedding) entropy, we identify a subtle yet robust regime in which\nsemantic entropy persistently dominates over structural entropy. This interplay\nis quantified by a dimensionless Critical Discovery Parameter that stabilizes\nat a small negative value, indicating a consistent excess of semantic entropy.\nEmpirically, we observe a stable fraction (12%) of \"surprising\" edges, links\nbetween semantically distant concepts, providing evidence of long-range or\ncross-domain connections that drive continuous innovation. Concomitantly, the\nsystem exhibits scale-free and small-world topological features, alongside a\nnegative cross-correlation between structural and semantic measures,\nreinforcing the analogy to self-organized criticality. These results establish\nclear parallels with critical phenomena in physical, biological, and cognitive\ncomplex systems, revealing an entropy-based principle governing adaptability\nand continuous innovation. Crucially, semantic richness emerges as the\nunderlying driver of sustained exploration, despite not being explicitly used\nby the reasoning process. Our findings provide interdisciplinary insights and\npractical strategies for engineering intelligent systems with intrinsic\ncapacities for long-term discovery and adaptation, and offer insights into how\nmodel training strategies can be developed that reinforce critical discovery.", "published": "2025-03-24 16:30:37", "link": "http://arxiv.org/abs/2503.18852v1", "categories": ["cs.AI", "cond-mat.mes-hall", "cs.LG", "nlin.AO", "physics.app-ph"], "primary_category": "cs.AI"}
{"title": "Three Kinds of AI Ethics", "abstract": "There is an overwhelming abundance of works in AI Ethics. This growth is\nchaotic because of how sudden it is, its volume, and its multidisciplinary\nnature. This makes difficult to keep track of debates, and to systematically\ncharacterize goals, research questions, methods, and expertise required by AI\nethicists. In this article, I show that the relation between AI and ethics can\nbe characterized in at least three ways, which correspond to three\nwell-represented kinds of AI ethics: ethics and AI; ethics in AI; ethics of AI.\nI elucidate the features of these three kinds of AI Ethics, characterize their\nresearch questions, and identify the kind of expertise that each kind needs. I\nalso show how certain criticisms to AI ethics are misplaced, as being done from\nthe point of view of one kind of AI ethics, to another kind with different\ngoals. All in all, this work sheds light on the nature of AI ethics, and sets\nthe groundwork for more informed discussions about the scope, methods, and\ntraining of AI ethicists.", "published": "2025-03-24 16:15:03", "link": "http://arxiv.org/abs/2503.18842v2", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Dual-domain Multi-path Self-supervised Diffusion Model for Accelerated MRI Reconstruction", "abstract": "Magnetic resonance imaging (MRI) is a vital diagnostic tool, but its\ninherently long acquisition times reduce clinical efficiency and patient\ncomfort. Recent advancements in deep learning, particularly diffusion models,\nhave improved accelerated MRI reconstruction. However, existing diffusion\nmodels' training often relies on fully sampled data, models incur high\ncomputational costs, and often lack uncertainty estimation, limiting their\nclinical applicability. To overcome these challenges, we propose a novel\nframework, called Dual-domain Multi-path Self-supervised Diffusion Model\n(DMSM), that integrates a self-supervised dual-domain diffusion model training\nscheme, a lightweight hybrid attention network for the reconstruction diffusion\nmodel, and a multi-path inference strategy, to enhance reconstruction accuracy,\nefficiency, and explainability. Unlike traditional diffusion-based models, DMSM\neliminates the dependency on training from fully sampled data, making it more\npractical for real-world clinical settings. We evaluated DMSM on two human MRI\ndatasets, demonstrating that it achieves favorable performance over several\nsupervised and self-supervised baselines, particularly in preserving fine\nanatomical structures and suppressing artifacts under high acceleration\nfactors. Additionally, our model generates uncertainty maps that correlate\nreasonably well with reconstruction errors, offering valuable clinically\ninterpretable guidance and potentially enhancing diagnostic confidence.", "published": "2025-03-24 16:10:51", "link": "http://arxiv.org/abs/2503.18836v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Interpretable and Fair Mechanisms for Abstaining Classifiers", "abstract": "Abstaining classifiers have the option to refrain from providing a prediction\nfor instances that are difficult to classify. The abstention mechanism is\ndesigned to trade off the classifier's performance on the accepted data while\nensuring a minimum number of predictions. In this setting, often fairness\nconcerns arise when the abstention mechanism solely reduces errors for the\nmajority groups of the data, resulting in increased performance differences\nacross demographic groups. While there exist a bunch of methods that aim to\nreduce discrimination when abstaining, there is no mechanism that can do so in\nan explainable way. In this paper, we fill this gap by introducing\nInterpretable and Fair Abstaining Classifier IFAC, an algorithm that can reject\npredictions both based on their uncertainty and their unfairness. By rejecting\npossibly unfair predictions, our method reduces error and positive decision\nrate differences across demographic groups of the non-rejected data. Since the\nunfairness-based rejections are based on an interpretable-by-design method,\ni.e., rule-based fairness checks and situation testing, we create a transparent\nprocess that can empower human decision-makers to review the unfair predictions\nand make more just decisions for them. This explainable aspect is especially\nimportant in light of recent AI regulations, mandating that any high-risk\ndecision task should be overseen by human experts to reduce discrimination\nrisks.", "published": "2025-03-24 16:06:43", "link": "http://arxiv.org/abs/2503.18826v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations", "abstract": "Prior research on out-of-distribution detection (OoDD) has primarily focused\non single-modality models. Recently, with the advent of large-scale pretrained\nvision-language models such as CLIP, OoDD methods utilizing such multi-modal\nrepresentations through zero-shot and prompt learning strategies have emerged.\nHowever, these methods typically involve either freezing the pretrained weights\nor only partially tuning them, which can be suboptimal for downstream datasets.\nIn this paper, we highlight that multi-modal fine-tuning (MMFT) can achieve\nnotable OoDD performance. Despite some recent works demonstrating the impact of\nfine-tuning methods for OoDD, there remains significant potential for\nperformance improvement. We investigate the limitation of na\\\"ive fine-tuning\nmethods, examining why they fail to fully leverage the pretrained knowledge.\nOur empirical analysis suggests that this issue could stem from the modality\ngap within in-distribution (ID) embeddings. To address this, we propose a\ntraining objective that enhances cross-modal alignment by regularizing the\ndistances between image and text embeddings of ID data. This adjustment helps\nin better utilizing pretrained textual information by aligning similar\nsemantics from different modalities (i.e., text and image) more closely in the\nhyperspherical representation space. We theoretically demonstrate that the\nproposed regularization corresponds to the maximum likelihood estimation of an\nenergy-based model on a hypersphere. Utilizing ImageNet-1k OoD benchmark\ndatasets, we show that our method, combined with post-hoc OoDD approaches\nleveraging pretrained knowledge (e.g., NegLabel), significantly outperforms\nexisting methods, achieving state-of-the-art OoDD performance and leading ID\naccuracy.", "published": "2025-03-24 16:00:21", "link": "http://arxiv.org/abs/2503.18817v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning Multi-Robot Coordination through Locality-Based Factorized Multi-Agent Actor-Critic Algorithm", "abstract": "In this work, we present a novel cooperative multi-agent reinforcement\nlearning method called \\textbf{Loc}ality based \\textbf{Fac}torized\n\\textbf{M}ulti-Agent \\textbf{A}ctor-\\textbf{C}ritic (Loc-FACMAC). Existing\nstate-of-the-art algorithms, such as FACMAC, rely on global reward information,\nwhich may not accurately reflect the quality of individual robots' actions in\ndecentralized systems. We integrate the concept of locality into critic\nlearning, where strongly related robots form partitions during training. Robots\nwithin the same partition have a greater impact on each other, leading to more\nprecise policy evaluation. Additionally, we construct a dependency graph to\ncapture the relationships between robots, facilitating the partitioning\nprocess. This approach mitigates the curse of dimensionality and prevents\nrobots from using irrelevant information. Our method improves existing\nalgorithms by focusing on local rewards and leveraging partition-based learning\nto enhance training efficiency and performance. We evaluate the performance of\nLoc-FACMAC in three environments: Hallway, Multi-cartpole, and\nBounded-Cooperative-Navigation. We explore the impact of partition sizes on the\nperformance and compare the result with baseline MARL algorithms such as LOMAQ,\nFACMAC, and QMIX. The experiments reveal that, if the locality structure is\ndefined properly, Loc-FACMAC outperforms these baseline algorithms up to 108\\%,\nindicating that exploiting the locality structure in the actor-critic framework\nimproves the MARL performance.", "published": "2025-03-24 16:00:16", "link": "http://arxiv.org/abs/2503.18816v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Towards Responsible AI Music: an Investigation of Trustworthy Features for Creative Systems", "abstract": "Generative AI is radically changing the creative arts, by fundamentally\ntransforming the way we create and interact with cultural artefacts. While\noffering unprecedented opportunities for artistic expression and\ncommercialisation, this technology also raises ethical, societal, and legal\nconcerns. Key among these are the potential displacement of human creativity,\ncopyright infringement stemming from vast training datasets, and the lack of\ntransparency, explainability, and fairness mechanisms. As generative systems\nbecome pervasive in this domain, responsible design is crucial. Whilst previous\nwork has tackled isolated aspects of generative systems (e.g., transparency,\nevaluation, data), we take a comprehensive approach, grounding these efforts\nwithin the Ethics Guidelines for Trustworthy Artificial Intelligence produced\nby the High-Level Expert Group on AI appointed by the European Commission - a\nframework for designing responsible AI systems across seven macro requirements.\nFocusing on generative music AI, we illustrate how these requirements can be\ncontextualised for the field, addressing trustworthiness across multiple\ndimensions and integrating insights from the existing literature. We further\npropose a roadmap for operationalising these contextualised requirements,\nemphasising interdisciplinary collaboration and stakeholder engagement. Our\nwork provides a foundation for designing and evaluating responsible music\ngeneration systems, calling for collaboration among AI experts, ethicists,\nlegal scholars, and artists. This manuscript is accompanied by a website:\nhttps://amresearchlab.github.io/raim-framework/.", "published": "2025-03-24 15:54:47", "link": "http://arxiv.org/abs/2503.18814v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Defeating Prompt Injections by Design", "abstract": "Large Language Models (LLMs) are increasingly deployed in agentic systems\nthat interact with an external environment. However, LLM agents are vulnerable\nto prompt injection attacks when handling untrusted data. In this paper we\npropose CaMeL, a robust defense that creates a protective system layer around\nthe LLM, securing it even when underlying models may be susceptible to attacks.\nTo operate, CaMeL explicitly extracts the control and data flows from the\n(trusted) query; therefore, the untrusted data retrieved by the LLM can never\nimpact the program flow. To further improve security, CaMeL relies on a notion\nof a capability to prevent the exfiltration of private data over unauthorized\ndata flows. We demonstrate effectiveness of CaMeL by solving $67\\%$ of tasks\nwith provable security in AgentDojo [NeurIPS 2024], a recent agentic security\nbenchmark.", "published": "2025-03-24 15:54:10", "link": "http://arxiv.org/abs/2503.18813v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Classical Planning with LLM-Generated Heuristics: Challenging the State of the Art with Python Code", "abstract": "In recent years, large language models (LLMs) have shown remarkable\ncapabilities in various artificial intelligence problems. However, they fail to\nplan reliably, even when prompted with a detailed definition of the planning\ntask. Attempts to improve their planning capabilities, such as chain-of-thought\nprompting, fine-tuning, and explicit \"reasoning\" still yield incorrect plans\nand usually fail to generalize to larger tasks. In this paper, we show how to\nuse LLMs to generate correct plans, even for out-of-distribution tasks of\nincreasing size. For a given planning domain, we ask an LLM to generate several\ndomain-dependent heuristic functions in the form of Python code, evaluate them\non a set of training tasks within a greedy best-first search, and choose the\nstrongest one. The resulting LLM-generated heuristics solve many more unseen\ntest tasks than state-of-the-art domain-independent heuristics for classical\nplanning. They are even competitive with the strongest learning algorithm for\ndomain-dependent planning. These findings are especially remarkable given that\nour proof-of-concept implementation is based on an unoptimized Python planner\nand the baselines all build upon highly optimized C++ code. In some domains,\nthe LLM-generated heuristics expand fewer states than the baselines, revealing\nthat they are not only efficiently computable, but sometimes even more\ninformative than the state-of-the-art heuristics. Overall, our results show\nthat sampling a set of planning heuristic function programs can significantly\nimprove the planning capabilities of LLMs.", "published": "2025-03-24 15:50:20", "link": "http://arxiv.org/abs/2503.18809v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Option Discovery Using LLM-guided Semantic Hierarchical Reinforcement Learning", "abstract": "Large Language Models (LLMs) have shown remarkable promise in reasoning and\ndecision-making, yet their integration with Reinforcement Learning (RL) for\ncomplex robotic tasks remains underexplored. In this paper, we propose an\nLLM-guided hierarchical RL framework, termed LDSC, that leverages LLM-driven\nsubgoal selection and option reuse to enhance sample efficiency,\ngeneralization, and multi-task adaptability. Traditional RL methods often\nsuffer from inefficient exploration and high computational cost. Hierarchical\nRL helps with these challenges, but existing methods often fail to reuse\noptions effectively when faced with new tasks. To address these limitations, we\nintroduce a three-stage framework that uses LLMs for subgoal generation given\nnatural language description of the task, a reusable option learning and\nselection method, and an action-level policy, enabling more effective\ndecision-making across diverse tasks. By incorporating LLMs for subgoal\nprediction and policy guidance, our approach improves exploration efficiency\nand enhances learning performance. On average, LDSC outperforms the baseline by\n55.9\\% in average reward, demonstrating its effectiveness in complex RL\nsettings. More details and experiment videos could be found in\n\\href{https://raaslab.org/projects/LDSC/}{this\nlink\\footnote{https://raaslab.org/projects/LDSC}}.", "published": "2025-03-24 15:49:56", "link": "http://arxiv.org/abs/2503.19007v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Computational Thinking with Computer Vision: Developing AI Competency in an Introductory Computer Science Course", "abstract": "Developing competency in artificial intelligence is becoming increasingly\ncrucial for computer science (CS) students at all levels of the CS curriculum.\nHowever, most previous research focuses on advanced CS courses, as traditional\nintroductory courses provide limited opportunities to develop AI skills and\nknowledge. This paper introduces an introductory CS course where students learn\ncomputational thinking through computer vision, a sub-field of AI, as an\napplication context. The course aims to achieve computational thinking outcomes\nalongside critical thinking outcomes that expose students to AI approaches and\ntheir societal implications. Through experiential activities such as individual\nprojects and reading discussions, our course seeks to balance technical\nlearning and critical thinking goals. Our evaluation, based on pre-and\npost-course surveys, shows an improved sense of belonging, self-efficacy, and\nAI ethics awareness among students. The results suggest that an AI-focused\ncontext can enhance participation and employability, student-selected projects\nsupport self-efficacy, and ethically grounded AI instruction can be effective\nfor interdisciplinary audiences. Students' discussions on reading assignments\ndemonstrated deep engagement with the complex challenges in today's AI\nlandscape. Finally, we share insights on scaling such courses for larger\ncohorts and improving the learning experience for introductory CS students.", "published": "2025-03-24 15:49:37", "link": "http://arxiv.org/abs/2503.19006v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Frequency Dynamic Convolution for Dense Image Prediction", "abstract": "While Dynamic Convolution (DY-Conv) has shown promising performance by\nenabling adaptive weight selection through multiple parallel weights combined\nwith an attention mechanism, the frequency response of these weights tends to\nexhibit high similarity, resulting in high parameter costs but limited\nadaptability. In this work, we introduce Frequency Dynamic Convolution\n(FDConv), a novel approach that mitigates these limitations by learning a fixed\nparameter budget in the Fourier domain. FDConv divides this budget into\nfrequency-based groups with disjoint Fourier indices, enabling the construction\nof frequency-diverse weights without increasing the parameter cost. To further\nenhance adaptability, we propose Kernel Spatial Modulation (KSM) and Frequency\nBand Modulation (FBM). KSM dynamically adjusts the frequency response of each\nfilter at the spatial level, while FBM decomposes weights into distinct\nfrequency bands in the frequency domain and modulates them dynamically based on\nlocal content. Extensive experiments on object detection, segmentation, and\nclassification validate the effectiveness of FDConv. We demonstrate that when\napplied to ResNet-50, FDConv achieves superior performance with a modest\nincrease of +3.6M parameters, outperforming previous methods that require\nsubstantial increases in parameter budgets (e.g., CondConv +90M, KW +76.5M).\nMoreover, FDConv seamlessly integrates into a variety of architectures,\nincluding ConvNeXt, Swin-Transformer, offering a flexible and efficient\nsolution for modern vision tasks. The code is made publicly available at\nhttps://github.com/Linwei-Chen/FDConv.", "published": "2025-03-24 15:32:06", "link": "http://arxiv.org/abs/2503.18783v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The case for delegated AI autonomy for Human AI teaming in healthcare", "abstract": "In this paper we propose an advanced approach to integrating artificial\nintelligence (AI) into healthcare: autonomous decision support. This approach\nallows the AI algorithm to act autonomously for a subset of patient cases\nwhilst serving a supportive role in other subsets of patient cases based on\ndefined delegation criteria. By leveraging the complementary strengths of both\nhumans and AI, it aims to deliver greater overall performance than existing\nhuman-AI teaming models. It ensures safe handling of patient cases and\npotentially reduces clinician review time, whilst being mindful of AI tool\nlimitations. After setting the approach within the context of current human-AI\nteaming models, we outline the delegation criteria and apply them to a specific\nAI-based tool used in histopathology. The potential impact of the approach and\nthe regulatory requirements for its successful implementation are then\ndiscussed.", "published": "2025-03-24 15:26:54", "link": "http://arxiv.org/abs/2503.18778v1", "categories": ["cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Mechanistic Interpretability of Fine-Tuned Vision Transformers on Distorted Images: Decoding Attention Head Behavior for Transparent and Trustworthy AI", "abstract": "Mechanistic interpretability improves the safety, reliability, and robustness\nof large AI models. This study examined individual attention heads in vision\ntransformers (ViTs) fine tuned on distorted 2D spectrogram images containing\nnon relevant content (axis labels, titles, color bars). By introducing\nextraneous features, the study analyzed how transformer components processed\nunrelated information, using mechanistic interpretability to debug issues and\nreveal insights into transformer architectures. Attention maps assessed head\ncontributions across layers. Heads in early layers (1 to 3) showed minimal task\nimpact with ablation increased MSE loss slightly ({\\mu}=0.11%, {\\sigma}=0.09%),\nindicating focus on less critical low level features. In contrast, deeper heads\n(e.g., layer 6) caused a threefold higher loss increase ({\\mu}=0.34%,\n{\\sigma}=0.02%), demonstrating greater task importance. Intermediate layers (6\nto 11) exhibited monosemantic behavior, attending exclusively to chirp regions.\nSome early heads (1 to 4) were monosemantic but non task relevant (e.g. text\ndetectors, edge or corner detectors). Attention maps distinguished monosemantic\nheads (precise chirp localization) from polysemantic heads (multiple irrelevant\nregions). These findings revealed functional specialization in ViTs, showing\nhow heads processed relevant vs. extraneous information. By decomposing\ntransformers into interpretable components, this work enhanced model\nunderstanding, identified vulnerabilities, and advanced safer, more transparent\nAI.", "published": "2025-03-24 15:11:24", "link": "http://arxiv.org/abs/2503.18762v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "EgoSurgery-HTS: A Dataset for Egocentric Hand-Tool Segmentation in Open Surgery Videos", "abstract": "Egocentric open-surgery videos capture rich, fine-grained details essential\nfor accurately modeling surgical procedures and human behavior in the operating\nroom. A detailed, pixel-level understanding of hands and surgical tools is\ncrucial for interpreting a surgeon's actions and intentions. We introduce\nEgoSurgery-HTS, a new dataset with pixel-wise annotations and a benchmark suite\nfor segmenting surgical tools, hands, and interacting tools in egocentric\nopen-surgery videos. Specifically, we provide a labeled dataset for (1) tool\ninstance segmentation of 14 distinct surgical tools, (2) hand instance\nsegmentation, and (3) hand-tool segmentation to label hands and the tools they\nmanipulate. Using EgoSurgery-HTS, we conduct extensive evaluations of\nstate-of-the-art segmentation methods and demonstrate significant improvements\nin the accuracy of hand and hand-tool segmentation in egocentric open-surgery\nvideos compared to existing datasets. The dataset will be released at\nhttps://github.com/Fujiry0/EgoSurgery.", "published": "2025-03-24 15:04:32", "link": "http://arxiv.org/abs/2503.18755v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "AED: Automatic Discovery of Effective and Diverse Vulnerabilities for Autonomous Driving Policy with Large Language Models", "abstract": "Assessing the safety of autonomous driving policy is of great importance, and\nreinforcement learning (RL) has emerged as a powerful method for discovering\ncritical vulnerabilities in driving policies. However, existing RL-based\napproaches often struggle to identify vulnerabilities that are both\neffective-meaning the autonomous vehicle is genuinely responsible for the\naccidents-and diverse-meaning they span various failure types. To address these\nchallenges, we propose AED, a framework that uses large language models (LLMs)\nto automatically discover effective and diverse vulnerabilities in autonomous\ndriving policies. We first utilize an LLM to automatically design reward\nfunctions for RL training. Then we let the LLM consider a diverse set of\naccident types and train adversarial policies for different accident types in\nparallel. Finally, we use preference-based learning to filter ineffective\naccidents and enhance the effectiveness of each vulnerability. Experiments\nacross multiple simulated traffic scenarios and tested policies show that AED\nuncovers a broader range of vulnerabilities and achieves higher attack success\nrates compared with expert-designed rewards, thereby reducing the need for\nmanual reward engineering and improving the diversity and effectiveness of\nvulnerability discovery.", "published": "2025-03-24 14:59:17", "link": "http://arxiv.org/abs/2503.20804v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Chirp Localization via Fine-Tuned Transformer Model: A Proof-of-Concept Study", "abstract": "Spectrograms are pivotal in time-frequency signal analysis, widely used in\naudio processing and computational neuroscience. Chirp-like patterns in\nelectroencephalogram (EEG) spectrograms (marked by linear or exponential\nfrequency sweep) are key biomarkers for seizure dynamics, but automated tools\nfor their detection, localization, and feature extraction are lacking. This\nstudy bridges this gap by fine-tuning a Vision Transformer (ViT) model on\nsynthetic spectrograms, augmented with Low-Rank Adaptation (LoRA) to boost\nadaptability. We generated 100000 synthetic spectrograms with chirp parameters,\ncreating the first large-scale benchmark for chirp localization. These\nspectrograms mimic neural chirps using linear or exponential frequency sweep,\nGaussian noise, and smoothing. A ViT model, adapted for regression, predicted\nchirp parameters. LoRA fine-tuned the attention layers, enabling efficient\nupdates to the pre-trained backbone. Training used MSE loss and the AdamW\noptimizer, with a learning rate scheduler and early stopping to curb\noverfitting. Only three features were targeted: Chirp Start Time (Onset Time),\nChirp Start Frequency (Onset Frequency), and Chirp End Frequency (Offset\nFrequency). Performance was evaluated via Pearson correlation between predicted\nand actual labels. Results showed strong alignment: 0.9841 correlation for\nchirp start time, with stable inference times (137 to 140s) and minimal bias in\nerror distributions. This approach offers a tool for chirp analysis in EEG\ntime-frequency representation, filling a critical methodological void.", "published": "2025-03-24 14:27:07", "link": "http://arxiv.org/abs/2503.22713v1", "categories": ["eess.AS", "cs.AI", "cs.CV", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Energy-Efficient Dynamic Training and Inference for GNN-Based Network Modeling", "abstract": "Efficient network modeling is essential for resource optimization and network\nplanning in next-generation large-scale complex networks. Traditional\napproaches, such as queuing theory-based modeling and packet-based simulators,\ncan be inefficient due to the assumption made and the computational expense,\nrespectively. To address these challenges, we propose an innovative\nenergy-efficient dynamic orchestration of Graph Neural Networks (GNN) based\nmodel training and inference framework for context-aware network modeling and\npredictions. We have developed a low-complexity solution framework, QAG, that\nis a Quantum approximation optimization (QAO) algorithm for Adaptive\norchestration of GNN-based network modeling. We leverage the tripartite graph\nmodel to represent a multi-application system with many compute nodes.\nThereafter, we apply the constrained graph-cutting using QAO to find the\nfeasible energy-efficient configurations of the GNN-based model and deploying\nthem on the available compute nodes to meet the network modeling application\nrequirements. The proposed QAG scheme closely matches the optimum and offers\natleast a 50% energy saving while meeting the application requirements with 60%\nlower churn-rate.", "published": "2025-03-24 14:17:57", "link": "http://arxiv.org/abs/2503.18706v1", "categories": ["cs.NI", "cs.AI", "cs.ET", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Efficient Continual Adaptation of Pretrained Robotic Policy with Online Meta-Learned Adapters", "abstract": "Continual adaptation is essential for general autonomous agents. For example,\na household robot pretrained with a repertoire of skills must still adapt to\nunseen tasks specific to each household. Motivated by this, building upon\nparameter-efficient fine-tuning in language models, prior works have explored\nlightweight adapters to adapt pretrained policies, which can preserve learned\nfeatures from the pretraining phase and demonstrate good adaptation\nperformances. However, these approaches treat task learning separately,\nlimiting knowledge transfer between tasks. In this paper, we propose Online\nMeta-Learned adapters (OMLA). Instead of applying adapters directly, OMLA can\nfacilitate knowledge transfer from previously learned tasks to current learning\ntasks through a novel meta-learning objective. Extensive experiments in both\nsimulated and real-world environments demonstrate that OMLA can lead to better\nadaptation performances compared to the baseline methods. The project link:\nhttps://ricky-zhu.github.io/OMLA/.", "published": "2025-03-24 13:55:47", "link": "http://arxiv.org/abs/2503.18684v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "CEFW: A Comprehensive Evaluation Framework for Watermark in Large Language Models", "abstract": "Text watermarking provides an effective solution for identifying synthetic\ntext generated by large language models. However, existing techniques often\nfocus on satisfying specific criteria while ignoring other key aspects, lacking\na unified evaluation. To fill this gap, we propose the Comprehensive Evaluation\nFramework for Watermark (CEFW), a unified framework that comprehensively\nevaluates watermarking methods across five key dimensions: ease of detection,\nfidelity of text quality, minimal embedding cost, robustness to adversarial\nattacks, and imperceptibility to prevent imitation or forgery. By assessing\nwatermarks according to all these key criteria, CEFW offers a thorough\nevaluation of their practicality and effectiveness. Moreover, we introduce a\nsimple and effective watermarking method called Balanced Watermark (BW), which\nguarantees robustness and imperceptibility through balancing the way watermark\ninformation is added. Extensive experiments show that BW outperforms existing\nmethods in overall performance across all evaluation dimensions. We release our\ncode to the community for future research.\nhttps://github.com/DrankXs/BalancedWatermark.", "published": "2025-03-24 13:50:32", "link": "http://arxiv.org/abs/2503.20802v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Any6D: Model-free 6D Pose Estimation of Novel Objects", "abstract": "We introduce Any6D, a model-free framework for 6D object pose estimation that\nrequires only a single RGB-D anchor image to estimate both the 6D pose and size\nof unknown objects in novel scenes. Unlike existing methods that rely on\ntextured 3D models or multiple viewpoints, Any6D leverages a joint object\nalignment process to enhance 2D-3D alignment and metric scale estimation for\nimproved pose accuracy. Our approach integrates a render-and-compare strategy\nto generate and refine pose hypotheses, enabling robust performance in\nscenarios with occlusions, non-overlapping views, diverse lighting conditions,\nand large cross-environment variations. We evaluate our method on five\nchallenging datasets: REAL275, Toyota-Light, HO3D, YCBINEOAT, and LM-O,\ndemonstrating its effectiveness in significantly outperforming state-of-the-art\nmethods for novel object pose estimation. Project page:\nhttps://taeyeop.com/any6d", "published": "2025-03-24 13:46:21", "link": "http://arxiv.org/abs/2503.18673v2", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "From Fragment to One Piece: A Survey on AI-Driven Graphic Design", "abstract": "This survey provides a comprehensive overview of the advancements in\nArtificial Intelligence in Graphic Design (AIGD), focusing on integrating AI\ntechniques to support design interpretation and enhance the creative process.\nWe categorize the field into two primary directions: perception tasks, which\ninvolve understanding and analyzing design elements, and generation tasks,\nwhich focus on creating new design elements and layouts. The survey covers\nvarious subtasks, including visual element perception and generation, aesthetic\nand semantic understanding, layout analysis, and generation. We highlight the\nrole of large language models and multimodal approaches in bridging the gap\nbetween localized visual features and global design intent. Despite significant\nprogress, challenges remain to understanding human intent, ensuring\ninterpretability, and maintaining control over multilayered compositions. This\nsurvey serves as a guide for researchers, providing information on the current\nstate of AIGD and potential future\ndirections\\footnote{https://github.com/zhangtianer521/excellent\\_Intelligent\\_graphic\\_design}.", "published": "2025-03-24 13:05:09", "link": "http://arxiv.org/abs/2503.18641v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards Human-Understandable Multi-Dimensional Concept Discovery", "abstract": "Concept-based eXplainable AI (C-XAI) aims to overcome the limitations of\ntraditional saliency maps by converting pixels into human-understandable\nconcepts that are consistent across an entire dataset. A crucial aspect of\nC-XAI is completeness, which measures how well a set of concepts explains a\nmodel's decisions. Among C-XAI methods, Multi-Dimensional Concept Discovery\n(MCD) effectively improves completeness by breaking down the CNN latent space\ninto distinct and interpretable concept subspaces. However, MCD's explanations\ncan be difficult for humans to understand, raising concerns about their\npractical utility. To address this, we propose Human-Understandable\nMulti-dimensional Concept Discovery (HU-MCD). HU-MCD uses the Segment Anything\nModel for concept identification and implements a CNN-specific input masking\ntechnique to reduce noise introduced by traditional masking methods. These\nchanges to MCD, paired with the completeness relation, enable HU-MCD to enhance\nconcept understandability while maintaining explanation faithfulness. Our\nexperiments, including human subject studies, show that HU-MCD provides more\nprecise and reliable explanations than existing C-XAI methods. The code is\navailable at https://github.com/grobruegge/hu-mcd.", "published": "2025-03-24 12:45:52", "link": "http://arxiv.org/abs/2503.18629v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Dig2DIG: Dig into Diffusion Information Gains for Image Fusion", "abstract": "Image fusion integrates complementary information from multi-source images to\ngenerate more informative results. Recently, the diffusion model, which\ndemonstrates unprecedented generative potential, has been explored in image\nfusion. However, these approaches typically incorporate predefined multimodal\nguidance into diffusion, failing to capture the dynamically changing\nsignificance of each modality, while lacking theoretical guarantees. To address\nthis issue, we reveal a significant spatio-temporal imbalance in image\ndenoising; specifically, the diffusion model produces dynamic information gains\nin different image regions with denoising steps. Based on this observation, we\nDig into the Diffusion Information Gains (Dig2DIG) and theoretically derive a\ndiffusion-based dynamic image fusion framework that provably reduces the upper\nbound of the generalization error. Accordingly, we introduce diffusion\ninformation gains (DIG) to quantify the information contribution of each\nmodality at different denoising steps, thereby providing dynamic guidance\nduring the fusion process. Extensive experiments on multiple fusion scenarios\nconfirm that our method outperforms existing diffusion-based approaches in\nterms of both fusion quality and inference efficiency.", "published": "2025-03-24 12:43:11", "link": "http://arxiv.org/abs/2503.18627v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Adventurer: Exploration with BiGAN for Deep Reinforcement Learning", "abstract": "Recent developments in deep reinforcement learning have been very successful\nin learning complex, previously intractable problems. Sample efficiency and\nlocal optimality, however, remain significant challenges. To address these\nchallenges, novelty-driven exploration strategies have emerged and shown\npromising potential. Unfortunately, no single algorithm outperforms all others\nin all tasks and most of them struggle with tasks with high-dimensional and\ncomplex observations. In this work, we propose Adventurer, a novelty-driven\nexploration algorithm that is based on Bidirectional Generative Adversarial\nNetworks (BiGAN), where BiGAN is trained to estimate state novelty.\nIntuitively, a generator that has been trained on the distribution of visited\nstates should only be able to generate a state coming from the distribution of\nvisited states. As a result, novel states using the generator to reconstruct\ninput states from certain latent representations would lead to larger\nreconstruction errors. We show that BiGAN performs well in estimating state\nnovelty for complex observations. This novelty estimation method can be\ncombined with intrinsic-reward-based exploration. Our empirical results show\nthat Adventurer produces competitive results on a range of popular benchmark\ntasks, including continuous robotic manipulation tasks (e.g. Mujoco robotics)\nand high-dimensional image-based tasks (e.g. Atari games).", "published": "2025-03-24 12:13:24", "link": "http://arxiv.org/abs/2503.18612v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Reinforcement Learning in Switching Non-Stationary Markov Decision Processes: Algorithms and Convergence Analysis", "abstract": "Reinforcement learning in non-stationary environments is challenging due to\nabrupt and unpredictable changes in dynamics, often causing traditional\nalgorithms to fail to converge. However, in many real-world cases,\nnon-stationarity has some structure that can be exploited to develop algorithms\nand facilitate theoretical analysis. We introduce one such structure, Switching\nNon-Stationary Markov Decision Processes (SNS-MDP), where environments switch\nover time based on an underlying Markov chain. Under a fixed policy, the value\nfunction of an SNS-MDP admits a closed-form solution determined by the Markov\nchain's statistical properties, and despite the inherent non-stationarity,\nTemporal Difference (TD) learning methods still converge to the correct value\nfunction. Furthermore, policy improvement can be performed, and it is shown\nthat policy iteration converges to the optimal policy. Moreover, since\nQ-learning converges to the optimal Q-function, it likewise yields the\ncorresponding optimal policy. To illustrate the practical advantages of\nSNS-MDPs, we present an example in communication networks where channel noise\nfollows a Markovian pattern, demonstrating how this framework can effectively\nguide decision-making in complex, time-varying contexts.", "published": "2025-03-24 12:05:30", "link": "http://arxiv.org/abs/2503.18607v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Adaptive Unimodal Regulation for Balanced Multimodal Information Acquisition", "abstract": "Sensory training during the early ages is vital for human development.\nInspired by this cognitive phenomenon, we observe that the early training stage\nis also important for the multimodal learning process, where dataset\ninformation is rapidly acquired. We refer to this stage as the prime learning\nwindow. However, based on our observation, this prime learning window in\nmultimodal learning is often dominated by information-sufficient modalities,\nwhich in turn suppresses the information acquisition of\ninformation-insufficient modalities. To address this issue, we propose\nInformation Acquisition Regulation (InfoReg), a method designed to balance\ninformation acquisition among modalities. Specifically, InfoReg slows down the\ninformation acquisition process of information-sufficient modalities during the\nprime learning window, which could promote information acquisition of\ninformation-insufficient modalities. This regulation enables a more balanced\nlearning process and improves the overall performance of the multimodal\nnetwork. Experiments show that InfoReg outperforms related multimodal\nimbalanced methods across various datasets, achieving superior model\nperformance. The code is available at\nhttps://github.com/GeWu-Lab/InfoReg_CVPR2025.", "published": "2025-03-24 11:52:57", "link": "http://arxiv.org/abs/2503.18595v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Role of Artificial Intelligence in Enhancing Insulin Recommendations and Therapy Outcomes", "abstract": "The growing worldwide incidence of diabetes requires more effective\napproaches for managing blood glucose levels. Insulin delivery systems have\nadvanced significantly, with artificial intelligence (AI) playing a key role in\nimproving their precision and adaptability. AI algorithms, particularly those\nbased on reinforcement learning, allow for personalised insulin dosing by\ncontinuously adapting to an individual's responses. Despite these advancements,\nchallenges such as data privacy, algorithm transparency, and accessibility\nstill need to be addressed. Continued progress and validation in AI-driven\ninsulin delivery systems promise to improve therapy outcomes further, offering\npeople more effective and individualised management of their diabetes. This\npaper presents an overview of current strategies, key challenges, and future\ndirections.", "published": "2025-03-24 11:50:14", "link": "http://arxiv.org/abs/2503.18592v1", "categories": ["cs.AI", "cs.LG", "physics.med-ph"], "primary_category": "cs.AI"}
{"title": "DisentTalk: Cross-lingual Talking Face Generation via Semantic Disentangled Diffusion Model", "abstract": "Recent advances in talking face generation have significantly improved facial\nanimation synthesis. However, existing approaches face fundamental limitations:\n3DMM-based methods maintain temporal consistency but lack fine-grained regional\ncontrol, while Stable Diffusion-based methods enable spatial manipulation but\nsuffer from temporal inconsistencies. The integration of these approaches is\nhindered by incompatible control mechanisms and semantic entanglement of facial\nrepresentations. This paper presents DisentTalk, introducing a data-driven\nsemantic disentanglement framework that decomposes 3DMM expression parameters\ninto meaningful subspaces for fine-grained facial control. Building upon this\ndisentangled representation, we develop a hierarchical latent diffusion\narchitecture that operates in 3DMM parameter space, integrating region-aware\nattention mechanisms to ensure both spatial precision and temporal coherence.\nTo address the scarcity of high-quality Chinese training data, we introduce\nCHDTF, a Chinese high-definition talking face dataset. Extensive experiments\nshow superior performance over existing methods across multiple metrics,\nincluding lip synchronization, expression quality, and temporal consistency.\nProject Page: https://kangweiiliu.github.io/DisentTalk.", "published": "2025-03-24 11:46:34", "link": "http://arxiv.org/abs/2503.19001v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Are Anxiety Detection Models Generalizable? A Cross-Activity and Cross-Population Study Using Wearables", "abstract": "Anxiety-provoking activities, such as public speaking, can trigger heightened\nanxiety responses in individuals with anxiety disorders. Recent research\nsuggests that physiological signals, including electrocardiogram (ECG) and\nelectrodermal activity (EDA), collected via wearable devices, can be used to\ndetect anxiety in such contexts through machine learning models. However, the\ngeneralizability of these anxiety prediction models across different activities\nand diverse populations remains underexplored-an essential step for assessing\nmodel bias and fostering user trust in broader applications. To address this\ngap, we conducted a study with 111 participants who engaged in three\nanxiety-provoking activities. Utilizing both our collected dataset and two\nwell-known publicly available datasets, we evaluated the generalizability of\nanxiety detection models within participants (for both same-activity and\ncross-activity scenarios) and across participants (within-activity and\ncross-activity). In total, we trained and tested more than 3348 anxiety\ndetection models (using six classifiers, 31 feature sets, and 18 train-test\nconfigurations). Our results indicate that three key metrics-AUROC, recall for\nanxious states, and recall for non-anxious states-were slightly above the\nbaseline score of 0.5. The best AUROC scores ranged from 0.62 to 0.73, with\nrecall for the anxious class spanning 35.19% to 74.3%. Interestingly, model\nperformance (as measured by AUROC) remained relatively stable across different\nactivities and participant groups, though recall for the anxious class did\nexhibit some variation.", "published": "2025-03-24 11:43:34", "link": "http://arxiv.org/abs/2504.03695v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding", "abstract": "Modern vision-language models (VLMs) develop patch embedding and convolution\nbackbone within vector space, especially Euclidean ones, at the very founding.\nWhen expanding VLMs to a galaxy scale for understanding astronomical phenomena,\nthe integration of spherical space for planetary orbits and hyperbolic spaces\nfor black holes raises two formidable challenges. a) The current pre-training\nmodel is confined to Euclidean space rather than a comprehensive geometric\nembedding. b) The predominant architecture lacks suitable backbones for\nanisotropic physical geometries. In this paper, we introduced Galaxy-Walker, a\ngeometry-aware VLM, for the universe-level vision understanding tasks. We\nproposed the geometry prompt that generates geometry tokens by random walks\nacross diverse spaces on a multi-scale physical graph, along with a geometry\nadapter that compresses and reshapes the space anisotropy in a\nmixture-of-experts manner. Extensive experiments demonstrate the effectiveness\nof our approach, with Galaxy-Walker achieving state-of-the-art performance in\nboth galaxy property estimation ($R^2$ scores up to $0.91$) and morphology\nclassification tasks (up to $+0.17$ F1 improvement in challenging features),\nsignificantly outperforming both domain-specific models and general-purpose\nVLMs.", "published": "2025-03-24 11:35:56", "link": "http://arxiv.org/abs/2503.18578v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Identifying and Characterising Higher Order Interactions in Mobility Networks Using Hypergraphs", "abstract": "Understanding human mobility is essential for applications ranging from urban\nplanning to public health. Traditional mobility models such as flow networks\nand colocation matrices capture only pairwise interactions between discrete\nlocations, overlooking higher-order relationships among locations (i.e.,\nmobility flow among two or more locations). To address this, we propose\nco-visitation hypergraphs, a model that leverages temporal observation windows\nto extract group interactions between locations from individual mobility\ntrajectory data. Using frequent pattern mining, our approach constructs\nhypergraphs that capture dynamic mobility behaviors across different spatial\nand temporal scales. We validate our method on a publicly available mobility\ndataset and demonstrate its effectiveness in analyzing city-scale mobility\npatterns, detecting shifts during external disruptions such as extreme weather\nevents, and examining how a location's connectivity (degree) relates to the\nnumber of points of interest (POIs) within it. Our results demonstrate that our\nhypergraph-based mobility analysis framework is a valuable tool with potential\napplications in diverse fields such as public health, disaster resilience, and\nurban planning.", "published": "2025-03-24 11:29:06", "link": "http://arxiv.org/abs/2503.18572v1", "categories": ["cs.SI", "cs.AI", "cs.DB", "cs.DM", "math.CO"], "primary_category": "cs.SI"}
{"title": "Anchor-based oversampling for imbalanced tabular data via contrastive and adversarial learning", "abstract": "Imbalanced data represent a distribution with more frequencies of one class\n(majority) than the other (minority). This phenomenon occurs across various\ndomains, such as security, medical care and human activity. In imbalanced\nlearning, classification algorithms are typically inclined to classify the\nmajority class accurately, resulting in artificially high accuracy rates. As a\nresult, many minority samples are mistakenly labelled as majority-class\ninstances, resulting in a bias that benefits the majority class. This study\npresents a framework based on boundary anchor samples to tackle the imbalance\nlearning challenge. First, we select and use anchor samples to train a\nmultilayer perceptron (MLP) classifier, which acts as a prior knowledge model\nand aids the adversarial and contrastive learning procedures. Then, we designed\na novel deep generative model called Anchor Stabilized Conditional Generative\nAdversarial Network or Anch-SCGAN in short. Anch-SCGAN is supported with two\ngenerators for the minority and majority classes and a discriminator\nincorporating additional class-specific information from the pre-trained\nfeature extractor MLP. In addition, we facilitate the generator's training\nprocedure in two ways. First, we define a new generator loss function based on\nreprocessed anchor samples and contrastive learning. Second, we apply a scoring\nstrategy to stabilize the adversarial training part in generators. We train\nAnch-SCGAN and further finetune it with anchor samples to improve the precision\nof the generated samples. Our experiments on 16 real-world imbalanced datasets\nillustrate that Anch-SCGAN outperforms the renowned methods in imbalanced\nlearning.", "published": "2025-03-24 11:25:21", "link": "http://arxiv.org/abs/2503.18569v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation", "abstract": "Conditional human animation transforms a static reference image into a\ndynamic sequence by applying motion cues such as poses. These motion cues are\ntypically derived from video data but are susceptible to limitations including\nlow temporal resolution, motion blur, overexposure, and inaccuracies under\nlow-light conditions. In contrast, event cameras provide data streams with\nexceptionally high temporal resolution, a wide dynamic range, and inherent\nresistance to motion blur and exposure issues. In this work, we propose\nEvAnimate, a framework that leverages event streams as motion cues to animate\nstatic human images. Our approach employs a specialized event representation\nthat transforms asynchronous event streams into 3-channel slices with\ncontrollable slicing rates and appropriate slice density, ensuring\ncompatibility with diffusion models. Subsequently, a dual-branch architecture\ngenerates high-quality videos by harnessing the inherent motion dynamics of the\nevent streams, thereby enhancing both video quality and temporal consistency.\nSpecialized data augmentation strategies further enhance cross-person\ngeneralization. Finally, we establish a new benchmarking, including simulated\nevent data for training and validation, and a real-world event dataset\ncapturing human actions under normal and extreme scenarios. The experiment\nresults demonstrate that EvAnimate achieves high temporal fidelity and robust\nperformance in scenarios where traditional video-derived cues fall short.", "published": "2025-03-24 11:05:41", "link": "http://arxiv.org/abs/2503.18552v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Discriminative protein sequence modelling with Latent Space Diffusion", "abstract": "We explore a framework for protein sequence representation learning that\ndecomposes the task between manifold learning and distributional modelling.\nSpecifically we present a Latent Space Diffusion architecture which combines a\nprotein sequence autoencoder with a denoising diffusion model operating on its\nlatent space. We obtain a one-parameter family of learned representations from\nthe diffusion model, along with the autoencoder's latent representation. We\npropose and evaluate two autoencoder architectures: a homogeneous model forcing\namino acids of the same type to be identically distributed in the latent space,\nand an inhomogeneous model employing a noise-based variant of masking. As a\nbaseline we take a latent space learned by masked language modelling, and\nevaluate discriminative capability on a range of protein property prediction\ntasks. Our finding is twofold: the diffusion models trained on both our\nproposed variants display higher discriminative power than the one trained on\nthe masked language model baseline, none of the diffusion representations\nachieve the performance of the masked language model embeddings themselves.", "published": "2025-03-24 11:03:57", "link": "http://arxiv.org/abs/2503.18551v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "RLCAD: Reinforcement Learning Training Gym for Revolution Involved CAD Command Sequence Generation", "abstract": "A CAD command sequence is a typical parametric design paradigm in 3D CAD\nsystems where a model is constructed by overlaying 2D sketches with operations\nsuch as extrusion, revolution, and Boolean operations. Although there is\ngrowing academic interest in the automatic generation of command sequences,\nexisting methods and datasets only support operations such as 2D sketching,\nextrusion,and Boolean operations. This limitation makes it challenging to\nrepresent more complex geometries. In this paper, we present a reinforcement\nlearning (RL) training environment (gym) built on a CAD geometric engine. Given\nan input boundary representation (B-Rep) geometry, the policy network in the RL\nalgorithm generates an action. This action, along with previously generated\nactions, is processed within the gym to produce the corresponding CAD geometry,\nwhich is then fed back into the policy network. The rewards, determined by the\ndifference between the generated and target geometries within the gym, are used\nto update the RL network. Our method supports operations beyond sketches,\nBoolean, and extrusion, including revolution operations. With this training\ngym, we achieve state-of-the-art (SOTA) quality in generating command sequences\nfrom B-Rep geometries. In addition, our method can significantly improve the\nefficiency of command sequence generation by a factor of 39X compared with the\nprevious training gym.", "published": "2025-03-24 11:01:05", "link": "http://arxiv.org/abs/2503.18549v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "An Identity and Interaction Based Network Forensic Analysis", "abstract": "In todays landscape of increasing electronic crime, network forensics plays a\npivotal role in digital investigations. It aids in understanding which systems\nto analyse and as a supplement to support evidence found through more\ntraditional computer based investigations. However, the nature and\nfunctionality of the existing Network Forensic Analysis Tools (NFATs) fall\nshort compared to File System Forensic Analysis Tools (FS FATs) in providing\nusable data. The analysis tends to focus upon IP addresses, which are not\nsynonymous with user identities, a point of significant interest to\ninvestigators. This paper presents several experiments designed to create a\nnovel NFAT approach that can identify users and understand how they are using\nnetwork based applications whilst the traffic remains encrypted. The\nexperiments build upon the prior art and investigate how effective this\napproach is in classifying users and their actions. Utilising an in-house\ndataset composed of 50 million packers, the experiments are formed of three\nincremental developments that assist in improving performance. Building upon\nthe successful experiments, a proposed NFAT interface is presented to\nillustrate the ease at which investigators would be able to ask relevant\nquestions of user interactions. The experiments profiled across 27 users, has\nyielded an average 93.3% True Positive Identification Rate (TPIR), with 41% of\nusers experiencing 100% TPIR. Skype, Wikipedia and Hotmail services achieved a\nnotably high level of recognition performance. The study has developed and\nevaluated an approach to analyse encrypted network traffic more effectively\nthrough the modelling of network traffic and to subsequently visualise these\ninteractions through a novel network forensic analysis tool.", "published": "2025-03-24 10:52:23", "link": "http://arxiv.org/abs/2503.18542v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "UniPCGC: Towards Practical Point Cloud Geometry Compression via an Efficient Unified Approach", "abstract": "Learning-based point cloud compression methods have made significant progress\nin terms of performance. However, these methods still encounter challenges\nincluding high complexity, limited compression modes, and a lack of support for\nvariable rate, which restrict the practical application of these methods. In\norder to promote the development of practical point cloud compression, we\npropose an efficient unified point cloud geometry compression framework, dubbed\nas UniPCGC. It is a lightweight framework that supports lossy compression,\nlossless compression, variable rate and variable complexity. First, we\nintroduce the Uneven 8-Stage Lossless Coder (UELC) in the lossless mode, which\nallocates more computational complexity to groups with higher coding\ndifficulty, and merges groups with lower coding difficulty. Second, Variable\nRate and Complexity Module (VRCM) is achieved in the lossy mode through joint\nadoption of a rate modulation module and dynamic sparse convolution. Finally,\nthrough the dynamic combination of UELC and VRCM, we achieve lossy compression,\nlossless compression, variable rate and complexity within a unified framework.\nCompared to the previous state-of-the-art method, our method achieves a\ncompression ratio (CR) gain of 8.1\\% on lossless compression, and a Bjontegaard\nDelta Rate (BD-Rate) gain of 14.02\\% on lossy compression, while also\nsupporting variable rate and variable complexity.", "published": "2025-03-24 10:51:28", "link": "http://arxiv.org/abs/2503.18541v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "HiRes-FusedMIM: A High-Resolution RGB-DSM Pre-trained Model for Building-Level Remote Sensing Applications", "abstract": "Recent advances in self-supervised learning have led to the development of\nfoundation models that have significantly advanced performance in various\ncomputer vision tasks. However, despite their potential, these models often\noverlook the crucial role of high-resolution digital surface models (DSMs) in\nunderstanding urban environments, particularly for building-level analysis,\nwhich is essential for applications like digital twins. To address this gap, we\nintroduce HiRes-FusedMIM, a novel pre-trained model specifically designed to\nleverage the rich information contained within high-resolution RGB and DSM\ndata. HiRes-FusedMIM utilizes a dual-encoder simple masked image modeling\n(SimMIM) architecture with a multi-objective loss function that combines\nreconstruction and contrastive objectives, enabling it to learn powerful, joint\nrepresentations from both modalities. We conducted a comprehensive evaluation\nof HiRes-FusedMIM on a diverse set of downstream tasks, including\nclassification, semantic segmentation, and instance segmentation. Our results\ndemonstrate that: 1) HiRes-FusedMIM outperforms previous state-of-the-art\ngeospatial methods on several building-related datasets, including WHU Aerial\nand LoveDA, demonstrating its effectiveness in capturing and leveraging\nfine-grained building information; 2) Incorporating DSMs during pre-training\nconsistently improves performance compared to using RGB data alone,\nhighlighting the value of elevation information for building-level analysis; 3)\nThe dual-encoder architecture of HiRes-FusedMIM, with separate encoders for RGB\nand DSM data, significantly outperforms a single-encoder model on the Vaihingen\nsegmentation task, indicating the benefits of learning specialized\nrepresentations for each modality. To facilitate further research and\napplications in this direction, we will publicly release the trained model\nweights.", "published": "2025-03-24 10:49:55", "link": "http://arxiv.org/abs/2503.18540v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "MMCR: Advancing Visual Language Model in Multimodal Multi-Turn Contextual Reasoning", "abstract": "Compared to single-turn dialogue, multi-turn dialogue involving multiple\nimages better aligns with the needs of real-world human-AI interactions.\nAdditionally, as training data, it provides richer contextual reasoning\ninformation, thereby guiding the model to achieve better performance. However,\nexisting vision-language models (VLMs) primarily rely on single-turn dialogue\ntraining and evaluation benchmarks. In this paper, following the\ncharacteristics of human dialogue, such as focused topics and concise, clear\ncontent, we present MMCR (Multimodal Multi-turn Contextual Reasoning), a novel\ndataset comprising: (1) MMCR-310k -- the largest multi-image multi-turn\ninstruction tuning dataset with 310K contextual dialogues, each covering 1-4\nimages and 4 or 8 dialogue turns; and (2) MMCR-Bench -- a diagnostic benchmark\nfeaturing dialogues, spanning 8 domains (Humanities, Natural, Science,\nEducation, etc.) and 40 sub-topics. Extensive evaluations demonstrate that\nmodels fine-tuned with MMCR-310k achieve 5.2\\% higher contextual accuracy on\nMMCR-Bench, while showing consistent improvements on existing benchmarks\n(+1.1\\% on AI2D, +1.2\\% on MMMU and MMVet). MMCR and prompt engineering will be\nreleased publicly.", "published": "2025-03-24 10:40:33", "link": "http://arxiv.org/abs/2503.18533v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Neuro-symbolic Weak Supervision: Theory and Semantics", "abstract": "Weak supervision allows machine learning models to learn from limited or\nnoisy labels, but it introduces challenges in interpretability and reliability\n- particularly in multi-instance partial label learning (MI-PLL), where models\nmust resolve both ambiguous labels and uncertain instance-label mappings. We\npropose a semantics for neuro-symbolic framework that integrates Inductive\nLogic Programming (ILP) to improve MI-PLL by providing structured relational\nconstraints that guide learning. Within our semantic characterization, ILP\ndefines a logical hypothesis space for label transitions, clarifies classifier\nsemantics, and establishes interpretable performance standards. This hybrid\napproach improves robustness, transparency, and accountability in weakly\nsupervised settings, ensuring neural predictions align with domain knowledge.\nBy embedding weak supervision into a logical framework, we enhance both\ninterpretability and learning, making weak supervision more suitable for\nreal-world, high-stakes applications.", "published": "2025-03-24 10:02:51", "link": "http://arxiv.org/abs/2503.18509v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Statistically Testing Training Data for Unwanted Error Patterns using Rule-Oriented Regression", "abstract": "Artificial intelligence models trained from data can only be as good as the\nunderlying data is. Biases in training data propagating through to the output\nof a machine learning model are a well-documented and well-understood\nphenomenon, but the machinery to prevent these undesired effects is much less\ndeveloped. Efforts to ensure data is clean during collection, such as using\nbias-aware sampling, are most effective when the entity controlling data\ncollection also trains the AI. In cases where the data is already available,\nhow do we find out if the data was already manipulated, i.e., ``poisoned'', so\nthat an undesired behavior would be trained into a machine learning model? This\nis a challenge fundamentally different to (just) improving approximation\naccuracy or efficiency, and we provide a method to test training data for\nflaws, to establish a trustworthy ground-truth for a subsequent training of\nmachine learning models (of any kind). Unlike the well-studied problem of\napproximating data using fuzzy rules that are generated from the data, our\nmethod hinges on a prior definition of rules to happen before seeing the data\nto be tested. Therefore, the proposed method can also discover hidden error\npatterns, which may also have substantial influence. Our approach extends the\nabilities of conventional statistical testing by letting the ``test-condition''\nbe any Boolean condition to describe a pattern in the data, whose presence we\nwish to determine. The method puts fuzzy inference into a regression model, to\nget the best of the two: explainability from fuzzy logic with statistical\nproperties and diagnostics from the regression, and finally also being\napplicable to ``small data'', hence not requiring large datasets as deep\nlearning methods do. We provide an open source implementation for demonstration\nand experiments.", "published": "2025-03-24 09:52:36", "link": "http://arxiv.org/abs/2503.18497v2", "categories": ["cs.LG", "cs.AI", "68T10 (Primary), 68M25, 62J86 (Secondary)"], "primary_category": "cs.LG"}
{"title": "Large Language Models powered Network Attack Detection: Architecture, Opportunities and Case Study", "abstract": "Network attack detection is a pivotal technology to identify network anomaly\nand classify malicious traffic. Large Language Models (LLMs) are trained on a\nvast corpus of text, have amassed remarkable capabilities of\ncontext-understanding and commonsense knowledge. This has opened up a new door\nfor network threat detection. Researchers have already initiated discussions\nregarding the application of LLMs on specific cyber-security tasks.\nUnfortunately, there is still a lack of comprehensive elaboration how to mine\nLLMs' potentials in network threat detections, as well as the opportunities and\nchallenges. In this paper, we mainly focus on the classification of malicious\ntraffic from the perspective of LLMs' capability. We present a holistic view of\nthe architecture of LLM-powered network attack detection, including\nPre-training, Fine-tuning, and Detection. Especially, by exploring the\nknowledge and capabilities of LLM, we identify three distinct roles LLM can act\nin network attack detection: \\textit{Classifier, Encoder, and Predictor}. For\neach of them, the modeling paradigm, opportunities and challenges are\nelaborated. Finally, we present our design on LLM-powered DDoS detection as a\ncase study. The proposed framework attains accurate detection on carpet bombing\nDDoS by exploiting LLMs' capabilities in contextual mining. The evaluation\nshows its efficacy, exhibiting a nearly $35$\\% improvement compared to existing\nsystems.", "published": "2025-03-24 09:40:46", "link": "http://arxiv.org/abs/2503.18487v1", "categories": ["cs.NI", "cs.AI", "cs.CR"], "primary_category": "cs.NI"}
{"title": "MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse", "abstract": "We present MetaSpatial, the first reinforcement learning (RL)-based framework\ndesigned to enhance 3D spatial reasoning in vision-language models (VLMs),\nenabling real-time 3D scene generation without the need for hard-coded\noptimizations. MetaSpatial addresses two core challenges: (i) the lack of\ninternalized 3D spatial reasoning in VLMs, which limits their ability to\ngenerate realistic layouts, and (ii) the inefficiency of traditional supervised\nfine-tuning (SFT) for layout generation tasks, as perfect ground truth\nannotations are unavailable. Our key innovation is a multi-turn RL-based\noptimization mechanism that integrates physics-aware constraints and rendered\nimage evaluations, ensuring generated 3D layouts are coherent, physically\nplausible, and aesthetically consistent. Methodologically, MetaSpatial\nintroduces an adaptive, iterative reasoning process, where the VLM refines\nspatial arrangements over multiple turns by analyzing rendered outputs,\nimproving scene coherence progressively. Empirical evaluations demonstrate that\nMetaSpatial significantly enhances the spatial consistency and formatting\nstability of various scale models. Post-training, object placements are more\nrealistic, aligned, and functionally coherent, validating the effectiveness of\nRL for 3D spatial reasoning in metaverse, AR/VR, digital twins, and game\ndevelopment applications. Our code, data, and training pipeline are publicly\navailable at https://github.com/PzySeere/MetaSpatial.", "published": "2025-03-24 09:18:01", "link": "http://arxiv.org/abs/2503.18470v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "PALATE: Peculiar Application of the Law of Total Expectation to Enhance the Evaluation of Deep Generative Models", "abstract": "Deep generative models (DGMs) have caused a paradigm shift in the field of\nmachine learning, yielding noteworthy advancements in domains such as image\nsynthesis, natural language processing, and other related areas. However, a\ncomprehensive evaluation of these models that accounts for the trichotomy\nbetween fidelity, diversity, and novelty in generated samples remains a\nformidable challenge. A recently introduced solution that has emerged as a\npromising approach in this regard is the Feature Likelihood Divergence (FLD), a\nmethod that offers a theoretically motivated practical tool, yet also exhibits\nsome computational challenges. In this paper, we propose PALATE, a novel\nenhancement to the evaluation of DGMs that addresses limitations of existing\nmetrics. Our approach is based on a peculiar application of the law of total\nexpectation to random variables representing accessible real data. When\ncombined with the MMD baseline metric and DINOv2 feature extractor, PALATE\noffers a holistic evaluation framework that matches or surpasses\nstate-of-the-art solutions while providing superior computational efficiency\nand scalability to large-scale datasets. Through a series of experiments, we\ndemonstrate the effectiveness of the PALATE enhancement, contributing a\ncomputationally efficient, holistic evaluation approach that advances the field\nof DGMs assessment, especially in detecting sample memorization and evaluating\ngeneralization capabilities.", "published": "2025-03-24 09:06:45", "link": "http://arxiv.org/abs/2503.18462v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "ModiGen: A Large Language Model-Based Workflow for Multi-Task Modelica Code Generation", "abstract": "Modelica is a widely adopted language for simulating complex physical\nsystems, yet effective model creation and optimization require substantial\ndomain expertise. Although large language models (LLMs) have demonstrated\npromising capabilities in code generation, their application to modeling\nremains largely unexplored. To address this gap, we have developed benchmark\ndatasets specifically designed to evaluate the performance of LLMs in\ngenerating Modelica component models and test cases. Our evaluation reveals\nsubstantial limitations in current LLMs, as the generated code often fails to\nsimulate successfully. To overcome these challenges, we propose a specialized\nworkflow that integrates supervised fine-tuning, graph retrieval-augmented\ngeneration, and feedback optimization to improve the accuracy and reliability\nof Modelica code generation. The evaluation results demonstrate significant\nperformance gains: the maximum improvement in pass@1 reached 0.3349 for the\ncomponent generation task and 0.2457 for the test case generation task. This\nresearch underscores the potential of LLMs to advance intelligent modeling\ntools and offers valuable insights for future developments in system modeling\nand engineering applications.", "published": "2025-03-24 09:04:49", "link": "http://arxiv.org/abs/2503.18460v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Generative AI in Knowledge Work: Design Implications for Data Navigation and Decision-Making", "abstract": "Our study of 20 knowledge workers revealed a common challenge: the difficulty\nof synthesizing unstructured information scattered across multiple platforms to\nmake informed decisions. Drawing on their vision of an ideal knowledge\nsynthesis tool, we developed Yodeai, an AI-enabled system, to explore both the\nopportunities and limitations of AI in knowledge work. Through a user study\nwith 16 product managers, we identified three key requirements for Generative\nAI in knowledge work: adaptable user control, transparent collaboration\nmechanisms, and the ability to integrate background knowledge with external\ninformation. However, we also found significant limitations, including\noverreliance on AI, user isolation, and contextual factors outside the AI's\nreach. As AI tools become increasingly prevalent in professional settings, we\npropose design principles that emphasize adaptability to diverse workflows,\naccountability in personal and collaborative contexts, and context-aware\ninteroperability to guide the development of human-centered AI systems for\nproduct managers and knowledge workers.", "published": "2025-03-24 08:02:44", "link": "http://arxiv.org/abs/2503.18419v1", "categories": ["cs.HC", "cs.AI", "cs.ET", "H.5.m"], "primary_category": "cs.HC"}
{"title": "Evidencing Unauthorized Training Data from AI Generated Content using Information Isotopes", "abstract": "In light of scaling laws, many AI institutions are intensifying efforts to\nconstruct advanced AIs on extensive collections of high-quality human data.\nHowever, in a rush to stay competitive, some institutions may inadvertently or\neven deliberately include unauthorized data (like privacy- or intellectual\nproperty-sensitive content) for AI training, which infringes on the rights of\ndata owners. Compounding this issue, these advanced AI services are typically\nbuilt on opaque cloud platforms, which restricts access to internal information\nduring AI training and inference, leaving only the generated outputs available\nfor forensics. Thus, despite the introduction of legal frameworks by various\ncountries to safeguard data rights, uncovering evidence of data misuse in\nmodern opaque AI applications remains a significant challenge. In this paper,\ninspired by the ability of isotopes to trace elements within chemical\nreactions, we introduce the concept of information isotopes and elucidate their\nproperties in tracing training data within opaque AI systems. Furthermore, we\npropose an information isotope tracing method designed to identify and provide\nevidence of unauthorized data usage by detecting the presence of target\ninformation isotopes in AI generations. We conduct experiments on ten AI models\n(including GPT-4o, Claude-3.5, and DeepSeek) and four benchmark datasets in\ncritical domains (medical data, copyrighted books, and news). Results show that\nour method can distinguish training datasets from non-training datasets with\n99\\% accuracy and significant evidence (p-value$<0.001$) by examining a data\nentry equivalent in length to a research paper. The findings show the potential\nof our work as an inclusive tool for empowering individuals, including those\nwithout expertise in AI, to safeguard their data rights in the rapidly evolving\nera of AI advancements and applications.", "published": "2025-03-24 07:35:59", "link": "http://arxiv.org/abs/2503.20800v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Knowledge Graph Enhanced Generative Multi-modal Models for Class-Incremental Learning", "abstract": "Continual learning in computer vision faces the critical challenge of\ncatastrophic forgetting, where models struggle to retain prior knowledge while\nadapting to new tasks. Although recent studies have attempted to leverage the\ngeneralization capabilities of pre-trained models to mitigate overfitting on\ncurrent tasks, models still tend to forget details of previously learned\ncategories as tasks progress, leading to misclassification. To address these\nlimitations, we introduce a novel Knowledge Graph Enhanced Generative\nMulti-modal model (KG-GMM) that builds an evolving knowledge graph throughout\nthe learning process. Our approach utilizes relationships within the knowledge\ngraph to augment the class labels and assigns different relations to similar\ncategories to enhance model differentiation. During testing, we propose a\nKnowledge Graph Augmented Inference method that locates specific categories by\nanalyzing relationships within the generated text, thereby reducing the loss of\ndetailed information about old classes when learning new knowledge and\nalleviating forgetting. Experiments demonstrate that our method effectively\nleverages relational information to help the model correct mispredictions,\nachieving state-of-the-art results in both conventional CIL and few-shot CIL\nsettings, confirming the efficacy of knowledge graphs at preserving knowledge\nin the continual learning scenarios.", "published": "2025-03-24 07:20:43", "link": "http://arxiv.org/abs/2503.18403v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "PRECTR: A Synergistic Framework for Integrating Personalized Search Relevance Matching and CTR Prediction", "abstract": "The two primary tasks in the search recommendation system are search\nrelevance matching and click-through rate (CTR) prediction -- the former\nfocuses on seeking relevant items for user queries whereas the latter forecasts\nwhich item may better match user interest. Prior research typically develops\ntwo models to predict the CTR and search relevance separately, then ranking\ncandidate items based on the fusion of the two outputs. However, such a\ndivide-and-conquer paradigm creates the inconsistency between different models.\nMeanwhile, the search relevance model mainly concentrates on the degree of\nobjective text matching while neglecting personalized differences among\ndifferent users, leading to restricted model performance. To tackle these\nissues, we propose a unified Personalized Search RElevance Matching and CTR\nPrediction Fusion Model(PRECTR). Specifically, based on the conditional\nprobability fusion mechanism, PRECTR integrates the CTR prediction and search\nrelevance matching into one framework to enhance the interaction and\nconsistency of the two modules. However, directly optimizing CTR binary\nclassification loss may bring challenges to the fusion model's convergence and\nindefinitely promote the exposure of items with high CTR, regardless of their\nsearch relevance. Hence, we further introduce two-stage training and semantic\nconsistency regularization to accelerate the model's convergence and restrain\nthe recommendation of irrelevant items. Finally, acknowledging that different\nusers may have varied relevance preferences, we assessed current users'\nrelevance preferences by analyzing past users' preferences for similar queries\nand tailored incentives for different candidate items accordingly. Extensive\nexperimental results on our production dataset and online A/B testing\ndemonstrate the effectiveness and superiority of our proposed PRECTR method.", "published": "2025-03-24 07:07:04", "link": "http://arxiv.org/abs/2503.18395v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Manipulation and the AI Act: Large Language Model Chatbots and the Danger of Mirrors", "abstract": "Large Language Model chatbots are increasingly taking the form and visage of\nhuman beings, adapting human faces, names, voices, personalities, and quirks,\nincluding those of celebrities and well-known political figures. Personifying\nAI chatbots could foreseeably increase their trust with users. However, it\ncould also make them more capable of manipulation, by creating the illusion of\na close and intimate relationship with an artificial entity. The European\nCommission has finalized the AI Act, with the EU Parliament making amendments\nbanning manipulative and deceptive AI systems that cause significant harm to\nusers. Although the AI Act covers harms that accumulate over time, it is\nunlikely to prevent harms associated with prolonged discussions with AI\nchatbots. Specifically, a chatbot could reinforce a person's negative emotional\nstate over weeks, months, or years through negative feedback loops, prolonged\nconversations, or harmful recommendations, contributing to a user's\ndeteriorating mental health.", "published": "2025-03-24 06:56:29", "link": "http://arxiv.org/abs/2503.18387v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Resource-Efficient Motion Control for Video Generation via Dynamic Mask Guidance", "abstract": "Recent advances in diffusion models bring new vitality to visual content\ncreation. However, current text-to-video generation models still face\nsignificant challenges such as high training costs, substantial data\nrequirements, and difficulties in maintaining consistency between given text\nand motion of the foreground object. To address these challenges, we propose\nmask-guided video generation, which can control video generation through mask\nmotion sequences, while requiring limited training data. Our model enhances\nexisting architectures by incorporating foreground masks for precise\ntext-position matching and motion trajectory control. Through mask motion\nsequences, we guide the video generation process to maintain consistent\nforeground objects throughout the sequence. Additionally, through a first-frame\nsharing strategy and autoregressive extension approach, we achieve more stable\nand longer video generation. Extensive qualitative and quantitative experiments\ndemonstrate that this approach excels in various video generation tasks, such\nas video editing and generating artistic videos, outperforming previous methods\nin terms of consistency and quality. Our generated results can be viewed in the\nsupplementary materials.", "published": "2025-03-24 06:53:08", "link": "http://arxiv.org/abs/2503.18386v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RoCA: Robust Contrastive One-class Time Series Anomaly Detection with Contaminated Data", "abstract": "The accumulation of time-series signals and the absence of labels make\ntime-series Anomaly Detection (AD) a self-supervised task of deep learning.\nMethods based on normality assumptions face the following three limitations:\n(1) A single assumption could hardly characterize the whole normality or lead\nto some deviation. (2) Some assumptions may go against the principle of AD. (3)\nTheir basic assumption is that the training data is uncontaminated (free of\nanomalies), which is unrealistic in practice, leading to a decline in\nrobustness. This paper proposes a novel robust approach, RoCA, which is the\nfirst to address all of the above three challenges, as far as we are aware. It\nfuses the separated assumptions of one-class classification and contrastive\nlearning in a single training process to characterize a more complete so-called\nnormality. Additionally, it monitors the training data and computes a carefully\ndesigned anomaly score throughout the training process. This score helps\nidentify latent anomalies, which are then used to define the classification\nboundary, inspired by the concept of outlier exposure. The performance on AIOps\ndatasets improved by 6% compared to when contamination was not considered\n(COCA). On two large and high-dimensional multivariate datasets, the\nperformance increased by 5% to 10%. RoCA achieves the highest average\nperformance on both univariate and multivariate datasets. The source code is\navailable at https://github.com/ruiking04/RoCA.", "published": "2025-03-24 06:52:28", "link": "http://arxiv.org/abs/2503.18385v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PP-FormulaNet: Bridging Accuracy and Efficiency in Advanced Formula Recognition", "abstract": "Formula recognition is an important task in document intelligence. It\ninvolves converting mathematical expressions from document images into\nstructured symbolic formats that computers can easily work with. LaTeX is the\nmost common format used for this purpose. In this work, we present\nPP-FormulaNet, a state-of-the-art formula recognition model that excels in both\naccuracy and efficiency. To meet the diverse needs of applications, we have\ndeveloped two specialized models: PP-FormulaNet-L, tailored for high-accuracy\nscenarios, and PP-FormulaNet-S, optimized for high-efficiency contexts. Our\nextensive evaluations reveal that PP-FormulaNet-L attains accuracy levels that\nsurpass those of prominent models such as UniMERNet by a significant 6%.\nConversely, PP-FormulaNet-S operates at speeds that are over 16 times faster.\nThese advancements facilitate seamless integration of PP-FormulaNet into a\nbroad spectrum of document processing environments that involve intricate\nmathematical formulas. Furthermore, we introduce a Formula Mining System, which\nis capable of extracting a vast amount of high-quality formula data. This\nsystem further enhances the robustness and applicability of our formula\nrecognition model. Code and models are publicly available at\nPaddleOCR(https://github.com/PaddlePaddle/PaddleOCR) and\nPaddleX(https://github.com/PaddlePaddle/PaddleX).", "published": "2025-03-24 06:39:51", "link": "http://arxiv.org/abs/2503.18382v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Maximum Redundancy Pruning: A Principle-Driven Layerwise Sparsity Allocation for LLMs", "abstract": "Large language models (LLMs) have demonstrated impressive capabilities, but\ntheir enormous size poses significant challenges for deployment in real-world\napplications. To address this issue, researchers have sought to apply network\npruning techniques to LLMs. A critical challenge in pruning is allocation the\nsparsity for each layer. Recent sparsity allocation methods is often based on\nheuristics or search that can easily lead to suboptimal performance. In this\npaper, we conducted an extensive investigation into various LLMs and revealed\nthree significant discoveries: (1) the layerwise pruning sensitivity (LPS) of\nLLMs is highly non-uniform, (2) the choice of pruning metric affects LPS, and\n(3) the performance of a sparse model is related to the uniformity of its\nlayerwise redundancy level. Based on these observations, we propose that the\nlayerwise sparsity of LLMs should adhere to three principles:\n\\emph{non-uniformity}, \\emph{pruning metric dependency}, and \\emph{uniform\nlayerwise redundancy level} in the pruned model. To this end, we proposed\nMaximum Redundancy Pruning (MRP), an iterative pruning algorithm that prunes in\nthe most redundant layers (\\emph{i.e.}, those with the highest non-outlier\nratio) at each iteration. The achieved layerwise sparsity aligns with the\noutlined principles. We conducted extensive experiments on publicly available\nLLMs, including the LLaMA2 and OPT, across various benchmarks. Experimental\nresults validate the effectiveness of MRP, demonstrating its superiority over\nprevious methods.", "published": "2025-03-24 06:17:30", "link": "http://arxiv.org/abs/2503.18377v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Modeling speech emotion with label variance and analyzing performance across speakers and unseen acoustic conditions", "abstract": "Spontaneous speech emotion data usually contain perceptual grades where\ngraders assign emotion score after listening to the speech files. Such\nperceptual grades introduce uncertainty in labels due to grader opinion\nvariation. Grader variation is addressed by using consensus grades as\ngroundtruth, where the emotion with the highest vote is selected. Consensus\ngrades fail to consider ambiguous instances where a speech sample may contain\nmultiple emotions, as captured through grader opinion uncertainty. We\ndemonstrate that using the probability density function of the emotion grades\nas targets instead of the commonly used consensus grades, provide better\nperformance on benchmark evaluation sets compared to results reported in the\nliterature. We show that a saliency driven foundation model (FM) representation\nselection helps to train a state-of-the-art speech emotion model for both\ndimensional and categorical emotion recognition. Comparing representations\nobtained from different FMs, we observed that focusing on overall test-set\nperformance can be deceiving, as it fails to reveal the models generalization\ncapacity across speakers and gender. We demonstrate that performance evaluation\nacross multiple test-sets and performance analysis across gender and speakers\nare useful in assessing usefulness of emotion models. Finally, we demonstrate\nthat label uncertainty and data-skew pose a challenge to model evaluation,\nwhere instead of using the best hypothesis, it is useful to consider the 2- or\n3-best hypotheses.", "published": "2025-03-24 06:13:27", "link": "http://arxiv.org/abs/2503.22711v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Latent Embedding Adaptation for Human Preference Alignment in Diffusion Planners", "abstract": "This work addresses the challenge of personalizing trajectories generated in\nautomated decision-making systems by introducing a resource-efficient approach\nthat enables rapid adaptation to individual users' preferences. Our method\nleverages a pretrained conditional diffusion model with Preference Latent\nEmbeddings (PLE), trained on a large, reward-free offline dataset. The PLE\nserves as a compact representation for capturing specific user preferences. By\nadapting the pretrained model using our proposed preference inversion method,\nwhich directly optimizes the learnable PLE, we achieve superior alignment with\nhuman preferences compared to existing solutions like Reinforcement Learning\nfrom Human Feedback (RLHF) and Low-Rank Adaptation (LoRA). To better reflect\npractical applications, we create a benchmark experiment using real human\npreferences on diverse, high-reward trajectories.", "published": "2025-03-24 05:11:58", "link": "http://arxiv.org/abs/2503.18347v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Optimizing Influence Campaigns: Nudging under Bounded Confidence", "abstract": "Influence campaigns in online social networks are often run by organizations,\npolitical parties, and nation states to influence large audiences. These\ncampaigns are employed through the use of agents in the network that share\npersuasive content. Yet, their impact might be minimal if the audiences remain\nunswayed, often due to the bounded confidence phenomenon, where only a narrow\nspectrum of viewpoints can influence them. Here we show that to persuade under\nbounded confidence, an agent must nudge its targets to gradually shift their\nopinions. Using a control theory approach, we show how to construct an agent's\nnudging policy under the bounded confidence opinion dynamics model and also how\nto select targets for multiple agents in an influence campaign on a social\nnetwork. Simulations on real Twitter networks show that a multi-agent nudging\npolicy can shift the mean opinion, decrease opinion polarization, or even\nincrease it. We find that our nudging based policies outperform other common\ntechniques that do not consider the bounded confidence effect. Finally, we show\nhow to craft prompts for large language models, such as ChatGPT, to generate\ntext-based content for real nudging policies. This illustrates the practical\nfeasibility of our approach, allowing one to go from mathematical nudging\npolicies to real social media content.", "published": "2025-03-24 04:30:58", "link": "http://arxiv.org/abs/2503.18331v1", "categories": ["cs.SI", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.SI"}
{"title": "Plug-and-Play Interpretable Responsible Text-to-Image Generation via Dual-Space Multi-facet Concept Control", "abstract": "Ethical issues around text-to-image (T2I) models demand a comprehensive\ncontrol over the generative content. Existing techniques addressing these\nissues for responsible T2I models aim for the generated content to be fair and\nsafe (non-violent/explicit). However, these methods remain bounded to handling\nthe facets of responsibility concepts individually, while also lacking in\ninterpretability. Moreover, they often require alteration to the original\nmodel, which compromises the model performance. In this work, we propose a\nunique technique to enable responsible T2I generation by simultaneously\naccounting for an extensive range of concepts for fair and safe content\ngeneration in a scalable manner. The key idea is to distill the target T2I\npipeline with an external plug-and-play mechanism that learns an interpretable\ncomposite responsible space for the desired concepts, conditioned on the target\nT2I pipeline. We use knowledge distillation and concept whitening to enable\nthis. At inference, the learned space is utilized to modulate the generative\ncontent. A typical T2I pipeline presents two plug-in points for our approach,\nnamely; the text embedding space and the diffusion model latent space. We\ndevelop modules for both points and show the effectiveness of our approach with\na range of strong results.", "published": "2025-03-24 04:06:39", "link": "http://arxiv.org/abs/2503.18324v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty", "abstract": "We present LoTUS, a novel Machine Unlearning (MU) method that eliminates the\ninfluence of training samples from pre-trained models, avoiding retraining from\nscratch. LoTUS smooths the prediction probabilities of the model up to an\ninformation-theoretic bound, mitigating its over-confidence stemming from data\nmemorization. We evaluate LoTUS on Transformer and ResNet18 models against\neight baselines across five public datasets. Beyond established MU benchmarks,\nwe evaluate unlearning on ImageNet1k, a large-scale dataset, where retraining\nis impractical, simulating real-world conditions. Moreover, we introduce the\nnovel Retrain-Free Jensen-Shannon Divergence (RF-JSD) metric to enable\nevaluation under real-world conditions. The experimental results show that\nLoTUS outperforms state-of-the-art methods in terms of both efficiency and\neffectiveness. Code: https://github.com/cspartalis/LoTUS.", "published": "2025-03-24 03:34:23", "link": "http://arxiv.org/abs/2503.18314v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DeepFund: Will LLM be Professional at Fund Investment? A Live Arena Perspective", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\nvarious domains, but their effectiveness in financial decision making,\nparticularly in fund investment, remains inadequately evaluated. Current\nbenchmarks primarily assess LLMs understanding of financial documents rather\nthan their ability to manage assets or analyze trading opportunities in dynamic\nmarket conditions. A critical limitation in existing evaluation methodologies\nis the backtesting approach, which suffers from information leakage when LLMs\nare evaluated on historical data they may have encountered during pretraining.\nThis paper introduces DeepFund, a comprehensive platform for evaluating LLM\nbased trading strategies in a simulated live environment. Our approach\nimplements a multi agent framework where LLMs serve as both analysts and\nmanagers, creating a realistic simulation of investment decision making. The\nplatform employs a forward testing methodology that mitigates information\nleakage by evaluating models on market data released after their training\ncutoff dates. We provide a web interface that visualizes model performance\nacross different market conditions and investment parameters, enabling detailed\ncomparative analysis. Through DeepFund, we aim to provide a more accurate and\nfair assessment of LLMs capabilities in fund investment, offering insights into\ntheir potential real world applications in financial markets.", "published": "2025-03-24 03:32:13", "link": "http://arxiv.org/abs/2503.18313v1", "categories": ["cs.MA", "cs.AI", "cs.CE", "cs.HC"], "primary_category": "cs.MA"}
{"title": "FACE: Few-shot Adapter with Cross-view Fusion for Cross-subject EEG Emotion Recognition", "abstract": "Cross-subject EEG emotion recognition is challenged by significant\ninter-subject variability and intricately entangled intra-subject variability.\nExisting works have primarily addressed these challenges through domain\nadaptation or generalization strategies. However, they typically require\nextensive target subject data or demonstrate limited generalization performance\nto unseen subjects. Recent few-shot learning paradigms attempt to address these\nlimitations but often encounter catastrophic overfitting during\nsubject-specific adaptation with limited samples. This article introduces the\nfew-shot adapter with a cross-view fusion method called FACE for cross-subject\nEEG emotion recognition, which leverages dynamic multi-view fusion and\neffective subject-specific adaptation. Specifically, FACE incorporates a\ncross-view fusion module that dynamically integrates global brain connectivity\nwith localized patterns via subject-specific fusion weights to provide\ncomplementary emotional information. Moreover, the few-shot adapter module is\nproposed to enable rapid adaptation for unseen subjects while reducing\noverfitting by enhancing adapter structures with meta-learning. Experimental\nresults on three public EEG emotion recognition benchmarks demonstrate FACE's\nsuperior generalization performance over state-of-the-art methods. FACE\nprovides a practical solution for cross-subject scenarios with limited labeled\ndata.", "published": "2025-03-24 03:16:52", "link": "http://arxiv.org/abs/2503.18998v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "How to Capture and Study Conversations Between Research Participants and ChatGPT: GPT for Researchers (g4r.org)", "abstract": "As large language models (LLMs) like ChatGPT become increasingly integrated\ninto our everyday lives--from customer service and education to creative work\nand personal productivity--understanding how people interact with these AI\nsystems has become a pressing issue. Despite the widespread use of LLMs,\nresearchers lack standardized tools for systematically studying people's\ninteractions with LLMs. To address this issue, we introduce GPT for Researchers\n(G4R), or g4r.org, a free website that researchers can use to easily create and\nintegrate a GPT Interface into their studies. At g4r.org, researchers can (1)\nenable their study participants to interact with GPT (such as ChatGPT), (2)\ncustomize GPT Interfaces to guide participants' interactions with GPT (e.g.,\nset constraints on topics or adjust GPT's tone or response style), and (3)\ncapture participants' interactions with GPT by downloading data on messages\nexchanged between participants and GPT. By facilitating study participants'\ninteractions with GPT and providing detailed data on these interactions, G4R\ncan support research on topics such as consumer interactions with AI agents or\nLLMs, AI-assisted decision-making, and linguistic patterns in human-AI\ncommunication. With this goal in mind, we provide a step-by-step guide to using\nG4R at g4r.org.", "published": "2025-03-24 03:10:12", "link": "http://arxiv.org/abs/2503.18303v1", "categories": ["cs.HC", "cs.AI", "cs.CY"], "primary_category": "cs.HC"}
{"title": "DiffMove: Group Mobility Tendency Enhanced Trajectory Recovery via Diffusion Model", "abstract": "In the real world, trajectory data is often sparse and incomplete due to low\ncollection frequencies or limited device coverage. Trajectory recovery aims to\nrecover these missing trajectory points, making the trajectories denser and\nmore complete. However, this task faces two key challenges: 1) The excessive\nsparsity of individual trajectories makes it difficult to effectively leverage\nhistorical information for recovery; 2) Sparse trajectories make it harder to\ncapture complex individual mobility preferences. To address these challenges,\nwe propose a novel method called DiffMove. Firstly, we harness crowd wisdom for\ntrajectory recovery. Specifically, we construct a group tendency graph using\nthe collective trajectories of all users and then integrate the group mobility\ntrends into the location representations via graph embedding. This solves the\nchallenge of sparse trajectories being unable to rely on individual historical\ntrajectories for recovery. Secondly, we capture individual mobility preferences\nfrom both historical and current perspectives. Finally, we integrate group\nmobility tendencies and individual preferences into the spatiotemporal\ndistribution of the trajectory to recover high-quality trajectories. Extensive\nexperiments on two real-world datasets demonstrate that DiffMove outperforms\nexisting state-of-the-art methods. Further analysis validates the robustness of\nour method.", "published": "2025-03-24 03:08:21", "link": "http://arxiv.org/abs/2503.18302v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Voxel-based Point Cloud Geometry Compression with Space-to-Channel Context", "abstract": "Voxel-based methods are among the most efficient for point cloud geometry\ncompression, particularly with dense point clouds. However, they face\nlimitations due to a restricted receptive field, especially when handling\nhigh-bit depth point clouds. To overcome this issue, we introduce a stage-wise\nSpace-to-Channel (S2C) context model for both dense point clouds and low-level\nsparse point clouds. This model utilizes a channel-wise autoregressive strategy\nto effectively integrate neighborhood information at a coarse resolution. For\nhigh-level sparse point clouds, we further propose a level-wise S2C context\nmodel that addresses resolution limitations by incorporating Geometry Residual\nCoding (GRC) for consistent-resolution cross-level prediction. Additionally, we\nuse the spherical coordinate system for its compact representation and enhance\nour GRC approach with a Residual Probability Approximation (RPA) module, which\nfeatures a large kernel size. Experimental results show that our S2C context\nmodel not only achieves bit savings while maintaining or improving\nreconstruction quality but also reduces computational complexity compared to\nstate-of-the-art voxel-based compression methods.", "published": "2025-03-24 01:56:08", "link": "http://arxiv.org/abs/2503.18283v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "TopV: Compatible Token Pruning with Inference Time Optimization for Fast and Low-Memory Multimodal Vision Language Model", "abstract": "Vision-Language Models (VLMs) demand substantial computational resources\nduring inference, largely due to the extensive visual input tokens for\nrepresenting visual information. Previous studies have noted that visual tokens\ntend to receive less attention than text tokens, suggesting their lower\nimportance during inference and potential for pruning. However, their methods\nencounter several challenges: reliance on greedy heuristic criteria for token\nimportance and incompatibility with FlashAttention and KV cache. To address\nthese issues, we introduce \\textbf{TopV}, a compatible \\textbf{TO}ken\n\\textbf{P}runing with inference Time Optimization for fast and low-memory\n\\textbf{V}LM, achieving efficient pruning without additional training or\nfine-tuning. Instead of relying on attention scores, we formulate token pruning\nas an optimization problem, accurately identifying important visual tokens\nwhile remaining compatible with FlashAttention. Additionally, since we only\nperform this pruning once during the prefilling stage, it effectively reduces\nKV cache size. Our optimization framework incorporates a visual-aware cost\nfunction considering factors such as Feature Similarity, Relative Spatial\nDistance, and Absolute Central Distance, to measure the importance of each\nsource visual token, enabling effective pruning of low-importance tokens.\nExtensive experiments demonstrate that our method outperforms previous token\npruning methods, validating the effectiveness and efficiency of our approach.", "published": "2025-03-24 01:47:26", "link": "http://arxiv.org/abs/2503.18278v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Risk Management for Distributed Arbitrage Systems: Integrating Artificial Intelligence", "abstract": "Effective risk management solutions become absolutely crucial when financial\nmarkets embrace distributed technology and decentralized financing (DeFi). This\nstudy offers a thorough survey and comparative analysis of the integration of\nartificial intelligence (AI) in risk management for distributed arbitrage\nsystems. We examine several modern caching techniques namely in memory caching,\ndistributed caching, and proxy caching and their functions in enhancing\nperformance in decentralized settings. Through literature review we examine the\nutilization of AI techniques for alleviating risks related to market\nvolatility, liquidity challenges, operational failures, regulatory compliance,\nand security threats. This comparison research evaluates various case studies\nfrom prominent DeFi technologies, emphasizing critical performance metrics like\nlatency reduction, load balancing, and system resilience. Additionally, we\nexamine the problems and trade offs associated with these technologies,\nemphasizing their effects on consistency, scalability, and fault tolerance. By\nmeticulously analyzing real world applications, specifically centering on the\nAave platform as our principal case study, we illustrate how the purposeful\namalgamation of AI with contemporary caching methodologies has revolutionized\nrisk management in distributed arbitrage systems.", "published": "2025-03-24 01:15:43", "link": "http://arxiv.org/abs/2503.18265v1", "categories": ["cs.DC", "cs.AI", "cs.LG", "I.2.11; G.3"], "primary_category": "cs.DC"}
{"title": "Severing Spurious Correlations with Data Pruning", "abstract": "Deep neural networks have been shown to learn and rely on spurious\ncorrelations present in the data that they are trained on. Reliance on such\ncorrelations can cause these networks to malfunction when deployed in the real\nworld, where these correlations may no longer hold. To overcome the learning of\nand reliance on such correlations, recent studies propose approaches that yield\npromising results. These works, however, study settings where the strength of\nthe spurious signal is significantly greater than that of the core, invariant\nsignal, making it easier to detect the presence of spurious features in\nindividual training samples and allow for further processing. In this paper, we\nidentify new settings where the strength of the spurious signal is relatively\nweaker, making it difficult to detect any spurious information while continuing\nto have catastrophic consequences. We also discover that spurious correlations\nare learned primarily due to only a handful of all the samples containing the\nspurious feature and develop a novel data pruning technique that identifies and\nprunes small subsets of the training data that contain these samples. Our\nproposed technique does not require inferred domain knowledge, information\nregarding the sample-wise presence or nature of spurious information, or human\nintervention. Finally, we show that such data pruning attains state-of-the-art\nperformance on previously studied settings where spurious information is\nidentifiable.", "published": "2025-03-24 00:57:32", "link": "http://arxiv.org/abs/2503.18258v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Human-Machine Identity Blur: A Unified Framework for Cybersecurity Risk Management in 2025", "abstract": "The modern enterprise is facing an unprecedented surge in digital identities,\nwith machine identities now significantly outnumbering human identities. This\npaper examines the cybersecurity risks emerging from what we define as the\n\"human-machine identity blur\" - the point at which human and machine identities\nintersect, delegate authority, and create new attack surfaces. Drawing from\nindustry data, expert insights, and real-world incident analysis, we identify\nkey governance gaps in current identity management models that treat human and\nmachine entities as separate domains. To address these challenges, we propose a\nUnified Identity Governance Framework based on four core principles: treating\nidentity as a continuum rather than a binary distinction, applying consistent\nrisk evaluation across all identity types, implementing continuous verification\nguided by zero trust principles, and maintaining governance throughout the\nentire identity lifecycle. Our research shows that organizations adopting this\nunified approach experience a 47 percent reduction in identity-related security\nincidents and a 62 percent improvement in incident response time. We conclude\nby offering a practical implementation roadmap and outlining future research\ndirections as AI-driven systems become increasingly autonomous.", "published": "2025-03-24 00:37:14", "link": "http://arxiv.org/abs/2503.18255v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "On the number of asynchronous attractors in AND-NOT Boolean networks", "abstract": "Boolean Networks (BNs) describe the time evolution of binary states using\nlogic functions on the nodes of a network. They are fundamental models for\ncomplex discrete dynamical systems, with applications in various areas of\nscience and engineering, and especially in systems biology. A key aspect of the\ndynamical behavior of BNs is the number of attractors, which determines the\ndiversity of long-term system trajectories. Due to the noisy nature and\nincomplete characterization of biological systems, a stochastic asynchronous\nupdate scheme is often more appropriate than the deterministic synchronous one.\nAND-NOT BNs, whose logic functions are the conjunction of literals, are an\nimportant subclass of BNs because of their structural simplicity and their\nusefulness in analyzing biological systems for which the only information\navailable is a collection of interactions among components. In this paper, we\nestablish new theoretical results regarding asynchronous attractors in AND-NOT\nBNs. We derive two new upper bounds for the number of asynchronous attractors\nin an AND-NOT BN based on structural properties (strong even cycles and\ndominating sets, respectively) of the AND-NOT BN. These findings contribute to\na more comprehensive understanding of asynchronous dynamics in AND-NOT BNs,\nwith implications for attractor enumeration and counting, as well as for\nnetwork design and control.", "published": "2025-03-24 21:06:32", "link": "http://arxiv.org/abs/2503.19147v1", "categories": ["cs.DM", "cs.LO"], "primary_category": "cs.DM"}
{"title": "When Distances Lie: Euclidean Embeddings in the Presence of Outliers and Distance Violations", "abstract": "Distance geometry explores the properties of distance spaces that can be\nexactly represented as the pairwise Euclidean distances between points in\n$\\mathbb{R}^d$ ($d \\geq 1$), or equivalently, distance spaces that can be\nisometrically embedded in $\\mathbb{R}^d$. In this work, we investigate whether\na distance space can be isometrically embedded in $\\mathbb{R}^d$ after applying\na limited number of modifications. Specifically, we focus on two types of\nmodifications: outlier deletion (removing points) and distance modification\n(adjusting distances between points). The central problem, Euclidean Embedding\nEditing (EEE), asks whether an input distance space on $n$ points can be\ntransformed, using at most $k$ modifications, into a space that is\nisometrically embeddable in $\\mathbb{R}^d$.\n  We present several fixed-parameter tractable (FPT) and approximation\nalgorithms for this problem. Our first result is an algorithm that solves EEE\nin time $(dk)^{\\mathcal{O}(d+k)} + n^{\\mathcal{O}(1)}$. The core subroutine of\nthis algorithm, which is of independent interest, is a polynomial-time method\nfor compressing the input distance space into an equivalent instance of EEE\nwith $\\mathcal{O}((dk)^2)$ points.\n  For the special but important case of EEE where only outlier deletions are\nallowed, we improve the parameter dependence of the FPT algorithm and obtain a\nrunning time of $\\min\\{(d+3)^k, 2^{d+k}\\} \\cdot n^{\\mathcal{O}(1)}$.\nAdditionally, we provide an FPT-approximation algorithm for this problem, which\noutputs a set of at most $2 \\cdot {\\rm OPT}$ outliers in time $2^d \\cdot\nn^{\\mathcal{O}(1)}$. This 2-approximation algorithm improves upon the previous\n$(3+\\varepsilon)$-approximation algorithm by Sidiropoulos, Wang, and Wang [SODA\n'17]. Furthermore, we complement our algorithms with hardness results\nmotivating our choice of parameterizations.", "published": "2025-03-24 19:25:53", "link": "http://arxiv.org/abs/2503.19093v1", "categories": ["cs.CG", "cs.DM", "cs.DS"], "primary_category": "cs.CG"}
{"title": "Path degeneracy and applications", "abstract": "In this work, we relate girth and path-degeneracy in classes with\nsub-exponential expansion, with explicit bounds for classes with polynomial\nexpansion and proper minor-closed classes that are tight up to a constant\nfactor (and tight up to second order terms if a classical conjecture on\nexistence of $g$-cages is verified). As an application, we derive bounds on the\ngeneralized acyclic indices, on the generalized arboricities, and on the weak\ncoloring numbers of high-girth graphs in such classes. Along the way, we prove\na conjecture proposed in [T.~Bartnicki et al., Generalized arboricity of graphs\nwith large girth, Discrete Mathematics 342 (2019), no.~5, 1343--1350.], which\nasserts that, for every integer $k$, there is an integer $g(p,k)$ such that\nevery $K_k$ minor-free graph with girth at least $g(p,k)$ has $p$-arboricity at\nmost $p+1$.", "published": "2025-03-24 12:13:57", "link": "http://arxiv.org/abs/2503.18614v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Counterexample to Winkler's conjecture on Venn diagrams", "abstract": "In 1984, Peter Winkler conjectured that every simple Venn diagram with $n$\ncurves can be extended to a simple Venn diagram with $n+1$ curves. We present a\ncounterexample to his conjecture for $n=7$, which is obtained by combining\ntheoretical ideas with computer assistance from state-of-the-art SAT solvers.", "published": "2025-03-24 11:06:34", "link": "http://arxiv.org/abs/2503.18554v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "CCMusic: An Open and Diverse Database for Chinese Music Information Retrieval Research", "abstract": "Data are crucial in various computer-related fields, including music\ninformation retrieval (MIR), an interdisciplinary area bridging computer\nscience and music. This paper introduces CCMusic, an open and diverse database\ncomprising multiple datasets specifically designed for tasks related to Chinese\nmusic, highlighting our focus on this culturally rich domain. The database\nintegrates both published and unpublished datasets, with steps taken such as\ndata cleaning, label refinement, and data structure unification to ensure data\nconsistency and create ready-to-use versions. We conduct benchmark evaluations\nfor all datasets using a unified evaluation framework developed specifically\nfor this purpose. This publicly available framework supports both\nclassification and detection tasks, ensuring standardized and reproducible\nresults across all datasets. The database is hosted on HuggingFace and\nModelScope, two open and multifunctional data and model hosting platforms,\nensuring ease of accessibility and usability.", "published": "2025-03-24 15:47:21", "link": "http://arxiv.org/abs/2503.18802v1", "categories": ["cs.IR", "cs.SD"], "primary_category": "cs.IR"}
{"title": "A Comprehensive Review on Hashtag Recommendation: From Traditional to Deep Learning and Beyond", "abstract": "The exponential growth of user-generated content on social media platforms\nhas precipitated significant challenges in information management, particularly\nin content organization, retrieval, and discovery. Hashtags, as a fundamental\ncategorization mechanism, play a pivotal role in enhancing content visibility\nand user engagement. However, the development of accurate and robust hashtag\nrecommendation systems remains a complex and evolving research challenge.\nExisting surveys in this domain are limited in scope and recency, focusing\nnarrowly on specific platforms, methodologies, or timeframes. To address this\ngap, this review article conducts a systematic analysis of hashtag\nrecommendation systems, comprehensively examining recent advancements across\nseveral dimensions. We investigate unimodal versus multimodal methodologies,\ndiverse problem formulations, filtering strategies, methodological evolution\nfrom traditional frequency-based models to advanced deep learning\narchitectures. Furthermore, we critically evaluate performance assessment\nparadigms, including quantitative metrics, qualitative analyses, and hybrid\nevaluation frameworks. Our analysis underscores a paradigm shift toward\ntransformer-based deep learning models, which harness contextual and semantic\nfeatures to achieve superior recommendation accuracy. Key challenges such as\ndata sparsity, cold-start scenarios, polysemy, and model explainability are\nrigorously discussed, alongside practical applications in tweet classification,\nsentiment analysis, and content popularity prediction. By synthesizing insights\nfrom diverse methodological and platform-specific perspectives, this survey\nprovides a structured taxonomy of current research, identifies unresolved gaps,\nand proposes future directions for developing adaptive, user-centric\nrecommendation systems.", "published": "2025-03-24 13:40:36", "link": "http://arxiv.org/abs/2503.18669v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Robust-IR @ SIGIR 2025: The First Workshop on Robust Information Retrieval", "abstract": "With the advancement of information retrieval (IR) technologies, robustness\nis increasingly attracting attention. When deploying technology into practice,\nwe consider not only its average performance under normal conditions but, more\nimportantly, its ability to maintain functionality across a variety of\nexceptional situations. In recent years, the research on IR robustness covers\ntheory, evaluation, methodology, and application, and all of them show a\ngrowing trend. The purpose of this workshop is to systematize the latest\nresults of each research aspect, to foster comprehensive communication within\nthis niche domain while also bridging robust IR research with the broader\ncommunity, and to promote further future development of robust IR. To avoid the\none-sided talk of mini-conferences, this workshop adopts a highly interactive\nformat, including round-table and panel discussion sessions, to encourage\nactive participation and meaningful exchange among attendees.", "published": "2025-03-24 08:10:22", "link": "http://arxiv.org/abs/2503.18426v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Food Recommendation With Balancing Comfort and Curiosity", "abstract": "Food is a key pleasure of traveling, but travelers face a trade-off between\nexploring curious new local food and choosing comfortable, familiar options.\nThis creates demand for personalized recommendation systems that balance these\ncompeting factors. To the best of our knowledge, conventional recommendation\nmethods cannot provide recommendations that offer both curiosity and comfort\nfor food unknown to the user at a travel destination. In this study, we propose\nnew quantitative methods for estimating comfort and curiosity: Kernel Density\nScoring (KDS) and Mahalanobis Distance Scoring (MDS). KDS probabilistically\nestimates food history distribution using kernel density estimation, while MDS\nuses Mahalanobis distances between foods. These methods score food based on how\ntheir representation vectors fit the estimated distributions. We also propose a\nranking method measuring the balance between comfort and curiosity based on\ntaste and ingredients. This balance is defined as curiosity (return) gained per\nunit of comfort (risk) in choosing a food. For evaluation the proposed method,\nwe newly collected a dataset containing user surveys on Japanese food and\nassessments of foreign food regarding comfort and curiosity. Comparing our\nmethods against the existing method, the Wilcoxon signed-rank test showed that\nwhen estimating comfort from taste and curiosity from ingredients, the\nMDS-based method outperformed the Baseline, while the KDS-based method showed\nno significant differences. When estimating curiosity from taste and comfort\nfrom ingredients, both methods outperformed the Baseline. The MDS-based method\nconsistently outperformed KDS in ROC-AUC values.", "published": "2025-03-24 05:32:37", "link": "http://arxiv.org/abs/2503.18355v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "RAU: Towards Regularized Alignment and Uniformity for Representation Learning in Recommendation", "abstract": "Recommender systems (RecSys) have become essential in modern society, driving\nuser engagement and satisfaction across diverse online platforms. Most RecSys\nfocuses on designing a powerful encoder to embed users and items into\nhigh-dimensional vector representation space, with loss functions optimizing\ntheir representation distributions. Recent studies reveal that directly\noptimizing key properties of the representation distribution, such as alignment\nand uniformity, can outperform complex encoder designs. However, existing\nmethods for optimizing critical attributes overlook the impact of dataset\nsparsity on the model: limited user-item interactions lead to sparse alignment,\nwhile excessive interactions result in uneven uniformity, both of which degrade\nperformance. In this paper, we identify the sparse alignment and uneven\nuniformity issues, and further propose Regularized Alignment and Uniformity\n(RAU) to cope with these two issues accordingly. RAU consists of two novel\nregularization methods for alignment and uniformity to learn better user/item\nrepresentation. 1) Center-strengthened alignment further aligns the average\nin-batch user/item representation to provide an enhanced alignment signal and\nfurther minimize the disparity between user and item representation. 2)\nLow-variance-guided uniformity minimizes the variance of pairwise distances\nalong with uniformity, which provides extra guidance to a more stabilized\nuniformity increase during training. We conducted extensive experiments on\nthree real-world datasets, and the proposed RAU resulted in significant\nperformance improvements compared to current state-of-the-art CF methods, which\nconfirms the advantages of the two proposed regularization methods.", "published": "2025-03-24 03:03:21", "link": "http://arxiv.org/abs/2503.18300v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Angular-Based Hybrid Beamforming for Wideband THz Massive MIMO Systems: Mitigating Beam Split by Leveraging Angular Spread", "abstract": "Beam split is a critical challenge in wideband THz massive MIMO systems,\narising from frequency-dependent beam misalignment that degrades communication\nperformance, particularly in scenarios with narrow beamwidths and large arrays.\nThis work proposes an angular-based hybrid beamforming framework that leverages\nangular spread to mitigate the beam split effect. Instead of relying on precise\nangular spread modeling, we utilize coarse angular information to guide the\ndesign of subcarrier-specific beams, effectively reducing misalignment across\nsubcarriers. By broadening the effective beamwidth through angular spread, the\nproposed method enhances user coverage and alleviates beam split without\nrequiring complex time-delay units or hardware-intensive solutions. Simulation\nresults demonstrate that the proposed approach achieves significant\nimprovements in spectral efficiency and beamforming accuracy while maintaining\nlow computational and hardware complexity. This work provides a practical and\nefficient solution for addressing beam split in next-generation wideband THz\ncommunication systems.", "published": "2025-03-24 20:19:40", "link": "http://arxiv.org/abs/2503.19124v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Detecting Arbitrary Planted Subgraphs in Random Graphs", "abstract": "The problems of detecting and recovering planted structures/subgraphs in\nErd\\H{o}s-R\\'{e}nyi random graphs, have received significant attention over the\npast three decades, leading to many exciting results and mathematical\ntechniques. However, prior work has largely focused on specific ad hoc planted\nstructures and inferential settings, while a general theory has remained\nelusive. In this paper, we bridge this gap by investigating the detection of an\n\\emph{arbitrary} planted subgraph $\\Gamma = \\Gamma_n$ in an Erd\\H{o}s-R\\'{e}nyi\nrandom graph $\\mathcal{G}(n, q_n)$, where the edge probability within $\\Gamma$\nis $p_n$. We examine both the statistical and computational aspects of this\nproblem and establish the following results. In the dense regime, where the\nedge probabilities $p_n$ and $q_n$ are fixed, we tightly characterize the\ninformation-theoretic and computational thresholds for detecting $\\Gamma$, and\nprovide conditions under which a computational-statistical gap arises. Most\nnotably, these thresholds depend on $\\Gamma$ only through its number of edges,\nmaximum degree, and maximum subgraph density. Our lower and upper bounds are\ngeneral and apply to any value of $p_n$ and $q_n$ as functions of $n$.\nAccordingly, we also analyze the sparse regime where $q_n =\n\\Theta(n^{-\\alpha})$ and $p_n-q_n =\\Theta(q_n)$, with $\\alpha\\in[0,2]$, as well\nas the critical regime where $p_n=1-o(1)$ and $q_n = \\Theta(n^{-\\alpha})$, both\nof which have been widely studied, for specific choices of $\\Gamma$. For these\nregimes, we show that our bounds are tight for all planted subgraphs\ninvestigated in the literature thus far\\textemdash{}and many more. Finally, we\nidentify conditions under which detection undergoes sharp phase transition,\nwhere the boundaries at which algorithms succeed or fail shift abruptly as a\nfunction of $q_n$.", "published": "2025-03-24 18:54:43", "link": "http://arxiv.org/abs/2503.19069v1", "categories": ["math.ST", "cs.IT", "cs.LG", "math.CO", "math.IT", "math.PR", "stat.TH"], "primary_category": "math.ST"}
{"title": "Learning Beamforming Codebooks for Active Sensing with Reconfigurable Intelligent Surface", "abstract": "This paper explores the design of beamforming codebooks for the base station\n(BS) and for the reconfigurable intelligent surfaces (RISs) in an active\nsensing scheme for uplink localization, in which the mobile user transmits a\nsequence of pilots to the BS through reflection at the RISs, and the BS and the\nRISs are adaptively configured by carefully choosing BS beamforming codeword\nand RIS codewords from their respective codebooks in a sequential manner to\nprogressively focus onto the user. Most existing codebook designs for RIS are\nnot tailored for active sensing, by which we mean the choice of the next\ncodeword should depend on the measurements made so far, and the sequence of\ncodewords should dynamically focus reflection toward the user. Moreover, most\nexisting codeword selection methods rely on exhaustive search in beam training\nto identify the codeword with the highest signal-to-noise ratio (SNR), thus\nincurring substantial pilot overhead as the size of the codebook scales. This\npaper proposes a learning-based approach for codebook construction and for\ncodeword selection for active sensing. The proposed learning approach aims to\nlocate a target in the service area by recursively selecting a sequence of BS\nbeamforming codewords and RIS codewords from the respective codebooks as more\nmeasurements become available without exhaustive beam training. The codebook\ndesign and the codeword selection fuse key ideas from the vector quantized\nvariational autoencoder (VQ-VAE) and the long short-term memory (LSTM) network\nto learn respectively the discrete function space of the codebook and the\ntemporal dependencies between measurements.", "published": "2025-03-24 18:15:58", "link": "http://arxiv.org/abs/2503.19046v2", "categories": ["eess.SP", "cs.IT", "cs.LG", "math.IT"], "primary_category": "eess.SP"}
{"title": "A Balanced Tree Transformation to Reduce GRAND Queries", "abstract": "Guessing Random Additive Noise Decoding (GRAND) and its variants, known for\ntheir near-maximum likelihood performance, have been introduced in recent\nyears. One such variant, Segmented GRAND, reduces decoding complexity by\ngenerating only noise patterns that meet specific constraints imposed by the\nlinear code. In this paper, we introduce a new method to efficiently derive\nmultiple constraints from the parity check matrix. By applying a random\ninvertible linear transformation and reorganizing the matrix into a tree\nstructure, we extract up to log2(n) constraints, reducing the number of\ndecoding queries while maintaining the structure of the original code for a\ncode length of n. We validate the method through theoretical analysis and\nexperimental simulations.", "published": "2025-03-24 18:06:03", "link": "http://arxiv.org/abs/2503.19033v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Entropic Analysis of Time Series through Kernel Density Estimation", "abstract": "This work presents a novel framework for time series analysis using entropic\nmeasures based on the kernel density estimate (KDE) of the time series' Takens'\nembeddings. Using this framework we introduce two distinct analytical tools:\n(1) a multi-scale KDE entropy metric, denoted as $\\Delta\\text{KE}$, which\nquantifies the evolution of time series complexity across different scales by\nmeasuring certain entropy changes, and (2) a sliding baseline method that\nemploys the Kullback-Leibler (KL) divergence to detect changes in time series\ndynamics through changes in KDEs. The $\\Delta{\\rm KE}$ metric offers insights\ninto the information content and ``unfolding'' properties of the time series'\nembedding related to dynamical systems, while the KL divergence-based approach\nprovides a noise and outlier robust approach for identifying time series change\npoints (injections in RF signals, e.g.). We demonstrate the versatility and\neffectiveness of these tools through a set of experiments encompassing diverse\ndomains. In the space of radio frequency (RF) signal processing, we achieve\naccurate detection of signal injections under varying noise and interference\nconditions. Furthermore, we apply our methodology to electrocardiography (ECG)\ndata, successfully identifying instances of ventricular fibrillation with high\naccuracy. Finally, we demonstrate the potential of our tools for dynamic state\ndetection by accurately identifying chaotic regimes within an intermittent\nsignal. These results show the broad applicability of our framework for\nextracting meaningful insights from complex time series data across various\nscientific disciplines.", "published": "2025-03-24 17:29:11", "link": "http://arxiv.org/abs/2503.18916v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Umlaut information", "abstract": "The sphere-packing bound quantifies the error exponent for noisy channel\ncoding for rates above a critical value. Here, we study the zero-rate limit of\nthe sphere-packing bound and show that it has an intriguing single-letter form,\nwhich we call the umlaut information of the channel, inspired by the lautum\ninformation introduced by Palomar and Verd\\'u. Unlike the latter quantity, we\nshow that the umlaut information is additive for parallel uses of channels. We\nshow that it has a twofold operational interpretation: as the zero-rate error\nexponent of non-signalling-assisted coding on the one hand, and as the\nzero-rate error exponent of list decoding in the large list limit on the other.", "published": "2025-03-24 17:21:07", "link": "http://arxiv.org/abs/2503.18910v1", "categories": ["cs.IT", "math-ph", "math.IT", "math.MP", "quant-ph"], "primary_category": "cs.IT"}
{"title": "Zak-OTFS for Identification of Linear Time-Varying Systems", "abstract": "Linear time-varying (LTV) systems model radar scenes where each\nreflector/target applies a delay, Doppler shift and complex amplitude scaling\nto a transmitted waveform. The receiver processes the received signal using the\ntransmitted signal as a reference. The self-ambiguity function of the\ntransmitted signal captures the cross-correlation of delay and Doppler shifts\nof the transmitted waveform. It acts as a blur that limits resolution, at the\nreceiver, of the delay and Doppler shifts of targets in close proximity. This\npaper considers resolution of multiple targets and compares performance of\ntraditional chirp waveforms with the Zak-OTFS waveform. The self-ambiguity\nfunction of a chirp is a line in the delay-Doppler domain, whereas the\nself-ambiguity function of the Zak-OTFS waveform is a lattice. The advantage of\nlattices over lines is better localization, and we show lattices provide\nsuperior noise-free estimation of the range and velocity of multiple targets.\nWhen the delay spread of the radar scene is less than the delay period of the\nZak-OTFS modulation, and the Doppler spread is less than the Doppler period, we\ndescribe how to localize targets by calculating cross-ambiguities in the\ndelay-Doppler domain. We show that the signal processing complexity of our\napproach is superior to the traditional approach of computing cross-ambiguities\nin the continuous time / frequency domain.", "published": "2025-03-24 17:14:01", "link": "http://arxiv.org/abs/2503.18900v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "RIS-Assisted Localization: A Novel Conditional Sample Mean Approach without CSI", "abstract": "Reconfigurable intelligent surface (RIS) has been recognized as a promising\nsolution for enhancing localization accuracy. Traditional RIS-based\nlocalization methods typically rely on prior channel knowledge, beam scanning,\nand pilot-based assistance. These approaches often result in substantial energy\nand computational overhead, and require real-time coordination between the base\nstation (BS) and the RIS. In this work, we propose a novel multiple RISs aided\nlocalization approach to address these challenges. The proposed method first\nestimates the angle-of-directions (AoDs) between the RISs and the user using\nthe conditional sample mean approach, and then uses the estimated multiple AoD\npairs to determine the user's position. This approach only requires measuring\nthe received signal strength at the BS for a set of randomly generated phase\nshifts across all RISs, thereby eliminating the need for real-time RIS phase\nshift design or user-to-BS pilot transmissions. Numerical results show that the\nproposed localization approach improves localization accuracy while\nsignificantly reducing energy and signaling overhead compared to conventional\nmethods.", "published": "2025-03-24 12:12:05", "link": "http://arxiv.org/abs/2503.18610v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Physical-Layer Security of Pinching-Antenna Systems", "abstract": "In this paper, we investigate the performance of physical-layer security of a\npinching-antenna system on a lossless dielectric waveguide. In particular, the\nsystem uses a single pinching-antenna to convey confidential information from a\nbase station to a legitimate destination equipped with a single antenna, while\nan eavesdropper, also equipped with a single antenna, attempts to decode the\ntransmitted information. As such, the performance of the pinching-antenna\nsystem is evaluated in terms of average secrecy capacity, strictly positive\nsecrecy capacity, and secrecy outage probability. To this end, accurate\nmathematical expressions for the aforementioned performance metrics are\nprovided. To validate the analysis, the analytical results are numerically\nevaluated and further validated through MonteCarlo simulations. The results\ndemonstrate that secrecy capacity between the base station and the legitimate\ndestination improves when the height of the pinching-antenna placed closer to\nthe destination. Additionally, the performance can be improved when the\neavesdropper's location over a rectangular area increases.", "published": "2025-03-24 04:00:57", "link": "http://arxiv.org/abs/2503.18322v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Byzantine-Resilient Over-the-Air Federated Learning under Zero-Trust Architecture", "abstract": "Over-the-air computation (AirComp) has emerged as an essential approach for\nenabling communication-efficient federated learning (FL) over wireless\nnetworks. Nonetheless, the inherent analog transmission mechanism in\nAirComp-based FL (AirFL) intensifies challenges posed by potential Byzantine\nattacks. In this paper, we propose a novel Byzantine-robust FL paradigm for\nover-the-air transmissions, referred to as federated learning with secure\nadaptive clustering (FedSAC). FedSAC aims to protect a portion of the devices\nfrom attacks through zero trust architecture (ZTA) based Byzantine\nidentification and adaptive device clustering. By conducting a one-step\nconvergence analysis, we theoretically characterize the convergence behavior\nwith different device clustering mechanisms and uneven aggregation weighting\nfactors for each device. Building upon our analytical results, we formulate a\njoint optimization problem for the clustering and weighting factors in each\ncommunication round. To facilitate the targeted optimization, we propose a\ndynamic Byzantine identification method using historical reputation based on\nZTA. Furthermore, we introduce a sequential clustering method, transforming the\njoint optimization into a weighting optimization problem without sacrificing\nthe optimality. To optimize the weighting, we capitalize on the penalty\nconvex-concave procedure (P-CCP) to obtain a stationary solution. Numerical\nresults substantiate the superiority of the proposed FedSAC over existing\nmethods in terms of both test accuracy and convergence rate.", "published": "2025-03-24 01:56:30", "link": "http://arxiv.org/abs/2503.18284v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Optimal Modified Feedback Strategies in LQ Games under Control Imperfections", "abstract": "Game-theoretic approaches and Nash equilibrium have been widely applied\nacross various engineering domains. However, practical challenges such as\ndisturbances, delays, and actuator limitations can hinder the precise execution\nof Nash equilibrium strategies. This work explores the impact of such\nimplementation imperfections on game trajectories and players' costs within the\ncontext of a two-player linear quadratic (LQ) nonzero-sum game. Specifically,\nwe analyze how small deviations by one player affect the state and cost\nfunction of the other player. To address these deviations, we propose an\nadjusted control policy that not only mitigates adverse effects optimally but\ncan also exploit the deviations to enhance performance. Rigorous mathematical\nanalysis and proofs are presented, demonstrating through a representative\nexample that the proposed policy modification achieves up to $61\\%$ improvement\ncompared to the unadjusted feedback policy and up to $0.59\\%$ compared to the\nfeedback Nash strategy.", "published": "2025-03-24 22:56:59", "link": "http://arxiv.org/abs/2503.19200v1", "categories": ["cs.GT", "cs.MA", "cs.RO", "cs.SY", "eess.SY", "math.OC"], "primary_category": "cs.GT"}
{"title": "Cooperative Control of Multi-Quadrotors for Transporting Cable-Suspended Payloads: Obstacle-Aware Planning and Event-Based Nonlinear Model Predictive Control", "abstract": "This paper introduces a novel methodology for the cooperative control of\nmultiple quadrotors transporting cablesuspended payloads, emphasizing\nobstacle-aware planning and event-based Nonlinear Model Predictive Control\n(NMPC). Our approach integrates trajectory planning with real-time control\nthrough a combination of the A* algorithm for global path planning and NMPC for\nlocal control, enhancing trajectory adaptability and obstacle avoidance. We\npropose an advanced event-triggered control system that updates based on events\nidentified through dynamically generated environmental maps. These maps are\nconstructed using a dual-camera setup, which includes multi-camera systems for\nstatic obstacle detection and event cameras for high-resolution, low-latency\ndetection of dynamic obstacles. This design is crucial for addressing\nfast-moving and transient obstacles that conventional cameras may overlook,\nparticularly in environments with rapid motion and variable lighting\nconditions. When new obstacles are detected, the A* algorithm recalculates\nwaypoints based on the updated map, ensuring safe and efficient navigation.\nThis real-time obstacle detection and map updating integration allows the\nsystem to adaptively respond to environmental changes, markedly improving\nsafety and navigation efficiency. The system employs SLAM and object detection\ntechniques utilizing data from multi-cameras, event cameras, and IMUs for\naccurate localization and comprehensive environmental mapping. The NMPC\nframework adeptly manages the complex dynamics of multiple quadrotors and\nsuspended payloads, incorporating safety constraints to maintain dynamic\nfeasibility and stability. Extensive simulations validate the proposed\napproach, demonstrating significant enhancements in energy efficiency,\ncomputational resource management, and responsiveness.", "published": "2025-03-24 20:45:24", "link": "http://arxiv.org/abs/2503.19135v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Multi-agent coordination for data gathering with periodic requests and deliveries", "abstract": "In this demo work we develop a method to plan and coordinate a multi-agent\nteam to gather information on demand. The data is periodically requested by a\nstatic Operation Center (OC) from changeable goals locations. The mission of\nthe team is to reach these locations, taking measurements and delivering the\ndata to the OC. Due to the limited communication range as well as signal\nattenuation because of the obstacles, the agents must travel to the OC, to\nupload the data. The agents can play two roles: ones as workers gathering data,\nthe others as collectors traveling invariant paths for collecting the data of\nthe workers to re-transmit it to the OC. The refreshing time of the delivered\ninformation depends on the number of available agents as well as of the\nscenario. The proposed algorithm finds out the best balance between the number\nof collectors-workers and the partition of the scenario into working areas in\nthe planning phase, which provides the minimum refreshing time and will be the\none executed by the agents.", "published": "2025-03-24 10:59:31", "link": "http://arxiv.org/abs/2503.18546v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Communication-aware planning for robot teams deployment", "abstract": "In the present work we address the problem of deploying a team of robots in a\nscenario where some locations of interest must be reached. Thus, a planning for\na deployment is required, before sending the robots. The obstacles, the limited\ncommunication range, and the need of communicating to a base station, constrain\nthe connectivity of the team and the deployment planning. We propose a method\nconsisting of three algorithms: a distributed path planner to obtain\ncommunication-aware trajectories; a deployment planner providing dual-use of\nthe robots, visiting primary goals and performing connectivity tasks; and a\nclustering algorithm to allocate the tasks to robots, and obtain the best goal\nvisit order for the mission.", "published": "2025-03-24 10:59:23", "link": "http://arxiv.org/abs/2503.18545v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Agent-based Modeling meets the Capability Approach for Human Development: Simulating Homelessness Policy-making", "abstract": "The global rise in homelessness calls for urgent and alternative policy\nsolutions. Non-profits and governmental organizations alert about the many\nchallenges faced by people experiencing homelessness (PEH), which include not\nonly the lack of shelter but also the lack of opportunities for personal\ndevelopment. In this context, the capability approach (CA), which underpins the\nUnited Nations Sustainable Development Goals (SDGs), provides a comprehensive\nframework to assess inequity in terms of real opportunities. This paper\nexplores how the CA can be combined with agent-based modelling and\nreinforcement learning. The goals are: (1) implementing the CA as a Markov\nDecision Process (MDP), (2) building on such MDP to develop a rich\ndecision-making model that accounts for more complex motivators of behaviour,\nsuch as values and needs, and (3) developing an agent-based simulation\nframework that allows to assess alternative policies aiming to expand or\nrestore people's capabilities. The framework is developed in a real case study\nof health inequity and homelessness, working in collaboration with\nstakeholders, non-profits and domain experts. The ultimate goal of the project\nis to develop a novel agent-based simulation framework, rooted in the CA, which\ncan be replicated in a diversity of social contexts to assess policies in a\nnon-invasive way.", "published": "2025-03-24 07:00:38", "link": "http://arxiv.org/abs/2503.18389v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Numerical Stability Revisited: A Family of Benchmark Problems for the Analysis of Explicit Stochastic Differential Equation integrators", "abstract": "In this paper, we revisit the numerical stability of four well-established\nexplicit stochastic integration schemes through a new generic benchmark\nstochastic differential equation (SDE) designed to assess asymptotic\nstatistical accuracy and stability properties. This one-parameter benchmark\nequation is derived from a general one-dimensional first-order SDE using\nspatio-temporal nondimensionalization and is employed to evaluate the\nperformance of (1) Euler-Maruyama (EM), (2) Milstein (Mil), (3) Stochastic Heun\n(SH), and (4) a three-stage Runge-Kutta scheme (RK3).\n  Our findings reveal that lower-order schemes can outperform higher-order ones\nover a range of time step sizes, depending on the benchmark parameters and\napplication context. The theoretical results are validated through a series of\nnumerical experiments, and we discuss their implications for more general\napplications, including a nonlinear example of particle transport in porous\nmedia under various conditions. Our results suggest that the insights obtained\nfrom the linear benchmark problem provide reliable guidance for time-stepping\nstrategies when simulating nonlinear SDEs.", "published": "2025-03-24 23:05:58", "link": "http://arxiv.org/abs/2503.19203v1", "categories": ["math.NA", "cs.NA", "60H35, 65L20"], "primary_category": "math.NA"}
{"title": "Least Squares with Equality constraints Extreme Learning Machines for the resolution of PDEs", "abstract": "In this paper, we investigate the use of single hidden-layer neural networks\nas a family of ansatz functions for the resolution of partial differential\nequations (PDEs). In particular, we train the network via Extreme Learning\nMachines (ELMs) on the residual of the equation collocated on -- eventually\nrandomly chosen -- points. Because the approximation is done directly in the\nformulation, such a method falls into the framework of Physically Informed\nNeural Networks (PINNs) and has been named PIELM. Since its first introduction,\nthe method has been refined variously, and one successful variant is the\nExtreme Theory of Functional Connections (XTFC). However, XTFC strongly takes\nadvantage of the description of the domain as a tensor product. Our aim is to\nextend XTFC to domains with general shapes. The novelty of the procedure\nproposed in the present paper is related to the treatment of boundary\nconditions via constrained imposition, so that our method is named Least\nSquares with Equality constraints ELM (LSEELM). An in-depth analysis and\ncomparison with the cited methods is performed, again with the analysis of the\nconvergence of the method in various scenarios. We show the efficiency of the\nprocedure both in terms of computational cost and in terms of overall accuracy.", "published": "2025-03-24 22:22:24", "link": "http://arxiv.org/abs/2503.19185v1", "categories": ["math.NA", "cs.NA", "65N12, 65N35, 68T07"], "primary_category": "math.NA"}
{"title": "Block Gauss-Seidel methods for t-product tensor regression", "abstract": "Randomized iterative algorithms, such as the randomized Kaczmarz method and\nthe randomized Gauss-Seidel method, have gained considerable popularity due to\ntheir efficacy in solving matrix-vector and matrix-matrix regression problems.\nOur present work leverages the insights gained from studying such algorithms to\ndevelop regression methods for tensors, which are the natural setting for many\napplication problems, e.g., image deblurring. In particular, we extend two\nvariants of the block-randomized Gauss-Seidel method to solve a t-product\ntensor regression problem. We additionally develop methods for the special case\nwhere the measurement tensor is given in factorized form. We provide\ntheoretical guarantees of the exponential convergence rate of our algorithms,\naccompanied by illustrative numerical simulations.", "published": "2025-03-24 21:22:53", "link": "http://arxiv.org/abs/2503.19155v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "High Probability Complexity Bounds of Trust-Region Stochastic Sequential Quadratic Programming with Heavy-Tailed Noise", "abstract": "In this paper, we consider nonlinear optimization problems with a stochastic\nobjective and deterministic equality constraints. We propose a Trust-Region\nStochastic Sequential Quadratic Programming (TR-SSQP) method and establish its\nhigh-probability iteration complexity bounds for identifying first- and\nsecond-order $\\epsilon$-stationary points. In our algorithm, we assume that\nexact objective values, gradients, and Hessians are not directly accessible but\ncan be estimated via zeroth-, first-, and second-order probabilistic oracles.\nCompared to existing complexity studies of SSQP methods that rely on a\nzeroth-order oracle with sub-exponential tail noise (i.e., light-tailed) and\nfocus mostly on first-order stationarity, our analysis accommodates irreducible\nand heavy-tailed noise in the zeroth-order oracle and significantly extends the\nanalysis to second-order stationarity. We show that under heavy-tailed noise\nconditions, our SSQP method achieves the same high-probability first-order\niteration complexity bounds as in the light-tailed noise setting, while further\nexhibiting promising second-order iteration complexity bounds. Specifically,\nthe method identifies a first-order $\\epsilon$-stationary point in\n$\\mathcal{O}(\\epsilon^{-2})$ iterations and a second-order\n$\\epsilon$-stationary point in $\\mathcal{O}(\\epsilon^{-3})$ iterations with\nhigh probability, provided that $\\epsilon$ is lower bounded by a constant\ndetermined by the irreducible noise level in estimation. We validate our\ntheoretical findings and evaluate the practical performance of our method on\nCUTEst benchmark test set.", "published": "2025-03-24 19:23:13", "link": "http://arxiv.org/abs/2503.19091v2", "categories": ["math.OC", "cs.CC", "cs.LG", "cs.NA", "math.NA", "stat.ML"], "primary_category": "math.OC"}
{"title": "On the numerical stability of sketched GMRES", "abstract": "We perform a backward stability analysis of preconditioned sketched GMRES\n[Nakatsukasa and Tropp, SIAM J. Matrix Anal. Appl, 2024] for solving linear\nsystems $Ax=b$, and show that the backward stability at iteration $i$ depends\non the conditioning of the Krylov basis $B_{1:i}$ as long as the condition\nnumber of $A B_{1:i}$ can be bounded by $1/O(u)$, where $u$ is the unit\nroundoff. Under this condition, we show that sketched GMRES is backward stable\nas long as the condition number of $B_{1:i}$ is not too large. Under additional\nassumptions, we then show that the stability of a restarted implementation of\nsketched GMRES can be independent of the condition number of $B_{1:i}$, and\nrestarted sketched GMRES is backward stable. We also derive sharper bounds that\nexplain why the backward error can be small even in cases when the basis\n$B_{1:i}$ is very ill-conditioned, which has been observed in the literature\nbut not yet explained theoretically. We present numerical experiments to\ndemonstrate the conclusions of our analysis, and also show that adaptively\nrestarting where appropriate allows us to recover backward stability in\nsketched GMRES.", "published": "2025-03-24 19:16:08", "link": "http://arxiv.org/abs/2503.19086v1", "categories": ["math.NA", "cs.NA", "65F10, 65F50, 65G50"], "primary_category": "math.NA"}
{"title": "Observations on Recurrent Loss in the Neural Network Model of a Partial Differential Equation: the Advection-Diffusion Equation", "abstract": "A growing body of literature has been leveraging techniques of machine\nlearning (ML) to build novel approaches to approximating the solutions to\npartial differential equations. Noticeably absent from the literature is a\nsystematic exploration of the stability of the solutions generated by these ML\napproaches. Here, a recurrent network is introduced that matches precisely the\nevaluation of a multistep method paired with a collocation method for\napproximating spatial derivatives in the advection diffusion equation. This\nallows for two things: 1) the use of traditional tools for analyzing the\nstability of a numerical method for solving PDEs and 2) bringing to bear\nefficient techniques of ML for the training of approximations for the action of\n(spatial) linear operators. Observations on impacts of varying the large number\nof parameters in even this simple linear problem are presented. Further, it is\ndemonstrated that stable solutions can be found even where traditional\nnumerical methods may fail.", "published": "2025-03-24 18:06:47", "link": "http://arxiv.org/abs/2503.19036v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fast and Accurate Interpolative Decompositions for General, Sparse, and Structured Tensors", "abstract": "In this work, we develop deterministic and random sketching-based algorithms\nfor two types of tensor interpolative decompositions (ID): the core\ninterpolative decomposition (CoreID, also known as the structure-preserving\nHOSVD) and the satellite interpolative decomposition (SatID, also known as the\nHOID or CURT). We adopt a new adaptive approach that leads to ID error bounds\nindependent of the size of the tensor. In addition to the adaptive approach, we\nuse tools from random sketching to enable an efficient and provably accurate\ncalculation of these decompositions. We also design algorithms specialized to\ntensors that are sparse or given as a sum of rank-one tensors, i.e., in the CP\nformat. Besides theoretical analyses, numerical experiments on both synthetic\nand real-world data demonstrate the power of the proposed algorithms.", "published": "2025-03-24 17:43:00", "link": "http://arxiv.org/abs/2503.18921v1", "categories": ["math.NA", "cs.NA", "15A69, 65F55, 68W20"], "primary_category": "math.NA"}
{"title": "High-Order and Energy-Stable Implicit-Explicit Relaxation Runge-Kutta Schemes for Gradient Flows", "abstract": "In this paper, we propose a class of high-order and energy-stable\nimplicit-explicit relaxation Runge-Kutta (IMEX RRK) schemes for solving the\nphase-field gradient flow models. By incorporating the scalar auxiliary\nvariable (SAV) method, the original equations are reformulated into equivalent\nforms, and the modified energy is introduced. Then, based on the reformulated\nequations, we propose a kind of IMEX RRK methods, which are rigorously proved\nto preserve the energy dissipation law and achieve high-order accuracy for both\nAllen-Cahn and Cahn-Hilliard equations. Numerical experiments are conducted to\nvalidate the theoretical results, including the accuracy of the approximate\nsolution and the efficiency of the proposed scheme. Furthermore, the schemes\nare extended to multi-component gradient flows, with the vector-valued\nAllen-Cahn equations serving as a representative example.", "published": "2025-03-24 16:18:37", "link": "http://arxiv.org/abs/2503.18844v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Dirichlet-to-Neumann operator for the Helmholtz problem with general wavenumbers on the $n$-sphere", "abstract": "This paper considers the Helmholtz problem in the exterior of a ball with\nDirichlet boundary conditions and radiation conditions imposed at infinity. The\ndifferential Helmholtz operator depends on the complex wavenumber with\nnon-negative real part and is formulated for general spatial dimension. We\nprove wavenumber explicit continuity estimates of the corresponding\nDirichlet-to-Neumann (DtN) operator which are valid for all wavenumbers under\nconsideration and do not deteriorate as they tend to zero.\n  The exterior Helmholtz problem can be equivalently reformulated on a bounded\ndomain with DtN boundary conditions on the artificial boundary of a ball. We\nderive wavenumber independent trace and Friedrichs-type inequalities for the\nsolution space in wavenumber-indexed norms.", "published": "2025-03-24 16:11:03", "link": "http://arxiv.org/abs/2503.18837v1", "categories": ["math.AP", "cs.NA", "math.NA", "31B10, 35J05, 47G10"], "primary_category": "math.AP"}
{"title": "On two families of iterative methods without memory", "abstract": "We study two natural families of methods of order $n\\ge 2$ that are useful\nfor solving numerically one variable equations $f(x)=0.$ The first family\nconsists on the methods that depend on $x,f(x)$ and its successive derivatives\nup to $f^{(n-1)}(x)$ and the second family comprises methods that depend on\n$x,g(x)$ until $g^{\\circ n}(x),$ where $g^{\\circ m}(x)=g(g^{\\circ (m-1)}(x))$\nand $g(x)=f(x)+x$. The first family includes the well-known Newton, Chebyshev,\nand Halley methods, while the second one contains the Steffensen method.\nAlthough the results for the first type of methods are well known and\nclassical, we provide new, simple, detailed, and self-contained proofs.", "published": "2025-03-24 15:54:48", "link": "http://arxiv.org/abs/2503.18815v1", "categories": ["math.NA", "cs.NA", "math.DS", "65H05, 58C30"], "primary_category": "math.NA"}
{"title": "Micro-Macro Coupling for Optimizing Scaffold Mediated Bone Regeneration", "abstract": "This work presents a framework for modeling three-dimensional\nscaffold-mediated bone regeneration and the associated optimization problem. By\nincorporating microstructure into the model through periodic homogenization, we\ncapture the effects of microscale fluctuations on the bone growth process.\nNumerical results and optimized scaffold designs that explicitly account for\nthe microstructure are presented, demonstrating the potential of this approach\nfor improving scaffold performance.", "published": "2025-03-24 15:40:20", "link": "http://arxiv.org/abs/2503.18795v1", "categories": ["math.NA", "cs.NA", "68Q25, 68R10, 68U05"], "primary_category": "math.NA"}
{"title": "Efficient QR-Based CP Decomposition Acceleration via Dimension Tree and Extrapolation", "abstract": "The canonical polyadic (CP) decomposition is one of the most widely used\ntensor decomposition techniques. The conventional CP decomposition algorithm\ncombines alternating least squares (ALS) with the normal equation. However, the\nnormal equation is susceptible to numerical ill-conditioning, which can\nadversely affect the decomposition results. To mitigate this issue, ALS\ncombined with QR decomposition has been proposed as a more numerically stable\nalternative. Although this method enhances stability, its iterative process\ninvolves tensor-times-matrix (TTM) operations, which typically result in higher\ncomputational costs. To reduce this cost, we propose branch reutilization of\ndimension tree, which increases the reuse of intermediate tensors and reduces\nthe number of TTM operations. This strategy achieves a $33\\%$ reduction in\ncomputational complexity for third and fourth order tensors. Additionally, we\nintroduce a specialized extrapolation method in CP-ALS-QR algorithm, leveraging\nthe unique structure of the matrix $\\mathbf{Q}_0$ to further enhance\nconvergence. By integrating both techniques, we develop a novel CP\ndecomposition algorithm that significantly improves efficiency. Numerical\nexperiments on five real-world datasets show that our proposed algorithm\nreduces iteration costs and enhances fitting accuracy compared to the CP-ALS-QR\nalgorithm.", "published": "2025-03-24 15:07:37", "link": "http://arxiv.org/abs/2503.18759v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Rough Heston model as the scaling limit of bivariate cumulative heavy-tailed INAR($\\infty$) processes and applications", "abstract": "This paper establishes a novel link between nearly unstable cumulative\nheavy-tailed integer-valued autoregressive (INAR($\\infty$)) processes and the\nrough Heston model via discrete scaling limits. We prove that a sequence of\nbivariate cumulative INAR($\\infty$) processes converge in law to the rough\nHeston model under appropriate scaling conditions, providing a rigorous\nmathematical foundation for understanding how microstructural order flow drives\nmacroscopic prices following rough volatility dynamics. Our theoretical\nframework extends the scaling limit techniques from Hawkes processes to the\nINAR($\\infty$) setting. Hence we can carry out efficient Monte Carlo simulation\nof the rough Heston model through simulating the corresponding approximating\nINAR($\\infty$) processes, which provides an alternative discrete-time\nsimulation method to the Euler-Maruyama method. Extensive numerical experiments\nillustrate the improved accuracy and efficiency of the proposed simulation\nscheme as compared to the literature, in the valuation of European options, and\nalso path-dependent options such as arithmetic Asian options, lookback options\nand barrier options.", "published": "2025-03-24 00:58:26", "link": "http://arxiv.org/abs/2503.18259v2", "categories": ["math.PR", "q-fin.MF", "60G22, 60H35, 91G20, 62M10, 60F17"], "primary_category": "math.PR"}
{"title": "Cryptocurrency Time Series on the Binary Complexity-Entropy Plane: Ranking Efficiency from the Perspective of Complex Systems", "abstract": "We report the first application of a tailored Complexity-Entropy Plane\ndesigned for binary sequences and structures. We do so by considering the daily\nup/down price fluctuations of the largest cryptocurrencies in terms of\ncapitalization (stable-coins excluded) that are worth $circa \\,\\, 90 \\%$ of the\ntotal crypto market capitalization. With that, we focus on the basic elements\nof price motion that compare with the random walk backbone features associated\nwith mathematical properties of the Efficient Market Hypothesis. From the\nlocation of each crypto on the Binary Complexity-Plane (BiCEP) we define an\ninefficiency score, $\\mathcal I$, and rank them accordingly. The results based\non the BiCEP analysis, which we substantiate with statistical testing, indicate\nthat only Shiba Inu (SHIB) is significantly inefficient, whereas the largest\nstake of crypto trading is reckoned to operate in close-to-efficient\nconditions. Generically, our $\\mathcal I$-based ranking hints the design and\nconsensus architecture of a crypto is at least as relevant to efficiency as the\nfeatures that are usually taken into account in the appraisal of the efficiency\nof financial instruments, namely canonical fiat money. Lastly, this set of\nresults supports the validity of the binary complexity analysis.", "published": "2025-03-24 22:01:24", "link": "http://arxiv.org/abs/2504.01974v1", "categories": ["q-fin.ST", "physics.data-an", "physics.soc-ph"], "primary_category": "q-fin.ST"}
{"title": "Analytic DAG Constraints for Differentiable DAG Learning", "abstract": "Recovering the underlying Directed Acyclic Graph (DAG) structures from\nobservational data presents a formidable challenge, partly due to the\ncombinatorial nature of the DAG-constrained optimization problem. Recently,\nresearchers have identified gradient vanishing as one of the primary obstacles\nin differentiable DAG learning and have proposed several DAG constraints to\nmitigate this issue. By developing the necessary theory to establish a\nconnection between analytic functions and DAG constraints, we demonstrate that\nanalytic functions from the set $\\{f(x) = c_0 + \\sum_{i=1}^{\\infty}c_ix^i |\n\\forall i > 0, c_i > 0; r = \\lim_{i\\rightarrow \\infty}c_{i}/c_{i+1} > 0\\}$ can\nbe employed to formulate effective DAG constraints. Furthermore, we establish\nthat this set of functions is closed under several functional operators,\nincluding differentiation, summation, and multiplication. Consequently, these\noperators can be leveraged to create novel DAG constraints based on existing\nones. Using these properties, we design a series of DAG constraints and develop\nan efficient algorithm to evaluate them. Experiments in various settings\ndemonstrate that our DAG constraints outperform previous state-of-the-art\ncomparators. Our implementation is available at\nhttps://github.com/zzhang1987/AnalyticDAGLearning.", "published": "2025-03-24 23:51:35", "link": "http://arxiv.org/abs/2503.19218v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Universal Architectures for the Learning of Polyhedral Norms and Convex Regularization Functionals", "abstract": "This paper addresses the task of learning convex regularizers to guide the\nreconstruction of images from limited data. By imposing that the reconstruction\nbe amplitude-equivariant, we narrow down the class of admissible functionals to\nthose that can be expressed as a power of a seminorm. We then show that such\nfunctionals can be approximated to arbitrary precision with the help of\npolyhedral norms. In particular, we identify two dual parameterizations of such\nsystems: (i) a synthesis form with an $\\ell_1$-penalty that involves some\nlearnable dictionary; and (ii) an analysis form with an $\\ell_\\infty$-penalty\nthat involves a trainable regularization operator. After having provided\ngeometric insights and proved that the two forms are universal, we propose an\nimplementation that relies on a specific architecture (tight frame with a\nweighted $\\ell_1$ penalty) that is easy to train. We illustrate its use for\ndenoising and the reconstruction of biomedical images. We find that the\nproposed framework outperforms the sparsity-based methods of compressed\nsensing, while it offers essentially the same convergence and robustness\nguarantees.", "published": "2025-03-24 22:32:10", "link": "http://arxiv.org/abs/2503.19190v1", "categories": ["stat.ML", "cs.LG", "math.OC"], "primary_category": "stat.ML"}
{"title": "Stochastic Poisson Surface Reconstruction with One Solve using Geometric Gaussian Processes", "abstract": "Poisson Surface Reconstruction is a widely-used algorithm for reconstructing\na surface from an oriented point cloud. To facilitate applications where only\npartial surface information is available, or scanning is performed\nsequentially, a recent line of work proposes to incorporate uncertainty into\nthe reconstructed surface via Gaussian process models. The resulting algorithms\nfirst perform Gaussian process interpolation, then solve a set of volumetric\npartial differential equations globally in space, resulting in a\ncomputationally expensive two-stage procedure. In this work, we apply\nrecently-developed techniques from geometric Gaussian processes to combine\ninterpolation and surface reconstruction into a single stage, requiring only\none linear solve per sample. The resulting reconstructed surface samples can be\nqueried locally in space, without the use of problem-dependent volumetric\nmeshes or grids. These capabilities enable one to (a) perform probabilistic\ncollision detection locally around the region of interest, (b) perform ray\ncasting without evaluating points not on the ray's trajectory, and (c) perform\nnext-view planning on a per-slice basis. They also improve reconstruction\nquality, by not requiring one to approximate kernel matrix inverses with\ndiagonal matrices as part of intermediate computations. Results show that our\napproach provides a cleaner, more-principled, and more-flexible stochastic\nsurface reconstruction pipeline.", "published": "2025-03-24 20:47:51", "link": "http://arxiv.org/abs/2503.19136v1", "categories": ["cs.GR", "cs.CV", "cs.LG", "stat.ML"], "primary_category": "cs.GR"}
{"title": "Tractable downfall of basis pursuit in structured sparse optimization", "abstract": "The problem of finding the sparsest solution to a linear underdetermined\nsystem of equations, as it often appears in data analysis, optimal control and\nsystem identification problems, is considered. This non-convex problem is\ncommonly solved by convexification via $\\ell_1$-norm minimization, also known\nas basis pursuit. In this work, a class of structured matrices, representing\nthe system of equations, is introduced for which the basis pursuit approach\ntractably fails to recover the sparsest solution. In particular, we are able to\nidentify matrix columns that correspond to unrecoverable non-zero entries of\nthe sparsest solution, as well as to conclude the uniqueness of the sparsest\nsolution in polynomial time. These deterministic guarantees contrast popular\nprobabilistic ones, and as such, provide valuable insights into the a priori\ndesign of sparse optimization problems. As our matrix structure appears\nnaturally in optimal control problems, we exemplify our findings by showing\nthat it is possible to verify a priori that basis pursuit may fail in finding\nfuel optimal regulators for a class of discrete-time linear time-invariant\nsystems.", "published": "2025-03-24 20:27:54", "link": "http://arxiv.org/abs/2503.19126v1", "categories": ["math.OC", "stat.ML", "90C06, 90C25, 90C26, 90C59, 49M25"], "primary_category": "math.OC"}
{"title": "Bayesian Semi-Parametric Spatial Dispersed Count Model for Precipitation Analysis", "abstract": "The appropriateness of the Poisson model is frequently challenged when\nexamining spatial count data marked by unbalanced distributions,\nover-dispersion, or under-dispersion. Moreover, traditional parametric models\nmay inadequately capture the relationships among variables when covariates\ndisplay ambiguous functional forms or when spatial patterns are intricate and\nindeterminate. To tackle these issues, we propose an innovative Bayesian\nhierarchical modeling system. This method combines non-parametric techniques\nwith an adapted dispersed count model based on renewal theory, facilitating the\neffective management of unequal dispersion, non-linear correlations, and\ncomplex geographic dependencies in count data. We illustrate the efficacy of\nour strategy by applying it to lung and bronchus cancer mortality data from\nIowa, emphasizing environmental and demographic factors like ozone\nconcentrations, PM2.5, green space, and asthma prevalence. Our analysis\ndemonstrates considerable regional heterogeneity and non-linear relationships,\nproviding important insights into the impact of environmental and\nhealth-related factors on cancer death rates. This application highlights the\nsignificance of our methodology in public health research, where precise\nmodeling and forecasting are essential for guiding policy and intervention\nefforts. Additionally, we performed a simulation study to assess the resilience\nand accuracy of the suggested method, validating its superiority in managing\ndispersion and capturing intricate spatial patterns relative to conventional\nmethods. The suggested framework presents a flexible and robust instrument for\ngeographical count analysis, offering innovative insights for academics and\npractitioners in disciplines such as epidemiology, environmental science, and\nspatial statistics.", "published": "2025-03-24 20:13:55", "link": "http://arxiv.org/abs/2503.19117v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Accelerating Langevin Monte Carlo Sampling: A Large Deviations Analysis", "abstract": "Langevin algorithms are popular Markov chain Monte Carlo methods that are\noften used to solve high-dimensional large-scale sampling problems in machine\nlearning. The most classical Langevin Monte Carlo algorithm is based on the\noverdamped Langevin dynamics. There are many variants of Langevin dynamics that\noften show superior performance in practice. In this paper, we provide a\nunified approach to study the acceleration of the variants of the overdamped\nLangevin dynamics through the lens of large deviations theory. Numerical\nexperiments using both synthetic and real data are provided to illustrate the\nefficiency of these variants.", "published": "2025-03-24 18:52:45", "link": "http://arxiv.org/abs/2503.19066v1", "categories": ["math.PR", "stat.ML"], "primary_category": "math.PR"}
{"title": "Causal Links Between Anthropogenic Emissions and Air Pollution Dynamics in Delhi", "abstract": "Air pollution poses significant health and environmental challenges,\nparticularly in rapidly urbanizing regions. Delhi-National Capital Region\nexperiences air pollution episodes due to complex interactions between\nanthropogenic emissions and meteorological conditions. Understanding the causal\ndrivers of key pollutants such as $PM_{2.5}$ and ground $O_3$ is crucial for\ndeveloping effective mitigation strategies. This study investigates the causal\nlinks of anthropogenic emissions on $PM_{2.5}$ and $O_3$ concentrations using\npredictive modeling and causal inference techniques. Integrating\nhigh-resolution air quality data from Jan 2018 to Aug 2023 across 32 monitoring\nstations, we develop predictive regression models that incorporate\nmeteorological variables (temperature and relative humidity), pollutant\nconcentrations ($NO_2, SO_2, CO$), and seasonal harmonic components to capture\nboth diurnal and annual cycles. Here, we show that reductions in anthropogenic\nemissions lead to significant decreases in $PM_{2.5}$ levels, whereas their\neffect on $O_3$ remains marginal and statistically insignificant. To address\nspatial heterogeneity, we employ Gaussian Process modeling. Further, we use\nGranger causality analysis and counterfactual simulation to establish direct\ncausal links. Validation using real-world data from the COVID-19 lockdown\nconfirms that reduced emissions led to a substantial drop in $PM_{2.5}$ but\nonly a slight, insignificant change in $O_3$. The findings highlight the\nnecessity of targeted emission reduction policies while emphasizing the need\nfor integrated strategies addressing both particulate and ozone pollution.\nThese insights are crucial for policymakers designing air pollution\ninterventions in other megacities, and offer a scalable methodology for\ntackling complex urban air pollution through data-driven decision-making.", "published": "2025-03-24 17:25:44", "link": "http://arxiv.org/abs/2503.18912v1", "categories": ["stat.AP", "physics.ao-ph", "physics.soc-ph", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Calibration Bands for Mean Estimates within the Exponential Dispersion Family", "abstract": "A statistical model is said to be calibrated if the resulting mean estimates\nperfectly match the true means of the underlying responses. Aiming for\ncalibration is often not achievable in practice as one has to deal with finite\nsamples of noisy observations. A weaker notion of calibration is\nauto-calibration. An auto-calibrated model satisfies that the expected value of\nthe responses being given the same mean estimate matches this estimate. Testing\nfor auto-calibration has only been considered recently in the literature and we\npropose a new approach based on calibration bands. Calibration bands denote a\nset of lower and upper bounds such that the probability that the true means lie\nsimultaneously inside those bounds exceeds some given confidence level. Such\nbands were constructed by Yang-Barber (2019) for sub-Gaussian distributions.\nDimitriadis et al. (2023) then introduced narrower bands for the Bernoulli\ndistribution and we use the same idea in order to extend the construction to\nthe entire exponential dispersion family that contains for example the\nbinomial, Poisson, negative binomial, gamma and normal distributions. Moreover,\nwe show that the obtained calibration bands allow us to construct various tests\nfor calibration and auto-calibration, respectively.", "published": "2025-03-24 17:09:19", "link": "http://arxiv.org/abs/2503.18896v1", "categories": ["math.ST", "stat.AP", "stat.ML", "stat.TH", "62P05 (Primary), 62G10 (Secondary), 91G05, 60E05", "G.3"], "primary_category": "math.ST"}
{"title": "Local Interference: Removing Interference Bias in Semi-Parametric Causal Models", "abstract": "Interference bias is a major impediment to identifying causal effects in\nreal-world settings. For example, vaccination reduces the transmission of a\nvirus in a population such that everyone benefits -- even those who are not\ntreated. This is a source of bias that must be accounted for if one wants to\nlearn the true effect of a vaccine on an individual's immune system. Previous\napproaches addressing interference bias require strong domain knowledge in the\nform of a graphical interaction network fully describing interference between\nunits. Moreover, they place additional constraints on the form the interference\ncan take, such as restricting to linear outcome models, and assuming that\ninterference experienced by a unit does not depend on the unit's covariates.\nOur work addresses these shortcomings. We first provide and justify a novel\ndefinition of causal models with local interference. We prove that the True\nAverage Causal Effect, a measure of causality where interference has been\nremoved, can be identified in certain semi-parametric models satisfying this\ndefinition. These models allow for non-linearity, and also for interference to\ndepend on a unit's covariates. An analytic estimand for the True Average Causal\nEffect is given in such settings. We further prove that the True Average Causal\nEffect cannot be identified in arbitrary models with local interference,\nshowing that identification requires semi-parametric assumptions. Finally, we\nprovide an empirical validation of our method on both simulated and real-world\ndatasets.", "published": "2025-03-24 15:06:05", "link": "http://arxiv.org/abs/2503.18756v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Dynamically Learning to Integrate in Recurrent Neural Networks", "abstract": "Learning to remember over long timescales is fundamentally challenging for\nrecurrent neural networks (RNNs). While much prior work has explored why RNNs\nstruggle to learn long timescales and how to mitigate this, we still lack a\nclear understanding of the dynamics involved when RNNs learn long timescales\nvia gradient descent. Here we build a mathematical theory of the learning\ndynamics of linear RNNs trained to integrate white noise. We show that when the\ninitial recurrent weights are small, the dynamics of learning are described by\na low-dimensional system that tracks a single outlier eigenvalue of the\nrecurrent weights. This reveals the precise manner in which the long timescale\nassociated with white noise integration is learned. We extend our analyses to\nRNNs learning a damped oscillatory filter, and find rich dynamical equations\nfor the evolution of a conjugate pair of outlier eigenvalues. Taken together,\nour analyses build a rich mathematical framework for studying dynamical\nlearning problems salient for both machine learning and neuroscience.", "published": "2025-03-24 15:03:23", "link": "http://arxiv.org/abs/2503.18754v1", "categories": ["q-bio.NC", "cond-mat.dis-nn", "stat.ML"], "primary_category": "q-bio.NC"}
{"title": "Thermalizer: Stable autoregressive neural emulation of spatiotemporal chaos", "abstract": "Autoregressive surrogate models (or \\textit{emulators}) of spatiotemporal\nsystems provide an avenue for fast, approximate predictions, with broad\napplications across science and engineering. At inference time, however, these\nmodels are generally unable to provide predictions over long time rollouts due\nto accumulation of errors leading to diverging trajectories. In essence,\nemulators operate out of distribution, and controlling the online distribution\nquickly becomes intractable in large-scale settings. To address this\nfundamental issue, and focusing on time-stationary systems admitting an\ninvariant measure, we leverage diffusion models to obtain an implicit estimator\nof the score of this invariant measure. We show that this model of the score\nfunction can be used to stabilize autoregressive emulator rollouts by applying\non-the-fly denoising during inference, a process we call\n\\textit{thermalization}. Thermalizing an emulator rollout is shown to extend\nthe time horizon of stable predictions by an order of magnitude in complex\nsystems exhibiting turbulent and chaotic behavior, opening up a novel\napplication of diffusion models in the context of neural emulation.", "published": "2025-03-24 14:38:33", "link": "http://arxiv.org/abs/2503.18731v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Differentially Private Joint Independence Test", "abstract": "Identification of joint dependence among more than two random vectors plays\nan important role in many statistical applications, where the data may contain\nsensitive or confidential information. In this paper, we consider the the\nd-variable Hilbert-Schmidt independence criterion (dHSIC) in the context of\ndifferential privacy. Given the limiting distribution of the empirical estimate\nof dHSIC is complicated Gaussian chaos, constructing tests in the non-privacy\nregime is typically based on permutation and bootstrap. To detect joint\ndependence in privacy, we propose a dHSIC-based testing procedure by employing\na differentially private permutation methodology. Our method enjoys privacy\nguarantee, valid level and pointwise consistency, while the bootstrap\ncounterpart suffers inconsistent power. We further investigate the uniform\npower of the proposed test in dHSIC metric and $L_2$ metric, indicating that\nthe proposed test attains the minimax optimal power across different privacy\nregimes. As a byproduct, our results also contain the pointwise and uniform\npower of the non-private permutation dHSIC, addressing an unsolved question\nremained in Pfister et al. (2018).", "published": "2025-03-24 14:32:05", "link": "http://arxiv.org/abs/2503.18721v1", "categories": ["math.ST", "cs.CR", "cs.LG", "stat.ME", "stat.ML", "stat.TH", "62G10, 62H20"], "primary_category": "math.ST"}
{"title": "Pitch Contour Exploration Across Audio Domains: A Vision-Based Transfer Learning Approach", "abstract": "This study examines pitch contours as a unifying semantic construct prevalent\nacross various audio domains including music, speech, bioacoustics, and\neveryday sounds. Analyzing pitch contours offers insights into the universal\nrole of pitch in the perceptual processing of audio signals and contributes to\na deeper understanding of auditory mechanisms in both humans and animals.\nConventional pitch-tracking methods, while optimized for music and speech, face\nchallenges in handling much broader frequency ranges and more rapid pitch\nvariations found in other audio domains. This study introduces a vision-based\napproach to pitch contour analysis that eliminates the need for explicit\npitch-tracking. The approach uses a convolutional neural network, pre-trained\nfor object detection in natural images and fine-tuned with a dataset of\nsynthetically generated pitch contours, to extract key contour parameters from\nthe time-frequency representation of short audio segments. A diverse set of\neight downstream tasks from four audio domains were selected to provide a\nchallenging evaluation scenario for cross-domain pitch contour analysis. The\nresults show that the proposed method consistently surpasses traditional\ntechniques based on pitch-tracking on a wide range of tasks. This suggests that\nthe vision-based approach establishes a foundation for comparative studies of\npitch contour characteristics across diverse audio domains.", "published": "2025-03-24 21:33:13", "link": "http://arxiv.org/abs/2503.19161v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Reliable and Efficient Detection Pipeline for Rodent Ultrasonic Vocalizations", "abstract": "Analyzing ultrasonic vocalizations (USVs) is crucial for understanding\nrodents' affective states and social behaviors, but the manual analysis is\ntime-consuming and prone to errors. Automated USV detection systems have been\ndeveloped to address these challenges. Yet, these systems often rely on machine\nlearning and fail to generalize effectively to new datasets. To tackle these\nshortcomings, we introduce ContourUSV, an efficient automated system for\ndetecting USVs from audio recordings. Our pipeline includes spectrogram\ngeneration, cleaning, pre-processing, contour detection, post-processing, and\nevaluation against manual annotations. To ensure robustness and reliability, we\ncompared ContourUSV with three state-of-the-art systems using an existing\nopen-access USV dataset (USVSEG) and a second dataset we are releasing publicly\nalong with this paper. On average, across the two datasets, ContourUSV\noutperformed the other three systems with a 1.51x improvement in precision,\n1.17x in recall, 1.80x in F1 score, and 1.49x in specificity while achieving an\naverage speedup of 117.07x.", "published": "2025-03-24 17:50:49", "link": "http://arxiv.org/abs/2503.18928v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Seeing Speech and Sound: Distinguishing and Locating Audios in Visual Scenes", "abstract": "We present a unified model capable of simultaneously grounding both spoken\nlanguage and non-speech sounds within a visual scene, addressing key\nlimitations in current audio-visual grounding models. Existing approaches are\ntypically limited to handling either speech or non-speech sounds independently,\nor at best, together but sequentially without mixing. This limitation prevents\nthem from capturing the complexity of real-world audio sources that are often\nmixed. Our approach introduces a 'mix-and-separate' framework with audio-visual\nalignment objectives that jointly learn correspondence and disentanglement\nusing mixed audio. Through these objectives, our model learns to produce\ndistinct embeddings for each audio type, enabling effective disentanglement and\ngrounding across mixed audio sources. Additionally, we created a new dataset to\nevaluate simultaneous grounding of mixed audio sources, demonstrating that our\nmodel outperforms prior methods. Our approach also achieves comparable or\nbetter performance in standard segmentation and cross-modal retrieval tasks,\nhighlighting the benefits of our mix-and-separate approach.", "published": "2025-03-24 16:56:04", "link": "http://arxiv.org/abs/2503.18880v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Wireless Hearables With Programmable Speech AI Accelerators", "abstract": "The conventional wisdom has been that designing ultra-compact,\nbattery-constrained wireless hearables with on-device speech AI models is\nchallenging due to the high computational demands of streaming deep learning\nmodels. Speech AI models require continuous, real-time audio processing,\nimposing strict computational and I/O constraints. We present NeuralAids, a\nfully on-device speech AI system for wireless hearables, enabling real-time\nspeech enhancement and denoising on compact, battery-constrained devices. Our\nsystem bridges the gap between state-of-the-art deep learning for speech\nenhancement and low-power AI hardware by making three key technical\ncontributions: 1) a wireless hearable platform integrating a speech AI\naccelerator for efficient on-device streaming inference, 2) an optimized\ndual-path neural network designed for low-latency, high-quality speech\nenhancement, and 3) a hardware-software co-design that uses mixed-precision\nquantization and quantization-aware training to achieve real-time performance\nunder strict power constraints. Our system processes 6 ms audio chunks in\nreal-time, achieving an inference time of 5.54 ms while consuming 71.6 mW. In\nreal-world evaluations, including a user study with 28 participants, our system\noutperforms prior on-device models in speech quality and noise suppression,\npaving the way for next-generation intelligent wireless hearables that can\nenhance hearing entirely on-device.", "published": "2025-03-24 14:10:30", "link": "http://arxiv.org/abs/2503.18698v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Risk-Calibrated Affective Speech Recognition via Conformal Coverage Guarantees: A Stochastic Calibrative Framework for Emergent Uncertainty Quantification", "abstract": "Traffic safety challenges arising from extreme driver emotions highlight the\nurgent need for reliable emotion recognition systems. Traditional deep learning\napproaches in speech emotion recognition suffer from overfitting and poorly\ncalibrated confidence estimates. We propose a framework integrating Conformal\nPrediction (CP) and Risk Control,using Mel-spectrogram features processed\nthrough a pre-trained convolutional neural network. Our key innovation is the\ndevelopment of a nonconformity score that heuristically measures how closely a\nclassifier's predictions align with given inputs. Through calibration samples,\nwe compute this score and derive a statistically rigorous threshold based on\nuser-specified risk level $\\alpha$, constructing prediction sets with provable\ncoverage guarantees ($\\geq 1-\\alpha$). The Risk Control framework enables\ntask-specific adaptation through customizable loss functions, dynamically\nadjusting prediction set sizes while maintaining coverage guarantees.\nCross-dataset experiments on IEMOCAP and TESS demonstrate: 1) Strict coverage\nguarantee, 2) Significant negative correlation between Average Prediction Set\nSize (APSS) and $\\alpha$, revealing reduced model uncertainty under high-risk\nconditions. We further propose APSS as a novel metric for evaluating\nclassification uncertainty. This approach enhances speech emotion recognition\nreliability, with direct applications in intelligent transportation systems and\nreal-time emotion monitoring.", "published": "2025-03-24 12:26:28", "link": "http://arxiv.org/abs/2503.22712v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Joint Spectrogram Separation and TDOA Estimation using Optimal Transport", "abstract": "Separating sources is a common challenge in applications such as speech\nenhancement and telecommunications, where distinguishing between overlapping\nsounds helps reduce interference and improve signal quality. Additionally, in\nmultichannel systems, correct calibration and synchronization are essential to\nseparate and locate source signals accurately. This work introduces a method\nfor blind source separation and estimation of the Time Difference of Arrival\n(TDOA) of signals in the time-frequency domain. Our proposed method effectively\nseparates signal mixtures into their original source spectrograms while\nsimultaneously estimating the relative delays between receivers, using Optimal\nTransport (OT) theory. By exploiting the structure of the OT problem, we\ncombine the separation and delay estimation processes into a unified framework,\noptimizing the system through a block coordinate descent algorithm. We analyze\nthe performance of the OT-based estimator under various noise conditions and\ncompare it with conventional TDOA and source separation methods. Numerical\nsimulation results demonstrate that our proposed approach can achieve a\nsignificant level of accuracy across diverse noise scenarios for physical\nspeech signals in both TDOA and source separation tasks.", "published": "2025-03-24 11:57:38", "link": "http://arxiv.org/abs/2503.18600v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Target Speaker Selection for Neural Network Beamforming in Multi-Speaker Scenarios", "abstract": "We propose a speaker selection mechanism (SSM) for the training of an\nend-to-end beamforming neural network, based on recent findings that a listener\nusually looks to the target speaker with a certain undershot angle. The\nmechanism allows the neural network model to learn toward which speaker to\nfocus, during training, in a multi-speaker scenario, based on the position of\nlistener and speakers. However, only audio information is necessary during\ninference. We perform acoustic simulations demonstrating the feasibility and\nperformance when the SSM is employed in training. The results show significant\nincrease in speech intelligibility, quality, and distortion metrics when\ncompared to the minimum variance distortionless filter and the same neural\nnetwork model trained without SSM. The success of the proposed method is a\nsignificant step forward toward the solution of the cocktail party problem.", "published": "2025-03-24 11:47:32", "link": "http://arxiv.org/abs/2503.18590v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Unsupervised Variational Acoustic Clustering", "abstract": "We propose an unsupervised variational acoustic clustering model for\nclustering audio data in the time-frequency domain. The model leverages\nvariational inference, extended to an autoencoder framework, with a Gaussian\nmixture model as a prior for the latent space. Specifically designed for audio\napplications, we introduce a convolutional-recurrent variational autoencoder\noptimized for efficient time-frequency processing. Our experimental results\nconsidering a spoken digits dataset demonstrate a significant improvement in\naccuracy and clustering performance compared to traditional methods, showcasing\nthe model's enhanced ability to capture complex audio patterns.", "published": "2025-03-24 11:36:13", "link": "http://arxiv.org/abs/2503.18579v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Music Similarity Representation Learning Focusing on Individual Instruments with Source Separation and Human Preference", "abstract": "This paper proposes music similarity representation learning (MSRL) based on\nindividual instrument sounds (InMSRL) utilizing music source separation (MSS)\nand human preference without requiring clean instrument sounds during\ninference. We propose three methods that effectively improve performance.\nFirst, we introduce end-to-end fine-tuning (E2E-FT) for the Cascade approach\nthat sequentially performs MSS and music similarity feature extraction. E2E-FT\nallows the model to minimize the adverse effects of a separation error on the\nfeature extraction. Second, we propose multi-task learning for the Direct\napproach that directly extracts disentangled music similarity features using a\nsingle music similarity feature extractor. Multi-task learning, which is based\non the disentangled music similarity feature extraction and MSS based on\nreconstruction with disentangled music similarity features, further enhances\ninstrument feature disentanglement. Third, we employ perception-aware\nfine-tuning (PAFT). PAFT utilizes human preference, allowing the model to\nperform InMSRL aligned with human perceptual similarity. We conduct\nexperimental evaluations and demonstrate that 1) E2E-FT for Cascade\nsignificantly improves InMSRL performance, 2) the multi-task learning for\nDirect is also helpful to improve disentanglement performance in the feature\nextraction, 3) PAFT significantly enhances the perceptual InMSRL performance,\nand 4) Cascade with E2E-FT and PAFT outperforms Direct with the multi-task\nlearning and PAFT.", "published": "2025-03-24 09:39:50", "link": "http://arxiv.org/abs/2503.18486v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Rough Heston model as the scaling limit of bivariate cumulative heavy-tailed INAR($\\infty$) processes and applications", "abstract": "This paper establishes a novel link between nearly unstable cumulative\nheavy-tailed integer-valued autoregressive (INAR($\\infty$)) processes and the\nrough Heston model via discrete scaling limits. We prove that a sequence of\nbivariate cumulative INAR($\\infty$) processes converge in law to the rough\nHeston model under appropriate scaling conditions, providing a rigorous\nmathematical foundation for understanding how microstructural order flow drives\nmacroscopic prices following rough volatility dynamics. Our theoretical\nframework extends the scaling limit techniques from Hawkes processes to the\nINAR($\\infty$) setting. Hence we can carry out efficient Monte Carlo simulation\nof the rough Heston model through simulating the corresponding approximating\nINAR($\\infty$) processes, which provides an alternative discrete-time\nsimulation method to the Euler-Maruyama method. Extensive numerical experiments\nillustrate the improved accuracy and efficiency of the proposed simulation\nscheme as compared to the literature, in the valuation of European options, and\nalso path-dependent options such as arithmetic Asian options, lookback options\nand barrier options.", "published": "2025-03-24 00:58:26", "link": "http://arxiv.org/abs/2503.18259v3", "categories": ["math.PR", "q-fin.MF", "60G22, 60H35, 91G20, 62M10, 60F17"], "primary_category": "math.PR"}
{"title": "QubitSwap: The Informational Edge in Decentralised Exchanges", "abstract": "Decentralised exchanges (DEXs) have transformed trading by enabling\ntrustless, permissionless transactions, yet they face significant challenges\nsuch as impermanent loss and slippage, which undermine profitability for\nliquidity providers and traders. In this paper, we introduce QubitSwap, an\ninnovative DEX model designed to tackle these issues through a hybrid approach\nthat integrates an external oracle price with internal pool dynamics. This is\nachieved via a parameter $z$, which governs the balance between these price\nsources, creating a flexible and adaptive pricing mechanism. Through rigorous\nmathematical analysis, we derive a novel reserve function and pricing model\nthat substantially reduces impermanent loss and slippage compared to\ntraditional DEX frameworks. Notably, our results show that as $z$ approaches 1,\nslippage approaches zero, enhancing trading stability. QubitSwap marks a novel\napproach in DEX design, delivering a more efficient and resilient platform.\nThis work not only advances the theoretical foundations of decentralised\nfinance but also provides actionable solutions for the broader DeFi ecosystem.", "published": "2025-03-24 06:13:40", "link": "http://arxiv.org/abs/2504.06281v1", "categories": ["q-fin.TR", "q-fin.MF"], "primary_category": "q-fin.TR"}
