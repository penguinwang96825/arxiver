{"title": "Reprint: a randomized extrapolation based on principal components for\n  data augmentation", "abstract": "Data scarcity and data imbalance have attracted a lot of attention in many\nfields. Data augmentation, explored as an effective approach to tackle them,\ncan improve the robustness and efficiency of classification models by\ngenerating new samples. This paper presents REPRINT, a simple and effective\nhidden-space data augmentation method for imbalanced data classification. Given\nhidden-space representations of samples in each class, REPRINT extrapolates, in\na randomized fashion, augmented examples for target class by using subspaces\nspanned by principal components to summarize distribution structure of both\nsource and target class. Consequently, the examples generated would diversify\nthe target while maintaining the original geometry of target distribution.\nBesides, this method involves a label refinement component which allows to\nsynthesize new soft labels for augmented examples. Compared with different NLP\ndata augmentation approaches under a range of data imbalanced scenarios on four\ntext classification benchmark, REPRINT shows prominent improvements. Moreover,\nthrough comprehensive ablation studies, we show that label refinement is better\nthan label-preserving for augmented examples, and that our method suggests\nstable and consistent improvements in terms of suitable choices of principal\ncomponents. Moreover, REPRINT is appealing for its easy-to-use since it\ncontains only one hyperparameter determining the dimension of subspace and\nrequires low computational resource.", "published": "2022-04-26 01:38:47", "link": "http://arxiv.org/abs/2204.12024v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pretraining Chinese BERT for Detecting Word Insertion and Deletion\n  Errors", "abstract": "Chinese BERT models achieve remarkable progress in dealing with grammatical\nerrors of word substitution. However, they fail to handle word insertion and\ndeletion because BERT assumes the existence of a word at each position. To\naddress this, we present a simple and effective Chinese pretrained model. The\nbasic idea is to enable the model to determine whether a word exists at a\nparticular position. We achieve this by introducing a special token\n\\texttt{[null]}, the prediction of which stands for the non-existence of a\nword. In the training stage, we design pretraining tasks such that the model\nlearns to predict \\texttt{[null]} and real words jointly given the surrounding\ncontext. In the inference stage, the model readily detects whether a word\nshould be inserted or deleted with the standard masked language modeling\nfunction. We further create an evaluation dataset to foster research on word\ninsertion and deletion. It includes human-annotated corrections for 7,726\nerroneous sentences. Results show that existing Chinese BERT performs poorly on\ndetecting insertion and deletion errors. Our approach significantly improves\nthe F1 scores from 24.1\\% to 78.1\\% for word insertion and from 26.5\\% to\n68.5\\% for word deletion, respectively.", "published": "2022-04-26 03:19:36", "link": "http://arxiv.org/abs/2204.12052v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PLOD: An Abbreviation Detection Dataset for Scientific Documents", "abstract": "The detection and extraction of abbreviations from unstructured texts can\nhelp to improve the performance of Natural Language Processing tasks, such as\nmachine translation and information retrieval. However, in terms of publicly\navailable datasets, there is not enough data for training\ndeep-neural-networks-based models to the point of generalising well over data.\nThis paper presents PLOD, a large-scale dataset for abbreviation detection and\nextraction that contains 160k+ segments automatically annotated with\nabbreviations and their long forms. We performed manual validation over a set\nof instances and a complete automatic validation for this dataset. We then used\nit to generate several baseline models for detecting abbreviations and long\nforms. The best models achieved an F1-score of 0.92 for abbreviations and 0.89\nfor detecting their corresponding long forms. We release this dataset along\nwith our code and all the models publicly in\nhttps://github.com/surrey-nlp/PLOD-AbbreviationDetection", "published": "2022-04-26 03:52:21", "link": "http://arxiv.org/abs/2204.12061v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Suggesting Relevant Questions for a Query Using Statistical Natural\n  Language Processing Technique", "abstract": "Suggesting similar questions for a user query has many applications ranging\nfrom reducing search time of users on e-commerce websites, training of\nemployees in companies to holistic learning for students. The use of Natural\nLanguage Processing techniques for suggesting similar questions is prevalent\nover the existing architecture. Mainly two approaches are studied for finding\ntext similarity namely syntactic and semantic, however each has its draw-backs\nand fail to provide the desired outcome. In this article, a self-learning\ncombined approach is proposed for determining textual similarity that\nintroduces a robust weighted syntactic and semantic similarity index for\ndetermining similar questions from a predetermined database, this approach\nlearns the optimal combination of the mentioned approaches for a database under\nconsideration. Comprehensive analysis has been carried out to justify the\nefficiency and efficacy of the proposed approach over the existing literature.", "published": "2022-04-26 04:30:16", "link": "http://arxiv.org/abs/2204.12069v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Symlink: A New Dataset for Scientific Symbol-Description Linking", "abstract": "Mathematical symbols and descriptions appear in various forms across document\nsection boundaries without explicit markup. In this paper, we present a new\nlarge-scale dataset that emphasizes extracting symbols and descriptions in\nscientific documents. Symlink annotates scientific papers of 5 different\ndomains (i.e., computer science, biology, physics, mathematics, and economics).\nOur experiments on Symlink demonstrate the challenges of the symbol-description\nlinking task for existing models and call for further research effort in this\narea. We will publicly release Symlink to facilitate future research.", "published": "2022-04-26 04:36:14", "link": "http://arxiv.org/abs/2204.12070v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Approach to Predicting News -- A Precise Multi-LSTM Network With BERT", "abstract": "Varieties of Democracy (V-Dem) is a new approach to conceptualizing and\nmeasuring democracy and politics. It has information for 200 countries and is\none of the biggest databases for political science. According to the V-Dem\nannual democracy report 2019, Taiwan is one of the two countries that got\ndisseminated false information from foreign governments the most. It also shows\nthat the \"made-up news\" has caused a great deal of confusion in Taiwanese\nsociety and has serious impacts on global stability. Although there are several\napplications helping distinguish the false information, we found out that the\npre-processing of categorizing the news is still done by human labor. However,\nhuman labor may cause mistakes and cannot work for a long time. The growing\ndemands for automatic machines in the near decades show that while the machine\ncan do as good as humans or even better, using machines can reduce humans'\nburden and cut down costs. Therefore, in this work, we build a predictive model\nto classify the category of news. The corpora we used contains 28358 news and\n200 news scraped from the online newspaper Liberty Times Net (LTN) website and\nincludes 8 categories: Technology, Entertainment, Fashion, Politics, Sports,\nInternational, Finance, and Health. At first, we use Bidirectional Encoder\nRepresentations from Transformers (BERT) for word embeddings which transform\neach Chinese character into a (1,768) vector. Then, we use a Long Short-Term\nMemory (LSTM) layer to transform word embeddings into sentence embeddings and\nadd another LSTM layer to transform them into document embeddings. Each\ndocument embedding is an input for the final predicting model, which contains\ntwo Dense layers and one Activation layer. And each document embedding is\ntransformed into 1 vector with 8 real numbers, then the highest one will\ncorrespond to the 8 news categories with up to 99% accuracy.", "published": "2022-04-26 06:14:01", "link": "http://arxiv.org/abs/2204.12093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Function-words Enhanced Attention Networks for Few-Shot Inverse Relation\n  Classification", "abstract": "The relation classification is to identify semantic relations between two\nentities in a given text. While existing models perform well for classifying\ninverse relations with large datasets, their performance is significantly\nreduced for few-shot learning. In this paper, we propose a function words\nadaptively enhanced attention framework (FAEA) for few-shot inverse relation\nclassification, in which a hybrid attention model is designed to attend\nclass-related function words based on meta-learning. As the involvement of\nfunction words brings in significant intra-class redundancy, an adaptive\nmessage passing mechanism is introduced to capture and transfer inter-class\ndifferences.We mathematically analyze the negative impact of function words\nfrom dot-product measurement, which explains why message passing mechanism\neffectively reduces the impact. Our experimental results show that FAEA\noutperforms strong baselines, especially the inverse relation accuracy is\nimproved by 14.33% under 1-shot setting in FewRel1.0.", "published": "2022-04-26 07:17:28", "link": "http://arxiv.org/abs/2204.12111v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Robust Contrastive Alignment Method For Multi-Domain Text\n  Classification", "abstract": "Multi-domain text classification can automatically classify texts in various\nscenarios. Due to the diversity of human languages, texts with the same label\nin different domains may differ greatly, which brings challenges to the\nmulti-domain text classification. Current advanced methods use the\nprivate-shared paradigm, capturing domain-shared features by a shared encoder,\nand training a private encoder for each domain to extract domain-specific\nfeatures. However, in realistic scenarios, these methods suffer from\ninefficiency as new domains are constantly emerging. In this paper, we propose\na robust contrastive alignment method to align text classification features of\nvarious domains in the same feature space by supervised contrastive learning.\nBy this means, we only need two universal feature extractors to achieve\nmulti-domain text classification. Extensive experimental results show that our\nmethod performs on par with or sometimes better than the state-of-the-art\nmethod, which uses the complex multi-classifier in a private-shared framework.", "published": "2022-04-26 07:34:24", "link": "http://arxiv.org/abs/2204.12125v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LM-Debugger: An Interactive Tool for Inspection and Intervention in\n  Transformer-Based Language Models", "abstract": "The opaque nature and unexplained behavior of transformer-based language\nmodels (LMs) have spurred a wide interest in interpreting their predictions.\nHowever, current interpretation methods mostly focus on probing models from\noutside, executing behavioral tests, and analyzing salience input features,\nwhile the internal prediction construction process is largely not understood.\nIn this work, we introduce LM-Debugger, an interactive debugger tool for\ntransformer-based LMs, which provides a fine-grained interpretation of the\nmodel's internal prediction process, as well as a powerful framework for\nintervening in LM behavior. For its backbone, LM-Debugger relies on a recent\nmethod that interprets the inner token representations and their updates by the\nfeed-forward layers in the vocabulary space. We demonstrate the utility of\nLM-Debugger for single-prediction debugging, by inspecting the internal\ndisambiguation process done by GPT2. Moreover, we show how easily LM-Debugger\nallows to shift model behavior in a direction of the user's choice, by\nidentifying a few vectors in the network and inducing effective interventions\nto the prediction process. We release LM-Debugger as an open-source tool and a\ndemo over GPT2 models.", "published": "2022-04-26 07:51:25", "link": "http://arxiv.org/abs/2204.12130v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When do Contrastive Word Alignments Improve Many-to-many Neural Machine\n  Translation?", "abstract": "Word alignment has proven to benefit many-to-many neural machine translation\n(NMT). However, high-quality ground-truth bilingual dictionaries were used for\npre-editing in previous methods, which are unavailable for most language pairs.\nMeanwhile, the contrastive objective can implicitly utilize automatically\nlearned word alignment, which has not been explored in many-to-many NMT. This\nwork proposes a word-level contrastive objective to leverage word alignments\nfor many-to-many NMT. Empirical results show that this leads to 0.8 BLEU gains\nfor several language pairs. Analyses reveal that in many-to-many NMT, the\nencoder's sentence retrieval performance highly correlates with the translation\nquality, which explains when the proposed method impacts translation. This\nmotivates future exploration for many-to-many NMT to improve the encoder's\nsentence retrieval performance.", "published": "2022-04-26 09:07:51", "link": "http://arxiv.org/abs/2204.12165v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Faster and Better Grammar-based Text-to-SQL Parsing via Clause-level\n  Parallel Decoding and Alignment Loss", "abstract": "Grammar-based parsers have achieved high performance in the cross-domain\ntext-to-SQL parsing task, but suffer from low decoding efficiency due to the\nmuch larger number of actions for grammar selection than that of tokens in SQL\nqueries. Meanwhile, how to better align SQL clauses and question segments has\nbeen a key challenge for parsing performance. Therefore, this paper proposes\nclause-level parallel decoding and alignment loss to enhance two\nhigh-performance grammar-based parsers, i.e., RATSQL and LGESQL. Experimental\nresults of two parsers show that our method obtains consistent improvements\nboth in accuracy and decoding speed.", "published": "2022-04-26 09:40:04", "link": "http://arxiv.org/abs/2204.12186v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Flow-Adapter Architecture for Unsupervised Machine Translation", "abstract": "In this work, we propose a flow-adapter architecture for unsupervised NMT. It\nleverages normalizing flows to explicitly model the distributions of\nsentence-level latent representations, which are subsequently used in\nconjunction with the attention mechanism for the translation task. The primary\nnovelties of our model are: (a) capturing language-specific sentence\nrepresentations separately for each language using normalizing flows and (b)\nusing a simple transformation of these latent representations for translating\nfrom one language to another. This architecture allows for unsupervised\ntraining of each language independently. While there is prior work on latent\nvariables for supervised MT, to the best of our knowledge, this is the first\nwork that uses latent variables and normalizing flows for unsupervised MT. We\nobtain competitive results on several unsupervised MT benchmarks.", "published": "2022-04-26 11:00:32", "link": "http://arxiv.org/abs/2204.12225v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a\n  Metamorphic Testing Perspective", "abstract": "Metamorphic testing has recently been used to check the safety of neural NLP\nmodels. Its main advantage is that it does not rely on a ground truth to\ngenerate test cases. However, existing studies are mostly concerned with\nrobustness-like metamorphic relations, limiting the scope of linguistic\nproperties they can test. We propose three new classes of metamorphic\nrelations, which address the properties of systematicity, compositionality and\ntransitivity. Unlike robustness, our relations are defined over multiple source\ninputs, thus increasing the number of test cases that we can produce by a\npolynomial factor. With them, we test the internal consistency of\nstate-of-the-art NLP models, and show that they do not always behave according\nto their expected linguistic properties. Lastly, we introduce a novel graphical\nnotation that efficiently summarises the inner structure of metamorphic\nrelations.", "published": "2022-04-26 13:50:07", "link": "http://arxiv.org/abs/2204.12316v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Disambiguation of morpho-syntactic features of African American English\n  -- the case of habitual be", "abstract": "Recent research has highlighted that natural language processing (NLP)\nsystems exhibit a bias against African American speakers. The bias errors are\noften caused by poor representation of linguistic features unique to African\nAmerican English (AAE), due to the relatively low probability of occurrence of\nmany such features in training data. We present a workflow to overcome such\nbias in the case of habitual \"be\". Habitual \"be\" is isomorphic, and therefore\nambiguous, with other forms of \"be\" found in both AAE and other varieties of\nEnglish. This creates a clear challenge for bias in NLP technologies. To\novercome the scarcity, we employ a combination of rule-based filters and data\naugmentation that generate a corpus balanced between habitual and non-habitual\ninstances. With this balanced corpus, we train unbiased machine learning\nclassifiers, as demonstrated on a corpus of AAE transcribed texts, achieving\n.65 F$_1$ score disambiguating habitual \"be\".", "published": "2022-04-26 16:30:22", "link": "http://arxiv.org/abs/2204.12421v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Hyperbolic Geometry Back to Word Embeddings", "abstract": "We choose random points in the hyperbolic disc and claim that these points\nare already word representations. However, it is yet to be uncovered which\npoint corresponds to which word of the human language of interest. This\ncorrespondence can be approximately established using a pointwise mutual\ninformation between words and recent alignment techniques.", "published": "2022-04-26 17:52:59", "link": "http://arxiv.org/abs/2204.12481v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Machine Translation Domain Adaptation", "abstract": "Machine translation models struggle when translating out-of-domain text,\nwhich makes domain adaptation a topic of critical importance. However, most\ndomain adaptation methods focus on fine-tuning or training the entire or part\nof the model on every new domain, which can be costly. On the other hand,\nsemi-parametric models have been shown to successfully perform domain\nadaptation by retrieving examples from an in-domain datastore (Khandelwal et\nal., 2021). A drawback of these retrieval-augmented models, however, is that\nthey tend to be substantially slower. In this paper, we explore several\napproaches to speed up nearest neighbor machine translation. We adapt the\nmethods recently proposed by He et al. (2021) for language modeling, and\nintroduce a simple but effective caching strategy that avoids performing\nretrieval when similar contexts have been seen before. Translation quality and\nruntimes for several domains show the effectiveness of the proposed solutions.", "published": "2022-04-26 21:47:54", "link": "http://arxiv.org/abs/2204.12608v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Developing Universal Dependency Treebanks for Magahi and Braj", "abstract": "In this paper, we discuss the development of treebanks for two low-resourced\nIndian languages - Magahi and Braj based on the Universal Dependencies\nframework. The Magahi treebank contains 945 sentences and Braj treebank around\n500 sentences marked with their lemmas, part-of-speech, morphological features\nand universal dependencies. This paper gives a description of the different\ndependency relationship found in the two languages and give some statistics of\nthe two treebanks. The dataset will be made publicly available on Universal\nDependency (UD) repository\n(https://github.com/UniversalDependencies/UD_Magahi-MGTB/tree/master) in the\nnext(v2.10) release.", "published": "2022-04-26 23:43:41", "link": "http://arxiv.org/abs/2204.12633v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Review on Text-Based Emotion Detection -- Techniques, Applications,\n  Datasets, and Future Directions", "abstract": "Artificial Intelligence (AI) has been used for processing data to make\ndecisions, interact with humans, and understand their feelings and emotions.\nWith the advent of the internet, people share and express their thoughts on\nday-to-day activities and global and local events through text messaging\napplications. Hence, it is essential for machines to understand emotions in\nopinions, feedback, and textual dialogues to provide emotionally aware\nresponses to users in today's online world. The field of text-based emotion\ndetection (TBED) is advancing to provide automated solutions to various\napplications, such as businesses, and finances, to name a few. TBED has gained\na lot of attention in recent times. The paper presents a systematic literature\nreview of the existing literature published between 2005 to 2021 in TBED. This\nreview has meticulously examined 63 research papers from IEEE, Science Direct,\nScopus, and Web of Science databases to address four primary research\nquestions. It also reviews the different applications of TBED across various\nresearch domains and highlights its use. An overview of various emotion models,\ntechniques, feature extraction methods, datasets, and research challenges with\nfuture directions has also been represented.", "published": "2022-04-26 15:20:00", "link": "http://arxiv.org/abs/2205.03235v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Label Anchored Contrastive Learning for Language Understanding", "abstract": "Contrastive learning (CL) has achieved astonishing progress in computer\nvision, speech, and natural language processing fields recently with\nself-supervised learning. However, CL approach to the supervised setting is not\nfully explored, especially for the natural language understanding\nclassification task. Intuitively, the class label itself has the intrinsic\nability to perform hard positive/negative mining, which is crucial for CL.\nMotivated by this, we propose a novel label anchored contrastive learning\napproach (denoted as LaCon) for language understanding. Specifically, three\ncontrastive objectives are devised, including a multi-head instance-centered\ncontrastive loss (ICL), a label-centered contrastive loss (LCL), and a label\nembedding regularizer (LER). Our approach does not require any specialized\nnetwork architecture or any extra data augmentation, thus it can be easily\nplugged into existing powerful pre-trained language models. Compared to the\nstate-of-the-art baselines, LaCon obtains up to 4.1% improvement on the popular\ndatasets of GLUE and CLUE benchmarks. Besides, LaCon also demonstrates\nsignificant advantages under the few-shot and data imbalance settings, which\nobtains up to 9.4% improvement on the FewGLUE and FewCLUE benchmarking tasks.", "published": "2022-04-26 15:33:01", "link": "http://arxiv.org/abs/2205.10227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Boundary Smoothing for Named Entity Recognition", "abstract": "Neural named entity recognition (NER) models may easily encounter the\nover-confidence issue, which degrades the performance and calibration. Inspired\nby label smoothing and driven by the ambiguity of boundary annotation in NER\nengineering, we propose boundary smoothing as a regularization technique for\nspan-based neural NER models. It re-assigns entity probabilities from annotated\nspans to the surrounding ones. Built on a simple but strong baseline, our model\nachieves results better than or competitive with previous state-of-the-art\nsystems on eight well-known NER benchmarks. Further empirical analysis suggests\nthat boundary smoothing effectively mitigates over-confidence, improves model\ncalibration, and brings flatter neural minima and more smoothed loss\nlandscapes.", "published": "2022-04-26 02:04:09", "link": "http://arxiv.org/abs/2204.12031v1", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "CoVERT: A Corpus of Fact-checked Biomedical COVID-19 Tweets", "abstract": "Over the course of the COVID-19 pandemic, large volumes of biomedical\ninformation concerning this new disease have been published on social media.\nSome of this information can pose a real danger to people's health,\nparticularly when false information is shared, for instance recommendations on\nhow to treat diseases without professional medical advice. Therefore, automatic\nfact-checking resources and systems developed specifically for the medical\ndomain are crucial. While existing fact-checking resources cover\nCOVID-19-related information in news or quantify the amount of misinformation\nin tweets, there is no dataset providing fact-checked COVID-19-related Twitter\nposts with detailed annotations for biomedical entities, relations and relevant\nevidence. We contribute CoVERT, a fact-checked corpus of tweets with a focus on\nthe domain of biomedicine and COVID-19-related (mis)information. The corpus\nconsists of 300 tweets, each annotated with medical named entities and\nrelations. We employ a novel crowdsourcing methodology to annotate all tweets\nwith fact-checking labels and supporting evidence, which crowdworkers search\nfor online. This methodology results in moderate inter-annotator agreement.\nFurthermore, we use the retrieved evidence extracts as part of a fact-checking\npipeline, finding that the real-world evidence is more useful than the\nknowledge indirectly available in pretrained language models.", "published": "2022-04-26 09:05:03", "link": "http://arxiv.org/abs/2204.12164v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Using Machine Learning to Fuse Verbal Autopsy Narratives and Binary\n  Features in the Analysis of Deaths from Hyperglycaemia", "abstract": "Lower-and-middle income countries are faced with challenges arising from a\nlack of data on cause of death (COD), which can limit decisions on population\nhealth and disease management. A verbal autopsy(VA) can provide information\nabout a COD in areas without robust death registration systems. A VA consists\nof structured data, combining numeric and binary features, and unstructured\ndata as part of an open-ended narrative text. This study assesses the\nperformance of various machine learning approaches when analyzing both the\nstructured and unstructured components of the VA report. The algorithms were\ntrained and tested via cross-validation in the three settings of binary\nfeatures, text features and a combination of binary and text features derived\nfrom VA reports from rural South Africa. The results obtained indicate\nnarrative text features contain valuable information for determining COD and\nthat a combination of binary and text features improves the automated COD\nclassification task.\n  Keywords: Diabetes Mellitus, Verbal Autopsy, Cause of Death, Machine\nLearning, Natural Language Processing", "published": "2022-04-26 09:14:11", "link": "http://arxiv.org/abs/2204.12169v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SkillNet-NLG: General-Purpose Natural Language Generation with a\n  Sparsely Activated Approach", "abstract": "We present SkillNet-NLG, a sparsely activated approach that handles many\nnatural language generation tasks with one model. Different from traditional\ndense models that always activate all the parameters, SkillNet-NLG selectively\nactivates relevant parts of the parameters to accomplish a task, where the\nrelevance is controlled by a set of predefined skills. The strength of such\nmodel design is that it provides an opportunity to precisely adapt relevant\nskills to learn new tasks effectively. We evaluate on Chinese natural language\ngeneration tasks. Results show that, with only one model file, SkillNet-NLG\noutperforms previous best performance methods on four of five tasks.\nSkillNet-NLG performs better than two multi-task learning baselines (a dense\nmodel and a Mixture-of-Expert model) and achieves comparable performance to\ntask-specific models. Lastly, SkillNet-NLG surpasses baseline systems when\nbeing adapted to new tasks.", "published": "2022-04-26 09:37:01", "link": "http://arxiv.org/abs/2204.12184v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EmpHi: Generating Empathetic Responses with Human-like Intents", "abstract": "In empathetic conversations, humans express their empathy to others with\nempathetic intents. However, most existing empathetic conversational methods\nsuffer from a lack of empathetic intents, which leads to monotonous empathy. To\naddress the bias of the empathetic intents distribution between empathetic\ndialogue models and humans, we propose a novel model to generate empathetic\nresponses with human-consistent empathetic intents, EmpHi for short. Precisely,\nEmpHi learns the distribution of potential empathetic intents with a discrete\nlatent variable, then combines both implicit and explicit intent representation\nto generate responses with various empathetic intents. Experiments show that\nEmpHi outperforms state-of-the-art models in terms of empathy, relevance, and\ndiversity on both automatic and human evaluation. Moreover, the case studies\ndemonstrate the high interpretability and outstanding performance of our model.", "published": "2022-04-26 09:49:49", "link": "http://arxiv.org/abs/2204.12191v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Event Detection Explorer: An Interactive Tool for Event Detection\n  Exploration", "abstract": "Event Detection (ED) is an important task in natural language processing. In\nthe past few years, many datasets have been introduced for advancing ED machine\nlearning models. However, most of these datasets are under-explored because not\nmany tools are available for people to study events, trigger words, and event\nmention instances systematically and efficiently. In this paper, we present an\ninteractive and easy-to-use tool, namely ED Explorer, for ED dataset and model\nexploration. ED Explorer consists of an interactive web application, an API,\nand an NLP toolkit, which can help both domain experts and non-experts to\nbetter understand the ED task. We use ED Explorer to analyze a recent proposed\nlarge-scale ED datasets (referred to as MAVEN), and discover several underlying\nproblems, including sparsity, label bias, label imbalance, and debatable\nannotations, which provide us with directions to improve the MAVEN dataset. The\nED Explorer can be publicly accessed through http://edx.leafnlp.org/. The\ndemonstration video is available here\nhttps://www.youtube.com/watch?v=6QPnxPwxg50.", "published": "2022-04-26 17:22:37", "link": "http://arxiv.org/abs/2204.12456v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data Bootstrapping Approaches to Improve Low Resource Abusive Language\n  Detection for Indic Languages", "abstract": "Abusive language is a growing concern in many social media platforms.\nRepeated exposure to abusive speech has created physiological effects on the\ntarget users. Thus, the problem of abusive language should be addressed in all\nforms for online peace and safety. While extensive research exists in abusive\nspeech detection, most studies focus on English. Recently, many smearing\nincidents have occurred in India, which provoked diverse forms of abusive\nspeech in online space in various languages based on the geographic location.\nTherefore it is essential to deal with such malicious content. In this paper,\nto bridge the gap, we demonstrate a large-scale analysis of multilingual\nabusive speech in Indic languages. We examine different interlingual transfer\nmechanisms and observe the performance of various multilingual models for\nabusive speech detection for eight different Indic languages. We also\nexperiment to show how robust these models are on adversarial attacks. Finally,\nwe conduct an in-depth error analysis by looking into the models' misclassified\nposts across various settings. We have made our code and models public for\nother researchers.", "published": "2022-04-26 18:56:01", "link": "http://arxiv.org/abs/2204.12543v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Parkinson's disease diagnostics using AI and natural language knowledge\n  transfer", "abstract": "In this work, the issue of Parkinson's disease (PD) diagnostics using\nnon-invasive antemortem techniques was tackled. A deep learning approach for\nclassification of raw speech recordings in patients with diagnosed PD was\nproposed. The core of proposed method is an audio classifier using knowledge\ntransfer from a pretrained natural language model, namely \\textit{wav2vec 2.0}.\nMethod was tested on a group of 38 PD patients and 10 healthy persons above the\nage of 50. A dataset of speech recordings acquired using a smartphone recorder\nwas constructed and the recordings were label as PD/non-PD with severity of the\ndisease additionally rated using Hoehn-Yahr scale. The audio recordings were\ncut into 2141 samples that include sentences, syllables, vowels and sustained\nphonation. The classifier scores up to 97.92\\% of cross-validated accuracy.\nAdditionally, paper presents results of a human-level performance assessment\nquestionnaire, which was consulted with the neurology professionals", "published": "2022-04-26 19:39:29", "link": "http://arxiv.org/abs/2204.12559v1", "categories": ["cs.CL", "cs.AI", "I.2 I.5"], "primary_category": "cs.CL"}
{"title": "Testing the Ability of Language Models to Interpret Figurative Language", "abstract": "Figurative and metaphorical language are commonplace in discourse, and\nfigurative expressions play an important role in communication and cognition.\nHowever, figurative language has been a relatively under-studied area in NLP,\nand it remains an open question to what extent modern language models can\ninterpret nonliteral phrases. To address this question, we introduce Fig-QA, a\nWinograd-style nonliteral language understanding task consisting of correctly\ninterpreting paired figurative phrases with divergent meanings. We evaluate the\nperformance of several state-of-the-art language models on this task, and find\nthat although language models achieve performance significantly over chance,\nthey still fall short of human performance, particularly in zero- or few-shot\nsettings. This suggests that further work is needed to improve the nonliteral\nreasoning capabilities of language models.", "published": "2022-04-26 23:42:22", "link": "http://arxiv.org/abs/2204.12632v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modular Domain Adaptation", "abstract": "Off-the-shelf models are widely used by computational social science\nresearchers to measure properties of text, such as sentiment. However, without\naccess to source data it is difficult to account for domain shift, which\nrepresents a threat to validity. Here, we treat domain adaptation as a modular\nprocess that involves separate model producers and model consumers, and show\nhow they can independently cooperate to facilitate more accurate measurements\nof text. We introduce two lightweight techniques for this scenario, and\ndemonstrate that they reliably increase out-of-domain accuracy on four\nmulti-domain text classification datasets when used with linear and contextual\nembedding models. We conclude with recommendations for model producers and\nconsumers, and release models and replication code to accompany this paper.", "published": "2022-04-26 22:08:58", "link": "http://arxiv.org/abs/2204.14213v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Word Embeddings and Validity Indexes in Fuzzy Clustering", "abstract": "In the new era of internet systems and applications, a concept of detecting\ndistinguished topics from huge amounts of text has gained a lot of attention.\nThese methods use representation of text in a numerical format -- called\nembeddings -- to imitate human-based semantic similarity between words. In this\nstudy, we perform a fuzzy-based analysis of various vector representations of\nwords, i.e., word embeddings. Also we introduce new methods of fuzzy clustering\nbased on hybrid implementation of fuzzy clustering methods with an evolutionary\nalgorithm named Forest Optimization. We use two popular fuzzy clustering\nalgorithms on count-based word embeddings, with different methods and\ndimensionality. Words about covid from Kaggle dataset gathered and calculated\ninto vectors and clustered. The results indicate that fuzzy clustering\nalgorithms are very sensitive to high-dimensional data, and parameter tuning\ncan dramatically change their performance. We evaluate results of experiments\nwith various clustering validity indexes to compare different algorithm\nvariation with different embeddings accuracy.", "published": "2022-04-26 18:08:19", "link": "http://arxiv.org/abs/2205.06802v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Non-determinsitic algebraic rewriting as adjunction", "abstract": "We develop a general model theoretic semantics to rewriting beyond the usual\nconfluence and termination assumptions. This is based on preordered algebra\nwhich is a model theory that extends many sorted algebra. In this framework we\ncharacterise rewriting in arbitrary algebras rather than term algebras (called\nalgebraic rewriting) as a persistent adjunction and use this result, on the one\nhand for proving the soundness and the completeness of an abstract\ncomputational model of rewriting that underlies the non-deterministic\nprogramming with Maude and CafeOBJ, and on the other hand for developing a\ncompositionality result for algebraic rewriting in the context of the\npushout-based modularisation technique.", "published": "2022-04-26 07:55:09", "link": "http://arxiv.org/abs/2204.12133v1", "categories": ["math.LO", "cs.CL", "cs.LO", "68Q42, 68Q65", "F.4.1; F.4.2"], "primary_category": "math.LO"}
{"title": "Science Checker: Extractive-Boolean Question Answering For Scientific\n  Fact Checking", "abstract": "With the explosive growth of scientific publications, making the synthesis of\nscientific knowledge and fact checking becomes an increasingly complex task. In\nthis paper, we propose a multi-task approach for verifying the scientific\nquestions based on a joint reasoning from facts and evidence in research\narticles. We propose an intelligent combination of (1) an automatic information\nsummarization and (2) a Boolean Question Answering which allows to generate an\nanswer to a scientific question from only extracts obtained after\nsummarization. Thus on a given topic, our proposed approach conducts structured\ncontent modeling based on paper abstracts to answer a scientific question while\nhighlighting texts from paper that discuss the topic. We based our final system\non an end-to-end Extractive Question Answering (EQA) combined with a three\noutputs classification model to perform in-depth semantic understanding of a\nquestion to illustrate the aggregation of multiple responses. With our light\nand fast proposed architecture, we achieved an average error rate of 4% and a\nF1-score of 95.6%. Our results are supported via experiments with two QA models\n(BERT, RoBERTa) over 3 Million Open Access (OA) articles in the medical and\nhealth domains on Europe PMC.", "published": "2022-04-26 12:35:23", "link": "http://arxiv.org/abs/2204.12263v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "I.2.7; H.3.3"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis of Cybersecurity Content on Twitter and Reddit", "abstract": "Sentiment Analysis provides an opportunity to understand the subject(s),\nespecially in the digital age, due to an abundance of public data and effective\nalgorithms. Cybersecurity is a subject where opinions are plentiful and\ndiffering in the public domain. This descriptive research analyzed\ncybersecurity content on Twitter and Reddit to measure its sentiment, positive\nor negative, or neutral. The data from Twitter and Reddit was amassed via\ntechnology-specific APIs during a selected timeframe to create datasets, which\nwere then analyzed individually for their sentiment by VADER, an NLP (Natural\nLanguage Processing) algorithm. A random sample of cybersecurity content (ten\ntweets and posts) was also classified for sentiments by twenty human annotators\nto evaluate the performance of VADER. Cybersecurity content on Twitter was at\nleast 48% positive, and Reddit was at least 26.5% positive. The positive or\nneutral content far outweighed negative sentiments across both platforms. When\ncompared to human classification, which was considered the standard or source\nof truth, VADER produced 60% accuracy for Twitter and 70% for Reddit in\nassessing the sentiment; in other words, some agreement between algorithm and\nhuman classifiers. Overall, the goal was to explore an uninhibited research\ntopic about cybersecurity sentiment", "published": "2022-04-26 12:46:55", "link": "http://arxiv.org/abs/2204.12267v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Monant Medical Misinformation Dataset: Mapping Articles to Fact-Checked\n  Claims", "abstract": "False information has a significant negative influence on individuals as well\nas on the whole society. Especially in the current COVID-19 era, we witness an\nunprecedented growth of medical misinformation. To help tackle this problem\nwith machine learning approaches, we are publishing a feature-rich dataset of\napprox. 317k medical news articles/blogs and 3.5k fact-checked claims. It also\ncontains 573 manually and more than 51k automatically labelled mappings between\nclaims and articles. Mappings consist of claim presence, i.e., whether a claim\nis contained in a given article, and article stance towards the claim. We\nprovide several baselines for these two tasks and evaluate them on the manually\nlabelled part of the dataset. The dataset enables a number of additional tasks\nrelated to medical misinformation, such as misinformation characterisation\nstudies or studies of misinformation diffusion between sources.", "published": "2022-04-26 13:18:27", "link": "http://arxiv.org/abs/2204.12294v1", "categories": ["cs.CL", "cs.CY", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Meta Word Embeddings by Unsupervised Weighted Concatenation of\n  Source Embeddings", "abstract": "Given multiple source word embeddings learnt using diverse algorithms and\nlexical resources, meta word embedding learning methods attempt to learn more\naccurate and wide-coverage word embeddings.\n  Prior work on meta-embedding has repeatedly discovered that simple vector\nconcatenation of the source embeddings to be a competitive baseline.\n  However, it remains unclear as to why and when simple vector concatenation\ncan produce accurate meta-embeddings.\n  We show that weighted concatenation can be seen as a spectrum matching\noperation between each source embedding and the meta-embedding, minimising the\npairwise inner-product loss.\n  Following this theoretical analysis, we propose two \\emph{unsupervised}\nmethods to learn the optimal concatenation weights for creating meta-embeddings\nfrom a given set of source embeddings.\n  Experimental results on multiple benchmark datasets show that the proposed\nweighted concatenated meta-embedding methods outperform previously proposed\nmeta-embedding learning methods.", "published": "2022-04-26 15:41:06", "link": "http://arxiv.org/abs/2204.12386v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "You Don't Know My Favorite Color: Preventing Dialogue Representations\n  from Revealing Speakers' Private Personas", "abstract": "Social chatbots, also known as chit-chat chatbots, evolve rapidly with large\npretrained language models. Despite the huge progress, privacy concerns have\narisen recently: training data of large language models can be extracted via\nmodel inversion attacks. On the other hand, the datasets used for training\nchatbots contain many private conversations between two individuals. In this\nwork, we further investigate the privacy leakage of the hidden states of\nchatbots trained by language modeling which has not been well studied yet. We\nshow that speakers' personas can be inferred through a simple neural network\nwith high accuracy. To this end, we propose effective defense objectives to\nprotect persona leakage from hidden states. We conduct extensive experiments to\ndemonstrate that our proposed defense objectives can greatly reduce the attack\naccuracy from 37.6% to 0.5%. Meanwhile, the proposed objectives preserve\nlanguage models' powerful generation ability.", "published": "2022-04-26 09:36:18", "link": "http://arxiv.org/abs/2205.10228v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mask scalar prediction for improving robust automatic speech recognition", "abstract": "Using neural network based acoustic frontends for improving robustness of\nstreaming automatic speech recognition (ASR) systems is challenging because of\nthe causality constraints and the resulting distortion that the frontend\nprocessing introduces in speech. Time-frequency masking based approaches have\nbeen shown to work well, but they need additional hyper-parameters to scale the\nmask to limit speech distortion. Such mask scalars are typically hand-tuned and\nchosen conservatively. In this work, we present a technique to predict mask\nscalars using an ASR-based loss in an end-to-end fashion, with minimal increase\nin the overall model size and complexity. We evaluate the approach on two\nrobust ASR tasks: multichannel enhancement in the presence of speech and\nnon-speech noise, and acoustic echo cancellation (AEC). Results show that the\npresented algorithm consistently improves word error rate (WER) without the\nneed for any additional tuning over strong baselines that use hand-tuned\nhyper-parameters: up to 16% for multichannel enhancement in noisy conditions,\nand up to 7% for AEC.", "published": "2022-04-26 06:10:48", "link": "http://arxiv.org/abs/2204.12092v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Masked Spectrogram Modeling using Masked Autoencoders for Learning\n  General-purpose Audio Representation", "abstract": "Recent general-purpose audio representations show state-of-the-art\nperformance on various audio tasks. These representations are pre-trained by\nself-supervised learning methods that create training signals from the input.\nFor example, typical audio contrastive learning uses temporal relationships\namong input sounds to create training signals, whereas some methods use a\ndifference among input views created by data augmentations. However, these\ntraining signals do not provide information derived from the intact input\nsound, which we think is suboptimal for learning representation that describes\nthe input as it is.\n  In this paper, we seek to learn audio representations from the input itself\nas supervision using a pretext task of auto-encoding of masked spectrogram\npatches, Masked Spectrogram Modeling (MSM, a variant of Masked Image Modeling\napplied to audio spectrogram). To implement MSM, we use Masked Autoencoders\n(MAE), an image self-supervised learning method. MAE learns to efficiently\nencode the small number of visible patches into latent representations to carry\nessential information for reconstructing a large number of masked patches.\nWhile training, MAE minimizes the reconstruction error, which uses the input as\ntraining signal, consequently achieving our goal.\n  We conducted experiments on our MSM using MAE (MSM-MAE) models under the\nevaluation benchmark of the HEAR 2021 NeurIPS Challenge. Our MSM-MAE models\noutperformed the HEAR 2021 Challenge results on seven out of 15 tasks (e.g.,\naccuracies of 73.4% on CREMA-D and 85.8% on LibriCount), while showing top\nperformance on other tasks where specialized models perform better. We also\ninvestigate how the design choices of MSM-MAE impact the performance and\nconduct qualitative analysis of visualization outcomes to gain an understanding\nof learned representations. We make our code available online.", "published": "2022-04-26 12:32:10", "link": "http://arxiv.org/abs/2204.12260v1", "categories": ["eess.AS", "cs.SD", "68T07"], "primary_category": "eess.AS"}
{"title": "ATST: Audio Representation Learning with Teacher-Student Transformer", "abstract": "Self-supervised learning (SSL) learns knowledge from a large amount of\nunlabeled data, and then transfers the knowledge to a specific problem with a\nlimited number of labeled data. SSL has achieved promising results in various\ndomains. This work addresses the problem of segment-level general audio SSL,\nand proposes a new transformer-based teacher-student SSL model, named ATST. A\ntransformer encoder is developed on a recently emerged teacher-student baseline\nscheme, which largely improves the modeling capability of pre-training. In\naddition, a new strategy for positive pair creation is designed to fully\nleverage the capability of transformer. Extensive experiments have been\nconducted, and the proposed model achieves the new state-of-the-art results on\nalmost all of the downstream tasks.", "published": "2022-04-26 05:10:25", "link": "http://arxiv.org/abs/2204.12076v3", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Reformulating Speaker Diarization as Community Detection With Emphasis\n  On Topological Structure", "abstract": "Clustering-based speaker diarization has stood firm as one of the major\napproaches in reality, despite recent development in end-to-end diarization.\nHowever, clustering methods have not been explored extensively for speaker\ndiarization. Commonly-used methods such as k-means, spectral clustering, and\nagglomerative hierarchical clustering only take into account properties such as\nproximity and relative densities. In this paper we propose to view\nclustering-based diarization as a community detection problem. By doing so the\ntopological structure is considered. This work has four major contributions.\nFirst it is shown that Leiden community detection algorithm significantly\noutperforms the previous methods on the clustering of speaker-segments. Second,\nwe propose to use uniform manifold approximation to reduce dimension while\nretaining global and local topological structure. Third, a masked filtering\napproach is introduced to extract \"clean\" speaker embeddings. Finally, the\ncommunity structure is applied to an end-to-end post-processing network to\nobtain diarization results. The final system presents a relative DER reduction\nof up to 70 percent. The breakdown contribution of each component is analyzed.", "published": "2022-04-26 07:18:05", "link": "http://arxiv.org/abs/2204.12112v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Comparative Study on Approaches to Acoustic Scene Classification using\n  CNNs", "abstract": "Acoustic scene classification is a process of characterizing and classifying\nthe environments from sound recordings. The first step is to generate features\n(representations) from the recorded sound and then classify the background\nenvironments. However, different kinds of representations have dramatic effects\non the accuracy of the classification. In this paper, we explored the three\nsuch representations on classification accuracy using neural networks. We\ninvestigated the spectrograms, MFCCs, and embeddings representations using\ndifferent CNN networks and autoencoders. Our dataset consists of sounds from\nthree settings of indoors and outdoors environments - thus the dataset contains\nsound from six different kinds of environments. We found that the spectrogram\nrepresentation has the highest classification accuracy while MFCC has the\nlowest classification accuracy. We reported our findings, insights as well as\nsome guidelines to achieve better accuracy for environment classification using\nsounds.", "published": "2022-04-26 09:23:29", "link": "http://arxiv.org/abs/2204.12177v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sound Localization by Self-Supervised Time Delay Estimation", "abstract": "Sounds reach one microphone in a stereo pair sooner than the other, resulting\nin an interaural time delay that conveys their directions. Estimating a sound's\ntime delay requires finding correspondences between the signals recorded by\neach microphone. We propose to learn these correspondences through\nself-supervision, drawing on recent techniques from visual tracking. We adapt\nthe contrastive random walk of Jabri et al. to learn a cycle-consistent\nrepresentation from unlabeled stereo sounds, resulting in a model that performs\non par with supervised methods on \"in the wild\" internet recordings. We also\npropose a multimodal contrastive learning model that solves a visually-guided\nlocalization task: estimating the time delay for a particular person in a\nmulti-speaker mixture, given a visual representation of their face. Project\nsite: https://ificl.github.io/stereocrw/", "published": "2022-04-26 17:59:01", "link": "http://arxiv.org/abs/2204.12489v3", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Named Entity Recognition for Audio De-Identification", "abstract": "Data anonymization is often a task carried out by humans. Automating it would\nreduce the cost and time required to complete this task. This paper presents a\npipeline to automate the anonymization of audio data in French. We propose a\npipeline, which takes audio files with their transcriptions and removes the\nnamed entities (NEs) present in the audio. Our pipeline is made up of a forced\naligner, which aligns words in an audio transcript with speech and a model that\nperforms named entity recognition (NER). Then, the audio segments that\ncorrespond to NEs are substituted with silence to anonymize audio. We compared\nforced aligners and NER models to find the best ones for our scenario. We\nevaluated our pipeline on a small hand-annotated dataset, achieving an F1 score\nof 0.769. This result shows that automating this task is feasible.", "published": "2022-04-26 22:38:02", "link": "http://arxiv.org/abs/2204.12622v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
