{"title": "Prior Art Search and Reranking for Generated Patent Text", "abstract": "Generative models, such as GPT-2, have demonstrated impressive results\nrecently. A fundamental question we'd like to address is: where did the\ngenerated text come from? This work is our initial effort toward answering the\nquestion by using prior art search. The purpose of the prior art search is to\nfind the most similar prior text in the training data of GPT-2. We take a\nreranking approach and apply it to the patent domain. Specifically, we\npre-train GPT-2 models from scratch by using the patent data from the USPTO.\nThe input for the prior art search is the patent text generated by the GPT-2\nmodel. We also pre-trained BERT models from scratch for converting patent text\nto embeddings. The steps of reranking are: (1) search the most similar text in\nthe training data of GPT-2 by taking a bag-of-word ranking approach (BM25), (2)\nconvert the search results in text format to BERT embeddings, and (3) provide\nthe final result by ranking the BERT embeddings based on their similarities\nwith the patent text generated by GPT-2. The experiments in this work show that\nsuch reranking is better than ranking with embeddings alone. However, our mixed\nresults also indicate that calculating the semantic similarities among long\ntext spans is still challenging. To our knowledge, this work is the first to\nimplement a reranking system to identify retrospectively the most similar\ninputs to a GPT model based on its output.", "published": "2020-09-19 01:16:18", "link": "http://arxiv.org/abs/2009.09132v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Dialogue Generation via Multi-Level Contrastive Learning", "abstract": "Most of the existing works for dialogue generation are data-driven models\ntrained directly on corpora crawled from websites. They mainly focus on\nimproving the model architecture to produce better responses but pay little\nattention to considering the quality of the training data contrastively. In\nthis paper, we propose a multi-level contrastive learning paradigm to model the\nfine-grained quality of the responses with respect to the query. A Rank-aware\nCalibration (RC) network is designed to construct the multi-level contrastive\noptimization objectives. Since these objectives are calculated based on the\nsentence level, which may erroneously encourage/suppress the generation of\nuninformative/informative words. To tackle this incidental issue, on one hand,\nwe design an exquisite token-level strategy for estimating the instance loss\nmore accurately. On the other hand, we build a Knowledge Inference (KI)\ncomponent to capture the keyword knowledge from the reference during training\nand exploit such information to encourage the generation of informative words.\nWe evaluate the proposed model on a carefully annotated dialogue dataset and\nthe results suggest that our model can generate more relevant and diverse\nresponses compared to the baseline models.", "published": "2020-09-19 02:41:04", "link": "http://arxiv.org/abs/2009.09147v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Weight Distillation: Transferring the Knowledge in Neural Network\n  Parameters", "abstract": "Knowledge distillation has been proven to be effective in model acceleration\nand compression. It allows a small network to learn to generalize in the same\nway as a large network. Recent successes in pre-training suggest the\neffectiveness of transferring model parameters. Inspired by this, we\ninvestigate methods of model acceleration and compression in another line of\nresearch. We propose Weight Distillation to transfer the knowledge in the large\nnetwork parameters through a parameter generator. Our experiments on WMT16\nEn-Ro, NIST12 Zh-En, and WMT14 En-De machine translation tasks show that weight\ndistillation can train a small network that is 1.88~2.94x faster than the large\nnetwork but with competitive performance. With the same sized small network,\nweight distillation can outperform knowledge distillation by 0.51~1.82 BLEU\npoints.", "published": "2020-09-19 03:23:26", "link": "http://arxiv.org/abs/2009.09152v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLEVR Parser: A Graph Parser Library for Geometric Learning on Language\n  Grounded Image Scenes", "abstract": "The CLEVR dataset has been used extensively in language grounded visual\nreasoning in Machine Learning (ML) and Natural Language Processing (NLP)\ndomains. We present a graph parser library for CLEVR, that provides\nfunctionalities for object-centric attributes and relationships extraction, and\nconstruction of structural graph representations for dual modalities.\nStructural order-invariant representations enable geometric learning and can\naid in downstream tasks like language grounding to vision, robotics,\ncompositionality, interpretability, and computational grammar construction. We\nprovide three extensible main components - parser, embedder, and visualizer\nthat can be tailored to suit specific learning setups. We also provide\nout-of-the-box functionality for seamless integration with popular deep graph\nneural network (GNN) libraries. Additionally, we discuss downstream usage and\napplications of the library, and how it accelerates research for the NLP\nresearch community.", "published": "2020-09-19 03:32:37", "link": "http://arxiv.org/abs/2009.09154v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Extracting Summary Knowledge Graphs from Long Documents", "abstract": "Knowledge graphs capture entities and relations from long documents and can\nfacilitate reasoning in many downstream applications. Extracting compact\nknowledge graphs containing only salient entities and relations is important\nbut challenging for understanding and summarizing long documents. We introduce\na new text-to-graph task of predicting summarized knowledge graphs from long\ndocuments. We develop a dataset of 200k document/graph pairs using automatic\nand human annotations. We also develop strong baselines for this task based on\ngraph learning and text summarization, and provide quantitative and qualitative\nstudies of their effect.", "published": "2020-09-19 04:37:33", "link": "http://arxiv.org/abs/2009.09162v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Nominal Compound Chain Extraction: A New Task for Semantic-enriched\n  Lexical Chain", "abstract": "Lexical chain consists of cohesion words in a document, which implies the\nunderlying structure of a text, and thus facilitates downstream NLP tasks.\nNevertheless, existing work focuses on detecting the simple surface lexicons\nwith shallow syntax associations, ignoring the semantic-aware lexical compounds\nas well as the latent semantic frames, (e.g., topic), which can be much more\ncrucial for real-world NLP applications. In this paper, we introduce a novel\ntask, Nominal Compound Chain Extraction (NCCE), extracting and clustering all\nthe nominal compounds that share identical semantic topics. In addition, we\nmodel the task as a two-stage prediction (i.e., compound extraction and chain\ndetection), which is handled via a proposed joint framework. The model employs\nthe BERT encoder to yield contextualized document representation. Also, HowNet\nis exploited as external resources for offering rich sememe information. The\nexperiments are based on our manually annotated corpus, and the results prove\nthe necessity of the NCCE task as well as the effectiveness of our joint\napproach.", "published": "2020-09-19 06:20:37", "link": "http://arxiv.org/abs/2009.09173v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aggressive Language Detection with Joint Text Normalization via\n  Adversarial Multi-task Learning", "abstract": "Aggressive language detection (ALD), detecting the abusive and offensive\nlanguage in texts, is one of the crucial applications in NLP community. Most\nexisting works treat ALD as regular classification with neural models, while\nignoring the inherent conflicts of social media text that they are quite\nunnormalized and irregular. In this work, we target improving the ALD by\njointly performing text normalization (TN), via an adversarial multi-task\nlearning framework. The private encoders for ALD and TN focus on the\ntask-specific features retrieving, respectively, and the shared encoder learns\nthe underlying common features over two tasks. During adversarial training, a\ntask discriminator distinguishes the separate learning of ALD or TN.\nExperimental results on four ALD datasets show that our model outperforms all\nbaselines under differing settings by large margins, demonstrating the\nnecessity of joint learning the TN with ALD. Further analysis is conducted for\na better understanding of our method.", "published": "2020-09-19 06:26:07", "link": "http://arxiv.org/abs/2009.09174v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BioALBERT: A Simple and Effective Pre-trained Language Model for\n  Biomedical Named Entity Recognition", "abstract": "In recent years, with the growing amount of biomedical documents, coupled\nwith advancement in natural language processing algorithms, the research on\nbiomedical named entity recognition (BioNER) has increased exponentially.\nHowever, BioNER research is challenging as NER in the biomedical domain are:\n(i) often restricted due to limited amount of training data, (ii) an entity can\nrefer to multiple types and concepts depending on its context and, (iii) heavy\nreliance on acronyms that are sub-domain specific. Existing BioNER approaches\noften neglect these issues and directly adopt the state-of-the-art (SOTA)\nmodels trained in general corpora which often yields unsatisfactory results. We\npropose biomedical ALBERT (A Lite Bidirectional Encoder Representations from\nTransformers for Biomedical Text Mining) bioALBERT, an effective\ndomain-specific language model trained on large-scale biomedical corpora\ndesigned to capture biomedical context-dependent NER. We adopted a\nself-supervised loss used in ALBERT that focuses on modelling inter-sentence\ncoherence to better learn context-dependent representations and incorporated\nparameter reduction techniques to lower memory consumption and increase the\ntraining speed in BioNER. In our experiments, BioALBERT outperformed\ncomparative SOTA BioNER models on eight biomedical NER benchmark datasets with\nfour different entity types. We trained four different variants of BioALBERT\nmodels which are available for the research community to be used in future\nresearch.", "published": "2020-09-19 12:58:47", "link": "http://arxiv.org/abs/2009.09223v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word class flexibility: A deep contextualized approach", "abstract": "Word class flexibility refers to the phenomenon whereby a single word form is\nused across different grammatical categories. Extensive work in linguistic\ntypology has sought to characterize word class flexibility across languages,\nbut quantifying this phenomenon accurately and at scale has been fraught with\ndifficulties. We propose a principled methodology to explore regularity in word\nclass flexibility. Our method builds on recent work in contextualized word\nembeddings to quantify semantic shift between word classes (e.g., noun-to-verb,\nverb-to-noun), and we apply this method to 37 languages. We find that\ncontextualized embeddings not only capture human judgment of class variation\nwithin words in English, but also uncover shared tendencies in class\nflexibility across languages. Specifically, we find greater semantic variation\nwhen flexible lemmas are used in their dominant word class, supporting the view\nthat word class flexibility is a directional process. Our work highlights the\nutility of deep contextualized models in linguistic typology.", "published": "2020-09-19 14:41:50", "link": "http://arxiv.org/abs/2009.09241v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Computational Linguistics in Minangkabau Language: Studies on\n  Sentiment Analysis and Machine Translation", "abstract": "Although some linguists (Rusmali et al., 1985; Crouch, 2009) have fairly\nattempted to define the morphology and syntax of Minangkabau, information\nprocessing in this language is still absent due to the scarcity of the\nannotated resource. In this work, we release two Minangkabau corpora: sentiment\nanalysis and machine translation that are harvested and constructed from\nTwitter and Wikipedia. We conduct the first computational linguistics in\nMinangkabau language employing classic machine learning and\nsequence-to-sequence models such as LSTM and Transformer. Our first experiments\nshow that the classification performance over Minangkabau text significantly\ndrops when tested with the model trained in Indonesian. Whereas, in the machine\ntranslation experiment, a simple word-to-word translation using a bilingual\ndictionary outperforms LSTM and Transformer model in terms of BLEU score.", "published": "2020-09-19 22:13:27", "link": "http://arxiv.org/abs/2009.09309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Computer Assisted Translation with Neural Quality Estimation and\n  Automatic Post-Editing", "abstract": "With the advent of neural machine translation, there has been a marked shift\ntowards leveraging and consuming the machine translation results. However, the\ngap between machine translation systems and human translators needs to be\nmanually closed by post-editing. In this paper, we propose an end-to-end deep\nlearning framework of the quality estimation and automatic post-editing of the\nmachine translation output. Our goal is to provide error correction suggestions\nand to further relieve the burden of human translators through an interpretable\nmodel. To imitate the behavior of human translators, we design three efficient\ndelegation modules -- quality estimation, generative post-editing, and atomic\noperation post-editing and construct a hierarchical model based on them. We\nexamine this approach with the English--German dataset from WMT 2017 APE shared\ntask and our experimental results can achieve the state-of-the-art performance.\nWe also verify that the certified translators can significantly expedite their\npost-editing processing with our model in human evaluation.", "published": "2020-09-19 00:29:00", "link": "http://arxiv.org/abs/2009.09126v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Long-Short Term Masking Transformer: A Simple but Effective Baseline for\n  Document-level Neural Machine Translation", "abstract": "Many document-level neural machine translation (NMT) systems have explored\nthe utility of context-aware architecture, usually requiring an increasing\nnumber of parameters and computational complexity. However, few attention is\npaid to the baseline model. In this paper, we research extensively the pros and\ncons of the standard transformer in document-level translation, and find that\nthe auto-regressive property can simultaneously bring both the advantage of the\nconsistency and the disadvantage of error accumulation. Therefore, we propose a\nsurprisingly simple long-short term masking self-attention on top of the\nstandard transformer to both effectively capture the long-range dependence and\nreduce the propagation of errors. We examine our approach on the two publicly\navailable document-level datasets. We can achieve a strong result in BLEU and\ncapture discourse phenomena.", "published": "2020-09-19 00:29:51", "link": "http://arxiv.org/abs/2009.09127v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge Transfer via Pre-training for Recommendation: A Review and\n  Prospect", "abstract": "Recommender systems aim to provide item recommendations for users, and are\nusually faced with data sparsity problem (e.g., cold start) in real-world\nscenarios. Recently pre-trained models have shown their effectiveness in\nknowledge transfer between domains and tasks, which can potentially alleviate\nthe data sparsity problem in recommender systems. In this survey, we first\nprovide a review of recommender systems with pre-training. In addition, we show\nthe benefits of pre-training to recommender systems through experiments.\nFinally, we discuss several promising directions for future research for\nrecommender systems with pre-training.", "published": "2020-09-19 13:06:27", "link": "http://arxiv.org/abs/2009.09226v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Active Learning for Product Type Ontology Enhancement in E-commerce", "abstract": "Entity-based semantic search has been widely adopted in modern search engines\nto improve search accuracy by understanding users' intent. In e-commerce, an\naccurate and complete product type (PT) ontology is essential for recognizing\nproduct entities in queries and retrieving relevant products from catalog.\nHowever, finding product types (PTs) to construct such an ontology is usually\nexpensive due to the considerable amount of human efforts it may involve. In\nthis work, we propose an active learning framework that efficiently utilizes\ndomain experts' knowledge for PT discovery. We also show the quality and\ncoverage of the resulting PTs in the experiment results.", "published": "2020-09-19 02:21:12", "link": "http://arxiv.org/abs/2009.09143v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "OpenAttack: An Open-source Textual Adversarial Attack Toolkit", "abstract": "Textual adversarial attacking has received wide and increasing attention in\nrecent years. Various attack models have been proposed, which are enormously\ndistinct and implemented with different programming frameworks and settings.\nThese facts hinder quick utilization and fair comparison of attack models. In\nthis paper, we present an open-source textual adversarial attack toolkit named\nOpenAttack to solve these issues. Compared with existing other textual\nadversarial attack toolkits, OpenAttack has its unique strengths in support for\nall attack types, multilinguality, and parallel processing. Currently,\nOpenAttack includes 15 typical attack models that cover all attack types. Its\nhighly inclusive modular design not only supports quick utilization of existing\nattack models, but also enables great flexibility and extensibility. OpenAttack\nhas broad uses including comparing and evaluating attack models, measuring\nrobustness of a model, assisting in developing new attack models, and\nadversarial training. Source code and documentation can be obtained at\nhttps://github.com/thunlp/OpenAttack.", "published": "2020-09-19 09:02:56", "link": "http://arxiv.org/abs/2009.09191v2", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Learning to Attack: Towards Textual Adversarial Attacking in Real-world\n  Situations", "abstract": "Adversarial attacking aims to fool deep neural networks with adversarial\nexamples. In the field of natural language processing, various textual\nadversarial attack models have been proposed, varying in the accessibility to\nthe victim model. Among them, the attack models that only require the output of\nthe victim model are more fit for real-world situations of adversarial\nattacking. However, to achieve high attack performance, these models usually\nneed to query the victim model too many times, which is neither efficient nor\nviable in practice. To tackle this problem, we propose a reinforcement learning\nbased attack model, which can learn from attack history and launch attacks more\nefficiently. In experiments, we evaluate our model by attacking several\nstate-of-the-art models on the benchmark datasets of multiple tasks including\nsentiment analysis, text classification and natural language inference.\nExperimental results demonstrate that our model consistently achieves both\nbetter attack performance and higher efficiency than recently proposed baseline\nmethods. We also find our attack model can bring more robustness improvement to\nthe victim model by adversarial training. All the code and data of this paper\nwill be made public.", "published": "2020-09-19 09:12:24", "link": "http://arxiv.org/abs/2009.09192v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Can questions summarize a corpus? Using question generation for\n  characterizing COVID-19 research", "abstract": "What are the latent questions on some textual data? In this work, we\ninvestigate using question generation models for exploring a collection of\ndocuments. Our method, dubbed corpus2question, consists of applying a\npre-trained question generation model over a corpus and aggregating the\nresulting questions by frequency and time. This technique is an alternative to\nmethods such as topic modelling and word cloud for summarizing large amounts of\ntextual data. Results show that applying corpus2question on a corpus of\nscientific articles related to COVID-19 yields relevant questions about the\ntopic. The most frequent questions are \"what is covid 19\" and \"what is the\ntreatment for covid\". Among the 1000 most frequent questions are \"what is the\nthreshold for herd immunity\" and \"what is the role of ace2 in viral entry\". We\nshow that the proposed method generated similar questions for 13 of the 27\nexpert-made questions from the CovidQA question answering dataset.\n  The code to reproduce our experiments and the generated questions are\navailable at: https://github.com/unicamp-dl/corpus2question", "published": "2020-09-19 19:57:44", "link": "http://arxiv.org/abs/2009.09290v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "H.3.3"], "primary_category": "cs.IR"}
