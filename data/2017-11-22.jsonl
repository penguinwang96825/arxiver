{"title": "Does Higher Order LSTM Have Better Accuracy for Segmenting and Labeling\n  Sequence Data?", "abstract": "Existing neural models usually predict the tag of the current token\nindependent of the neighboring tags. The popular LSTM-CRF model considers the\ntag dependencies between every two consecutive tags. However, it is hard for\nexisting neural models to take longer distance dependencies of tags into\nconsideration. The scalability is mainly limited by the complex model\nstructures and the cost of dynamic programming during training. In our work, we\nfirst design a new model called \"high order LSTM\" to predict multiple tags for\nthe current token which contains not only the current tag but also the previous\nseveral tags. We call the number of tags in one prediction as \"order\". Then we\npropose a new method called Multi-Order BiLSTM (MO-BiLSTM) which combines low\norder and high order LSTMs together. MO-BiLSTM keeps the scalability to high\norder models with a pruning technique. We evaluate MO-BiLSTM on all-phrase\nchunking and NER datasets. Experiment results show that MO-BiLSTM achieves the\nstate-of-the-art result in chunking and highly competitive results in two NER\ndatasets.", "published": "2017-11-22 11:18:31", "link": "http://arxiv.org/abs/1711.08231v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Customized Nonlinear Bandits for Online Response Selection in Neural\n  Conversation Models", "abstract": "Dialog response selection is an important step towards natural response\ngeneration in conversational agents. Existing work on neural conversational\nmodels mainly focuses on offline supervised learning using a large set of\ncontext-response pairs. In this paper, we focus on online learning of response\nselection in retrieval-based dialog systems. We propose a contextual\nmulti-armed bandit model with a nonlinear reward function that uses distributed\nrepresentation of text for online response selection. A bidirectional LSTM is\nused to produce the distributed representations of dialog context and\nresponses, which serve as the input to a contextual bandit. In learning the\nbandit, we propose a customized Thompson sampling method that is applied to a\npolynomial feature space in approximating the reward. Experimental results on\nthe Ubuntu Dialogue Corpus demonstrate significant performance gains of the\nproposed method over conventional linear contextual bandits. Moreover, we\nreport encouraging response selection performance of the proposed neural bandit\nmodel using the Recall@k metric for a small set of online training samples.", "published": "2017-11-22 20:15:01", "link": "http://arxiv.org/abs/1711.08493v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Automatic Generation of Medical Imaging Reports", "abstract": "Medical imaging is widely used in clinical practice for diagnosis and\ntreatment. Report-writing can be error-prone for unexperienced physicians, and\ntime- consuming and tedious for experienced physicians. To address these\nissues, we study the automatic generation of medical imaging reports. This task\npresents several challenges. First, a complete report contains multiple\nheterogeneous forms of information, including findings and tags. Second,\nabnormal regions in medical images are difficult to identify. Third, the re-\nports are typically long, containing multiple sentences. To cope with these\nchallenges, we (1) build a multi-task learning framework which jointly performs\nthe pre- diction of tags and the generation of para- graphs, (2) propose a\nco-attention mechanism to localize regions containing abnormalities and\ngenerate narrations for them, (3) develop a hierarchical LSTM model to generate\nlong paragraphs. We demonstrate the effectiveness of the proposed methods on\ntwo publicly available datasets.", "published": "2017-11-22 09:45:51", "link": "http://arxiv.org/abs/1711.08195v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes", "abstract": "Word embeddings use vectors to represent words such that the geometry between\nvectors captures semantic relationship between the words. In this paper, we\ndevelop a framework to demonstrate how the temporal dynamics of the embedding\ncan be leveraged to quantify changes in stereotypes and attitudes toward women\nand ethnic minorities in the 20th and 21st centuries in the United States. We\nintegrate word embeddings trained on 100 years of text data with the U.S.\nCensus to show that changes in the embedding track closely with demographic and\noccupation shifts over time. The embedding captures global social shifts --\ne.g., the women's movement in the 1960s and Asian immigration into the U.S --\nand also illuminates how specific adjectives and occupations became more\nclosely associated with certain populations over time. Our framework for\ntemporal analysis of word embedding opens up a powerful new intersection\nbetween machine learning and quantitative social science.", "published": "2017-11-22 17:39:58", "link": "http://arxiv.org/abs/1711.08412v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "EMFET: E-mail Features Extraction Tool", "abstract": "EMFET is an open source and flexible tool that can be used to extract a large\nnumber of features from any email corpus with emails saved in EML format. The\nextracted features can be categorized into three main groups: header features,\npayload (body) features, and attachment features. The purpose of the tool is to\nhelp practitioners and researchers to build datasets that can be used for\ntraining machine learning models for spam detection. So far, 140 features can\nbe extracted using EMFET. EMFET is extensible and easy to use. The source code\nof EMFET is publicly available at GitHub\n(https://github.com/WadeaHijjawi/EmailFeaturesExtraction)", "published": "2017-11-22 22:24:20", "link": "http://arxiv.org/abs/1711.08521v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
