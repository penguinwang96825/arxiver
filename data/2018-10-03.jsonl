{"title": "A Deep Learning Architecture for De-identification of Patient Notes:\n  Implementation and Evaluation", "abstract": "De-identification is the process of removing 18 protected health information\n(PHI) from clinical notes in order for the text to be considered not\nindividually identifiable. Recent advances in natural language processing (NLP)\nhas allowed for the use of deep learning techniques for the task of\nde-identification. In this paper, we present a deep learning architecture that\nbuilds on the latest NLP advances by incorporating deep contextualized word\nembeddings and variational drop out Bi-LSTMs. We test this architecture on two\ngold standard datasets and show that the architecture achieves state-of-the-art\nperformance on both data sets while also converging faster than other systems\nwithout the use of dictionaries or other knowledge sources.", "published": "2018-10-03 02:53:04", "link": "http://arxiv.org/abs/1810.01570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparative Study of Neural Network Models for Sentence Classification", "abstract": "This paper presents an extensive comparative study of four neural network\nmodels, including feed-forward networks, convolutional networks, recurrent\nnetworks and long short-term memory networks, on two sentence classification\ndatasets of English and Vietnamese text. We show that on the English dataset,\nthe convolutional network models without any feature engineering outperform\nsome competitive sentence classifiers with rich hand-crafted linguistic\nfeatures. We demonstrate that the GloVe word embeddings are consistently better\nthan both Skip-gram word embeddings and word count vectors. We also show the\nsuperiority of convolutional neural network models on a Vietnamese newspaper\nsentence dataset over strong baseline models. Our experimental results suggest\nsome good practices for applying neural network models in sentence\nclassification.", "published": "2018-10-03 09:36:20", "link": "http://arxiv.org/abs/1810.01656v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Neural Transition-based Model for Nested Mention Recognition", "abstract": "It is common that entity mentions can contain other mentions recursively.\nThis paper introduces a scalable transition-based method to model the nested\nstructure of mentions. We first map a sentence with nested mentions to a\ndesignated forest where each mention corresponds to a constituent of the\nforest. Our shift-reduce based system then learns to construct the forest\nstructure in a bottom-up manner through an action sequence whose maximal length\nis guaranteed to be three times of the sentence length. Based on Stack-LSTM\nwhich is employed to efficiently and effectively represent the states of the\nsystem in a continuous space, our system is further incorporated with a\ncharacter-based component to capture letter-level patterns. Our model achieves\nthe state-of-the-art results on ACE datasets, showing its effectiveness in\ndetecting nested mentions.", "published": "2018-10-03 15:53:37", "link": "http://arxiv.org/abs/1810.01808v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Segmental Hypergraphs for Overlapping Mention Recognition", "abstract": "In this work, we propose a novel segmental hypergraph representation to model\noverlapping entity mentions that are prevalent in many practical datasets. We\nshow that our model built on top of such a new representation is able to\ncapture features and interactions that cannot be captured by previous models\nwhile maintaining a low time complexity for inference. We also present a\ntheoretical analysis to formally assess how our representation is better than\nalternative representations reported in the literature in terms of\nrepresentational power. Coupled with neural networks for feature learning, our\nmodel achieves the state-of-the-art performance in three benchmark datasets\nannotated with overlapping mentions.", "published": "2018-10-03 16:13:26", "link": "http://arxiv.org/abs/1810.01817v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fast Approach to Build an Automatic Sentiment Annotator for Legal Domain\n  using Transfer Learning", "abstract": "This study proposes a novel way of identifying the sentiment of the phrases\nused in the legal domain. The added complexity of the language used in law, and\nthe inability of the existing systems to accurately predict the sentiments of\nwords in law are the main motivations behind this study. This is a transfer\nlearning approach, which can be used for other domain adaptation tasks as well.\nThe proposed methodology achieves an improvement of over 6\\% compared to the\nsource model's accuracy in the legal domain.", "published": "2018-10-03 18:45:40", "link": "http://arxiv.org/abs/1810.01912v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Active Learning for New Domains in Natural Language Understanding", "abstract": "We explore active learning (AL) for improving the accuracy of new domains in\na natural language understanding (NLU) system. We propose an algorithm called\nMajority-CRF that uses an ensemble of classification models to guide the\nselection of relevant utterances, as well as a sequence labeling model to help\nprioritize informative examples. Experiments with three domains show that\nMajority-CRF achieves 6.6%-9% relative error rate reduction compared to random\nsampling with the same annotation budget, and statistically significant\nimprovements compared to other AL approaches. Additionally, case studies with\nhuman-in-the-loop AL on six new domains show 4.6%-9% improvement on an existing\nNLU system.", "published": "2018-10-03 12:50:56", "link": "http://arxiv.org/abs/1810.03450v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Machine Learning Suites for Online Toxicity Detection", "abstract": "To identify and classify toxic online commentary, the modern tools of data\nscience transform raw text into key features from which either thresholding or\nlearning algorithms can make predictions for monitoring offensive\nconversations. We systematically evaluate 62 classifiers representing 19 major\nalgorithmic families against features extracted from the Jigsaw dataset of\nWikipedia comments. We compare the classifiers based on statistically\nsignificant differences in accuracy and relative execution time. Among these\nclassifiers for identifying toxic comments, tree-based algorithms provide the\nmost transparently explainable rules and rank-order the predictive contribution\nof each feature. Among 28 features of syntax, sentiment, emotion and outlier\nword dictionaries, a simple bad word list proves most predictive of offensive\ncommentary.", "published": "2018-10-03 13:22:44", "link": "http://arxiv.org/abs/1810.01869v1", "categories": ["cs.LG", "cs.CL", "cs.NE", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Transfer Learning via Unsupervised Task Discovery for Visual Question\n  Answering", "abstract": "We study how to leverage off-the-shelf visual and linguistic data to cope\nwith out-of-vocabulary answers in visual question answering task. Existing\nlarge-scale visual datasets with annotations such as image class labels,\nbounding boxes and region descriptions are good sources for learning rich and\ndiverse visual concepts. However, it is not straightforward how the visual\nconcepts can be captured and transferred to visual question answering models\ndue to missing link between question dependent answering models and visual data\nwithout question. We tackle this problem in two steps: 1) learning a task\nconditional visual classifier, which is capable of solving diverse\nquestion-specific visual recognition tasks, based on unsupervised task\ndiscovery and 2) transferring the task conditional visual classifier to visual\nquestion answering models. Specifically, we employ linguistic knowledge sources\nsuch as structured lexical database (e.g. WordNet) and visual descriptions for\nunsupervised task discovery, and transfer a learned task conditional visual\nclassifier as an answering unit in a visual question answering model. We\nempirically show that the proposed algorithm generalizes to out-of-vocabulary\nanswers successfully using the knowledge transferred from the visual dataset.", "published": "2018-10-03 19:48:38", "link": "http://arxiv.org/abs/1810.02358v2", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Exploiting Contextual Information via Dynamic Memory Network for Event\n  Detection", "abstract": "The task of event detection involves identifying and categorizing event\ntriggers. Contextual information has been shown effective on the task. However,\nexisting methods which utilize contextual information only process the context\nonce. We argue that the context can be better exploited by processing the\ncontext multiple times, allowing the model to perform complex reasoning and to\ngenerate better context representation, thus improving the overall performance.\nMeanwhile, dynamic memory network (DMN) has demonstrated promising capability\nin capturing contextual information and has been applied successfully to\nvarious tasks. In light of the multi-hop mechanism of the DMN to model the\ncontext, we propose the trigger detection dynamic memory network (TD-DMN) to\ntackle the event detection problem. We performed a five-fold cross-validation\non the ACE-2005 dataset and experimental results show that the multi-hop\nmechanism does improve the performance and the proposed model achieves best\n$F_1$ score compared to the state-of-the-art methods.", "published": "2018-10-03 08:43:11", "link": "http://arxiv.org/abs/1810.03449v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SAM-GCNN: A Gated Convolutional Neural Network with Segment-Level\n  Attention Mechanism for Home Activity Monitoring", "abstract": "In this paper, we propose a method for home activity monitoring. We\ndemonstrate our model on dataset of Detection and Classification of Acoustic\nScenes and Events (DCASE) 2018 Challenge Task 5. This task aims to classify\nmulti-channel audios into one of the provided pre-defined classes. All of these\nclasses are daily activities performed in a home environment. To tackle this\ntask, we propose a gated convolutional neural network with segment-level\nattention mechanism (SAM-GCNN). The proposed framework is a convolutional model\nwith two auxiliary modules: a gated convolutional neural network and a\nsegment-level attention mechanism. Furthermore, we adopted model ensemble to\nenhance the capability of generalization of our model. We evaluated our work on\nthe development dataset of DCASE 2018 Task 5 and achieved competitive\nperformance, with a macro-averaged F-1 score increasing from 83.76% to 89.33%,\ncompared with the convolutional baseline system.", "published": "2018-10-03 14:55:32", "link": "http://arxiv.org/abs/1810.03986v2", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
