{"title": "CORWA: A Citation-Oriented Related Work Annotation Dataset", "abstract": "Academic research is an exploratory activity to discover new solutions to\nproblems. By this nature, academic research works perform literature reviews to\ndistinguish their novelties from prior work. In natural language processing,\nthis literature review is usually conducted under the \"Related Work\" section.\nThe task of related work generation aims to automatically generate the related\nwork section given the rest of the research paper and a list of papers to cite.\nPrior work on this task has focused on the sentence as the basic unit of\ngeneration, neglecting the fact that related work sections consist of variable\nlength text fragments derived from different information sources. As a first\nstep toward a linguistically-motivated related work generation framework, we\npresent a Citation Oriented Related Work Annotation (CORWA) dataset that labels\ndifferent types of citation text fragments from different information sources.\nWe train a strong baseline model that automatically tags the CORWA labels on\nmassive unlabeled related work section texts. We further suggest a novel\nframework for human-in-the-loop, iterative, abstractive related work\ngeneration.", "published": "2022-05-07 00:23:46", "link": "http://arxiv.org/abs/2205.03512v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SubGraph Networks based Entity Alignment for Cross-lingual Knowledge\n  Graph", "abstract": "Entity alignment is the task of finding entities representing the same\nreal-world object in two knowledge graphs(KGs). Cross-lingual knowledge graph\nentity alignment aims to discover the cross-lingual links in the multi-language\nKGs, which is of great significance to the NLP applications and multi-language\nKGs fusion. In the task of aligning cross-language knowledge graphs, the\nstructures of the two graphs are very similar, and the equivalent entities\noften have the same subgraph structure characteristics. The traditional GCN\nmethod neglects to obtain structural features through representative parts of\nthe original graph and the use of adjacency matrix is not enough to effectively\nrepresent the structural features of the graph. In this paper, we introduce the\nsubgraph network (SGN) method into the GCN-based cross-lingual KG entity\nalignment method. In the method, we extracted the first-order subgraphs of the\nKGs to expand the structural features of the original graph to enhance the\nrepresentation ability of the entity embedding and improve the alignment\naccuracy. Experiments show that the proposed method outperforms the\nstate-of-the-art GCN-based method.", "published": "2022-05-07 05:13:15", "link": "http://arxiv.org/abs/2205.03557v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Disentangled Textual Representations via Statistical Measures\n  of Similarity", "abstract": "When working with textual data, a natural application of disentangled\nrepresentations is fair classification where the goal is to make predictions\nwithout being biased (or influenced) by sensitive attributes that may be\npresent in the data (e.g., age, gender or race). Dominant approaches to\ndisentangle a sensitive attribute from textual representations rely on learning\nsimultaneously a penalization term that involves either an adversarial loss\n(e.g., a discriminator) or an information measure (e.g., mutual information).\nHowever, these methods require the training of a deep neural network with\nseveral parameter updates for each update of the representation model. As a\nmatter of fact, the resulting nested optimization loop is both time consuming,\nadding complexity to the optimization dynamic, and requires a fine\nhyperparameter selection (e.g., learning rates, architecture). In this work, we\nintroduce a family of regularizers for learning disentangled representations\nthat do not require training. These regularizers are based on statistical\nmeasures of similarity between the conditional probability distributions with\nrespect to the sensitive attributes. Our novel regularizers do not require\nadditional training, are faster and do not involve additional tuning while\nachieving better results both when combined with pretrained and randomly\ninitialized text encoders.", "published": "2022-05-07 08:06:22", "link": "http://arxiv.org/abs/2205.03589v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UniMorph 4.0: Universal Morphology", "abstract": "The Universal Morphology (UniMorph) project is a collaborative effort\nproviding broad-coverage instantiated normalized morphological inflection\ntables for hundreds of diverse world languages. The project comprises two major\nthrusts: a language-independent feature schema for rich morphological\nannotation and a type-level resource of annotated data in diverse languages\nrealizing that schema. This paper presents the expansions and improvements made\non several fronts over the last couple of years (since McCarthy et al. (2020)).\nCollaborative efforts by numerous linguists have added 67 new languages,\nincluding 30 endangered languages. We have implemented several improvements to\nthe extraction pipeline to tackle some issues, e.g. missing gender and macron\ninformation. We have also amended the schema to use a hierarchical structure\nthat is needed for morphological phenomena like multiple-argument agreement and\ncase stacking, while adding some missing morphological features to make the\nschema more inclusive. In light of the last UniMorph release, we also augmented\nthe database with morpheme segmentation for 16 languages. Lastly, this new\nrelease makes a push towards inclusion of derivational morphology in UniMorph\nby enriching the data and annotation schema with instances representing\nderivational processes from MorphyNet.", "published": "2022-05-07 09:19:02", "link": "http://arxiv.org/abs/2205.03608v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vector Representations of Idioms in Conversational Systems", "abstract": "We demonstrate, in this study, that an open-domain conversational system\ntrained on idioms or figurative language generates more fitting responses to\nprompts containing idioms. Idioms are part of everyday speech in many\nlanguages, across many cultures, but they pose a great challenge for many\nNatural Language Processing (NLP) systems that involve tasks such as\nInformation Retrieval (IR) and Machine Translation (MT), besides conversational\nAI. We utilize the Potential Idiomatic Expression (PIE)-English idioms corpus\nfor the two tasks that we investigate: classification and conversation\ngeneration. We achieve state-of-the-art (SoTA) result of 98% macro F1 score on\nthe classification task by using the SoTA T5 model. We experiment with three\ninstances of the SoTA dialogue model, Dialogue Generative Pre-trained\nTransformer (DialoGPT), for conversation generation. Their performances are\nevaluated using the automatic metric perplexity and human evaluation. The\nresults show that the model trained on the idiom corpus generates more fitting\nresponses to prompts containing idioms 71.9% of the time, compared to a similar\nmodel not trained on the idioms corpus. We contribute the model checkpoint/demo\nand code on the HuggingFace hub for public access.", "published": "2022-05-07 14:50:05", "link": "http://arxiv.org/abs/2205.03666v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Empathetic Response Generation with State Management", "abstract": "A good empathetic dialogue system should first track and understand a user's\nemotion and then reply with an appropriate emotion. However, current approaches\nto this task either focus on improving the understanding of users' emotion or\non proposing better responding strategies, and very few works consider both at\nthe same time. Our work attempts to fill this vacancy. Inspired by\ntask-oriented dialogue systems, we propose a novel empathetic response\ngeneration model with emotion-aware dialogue management. The emotion-aware\ndialogue management contains two parts: (1) Emotion state tracking maintains\nthe current emotion state of the user and (2) Empathetic dialogue policy\nselection predicts a target emotion and a user's intent based on the results of\nthe emotion state tracking. The predicted information is then used to guide the\ngeneration of responses. Experimental results show that dynamically managing\ndifferent information can help the model generate more empathetic responses\ncompared with several baselines under both automatic and human evaluations.", "published": "2022-05-07 16:17:28", "link": "http://arxiv.org/abs/2205.03676v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Better Retrieval May Not Lead to Better Question Answering", "abstract": "Considerable progress has been made recently in open-domain question\nanswering (QA) problems, which require Information Retrieval (IR) and Reading\nComprehension (RC). A popular approach to improve the system's performance is\nto improve the quality of the retrieved context from the IR stage. In this work\nwe show that for StrategyQA, a challenging open-domain QA dataset that requires\nmulti-hop reasoning, this common approach is surprisingly ineffective --\nimproving the quality of the retrieved context hardly improves the system's\nperformance. We further analyze the system's behavior to identify potential\nreasons.", "published": "2022-05-07 16:59:38", "link": "http://arxiv.org/abs/2205.03685v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AKI-BERT: a Pre-trained Clinical Language Model for Early Prediction of\n  Acute Kidney Injury", "abstract": "Acute kidney injury (AKI) is a common clinical syndrome characterized by a\nsudden episode of kidney failure or kidney damage within a few hours or a few\ndays. Accurate early prediction of AKI for patients in ICU who are more likely\nthan others to have AKI can enable timely interventions, and reduce the\ncomplications of AKI. Much of the clinical information relevant to AKI is\ncaptured in clinical notes that are largely unstructured text and requires\nadvanced natural language processing (NLP) for useful information extraction.\nOn the other hand, pre-trained contextual language models such as Bidirectional\nEncoder Representations from Transformers (BERT) have improved performances for\nmany NLP tasks in general domain recently. However, few have explored BERT on\ndisease-specific medical domain tasks such as AKI early prediction. In this\npaper, we try to apply BERT to specific diseases and present an AKI\ndomain-specific pre-trained language model based on BERT (AKI-BERT) that could\nbe used to mine the clinical notes for early prediction of AKI. AKI-BERT is a\nBERT model pre-trained on the clinical notes of patients having risks for AKI.\nOur experiments on Medical Information Mart for Intensive Care III (MIMIC-III)\ndataset demonstrate that AKI-BERT can yield performance improvements for early\nAKI prediction, thus expanding the utility of the BERT model from general\nclinical domain to disease-specific domain.", "published": "2022-05-07 18:04:31", "link": "http://arxiv.org/abs/2205.03695v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CogIntAc: Modeling the Relationships between Intention, Emotion and\n  Action in Interactive Process from Cognitive Perspective", "abstract": "Intention, emotion and action are important psychological factors in human\nactivities, which play an important role in the interaction between\nindividuals. How to model the interaction process between individuals by\nanalyzing the relationship of their intentions, emotions, and actions at the\ncognitive level is challenging. In this paper, we propose a novel cognitive\nframework of individual interaction. The core of the framework is that\nindividuals achieve interaction through external action driven by their inner\nintention. Based on this idea, the interactions between individuals can be\nconstructed by establishing relationships between the intention, emotion and\naction. Furthermore, we conduct analysis on the interaction between individuals\nand give a reasonable explanation for the predicting results. To verify the\neffectiveness of the framework, we reconstruct a dataset and propose three\ntasks as well as the corresponding baseline models, including action abduction,\nemotion prediction and action generation. The novel framework shows an\ninteresting perspective on mimicking the mental state of human beings in\ncognitive science.", "published": "2022-05-07 03:54:51", "link": "http://arxiv.org/abs/2205.03540v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Improving Downstream Task Performance by Treating Numbers as Entities", "abstract": "Numbers are essential components of text, like any other word tokens, from\nwhich natural language processing (NLP) models are built and deployed. Though\nnumbers are typically not accounted for distinctly in most NLP tasks, there is\nstill an underlying amount of numeracy already exhibited by NLP models. In this\nwork, we attempt to tap this potential of state-of-the-art NLP models and\ntransfer their ability to boost performance in related tasks. Our proposed\nclassification of numbers into entities helps NLP models perform well on\nseveral tasks, including a handcrafted Fill-In-The-Blank (FITB) task and on\nquestion answering using joint embeddings, outperforming the BERT and RoBERTa\nbaseline classification.", "published": "2022-05-07 05:22:43", "link": "http://arxiv.org/abs/2205.03559v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Computationally Feasible Deep Active Learning", "abstract": "Active learning (AL) is a prominent technique for reducing the annotation\neffort required for training machine learning models. Deep learning offers a\nsolution for several essential obstacles to deploying AL in practice but\nintroduces many others. One of such problems is the excessive computational\nresources required to train an acquisition model and estimate its uncertainty\non instances in the unlabeled pool. We propose two techniques that tackle this\nissue for text classification and tagging tasks, offering a substantial\nreduction of AL iteration duration and the computational overhead introduced by\ndeep acquisition models in AL. We also demonstrate that our algorithm that\nleverages pseudo-labeling and distilled models overcomes one of the essential\nobstacles revealed previously in the literature. Namely, it was shown that due\nto differences between an acquisition model used to select instances during AL\nand a successor model trained on the labeled data, the benefits of AL can\ndiminish. We show that our algorithm, despite using a smaller and faster\nacquisition model, is capable of training a more expressive successor model\nwith higher performance.", "published": "2022-05-07 08:47:42", "link": "http://arxiv.org/abs/2205.03598v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Label-aware Multi-level Contrastive Learning for Cross-lingual Spoken\n  Language Understanding", "abstract": "Despite the great success of spoken language understanding (SLU) in\nhigh-resource languages, it remains challenging in low-resource languages\nmainly due to the lack of labeled training data. The recent multilingual\ncode-switching approach achieves better alignments of model representations\nacross languages by constructing a mixed-language context in zero-shot\ncross-lingual SLU. However, current code-switching methods are limited to\nimplicit alignment and disregard the inherent semantic structure in SLU, i.e.,\nthe hierarchical inclusion of utterances, slots, and words. In this paper, we\npropose to model the utterance-slot-word structure by a multi-level contrastive\nlearning framework at the utterance, slot, and word levels to facilitate\nexplicit alignment. Novel code-switching schemes are introduced to generate\nhard negative examples for our contrastive learning framework. Furthermore, we\ndevelop a label-aware joint model leveraging label semantics to enhance the\nimplicit alignment and feed to contrastive learning. Our experimental results\nshow that our proposed methods significantly improve the performance compared\nwith the strong baselines on two zero-shot cross-lingual SLU benchmark\ndatasets.", "published": "2022-05-07 13:44:28", "link": "http://arxiv.org/abs/2205.03656v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards a Progression-Aware Autonomous Dialogue Agent", "abstract": "Recent advances in large-scale language modeling and generation have enabled\nthe creation of dialogue agents that exhibit human-like responses in a wide\nrange of conversational scenarios spanning a diverse set of tasks, from general\nchit-chat to focused goal-oriented discourse. While these agents excel at\ngenerating high-quality responses that are relevant to prior context, they\nsuffer from a lack of awareness of the overall direction in which the\nconversation is headed, and the likelihood of task success inherent therein.\nThus, we propose a framework in which dialogue agents can evaluate the\nprogression of a conversation toward or away from desired outcomes, and use\nthis signal to inform planning for subsequent responses. Our framework is\ncomposed of three key elements: (1) the notion of a \"global\" dialogue state\n(GDS) space, (2) a task-specific progression function (PF) computed in terms of\na conversation's trajectory through this space, and (3) a planning mechanism\nbased on dialogue rollouts by which an agent may use progression signals to\nselect its next response.", "published": "2022-05-07 17:37:43", "link": "http://arxiv.org/abs/2205.03692v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Empowering parameter-efficient transfer learning by recognizing the\n  kernel structure in self-attention", "abstract": "The massive amount of trainable parameters in the pre-trained language models\n(PLMs) makes them hard to be deployed to multiple downstream tasks. To address\nthis issue, parameter-efficient transfer learning methods have been proposed to\ntune only a few parameters during fine-tuning while freezing the rest. This\npaper looks at existing methods along this line through the \\textit{kernel\nlens}. Motivated by the connection between self-attention in transformer-based\nPLMs and kernel learning, we propose \\textit{kernel-wise adapters}, namely\n\\textit{Kernel-mix}, that utilize the kernel structure in self-attention to\nguide the assignment of the tunable parameters. These adapters use guidelines\nfound in classical kernel learning and enable separate parameter tuning for\neach attention head. Our empirical results, over a diverse set of natural\nlanguage generation and understanding tasks, show that our proposed adapters\ncan attain or improve the strong performance of existing baselines.", "published": "2022-05-07 20:52:54", "link": "http://arxiv.org/abs/2205.03720v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Simple Yet Efficient Method for Adversarial Word-Substitute Attack", "abstract": "NLP researchers propose different word-substitute black-box attacks that can\nfool text classification models. In such attack, an adversary keeps sending\ncrafted adversarial queries to the target model until it can successfully\nachieve the intended outcome. State-of-the-art attack methods usually require\nhundreds or thousands of queries to find one adversarial example. In this\npaper, we study whether a sophisticated adversary can attack the system with\nmuch less queries. We propose a simple yet efficient method that can reduce the\naverage number of adversarial queries by 3-30 times and maintain the attack\neffectiveness. This research highlights that an adversary can fool a deep NLP\nmodel with much less cost.", "published": "2022-05-07 14:20:57", "link": "http://arxiv.org/abs/2206.05015v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Attract me to Buy: Advertisement Copywriting Generation with Multimodal\n  Multi-structured Information", "abstract": "Recently, online shopping has gradually become a common way of shopping for\npeople all over the world. Wonderful merchandise advertisements often attract\nmore people to buy. These advertisements properly integrate multimodal\nmulti-structured information of commodities, such as visual spatial information\nand fine-grained structure information. However, traditional multimodal text\ngeneration focuses on the conventional description of what existed and\nhappened, which does not match the requirement of advertisement copywriting in\nthe real world. Because advertisement copywriting has a vivid language style\nand higher requirements of faithfulness. Unfortunately, there is a lack of\nreusable evaluation frameworks and a scarcity of datasets. Therefore, we\npresent a dataset, E-MMAD (e-commercial multimodal multi-structured\nadvertisement copywriting), which requires, and supports much more detailed\ninformation in text generation. Noticeably, it is one of the largest video\ncaptioning datasets in this field. Accordingly, we propose a baseline method\nand faithfulness evaluation metric on the strength of structured information\nreasoning to solve the demand in reality on this dataset. It surpasses the\nprevious methods by a large margin on all metrics. The dataset and method are\ncoming soon on \\url{https://e-mmad.github.io/e-mmad.net/index.html}.", "published": "2022-05-07 03:33:00", "link": "http://arxiv.org/abs/2205.03534v1", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Good Visual Guidance Makes A Better Extractor: Hierarchical Visual\n  Prefix for Multimodal Entity and Relation Extraction", "abstract": "Multimodal named entity recognition and relation extraction (MNER and MRE) is\na fundamental and crucial branch in information extraction. However, existing\napproaches for MNER and MRE usually suffer from error sensitivity when\nirrelevant object images incorporated in texts. To deal with these issues, we\npropose a novel Hierarchical Visual Prefix fusion NeTwork (HVPNeT) for\nvisual-enhanced entity and relation extraction, aiming to achieve more\neffective and robust performance. Specifically, we regard visual representation\nas pluggable visual prefix to guide the textual representation for error\ninsensitive forecasting decision. We further propose a dynamic gated\naggregation strategy to achieve hierarchical multi-scaled visual features as\nvisual prefix for fusion. Extensive experiments on three benchmark datasets\ndemonstrate the effectiveness of our method, and achieve state-of-the-art\nperformance. Code is available in https://github.com/zjunlp/HVPNeT.", "published": "2022-05-07 02:10:55", "link": "http://arxiv.org/abs/2205.03521v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Mask-based Neural Beamforming for Moving Speakers with\n  Self-Attention-based Tracking", "abstract": "Beamforming is a powerful tool designed to enhance speech signals from the\ndirection of a target source. Computing the beamforming filter requires\nestimating spatial covariance matrices (SCMs) of the source and noise signals.\nTime-frequency masks are often used to compute these SCMs. Most studies of\nmask-based beamforming have assumed that the sources do not move. However,\nsources often move in practice, which causes performance degradation. In this\npaper, we address the problem of mask-based beamforming for moving sources. We\nfirst review classical approaches to tracking a moving source, which perform\nonline or blockwise computation of the SCMs. We show that these approaches can\nbe interpreted as computing a sum of instantaneous SCMs weighted by attention\nweights. These weights indicate which time frames of the signal to consider in\nthe SCM computation. Online or blockwise computation assumes a heuristic and\ndeterministic way of computing these attention weights that, although simple,\nmay not result in optimal performance. We thus introduce a learning-based\nframework that computes optimal attention weights for beamforming. We achieve\nthis using a neural network implemented with self-attention layers. We show\nexperimentally that our proposed framework can greatly improve beamforming\nperformance in moving source situations while maintaining high performance in\nnon-moving situations, thus enabling the development of mask-based beamformers\nrobust to source movements.", "published": "2022-05-07 06:23:00", "link": "http://arxiv.org/abs/2205.03568v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Acoustic echo suppression using a learning-based multi-frame minimum\n  variance distortionless response filter", "abstract": "Distortion resulting from acoustic echo suppression (AES) is a common issue\nin full-duplex communication. To address the distortion problem, a multi-frame\nminimum variance distortionless response (MFMVDR) filtering technique is\nproposed. The MFMVDR filter with parameter estimation which was used in speech\nenhancement problems is extended in this study from a deep learning\nperspective. To alleviate numerical instability of the MFMVDR filter, we\npropose to directly estimate the inverse of the correlation matrix. The AES\nsystem is advantageous in that no double-talk detection is required. The\nnegative scale-invariant signal-to-distortion ratio is employed as the loss\nfunction in training the network at the output of the MFMVDR filter. Simulation\nresults have demonstrated the efficacy of the proposed learning-based AES\nsystem in double-talk, background noise, and nonlinear distortion conditions.", "published": "2022-05-07 08:35:03", "link": "http://arxiv.org/abs/2205.03594v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
