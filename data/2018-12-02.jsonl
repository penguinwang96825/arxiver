{"title": "A Study on Dialogue Reward Prediction for Open-Ended Conversational\n  Agents", "abstract": "The amount of dialogue history to include in a conversational agent is often\nunderestimated and/or set in an empirical and thus possibly naive way. This\nsuggests that principled investigations into optimal context windows are\nurgently needed given that the amount of dialogue history and corresponding\nrepresentations can play an important role in the overall performance of a\nconversational system. This paper studies the amount of history required by\nconversational agents for reliably predicting dialogue rewards. The task of\ndialogue reward prediction is chosen for investigating the effects of varying\namounts of dialogue history and their impact on system performance.\nExperimental results using a dataset of 18K human-human dialogues report that\nlengthy dialogue histories of at least 10 sentences are preferred (25 sentences\nbeing the best in our experiments) over short ones, and that lengthy histories\nare useful for training dialogue reward predictors with strong positive\ncorrelations between target dialogue rewards and predicted ones.", "published": "2018-12-02 08:03:12", "link": "http://arxiv.org/abs/1812.00350v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improved and Robust Controversy Detection in General Web Pages Using\n  Semantic Approaches under Large Scale Conditions", "abstract": "Detecting controversy in general web pages is a daunting task, but\nincreasingly essential to efficiently moderate discussions and effectively\nfilter problematic content. Unfortunately, controversies occur across many\ntopics and domains, with great changes over time. This paper investigates\nneural classifiers as a more robust methodology for controversy detection in\ngeneral web pages. Current models have often cast controversy detection on\ngeneral web pages as Wikipedia linking, or exact lexical matching tasks. The\ndiverse and changing nature of controversies suggest that semantic approaches\nare better able to detect controversy. We train neural networks that can\ncapture semantic information from texts using weak signal data. By leveraging\nthe semantic properties of word embeddings we robustly improve on existing\ncontroversy detection methods. To evaluate model stability over time and to\nunseen topics, we asses model performance under varying training conditions to\ntest cross-temporal, cross-topic, cross-domain performance and annotator\ncongruence. In doing so, we demonstrate that weak-signal based neural\napproaches are closer to human estimates of controversy and are more robust to\nthe inherent variability of controversies.", "published": "2018-12-02 12:41:03", "link": "http://arxiv.org/abs/1812.00382v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Learning Representations of Social Media Users", "abstract": "User representations are routinely used in recommendation systems by platform\ndevelopers, targeted advertisements by marketers, and by public policy\nresearchers to gauge public opinion across demographic groups. Computer\nscientists consider the problem of inferring user representations more\nabstractly; how does one extract a stable user representation - effective for\nmany downstream tasks - from a medium as noisy and complicated as social media?\n  The quality of a user representation is ultimately task-dependent (e.g. does\nit improve classifier performance, make more accurate recommendations in a\nrecommendation system) but there are proxies that are less sensitive to the\nspecific task. Is the representation predictive of latent properties such as a\nperson's demographic features, socioeconomic class, or mental health state? Is\nit predictive of the user's future behavior?\n  In this thesis, we begin by showing how user representations can be learned\nfrom multiple types of user behavior on social media. We apply several\nextensions of generalized canonical correlation analysis to learn these\nrepresentations and evaluate them at three tasks: predicting future hashtag\nmentions, friending behavior, and demographic features. We then show how user\nfeatures can be employed as distant supervision to improve topic model fit.\nFinally, we show how user features can be integrated into and improve existing\nclassifiers in the multitask learning framework. We treat user representations\n- ground truth gender and mental health features - as auxiliary tasks to\nimprove mental health state prediction. We also use distributed user\nrepresentations learned in the first chapter to improve tweet-level stance\nclassifiers, showing that distant user information can inform classification\ntasks at the granularity of a single message.", "published": "2018-12-02 17:57:04", "link": "http://arxiv.org/abs/1812.00436v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Survey of Fake News: Fundamental Theories, Detection Methods, and\n  Opportunities", "abstract": "The explosive growth in fake news and its erosion to democracy, justice, and\npublic trust has increased the demand for fake news detection and intervention.\nThis survey reviews and evaluates methods that can detect fake news from four\nperspectives: (1) the false knowledge it carries, (2) its writing style, (3)\nits propagation patterns, and (4) the credibility of its source. The survey\nalso highlights some potential research tasks based on the review. In\nparticular, we identify and detail related fundamental theories across various\ndisciplines to encourage interdisciplinary research on fake news. We hope this\nsurvey can facilitate collaborative efforts among experts in computer and\ninformation sciences, social sciences, political science, and journalism to\nresearch fake news, where such efforts can lead to fake news detection that is\nnot only efficient but more importantly, explainable.", "published": "2018-12-02 03:27:15", "link": "http://arxiv.org/abs/1812.00315v2", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Towards Automatic Discovery of Cybercrime Supply Chains", "abstract": "Cybercrime forums enable modern criminal entrepreneurs to collaborate with\nother criminals into increasingly efficient and sophisticated criminal\nendeavors. Understanding the connections between different products and\nservices can often illuminate effective interventions. However, generating this\nunderstanding of supply chains currently requires time-consuming manual effort.\n  In this paper, we propose a language-agnostic method to automatically extract\nsupply chains from cybercrime forum posts and replies. Our supply chain\ndetection algorithm can identify 36% and 58% relevant chains within major\nEnglish and Russian forums, respectively, showing improvements over the\nbaselines of 13% and 36%, respectively. Our analysis of the automatically\ngenerated supply chains demonstrates underlying connections between products\nand services within these forums. For example, the extracted supply chain\nilluminated the connection between hack-for-hire services and the selling of\nrare and valuable `OG' accounts, which has only recently been reported. The\nunderstanding of connections between products and services exposes potentially\neffective intervention points.", "published": "2018-12-02 12:38:58", "link": "http://arxiv.org/abs/1812.00381v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
