{"title": "AI/ML Life Cycle Management for Interoperable AI Native RAN", "abstract": "Artificial intelligence (AI) and machine learning (ML) models are rapidly\npermeating the 5G Radio Access Network (RAN), powering beam management, channel\nstate information (CSI) feedback, positioning, and mobility prediction.\nHowever, without a standardized life-cycle management (LCM) framework,\nchallenges, such as model drift, vendor lock-in, and limited transparency,\nhinder large-scale adoption. 3GPP Releases 16-20 progressively evolve AI/ML\nfrom experimental features to managed, interoperable network functions.\nBeginning with the Network Data Analytics Function (NWDAF) in Rel-16,\nsubsequent releases introduced standardized interfaces for model transfer,\nexecution, performance monitoring, and closed-loop control, culminating in\nRel-20's two-sided CSI-compression Work Item and vendor-agnostic LCM profile.\nThis article reviews the resulting five-block LCM architecture, KPI-driven\nmonitoring mechanisms, and inter-vendor collaboration schemes, while\nidentifying open challenges in resource-efficient monitoring, environment drift\ndetection, intelligent decision-making, and flexible model training. These\ndevelopments lay the foundation for AI-native transceivers as a key enabler for\n6G.", "published": "2025-07-24 16:04:59", "link": "http://arxiv.org/abs/2507.18538v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Role of Age and Semantics of Information in Remote Estimation of Markov Sources", "abstract": "This paper investigates the semantics-aware remote estimation of a\nfinite-state Markov chain. We employ the maximum a posteriori (MAP) estimator\nand aim to devise a transmission policy to optimize estimation performance\nsubject to a transmission frequency constraint. We leverage two metrics, namely\nthe Age of Consecutive Error (AoCE) and the Age of Information (AoI), to\nquantify, respectively, the significance of estimation error at the transmitter\nand the predictability of outdated information at the receiver. The optimal\ntransmission problem is formulated as a constrained Markov decision process\n(CMDP) with unbounded costs. We show the existence of an optimal simple mixture\npolicy, which randomly selects between two deterministic switching policies\nwith a fixed probability. Notably, each switching policy triggers a\ntransmission only when the AoCE exceeds a threshold value that depends on both\nthe AoI and the instantaneous estimation error. We further derive sufficient\nconditions under which the switching policy reduces to a simple threshold\npolicy; that is, it admits identical thresholds for all estimation errors.\nLeveraging these results, we develop an efficient structure-aware algorithm,\nInsec-SPI, that computes the optimal policy with reduced computation overhead.\nOur results demonstrate that incorporating both AoI and AoCE yields\nsignificantly improved estimation quality compared to using either metric\nalone.", "published": "2025-07-24 15:36:27", "link": "http://arxiv.org/abs/2507.18514v1", "categories": ["cs.IT", "cs.NI", "cs.SY", "eess.SY", "math.IT"], "primary_category": "cs.IT"}
{"title": "Hermitian hull of some GRS codes and new EAQMDS codes", "abstract": "We study the Hermitian hull of a particular family of generalized\nReed-Solomon codes. The problem of computing the dimension of the hull is\ntranslated to a counting problem in a lattice. By solving this problem, we\nprovide explicit formulas for the dimension of the hull, which determines the\nminimum number required of maximally entangled pairs for the associated\nentanglement-assisted quantum error-correcting codes. This flexible\nconstruction allows to obtain a wide range of entanglement-assisted quantum MDS\ncodes, as well as new parameters.", "published": "2025-07-24 12:33:08", "link": "http://arxiv.org/abs/2507.18361v1", "categories": ["cs.IT", "math.IT", "81P70 (Primary) 94B05 (Secondary)"], "primary_category": "cs.IT"}
{"title": "Covert Communications in MEC-Based Networked ISAC Systems Towards Low-Altitude Economy", "abstract": "Low-altitude economy (LAE) is an emerging business model, which heavily\nrelies on integrated sensing and communications (ISAC), mobile edge computing\n(MEC), and covert communications. This paper investigates the convert\ntransmission design in MEC-based networked ISAC systems towards LAE, where an\nMEC server coordinates multiple access points to simultaneously receive\ncomputation tasks from multiple unmanned aerial vehicles (UAVs), locate a\ntarget in a sensing area, and maintain UAVs' covert transmission against\nmultiple wardens. We first derive closed-form expressions for the detection\nerror probability (DEP) at wardens. Then, we formulate a total energy\nconsumption minimization problem by optimizing communication, sensing, and\ncomputation resources as well as UAV trajectories, subject to the requirements\non quality of MEC services, DEP, and radar signal-to-interference-and-noise\nratio, and the causality of UAV trajectories. An alternating optimization based\nalgorithm is proposed to handle the considered problem, which decomposes it\ninto two subproblems: joint optimization of communication, sensing, and\ncomputation resources, and UAV trajectory optimization. The former is addressed\nby a successive convex approximation based algorithm, while the latter is\nsolved via a trust-region based algorithm. Simulations validate the\neffectiveness of the proposed algorithm compared with various benchmarks, and\nreveal the trade-offs among communication, sensing, and computation in LAE\nsystems.", "published": "2025-07-24 08:53:08", "link": "http://arxiv.org/abs/2507.18194v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "GNSS Jammer and Spoofer Mitigation via Multi-Antenna Processing", "abstract": "Modern positioning relies on radio signals from global navigation satellite\nsystems (GNSS). Their low receive power renders these radio signals susceptible\nto jamming attacks, in which malicious transmitters emit strong interference to\ndisrupt signal acquisition. Moreover, GNSS are vulnerable to spoofing attacks,\nin which malicious transmitters mimic legitimate satellites by transmitting\nspurious GNSS signals. We propose SCHIEBER, a novel method for multi-antenna\nGNSS receivers that mitigates jammers as well as spoofers without requiring any\nprior knowledge of the receiver position or attack type: Jammers are mitigated\nduring signal acquisition using a recently developed adaptive spatial filtering\ntechnique. Spoofers are identified and rejected after signal acquisition using\na novel approach that tests the consistency of acquired signals by comparing\ntheir respective direction of arrival (DoA) and pseudorange estimates in a test\nthat is invariant with respect to the unknown receiver position. We demonstrate\nthe efficacy of our method using extensive simulations of a GPS L1 C/A system\nunder spoofing and jamming attacks.", "published": "2025-07-24 08:04:26", "link": "http://arxiv.org/abs/2507.18166v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Information Entropy-Based Framework for Quantifying Tortuosity in Meibomian Gland Uneven Atrophy", "abstract": "In the medical image analysis field, precise quantification of curve\ntortuosity plays a critical role in the auxiliary diagnosis and pathological\nassessment of various diseases. In this study, we propose a novel framework for\ntortuosity quantification and demonstrate its effectiveness through the\nevaluation of meibomian gland atrophy uniformity,serving as a representative\napplication scenario.\n  We introduce an information entropy-based tortuosity quantification framework\nthat integrates probability modeling with entropy theory and incorporates\ndomain transformation of curve data. Unlike traditional methods such as\ncurvature or arc-chord ratio, this approach evaluates the tortuosity of a\ntarget curve by comparing it to a designated reference curve. Consequently, it\nis more suitable for tortuosity assessment tasks in medical data where\nbiologically plausible reference curves are available, providing a more robust\nand objective evaluation metric without relying on idealized straight-line\ncomparisons.\n  First, we conducted numerical simulation experiments to preliminarily assess\nthe stability and validity of the method. Subsequently, the framework was\napplied to quantify the spatial uniformity of meibomian gland atrophy and to\nanalyze the difference in this uniformity between \\textit{Demodex}-negative and\n\\textit{Demodex}-positive patient groups. The results demonstrated a\nsignificant difference in tortuosity-based uniformity between the two groups,\nwith an area under the curve of 0.8768, sensitivity of 0.75, and specificity of\n0.93. These findings highlight the clinical utility of the proposed framework\nin curve tortuosity analysis and its potential as a generalizable tool for\nquantitative morphological evaluation in medical diagnostics.", "published": "2025-07-24 06:51:10", "link": "http://arxiv.org/abs/2507.18135v1", "categories": ["cs.CV", "cs.IT", "math.IT"], "primary_category": "cs.CV"}
{"title": "A Novel Coded Computing Approach for Distributed Multi-Task Learning", "abstract": "Distributed multi-task learning (DMTL) effectively improves model\ngeneralization performance through the collaborative training of multiple\nrelated models. However, in large-scale learning scenarios, communication\nbottlenecks severely limit practical system performance. In this paper, we\ninvestigate the communication bottleneck within a typical DMTL system that\nemploys non-linear global updates. This system involves distributed workers,\nassisted by a central server, who collaboratively learn distinct models derived\nfrom a non-linear aggregation of their local model parameters. We first\ncharacterize the communication process as a matrix decomposition problem. It\ntransforms workers' data storage constraints into structural characteristics of\nthe uplink encoding matrix, and worker data retrieval demands into Maximum\nDistance Separable (MDS) properties of the downlink encoding matrix. Building\non this, we propose a novel coded DTML scheme that can greatly reduce the\ncommunication cost of the DTML with heterogeneous data placement. Theoretical\nanalysis demonstrates that the proposed scheme achieves the theoretical lower\nbound for communication overhead under mild conditions. Remarkably, this\noptimality holds for both traditional homogeneous computing environments and\nvarious heterogeneous scenarios. Furthermore, our scheme is extensible to a\ndistributed linearly separable computation problem where the target function\ninvolves multiple linear combinations of local update values. This indicates\nthat our scheme offers a new way of tackling heterogeneous data placement\nchallenges in various distributed applications.", "published": "2025-07-24 01:55:15", "link": "http://arxiv.org/abs/2507.18025v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Moving Out: Physically-grounded Human-AI Collaboration", "abstract": "The ability to adapt to physical actions and constraints in an environment is\ncrucial for embodied agents (e.g., robots) to effectively collaborate with\nhumans. Such physically grounded human-AI collaboration must account for the\nincreased complexity of the continuous state-action space and constrained\ndynamics caused by physical constraints. In this paper, we introduce\n\\textit{Moving Out}, a new human-AI collaboration benchmark that resembles a\nwide range of collaboration modes affected by physical attributes and\nconstraints, such as moving heavy items together and maintaining consistent\nactions to move a big item around a corner. Using Moving Out, we designed two\ntasks and collected human-human interaction data to evaluate models' abilities\nto adapt to diverse human behaviors and unseen physical attributes. To address\nthe challenges in physical environments, we propose a novel method, BASS\n(Behavior Augmentation, Simulation, and Selection), to enhance the diversity of\nagents and their understanding of the outcome of actions. Our experiments show\nthat BASS outperforms state-of-the-art models in AI-AI and human-AI\ncollaboration. The project page is available at\n\\href{https://live-robotics-uva.github.io/movingout_ai/}{https://live-robotics-uva.github.io/movingout\\_ai/}.", "published": "2025-07-24 17:57:18", "link": "http://arxiv.org/abs/2507.18623v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Remembering the Markov Property in Cooperative MARL", "abstract": "Cooperative multi-agent reinforcement learning (MARL) is typically formalised\nas a Decentralised Partially Observable Markov Decision Process (Dec-POMDP),\nwhere agents must reason about the environment and other agents' behaviour. In\npractice, current model-free MARL algorithms use simple recurrent function\napproximators to address the challenge of reasoning about others using partial\ninformation. In this position paper, we argue that the empirical success of\nthese methods is not due to effective Markov signal recovery, but rather to\nlearning simple conventions that bypass environment observations and memory.\nThrough a targeted case study, we show that co-adapting agents can learn\nbrittle conventions, which then fail when partnered with non-adaptive agents.\nCrucially, the same models can learn grounded policies when the task design\nnecessitates it, revealing that the issue is not a fundamental limitation of\nthe learning models but a failure of the benchmark design. Our analysis also\nsuggests that modern MARL environments may not adequately test the core\nassumptions of Dec-POMDPs. We therefore advocate for new cooperative\nenvironments built upon two core principles: (1) behaviours grounded in\nobservations and (2) memory-based reasoning about other agents, ensuring\nsuccess requires genuine skill rather than fragile, co-adapted agreements.", "published": "2025-07-24 11:59:42", "link": "http://arxiv.org/abs/2507.18333v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Designing Value-Aligned Traffic Agents through Conflict Sensitivity", "abstract": "Autonomous traffic agents (ATAs) are expected to act in ways tat are not only\nsafe, but also aligned with stakeholder values across legal, social, and moral\ndimensions. In this paper, we adopt an established formal model of conflict\nfrom epistemic game theory to support the development of such agents. We focus\non value conflicts-situations in which agents face competing goals rooted in\nvalue-laden situations and show how conflict analysis can inform key phases of\nthe design process. This includes value elicitation, capability specification,\nexplanation, and adaptive system refinement. We elaborate and apply the concept\nof Value-Aligned Operational Design Domains (VODDs) to structure autonomy in\naccordance with contextual value priorities. Our approach shifts the emphasis\nfrom solving moral dilemmas at runtime to anticipating and structuring\nvalue-sensitive behaviour during development.", "published": "2025-07-24 10:37:00", "link": "http://arxiv.org/abs/2507.18284v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation", "abstract": "Multi-agent systems (MAS) based on large language models (LLMs) have emerged\nas a powerful solution for dealing with complex problems across diverse\ndomains. The effectiveness of MAS is critically dependent on its collaboration\ntopology, which has become a focal point for automated design research.\nHowever, existing approaches are fundamentally constrained by their reliance on\na template graph modification paradigm with a predefined set of agents and\nhard-coded interaction structures, significantly limiting their adaptability to\ntask-specific requirements. To address these limitations, we reframe MAS design\nas a conditional autoregressive graph generation task, where both the system\ncomposition and structure are designed jointly. We propose ARG-Designer, a\nnovel autoregressive model that operationalizes this paradigm by constructing\nthe collaboration graph from scratch. Conditioned on a natural language task\nquery, ARG-Designer sequentially and dynamically determines the required number\nof agents, selects their appropriate roles from an extensible pool, and\nestablishes the optimal communication links between them. This generative\napproach creates a customized topology in a flexible and extensible manner,\nprecisely tailored to the unique demands of different tasks. Extensive\nexperiments across six diverse benchmarks demonstrate that ARG-Designer not\nonly achieves state-of-the-art performance but also enjoys significantly\ngreater token efficiency and enhanced extensibility. The source code of\nARG-Designer is available at https://github.com/Shiy-Li/ARG-Designer.", "published": "2025-07-24 09:17:41", "link": "http://arxiv.org/abs/2507.18224v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Multi-Agent Guided Policy Optimization", "abstract": "Due to practical constraints such as partial observability and limited\ncommunication, Centralized Training with Decentralized Execution (CTDE) has\nbecome the dominant paradigm in cooperative Multi-Agent Reinforcement Learning\n(MARL). However, existing CTDE methods often underutilize centralized training\nor lack theoretical guarantees. We propose Multi-Agent Guided Policy\nOptimization (MAGPO), a novel framework that better leverages centralized\ntraining by integrating centralized guidance with decentralized execution.\nMAGPO uses an auto-regressive joint policy for scalable, coordinated\nexploration and explicitly aligns it with decentralized policies to ensure\ndeployability under partial observability. We provide theoretical guarantees of\nmonotonic policy improvement and empirically evaluate MAGPO on 43 tasks across\n6 diverse environments. Results show that MAGPO consistently outperforms strong\nCTDE baselines and matches or surpasses fully centralized approaches, offering\na principled and practical solution for decentralized multi-agent learning. Our\ncode and experimental data can be found in https://github.com/liyheng/MAGPO.", "published": "2025-07-24 03:22:21", "link": "http://arxiv.org/abs/2507.18059v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Information-minimizing stationary financial market dynamics", "abstract": "The paper derives the dynamics of a financial market from basic mathematical\nprinciples. It models the market dynamics using independent stationary scalar\ndiffusions, assumes the existence of its growth optimal portfolio (GOP),\ninterprets the market as a communication system, and minimizes, in an\ninformation-theoretical sense, the joint information of the risk-neutral\npricing measure with respect to the real-world probability measure. In this\ninformation-minimizing market, its basic independent securities, their sums,\nminimum variance portfolio, and GOP, as well as the GOP of the entire market,\nrepresent squared radial Ornstein-Uhlenbeck processes with additivity and\nself-similarity properties.", "published": "2025-07-24 13:26:28", "link": "http://arxiv.org/abs/2507.18395v1", "categories": ["q-fin.MF", "62P05, 60G35, 62P20"], "primary_category": "q-fin.MF"}
{"title": "Pathwise analysis of log-optimal portfolios", "abstract": "Based on the theory of c\\`adl\\`ag rough paths, we develop a pathwise approach\nto analyze stability and approximation properties of portfolios along\nindividual price trajectories generated by standard models of financial\nmarkets. As a prototypical example from portfolio theory, we study the\nlog-optimal portfolio in a classical investment-consumption optimization\nproblem on a frictionless financial market modelled by an It\\^o diffusion\nprocess. We identify a fully deterministic framework that enables a pathwise\nconstruction of the log-optimal portfolio, for which we then establish pathwise\nstability estimates with respect to the underlying model parameters. We also\nderive pathwise error estimates arising from the time-discretization of the\nlog-optimal portfolio and its associated capital process.", "published": "2025-07-24 09:22:26", "link": "http://arxiv.org/abs/2507.18232v1", "categories": ["q-fin.MF", "math.PR", "q-fin.PM", "91G10, 60L20"], "primary_category": "q-fin.MF"}
{"title": "FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs", "abstract": "Opinions expressed in online finance-related textual data are having an\nincreasingly profound impact on trading decisions and market movements. This\ntrend highlights the vital role of sentiment analysis as a tool for quantifying\nthe nature and strength of such opinions. With the rapid development of\nGenerative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs)\nhave become the de facto standard for financial sentiment analysis. However,\nthe SFT paradigm can lead to memorization of the training data and often fails\nto generalize to unseen samples. This is a critical limitation in financial\ndomains, where models must adapt to previously unobserved events and the\nnuanced, domain-specific language of finance. To this end, we introduce FinDPO,\nthe first finance-specific LLM framework based on post-training human\npreference alignment via Direct Preference Optimization (DPO). The proposed\nFinDPO achieves state-of-the-art performance on standard sentiment\nclassification benchmarks, outperforming existing supervised fine-tuned models\nby 11% on the average. Uniquely, the FinDPO framework enables the integration\nof a fine-tuned causal LLM into realistic portfolio strategies through a novel\n'logit-to-score' conversion, which transforms discrete sentiment predictions\ninto continuous, rankable sentiment scores (probabilities). In this way,\nsimulations demonstrate that FinDPO is the first sentiment-based approach to\nmaintain substantial positive returns of 67% annually and strong risk-adjusted\nperformance, as indicated by a Sharpe ratio of 2.0, even under realistic\ntransaction costs of 5 basis points (bps).", "published": "2025-07-24 13:57:05", "link": "http://arxiv.org/abs/2507.18417v1", "categories": ["cs.CL", "cs.LG", "q-fin.ST", "q-fin.TR"], "primary_category": "cs.CL"}
{"title": "Streaming Sortformer: Speaker Cache-Based Online Speaker Diarization with Arrival-Time Ordering", "abstract": "This paper presents a streaming extension for the Sortformer speaker\ndiarization framework, whose key property is the arrival-time ordering of\noutput speakers. The proposed approach employs an Arrival-Order Speaker Cache\n(AOSC) to store frame-level acoustic embeddings of previously observed\nspeakers. Unlike conventional speaker-tracing buffers, AOSC orders embeddings\nby speaker index corresponding to their arrival time order, and is dynamically\nupdated by selecting frames with the highest scores based on the model's past\npredictions. Notably, the number of stored embeddings per speaker is determined\ndynamically by the update mechanism, ensuring efficient cache utilization and\nprecise speaker tracking. Experiments on benchmark datasets confirm the\neffectiveness and flexibility of our approach, even in low-latency setups.\nThese results establish Streaming Sortformer as a robust solution for real-time\nmulti-speaker tracking and a foundation for streaming multi-talker speech\nprocessing.", "published": "2025-07-24 14:30:48", "link": "http://arxiv.org/abs/2507.18446v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation", "abstract": "The training of high-quality, robust machine learning models for\nspeech-driven 3D facial animation requires a large, diverse dataset of\nhigh-quality audio-animation pairs. To overcome the lack of such a dataset,\nrecent work has introduced large pre-trained speech encoders that are robust to\nvariations in the input audio and, therefore, enable the facial animation model\nto generalize across speakers, audio quality, and languages. However, the\nresulting facial animation models are prohibitively large and lend themselves\nonly to offline inference on a dedicated machine. In this work, we explore\non-device, real-time facial animation models in the context of game\ndevelopment. We overcome the lack of large datasets by using hybrid knowledge\ndistillation with pseudo-labeling. Given a large audio dataset, we employ a\nhigh-performing teacher model to train very small student models. In contrast\nto the pre-trained speech encoders, our student models only consist of\nconvolutional and fully-connected layers, removing the need for attention\ncontext or recurrent updates. In our experiments, we demonstrate that we can\nreduce the memory footprint to up to 3.4 MB and required future audio context\nto up to 81 ms while maintaining high-quality animations. This paves the way\nfor on-device inference, an important step towards realistic, model-driven\ndigital characters.", "published": "2025-07-24 12:25:12", "link": "http://arxiv.org/abs/2507.18352v1", "categories": ["cs.GR", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
{"title": "Speech Enhancement with Dual-path Multi-Channel Linear Prediction Filter and Multi-norm Beamforming", "abstract": "In this paper, we propose a speech enhancement method us ing dual-path\nMulti-Channel Linear Prediction (MCLP) filters\n  and multi-norm beamforming. Specifically, the MCLP part in\n  the proposed method is designed with dual-path filters in both\n  time and frequency dimensions. For the beamforming part, we\n  minimize the power of the microphone array output as well as\n  the l1 norm of the denoised signals while preserving source sig nals from the\ntarget directions. An efficient method to select the\n  prediction orders in the dual-path filters is also proposed, which\n  is robust for signals with different reverberation time (T60) val ues and can\nbe applied to other MCLP-based methods. Eval uations demonstrate that our\nproposed method outperforms the\n  baseline methods for speech enhancement, particularly in high\n  reverberation scenarios.", "published": "2025-07-24 12:22:45", "link": "http://arxiv.org/abs/2507.18350v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Bird Classification with Primary Color Additives", "abstract": "We address the problem of classifying bird species using their song\nrecordings, a challenging task due to environmental noise, overlapping\nvocalizations, and missing labels. Existing models struggle with low-SNR or\nmulti-species recordings. We hypothesize that birds can be classified by\nvisualizing their pitch pattern, speed, and repetition, collectively called\nmotifs. Deep learning models applied to spectrogram images help, but similar\nmotifs across species cause confusion. To mitigate this, we embed frequency\ninformation into spectrograms using primary color additives. This enhances\nspecies distinction and improves classification accuracy. Our experiments show\nthat the proposed approach achieves statistically significant gains over models\nwithout colorization and surpasses the BirdCLEF 2024 winner, improving F1 by\n7.3%, ROC-AUC by 6.2%, and CMAP by 6.6%. These results demonstrate the\neffectiveness of incorporating frequency information via colorization.", "published": "2025-07-24 12:05:17", "link": "http://arxiv.org/abs/2507.18334v1", "categories": ["cs.CV", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "SpecASR: Accelerating LLM-based Automatic Speech Recognition via Speculative Decoding", "abstract": "Large language model (LLM)-based automatic speech recognition (ASR) has\nrecently attracted a lot of attention due to its high recognition accuracy and\nenhanced multi-dialect support. However, the high decoding latency of LLMs\nchallenges the real-time ASR requirements. Although speculative decoding has\nbeen explored for better decoding efficiency, they usually ignore the key\ncharacteristics of the ASR task and achieve limited speedup. To further reduce\nthe real-time ASR latency, in this paper, we propose a novel speculative\ndecoding framework specialized for ASR, dubbed SpecASR. SpecASR is developed\nbased on our core observation that ASR decoding is audio-conditioned, which\nresults in high output alignment between small and large ASR models, even given\noutput mismatches in intermediate decoding steps. Therefore, SpecASR features\nan adaptive draft sequence generation process that dynamically modifies the\ndraft sequence length to maximize the token acceptance length. SpecASR further\nproposes a draft sequence recycling strategy that reuses the previously\ngenerated draft sequence to reduce the draft ASR model latency. Moreover, a\ntwo-pass sparse token tree generation algorithm is also proposed to balance the\nlatency of draft and target ASR models. With extensive experimental results, we\ndemonstrate SpecASR achieves 3.04x-3.79x and 1.25x-1.84x speedup over the\nbaseline autoregressive decoding and speculative decoding, respectively,\nwithout any loss in recognition accuracy.", "published": "2025-07-24 08:27:53", "link": "http://arxiv.org/abs/2507.18181v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Recent Trends in Distant Conversational Speech Recognition: A Review of CHiME-7 and 8 DASR Challenges", "abstract": "The CHiME-7 and 8 distant speech recognition (DASR) challenges focus on\nmulti-channel, generalizable, joint automatic speech recognition (ASR) and\ndiarization of conversational speech. With participation from 9 teams\nsubmitting 32 diverse systems, these challenges have contributed to\nstate-of-the-art research in the field. This paper outlines the challenges'\ndesign, evaluation metrics, datasets, and baseline systems while analyzing key\ntrends from participant submissions. From this analysis it emerges that: 1)\nMost participants use end-to-end (e2e) ASR systems, whereas hybrid systems were\nprevalent in previous CHiME challenges. This transition is mainly due to the\navailability of robust large-scale pre-trained models, which lowers the data\nburden for e2e-ASR. 2) Despite recent advances in neural speech separation and\nenhancement (SSE), all teams still heavily rely on guided source separation,\nsuggesting that current neural SSE techniques are still unable to reliably deal\nwith complex scenarios and different recording setups. 3) All best systems\nemploy diarization refinement via target-speaker diarization techniques.\nAccurate speaker counting in the first diarization pass is thus crucial to\navoid compounding errors and CHiME-8 DASR participants especially focused on\nthis part. 4) Downstream evaluation via meeting summarization can correlate\nweakly with transcription quality due to the remarkable effectiveness of\nlarge-language models in handling errors. On the NOTSOFAR-1 scenario, even\nsystems with over 50\\% time-constrained minimum permutation WER can perform\nroughly on par with the most effective ones (around 11\\%). 5) Despite recent\nprogress, accurately transcribing spontaneous speech in challenging acoustic\nenvironments remains difficult, even when using computationally intensive\nsystem ensembles.", "published": "2025-07-24 07:56:24", "link": "http://arxiv.org/abs/2507.18161v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "GOAT-SLM: A Spoken Language Model with Paralinguistic and Speaker Characteristic Awareness", "abstract": "Recent advances in end-to-end spoken language models (SLMs) have\nsignificantly improved the ability of AI systems to engage in natural spoken\ninteractions. However, most existing models treat speech merely as a vehicle\nfor linguistic content, often overlooking the rich paralinguistic and speaker\ncharacteristic cues embedded in human speech, such as dialect, age, emotion,\nand non-speech vocalizations. In this work, we introduce GOAT-SLM, a novel\nspoken language model with paralinguistic and speaker characteristic awareness,\ndesigned to extend spoken language modeling beyond text semantics. GOAT-SLM\nadopts a dual-modality head architecture that decouples linguistic modeling\nfrom acoustic realization, enabling robust language understanding while\nsupporting expressive and adaptive speech generation. To enhance model\nefficiency and versatility, we propose a modular, staged training strategy that\nprogressively aligns linguistic, paralinguistic, and speaker characteristic\ninformation using large-scale speech-text corpora. Experimental results on\nTELEVAL, a multi-dimensional evaluation benchmark, demonstrate that GOAT-SLM\nachieves well-balanced performance across both semantic and non-semantic tasks,\nand outperforms existing open-source models in handling emotion, dialectal\nvariation, and age-sensitive interactions. This work highlights the importance\nof modeling beyond linguistic content and advances the development of more\nnatural, adaptive, and socially aware spoken language systems.", "published": "2025-07-24 06:10:29", "link": "http://arxiv.org/abs/2507.18119v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios", "abstract": "Spoken language models (SLMs) have seen rapid progress in recent years, along\nwith the development of numerous benchmarks for evaluating their performance.\nHowever, most existing benchmarks primarily focus on evaluating whether SLMs\ncan perform complex tasks comparable to those tackled by large language models\n(LLMs), often failing to align with how users naturally interact in real-world\nconversational scenarios. In this paper, we propose TELEVAL, a dynamic\nbenchmark specifically designed to evaluate SLMs' effectiveness as\nconversational agents in realistic Chinese interactive settings. TELEVAL\ndefines three evaluation dimensions: Explicit Semantics, Paralinguistic and\nImplicit Semantics, and System Abilities. It adopts a dialogue format\nconsistent with real-world usage and evaluates text and audio outputs\nseparately. TELEVAL particularly focuses on the model's ability to extract\nimplicit cues from user speech and respond appropriately without additional\ninstructions. Our experiments demonstrate that despite recent progress,\nexisting SLMs still have considerable room for improvement in natural\nconversational tasks. We hope that TELEVAL can serve as a user-centered\nevaluation framework that directly reflects the user experience and contributes\nto the development of more capable dialogue-oriented SLMs.", "published": "2025-07-24 03:23:55", "link": "http://arxiv.org/abs/2507.18061v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The TEA-ASLP System for Multilingual Conversational Speech Recognition and Speech Diarization in MLC-SLM 2025 Challenge", "abstract": "This paper presents the TEA-ASLP's system submitted to the MLC-SLM 2025\nChallenge, addressing multilingual conversational automatic speech recognition\n(ASR) in Task I and speech diarization ASR in Task II. For Task I, we enhance\nIdeal-LLM model by integrating known language identification and a multilingual\nMOE LoRA structure, along with using CTC-predicted tokens as prompts to improve\nautoregressive generation. The model is trained on approximately 180k hours of\nmultilingual ASR data. In Task II, we replace the baseline English-Chinese\nspeaker diarization model with a more suitable English-only version. Our\napproach achieves a 30.8% reduction in word error rate (WER) compared to the\nbaseline speech language model, resulting in a final WER of 9.60% in Task I and\na time-constrained minimum-permutation WER of 17.49% in Task II, earning first\nand second place in the respective challenge tasks.", "published": "2025-07-24 02:56:29", "link": "http://arxiv.org/abs/2507.18051v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Foundation Model for Massive MIMO Precoding with an Adaptive per-User Rate-Power Tradeoff", "abstract": "Deep learning (DL) has emerged as a solution for precoding in massive\nmultiple-input multiple-output (mMIMO) systems due to its capacity to learn the\ncharacteristics of the propagation environment. However, training such a model\nrequires high-quality, local datasets at the deployment site, which are often\ndifficult to collect. We propose a transformer-based foundation model for mMIMO\nprecoding that seeks to minimize the energy consumption of the transmitter\nwhile dynamically adapting to per-user rate requirements. At equal energy\nconsumption, zero-shot deployment of the proposed foundation model\nsignificantly outperforms zero forcing, and approaches weighted minimum mean\nsquared error performance with 8x less complexity. To address model adaptation\nin data-scarce settings, we introduce a data augmentation method that finds\ntraining samples similar to the target distribution by computing the cosine\nsimilarity between the outputs of the pre-trained feature extractor. Our work\nenables the implementation of DL-based solutions in practice by addressing\nchallenges of data availability and training complexity. Moreover, the ability\nto dynamically configure per-user rate requirements can be leveraged by higher\nlevel resource allocation and scheduling algorithms for greater control over\nenergy efficiency, spectral efficiency and fairness.", "published": "2025-07-24 17:10:06", "link": "http://arxiv.org/abs/2507.18587v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "Quantized Signal Recovery with Interference via Parametrized Look-Up Tables", "abstract": "Efficient all-digital post-correction of low-resolution analog-to-digital\nconverters can be achieved by using Look-Up Tables (LUTs). The performance of a\nLUT can be optimized by incorporating a parametric model for the expected input\nsignal, noise level, and interference signals. We evaluate three analytical\nestimators for integration with parametrized LUTs, especially with applications\nto low-resolution, non-linear, or wideband quantizers. We also propose several\napproximations to improve tractability of the estimation problem for\nPhase-Shift Keyed input signals and Linear Frequency Modulated interference\nsignals. Simulated results validate the ability of our estimator to recover the\ninstantaneous value of the desired input signal in real-time with a high degree\nof accuracy. This includes cancellation of harmonic distortion that aliases\ninto the desired signal bandwidth from front-end saturation due to high-power\nout-of-band interference. Our estimators are shown to achieve a significant\ngain over conventional linear-filtering techniques while also being robust to\nchanges in input parameters, non-linear quantizers, and time-variant\ninterference sources. For a tone input quantized to 3 bits and estimated with a\nfixed 12-tap model order we achieve $>$10 dB improvement in Mean Square Error\nand $>$20 dBc improvement in Spurious-Free Dynamic Range.", "published": "2025-07-24 12:48:00", "link": "http://arxiv.org/abs/2507.18370v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation", "abstract": "Electrocardiogram (ECG) delineation, the segmentation of meaningful waveform\nfeatures, is critical for clinical diagnosis. Despite recent advances using\ndeep learning, progress has been limited by the scarcity of publicly available\nannotated datasets. Semi-supervised learning presents a promising solution by\nleveraging abundant unlabeled ECG data. In this study, we present the first\nsystematic benchmark for semi-supervised semantic segmentation (SemiSeg) in ECG\ndelineation. We curated and unified multiple public datasets, including\npreviously underused sources, to support robust and diverse evaluation. We\nadopted five representative SemiSeg algorithms from computer vision,\nimplemented them on two different architectures: the convolutional network and\nthe transformer, and evaluated them in two different settings: in-domain and\ncross-domain. Additionally, we propose ECG-specific training configurations and\naugmentation strategies and introduce a standardized evaluation framework. Our\nresults show that the transformer outperforms the convolutional network in\nsemi-supervised ECG delineation. We anticipate that our benchmark will serve as\na foundation for advancing semi-supervised ECG delineation methods and will\nfacilitate further research in this domain.", "published": "2025-07-24 11:49:46", "link": "http://arxiv.org/abs/2507.18323v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.SP"], "primary_category": "cs.CV"}
{"title": "ICWLM: A Multi-Task Wireless Large Model via In-Context Learning", "abstract": "The rapid evolution of wireless communication technologies, particularly\nmassive multiple-input multiple-output (mMIMO) and millimeter-wave (mmWave),\nintroduces significant network complexity and computational demands.\nSignificant research efforts have been made to improve physical layer\nperformance by resorting to deep learning (DL) methods, which, however, are\nusually task-specific and struggle with data scarcity and generalization. To\naddress these challenges, we propose a novel In-Context Wireless Large Model\n(ICWLM), a wireless-native foundation model designed for simultaneous\nmulti-task learning at the physical layer. Unlike conventional methods that\nadapt wireless data to pre-trained large language models (LLMs), ICWLM is\ntrained directly on large-scale, mixed wireless datasets from scratch. It\njointly solves multiple classical physical layer problems, including multi-user\nprecoding (sum-rate maximization and max-min SINR) and channel prediction. A\nkey innovation of ICWLM is its utilization of in-context learning (ICL),\nenabling the model to adapt to varying system configurations and channel\nconditions with minimal demonstration pairs, eliminating the need for extensive\nretraining. Furthermore, we employ the Dynamic Weight Averaging (DWA) algorithm\nto dynamically balance the individual task losses during multi-task training,\nensuring efficient and stable learning across diverse objectives. Extensive\nsimulation results demonstrate that ICWLM achieves competitive performance\ncompared to task-specific methods while exhibiting remarkable generalization\ncapabilities to unseen system configurations. This work offers a promising\nparadigm for developing unified and adaptive AI models for future wireless\nnetworks, potentially reducing deployment complexity and enhancing intelligent\nresource management.", "published": "2025-07-24 08:04:39", "link": "http://arxiv.org/abs/2507.18167v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Envelope Control Enabled Probabilistic Shaping for Peak Power Constrained IM DD Systems", "abstract": "Probabilistic shaping (PS) has attracted significant attention in\nintensity-modulation and direct-detection (IM-DD) systems. However, due to the\nunique system model and inherent constraints, the effective application of the\nPS technique is still an open question in IM-DD systems, particularly in\nsystems with memory effects. In this paper, a novel indirect PS scheme tailored\nfor peak power constrained (PPC) IM-DD systems is proposed. The key idea lies\nin strategically controlling the signal envelope to mitigate memory-induced\nimpairments, such as nonlinearity, overshoot, peak-to-average power ratio\nenhancement, etc. The proposed scheme incorporates a dynamic selective mapping\n(DSLM) mechanism at the transmitter, enabling an untypical bit-to-symbol\nmapping in which the current symbol is not only determined by the current bits\npattern but also by previously generated symbols within a specified memory\nlength. At the receiver side, a turbo equalizer with a modified M-BCJR\nalgorithm is proposed to achieve the recovery of ambiguous bits induced by\nDSLM. Experimental verification in a 56GBaud PAM8 system demonstrates that the\nproposed scheme exhibits 1dB receiver sensitivity improvement over 2km\nsingle-mode fiber transmission. In addition, the proposed scheme has also been\ndemonstrated to be compatible with the typical probabilistic amplitude shaping\narchitecture, enabling a simple and fine-granularity rate adaptation\ncapability. To the best of our knowledge, this work opens a new sight for the\napplication of the PS technique in PPC IM-DD systems with memory effects.", "published": "2025-07-24 07:31:59", "link": "http://arxiv.org/abs/2507.18149v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Geometrical portrait of Multipath error propagation in GNSS Direct Position Estimation", "abstract": "Direct Position Estimation (DPE) is a method that directly estimate position,\nvelocity, and time (PVT) information from cross ambiguity function (CAF) of the\nGNSS signals, significantly enhancing receiver robustness in urban\nenvironments. However, there is still a lack of theoretical characterization on\nmultipath errors in the context of DPE theory. Geometric observations highlight\nthe unique characteristics of DPE errors stemming from multipath and thermal\nnoise as estimation bias and variance respectively. Expanding upon the\ntheoretical framework of DPE noise variance through geometric analysis, this\npaper focuses on a geometric representation of multipath errors by quantifying\nthe deviations in CAF and PVT solutions caused by off-centering bias relative\nto the azimuth and elevation angles. A satellite circular multipath bias (SCMB)\nmodel is introduced, amalgamating CAF and PVT errors from multiple satellite\nchannels. The boundaries for maximum or minimum PVT bias are established\nthrough discussions encompassing various multipath conditions. The correctness\nof the multipath geometrical portrait is confirmed through both Monte Carlo\nsimulations and urban canyon tests. The findings indicate that the maximum PVT\nbias depends on the largest multipath errors observed across various satellite\nchannels. Additionally, the PVT bias increases with satellite elevation angles,\ninfluenced by the CAF multipath bias projection. This serves as a reference for\nselecting DPE satellites from a geometric standpoint, underscoring the\nimportance of choosing a balanced combination of high and low elevation angles\nto achieve an optimal satellite geometry configuration.", "published": "2025-07-24 05:17:58", "link": "http://arxiv.org/abs/2507.18096v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Modular Robot and Landmark Localisation Using Relative Bearing Measurements", "abstract": "In this paper we propose a modular nonlinear least squares filtering approach\nfor systems composed of independent subsystems. The state and error covariance\nestimate of each subsystem is updated independently, even when a relative\nmeasurement simultaneously depends on the states of multiple subsystems. We\nintegrate the Covariance Intersection (CI) algorithm as part of our solution in\norder to prevent double counting of information when subsystems share estimates\nwith each other. An alternative derivation of the CI algorithm based on least\nsquares estimation makes this integration possible. We particularise the\nproposed approach to the robot-landmark localization problem. In this problem,\nnoisy measurements of the bearing angle to a stationary landmark position\nmeasured relative to the SE(2) pose of a moving robot couple the estimation\nproblems for the robot pose and the landmark position. In a randomized\nsimulation study, we benchmark the proposed modular method against a monolithic\njoint state filter to elucidate their respective trade-offs. In this study we\nalso include variants of the proposed method that achieve a graceful\ndegradation of performance with reduced communication and bandwidth\nrequirements.", "published": "2025-07-24 03:49:43", "link": "http://arxiv.org/abs/2507.18070v1", "categories": ["cs.RO", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Multiple Active STAR-RIS-Assisted Secure Integrated Sensing and Communication via Cooperative Beamforming", "abstract": "This paper explores an integrated sensing and communication (ISAC) network\nempowered by multiple active simultaneously transmitting and reflecting\nreconfigurable intelligent surfaces (STAR-RISs). A base station (BS) furnishes\ndownlink communication to multiple users while concurrently interrogating a\nsensing target. We jointly optimize the BS transmit beamformer and the\nreflection/transmission coefficients of every active STAR-RIS in order to\nmaximize the aggregate communication sum-rate, subject to (i) a stringent\nsensing signal-to-interference-plus-noise ratio (SINR) requirement, (ii) an\nupper bound on the leakage of confidential information, and (iii) individual\nhardware and total power constraints at both the BS and the STAR-RISs. The\nresulting highly non-convex program is tackled with an efficient alternating\noptimization (AO) framework. First, the original formulation is reformulated\ninto an equivalent yet more tractable representation and partitioned into\nsubproblems. The BS beamformer is updated in closed form via the\nKarush-Kuhn-Tucker (KKT) conditions, whereas the STAR-RIS reflection and\ntransmission vectors are refined through successive convex approximation (SCA),\nyielding a semidefinite program that is then solved via semidefinite\nrelaxation. Comprehensive simulations demonstrate that the proposed algorithm\ndelivers substantial sum-rate gains over passive-RIS and single STAR-RIS\nbaselines, all the while rigorously meeting the prescribed sensing and security\nconstraints.", "published": "2025-07-24 02:07:26", "link": "http://arxiv.org/abs/2507.18035v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
