{"title": "VITA-Audio: Fast Interleaved Cross-Modal Token Generation for Efficient Large Speech-Language Model", "abstract": "With the growing requirement for natural human-computer interaction,\nspeech-based systems receive increasing attention as speech is one of the most\ncommon forms of daily communication. However, the existing speech models still\nexperience high latency when generating the first audio token during streaming,\nwhich poses a significant bottleneck for deployment. To address this issue, we\npropose VITA-Audio, an end-to-end large speech model with fast audio-text token\ngeneration. Specifically, we introduce a lightweight Multiple Cross-modal Token\nPrediction (MCTP) module that efficiently generates multiple audio tokens\nwithin a single model forward pass, which not only accelerates the inference\nbut also significantly reduces the latency for generating the first audio in\nstreaming scenarios. In addition, a four-stage progressive training strategy is\nexplored to achieve model acceleration with minimal loss of speech quality. To\nour knowledge, VITA-Audio is the first multi-modal large language model capable\nof generating audio output during the first forward pass, enabling real-time\nconversational capabilities with minimal latency. VITA-Audio is fully\nreproducible and is trained on open-source data only. Experimental results\ndemonstrate that our model achieves an inference speedup of 3~5x at the 7B\nparameter scale, but also significantly outperforms open-source models of\nsimilar model size on multiple benchmarks for automatic speech recognition\n(ASR), text-to-speech (TTS), and spoken question answering (SQA) tasks.", "published": "2025-05-06 17:59:53", "link": "http://arxiv.org/abs/2505.03739v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch", "abstract": "LLM-based agents have demonstrated great potential in generating and managing\ncode within complex codebases. In this paper, we introduce WebGen-Bench, a\nnovel benchmark designed to measure an LLM-based agent's ability to create\nmulti-file website codebases from scratch. It contains diverse instructions for\nwebsite generation, created through the combined efforts of human annotators\nand GPT-4o. These instructions span three major categories and thirteen minor\ncategories, encompassing nearly all important types of web applications. To\nassess the quality of the generated websites, we use GPT-4o to generate test\ncases targeting each functionality described in the instructions, and then\nmanually filter, adjust, and organize them to ensure accuracy, resulting in 647\ntest cases. Each test case specifies an operation to be performed on the\nwebsite and the expected result after the operation. To automate testing and\nimprove reproducibility, we employ a powerful web-navigation agent to execute\ntests on the generated websites and determine whether the observed responses\nalign with the expected results. We evaluate three high-performance code-agent\nframeworks, Bolt.diy, OpenHands, and Aider, using multiple proprietary and\nopen-source LLMs as engines. The best-performing combination, Bolt.diy powered\nby DeepSeek-R1, achieves only 27.8\\% accuracy on the test cases, highlighting\nthe challenging nature of our benchmark. Additionally, we construct\nWebGen-Instruct, a training set consisting of 6,667 website-generation\ninstructions. Training Qwen2.5-Coder-32B-Instruct on Bolt.diy trajectories\ngenerated from a subset of this training set achieves an accuracy of 38.2\\%,\nsurpassing the performance of the best proprietary model.", "published": "2025-05-06 17:59:15", "link": "http://arxiv.org/abs/2505.03733v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NBF at SemEval-2025 Task 5: Light-Burst Attention Enhanced System for Multilingual Subject Recommendation", "abstract": "We present our system submission for SemEval 2025 Task 5, which focuses on\ncross-lingual subject classification in the English and German academic\ndomains. Our approach leverages bilingual data during training, employing\nnegative sampling and a margin-based retrieval objective. We demonstrate that a\ndimension-as-token self-attention mechanism designed with significantly reduced\ninternal dimensions can effectively encode sentence embeddings for subject\nretrieval. In quantitative evaluation, our system achieved an average recall\nrate of 32.24% in the general quantitative setting (all subjects), 43.16% and\n31.53% of the general qualitative evaluation methods with minimal GPU usage,\nhighlighting their competitive performance. Our results demonstrate that our\napproach is effective in capturing relevant subject information under resource\nconstraints, although there is still room for improvement.", "published": "2025-05-06 17:33:46", "link": "http://arxiv.org/abs/2505.03711v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IndicSQuAD: A Comprehensive Multilingual Question Answering Dataset for Indic Languages", "abstract": "The rapid progress in question-answering (QA) systems has predominantly\nbenefited high-resource languages, leaving Indic languages largely\nunderrepresented despite their vast native speaker base. In this paper, we\npresent IndicSQuAD, a comprehensive multi-lingual extractive QA dataset\ncovering nine major Indic languages, systematically derived from the SQuAD\ndataset. Building on previous work with MahaSQuAD for Marathi, our approach\nadapts and extends translation techniques to maintain high linguistic fidelity\nand accurate answer-span alignment across diverse languages. IndicSQuAD\ncomprises extensive training, validation, and test sets for each language,\nproviding a robust foundation for model development. We evaluate baseline\nperformances using language-specific monolingual BERT models and the\nmultilingual MuRIL-BERT. The results indicate some challenges inherent in\nlow-resource settings. Moreover, our experiments suggest potential directions\nfor future work, including expanding to additional languages, developing\ndomain-specific datasets, and incorporating multimodal data. The dataset and\nmodels are publicly shared at https://github.com/l3cube-pune/indic-nlp", "published": "2025-05-06 16:42:54", "link": "http://arxiv.org/abs/2505.03688v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards conversational assistants for health applications: using ChatGPT to generate conversations about heart failure", "abstract": "We explore the potential of ChatGPT (3.5-turbo and 4) to generate\nconversations focused on self-care strategies for African-American heart\nfailure patients -- a domain with limited specialized datasets. To simulate\npatient-health educator dialogues, we employed four prompting strategies:\ndomain, African American Vernacular English (AAVE), Social Determinants of\nHealth (SDOH), and SDOH-informed reasoning. Conversations were generated across\nkey self-care domains of food, exercise, and fluid intake, with varying turn\nlengths (5, 10, 15) and incorporated patient-specific SDOH attributes such as\nage, gender, neighborhood, and socioeconomic status. Our findings show that\neffective prompt design is essential. While incorporating SDOH and reasoning\nimproves dialogue quality, ChatGPT still lacks the empathy and engagement\nneeded for meaningful healthcare communication.", "published": "2025-05-06 16:21:10", "link": "http://arxiv.org/abs/2505.03675v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rational Retrieval Acts: Leveraging Pragmatic Reasoning to Improve Sparse Retrieval", "abstract": "Current sparse neural information retrieval (IR) methods, and to a lesser\nextent more traditional models such as BM25, do not take into account the\ndocument collection and the complex interplay between different term weights\nwhen representing a single document. In this paper, we show how the Rational\nSpeech Acts (RSA), a linguistics framework used to minimize the number of\nfeatures to be communicated when identifying an object in a set, can be adapted\nto the IR case -- and in particular to the high number of potential features\n(here, tokens). RSA dynamically modulates token-document interactions by\nconsidering the influence of other documents in the dataset, better contrasting\ndocument representations. Experiments show that incorporating RSA consistently\nimproves multiple sparse retrieval models and achieves state-of-the-art\nperformance on out-of-domain datasets from the BEIR benchmark.\nhttps://github.com/arthur-75/Rational-Retrieval-Acts", "published": "2025-05-06 16:21:10", "link": "http://arxiv.org/abs/2505.03676v1", "categories": ["cs.IR", "cs.CL", "68P20, 68T50", "H.3"], "primary_category": "cs.IR"}
{"title": "Say It Another Way: A Framework for User-Grounded Paraphrasing", "abstract": "Small changes in how a prompt is worded can lead to meaningful differences in\nthe behavior of large language models (LLMs), raising concerns about the\nstability and reliability of their evaluations. While prior work has explored\nsimple formatting changes, these rarely capture the kinds of natural variation\nseen in real-world language use. We propose a controlled paraphrasing framework\nbased on a taxonomy of minimal linguistic transformations to systematically\ngenerate natural prompt variations. Using the BBQ dataset, we validate our\nmethod with both human annotations and automated checks, then use it to study\nhow LLMs respond to paraphrased prompts in stereotype evaluation tasks. Our\nanalysis shows that even subtle prompt modifications can lead to substantial\nchanges in model behavior. These results highlight the need for robust,\nparaphrase-aware evaluation protocols.", "published": "2025-05-06 14:17:30", "link": "http://arxiv.org/abs/2505.03563v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Faster MoE LLM Inference for Extremely Large Models", "abstract": "Sparse Mixture of Experts (MoE) large language models (LLMs) are gradually\nbecoming the mainstream approach for ultra-large-scale models. Existing\noptimization efforts for MoE models have focused primarily on coarse-grained\nMoE architectures. With the emergence of DeepSeek Models, fine-grained MoE\nmodels are gaining popularity, yet research on them remains limited. Therefore,\nwe want to discuss the efficiency dynamic under different service loads.\nAdditionally, fine-grained models allow deployers to reduce the number of\nrouted experts, both activated counts and total counts, raising the question of\nhow this reduction affects the trade-off between MoE efficiency and\nperformance. Our findings indicate that while deploying MoE models presents\ngreater challenges, it also offers significant optimization opportunities.\nReducing the number of activated experts can lead to substantial efficiency\nimprovements in certain scenarios, with only minor performance degradation.\nReducing the total number of experts provides limited efficiency gains but\nresults in severe performance degradation. Our method can increase throughput\nby at least 10\\% without any performance degradation. Overall, we conclude that\nMoE inference optimization remains an area with substantial potential for\nexploration and improvement.", "published": "2025-05-06 13:41:17", "link": "http://arxiv.org/abs/2505.03531v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BadLingual: A Novel Lingual-Backdoor Attack against Large Language Models", "abstract": "In this paper, we present a new form of backdoor attack against Large\nLanguage Models (LLMs): lingual-backdoor attacks. The key novelty of\nlingual-backdoor attacks is that the language itself serves as the trigger to\nhijack the infected LLMs to generate inflammatory speech. They enable the\nprecise targeting of a specific language-speaking group, exacerbating racial\ndiscrimination by malicious entities. We first implement a baseline\nlingual-backdoor attack, which is carried out by poisoning a set of training\ndata for specific downstream tasks through translation into the trigger\nlanguage. However, this baseline attack suffers from poor task generalization\nand is impractical in real-world settings. To address this challenge, we design\nBadLingual, a novel task-agnostic lingual-backdoor, capable of triggering any\ndownstream tasks within the chat LLMs, regardless of the specific questions of\nthese tasks. We design a new approach using PPL-constrained Greedy Coordinate\nGradient-based Search (PGCG) based adversarial training to expand the decision\nboundary of lingual-backdoor, thereby enhancing the generalization ability of\nlingual-backdoor across various tasks. We perform extensive experiments to\nvalidate the effectiveness of our proposed attacks. Specifically, the baseline\nattack achieves an ASR of over 90% on the specified tasks. However, its ASR\nreaches only 37.61% across six tasks in the task-agnostic scenario. In\ncontrast, BadLingual brings up to 37.35% improvement over the baseline. Our\nstudy sheds light on a new perspective of vulnerabilities in LLMs with\nmultilingual capabilities and is expected to promote future research on the\npotential defenses to enhance the LLMs' robustness", "published": "2025-05-06 13:07:57", "link": "http://arxiv.org/abs/2505.03501v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Sentence Embeddings as an intermediate target in end-to-end summarisation", "abstract": "Current neural network-based methods to the problem of document summarisation\nstruggle when applied to datasets containing large inputs. In this paper we\npropose a new approach to the challenge of content-selection when dealing with\nend-to-end summarisation of user reviews of accommodations. We show that by\ncombining an extractive approach with externally pre-trained sentence level\nembeddings in an addition to an abstractive summarisation model we can\noutperform existing methods when this is applied to the task of summarising a\nlarge input dataset. We also prove that predicting sentence level embedding of\na summary increases the quality of an end-to-end system for loosely aligned\nsource to target corpora, than compared to commonly predicting probability\ndistributions of sentence selection.", "published": "2025-05-06 12:34:59", "link": "http://arxiv.org/abs/2505.03481v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation of LLMs on Long-tail Entity Linking in Historical Documents", "abstract": "Entity Linking (EL) plays a crucial role in Natural Language Processing (NLP)\napplications, enabling the disambiguation of entity mentions by linking them to\ntheir corresponding entries in a reference knowledge base (KB). Thanks to their\ndeep contextual understanding capabilities, LLMs offer a new perspective to\ntackle EL, promising better results than traditional methods. Despite the\nimpressive generalization capabilities of LLMs, linking less popular, long-tail\nentities remains challenging as these entities are often underrepresented in\ntraining data and knowledge bases. Furthermore, the long-tail EL task is an\nunderstudied problem, and limited studies address it with LLMs. In the present\nwork, we assess the performance of two popular LLMs, GPT and LLama3, in a\nlong-tail entity linking scenario. Using MHERCL v0.1, a manually annotated\nbenchmark of sentences from domain-specific historical texts, we quantitatively\ncompare the performance of LLMs in identifying and linking entities to their\ncorresponding Wikidata entries against that of ReLiK, a state-of-the-art Entity\nLinking and Relation Extraction framework. Our preliminary experiments reveal\nthat LLMs perform encouragingly well in long-tail EL, indicating that this\ntechnology can be a valuable adjunct in filling the gap between head and\nlong-tail EL.", "published": "2025-05-06 12:25:15", "link": "http://arxiv.org/abs/2505.03473v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting Efficient Reasoning in Large Language Models", "abstract": "Recent advances in large language models have demonstrated that Supervised\nFine-Tuning (SFT) with Chain-of-Thought (CoT) reasoning data distilled from\nlarge reasoning models (e.g., DeepSeek R1) can effectively transfer reasoning\ncapabilities to non-reasoning models. However, models fine-tuned with this\napproach inherit the \"overthinking\" problem from teacher models, producing\nverbose and redundant reasoning chains during inference. To address this\nchallenge, we propose \\textbf{L}ong-\\textbf{S}hort Chain-of-Thought\n\\textbf{Mixture} \\textbf{S}upervised \\textbf{F}ine-\\textbf{T}uning\n(\\textbf{LS-Mixture SFT}), which combines long CoT reasoning dataset with their\nshort counterparts obtained through structure-preserved rewriting. Our\nexperiments demonstrate that models trained using the LS-Mixture SFT method,\ncompared to those trained with direct SFT, achieved an average accuracy\nimprovement of 2.3\\% across various benchmarks while substantially reducing\nmodel response length by approximately 47.61\\%. This work offers an approach to\nendow non-reasoning models with reasoning capabilities through supervised\nfine-tuning while avoiding the inherent overthinking problems inherited from\nteacher models, thereby enabling efficient reasoning in the fine-tuned models.", "published": "2025-05-06 12:18:11", "link": "http://arxiv.org/abs/2505.03469v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncertainty-Aware Large Language Models for Explainable Disease Diagnosis", "abstract": "Explainable disease diagnosis, which leverages patient information (e.g.,\nsigns and symptoms) and computational models to generate probable diagnoses and\nreasonings, offers clear clinical values. However, when clinical notes\nencompass insufficient evidence for a definite diagnosis, such as the absence\nof definitive symptoms, diagnostic uncertainty usually arises, increasing the\nrisk of misdiagnosis and adverse outcomes. Although explicitly identifying and\nexplaining diagnostic uncertainties is essential for trustworthy diagnostic\nsystems, it remains under-explored. To fill this gap, we introduce ConfiDx, an\nuncertainty-aware large language model (LLM) created by fine-tuning open-source\nLLMs with diagnostic criteria. We formalized the task and assembled richly\nannotated datasets that capture varying degrees of diagnostic ambiguity.\nEvaluating ConfiDx on real-world datasets demonstrated that it excelled in\nidentifying diagnostic uncertainties, achieving superior diagnostic\nperformance, and generating trustworthy explanations for diagnoses and\nuncertainties. To our knowledge, this is the first study to jointly address\ndiagnostic uncertainty recognition and explanation, substantially enhancing the\nreliability of automatic diagnostic systems.", "published": "2025-05-06 12:12:48", "link": "http://arxiv.org/abs/2505.03467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation", "abstract": "Finding the optimal Retrieval-Augmented Generation (RAG) configuration for a\ngiven use case can be complex and expensive. Motivated by this challenge,\nframeworks for RAG hyper-parameter optimization (HPO) have recently emerged,\nyet their effectiveness has not been rigorously benchmarked. To address this\ngap, we present a comprehensive study involving 5 HPO algorithms over 5\ndatasets from diverse domains, including a new one collected for this work on\nreal-world product documentation. Our study explores the largest HPO search\nspace considered to date, with two optimized evaluation metrics. Analysis of\nthe results shows that RAG HPO can be done efficiently, either greedily or with\niterative random search, and that it significantly boosts RAG performance for\nall datasets. For greedy HPO approaches, we show that optimizing models first\nis preferable to the prevalent practice of optimizing sequentially according to\nthe RAG pipeline order.", "published": "2025-05-06 11:47:52", "link": "http://arxiv.org/abs/2505.03452v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Elevating Semantic Exploration: A Novel Approach Utilizing Distributed Repositories", "abstract": "Centralized and distributed systems are two main approaches to organizing ICT\ninfrastructure, each with its pros and cons. Centralized systems concentrate\nresources in one location, making management easier but creating single points\nof failure. Distributed systems, on the other hand, spread resources across\nmultiple nodes, offering better scalability and fault tolerance, but requiring\nmore complex management. The choice between them depends on factors like\napplication needs, scalability, and data sensitivity. Centralized systems suit\napplications with limited scalability and centralized control, while\ndistributed systems excel in large-scale environments requiring high\navailability and performance. This paper explores a distributed document\nrepository system developed for the Italian Ministry of Justice, using edge\nrepositories to analyze textual data and metadata, enhancing semantic\nexploration capabilities.", "published": "2025-05-06 11:30:16", "link": "http://arxiv.org/abs/2505.03443v1", "categories": ["cs.DC", "cs.AI", "cs.CL"], "primary_category": "cs.DC"}
{"title": "MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks", "abstract": "Large Language Models (LLMs) have demonstrated significant promise for\nvarious applications in healthcare. However, their efficacy in the Arabic\nmedical domain remains unexplored due to the lack of high-quality\ndomain-specific datasets and benchmarks. This study introduces MedArabiQ, a\nnovel benchmark dataset consisting of seven Arabic medical tasks, covering\nmultiple specialties and including multiple choice questions,\nfill-in-the-blank, and patient-doctor question answering. We first constructed\nthe dataset using past medical exams and publicly available datasets. We then\nintroduced different modifications to evaluate various LLM capabilities,\nincluding bias mitigation. We conducted an extensive evaluation with five\nstate-of-the-art open-source and proprietary LLMs, including GPT-4o, Claude\n3.5-Sonnet, and Gemini 1.5. Our findings highlight the need for the creation of\nnew high-quality benchmarks that span different languages to ensure fair\ndeployment and scalability of LLMs in healthcare. By establishing this\nbenchmark and releasing the dataset, we provide a foundation for future\nresearch aimed at evaluating and enhancing the multilingual capabilities of\nLLMs for the equitable use of generative AI in healthcare.", "published": "2025-05-06 11:07:26", "link": "http://arxiv.org/abs/2505.03427v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Enhancing Target-unspecific Tasks through a Features Matrix", "abstract": "Recent developments in prompt learning of large vision-language models have\nsignificantly improved performance in target-specific tasks. However, these\nprompt optimizing methods often struggle to tackle the target-unspecific or\ngeneralizable tasks effectively. It may be attributed to the fact that\noverfitting training causes the model to forget its general knowledge having\nstrong promotion on target-unspecific tasks. To alleviate this issue, we\npropose a novel Features Matrix (FM) regularization approach designed to\nenhance these models on target-unspecific tasks. Our method extracts and\nleverages general knowledge, shaping a Features Matrix (FM). Specifically, the\nFM captures the semantics of diverse inputs from a deep and fine perspective,\npreserving essential general knowledge, which mitigates the risk of\noverfitting. Representative evaluations demonstrate that: 1) the FM is\ncompatible with existing frameworks as a generic and flexible module, and 2)\nthe FM significantly showcases its effectiveness in enhancing target-unspecific\ntasks, achieving state-of-the-art performance.", "published": "2025-05-06 10:41:53", "link": "http://arxiv.org/abs/2505.03414v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation", "abstract": "This research paper investigates the application of Large Language Models\n(LLMs) in healthcare, specifically focusing on enhancing medical decision\nsupport through Retrieval-Augmented Generation (RAG) integrated with\nhospital-specific data and fine-tuning using Quantized Low-Rank Adaptation\n(QLoRA). The system utilizes Llama 3.2-3B-Instruct as its foundation model. By\nembedding and retrieving context-relevant healthcare information, the system\nsignificantly improves response accuracy. QLoRA facilitates notable parameter\nefficiency and memory optimization, preserving the integrity of medical\ninformation through specialized quantization techniques. Our research also\nshows that our model performs relatively well on various medical benchmarks,\nindicating that it can be used to make basic medical suggestions. This paper\ndetails the system's technical components, including its architecture,\nquantization methods, and key healthcare applications such as enhanced disease\nprediction from patient symptoms and medical history, treatment suggestions,\nand efficient summarization of complex medical reports. We touch on the ethical\nconsiderations-patient privacy, data security, and the need for rigorous\nclinical validation-as well as the practical challenges of integrating such\nsystems into real-world healthcare workflows. Furthermore, the lightweight\nquantized weights ensure scalability and ease of deployment even in\nlow-resource hospital environments. Finally, the paper concludes with an\nanalysis of the broader impact of LLMs on healthcare and outlines future\ndirections for LLMs in medical settings.", "published": "2025-05-06 10:31:54", "link": "http://arxiv.org/abs/2505.03406v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Absolute Zero: Reinforced Self-play Reasoning with Zero Data", "abstract": "Reinforcement learning with verifiable rewards (RLVR) has shown promise in\nenhancing the reasoning capabilities of large language models by learning\ndirectly from outcome-based rewards. Recent RLVR works that operate under the\nzero setting avoid supervision in labeling the reasoning process, but still\ndepend on manually curated collections of questions and answers for training.\nThe scarcity of high-quality, human-produced examples raises concerns about the\nlong-term scalability of relying on human supervision, a challenge already\nevident in the domain of language model pretraining. Furthermore, in a\nhypothetical future where AI surpasses human intelligence, tasks provided by\nhumans may offer limited learning potential for a superintelligent system. To\naddress these concerns, we propose a new RLVR paradigm called Absolute Zero, in\nwhich a single model learns to propose tasks that maximize its own learning\nprogress and improves reasoning by solving them, without relying on any\nexternal data. Under this paradigm, we introduce the Absolute Zero Reasoner\n(AZR), a system that self-evolves its training curriculum and reasoning ability\nby using a code executor to both validate proposed code reasoning tasks and\nverify answers, serving as an unified source of verifiable reward to guide\nopen-ended yet grounded learning. Despite being trained entirely without\nexternal data, AZR achieves overall SOTA performance on coding and mathematical\nreasoning tasks, outperforming existing zero-setting models that rely on tens\nof thousands of in-domain human-curated examples. Furthermore, we demonstrate\nthat AZR can be effectively applied across different model scales and is\ncompatible with various model classes.", "published": "2025-05-06 09:08:00", "link": "http://arxiv.org/abs/2505.03335v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation", "abstract": "Mamba's theoretical infinite-context potential is limited in practice when\nsequences far exceed training lengths. This work explores unlocking Mamba's\nlong-context memory ability by a simple-yet-effective method, Recall with\nReasoning (RwR), by distilling chain-of-thought (CoT) summarization from a\nteacher model. Specifically, RwR prepends these summarization as CoT prompts\nduring fine-tuning, teaching Mamba to actively recall and reason over long\ncontexts. Experiments on LONGMEMEVAL and HELMET show RwR boosts Mamba's\nlong-context performance against comparable Transformer/hybrid baselines under\nsimilar pretraining conditions, while preserving short-context capabilities,\nall without architectural changes.", "published": "2025-05-06 08:47:58", "link": "http://arxiv.org/abs/2505.03320v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\u03a8-Arena: Interactive Assessment and Optimization of LLM-based Psychological Counselors with Tripartite Feedback", "abstract": "Large language models (LLMs) have shown promise in providing scalable mental\nhealth support, while evaluating their counseling capability remains crucial to\nensure both efficacy and safety. Existing evaluations are limited by the static\nassessment that focuses on knowledge tests, the single perspective that centers\non user experience, and the open-loop framework that lacks actionable feedback.\nTo address these issues, we propose {\\Psi}-Arena, an interactive framework for\ncomprehensive assessment and optimization of LLM-based counselors, featuring\nthree key characteristics: (1) Realistic arena interactions that simulate\nreal-world counseling through multi-stage dialogues with psychologically\nprofiled NPC clients, (2) Tripartite evaluation that integrates assessments\nfrom the client, counselor, and supervisor perspectives, and (3) Closed-loop\noptimization that iteratively improves LLM counselors using diagnostic\nfeedback. Experiments across eight state-of-the-art LLMs show significant\nperformance variations in different real-world scenarios and evaluation\nperspectives. Moreover, reflection-based optimization results in up to a 141%\nimprovement in counseling performance. We hope PsychoArena provides a\nfoundational resource for advancing reliable and human-aligned LLM applications\nin mental healthcare.", "published": "2025-05-06 08:22:51", "link": "http://arxiv.org/abs/2505.03293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SepALM: Audio Language Models Are Error Correctors for Robust Speech Separation", "abstract": "While contemporary speech separation technologies adeptly process lengthy\nmixed audio waveforms, they are frequently challenged by the intricacies of\nreal-world environments, including noisy and reverberant settings, which can\nresult in artifacts or distortions in the separated speech. To overcome these\nlimitations, we introduce SepALM, a pioneering approach that employs audio\nlanguage models (ALMs) to rectify and re-synthesize speech within the text\ndomain following preliminary separation. SepALM comprises four core components:\na separator, a corrector, a synthesizer, and an aligner. By integrating an\nALM-based end-to-end error correction mechanism, we mitigate the risk of error\naccumulation and circumvent the optimization hurdles typically encountered in\nconventional methods that amalgamate automatic speech recognition (ASR) with\nlarge language models (LLMs). Additionally, we have developed Chain-of-Thought\n(CoT) prompting and knowledge distillation techniques to facilitate the\nreasoning and training processes of the ALM. Our experiments substantiate that\nSepALM not only elevates the precision of speech separation but also markedly\nbolsters adaptability in novel acoustic environments.", "published": "2025-05-06 08:04:37", "link": "http://arxiv.org/abs/2505.03273v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Survey of Abstract Meaning Representation: Then, Now, Future", "abstract": "This paper presents a survey of Abstract Meaning Representation (AMR), a\nsemantic representation framework that captures the meaning of sentences\nthrough a graph-based structure. AMR represents sentences as rooted, directed\nacyclic graphs, where nodes correspond to concepts and edges denote\nrelationships, effectively encoding the meaning of complex sentences. This\nsurvey investigates AMR and its extensions, focusing on AMR capabilities. It\nthen explores the parsing (text-to-AMR) and generation (AMR-to-text) tasks by\nshowing traditional, current, and possible futures approaches. It also reviews\nvarious applications of AMR including text generation, text classification, and\ninformation extraction and information seeking. By analyzing recent\ndevelopments and challenges in the field, this survey provides insights into\nfuture directions for research and the potential impact of AMR on enhancing\nmachine understanding of human language.", "published": "2025-05-06 06:45:40", "link": "http://arxiv.org/abs/2505.03229v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMO: Adaptive Motion Optimization for Hyper-Dexterous Humanoid Whole-Body Control", "abstract": "Humanoid robots derive much of their dexterity from hyper-dexterous\nwhole-body movements, enabling tasks that require a large operational\nworkspace: such as picking objects off the ground. However, achieving these\ncapabilities on real humanoids remains challenging due to their high degrees of\nfreedom (DoF) and nonlinear dynamics. We propose Adaptive Motion Optimization\n(AMO), a framework that integrates sim-to-real reinforcement learning (RL) with\ntrajectory optimization for real-time, adaptive whole-body control. To mitigate\ndistribution bias in motion imitation RL, we construct a hybrid AMO dataset and\ntrain a network capable of robust, on-demand adaptation to potentially O.O.D.\ncommands. We validate AMO in simulation and on a 29-DoF Unitree G1 humanoid\nrobot, demonstrating superior stability and an expanded workspace compared to\nstrong baselines. Finally, we show that AMO's consistent performance supports\nautonomous task execution via imitation learning, underscoring the system's\nversatility and robustness.", "published": "2025-05-06 17:59:51", "link": "http://arxiv.org/abs/2505.03738v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "FlexiAct: Towards Flexible Action Control in Heterogeneous Scenarios", "abstract": "Action customization involves generating videos where the subject performs\nactions dictated by input control signals. Current methods use pose-guided or\nglobal motion customization but are limited by strict constraints on spatial\nstructure, such as layout, skeleton, and viewpoint consistency, reducing\nadaptability across diverse subjects and scenarios. To overcome these\nlimitations, we propose FlexiAct, which transfers actions from a reference\nvideo to an arbitrary target image. Unlike existing methods, FlexiAct allows\nfor variations in layout, viewpoint, and skeletal structure between the subject\nof the reference video and the target image, while maintaining identity\nconsistency. Achieving this requires precise action control, spatial structure\nadaptation, and consistency preservation. To this end, we introduce RefAdapter,\na lightweight image-conditioned adapter that excels in spatial adaptation and\nconsistency preservation, surpassing existing methods in balancing appearance\nconsistency and structural flexibility. Additionally, based on our\nobservations, the denoising process exhibits varying levels of attention to\nmotion (low frequency) and appearance details (high frequency) at different\ntimesteps. So we propose FAE (Frequency-aware Action Extraction), which, unlike\nexisting methods that rely on separate spatial-temporal architectures, directly\nachieves action extraction during the denoising process. Experiments\ndemonstrate that our method effectively transfers actions to subjects with\ndiverse layouts, skeletons, and viewpoints. We release our code and model\nweights to support further research at\nhttps://shiyi-zh0408.github.io/projectpages/FlexiAct/", "published": "2025-05-06 17:58:02", "link": "http://arxiv.org/abs/2505.03730v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Actor-Critics Can Achieve Optimal Sample Efficiency", "abstract": "Actor-critic algorithms have become a cornerstone in reinforcement learning\n(RL), leveraging the strengths of both policy-based and value-based methods.\nDespite recent progress in understanding their statistical efficiency, no\nexisting work has successfully learned an $\\epsilon$-optimal policy with a\nsample complexity of $O(1/\\epsilon^2)$ trajectories with general function\napproximation when strategic exploration is necessary.\n  We address this open problem by introducing a novel actor-critic algorithm\nthat attains a sample-complexity of $O(dH^5 \\log|\\mathcal{A}|/\\epsilon^2 + d\nH^4 \\log|\\mathcal{F}|/ \\epsilon^2)$ trajectories, and accompanying $\\sqrt{T}$\nregret when the Bellman eluder dimension $d$ does not increase with $T$ at more\nthan a $\\log T$ rate.\n  Here, $\\mathcal{F}$ is the critic function class, $\\mathcal{A}$ is the action\nspace, and $H$ is the horizon in the finite horizon MDP setting. Our algorithm\nintegrates optimism, off-policy critic estimation targeting the optimal\nQ-function, and rare-switching policy resets.\n  We extend this to the setting of Hybrid RL, showing that initializing the\ncritic with offline data yields sample efficiency gains compared to purely\noffline or online RL. Further, utilizing access to offline data, we provide a\n\\textit{non-optimistic} provably efficient actor-critic algorithm that only\nadditionally requires $N_{\\text{off}} \\geq c_{\\text{off}}^*dH^4/\\epsilon^2$ in\nexchange for omitting optimism, where $c_{\\text{off}}^*$ is the single-policy\nconcentrability coefficient and $N_{\\text{off}}$ is the number of offline\nsamples. This addresses another open problem in the literature. We further\nprovide numerical experiments to support our theoretical findings.", "published": "2025-05-06 17:32:39", "link": "http://arxiv.org/abs/2505.03710v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Demonstrating ViSafe: Vision-enabled Safety for High-speed Detect and Avoid", "abstract": "Assured safe-separation is essential for achieving seamless high-density\noperation of airborne vehicles in a shared airspace. To equip\nresource-constrained aerial systems with this safety-critical capability, we\npresent ViSafe, a high-speed vision-only airborne collision avoidance system.\nViSafe offers a full-stack solution to the Detect and Avoid (DAA) problem by\ntightly integrating a learning-based edge-AI framework with a custom\nmulti-camera hardware prototype designed under SWaP-C constraints. By\nleveraging perceptual input-focused control barrier functions (CBF) to design,\nencode, and enforce safety thresholds, ViSafe can provide provably safe runtime\nguarantees for self-separation in high-speed aerial operations. We evaluate\nViSafe's performance through an extensive test campaign involving both\nsimulated digital twins and real-world flight scenarios. By independently\nvarying agent types, closure rates, interaction geometries, and environmental\nconditions (e.g., weather and lighting), we demonstrate that ViSafe\nconsistently ensures self-separation across diverse scenarios. In\nfirst-of-its-kind real-world high-speed collision avoidance tests with closure\nrates reaching 144 km/h, ViSafe sets a new benchmark for vision-only autonomous\ncollision avoidance, establishing a new standard for safety in high-speed\naerial navigation.", "published": "2025-05-06 16:59:54", "link": "http://arxiv.org/abs/2505.03694v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Graph Drawing for LLMs: An Empirical Evaluation", "abstract": "Our work contributes to the fast-growing literature on the use of Large\nLanguage Models (LLMs) to perform graph-related tasks. In particular, we focus\non usage scenarios that rely on the visual modality, feeding the model with a\ndrawing of the graph under analysis. We investigate how the model's performance\nis affected by the chosen layout paradigm, the aesthetics of the drawing, and\nthe prompting technique used for the queries. We formulate three corresponding\nresearch questions and present the results of a thorough experimental analysis.\nOur findings reveal that choosing the right layout paradigm and optimizing the\nreadability of the input drawing from a human perspective can significantly\nimprove the performance of the model on the given task. Moreover, selecting the\nmost effective prompting technique is a challenging yet crucial task for\nachieving optimal performance.", "published": "2025-05-06 16:23:42", "link": "http://arxiv.org/abs/2505.03678v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Gap the (Theory of) Mind: Sharing Beliefs About Teammates' Goals Boosts Collaboration Perception, Not Performance", "abstract": "In human-agent teams, openly sharing goals is often assumed to enhance\nplanning, collaboration, and effectiveness. However, direct communication of\nthese goals is not always feasible, requiring teammates to infer their\npartner's intentions through actions. Building on this, we investigate whether\nan AI agent's ability to share its inferred understanding of a human teammate's\ngoals can improve task performance and perceived collaboration. Through an\nexperiment comparing three conditions-no recognition (NR), viable goals (VG),\nand viable goals on-demand (VGod) - we find that while goal-sharing information\ndid not yield significant improvements in task performance or overall\nsatisfaction scores, thematic analysis suggests that it supported strategic\nadaptations and subjective perceptions of collaboration. Cognitive load\nassessments revealed no additional burden across conditions, highlighting the\nchallenge of balancing informativeness and simplicity in human-agent\ninteractions. These findings highlight the nuanced trade-off of goal-sharing:\nwhile it fosters trust and enhances perceived collaboration, it can\noccasionally hinder objective performance gains.", "published": "2025-05-06 16:15:24", "link": "http://arxiv.org/abs/2505.03674v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Learning Symbolic Persistent Macro-Actions for POMDP Solving Over Time", "abstract": "This paper proposes an integration of temporal logical reasoning and\nPartially Observable Markov Decision Processes (POMDPs) to achieve\ninterpretable decision-making under uncertainty with macro-actions. Our method\nleverages a fragment of Linear Temporal Logic (LTL) based on Event Calculus\n(EC) to generate \\emph{persistent} (i.e., constant) macro-actions, which guide\nMonte Carlo Tree Search (MCTS)-based POMDP solvers over a time horizon,\nsignificantly reducing inference time while ensuring robust performance. Such\nmacro-actions are learnt via Inductive Logic Programming (ILP) from a few\ntraces of execution (belief-action pairs), thus eliminating the need for\nmanually designed heuristics and requiring only the specification of the POMDP\ntransition model. In the Pocman and Rocksample benchmark scenarios, our learned\nmacro-actions demonstrate increased expressiveness and generality when compared\nto time-independent heuristics, indeed offering substantial computational\nefficiency improvements.", "published": "2025-05-06 16:08:55", "link": "http://arxiv.org/abs/2505.03668v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Revolutionizing Brain Tumor Imaging: Generating Synthetic 3D FA Maps from T1-Weighted MRI using CycleGAN Models", "abstract": "Fractional anisotropy (FA) and directionally encoded colour (DEC) maps are\nessential for evaluating white matter integrity and structural connectivity in\nneuroimaging. However, the spatial misalignment between FA maps and\ntractography atlases hinders their effective integration into predictive\nmodels. To address this issue, we propose a CycleGAN based approach for\ngenerating FA maps directly from T1-weighted MRI scans, representing the first\napplication of this technique to both healthy and tumour-affected tissues. Our\nmodel, trained on unpaired data, produces high fidelity maps, which have been\nrigorously evaluated using Structural Similarity Index (SSIM) and Peak\nSignal-to-Noise Ratio (PSNR), demonstrating particularly robust performance in\ntumour regions. Radiological assessments further underscore the model's\npotential to enhance clinical workflows by providing an AI-driven alternative\nthat reduces the necessity for additional scans.", "published": "2025-05-06 16:05:22", "link": "http://arxiv.org/abs/2505.03662v1", "categories": ["cs.CV", "cs.AI", "68U10"], "primary_category": "cs.CV"}
{"title": "Counterfactual Inference for Eliminating Sentiment Bias in Recommender Systems", "abstract": "Recommender Systems (RSs) aim to provide personalized recommendations for\nusers. A newly discovered bias, known as sentiment bias, uncovers a common\nphenomenon within Review-based RSs (RRSs): the recommendation accuracy of users\nor items with negative reviews deteriorates compared with users or items with\npositive reviews. Critical users and niche items are disadvantaged by such\nunfair recommendations. We study this problem from the perspective of\ncounterfactual inference with two stages. At the model training stage, we build\na causal graph and model how sentiment influences the final rating score.\nDuring the inference stage, we decouple the direct and indirect effects to\nmitigate the impact of sentiment bias and remove the indirect effect using\ncounterfactual inference. We have conducted extensive experiments, and the\nresults validate that our model can achieve comparable performance on rating\nprediction for better recommendations and effective mitigation of sentiment\nbias. To the best of our knowledge, this is the first work to employ\ncounterfactual inference on sentiment bias mitigation in RSs.", "published": "2025-05-06 16:00:41", "link": "http://arxiv.org/abs/2505.03655v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant", "abstract": "Recent advances in personalized MLLMs enable effective capture of\nuser-specific concepts, supporting both recognition of personalized concepts\nand contextual captioning. However, humans typically explore and reason over\nrelations among objects and individuals, transcending surface-level information\nto achieve more personalized and contextual understanding. To this end,\nexisting methods may face three main limitations: Their training data lacks\nmulti-object sets in which relations among objects are learnable. Building on\nthe limited training data, their models overlook the relations between\ndifferent personalized concepts and fail to reason over them. Their experiments\nmainly focus on a single personalized concept, where evaluations are limited to\nrecognition and captioning tasks. To address the limitations, we present a new\ndataset named ReGraP, consisting of 120 sets of personalized knowledge. Each\nset includes images, KGs, and CoT QA pairs derived from the KGs, enabling more\nstructured and sophisticated reasoning pathways. We propose ReGraP-LLaVA, an\nMLLM trained with the corresponding KGs and CoT QA pairs, where soft and hard\ngraph prompting methods are designed to align KGs within the model's semantic\nspace. We establish the ReGraP Benchmark, which contains diverse task types:\nmultiple-choice, fill-in-the-blank, True/False, and descriptive questions in\nboth open- and closed-ended settings. The proposed benchmark is designed to\nevaluate the relational reasoning and knowledge-connection capability of\npersonalized MLLMs. We conduct experiments on the proposed ReGraP-LLaVA and\nother competitive MLLMs. Results show that the proposed model not only learns\npersonalized knowledge but also performs relational reasoning in responses,\nachieving the SoTA performance compared with the competitive methods. All the\ncodes and datasets are released at: https://github.com/xyfyyds/ReGraP.", "published": "2025-05-06 16:00:13", "link": "http://arxiv.org/abs/2505.03654v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Binding threshold units with artificial oscillatory neurons", "abstract": "Artificial Kuramoto oscillatory neurons were recently introduced as an\nalternative to threshold units. Empirical evidence suggests that oscillatory\nunits outperform threshold units in several tasks including unsupervised object\ndiscovery and certain reasoning problems. The proposed coupling mechanism for\nthese oscillatory neurons is heterogeneous, combining a generalized Kuramoto\nequation with standard coupling methods used for threshold units. In this\nresearch note, we present a theoretical framework that clearly distinguishes\noscillatory neurons from threshold units and establishes a coupling mechanism\nbetween them. We argue that, from a biological standpoint, oscillatory and\nthreshold units realise distinct aspects of neural coding: roughly, threshold\nunits model intensity of neuron firing, while oscillatory units facilitate\ninformation exchange by frequency modulation. To derive interaction between\nthese two types of units, we constrain their dynamics by focusing on dynamical\nsystems that admit Lyapunov functions. For threshold units, this leads to\nHopfield associative memory model, and for oscillatory units it yields a\nspecific form of generalized Kuramoto model. The resulting dynamical systems\ncan be naturally coupled to form a Hopfield-Kuramoto associative memory model,\nwhich also admits a Lyapunov function. Various forms of coupling are possible.\nNotably, oscillatory neurons can be employed to implement a low-rank correction\nto the weight matrix of a Hopfield network. This correction can be viewed\neither as a form of Hebbian learning or as a popular LoRA method used for\nfine-tuning of large language models. We demonstrate the practical realization\nof this particular coupling through illustrative toy experiments.", "published": "2025-05-06 15:54:52", "link": "http://arxiv.org/abs/2505.03648v1", "categories": ["q-bio.NC", "cs.AI", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "ALMA: Aggregated Lipschitz Maximization Attack on Auto-encoders", "abstract": "Despite the extensive use of deep autoencoders (AEs) in critical\napplications, their adversarial robustness remains relatively underexplored\ncompared to classification models. AE robustness is characterized by the\nLipschitz bounds of its components. Existing robustness evaluation frameworks\nbased on white-box attacks do not fully exploit the vulnerabilities of\nintermediate ill-conditioned layers in AEs. In the context of optimizing\nimperceptible norm-bounded additive perturbations to maximize output damage,\nexisting methods struggle to effectively propagate adversarial loss gradients\nthroughout the network, often converging to less effective perturbations. To\naddress this, we propose a novel layer-conditioning-based adversarial\noptimization objective that effectively guides the adversarial map toward\nregions of local Lipschitz bounds by enhancing loss gradient information\npropagation during attack optimization. We demonstrate through extensive\nexperiments on state-of-the-art AEs that our adversarial objective results in\nstronger attacks, outperforming existing methods in both universal and\nsample-specific scenarios. As a defense method against this attack, we\nintroduce an inference-time adversarially trained defense plugin that mitigates\nthe effects of adversarial examples.", "published": "2025-05-06 15:52:14", "link": "http://arxiv.org/abs/2505.03646v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "BURNS: Backward Underapproximate Reachability for Neural-Feedback-Loop Systems", "abstract": "Learning-enabled planning and control algorithms are increasingly popular,\nbut they often lack rigorous guarantees of performance or safety. We introduce\nan algorithm for computing underapproximate backward reachable sets of\nnonlinear discrete time neural feedback loops. We then use the backward\nreachable sets to check goal-reaching properties. Our algorithm is based on\noverapproximating the system dynamics function to enable computation of\nunderapproximate backward reachable sets through solutions of mixed-integer\nlinear programs. We rigorously analyze the soundness of our algorithm and\ndemonstrate it on a numerical example. Our work expands the class of properties\nthat can be verified for learning-enabled systems.", "published": "2025-05-06 15:50:43", "link": "http://arxiv.org/abs/2505.03643v1", "categories": ["cs.AI", "cs.LO", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering and Manipulating Human Perceptual Variability", "abstract": "Human decision-making in cognitive tasks and daily life exhibits considerable\nvariability, shaped by factors such as task difficulty, individual preferences,\nand personal experiences. Understanding this variability across individuals is\nessential for uncovering the perceptual and decision-making mechanisms that\nhumans rely on when faced with uncertainty and ambiguity. We present a\ncomputational framework BAM (Boundary Alignment & Manipulation framework) that\ncombines perceptual boundary sampling in ANNs and human behavioral experiments\nto systematically investigate this phenomenon. Our perceptual boundary sampling\nalgorithm generates stimuli along ANN decision boundaries that intrinsically\ninduce significant perceptual variability. The efficacy of these stimuli is\nempirically validated through large-scale behavioral experiments involving 246\nparticipants across 116,715 trials, culminating in the variMNIST dataset\ncontaining 19,943 systematically annotated images. Through personalized model\nalignment and adversarial generation, we establish a reliable method for\nsimultaneously predicting and manipulating the divergent perceptual decisions\nof pairs of participants. This work bridges the gap between computational\nmodels and human individual difference research, providing new tools for\npersonalized perception analysis.", "published": "2025-05-06 15:44:42", "link": "http://arxiv.org/abs/2505.03641v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Delayed Observation", "abstract": "In real-world multi-agent systems (MASs), observation delays are ubiquitous,\npreventing agents from making decisions based on the environment's true state.\nAn individual agent's local observation often consists of multiple components\nfrom other agents or dynamic entities in the environment. These discrete\nobservation components with varying delay characteristics pose significant\nchallenges for multi-agent reinforcement learning (MARL). In this paper, we\nfirst formulate the decentralized stochastic individual delay partially\nobservable Markov decision process (DSID-POMDP) by extending the standard\nDec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL\ntraining framework for addressing stochastic individual delays, along with\nrecommended implementations for its constituent modules. We implement the\nDSID-POMDP's observation generation pattern using standard MARL benchmarks,\nincluding MPE and SMAC. Experiments demonstrate that baseline MARL methods\nsuffer severe performance degradation under fixed and unfixed delays. The\nRDC-enhanced approach mitigates this issue, remarkably achieving ideal\ndelay-free performance in certain delay scenarios while maintaining\ngeneralization capability. Our work provides a novel perspective on multi-agent\ndelayed observation problems and offers an effective solution framework.", "published": "2025-05-06 14:47:56", "link": "http://arxiv.org/abs/2505.03586v1", "categories": ["cs.MA", "cs.AI", "68T07 (Primary), 68T20, 68T42 (Secondary)", "I.2"], "primary_category": "cs.MA"}
{"title": "BCause: Human-AI collaboration to improve hybrid mapping and ideation in argumentation-grounded deliberation", "abstract": "Public deliberation, as in open discussion of issues of public concern, often\nsuffers from scattered and shallow discourse, poor sensemaking, and a\ndisconnect from actionable policy outcomes. This paper introduces BCause, a\ndiscussion system leveraging generative AI and human-machine collaboration to\ntransform unstructured dialogue around public issues (such as urban living,\npolicy changes, and current socio-economic transformations) into structured,\nactionable democratic processes. We present three innovations: (i) importing\nand transforming unstructured transcripts into argumentative discussions, (ii)\ngeo-deliberated problem-sensing via a Telegram bot for local issue reporting,\nand (iii) smart reporting with customizable widgets (e.g., summaries, topic\nmodelling, policy recommendations, clustered arguments). The system's human-AI\npartnership preserves critical human participation to ensure ethical oversight,\ncontextual relevance, and creative synthesis.", "published": "2025-05-06 14:43:49", "link": "http://arxiv.org/abs/2505.03584v1", "categories": ["cs.HC", "cs.AI", "cs.CY", "I.2"], "primary_category": "cs.HC"}
{"title": "LlamaFirewall: An open source guardrail system for building secure AI agents", "abstract": "Large language models (LLMs) have evolved from simple chatbots into\nautonomous agents capable of performing complex tasks such as editing\nproduction code, orchestrating workflows, and taking higher-stakes actions\nbased on untrusted inputs like webpages and emails. These capabilities\nintroduce new security risks that existing security measures, such as model\nfine-tuning or chatbot-focused guardrails, do not fully address. Given the\nhigher stakes and the absence of deterministic solutions to mitigate these\nrisks, there is a critical need for a real-time guardrail monitor to serve as a\nfinal layer of defense, and support system level, use case specific safety\npolicy definition and enforcement. We introduce LlamaFirewall, an open-source\nsecurity focused guardrail framework designed to serve as a final layer of\ndefense against security risks associated with AI Agents. Our framework\nmitigates risks such as prompt injection, agent misalignment, and insecure code\nrisks through three powerful guardrails: PromptGuard 2, a universal jailbreak\ndetector that demonstrates clear state of the art performance; Agent Alignment\nChecks, a chain-of-thought auditor that inspects agent reasoning for prompt\ninjection and goal misalignment, which, while still experimental, shows\nstronger efficacy at preventing indirect injections in general scenarios than\npreviously proposed approaches; and CodeShield, an online static analysis\nengine that is both fast and extensible, aimed at preventing the generation of\ninsecure or dangerous code by coding agents. Additionally, we include\neasy-to-use customizable scanners that make it possible for any developer who\ncan write a regular expression or an LLM prompt to quickly update an agent's\nsecurity guardrails.", "published": "2025-05-06 14:34:21", "link": "http://arxiv.org/abs/2505.03574v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "OSUniverse: Benchmark for Multimodal GUI-navigation AI Agents", "abstract": "In this paper, we introduce OSUniverse: a benchmark of complex, multimodal\ndesktop-oriented tasks for advanced GUI-navigation AI agents that focuses on\nease of use, extensibility, comprehensive coverage of test cases, and automated\nvalidation. We divide the tasks in increasing levels of complexity, from basic\nprecision clicking to multistep, multiapplication tests requiring dexterity,\nprecision, and clear thinking from the agent. In version one of the benchmark,\npresented here, we have calibrated the complexity of the benchmark test cases\nto ensure that the SOTA (State of the Art) agents (at the time of publication)\ndo not achieve results higher than 50%, while the average white collar worker\ncan perform all these tasks with perfect accuracy. The benchmark can be scored\nmanually, but we also introduce an automated validation mechanism that has an\naverage error rate less than 2%. Therefore, this benchmark presents solid\nground for fully automated measuring of progress, capabilities and the\neffectiveness of GUI-navigation AI agents over the short and medium-term\nhorizon. The source code of the benchmark is available at\nhttps://github.com/agentsea/osuniverse.", "published": "2025-05-06 14:29:47", "link": "http://arxiv.org/abs/2505.03570v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Real-Time Person Image Synthesis Using a Flow Matching Model", "abstract": "Pose-Guided Person Image Synthesis (PGPIS) generates realistic person images\nconditioned on a target pose and a source image. This task plays a key role in\nvarious real-world applications, such as sign language video generation, AR/VR,\ngaming, and live streaming. In these scenarios, real-time PGPIS is critical for\nproviding immediate visual feedback and maintaining user immersion.However,\nachieving real-time performance remains a significant challenge due to the\ncomplexity of synthesizing high-fidelity images from diverse and dynamic human\nposes. Recent diffusion-based methods have shown impressive image quality in\nPGPIS, but their slow sampling speeds hinder deployment in time-sensitive\napplications. This latency is particularly problematic in tasks like generating\nsign language videos during live broadcasts, where rapid image updates are\nrequired. Therefore, developing a fast and reliable PGPIS model is a crucial\nstep toward enabling real-time interactive systems. To address this challenge,\nwe propose a generative model based on flow matching (FM). Our approach enables\nfaster, more stable, and more efficient training and sampling. Furthermore, the\nproposed model supports conditional generation and can operate in latent space,\nmaking it especially suitable for real-time PGPIS applications where both speed\nand quality are critical. We evaluate our proposed method, Real-Time Person\nImage Synthesis Using a Flow Matching Model (RPFM), on the widely used\nDeepFashion dataset for PGPIS tasks. Our results show that RPFM achieves\nnear-real-time sampling speeds while maintaining performance comparable to the\nstate-of-the-art models. Our methodology trades off a slight, acceptable\ndecrease in generated-image accuracy for over a twofold increase in generation\nspeed, thereby ensuring real-time performance.", "published": "2025-05-06 14:13:44", "link": "http://arxiv.org/abs/2505.03562v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Ergodic Generative Flows", "abstract": "Generative Flow Networks (GFNs) were initially introduced on directed acyclic\ngraphs to sample from an unnormalized distribution density. Recent works have\nextended the theoretical framework for generative methods allowing more\nflexibility and enhancing application range. However, many challenges remain in\ntraining GFNs in continuous settings and for imitation learning (IL), including\nintractability of flow-matching loss, limited tests of non-acyclic training,\nand the need for a separate reward model in imitation learning. The present\nwork proposes a family of generative flows called Ergodic Generative Flows\n(EGFs) which are used to address the aforementioned issues. First, we leverage\nergodicity to build simple generative flows with finitely many globally defined\ntransformations (diffeomorphisms) with universality guarantees and tractable\nflow-matching loss (FM loss). Second, we introduce a new loss involving\ncross-entropy coupled to weak flow-matching control, coined KL-weakFM loss. It\nis designed for IL training without a separate reward model. We evaluate\nIL-EGFs on toy 2D tasks and real-world datasets from NASA on the sphere, using\nthe KL-weakFM loss. Additionally, we conduct toy 2D reinforcement learning\nexperiments with a target reward, using the FM loss.", "published": "2025-05-06 14:13:21", "link": "http://arxiv.org/abs/2505.03561v1", "categories": ["cs.LG", "cs.AI", "math.DG", "math.DS", "37A25, 68T07, 68W20, 68Q87, 68T99"], "primary_category": "cs.LG"}
{"title": "Rapid AI-based generation of coverage paths for dispensing applications", "abstract": "Coverage Path Planning of Thermal Interface Materials (TIM) plays a crucial\nrole in the design of power electronics and electronic control units. Up to\nnow, this is done manually by experts or by using optimization approaches with\na high computational effort. We propose a novel AI-based approach to generate\ndispense paths for TIM and similar dispensing applications. It is a drop-in\nreplacement for optimization-based approaches. An Artificial Neural Network\n(ANN) receives the target cooling area as input and directly outputs the\ndispense path. Our proposed setup does not require labels and we show its\nfeasibility on multiple target areas. The resulting dispense paths can be\ndirectly transferred to automated manufacturing equipment and do not exhibit\nair entrapments. The approach of using an ANN to predict process parameters for\na desired target state in real-time could potentially be transferred to other\nmanufacturing processes.", "published": "2025-05-06 14:13:20", "link": "http://arxiv.org/abs/2505.03560v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID", "abstract": "The personalization of Stable Diffusion for generating professional portraits\nfrom amateur photographs is a burgeoning area, with applications in various\ndownstream contexts. This paper investigates the impact of augmentations on\nimproving facial resemblance when using two prominent personalization\ntechniques: DreamBooth and InstantID. Through a series of experiments with\ndiverse subject datasets, we assessed the effectiveness of various augmentation\nstrategies on the generated headshots' fidelity to the original subject. We\nintroduce FaceDistance, a wrapper around FaceNet, to rank the generations based\non facial similarity, which aided in our assessment. Ultimately, this research\nprovides insights into the role of augmentations in enhancing facial\nresemblance in SDXL-generated portraits, informing strategies for their\neffective deployment in downstream applications.", "published": "2025-05-06 14:11:02", "link": "http://arxiv.org/abs/2505.03557v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Hashgraph-Inspired Consensus Mechanism for Reliable Multi-Model Reasoning", "abstract": "Inconsistent outputs and hallucinations from large language models (LLMs) are\nmajor obstacles to reliable AI systems. When different proprietary reasoning\nmodels (RMs), such as those by OpenAI, Google, Anthropic, DeepSeek, and xAI,\nare given the same complex request, they often produce divergent results due to\nvariations in training and inference. This paper proposes a novel consensus\nmechanism, inspired by distributed ledger technology, to validate and converge\nthese outputs, treating each RM as a black-box peer. Building on the Hashgraph\nconsensus algorithm, our approach employs gossip-about-gossip communication and\nvirtual voting to achieve agreement among an ensemble of RMs. We present an\narchitectural design for a prototype system in which RMs iteratively exchange\nand update their answers, using information from each round to improve accuracy\nand confidence in subsequent rounds. This approach goes beyond simple majority\nvoting by incorporating the knowledge and cross-verification content of every\nmodel. We justify the feasibility of this Hashgraph-inspired consensus for AI\nensembles and outline its advantages over traditional ensembling techniques in\nreducing nonfactual outputs. Preliminary considerations for implementation,\nevaluation criteria for convergence and accuracy, and potential challenges are\ndiscussed. The proposed mechanism demonstrates a promising direction for\nmulti-agent AI systems to self-validate and deliver high-fidelity responses in\ncomplex tasks.", "published": "2025-05-06 14:05:12", "link": "http://arxiv.org/abs/2505.03553v1", "categories": ["cs.AI", "cs.DC"], "primary_category": "cs.AI"}
{"title": "STORY2GAME: Generating (Almost) Everything in an Interactive Fiction Game", "abstract": "We introduce STORY2GAME, a novel approach to using Large Language Models to\ngenerate text-based interactive fiction games that starts by generating a\nstory, populates the world, and builds the code for actions in a game engine\nthat enables the story to play out interactively. Whereas a given set of\nhard-coded actions can artificially constrain story generation, the ability to\ngenerate actions means the story generation process can be more open-ended but\nstill allow for experiences that are grounded in a game state. The key to\nsuccessful action generation is to use LLM-generated preconditions and effects\nof actions in the stories as guides for what aspects of the game state must be\ntracked and changed by the game engine when a player performs an action. We\nalso introduce a technique for dynamically generating new actions to\naccommodate the player's desire to perform actions that they think of that are\nnot part of the story. Dynamic action generation may require on-the-fly updates\nto the game engine's state representation and revision of previously generated\nactions. We evaluate the success rate of action code generation with respect to\nwhether a player can interactively play through the entire generated story.", "published": "2025-05-06 14:00:41", "link": "http://arxiv.org/abs/2505.03547v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Optimization of Module Transferability in Single Image Super-Resolution: Universality Assessment and Cycle Residual Blocks", "abstract": "Deep learning has substantially advanced the Single Image Super-Resolution\n(SISR). However, existing researches have predominantly focused on raw\nperformance gains, with little attention paid to quantifying the\ntransferability of architectural components. In this paper, we introduce the\nconcept of \"Universality\" and its associated definitions which extend the\ntraditional notion of \"Generalization\" to encompass the modules' ease of\ntransferability, thus revealing the relationships between module universality\nand model generalizability. Then we propose the Universality Assessment\nEquation (UAE), a metric for quantifying how readily a given module could be\ntransplanted across models. Guided by the UAE results of standard residual\nblocks and other plug-and-play modules, we further design two optimized\nmodules, Cycle Residual Block (CRB) and Depth-Wise Cycle Residual Block (DCRB).\nThrough comprehensive experiments on natural-scene benchmarks, remote-sensing\ndatasets, extreme-industrial imagery and on-device deployments, we demonstrate\nthat networks embedded with the proposed plug-and-play modules outperform\nseveral state-of-the-arts, reaching a PSNR enhancement of up to 0.83dB or\nenabling a 71.3% reduction in parameters with negligible loss in reconstruction\nfidelity.", "published": "2025-05-06 13:35:59", "link": "http://arxiv.org/abs/2505.03522v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "From Neurons to Computation: Biological Reservoir Computing for Pattern Recognition", "abstract": "In this paper, we introduce a novel paradigm for reservoir computing (RC)\nthat leverages a pool of cultured biological neurons as the reservoir\nsubstrate, creating a biological reservoir computing (BRC). This system\noperates similarly to an echo state network (ESN), with the key distinction\nthat the neural activity is generated by a network of cultured neurons, rather\nthan being modeled by traditional artificial computational units. The neuronal\nactivity is recorded using a multi-electrode array (MEA), which enables\nhigh-throughput recording of neural signals. In our approach, inputs are\nintroduced into the network through a subset of the MEA electrodes, while the\nremaining electrodes capture the resulting neural activity. This generates a\nnonlinear mapping of the input data to a high-dimensional biological feature\nspace, where distinguishing between data becomes more efficient and\nstraightforward, allowing a simple linear classifier to perform pattern\nrecognition tasks effectively. To evaluate the performance of our proposed\nsystem, we present an experimental study that includes various input patterns,\nsuch as positional codes, bars with different orientations, and a digit\nrecognition task. The results demonstrate the feasibility of using biological\nneural networks to perform tasks traditionally handled by artificial neural\nnetworks, paving the way for further exploration of biologically-inspired\ncomputing systems, with potential applications in neuromorphic engineering and\nbio-hybrid computing.", "published": "2025-05-06 13:20:04", "link": "http://arxiv.org/abs/2505.03510v1", "categories": ["cs.NE", "cs.AI", "cs.CV"], "primary_category": "cs.NE"}
{"title": "Augmenting Human Cognition through Everyday AR", "abstract": "As spatial computing and multimodal LLMs mature, AR is tending to become an\nintuitive \"thinking tool,\" embedding semantic and context-aware intelligence\ndirectly into everyday environments. This paper explores how always-on AR can\nseamlessly bridge digital cognition and physical affordances, enabling\nproactive, context-sensitive interactions that enhance human task performance\nand understanding.", "published": "2025-05-06 12:48:38", "link": "http://arxiv.org/abs/2505.03492v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "A new membership inference attack that spots memorization in generative and predictive models: Loss-Based with Reference Model algorithm (LBRM)", "abstract": "Generative models can unintentionally memorize training data, posing\nsignificant privacy risks. This paper addresses the memorization phenomenon in\ntime series imputation models, introducing the Loss-Based with Reference Model\n(LBRM) algorithm. The LBRM method leverages a reference model to enhance the\naccuracy of membership inference attacks, distinguishing between training and\ntest data. Our contributions are twofold: first, we propose an innovative\nmethod to effectively extract and identify memorized training data,\nsignificantly improving detection accuracy. On average, without fine-tuning,\nthe AUROC improved by approximately 40\\%. With fine-tuning, the AUROC increased\nby approximately 60\\%. Second, we validate our approach through membership\ninference attacks on two types of architectures designed for time series\nimputation, demonstrating the robustness and versatility of the LBRM approach\nin different contexts. These results highlight the significant enhancement in\ndetection accuracy provided by the LBRM approach, addressing privacy risks in\ntime series imputation models.", "published": "2025-05-06 12:47:24", "link": "http://arxiv.org/abs/2505.03490v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "am-ELO: A Stable Framework for Arena-based LLM Evaluation", "abstract": "Arena-based evaluation is a fundamental yet significant evaluation paradigm\nfor modern AI models, especially large language models (LLMs). Existing\nframework based on ELO rating system suffers from the inevitable instability\nproblem due to ranking inconsistency and the lack of attention to the varying\nabilities of annotators. In this paper, we introduce a novel stable arena\nframework to address these issues by enhancing the ELO Rating System.\nSpecifically, we replace the iterative update method with a Maximum Likelihood\nEstimation (MLE) approach, m-ELO, and provide theoretical proof of the\nconsistency and stability of the MLE approach for model ranking. Additionally,\nwe proposed the am-ELO, which modify the Elo Rating's probability function to\nincorporate annotator abilities, enabling the simultaneous estimation of model\nscores and annotator reliability. Experiments demonstrate that this method\nensures stability, proving that this framework offers a more robust, accurate,\nand stable evaluation method for LLMs.", "published": "2025-05-06 12:28:50", "link": "http://arxiv.org/abs/2505.03475v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Blending 3D Geometry and Machine Learning for Multi-View Stereopsis", "abstract": "Traditional multi-view stereo (MVS) methods primarily depend on photometric\nand geometric consistency constraints. In contrast, modern learning-based\nalgorithms often rely on the plane sweep algorithm to infer 3D geometry,\napplying explicit geometric consistency (GC) checks only as a post-processing\nstep, with no impact on the learning process itself. In this work, we introduce\nGC MVSNet plus plus, a novel approach that actively enforces geometric\nconsistency of reference view depth maps across multiple source views (multi\nview) and at various scales (multi scale) during the learning phase (see Fig.\n1). This integrated GC check significantly accelerates the learning process by\ndirectly penalizing geometrically inconsistent pixels, effectively halving the\nnumber of training iterations compared to other MVS methods. Furthermore, we\nintroduce a densely connected cost regularization network with two distinct\nblock designs simple and feature dense optimized to harness dense feature\nconnections for enhanced regularization. Extensive experiments demonstrate that\nour approach achieves a new state of the art on the DTU and BlendedMVS datasets\nand secures second place on the Tanks and Temples benchmark. To our knowledge,\nGC MVSNet plus plus is the first method to enforce multi-view, multi-scale\nsupervised geometric consistency during learning. Our code is available.", "published": "2025-05-06 12:22:45", "link": "http://arxiv.org/abs/2505.03470v1", "categories": ["cs.CV", "cs.AI", "cs.CG", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Detecting Quishing Attacks with Machine Learning Techniques Through QR Code Analysis", "abstract": "The rise of QR code based phishing (\"Quishing\") poses a growing cybersecurity\nthreat, as attackers increasingly exploit QR codes to bypass traditional\nphishing defenses. Existing detection methods predominantly focus on URL\nanalysis, which requires the extraction of the QR code payload, and may\ninadvertently expose users to malicious content. Moreover, QR codes can encode\nvarious types of data beyond URLs, such as Wi-Fi credentials and payment\ninformation, making URL-based detection insufficient for broader security\nconcerns. To address these gaps, we propose the first framework for quishing\ndetection that directly analyzes QR code structure and pixel patterns without\nextracting the embedded content. We generated a dataset of phishing and benign\nQR codes and we used it to train and evaluate multiple machine learning models,\nincluding Logistic Regression, Decision Trees, Random Forest, Naive Bayes,\nLightGBM, and XGBoost. Our best-performing model (XGBoost) achieves an AUC of\n0.9106, demonstrating the feasibility of QR-centric detection. Through feature\nimportance analysis, we identify key visual indicators of malicious intent and\nrefine our feature set by removing non-informative pixels, improving\nperformance to an AUC of 0.9133 with a reduced feature space. Our findings\nreveal that the structural features of QR code correlate strongly with phishing\nrisk. This work establishes a foundation for quishing mitigation and highlights\nthe potential of direct QR analysis as a critical layer in modern phishing\ndefenses.", "published": "2025-05-06 11:47:13", "link": "http://arxiv.org/abs/2505.03451v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "The Steganographic Potentials of Language Models", "abstract": "The potential for large language models (LLMs) to hide messages within plain\ntext (steganography) poses a challenge to detection and thwarting of unaligned\nAI agents, and undermines faithfulness of LLMs reasoning. We explore the\nsteganographic capabilities of LLMs fine-tuned via reinforcement learning (RL)\nto: (1) develop covert encoding schemes, (2) engage in steganography when\nprompted, and (3) utilize steganography in realistic scenarios where hidden\nreasoning is likely, but not prompted. In these scenarios, we detect the\nintention of LLMs to hide their reasoning as well as their steganography\nperformance. Our findings in the fine-tuning experiments as well as in\nbehavioral non fine-tuning evaluations reveal that while current models exhibit\nrudimentary steganographic abilities in terms of security and capacity,\nexplicit algorithmic guidance markedly enhances their capacity for information\nconcealment.", "published": "2025-05-06 11:25:52", "link": "http://arxiv.org/abs/2505.03439v1", "categories": ["cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents", "abstract": "Large Language Models (LLMs) represent a landmark achievement in Artificial\nIntelligence (AI), demonstrating unprecedented proficiency in procedural tasks\nsuch as text generation, code completion, and conversational coherence. These\ncapabilities stem from their architecture, which mirrors human procedural\nmemory -- the brain's ability to automate repetitive, pattern-driven tasks\nthrough practice. However, as LLMs are increasingly deployed in real-world\napplications, it becomes impossible to ignore their limitations operating in\ncomplex, unpredictable environments. This paper argues that LLMs, while\ntransformative, are fundamentally constrained by their reliance on procedural\nmemory. To create agents capable of navigating ``wicked'' learning environments\n-- where rules shift, feedback is ambiguous, and novelty is the norm -- we must\naugment LLMs with semantic memory and associative learning systems. By adopting\na modular architecture that decouples these cognitive functions, we can bridge\nthe gap between narrow procedural expertise and the adaptive intelligence\nrequired for real-world problem-solving.", "published": "2025-05-06 11:18:34", "link": "http://arxiv.org/abs/2505.03434v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Phenotype-Guided Generative Model for High-Fidelity Cardiac MRI Synthesis: Advancing Pretraining and Clinical Applications", "abstract": "Cardiac Magnetic Resonance (CMR) imaging is a vital non-invasive tool for\ndiagnosing heart diseases and evaluating cardiac health. However, the limited\navailability of large-scale, high-quality CMR datasets poses a major challenge\nto the effective application of artificial intelligence (AI) in this domain.\nEven the amount of unlabeled data and the health status it covers are difficult\nto meet the needs of model pretraining, which hinders the performance of AI\nmodels on downstream tasks. In this study, we present Cardiac Phenotype-Guided\nCMR Generation (CPGG), a novel approach for generating diverse CMR data that\ncovers a wide spectrum of cardiac health status. The CPGG framework consists of\ntwo stages: in the first stage, a generative model is trained using cardiac\nphenotypes derived from CMR data; in the second stage, a masked autoregressive\ndiffusion model, conditioned on these phenotypes, generates high-fidelity CMR\ncine sequences that capture both structural and functional features of the\nheart in a fine-grained manner. We synthesized a massive amount of CMR to\nexpand the pretraining data. Experimental results show that CPGG generates\nhigh-quality synthetic CMR data, significantly improving performance on various\ndownstream tasks, including diagnosis and cardiac phenotypes prediction. These\ngains are demonstrated across both public and private datasets, highlighting\nthe effectiveness of our approach. Code is availabel at\nhttps://anonymous.4open.science/r/CPGG.", "published": "2025-05-06 11:06:41", "link": "http://arxiv.org/abs/2505.03426v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Framework GNN-AID: Graph Neural Network Analysis Interpretation and Defense", "abstract": "The growing need for Trusted AI (TAI) highlights the importance of\ninterpretability and robustness in machine learning models. However, many\nexisting tools overlook graph data and rarely combine these two aspects into a\nsingle solution. Graph Neural Networks (GNNs) have become a popular approach,\nachieving top results across various tasks. We introduce GNN-AID (Graph Neural\nNetwork Analysis, Interpretation, and Defense), an open-source framework\ndesigned for graph data to address this gap. Built as a Python library, GNN-AID\nsupports advanced trust methods and architectural layers, allowing users to\nanalyze graph datasets and GNN behavior using attacks, defenses, and\ninterpretability methods.\n  GNN-AID is built on PyTorch-Geometric, offering preloaded datasets, models,\nand support for any GNNs through customizable interfaces. It also includes a\nweb interface with tools for graph visualization and no-code features like an\ninteractive model builder, simplifying the exploration and analysis of GNNs.\nThe framework also supports MLOps techniques, ensuring reproducibility and\nresult versioning to track and revisit analyses efficiently.\n  GNN-AID is a flexible tool for developers and researchers. It helps\ndevelopers create, analyze, and customize graph models, while also providing\naccess to prebuilt datasets and models for quick experimentation. Researchers\ncan use the framework to explore advanced topics on the relationship between\ninterpretability and robustness, test defense strategies, and combine methods\nto protect against different types of attacks.\n  We also show how defenses against evasion and poisoning attacks can conflict\nwhen applied to graph data, highlighting the complex connections between\ndefense strategies.\n  GNN-AID is available at\n\\href{https://github.com/ispras/GNN-AID}{github.com/ispras/GNN-AID}", "published": "2025-05-06 11:03:19", "link": "http://arxiv.org/abs/2505.03424v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation", "abstract": "Radiology Report Generation (RRG) automates the creation of radiology reports\nfrom medical imaging, enhancing the efficiency of the reporting process.\nLongitudinal Radiology Report Generation (LRRG) extends RRG by incorporating\nthe ability to compare current and prior exams, facilitating the tracking of\ntemporal changes in clinical findings. Existing LRRG approaches only extract\nfeatures from prior and current images using a visual pre-trained encoder,\nwhich are then concatenated to generate the final report. However, these\nmethods struggle to effectively capture both spatial and temporal correlations\nduring the feature extraction process. Consequently, the extracted features\ninadequately capture the information of difference across exams and thus\nunderrepresent the expected progressions, leading to sub-optimal performance in\nLRRG. To address this, we develop a novel dynamic difference-aware temporal\nresidual network (DDaTR). In DDaTR, we introduce two modules at each stage of\nthe visual encoder to capture multi-level spatial correlations. The Dynamic\nFeature Alignment Module (DFAM) is designed to align prior features across\nmodalities for the integrity of prior clinical information. Prompted by the\nenriched prior features, the dynamic difference-aware module (DDAM) captures\nfavorable difference information by identifying relationships across exams.\nFurthermore, our DDaTR employs the dynamic residual network to unidirectionally\ntransmit longitudinal information, effectively modelling temporal correlations.\nExtensive experiments demonstrated superior performance over existing methods\non three benchmarks, proving its efficacy in both RRG and LRRG tasks.", "published": "2025-05-06 10:29:23", "link": "http://arxiv.org/abs/2505.03401v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Automatic Calibration for Membership Inference Attack on Large Language Models", "abstract": "Membership Inference Attacks (MIAs) have recently been employed to determine\nwhether a specific text was part of the pre-training data of Large Language\nModels (LLMs). However, existing methods often misinfer non-members as members,\nleading to a high false positive rate, or depend on additional reference models\nfor probability calibration, which limits their practicality. To overcome these\nchallenges, we introduce a novel framework called Automatic Calibration\nMembership Inference Attack (ACMIA), which utilizes a tunable temperature to\ncalibrate output probabilities effectively. This approach is inspired by our\ntheoretical insights into maximum likelihood estimation during the pre-training\nof LLMs. We introduce ACMIA in three configurations designed to accommodate\ndifferent levels of model access and increase the probability gap between\nmembers and non-members, improving the reliability and robustness of membership\ninference. Extensive experiments on various open-source LLMs demonstrate that\nour proposed attack is highly effective, robust, and generalizable, surpassing\nstate-of-the-art baselines across three widely used benchmarks. Our code is\navailable at:\n\\href{https://github.com/Salehzz/ACMIA}{\\textcolor{blue}{Github}}.", "published": "2025-05-06 10:15:05", "link": "http://arxiv.org/abs/2505.03392v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Reinforced Correlation Between Vision and Language for Precise Medical AI Assistant", "abstract": "Medical AI assistants support doctors in disease diagnosis, medical image\nanalysis, and report generation. However, they still face significant\nchallenges in clinical use, including limited accuracy with multimodal content\nand insufficient validation in real-world settings. We propose RCMed, a\nfull-stack AI assistant that improves multimodal alignment in both input and\noutput, enabling precise anatomical delineation, accurate localization, and\nreliable diagnosis through hierarchical vision-language grounding. A\nself-reinforcing correlation mechanism allows visual features to inform\nlanguage context, while language semantics guide pixel-wise attention, forming\na closed loop that refines both modalities. This correlation is enhanced by a\ncolor region description strategy, translating anatomical structures into\nsemantically rich text to learn shape-location-text relationships across\nscales. Trained on 20 million image-mask-description triplets, RCMed achieves\nstate-of-the-art precision in contextualizing irregular lesions and subtle\nanatomical boundaries, excelling in 165 clinical tasks across 9 modalities. It\nachieved a 23.5% relative improvement in cell segmentation from microscopy\nimages over prior methods. RCMed's strong vision-language alignment enables\nexceptional generalization, with state-of-the-art performance in external\nvalidation across 20 clinically significant cancer types, including novel\ntasks. This work demonstrates how integrated multimodal models capture\nfine-grained patterns, enabling human-level interpretation in complex scenarios\nand advancing human-centric AI healthcare.", "published": "2025-05-06 10:00:08", "link": "http://arxiv.org/abs/2505.03380v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "SPAP: Structured Pruning via Alternating Optimization and Penalty Methods", "abstract": "The deployment of large language models (LLMs) is often constrained by their\nsubstantial computational and memory demands. While structured pruning presents\na viable approach by eliminating entire network components, existing methods\nsuffer from performance degradation, reliance on heuristic metrics, or\nexpensive finetuning. To address these challenges, we propose SPAP (Structured\nPruning via Alternating Optimization and Penalty Methods), a novel and\nefficient structured pruning framework for LLMs grounded in optimization\ntheory. SPAP formulates the pruning problem through a mixed-integer\noptimization model, employs a penalty method that effectively makes pruning\ndecisions to minimize pruning errors, and introduces an alternating\nminimization algorithm tailored to the splittable problem structure for\nefficient weight updates and performance recovery. Extensive experiments on\nOPT, LLaMA-3/3.1/3.2, and Qwen2.5 models demonstrate SPAP's superiority over\nstate-of-the-art methods, delivering linear inference speedups (1.29$\\times$ at\n30% sparsity) and proportional memory reductions. Our work offers a practical,\noptimization-driven solution for pruning LLMs while preserving model\nperformance.", "published": "2025-05-06 09:47:53", "link": "http://arxiv.org/abs/2505.03373v1", "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "cs.LG"}
{"title": "Validating the Effectiveness of a Large Language Model-based Approach for Identifying Children's Development across Various Free Play Settings in Kindergarten", "abstract": "Free play is a fundamental aspect of early childhood education, supporting\nchildren's cognitive, social, emotional, and motor development. However,\nassessing children's development during free play poses significant challenges\ndue to the unstructured and spontaneous nature of the activity. Traditional\nassessment methods often rely on direct observations by teachers, parents, or\nresearchers, which may fail to capture comprehensive insights from free play\nand provide timely feedback to educators. This study proposes an innovative\napproach combining Large Language Models (LLMs) with learning analytics to\nanalyze children's self-narratives of their play experiences. The LLM\nidentifies developmental abilities, while performance scores across different\nplay settings are calculated using learning analytics techniques. We collected\n2,224 play narratives from 29 children in a kindergarten, covering four\ndistinct play areas over one semester. According to the evaluation results from\neight professionals, the LLM-based approach achieved high accuracy in\nidentifying cognitive, motor, and social abilities, with accuracy exceeding 90%\nin most domains. Moreover, significant differences in developmental outcomes\nwere observed across play settings, highlighting each area's unique\ncontributions to specific abilities. These findings confirm that the proposed\napproach is effective in identifying children's development across various free\nplay settings. This study demonstrates the potential of integrating LLMs and\nlearning analytics to provide child-centered insights into developmental\ntrajectories, offering educators valuable data to support personalized learning\nand enhance early childhood education practices.", "published": "2025-05-06 09:40:47", "link": "http://arxiv.org/abs/2505.03369v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Domain Adversarial Training for Mitigating Gender Bias in Speech-based Mental Health Detection", "abstract": "Speech-based AI models are emerging as powerful tools for detecting\ndepression and the presence of Post-traumatic stress disorder (PTSD), offering\na non-invasive and cost-effective way to assess mental health. However, these\nmodels often struggle with gender bias, which can lead to unfair and inaccurate\npredictions. In this study, our study addresses this issue by introducing a\ndomain adversarial training approach that explicitly considers gender\ndifferences in speech-based depression and PTSD detection. Specifically, we\ntreat different genders as distinct domains and integrate this information into\na pretrained speech foundation model. We then validate its effectiveness on the\nE-DAIC dataset to assess its impact on performance. Experimental results show\nthat our method notably improves detection performance, increasing the F1-score\nby up to 13.29 percentage points compared to the baseline. This highlights the\nimportance of addressing demographic disparities in AI-driven mental health\nassessment.", "published": "2025-05-06 09:29:14", "link": "http://arxiv.org/abs/2505.03359v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Safer Prompts: Reducing IP Risk in Visual Generative AI", "abstract": "Visual Generative AI models have demonstrated remarkable capability in\ngenerating high-quality images from simple inputs like text prompts. However,\nbecause these models are trained on images from diverse sources, they risk\nmemorizing and reproducing specific content, raising concerns about\nintellectual property (IP) infringement. Recent advances in prompt engineering\noffer a cost-effective way to enhance generative AI performance. In this paper,\nwe evaluate the effectiveness of prompt engineering techniques in mitigating IP\ninfringement risks in image generation. Our findings show that Chain of Thought\nPrompting and Task Instruction Prompting significantly reduce the similarity\nbetween generated images and the training data of diffusion models, thereby\nlowering the risk of IP infringement.", "published": "2025-05-06 09:10:12", "link": "http://arxiv.org/abs/2505.03338v1", "categories": ["math.NA", "cs.AI", "cs.NA"], "primary_category": "math.NA"}
{"title": "Avoid Recommending Out-of-Domain Items: Constrained Generative Recommendation with LLMs", "abstract": "Large Language Models (LLMs) have shown promise for generative recommender\nsystems due to their transformative capabilities in user interaction. However,\nensuring they do not recommend out-of-domain (OOD) items remains a challenge.\nWe study two distinct methods to address this issue: RecLM-ret, a\nretrieval-based method, and RecLM-cgen, a constrained generation method. Both\nmethods integrate seamlessly with existing LLMs to ensure in-domain\nrecommendations. Comprehensive experiments on three recommendation datasets\ndemonstrate that RecLM-cgen consistently outperforms RecLM-ret and existing\nLLM-based recommender models in accuracy while eliminating OOD recommendations,\nmaking it the preferred method for adoption. Additionally, RecLM-cgen maintains\nstrong generalist capabilities and is a lightweight plug-and-play module for\neasy integration into LLMs, offering valuable practical benefits for the\ncommunity. Source code is available at https://github.com/microsoft/RecAI", "published": "2025-05-06 09:08:36", "link": "http://arxiv.org/abs/2505.03336v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning", "abstract": "Critical peer review of scientific manuscripts presents a significant\nchallenge for Large Language Models (LLMs), partly due to data limitations and\nthe complexity of expert reasoning. This report introduces Persistent Workflow\nPrompting (PWP), a potentially broadly applicable prompt engineering\nmethodology designed to bridge this gap using standard LLM chat interfaces\n(zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical\nanalysis of experimental chemistry manuscripts, featuring a hierarchical,\nmodular architecture (structured via Markdown) that defines detailed analysis\nworkflows. We develop this PWP prompt through iterative application of\nmeta-prompting techniques and meta-reasoning aimed at systematically codifying\nexpert review workflows, including tacit knowledge. Submitted once at the start\nof a session, this PWP prompt equips the LLM with persistent workflows\ntriggered by subsequent queries, guiding modern reasoning LLMs through\nsystematic, multimodal evaluations. Demonstrations show the PWP-guided LLM\nidentifying major methodological flaws in a test case while mitigating LLM\ninput bias and performing complex tasks, including distinguishing claims from\nevidence, integrating text/photo/figure analysis to infer parameters, executing\nquantitative feasibility checks, comparing estimates against claims, and\nassessing a priori plausibility. To ensure transparency and facilitate\nreplication, we provide full prompts, detailed demonstration analyses, and logs\nof interactive chats as supplementary resources. Beyond the specific\napplication, this work offers insights into the meta-development process\nitself, highlighting the potential of PWP, informed by detailed workflow\nformalization, to enable sophisticated analysis using readily available LLMs\nfor complex scientific tasks.", "published": "2025-05-06 09:06:18", "link": "http://arxiv.org/abs/2505.03332v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Very High-Resolution Forest Mapping with TanDEM-X InSAR Data and Self-Supervised Learning", "abstract": "Deep learning models have shown encouraging capabilities for mapping\naccurately forests at medium resolution with TanDEM-X interferometric SAR data.\nSuch models, as most of current state-of-the-art deep learning techniques in\nremote sensing, are trained in a fully-supervised way, which requires a large\namount of labeled data for training and validation. In this work, our aim is to\nexploit the high-resolution capabilities of the TanDEM-X mission to map forests\nat 6 m. The goal is to overcome the intrinsic limitations posed by\nmidresolution products, which affect, e.g., the detection of narrow roads\nwithin vegetated areas and the precise delineation of forested regions\ncontours. To cope with the lack of extended reliable reference datasets at such\na high resolution, we investigate self-supervised learning techniques for\nextracting highly informative representations from the input features, followed\nby a supervised training step with a significantly smaller number of reliable\nlabels. A 1 m resolution forest/non-forest reference map over Pennsylvania,\nUSA, allows for comparing different training approaches for the development of\nan effective forest mapping framework with limited labeled samples. We select\nthe best-performing approach over this test region and apply it in a real-case\nforest mapping scenario over the Amazon rainforest, where only very few labeled\ndata at high resolution are available. In this challenging scenario, the\nproposed self-supervised framework significantly enhances the classification\naccuracy with respect to fully-supervised methods, trained using the same\namount of labeled data, representing an extremely promising starting point for\nlarge-scale, very high-resolution forest mapping with TanDEM-X data.", "published": "2025-05-06 08:54:28", "link": "http://arxiv.org/abs/2505.03327v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "primary_category": "cs.CV"}
{"title": "SD-VSum: A Method and Dataset for Script-Driven Video Summarization", "abstract": "In this work, we introduce the task of script-driven video summarization,\nwhich aims to produce a summary of the full-length video by selecting the parts\nthat are most relevant to a user-provided script outlining the visual content\nof the desired summary. Following, we extend a recently-introduced large-scale\ndataset for generic video summarization (VideoXum) by producing natural\nlanguage descriptions of the different human-annotated summaries that are\navailable per video. In this way we make it compatible with the introduced\ntask, since the available triplets of ``video, summary and summary\ndescription'' can be used for training a method that is able to produce\ndifferent summaries for a given video, driven by the provided script about the\ncontent of each summary. Finally, we develop a new network architecture for\nscript-driven video summarization (SD-VSum), that relies on the use of a\ncross-modal attention mechanism for aligning and fusing information from the\nvisual and text modalities. Our experimental evaluations demonstrate the\nadvanced performance of SD-VSum against state-of-the-art approaches for\nquery-driven and generic (unimodal and multimodal) summarization from the\nliterature, and document its capacity to produce video summaries that are\nadapted to each user's needs about their content.", "published": "2025-05-06 08:47:14", "link": "http://arxiv.org/abs/2505.03319v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Artificial Behavior Intelligence: Technology, Challenges, and Future Directions", "abstract": "Understanding and predicting human behavior has emerged as a core capability\nin various AI application domains such as autonomous driving, smart healthcare,\nsurveillance systems, and social robotics. This paper defines the technical\nframework of Artificial Behavior Intelligence (ABI), which comprehensively\nanalyzes and interprets human posture, facial expressions, emotions, behavioral\nsequences, and contextual cues. It details the essential components of ABI,\nincluding pose estimation, face and emotion recognition, sequential behavior\nanalysis, and context-aware modeling. Furthermore, we highlight the\ntransformative potential of recent advances in large-scale pretrained models,\nsuch as large language models (LLMs), vision foundation models, and multimodal\nintegration models, in significantly improving the accuracy and\ninterpretability of behavior recognition. Our research team has a strong\ninterest in the ABI domain and is actively conducting research, particularly\nfocusing on the development of intelligent lightweight models capable of\nefficiently inferring complex human behaviors. This paper identifies several\ntechnical challenges that must be addressed to deploy ABI in real-world\napplications including learning behavioral intelligence from limited data,\nquantifying uncertainty in complex behavior prediction, and optimizing model\nstructures for low-power, real-time inference. To tackle these challenges, our\nteam is exploring various optimization strategies including lightweight\ntransformers, graph-based recognition architectures, energy-aware loss\nfunctions, and multimodal knowledge distillation, while validating their\napplicability in real-time environments.", "published": "2025-05-06 08:45:44", "link": "http://arxiv.org/abs/2505.03315v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Mamba-Diffusion Model with Learnable Wavelet for Controllable Symbolic Music Generation", "abstract": "The recent surge in the popularity of diffusion models for image synthesis\nhas attracted new attention to their potential for generation tasks in other\ndomains. However, their applications to symbolic music generation remain\nlargely under-explored because symbolic music is typically represented as\nsequences of discrete events and standard diffusion models are not well-suited\nfor discrete data. We represent symbolic music as image-like pianorolls,\nfacilitating the use of diffusion models for the generation of symbolic music.\nMoreover, this study introduces a novel diffusion model that incorporates our\nproposed Transformer-Mamba block and learnable wavelet transform.\nClassifier-free guidance is utilised to generate symbolic music with target\nchords. Our evaluation shows that our method achieves compelling results in\nterms of music quality and controllability, outperforming the strong baseline\nin pianoroll generation. Our code is available at\nhttps://github.com/jinchengzhanggg/proffusion.", "published": "2025-05-06 08:44:52", "link": "http://arxiv.org/abs/2505.03314v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Comparative Analysis of Lightweight Deep Learning Models for Memory-Constrained Devices", "abstract": "This paper presents a comprehensive evaluation of lightweight deep learning\nmodels for image classification, emphasizing their suitability for deployment\nin resource-constrained environments such as low-memory devices. Five\nstate-of-the-art architectures - MobileNetV3 Small, ResNet18, SqueezeNet,\nEfficientNetV2-S, and ShuffleNetV2 - are benchmarked across three diverse\ndatasets: CIFAR-10, CIFAR-100, and Tiny ImageNet. The models are assessed using\nfour key performance metrics: classification accuracy, inference time,\nfloating-point operations (FLOPs), and model size. Additionally, we investigate\nthe impact of hyperparameter tuning, data augmentation, and training paradigms\nby comparing pretrained models with scratch-trained counterparts, focusing on\nMobileNetV3 Small. Our findings reveal that transfer learning significantly\nenhances model accuracy and computational efficiency, particularly for complex\ndatasets like Tiny ImageNet. EfficientNetV2 consistently achieves the highest\naccuracy, while MobileNetV3 offers the best balance between accuracy and\nefficiency, and SqueezeNet excels in inference speed and compactness. This\nstudy highlights critical trade-offs between accuracy and efficiency, offering\nactionable insights for deploying lightweight models in real-world applications\nwhere computational resources are limited. By addressing these challenges, this\nresearch contributes to optimizing deep learning systems for edge computing and\nmobile platforms.", "published": "2025-05-06 08:36:01", "link": "http://arxiv.org/abs/2505.03303v1", "categories": ["cs.CV", "cs.AI", "68-XX (Primary) 68Txx, 68T07 (Secondary)"], "primary_category": "cs.CV"}
{"title": "Towards Efficient Benchmarking of Foundation Models in Remote Sensing: A Capabilities Encoding Approach", "abstract": "Foundation models constitute a significant advancement in computer vision:\nafter a single, albeit costly, training phase, they can address a wide array of\ntasks. In the field of Earth observation, over 75 remote sensing vision\nfoundation models have been developed in the past four years. However, none has\nconsistently outperformed the others across all available downstream tasks. To\nfacilitate their comparison, we propose a cost-effective method for predicting\na model's performance on multiple downstream tasks without the need for\nfine-tuning on each one. This method is based on what we call \"capabilities\nencoding.\" The utility of this novel approach is twofold: we demonstrate its\npotential to simplify the selection of a foundation model for a given new task,\nand we employ it to offer a fresh perspective on the existing literature,\nsuggesting avenues for future research. Codes are available at\nhttps://github.com/pierreadorni/capabilities-encoding.", "published": "2025-05-06 08:29:18", "link": "http://arxiv.org/abs/2505.03299v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Unreasonable Effectiveness of Discrete-Time Gaussian Process Mixtures for Robot Policy Learning", "abstract": "We present Mixture of Discrete-time Gaussian Processes (MiDiGap), a novel\napproach for flexible policy representation and imitation learning in robot\nmanipulation. MiDiGap enables learning from as few as five demonstrations using\nonly camera observations and generalizes across a wide range of challenging\ntasks. It excels at long-horizon behaviors such as making coffee, highly\nconstrained motions such as opening doors, dynamic actions such as scooping\nwith a spatula, and multimodal tasks such as hanging a mug. MiDiGap learns\nthese tasks on a CPU in less than a minute and scales linearly to large\ndatasets. We also develop a rich suite of tools for inference-time steering\nusing evidence such as collision signals and robot kinematic constraints. This\nsteering enables novel generalization capabilities, including obstacle\navoidance and cross-embodiment policy transfer. MiDiGap achieves\nstate-of-the-art performance on diverse few-shot manipulation benchmarks. On\nconstrained RLBench tasks, it improves policy success by 76 percentage points\nand reduces trajectory cost by 67%. On multimodal tasks, it improves policy\nsuccess by 48 percentage points and increases sample efficiency by a factor of\n20. In cross-embodiment transfer, it more than doubles policy success. We make\nthe code publicly available at https://midigap.cs.uni-freiburg.de.", "published": "2025-05-06 08:27:23", "link": "http://arxiv.org/abs/2505.03296v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing Existing Libraries and Interfaces", "abstract": "Modern automation systems increasingly rely on modular architectures, with\ncapabilities and skills as one solution approach. Capabilities define the\nfunctions of resources in a machine-readable form and skills provide the\nconcrete implementations that realize those capabilities. However, the\ndevelopment of a skill implementation conforming to a corresponding capability\nremains a time-consuming and challenging task. In this paper, we present a\nmethod that treats capabilities as contracts for skill implementations and\nleverages large language models to generate executable code based on natural\nlanguage user input. A key feature of our approach is the integration of\nexisting software libraries and interface technologies, enabling the generation\nof skill implementations across different target languages. We introduce a\nframework that allows users to incorporate their own libraries and resource\ninterfaces into the code generation process through a retrieval-augmented\ngeneration architecture. The proposed method is evaluated using an autonomous\nmobile robot controlled via Python and ROS 2, demonstrating the feasibility and\nflexibility of the approach.", "published": "2025-05-06 08:27:04", "link": "http://arxiv.org/abs/2505.03295v1", "categories": ["cs.AI", "cs.RO", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Physics-inspired Energy Transition Neural Network for Sequence Learning", "abstract": "Recently, the superior performance of Transformers has made them a more\nrobust and scalable solution for sequence modeling than traditional recurrent\nneural networks (RNNs). However, the effectiveness of Transformer in capturing\nlong-term dependencies is primarily attributed to their comprehensive\npair-modeling process rather than inherent inductive biases toward sequence\nsemantics. In this study, we explore the capabilities of pure RNNs and reassess\ntheir long-term learning mechanisms. Inspired by the physics energy transition\nmodels that track energy changes over time, we propose a effective recurrent\nstructure called the``Physics-inspired Energy Transition Neural Network\"\n(PETNN). We demonstrate that PETNN's memory mechanism effectively stores\ninformation over long-term dependencies. Experimental results indicate that\nPETNN outperforms transformer-based methods across various sequence tasks.\nFurthermore, owing to its recurrent nature, PETNN exhibits significantly lower\ncomplexity. Our study presents an optimal foundational recurrent architecture\nand highlights the potential for developing effective recurrent neural networks\nin fields currently dominated by Transformer.", "published": "2025-05-06 08:07:15", "link": "http://arxiv.org/abs/2505.03281v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation", "abstract": "Large language models (LLMs) struggle to effectively utilize a growing number\nof external tools, such as those defined by the Model Context Protocol\n(MCP)\\cite{IntroducingMCP}, due to prompt bloat and selection complexity. We\nintroduce RAG-MCP, a Retrieval-Augmented Generation framework that overcomes\nthis challenge by offloading tool discovery. RAG-MCP uses semantic retrieval to\nidentify the most relevant MCP(s) for a given query from an external index\nbefore engaging the LLM. Only the selected tool descriptions are passed to the\nmodel, drastically reducing prompt size and simplifying decision-making.\nExperiments, including an MCP stress test, demonstrate RAG-MCP significantly\ncuts prompt tokens (e.g., by over 50%) and more than triples tool selection\naccuracy (43.13% vs 13.62% baseline) on benchmark tasks. RAG-MCP enables\nscalable and accurate tool integration for LLMs.", "published": "2025-05-06 08:05:35", "link": "http://arxiv.org/abs/2505.03275v1", "categories": ["cs.AI", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Synthline: A Product Line Approach for Synthetic Requirements Engineering Data Generation using Large Language Models", "abstract": "While modern Requirements Engineering (RE) heavily relies on natural language\nprocessing and Machine Learning (ML) techniques, their effectiveness is limited\nby the scarcity of high-quality datasets. This paper introduces Synthline, a\nProduct Line (PL) approach that leverages Large Language Models to\nsystematically generate synthetic RE data for classification-based use cases.\nThrough an empirical evaluation conducted in the context of using ML for the\nidentification of requirements specification defects, we investigated both the\ndiversity of the generated data and its utility for training downstream models.\nOur analysis reveals that while synthetic datasets exhibit less diversity than\nreal data, they are good enough to serve as viable training resources.\nMoreover, our evaluation shows that combining synthetic and real data leads to\nsubstantial performance improvements. Specifically, hybrid approaches achieve\nup to 85% improvement in precision and a 2x increase in recall compared to\nmodels trained exclusively on real data. These findings demonstrate the\npotential of PL-based synthetic data generation to address data scarcity in RE.\nWe make both our implementation and generated datasets publicly available to\nsupport reproducibility and advancement in the field.", "published": "2025-05-06 07:57:16", "link": "http://arxiv.org/abs/2505.03265v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Seeing the Abstract: Translating the Abstract Language for Vision Language Models", "abstract": "Natural language goes beyond dryly describing visual content. It contains\nrich abstract concepts to express feeling, creativity and properties that\ncannot be directly perceived. Yet, current research in Vision Language Models\n(VLMs) has not shed light on abstract-oriented language. Our research breaks\nnew ground by uncovering its wide presence and under-estimated value, with\nextensive analysis. Particularly, we focus our investigation on the fashion\ndomain, a highly-representative field with abstract expressions. By analyzing\nrecent large-scale multimodal fashion datasets, we find that abstract terms\nhave a dominant presence, rivaling the concrete ones, providing novel\ninformation, and being useful in the retrieval task. However, a critical\nchallenge emerges: current general-purpose or fashion-specific VLMs are\npre-trained with databases that lack sufficient abstract words in their text\ncorpora, thus hindering their ability to effectively represent\nabstract-oriented language. We propose a training-free and model-agnostic\nmethod, Abstract-to-Concrete Translator (ACT), to shift abstract\nrepresentations towards well-represented concrete ones in the VLM latent space,\nusing pre-trained models and existing multimodal databases. On the\ntext-to-image retrieval task, despite being training-free, ACT outperforms the\nfine-tuned VLMs in both same- and cross-dataset settings, exhibiting its\neffectiveness with a strong generalization capability. Moreover, the\nimprovement introduced by ACT is consistent with various VLMs, making it a\nplug-and-play solution.", "published": "2025-05-06 07:14:10", "link": "http://arxiv.org/abs/2505.03242v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Accelerating Evolution: Integrating PSO Principles into Real-Coded Genetic Algorithm Crossover", "abstract": "This study introduces an innovative crossover operator named Particle Swarm\nOptimization-inspired Crossover (PSOX), which is specifically developed for\nreal-coded genetic algorithms. Departing from conventional crossover approaches\nthat only exchange information between individuals within the same generation,\nPSOX uniquely incorporates guidance from both the current global best solution\nand historical optimal solutions across multiple generations. This novel\nmechanism enables the algorithm to maintain population diversity while\nsimultaneously accelerating convergence toward promising regions of the search\nspace. The effectiveness of PSOX is rigorously evaluated through comprehensive\nexperiments on 15 benchmark test functions with diverse characteristics,\nincluding unimodal, multimodal, and highly complex landscapes. Comparative\nanalysis against five state-of-the-art crossover operators reveals that PSOX\nconsistently delivers superior performance in terms of solution accuracy,\nalgorithmic stability, and convergence speed, especially when combined with an\nappropriate mutation strategy. Furthermore, the study provides an in-depth\ninvestigation of how different mutation rates influence PSOX's performance,\nyielding practical guidelines for parameter tuning when addressing optimization\nproblems with varying landscape properties.", "published": "2025-05-06 06:17:57", "link": "http://arxiv.org/abs/2505.03217v1", "categories": ["cs.NE", "cs.AI", "I.2.8; G.1.6"], "primary_category": "cs.NE"}
{"title": "DocSpiral: A Platform for Integrated Assistive Document Annotation through Human-in-the-Spiral", "abstract": "Acquiring structured data from domain-specific, image-based documents such as\nscanned reports is crucial for many downstream tasks but remains challenging\ndue to document variability. Many of these documents exist as images rather\nthan as machine-readable text, which requires human annotation to train\nautomated extraction systems. We present DocSpiral, the first\nHuman-in-the-Spiral assistive document annotation platform, designed to address\nthe challenge of extracting structured information from domain-specific,\nimage-based document collections. Our spiral design establishes an iterative\ncycle in which human annotations train models that progressively require less\nmanual intervention. DocSpiral integrates document format normalization,\ncomprehensive annotation interfaces, evaluation metrics dashboard, and API\nendpoints for the development of AI / ML models into a unified workflow.\nExperiments demonstrate that our framework reduces annotation time by at least\n41\\% while showing consistent performance gains across three iterations during\nmodel training. By making this annotation platform freely accessible, we aim to\nlower barriers to AI/ML models development in document processing, facilitating\nthe adoption of large language models in image-based, document-intensive fields\nsuch as geoscience and healthcare. The system is freely available at:\nhttps://app.ai4wa.com. The demonstration video is available:\nhttps://app.ai4wa.com/docs/docspiral/demo.", "published": "2025-05-06 06:02:42", "link": "http://arxiv.org/abs/2505.03214v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "DCS-ST for Classification of Breast Cancer Histopathology Images with Limited Annotations", "abstract": "Deep learning methods have shown promise in classifying breast cancer\nhistopathology images, but their performance often declines with limited\nannotated data, a critical challenge in medical imaging due to the high cost\nand expertise required for annotations.", "published": "2025-05-06 05:38:17", "link": "http://arxiv.org/abs/2505.03204v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case", "abstract": "Large Language Models (LLMs) demonstrate strong potential across a variety of\ntasks in communications and networking due to their advanced reasoning\ncapabilities. However, because different LLMs have different model structures\nand are trained using distinct corpora and methods, they may offer varying\noptimization strategies for the same network issues. Moreover, the limitations\nof an individual LLM's training data, aggravated by the potential maliciousness\nof its hosting device, can result in responses with low confidence or even\nbias. To address these challenges, we propose a blockchain-enabled\ncollaborative framework that connects multiple LLMs into a Trustworthy\nMulti-LLM Network (MultiLLMN). This architecture enables the cooperative\nevaluation and selection of the most reliable and high-quality responses to\ncomplex network optimization problems. Specifically, we begin by reviewing\nrelated work and highlighting the limitations of existing LLMs in collaboration\nand trust, emphasizing the need for trustworthiness in LLM-based systems. We\nthen introduce the workflow and design of the proposed Trustworthy MultiLLMN\nframework. Given the severity of False Base Station (FBS) attacks in B5G and 6G\ncommunication systems and the difficulty of addressing such threats through\ntraditional modeling techniques, we present FBS defense as a case study to\nempirically validate the effectiveness of our approach. Finally, we outline\npromising future research directions in this emerging area.", "published": "2025-05-06 05:32:46", "link": "http://arxiv.org/abs/2505.03196v1", "categories": ["cs.NI", "cs.AI"], "primary_category": "cs.NI"}
{"title": "A study on audio synchronous steganography detection and distributed guide inference model based on sliding spectral features and intelligent inference drive", "abstract": "With the rise of short video platforms in global communication, embedding\nsteganographic data in audio synchronization streams has emerged as a new\ncovert communication method. To address the limitations of traditional\ntechniques in detecting synchronized steganography, this paper proposes a\ndetection and distributed guidance reconstruction model based on short video\n\"Yupan\" samples released by China's South Sea Fleet on TikTok. The method\nintegrates sliding spectrum feature extraction and intelligent inference\nmechanisms. A 25 ms sliding window with short-time Fourier transform (STFT) is\nused to extract the main frequency trajectory and construct the synchronization\nframe detection model (M1), identifying a frame flag \"FFFFFFFFFFFFFFFFFF80\".\nThe subsequent 32-byte payload is decoded by a structured model (M2) to infer\ndistributed guidance commands. Analysis reveals a low-entropy, repetitive byte\nsequence in the 36 to 45 second audio segment with highly concentrated spectral\nenergy, confirming the presence of synchronization frames. Although plaintext\nsemantics are not restored, the consistency in command field layout suggests\nfeatures of military communication protocols. The multi-segment splicing model\nfurther shows cross-video embedding and centralized decoding capabilities. The\nproposed framework validates the effectiveness of sliding spectral features for\nsynchronized steganography detection and builds an extensible inference model\nfor covert communication analysis and tactical guidance simulation on open\nplatforms.", "published": "2025-05-06 05:24:11", "link": "http://arxiv.org/abs/2505.03193v1", "categories": ["cs.SD", "cs.AI", "cs.CR", "eess.AS", "94A12 (Primary), 68T07, 42A38 (Secondary)", "H.3.3; I.5.4; I.2.6"], "primary_category": "cs.SD"}
{"title": "Patterns and Mechanisms of Contrastive Activation Engineering", "abstract": "Controlling the behavior of Large Language Models (LLMs) remains a\nsignificant challenge due to their inherent complexity and opacity. While\ntechniques like fine-tuning can modify model behavior, they typically require\nextensive computational resources. Recent work has introduced a class of\ncontrastive activation engineering (CAE) techniques as promising approaches for\nsteering LLM outputs through targeted modifications to their internal\nrepresentations. Applied at inference-time with zero cost, CAE has the\npotential to introduce a new paradigm of flexible, task-specific LLM behavior\ntuning. We analyze the performance of CAE in in-distribution,\nout-of-distribution settings, evaluate drawbacks, and begin to develop\ncomprehensive guidelines for its effective deployment. We find that 1. CAE is\nonly reliably effective when applied to in-distribution contexts. 2. Increasing\nthe number of samples used to generate steering vectors has diminishing returns\nat around 80 samples. 3. Steering vectors are susceptible to adversarial inputs\nthat reverses the behavior that is steered for. 4. Steering vectors harm the\noverall model perplexity. 5. Larger models are more resistant to\nsteering-induced degradation.", "published": "2025-05-06 05:15:12", "link": "http://arxiv.org/abs/2505.03189v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models", "abstract": "Current self-supervised algorithms mostly rely on transformations such as\ndata augmentation and masking to learn visual representations. This is achieved\nby inducing invariance or equivariance with respect to these transformations\nafter encoding two views of an image. This dominant two-view paradigm can limit\nthe flexibility of learned representations for downstream adaptation by\ncreating performance trade-offs between invariance-related tasks such as image\nclassification and more fine-grained equivariance-related tasks. In this work,\nwe introduce \\emph{seq-JEPA}, a world modeling paradigm based on\njoint-embedding predictive architecture that leverages architectural inductive\nbiases to resolve this trade-off. Without requiring an additional equivariance\npredictor or loss term, seq-JEPA simultaneously learns two architecturally\nsegregated representations: one equivariant to the specified transformations\nand another invariant to them and suited for tasks such as classification. To\ndo so, our model processes a short sequence of different views (observations)\nof an input image. Each encoded view is concatenated with embeddings\ncorresponding to the relative transformation (action) producing the next\nobservation in the sequence. A transformer encoder outputs an aggregate\nrepresentation of this sequence, which is subsequently conditioned on the\naction leading to the next observation to predict its representation.\nEmpirically, seq-JEPA achieves strong performance on equivariant benchmarks and\nimage classification without sacrificing one for the other. Additionally, our\nframework excels at tasks that inherently require aggregating a sequence of\nobservations, such as path integration across actions and predictive learning\nacross eye movements.", "published": "2025-05-06 04:39:11", "link": "http://arxiv.org/abs/2505.03176v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "RAVU: Retrieval Augmented Video Understanding with Compositional Reasoning over Graph", "abstract": "Comprehending long videos remains a significant challenge for Large\nMulti-modal Models (LMMs). Current LMMs struggle to process even minutes to\nhours videos due to their lack of explicit memory and retrieval mechanisms. To\naddress this limitation, we propose RAVU (Retrieval Augmented Video\nUnderstanding), a novel framework for video understanding enhanced by retrieval\nwith compositional reasoning over a spatio-temporal graph. We construct a graph\nrepresentation of the video, capturing both spatial and temporal relationships\nbetween entities. This graph serves as a long-term memory, allowing us to track\nobjects and their actions across time. To answer complex queries, we decompose\nthe queries into a sequence of reasoning steps and execute these steps on the\ngraph, retrieving relevant key information. Our approach enables more accurate\nunderstanding of long videos, particularly for queries that require multi-hop\nreasoning and tracking objects across frames. Our approach demonstrate superior\nperformances with limited retrieved frames (5-10) compared with other SOTA\nmethods and baselines on two major video QA datasets, NExT-QA and EgoSchema.", "published": "2025-05-06 04:38:09", "link": "http://arxiv.org/abs/2505.03173v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Null Counterfactual Factor Interactions for Goal-Conditioned Reinforcement Learning", "abstract": "Hindsight relabeling is a powerful tool for overcoming sparsity in\ngoal-conditioned reinforcement learning (GCRL), especially in certain domains\nsuch as navigation and locomotion. However, hindsight relabeling can struggle\nin object-centric domains. For example, suppose that the goal space consists of\na robotic arm pushing a particular target block to a goal location. In this\ncase, hindsight relabeling will give high rewards to any trajectory that does\nnot interact with the block. However, these behaviors are only useful when the\nobject is already at the goal -- an extremely rare case in practice. A dataset\ndominated by these kinds of trajectories can complicate learning and lead to\nfailures. In object-centric domains, one key intuition is that meaningful\ntrajectories are often characterized by object-object interactions such as\npushing the block with the gripper. To leverage this intuition, we introduce\nHindsight Relabeling using Interactions (HInt), which combines interactions\nwith hindsight relabeling to improve the sample efficiency of downstream RL.\nHowever because interactions do not have a consensus statistical definition\ntractable for downstream GCRL, we propose a definition of interactions based on\nthe concept of null counterfactual: a cause object is interacting with a target\nobject if, in a world where the cause object did not exist, the target object\nwould have different transition dynamics. We leverage this definition to infer\ninteractions in Null Counterfactual Interaction Inference (NCII), which uses a\n\"nulling'' operation with a learned model to infer interactions. NCII is able\nto achieve significantly improved interaction inference accuracy in both simple\nlinear dynamics domains and dynamic robotic domains in Robosuite, Robot Air\nHockey, and Franka Kitchen and HInt improves sample efficiency by up to 4x.", "published": "2025-05-06 04:32:47", "link": "http://arxiv.org/abs/2505.03172v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CombiBench: Benchmarking LLM Capability for Combinatorial Mathematics", "abstract": "Neurosymbolic approaches integrating large language models with formal\nreasoning have recently achieved human-level performance on mathematics\ncompetition problems in algebra, geometry and number theory. In comparison,\ncombinatorics remains a challenging domain, characterized by a lack of\nappropriate benchmarks and theorem libraries. To address this gap, we introduce\nCombiBench, a comprehensive benchmark comprising 100 combinatorial problems,\neach formalized in Lean~4 and paired with its corresponding informal statement.\nThe problem set covers a wide spectrum of difficulty levels, ranging from\nmiddle school to IMO and university level, and span over ten combinatorial\ntopics. CombiBench is suitable for testing IMO solving capabilities since it\nincludes all IMO combinatorial problems since 2000 (except IMO 2004 P3 as its\nstatement contain an images). Furthermore, we provide a comprehensive and\nstandardized evaluation framework, dubbed Fine-Eval (for\n$\\textbf{F}$ill-in-the-blank $\\textbf{in}$ L$\\textbf{e}$an Evaluation), for\nformal mathematics. It accommodates not only proof-based problems but also, for\nthe first time, the evaluation of fill-in-the-blank questions. Using Fine-Eval\nas the evaluation method and Kimina Lean Server as the backend, we benchmark\nseveral LLMs on CombiBench and observe that their capabilities for formally\nsolving combinatorial problems remain limited. Among all models tested (none of\nwhich has been trained for this particular task), Kimina-Prover attains the\nbest results, solving 7 problems (out of 100) under both ``with solution'' and\n``without solution'' scenarios. We open source the benchmark dataset alongside\nwith the code of the proposed evaluation method at\nhttps://github.com/MoonshotAI/CombiBench/.", "published": "2025-05-06 04:32:17", "link": "http://arxiv.org/abs/2505.03171v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Soft Best-of-n Sampling for Model Alignment", "abstract": "Best-of-$n$ (BoN) sampling is a practical approach for aligning language\nmodel outputs with human preferences without expensive fine-tuning. BoN\nsampling is performed by generating $n$ responses to a prompt and then\nselecting the sample that maximizes a reward function. BoN yields high reward\nvalues in practice at a distortion cost, as measured by the KL-divergence\nbetween the sampled and original distribution. This distortion is coarsely\ncontrolled by varying the number of samples: larger $n$ yields a higher reward\nat a higher distortion cost. We introduce Soft Best-of-$n$ sampling, a\ngeneralization of BoN that allows for smooth interpolation between the original\ndistribution and reward-maximizing distribution through a temperature parameter\n$\\lambda$. We establish theoretical guarantees showing that Soft Best-of-$n$\nsampling converges sharply to the optimal tilted distribution at a rate of\n$O(1/n)$ in KL and the expected (relative) reward. For sequences of discrete\noutputs, we analyze an additive reward model that reveals the fundamental\nlimitations of blockwise sampling.", "published": "2025-05-06 04:03:11", "link": "http://arxiv.org/abs/2505.03156v1", "categories": ["cs.IT", "cs.AI", "math.IT"], "primary_category": "cs.IT"}
{"title": "StableMotion: Training Motion Cleanup Models with Unpaired Corrupted Data", "abstract": "Motion capture (mocap) data often exhibits visually jarring artifacts due to\ninaccurate sensors and post-processing. Cleaning this corrupted data can\nrequire substantial manual effort from human experts, which can be a costly and\ntime-consuming process. Previous data-driven motion cleanup methods offer the\npromise of automating this cleanup process, but often require in-domain paired\ncorrupted-to-clean training data. Constructing such paired datasets requires\naccess to high-quality, relatively artifact-free motion clips, which often\nnecessitates laborious manual cleanup. In this work, we present StableMotion, a\nsimple yet effective method for training motion cleanup models directly from\nunpaired corrupted datasets that need cleanup. The core component of our method\nis the introduction of motion quality indicators, which can be easily annotated\nthrough manual labeling or heuristic algorithms and enable training of\nquality-aware motion generation models on raw motion data with mixed quality.\nAt test time, the model can be prompted to generate high-quality motions using\nthe quality indicators. Our method can be implemented through a simple\ndiffusion-based framework, leading to a unified motion generate-discriminate\nmodel, which can be used to both identify and fix corrupted frames. We\ndemonstrate that our proposed method is effective for training motion cleanup\nmodels on raw mocap data in production scenarios by applying StableMotion to\nSoccerMocap, a 245-hour soccer mocap dataset containing real-world motion\nartifacts. The trained model effectively corrects a wide range of motion\nartifacts, reducing motion pops and frozen frames by 68% and 81%, respectively.\nSee https://youtu.be/3Y7MMAH02B4 for more results.", "published": "2025-05-06 04:02:47", "link": "http://arxiv.org/abs/2505.03154v1", "categories": ["cs.CV", "cs.AI", "cs.GR"], "primary_category": "cs.CV"}
{"title": "Motion-compensated cardiac MRI using low-rank diffeomorphic flow (DMoCo)", "abstract": "We introduce an unsupervised motion-compensated image reconstruction\nalgorithm for free-breathing and ungated 3D cardiac magnetic resonance imaging\n(MRI). We express the image volume corresponding to each specific motion phase\nas the deformation of a single static image template. The main contribution of\nthe work is the low-rank model for the compact joint representation of the\nfamily of diffeomorphisms, parameterized by the motion phases. The\ndiffeomorphism at a specific motion phase is obtained by integrating a\nparametric velocity field along a path connecting the reference template phase\nto the motion phase. The velocity field at different phases is represented\nusing a low-rank model. The static template and the low-rank motion model\nparameters are learned directly from the k-space data in an unsupervised\nfashion. The more constrained motion model is observed to offer improved\nrecovery compared to current motion-resolved and motion-compensated algorithms\nfor free-breathing 3D cine MRI.", "published": "2025-05-06 03:52:17", "link": "http://arxiv.org/abs/2505.03149v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Holmes: Automated Fact Check with Large Language Models", "abstract": "The rise of Internet connectivity has accelerated the spread of\ndisinformation, threatening societal trust, decision-making, and national\nsecurity. Disinformation has evolved from simple text to complex multimodal\nforms combining images and text, challenging existing detection methods.\nTraditional deep learning models struggle to capture the complexity of\nmultimodal disinformation. Inspired by advances in AI, this study explores\nusing Large Language Models (LLMs) for automated disinformation detection. The\nempirical study shows that (1) LLMs alone cannot reliably assess the\ntruthfulness of claims; (2) providing relevant evidence significantly improves\ntheir performance; (3) however, LLMs cannot autonomously search for accurate\nevidence. To address this, we propose Holmes, an end-to-end framework featuring\na novel evidence retrieval method that assists LLMs in collecting high-quality\nevidence. Our approach uses (1) LLM-powered summarization to extract key\ninformation from open sources and (2) a new algorithm and metrics to evaluate\nevidence quality. Holmes enables LLMs to verify claims and generate\njustifications effectively. Experiments show Holmes achieves 88.3% accuracy on\ntwo open-source datasets and 90.2% in real-time verification tasks. Notably,\nour improved evidence retrieval boosts fact-checking accuracy by 30.8% over\nexisting methods", "published": "2025-05-06 03:19:51", "link": "http://arxiv.org/abs/2505.03135v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "VISLIX: An XAI Framework for Validating Vision Models with Slice Discovery and Analysis", "abstract": "Real-world machine learning models require rigorous evaluation before\ndeployment, especially in safety-critical domains like autonomous driving and\nsurveillance. The evaluation of machine learning models often focuses on data\nslices, which are subsets of the data that share a set of characteristics. Data\nslice finding automatically identifies conditions or data subgroups where\nmodels underperform, aiding developers in mitigating performance issues.\nDespite its popularity and effectiveness, data slicing for vision model\nvalidation faces several challenges. First, data slicing often needs additional\nimage metadata or visual concepts, and falls short in certain computer vision\ntasks, such as object detection. Second, understanding data slices is a\nlabor-intensive and mentally demanding process that heavily relies on the\nexpert's domain knowledge. Third, data slicing lacks a human-in-the-loop\nsolution that allows experts to form hypothesis and test them interactively. To\novercome these limitations and better support the machine learning operations\nlifecycle, we introduce VISLIX, a novel visual analytics framework that employs\nstate-of-the-art foundation models to help domain experts analyze slices in\ncomputer vision models. Our approach does not require image metadata or visual\nconcepts, automatically generates natural language insights, and allows users\nto test data slice hypothesis interactively. We evaluate VISLIX with an expert\nstudy and three use cases, that demonstrate the effectiveness of our tool in\nproviding comprehensive insights for validating object detection models.", "published": "2025-05-06 03:09:15", "link": "http://arxiv.org/abs/2505.03132v1", "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Is AI currently capable of identifying wild oysters? A comparison of human annotators against the AI model, ODYSSEE", "abstract": "Oysters are ecologically and commercially important species that require\nfrequent monitoring to track population demographics (e.g. abundance, growth,\nmortality). Current methods of monitoring oyster reefs often require\ndestructive sampling methods and extensive manual effort. Therefore, they are\nsuboptimal for small-scale or sensitive environments. A recent alternative, the\nODYSSEE model, was developed to use deep learning techniques to identify live\noysters using video or images taken in the field of oyster reefs to assess\nabundance. The validity of this model in identifying live oysters on a reef was\ncompared to expert and non-expert annotators. In addition, we identified\npotential sources of prediction error. Although the model can make inferences\nsignificantly faster than expert and non-expert annotators (39.6 s, $2.34 \\pm\n0.61$ h, $4.50 \\pm 1.46$ h, respectively), the model overpredicted the number\nof live oysters, achieving lower accuracy (63\\%) in identifying live oysters\ncompared to experts (74\\%) and non-experts (75\\%) alike. Image quality was an\nimportant factor in determining the accuracy of the model and the annotators.\nBetter quality images improved human accuracy and worsened model accuracy.\nAlthough ODYSSEE was not sufficiently accurate, we anticipate that future\ntraining on higher-quality images, utilizing additional live imagery, and\nincorporating additional annotation training classes will greatly improve the\nmodel's predictive power based on the results of this analysis. Future research\nshould address methods that improve the detection of living vs. dead oysters.", "published": "2025-05-06 02:01:27", "link": "http://arxiv.org/abs/2505.03108v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Cognitio Emergens: Agency, Dimensions, and Dynamics in Human-AI Knowledge Co-Creation", "abstract": "Scientific knowledge creation is fundamentally transforming as humans and AI\nsystems evolve beyond tool-user relationships into co-evolutionary epistemic\npartnerships. When AlphaFold revolutionized protein structure prediction,\nresearchers described engaging with an epistemic partner that reshaped how they\nconceptualized fundamental relationships. This article introduces Cognitio\nEmergens (CE), a framework addressing critical limitations in existing models\nthat focus on static roles or narrow metrics while failing to capture how\nscientific understanding emerges through recursive human-AI interaction over\ntime. CE integrates three components addressing these limitations: Agency\nConfigurations describing how authority distributes between humans and AI\n(Directed, Contributory, Partnership), with partnerships dynamically\noscillating between configurations rather than following linear progression;\nEpistemic Dimensions capturing six specific capabilities emerging through\ncollaboration across Discovery, Integration, and Projection axes, creating\ndistinctive \"capability signatures\" that guide development; and Partnership\nDynamics identifying forces shaping how these relationships evolve,\nparticularly the risk of epistemic alienation where researchers lose\ninterpretive control over knowledge they formally endorse. Drawing from\nautopoiesis theory, social systems theory, and organizational modularity, CE\nreveals how knowledge co-creation emerges through continuous negotiation of\nroles, values, and organizational structures. By reconceptualizing human-AI\nscientific collaboration as fundamentally co-evolutionary, CE offers a balanced\nperspective that neither uncritically celebrates nor unnecessarily fears AI's\nevolving role, instead providing conceptual tools for cultivating partnerships\nthat maintain meaningful human participation while enabling transformative\nscientific breakthroughs.", "published": "2025-05-06 01:49:44", "link": "http://arxiv.org/abs/2505.03105v1", "categories": ["cs.HC", "cs.AI", "cs.CY", "H.5.3; I.2.11; K.4.3; H.1.2; I.2.4"], "primary_category": "cs.HC"}
{"title": "Assessing and Enhancing the Robustness of LLM-based Multi-Agent Systems Through Chaos Engineering", "abstract": "This study explores the application of chaos engineering to enhance the\nrobustness of Large Language Model-Based Multi-Agent Systems (LLM-MAS) in\nproduction-like environments under real-world conditions. LLM-MAS can\npotentially improve a wide range of tasks, from answering questions and\ngenerating content to automating customer support and improving decision-making\nprocesses. However, LLM-MAS in production or preproduction environments can be\nvulnerable to emergent errors or disruptions, such as hallucinations, agent\nfailures, and agent communication failures. This study proposes a chaos\nengineering framework to proactively identify such vulnerabilities in LLM-MAS,\nassess and build resilience against them, and ensure reliable performance in\ncritical applications.", "published": "2025-05-06 01:13:14", "link": "http://arxiv.org/abs/2505.03096v1", "categories": ["cs.MA", "cs.AI", "cs.SE"], "primary_category": "cs.MA"}
{"title": "Latent Adaptive Planner for Dynamic Manipulation", "abstract": "This paper presents Latent Adaptive Planner (LAP), a novel approach for\ndynamic nonprehensile manipulation tasks that formulates planning as latent\nspace inference, effectively learned from human demonstration videos. Our\nmethod addresses key challenges in visuomotor policy learning through a\nprincipled variational replanning framework that maintains temporal consistency\nwhile efficiently adapting to environmental changes. LAP employs Bayesian\nupdating in latent space to incrementally refine plans as new observations\nbecome available, striking an optimal balance between computational efficiency\nand real-time adaptability. We bridge the embodiment gap between humans and\nrobots through model-based proportional mapping that regenerates accurate\nkinematic-dynamic joint states and object positions from human demonstrations.\nExperimental evaluations across multiple complex manipulation benchmarks\ndemonstrate that LAP achieves state-of-the-art performance, outperforming\nexisting approaches in success rate, trajectory smoothness, and energy\nefficiency, particularly in dynamic adaptation scenarios. Our approach enables\nrobots to perform complex interactions with human-like adaptability while\nproviding an expandable framework applicable to diverse robotic platforms using\nthe same human demonstration videos.", "published": "2025-05-06 00:09:09", "link": "http://arxiv.org/abs/2505.03077v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Multi-Agent System for Comprehensive Soccer Understanding", "abstract": "Recent advancements in AI-driven soccer understanding have demonstrated rapid\nprogress, yet existing research predominantly focuses on isolated or narrow\ntasks. To bridge this gap, we propose a comprehensive framework for holistic\nsoccer understanding. Specifically, we make the following contributions in this\npaper: (i) we construct SoccerWiki, the first large-scale multimodal soccer\nknowledge base, integrating rich domain knowledge about players, teams,\nreferees, and venues to enable knowledge-driven reasoning; (ii) we present\nSoccerBench, the largest and most comprehensive soccer-specific benchmark,\nfeaturing around 10K standardized multimodal (text, image, video) multi-choice\nQA pairs across 13 distinct understanding tasks, curated through automated\npipelines and manual verification; (iii) we introduce SoccerAgent, a novel\nmulti-agent system that decomposes complex soccer questions via collaborative\nreasoning, leveraging domain expertise from SoccerWiki and achieving robust\nperformance; (iv) extensive evaluations and ablations that benchmark\nstate-of-the-art MLLMs on SoccerBench, highlighting the superiority of our\nproposed agentic system. All data and code are publicly available at:\nhttps://jyrao.github.io/SoccerAgent/.", "published": "2025-05-06 17:59:31", "link": "http://arxiv.org/abs/2505.03735v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visual Imitation Enables Contextual Humanoid Control", "abstract": "How can we teach humanoids to climb staircases and sit on chairs using the\nsurrounding environment context? Arguably, the simplest way is to just show\nthem-casually capture a human motion video and feed it to humanoids. We\nintroduce VIDEOMIMIC, a real-to-sim-to-real pipeline that mines everyday\nvideos, jointly reconstructs the humans and the environment, and produces\nwhole-body control policies for humanoid robots that perform the corresponding\nskills. We demonstrate the results of our pipeline on real humanoid robots,\nshowing robust, repeatable contextual control such as staircase ascents and\ndescents, sitting and standing from chairs and benches, as well as other\ndynamic whole-body skills-all from a single policy, conditioned on the\nenvironment and global root commands. VIDEOMIMIC offers a scalable path towards\nteaching humanoids to operate in diverse real-world environments.", "published": "2025-05-06 17:57:12", "link": "http://arxiv.org/abs/2505.03729v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "DISARM++: Beyond scanner-free harmonization", "abstract": "Harmonization of T1-weighted MR images across different scanners is crucial\nfor ensuring consistency in neuroimaging studies. This study introduces a novel\napproach to direct image harmonization, moving beyond feature standardization\nto ensure that extracted features remain inherently reliable for downstream\nanalysis. Our method enables image transfer in two ways: (1) mapping images to\na scanner-free space for uniform appearance across all scanners, and (2)\ntransforming images into the domain of a specific scanner used in model\ntraining, embedding its unique characteristics. Our approach presents strong\ngeneralization capability, even for unseen scanners not included in the\ntraining phase. We validated our method using MR images from diverse cohorts,\nincluding healthy controls, traveling subjects, and individuals with\nAlzheimer's disease (AD). The model's effectiveness is tested in multiple\napplications, such as brain age prediction (R2 = 0.60 \\pm 0.05), biomarker\nextraction, AD classification (Test Accuracy = 0.86 \\pm 0.03), and diagnosis\nprediction (AUC = 0.95). In all cases, our harmonization technique outperforms\nstate-of-the-art methods, showing improvements in both reliability and\npredictive accuracy. Moreover, our approach eliminates the need for extensive\npreprocessing steps, such as skull-stripping, which can introduce errors by\nmisclassifying brain and non-brain structures. This makes our method\nparticularly suitable for applications that require full-head analysis,\nincluding research on head trauma and cranial deformities. Additionally, our\nharmonization model does not require retraining for new datasets, allowing\nsmooth integration into various neuroimaging workflows. By ensuring\nscanner-invariant image quality, our approach provides a robust and efficient\nsolution for improving neuroimaging studies across diverse settings. The code\nis available at this link.", "published": "2025-05-06 17:36:49", "link": "http://arxiv.org/abs/2505.03715v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fill the Gap: Quantifying and Reducing the Modality Gap in Image-Text Representation Learning", "abstract": "Vision-language models (VLMs) allow to embed texts and images in a shared\nrepresentation space. However, it has been shown that these models are subject\nto a modality gap phenomenon meaning there exists a clear separation between\nthe embeddings from one modality and another in the embedding space. While this\nmisalignment is detrimental for downstream tasks such as multimodal retrieval,\nmultimodal clustering or zero-shot classification, etc. no generic and\npractical methods have so far been proposed to assess it precisely and even\nreduce it. We therefore propose novel measures and effective techniques\n(spectral- and optimal transport-based methods) to achieve this goal. Extensive\nexperiments conducted on several image-text datasets and models demonstrate\ntheir effectiveness and beneficial effects on downstream tasks. Our code is\navailable at the URL provided in the paper's abstract.", "published": "2025-05-06 17:24:41", "link": "http://arxiv.org/abs/2505.03703v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Self-Supervised Learning for Robotic Leaf Manipulation: A Hybrid Geometric-Neural Approach", "abstract": "Automating leaf manipulation in agricultural settings faces significant\nchallenges, including the variability of plant morphologies and deformable\nleaves. We propose a novel hybrid geometric-neural approach for autonomous leaf\ngrasping that combines traditional computer vision with neural networks through\nself-supervised learning. Our method integrates YOLOv8 for instance\nsegmentation and RAFT-Stereo for 3D depth estimation to build rich leaf\nrepresentations, which feed into both a geometric feature scoring pipeline and\na neural refinement module (GraspPointCNN). The key innovation is our\nconfidence-weighted fusion mechanism that dynamically balances the contribution\nof each approach based on prediction certainty. Our self-supervised framework\nuses the geometric pipeline as an expert teacher to automatically generate\ntraining data. Experiments demonstrate that our approach achieves an 88.0%\nsuccess rate in controlled environments and 84.7% in real greenhouse\nconditions, significantly outperforming both purely geometric (75.3%) and\nneural (60.2%) methods. This work establishes a new paradigm for agricultural\nrobotics where domain expertise is seamlessly integrated with machine learning\ncapabilities, providing a foundation for fully automated crop monitoring\nsystems.", "published": "2025-05-06 17:22:21", "link": "http://arxiv.org/abs/2505.03702v1", "categories": ["cs.RO", "cs.CV", "cs.LG", "I.2.10"], "primary_category": "cs.RO"}
{"title": "Matching Distance and Geometric Distribution Aided Learning Multiview Point Cloud Registration", "abstract": "Multiview point cloud registration plays a crucial role in robotics,\nautomation, and computer vision fields. This paper concentrates on pose graph\nconstruction and motion synchronization within multiview registration. Previous\nmethods for pose graph construction often pruned fully connected graphs or\nconstructed sparse graph using global feature aggregated from local\ndescriptors, which may not consistently yield reliable results. To identify\ndependable pairs for pose graph construction, we design a network model that\nextracts information from the matching distance between point cloud pairs. For\nmotion synchronization, we propose another neural network model to calculate\nthe absolute pose in a data-driven manner, rather than optimizing inaccurate\nhandcrafted loss functions. Our model takes into account geometric distribution\ninformation and employs a modified attention mechanism to facilitate flexible\nand reliable feature interaction. Experimental results on diverse indoor and\noutdoor datasets confirm the effectiveness and generalizability of our\napproach. The source code is available at https://github.com/Shi-Qi-Li/MDGD.", "published": "2025-05-06 16:54:07", "link": "http://arxiv.org/abs/2505.03692v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "CaRaFFusion: Improving 2D Semantic Segmentation with Camera-Radar Point Cloud Fusion and Zero-Shot Image Inpainting", "abstract": "Segmenting objects in an environment is a crucial task for autonomous driving\nand robotics, as it enables a better understanding of the surroundings of each\nagent. Although camera sensors provide rich visual details, they are vulnerable\nto adverse weather conditions. In contrast, radar sensors remain robust under\nsuch conditions, but often produce sparse and noisy data. Therefore, a\npromising approach is to fuse information from both sensors. In this work, we\npropose a novel framework to enhance camera-only baselines by integrating a\ndiffusion model into a camera-radar fusion architecture. We leverage radar\npoint features to create pseudo-masks using the Segment-Anything model,\ntreating the projected radar points as point prompts. Additionally, we propose\na noise reduction unit to denoise these pseudo-masks, which are further used to\ngenerate inpainted images that complete the missing information in the original\nimages. Our method improves the camera-only segmentation baseline by 2.63% in\nmIoU and enhances our camera-radar fusion architecture by 1.48% in mIoU on the\nWaterscenes dataset. This demonstrates the effectiveness of our approach for\nsemantic segmentation using camera-radar fusion under adverse weather\nconditions.", "published": "2025-05-06 16:25:38", "link": "http://arxiv.org/abs/2505.03679v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Distribution-Conditional Generation: From Class Distribution to Creative Generation", "abstract": "Text-to-image (T2I) diffusion models are effective at producing semantically\naligned images, but their reliance on training data distributions limits their\nability to synthesize truly novel, out-of-distribution concepts. Existing\nmethods typically enhance creativity by combining pairs of known concepts,\nyielding compositions that, while out-of-distribution, remain linguistically\ndescribable and bounded within the existing semantic space. Inspired by the\nsoft probabilistic outputs of classifiers on ambiguous inputs, we propose\nDistribution-Conditional Generation, a novel formulation that models creativity\nas image synthesis conditioned on class distributions, enabling semantically\nunconstrained creative generation. Building on this, we propose DisTok, an\nencoder-decoder framework that maps class distributions into a latent space and\ndecodes them into tokens of creative concept. DisTok maintains a dynamic\nconcept pool and iteratively sampling and fusing concept pairs, enabling the\ngeneration of tokens aligned with increasingly complex class distributions. To\nenforce distributional consistency, latent vectors sampled from a Gaussian\nprior are decoded into tokens and rendered into images, whose class\ndistributions-predicted by a vision-language model-supervise the alignment\nbetween input distributions and the visual semantics of generated tokens. The\nresulting tokens are added to the concept pool for subsequent composition.\nExtensive experiments demonstrate that DisTok, by unifying\ndistribution-conditioned fusion and sampling-based synthesis, enables efficient\nand flexible token-level generation, achieving state-of-the-art performance\nwith superior text-image alignment and human preference scores.", "published": "2025-05-06 16:07:12", "link": "http://arxiv.org/abs/2505.03667v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Smart Point-and-Shoot Photography", "abstract": "Hundreds of millions of people routinely take photos using their smartphones\nas point and shoot (PAS) cameras, yet very few would have the photography\nskills to compose a good shot of a scene. While traditional PAS cameras have\nbuilt-in functions to ensure a photo is well focused and has the right\nbrightness, they cannot tell the users how to compose the best shot of a scene.\nIn this paper, we present a first of its kind smart point and shoot (SPAS)\nsystem to help users to take good photos. Our SPAS proposes to help users to\ncompose a good shot of a scene by automatically guiding the users to adjust the\ncamera pose live on the scene. We first constructed a large dataset containing\n320K images with camera pose information from 4000 scenes. We then developed an\ninnovative CLIP-based Composition Quality Assessment (CCQA) model to assign\npseudo labels to these images. The CCQA introduces a unique learnable text\nembedding technique to learn continuous word embeddings capable of discerning\nsubtle visual quality differences in the range covered by five levels of\nquality description words {bad, poor, fair, good, perfect}. And finally we have\ndeveloped a camera pose adjustment model (CPAM) which first determines if the\ncurrent view can be further improved and if so it outputs the adjust suggestion\nin the form of two camera pose adjustment angles. The two tasks of CPAM make\ndecisions in a sequential manner and each involves different sets of training\nsamples, we have developed a mixture-of-experts model with a gated loss\nfunction to train the CPAM in an end-to-end manner. We will present extensive\nresults to demonstrate the performances of our SPAS system using publicly\navailable image composition datasets.", "published": "2025-05-06 15:40:14", "link": "http://arxiv.org/abs/2505.03638v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Breaking Annotation Barriers: Generalized Video Quality Assessment via Ranking-based Self-Supervision", "abstract": "Video quality assessment (VQA) is essential for quantifying perceptual\nquality in various video processing workflows, spanning from camera capture\nsystems to over-the-top streaming platforms. While recent supervised VQA models\nhave made substantial progress, the reliance on manually annotated datasets --\na process that is labor-intensive, costly, and difficult to scale up -- has\nhindered further optimization of their generalization to unseen video content\nand distortions. To bridge this gap, we introduce a self-supervised learning\nframework for VQA to learn quality assessment capabilities from large-scale,\nunlabeled web videos. Our approach leverages a \\textbf{learning-to-rank}\nparadigm to train a large multimodal model (LMM) on video pairs automatically\nlabeled via two manners, including quality pseudo-labeling by existing VQA\nmodels and relative quality ranking based on synthetic distortion simulations.\nFurthermore, we introduce a novel \\textbf{iterative self-improvement training\nstrategy}, where the trained model acts an improved annotator to iteratively\nrefine the annotation quality of training data. By training on a dataset\n$10\\times$ larger than the existing VQA benchmarks, our model: (1) achieves\nzero-shot performance on in-domain VQA benchmarks that matches or surpasses\nsupervised models; (2) demonstrates superior out-of-distribution (OOD)\ngeneralization across diverse video content and distortions; and (3) sets a new\nstate-of-the-art when fine-tuned on human-labeled datasets. Extensive\nexperimental results validate the effectiveness of our self-supervised approach\nin training generalized VQA models. The datasets and code will be publicly\nreleased to facilitate future research.", "published": "2025-05-06 15:29:32", "link": "http://arxiv.org/abs/2505.03631v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bounding Box-Guided Diffusion for Synthesizing Industrial Images and Segmentation Map", "abstract": "Synthetic dataset generation in Computer Vision, particularly for industrial\napplications, is still underexplored. Industrial defect segmentation, for\ninstance, requires highly accurate labels, yet acquiring such data is costly\nand time-consuming. To address this challenge, we propose a novel\ndiffusion-based pipeline for generating high-fidelity industrial datasets with\nminimal supervision. Our approach conditions the diffusion model on enriched\nbounding box representations to produce precise segmentation masks, ensuring\nrealistic and accurately localized defect synthesis. Compared to existing\nlayout-conditioned generative methods, our approach improves defect consistency\nand spatial accuracy. We introduce two quantitative metrics to evaluate the\neffectiveness of our method and assess its impact on a downstream segmentation\ntask trained on real and synthetic data. Our results demonstrate that\ndiffusion-based synthesis can bridge the gap between artificial and real-world\nindustrial data, fostering more reliable and cost-efficient segmentation\nmodels. The code is publicly available at\nhttps://github.com/covisionlab/diffusion_labeling.", "published": "2025-05-06 15:21:36", "link": "http://arxiv.org/abs/2505.03623v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PhysLLM: Harnessing Large Language Models for Cross-Modal Remote Physiological Sensing", "abstract": "Remote photoplethysmography (rPPG) enables non-contact physiological\nmeasurement but remains highly susceptible to illumination changes, motion\nartifacts, and limited temporal modeling. Large Language Models (LLMs) excel at\ncapturing long-range dependencies, offering a potential solution but struggle\nwith the continuous, noise-sensitive nature of rPPG signals due to their\ntext-centric design. To bridge this gap, we introduce PhysLLM, a collaborative\noptimization framework that synergizes LLMs with domain-specific rPPG\ncomponents. Specifically, the Text Prototype Guidance (TPG) strategy is\nproposed to establish cross-modal alignment by projecting hemodynamic features\ninto LLM-interpretable semantic space, effectively bridging the\nrepresentational gap between physiological signals and linguistic tokens.\nBesides, a novel Dual-Domain Stationary (DDS) Algorithm is proposed for\nresolving signal instability through adaptive time-frequency domain feature\nre-weighting. Finally, rPPG task-specific cues systematically inject\nphysiological priors through physiological statistics, environmental contextual\nanswering, and task description, leveraging cross-modal learning to integrate\nboth visual and textual information, enabling dynamic adaptation to challenging\nscenarios like variable illumination and subject movements. Evaluation on four\nbenchmark datasets, PhysLLM achieves state-of-the-art accuracy and robustness,\ndemonstrating superior generalization across lighting variations and motion\nscenarios.", "published": "2025-05-06 15:18:38", "link": "http://arxiv.org/abs/2505.03621v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Unknown Spoof Prompts for Generalized Face Anti-Spoofing Using Only Real Face Images", "abstract": "Face anti-spoofing is a critical technology for ensuring the security of face\nrecognition systems. However, its ability to generalize across diverse\nscenarios remains a significant challenge. In this paper, we attribute the\nlimited generalization ability to two key factors: covariate shift, which\narises from external data collection variations, and semantic shift, which\nresults from substantial differences in emerging attack types. To address both\nchallenges, we propose a novel approach for learning unknown spoof prompts,\nrelying solely on real face images from a single source domain. Our method\ngenerates textual prompts for real faces and potential unknown spoof attacks by\nleveraging the general knowledge embedded in vision-language models, thereby\nenhancing the model's ability to generalize to unseen target domains.\nSpecifically, we introduce a diverse spoof prompt optimization framework to\nlearn effective prompts. This framework constrains unknown spoof prompts within\na relaxed prior knowledge space while maximizing their distance from real face\nimages. Moreover, it enforces semantic independence among different spoof\nprompts to capture a broad range of spoof patterns. Experimental results on\nnine datasets demonstrate that the learned prompts effectively transfer the\nknowledge of vision-language models, enabling state-of-the-art generalization\nability against diverse unknown attack types across unseen target domains\nwithout using any spoof face images.", "published": "2025-05-06 15:09:37", "link": "http://arxiv.org/abs/2505.03611v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Knowledge-based Prompts for Robust 3D Mask Presentation Attack Detection", "abstract": "3D mask presentation attack detection is crucial for protecting face\nrecognition systems against the rising threat of 3D mask attacks. While most\nexisting methods utilize multimodal features or remote photoplethysmography\n(rPPG) signals to distinguish between real faces and 3D masks, they face\nsignificant challenges, such as the high costs associated with multimodal\nsensors and limited generalization ability. Detection-related text descriptions\noffer concise, universal information and are cost-effective to obtain. However,\nthe potential of vision-language multimodal features for 3D mask presentation\nattack detection remains unexplored. In this paper, we propose a novel\nknowledge-based prompt learning framework to explore the strong generalization\ncapability of vision-language models for 3D mask presentation attack detection.\nSpecifically, our approach incorporates entities and triples from knowledge\ngraphs into the prompt learning process, generating fine-grained, task-specific\nexplicit prompts that effectively harness the knowledge embedded in pre-trained\nvision-language models. Furthermore, considering different input images may\nemphasize distinct knowledge graph elements, we introduce a visual-specific\nknowledge filter based on an attention mechanism to refine relevant elements\naccording to the visual context. Additionally, we leverage causal graph theory\ninsights into the prompt learning process to further enhance the generalization\nability of our method. During training, a spurious correlation elimination\nparadigm is employed, which removes category-irrelevant local image patches\nusing guidance from knowledge-based text features, fostering the learning of\ngeneralized causal prompts that align with category-relevant local patches.\nExperimental results demonstrate that the proposed method achieves\nstate-of-the-art intra- and cross-scenario detection performance on benchmark\ndatasets.", "published": "2025-05-06 15:09:23", "link": "http://arxiv.org/abs/2505.03610v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PAHA: Parts-Aware Audio-Driven Human Animation with Diffusion Model", "abstract": "Audio-driven human animation technology is widely used in human-computer\ninteraction, and the emergence of diffusion models has further advanced its\ndevelopment. Currently, most methods rely on multi-stage generation and\nintermediate representations, resulting in long inference time and issues with\ngeneration quality in specific foreground regions and audio-motion consistency.\nThese shortcomings are primarily due to the lack of localized fine-grained\nsupervised guidance. To address above challenges, we propose PAHA, an\nend-to-end audio-driven upper-body human animation framework with diffusion\nmodel. We introduce two key methods: Parts-Aware Re-weighting (PAR) and Parts\nConsistency Enhancement (PCE). PAR dynamically adjusts regional training loss\nweights based on pose confidence scores, effectively improving visual quality.\nPCE constructs and trains diffusion-based regional audio-visual classifiers to\nimprove the consistency of motion and co-speech audio. Afterwards, we design\ntwo novel inference guidance methods for the foregoing classifiers, Sequential\nGuidance (SG) and Differential Guidance (DG), to balance efficiency and quality\nrespectively. Additionally, we build CNAS, the first public Chinese News Anchor\nSpeech dataset, to advance research and validation in this field. Extensive\nexperimental results and user studies demonstrate that PAHA significantly\noutperforms existing methods in audio-motion alignment and video-related\nevaluations. The codes and CNAS dataset will be released upon acceptance.", "published": "2025-05-06 15:03:58", "link": "http://arxiv.org/abs/2505.03603v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "From Pixels to Polygons: A Survey of Deep Learning Approaches for Medical Image-to-Mesh Reconstruction", "abstract": "Deep learning-based medical image-to-mesh reconstruction has rapidly evolved,\nenabling the transformation of medical imaging data into three-dimensional mesh\nmodels that are critical in computational medicine and in silico trials for\nadvancing our understanding of disease mechanisms, and diagnostic and\ntherapeutic techniques in modern medicine. This survey systematically\ncategorizes existing approaches into four main categories: template models,\nstatistical models, generative models, and implicit models. Each category is\nanalysed in detail, examining their methodological foundations, strengths,\nlimitations, and applicability to different anatomical structures and imaging\nmodalities. We provide an extensive evaluation of these methods across various\nanatomical applications, from cardiac imaging to neurological studies,\nsupported by quantitative comparisons using standard metrics. Additionally, we\ncompile and analyze major public datasets available for medical mesh\nreconstruction tasks and discuss commonly used evaluation metrics and loss\nfunctions. The survey identifies current challenges in the field, including\nrequirements for topological correctness, geometric accuracy, and\nmulti-modality integration. Finally, we present promising future research\ndirections in this domain. This systematic review aims to serve as a\ncomprehensive reference for researchers and practitioners in medical image\nanalysis and computational medicine.", "published": "2025-05-06 15:01:43", "link": "http://arxiv.org/abs/2505.03599v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fixed-Length Dense Fingerprint Representation", "abstract": "Fixed-length fingerprint representations, which map each fingerprint to a\ncompact and fixed-size feature vector, are computationally efficient and\nwell-suited for large-scale matching. However, designing a robust\nrepresentation that effectively handles diverse fingerprint modalities, pose\nvariations, and noise interference remains a significant challenge. In this\nwork, we propose a fixed-length dense descriptor of fingerprints, and introduce\nFLARE-a fingerprint matching framework that integrates the Fixed-Length dense\ndescriptor with pose-based Alignment and Robust Enhancement. This fixed-length\nrepresentation employs a three-dimensional dense descriptor to effectively\ncapture spatial relationships among fingerprint ridge structures, enabling\nrobust and locally discriminative representations. To ensure consistency within\nthis dense feature space, FLARE incorporates pose-based alignment using\ncomplementary estimation methods, along with dual enhancement strategies that\nrefine ridge clarity while preserving the original fingerprint modality. The\nproposed dense descriptor supports fixed-length representation while\nmaintaining spatial correspondence, enabling fast and accurate similarity\ncomputation. Extensive experiments demonstrate that FLARE achieves superior\nperformance across rolled, plain, latent, and contactless fingerprints,\nsignificantly outperforming existing methods in cross-modality and low-quality\nscenarios. Further analysis validates the effectiveness of the dense descriptor\ndesign, as well as the impact of alignment and enhancement modules on the\naccuracy of dense descriptor matching. Experimental results highlight the\neffectiveness and generalizability of FLARE as a unified and scalable solution\nfor robust fingerprint representation and matching. The implementation and code\nwill be publicly available at https://github.com/Yu-Yy/FLARE.", "published": "2025-05-06 14:59:25", "link": "http://arxiv.org/abs/2505.03597v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DyGEnc: Encoding a Sequence of Textual Scene Graphs to Reason and Answer Questions in Dynamic Scenes", "abstract": "The analysis of events in dynamic environments poses a fundamental challenge\nin the development of intelligent agents and robots capable of interacting with\nhumans. Current approaches predominantly utilize visual models. However, these\nmethods often capture information implicitly from images, lacking interpretable\nspatial-temporal object representations. To address this issue we introduce\nDyGEnc - a novel method for Encoding a Dynamic Graph. This method integrates\ncompressed spatial-temporal structural observation representation with the\ncognitive capabilities of large language models. The purpose of this\nintegration is to enable advanced question answering based on a sequence of\ntextual scene graphs. Extended evaluations on the STAR and AGQA datasets\nindicate that DyGEnc outperforms existing visual methods by a large margin of\n15-25% in addressing queries regarding the history of human-to-object\ninteractions. Furthermore, the proposed method can be seamlessly extended to\nprocess raw input images utilizing foundational models for extracting explicit\ntextual scene graphs, as substantiated by the results of a robotic experiment\nconducted with a wheeled manipulator platform. We hope that these findings will\ncontribute to the implementation of robust and compressed graph-based robotic\nmemory for long-horizon reasoning. Code is available at\ngithub.com/linukc/DyGEnc.", "published": "2025-05-06 14:41:42", "link": "http://arxiv.org/abs/2505.03581v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Supervised and Unsupervised Textile Classification via Near-Infrared Hyperspectral Imaging and Deep Learning", "abstract": "Recycling textile fibers is critical to reducing the environmental impact of\nthe textile industry. Hyperspectral near-infrared (NIR) imaging combined with\nadvanced deep learning algorithms offers a promising solution for efficient\nfiber classification and sorting. In this study, we investigate supervised and\nunsupervised deep learning models and test their generalization capabilities on\ndifferent textile structures. We show that optimized convolutional neural\nnetworks (CNNs) and autoencoder networks achieve robust generalization under\nvarying conditions. These results highlight the potential of hyperspectral\nimaging and deep learning to advance sustainable textile recycling through\naccurate and robust classification.", "published": "2025-05-06 14:34:31", "link": "http://arxiv.org/abs/2505.03575v1", "categories": ["cs.CV", "physics.app-ph"], "primary_category": "cs.CV"}
{"title": "Corner Cases: How Size and Position of Objects Challenge ImageNet-Trained Models", "abstract": "Backgrounds in images play a major role in contributing to spurious\ncorrelations among different data points. Owing to aesthetic preferences of\nhumans capturing the images, datasets can exhibit positional (location of the\nobject within a given frame) and size (region-of-interest to image ratio)\nbiases for different classes. In this paper, we show that these biases can\nimpact how much a model relies on spurious features in the background to make\nits predictions. To better illustrate our findings, we propose a synthetic\ndataset derived from ImageNet1k, Hard-Spurious-ImageNet, which contains images\nwith various backgrounds, object positions, and object sizes. By evaluating the\ndataset on different pretrained models, we find that most models rely heavily\non spurious features in the background when the region-of-interest (ROI) to\nimage ratio is small and the object is far from the center of the image.\nMoreover, we also show that current methods that aim to mitigate harmful\nspurious features, do not take into account these factors, hence fail to\nachieve considerable performance gains for worst-group accuracies when the size\nand location of core features in an image change.", "published": "2025-05-06 14:27:01", "link": "http://arxiv.org/abs/2505.03569v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Uncertainty-Aware Prototype Semantic Decoupling for Text-Based Person Search in Full Images", "abstract": "Text-based pedestrian search (TBPS) in full images aims to locate a target\npedestrian in untrimmed images using natural language descriptions. However, in\ncomplex scenes with multiple pedestrians, existing methods are limited by\nuncertainties in detection and matching, leading to degraded performance. To\naddress this, we propose UPD-TBPS, a novel framework comprising three modules:\nMulti-granularity Uncertainty Estimation (MUE), Prototype-based Uncertainty\nDecoupling (PUD), and Cross-modal Re-identification (ReID). MUE conducts\nmulti-granularity queries to identify potential targets and assigns confidence\nscores to reduce early-stage uncertainty. PUD leverages visual context\ndecoupling and prototype mining to extract features of the target pedestrian\ndescribed in the query. It separates and learns pedestrian prototype\nrepresentations at both the coarse-grained cluster level and the fine-grained\nindividual level, thereby reducing matching uncertainty. ReID evaluates\ncandidates with varying confidence levels, improving detection and retrieval\naccuracy. Experiments on CUHK-SYSU-TBPS and PRW-TBPS datasets validate the\neffectiveness of our framework.", "published": "2025-05-06 14:25:30", "link": "http://arxiv.org/abs/2505.03567v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Read My Ears! Horse Ear Movement Detection for Equine Affective State Assessment", "abstract": "The Equine Facial Action Coding System (EquiFACS) enables the systematic\nannotation of facial movements through distinct Action Units (AUs). It serves\nas a crucial tool for assessing affective states in horses by identifying\nsubtle facial expressions associated with discomfort. However, the field of\nhorse affective state assessment is constrained by the scarcity of annotated\ndata, as manually labelling facial AUs is both time-consuming and costly. To\naddress this challenge, automated annotation systems are essential for\nleveraging existing datasets and improving affective states detection tools. In\nthis work, we study different methods for specific ear AU detection and\nlocalization from horse videos. We leverage past works on deep learning-based\nvideo feature extraction combined with recurrent neural networks for the video\nclassification task, as well as a classic optical flow based approach. We\nachieve 87.5% classification accuracy of ear movement presence on a public\nhorse video dataset, demonstrating the potential of our approach. We discuss\nfuture directions to develop these systems, with the aim of bridging the gap\nbetween automated AU detection and practical applications in equine welfare and\nveterinary diagnostics. Our code will be made publicly available at\nhttps://github.com/jmalves5/read-my-ears.", "published": "2025-05-06 14:05:49", "link": "http://arxiv.org/abs/2505.03554v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Panoramic Out-of-Distribution Segmentation", "abstract": "Panoramic imaging enables capturing 360{\\deg} images with an ultra-wide\nField-of-View (FoV) for dense omnidirectional perception. However, current\npanoramic semantic segmentation methods fail to identify outliers, and pinhole\nOut-of-distribution Segmentation (OoS) models perform unsatisfactorily in the\npanoramic domain due to background clutter and pixel distortions. To address\nthese issues, we introduce a new task, Panoramic Out-of-distribution\nSegmentation (PanOoS), achieving OoS for panoramas. Furthermore, we propose the\nfirst solution, POS, which adapts to the characteristics of panoramic images\nthrough text-guided prompt distribution learning. Specifically, POS integrates\na disentanglement strategy designed to materialize the cross-domain\ngeneralization capability of CLIP. The proposed Prompt-based Restoration\nAttention (PRA) optimizes semantic decoding by prompt guidance and\nself-adaptive correction, while Bilevel Prompt Distribution Learning (BPDL)\nrefines the manifold of per-pixel mask embeddings via semantic prototype\nsupervision. Besides, to compensate for the scarcity of PanOoS datasets, we\nestablish two benchmarks: DenseOoS, which features diverse outliers in complex\nenvironments, and QuadOoS, captured by a quadruped robot with a panoramic\nannular lens system. Extensive experiments demonstrate superior performance of\nPOS, with AuPRC improving by 34.25% and FPR95 decreasing by 21.42% on DenseOoS,\noutperforming state-of-the-art pinhole-OoS methods. Moreover, POS achieves\nleading closed-set segmentation capabilities. Code and datasets will be\navailable at https://github.com/MengfeiD/PanOoS.", "published": "2025-05-06 13:51:26", "link": "http://arxiv.org/abs/2505.03539v1", "categories": ["cs.CV", "cs.RO", "eess.IV"], "primary_category": "cs.CV"}
{"title": "RAIL: Region-Aware Instructive Learning for Semi-Supervised Tooth Segmentation in CBCT", "abstract": "Semi-supervised learning has become a compelling approach for 3D tooth\nsegmentation from CBCT scans, where labeled data is minimal. However, existing\nmethods still face two persistent challenges: limited corrective supervision in\nstructurally ambiguous or mislabeled regions during supervised training and\nperformance degradation caused by unreliable pseudo-labels on unlabeled data.\nTo address these problems, we propose Region-Aware Instructive Learning (RAIL),\na dual-group dual-student, semi-supervised framework. Each group contains two\nstudent models guided by a shared teacher network. By alternating training\nbetween the two groups, RAIL promotes intergroup knowledge transfer and\ncollaborative region-aware instruction while reducing overfitting to the\ncharacteristics of any single model. Specifically, RAIL introduces two\ninstructive mechanisms. Disagreement-Focused Supervision (DFS) Controller\nimproves supervised learning by instructing predictions only within areas where\nstudent outputs diverge from both ground truth and the best student, thereby\nconcentrating supervision on structurally ambiguous or mislabeled areas. In the\nunsupervised phase, Confidence-Aware Learning (CAL) Modulator reinforces\nagreement in regions with high model certainty while reducing the effect of\nlow-confidence predictions during training. This helps prevent our model from\nlearning unstable patterns and improves the overall reliability of\npseudo-labels. Extensive experiments on four CBCT tooth segmentation datasets\nshow that RAIL surpasses state-of-the-art methods under limited annotation. Our\ncode will be available at https://github.com/Tournesol-Saturday/RAIL.", "published": "2025-05-06 13:50:57", "link": "http://arxiv.org/abs/2505.03538v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Coop-WD: Cooperative Perception with Weighting and Denoising for Robust V2V Communication", "abstract": "Cooperative perception, leveraging shared information from multiple vehicles\nvia vehicle-to-vehicle (V2V) communication, plays a vital role in autonomous\ndriving to alleviate the limitation of single-vehicle perception. Existing\nworks have explored the effects of V2V communication impairments on perception\nprecision, but they lack generalization to different levels of impairments. In\nthis work, we propose a joint weighting and denoising framework, Coop-WD, to\nenhance cooperative perception subject to V2V channel impairments. In this\nframework, the self-supervised contrastive model and the conditional diffusion\nprobabilistic model are adopted hierarchically for vehicle-level and\npixel-level feature enhancement. An efficient variant model, Coop-WD-eco, is\nproposed to selectively deactivate denoising to reduce processing overhead.\nRician fading, non-stationarity, and time-varying distortion are considered.\nSimulation results demonstrate that the proposed Coop-WD outperforms\nconventional benchmarks in all types of channels. Qualitative analysis with\nvisual examples further proves the superiority of our proposed method. The\nproposed Coop-WD-eco achieves up to 50% reduction in computational cost under\nsevere distortion while maintaining comparable accuracy as channel conditions\nimprove.", "published": "2025-05-06 13:38:35", "link": "http://arxiv.org/abs/2505.03528v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Modality-Guided Dynamic Graph Fusion and Temporal Diffusion for Self-Supervised RGB-T Tracking", "abstract": "To reduce the reliance on large-scale annotations, self-supervised RGB-T\ntracking approaches have garnered significant attention. However, the omission\nof the object region by erroneous pseudo-label or the introduction of\nbackground noise affects the efficiency of modality fusion, while pseudo-label\nnoise triggered by similar object noise can further affect the tracking\nperformance. In this paper, we propose GDSTrack, a novel approach that\nintroduces dynamic graph fusion and temporal diffusion to address the above\nchallenges in self-supervised RGB-T tracking. GDSTrack dynamically fuses the\nmodalities of neighboring frames, treats them as distractor noise, and\nleverages the denoising capability of a generative model. Specifically, by\nconstructing an adjacency matrix via an Adjacency Matrix Generator (AMG), the\nproposed Modality-guided Dynamic Graph Fusion (MDGF) module uses a dynamic\nadjacency matrix to guide graph attention, focusing on and fusing the object's\ncoherent regions. Temporal Graph-Informed Diffusion (TGID) models MDGF features\nfrom neighboring frames as interference, and thus improving robustness against\nsimilar-object noise. Extensive experiments conducted on four public RGB-T\ntracking datasets demonstrate that GDSTrack outperforms the existing\nstate-of-the-art methods. The source code is available at\nhttps://github.com/LiShenglana/GDSTrack.", "published": "2025-05-06 13:15:34", "link": "http://arxiv.org/abs/2505.03507v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MRI motion correction via efficient residual-guided denoising diffusion probabilistic models", "abstract": "Purpose: Motion artifacts in magnetic resonance imaging (MRI) significantly\ndegrade image quality and impair quantitative analysis. Conventional mitigation\nstrategies, such as repeated acquisitions or motion tracking, are costly and\nworkflow-intensive. This study introduces Res-MoCoDiff, an efficient denoising\ndiffusion probabilistic model tailored for MRI motion artifact correction.\nMethods: Res-MoCoDiff incorporates a novel residual error shifting mechanism in\nthe forward diffusion process, aligning the noise distribution with\nmotion-corrupted data and enabling an efficient four-step reverse diffusion. A\nU-net backbone enhanced with Swin-Transformer blocks conventional attention\nlayers, improving adaptability across resolutions. Training employs a combined\nl1+l2 loss, which promotes image sharpness and reduces pixel-level errors.\nRes-MoCoDiff was evaluated on synthetic dataset generated using a realistic\nmotion simulation framework and on an in-vivo dataset. Comparative analyses\nwere conducted against established methods, including CycleGAN, Pix2pix, and\nMT-DDPM using quantitative metrics such as peak signal-to-noise ratio (PSNR),\nstructural similarity index measure (SSIM), and normalized mean squared error\n(NMSE). Results: The proposed method demonstrated superior performance in\nremoving motion artifacts across all motion severity levels. Res-MoCoDiff\nconsistently achieved the highest SSIM and the lowest NMSE values, with a PSNR\nof up to 41.91+-2.94 dB for minor distortions. Notably, the average sampling\ntime was reduced to 0.37 seconds per batch of two image slices, compared with\n101.74 seconds for conventional approaches.", "published": "2025-05-06 13:02:40", "link": "http://arxiv.org/abs/2505.03498v1", "categories": ["cs.CV", "physics.med-ph"], "primary_category": "cs.CV"}
{"title": "UPMAD-Net: A Brain Tumor Segmentation Network with Uncertainty Guidance and Adaptive Multimodal Feature Fusion", "abstract": "Background: Brain tumor segmentation has a significant impact on the\ndiagnosis and treatment of brain tumors. Accurate brain tumor segmentation\nremains challenging due to their irregular shapes, vague boundaries, and high\nvariability. Objective: We propose a brain tumor segmentation method that\ncombines deep learning with prior knowledge derived from a region-growing\nalgorithm. Methods: The proposed method utilizes a multi-scale feature fusion\n(MSFF) module and adaptive attention mechanisms (AAM) to extract multi-scale\nfeatures and capture global contextual information. To enhance the model's\nrobustness in low-confidence regions, the Monte Carlo Dropout (MC Dropout)\nstrategy is employed for uncertainty estimation. Results: Extensive experiments\ndemonstrate that the proposed method achieves superior performance on Brain\nTumor Segmentation (BraTS) datasets, significantly outperforming various\nstate-of-the-art methods. On the BraTS2021 dataset, the test Dice scores are\n89.18% for Enhancing Tumor (ET) segmentation, 93.67% for Whole Tumor (WT)\nsegmentation, and 91.23% for Tumor Core (TC) segmentation. On the BraTS2019\nvalidation set, the validation Dice scores are 87.43%, 90.92%, and 90.40% for\nET, WT, and TC segmentation, respectively. Ablation studies further confirmed\nthe contribution of each module to segmentation accuracy, indicating that each\ncomponent played a vital role in overall performance improvement. Conclusion:\nThis study proposed a novel 3D brain tumor segmentation network based on the\nU-Net architecture. By incorporating the prior knowledge and employing the\nuncertainty estimation method, the robustness and performance were improved.\nThe code for the proposed method is available at\nhttps://github.com/chenzhao2023/UPMAD_Net_BrainSeg.", "published": "2025-05-06 12:56:04", "link": "http://arxiv.org/abs/2505.03494v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Nonperiodic dynamic CT reconstruction using backward-warping INR with regularization of diffeomorphism (BIRD)", "abstract": "Dynamic computed tomography (CT) reconstruction faces significant challenges\nin addressing motion artifacts, particularly for nonperiodic rapid movements\nsuch as cardiac imaging with fast heart rates. Traditional methods struggle\nwith the extreme limited-angle problems inherent in nonperiodic cases. Deep\nlearning methods have improved performance but face generalization challenges.\nRecent implicit neural representation (INR) techniques show promise through\nself-supervised deep learning, but have critical limitations: computational\ninefficiency due to forward-warping modeling, difficulty balancing DVF\ncomplexity with anatomical plausibility, and challenges in preserving fine\ndetails without additional patient-specific pre-scans. This paper presents a\nnovel INR-based framework, BIRD, for nonperiodic dynamic CT reconstruction. It\naddresses these challenges through four key contributions: (1) backward-warping\ndeformation that enables direct computation of each dynamic voxel with\nsignificantly reduced computational cost, (2) diffeomorphism-based DVF\nregularization that ensures anatomically plausible deformations while\nmaintaining representational capacity, (3) motion-compensated analytical\nreconstruction that enhances fine details without requiring additional\npre-scans, and (4) dimensional-reduction design for efficient 4D coordinate\nencoding. Through various simulations and practical studies, including digital\nand physical phantoms and retrospective patient data, we demonstrate the\neffectiveness of our approach for nonperiodic dynamic CT reconstruction with\nenhanced details and reduced motion artifacts. The proposed framework enables\nmore accurate dynamic CT reconstruction with potential clinical applications,\nsuch as one-beat cardiac reconstruction, cinematic image sequences for\nfunctional imaging, and motion artifact reduction in conventional CT scans.", "published": "2025-05-06 12:01:40", "link": "http://arxiv.org/abs/2505.03463v1", "categories": ["cs.CV", "physics.med-ph"], "primary_category": "cs.CV"}
{"title": "Polar Coordinate-Based 2D Pose Prior with Neural Distance Field", "abstract": "Human pose capture is essential for sports analysis, enabling precise\nevaluation of athletes' movements. While deep learning-based human pose\nestimation (HPE) models from RGB videos have achieved impressive performance on\npublic datasets, their effectiveness in real-world sports scenarios is often\nhindered by motion blur, occlusions, and domain shifts across different pose\nrepresentations. Fine-tuning these models can partially alleviate such\nchallenges but typically requires large-scale annotated data and still\nstruggles to generalize across diverse sports environments. To address these\nlimitations, we propose a 2D pose prior-guided refinement approach based on\nNeural Distance Fields (NDF). Unlike existing approaches that rely solely on\nangular representations of human poses, we introduce a polar coordinate-based\nrepresentation that explicitly incorporates joint connection lengths, enabling\na more accurate correction of erroneous pose estimations. Additionally, we\ndefine a novel non-geodesic distance metric that separates angular and radial\ndiscrepancies, which we demonstrate is better suited for polar representations\nthan traditional geodesic distances. To mitigate data scarcity, we develop a\ngradient-based batch-projection augmentation strategy, which synthesizes\nrealistic pose samples through iterative refinement. Our method is evaluated on\na long jump dataset, demonstrating its ability to improve 2D pose estimation\nacross multiple pose representations, making it robust across different\ndomains. Experimental results show that our approach enhances pose plausibility\nwhile requiring only limited training data. Code is available at:\nhttps://github.com/QGAN2019/polar-NDF.", "published": "2025-05-06 11:31:14", "link": "http://arxiv.org/abs/2505.03445v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Robustness in AI-Generated Detection: Enhancing Resistance to Adversarial Attacks", "abstract": "The rapid advancement of generative image technology has introduced\nsignificant security concerns, particularly in the domain of face generation\ndetection. This paper investigates the vulnerabilities of current AI-generated\nface detection systems. Our study reveals that while existing detection methods\noften achieve high accuracy under standard conditions, they exhibit limited\nrobustness against adversarial attacks. To address these challenges, we propose\nan approach that integrates adversarial training to mitigate the impact of\nadversarial examples. Furthermore, we utilize diffusion inversion and\nreconstruction to further enhance detection robustness. Experimental results\ndemonstrate that minor adversarial perturbations can easily bypass existing\ndetection systems, but our method significantly improves the robustness of\nthese systems. Additionally, we provide an in-depth analysis of adversarial and\nbenign examples, offering insights into the intrinsic characteristics of\nAI-generated content. All associated code will be made publicly available in a\ndedicated repository to facilitate further research and verification.", "published": "2025-05-06 11:19:01", "link": "http://arxiv.org/abs/2505.03435v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Fusion-Guided Inception Network for Hyperspectral Image Super-Resolution", "abstract": "The fusion of low-spatial-resolution hyperspectral images (HSIs) with\nhigh-spatial-resolution conventional images (e.g., panchromatic or RGB) has\nplayed a significant role in recent advancements in HSI super-resolution.\nHowever, this fusion process relies on the availability of precise alignment\nbetween image pairs, which is often challenging in real-world scenarios. To\nmitigate this limitation, we propose a single-image super-resolution model\ncalled the Fusion-Guided Inception Network (FGIN). Specifically, we first\nemploy a spectral-spatial fusion module to effectively integrate spectral and\nspatial information at an early stage. Next, an Inception-like hierarchical\nfeature extraction strategy is used to capture multiscale spatial dependencies,\nfollowed by a dedicated multi-scale fusion block. To further enhance\nreconstruction quality, we incorporate an optimized upsampling module that\ncombines bilinear interpolation with depthwise separable convolutions.\nExperimental evaluations on two publicly available hyperspectral datasets\ndemonstrate the competitive performance of our method.", "published": "2025-05-06 11:15:59", "link": "http://arxiv.org/abs/2505.03431v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LiftFeat: 3D Geometry-Aware Local Feature Matching", "abstract": "Robust and efficient local feature matching plays a crucial role in\napplications such as SLAM and visual localization for robotics. Despite great\nprogress, it is still very challenging to extract robust and discriminative\nvisual features in scenarios with drastic lighting changes, low texture areas,\nor repetitive patterns. In this paper, we propose a new lightweight network\ncalled \\textit{LiftFeat}, which lifts the robustness of raw descriptor by\naggregating 3D geometric feature. Specifically, we first adopt a pre-trained\nmonocular depth estimation model to generate pseudo surface normal label,\nsupervising the extraction of 3D geometric feature in terms of predicted\nsurface normal. We then design a 3D geometry-aware feature lifting module to\nfuse surface normal feature with raw 2D descriptor feature. Integrating such 3D\ngeometric feature enhances the discriminative ability of 2D feature description\nin extreme conditions. Extensive experimental results on relative pose\nestimation, homography estimation, and visual localization tasks, demonstrate\nthat our LiftFeat outperforms some lightweight state-of-the-art methods. Code\nwill be released at : https://github.com/lyp-deeplearning/LiftFeat.", "published": "2025-05-06 10:59:23", "link": "http://arxiv.org/abs/2505.03422v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Mitigating Image Captioning Hallucinations in Vision-Language Models", "abstract": "Hallucinations in vision-language models (VLMs) hinder reliability and\nreal-world applicability, usually stemming from distribution shifts between\npretraining data and test samples. Existing solutions, such as retraining or\nfine-tuning on additional data, demand significant computational resources and\nlabor-intensive data collection, while ensemble-based methods incur additional\ncosts by introducing auxiliary VLMs. To address these challenges, we propose a\nnovel test-time adaptation framework using reinforcement learning to mitigate\nhallucinations during inference without retraining or any auxiliary VLMs. By\nupdating only the learnable parameters in the layer normalization of the\nlanguage model (approximately 0.003% of the model parameters), our method\nreduces distribution shifts between test samples and pretraining samples. A\nCLIP-based hallucination evaluation model is proposed to provide dual rewards\nto VLMs. Experimental results demonstrate a 15.4% and 17.3% reduction in\nhallucination rates on LLaVA and InstructBLIP, respectively. Our approach\noutperforms state-of-the-art baselines with a 68.3% improvement in\nhallucination mitigation, demonstrating its effectiveness.", "published": "2025-05-06 10:55:21", "link": "http://arxiv.org/abs/2505.03420v1", "categories": ["cs.MM", "cs.CV"], "primary_category": "cs.MM"}
{"title": "CXR-AD: Component X-ray Image Dataset for Industrial Anomaly Detection", "abstract": "Internal defect detection constitutes a critical process in ensuring\ncomponent quality, for which anomaly detection serves as an effective solution.\nHowever, existing anomaly detection datasets predominantly focus on surface\ndefects in visible-light images, lacking publicly available X-ray datasets\ntargeting internal defects in components. To address this gap, we construct the\nfirst publicly accessible component X-ray anomaly detection (CXR-AD) dataset,\ncomprising real-world X-ray images. The dataset covers five industrial\ncomponent categories, including 653 normal samples and 561 defect samples with\nprecise pixel-level mask annotations. We systematically analyze the dataset\ncharacteristics and identify three major technical challenges: (1) strong\ncoupling between complex internal structures and defect regions, (2) inherent\nlow contrast and high noise interference in X-ray imaging, and (3) significant\nvariations in defect scales and morphologies. To evaluate dataset complexity,\nwe benchmark three state-of-the-art anomaly detection frameworks\n(feature-based, reconstruction-based, and zero-shot learning methods).\nExperimental results demonstrate a 29.78% average performance degradation on\nCXR-AD compared to MVTec AD, highlighting the limitations of current algorithms\nin handling internal defect detection tasks. To the best of our knowledge,\nCXR-AD represents the first publicly available X-ray dataset for component\nanomaly detection, providing a real-world industrial benchmark to advance\nalgorithm development and enhance precision in internal defect inspection\ntechnologies.", "published": "2025-05-06 10:38:24", "link": "http://arxiv.org/abs/2505.03412v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EOPose : Exemplar-based object reposing using Generalized Pose Correspondences", "abstract": "Reposing objects in images has a myriad of applications, especially for\ne-commerce where several variants of product images need to be produced\nquickly. In this work, we leverage the recent advances in unsupervised keypoint\ncorrespondence detection between different object images of the same class to\npropose an end-to-end framework for generic object reposing. Our method,\nEOPose, takes a target pose-guidance image as input and uses its keypoint\ncorrespondence with the source object image to warp and re-render the latter\ninto the target pose using a novel three-step approach. Unlike generative\napproaches, our method also preserves the fine-grained details of the object\nsuch as its exact colors, textures, and brand marks. We also prepare a new\ndataset of paired objects based on the Objaverse dataset to train and test our\nnetwork. EOPose produces high-quality reposing output as evidenced by different\nimage quality metrics (PSNR, SSIM and FID). Besides a description of the method\nand the dataset, the paper also includes detailed ablation and user studies to\nindicate the efficacy of the proposed method", "published": "2025-05-06 10:17:32", "link": "http://arxiv.org/abs/2505.03394v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Attention-aggregated Attack for Boosting the Transferability of Facial Adversarial Examples", "abstract": "Adversarial examples have revealed the vulnerability of deep learning models\nand raised serious concerns about information security. The transfer-based\nattack is a hot topic in black-box attacks that are practical to real-world\nscenarios where the training datasets, parameters, and structure of the target\nmodel are unknown to the attacker. However, few methods consider the\nparticularity of class-specific deep models for fine-grained vision tasks, such\nas face recognition (FR), giving rise to unsatisfactory attacking performance.\nIn this work, we first investigate what in a face exactly contributes to the\nembedding learning of FR models and find that both decisive and auxiliary\nfacial features are specific to each FR model, which is quite different from\nthe biological mechanism of human visual system. Accordingly we then propose a\nnovel attack method named Attention-aggregated Attack (AAA) to enhance the\ntransferability of adversarial examples against FR, which is inspired by the\nattention divergence and aims to destroy the facial features that are critical\nfor the decision-making of other FR models by imitating their attentions on the\nclean face images. Extensive experiments conducted on various FR models\nvalidate the superiority and robust effectiveness of the proposed method over\nexisting methods.", "published": "2025-05-06 10:02:56", "link": "http://arxiv.org/abs/2505.03383v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reducing Annotation Burden in Physical Activity Research Using Vision-Language Models", "abstract": "Introduction: Data from wearable devices collected in free-living settings,\nand labelled with physical activity behaviours compatible with health research,\nare essential for both validating existing wearable-based measurement\napproaches and developing novel machine learning approaches. One common way of\nobtaining these labels relies on laborious annotation of sequences of images\ncaptured by cameras worn by participants through the course of a day. Methods:\nWe compare the performance of three vision language models and two\ndiscriminative models on two free-living validation studies with 161 and 111\nparticipants, collected in Oxfordshire, United Kingdom and Sichuan, China,\nrespectively, using the Autographer (OMG Life, defunct) wearable camera.\nResults: We found that the best open-source vision-language model (VLM) and\nfine-tuned discriminative model (DM) achieved comparable performance when\npredicting sedentary behaviour from single images on unseen participants in the\nOxfordshire study; median F1-scores: VLM = 0.89 (0.84, 0.92), DM = 0.91 (0.86,\n0.95). Performance declined for light (VLM = 0.60 (0.56,0.67), DM = 0.70 (0.63,\n0.79)), and moderate-to-vigorous intensity physical activity (VLM = 0.66 (0.53,\n0.85); DM = 0.72 (0.58, 0.84)). When applied to the external Sichuan study,\nperformance fell across all intensity categories, with median Cohen's\nkappa-scores falling from 0.54 (0.49, 0.64) to 0.26 (0.15, 0.37) for the VLM,\nand from 0.67 (0.60, 0.74) to 0.19 (0.10, 0.30) for the DM. Conclusion: Freely\navailable computer vision models could help annotate sedentary behaviour,\ntypically the most prevalent activity of daily living, from wearable camera\nimages within similar populations to seen data, reducing the annotation burden.", "published": "2025-05-06 09:49:45", "link": "http://arxiv.org/abs/2505.03374v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Surface Reconstruction with Enhanced High-Frequency Details", "abstract": "Neural implicit 3D reconstruction can reproduce shapes without 3D\nsupervision, and it learns the 3D scene through volume rendering methods and\nneural implicit representations. Current neural surface reconstruction methods\ntend to randomly sample the entire image, making it difficult to learn\nhigh-frequency details on the surface, and thus the reconstruction results tend\nto be too smooth. We designed a method (FreNeuS) based on high-frequency\ninformation to solve the problem of insufficient surface detail. Specifically,\nFreNeuS uses pixel gradient changes to easily acquire high-frequency regions in\nan image and uses the obtained high-frequency information to guide surface\ndetail reconstruction. High-frequency information is first used to guide the\ndynamic sampling of rays, applying different sampling strategies according to\nvariations in high-frequency regions. To further enhance the focus on surface\ndetails, we have designed a high-frequency weighting method that constrains the\nrepresentation of high-frequency details during the reconstruction process.\nQualitative and quantitative results show that our method can reconstruct fine\nsurface details and obtain better surface reconstruction quality compared to\nexisting methods. In addition, our method is more applicable and can be\ngeneralized to any NeuS-based work.", "published": "2025-05-06 09:37:04", "link": "http://arxiv.org/abs/2505.03362v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Interpretable Zero-shot Learning with Infinite Class Concepts", "abstract": "Zero-shot learning (ZSL) aims to recognize unseen classes by aligning images\nwith intermediate class semantics, like human-annotated concepts or class\ndefinitions. An emerging alternative leverages Large-scale Language Models\n(LLMs) to automatically generate class documents. However, these methods often\nface challenges with transparency in the classification process and may suffer\nfrom the notorious hallucination problem in LLMs, resulting in non-visual class\nsemantics. This paper redefines class semantics in ZSL with a focus on\ntransferability and discriminability, introducing a novel framework called\nZero-shot Learning with Infinite Class Concepts (InfZSL). Our approach\nleverages the powerful capabilities of LLMs to dynamically generate an\nunlimited array of phrase-level class concepts. To address the hallucination\nchallenge, we introduce an entropy-based scoring process that incorporates a\n``goodness\" concept selection mechanism, ensuring that only the most\ntransferable and discriminative concepts are selected. Our InfZSL framework not\nonly demonstrates significant improvements on three popular benchmark datasets\nbut also generates highly interpretable, image-grounded concepts. Code will be\nreleased upon acceptance.", "published": "2025-05-06 09:30:30", "link": "http://arxiv.org/abs/2505.03361v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GUAVA: Generalizable Upper Body 3D Gaussian Avatar", "abstract": "Reconstructing a high-quality, animatable 3D human avatar with expressive\nfacial and hand motions from a single image has gained significant attention\ndue to its broad application potential. 3D human avatar reconstruction\ntypically requires multi-view or monocular videos and training on individual\nIDs, which is both complex and time-consuming. Furthermore, limited by SMPLX's\nexpressiveness, these methods often focus on body motion but struggle with\nfacial expressions. To address these challenges, we first introduce an\nexpressive human model (EHM) to enhance facial expression capabilities and\ndevelop an accurate tracking method. Based on this template model, we propose\nGUAVA, the first framework for fast animatable upper-body 3D Gaussian avatar\nreconstruction. We leverage inverse texture mapping and projection sampling\ntechniques to infer Ubody (upper-body) Gaussians from a single image. The\nrendered images are refined through a neural refiner. Experimental results\ndemonstrate that GUAVA significantly outperforms previous methods in rendering\nquality and offers significant speed improvements, with reconstruction times in\nthe sub-second range (0.1s), and supports real-time animation and rendering.", "published": "2025-05-06 09:19:16", "link": "http://arxiv.org/abs/2505.03351v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Vision-Language Model for Focal Liver Lesion Classification", "abstract": "Accurate classification of focal liver lesions is crucial for diagnosis and\ntreatment in hepatology. However, traditional supervised deep learning models\ndepend on large-scale annotated datasets, which are often limited in medical\nimaging. Recently, Vision-Language models (VLMs) such as Contrastive\nLanguage-Image Pre-training model (CLIP) has been applied to image\nclassifications. Compared to the conventional convolutional neural network\n(CNN), which classifiers image based on visual information only, VLM leverages\nmultimodal learning with text and images, allowing it to learn effectively even\nwith a limited amount of labeled data. Inspired by CLIP, we pro-pose a\nLiver-VLM, a model specifically designed for focal liver lesions (FLLs)\nclassification. First, Liver-VLM incorporates class information into the text\nencoder without introducing additional inference overhead. Second, by\ncalculating the pairwise cosine similarities between image and text embeddings\nand optimizing the model with a cross-entropy loss, Liver-VLM ef-fectively\naligns image features with class-level text features. Experimental results on\nMPCT-FLLs dataset demonstrate that the Liver-VLM model out-performs both the\nstandard CLIP and MedCLIP models in terms of accuracy and Area Under the Curve\n(AUC). Further analysis shows that using a lightweight ResNet18 backbone\nenhances classification performance, particularly under data-constrained\nconditions.", "published": "2025-05-06 09:19:12", "link": "http://arxiv.org/abs/2505.03350v1", "categories": ["cs.CV", "I.2.10; I.4.8"], "primary_category": "cs.CV"}
{"title": "From Word to Sentence: A Large-Scale Multi-Instance Dataset for Open-Set Aerial Detection", "abstract": "In recent years, language-guided open-world aerial object detection has\ngained significant attention due to its better alignment with real-world\napplication needs. However, due to limited datasets, most existing\nlanguage-guided methods primarily focus on vocabulary, which fails to meet the\ndemands of more fine-grained open-world detection. To address this limitation,\nwe propose constructing a large-scale language-guided open-set aerial detection\ndataset, encompassing three levels of language guidance: from words to phrases,\nand ultimately to sentences. Centered around an open-source large\nvision-language model and integrating image-operation-based preprocessing with\nBERT-based postprocessing, we present the OS-W2S Label Engine, an automatic\nannotation pipeline capable of handling diverse scene annotations for aerial\nimages. Using this label engine, we expand existing aerial detection datasets\nwith rich textual annotations and construct a novel benchmark dataset, called\nMulti-instance Open-set Aerial Dataset (MI-OAD), addressing the limitations of\ncurrent remote sensing grounding data and enabling effective open-set aerial\ndetection. Specifically, MI-OAD contains 163,023 images and 2 million\nimage-caption pairs, approximately 40 times larger than comparable datasets. We\nalso employ state-of-the-art open-set methods from the natural image domain,\ntrained on our proposed dataset, to validate the model's open-set detection\ncapabilities. For instance, when trained on our dataset, Grounding DINO\nachieves improvements of 29.5 AP_{50} and 33.7 Recall@10 for sentence inputs\nunder zero-shot transfer conditions. Both the dataset and the label engine will\nbe released publicly.", "published": "2025-05-06 09:07:52", "link": "http://arxiv.org/abs/2505.03334v1", "categories": ["cs.CV", "cs.DB"], "primary_category": "cs.CV"}
{"title": "FLUX-Text: A Simple and Advanced Diffusion Transformer Baseline for Scene Text Editing", "abstract": "The task of scene text editing is to modify or add texts on images while\nmaintaining the fidelity of newly generated text and visual coherence with the\nbackground. Recent works based on latent diffusion models (LDM) show improved\ntext editing results, yet still face challenges and often generate inaccurate\nor unrecognizable characters, especially for non-Latin ones (\\eg, Chinese),\nwhich have complex glyph structures. To address these issues, we present\nFLUX-Text, a simple and advanced multilingual scene text editing framework\nbased on FLUX-Fill. Specifically, we carefully investigate glyph conditioning,\nconsidering both visual and textual modalities. To retain the original\ngenerative capabilities of FLUX-Fill while enhancing its understanding and\ngeneration of glyphs, we propose lightweight glyph and text embedding modules.\nOwning to the lightweight design, FLUX-Text is trained only with $100K$\ntraining examples compared to current popular methods trained with 2.9M ones.\nWith no bells and whistles, our method achieves state-of-the-art performance on\ntext editing tasks. Qualitative and quantitative experiments on the public\ndatasets demonstrate that our method surpasses previous works in text fidelity.", "published": "2025-05-06 08:56:28", "link": "http://arxiv.org/abs/2505.03329v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unified Multimodal Chain-of-Thought Reward Model through Reinforcement Fine-Tuning", "abstract": "Recent advances in multimodal Reward Models (RMs) have shown significant\npromise in delivering reward signals to align vision models with human\npreferences. However, current RMs are generally restricted to providing direct\nresponses or engaging in shallow reasoning processes with limited depth, often\nleading to inaccurate reward signals. We posit that incorporating explicit long\nchains of thought (CoT) into the reward reasoning process can significantly\nstrengthen their reliability and robustness. Furthermore, we believe that once\nRMs internalize CoT reasoning, their direct response accuracy can also be\nimproved through implicit reasoning capabilities. To this end, this paper\nproposes UnifiedReward-Think, the first unified multimodal CoT-based reward\nmodel, capable of multi-dimensional, step-by-step long-chain reasoning for both\nvisual understanding and generation reward tasks. Specifically, we adopt an\nexploration-driven reinforcement fine-tuning approach to elicit and incentivize\nthe model's latent complex reasoning ability: (1) We first use a small amount\nof image generation preference data to distill the reasoning process of GPT-4o,\nwhich is then used for the model's cold start to learn the format and structure\nof CoT reasoning. (2) Subsequently, by leveraging the model's prior knowledge\nand generalization capabilities, we prepare large-scale unified multimodal\npreference data to elicit the model's reasoning process across various vision\ntasks. During this phase, correct reasoning outputs are retained for rejection\nsampling to refine the model (3) while incorrect predicted samples are finally\nused for Group Relative Policy Optimization (GRPO) based reinforcement\nfine-tuning, enabling the model to explore diverse reasoning paths and optimize\nfor correct and robust solutions. Extensive experiments across various vision\nreward tasks demonstrate the superiority of our model.", "published": "2025-05-06 08:46:41", "link": "http://arxiv.org/abs/2505.03318v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Gaussian Splatting Data Compression with Mixture of Priors", "abstract": "3D Gaussian Splatting (3DGS) data compression is crucial for enabling\nefficient storage and transmission in 3D scene modeling. However, its\ndevelopment remains limited due to inadequate entropy models and suboptimal\nquantization strategies for both lossless and lossy compression scenarios,\nwhere existing methods have yet to 1) fully leverage hyperprior information to\nconstruct robust conditional entropy models, and 2) apply fine-grained,\nelement-wise quantization strategies for improved compression granularity. In\nthis work, we propose a novel Mixture of Priors (MoP) strategy to\nsimultaneously address these two challenges. Specifically, inspired by the\nMixture-of-Experts (MoE) paradigm, our MoP approach processes hyperprior\ninformation through multiple lightweight MLPs to generate diverse prior\nfeatures, which are subsequently integrated into the MoP feature via a gating\nmechanism. To enhance lossless compression, the resulting MoP feature is\nutilized as a hyperprior to improve conditional entropy modeling. Meanwhile,\nfor lossy compression, we employ the MoP feature as guidance information in an\nelement-wise quantization procedure, leveraging a prior-guided Coarse-to-Fine\nQuantization (C2FQ) strategy with a predefined quantization step value.\nSpecifically, we expand the quantization step value into a matrix and\nadaptively refine it from coarse to fine granularity, guided by the MoP\nfeature, thereby obtaining a quantization step matrix that facilitates\nelement-wise quantization. Extensive experiments demonstrate that our proposed\n3DGS data compression framework achieves state-of-the-art performance across\nmultiple benchmarks, including Mip-NeRF360, BungeeNeRF, DeepBlending, and\nTank&Temples.", "published": "2025-05-06 08:42:39", "link": "http://arxiv.org/abs/2505.03310v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "3D Can Be Explored In 2D: Pseudo-Label Generation for LiDAR Point Clouds Using Sensor-Intensity-Based 2D Semantic Segmentation", "abstract": "Semantic segmentation of 3D LiDAR point clouds, essential for autonomous\ndriving and infrastructure management, is best achieved by supervised learning,\nwhich demands extensive annotated datasets and faces the problem of domain\nshifts. We introduce a new 3D semantic segmentation pipeline that leverages\naligned scenes and state-of-the-art 2D segmentation methods, avoiding the need\nfor direct 3D annotation or reliance on additional modalities such as camera\nimages at inference time. Our approach generates 2D views from LiDAR scans\ncolored by sensor intensity and applies 2D semantic segmentation to these views\nusing a camera-domain pretrained model. The segmented 2D outputs are then\nback-projected onto the 3D points, with a simple voting-based estimator that\nmerges the labels associated to each 3D point. Our main contribution is a\nglobal pipeline for 3D semantic segmentation requiring no prior 3D annotation\nand not other modality for inference, which can be used for pseudo-label\ngeneration. We conduct a thorough ablation study and demonstrate the potential\nof the generated pseudo-labels for the Unsupervised Domain Adaptation task.", "published": "2025-05-06 08:31:32", "link": "http://arxiv.org/abs/2505.03300v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Base-Detail Feature Learning Framework for Visible-Infrared Person Re-Identification", "abstract": "Visible-infrared person re-identification (VIReID) provides a solution for\nReID tasks in 24-hour scenarios; however, significant challenges persist in\nachieving satisfactory performance due to the substantial discrepancies between\nvisible (VIS) and infrared (IR) modalities. Existing methods inadequately\nleverage information from different modalities, primarily focusing on digging\ndistinguishing features from modality-shared information while neglecting\nmodality-specific details. To fully utilize differentiated minutiae, we propose\na Base-Detail Feature Learning Framework (BDLF) that enhances the learning of\nboth base and detail knowledge, thereby capitalizing on both modality-shared\nand modality-specific information. Specifically, the proposed BDLF mines detail\nand base features through a lossless detail feature extraction module and a\ncomplementary base embedding generation mechanism, respectively, supported by a\nnovel correlation restriction method that ensures the features gained by BDLF\nenrich both detail and base knowledge across VIS and IR features. Comprehensive\nexperiments conducted on the SYSU-MM01, RegDB, and LLCM datasets validate the\neffectiveness of BDLF.", "published": "2025-05-06 08:14:07", "link": "http://arxiv.org/abs/2505.03286v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OccCylindrical: Multi-Modal Fusion with Cylindrical Representation for 3D Semantic Occupancy Prediction", "abstract": "The safe operation of autonomous vehicles (AVs) is highly dependent on their\nunderstanding of the surroundings. For this, the task of 3D semantic occupancy\nprediction divides the space around the sensors into voxels, and labels each\nvoxel with both occupancy and semantic information. Recent perception models\nhave used multisensor fusion to perform this task. However, existing\nmultisensor fusion-based approaches focus mainly on using sensor information in\nthe Cartesian coordinate system. This ignores the distribution of the sensor\nreadings, leading to a loss of fine-grained details and performance\ndegradation. In this paper, we propose OccCylindrical that merges and refines\nthe different modality features under cylindrical coordinates. Our method\npreserves more fine-grained geometry detail that leads to better performance.\nExtensive experiments conducted on the nuScenes dataset, including challenging\nrainy and nighttime scenarios, confirm our approach's effectiveness and\nstate-of-the-art performance. The code will be available at:\nhttps://github.com/DanielMing123/OccCylindrical", "published": "2025-05-06 08:12:31", "link": "http://arxiv.org/abs/2505.03284v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "DiffVQA: Video Quality Assessment Using Diffusion Feature Extractor", "abstract": "Video Quality Assessment (VQA) aims to evaluate video quality based on\nperceptual distortions and human preferences. Despite the promising performance\nof existing methods using Convolutional Neural Networks (CNNs) and Vision\nTransformers (ViTs), they often struggle to align closely with human\nperceptions, particularly in diverse real-world scenarios. This challenge is\nexacerbated by the limited scale and diversity of available datasets. To\naddress this limitation, we introduce a novel VQA framework, DiffVQA, which\nharnesses the robust generalization capabilities of diffusion models\npre-trained on extensive datasets. Our framework adapts these models to\nreconstruct identical input frames through a control module. The adapted\ndiffusion model is then used to extract semantic and distortion features from a\nresizing branch and a cropping branch, respectively. To enhance the model's\nability to handle long-term temporal dynamics, a parallel Mamba module is\nintroduced, which extracts temporal coherence augmented features that are\nmerged with the diffusion features to predict the final score. Experiments\nacross multiple datasets demonstrate DiffVQA's superior performance on\nintra-dataset evaluations and its exceptional generalization across datasets.\nThese results confirm that leveraging a diffusion model as a feature extractor\ncan offer enhanced VQA performance compared to CNN and ViT backbones.", "published": "2025-05-06 07:42:24", "link": "http://arxiv.org/abs/2505.03261v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "PROM: Prioritize Reduction of Multiplications Over Lower Bit-Widths for Efficient CNNs", "abstract": "Convolutional neural networks (CNNs) are crucial for computer vision tasks on\nresource-constrained devices. Quantization effectively compresses these models,\nreducing storage size and energy cost. However, in modern depthwise-separable\narchitectures, the computational cost is distributed unevenly across its\ncomponents, with pointwise operations being the most expensive. By applying a\ngeneral quantization scheme to this imbalanced cost distribution, existing\nquantization approaches fail to fully exploit potential efficiency gains. To\nthis end, we introduce PROM, a straightforward approach for quantizing modern\ndepthwise-separable convolutional networks by selectively using two distinct\nbit-widths. Specifically, pointwise convolutions are quantized to ternary\nweights, while the remaining modules use 8-bit weights, which is achieved\nthrough a simple quantization-aware training procedure. Additionally, by\nquantizing activations to 8-bit, our method transforms pointwise convolutions\nwith ternary weights into int8 additions, which enjoy broad support across\nhardware platforms and effectively eliminates the need for expensive\nmultiplications. Applying PROM to MobileNetV2 reduces the model's energy cost\nby more than an order of magnitude (23.9x) and its storage size by 2.7x\ncompared to the float16 baseline while retaining similar classification\nperformance on ImageNet. Our method advances the Pareto frontier for energy\nconsumption vs. top-1 accuracy for quantized convolutional models on ImageNet.\nPROM addresses the challenges of quantizing depthwise-separable convolutional\nnetworks to both ternary and 8-bit weights, offering a simple way to reduce\nenergy cost and storage size.", "published": "2025-05-06 07:32:24", "link": "http://arxiv.org/abs/2505.03254v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Dual-Domain Masked Image Modeling: A Self-Supervised Pretraining Strategy Using Spatial and Frequency Domain Masking for Hyperspectral Data", "abstract": "Hyperspectral images (HSIs) capture rich spectral signatures that reveal\nvital material properties, offering broad applicability across various domains.\nHowever, the scarcity of labeled HSI data limits the full potential of deep\nlearning, especially for transformer-based architectures that require\nlarge-scale training. To address this constraint, we propose Spatial-Frequency\nMasked Image Modeling (SFMIM), a self-supervised pretraining strategy for\nhyperspectral data that utilizes the large portion of unlabeled data. Our\nmethod introduces a novel dual-domain masking mechanism that operates in both\nspatial and frequency domains. The input HSI cube is initially divided into\nnon-overlapping patches along the spatial dimension, with each patch comprising\nthe entire spectrum of its corresponding spatial location. In spatial masking,\nwe randomly mask selected patches and train the model to reconstruct the masked\ninputs using the visible patches. Concurrently, in frequency masking, we remove\nportions of the frequency components of the input spectra and predict the\nmissing frequencies. By learning to reconstruct these masked components, the\ntransformer-based encoder captures higher-order spectral-spatial correlations.\nWe evaluate our approach on three publicly available HSI classification\nbenchmarks and demonstrate that it achieves state-of-the-art performance.\nNotably, our model shows rapid convergence during fine-tuning, highlighting the\nefficiency of our pretraining strategy.", "published": "2025-05-06 06:24:21", "link": "http://arxiv.org/abs/2505.03220v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PiCo: Enhancing Text-Image Alignment with Improved Noise Selection and Precise Mask Control in Diffusion Models", "abstract": "Advanced diffusion models have made notable progress in text-to-image\ncompositional generation. However, it is still a challenge for existing models\nto achieve text-image alignment when confronted with complex text prompts. In\nthis work, we highlight two factors that affect this alignment: the quality of\nthe randomly initialized noise and the reliability of the generated controlling\nmask. We then propose PiCo (Pick-and-Control), a novel training-free approach\nwith two key components to tackle these two factors. First, we develop a noise\nselection module to assess the quality of the random noise and determine\nwhether the noise is suitable for the target text. A fast sampling strategy is\nutilized to ensure efficiency in the noise selection stage. Second, we\nintroduce a referring mask module to generate pixel-level masks and to\nprecisely modulate the cross-attention maps. The referring mask is applied to\nthe standard diffusion process to guide the reasonable interaction between text\nand image features. Extensive experiments have been conducted to verify the\neffectiveness of PiCo in liberating users from the tedious process of random\ngeneration and in enhancing the text-image alignment for diverse text\ndescriptions.", "published": "2025-05-06 05:38:13", "link": "http://arxiv.org/abs/2505.03203v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CoGenAV: Versatile Audio-Visual Representation Learning via Contrastive-Generative Synchronization", "abstract": "The inherent synchronization between a speaker's lip movements, voice, and\nthe underlying linguistic content offers a rich source of information for\nimproving speech processing tasks, especially in challenging conditions where\ntraditional audio-only systems falter. We introduce CoGenAV, a powerful and\ndata-efficient model designed to learn versatile audio-visual representations\napplicable across a wide range of speech and audio-visual tasks. CoGenAV is\ntrained by optimizing a dual objective derived from natural audio-visual\nsynchrony, contrastive feature alignment and generative text prediction, using\nonly 223 hours of labeled data from the LRS2 dataset. This\ncontrastive-generative synchronization strategy effectively captures\nfundamental cross-modal correlations. We showcase the effectiveness and\nversatility of the learned CoGenAV representations on multiple benchmarks. When\nutilized for Audio-Visual Speech Recognition (AVSR) on LRS2, these\nrepresentations contribute to achieving a state-of-the-art Word Error Rate\n(WER) of 1.27. They also enable strong performance in Visual Speech Recognition\n(VSR) with a WER of 22.0 on LRS2, and significantly improve performance in\nnoisy environments by over 70%. Furthermore, CoGenAV representations benefit\nspeech reconstruction tasks, boosting performance in Speech Enhancement and\nSeparation, and achieve competitive results in audio-visual synchronization\ntasks like Active Speaker Detection (ASD). Our model will be open-sourced to\nfacilitate further development and collaboration within both academia and\nindustry.", "published": "2025-05-06 05:07:11", "link": "http://arxiv.org/abs/2505.03186v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Interactive Instance Annotation with Siamese Networks", "abstract": "Annotating instance masks is time-consuming and labor-intensive. A promising\nsolution is to predict contours using a deep learning model and then allow\nusers to refine them. However, most existing methods focus on in-domain\nscenarios, limiting their effectiveness for cross-domain annotation tasks. In\nthis paper, we propose SiamAnno, a framework inspired by the use of Siamese\nnetworks in object tracking. SiamAnno leverages one-shot learning to annotate\npreviously unseen objects by taking a bounding box as input and predicting\nobject boundaries, which can then be adjusted by annotators. Trained on one\ndataset and tested on another without fine-tuning, SiamAnno achieves\nstate-of-the-art (SOTA) performance across multiple datasets, demonstrating its\nability to handle domain and environment shifts in cross-domain tasks. We also\nprovide more comprehensive results compared to previous work, establishing a\nstrong baseline for future research. To our knowledge, SiamAnno is the first\nmodel to explore Siamese architecture for instance annotation.", "published": "2025-05-06 05:04:56", "link": "http://arxiv.org/abs/2505.03184v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets", "abstract": "Instruction-Action (IA) data pairs are valuable for training robotic systems,\nespecially autonomous vehicles (AVs), but having humans manually annotate this\ndata is costly and time-inefficient. This paper explores the potential of using\nmobile application Global Positioning System (GPS) references and Natural\nLanguage Processing (NLP) to automatically generate large volumes of IA\ncommands and responses without having a human generate or retroactively tag the\ndata. In our pilot data collection, by driving to various destinations and\ncollecting voice instructions from GPS applications, we demonstrate a means to\ncollect and categorize the diverse sets of instructions, further accompanied by\nvideo data to form complete vision-language-action triads. We provide details\non our completely automated data collection prototype system, ADVLAT-Engine. We\ncharacterize collected GPS voice instructions into eight different\nclassifications, highlighting the breadth of commands and referentialities\navailable for curation from freely available mobile applications. Through\nresearch and exploration into the automation of IA data pairs using GPS\nreferences, the potential to increase the speed and volume at which\nhigh-quality IA datasets are created, while minimizing cost, can pave the way\nfor robust vision-language-action (VLA) models to serve tasks in\nvision-language navigation (VLN) and human-interactive autonomous systems.", "published": "2025-05-06 04:38:41", "link": "http://arxiv.org/abs/2505.03174v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Robust Fairness Vision-Language Learning for Medical Image Analysis", "abstract": "The advent of Vision-Language Models (VLMs) in medical image analysis has the\npotential to help process multimodal inputs and increase performance over\ntraditional inference methods. However, when considering the domain in which\nthese models will be implemented, fairness and robustness are important to\nensure the model stays true for any patient. In this paper, we introduce a\nframework for ensuring robustness and fairness of VLM models. This framework\nmodifies the loss function at training by identifying and adjusting faulty\nimage-text pairs through a Dynamic Bad Pair Mining algorithm and also utilizing\nSinkhorn distance to ensure the loss distributions of protected groups do not\ndeviate from the total loss. Experimental testing of our framework shows up to\na 8.6\\% improvement when looking at equity-scaled AUC.", "published": "2025-05-06 03:59:25", "link": "http://arxiv.org/abs/2505.03153v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Glass Defect Detection with Diffusion Models: Addressing Imbalanced Datasets in Manufacturing Quality Control", "abstract": "Visual defect detection in industrial glass manufacturing remains a critical\nchallenge due to the low frequency of defective products, leading to imbalanced\ndatasets that limit the performance of deep learning models and computer vision\nsystems. This paper presents a novel approach using Denoising Diffusion\nProbabilistic Models (DDPMs) to generate synthetic defective glass product\nimages for data augmentation, effectively addressing class imbalance issues in\nmanufacturing quality control and automated visual inspection. The methodology\nsignificantly enhances image classification performance of standard CNN\narchitectures (ResNet50V2, EfficientNetB0, and MobileNetV2) in detecting\nanomalies by increasing the minority class representation. Experimental results\ndemonstrate substantial improvements in key machine learning metrics,\nparticularly in recall for defective samples across all tested deep neural\nnetwork architectures while maintaining perfect precision. The most dramatic\nimprovement was observed in ResNet50V2's overall classification accuracy, which\nincreased from 78 percent to 93 percent when trained with the augmented data.\nThis work provides a scalable, cost-effective approach to enhancing automated\ndefect detection in glass manufacturing that can potentially be extended to\nother industrial quality assurance systems and industries with similar class\nimbalance challenges.", "published": "2025-05-06 03:16:56", "link": "http://arxiv.org/abs/2505.03134v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "STG: Spatiotemporal Graph Neural Network with Fusion and Spatiotemporal Decoupling Learning for Prognostic Prediction of Colorectal Cancer Liver Metastasis", "abstract": "We propose a multimodal spatiotemporal graph neural network (STG) framework\nto predict colorectal cancer liver metastasis (CRLM) progression. Current\nclinical models do not effectively integrate the tumor's spatial heterogeneity,\ndynamic evolution, and complex multimodal data relationships, limiting their\npredictive accuracy. Our STG framework combines preoperative CT imaging and\nclinical data into a heterogeneous graph structure, enabling joint modeling of\ntumor distribution and temporal evolution through spatial topology and\ncross-modal edges. The framework uses GraphSAGE to aggregate spatiotemporal\nneighborhood information and leverages supervised and contrastive learning\nstrategies to enhance the model's ability to capture temporal features and\nimprove robustness. A lightweight version of the model reduces parameter count\nby 78.55%, maintaining near-state-of-the-art performance. The model jointly\noptimizes recurrence risk regression and survival analysis tasks, with\ncontrastive loss improving feature representational discriminability and\ncross-modal consistency. Experimental results on the MSKCC CRLM dataset show a\ntime-adjacent accuracy of 85% and a mean absolute error of 1.1005,\nsignificantly outperforming existing methods. The innovative heterogeneous\ngraph construction and spatiotemporal decoupling mechanism effectively uncover\nthe associations between dynamic tumor microenvironment changes and prognosis,\nproviding reliable quantitative support for personalized treatment decisions.", "published": "2025-05-06 02:41:34", "link": "http://arxiv.org/abs/2505.03123v1", "categories": ["eess.IV", "cs.CV", "cs.MM"], "primary_category": "eess.IV"}
{"title": "TimeTracker: Event-based Continuous Point Tracking for Video Frame Interpolation with Non-linear Motion", "abstract": "Video frame interpolation (VFI) that leverages the bio-inspired event cameras\nas guidance has recently shown better performance and memory efficiency than\nthe frame-based methods, thanks to the event cameras' advantages, such as high\ntemporal resolution. A hurdle for event-based VFI is how to effectively deal\nwith non-linear motion, caused by the dynamic changes in motion direction and\nspeed within the scene. Existing methods either use events to estimate sparse\noptical flow or fuse events with image features to estimate dense optical flow.\nUnfortunately, motion errors often degrade the VFI quality as the continuous\nmotion cues from events do not align with the dense spatial information of\nimages in the temporal dimension. In this paper, we find that object motion is\ncontinuous in space, tracking local regions over continuous time enables more\naccurate identification of spatiotemporal feature correlations. In light of\nthis, we propose a novel continuous point tracking-based VFI framework, named\nTimeTracker. Specifically, we first design a Scene-Aware Region Segmentation\n(SARS) module to divide the scene into similar patches. Then, a Continuous\nTrajectory guided Motion Estimation (CTME) module is proposed to track the\ncontinuous motion trajectory of each patch through events. Finally,\nintermediate frames at any given time are generated through global motion\noptimization and frame refinement. Moreover, we collect a real-world dataset\nthat features fast non-linear motion. Extensive experiments show that our\nmethod outperforms prior arts in both motion estimation and frame interpolation\nquality.", "published": "2025-05-06 02:12:19", "link": "http://arxiv.org/abs/2505.03116v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Path and Bone-Contour Regularized Unpaired MRI-to-CT Translation", "abstract": "Accurate MRI-to-CT translation promises the integration of complementary\nimaging information without the need for additional imaging sessions. Given the\npractical challenges associated with acquiring paired MRI and CT scans, the\ndevelopment of robust methods capable of leveraging unpaired datasets is\nessential for advancing the MRI-to-CT translation. Current unpaired MRI-to-CT\ntranslation methods, which predominantly rely on cycle consistency and\ncontrastive learning frameworks, frequently encounter challenges in accurately\ntranslating anatomical features that are highly discernible on CT but less\ndistinguishable on MRI, such as bone structures. This limitation renders these\napproaches less suitable for applications in radiation therapy, where precise\nbone representation is essential for accurate treatment planning. To address\nthis challenge, we propose a path- and bone-contour regularized approach for\nunpaired MRI-to-CT translation. In our method, MRI and CT images are projected\nto a shared latent space, where the MRI-to-CT mapping is modeled as a\ncontinuous flow governed by neural ordinary differential equations. The optimal\nmapping is obtained by minimizing the transition path length of the flow. To\nenhance the accuracy of translated bone structures, we introduce a trainable\nneural network to generate bone contours from MRI and implement mechanisms to\ndirectly and indirectly encourage the model to focus on bone contours and their\nadjacent regions. Evaluations conducted on three datasets demonstrate that our\nmethod outperforms existing unpaired MRI-to-CT translation approaches,\nachieving lower overall error rates. Moreover, in a downstream bone\nsegmentation task, our approach exhibits superior performance in preserving the\nfidelity of bone structures. Our code is available at:\nhttps://github.com/kennysyp/PaBoT.", "published": "2025-05-06 02:08:35", "link": "http://arxiv.org/abs/2505.03114v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Image Recognition with Online Lightweight Vision Transformer: A Survey", "abstract": "The Transformer architecture has achieved significant success in natural\nlanguage processing, motivating its adaptation to computer vision tasks. Unlike\nconvolutional neural networks, vision transformers inherently capture\nlong-range dependencies and enable parallel processing, yet lack inductive\nbiases and efficiency benefits, facing significant computational and memory\nchallenges that limit its real-world applicability. This paper surveys various\nonline strategies for generating lightweight vision transformers for image\nrecognition, focusing on three key areas: Efficient Component Design, Dynamic\nNetwork, and Knowledge Distillation. We evaluate the relevant exploration for\neach topic on the ImageNet-1K benchmark, analyzing trade-offs among precision,\nparameters, throughput, and more to highlight their respective advantages,\ndisadvantages, and flexibility. Finally, we propose future research directions\nand potential challenges in the lightweighting of vision transformers with the\naim of inspiring further exploration and providing practical guidance for the\ncommunity. Project Page: https://github.com/ajxklo/Lightweight-VIT", "published": "2025-05-06 02:07:54", "link": "http://arxiv.org/abs/2505.03113v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Not All Parameters Matter: Masking Diffusion Models for Enhancing Generation Ability", "abstract": "The diffusion models, in early stages focus on constructing basic image\nstructures, while the refined details, including local features and textures,\nare generated in later stages. Thus the same network layers are forced to learn\nboth structural and textural information simultaneously, significantly\ndiffering from the traditional deep learning architectures (e.g., ResNet or\nGANs) which captures or generates the image semantic information at different\nlayers. This difference inspires us to explore the time-wise diffusion models.\nWe initially investigate the key contributions of the U-Net parameters to the\ndenoising process and identify that properly zeroing out certain parameters\n(including large parameters) contributes to denoising, substantially improving\nthe generation quality on the fly. Capitalizing on this discovery, we propose a\nsimple yet effective method-termed ``MaskUNet''- that enhances generation\nquality with negligible parameter numbers. Our method fully leverages timestep-\nand sample-dependent effective U-Net parameters. To optimize MaskUNet, we offer\ntwo fine-tuning strategies: a training-based approach and a training-free\napproach, including tailored networks and optimization functions. In zero-shot\ninference on the COCO dataset, MaskUNet achieves the best FID score and further\ndemonstrates its effectiveness in downstream task evaluations. Project page:\nhttps://gudaochangsheng.github.io/MaskUnet-Page/", "published": "2025-05-06 01:14:20", "link": "http://arxiv.org/abs/2505.03097v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Estimating the Diameter at Breast Height of Trees in a Forest With a Single 360 Camera", "abstract": "Forest inventories rely on accurate measurements of the diameter at breast\nheight (DBH) for ecological monitoring, resource management, and carbon\naccounting. While LiDAR-based techniques can achieve centimeter-level\nprecision, they are cost-prohibitive and operationally complex. We present a\nlow-cost alternative that only needs a consumer-grade 360 video camera. Our\nsemi-automated pipeline comprises of (i) a dense point cloud reconstruction\nusing Structure from Motion (SfM) photogrammetry software called Agisoft\nMetashape, (ii) semantic trunk segmentation by projecting Grounded Segment\nAnything (SAM) masks onto the 3D cloud, and (iii) a robust RANSAC-based\ntechnique to estimate cross section shape and DBH. We introduce an interactive\nvisualization tool for inspecting segmented trees and their estimated DBH. On\n61 acquisitions of 43 trees under a variety of conditions, our method attains\nmedian absolute relative errors of 5-9% with respect to \"ground-truth\" manual\nmeasurements. This is only 2-4% higher than LiDAR-based estimates, while\nemploying a single 360 camera that costs orders of magnitude less, requires\nminimal setup, and is widely available.", "published": "2025-05-06 01:09:07", "link": "http://arxiv.org/abs/2505.03093v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On edge-colouring-games by Erd\u0151s, and Bensmail and Mc Inerney", "abstract": "We consider two games proposed by Erd\\H{o}s, and one game by Bensmail and Mc\nInerney, all with the same setup of two players alternately colouring one edge\nof a clique. We give observations and particular behaviour for each of these\nproblems, and prove a first reduction towards confirming the conjecture by\nBensmail and Mc Inerney. We state a conjecture for Erd\\H{o}s' game on the\nlargest induced maximum degree, and extensions to edge-transitive and,\nrespectively, regular graphs.", "published": "2025-05-06 13:01:30", "link": "http://arxiv.org/abs/2505.03497v1", "categories": ["math.CO", "cs.DM", "cs.GT", "05C15, 05C57, 91A10, 91A05, 91A43, 91A46, 91A68"], "primary_category": "math.CO"}
{"title": "Familiarizing with Music: Discovery Patterns for Different Music Discovery Needs", "abstract": "Humans have the tendency to discover and explore. This natural tendency is\nreflected in data from streaming platforms as the amount of previously unknown\ncontent accessed by users. Additionally, in domains such as that of music\nstreaming there is evidence that recommending novel content improves users'\nexperience with the platform. Therefore, understanding users' discovery\npatterns, such as the amount to which and the way users access previously\nunknown content, is a topic of relevance for both the scientific community and\nthe streaming industry, particularly the music one. Previous works studied how\nmusic consumption differs for users of different traits and looked at\ndiversity, novelty, and consistency over time of users' music preferences.\nHowever, very little is known about how users discover and explore previously\nunknown music, and how this behavior differs for users of varying discovery\nneeds. In this paper we bridge this gap by analyzing data from a survey\nanswered by users of the major music streaming platform Deezer in combination\nwith their streaming data. We first address questions regarding whether users\nwho declare a higher interest in unfamiliar music listen to more diverse music,\nhave more stable music preferences over time, and explore more music within a\nsame time window, compared to those who declare a lower interest. We then\ninvestigate which type of music tracks users choose to listen to when they\nexplore unfamiliar music, identifying clear patterns of popularity and genre\nrepresentativeness that vary for users of different discovery needs.\n  Our findings open up possibilities to infer users' interest in unfamiliar\nmusic from streaming data as well as possibilities to develop recommender\nsystems that guide users in exploring music in a more natural way.", "published": "2025-05-06 14:26:00", "link": "http://arxiv.org/abs/2505.03568v1", "categories": ["cs.IR", "cs.HC"], "primary_category": "cs.IR"}
{"title": "1$^{st}$ Place Solution of WWW 2025 EReL@MIR Workshop Multimodal CTR Prediction Challenge", "abstract": "The WWW 2025 EReL@MIR Workshop Multimodal CTR Prediction Challenge focuses on\neffectively applying multimodal embedding features to improve click-through\nrate (CTR) prediction in recommender systems. This technical report presents\nour 1$^{st}$ place winning solution for Task 2, combining sequential modeling\nand feature interaction learning to effectively capture user-item interactions.\nFor multimodal information integration, we simply append the frozen multimodal\nembeddings to each item embedding. Experiments on the challenge dataset\ndemonstrate the effectiveness of our method, achieving superior performance\nwith a 0.9839 AUC on the leaderboard, much higher than the baseline model. Code\nand configuration are available in our GitHub repository and the checkpoint of\nour model can be found in HuggingFace.", "published": "2025-05-06 13:55:22", "link": "http://arxiv.org/abs/2505.03543v1", "categories": ["cs.IR", "H.3.1; I.2"], "primary_category": "cs.IR"}
{"title": "STAR-Rec: Making Peace with Length Variance and Pattern Diversity in Sequential Recommendation", "abstract": "Recent deep sequential recommendation models often struggle to effectively\nmodel key characteristics of user behaviors, particularly in handling sequence\nlength variations and capturing diverse interaction patterns. We propose\nSTAR-Rec, a novel architecture that synergistically combines preference-aware\nattention and state-space modeling through a sequence-level mixture-of-experts\nframework. STAR-Rec addresses these challenges by: (1) employing\npreference-aware attention to capture both inherently similar item\nrelationships and diverse preferences, (2) utilizing state-space modeling to\nefficiently process variable-length sequences with linear complexity, and (3)\nincorporating a mixture-of-experts component that adaptively routes different\nbehavioral patterns to specialized experts, handling both focused\ncategory-specific browsing and diverse category exploration patterns. We\ntheoretically demonstrate how the state space model and attention mechanisms\ncan be naturally unified in recommendation scenarios, where SSM captures\ntemporal dynamics through state compression while attention models both similar\nand diverse item relationships. Extensive experiments on four real-world\ndatasets demonstrate that STAR-Rec consistently outperforms state-of-the-art\nsequential recommendation methods, particularly in scenarios involving diverse\nuser behaviors and varying sequence lengths.", "published": "2025-05-06 12:40:38", "link": "http://arxiv.org/abs/2505.03484v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Modeling Musical Genre Trajectories through Pathlet Learning", "abstract": "The increasing availability of user data on music streaming platforms opens\nup new possibilities for analyzing music consumption. However, understanding\nthe evolution of user preferences remains a complex challenge, particularly as\ntheir musical tastes change over time. This paper uses the dictionary learning\nparadigm to model user trajectories across different musical genres. We define\na new framework that captures recurring patterns in genre trajectories, called\npathlets, enabling the creation of comprehensible trajectory embeddings. We\nshow that pathlet learning reveals relevant listening patterns that can be\nanalyzed both qualitatively and quantitatively. This work improves our\nunderstanding of users' interactions with music and opens up avenues of\nresearch into user behavior and fostering diversity in recommender systems. A\ndataset of 2000 user histories tagged by genre over 17 months, supplied by\nDeezer (a leading music streaming company), is also released with the code.", "published": "2025-05-06 12:33:40", "link": "http://arxiv.org/abs/2505.03480v1", "categories": ["cs.IR", "cs.LG", "cs.MM"], "primary_category": "cs.IR"}
{"title": "Advancing Remote and Continuous Cardiovascular Patient Monitoring through a Novel and Resource-efficient IoT-Driven Framework", "abstract": "Cardiovascular diseases are a leading cause of fatalities worldwide, often\noccurring suddenly with limited time for intervention. Current healthcare\nmonitoring systems for cardiac patients rely heavily on hospitalization, which\ncan be impractical for continuous monitoring. This paper presents a novel\nIoT-based solution for remote, real-time tracking of critical cardiac metrics,\naddressing the pressing need for accessible and continuous healthcare,\nparticularly for the aging population in Pakistan. The proposed IoT kit\nmeasures essential parameters such as body temperature, heart rate (HR), blood\npressure (BP), oxygen saturation (SPO2), and electrocardiography (ECG).\n  A key innovation of the system is its integration with a cloud-based\napplication, enabling constant remote monitoring and incorporating an alarm\nmechanism to alert medical professionals for timely intervention, reducing the\nrisk of catastrophic incidents. The system was tested in a clinical environment\nwith 20 participants, demonstrating results closely aligned with those obtained\nusing standard medical devices. The findings validate the system's potential\nfor reliable remote monitoring, offering a significant step forward in\nproactive cardiac healthcare management. This novel approach combines IoT\ntechnology with cloud-based applications to provide a cost-effective and\nefficient solution for reducing unexpected fatalities among cardiac patients.", "published": "2025-05-06 10:35:31", "link": "http://arxiv.org/abs/2505.03409v1", "categories": ["cs.NI", "cs.IR"], "primary_category": "cs.NI"}
{"title": "CB-cPIR: Code-Based Computational Private Information Retrieval", "abstract": "A private information retrieval (PIR) scheme is a protocol that allows a user\nto retrieve a file from a database without revealing the identity of the\ndesired file to a curious database. Given a distributed data storage system,\nefficient PIR can be achieved by making assumptions about the colluding\ncapabilities of the storage servers holding the database. If these assumptions\nturn out to be incorrect, privacy is lost. In this work, we focus on the\nworst-case assumption: full collusion or, equivalently, viewing the storage\nsystem virtually as a single honest-but-curious server. We present CB-cPIR, a\nsingle-server code-based computational private information retrieval (cPIR)\nscheme that derives security from code-based cryptography. Specifically, the\nqueries are protected by the hardness of decoding a random linear code. The\nscheme is heavily inspired by the pioneering code-based cPIR scheme proposed by\nHolzbaur, Hollanti, and Wachter-Zeh in [Holzbaur et al., \"Computational\nCode-Based Single-Server Private Information Retrieval\", 2020 IEEE ISIT] and\nfixes the vulnerabilities of the original scheme arising from highly probable\nrank differences in submatrices of the user's query. For further validation, we\ndraw comparisons to the state-of-the-art lattice-based cPIR schemes.", "published": "2025-05-06 10:34:44", "link": "http://arxiv.org/abs/2505.03407v1", "categories": ["cs.IR", "cs.IT", "math.IT"], "primary_category": "cs.IR"}
{"title": "Tell Me the Good Stuff: User Preferences in Movie Recommendation Explanations", "abstract": "Recommender systems play a vital role in helping users discover content in\nstreaming services, but their effectiveness depends on users understanding why\nitems are recommended. In this study, explanations were based solely on item\nfeatures rather than personalized data, simulating recommendation scenarios. We\ncompared user perceptions of one-sided (purely positive) and two-sided\n(positive and negative) feature-based explanations for popular movie\nrecommendations. Through an online study with 129 participants, we examined how\nexplanation style affected perceived trust, transparency, effectiveness, and\nsatisfaction. One-sided explanations consistently received higher ratings\nacross all dimensions. Our findings suggest that in low-stakes entertainment\ndomains such as popular movie recommendations, simpler positive explanations\nmay be more effective. However, the results should be interpreted with caution\ndue to potential confounding factors such as item familiarity and the placement\nof negative information in explanations. This work provides practical insights\nfor explanation design in recommender interfaces and highlights the importance\nof context in shaping user preferences.", "published": "2025-05-06 09:52:33", "link": "http://arxiv.org/abs/2505.03376v1", "categories": ["cs.IR", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Soft Reasoning Paths for Knowledge Graph Completion", "abstract": "Reasoning paths are reliable information in knowledge graph completion (KGC)\nin which algorithms can find strong clues of the actual relation between\nentities. However, in real-world applications, it is difficult to guarantee\nthat computationally affordable paths exist toward all candidate entities.\nAccording to our observation, the prediction accuracy drops significantly when\npaths are absent. To make the proposed algorithm more stable against the\nmissing path circumstances, we introduce soft reasoning paths. Concretely, a\nspecific learnable latent path embedding is concatenated to each relation to\nhelp better model the characteristics of the corresponding paths. The\ncombination of the relation and the corresponding learnable embedding is termed\na soft path in our paper. By aligning the soft paths with the reasoning paths,\na learnable embedding is guided to learn a generalized path representation of\nthe corresponding relation. In addition, we introduce a hierarchical ranking\nstrategy to make full use of information about the entity, relation, path, and\nsoft path to help improve both the efficiency and accuracy of the model.\nExtensive experimental results illustrate that our algorithm outperforms the\ncompared state-of-the-art algorithms by a notable margin. The code will be made\npublicly available after the paper is officially accepted.", "published": "2025-05-06 08:12:48", "link": "http://arxiv.org/abs/2505.03285v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Characterising Topic Familiarity and Query Specificity Using Eye-Tracking Data", "abstract": "Eye-tracking data has been shown to correlate with a user's knowledge level\nand query formulation behaviour. While previous work has focused primarily on\neye gaze fixations for attention analysis, often requiring additional\ncontextual information, our study investigates the memory-related cognitive\ndimension by relying solely on pupil dilation and gaze velocity to infer users'\ntopic familiarity and query specificity without needing any contextual\ninformation. Using eye-tracking data collected via a lab user study (N=18), we\nachieved a Macro F1 score of 71.25% for predicting topic familiarity with a\nGradient Boosting classifier, and a Macro F1 score of 60.54% with a k-nearest\nneighbours (KNN) classifier for query specificity. Furthermore, we developed a\nnovel annotation guideline -- specifically tailored for question answering --\nto manually classify queries as Specific or Non-specific. This study\ndemonstrates the feasibility of eye-tracking to better understand topic\nfamiliarity and query specificity in search.", "published": "2025-05-06 03:22:04", "link": "http://arxiv.org/abs/2505.03136v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "DNA Tails for Molecular Flash Memory", "abstract": "DNA-based data storage systems face practical challenges due to the high cost\nof DNA synthesis. A strategy to address the problem entails encoding data via\ntopological modifications of the DNA sugar-phosphate backbone. The DNA\nPunchcards system, which introduces nicks (cuts) in the DNA backbone, encodes\nonly one bit per nicking site, limiting density. We propose \\emph{DNA Tails,} a\nstorage paradigm that encodes nonbinary symbols at nicking sites by growing\nenzymatically synthesized single-stranded DNA of varied lengths. The average\ntail lengths encode multiple information bits and are controlled via a\nstaggered nicking-tail extension process. We demonstrate the feasibility of\nthis encoding approach experimentally and identify common sources of errors,\nsuch as calibration errors and stumped tail growth errors. To mitigate\ncalibration errors, we use rank modulation proposed for flash memory. To\ncorrect stumped tail growth errors, we introduce a new family of rank\nmodulation codes that can correct ``stuck-at'' errors. Our analytical results\ninclude constructions for order-optimal-redundancy permutation codes and\naccompanying encoding and decoding algorithms.", "published": "2025-05-06 15:28:23", "link": "http://arxiv.org/abs/2505.03629v1", "categories": ["cs.ET", "cs.IT", "math.IT"], "primary_category": "cs.ET"}
{"title": "Information-theoretic reduction of deep neural networks to linear models in the overparametrized proportional regime", "abstract": "We rigorously analyse fully-trained neural networks of arbitrary depth in the\nBayesian optimal setting in the so-called proportional scaling regime where the\nnumber of training samples and width of the input and all inner layers diverge\nproportionally. We prove an information-theoretic equivalence between the\nBayesian deep neural network model trained from data generated by a teacher\nwith matching architecture, and a simpler model of optimal inference in a\ngeneralized linear model. This equivalence enables us to compute the optimal\ngeneralization error for deep neural networks in this regime. We thus prove the\n\"deep Gaussian equivalence principle\" conjectured in Cui et al. (2023)\n(arXiv:2302.00375). Our result highlights that in order to escape this\n\"trivialisation\" of deep neural networks (in the sense of reduction to a linear\nmodel) happening in the strongly overparametrized proportional regime, models\ntrained from much more data have to be considered.", "published": "2025-05-06 14:36:07", "link": "http://arxiv.org/abs/2505.03577v1", "categories": ["math.ST", "cond-mat.dis-nn", "cs.IT", "math-ph", "math.IT", "math.MP", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "A Comprehensive Survey of Large AI Models for Future Communications: Foundations, Applications and Challenges", "abstract": "The 6G wireless communications aim to establish an intelligent world of\nubiquitous connectivity, providing an unprecedented communication experience.\nLarge artificial intelligence models (LAMs) are characterized by significantly\nlarger scales (e.g., billions or trillions of parameters) compared to typical\nartificial intelligence (AI) models. LAMs exhibit outstanding cognitive\nabilities, including strong generalization capabilities for fine-tuning to\ndownstream tasks, and emergent capabilities to handle tasks unseen during\ntraining. Therefore, LAMs efficiently provide AI services for diverse\ncommunication applications, making them crucial tools for addressing complex\nchallenges in future wireless communication systems. This study provides a\ncomprehensive review of the foundations, applications, and challenges of LAMs\nin communication. First, we introduce the current state of AI-based\ncommunication systems, emphasizing the motivation behind integrating LAMs into\ncommunications and summarizing the key contributions. We then present an\noverview of the essential concepts of LAMs in communication. This includes an\nintroduction to the main architectures of LAMs, such as transformer, diffusion\nmodels, and mamba. We also explore the classification of LAMs, including large\nlanguage models (LLMs), large vision models (LVMs), large multimodal models\n(LMMs), and world models, and examine their potential applications in\ncommunication. Additionally, we cover the training methods and evaluation\ntechniques for LAMs in communication systems. Lastly, we introduce optimization\nstrategies such as chain of thought (CoT), retrieval augmented generation\n(RAG), and agentic systems. Following this, we discuss the research\nadvancements of LAMs across various communication scenarios. Finally, we\nanalyze the challenges in the current research and provide insights into\npotential future research directions.", "published": "2025-05-06 14:09:29", "link": "http://arxiv.org/abs/2505.03556v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "SKALD: Scalable K-Anonymisation for Large Datasets", "abstract": "Data privacy and anonymisation are critical concerns in today's data-driven\nsociety, particularly when handling personal and sensitive user data.\nRegulatory frameworks worldwide recommend privacy-preserving protocols such as\nk-anonymisation to de-identify releases of tabular data. Available hardware\nresources provide an upper bound on the maximum size of dataset that can be\nprocessed at a time. Large datasets with sizes exceeding this upper bound must\nbe broken up into smaller data chunks for processing. In these cases, standard\nk-anonymisation tools such as ARX can only operate on a per-chunk basis. This\npaper proposes SKALD, a novel algorithm for performing k-anonymisation on large\ndatasets with limited RAM. Our SKALD algorithm offers multi-fold performance\nimprovement over standard k-anonymisation methods by extracting and combining\nsufficient statistics from each chunk during processing to ensure successful\nk-anonymisation while providing better utility.", "published": "2025-05-06 13:38:53", "link": "http://arxiv.org/abs/2505.03529v1", "categories": ["cs.IT", "cs.CR", "math.IT"], "primary_category": "cs.IT"}
{"title": "Signal Prediction by Derivative Samples from the Past via Perfect Reconstruction", "abstract": "This paper investigates signal prediction through the perfect reconstruction\nof signals from shift-invariant spaces using nonuniform samples of both the\nsignal and its derivatives. The key advantage of derivative sampling is its\nability to reduce the sampling rate. We derive a sampling formula based on\nperiodic nonuniform sampling (PNS) sets with derivatives in a shift-invariant\nspace. We establish the necessary and sufficient conditions for such a set to\nform a complete interpolating sequence (CIS) of order $r-1$. This framework is\nthen used to develop an efficient approximation scheme in a shift-invariant\nspace generated by a compactly supported function. Building on this, we propose\na prediction algorithm that reconstructs a signal from a finite number of past\nderivative samples using the derived perfect reconstruction formula. Finally,\nwe validate our theoretical results through practical examples involving cubic\nsplines and the Daubechies scaling function of order 3.", "published": "2025-05-06 12:23:07", "link": "http://arxiv.org/abs/2505.03471v1", "categories": ["cs.IT", "math.IT", "Primary 42C15, 94A20"], "primary_category": "cs.IT"}
{"title": "GNN-enabled Precoding for Massive MIMO LEO Satellite Communications", "abstract": "Low Earth Orbit (LEO) satellite communication is a critical component in the\ndevelopment of sixth generation (6G) networks. The integration of massive\nmultiple-input multiple-output (MIMO) technology is being actively explored to\nenhance the performance of LEO satellite communications. However, the limited\npower of LEO satellites poses a significant challenge in improving\ncommunication energy efficiency (EE) under constrained power conditions.\nArtificial intelligence (AI) methods are increasingly recognized as promising\nsolutions for optimizing energy consumption while enhancing system performance,\nthus enabling more efficient and sustainable communications. This paper\nproposes approaches to address the challenges associated with precoding in\nmassive MIMO LEO satellite communications. First, we introduce an end-to-end\ngraph neural network (GNN) framework that effectively reduces the computational\ncomplexity of traditional precoding methods. Next, we introduce a deep\nunfolding of the Dinkelbach algorithm and the weighted minimum mean square\nerror (WMMSE) approach to achieve enhanced EE, transforming iterative\noptimization processes into a structured neural network, thereby improving\nconvergence speed and computational efficiency. Furthermore, we incorporate the\nTaylor expansion method to approximate matrix inversion within the GNN,\nenhancing both the interpretability and performance of the proposed method.\nNumerical experiments demonstrate the validity of our proposed method in terms\nof complexity and robustness, achieving significant improvements over\nstate-of-the-art methods.", "published": "2025-05-06 08:43:15", "link": "http://arxiv.org/abs/2505.03311v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Rapid diagnostics of reconfigurable intelligent surfaces using space-time-coding modulation", "abstract": "Reconfigurable intelligent surfaces (RISs) have emerged as a key technology\nfor shaping smart wireless environments in next-generation wireless\ncommunication systems. To support the large-scale deployment of RISs, a\nreliable and efficient diagnostic method is essential to ensure optimal\nperformance. In this work, a robust and efficient approach for RIS diagnostics\nis proposed using a space-time coding strategy with orthogonal codes. The\nmethod encodes the reflected signals from individual RIS elements into distinct\ncode channels, enabling the recovery of channel power at the receiving\nterminals for fault identification. Theoretical analysis shows that the\nnormally functioning elements generate high power in their respective code\nchannels, whereas the faulty elements exhibit significantly lower power. This\ndistinction enables rapid and accurate diagnostics of elements' operational\nstates through simple signal processing techniques. Simulation results validate\nthe effectiveness of the proposed method, even under high fault ratios and\nvarying reception angles. Proof-of-principle experiments on two RIS prototypes\nare conducted, implementing two coding strategies: direct and segmented.\nExperimental results in a realistic scenario confirm the reliability of the\ndiagnostic method, demonstrating its potential for large-scale RIS deployment\nin future wireless communication systems and radar applications.", "published": "2025-05-06 07:58:26", "link": "http://arxiv.org/abs/2505.03266v1", "categories": ["physics.optics", "cs.IT", "eess.SP", "math.IT"], "primary_category": "physics.optics"}
{"title": "Multiuser Communications Aided by Cross-Linked Movable Antenna Array: Architecture and Optimization", "abstract": "Movable antenna (MA) has been regarded as a promising technology to enhance\nwireless communication performance by enabling flexible antenna movement.\nHowever, the hardware cost of conventional MA systems scales with the number of\nmovable elements due to the need for independently controllable driving\ncomponents. To reduce hardware cost, we propose in this paper a novel\narchitecture named cross-linked MA (CL-MA) array, which enables the collective\nmovement of multiple antennas in both horizontal and vertical directions. To\nevaluate the performance benefits of the CL-MA array, we consider an uplink\nmultiuser communication scenario. Specifically, we aim to minimize the total\ntransmit power while satisfying a given minimum rate requirement for each user\nby jointly optimizing the horizontal and vertical antenna position vectors\n(APVs), the receive combining at the base station (BS), and the transmit power\nof users. A globally lower bound on the total transmit power is derived, with\nclosed-form solutions for the APVs obtained under the condition of a single\nchannel path for each user. For the more general case of multiple channel\npaths, we develop a low-complexity algorithm based on discrete antenna position\noptimization. Additionally, to further reduce antenna movement overhead, a\nstatistical channel-based antenna position optimization approach is proposed,\nallowing for unchanged APVs over a long time period. Simulation results\ndemonstrate that the proposed CL-MA schemes significantly outperform\nconventional fixed-position antenna (FPA) systems and closely approach the\ntheoretical lower bound on the total transmit power. Compared to the\ninstantaneous channel-based CL-MA optimization, the statistical channel-based\napproach incurs a slight performance loss but achieves significantly lower\nmovement overhead, making it an appealing solution for practical wireless\nsystems.", "published": "2025-05-06 04:39:05", "link": "http://arxiv.org/abs/2505.03175v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Edge Large AI Models: Collaborative Deployment and IoT Applications", "abstract": "Large artificial intelligence models (LAMs) emulate human-like\nproblem-solving capabilities across diverse domains, modalities, and tasks. By\nleveraging the communication and computation resources of geographically\ndistributed edge devices, edge LAMs enable real-time intelligent services at\nthe network edge. Unlike conventional edge AI, which relies on small or\nmoderate-sized models for direct feature-to-prediction mappings, edge LAMs\nleverage the intricate coordination of modular components to enable\ncontext-aware generative tasks and multi-modal inference. We shall propose a\ncollaborative deployment framework for edge LAM by characterizing the LAM\nintelligent capabilities and limited edge network resources. Specifically, we\npropose a collaborative training framework over heterogeneous edge networks\nthat adaptively decomposes LAMs according to computation resources, data\nmodalities, and training objectives, reducing communication and computation\noverheads during the fine-tuning process. Furthermore, we introduce a\nmicroservice-based inference framework that virtualizes the functional modules\nof edge LAMs according to their architectural characteristics, thereby\nimproving resource utilization and reducing inference latency. The developed\nedge LAM will provide actionable solutions to enable diversified\nInternet-of-Things (IoT) applications, facilitated by constructing mappings\nfrom diverse sensor data to token representations and fine-tuning based on\ndomain knowledge.", "published": "2025-05-06 03:27:54", "link": "http://arxiv.org/abs/2505.03139v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Integrated Sensing, Computing, Communication, and Control for Time-Sequence-Based Semantic Communications", "abstract": "In the upcoming industrial internet of things (IIoT) era, a surge of\ntask-oriented applications will rely on real-time wireless control systems\n(WCSs). For these systems, ultra-reliable and low-latency wireless\ncommunication will be crucial to ensure the timely transmission of control\ninformation. To achieve this purpose, we propose a novel time-sequence-based\nsemantic communication paradigm, where an integrated sensing, computing,\ncommunication, and control (ISC3) architecture is developed to make sensible\nsemantic inference (SI) for the control information over time sequences,\nenabling adaptive control of the robot. However, due to the causal correlations\nin the time sequence, the control information does not present the Markov\nproperty. To address this challenge, we compute the mutual information of the\ncontrol information sensed at the transmitter (Tx) over different time and\nidentify their temporal semantic correlation via a semantic feature extractor\n(SFE) module. By this means, highly correlated information transmission can be\navoided, thus greatly reducing the communication overhead. Meanwhile, a\nsemantic feature reconstructor (SFR) module is employed at the receiver (Rx) to\nreconstruct the control information based on the previously received one if the\ninformation transmission is not activated at the Tx. Furthermore, a control\ngain policy is also employed at the Rx to adaptively adjust the control gain\nfor the controlled target based on several practical aspects such as the\nquality of the information transmission from the Tx to the Rx. We design the\nneural network structures of the above modules/policies and train their\nparameters by a novel hybrid reward multi-agent deep reinforcement learning\nframework. On-site experiments are conducted to evaluate the performance of our\nproposed method in practice, which shows significant gains over other baseline\nschemes.", "published": "2025-05-06 03:01:39", "link": "http://arxiv.org/abs/2505.03127v1", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT"], "primary_category": "eess.SY"}
{"title": "USF Spectral Estimation: Prevalence of Gaussian Cram\u00e9r-Rao Bounds Despite Modulo Folding", "abstract": "Spectral Estimation (SpecEst) is a core area of signal processing with a\nhistory spanning two centuries and applications across various fields. With the\nadvent of digital acquisition, SpecEst algorithms have been widely applied to\ntasks like frequency super-resolution. However, conventional digital\nacquisition imposes a trade-off: for a fixed bit budget, one can optimize\neither signal dynamic range or digital resolution (noise floor), but not both\nsimultaneously. The Unlimited Sensing Framework (USF) overcomes this limitation\nusing modulo non-linearity in analog hardware, enabling a novel approach to\nSpecEst (USF-SpecEst). However, USF-SpecEst requires new theoretical and\nalgorithmic developments to handle folded samples effectively. In this paper,\nwe derive the Cram\\'er-Rao Bounds (CRBs) for SpecEst with noisy modulo-folded\nsamples and reveal a surprising result: the CRBs for USF-SpecEst are scaled\nversions of the Gaussian CRBs for conventional samples. Numerical experiments\nvalidate these bounds, providing a benchmark for USF-SpecEst and facilitating\nits practical deployment.", "published": "2025-05-06 01:19:51", "link": "http://arxiv.org/abs/2505.03098v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Sustainable Smart Farm Networks: Enhancing Resilience and Efficiency with Decision Theory-Guided Deep Reinforcement Learning", "abstract": "Solar sensor-based monitoring systems have become a crucial agricultural\ninnovation, advancing farm management and animal welfare through integrating\nsensor technology, Internet-of-Things, and edge and cloud computing. However,\nthe resilience of these systems to cyber-attacks and their adaptability to\ndynamic and constrained energy supplies remain largely unexplored. To address\nthese challenges, we propose a sustainable smart farm network designed to\nmaintain high-quality animal monitoring under various cyber and adversarial\nthreats, as well as fluctuating energy conditions. Our approach utilizes deep\nreinforcement learning (DRL) to devise optimal policies that maximize both\nmonitoring effectiveness and energy efficiency. To overcome DRL's inherent\nchallenge of slow convergence, we integrate transfer learning (TL) and decision\ntheory (DT) to accelerate the learning process. By incorporating DT-guided\nstrategies, we optimize monitoring quality and energy sustainability,\nsignificantly reducing training time while achieving comparable performance\nrewards. Our experimental results prove that DT-guided DRL outperforms\nTL-enhanced DRL models, improving system performance and reducing training\nruntime by 47.5%.", "published": "2025-05-06 17:49:06", "link": "http://arxiv.org/abs/2505.03721v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Nonnegative Low-rank Matrix Recovery Can Have Spurious Local Minima", "abstract": "The classical low-rank matrix recovery problem is well-known to exhibit\n\\emph{benign nonconvexity} under the restricted isometry property (RIP): local\noptimization is guaranteed to converge to the global optimum, where the ground\ntruth is recovered. We investigate whether benign nonconvexity continues to\nhold when the factor matrices are constrained to be elementwise nonnegative --\na common practical requirement. In the simple setting of a rank-1 nonnegative\nground truth, we confirm that benign nonconvexity holds in the fully-observed\ncase with RIP constant $\\delta=0$. Surprisingly, however, this property fails\nto extend to the partially-observed case with any arbitrarily small RIP\nconstant $\\delta\\to0^{+}$, irrespective of rank overparameterization. This\nfinding exposes a critical theoretical gap: the continuity argument widely used\nto explain the empirical robustness of low-rank matrix recovery fundamentally\nbreaks down once nonnegative constraints are imposed.", "published": "2025-05-06 17:43:35", "link": "http://arxiv.org/abs/2505.03717v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "Learning Survival Distributions with the Asymmetric Laplace Distribution", "abstract": "Probabilistic survival analysis models seek to estimate the distribution of\nthe future occurrence (time) of an event given a set of covariates. In recent\nyears, these models have preferred nonparametric specifications that avoid\ndirectly estimating survival distributions via discretization. Specifically,\nthey estimate the probability of an individual event at fixed times or the time\nof an event at fixed probabilities (quantiles), using supervised learning.\nBorrowing ideas from the quantile regression literature, we propose a\nparametric survival analysis method based on the Asymmetric Laplace\nDistribution (ALD). This distribution allows for closed-form calculation of\npopular event summaries such as mean, median, mode, variation, and quantiles.\nThe model is optimized by maximum likelihood to learn, at the individual level,\nthe parameters (location, scale, and asymmetry) of the ALD distribution.\nExtensive results on synthetic and real-world data demonstrate that the\nproposed method outperforms parametric and nonparametric approaches in terms of\naccuracy, discrimination and calibration.", "published": "2025-05-06 17:34:41", "link": "http://arxiv.org/abs/2505.03712v1", "categories": ["cs.LG", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Multi-modal cascade feature transfer for polymer property prediction", "abstract": "In this paper, we propose a novel transfer learning approach called\nmulti-modal cascade model with feature transfer for polymer property\nprediction.Polymers are characterized by a composite of data in several\ndifferent formats, including molecular descriptors and additive information as\nwell as chemical structures. However, in conventional approaches, prediction\nmodels were often constructed using each type of data separately. Our model\nenables more accurate prediction of physical properties for polymers by\ncombining features extracted from the chemical structure by graph convolutional\nneural networks (GCN) with features such as molecular descriptors and additive\ninformation. The predictive performance of the proposed method is empirically\nevaluated using several polymer datasets. We report that the proposed method\nshows high predictive performance compared to the baseline conventional\napproach using a single feature.", "published": "2025-05-06 17:24:43", "link": "http://arxiv.org/abs/2505.03704v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Neural Integral Operators for Inverse problems in Spectroscopy", "abstract": "Deep learning has shown high performance on spectroscopic inverse problems\nwhen sufficient data is available. However, it is often the case that data in\nspectroscopy is scarce, and this usually causes severe overfitting problems\nwith deep learning methods. Traditional machine learning methods are viable\nwhen datasets are smaller, but the accuracy and applicability of these methods\nis generally more limited.\n  We introduce a deep learning method for classification of molecular spectra\nbased on learning integral operators via integral equations of the first kind,\nwhich results in an algorithm that is less affected by overfitting issues on\nsmall datasets, compared to other deep learning models.\n  The problem formulation of the deep learning approach is based on inverse\nproblems, which have traditionally found important applications in\nspectroscopy. We perform experiments on real world data to showcase our\nalgorithm. It is seen that the model outperforms traditional machine learning\napproaches such as decision tree and support vector machine, and for small\ndatasets it outperforms other deep learning models. Therefore, our methodology\nleverages the power of deep learning, still maintaining the performance when\nthe available data is very limited, which is one of the main issues that deep\nlearning faces in spectroscopy, where datasets are often times of small size.", "published": "2025-05-06 16:22:46", "link": "http://arxiv.org/abs/2505.03677v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Vector valued optimal transport: from dynamic to static formulations", "abstract": "Motivated by applications in classification of vector valued measures and\nmultispecies PDE, we develop a theory that unifies existing notions of vector\nvalued optimal transport, from dynamic formulations (\\`a la Benamou-Brenier) to\nstatic formulations (\\`a la Kantorovich). In our framework, vector valued\nmeasures are modeled as probability measures on a product space $\\mathbb{R}^d\n\\times G$, where $G$ is a weighted graph over a finite set of nodes and the\ngraph geometry strongly influences the associated dynamic and static distances.\nWe obtain sharp inequalities relating four notions of vector valued optimal\ntransport and prove that the distances are mutually bi-H\\\"older equivalent. We\ndiscuss the theoretical and practical advantages of each metric and indicate\npotential applications in multispecies PDE and data analysis. In particular,\none of the static formulations discussed in the paper is amenable to\nlinearization, a technique that has been explored in recent years to accelerate\nthe computation of pairwise optimal transport distances.", "published": "2025-05-06 16:10:03", "link": "http://arxiv.org/abs/2505.03670v1", "categories": ["math.AP", "cs.LG", "math.MG"], "primary_category": "math.AP"}
{"title": "Mitigating mode collapse in normalizing flows by annealing with an adaptive schedule: Application to parameter estimation", "abstract": "Normalizing flows (NFs) provide uncorrelated samples from complex\ndistributions, making them an appealing tool for parameter estimation. However,\nthe practical utility of NFs remains limited by their tendency to collapse to a\nsingle mode of a multimodal distribution. In this study, we show that annealing\nwith an adaptive schedule based on the effective sample size (ESS) can mitigate\nmode collapse. We demonstrate that our approach can converge the marginal\nlikelihood for a biochemical oscillator model fit to time-series data in\nten-fold less computation time than a widely used ensemble Markov chain Monte\nCarlo (MCMC) method. We show that the ESS can also be used to reduce variance\nby pruning the samples. We expect these developments to be of general use for\nsampling with NFs and discuss potential opportunities for further improvements.", "published": "2025-05-06 15:58:48", "link": "http://arxiv.org/abs/2505.03652v1", "categories": ["cs.LG", "physics.comp-ph", "physics.data-an", "q-bio.QM", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Weighted Random Dot Product Graphs", "abstract": "Modeling of intricate relational patterns % through the analysis structures\nof network data has become a cornerstone of contemporary statistical research\nand related data science fields. Networks, represented as graphs, offer a\nnatural framework for this analysis. This paper extends the Random Dot Product\nGraph (RDPG) model to accommodate weighted graphs, markedly broadening the\nmodel's scope to scenarios where edges exhibit heterogeneous weight\ndistributions. We propose a nonparametric weighted (W)RDPG model that assigns a\nsequence of latent positions to each node. Inner products of these nodal\nvectors specify the moments of their incident edge weights' distribution via\nmoment-generating functions. In this way, and unlike prior art, the WRDPG can\ndiscriminate between weight distributions that share the same mean but differ\nin other higher-order moments. We derive statistical guarantees for an\nestimator of the nodal's latent positions adapted from the workhorse adjacency\nspectral embedding, establishing its consistency and asymptotic normality. We\nalso contribute a generative framework that enables sampling of graphs that\nadhere to a (prescribed or data-fitted) WRDPG, facilitating, e.g., the analysis\nand testing of observed graph metrics using judicious reference distributions.\nThe paper is organized to formalize the model's definition, the estimation (or\nnodal embedding) process and its guarantees, as well as the methodologies for\ngenerating weighted graphs, all complemented by illustrative and reproducible\nexamples showcasing the WRDPG's effectiveness in various network analytic\napplications.", "published": "2025-05-06 15:57:00", "link": "http://arxiv.org/abs/2505.03649v1", "categories": ["stat.ML", "cs.LG", "math.CO", "math.PR"], "primary_category": "stat.ML"}
{"title": "Understand the Effect of Importance Weighting in Deep Learning on Dataset Shift", "abstract": "We evaluate the effectiveness of importance weighting in deep neural networks\nunder label shift and covariate shift. On synthetic 2D data (linearly separable\nand moon-shaped) using logistic regression and MLPs, we observe that weighting\nstrongly affects decision boundaries early in training but fades with prolonged\noptimization. On CIFAR-10 with various class imbalances, only L2 regularization\n(not dropout) helps preserve weighting effects. In a covariate-shift\nexperiment, importance weighting yields no significant performance gain,\nhighlighting challenges on complex data. Our results call into question the\npractical utility of importance weighting for real-world distribution shifts.", "published": "2025-05-06 15:16:38", "link": "http://arxiv.org/abs/2505.03617v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Anant-Net: Breaking the Curse of Dimensionality with Scalable and Interpretable Neural Surrogate for High-Dimensional PDEs", "abstract": "High-dimensional partial differential equations (PDEs) arise in diverse\nscientific and engineering applications but remain computationally intractable\ndue to the curse of dimensionality. Traditional numerical methods struggle with\nthe exponential growth in computational complexity, particularly on hypercubic\ndomains, where the number of required collocation points increases rapidly with\ndimensionality. Here, we introduce Anant-Net, an efficient neural surrogate\nthat overcomes this challenge, enabling the solution of PDEs in high\ndimensions. Unlike hyperspheres, where the internal volume diminishes as\ndimensionality increases, hypercubes retain or expand their volume (for unit or\nlarger length), making high-dimensional computations significantly more\ndemanding. Anant-Net efficiently incorporates high-dimensional boundary\nconditions and minimizes the PDE residual at high-dimensional collocation\npoints. To enhance interpretability, we integrate Kolmogorov-Arnold networks\ninto the Anant-Net architecture. We benchmark Anant-Net's performance on\nseveral linear and nonlinear high-dimensional equations, including the Poisson,\nSine-Gordon, and Allen-Cahn equations, demonstrating high accuracy and\nrobustness across randomly sampled test points from high-dimensional space.\nImportantly, Anant-Net achieves these results with remarkable efficiency,\nsolving 300-dimensional problems on a single GPU within a few hours. We also\ncompare Anant-Net's results for accuracy and runtime with other\nstate-of-the-art methods. Our findings establish Anant-Net as an accurate,\ninterpretable, and scalable framework for efficiently solving high-dimensional\nPDEs.", "published": "2025-05-06 14:56:43", "link": "http://arxiv.org/abs/2505.03595v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Physics-Informed Sylvester Normalizing Flows for Bayesian Inference in Magnetic Resonance Spectroscopy", "abstract": "Magnetic resonance spectroscopy (MRS) is a non-invasive technique to measure\nthe metabolic composition of tissues, offering valuable insights into\nneurological disorders, tumor detection, and other metabolic dysfunctions.\nHowever, accurate metabolite quantification is hindered by challenges such as\nspectral overlap, low signal-to-noise ratio, and various artifacts. Traditional\nmethods like linear-combination modeling are susceptible to ambiguities and\ncommonly only provide a theoretical lower bound on estimation accuracy in the\nform of the Cram\\'er-Rao bound. This work introduces a Bayesian inference\nframework using Sylvester normalizing flows (SNFs) to approximate posterior\ndistributions over metabolite concentrations, enhancing quantification\nreliability. A physics-based decoder incorporates prior knowledge of MRS signal\nformation, ensuring realistic distribution representations. We validate the\nmethod on simulated 7T proton MRS data, demonstrating accurate metabolite\nquantification, well-calibrated uncertainties, and insights into parameter\ncorrelations and multi-modal distributions.", "published": "2025-05-06 14:50:14", "link": "http://arxiv.org/abs/2505.03590v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Decision Making under Model Misspecification: DRO with Robust Bayesian Ambiguity Sets", "abstract": "Distributionally Robust Optimisation (DRO) protects risk-averse\ndecision-makers by considering the worst-case risk within an ambiguity set of\ndistributions based on the empirical distribution or a model. To further guard\nagainst finite, noisy data, model-based approaches admit Bayesian formulations\nthat propagate uncertainty from the posterior to the decision-making problem.\nHowever, when the model is misspecified, the decision maker must stretch the\nambiguity set to contain the data-generating process (DGP), leading to overly\nconservative decisions. We address this challenge by introducing DRO with\nRobust, to model misspecification, Bayesian Ambiguity Sets (DRO-RoBAS). These\nare Maximum Mean Discrepancy ambiguity sets centred at a robust posterior\npredictive distribution that incorporates beliefs about the DGP. We show that\nthe resulting optimisation problem obtains a dual formulation in the\nReproducing Kernel Hilbert Space and we give probabilistic guarantees on the\ntolerance level of the ambiguity set. Our method outperforms other Bayesian and\nempirical DRO approaches in out-of-sample performance on the Newsvendor and\nPortfolio problems with various cases of model misspecification.", "published": "2025-05-06 14:46:16", "link": "http://arxiv.org/abs/2505.03585v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Efficient Training of Physics-enhanced Neural ODEs via Direct Collocation and Nonlinear Programming", "abstract": "We propose a novel approach for training Physics-enhanced Neural ODEs\n(PeNODEs) by expressing the training process as a dynamic optimization problem.\nThe full model, including neural components, is discretized using a high-order\nimplicit Runge-Kutta method with flipped Legendre-Gauss-Radau points, resulting\nin a large-scale nonlinear program (NLP) efficiently solved by state-of-the-art\nNLP solvers such as Ipopt. This formulation enables simultaneous optimization\nof network parameters and state trajectories, addressing key limitations of ODE\nsolver-based training in terms of stability, runtime, and accuracy. Extending\non a recent direct collocation-based method for Neural ODEs, we generalize to\nPeNODEs, incorporate physical constraints, and present a custom, parallelized,\nopen-source implementation. Benchmarks on a Quarter Vehicle Model and a\nVan-der-Pol oscillator demonstrate superior accuracy, speed, and generalization\nwith smaller networks compared to other training techniques. We also outline a\nplanned integration into OpenModelica to enable accessible training of Neural\nDAEs.", "published": "2025-05-06 14:04:46", "link": "http://arxiv.org/abs/2505.03552v1", "categories": ["cs.LG", "math.DS", "math.OC", "90C30, 68T05", "G.1.6; I.2.6"], "primary_category": "cs.LG"}
{"title": "Small-Scale-Fading-Aware Resource Allocation in Wireless Federated Learning", "abstract": "Judicious resource allocation can effectively enhance federated learning (FL)\ntraining performance in wireless networks by addressing both system and\nstatistical heterogeneity. However, existing strategies typically rely on block\nfading assumptions, which overlooks rapid channel fluctuations within each\nround of FL gradient uploading, leading to a degradation in FL training\nperformance. Therefore, this paper proposes a small-scale-fading-aware resource\nallocation strategy using a multi-agent reinforcement learning (MARL)\nframework. Specifically, we establish a one-step convergence bound of the FL\nalgorithm and formulate the resource allocation problem as a decentralized\npartially observable Markov decision process (Dec-POMDP), which is subsequently\nsolved using the QMIX algorithm. In our framework, each client serves as an\nagent that dynamically determines spectrum and power allocations within each\ncoherence time slot, based on local observations and a reward derived from the\nconvergence analysis. The MARL setting reduces the dimensionality of the action\nspace and facilitates decentralized decision-making, enhancing the scalability\nand practicality of the solution. Experimental results demonstrate that our\nQMIX-based resource allocation strategy significantly outperforms baseline\nmethods across various degrees of statistical heterogeneity. Additionally,\nablation studies validate the critical importance of incorporating small-scale\nfading dynamics, highlighting its role in optimizing FL performance.", "published": "2025-05-06 13:41:59", "link": "http://arxiv.org/abs/2505.03533v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Causal Intervention Framework for Variational Auto Encoder Mechanistic Interpretability", "abstract": "Mechanistic interpretability of deep learning models has emerged as a crucial\nresearch direction for understanding the functioning of neural networks. While\nsignificant progress has been made in interpreting discriminative models like\ntransformers, understanding generative models such as Variational Autoencoders\n(VAEs) remains challenging. This paper introduces a comprehensive causal\nintervention framework for mechanistic interpretability of VAEs. We develop\ntechniques to identify and analyze \"circuit motifs\" in VAEs, examining how\nsemantic factors are encoded, processed, and disentangled through the network\nlayers. Our approach uses targeted interventions at different levels: input\nmanipulations, latent space perturbations, activation patching, and causal\nmediation analysis. We apply our framework to both synthetic datasets with\nknown causal relationships and standard disentanglement benchmarks. Results\nshow that our interventions can successfully isolate functional circuits, map\ncomputational graphs to causal graphs of semantic factors, and distinguish\nbetween polysemantic and monosemantic units. Furthermore, we introduce metrics\nfor causal effect strength, intervention specificity, and circuit modularity\nthat quantify the interpretability of VAE components. Experimental results\ndemonstrate clear differences between VAE variants, with FactorVAE achieving\nhigher disentanglement scores (0.084) and effect strengths (mean 4.59) compared\nto standard VAE (0.064, 3.99) and Beta-VAE (0.051, 3.43). Our framework\nadvances the mechanistic understanding of generative models and provides tools\nfor more transparent and controllable VAE architectures.", "published": "2025-05-06 13:40:59", "link": "http://arxiv.org/abs/2505.03530v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Uncovering the Limitations of Model Inversion Evaluation: Benchmarks and Connection to Type-I Adversarial Attacks", "abstract": "Model Inversion (MI) attacks aim to reconstruct information of private\ntraining data by exploiting access to machine learning models. The most common\nevaluation framework for MI attacks/defenses relies on an evaluation model that\nhas been utilized to assess progress across almost all MI attacks and defenses\nproposed in recent years. In this paper, for the first time, we present an\nin-depth study of MI evaluation. Firstly, we construct the first comprehensive\nhuman-annotated dataset of MI attack samples, based on 28 setups of different\nMI attacks, defenses, private and public datasets. Secondly, using our dataset,\nwe examine the accuracy of the MI evaluation framework and reveal that it\nsuffers from a significant number of false positives. These findings raise\nquestions about the previously reported success rates of SOTA MI attacks.\nThirdly, we analyze the causes of these false positives, design controlled\nexperiments, and discover the surprising effect of Type I adversarial features\non MI evaluation, as well as adversarial transferability, highlighting a\nrelationship between two previously distinct research areas. Our findings\nsuggest that the performance of SOTA MI attacks has been overestimated, with\nthe actual privacy leakage being significantly less than previously reported.\nIn conclusion, we highlight critical limitations in the widely used MI\nevaluation framework and present our methods to mitigate false positive rates.\nWe remark that prior research has shown that Type I adversarial attacks are\nvery challenging, with no existing solution. Therefore, we urge to consider\nhuman evaluation as a primary MI evaluation framework rather than merely a\nsupplement as in previous MI research. We also encourage further work on\ndeveloping more robust and reliable automatic evaluation frameworks.", "published": "2025-05-06 13:32:12", "link": "http://arxiv.org/abs/2505.03519v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "AnomalyMatch: Discovering Rare Objects of Interest with Semi-supervised and Active Learning", "abstract": "Anomaly detection in large datasets is essential in fields such as astronomy\nand computer vision; however, supervised methods typically require extensive\nanomaly labelling, which is often impractical. We present AnomalyMatch, an\nanomaly detection framework combining the semi-supervised FixMatch algorithm\nusing EfficientNet classifiers with active learning. By treating anomaly\ndetection as a semi-supervised binary classification problem, we efficiently\nutilise limited labelled and abundant unlabelled images. We allow iterative\nmodel refinement in a user interface for expert verification of high-confidence\nanomalies and correction of false positives. Built for astronomical data,\nAnomalyMatch generalises readily to other domains facing similar data\nchallenges. Evaluations on the GalaxyMNIST astronomical dataset and the\nminiImageNet natural-image benchmark under severe class imbalance (1% anomalies\nfor miniImageNet) display strong performance: starting from five to ten\nlabelled anomalies and after three active learning cycles, we achieve an\naverage AUROC of 0.95 (miniImageNet) and 0.86 (GalaxyMNIST), with respective\nAUPRC of 0.77 and 0.71. After active learning cycles, anomalies are ranked with\n71% (miniImageNet) to 93% precision in the 1% of the highest-ranked images.\nAnomalyMatch is tailored for large-scale applications, efficiently processing\npredictions for 100 million images within three days on a single GPU.\nIntegrated into ESAs Datalabs platform, AnomalyMatch facilitates targeted\ndiscovery of scientifically valuable anomalies in vast astronomical datasets.\nOur results underscore the exceptional utility and scalability of this approach\nfor anomaly discovery, highlighting the value of specialised approaches for\ndomains characterised by severe label scarcity.", "published": "2025-05-06 13:19:15", "link": "http://arxiv.org/abs/2505.03509v1", "categories": ["cs.LG", "astro-ph.IM"], "primary_category": "cs.LG"}
{"title": "Knowledge Distillation for Speech Denoising by Latent Representation Alignment with Cosine Distance", "abstract": "Speech denoising is a generally adopted and impactful task, appearing in many\ncommon and everyday-life use cases. Although there are very powerful methods\npublished, most of those are too complex for deployment in everyday and\nlow-resources computational environments, like hand-held devices, intelligent\nglasses, hearing aids, etc. Knowledge distillation (KD) is a prominent way for\nalleviating this complexity mismatch and is based on the\ntransferring/distilling of knowledge from a pre-trained complex model, the\nteacher, to another less complex one, the student. Existing KD methods for\nspeech denoising are based on processes that potentially hamper the KD by\nbounding the learning of the student to the distribution, information ordering,\nand feature dimensionality learned by the teacher. In this paper, we present\nand assess a method that tries to treat this issue, by exploiting the\nwell-known denoising-autoencoder framework, the linear inverted bottlenecks,\nand the properties of the cosine similarity. We use a public dataset and\nconduct repeated experiments with different mismatching scenarios between the\nteacher and the student, reporting the mean and standard deviation of the\nmetrics of our method and another, state-of-the-art method that is used as a\nbaseline. Our results show that with the proposed method, the student can\nperform better and can also retain greater mismatching conditions compared to\nthe teacher.", "published": "2025-05-06 11:28:28", "link": "http://arxiv.org/abs/2505.03442v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Wasserstein Convergence of Score-based Generative Models under Semiconvexity and Discontinuous Gradients", "abstract": "Score-based Generative Models (SGMs) approximate a data distribution by\nperturbing it with Gaussian noise and subsequently denoising it via a learned\nreverse diffusion process. These models excel at modeling complex data\ndistributions and generating diverse samples, achieving state-of-the-art\nperformance across domains such as computer vision, audio generation,\nreinforcement learning, and computational biology. Despite their empirical\nsuccess, existing Wasserstein-2 convergence analysis typically assume strong\nregularity conditions-such as smoothness or strict log-concavity of the data\ndistribution-that are rarely satisfied in practice. In this work, we establish\nthe first non-asymptotic Wasserstein-2 convergence guarantees for SGMs\ntargeting semiconvex distributions with potentially discontinuous gradients.\nOur upper bounds are explicit and sharp in key parameters, achieving optimal\ndependence of $O(\\sqrt{d})$ on the data dimension $d$ and convergence rate of\norder one. The framework accommodates a wide class of practically relevant\ndistributions, including symmetric modified half-normal distributions, Gaussian\nmixtures, double-well potentials, and elastic net potentials. By leveraging\nsemiconvexity without requiring smoothness assumptions on the potential such as\ndifferentiability, our results substantially broaden the theoretical\nfoundations of SGMs, bridging the gap between empirical success and rigorous\nguarantees in non-smooth, complex data regimes.", "published": "2025-05-06 11:17:15", "link": "http://arxiv.org/abs/2505.03432v1", "categories": ["cs.LG", "math.OC", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Knowledge Augmented Complex Problem Solving with Large Language Models: A Survey", "abstract": "Problem-solving has been a fundamental driver of human progress in numerous\ndomains. With advancements in artificial intelligence, Large Language Models\n(LLMs) have emerged as powerful tools capable of tackling complex problems\nacross diverse domains. Unlike traditional computational systems, LLMs combine\nraw computational power with an approximation of human reasoning, allowing them\nto generate solutions, make inferences, and even leverage external\ncomputational tools. However, applying LLMs to real-world problem-solving\npresents significant challenges, including multi-step reasoning, domain\nknowledge integration, and result verification. This survey explores the\ncapabilities and limitations of LLMs in complex problem-solving, examining\ntechniques including Chain-of-Thought (CoT) reasoning, knowledge augmentation,\nand various LLM-based and tool-based verification techniques. Additionally, we\nhighlight domain-specific challenges in various domains, such as software\nengineering, mathematical reasoning and proving, data analysis and modeling,\nand scientific research. The paper further discusses the fundamental\nlimitations of the current LLM solutions and the future directions of LLM-based\ncomplex problems solving from the perspective of multi-step reasoning, domain\nknowledge integration and result verification.", "published": "2025-05-06 10:53:58", "link": "http://arxiv.org/abs/2505.03418v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quantum Feature Space of a Qubit Coupled to an Arbitrary Bath", "abstract": "Qubit control protocols have traditionally leveraged a characterisation of\nthe qubit-bath coupling via its power spectral density. Previous work proposed\nthe inference of noise operators that characterise the influence of a classical\nbath using a grey-box approach that combines deep neural networks with\nphysics-encoded layers. This overall structure is complex and poses challenges\nin scaling and real-time operations. Here, we show that no expensive neural\nnetworks are needed and that this noise operator description admits an\nefficient parameterisation. We refer to the resulting parameter space as the\n\\textit{quantum feature space} of the qubit dynamics resulting from the coupled\nbath. We show that the Euclidean distance defined over the quantum feature\nspace provides an effective method for classifying noise processes in the\npresence of a given set of controls. Using the quantum feature space as the\ninput space for a simple machine learning algorithm (random forest, in this\ncase), we demonstrate that it can effectively classify the stationarity and the\nbroad class of noise processes perturbing a qubit. Finally, we explore how\ncontrol pulse parameters map to the quantum feature space.", "published": "2025-05-06 10:25:50", "link": "http://arxiv.org/abs/2505.03397v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Prediction Models That Learn to Avoid Missing Values", "abstract": "Handling missing values at test time is challenging for machine learning\nmodels, especially when aiming for both high accuracy and interpretability.\nEstablished approaches often add bias through imputation or excessive model\ncomplexity via missingness indicators. Moreover, either method can obscure\ninterpretability, making it harder to understand how the model utilizes the\nobserved variables in predictions. We propose missingness-avoiding (MA) machine\nlearning, a general framework for training models to rarely require the values\nof missing (or imputed) features at test time. We create tailored MA learning\nalgorithms for decision trees, tree ensembles, and sparse linear models by\nincorporating classifier-specific regularization terms in their learning\nobjectives. The tree-based models leverage contextual missingness by reducing\nreliance on missing values based on the observed context. Experiments on\nreal-world datasets demonstrate that MA-DT, MA-LASSO, MA-RF, and MA-GBT\neffectively reduce the reliance on features with missing values while\nmaintaining predictive performance competitive with their unregularized\ncounterparts. This shows that our framework gives practitioners a powerful tool\nto maintain interpretability in predictions with test-time missing values.", "published": "2025-05-06 10:16:35", "link": "http://arxiv.org/abs/2505.03393v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Concept Factorization via Self-Representation and Adaptive Graph Structure Learning", "abstract": "Concept Factorization (CF) models have attracted widespread attention due to\ntheir excellent performance in data clustering. In recent years, many variant\nmodels based on CF have achieved great success in clustering by taking into\naccount the internal geometric manifold structure of the dataset and using\ngraph regularization techniques. However, their clustering performance depends\ngreatly on the construction of the initial graph structure. In order to enable\nadaptive learning of the graph structure of the data, we propose a Concept\nFactorization Based on Self-Representation and Adaptive Graph Structure\nLearning (CFSRAG) Model. CFSRAG learns the affinity relationship between data\nthrough a self-representation method, and uses the learned affinity matrix to\nimplement dynamic graph regularization constraints, thereby ensuring dynamic\nlearning of the internal geometric structure of the data. Finally, we give the\nCFSRAG update rule and convergence analysis, and conduct comparative\nexperiments on four real datasets. The results show that our model outperforms\nother state-of-the-art models.", "published": "2025-05-06 10:12:59", "link": "http://arxiv.org/abs/2505.03390v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improving Omics-Based Classification: The Role of Feature Selection and Synthetic Data Generation", "abstract": "Given the increasing complexity of omics datasets, a key challenge is not\nonly improving classification performance but also enhancing the transparency\nand reliability of model decisions. Effective model performance and feature\nselection are fundamental for explainability and reliability. In many cases,\nhigh dimensional omics datasets suffer from limited number of samples due to\nclinical constraints, patient conditions, phenotypes rarity and others\nconditions. Current omics based classification models often suffer from narrow\ninterpretability, making it difficult to discern meaningful insights where\ntrust and reproducibility are critical. This study presents a machine learning\nbased classification framework that integrates feature selection with data\naugmentation techniques to achieve high standard classification accuracy while\nensuring better interpretability. Using the publicly available dataset (E MTAB\n8026), we explore a bootstrap analysis in six binary classification scenarios\nto evaluate the proposed model's behaviour. We show that the proposed pipeline\nyields cross validated perfomance on small dataset that is conserved when the\ntrained classifier is applied to a larger test set. Our findings emphasize the\nfundamental balance between accuracy and feature selection, highlighting the\npositive effect of introducing synthetic data for better generalization, even\nin scenarios with very limited samples availability.", "published": "2025-05-06 10:09:50", "link": "http://arxiv.org/abs/2505.03387v1", "categories": ["cs.LG", "I.2.1; I.5.2; I.5.4; I.2.8"], "primary_category": "cs.LG"}
{"title": "Solar Flare Forecast: A Comparative Analysis of Machine Learning Algorithms for Solar Flare Class Prediction", "abstract": "Solar flares are among the most powerful and dynamic events in the solar\nsystem, resulting from the sudden release of magnetic energy stored in the\nSun's atmosphere. These energetic bursts of electromagnetic radiation can\nrelease up to 10^32 erg of energy, impacting space weather and posing risks to\ntechnological infrastructure and therefore require accurate forecasting of\nsolar flare occurrences and intensities. This study evaluates the predictive\nperformance of three machine learning algorithms: Random Forest, k-Nearest\nNeighbors (KNN), and Extreme Gradient Boosting (XGBoost) for classifying solar\nflares into 4 categories (B, C, M, X). Using the dataset of 13 SHARP\nparameters, the effectiveness of the models was evaluated in binary and\nmulticlass classification tasks. The analysis utilized 8 principal components\n(PC), capturing 95% of data variance, and 100 PCs, capturing 97.5% of variance.\nOur approach uniquely combines binary and multiclass classification with\ndifferent levels of dimensionality reduction, an innovative methodology not\npreviously explored in the context of solar flare prediction. Employing a\n10-fold stratified cross-validation and grid search for hyperparameter tuning\nensured robust model evaluation. Our findings indicate that Random Forest and\nXGBoost consistently demonstrate strong performance across all metrics,\nbenefiting significantly from increased dimensionality. The insights of this\nstudy enhance future research by optimizing dimensionality reduction techniques\nand informing model selection for astrophysical tasks. By integrating this\nnewly acquired knowledge into future research, more accurate space weather\nforecasting systems can be developed, along with a deeper understanding of\nsolar physics.", "published": "2025-05-06 10:08:41", "link": "http://arxiv.org/abs/2505.03385v1", "categories": ["astro-ph.SR", "astro-ph.IM", "cs.LG", "I.5.0"], "primary_category": "astro-ph.SR"}
{"title": "Physics-informed neural network estimation of active material properties in time-dependent cardiac biomechanical models", "abstract": "Active stress models in cardiac biomechanics account for the mechanical\ndeformation caused by muscle activity, thus providing a link between the\nelectrophysiological and mechanical properties of the tissue. The accurate\nassessment of active stress parameters is fundamental for a precise\nunderstanding of myocardial function but remains difficult to achieve in a\nclinical setting, especially when only displacement and strain data from\nmedical imaging modalities are available. This work investigates, through an\nin-silico study, the application of physics-informed neural networks (PINNs)\nfor inferring active contractility parameters in time-dependent cardiac\nbiomechanical models from these types of imaging data. In particular, by\nparametrising the sought state and parameter field with two neural networks,\nrespectively, and formulating an energy minimisation problem to search for the\noptimal network parameters, we are able to reconstruct in various settings\nactive stress fields in the presence of noise and with a high spatial\nresolution. To this end, we also advance the vanilla PINN learning algorithm\nwith the use of adaptive weighting schemes, ad-hoc regularisation strategies,\nFourier features, and suitable network architectures. In addition, we\nthoroughly analyse the influence of the loss weights in the reconstruction of\nactive stress parameters. Finally, we apply the method to the characterisation\nof tissue inhomogeneities and detection of fibrotic scars in myocardial tissue.\nThis approach opens a new pathway to significantly improve the diagnosis,\ntreatment planning, and management of heart conditions associated with cardiac\nfibrosis.", "published": "2025-05-06 10:01:16", "link": "http://arxiv.org/abs/2505.03382v1", "categories": ["cs.LG", "cs.NA", "math.NA", "G.1.8; I.2.0; I.6.4; J.3"], "primary_category": "cs.LG"}
{"title": "Geospatial Mechanistic Interpretability of Large Language Models", "abstract": "Large Language Models (LLMs) have demonstrated unprecedented capabilities\nacross various natural language processing tasks. Their ability to process and\ngenerate viable text and code has made them ubiquitous in many fields, while\ntheir deployment as knowledge bases and \"reasoning\" tools remains an area of\nongoing research. In geography, a growing body of literature has been focusing\non evaluating LLMs' geographical knowledge and their ability to perform spatial\nreasoning. However, very little is still known about the internal functioning\nof these models, especially about how they process geographical information.\n  In this chapter, we establish a novel framework for the study of geospatial\nmechanistic interpretability - using spatial analysis to reverse engineer how\nLLMs handle geographical information. Our aim is to advance our understanding\nof the internal representations that these complex models generate while\nprocessing geographical information - what one might call \"how LLMs think about\ngeographic information\" if such phrasing was not an undue anthropomorphism.\n  We first outline the use of probing in revealing internal structures within\nLLMs. We then introduce the field of mechanistic interpretability, discussing\nthe superposition hypothesis and the role of sparse autoencoders in\ndisentangling polysemantic internal representations of LLMs into more\ninterpretable, monosemantic features. In our experiments, we use spatial\nautocorrelation to show how features obtained for placenames display spatial\npatterns related to their geographic location and can thus be interpreted\ngeospatially, providing insights into how these models process geographical\ninformation. We conclude by discussing how our framework can help shape the\nstudy and use of foundation models in geography.", "published": "2025-05-06 09:40:06", "link": "http://arxiv.org/abs/2505.03368v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RIFT: Closed-Loop RL Fine-Tuning for Realistic and Controllable Traffic Simulation", "abstract": "Achieving both realism and controllability in interactive closed-loop traffic\nsimulation remains a key challenge in autonomous driving. Data-driven\nsimulation methods reproduce realistic trajectories but suffer from covariate\nshift in closed-loop deployment, compounded by simplified dynamics models that\nfurther reduce reliability. Conversely, physics-based simulation methods\nenhance reliable and controllable closed-loop interactions but often lack\nexpert demonstrations, compromising realism. To address these challenges, we\nintroduce a dual-stage AV-centered simulation framework that conducts open-loop\nimitation learning pre-training in a data-driven simulator to capture\ntrajectory-level realism and multimodality, followed by closed-loop\nreinforcement learning fine-tuning in a physics-based simulator to enhance\ncontrollability and mitigate covariate shift. In the fine-tuning stage, we\npropose RIFT, a simple yet effective closed-loop RL fine-tuning strategy that\npreserves the trajectory-level multimodality through a GRPO-style\ngroup-relative advantage formulation, while enhancing controllability and\ntraining stability by replacing KL regularization with the dual-clip mechanism.\nExtensive experiments demonstrate that RIFT significantly improves the realism\nand controllability of generated traffic scenarios, providing a robust platform\nfor evaluating autonomous vehicle performance in diverse and interactive\nscenarios.", "published": "2025-05-06 09:12:37", "link": "http://arxiv.org/abs/2505.03344v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Unraveling the Rainbow: can value-based methods schedule?", "abstract": "Recently, deep reinforcement learning has emerged as a promising approach for\nsolving complex combinatorial optimization problems. Broadly, deep\nreinforcement learning methods fall into two categories: policy-based and\nvalue-based. While value-based approaches have achieved notable success in\ndomains such as the Arcade Learning Environment, the combinatorial optimization\ncommunity has predominantly favored policy-based methods, often overlooking the\npotential of value-based algorithms. In this work, we conduct a comprehensive\nempirical evaluation of value-based algorithms, including the deep q-network\nand several of its advanced extensions, within the context of two complex\ncombinatorial problems: the job-shop and the flexible job-shop scheduling\nproblems, two fundamental challenges with multiple industrial applications. Our\nresults challenge the assumption that policy-based methods are inherently\nsuperior for combinatorial optimization. We show that several value-based\napproaches can match or even outperform the widely adopted proximal policy\noptimization algorithm, suggesting that value-based strategies deserve greater\nattention from the combinatorial optimization community. Our code is openly\navailable at: https://github.com/AJ-Correa/Unraveling-the-Rainbow.", "published": "2025-05-06 08:51:17", "link": "http://arxiv.org/abs/2505.03323v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "An Active Inference perspective on Neurofeedback Training", "abstract": "Neurofeedback training (NFT) aims to teach self-regulation of brain activity\nthrough real-time feedback, but suffers from highly variable outcomes and\npoorly understood mechanisms, hampering its validation. To address these\nissues, we propose a formal computational model of the NFT closed loop. Using\nActive Inference, a Bayesian framework modelling perception, action, and\nlearning, we simulate agents interacting with an NFT environment. This enables\nus to test the impact of design choices (e.g., feedback quality, biomarker\nvalidity) and subject factors (e.g., prior beliefs) on training. Simulations\nshow that training effectiveness is sensitive to feedback noise or bias, and to\nprior beliefs (highlighting the importance of guiding instructions), but also\nreveal that perfect feedback is insufficient to guarantee high performance.\nThis approach provides a tool for assessing and predicting NFT variability,\ninterpret empirical data, and potentially develop personalized training\nprotocols.", "published": "2025-05-06 08:41:31", "link": "http://arxiv.org/abs/2505.03308v1", "categories": ["q-bio.NC", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "MDPs with a State Sensing Cost", "abstract": "In many practical sequential decision-making problems, tracking the state of\nthe environment incurs a sensing/communication/computation cost. In these\nsettings, the agent's interaction with its environment includes the additional\ncomponent of deciding $\\textit{when}$ to sense the state, in a manner that\nbalances the value associated with optimal (state-specific) actions and the\ncost of sensing. We formulate this as an expected discounted cost Markov\nDecision Process (MDP), wherein the agent incurs an additional cost for sensing\nits next state, but has the option to take actions while remaining 'blind' to\nthe system state.\n  We pose this problem as a classical discounted cost MDP with an expanded\n(countably infinite) state space. While computing the optimal policy for this\nMDP is intractable in general, we bound the sub-optimality gap associated with\noptimal policies in a restricted class, where the number of consecutive\nnon-sensing (a.k.a., blind) actions is capped. We also design a computationally\nefficient heuristic algorithm based on policy improvement, which in practice\nperforms close to the optimal policy. Finally, we benchmark against the state\nof the art via a numerical case study.", "published": "2025-05-06 08:06:45", "link": "http://arxiv.org/abs/2505.03280v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Joint Resource Management for Energy-efficient UAV-assisted SWIPT-MEC: A Deep Reinforcement Learning Approach", "abstract": "The integration of simultaneous wireless information and power transfer\n(SWIPT) technology in 6G Internet of Things (IoT) networks faces significant\nchallenges in remote areas and disaster scenarios where ground infrastructure\nis unavailable. This paper proposes a novel unmanned aerial vehicle\n(UAV)-assisted mobile edge computing (MEC) system enhanced by directional\nantennas to provide both computational resources and energy support for ground\nIoT terminals. However, such systems require multiple trade-off policies to\nbalance UAV energy consumption, terminal battery levels, and computational\nresource allocation under various constraints, including limited UAV battery\ncapacity, non-linear energy harvesting characteristics, and dynamic task\narrivals. To address these challenges comprehensively, we formulate a\nbi-objective optimization problem that simultaneously considers system energy\nefficiency and terminal battery sustainability. We then reformulate this\nnon-convex problem with a hybrid solution space as a Markov decision process\n(MDP) and propose an improved soft actor-critic (SAC) algorithm with an action\nsimplification mechanism to enhance its convergence and generalization\ncapabilities. Simulation results have demonstrated that our proposed approach\noutperforms various baselines in different scenarios, achieving efficient\nenergy management while maintaining high computational performance.\nFurthermore, our method shows strong generalization ability across different\nscenarios, particularly in complex environments, validating the effectiveness\nof our designed boundary penalty and charging reward mechanisms.", "published": "2025-05-06 06:46:19", "link": "http://arxiv.org/abs/2505.03230v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Lower Bounds for Greedy Teaching Set Constructions", "abstract": "A fundamental open problem in learning theory is to characterize the\nbest-case teaching dimension $\\operatorname{TS}_{\\min}$ of a concept class\n$\\mathcal{C}$ with finite VC dimension $d$. Resolving this problem will, in\nparticular, settle the conjectured upper bound on Recursive Teaching Dimension\nposed by [Simon and Zilles; COLT 2015]. Prior work used a natural greedy\nalgorithm to construct teaching sets recursively, thereby proving upper bounds\non $\\operatorname{TS}_{\\min}$, with the best known bound being $O(d^2)$ [Hu,\nWu, Li, and Wang; COLT 2017]. In each iteration, this greedy algorithm chooses\nto add to the teaching set the $k$ labeled points that restrict the concept\nclass the most. In this work, we prove lower bounds on the performance of this\ngreedy approach for small $k$. Specifically, we show that for $k = 1$, the\nalgorithm does not improve upon the halving-based bound of\n$O(\\log(|\\mathcal{C}|))$. Furthermore, for $k = 2$, we complement the upper\nbound of $O\\left(\\log(\\log(|\\mathcal{C}|))\\right)$ from [Moran, Shpilka,\nWigderson, and Yuhudayoff; FOCS 2015] with a matching lower bound. Most\nconsequentially, our lower bound extends up to $k \\le \\lceil c d \\rceil$ for\nsmall constant $c>0$: suggesting that studying higher-order interactions may be\nnecessary to resolve the conjecture that $\\operatorname{TS}_{\\min} = O(d)$.", "published": "2025-05-06 06:30:01", "link": "http://arxiv.org/abs/2505.03223v1", "categories": ["stat.ML", "cs.DS", "cs.LG", "math.CO"], "primary_category": "stat.ML"}
{"title": "DYSTIL: Dynamic Strategy Induction with Large Language Models for Reinforcement Learning", "abstract": "Reinforcement learning from expert demonstrations has long remained a\nchallenging research problem, and existing state-of-the-art methods using\nbehavioral cloning plus further RL training often suffer from poor\ngeneralization, low sample efficiency, and poor model interpretability.\nInspired by the strong reasoning abilities of large language models (LLMs), we\npropose a novel strategy-based reinforcement learning framework integrated with\nLLMs called DYnamic STrategy Induction with Llms for reinforcement learning\n(DYSTIL) to overcome these limitations. DYSTIL dynamically queries a\nstrategy-generating LLM to induce textual strategies based on advantage\nestimations and expert demonstrations, and gradually internalizes induced\nstrategies into the RL agent through policy optimization to improve its\nperformance through boosting policy generalization and enhancing sample\nefficiency. It also provides a direct textual channel to observe and interpret\nthe evolution of the policy's underlying strategies during training. We test\nDYSTIL over challenging RL environments from Minigrid and BabyAI, and\nempirically demonstrate that DYSTIL significantly outperforms state-of-the-art\nbaseline methods by 17.75% in average success rate while also enjoying higher\nsample efficiency during the learning process.", "published": "2025-05-06 05:53:09", "link": "http://arxiv.org/abs/2505.03209v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Partial Label Clustering", "abstract": "Partial label learning (PLL) is a significant weakly supervised learning\nframework, where each training example corresponds to a set of candidate labels\nand only one label is the ground-truth label. For the first time, this paper\ninvestigates the partial label clustering problem, which takes advantage of the\nlimited available partial labels to improve the clustering performance.\nSpecifically, we first construct a weight matrix of examples based on their\nrelationships in the feature space and disambiguate the candidate labels to\nestimate the ground-truth label based on the weight matrix. Then, we construct\na set of must-link and cannot-link constraints based on the disambiguation\nresults. Moreover, we propagate the initial must-link and cannot-link\nconstraints based on an adversarial prior promoted dual-graph learning\napproach. Finally, we integrate weight matrix construction, label\ndisambiguation, and pairwise constraints propagation into a joint model to\nachieve mutual enhancement. We also theoretically prove that a better\ndisambiguated label matrix can help improve clustering performance.\nComprehensive experiments demonstrate our method realizes superior performance\nwhen comparing with state-of-the-art constrained clustering methods, and\noutperforms PLL and semi-supervised PLL methods when only limited samples are\nannotated. The code is publicly available at https://github.com/xyt-ml/PLC.", "published": "2025-05-06 05:43:55", "link": "http://arxiv.org/abs/2505.03207v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Transformers for Learning on Noisy and Task-Level Manifolds: Approximation and Generalization Insights", "abstract": "Transformers serve as the foundational architecture for large language and\nvideo generation models, such as GPT, BERT, SORA and their successors.\nEmpirical studies have demonstrated that real-world data and learning tasks\nexhibit low-dimensional structures, along with some noise or measurement error.\nThe performance of transformers tends to depend on the intrinsic dimension of\nthe data/tasks, though theoretical understandings remain largely unexplored for\ntransformers. This work establishes a theoretical foundation by analyzing the\nperformance of transformers for regression tasks involving noisy input data on\na manifold. Specifically, the input data are in a tubular neighborhood of a\nmanifold, while the ground truth function depends on the projection of the\nnoisy data onto the manifold. We prove approximation and generalization errors\nwhich crucially depend on the intrinsic dimension of the manifold. Our results\ndemonstrate that transformers can leverage low-complexity structures in\nlearning task even when the input data are perturbed by high-dimensional noise.\nOur novel proof technique constructs representations of basic arithmetic\noperations by transformers, which may hold independent interest.", "published": "2025-05-06 05:41:46", "link": "http://arxiv.org/abs/2505.03205v1", "categories": ["cs.LG", "cs.NA", "math.NA", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Weighted Average Gradients for Feature Attribution", "abstract": "In explainable AI, Integrated Gradients (IG) is a widely adopted technique\nfor assessing the significance of feature attributes of the input on model\noutputs by evaluating contributions from a baseline input to the current input.\nThe choice of the baseline input significantly influences the resulting\nexplanation. While the traditional Expected Gradients (EG) method assumes\nbaselines can be uniformly sampled and averaged with equal weights, this study\nargues that baselines should not be treated equivalently. We introduce Weighted\nAverage Gradients (WG), a novel approach that unsupervisedly evaluates baseline\nsuitability and incorporates a strategy for selecting effective baselines.\nTheoretical analysis demonstrates that WG satisfies essential explanation\nmethod criteria and offers greater stability than prior approaches.\nExperimental results further confirm that WG outperforms EG across diverse\nscenarios, achieving an improvement of 10-35\\% on main metrics. Moreover, by\nevaluating baselines, our method can filter a subset of effective baselines for\neach input to calculate explanations, maintaining high accuracy while reducing\ncomputational cost. The code is available at:\nhttps://github.com/Tamnt240904/weighted_baseline.", "published": "2025-05-06 05:36:47", "link": "http://arxiv.org/abs/2505.03201v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Convergence Of Consistency Model With Multistep Sampling Under General Data Assumptions", "abstract": "Diffusion models accomplish remarkable success in data generation tasks\nacross various domains. However, the iterative sampling process is\ncomputationally expensive. Consistency models are proposed to learn consistency\nfunctions to map from noise to data directly, which allows one-step fast data\ngeneration and multistep sampling to improve sample quality. In this paper, we\nstudy the convergence of consistency models when the self-consistency property\nholds approximately under the training distribution. Our analysis requires only\nmild data assumption and applies to a family of forward processes. When the\ntarget data distribution has bounded support or has tails that decay\nsufficiently fast, we show that the samples generated by the consistency model\nare close to the target distribution in Wasserstein distance; when the target\ndistribution satisfies some smoothness assumption, we show that with an\nadditional perturbation step for smoothing, the generated samples are close to\nthe target distribution in total variation distance. We provide two case\nstudies with commonly chosen forward processes to demonstrate the benefit of\nmultistep sampling.", "published": "2025-05-06 05:31:10", "link": "http://arxiv.org/abs/2505.03194v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "VLM Q-Learning: Aligning Vision-Language Models for Interactive Decision-Making", "abstract": "Recent research looks to harness the general knowledge and reasoning of large\nlanguage models (LLMs) into agents that accomplish user-specified goals in\ninteractive environments. Vision-language models (VLMs) extend LLMs to\nmulti-modal data and provide agents with the visual reasoning necessary for new\napplications in areas such as computer automation. However, agent tasks\nemphasize skills where accessible open-weight VLMs lag behind their LLM\nequivalents. For example, VLMs are less capable of following an environment's\nstrict output syntax requirements and are more focused on open-ended question\nanswering. Overcoming these limitations requires supervised fine-tuning (SFT)\non task-specific expert demonstrations. Our work approaches these challenges\nfrom an offline-to-online reinforcement learning (RL) perspective. RL lets us\nfine-tune VLMs to agent tasks while learning from the unsuccessful decisions of\nour own model or more capable (larger) models. We explore an off-policy RL\nsolution that retains the stability and simplicity of the widely used SFT\nworkflow while allowing our agent to self-improve and learn from low-quality\ndatasets. We demonstrate this technique with two open-weight VLMs across three\nmulti-modal agent domains.", "published": "2025-05-06 04:51:57", "link": "http://arxiv.org/abs/2505.03181v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "RADE: Learning Risk-Adjustable Driving Environment via Multi-Agent Conditional Diffusion", "abstract": "Generating safety-critical scenarios in high-fidelity simulations offers a\npromising and cost-effective approach for efficient testing of autonomous\nvehicles. Existing methods typically rely on manipulating a single vehicle's\ntrajectory through sophisticated designed objectives to induce adversarial\ninteractions, often at the cost of realism and scalability. In this work, we\npropose the Risk-Adjustable Driving Environment (RADE), a simulation framework\nthat generates statistically realistic and risk-adjustable traffic scenes.\nBuilt upon a multi-agent diffusion architecture, RADE jointly models the\nbehavior of all agents in the environment and conditions their trajectories on\na surrogate risk measure. Unlike traditional adversarial methods, RADE learns\nrisk-conditioned behaviors directly from data, preserving naturalistic\nmulti-agent interactions with controllable risk levels. To ensure physical\nplausibility, we incorporate a tokenized dynamics check module that efficiently\nfilters generated trajectories using a motion vocabulary. We validate RADE on\nthe real-world rounD dataset, demonstrating that it preserves statistical\nrealism across varying risk levels and naturally increases the likelihood of\nsafety-critical events as the desired risk level grows up. Our results\nhighlight RADE's potential as a scalable and realistic tool for AV safety\nevaluation.", "published": "2025-05-06 04:41:20", "link": "http://arxiv.org/abs/2505.03178v1", "categories": ["cs.LG", "cs.RO"], "primary_category": "cs.LG"}
{"title": "A Symbolic and Statistical Learning Framework to Discover Bioprocessing Regulatory Mechanism: Cell Culture Example", "abstract": "Bioprocess mechanistic modeling is essential for advancing intelligent\ndigital twin representation of biomanufacturing, yet challenges persist due to\ncomplex intracellular regulation, stochastic system behavior, and limited\nexperimental data. This paper introduces a symbolic and statistical learning\nframework to identify key regulatory mechanisms and quantify model uncertainty.\nBioprocess dynamics is formulated with stochastic differential equations\ncharacterizing intrinsic process variability, with a predefined set of\ncandidate regulatory mechanisms constructed from biological knowledge. A\nBayesian learning approach is developed, which is based on a joint learning of\nkinetic parameters and regulatory structure through a formulation of the\nmixture model. To enhance computational efficiency, a Metropolis-adjusted\nLangevin algorithm with adjoint sensitivity analysis is developed for posterior\nexploration. Compared to state-of-the-art Bayesian inference approaches, the\nproposed framework achieves improved sample efficiency and robust model\nselection. An empirical study demonstrates its ability to recover missing\nregulatory mechanisms and improve model fidelity under data-limited conditions.", "published": "2025-05-06 04:39:34", "link": "http://arxiv.org/abs/2505.03177v1", "categories": ["stat.ML", "cs.LG", "q-bio.QM"], "primary_category": "stat.ML"}
{"title": "Improving the Reproducibility of Deep Learning Software: An Initial Investigation through a Case Study Analysis", "abstract": "The field of deep learning has witnessed significant breakthroughs, spanning\nvarious applications, and fundamentally transforming current software\ncapabilities. However, alongside these advancements, there have been increasing\nconcerns about reproducing the results of these deep learning methods. This is\nsignificant because reproducibility is the foundation of reliability and\nvalidity in software development, particularly in the rapidly evolving domain\nof deep learning. The difficulty of reproducibility may arise due to several\nreasons, including having differences from the original execution environment,\nincompatible software libraries, proprietary data and source code, lack of\ntransparency, and the stochastic nature in some software. A study conducted by\nthe Nature journal reveals that more than 70% of researchers failed to\nreproduce other researchers experiments and over 50% failed to reproduce their\nown experiments. Irreproducibility of deep learning poses significant\nchallenges for researchers and practitioners. To address these concerns, this\npaper presents a systematic approach at analyzing and improving the\nreproducibility of deep learning models by demonstrating these guidelines using\na case study. We illustrate the patterns and anti-patterns involved with these\nguidelines for improving the reproducibility of deep learning models. These\nguidelines encompass establishing a methodology to replicate the original\nsoftware environment, implementing end-to-end training and testing algorithms,\ndisclosing architectural designs, and enhancing transparency in data processing\nand training pipelines. We also conduct a sensitivity analysis to understand\nthe model performance across diverse conditions. By implementing these\nstrategies, we aim to bridge the gap between research and practice, so that\ninnovations in deep learning can be effectively reproduced and deployed within\nsoftware.", "published": "2025-05-06 04:20:15", "link": "http://arxiv.org/abs/2505.03165v1", "categories": ["cs.LG", "cs.SE"], "primary_category": "cs.LG"}
{"title": "Systematic Evaluation of Initial States and Exploration-Exploitation Strategies in PID Auto-Tuning: A Framework-Driven Approach Applied on Mobile Robots", "abstract": "PID controllers are widely used in control systems because of their\nsimplicity and effectiveness. Although advanced optimization techniques such as\nBayesian Optimization and Differential Evolution have been applied to address\nthe challenges of automatic tuning of PID controllers, the influence of initial\nsystem states on convergence and the balance between exploration and\nexploitation remains underexplored. Moreover, experimenting the influence\ndirectly on real cyber-physical systems such as mobile robots is crucial for\nderiving realistic insights. In the present paper, a novel framework is\nintroduced to evaluate the impact of systematically varying these factors on\nthe PID auto-tuning processes that utilize Bayesian Optimization and\nDifferential Evolution. Testing was conducted on two distinct PID-controlled\nrobotic platforms, an omnidirectional robot and a differential drive mobile\nrobot, to assess the effects on convergence rate, settling time, rise time, and\novershoot percentage. As a result, the experimental outcomes yield evidence on\nthe effects of the systematic variations, thereby providing an empirical basis\nfor future research studies in the field.", "published": "2025-05-06 04:12:09", "link": "http://arxiv.org/abs/2505.03159v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Rethinking the Global Convergence of Softmax Policy Gradient with Linear Function Approximation", "abstract": "Policy gradient (PG) methods have played an essential role in the empirical\nsuccesses of reinforcement learning. In order to handle large state-action\nspaces, PG methods are typically used with function approximation. In this\nsetting, the approximation error in modeling problem-dependent quantities is a\nkey notion for characterizing the global convergence of PG methods. We focus on\nSoftmax PG with linear function approximation (referred to as\n$\\texttt{Lin-SPG}$) and demonstrate that the approximation error is irrelevant\nto the algorithm's global convergence even for the stochastic bandit setting.\nConsequently, we first identify the necessary and sufficient conditions on the\nfeature representation that can guarantee the asymptotic global convergence of\n$\\texttt{Lin-SPG}$. Under these feature conditions, we prove that $T$\niterations of $\\texttt{Lin-SPG}$ with a problem-specific learning rate result\nin an $O(1/T)$ convergence to the optimal policy. Furthermore, we prove that\n$\\texttt{Lin-SPG}$ with any arbitrary constant learning rate can ensure\nasymptotic global convergence to the optimal policy.", "published": "2025-05-06 04:03:06", "link": "http://arxiv.org/abs/2505.03155v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learn to Swim: Data-Driven LSTM Hydrodynamic Model for Quadruped Robot Gait Optimization", "abstract": "This paper presents a Long Short-Term Memory network-based Fluid Experiment\nData-Driven model (FED-LSTM) for predicting unsteady, nonlinear hydrodynamic\nforces on the underwater quadruped robot we constructed. Trained on\nexperimental data from leg force and body drag tests conducted in both a\nrecirculating water tank and a towing tank, FED-LSTM outperforms traditional\nEmpirical Formulas (EF) commonly used for flow prediction over flat surfaces.\nThe model demonstrates superior accuracy and adaptability in capturing complex\nfluid dynamics, particularly in straight-line and turning-gait optimizations\nvia the NSGA-II algorithm. FED-LSTM reduces deflection errors during\nstraight-line swimming and improves turn times without increasing the turning\nradius. Hardware experiments further validate the model's precision and\nstability over EF. This approach provides a robust framework for enhancing the\nswimming performance of legged robots, laying the groundwork for future\nadvances in underwater robotic locomotion.", "published": "2025-05-06 03:42:16", "link": "http://arxiv.org/abs/2505.03146v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "HMAE: Self-Supervised Few-Shot Learning for Quantum Spin Systems", "abstract": "Quantum machine learning for spin and molecular systems faces critical\nchallenges of scarce labeled data and computationally expensive simulations. To\naddress these limitations, we introduce Hamiltonian-Masked Autoencoding (HMAE),\na novel self-supervised framework that pre-trains transformers on unlabeled\nquantum Hamiltonians, enabling efficient few-shot transfer learning. Unlike\nrandom masking approaches, HMAE employs a physics-informed strategy based on\nquantum information theory to selectively mask Hamiltonian terms based on their\nphysical significance. Experiments on 12,500 quantum Hamiltonians (60%\nreal-world, 40% synthetic) demonstrate that HMAE achieves 85.3% $\\pm$ 1.5%\naccuracy in phase classification and 0.15 $\\pm$ 0.02 eV MAE in ground state\nenergy prediction with merely 10 labeled examples - a statistically significant\nimprovement (p < 0.01) over classical graph neural networks (78.1% $\\pm$ 2.1%)\nand quantum neural networks (76.8% $\\pm$ 2.3%). Our method's primary advantage\nis exceptional sample efficiency - reducing required labeled examples by 3-5x\ncompared to baseline methods - though we emphasize that ground truth values for\nfine-tuning and evaluation still require exact diagonalization or tensor\nnetworks. We explicitly acknowledge that our current approach is limited to\nsmall quantum systems (specifically limited to 12 qubits during training, with\nlimited extension to 16-20 qubits in testing) and that, while promising within\nthis regime, this size restriction prevents immediate application to larger\nsystems of practical interest in materials science and quantum chemistry.", "published": "2025-05-06 03:32:16", "link": "http://arxiv.org/abs/2505.03140v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Adversarial Sample Generation for Anomaly Detection in Industrial Control Systems", "abstract": "Machine learning (ML)-based intrusion detection systems (IDS) are vulnerable\nto adversarial attacks. It is crucial for an IDS to learn to recognize\nadversarial examples before malicious entities exploit them. In this paper, we\ngenerated adversarial samples using the Jacobian Saliency Map Attack (JSMA). We\nvalidate the generalization and scalability of the adversarial samples to\ntackle a broad range of real attacks on Industrial Control Systems (ICS). We\nevaluated the impact by assessing multiple attacks generated using the proposed\nmethod. The model trained with adversarial samples detected attacks with 95%\naccuracy on real-world attack data not used during training. The study was\nconducted using an operational secure water treatment (SWaT) testbed.", "published": "2025-05-06 02:27:17", "link": "http://arxiv.org/abs/2505.03120v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Adaptive Thresholding for Multi-Label Classification via Global-Local Signal Fusion", "abstract": "Multi-label classification (MLC) requires predicting multiple labels per\nsample, often under heavy class imbalance and noisy conditions. Traditional\napproaches apply fixed thresholds or treat labels independently, overlooking\ncontext and global rarity. We introduce an adaptive thresholding mechanism that\nfuses global (IDF-based) and local (KNN-based) signals to produce per-label,\nper-instance thresholds. Instead of applying these as hard cutoffs, we treat\nthem as differentiable penalties in the loss, providing smooth supervision and\nbetter calibration. Our architecture is lightweight, interpretable, and highly\nmodular. On the AmazonCat-13K benchmark, it achieves a macro-F1 of 0.1712,\nsubstantially outperforming tree-based and pretrained transformer-based\nmethods. We release full code for reproducibility and future extensions.", "published": "2025-05-06 02:19:37", "link": "http://arxiv.org/abs/2505.03118v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Plug-and-Play AMC: Context Is King in Training-Free, Open-Set Modulation with LLMs", "abstract": "Automatic Modulation Classification (AMC) is critical for efficient spectrum\nmanagement and robust wireless communications. However, AMC remains challenging\ndue to the complex interplay of signal interference and noise. In this work, we\npropose an innovative framework that integrates traditional signal processing\ntechniques with Large-Language Models (LLMs) to address AMC. Our approach\nleverages higher-order statistics and cumulant estimation to convert\nquantitative signal features into structured natural language prompts. By\nincorporating exemplar contexts into these prompts, our method exploits the\nLLM's inherent familiarity with classical signal processing, enabling effective\none-shot classification without additional training or preprocessing (e.g.,\ndenoising). Experimental evaluations on synthetically generated datasets,\nspanning both noiseless and noisy conditions, demonstrate that our framework\nachieves competitive performance across diverse modulation schemes and\nSignal-to-Noise Ratios (SNRs). Moreover, our approach paves the way for robust\nfoundation models in wireless communications across varying channel conditions,\nsignificantly reducing the expense associated with developing channel-specific\nmodels. This work lays the foundation for scalable, interpretable, and\nversatile signal classification systems in next-generation wireless networks.\nThe source code is available at https://github.com/RU-SIT/context-is-king", "published": "2025-05-06 02:07:47", "link": "http://arxiv.org/abs/2505.03112v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Deep Learning in Renewable Energy Forecasting: A Cross-Dataset Evaluation of Temporal and Spatial Models", "abstract": "Unpredictability of renewable energy sources coupled with the complexity of\nthose methods used for various purposes in this area calls for the development\nof robust methods such as DL models within the renewable energy domain. Given\nthe nonlinear relationships among variables in renewable energy datasets, DL\nmodels are preferred over traditional machine learning (ML) models because they\ncan effectively capture and model complex interactions between variables. This\nresearch aims to identify the factors responsible for the accuracy of DL\ntechniques, such as sampling, stationarity, linearity, and hyperparameter\noptimization for different algorithms. The proposed DL framework compares\nvarious methods and alternative training/test ratios. Seven ML methods, such as\nLong-Short Term Memory (LSTM), Stacked LSTM, Convolutional Neural Network\n(CNN), CNN-LSTM, Deep Neural Network (DNN), Multilayer Perceptron (MLP), and\nEncoder-Decoder (ED), were evaluated on two different datasets. The first\ndataset contains the weather and power generation data. It encompasses two\ndistinct datasets, hourly energy demand data and hourly weather data in Spain,\nwhile the second dataset includes power output generated by the photovoltaic\npanels at 12 locations. This study deploys regularization approaches, including\nearly stopping, neuron dropping, and L2 regularization, to reduce the\noverfitting problem associated with DL models. The LSTM and MLP models show\nsuperior performance. Their validation data exhibit exceptionally low root mean\nsquare error values.", "published": "2025-05-06 02:05:19", "link": "http://arxiv.org/abs/2505.03109v1", "categories": ["cs.LG", "econ.GN", "q-fin.EC"], "primary_category": "cs.LG"}
{"title": "Adversarial Attacks in Multimodal Systems: A Practitioner's Survey", "abstract": "The introduction of multimodal models is a huge step forward in Artificial\nIntelligence. A single model is trained to understand multiple modalities:\ntext, image, video, and audio. Open-source multimodal models have made these\nbreakthroughs more accessible. However, considering the vast landscape of\nadversarial attacks across these modalities, these models also inherit\nvulnerabilities of all the modalities, and ultimately, the adversarial threat\namplifies. While broad research is available on possible attacks within or\nacross these modalities, a practitioner-focused view that outlines attack types\nremains absent in the multimodal world. As more Machine Learning Practitioners\nadopt, fine-tune, and deploy open-source models in real-world applications,\nit's crucial that they can view the threat landscape and take the preventive\nactions necessary. This paper addresses the gap by surveying adversarial\nattacks targeting all four modalities: text, image, video, and audio. This\nsurvey provides a view of the adversarial attack landscape and presents how\nmultimodal adversarial threats have evolved. To the best of our knowledge, this\nsurvey is the first comprehensive summarization of the threat landscape in the\nmultimodal world.", "published": "2025-05-06 00:41:16", "link": "http://arxiv.org/abs/2505.03084v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Communication-First Account of Explanation", "abstract": "This paper develops a formal account of causal explanation, grounded in a\ntheory of conversational pragmatics, and inspired by the interventionist idea\nthat explanation is about asking and answering\nwhat-if-things-had-been-different questions. We illustrate the fruitfulness of\nthe account, relative to previous accounts, by showing that widely recognised\nexplanatory virtues emerge naturally, as do subtle empirical patterns\nconcerning the impact of norms on causal judgments. This shows the value of a\ncommunication-first approach to explanation: getting clear on explanation's\ncommunicative dimension is an important prerequisite for philosophical work on\nexplanation. The result is a simple but powerful framework for incorporating\ninsights from the cognitive sciences into philosophical work on explanation,\nwhich will be useful for philosophers or cognitive scientists interested in\nexplanation.", "published": "2025-05-06 17:59:10", "link": "http://arxiv.org/abs/2505.03732v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Simulation to Reality: Testbeds and Architectures for Connected and Automated Vehicles", "abstract": "Ensuring the safe and efficient operation of CAVs relies heavily on the\nsoftware framework used. A software framework needs to ensure real-time\nproperties, reliable communication, and efficient resource utilization.\nFurthermore, a software framework needs to enable seamless transition between\ntesting stages, from simulation to small-scale to full-scale experiments. In\nthis paper, we survey prominent software frameworks used for in-vehicle and\ninter-vehicle communication in CAVs. We analyze these frameworks regarding\nopportunities and challenges, such as their real-time properties and\ntransitioning capabilities. Additionally, we delve into the tooling\nrequirements necessary for addressing the associated challenges. We illustrate\nthe practical implications of these challenges through case studies focusing on\ncritical areas such as perception, motion planning, and control. Furthermore,\nwe identify research gaps in the field, highlighting areas where further\ninvestigation is needed to advance the development and deployment of safe and\nefficient CAV systems.", "published": "2025-05-06 12:23:18", "link": "http://arxiv.org/abs/2505.03472v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Multi-Agent Deep Reinforcement Learning for Zonal Ancillary Market Coupling", "abstract": "We characterize zonal ancillary market coupling relying on noncooperative\ngame theory. To that purpose, we formulate the ancillary market as a\nmulti-leader single follower bilevel problem, that we subsequently cast as a\ngeneralized Nash game with side constraints and nonconvex feasibility sets. We\ndetermine conditions for equilibrium existence and show that the game has a\ngeneralized potential game structure. To compute market equilibrium, we rely on\ntwo exact approaches: an integrated optimization approach and Gauss-Seidel\nbest-response, that we compare against multi-agent deep reinforcement learning.\nOn real data from Germany and Austria, simulations indicate that multi-agent\ndeep reinforcement learning achieves the smallest convergence rate but requires\npretraining, while best-response is the slowest. On the economics side,\nmulti-agent deep reinforcement learning results in smaller market costs\ncompared to the exact methods, but at the cost of higher variability in the\nprofit allocation among stakeholders. Further, stronger coupling between zones\ntends to reduce costs for larger zones.", "published": "2025-05-06 08:15:39", "link": "http://arxiv.org/abs/2505.03288v1", "categories": ["cs.MA", "cs.GT", "econ.GN", "q-fin.EC"], "primary_category": "cs.MA"}
{"title": "Global Task-aware Fault Detection, Identification For On-Orbit Multi-Spacecraft Collaborative Inspection", "abstract": "In this paper, we present a global-to-local task-aware fault detection and\nidentification algorithm to detect failures in a multi-spacecraft system\nperforming a collaborative inspection (referred to as global) task. The\ninspection task is encoded as a cost functional $\\costH$ that informs global\n(task allocation and assignment) and local (agent-level) decision-making. The\nmetric $\\costH$ is a function of the inspection sensor model, and the agent\nfull-pose. We use the cost functional $\\costH$ to design a metric that compares\nthe expected and actual performance to detect the faulty agent using a\nthreshold. We use higher-order cost gradients $\\costH$ to derive a new metric\nto identify the type of fault, including task-specific sensor fault, an\nagent-level actuator, and sensor faults. Furthermore, we propose an approach to\ndesign adaptive thresholds for each fault mentioned above to incorporate the\ntime dependence of the inspection task. We demonstrate the efficacy of the\nproposed method empirically, by simulating and detecting faults (such as\ninspection sensor faults, actuators, and sensor faults) in a low-Earth orbit\ncollaborative spacecraft inspection task using the metrics and the threshold\ndesigned using the global task cost $\\costH$.", "published": "2025-05-06 00:51:13", "link": "http://arxiv.org/abs/2505.03088v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Numerical Reconstruction and Analysis of Backward Semilinear Subdiffusion Problems", "abstract": "This paper aims to develop and analyze a numerical scheme for solving the\nbackward problem of semilinear subdiffusion equations. We establish the\nexistence, uniqueness, and conditional stability of the solution to the inverse\nproblem by applying the smoothing and asymptotic properties of solution\noperators and constructing a fixed-point iteration. This derived conditional\nstability further inspires a numerical reconstruction scheme. To address the\nmildly ill-posed nature of the problem, we employ the quasi-boundary value\nmethod for regularization. A fully discrete scheme is proposed, utilizing the\nfinite element method for spatial discretization and convolution quadrature for\ntemporal discretization. A thorough error analysis of the resulting discrete\nsystem is provided for both smooth and nonsmooth data. This analysis relies on\nthe smoothing properties of discrete solution operators, some nonstandard error\nestimates optimal with respect to data regularity in the direct problem, and\nthe arguments used in stability analysis. The derived a priori error estimate\noffers guidance for selecting the regularization parameter and discretization\nparameters based on the noise level. Moreover, we propose an easy-to-implement\niterative algorithm for solving the fully discrete scheme and prove its linear\nconvergence. Numerical examples are provided to illustrate the theoretical\nestimates and demonstrate the necessity of the assumption required in the\nanalysis.", "published": "2025-05-06 15:22:31", "link": "http://arxiv.org/abs/2505.03625v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An Enriched Immersed Finite Element Method for 3D Interface Problems", "abstract": "We introduce an enriched immersed finite element method for addressing\ninterface problems characterized by general non-homogeneous jump conditions.\nUnlike many existing unfitted mesh methods, our approach incorporates a\nhomogenization concept. The IFE trial function set is composed of two\ncomponents: the standard homogeneous IFE space and additional enrichment IFE\nfunctions. These enrichment functions are directly determined by the jump data,\nwithout adding extra degrees of freedom to the system. Meanwhile, the\nhomogeneous IFE space is isomorphic to the standard finite element space on the\nsame mesh. This isomorphism remains stable regardless of interface location\nrelative to the mesh, ensuring optimal $\\mathcal{O}(h^2)$ conditioning that is\nindependent of the interface location and facilitates an immediate development\nof a multigrid fast solver; namely the iteration numbers are independent of not\nonly the mesh size but also the relative interface location. Theoretical\nanalysis and extensive numerical experiments are carried out in the efforts to\ndemonstrate these features.", "published": "2025-05-06 14:59:56", "link": "http://arxiv.org/abs/2505.03598v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Hierarchical dynamic domain decomposition for the multiscale Boltzmann equation", "abstract": "In this work, we present a hierarchical domain decomposition method for the\nmulti-scale Boltzmann equation based on moment realizability matrices, a\nconcept introduced by Levermore, Morokoff, and Nadiga in\n\\cite{lev-mor-nad-1998}. This criterion is used to dynamically partition the\ntwo-dimensional spatial domain into three regimes: the Euler regime, an\nintermediate kinetic regime governed by the ES-BGK model, and the full\nBoltzmann regime. The key advantage of this approach lies in the use of Euler\nequations in regions where the flow is near hydrodynamic equilibrium, the\nES-BGK model in moderately non-equilibrium regions where a fluid description is\ninsufficient but full kinetic resolution is not yet necessary, and the full\nBoltzmann solver where strong non-equilibrium effects dominate, such as near\nshocks and boundary layers. This allows for both high accuracy and significant\ncomputational savings, as the Euler solver and the ES-BGK models are\nconsiderably cheaper than the full kinetic Boltzmann model.\n  To ensure accurate and efficient coupling between regimes, we employ\nasymptotic-preserving (AP) numerical schemes and fast spectral solvers for\nevaluating the Boltzmann collision operator. Among the main novelties of this\nwork are the use of a full 2D spatial and 3D velocity decomposition, the\nintegration of three distinct physical regimes within a unified solver\nframework, and a parallelized implementation exploiting CPU multithreading.\nThis combination enables robust and scalable simulation of multiscale kinetic\nflows with complex geometries.", "published": "2025-05-06 09:29:37", "link": "http://arxiv.org/abs/2505.03360v1", "categories": ["math.NA", "cs.NA", "76P05, 82C40, 65N08, 65N35"], "primary_category": "math.NA"}
{"title": "Variable projection framework for the reduced-rank matrix approximation problem by weighted least-squares", "abstract": "In this monograph, we review and develop variable projection Gauss-Newton,\nLevenberg-Marquardt and Newton methods for the Weighted Low-Rank Approximation\n(WLRA) problem, which has now an increasing number of applications in many\nscientific fields. Particular attention is drawn at the robustness, efficiency\nand scalability of these variable projection second-order algorithms such that\nthey can be used also on larger datasets now commonly found in many practical\nproblems for which only first-order algorithms based on sequential repetitions\nof local optimization (e.g., majorization, Expectation-Maximization or\nalternating least-squares methods) or variations of gradient descent (e.g.,\nconjugate, proximal or stochastic gradient descent methods), or hybrid\nalgorithms from these two classes of methods, were only feasible due to their\nlower cost and memory requirement per iteration. In parallel with this review\nof variable projection algorithms, we develop new formulae for the Jacobian and\nHessian matrices involved in these variable projection methods and demonstrate\ntheir very specific properties such as the uniform rank deficiency of the\nJacobian matrix or the rank deficiency of the Hessian matrix at the (local)\nminimizers of the cost function associated with the WLRA problem. These\nsystematic deficiencies must be taken into account in any practical\nimplementations of the algorithms. These different properties and the very\nparticular geometry of the WLRA problem have not been well appreciated in the\npast and have been the main obstacles in the development of robust variable\nprojection second-order algorithms for solving the WLRA problem. In addition,\nwe demonstrate that the variable projection framework gives original insights\non the solvability, the landscape and the non-smoothness of the WLRA problem.\nIt also helps to describe the tight links between previously unrelated methods,\nwhich have been proposed to solve it. Specifically, we illustrate the closed\nlinks between the variable projection framework and Riemannian optimization on\nthe Grassmann manifold for the WLRA problem. We expect that software's\ndevelopers and practitioners in different fields such as computer vision,\nsignal processing, recommender systems, machine learning, multivariate\nstatistics and geophysical sciences will benefit from the results in this\nmonograph in order to devise more robust and accurate algorithms to solve the\nWLRA problem.", "published": "2025-05-06 09:14:30", "link": "http://arxiv.org/abs/2505.03347v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "Fully discrete backward error analysis for the midpoint rule applied to the nonlinear Schroedinger equation", "abstract": "The use of symplectic numerical schemes on Hamiltonian systems is widely\nknown to lead to favorable long-time behaviour. While this phenomenon is\nthoroughly understood in the context of finite-dimensional Hamiltonian systems,\nmuch less is known in the context of Hamiltonian PDEs. In this work we provide\nthe first dimension-independent backward error analysis for a Runge-Kutta-type\nmethod, the midpoint rule, which shows the existence of a modified energy for\nthis method when applied to nonlinear Schroedinger equations regardless of the\nlevel of spatial discretisation. We use this to establish long-time stability\nof the numerical flow for the midpoint rule.", "published": "2025-05-06 08:02:07", "link": "http://arxiv.org/abs/2505.03271v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "Geometric means of HPD GLT matrix-sequences: a maximal result beyond invertibility assumptions on the GLT symbols", "abstract": "In the current work, we consider the study of the spectral distribution of\nthe geometric mean matrix-sequence of two matrix-sequences $\\{G(A_n, B_n)\\}_n$\nformed by Hermitian Positive Definite (HPD) matrices,\n  assuming that the two input matrix-sequences $\\{A_n\\}_n, \\{B_n\\}_n$ belong to\nthe same $d$-level $r$-block Generalized Locally Toeplitz (GLT) $\\ast$-algebra\nwith $d,r\\ge 1$ and with GLT symbols $\\kappa, \\xi$. Building on recent results\nin the literature, we examine whether the assumption that at least one of the\ninput GLT symbols is invertible almost everywhere (a.e.) is necessary. Since\ninversion is mainly required due to the non-commutativity of the matrix\nproduct, it was conjectured that the hypothesis on the invertibility of the GLT\nsymbols can be removed. In fact, we prove the conjectured statement that is \\[\n\\{G(A_n, B_n)\\}_n \\sim_{\\mathrm{GLT}} (\\kappa \\xi)^{1/2} \\] when the symbols\n$\\kappa, \\xi$ commute, which implies the important case where $r=1$ and $d \\geq\n1 $, while the statement is generally false or even not well posed when the\nsymbols are not invertible a.e. and do not commute. In fact, numerical\nexperiments are conducted in the case where the two symbols do not commute,\nshowing that the main results of the present work are maximal. Further\nnumerical experiments, visualizations, and conclusions end the present\ncontribution.", "published": "2025-05-06 07:36:30", "link": "http://arxiv.org/abs/2505.03256v1", "categories": ["math.NA", "cs.NA", "47A64, 47B35, 15A18, 15B48, 39A12"], "primary_category": "math.NA"}
{"title": "Well-balanced POD-based reduced-order models for finite volume approximation of hyperbolic balance laws", "abstract": "This paper introduces a reduced-order modeling approach based on finite\nvolume methods for hyperbolic systems, combining Proper Orthogonal\nDecomposition (POD) with the Discrete Empirical Interpolation Method (DEIM) and\nProper Interval Decomposition (PID). Applied to systems such as the transport\nequation with source term, non-homogeneous Burgers equation, and shallow water\nequations with non-flat bathymetry and Manning friction, this method achieves\nsignificant improvements in computational efficiency and accuracy compared to\nprevious time-averaging techniques. A theoretical result justifying the use of\nwell-balanced Full-Order Models (FOMs) is presented. Numerical experiments\nvalidate the approach, demonstrating its accuracy and efficiency. Furthermore,\nthe question of prediction of solutions for systems that depend on some\nphysical parameters is also addressed, and a sensitivity analysis on POD\nparameters confirms the model's robustness and efficiency in this case.", "published": "2025-05-06 07:05:56", "link": "http://arxiv.org/abs/2505.03237v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Regeneration-based a Posteriori Error Bound for a Markov Chain Stationary Distribution Truncation Algorithm", "abstract": "When the state space of a discrete state space positive recurrent Markov\nchain is infinite or very large, it becomes necessary to truncate the state\nspace in order to facilitate numerical computation of the stationary\ndistribution. This paper develops a new approach for bounding the truncation\nerror that arises when computing approximations to the stationary distribution.\nThis rigorous a posteriori error bound exploits the regenerative structure of\nthe chain and assumes knowledge of a Lyapunov function. Because the bound is a\nposteriori (and leverages the computations done to calculate the stationary\ndistribution itself), it tends to be much tighter than a priori bounds. The\nbound decomposes the regenerative cycle into a random number of excursions from\na set $K$ defined in terms of the Lyapunov function into the complement of the\ntruncation set $A$. The bound can be easily computed, and does not (for\nexample) involve a linear program, as do some other error bounds.", "published": "2025-05-06 04:10:09", "link": "http://arxiv.org/abs/2505.03157v1", "categories": ["math.PR", "cs.NA", "math.NA"], "primary_category": "math.PR"}
{"title": "Analysis of beam hardening streaks in tomography", "abstract": "The mathematical foundation of X-ray CT is based on the assumption that by\nmeasuring the attenuation of X-rays passing through an object, one can recover\nthe integrals of the attenuation coefficient $\\mu(x)$ along a sufficiently rich\nfamily of lines $L$, $\\int_L \\mu(x) \\text{d} x$. This assumption is inaccurate\nbecause the energy spectrum of an X-ray beam in a typical CT scanner is wide.\nAt the same time, the X-ray attenuation coefficient of most materials is\nenergy-dependent, and this dependence varies among materials. Thus,\nreconstruction from X-ray CT data is a nonlinear problem. If the nonlinear\nnature of CT data is ignored and a conventional linear reconstruction formula\nis used, which is frequently the case, the resulting image contains\nbeam-hardening artifacts such as streaks. In this work, we describe the\nnonlinearity of CT data using the conventional model accepted by all CT\npractitioners. Our main result is the characterization of streak artifacts\ncaused by nonlinearity. We also obtain an explicit expression for the leading\nsingular behavior of the artifacts. Finally, a numerical experiment is\nconducted to validate the theoretical results.", "published": "2025-05-06 01:12:15", "link": "http://arxiv.org/abs/2505.03095v1", "categories": ["math.NA", "cs.NA", "math.FA"], "primary_category": "math.NA"}
{"title": "The Inverse Drum Machine: Source Separation Through Joint Transcription and Analysis-by-Synthesis", "abstract": "We introduce the Inverse Drum Machine (IDM), a novel approach to drum source\nseparation that combines analysis-by-synthesis with deep learning. Unlike\nrecent supervised methods that rely on isolated stems, IDM requires only\ntranscription annotations. It jointly optimizes automatic drum transcription\nand one-shot drum sample synthesis in an end-to-end framework. By convolving\nsynthesized one-shot samples with estimated onsets-mimicking a drum machine-IDM\nreconstructs individual drum stems and trains a neural network to match the\noriginal mixture. Evaluations on the StemGMD dataset show that IDM achieves\nseparation performance on par with state-of-the-art supervised methods, while\nsubstantially outperforming matrix decomposition baselines.", "published": "2025-05-06 09:08:50", "link": "http://arxiv.org/abs/2505.03337v1", "categories": ["cs.SD", "eess.AS", "eess.SP", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Bayesian full waveform inversion with sequential surrogate model refinement", "abstract": "Bayesian formulations of inverse problems are attractive for their ability to\nincorporate prior knowledge and update probabilistic models as new data become\navailable. Markov chain Monte Carlo (MCMC) methods sample posterior probability\ndensity functions (pdfs) but require accurate prior models and many likelihood\nevaluations. Dimensionality-reduction methods, such as principal component\nanalysis (PCA), can help define the prior and train surrogate models that\nefficiently approximate costly forward solvers. However, for problems like full\nwaveform inversion, the complex input/output relations often cannot be captured\nwell by surrogate models trained only on prior samples, leading to biased\nresults. Including samples from high-posterior-probability regions can improve\naccuracy, but these regions are hard to identify in advance. We propose an\niterative method that progressively refines the surrogate model. Starting with\nlow-frequency data, we train an initial surrogate and perform an MCMC\ninversion. The resulting posterior samples are then used to retrain the\nsurrogate, allowing us to expand the frequency bandwidth in the next inversion\nstep. Repeating this process reduces model errors and improves the surrogate's\naccuracy over the relevant input domain. Ultimately, we obtain a highly\naccurate surrogate across the full bandwidth, enabling a final MCMC inversion.\nNumerical results from 2D synthetic crosshole Ground Penetrating Radar (GPR)\nexamples show that our method outperforms ray-based approaches and those\nrelying solely on prior sampling. The overall computational cost is reduced by\nabout two orders of magnitude compared to full finite-difference time-domain\nmodeling.", "published": "2025-05-06 07:17:03", "link": "http://arxiv.org/abs/2505.03246v1", "categories": ["physics.geo-ph", "stat.ML"], "primary_category": "physics.geo-ph"}
{"title": "Nonparametric learning of covariate-based Markov jump processes using RKHS techniques", "abstract": "We propose a novel nonparametric approach for linking covariates to\nContinuous Time Markov Chains (CTMCs) using the mathematical framework of\nReproducing Kernel Hilbert Spaces (RKHS). CTMCs provide a robust framework for\nmodeling transitions across clinical or behavioral states, but traditional\nmultistate models often rely on linear relationships. In contrast, we use a\ngeneralized Representer Theorem to enable tractable inference in functional\nspace. For the Frequentist version, we apply normed square penalties, while for\nthe Bayesian version, we explore sparsity inducing spike and slab priors. Due\nto the computational challenges posed by high-dimensional spaces, we\nsuccessfully adapt the Expectation Maximization Variable Selection (EMVS)\nalgorithm to efficiently identify the posterior mode. We demonstrate the\neffectiveness of our method through extensive simulation studies and an\napplication to follicular cell lymphoma data. Our performance metrics include\nthe normalized difference between estimated and true nonlinear transition\nfunctions, as well as the difference in the probability of getting absorbed in\none the final states, capturing the ability of our approach to predict\nlong-term behaviors.", "published": "2025-05-06 02:26:02", "link": "http://arxiv.org/abs/2505.03119v1", "categories": ["stat.ME", "q-bio.QM", "stat.CO", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Fairness of Automatic Speech Recognition in Cleft Lip and Palate Speech", "abstract": "Speech produced by individuals with cleft lip and palate (CLP) is often\nhighly nasalized and breathy due to structural anomalies, causing shifts in\nformant structure that affect automatic speech recognition (ASR) performance\nand fairness. This study hypothesizes that publicly available ASR systems\nexhibit reduced fairness for CLP speech and confirms this through experiments.\nDespite formant disruptions, mild and moderate CLP speech retains some\nspectro-temporal alignment with normal speech, motivating augmentation\nstrategies to enhance fairness. The study systematically explores augmenting\nCLP speech with normal speech across severity levels and evaluates its impact\non ASR fairness. Three ASR models-GMM-HMM, Whisper, and XLS-R-were tested on\nAIISH and NMCPC datasets. Results indicate that training with normal speech and\ntesting on mixed data improves word error rate (WER). Notably, WER decreased\nfrom $22.64\\%$ to $18.76\\%$ (GMM-HMM, AIISH) and $28.45\\%$ to $18.89\\%$\n(Whisper, NMCPC). The superior performance of GMM-HMM on AIISH may be due to\nits suitability for Kannada children's speech, a challenge for foundation\nmodels like XLS-R and Whisper. To assess fairness, a fairness score was\nintroduced, revealing improvements of $17.89\\%$ (AIISH) and $47.50\\%$ (NMCPC)\nwith augmentation.", "published": "2025-05-06 17:04:20", "link": "http://arxiv.org/abs/2505.03697v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "SonicRAG : High Fidelity Sound Effects Synthesis Based on Retrival Augmented Generation", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language processing (NLP) and multimodal learning, with successful\napplications in text generation and speech synthesis, enabling a deeper\nunderstanding and generation of multimodal content. In the field of sound\neffects (SFX) generation, LLMs have been leveraged to orchestrate multiple\nmodels for audio synthesis. However, due to the scarcity of annotated datasets,\nand the complexity of temproal modeling. current SFX generation techniques\nstill fall short in achieving high-fidelity audio. To address these\nlimitations, this paper introduces a novel framework that integrates LLMs with\nexisting sound effect databases, allowing for the retrieval, recombination, and\nsynthesis of audio based on user requirements. By leveraging this approach, we\nenhance the diversity and quality of generated sound effects while eliminating\nthe need for additional recording costs, offering a flexible and efficient\nsolution for sound design and application.", "published": "2025-05-06 07:15:04", "link": "http://arxiv.org/abs/2505.03244v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MGFF-TDNN: A Multi-Granularity Feature Fusion TDNN Model with Depth-Wise Separable Module for Speaker Verification", "abstract": "In speaker verification, traditional models often emphasize modeling\nlong-term contextual features to capture global speaker characteristics.\nHowever, this approach can neglect fine-grained voiceprint information, which\ncontains highly discriminative features essential for robust speaker\nembeddings. This paper introduces a novel model architecture, termed MGFF-TDNN,\nbased on multi-granularity feature fusion. The MGFF-TDNN leverages a\ntwo-dimensional depth-wise separable convolution module, enhanced with local\nfeature modeling, as a front-end feature extractor to effectively capture\ntime-frequency domain features. To achieve comprehensive multi-granularity\nfeature fusion, we propose the M-TDNN structure, which integrates global\ncontextual modeling with fine-grained feature extraction by combining\ntime-delay neural networks and phoneme-level feature pooling. Experiments on\nthe VoxCeleb dataset demonstrate that the MGFF-TDNN achieves outstanding\nperformance in speaker verification while remaining efficient in terms of\nparameters and computational resources.", "published": "2025-05-06 06:42:58", "link": "http://arxiv.org/abs/2505.03228v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Affine Filter Bank Modulation: A New Waveform for High Mobility Communications", "abstract": "We propose a new waveform suitable for integrated sensing and communications\n(ISAC) systems facing doubly-dispersive (DD) channel conditions, as typically\nencountered in high mobility scenarios. Dubbed Affine Filter Bank Modulation\n(AFBM), this novel waveform is designed based on a filter-bank structure, known\nfor its ability to suppress out-of-band emissions (OOBE), while integrating a\ndiscrete affine Fourier transform (DAFT) precoding stage which yields low\npeak-to-average power ratio (PAPR) and robustness to DD distortion, as well as\nother features desirable for ISAC. Analytical and simulation results\ndemonstrate that AFBM maintains quasi-orthogonality similar to that of affine\nfrequency division multiplexing (AFDM) in DD channels, while achieving PAPR\nlevels 3 dB lower, in addition to OOBE as low as -100 dB when implemented with\nPHYDYAS prototype filters.", "published": "2025-05-06 14:49:37", "link": "http://arxiv.org/abs/2505.03589v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Design and Development of a Robust Tolerance Optimisation Framework for Automated Optical Inspection in Semiconductor Manufacturing", "abstract": "Automated Optical Inspection (AOI) is widely used across various industries,\nincluding surface mount technology in semiconductor manufacturing. One of the\nkey challenges in AOI is optimising inspection tolerances. Traditionally, this\nprocess relies heavily on the expertise and intuition of engineers, making it\nsubjective and prone to inconsistency. To address this, we are developing an\nintelligent, data-driven approach to optimise inspection tolerances in a more\nobjective and consistent manner. Most existing research in this area focuses\nprimarily on minimising false calls, often at the risk of allowing actual\ndefects to go undetected. This oversight can compromise product quality,\nespecially in critical sectors such as medical, defence, and automotive\nindustries. Our approach introduces the use of percentile rank, amongst other\nlogical strategies, to ensure that genuine defects are not overlooked. With\ncontinued refinement, our method aims to reach a point where every flagged item\nis a true defect, thereby eliminating the need for manual inspection. Our proof\nof concept achieved an 18% reduction in false calls at the 80th percentile\nrank, while maintaining a 100% recall rate. This makes the system both\nefficient and reliable, offering significant time and cost savings.", "published": "2025-05-06 14:35:58", "link": "http://arxiv.org/abs/2505.03576v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Memory-Efficient Distributed Unlearning", "abstract": "Machine unlearning considers the removal of the contribution of a set of data\npoints from a trained model. In a distributed setting, where a server\norchestrates training using data available at a set of remote users, unlearning\nis essential to cope with late-detected malicious or corrupted users. Existing\ndistributed unlearning algorithms require the server to store all model updates\nobserved in training, leading to immense storage overhead for preserving the\nability to unlearn. In this work we study lossy compression schemes for\nfacilitating distributed server-side unlearning with limited memory footprint.\nWe propose memory-efficient distributed unlearning (MEDU), a hierarchical lossy\ncompression scheme tailored for server-side unlearning, that integrates user\nsparsification, differential thresholding, and random lattice coding, to\nsubstantially reduce memory footprint. We rigorously analyze MEDU, deriving an\nupper bound on the difference between the desired model that is trained from\nscratch and the model unlearned from lossy compressed stored updates. Our bound\noutperforms the state-of-the-art known bounds for non-compressed decentralized\nserver-side unlearning, even when lossy compression is incorporated. We further\nprovide a numerical study, which shows that suited lossy compression can enable\ndistributed unlearning with notably reduced memory footprint at the server\nwhile preserving the utility of the unlearned model.", "published": "2025-05-06 10:10:18", "link": "http://arxiv.org/abs/2505.03388v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Hybrid NOMA Assisted Heterogeneous Semantic and Bit Users Communication", "abstract": "In this paper, we utilize a downlink hybrid Non-Orthogonal Multiple Access\n(NOMA) framework to support multiple semantic and bit users within the\ncommunication network. The hybrid NOMA setup exploits both NOMA and Orthogonal\nMultiple Access (OMA) which has the benefit of enhancing Spectral Efficiency\n(SE) by allowing users to dynamically access the resources in multiple\nheterogeneous slots. This enables integrating semantic and bit users based on\ntheir channel gains, while adopting bit-to-semantic decoding order in slots\nincluding heterogeneous users. An optimization problem for the power allocation\nis formulated with the aim of maximizing the equivalent ergodic semantic SE\nwith a constraint on the total available power of the Access Point (AP). The\nproposed algorithm uses NOMA in shared slots and OMA in bit-user-only slots.\nSimulation results validate the benefits of heterogeneous users hybrid NOMA\nsetup in comparison to OMA-only for heterogeneous users.", "published": "2025-05-06 09:56:50", "link": "http://arxiv.org/abs/2505.03379v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Enhancing Target-unspecific Tasks through a Features Matrix", "abstract": "Recent developments in prompt learning of large vision-language models have\nsignificantly improved performance in target-specific tasks. However, these\nprompt optimizing methods often struggle to tackle the target-unspecific or\ngeneralizable tasks effectively. It may be attributed to the fact that\noverfitting training causes the model to forget its general knowledge having\nstrong promotion on target-unspecific tasks. To alleviate this issue, we\npropose a novel Features Matrix (FM) regularization approach designed to\nenhance these models on target-unspecific tasks. Our method extracts and\nleverages general knowledge, shaping a Features Matrix (FM). Specifically, the\nFM captures the semantics of diverse inputs from a deep and fine perspective,\npreserving essential general knowledge, which mitigates the risk of\noverfitting. Representative evaluations demonstrate that: 1) the FM is\ncompatible with existing frameworks as a generic and flexible module, and 2)\nthe FM significantly showcases its effectiveness in enhancing target-unspecific\ntasks, achieving state-of-the-art performance.", "published": "2025-05-06 10:41:53", "link": "http://arxiv.org/abs/2505.03414v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Absolute Zero: Reinforced Self-play Reasoning with Zero Data", "abstract": "Reinforcement learning with verifiable rewards (RLVR) has shown promise in\nenhancing the reasoning capabilities of large language models by learning\ndirectly from outcome-based rewards. Recent RLVR works that operate under the\nzero setting avoid supervision in labeling the reasoning process, but still\ndepend on manually curated collections of questions and answers for training.\nThe scarcity of high-quality, human-produced examples raises concerns about the\nlong-term scalability of relying on human supervision, a challenge already\nevident in the domain of language model pretraining. Furthermore, in a\nhypothetical future where AI surpasses human intelligence, tasks provided by\nhumans may offer limited learning potential for a superintelligent system. To\naddress these concerns, we propose a new RLVR paradigm called Absolute Zero, in\nwhich a single model learns to propose tasks that maximize its own learning\nprogress and improves reasoning by solving them, without relying on any\nexternal data. Under this paradigm, we introduce the Absolute Zero Reasoner\n(AZR), a system that self-evolves its training curriculum and reasoning ability\nby using a code executor to both validate proposed code reasoning tasks and\nverify answers, serving as an unified source of verifiable reward to guide\nopen-ended yet grounded learning. Despite being trained entirely without\nexternal data, AZR achieves overall SOTA performance on coding and mathematical\nreasoning tasks, outperforming existing zero-setting models that rely on tens\nof thousands of in-domain human-curated examples. Furthermore, we demonstrate\nthat AZR can be effectively applied across different model scales and is\ncompatible with various model classes.", "published": "2025-05-06 09:08:00", "link": "http://arxiv.org/abs/2505.03335v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DCS-ST for Classification of Breast Cancer Histopathology Images with Limited Annotations", "abstract": "Deep learning methods have shown promise in classifying breast cancer\nhistopathology images, but their performance often declines with limited\nannotated data, a critical challenge in medical imaging due to the high cost\nand expertise required for annotations.", "published": "2025-05-06 05:38:17", "link": "http://arxiv.org/abs/2505.03204v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Visual Imitation Enables Contextual Humanoid Control", "abstract": "How can we teach humanoids to climb staircases and sit on chairs using the\nsurrounding environment context? Arguably, the simplest way is to just show\nthem-casually capture a human motion video and feed it to humanoids. We\nintroduce VIDEOMIMIC, a real-to-sim-to-real pipeline that mines everyday\nvideos, jointly reconstructs the humans and the environment, and produces\nwhole-body control policies for humanoid robots that perform the corresponding\nskills. We demonstrate the results of our pipeline on real humanoid robots,\nshowing robust, repeatable contextual control such as staircase ascents and\ndescents, sitting and standing from chairs and benches, as well as other\ndynamic whole-body skills-all from a single policy, conditioned on the\nenvironment and global root commands. VIDEOMIMIC offers a scalable path towards\nteaching humanoids to operate in diverse real-world environments.", "published": "2025-05-06 17:57:12", "link": "http://arxiv.org/abs/2505.03729v2", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Breaking Annotation Barriers: Generalized Video Quality Assessment via Ranking-based Self-Supervision", "abstract": "Video quality assessment (VQA) is essential for quantifying perceptual\nquality in various video processing workflows, spanning from camera capture\nsystems to over-the-top streaming platforms. While recent supervised VQA models\nhave made substantial progress, the reliance on manually annotated datasets --\na process that is labor-intensive, costly, and difficult to scale up -- has\nhindered further optimization of their generalization to unseen video content\nand distortions. To bridge this gap, we introduce a self-supervised learning\nframework for VQA to learn quality assessment capabilities from large-scale,\nunlabeled web videos. Our approach leverages a \\textbf{learning-to-rank}\nparadigm to train a large multimodal model (LMM) on video pairs automatically\nlabeled via two manners, including quality pseudo-labeling by existing VQA\nmodels and relative quality ranking based on synthetic distortion simulations.\nFurthermore, we introduce a novel \\textbf{iterative self-improvement training\nstrategy}, where the trained model acts an improved annotator to iteratively\nrefine the annotation quality of training data. By training on a dataset\n$10\\times$ larger than the existing VQA benchmarks, our model: (1) achieves\nzero-shot performance on in-domain VQA benchmarks that matches or surpasses\nsupervised models; (2) demonstrates superior out-of-distribution (OOD)\ngeneralization across diverse video content and distortions; and (3) sets a new\nstate-of-the-art when fine-tuned on human-labeled datasets. Extensive\nexperimental results validate the effectiveness of our self-supervised approach\nin training generalized VQA models. The datasets and code will be publicly\nreleased to facilitate future research.", "published": "2025-05-06 15:29:32", "link": "http://arxiv.org/abs/2505.03631v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PAHA: Parts-Aware Audio-Driven Human Animation with Diffusion Model", "abstract": "Audio-driven human animation technology is widely used in human-computer\ninteraction, and the emergence of diffusion models has further advanced its\ndevelopment. Currently, most methods rely on multi-stage generation and\nintermediate representations, resulting in long inference time and issues with\ngeneration quality in specific foreground regions and audio-motion consistency.\nThese shortcomings are primarily due to the lack of localized fine-grained\nsupervised guidance. To address above challenges, we propose PAHA, an\nend-to-end audio-driven upper-body human animation framework with diffusion\nmodel. We introduce two key methods: Parts-Aware Re-weighting (PAR) and Parts\nConsistency Enhancement (PCE). PAR dynamically adjusts regional training loss\nweights based on pose confidence scores, effectively improving visual quality.\nPCE constructs and trains diffusion-based regional audio-visual classifiers to\nimprove the consistency of motion and co-speech audio. Afterwards, we design\ntwo novel inference guidance methods for the foregoing classifiers, Sequential\nGuidance (SG) and Differential Guidance (DG), to balance efficiency and quality\nrespectively. Additionally, we build CNAS, the first public Chinese News Anchor\nSpeech dataset, to advance research and validation in this field. Extensive\nexperimental results and user studies demonstrate that PAHA significantly\noutperforms existing methods in audio-motion alignment and video-related\nevaluations. The codes and CNAS dataset will be released upon acceptance.", "published": "2025-05-06 15:03:58", "link": "http://arxiv.org/abs/2505.03603v2", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Uncertainty-Aware Prototype Semantic Decoupling for Text-Based Person Search in Full Images", "abstract": "Text-based pedestrian search (TBPS) in full images aims to locate a target\npedestrian in untrimmed images using natural language descriptions. However, in\ncomplex scenes with multiple pedestrians, existing methods are limited by\nuncertainties in detection and matching, leading to degraded performance. To\naddress this, we propose UPD-TBPS, a novel framework comprising three modules:\nMulti-granularity Uncertainty Estimation (MUE), Prototype-based Uncertainty\nDecoupling (PUD), and Cross-modal Re-identification (ReID). MUE conducts\nmulti-granularity queries to identify potential targets and assigns confidence\nscores to reduce early-stage uncertainty. PUD leverages visual context\ndecoupling and prototype mining to extract features of the target pedestrian\ndescribed in the query. It separates and learns pedestrian prototype\nrepresentations at both the coarse-grained cluster level and the fine-grained\nindividual level, thereby reducing matching uncertainty. ReID evaluates\ncandidates with varying confidence levels, improving detection and retrieval\naccuracy. Experiments on CUHK-SYSU-TBPS and PRW-TBPS datasets validate the\neffectiveness of our framework.", "published": "2025-05-06 14:25:30", "link": "http://arxiv.org/abs/2505.03567v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Survival Distributions with the Asymmetric Laplace Distribution", "abstract": "Probabilistic survival analysis models seek to estimate the distribution of\nthe future occurrence (time) of an event given a set of covariates. In recent\nyears, these models have preferred nonparametric specifications that avoid\ndirectly estimating survival distributions via discretization. Specifically,\nthey estimate the probability of an individual event at fixed times or the time\nof an event at fixed probabilities (quantiles), using supervised learning.\nBorrowing ideas from the quantile regression literature, we propose a\nparametric survival analysis method based on the Asymmetric Laplace\nDistribution (ALD). This distribution allows for closed-form calculation of\npopular event summaries such as mean, median, mode, variation, and quantiles.\nThe model is optimized by maximum likelihood to learn, at the individual level,\nthe parameters (location, scale, and asymmetry) of the ALD distribution.\nExtensive results on synthetic and real-world data demonstrate that the\nproposed method outperforms parametric and nonparametric approaches in terms of\naccuracy, discrimination and calibration.", "published": "2025-05-06 17:34:41", "link": "http://arxiv.org/abs/2505.03712v2", "categories": ["cs.LG", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Multi-modal cascade feature transfer for polymer property prediction", "abstract": "In this paper, we propose a novel transfer learning approach called\nmulti-modal cascade model with feature transfer for polymer property\nprediction.Polymers are characterized by a composite of data in several\ndifferent formats, including molecular descriptors and additive information as\nwell as chemical structures. However, in conventional approaches, prediction\nmodels were often constructed using each type of data separately. Our model\nenables more accurate prediction of physical properties for polymers by\ncombining features extracted from the chemical structure by graph convolutional\nneural networks (GCN) with features such as molecular descriptors and additive\ninformation. The predictive performance of the proposed method is empirically\nevaluated using several polymer datasets. We report that the proposed method\nshows high predictive performance compared to the baseline conventional\napproach using a single feature.", "published": "2025-05-06 17:24:43", "link": "http://arxiv.org/abs/2505.03704v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Weighted Random Dot Product Graphs", "abstract": "Modeling of intricate relational patterns has become a cornerstone of\ncontemporary statistical research and related data science fields. Networks,\nrepresented as graphs, offer a natural framework for this analysis. This paper\nextends the Random Dot Product Graph (RDPG) model to accommodate weighted\ngraphs, markedly broadening the model's scope to scenarios where edges exhibit\nheterogeneous weight distributions. We propose a nonparametric weighted (W)RDPG\nmodel that assigns a sequence of latent positions to each node. Inner products\nof these nodal vectors specify the moments of their incident edge weights'\ndistribution via moment-generating functions. In this way, and unlike prior\nart, the WRDPG can discriminate between weight distributions that share the\nsame mean but differ in other higher-order moments. We derive statistical\nguarantees for an estimator of the nodal's latent positions adapted from the\nworkhorse adjacency spectral embedding, establishing its consistency and\nasymptotic normality. We also contribute a generative framework that enables\nsampling of graphs that adhere to a (prescribed or data-fitted) WRDPG,\nfacilitating, e.g., the analysis and testing of observed graph metrics using\njudicious reference distributions. The paper is organized to formalize the\nmodel's definition, the estimation (or nodal embedding) process and its\nguarantees, as well as the methodologies for generating weighted graphs, all\ncomplemented by illustrative and reproducible examples showcasing the WRDPG's\neffectiveness in various network analytic applications.", "published": "2025-05-06 15:57:00", "link": "http://arxiv.org/abs/2505.03649v2", "categories": ["stat.ML", "cs.LG", "math.CO", "math.PR"], "primary_category": "stat.ML"}
{"title": "Anant-Net: Breaking the Curse of Dimensionality with Scalable and Interpretable Neural Surrogate for High-Dimensional PDEs", "abstract": "High-dimensional partial differential equations (PDEs) arise in diverse\nscientific and engineering applications but remain computationally intractable\ndue to the curse of dimensionality. Traditional numerical methods struggle with\nthe exponential growth in computational complexity, particularly on hypercubic\ndomains, where the number of required collocation points increases rapidly with\ndimensionality. Here, we introduce Anant-Net, an efficient neural surrogate\nthat overcomes this challenge, enabling the solution of PDEs in high\ndimensions. Unlike hyperspheres, where the internal volume diminishes as\ndimensionality increases, hypercubes retain or expand their volume (for unit or\nlarger length), making high-dimensional computations significantly more\ndemanding. Anant-Net efficiently incorporates high-dimensional boundary\nconditions and minimizes the PDE residual at high-dimensional collocation\npoints. To enhance interpretability, we integrate Kolmogorov-Arnold networks\ninto the Anant-Net architecture. We benchmark Anant-Net's performance on\nseveral linear and nonlinear high-dimensional equations, including the Poisson,\nSine-Gordon, and Allen-Cahn equations, demonstrating high accuracy and\nrobustness across randomly sampled test points from high-dimensional space.\nImportantly, Anant-Net achieves these results with remarkable efficiency,\nsolving 300-dimensional problems on a single GPU within a few hours. We also\ncompare Anant-Net's results for accuracy and runtime with other\nstate-of-the-art methods. Our findings establish Anant-Net as an accurate,\ninterpretable, and scalable framework for efficiently solving high-dimensional\nPDEs.", "published": "2025-05-06 14:56:43", "link": "http://arxiv.org/abs/2505.03595v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Quantum Feature Space of a Qubit Coupled to an Arbitrary Bath", "abstract": "Qubit control protocols have traditionally leveraged a characterisation of\nthe qubit-bath coupling via its power spectral density. Previous work proposed\nthe inference of noise operators that characterise the influence of a classical\nbath using a grey-box approach that combines deep neural networks with\nphysics-encoded layers. This overall structure is complex and poses challenges\nin scaling and real-time operations. Here, we show that no expensive neural\nnetworks are needed and that this noise operator description admits an\nefficient parameterisation. We refer to the resulting parameter space as the\n\\textit{quantum feature space} of the qubit dynamics resulting from the coupled\nbath. We show that the Euclidean distance defined over the quantum feature\nspace provides an effective method for classifying noise processes in the\npresence of a given set of controls. Using the quantum feature space as the\ninput space for a simple machine learning algorithm (random forest, in this\ncase), we demonstrate that it can effectively classify the stationarity and the\nbroad class of noise processes perturbing a qubit. Finally, we explore how\ncontrol pulse parameters map to the quantum feature space.", "published": "2025-05-06 10:25:50", "link": "http://arxiv.org/abs/2505.03397v2", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "SLOT: Structuring the Output of Large Language Models", "abstract": "Structured outputs are essential for large language models (LLMs) in critical\napplications like agents and information extraction. Despite their\ncapabilities, LLMs often generate outputs that deviate from predefined schemas,\nsignificantly hampering reliable application development. We present SLOT\n(Structured LLM Output Transformer), a model-agnostic approach that transforms\nunstructured LLM outputs into precise structured formats. While existing\nsolutions predominantly rely on constrained decoding techniques or are tightly\ncoupled with specific models, SLOT employs a fine-tuned lightweight language\nmodel as a post-processing layer, achieving flexibility across various LLMs and\nschema specifications. We introduce a systematic pipeline for data curation and\nsynthesis alongside a formal evaluation methodology that quantifies both schema\naccuracy and content fidelity. Our results demonstrate that fine-tuned\nMistral-7B model with constrained decoding achieves near perfect schema\naccuracy (99.5%) and content similarity (94.0%), outperforming\nClaude-3.5-Sonnet by substantial margins (+25 and +20 percentage points,\nrespectively). Notably, even compact models like Llama-3.2-1B can match or\nexceed the structured output capabilities of much larger proprietary models\nwhen equipped with SLOT, enabling reliable structured generation in\nresource-constrained environments.", "published": "2025-05-06 23:29:43", "link": "http://arxiv.org/abs/2505.04016v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Quiet Feature Learning in Algorithmic Tasks", "abstract": "We train Transformer-based language models on ten foundational algorithmic\ntasks and observe pronounced phase transitions in their loss curves that\ndeviate from established power-law scaling trends. Over large ranges of\ncompute, the validation loss barely improves, then abruptly decreases. Probing\nthe models' internal representations reveals the learning of quiet features\nduring the stagnant phase, followed by sudden acquisition of loud features that\ncoincide with the sharp drop in loss. Our ablation experiments show that\ndisrupting a single learned feature can dramatically degrade performance,\nproviding evidence of their causal role in task performance. These findings\nchallenge the prevailing assumption that next-token predictive loss reliably\ntracks incremental progress; instead, key internal features may be developing\nbelow the surface until they coalesce, triggering a rapid performance gain.", "published": "2025-05-06 22:18:50", "link": "http://arxiv.org/abs/2505.03997v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "X-Reasoner: Towards Generalizable Reasoning Across Modalities and Domains", "abstract": "Recent proprietary models (e.g., o3) have begun to demonstrate strong\nmultimodal reasoning capabilities. Yet, most existing open-source research\nconcentrates on training text-only reasoning models, with evaluations limited\nto mainly mathematical and general-domain tasks. Therefore, it remains unclear\nhow to effectively extend reasoning capabilities beyond text input and general\ndomains. This paper explores a fundamental research question: Is reasoning\ngeneralizable across modalities and domains? Our findings support an\naffirmative answer: General-domain text-based post-training can enable such\nstrong generalizable reasoning. Leveraging this finding, we introduce\nX-Reasoner, a vision-language model post-trained solely on general-domain text\nfor generalizable reasoning, using a two-stage approach: an initial supervised\nfine-tuning phase with distilled long chain-of-thoughts, followed by\nreinforcement learning with verifiable rewards. Experiments show that\nX-Reasoner successfully transfers reasoning capabilities to both multimodal and\nout-of-domain settings, outperforming existing state-of-the-art models trained\nwith in-domain and multimodal data across various general and medical\nbenchmarks (Figure 1). Additionally, we find that X-Reasoner's performance in\nspecialized domains can be further enhanced through continued training on\ndomain-specific text-only data. Building upon this, we introduce\nX-Reasoner-Med, a medical-specialized variant that achieves new state of the\nart on numerous text-only and multimodal medical benchmarks.", "published": "2025-05-06 21:08:27", "link": "http://arxiv.org/abs/2505.03981v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale", "abstract": "LLM-based optimization has shown remarkable potential in enhancing agentic\nsystems. However, the conventional approach of prompting LLM optimizer with the\nwhole training trajectories on training dataset in a single pass becomes\nuntenable as datasets grow, leading to context window overflow and degraded\npattern recognition. To address these challenges, we propose Fine-Grained\nOptimization (FGO), a scalable framework that divides large optimization tasks\ninto manageable subsets, performs targeted optimizations, and systematically\ncombines optimized components through progressive merging. Evaluation across\nALFWorld, LogisticsQA, and GAIA benchmarks demonstrate that FGO outperforms\nexisting approaches by 1.6-8.6% while reducing average prompt token consumption\nby 56.3%. Our framework provides a practical solution for scaling up LLM-based\noptimization of increasingly sophisticated agent systems. Further analysis\ndemonstrates that FGO achieves the most consistent performance gain in all\ntraining dataset sizes, showcasing its scalability and efficiency.", "published": "2025-05-06 20:50:27", "link": "http://arxiv.org/abs/2505.03973v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Reasoning-Focused Legal Retrieval Benchmark", "abstract": "As the legal community increasingly examines the use of large language models\n(LLMs) for various legal applications, legal AI developers have turned to\nretrieval-augmented LLMs (\"RAG\" systems) to improve system performance and\nrobustness. An obstacle to the development of specialized RAG systems is the\nlack of realistic legal RAG benchmarks which capture the complexity of both\nlegal retrieval and downstream legal question-answering. To address this, we\nintroduce two novel legal RAG benchmarks: Bar Exam QA and Housing Statute QA.\nOur tasks correspond to real-world legal research tasks, and were produced\nthrough annotation processes which resemble legal research. We describe the\nconstruction of these benchmarks and the performance of existing retriever\npipelines. Our results suggest that legal RAG remains a challenging\napplication, thus motivating future research.", "published": "2025-05-06 20:44:03", "link": "http://arxiv.org/abs/2505.03970v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete", "abstract": "According to Yuval Noah Harari, large-scale human cooperation is driven by\nshared narratives that encode common beliefs and values. This study explores\nwhether such narratives can similarly nudge LLM agents toward collaboration. We\nuse a finitely repeated public goods game in which LLM agents choose either\ncooperative or egoistic spending strategies. We prime agents with stories\nhighlighting teamwork to different degrees and test how this influences\nnegotiation outcomes. Our experiments explore four questions:(1) How do\nnarratives influence negotiation behavior? (2) What differs when agents share\nthe same story versus different ones? (3) What happens when the agent numbers\ngrow? (4) Are agents resilient against self-serving negotiators? We find that\nstory-based priming significantly affects negotiation strategies and success\nrates. Common stories improve collaboration, benefiting each agent. By\ncontrast, priming agents with different stories reverses this effect, and those\nagents primed toward self-interest prevail. We hypothesize that these results\ncarry implications for multi-agent system design and AI alignment.", "published": "2025-05-06 20:23:25", "link": "http://arxiv.org/abs/2505.03961v1", "categories": ["cs.AI", "cs.CL", "cs.MA", "I.2.11; I.2.7; I.6; J.4"], "primary_category": "cs.AI"}
{"title": "Hesitation is defeat? Connecting Linguistic and Predictive Uncertainty", "abstract": "Automating chest radiograph interpretation using Deep Learning (DL) models\nhas the potential to significantly improve clinical workflows, decision-making,\nand large-scale health screening. However, in medical settings, merely\noptimising predictive performance is insufficient, as the quantification of\nuncertainty is equally crucial. This paper investigates the relationship\nbetween predictive uncertainty, derived from Bayesian Deep Learning\napproximations, and human/linguistic uncertainty, as estimated from free-text\nradiology reports labelled by rule-based labellers. Utilising BERT as the model\nof choice, this study evaluates different binarisation methods for uncertainty\nlabels and explores the efficacy of Monte Carlo Dropout and Deep Ensembles in\nestimating predictive uncertainty. The results demonstrate good model\nperformance, but also a modest correlation between predictive and linguistic\nuncertainty, highlighting the challenges in aligning machine uncertainty with\nhuman interpretation nuances. Our findings suggest that while Bayesian\napproximations provide valuable uncertainty estimates, further refinement is\nnecessary to fully capture and utilise the subtleties of human uncertainty in\nclinical applications.", "published": "2025-05-06 18:34:37", "link": "http://arxiv.org/abs/2505.03910v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prism: Unleashing GPU Sharing for Cost-Efficient Multi-LLM Serving", "abstract": "Serving large language models (LLMs) is expensive, especially for providers\nhosting many models, making cost reduction essential. The unique workload\npatterns of serving multiple LLMs (i.e., multi-LLM serving) create new\nopportunities and challenges for this task. The long-tail popularity of models\nand their long idle periods present opportunities to improve utilization\nthrough GPU sharing. However, existing GPU sharing systems lack the ability to\nadjust their resource allocation and sharing policies at runtime, making them\nineffective at meeting latency service-level objectives (SLOs) under rapidly\nfluctuating workloads.\n  This paper presents Prism, a multi-LLM serving system that unleashes the full\npotential of GPU sharing to achieve both cost efficiency and SLO attainment. At\nits core, Prism tackles a key limitation of existing\nsystems$\\unicode{x2014}$the lack of $\\textit{cross-model memory coordination}$,\nwhich is essential for flexibly sharing GPU memory across models under dynamic\nworkloads. Prism achieves this with two key designs. First, it supports\non-demand memory allocation by dynamically mapping physical to virtual memory\npages, allowing flexible memory redistribution among models that space- and\ntime-share a GPU. Second, it improves memory efficiency through a two-level\nscheduling policy that dynamically adjusts sharing strategies based on models'\nruntime demands. Evaluations on real-world traces show that Prism achieves more\nthan $2\\times$ cost savings and $3.3\\times$ SLO attainment compared to\nstate-of-the-art systems.", "published": "2025-05-06 23:38:33", "link": "http://arxiv.org/abs/2505.04021v1", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "cs.DC"}
{"title": "Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation Forest", "abstract": "The need to explain predictive models is well-established in modern machine\nlearning. However, beyond model interpretability, understanding pre-processing\nmethods is equally essential. Understanding how data modifications impact model\nperformance improvements and potential biases and promoting a reliable pipeline\nis mandatory for developing robust machine learning solutions. Isolation Forest\n(iForest) is a widely used technique for outlier detection that performs well.\nIts effectiveness increases with the number of tree-based learners. However,\nthis also complicates the explanation of outlier selection and the decision\nboundaries for inliers. This research introduces a novel Explainable AI (XAI)\nmethod, tackling the problem of global explainability. In detail, it aims to\noffer a global explanation for outlier detection to address its opaque nature.\nOur approach is based on the Decision Predicate Graph (DPG), which clarifies\nthe logic of ensemble methods and provides both insights and a graph-based\nmetric to explain how samples are identified as outliers using the proposed\nInlier-Outlier Propagation Score (IOP-Score). Our proposal enhances iForest's\nexplainability and provides a comprehensive view of the decision-making\nprocess, detailing which features contribute to outlier identification and how\nthe model utilizes them. This method advances the state-of-the-art by providing\ninsights into decision boundaries and a comprehensive view of holistic feature\nusage in outlier identification. -- thus promoting a fully explainable machine\nlearning pipeline.", "published": "2025-05-06 23:32:16", "link": "http://arxiv.org/abs/2505.04019v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MergeGuard: Efficient Thwarting of Trojan Attacks in Machine Learning Models", "abstract": "This paper proposes MergeGuard, a novel methodology for mitigation of AI\nTrojan attacks. Trojan attacks on AI models cause inputs embedded with triggers\nto be misclassified to an adversary's target class, posing a significant threat\nto model usability trained by an untrusted third party. The core of MergeGuard\nis a new post-training methodology for linearizing and merging fully connected\nlayers which we show simultaneously improves model generalizability and\nperformance. Our Proof of Concept evaluation on Transformer models demonstrates\nthat MergeGuard maintains model accuracy while decreasing trojan attack success\nrate, outperforming commonly used (post-training) Trojan mitigation by\nfine-tuning methodologies.", "published": "2025-05-06 23:26:25", "link": "http://arxiv.org/abs/2505.04015v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers", "abstract": "Humans excel in navigating diverse, complex environments with agile motor\nskills, exemplified by parkour practitioners performing dynamic maneuvers, such\nas climbing up walls and jumping across gaps. Reproducing these agile movements\nwith simulated characters remains challenging, in part due to the scarcity of\nmotion capture data for agile terrain traversal behaviors and the high cost of\nacquiring such data. In this work, we introduce PARC (Physics-based\nAugmentation with Reinforcement Learning for Character Controllers), a\nframework that leverages machine learning and physics-based simulation to\niteratively augment motion datasets and expand the capabilities of terrain\ntraversal controllers. PARC begins by training a motion generator on a small\ndataset consisting of core terrain traversal skills. The motion generator is\nthen used to produce synthetic data for traversing new terrains. However, these\ngenerated motions often exhibit artifacts, such as incorrect contacts or\ndiscontinuities. To correct these artifacts, we train a physics-based tracking\ncontroller to imitate the motions in simulation. The corrected motions are then\nadded to the dataset, which is used to continue training the motion generator\nin the next iteration. PARC's iterative process jointly expands the\ncapabilities of the motion generator and tracker, creating agile and versatile\nmodels for interacting with complex environments. PARC provides an effective\napproach to develop controllers for agile terrain traversal, which bridges the\ngap between the scarcity of motion data and the need for versatile character\ncontrollers.", "published": "2025-05-06 22:29:07", "link": "http://arxiv.org/abs/2505.04002v1", "categories": ["cs.GR", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.GR"}
{"title": "An alignment safety case sketch based on debate", "abstract": "If AI systems match or exceed human capabilities on a wide range of tasks, it\nmay become difficult for humans to efficiently judge their actions -- making it\nhard to use human feedback to steer them towards desirable traits. One proposed\nsolution is to leverage another superhuman system to point out flaws in the\nsystem's outputs via a debate. This paper outlines the value of debate for AI\nsafety, as well as the assumptions and further research required to make debate\nwork. It does so by sketching an ``alignment safety case'' -- an argument that\nan AI system will not autonomously take actions which could lead to egregious\nharm, despite being able to do so. The sketch focuses on the risk of an AI R\\&D\nagent inside an AI company sabotaging research, for example by producing false\nresults. To prevent this, the agent is trained via debate, subject to\nexploration guarantees, to teach the system to be honest. Honesty is maintained\nthroughout deployment via online training. The safety case rests on four key\nclaims: (1) the agent has become good at the debate game, (2) good performance\nin the debate game implies that the system is mostly honest, (3) the system\nwill not become significantly less honest during deployment, and (4) the\ndeployment context is tolerant of some errors. We identify open research\nproblems that, if solved, could render this a compelling argument that an AI\nsystem is safe.", "published": "2025-05-06 21:53:44", "link": "http://arxiv.org/abs/2505.03989v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Can Large Language Models Predict Parallel Code Performance?", "abstract": "Accurate determination of the performance of parallel GPU code typically\nrequires execution-time profiling on target hardware -- an increasingly\nprohibitive step due to limited access to high-end GPUs. This paper explores\nwhether Large Language Models (LLMs) can offer an alternative approach for GPU\nperformance prediction without relying on hardware. We frame the problem as a\nroofline classification task: given the source code of a GPU kernel and the\nhardware specifications of a target GPU, can an LLM predict whether the GPU\nkernel is compute-bound or bandwidth-bound?\n  For this study, we build a balanced dataset of 340 GPU kernels, obtained from\nHeCBench benchmark and written in CUDA and OpenMP, along with their\nground-truth labels obtained via empirical GPU profiling. We evaluate LLMs\nacross four scenarios: (1) with access to profiling data of the kernel source,\n(2) zero-shot with source code only, (3) few-shot with code and label pairs,\nand (4) fine-tuned on a small custom dataset.\n  Our results show that state-of-the-art LLMs have a strong understanding of\nthe Roofline model, achieving 100% classification accuracy when provided with\nexplicit profiling data. We also find that reasoning-capable LLMs significantly\noutperform standard LLMs in zero- and few-shot settings, achieving up to 64%\naccuracy on GPU source codes, without profiling information. Lastly, we find\nthat LLM fine-tuning will require much more data than what we currently have\navailable.\n  This work is among the first to use LLMs for source-level roofline\nperformance prediction via classification, and illustrates their potential to\nguide optimization efforts when runtime profiling is infeasible. Our findings\nsuggest that with better datasets and prompt strategies, LLMs could become\npractical tools for HPC performance analysis and performance portability.", "published": "2025-05-06 21:41:20", "link": "http://arxiv.org/abs/2505.03988v1", "categories": ["cs.DC", "cs.AI", "cs.PF"], "primary_category": "cs.DC"}
{"title": "LogiDebrief: A Signal-Temporal Logic based Automated Debriefing Approach with Large Language Models Integration", "abstract": "Emergency response services are critical to public safety, with 9-1-1\ncall-takers playing a key role in ensuring timely and effective emergency\noperations. To ensure call-taking performance consistency, quality assurance is\nimplemented to evaluate and refine call-takers' skillsets. However, traditional\nhuman-led evaluations struggle with high call volumes, leading to low coverage\nand delayed assessments. We introduce LogiDebrief, an AI-driven framework that\nautomates traditional 9-1-1 call debriefing by integrating Signal-Temporal\nLogic (STL) with Large Language Models (LLMs) for fully-covered rigorous\nperformance evaluation. LogiDebrief formalizes call-taking requirements as\nlogical specifications, enabling systematic assessment of 9-1-1 calls against\nprocedural guidelines. It employs a three-step verification process: (1)\ncontextual understanding to identify responder types, incident classifications,\nand critical conditions; (2) STL-based runtime checking with LLM integration to\nensure compliance; and (3) automated aggregation of results into quality\nassurance reports. Beyond its technical contributions, LogiDebrief has\ndemonstrated real-world impact. Successfully deployed at Metro Nashville\nDepartment of Emergency Communications, it has assisted in debriefing 1,701\nreal-world calls, saving 311.85 hours of active engagement. Empirical\nevaluation with real-world data confirms its accuracy, while a case study and\nextensive user study highlight its effectiveness in enhancing call-taking\nperformance.", "published": "2025-05-06 21:27:07", "link": "http://arxiv.org/abs/2505.03985v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Diffusion Models are Secretly Exchangeable: Parallelizing DDPMs via Autospeculation", "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) have emerged as powerful\ntools for generative modeling. However, their sequential computation\nrequirements lead to significant inference-time bottlenecks. In this work, we\nutilize the connection between DDPMs and Stochastic Localization to prove that,\nunder an appropriate reparametrization, the increments of DDPM satisfy an\nexchangeability property. This general insight enables near-black-box\nadaptation of various performance optimization techniques from autoregressive\nmodels to the diffusion setting. To demonstrate this, we introduce\n\\emph{Autospeculative Decoding} (ASD), an extension of the widely used\nspeculative decoding algorithm to DDPMs that does not require any auxiliary\ndraft models. Our theoretical analysis shows that ASD achieves a $\\tilde{O}\n(K^{\\frac{1}{3}})$ parallel runtime speedup over the $K$ step sequential DDPM.\nWe also demonstrate that a practical implementation of autospeculative decoding\naccelerates DDPM inference significantly in various domains.", "published": "2025-05-06 21:10:37", "link": "http://arxiv.org/abs/2505.03983v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Deep Learning Framework for Infrastructure Maintenance: Crack Detection and High-Resolution Imaging of Infrastructure Surfaces", "abstract": "Recently, there has been an impetus for the application of cutting-edge data\ncollection platforms such as drones mounted with camera sensors for\ninfrastructure asset management. However, the sensor characteristics, proximity\nto the structure, hard-to-reach access, and environmental conditions often\nlimit the resolution of the datasets. A few studies used super-resolution\ntechniques to address the problem of low-resolution images. Nevertheless, these\ntechniques were observed to increase computational cost and false alarms of\ndistress detection due to the consideration of all the infrastructure images\ni.e., positive and negative distress classes. In order to address the\npre-processing of false alarm and achieve efficient super-resolution, this\nstudy developed a framework consisting of convolutional neural network (CNN)\nand efficient sub-pixel convolutional neural network (ESPCNN). CNN accurately\nclassified both the classes. ESPCNN, which is the lightweight super-resolution\ntechnique, generated high-resolution infrastructure image of positive distress\nobtained from CNN. The ESPCNN outperformed bicubic interpolation in all the\nevaluation metrics for super-resolution. Based on the performance metrics, the\ncombination of CNN and ESPCNN was observed to be effective in preprocessing the\ninfrastructure images with negative distress, reducing the computational cost\nand false alarms in the next step of super-resolution. The visual inspection\nshowed that EPSCNN is able to capture crack propagation, complex geometry of\neven minor cracks. The proposed framework is expected to help the highway\nagencies in accurately performing distress detection and assist in efficient\nasset management practices.", "published": "2025-05-06 20:52:58", "link": "http://arxiv.org/abs/2505.03974v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents", "abstract": "One of the primary aspirations in reinforcement learning research is\ndeveloping general-purpose agents capable of rapidly adapting to and mastering\nnovel tasks. While RL gaming agents have mastered many Atari games, they remain\nslow and costly to train for each game. In this work, we demonstrate that\nlatest reasoning LLMs with out-of-domain RL post-training can play a\nchallenging Atari game called Frogger under a zero-shot setting. We then\ninvestigate the effect of in-context learning and the amount of reasoning\neffort on LLM performance. Lastly, we demonstrate a way to bootstrap\ntraditional RL method with LLM demonstrations, which significantly improves\ntheir performance and sample efficiency. Our implementation is open sourced at\nhttps://github.com/AlienKevin/frogger.", "published": "2025-05-06 19:51:41", "link": "http://arxiv.org/abs/2505.03947v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Decentralized Distributed Proximal Policy Optimization (DD-PPO) for High Performance Computing Scheduling on Multi-User Systems", "abstract": "Resource allocation in High Performance Computing (HPC) environments presents\na complex and multifaceted challenge for job scheduling algorithms. Beyond the\nefficient allocation of system resources, schedulers must account for and\noptimize multiple performance metrics, including job wait time and system\nutilization. While traditional rule-based scheduling algorithms dominate the\ncurrent deployments of HPC systems, the increasing heterogeneity and scale of\nthose systems is expected to challenge the efficiency and flexibility of those\nalgorithms in minimizing job wait time and maximizing utilization. Recent\nresearch efforts have focused on leveraging advancements in Reinforcement\nLearning (RL) to develop more adaptable and intelligent scheduling strategies.\nRecent RL-based scheduling approaches have explored a range of algorithms, from\nDeep Q-Networks (DQN) to Proximal Policy Optimization (PPO), and more recently,\nhybrid methods that integrate Graph Neural Networks with RL techniques.\nHowever, a common limitation across these methods is their reliance on\nrelatively small datasets, and these methods face scalability issues when using\nlarge datasets. This study introduces a novel RL-based scheduler utilizing the\nDecentralized Distributed Proximal Policy Optimization (DD-PPO) algorithm,\nwhich supports large-scale distributed training across multiple workers without\nrequiring parameter synchronization at every step. By eliminating reliance on\ncentralized updates to a shared policy, the DD-PPO scheduler enhances\nscalability, training efficiency, and sample utilization. The validation\ndataset leveraged over 11.5 million real HPC job traces for comparing DD-PPO\nperformance between traditional and advanced scheduling approaches, and the\nexperimental results demonstrate improved scheduling performance in comparison\nto both rule-based schedulers and existing RL-based scheduling algorithms.", "published": "2025-05-06 19:50:37", "link": "http://arxiv.org/abs/2505.03946v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "AI-Driven Security in Cloud Computing: Enhancing Threat Detection, Automated Response, and Cyber Resilience", "abstract": "Cloud security concerns have been greatly realized in recent years due to the\nincrease of complicated threats in the computing world. Many traditional\nsolutions do not work well in real-time to detect or prevent more complex\nthreats. Artificial intelligence is today regarded as a revolution in\ndetermining a protection plan for cloud data architecture through machine\nlearning, statistical visualization of computing infrastructure, and detection\nof security breaches followed by counteraction. These AI-enabled systems make\nwork easier as more network activities are scrutinized, and any anomalous\nbehavior that might be a precursor to a more serious breach is prevented. This\npaper examines ways AI can enhance cloud security by applying predictive\nanalytics, behavior-based security threat detection, and AI-stirring\nencryption. It also outlines the problems of the previous security models and\nhow AI overcomes them. For a similar reason, issues like data privacy, biases\nin the AI model, and regulatory compliance are also covered. So, AI improves\nthe protection of cloud computing contexts; however, more efforts are needed in\nthe subsequent phases to extend the technology's reliability, modularity, and\nethical aspects. This means that AI can be blended with other new computing\ntechnologies, including blockchain, to improve security frameworks further. The\npaper discusses the current trends in securing cloud data architecture using AI\nand presents further research and application directions.", "published": "2025-05-06 19:45:13", "link": "http://arxiv.org/abs/2505.03945v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "GRAML: Dynamic Goal Recognition As Metric Learning", "abstract": "Goal Recognition (GR) is the problem of recognizing an agent's objectives\nbased on observed actions. Recent data-driven approaches for GR alleviate the\nneed for costly, manually crafted domain models. However, these approaches can\nonly reason about a pre-defined set of goals, and time-consuming training is\nneeded for new emerging goals. To keep this model-learning automated while\nenabling quick adaptation to new goals, this paper introduces GRAML: Goal\nRecognition As Metric Learning. GRAML uses a Siamese network to treat GR as a\ndeep metric learning task, employing an RNN that learns a metric over an\nembedding space, where the embeddings for observation traces leading to\ndifferent goals are distant, and embeddings of traces leading to the same goals\nare close. This metric is especially useful when adapting to new goals, even if\ngiven just one example observation trace per goal. Evaluated on a versatile set\nof environments, GRAML shows speed, flexibility, and runtime improvements over\nthe state-of-the-art GR while maintaining accurate recognition.", "published": "2025-05-06 19:38:07", "link": "http://arxiv.org/abs/2505.03941v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Graphical Global Optimization Framework for Parameter Estimation of Statistical Models with Nonconvex Regularization Functions", "abstract": "Optimization problems with norm-bounding constraints arise in a variety of\napplications, including portfolio optimization, machine learning, and feature\nselection. A common approach to these problems involves relaxing the norm\nconstraint via Lagrangian relaxation, transforming it into a regularization\nterm in the objective function. A particularly challenging class includes the\nzero-norm function, which promotes sparsity in statistical parameter\nestimation. Most existing exact methods for solving these problems introduce\nbinary variables and artificial bounds to reformulate them as\nhigher-dimensional mixed-integer programs, solvable by standard solvers. Other\nexact approaches exploit specific structural properties of the objective,\nmaking them difficult to generalize across different problem types. Alternative\nmethods employ nonconvex penalties with favorable statistical characteristics,\nbut these are typically addressed using heuristic or local optimization\ntechniques due to their structural complexity. In this paper, we propose a\nnovel graph-based method to globally solve optimization problems involving\ngeneralized norm-bounding constraints. Our approach encompasses standard\n$\\ell_p$-norms for $p \\in [0, \\infty)$ and nonconvex penalties such as SCAD and\nMCP. We leverage decision diagrams to construct strong convex relaxations\ndirectly in the original variable space, eliminating the need for auxiliary\nvariables or artificial bounds. Integrated into a spatial branch-and-cut\nframework, our method guarantees convergence to the global optimum. We\ndemonstrate its effectiveness through preliminary computational experiments on\nbenchmark sparse linear regression problems involving complex nonconvex\npenalties, which are not tractable using existing global optimization\ntechniques.", "published": "2025-05-06 18:09:54", "link": "http://arxiv.org/abs/2505.03899v1", "categories": ["math.OC", "cs.AI", "math.ST", "stat.TH"], "primary_category": "math.OC"}
{"title": "Novel Extraction of Discriminative Fine-Grained Feature to Improve Retinal Vessel Segmentation", "abstract": "Retinal vessel segmentation is a vital early detection method for several\nsevere ocular diseases. Despite significant progress in retinal vessel\nsegmentation with the advancement of Neural Networks, there are still\nchallenges to overcome. Specifically, retinal vessel segmentation aims to\npredict the class label for every pixel within a fundus image, with a primary\nfocus on intra-image discrimination, making it vital for models to extract more\ndiscriminative features. Nevertheless, existing methods primarily focus on\nminimizing the difference between the output from the decoder and the label,\nbut ignore fully using feature-level fine-grained representations from the\nencoder. To address these issues, we propose a novel Attention U-shaped\nKolmogorov-Arnold Network named AttUKAN along with a novel Label-guided\nPixel-wise Contrastive Loss for retinal vessel segmentation. Specifically, we\nimplement Attention Gates into Kolmogorov-Arnold Networks to enhance model\nsensitivity by suppressing irrelevant feature activations and model\ninterpretability by non-linear modeling of KAN blocks. Additionally, we also\ndesign a novel Label-guided Pixel-wise Contrastive Loss to supervise our\nproposed AttUKAN to extract more discriminative features by distinguishing\nbetween foreground vessel-pixel pairs and background pairs. Experiments are\nconducted across four public datasets including DRIVE, STARE, CHASE_DB1, HRF\nand our private dataset. AttUKAN achieves F1 scores of 82.50%, 81.14%, 81.34%,\n80.21% and 80.09%, along with MIoU scores of 70.24%, 68.64%, 68.59%, 67.21% and\n66.94% in the above datasets, which are the highest compared to 11 networks for\nretinal vessel segmentation. Quantitative and qualitative results show that our\nAttUKAN achieves state-of-the-art performance and outperforms existing retinal\nvessel segmentation methods. Our code will be available at\nhttps://github.com/stevezs315/AttUKAN.", "published": "2025-05-06 18:03:41", "link": "http://arxiv.org/abs/2505.03896v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Scratch Copilot: Supporting Youth Creative Coding with AI", "abstract": "Creative coding platforms like Scratch have democratized programming for\nchildren, yet translating imaginative ideas into functional code remains a\nsignificant hurdle for many young learners. While AI copilots assist adult\nprogrammers, few tools target children in block-based environments. Building on\nprior research \\cite{druga_how_2021,druga2023ai, druga2023scratch}, we present\nCognimates Scratch Copilot: an AI-powered assistant integrated into a\nScratch-like environment, providing real-time support for ideation, code\ngeneration, debugging, and asset creation. This paper details the system\narchitecture and findings from an exploratory qualitative evaluation with 18\ninternational children (ages 7--12). Our analysis reveals how the AI Copilot\nsupported key creative coding processes, particularly aiding ideation and\ndebugging. Crucially, it also highlights how children actively negotiated the\nuse of AI, demonstrating strong agency by adapting or rejecting suggestions to\nmaintain creative control. Interactions surfaced design tensions between\nproviding helpful scaffolding and fostering independent problem-solving, as\nwell as learning opportunities arising from navigating AI limitations and\nerrors. Findings indicate Cognimates Scratch Copilot's potential to enhance\ncreative self-efficacy and engagement. Based on these insights, we propose\ninitial design guidelines for AI coding assistants that prioritize youth agency\nand critical interaction alongside supportive scaffolding.", "published": "2025-05-06 17:13:29", "link": "http://arxiv.org/abs/2505.03867v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "From Glue-Code to Protocols: A Critical Analysis of A2A and MCP Integration for Scalable Agent Systems", "abstract": "Artificial intelligence is rapidly evolving towards multi-agent systems where\nnumerous AI agents collaborate and interact with external tools. Two key open\nstandards, Google's Agent to Agent (A2A) protocol for inter-agent communication\nand Anthropic's Model Context Protocol (MCP) for standardized tool access,\npromise to overcome the limitations of fragmented, custom integration\napproaches. While their potential synergy is significant, this paper argues\nthat effectively integrating A2A and MCP presents unique, emergent challenges\nat their intersection, particularly concerning semantic interoperability\nbetween agent tasks and tool capabilities, the compounded security risks\narising from combined discovery and execution, and the practical governance\nrequired for the envisioned \"Agent Economy\". This work provides a critical\nanalysis, moving beyond a survey to evaluate the practical implications and\ninherent difficulties of combining these horizontal and vertical integration\nstandards. We examine the benefits (e.g., specialization, scalability) while\ncritically assessing their dependencies and trade-offs in an integrated\ncontext. We identify key challenges increased by the integration, including\nnovel security vulnerabilities, privacy complexities, debugging difficulties\nacross protocols, and the need for robust semantic negotiation mechanisms. In\nsummary, A2A+MCP offers a vital architectural foundation, but fully realizing\nits potential requires substantial advancements to manage the complexities of\ntheir combined operation.", "published": "2025-05-06 16:40:39", "link": "http://arxiv.org/abs/2505.03864v1", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Data-Driven Falsification of Cyber-Physical Systems", "abstract": "Cyber-Physical Systems (CPS) are abundant in safety-critical domains such as\nhealthcare, avionics, and autonomous vehicles. Formal verification of their\noperational safety is, therefore, of utmost importance. In this paper, we\naddress the falsification problem, where the focus is on searching for an\nunsafe execution in the system instead of proving their absence. The\ncontribution of this paper is a framework that (a) connects the falsification\nof CPS with the falsification of deep neural networks (DNNs) and (b) leverages\nthe inherent interpretability of Decision Trees for faster falsification of\nCPS. This is achieved by: (1) building a surrogate model of the CPS under test,\neither as a DNN model or a Decision Tree, (2) application of various DNN\nfalsification tools to falsify CPS, and (3) a novel falsification algorithm\nguided by the explanations of safety violations of the CPS model extracted from\nits Decision Tree surrogate. The proposed framework has the potential to\nexploit a repertoire of \\emph{adversarial attack} algorithms designed to\nfalsify robustness properties of DNNs, as well as state-of-the-art\nfalsification algorithms for DNNs. Although the presented methodology is\napplicable to systems that can be executed/simulated in general, we demonstrate\nits effectiveness, particularly in CPS. We show that our framework, implemented\nas a tool \\textsc{FlexiFal}, can detect hard-to-find counterexamples in CPS\nthat have linear and non-linear dynamics. Decision tree-guided falsification\nshows promising results in efficiently finding multiple counterexamples in the\nARCH-COMP 2024 falsification benchmarks~\\cite{khandait2024arch}.", "published": "2025-05-06 16:33:06", "link": "http://arxiv.org/abs/2505.03863v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "The Eye as a Window to Systemic Health: A Survey of Retinal Imaging from Classical Techniques to Oculomics", "abstract": "The unique vascularized anatomy of the human eye, encased in the retina,\nprovides an opportunity to act as a window for human health. The retinal\nstructure assists in assessing the early detection, monitoring of disease\nprogression and intervention for both ocular and non-ocular diseases. The\nadvancement in imaging technology leveraging Artificial Intelligence has seized\nthis opportunity to bridge the gap between the eye and human health. This track\npaves the way for unveiling systemic health insight from the ocular system and\nsurrogating non-invasive markers for timely intervention and identification.\nThe new frontiers of oculomics in ophthalmology cover both ocular and systemic\ndiseases, and getting more attention to explore them. In this survey paper, we\nexplore the evolution of retinal imaging techniques, the dire need for the\nintegration of AI-driven analysis, and the shift of retinal imaging from\nclassical techniques to oculomics. We also discuss some hurdles that may be\nfaced in the progression of oculomics, highlighting the research gaps and\nfuture directions.", "published": "2025-05-06 22:35:54", "link": "http://arxiv.org/abs/2505.04006v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prototype-Based Information Compensation Network for Multi-Source Remote Sensing Data Classification", "abstract": "Multi-source remote sensing data joint classification aims to provide\naccuracy and reliability of land cover classification by leveraging the\ncomplementary information from multiple data sources. Existing methods confront\ntwo challenges: inter-frequency multi-source feature coupling and inconsistency\nof complementary information exploration. To solve these issues, we present a\nPrototype-based Information Compensation Network (PICNet) for land cover\nclassification based on HSI and SAR/LiDAR data. Specifically, we first design a\nfrequency interaction module to enhance the inter-frequency coupling in\nmulti-source feature extraction. The multi-source features are first decoupled\ninto high- and low-frequency components. Then, these features are recoupled to\nachieve efficient inter-frequency communication. Afterward, we design a\nprototype-based information compensation module to model the global\nmulti-source complementary information. Two sets of learnable modality\nprototypes are introduced to represent the global modality information of\nmulti-source data. Subsequently, cross-modal feature integration and alignment\nare achieved through cross-attention computation between the modality-specific\nprototype vectors and the raw feature representations. Extensive experiments on\nthree public datasets demonstrate the significant superiority of our PICNet\nover state-of-the-art methods. The codes are available at\nhttps://github.com/oucailab/PICNet.", "published": "2025-05-06 22:30:23", "link": "http://arxiv.org/abs/2505.04003v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Action Spotting and Precise Event Detection in Sports: Datasets, Methods, and Challenges", "abstract": "Video event detection has become an essential component of sports analytics,\nenabling automated identification of key moments and enhancing performance\nanalysis, viewer engagement, and broadcast efficiency. Recent advancements in\ndeep learning, particularly Convolutional Neural Networks (CNNs) and\nTransformers, have significantly improved accuracy and efficiency in Temporal\nAction Localization (TAL), Action Spotting (AS), and Precise Event Spotting\n(PES). This survey provides a comprehensive overview of these three key tasks,\nemphasizing their differences, applications, and the evolution of\nmethodological approaches. We thoroughly review and categorize existing\ndatasets and evaluation metrics specifically tailored for sports contexts,\nhighlighting the strengths and limitations of each. Furthermore, we analyze\nstate-of-the-art techniques, including multi-modal approaches that integrate\naudio and visual information, methods utilizing self-supervised learning and\nknowledge distillation, and approaches aimed at generalizing across multiple\nsports. Finally, we discuss critical open challenges and outline promising\nresearch directions toward developing more generalized, efficient, and robust\nevent detection frameworks applicable to diverse sports. This survey serves as\na foundation for future research on efficient, generalizable, and multi-modal\nsports event detection.", "published": "2025-05-06 22:02:30", "link": "http://arxiv.org/abs/2505.03991v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation", "abstract": "Dual-system VLA (Vision-Language-Action) architectures have become a hot\ntopic in embodied intelligence research, but there is a lack of sufficient\nopen-source work for further performance analysis and optimization. To address\nthis problem, this paper will summarize and compare the structural designs of\nexisting dual-system architectures, and conduct systematic empirical\nevaluations on the core design elements of existing dual-system architectures.\nUltimately, it will provide a low-cost open-source model for further\nexploration. Of course, this project will continue to update with more\nexperimental conclusions and open-source models with improved performance for\neveryone to choose from. Project page: https://openhelix-robot.github.io/.", "published": "2025-05-06 18:35:07", "link": "http://arxiv.org/abs/2505.03912v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Deepfakes on Demand: the rise of accessible non-consensual deepfake image generators", "abstract": "Advances in multimodal machine learning have made text-to-image (T2I) models\nincreasingly accessible and popular. However, T2I models introduce risks such\nas the generation of non-consensual depictions of identifiable individuals,\notherwise known as deepfakes. This paper presents an empirical study exploring\nthe accessibility of deepfake model variants online. Through a metadata\nanalysis of thousands of publicly downloadable model variants on two popular\nrepositories, Hugging Face and Civitai, we demonstrate a huge rise in easily\naccessible deepfake models. Almost 35,000 examples of publicly downloadable\ndeepfake model variants are identified, primarily hosted on Civitai. These\ndeepfake models have been downloaded almost 15 million times since November\n2022, with the models targeting a range of individuals from global celebrities\nto Instagram users with under 10,000 followers. Both Stable Diffusion and Flux\nmodels are used for the creation of deepfake models, with 96% of these\ntargeting women and many signalling intent to generate non-consensual intimate\nimagery (NCII). Deepfake model variants are often created via the\nparameter-efficient fine-tuning technique known as low rank adaptation (LoRA),\nrequiring as few as 20 images, 24GB VRAM, and 15 minutes of time, making this\nprocess widely accessible via consumer-grade computers. Despite these models\nviolating the Terms of Service of hosting platforms, and regulation seeking to\nprevent dissemination, these results emphasise the pressing need for greater\naction to be taken against the creation of deepfakes and NCII.", "published": "2025-05-06 15:00:59", "link": "http://arxiv.org/abs/2505.03859v1", "categories": ["cs.CY", "cs.AI", "cs.CV", "68T01"], "primary_category": "cs.CY"}
{"title": "SAT-Solving the Poset Cover Problem", "abstract": "The poset cover problem seeks a minimum set of partial orders whose linear\nextensions cover a given set of linear orders. Recognizing its NP-completeness,\nwe devised a non-trivial reduction to the Boolean satisfiability problem using\na technique we call swap graphs, which avoids the complexity explosion of the\nnaive method. By leveraging modern SAT solvers, we efficiently solve instances\nwith reasonable universe sizes. Experimental results using the Z3 theorem\nprover on randomly generated inputs demonstrate the effectiveness of our\nmethod.", "published": "2025-05-06 23:13:42", "link": "http://arxiv.org/abs/2505.04013v1", "categories": ["cs.LO", "cs.DM"], "primary_category": "cs.LO"}
{"title": "Hybrid Quantum-Classical Maximum-Likelihood Detection via Grover-based Adaptive Search for RIS-assisted Broadband Wireless Systems", "abstract": "The escalating complexity and stringent performance demands of\nsixth-generation wireless systems necessitate advanced signal processing\nmethods capable of simultaneously achieving high spectral efficiency and low\ncomputational complexity, especially under frequency-selective propagation\nconditions. In this paper, we propose a hybrid quantum-classical detection\nframework for broadband systems enhanced by reconfigurable intelligent surfaces\n(RISs). We address the maximum likelihood detection (MLD) problem for RIS-aided\nbroadband wireless communications by formulating it as a quadratic\nunconstrained binary optimization problem, that is then solved using Grover\nadaptive search (GAS). To accelerate convergence, we initialize the GAS\nalgorithm with a threshold based on a classical minimum mean-squared error\ndetector. The simulation results show that the proposed hybrid\nclassical-quantum detection scheme achieves near-optimal MLD performance while\nsubstantially reducing query complexity. These findings highlight the potential\nof quantum-enhanced detection strategies combined with RIS technology, offering\nefficient and near-optimal solutions for broadband wireless communications.", "published": "2025-05-06 18:40:40", "link": "http://arxiv.org/abs/2505.03914v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Variational Formulation of the Particle Flow Particle Filter", "abstract": "This paper provides a formulation of the particle flow particle filter from\nthe perspective of variational inference. We show that the transient density\nused to derive the particle flow particle filter follows a time-scaled\ntrajectory of the Fisher-Rao gradient flow in the space of probability\ndensities. The Fisher-Rao gradient flow is obtained as a continuous-time\nalgorithm for variational inference, minimizing the Kullback-Leibler divergence\nbetween a variational density and the true posterior density.", "published": "2025-05-06 22:44:55", "link": "http://arxiv.org/abs/2505.04007v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Iterative Orthogonalization Scaling Laws", "abstract": "The muon optimizer has picked up much attention as of late as a possible\nreplacement to the seemingly omnipresent Adam optimizer. Recently, care has\nbeen taken to document the scaling laws of hyper-parameters under muon such as\nweight decay and learning rate. However, at much larger scales the iterative\northogonalization procedure present in muon may suffer a possible issue as the\nsingular values of random matrices shrink with scale. This paper shows this\nscaling behavior theoretically and empirically on random matrices but does not\nsuggest what to do about it.", "published": "2025-05-06 22:34:55", "link": "http://arxiv.org/abs/2505.04005v1", "categories": ["cs.LG", "68T07"], "primary_category": "cs.LG"}
{"title": "Algorithmic Accountability in Small Data: Sample-Size-Induced Bias Within Classification Metrics", "abstract": "Evaluating machine learning models is crucial not only for determining their\ntechnical accuracy but also for assessing their potential societal\nimplications. While the potential for low-sample-size bias in algorithms is\nwell known, we demonstrate the significance of sample-size bias induced by\ncombinatorics in classification metrics. This revelation challenges the\nefficacy of these metrics in assessing bias with high resolution, especially\nwhen comparing groups of disparate sizes, which frequently arise in social\napplications. We provide analyses of the bias that appears in several commonly\napplied metrics and propose a model-agnostic assessment and correction\ntechnique. Additionally, we analyze counts of undefined cases in metric\ncalculations, which can lead to misleading evaluations if improperly handled.\nThis work illuminates the previously unrecognized challenge of combinatorics\nand probability in standard evaluation practices and thereby advances\napproaches for performing fair and trustworthy classification methods.", "published": "2025-05-06 22:02:53", "link": "http://arxiv.org/abs/2505.03992v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Comparing statistical and deep learning techniques for parameter estimation of continuous-time stochastic differentiable equations", "abstract": "Stochastic differential equations such as the Ornstein-Uhlenbeck process have\nlong been used to model realworld probablistic events such as stock prices and\ntemperature fluctuations. While statistical methods such as Maximum Likelihood\nEstimation (MLE), Kalman Filtering, Inverse Variable Method, and more have\nhistorically been used to estimate the parameters of stochastic differential\nequations, the recent explosion of deep learning technology suggests that\nmodels such as a Recurrent Neural Network (RNN) could produce more precise\nestimators. We present a series of experiments that compare the estimation\naccuracy and computational expensiveness of a statistical method (MLE) with a\ndeep learning model (RNN) for the parameters of the Ornstein-Uhlenbeck process.", "published": "2025-05-06 21:07:53", "link": "http://arxiv.org/abs/2505.03980v1", "categories": ["cs.LG", "math.PR"], "primary_category": "cs.LG"}
{"title": "Call for Action: towards the next generation of symbolic regression benchmark", "abstract": "Symbolic Regression (SR) is a powerful technique for discovering\ninterpretable mathematical expressions. However, benchmarking SR methods\nremains challenging due to the diversity of algorithms, datasets, and\nevaluation criteria. In this work, we present an updated version of SRBench.\nOur benchmark expands the previous one by nearly doubling the number of\nevaluated methods, refining evaluation metrics, and using improved\nvisualizations of the results to understand the performances. Additionally, we\nanalyze trade-offs between model complexity, accuracy, and energy consumption.\nOur results show that no single algorithm dominates across all datasets. We\npropose a call for action from SR community in maintaining and evolving SRBench\nas a living benchmark that reflects the state-of-the-art in symbolic\nregression, by standardizing hyperparameter tuning, execution constraints, and\ncomputational resource allocation. We also propose deprecation criteria to\nmaintain the benchmark's relevance and discuss best practices for improving SR\nalgorithms, such as adaptive hyperparameter tuning and energy-efficient\nimplementations.", "published": "2025-05-06 21:02:20", "link": "http://arxiv.org/abs/2505.03977v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Hierarchical Forecast Reconciliation on Networks: A Network Flow Optimization Formulation", "abstract": "Hierarchical forecasting with reconciliation requires forecasting values of a\nhierarchy (e.g.~customer demand in a state and district), such that forecast\nvalues are linked (e.g.~ district forecasts should add up to the state\nforecast). Basic forecasting provides no guarantee for these desired structural\nrelationships. Reconciliation addresses this problem, which is crucial for\norganizations requiring coherent predictions across multiple aggregation\nlevels. Current methods like minimum trace (MinT) are mostly limited to tree\nstructures and are computationally expensive. We introduce FlowRec, which\nreformulates hierarchical forecast reconciliation as a network flow\noptimization, enabling forecasting on generalized network structures. While\nreconciliation under the $\\ell_0$ norm is NP-hard, we prove polynomial-time\nsolvability for all $\\ell_{p > 0}$ norms and , for any strictly convex and\ncontinuously differentiable loss function. For sparse networks, FlowRec\nachieves $O(n^2\\log n)$ complexity, significantly improving upon MinT's\n$O(n^3)$. Furthermore, we prove that FlowRec extends MinT to handle general\nnetworks, replacing MinT's error-covariance estimation step with direct network\nstructural information. A key novelty of our approach is its handling of\ndynamic scenarios: while traditional methods recompute both base forecasts and\nreconciliation, FlowRec provides efficient localised updates with optimality\nguarantees. Monotonicity ensures that when forecasts improve incrementally, the\ninitial reconciliation remains optimal. We also establish efficient,\nerror-bounded approximate reconciliation, enabling fast updates in\ntime-critical applications. Experiments on both simulated and real benchmarks\ndemonstrate that FlowRec improves accuracy, runtime by 3-40x and memory usage\nby 5-7x. These results establish FlowRec as a powerful tool for large-scale\nhierarchical forecasting applications.", "published": "2025-05-06 20:16:28", "link": "http://arxiv.org/abs/2505.03955v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sufficient Decision Proxies for Decision-Focused Learning", "abstract": "When solving optimization problems under uncertainty with contextual data,\nutilizing machine learning to predict the uncertain parameters is a popular and\neffective approach. Decision-focused learning (DFL) aims at learning a\npredictive model such that decision quality, instead of prediction accuracy, is\nmaximized. Common practice here is to predict a single value for each uncertain\nparameter, implicitly assuming that there exists a (single-scenario)\ndeterministic problem approximation (proxy) that is sufficient to obtain an\noptimal decision. Other work assumes the opposite, where the underlying\ndistribution needs to be estimated. However, little is known about when either\nchoice is valid. This paper investigates for the first time problem properties\nthat justify using either assumption. Using this, we present effective decision\nproxies for DFL, with very limited compromise on the complexity of the learning\ntask. We show the effectiveness of presented approaches in experiments on\nproblems with continuous and discrete variables, as well as uncertainty in the\nobjective function and in the constraints.", "published": "2025-05-06 20:10:17", "link": "http://arxiv.org/abs/2505.03953v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Deep Q-Network (DQN) multi-agent reinforcement learning (MARL) for Stock Trading", "abstract": "This project addresses the challenge of automated stock trading, where\ntraditional methods and direct reinforcement learning (RL) struggle with market\nnoise, complexity, and generalization. Our proposed solution is an integrated\ndeep learning framework combining a Convolutional Neural Network (CNN) to\nidentify patterns in technical indicators formatted as images, a Long\nShort-Term Memory (LSTM) network to capture temporal dependencies across both\nprice history and technical indicators, and a Deep Q-Network (DQN) agent which\nlearns the optimal trading policy (buy, sell, hold) based on the features\nextracted by the CNN and LSTM.", "published": "2025-05-06 19:55:57", "link": "http://arxiv.org/abs/2505.03949v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SAND: One-Shot Feature Selection with Additive Noise Distortion", "abstract": "Feature selection is a critical step in data-driven applications, reducing\ninput dimensionality to enhance learning accuracy, computational efficiency,\nand interpretability. Existing state-of-the-art methods often require\npost-selection retraining and extensive hyperparameter tuning, complicating\ntheir adoption. We introduce a novel, non-intrusive feature selection layer\nthat, given a target feature count $k$, automatically identifies and selects\nthe $k$ most informative features during neural network training. Our method is\nuniquely simple, requiring no alterations to the loss function, network\narchitecture, or post-selection retraining. The layer is mathematically elegant\nand can be fully described by: \\begin{align} \\nonumber \\tilde{x}_i = a_i x_i +\n(1-a_i)z_i \\end{align} where $x_i$ is the input feature, $\\tilde{x}_i$ the\noutput, $z_i$ a Gaussian noise, and $a_i$ trainable gain such that\n$\\sum_i{a_i^2}=k$. This formulation induces an automatic clustering effect,\ndriving $k$ of the $a_i$ gains to $1$ (selecting informative features) and the\nrest to $0$ (discarding redundant ones) via weighted noise distortion and gain\nnormalization. Despite its extreme simplicity, our method delivers\nstate-of-the-art performance on standard benchmark datasets and a novel\nreal-world dataset, outperforming or matching existing approaches without\nrequiring hyperparameter search for $k$ or retraining. Theoretical analysis in\nthe context of linear regression further validates its efficacy. Our work\ndemonstrates that simplicity and performance are not mutually exclusive,\noffering a powerful yet straightforward tool for feature selection in machine\nlearning.", "published": "2025-05-06 18:59:35", "link": "http://arxiv.org/abs/2505.03923v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Explaining Anomalies with Tensor Networks", "abstract": "Tensor networks, a class of variational quantum many-body wave functions have\nattracted considerable research interest across many disciplines, including\nclassical machine learning. Recently, Aizpurua et al. demonstrated explainable\nanomaly detection with matrix product states on a discrete-valued\ncyber-security task, using quantum-inspired methods to gain insight into the\nlearned model and detected anomalies. Here, we extend this framework to\nreal-valued data domains. We furthermore introduce tree tensor networks for the\ntask of explainable anomaly detection. We demonstrate these methods with three\nbenchmark problems, show adequate predictive performance compared to several\nbaseline models and both tensor network architectures' ability to explain\nanomalous samples. We thereby extend the application of tensor networks to a\nbroader class of potential problems and open a pathway for future extensions to\nmore complex tensor network architectures.", "published": "2025-05-06 18:35:05", "link": "http://arxiv.org/abs/2505.03911v1", "categories": ["cs.LG", "quant-ph"], "primary_category": "cs.LG"}
{"title": "MARCO: A Multi-Agent System for Optimizing HPC Code Generation Using Large Language Models", "abstract": "Large language models (LLMs) have transformed software development through\ncode generation capabilities, yet their effectiveness for high-performance\ncomputing (HPC) remains limited. HPC code requires specialized optimizations\nfor parallelism, memory efficiency, and architecture-specific considerations\nthat general-purpose LLMs often overlook. We present MARCO (Multi-Agent\nReactive Code Optimizer), a novel framework that enhances LLM-generated code\nfor HPC through a specialized multi-agent architecture. MARCO employs separate\nagents for code generation and performance evaluation, connected by a feedback\nloop that progressively refines optimizations. A key innovation is MARCO's\nweb-search component that retrieves real-time optimization techniques from\nrecent conference proceedings and research publications, bridging the knowledge\ngap in pre-trained LLMs. Our extensive evaluation on the LeetCode 75 problem\nset demonstrates that MARCO achieves a 14.6% average runtime reduction compared\nto Claude 3.5 Sonnet alone, while the integration of the web-search component\nyields a 30.9% performance improvement over the base MARCO system. These\nresults highlight the potential of multi-agent systems to address the\nspecialized requirements of high-performance code generation, offering a\ncost-effective alternative to domain-specific model fine-tuning.", "published": "2025-05-06 18:22:38", "link": "http://arxiv.org/abs/2505.03906v1", "categories": ["cs.DC", "cs.LG", "cs.SE"], "primary_category": "cs.DC"}
{"title": "Recovery of the matrix potential of the one-dimensional Dirac equation from spectral data", "abstract": "A method for solving an inverse spectral problem for the one-dimensional\nDirac equation is developed. The method is based on the Gelfand-Levitan\nequation and the Fourier-Legendre series expansion of the transmutation kernel.\nA linear algebraic system of equations is obtained, which can be solved\nnumerically. To the best of our knowledge, this is the first practical method\nfor the solution of the inverse problem for the one-dimensional Dirac equation\non a finite interval.", "published": "2025-05-06 23:09:01", "link": "http://arxiv.org/abs/2505.04010v1", "categories": ["math.CA", "cs.NA", "math-ph", "math.MP", "math.NA", "34A25, 34A30, 34A45, 34A55, 34B30, 34L40, 33C45, 65L09, 65L60, 81Q05"], "primary_category": "math.CA"}
{"title": "Bridging the Gap Between Deterministic and Probabilistic Approaches to State Estimation", "abstract": "We consider the problem of state estimation from limited discrete and noisy\nmeasurements. In particular, we focus on modal state estimation, which\napproximates the unknown state of the system within a prescribed basis. We\nestimate the coefficients of the modal expansion using available observational\ndata. This is usually accomplished through two distinct frameworks. One is\ndeterministic and estimates the expansion coefficients by solving a\nleast-squares (LS) problem. The second is probabilistic and uses a Bayesian\napproach to derive a distribution for the coefficients, resulting in the\nmaximum-a-posteriori (MAP) estimate. Here, we seek to quantify and compare the\naccuracy of these two approaches. To this end, we derive a computable\nexpression for the difference in Bayes risk between the deterministic LS and\nthe Bayesian MAP estimates. We prove that this difference is always\nnonnegative, indicating that the MAP estimate is always more reliable than the\nLS estimate. We further show that this difference comprises two nonnegative\ncomponents representing measurement noise and prior uncertainty, and identify\nregimes where one component dominates the other in magnitude. We also derive a\nnovel prior distribution from the sample covariance matrix of the training\ndata, and examine the greedy Bayesian and column-pivoted QR (CPQR) sensor\nplacement algorithms with this prior as an input. Using numerical examples, we\nshow that the greedy Bayesian algorithm returns nearly optimal sensor\nlocations. We show that, under certain conditions, the greedy Bayesian sensor\nlocations are identical or nearly identical to those of CPQR when applied to a\nregularized modal basis.", "published": "2025-05-06 22:32:19", "link": "http://arxiv.org/abs/2505.04004v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Alternating projections between two inconsistent affine subspaces with varying relaxation", "abstract": "In a Hilbert space, we study the convergence in norm of alternating\nprojections between two inconsistent affine subspaces with varying relaxation\non one side.", "published": "2025-05-06 21:10:23", "link": "http://arxiv.org/abs/2505.03982v1", "categories": ["math.FA", "cs.NA", "math.NA", "G.1.2"], "primary_category": "math.FA"}
{"title": "Categorical and geometric methods in statistical, manifold, and machine learning", "abstract": "We present and discuss applications of the category of probabilistic\nmorphisms, initially developed in \\cite{Le2023}, as well as some geometric\nmethods to several classes of problems in statistical, machine and manifold\nlearning which shall be, along with many other topics, considered in depth in\nthe forthcoming book \\cite{LMPT2024}.", "published": "2025-05-06 16:27:06", "link": "http://arxiv.org/abs/2505.03862v1", "categories": ["stat.ML", "cs.LG", "math.CT", "math.DG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Machine Learning: a Lecture Note", "abstract": "This lecture note is intended to prepare early-year master's and PhD students\nin data science or a related discipline with foundational ideas in machine\nlearning. It starts with basic ideas in modern machine learning with\nclassification as a main target task. These basic ideas include loss\nformulation, backpropagation, stochastic gradient descent, generalization,\nmodel selection as well as fundamental blocks of artificial neural networks.\nBased on these basic ideas, the lecture note explores in depth the probablistic\napproach to unsupervised learning, covering directed latent variable models,\nproduct of experts, generative adversarial networks and autoregressive models.\nFinally, the note ends by covering a diverse set of further topics, such as\nreinforcement learning, ensemble methods and meta-learning. After reading this\nlecture note, a student should be ready to embark on studying and researching\nmore advanced topics in machine learning and more broadly artificial\nintelligence.", "published": "2025-05-06 16:03:41", "link": "http://arxiv.org/abs/2505.03861v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Modal Decomposition and Identification for a Population of Structures Using Physics-Informed Graph Neural Networks and Transformers", "abstract": "Modal identification is crucial for structural health monitoring and\nstructural control, providing critical insights into structural dynamics and\nperformance. This study presents a novel deep learning framework that\nintegrates graph neural networks (GNNs), transformers, and a physics-informed\nloss function to achieve modal decomposition and identification across a\npopulation of structures. The transformer module decomposes\nmulti-degrees-of-freedom (MDOF) structural dynamic measurements into\nsingle-degree-of-freedom (SDOF) modal responses, facilitating the\nidentification of natural frequencies and damping ratios. Concurrently, the GNN\ncaptures the structural configurations and identifies mode shapes corresponding\nto the decomposed SDOF modal responses. The proposed model is trained in a\npurely physics-informed and unsupervised manner, leveraging modal decomposition\ntheory and the independence of structural modes to guide learning without the\nneed for labeled data. Validation through numerical simulations and laboratory\nexperiments demonstrates its effectiveness in accurately decomposing dynamic\nresponses and identifying modal properties from sparse structural dynamic\nmeasurements, regardless of variations in external loads or structural\nconfigurations. Comparative analyses against established modal identification\ntechniques and model variations further underscore its superior performance,\npositioning it as a favorable approach for population-based structural health\nmonitoring.", "published": "2025-05-06 23:31:37", "link": "http://arxiv.org/abs/2505.04018v1", "categories": ["cs.CE", "eess.SP"], "primary_category": "cs.CE"}
{"title": "The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete", "abstract": "According to Yuval Noah Harari, large-scale human cooperation is driven by\nshared narratives that encode common beliefs and values. This study explores\nwhether such narratives can similarly nudge LLM agents toward collaboration. We\nuse a finitely repeated public goods game in which LLM agents choose either\ncooperative or egoistic spending strategies. We prime agents with stories\nhighlighting teamwork to different degrees and test how this influences\nnegotiation outcomes. Our experiments explore four questions:(1) How do\nnarratives influence negotiation behavior? (2) What differs when agents share\nthe same story versus different ones? (3) What happens when the agent numbers\ngrow? (4) Are agents resilient against self-serving negotiators? We find that\nstory-based priming significantly affects negotiation strategies and success\nrates. Common stories improve collaboration, benefiting each agent. By\ncontrast, priming agents with different stories reverses this effect, and those\nagents primed toward self-interest prevail. We hypothesize that these results\ncarry implications for multi-agent system design and AI alignment.", "published": "2025-05-06 20:23:25", "link": "http://arxiv.org/abs/2505.03961v2", "categories": ["cs.AI", "cs.CL", "cs.MA", "I.2.11; I.2.7; I.6; J.4"], "primary_category": "cs.AI"}
{"title": "An alignment safety case sketch based on debate", "abstract": "If AI systems match or exceed human capabilities on a wide range of tasks, it\nmay become difficult for humans to efficiently judge their actions -- making it\nhard to use human feedback to steer them towards desirable traits. One proposed\nsolution is to leverage another superhuman system to point out flaws in the\nsystem's outputs via a debate. This paper outlines the value of debate for AI\nsafety, as well as the assumptions and further research required to make debate\nwork. It does so by sketching an ``alignment safety case'' -- an argument that\nan AI system will not autonomously take actions which could lead to egregious\nharm, despite being able to do so. The sketch focuses on the risk of an AI R\\&D\nagent inside an AI company sabotaging research, for example by producing false\nresults. To prevent this, the agent is trained via debate, subject to\nexploration guarantees, to teach the system to be honest. Honesty is maintained\nthroughout deployment via online training. The safety case rests on four key\nclaims: (1) the agent has become good at the debate game, (2) good performance\nin the debate game implies that the system is mostly honest, (3) the system\nwill not become significantly less honest during deployment, and (4) the\ndeployment context is tolerant of some errors. We identify open research\nproblems that, if solved, could render this a compelling argument that an AI\nsystem is safe.", "published": "2025-05-06 21:53:44", "link": "http://arxiv.org/abs/2505.03989v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Demonstrating ViSafe: Vision-enabled Safety for High-speed Detect and Avoid", "abstract": "Assured safe-separation is essential for achieving seamless high-density\noperation of airborne vehicles in a shared airspace. To equip\nresource-constrained aerial systems with this safety-critical capability, we\npresent ViSafe, a high-speed vision-only airborne collision avoidance system.\nViSafe offers a full-stack solution to the Detect and Avoid (DAA) problem by\ntightly integrating a learning-based edge-AI framework with a custom\nmulti-camera hardware prototype designed under SWaP-C constraints. By\nleveraging perceptual input-focused control barrier functions (CBF) to design,\nencode, and enforce safety thresholds, ViSafe can provide provably safe runtime\nguarantees for self-separation in high-speed aerial operations. We evaluate\nViSafe's performance through an extensive test campaign involving both\nsimulated digital twins and real-world flight scenarios. By independently\nvarying agent types, closure rates, interaction geometries, and environmental\nconditions (e.g., weather and lighting), we demonstrate that ViSafe\nconsistently ensures self-separation across diverse scenarios. In\nfirst-of-its-kind real-world high-speed collision avoidance tests with closure\nrates reaching 144 km/h, ViSafe sets a new benchmark for vision-only autonomous\ncollision avoidance, establishing a new standard for safety in high-speed\naerial navigation.", "published": "2025-05-06 16:59:54", "link": "http://arxiv.org/abs/2505.03694v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Iterative Orthogonalization Scaling Laws", "abstract": "The muon optimizer has picked up much attention as of late as a possible\nreplacement to the seemingly omnipresent Adam optimizer. Recently, care has\nbeen taken to document the scaling laws of hyper-parameters under muon such as\nweight decay and learning rate. However, at much larger scales the iterative\northogonalization procedure present in muon may suffer a possible issue as the\nsingular values of random matrices shrink with scale. This paper shows this\nscaling behavior theoretically and empirically on random matrices but does not\nsuggest what to do about it.", "published": "2025-05-06 22:34:55", "link": "http://arxiv.org/abs/2505.04005v2", "categories": ["cs.LG", "68T07"], "primary_category": "cs.LG"}
