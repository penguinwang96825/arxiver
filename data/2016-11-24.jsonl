{"title": "User Personalized Satisfaction Prediction via Multiple Instance Deep\n  Learning", "abstract": "Community based question answering services have arisen as a popular\nknowledge sharing pattern for netizens. With abundant interactions among users,\nindividuals are capable of obtaining satisfactory information. However, it is\nnot effective for users to attain answers within minutes. Users have to check\nthe progress over time until the satisfying answers submitted. We address this\nproblem as a user personalized satisfaction prediction task. Existing methods\nusually exploit manual feature selection. It is not desirable as it requires\ncareful design and is labor intensive. In this paper, we settle this issue by\ndeveloping a new multiple instance deep learning framework. Specifically, in\nour settings, each question follows a weakly supervised learning multiple\ninstance learning assumption, where its obtained answers can be regarded as\ninstance sets and we define the question resolved with at least one\nsatisfactory answer. We thus design an efficient framework exploiting multiple\ninstance learning property with deep learning to model the question answer\npairs. Extensive experiments on large scale datasets from Stack Exchange\ndemonstrate the feasibility of our proposed framework in predicting askers\npersonalized satisfaction. Our framework can be extended to numerous\napplications such as UI satisfaction Prediction, multi armed bandit problem,\nexpert finding and so on.", "published": "2016-11-24 08:43:03", "link": "http://arxiv.org/abs/1611.08096v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Question Retrieval for Community-based Question Answering via\n  Heterogeneous Network Integration Learning", "abstract": "Community based question answering platforms have attracted substantial users\nto share knowledge and learn from each other. As the rapid enlargement of CQA\nplatforms, quantities of overlapped questions emerge, which makes users\nconfounded to select a proper reference. It is urgent for us to take effective\nautomated algorithms to reuse historical questions with corresponding answers.\nIn this paper we focus on the problem with question retrieval, which aims to\nmatch historical questions that are relevant or semantically equivalent to\nresolve one s query directly. The challenges in this task are the lexical gaps\nbetween questions for the word ambiguity and word mismatch problem.\nFurthermore, limited words in queried sentences cause sparsity of word\nfeatures. To alleviate these challenges, we propose a novel framework named\nHNIL which encodes not only the question contents but also the askers social\ninteractions to enhance the question embedding performance. More specifically,\nwe apply random walk based learning method with recurrent neural network to\nmatch the similarities between askers question and historical questions\nproposed by other users. Extensive experiments on a large scale dataset from a\nreal world CQA site show that employing the heterogeneous social network\ninformation outperforms the other state of the art solutions in this task.", "published": "2016-11-24 11:01:32", "link": "http://arxiv.org/abs/1611.08135v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Learning Python Code Suggestion with a Sparse Pointer Network", "abstract": "To enhance developer productivity, all modern integrated development\nenvironments (IDEs) include code suggestion functionality that proposes likely\nnext tokens at the cursor. While current IDEs work well for statically-typed\nlanguages, their reliance on type annotations means that they do not provide\nthe same level of support for dynamic programming languages as for\nstatically-typed languages. Moreover, suggestion engines in modern IDEs do not\npropose expressions or multi-statement idiomatic code. Recent work has shown\nthat language models can improve code suggestion systems by learning from\nsoftware repositories. This paper introduces a neural language model with a\nsparse pointer network aimed at capturing very long-range dependencies. We\nrelease a large-scale code suggestion corpus of 41M lines of Python code\ncrawled from GitHub. On this corpus, we found standard neural language models\nto perform well at suggesting local phenomena, but struggle to refer to\nidentifiers that are introduced many tokens in the past. By augmenting a neural\nlanguage model with a pointer network specialized in referring to predefined\nclasses of identifiers, we obtain a much lower perplexity and a 5 percentage\npoints increase in accuracy for code suggestion compared to an LSTM baseline.\nIn fact, this increase in code suggestion accuracy is due to a 13 times more\naccurate prediction of identifiers. Furthermore, a qualitative analysis shows\nthis model indeed captures interesting long-range dependencies, like referring\nto a class member defined over 60 tokens in the past.", "published": "2016-11-24 21:01:46", "link": "http://arxiv.org/abs/1611.08307v1", "categories": ["cs.NE", "cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.NE"}
{"title": "Training and Evaluating Multimodal Word Embeddings with Large-scale Web\n  Annotated Images", "abstract": "In this paper, we focus on training and evaluating effective word embeddings\nwith both text and visual information. More specifically, we introduce a\nlarge-scale dataset with 300 million sentences describing over 40 million\nimages crawled and downloaded from publicly available Pins (i.e. an image with\nsentence descriptions uploaded by users) on Pinterest. This dataset is more\nthan 200 times larger than MS COCO, the standard large-scale image dataset with\nsentence descriptions. In addition, we construct an evaluation dataset to\ndirectly assess the effectiveness of word embeddings in terms of finding\nsemantically similar or related words and phrases. The word/phrase pairs in\nthis evaluation dataset are collected from the click data with millions of\nusers in an image search system, thus contain rich semantic relationships.\nBased on these datasets, we propose and compare several Recurrent Neural\nNetworks (RNNs) based multimodal (text and image) models. Experiments show that\nour model benefits from incorporating the visual information into the word\nembeddings, and a weight sharing strategy is crucial for learning such\nmultimodal embeddings. The project page is:\nhttp://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html", "published": "2016-11-24 23:15:56", "link": "http://arxiv.org/abs/1611.08321v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "I.2.6; I.2.7; I.2.10"], "primary_category": "cs.LG"}
