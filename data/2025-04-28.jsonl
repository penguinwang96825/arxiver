{"title": "AutoJudge: Judge Decoding Without Manual Annotation", "abstract": "We introduce AutoJudge, a framework that accelerates large language model\n(LLM) inference with task-specific lossy speculative decoding. Instead of\nmatching the original model output distribution token-by-token, we identify\nwhich of the generated tokens affect the downstream quality of the generated\nresponse, relaxing the guarantee so that the \"unimportant\" tokens can be\ngenerated faster. Our approach relies on a semi-greedy search algorithm to test\nwhich of the mismatches between target and draft model should be corrected to\npreserve quality, and which ones may be skipped. We then train a lightweight\nclassifier based on existing LLM embeddings to predict, at inference time,\nwhich mismatching tokens can be safely accepted without compromising the final\nanswer quality. We test our approach with Llama 3.2 1B (draft) and Llama 3.1 8B\n(target) models on zero-shot GSM8K reasoning, where it achieves up to 1.5x more\naccepted tokens per verification cycle with under 1% degradation in answer\naccuracy compared to standard speculative decoding and over 2x with small loss\nin accuracy. When applied to the LiveCodeBench benchmark, our approach\nautomatically detects other, programming-specific important tokens and shows\nsimilar speedups, demonstrating its ability to generalize across tasks.", "published": "2025-04-28 17:59:28", "link": "http://arxiv.org/abs/2504.20039v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Better To Ask in English? Evaluating Factual Accuracy of Multilingual LLMs in English and Low-Resource Languages", "abstract": "Multilingual Large Language Models (LLMs) have demonstrated significant\neffectiveness across various languages, particularly in high-resource languages\nsuch as English. However, their performance in terms of factual accuracy across\nother low-resource languages, especially Indic languages, remains an area of\ninvestigation. In this study, we assess the factual accuracy of LLMs - GPT-4o,\nGemma-2-9B, Gemma-2-2B, and Llama-3.1-8B - by comparing their performance in\nEnglish and Indic languages using the IndicQuest dataset, which contains\nquestion-answer pairs in English and 19 Indic languages. By asking the same\nquestions in English and their respective Indic translations, we analyze\nwhether the models are more reliable for regional context questions in Indic\nlanguages or when operating in English. Our findings reveal that LLMs often\nperform better in English, even for questions rooted in Indic contexts.\nNotably, we observe a higher tendency for hallucination in responses generated\nin low-resource Indic languages, highlighting challenges in the multilingual\nunderstanding capabilities of current LLMs.", "published": "2025-04-28 17:48:13", "link": "http://arxiv.org/abs/2504.20022v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation", "abstract": "Online fake news moderation now faces a new challenge brought by the\nmalicious use of large language models (LLMs) in fake news production. Though\nexisting works have shown LLM-generated fake news is hard to detect from an\nindividual aspect, it remains underexplored how its large-scale release will\nimpact the news ecosystem. In this study, we develop a simulation pipeline and\na dataset with ~56k generated news of diverse types to investigate the effects\nof LLM-generated fake news within neural news recommendation systems. Our\nfindings expose a truth decay phenomenon, where real news is gradually losing\nits advantageous position in news ranking against fake news as LLM-generated\nnews is involved in news recommendation. We further provide an explanation\nabout why truth decay occurs from a familiarity perspective and show the\npositive correlation between perplexity and news ranking. Finally, we discuss\nthe threats of LLM-generated fake news and provide possible countermeasures. We\nurge stakeholders to address this emerging challenge to preserve the integrity\nof news ecosystems.", "published": "2025-04-28 17:32:38", "link": "http://arxiv.org/abs/2504.20013v1", "categories": ["cs.CL", "cs.CY", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Knowledge Distillation of Domain-adapted LLMs for Question-Answering in Telecom", "abstract": "Knowledge Distillation (KD) is one of the approaches to reduce the size of\nLarge Language Models (LLMs). A LLM with smaller number of model parameters\n(student) is trained to mimic the performance of a LLM of a larger size\n(teacher model) on a specific task. For domain-specific tasks, it is not clear\nif teacher or student model, or both, must be considered for domain adaptation.\nIn this work, we study this problem from perspective of telecom domain\nQuestion-Answering (QA) task. We systematically experiment with Supervised\nFine-tuning (SFT) of teacher only, SFT of student only and SFT of both prior to\nKD. We design experiments to study the impact of vocabulary (same and\ndifferent) and KD algorithms (vanilla KD and Dual Space KD, DSKD) on the\ndistilled model. Multi-faceted evaluation of the distillation using 14\ndifferent metrics (N-gram, embedding and LLM-based metrics) is considered.\nExperimental results show that SFT of teacher improves performance of distilled\nmodel when both models have same vocabulary, irrespective of algorithm and\nmetrics. Overall, SFT of both teacher and student results in better performance\nacross all metrics, although the statistical significance of the same depends\non the vocabulary of the teacher models.", "published": "2025-04-28 17:19:25", "link": "http://arxiv.org/abs/2504.20000v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons", "abstract": "Task-oriented dialogue (TOD) systems are experiencing a revolution driven by\nLarge Language Models (LLMs), yet the evaluation methodologies for these\nsystems remain insufficient for their growing sophistication. While traditional\nautomatic metrics effectively assessed earlier modular systems, they focus\nsolely on the dialogue level and cannot detect critical intermediate errors\nthat can arise during user-agent interactions. In this paper, we introduce\nTD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework\nthat unifies fine-grained turn-level analysis with holistic dialogue-level\ncomparisons. At turn level, we evaluate each response along three TOD-specific\ndimensions: conversation cohesion, backend knowledge consistency, and policy\ncompliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons\nto provide a measure of dialogue-level quality. Through experiments on MultiWOZ\n2.4 and {\\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the\nconversational errors that conventional metrics miss. Furthermore, TD-EVAL\nexhibits better alignment with human judgments than traditional and LLM-based\nmetrics. These findings demonstrate that TD-EVAL introduces a new paradigm for\nTOD system evaluation, efficiently assessing both turn and system levels with a\nplug-and-play framework for future research.", "published": "2025-04-28 16:57:17", "link": "http://arxiv.org/abs/2504.19982v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GenCLS++: Pushing the Boundaries of Generative Classification in LLMs Through Comprehensive SFT and RL Studies Across Diverse Datasets", "abstract": "As a fundamental task in machine learning, text classification plays a\ncrucial role in many areas. With the rapid scaling of Large Language Models\n(LLMs), particularly through reinforcement learning (RL), there is a growing\nneed for more capable discriminators. Consequently, advances in classification\nare becoming increasingly vital for enhancing the overall capabilities of LLMs.\nTraditional discriminative methods map text to labels but overlook LLMs'\nintrinsic generative strengths. Generative classification addresses this by\nprompting the model to directly output labels. However, existing studies still\nrely on simple SFT alone, seldom probing the interplay between training and\ninference prompts, and no work has systematically leveraged RL for generative\ntext classifiers and unified SFT, RL, and inference-time prompting in one\nframework. We bridge this gap with GenCLS++, a framework that jointly optimizes\nSFT and RL while systematically exploring five high-level strategy\ndimensions-in-context learning variants, category definitions, explicit\nuncertainty labels, semantically irrelevant numeric labels, and\nperplexity-based decoding-during both training and inference. After an SFT\n\"policy warm-up,\" we apply RL with a simple rule-based reward, yielding sizable\nextra gains. Across seven datasets, GenCLS++ achieves an average accuracy\nimprovement of 3.46% relative to the naive SFT baseline; on public datasets,\nthis improvement rises to 4.00%. Notably, unlike reasoning-intensive tasks that\nbenefit from explicit thinking processes, we find that classification tasks\nperform better without such reasoning steps. These insights into the role of\nexplicit reasoning provide valuable guidance for future LLM applications.", "published": "2025-04-28 15:30:58", "link": "http://arxiv.org/abs/2504.19898v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "semi-PD: Towards Efficient LLM Serving via Phase-Wise Disaggregated Computation and Unified Storage", "abstract": "Existing large language model (LLM) serving systems fall into two categories:\n1) a unified system where prefill phase and decode phase are co-located on the\nsame GPU, sharing the unified computational resource and storage, and 2) a\ndisaggregated system where the two phases are disaggregated to different GPUs.\nThe design of the disaggregated system addresses the latency interference and\nsophisticated scheduling issues in the unified system but leads to storage\nchallenges including 1) replicated weights for both phases that prevent\nflexible deployment, 2) KV cache transfer overhead between the two phases, 3)\nstorage imbalance that causes substantial wasted space of the GPU capacity, and\n4) suboptimal resource adjustment arising from the difficulties in migrating KV\ncache. Such storage inefficiency delivers poor serving performance under high\nrequest rates.\n  In this paper, we identify that the advantage of the disaggregated system\nlies in the disaggregated computation, i.e., partitioning the computational\nresource to enable the asynchronous computation of two phases. Thus, we propose\na novel LLM serving system, semi-PD, characterized by disaggregated computation\nand unified storage. In semi-PD, we introduce a computation resource controller\nto achieve disaggregated computation at the streaming multi-processor (SM)\nlevel, and a unified memory manager to manage the asynchronous memory access\nfrom both phases. semi-PD has a low-overhead resource adjustment mechanism\nbetween the two phases, and a service-level objective (SLO) aware dynamic\npartitioning algorithm to optimize the SLO attainment. Compared to\nstate-of-the-art systems, semi-PD maintains lower latency at higher request\nrates, reducing the average end-to-end latency per request by 1.27-2.58x on\nDeepSeek series models, and serves 1.55-1.72x more requests adhering to latency\nconstraints on Llama series models.", "published": "2025-04-28 15:00:03", "link": "http://arxiv.org/abs/2504.19867v1", "categories": ["cs.CL", "cs.DC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Domain-adaptive Continual Pretraining for the Process Industry in the German Language", "abstract": "Domain-adaptive continual pretraining (DAPT) is a state-of-the-art technique\nthat further trains a language model (LM) on its pretraining task, e.g.,\nlanguage masking. Although popular, it requires a significant corpus of\ndomain-related data, which is difficult to obtain for specific domains in\nlanguages other than English, such as the process industry in the German\nlanguage. This paper introduces an efficient approach called ICL-augmented\npretraining or ICL-APT that leverages in-context learning (ICL) and k-nearest\nneighbors (kNN) to augment target data with domain-related and in-domain texts,\nsignificantly reducing GPU time while maintaining strong model performance. Our\nresults show that this approach performs better than traditional DAPT by 3.5 of\nthe average IR metrics (e.g., mAP, MRR, and nDCG) and requires almost 4 times\nless computing time, providing a cost-effective solution for industries with\nlimited computational capacity. The findings highlight the broader\napplicability of this framework to other low-resource industries, making\nNLP-based solutions more accessible and feasible in production environments.", "published": "2025-04-28 14:49:00", "link": "http://arxiv.org/abs/2504.19856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "To MT or not to MT: An eye-tracking study on the reception by Dutch readers of different translation and creativity levels", "abstract": "This article presents the results of a pilot study involving the reception of\na fictional short story translated from English into Dutch under four\nconditions: machine translation (MT), post-editing (PE), human translation (HT)\nand original source text (ST). The aim is to understand how creativity and\nerrors in different translation modalities affect readers, specifically\nregarding cognitive load. Eight participants filled in a questionnaire, read a\nstory using an eye-tracker, and conducted a retrospective think-aloud (RTA)\ninterview. The results show that units of creative potential (UCP) increase\ncognitive load and that this effect is highest for HT and lowest for MT; no\neffect of error was observed. Triangulating the data with RTAs leads us to\nhypothesize that the higher cognitive load in UCPs is linked to increases in\nreader enjoyment and immersion. The effect of translation creativity on\ncognitive load in different translation modalities at word-level is novel and\nopens up new avenues for further research. All the code and data are available\nat https://github.com/INCREC/Pilot_to_MT_or_not_to_MT", "published": "2025-04-28 14:45:56", "link": "http://arxiv.org/abs/2504.19850v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can a Crow Hatch a Falcon? Lineage Matters in Predicting Large Language Model Performance", "abstract": "Accurately forecasting the performance of Large Language Models (LLMs) before\nextensive fine-tuning or merging can substantially reduce both computational\nexpense and development time. Although prior approaches like scaling laws\naccount for global factors such as parameter size or training tokens, they\noften overlook explicit lineage relationships - i.e., which models are derived\nor merged from which parents. In this work, we propose a novel\nLineage-Regularized Matrix Factorization (LRMF) framework that encodes\nancestral ties among LLMs via a graph Laplacian regularizer. By leveraging\nmulti-hop parent-child connections, LRMF consistently outperforms conventional\nmatrix factorization and collaborative filtering methods in both instance-level\nand benchmark-level performance prediction. Our large-scale study includes\n2,934 publicly available Hugging Face models and 21,000+ instances across 6\nmajor benchmarks, showing that lineage constraints yield up to 7-10 percentage\npoints higher correlation with actual performance compared to baselines.\nMoreover, LRMF effectively addresses the cold-start problem, providing accurate\nestimates for newly derived or merged models even with minimal data. This\nlineage-guided strategy thus offers a resource-efficient way to inform\nhyperparameter tuning, data selection, and model combination in modern LLM\ndevelopment.", "published": "2025-04-28 14:08:45", "link": "http://arxiv.org/abs/2504.19811v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Moral Reasoning Across Languages: The Critical Role of Low-Resource Languages in LLMs", "abstract": "In this paper, we introduce the Multilingual Moral Reasoning Benchmark (MMRB)\nto evaluate the moral reasoning abilities of large language models (LLMs)\nacross five typologically diverse languages and three levels of contextual\ncomplexity: sentence, paragraph, and document. Our results show moral reasoning\nperformance degrades with increasing context complexity, particularly for\nlow-resource languages such as Vietnamese. We further fine-tune the open-source\nLLaMA-3-8B model using curated monolingual data for alignment and poisoning.\nSurprisingly, low-resource languages have a stronger impact on multilingual\nreasoning than high-resource ones, highlighting their critical role in\nmultilingual NLP.", "published": "2025-04-28 12:56:36", "link": "http://arxiv.org/abs/2504.19759v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reconstructing Context: Evaluating Advanced Chunking Strategies for Retrieval-Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) has become a transformative approach for\nenhancing large language models (LLMs) by grounding their outputs in external\nknowledge sources. Yet, a critical question persists: how can vast volumes of\nexternal knowledge be managed effectively within the input constraints of LLMs?\nTraditional methods address this by chunking external documents into smaller,\nfixed-size segments. While this approach alleviates input limitations, it often\nfragments context, resulting in incomplete retrieval and diminished coherence\nin generation. To overcome these shortcomings, two advanced techniques, late\nchunking and contextual retrieval, have been introduced, both aiming to\npreserve global context. Despite their potential, their comparative strengths\nand limitations remain unclear. This study presents a rigorous analysis of late\nchunking and contextual retrieval, evaluating their effectiveness and\nefficiency in optimizing RAG systems. Our results indicate that contextual\nretrieval preserves semantic coherence more effectively but requires greater\ncomputational resources. In contrast, late chunking offers higher efficiency\nbut tends to sacrifice relevance and completeness.", "published": "2025-04-28 12:52:05", "link": "http://arxiv.org/abs/2504.19754v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "LLM-Assisted Automated Deductive Coding of Dialogue Data: Leveraging Dialogue-Specific Characteristics to Enhance Contextual Understanding", "abstract": "Dialogue data has been a key source for understanding learning processes,\noffering critical insights into how students engage in collaborative\ndiscussions and how these interactions shape their knowledge construction. The\nadvent of Large Language Models (LLMs) has introduced promising opportunities\nfor advancing qualitative research, particularly in the automated coding of\ndialogue data. However, the inherent contextual complexity of dialogue presents\nunique challenges for these models, especially in understanding and\ninterpreting complex contextual information. This study addresses these\nchallenges by developing a novel LLM-assisted automated coding approach for\ndialogue data. The novelty of our proposed framework is threefold: 1) We\npredict the code for an utterance based on dialogue-specific characteristics --\ncommunicative acts and communicative events -- using separate prompts following\nthe role prompts and chain-of-thoughts methods; 2) We engaged multiple LLMs\nincluding GPT-4-turbo, GPT-4o, DeepSeek in collaborative code prediction; 3) We\nleveraged the interrelation between events and acts to implement consistency\nchecking using GPT-4o. In particular, our contextual consistency checking\nprovided a substantial accuracy improvement. We also found the accuracy of act\npredictions was consistently higher than that of event predictions. This study\ncontributes a new methodological framework for enhancing the precision of\nautomated coding of dialogue data as well as offers a scalable solution for\naddressing the contextual challenges inherent in dialogue analysis.", "published": "2025-04-28 12:31:38", "link": "http://arxiv.org/abs/2504.19734v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Evaluate-and-Purify: Fortifying Code Language Models Against Adversarial Attacks Using LLM-as-a-Judge", "abstract": "The widespread adoption of code language models in software engineering tasks\nhas exposed vulnerabilities to adversarial attacks, especially the identifier\nsubstitution attacks. Although existing identifier substitution attackers\ndemonstrate high success rates, they often produce adversarial examples with\nunnatural code patterns. In this paper, we systematically assess the quality of\nadversarial examples using LLM-as-a-Judge. Our analysis reveals that over 80%\nof adversarial examples generated by state-of-the-art identifier substitution\nattackers (e.g., ALERT) are actually detectable. Based on this insight, we\npropose EP-Shield, a unified framework for evaluating and purifying identifier\nsubstitution attacks via naturalness-aware reasoning. Specifically, we first\nevaluate the naturalness of code and identify the perturbed adversarial code,\nthen purify it so that the victim model can restore correct prediction.\nExtensive experiments demonstrate the superiority of EP-Shield over adversarial\nfine-tuning (up to 83.36% improvement) and its lightweight design 7B\nparameters) with GPT-4-level performance.", "published": "2025-04-28 12:28:55", "link": "http://arxiv.org/abs/2504.19730v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Taming the Titans: A Survey of Efficient LLM Inference Serving", "abstract": "Large Language Models (LLMs) for Generative AI have achieved remarkable\nprogress, evolving into sophisticated and versatile tools widely adopted across\nvarious domains and applications. However, the substantial memory overhead\ncaused by their vast number of parameters, combined with the high computational\ndemands of the attention mechanism, poses significant challenges in achieving\nlow latency and high throughput for LLM inference services. Recent\nadvancements, driven by groundbreaking research, have significantly accelerated\nprogress in this field. This paper provides a comprehensive survey of these\nmethods, covering fundamental instance-level approaches, in-depth cluster-level\nstrategies, emerging scenario directions, and other miscellaneous but important\nareas. At the instance level, we review model placement, request scheduling,\ndecoding length prediction, storage management, and the disaggregation\nparadigm. At the cluster level, we explore GPU cluster deployment,\nmulti-instance load balancing, and cloud service solutions. For emerging\nscenarios, we organize the discussion around specific tasks, modules, and\nauxiliary methods. To ensure a holistic overview, we also highlight several\nniche yet critical areas. Finally, we outline potential research directions to\nfurther advance the field of LLM inference serving.", "published": "2025-04-28 12:14:02", "link": "http://arxiv.org/abs/2504.19720v1", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Annif at SemEval-2025 Task 5: Traditional XMTC augmented by LLMs", "abstract": "This paper presents the Annif system in SemEval-2025 Task 5 (LLMs4Subjects),\nwhich focussed on subject indexing using large language models (LLMs). The task\nrequired creating subject predictions for bibliographic records from the\nbilingual TIBKAT database using the GND subject vocabulary. Our approach\ncombines traditional natural language processing and machine learning\ntechniques implemented in the Annif toolkit with innovative LLM-based methods\nfor translation and synthetic data generation, and merging predictions from\nmonolingual models. The system ranked first in the all-subjects category and\nsecond in the tib-core-subjects category in the quantitative evaluation, and\nfourth in qualitative evaluations. These findings demonstrate the potential of\ncombining traditional XMTC algorithms with modern LLM techniques to improve the\naccuracy and efficiency of subject indexing in multilingual contexts.", "published": "2025-04-28 11:04:23", "link": "http://arxiv.org/abs/2504.19675v1", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.IR", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Multimodal Conditioned Diffusive Time Series Forecasting", "abstract": "Diffusion models achieve remarkable success in processing images and text,\nand have been extended to special domains such as time series forecasting\n(TSF). Existing diffusion-based approaches for TSF primarily focus on modeling\nsingle-modality numerical sequences, overlooking the rich multimodal\ninformation in time series data. To effectively leverage such information for\nprediction, we propose a multimodal conditioned diffusion model for TSF,\nnamely, MCD-TSF, to jointly utilize timestamps and texts as extra guidance for\ntime series modeling, especially for forecasting. Specifically, Timestamps are\ncombined with time series to establish temporal and semantic correlations among\ndifferent data points when aggregating information along the temporal\ndimension. Texts serve as supplementary descriptions of time series' history,\nand adaptively aligned with data points as well as dynamically controlled in a\nclassifier-free manner. Extensive experiments on real-world benchmark datasets\nacross eight domains demonstrate that the proposed MCD-TSF model achieves\nstate-of-the-art performance.", "published": "2025-04-28 10:56:23", "link": "http://arxiv.org/abs/2504.19669v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Part-of-Speech Tagging to Standardize Central-Kurdish Language: A Research Guide for Kurdish Natural Language Processing Tasks", "abstract": "- The field of natural language processing (NLP) has dramatically expanded\nwithin the last decade. Many human-being applications are conducted daily via\nNLP tasks, starting from machine translation, speech recognition, text\ngeneration and recommendations, Part-of-Speech tagging (POS), and Named-Entity\nRecognition (NER). However, low-resourced languages, such as the\nCentral-Kurdish language (CKL), mainly remain unexamined due to shortage of\nnecessary resources to support their development. The POS tagging task is the\nbase of other NLP tasks; for example, the POS tag set has been used to\nstandardized languages to provide the relationship between words among the\nsentences, followed by machine translation and text recommendation.\nSpecifically, for the CKL, most of the utilized or provided POS tagsets are\nneither standardized nor comprehensive. To this end, this study presented an\naccurate and comprehensive POS tagset for the CKL to provide better performance\nof the Kurdish NLP tasks. The article also collected most of the POS tags from\ndifferent studies as well as from Kurdish linguistic experts to standardized\npart-of-speech tags. The proposed POS tagset is designed to annotate a large\nCKL corpus and support Kurdish NLP tasks. The initial investigations of this\nstudy via comparison with the Universal Dependencies framework for standard\nlanguages, show that the proposed POS tagset can streamline or correct\nsentences more accurately for Kurdish NLP tasks.", "published": "2025-04-28 10:02:11", "link": "http://arxiv.org/abs/2504.19645v1", "categories": ["cs.CL", "cs.AI", "K.5; K.7; J.7"], "primary_category": "cs.CL"}
{"title": "VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning", "abstract": "Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks like\nembodied intelligence due to their strong vision-language reasoning abilities.\nHowever, current LVLMs process entire images at the token level, which is\ninefficient compared to humans who analyze information and generate content at\nthe conceptual level, extracting relevant visual concepts with minimal effort.\nThis inefficiency, stemming from the lack of a visual concept model, limits\nLVLMs' usability in real-world applications. To address this, we propose VCM,\nan end-to-end self-supervised visual concept modeling framework. VCM leverages\nimplicit contrastive learning across multiple sampled instances and\nvision-language fine-tuning to construct a visual concept model without\nrequiring costly concept-level annotations. Our results show that VCM\nsignificantly reduces computational costs (e.g., 85\\% fewer FLOPs for\nLLaVA-1.5-7B) while maintaining strong performance across diverse image\nunderstanding tasks. Moreover, VCM enhances visual encoders' capabilities in\nclassic visual concept perception tasks. Extensive quantitative and qualitative\nexperiments validate the effectiveness and efficiency of VCM.", "published": "2025-04-28 09:39:07", "link": "http://arxiv.org/abs/2504.19627v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Coreference Resolution for Vietnamese Narrative Texts", "abstract": "Coreference resolution is a vital task in natural language processing (NLP)\nthat involves identifying and linking different expressions in a text that\nrefer to the same entity. This task is particularly challenging for Vietnamese,\na low-resource language with limited annotated datasets. To address these\nchallenges, we developed a comprehensive annotated dataset using narrative\ntexts from VnExpress, a widely-read Vietnamese online news platform. We\nestablished detailed guidelines for annotating entities, focusing on ensuring\nconsistency and accuracy. Additionally, we evaluated the performance of large\nlanguage models (LLMs), specifically GPT-3.5-Turbo and GPT-4, on this dataset.\nOur results demonstrate that GPT-4 significantly outperforms GPT-3.5-Turbo in\nterms of both accuracy and response consistency, making it a more reliable tool\nfor coreference resolution in Vietnamese.", "published": "2025-04-28 09:10:41", "link": "http://arxiv.org/abs/2504.19606v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Arabic Metaphor Sentiment Classification Using Semantic Information", "abstract": "In this paper, I discuss the testing of the Arabic Metaphor Corpus (AMC) [1]\nusing newly designed automatic tools for sentiment classification for AMC based\non semantic tags. The tool incorporates semantic emotional tags for sentiment\nclassification. I evaluate the tool using standard methods, which are F-score,\nrecall, and precision. The method is to show the impact of Arabic online\nmetaphors on sentiment through the newly designed tools. To the best of our\nknowledge, this is the first approach to conduct sentiment classification for\nArabic metaphors using semantic tags to find the impact of the metaphor.", "published": "2025-04-28 08:53:28", "link": "http://arxiv.org/abs/2504.19590v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graph-Based Spectral Decomposition for Parameter Coordination in Language Model Fine-Tuning", "abstract": "This paper proposes a parameter collaborative optimization algorithm for\nlarge language models, enhanced with graph spectral analysis. The goal is to\nimprove both fine-tuning efficiency and structural awareness during training.\nIn the proposed method, the parameters of a pre-trained language model are\ntreated as nodes in a graph. A weighted graph is constructed, and Laplacian\nspectral decomposition is applied to enable frequency-domain modeling and\nstructural representation of the parameter space. Based on this structure, a\njoint loss function is designed. It combines the task loss with a spectral\nregularization term to facilitate collaborative updates among parameters. In\naddition, a spectral filtering mechanism is introduced during the optimization\nphase. This mechanism adjusts gradients in a structure-aware manner, enhancing\nthe model's training stability and convergence behavior. The method is\nevaluated on multiple tasks, including traditional fine-tuning comparisons,\nfew-shot generalization tests, and convergence speed analysis. In all settings,\nthe proposed approach demonstrates superior performance. The experimental\nresults confirm that the spectral collaborative optimization framework\neffectively reduces parameter perturbations and improves fine-tuning quality\nwhile preserving overall model performance. This work contributes significantly\nto the field of artificial intelligence by advancing parameter-efficient\ntraining methodologies for large-scale models, reinforcing the importance of\nstructural signal processing in deep learning optimization, and offering a\nrobust, generalizable framework for enhancing language model adaptability and\nperformance.", "published": "2025-04-28 08:42:35", "link": "http://arxiv.org/abs/2504.19583v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training", "abstract": "The rapid progress of large language models (LLMs) in biomedical research has\nunderscored the limitations of existing open-source annotated scientific\ncorpora, which are often insufficient in quantity and quality. Addressing the\nchallenge posed by the complex hierarchy of biomedical knowledge, we propose a\nknowledge-driven, multi-agent framework for scientific corpus distillation\ntailored for LLM training in the biomedical domain. Central to our approach is\na collaborative multi-agent architecture, where specialized agents, each guided\nby the Medical Subject Headings (MeSH) hierarchy, work in concert to\nautonomously extract, synthesize, and self-evaluate high-quality textual data\nfrom vast scientific literature. These agents collectively generate and refine\ndomain-specific question-answer pairs, ensuring comprehensive coverage and\nconsistency with biomedical ontologies while minimizing manual involvement.\nExtensive experimental results show that language models trained on our\nmulti-agent distilled datasets achieve notable improvements in biomedical\nquestion-answering tasks, outperforming both strong life sciences LLM baselines\nand advanced proprietary models. Notably, our AI-Ready dataset enables\nLlama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger\nscale. Detailed ablation studies and case analyses further validate the\neffectiveness and synergy of each agent within the framework, highlighting the\npotential of multi-agent collaboration in biomedical LLM training.", "published": "2025-04-28 08:18:24", "link": "http://arxiv.org/abs/2504.19565v1", "categories": ["cs.CL", "cs.AI", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "Detecting Effects of AI-Mediated Communication on Language Complexity and Sentiment", "abstract": "Given the subtle human-like effects of large language models on linguistic\npatterns, this study examines shifts in language over time to detect the impact\nof AI-mediated communication (AI- MC) on social media. We compare a replicated\ndataset of 970,919 tweets from 2020 (pre-ChatGPT) with 20,000 tweets from the\nsame period in 2024, all of which mention Donald Trump during election periods.\nUsing a combination of Flesch-Kincaid readability and polarity scores, we\nanalyze changes in text complexity and sentiment. Our findings reveal a\nsignificant increase in mean sentiment polarity (0.12 vs. 0.04) and a shift\nfrom predominantly neutral content (54.8% in 2020 to 39.8% in 2024) to more\npositive expressions (28.6% to 45.9%). These findings suggest not only an\nincreasing presence of AI in social media communication but also its impact on\nlanguage and emotional expression patterns.", "published": "2025-04-28 08:01:38", "link": "http://arxiv.org/abs/2504.19556v1", "categories": ["cs.CL", "cs.HC", "J.4; K.4.0; I.2.7"], "primary_category": "cs.CL"}
{"title": "FlashOverlap: A Lightweight Design for Efficiently Overlapping Communication and Computation", "abstract": "Generative models have achieved remarkable success across various\napplications, driving the demand for multi-GPU computing. Inter-GPU\ncommunication becomes a bottleneck in multi-GPU computing systems, particularly\non consumer-grade GPUs. By exploiting concurrent hardware execution,\noverlapping computation and communication latency is an effective technique for\nmitigating the communication overhead. We identify that an efficient and\nadaptable overlapping design should satisfy (1) tile-wise overlapping to\nmaximize the overlapping opportunity, (2) interference-free computation to\nmaintain the original computational performance, and (3) communication\nagnosticism to reduce the development burden against varying communication\nprimitives. Nevertheless, current designs fail to simultaneously optimize for\nall of those features.\n  To address the issue, we propose FlashOverlap, a lightweight design\ncharacterized by tile-wise overlapping, interference-free computation, and\ncommunication agnosticism. FlashOverlap utilizes a novel signaling mechanism to\nidentify tile-wise data dependency without interrupting the computation\nprocess, and reorders data to contiguous addresses, enabling communication by\nsimply calling NCCL APIs. Experiments show that such a lightweight design\nachieves up to 1.65x speedup, outperforming existing works in most cases.", "published": "2025-04-28 06:37:57", "link": "http://arxiv.org/abs/2504.19519v1", "categories": ["cs.DC", "cs.CL", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Masked Point-Entity Contrast for Open-Vocabulary 3D Scene Understanding", "abstract": "Open-vocabulary 3D scene understanding is pivotal for enhancing physical\nintelligence, as it enables embodied agents to interpret and interact\ndynamically within real-world environments. This paper introduces MPEC, a novel\nMasked Point-Entity Contrastive learning method for open-vocabulary 3D semantic\nsegmentation that leverages both 3D entity-language alignment and point-entity\nconsistency across different point cloud views to foster entity-specific\nfeature representations. Our method improves semantic discrimination and\nenhances the differentiation of unique instances, achieving state-of-the-art\nresults on ScanNet for open-vocabulary 3D semantic segmentation and\ndemonstrating superior zero-shot scene understanding capabilities. Extensive\nfine-tuning experiments on 8 datasets, spanning from low-level perception to\nhigh-level reasoning tasks, showcase the potential of learned 3D features,\ndriving consistent performance gains across varied 3D scene understanding\ntasks. Project website: https://mpec-3d.github.io/", "published": "2025-04-28 05:43:14", "link": "http://arxiv.org/abs/2504.19500v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Improving Reasoning Performance in Large Language Models via Representation Engineering", "abstract": "Recent advancements in large language models (LLMs) have resulted in\nincreasingly anthropomorphic language concerning the ability of LLMs to reason.\nWhether reasoning in LLMs should be understood to be inherently different is,\nhowever, widely debated. We propose utilizing a representation engineering\napproach wherein model activations are read from the residual stream of an LLM\nwhen processing a reasoning task. The activations are used to derive a control\nvector that is applied to the model as an inference-time intervention,\nmodulating the representational space of the model, to improve performance on\nthe specified task. We publish the code for deriving control vectors and\nanalyzing model representations. The method allows us to improve performance on\nreasoning benchmarks and assess how control vectors influence the final logit\ndistribution of a model via metrics such as KL divergence and entropy. We apply\ncontrol vectors to Mistral-7B-Instruct and a range of Pythia models on an\ninductive, a deductive and mathematical reasoning task. We show that an LLM\ncan, to a certain degree, be controlled to improve its perceived reasoning\nability by modulating activations. The intervention is dependent upon the\nability to reliably extract the model's typical state when correctly solving a\ntask. Our results suggest that reasoning performance can be modulated in the\nsame manner as other information-processing tasks performed by LLMs and\ndemonstrate that we are capable of improving performance on specific tasks via\na simple intervention on the residual stream with no additional training.", "published": "2025-04-28 04:58:43", "link": "http://arxiv.org/abs/2504.19483v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Conflicts in Texts: Data, Implications and Challenges", "abstract": "As NLP models become increasingly integrated into real-world applications, it\nbecomes clear that there is a need to address the fact that models often rely\non and generate conflicting information. Conflicts could reflect the complexity\nof situations, changes that need to be explained and dealt with, difficulties\nin data annotation, and mistakes in generated outputs. In all cases,\ndisregarding the conflicts in data could result in undesired behaviors of\nmodels and undermine NLP models' reliability and trustworthiness. This survey\ncategorizes these conflicts into three key areas: (1) natural texts on the web,\nwhere factual inconsistencies, subjective biases, and multiple perspectives\nintroduce contradictions; (2) human-annotated data, where annotator\ndisagreements, mistakes, and societal biases impact model training; and (3)\nmodel interactions, where hallucinations and knowledge conflicts emerge during\ndeployment. While prior work has addressed some of these conflicts in\nisolation, we unify them under the broader concept of conflicting information,\nanalyze their implications, and discuss mitigation strategies. We highlight key\nchallenges and future directions for developing conflict-aware NLP systems that\ncan reason over and reconcile conflicting information more effectively.", "published": "2025-04-28 04:24:01", "link": "http://arxiv.org/abs/2504.19472v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text", "abstract": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, current evaluations of LLMs in clinical contexts remain limited. Most\nexisting benchmarks rely on medical exam-style questions or PubMed-derived\ntext, failing to capture the complexity of real-world electronic health record\n(EHR) data. Others focus narrowly on specific application scenarios, limiting\ntheir generalizability across broader clinical use. To address this gap, we\npresent BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks\nsourced from real-world clinical data sources across nine languages. We\nsystematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,\nGPT-4o, Gemini, and Llama 4) under various inference strategies. With a total\nof 13,572 experiments, our results reveal substantial performance variation\nacross model sizes, languages, natural language processing tasks, and clinical\nspecialties. Notably, we demonstrate that open-source LLMs can achieve\nperformance comparable to proprietary models, while medically fine-tuned LLMs\nbased on older architectures often underperform versus updated general-purpose\nmodels. The BRIDGE and its corresponding leaderboard serve as a foundational\nresource and a unique reference for the development and evaluation of new LLMs\nin real-world clinical text understanding.", "published": "2025-04-28 04:13:18", "link": "http://arxiv.org/abs/2504.19467v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mitigating Modality Bias in Multi-modal Entity Alignment from a Causal Perspective", "abstract": "Multi-Modal Entity Alignment (MMEA) aims to retrieve equivalent entities from\ndifferent Multi-Modal Knowledge Graphs (MMKGs), a critical information\nretrieval task. Existing studies have explored various fusion paradigms and\nconsistency constraints to improve the alignment of equivalent entities, while\noverlooking that the visual modality may not always contribute positively.\nEmpirically, entities with low-similarity images usually generate\nunsatisfactory performance, highlighting the limitation of overly relying on\nvisual features. We believe the model can be biased toward the visual modality,\nleading to a shortcut image-matching task. To address this, we propose a\ncounterfactual debiasing framework for MMEA, termed CDMEA, which investigates\nvisual modality bias from a causal perspective. Our approach aims to leverage\nboth visual and graph modalities to enhance MMEA while suppressing the direct\ncausal effect of the visual modality on model predictions. By estimating the\nTotal Effect (TE) of both modalities and excluding the Natural Direct Effect\n(NDE) of the visual modality, we ensure that the model predicts based on the\nTotal Indirect Effect (TIE), effectively utilizing both modalities and reducing\nvisual modality bias. Extensive experiments on 9 benchmark datasets show that\nCDMEA outperforms 14 state-of-the-art methods, especially in low-similarity,\nhigh-noise, and low-resource data scenarios.", "published": "2025-04-28 03:48:23", "link": "http://arxiv.org/abs/2504.19458v1", "categories": ["cs.MM", "cs.CL", "cs.IR"], "primary_category": "cs.MM"}
{"title": "Towards Long Context Hallucination Detection", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious tasks. However, they are prone to contextual hallucination, generating\ninformation that is either unsubstantiated or contradictory to the given\ncontext. Although many studies have investigated contextual hallucinations in\nLLMs, addressing them in long-context inputs remains an open problem. In this\nwork, we take an initial step toward solving this problem by constructing a\ndataset specifically designed for long-context hallucination detection.\nFurthermore, we propose a novel architecture that enables pre-trained encoder\nmodels, such as BERT, to process long contexts and effectively detect\ncontextual hallucinations through a decomposition and aggregation mechanism.\nOur experimental results show that the proposed architecture significantly\noutperforms previous models of similar size as well as LLM-based models across\nvarious metrics, while providing substantially faster inference.", "published": "2025-04-28 03:47:05", "link": "http://arxiv.org/abs/2504.19457v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Systematic Bias in Large Language Models: Discrepant Response Patterns in Binary vs. Continuous Judgment Tasks", "abstract": "Large Language Models (LLMs) are increasingly used in tasks such as\npsychological text analysis and decision-making in automated workflows.\nHowever, their reliability remains a concern due to potential biases inherited\nfrom their training process. In this study, we examine how different response\nformat: binary versus continuous, may systematically influence LLMs' judgments.\nIn a value statement judgments task and a text sentiment analysis task, we\nprompted LLMs to simulate human responses and tested both formats across\nseveral models, including both open-source and commercial models. Our findings\nrevealed a consistent negative bias: LLMs were more likely to deliver\n\"negative\" judgments in binary formats compared to continuous ones. Control\nexperiments further revealed that this pattern holds across both tasks. Our\nresults highlight the importance of considering response format when applying\nLLMs to decision tasks, as small changes in task design can introduce\nsystematic biases.", "published": "2025-04-28 03:20:55", "link": "http://arxiv.org/abs/2504.19445v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models are Qualified Benchmark Builders: Rebuilding Pre-Training Datasets for Advancing Code Intelligence Tasks", "abstract": "Pre-trained code models rely heavily on high-quality pre-training data,\nparticularly human-written reference comments that bridge code and natural\nlanguage. However, these comments often become outdated as software evolves,\ndegrading model performance. Large language models (LLMs) excel at generating\nhigh-quality code comments. We investigate whether replacing human-written\ncomments with LLM-generated ones improves pre-training datasets. Since standard\nmetrics cannot assess reference comment quality, we propose two novel\nreference-free evaluation tasks: code-comment inconsistency detection and\nsemantic code search. Results show that LLM-generated comments are more\nsemantically consistent with code than human-written ones, as confirmed by\nmanual evaluation. Leveraging this finding, we rebuild the CodeSearchNet\ndataset with LLM-generated comments and re-pre-train CodeT5. Evaluations\ndemonstrate that models trained on LLM-enhanced data outperform those using\noriginal human comments in code summarization, generation, and translation\ntasks. This work validates rebuilding pre-training datasets with LLMs to\nadvance code intelligence, challenging the traditional reliance on human\nreference comments.", "published": "2025-04-28 03:16:34", "link": "http://arxiv.org/abs/2504.19444v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Context-Guided Dynamic Retrieval for Improving Generation Quality in RAG Models", "abstract": "This paper focuses on the dynamic optimization of the Retrieval-Augmented\nGeneration (RAG) architecture. It proposes a state-aware dynamic knowledge\nretrieval mechanism to enhance semantic understanding and knowledge scheduling\nefficiency in large language models for open-domain question answering and\ncomplex generation tasks. The method introduces a multi-level perceptive\nretrieval vector construction strategy and a differentiable document matching\npath. These components enable end-to-end joint training and collaborative\noptimization of the retrieval and generation modules. This effectively\naddresses the limitations of static RAG structures in context adaptation and\nknowledge access. Experiments are conducted on the Natural Questions dataset.\nThe proposed structure is thoroughly evaluated across different large models,\nincluding GPT-4, GPT-4o, and DeepSeek. Comparative and ablation experiments\nfrom multiple perspectives confirm the significant improvements in BLEU and\nROUGE-L scores. The approach also demonstrates stronger robustness and\ngeneration consistency in tasks involving semantic ambiguity and multi-document\nfusion. These results highlight its broad application potential and practical\nvalue in building high-quality language generation systems.", "published": "2025-04-28 02:50:45", "link": "http://arxiv.org/abs/2504.19436v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory", "abstract": "Large Language Models (LLMs) have demonstrated remarkable prowess in\ngenerating contextually coherent responses, yet their fixed context windows\npose fundamental challenges for maintaining consistency over prolonged\nmulti-session dialogues. We introduce Mem0, a scalable memory-centric\narchitecture that addresses this issue by dynamically extracting,\nconsolidating, and retrieving salient information from ongoing conversations.\nBuilding on this foundation, we further propose an enhanced variant that\nleverages graph-based memory representations to capture complex relational\nstructures among conversational elements. Through comprehensive evaluations on\nLOCOMO benchmark, we systematically compare our approaches against six baseline\ncategories: (i) established memory-augmented systems, (ii) retrieval-augmented\ngeneration (RAG) with varying chunk sizes and k-values, (iii) a full-context\napproach that processes the entire conversation history, (iv) an open-source\nmemory solution, (v) a proprietary model system, and (vi) a dedicated memory\nmanagement platform. Empirical results show that our methods consistently\noutperform all existing memory systems across four question categories:\nsingle-hop, temporal, multi-hop, and open-domain. Notably, Mem0 achieves 26%\nrelative improvements in the LLM-as-a-Judge metric over OpenAI, while Mem0 with\ngraph memory achieves around 2% higher overall score than the base\nconfiguration. Beyond accuracy gains, we also markedly reduce computational\noverhead compared to full-context method. In particular, Mem0 attains a 91%\nlower p95 latency and saves more than 90% token cost, offering a compelling\nbalance between advanced reasoning capabilities and practical deployment\nconstraints. Our findings highlight critical role of structured, persistent\nmemory mechanisms for long-term conversational coherence, paving the way for\nmore reliable and efficient LLM-driven AI agents.", "published": "2025-04-28 01:46:35", "link": "http://arxiv.org/abs/2504.19413v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Context Selection and Rewriting for Video-based EducationalQuestion Generation", "abstract": "Educational question generation (EQG) is a crucial component of intelligent\neducational systems, significantly aiding self-assessment, active learning, and\npersonalized education. While EQG systems have emerged, existing datasets\ntypically rely on predefined, carefully edited texts, failing to represent\nreal-world classroom content, including lecture speech with a set of\ncomplementary slides. To bridge this gap, we collect a dataset of educational\nquestions based on lectures from real-world classrooms. On this realistic\ndataset, we find that current methods for EQG struggle with accurately\ngenerating questions from educational videos, particularly in aligning with\nspecific timestamps and target answers. Common challenges include selecting\ninformative contexts from extensive transcripts and ensuring generated\nquestions meaningfully incorporate the target answer. To address the\nchallenges, we introduce a novel framework utilizing large language models for\ndynamically selecting and rewriting contexts based on target timestamps and\nanswers. First, our framework selects contexts from both lecture transcripts\nand video keyframes based on answer relevance and temporal proximity. Then, we\nintegrate the contexts selected from both modalities and rewrite them into\nanswer-containing knowledge statements, to enhance the logical connection\nbetween the contexts and the desired answer. This approach significantly\nimproves the quality and relevance of the generated questions. Our dataset and\ncode are released in https://github.com/mengxiayu/COSER.", "published": "2025-04-28 01:18:08", "link": "http://arxiv.org/abs/2504.19406v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ICL CIPHERS: Quantifying \"Learning'' in In-Context Learning via Substitution Ciphers", "abstract": "Recent works have suggested that In-Context Learning (ICL) operates in dual\nmodes, i.e. task retrieval (remember learned patterns from pre-training) and\ntask learning (inference-time ``learning'' from demonstrations). However,\ndisentangling these the two modes remains a challenging goal. We introduce ICL\nCIPHERS, a class of task reformulations based on substitution ciphers borrowed\nfrom classic cryptography. In this approach, a subset of tokens in the\nin-context inputs are substituted with other (irrelevant) tokens, rendering\nEnglish sentences less comprehensible to human eye. However, by design, there\nis a latent, fixed pattern to this substitution, making it reversible. This\nbijective (reversible) cipher ensures that the task remains a well-defined task\nin some abstract sense, despite the transformations. It is a curious question\nif LLMs can solve ICL CIPHERS with a BIJECTIVE mapping, which requires\ndeciphering the latent cipher. We show that LLMs are better at solving ICL\nCIPHERS with BIJECTIVE mappings than the NON-BIJECTIVE (irreversible) baseline,\nproviding a novel approach to quantify ``learning'' in ICL. While this gap is\nsmall, it is consistent across the board on four datasets and six models.\nFinally, we examine LLMs' internal representations and identify evidence in\ntheir ability to decode the ciphered inputs.", "published": "2025-04-28 00:05:29", "link": "http://arxiv.org/abs/2504.19395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields", "abstract": "We present Large Inverse Rendering Model (LIRM), a transformer architecture\nthat jointly reconstructs high-quality shape, materials, and radiance fields\nwith view-dependent effects in less than a second. Our model builds upon the\nrecent Large Reconstruction Models (LRMs) that achieve state-of-the-art\nsparse-view reconstruction quality. However, existing LRMs struggle to\nreconstruct unseen parts accurately and cannot recover glossy appearance or\ngenerate relightable 3D contents that can be consumed by standard Graphics\nengines. To address these limitations, we make three key technical\ncontributions to build a more practical multi-view 3D reconstruction framework.\nFirst, we introduce an update model that allows us to progressively add more\ninput views to improve our reconstruction. Second, we propose a hexa-plane\nneural SDF representation to better recover detailed textures, geometry and\nmaterial parameters. Third, we develop a novel neural directional-embedding\nmechanism to handle view-dependent effects. Trained on a large-scale shape and\nmaterial dataset with a tailored coarse-to-fine training scheme, our model\nachieves compelling results. It compares favorably to optimization-based\ndense-view inverse rendering methods in terms of geometry and relighting\naccuracy, while requiring only a fraction of the inference time.", "published": "2025-04-28 17:48:58", "link": "http://arxiv.org/abs/2504.20026v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models", "abstract": "Large language models (LLMs) have dramatically advanced machine learning\nresearch including natural language processing, computer vision, data mining,\netc., yet they still exhibit critical limitations in reasoning, factual\nconsistency, and interpretability. In this paper, we introduce a novel learning\nparadigm -- Modular Machine Learning (MML) -- as an essential approach toward\nnew-generation LLMs. MML decomposes the complex structure of LLMs into three\ninterdependent components: modular representation, modular model, and modular\nreasoning, aiming to enhance LLMs' capability of counterfactual reasoning,\nmitigating hallucinations, as well as promoting fairness, safety, and\ntransparency. Specifically, the proposed MML paradigm can: i) clarify the\ninternal working mechanism of LLMs through the disentanglement of semantic\ncomponents; ii) allow for flexible and task-adaptive model design; iii) enable\ninterpretable and logic-driven decision-making process. We present a feasible\nimplementation of MML-based LLMs via leveraging advanced techniques such as\ndisentangled representation learning, neural architecture search and\nneuro-symbolic learning. We critically identify key challenges, such as the\nintegration of continuous neural and discrete symbolic processes, joint\noptimization, and computational scalability, present promising future research\ndirections that deserve further exploration. Ultimately, the integration of the\nMML paradigm with LLMs has the potential to bridge the gap between statistical\n(deep) learning and formal (logical) reasoning, thereby paving the way for\nrobust, adaptable, and trustworthy AI systems across a wide range of real-world\napplications.", "published": "2025-04-28 17:42:02", "link": "http://arxiv.org/abs/2504.20020v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Modelling of Underwater Vehicles using Physics-Informed Neural Networks with Control", "abstract": "Physics-informed neural networks (PINNs) integrate physical laws with\ndata-driven models to improve generalization and sample efficiency. This work\nintroduces an open-source implementation of the Physics-Informed Neural Network\nwith Control (PINC) framework, designed to model the dynamics of an underwater\nvehicle. Using initial states, control actions, and time inputs, PINC extends\nPINNs to enable physically consistent transitions beyond the training domain.\nVarious PINC configurations are tested, including differing loss functions,\ngradient-weighting schemes, and hyperparameters. Validation on a simulated\nunderwater vehicle demonstrates more accurate long-horizon predictions compared\nto a non-physics-informed baseline", "published": "2025-04-28 17:38:57", "link": "http://arxiv.org/abs/2504.20019v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "cs.LG"}
{"title": "MINT: Multi-Vector Search Index Tuning", "abstract": "Vector search plays a crucial role in many real-world applications. In\naddition to single-vector search, multi-vector search becomes important for\nmulti-modal and multi-feature scenarios today. In a multi-vector database, each\nrow is an item, each column represents a feature of items, and each cell is a\nhigh-dimensional vector. In multi-vector databases, the choice of indexes can\nhave a significant impact on performance. Although index tuning for relational\ndatabases has been extensively studied, index tuning for multi-vector search\nremains unclear and challenging. In this paper, we define multi-vector search\nindex tuning and propose a framework to solve it. Specifically, given a\nmulti-vector search workload, we develop algorithms to find indexes that\nminimize latency and meet storage and recall constraints. Compared to the\nbaseline, our latency achieves 2.1X to 8.3X speedup.", "published": "2025-04-28 17:36:06", "link": "http://arxiv.org/abs/2504.20018v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "Towards Automated Scoping of AI for Social Good Projects", "abstract": "Artificial Intelligence for Social Good (AI4SG) is an emerging effort that\naims to address complex societal challenges with the powerful capabilities of\nAI systems. These challenges range from local issues with transit networks to\nglobal wildlife preservation. However, regardless of scale, a critical\nbottleneck for many AI4SG initiatives is the laborious process of problem\nscoping -- a complex and resource-intensive task -- due to a scarcity of\nprofessionals with both technical and domain expertise. Given the remarkable\napplications of large language models (LLM), we propose a Problem Scoping Agent\n(PSA) that uses an LLM to generate comprehensive project proposals grounded in\nscientific literature and real-world knowledge. We demonstrate that our PSA\nframework generates proposals comparable to those written by experts through a\nblind review and AI evaluations. Finally, we document the challenges of\nreal-world problem scoping and note several areas for future work.", "published": "2025-04-28 17:29:51", "link": "http://arxiv.org/abs/2504.20010v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage", "abstract": "This paper proposes a novel interdisciplinary framework for analyzing police\nbody-worn camera (BWC) footage from the Rochester Police Department (RPD) using\nadvanced artificial intelligence (AI) and statistical machine learning (ML)\ntechniques. Our goal is to detect, classify, and analyze patterns of\ninteraction between police officers and civilians to identify key behavioral\ndynamics, such as respect, disrespect, escalation, and de-escalation. We apply\nmultimodal data analysis by integrating video, audio, and natural language\nprocessing (NLP) techniques to extract meaningful insights from BWC footage. We\npresent our methodology, computational techniques, and findings, outlining a\npractical approach for law enforcement while advancing the frontiers of\nknowledge discovery from police BWC data.", "published": "2025-04-28 17:25:23", "link": "http://arxiv.org/abs/2504.20007v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Simplified and Secure MCP Gateways for Enterprise AI Integration", "abstract": "The increased adoption of the Model Context Protocol (MCP) for AI Agents\nnecessitates robust security for Enterprise integrations. This paper introduces\nthe MCP Gateway to simplify self-hosted MCP server integration. The proposed\narchitecture integrates security principles, authentication, intrusion\ndetection, and secure tunneling, enabling secure self-hosting without exposing\ninfrastructure. Key contributions include a reference architecture, threat\nmodel mapping, simplified integration strategies, and open-source\nimplementation recommendations. This work focuses on the unique challenges of\nenterprise-centric, self-hosted AI integrations, unlike existing public MCP\nserver solutions.", "published": "2025-04-28 17:17:42", "link": "http://arxiv.org/abs/2504.19997v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Monitoring digestate application on agricultural crops using Sentinel-2 Satellite imagery", "abstract": "The widespread use of Exogenous Organic Matter in agriculture necessitates\nmonitoring to assess its effects on soil and crop health. This study evaluates\noptical Sentinel-2 satellite imagery for detecting digestate application, a\npractice that enhances soil fertility but poses environmental risks like\nmicroplastic contamination and nitrogen losses. In the first instance,\nSentinel-2 satellite image time series (SITS) analysis of specific indices\n(EOMI, NDVI, EVI) was used to characterize EOM's spectral behavior after\napplication on the soils of four different crop types in Thessaly, Greece.\nFurthermore, Machine Learning (ML) models (namely Random Forest, k-NN, Gradient\nBoosting and a Feed-Forward Neural Network), were used to investigate digestate\npresence detection, achieving F1-scores up to 0.85. The findings highlight the\npotential of combining remote sensing and ML for scalable and cost-effective\nmonitoring of EOM applications, supporting precision agriculture and\nsustainability.", "published": "2025-04-28 17:16:40", "link": "http://arxiv.org/abs/2504.19996v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Mitigating Societal Cognitive Overload in the Age of AI: Challenges and Directions", "abstract": "Societal cognitive overload, driven by the deluge of information and\ncomplexity in the AI age, poses a critical challenge to human well-being and\nsocietal resilience. This paper argues that mitigating cognitive overload is\nnot only essential for improving present-day life but also a crucial\nprerequisite for navigating the potential risks of advanced AI, including\nexistential threats. We examine how AI exacerbates cognitive overload through\nvarious mechanisms, including information proliferation, algorithmic\nmanipulation, automation anxieties, deregulation, and the erosion of meaning.\nThe paper reframes the AI safety debate to center on cognitive overload,\nhighlighting its role as a bridge between near-term harms and long-term risks.\nIt concludes by discussing potential institutional adaptations, research\ndirections, and policy considerations that arise from adopting an\noverload-resilient perspective on human-AI alignment, suggesting pathways for\nfuture exploration rather than prescribing definitive solutions.", "published": "2025-04-28 17:06:30", "link": "http://arxiv.org/abs/2504.19990v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Real-Time Imitation of Human Head Motions, Blinks and Emotions by Nao Robot: A Closed-Loop Approach", "abstract": "This paper introduces a novel approach for enabling real-time imitation of\nhuman head motion by a Nao robot, with a primary focus on elevating human-robot\ninteractions. By using the robust capabilities of the MediaPipe as a computer\nvision library and the DeepFace as an emotion recognition library, this\nresearch endeavors to capture the subtleties of human head motion, including\nblink actions and emotional expressions, and seamlessly incorporate these\nindicators into the robot's responses. The result is a comprehensive framework\nwhich facilitates precise head imitation within human-robot interactions,\nutilizing a closed-loop approach that involves gathering real-time feedback\nfrom the robot's imitation performance. This feedback loop ensures a high\ndegree of accuracy in modeling head motion, as evidenced by an impressive R2\nscore of 96.3 for pitch and 98.9 for yaw. Notably, the proposed approach holds\npromise in improving communication for children with autism, offering them a\nvaluable tool for more effective interaction. In essence, proposed work\nexplores the integration of real-time head imitation and real-time emotion\nrecognition to enhance human-robot interactions, with potential benefits for\nindividuals with unique communication needs.", "published": "2025-04-28 17:01:54", "link": "http://arxiv.org/abs/2504.19985v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "How Group Lives Go Well", "abstract": "This paper explores the ontological space of group well being, proposing a\nframework for representing collective welfare, group functions, and long term\ncontributions within an ontology engineering context. Traditional well being\ntheories focus on individual states, often relying on hedonistic, desire\nsatisfaction, or objective list models. Such approaches struggle to account for\ncases where individual sacrifices contribute to broader social progress, a\ncritical challenge in modeling group flourishing. To address this, the paper\nrefines and extends the Counterfactual Account (CT) of well being, which\nevaluates goodness of an event by comparing an individual's actual well being\nwith a hypothetical counterpart in a nearby possible world. While useful, this\nframework is insufficient for group level ontologies, where well being depends\non functional persistence, institutional roles, and historical impact rather\nthan immediate individual outcomes. Drawing on Basic Formal Ontology (BFO), the\npaper introduces a model in which group flourishing is evaluated in terms of\ngroup functional, where members bear roles and exhibit persistence conditions\nakin to biological systems or designed artifacts. This approach enables\nsemantic interoperability for modeling longitudinal social contributions,\nallowing for structured reasoning about group welfare, social institutions, and\ngroup flourishing over time.", "published": "2025-04-28 16:40:06", "link": "http://arxiv.org/abs/2504.19968v1", "categories": ["cs.AI", "cs.GT"], "primary_category": "cs.AI"}
{"title": "Enhancing short-term traffic prediction by integrating trends and fluctuations with attention mechanism", "abstract": "Traffic flow prediction is a critical component of intelligent transportation\nsystems, yet accurately forecasting traffic remains challenging due to the\ninteraction between long-term trends and short-term fluctuations. Standard deep\nlearning models often struggle with these challenges because their\narchitectures inherently smooth over fine-grained fluctuations while focusing\non general trends. This limitation arises from low-pass filtering effects, gate\nbiases favoring stability, and memory update mechanisms that prioritize\nlong-term information retention. To address these shortcomings, this study\nintroduces a hybrid deep learning framework that integrates both long-term\ntrend and short-term fluctuation information using two input features processed\nin parallel, designed to capture complementary aspects of traffic flow\ndynamics. Further, our approach leverages attention mechanisms, specifically\nBahdanau attention, to selectively focus on critical time steps within traffic\ndata, enhancing the model's ability to predict congestion and other transient\nphenomena. Experimental results demonstrate that features learned from both\nbranches are complementary, significantly improving the goodness-of-fit\nstatistics across multiple prediction horizons compared to a baseline model.\nNotably, the attention mechanism enhances short-term forecast accuracy by\ndirectly targeting immediate fluctuations, though challenges remain in fully\nintegrating long-term trends. This framework can contribute to more effective\ncongestion mitigation and urban mobility planning by advancing the robustness\nand precision of traffic prediction models.", "published": "2025-04-28 16:38:46", "link": "http://arxiv.org/abs/2504.19967v1", "categories": ["cs.ET", "cs.AI", "cs.LG", "stat.AP"], "primary_category": "cs.ET"}
{"title": "Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents", "abstract": "As generative AI (GenAI) agents become more common in enterprise settings,\nthey introduce security challenges that differ significantly from those posed\nby traditional systems. These agents are not just LLMs; they reason, remember,\nand act, often with minimal human oversight. This paper introduces a\ncomprehensive threat model tailored specifically for GenAI agents, focusing on\nhow their autonomy, persistent memory access, complex reasoning, and tool\nintegration create novel risks. This research work identifies 9 primary threats\nand organizes them across five key domains: cognitive architecture\nvulnerabilities, temporal persistence threats, operational execution\nvulnerabilities, trust boundary violations, and governance circumvention. These\nthreats are not just theoretical they bring practical challenges such as\ndelayed exploitability, cross-system propagation, cross system lateral\nmovement, and subtle goal misalignments that are hard to detect with existing\nframeworks and standard approaches. To help address this, the research work\npresent two complementary frameworks: ATFAA - Advanced Threat Framework for\nAutonomous AI Agents, which organizes agent-specific risks, and SHIELD, a\nframework proposing practical mitigation strategies designed to reduce\nenterprise exposure. While this work builds on existing work in LLM and AI\nsecurity, the focus is squarely on what makes agents different and why those\ndifferences matter. Ultimately, this research argues that GenAI agents require\na new lens for security. If we fail to adapt our threat models and defenses to\naccount for their unique architecture and behavior, we risk turning a powerful\nnew tool into a serious enterprise liability.", "published": "2025-04-28 16:29:24", "link": "http://arxiv.org/abs/2504.19956v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach", "abstract": "The rise of generative AI (GenAI) multi-agent systems (MAS) necessitates\nstandardized protocols enabling agents to discover and interact with external\ntools. However, these protocols introduce new security challenges,\nparticularly; tool squatting; the deceptive registration or representation of\ntools. This paper analyzes tool squatting threats within the context of\nemerging interoperability standards, such as Model Context Protocol (MCP) or\nseamless communication between agents protocols. It introduces a comprehensive\nTool Registry system designed to mitigate these risks. We propose a\nsecurity-focused architecture featuring admin-controlled registration,\ncentralized tool discovery, fine grained access policies enforced via dedicated\nAgent and Tool Registry services, a dynamic trust scoring mechanism based on\ntool versioning and known vulnerabilities, and just in time credential\nprovisioning. Based on its design principles, the proposed registry framework\naims to effectively prevent common tool squatting vectors while preserving the\nflexibility and power of multi-agent systems. This work addresses a critical\nsecurity gap in the rapidly evolving GenAI ecosystem and provides a foundation\nfor secure tool integration in production environments.", "published": "2025-04-28 16:22:21", "link": "http://arxiv.org/abs/2504.19951v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Capturing Aerodynamic Characteristics of ATTAS Aircraft with Evolving Intelligent System", "abstract": "Accurate modeling of aerodynamic coefficients is crucial for understanding\nand optimizing the performance of modern aircraft systems. This paper presents\nthe novel deployment of an Evolving Type-2 Quantum Fuzzy Neural Network\n(eT2QFNN) for modeling the aerodynamic coefficients of the ATTAS aircraft to\nexpress the aerodynamic characteristics. eT2QFNN can represent the nonlinear\naircraft model by creating multiple linear submodels with its rule-based\nstructure through an incremental learning strategy rather than a traditional\nbatch learning approach. Moreover, it enhances robustness to uncertainties and\ndata noise through its quantum membership functions, as well as its automatic\nrule-learning and parameter-tuning capabilities. During the estimation of the\naerodynamic coefficients via the flight data of the ATTAS, two different\nstudies are conducted in the training phase: one with a large amount of data\nand the other with a limited amount of data. The results show that the modeling\nperformance of the eT2QFNN is superior in comparison to baseline counterparts.\nFurthermore, eT2QFNN estimated the aerodynamic model with fewer rules compared\nto Type-1 fuzzy counterparts. In addition, by applying the Delta method to the\nproposed approach, the stability and control derivatives of the aircraft are\nanalyzed. The results prove the superiority of the proposed eT2QFNN in\nrepresenting aerodynamic coefficients.", "published": "2025-04-28 16:21:20", "link": "http://arxiv.org/abs/2504.19949v1", "categories": ["eess.SY", "cs.AI", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Probabilistic and Causal Satisfiability: Constraining the Model", "abstract": "We study the complexity of satisfiability problems in probabilistic and\ncausal reasoning. Given random variables $X_1, X_2,\\ldots$ over finite domains,\nthe basic terms are probabilities of propositional formulas over atomic events\n$X_i = x_i$, such as $P(X_1 = x_1)$ or $P(X_1 = x_1 \\vee X_2 = x_2)$. The basic\nterms can be combined using addition (yielding linear terms) or multiplication\n(polynomial terms). The probabilistic satisfiability problem asks whether a\njoint probability distribution satisfies a Boolean combination of\n(in)equalities over such terms. Fagin et al. (1990) showed that for basic and\nlinear terms, this problem is NP-complete, making it no harder than Boolean\nsatisfiability, while Moss\\'e et al. (2022) proved that for polynomial terms,\nit is complete for the existential theory of the reals.\n  Pearl's Causal Hierarchy (PCH) extends the probabilistic setting with\ninterventional and counterfactual reasoning, enriching the expressiveness of\nlanguages. However, Moss\\'e et al. (2022) found that satisfiability complexity\nremains unchanged. Van der Zander et al. (2023) showed that introducing a\nmarginalization operator to languages induces a significant increase in\ncomplexity.\n  We extend this line of work by adding two new dimensions to the problem by\nconstraining the models. First, we fix the graph structure of the underlying\nstructural causal model, motivated by settings like Pearl's do-calculus, and\ngive a nearly complete landscape across different arithmetics and PCH levels.\nSecond, we study small models. While earlier work showed that satisfiable\ninstances admit polynomial-size models, this is no longer guaranteed with\ncompact marginalization. We characterize the complexities of satisfiability\nunder small-model constraints across different settings.", "published": "2025-04-28 16:14:06", "link": "http://arxiv.org/abs/2504.19944v1", "categories": ["cs.CC", "cs.AI", "cs.LO"], "primary_category": "cs.CC"}
{"title": "Automated decision-making for dynamic task assignment at scale", "abstract": "The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\ntasks in real time while minimizing some objectives, like resource costs or\ntask cycle time. In this work, we consider a DTAP variant where every task is a\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\ninvolves the decision of which employee to assign to which activity to process\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\nresearch is limited to solving small-scale, synthetic problems, neglecting the\nchallenges posed by real-world use cases. To bridge this gap, this work\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\nTo this end, we introduce a DRL agent with two novel elements: a graph\nstructure for observations and actions that can effectively represent any DTAP\nand a reward function that is provably equivalent to the objective of\nminimizing the average cycle time of tasks. The combination of these two\nnovelties allows the agent to learn effective and generalizable assignment\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\ninstances whose parameters are extracted from real-world logs through process\nmining. The experimental evaluation shows how the proposed DRL agent matches or\noutperforms the best baseline in all DTAP instances and generalizes on\ndifferent time horizons and across instances.", "published": "2025-04-28 16:08:35", "link": "http://arxiv.org/abs/2504.19933v1", "categories": ["cs.AI", "cs.LG", "math.OC"], "primary_category": "cs.AI"}
{"title": "Enhancing Surgical Documentation through Multimodal Visual-Temporal Transformers and Generative AI", "abstract": "The automatic summarization of surgical videos is essential for enhancing\nprocedural documentation, supporting surgical training, and facilitating\npost-operative analysis. This paper presents a novel method at the intersection\nof artificial intelligence and medicine, aiming to develop machine learning\nmodels with direct real-world applications in surgical contexts. We propose a\nmulti-modal framework that leverages recent advancements in computer vision and\nlarge language models to generate comprehensive video summaries. % The approach\nis structured in three key stages. First, surgical videos are divided into\nclips, and visual features are extracted at the frame level using visual\ntransformers. This step focuses on detecting tools, tissues, organs, and\nsurgical actions. Second, the extracted features are transformed into\nframe-level captions via large language models. These are then combined with\ntemporal features, captured using a ViViT-based encoder, to produce clip-level\nsummaries that reflect the broader context of each video segment. Finally, the\nclip-level descriptions are aggregated into a full surgical report using a\ndedicated LLM tailored for the summarization task. % We evaluate our method on\nthe CholecT50 dataset, using instrument and action annotations from 50\nlaparoscopic videos. The results show strong performance, achieving 96\\%\nprecision in tool detection and a BERT score of 0.74 for temporal context\nsummarization. This work contributes to the advancement of AI-assisted tools\nfor surgical reporting, offering a step toward more intelligent and reliable\nclinical documentation.", "published": "2025-04-28 15:46:02", "link": "http://arxiv.org/abs/2504.19918v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Can AI Agents Design and Implement Drug Discovery Pipelines?", "abstract": "The rapid advancement of artificial intelligence, particularly autonomous\nagentic systems based on Large Language Models (LLMs), presents new\nopportunities to accelerate drug discovery by improving in-silico modeling and\nreducing dependence on costly experimental trials. Current AI agent-based\nsystems demonstrate proficiency in solving programming challenges and\nconducting research, indicating an emerging potential to develop software\ncapable of addressing complex problems such as pharmaceutical design and drug\ndiscovery. This paper introduces DO Challenge, a benchmark designed to evaluate\nthe decision-making abilities of AI agents in a single, complex problem\nresembling virtual screening scenarios. The benchmark challenges systems to\nindependently develop, implement, and execute efficient strategies for\nidentifying promising molecular structures from extensive datasets, while\nnavigating chemical space, selecting models, and managing limited resources in\na multi-objective context. We also discuss insights from the DO Challenge 2025,\na competition based on the proposed benchmark, which showcased diverse\nstrategies explored by human participants. Furthermore, we present the Deep\nThought multi-agent system, which demonstrated strong performance on the\nbenchmark, outperforming most human teams. Among the language models tested,\nClaude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles,\nand GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While\npromising, the system's performance still fell short of expert-designed\nsolutions and showed high instability, highlighting both the potential and\ncurrent limitations of AI-driven methodologies in transforming drug discovery\nand broader scientific research.", "published": "2025-04-28 15:41:28", "link": "http://arxiv.org/abs/2504.19912v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Attention Mechanism, Max-Affine Partition, and Universal Approximation", "abstract": "We establish the universal approximation capability of single-layer,\nsingle-head self- and cross-attention mechanisms with minimal attached\nstructures. Our key insight is to interpret single-head attention as an input\ndomain-partition mechanism that assigns distinct values to subregions. This\nallows us to engineer the attention weights such that this assignment imitates\nthe target function. Building on this, we prove that a single self-attention\nlayer, preceded by sum-of-linear transformations, is capable of approximating\nany continuous function on a compact domain under the $L_\\infty$-norm.\nFurthermore, we extend this construction to approximate any Lebesgue integrable\nfunction under $L_p$-norm for $1\\leq p <\\infty$. Lastly, we also extend our\ntechniques and show that, for the first time, single-head cross-attention\nachieves the same universal approximation guarantees.", "published": "2025-04-28 15:31:45", "link": "http://arxiv.org/abs/2504.19901v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Breast Cancer Detection from Multi-View Screening Mammograms with Visual Prompt Tuning", "abstract": "Accurate detection of breast cancer from high-resolution mammograms is\ncrucial for early diagnosis and effective treatment planning. Previous studies\nhave shown the potential of using single-view mammograms for breast cancer\ndetection. However, incorporating multi-view data can provide more\ncomprehensive insights. Multi-view classification, especially in medical\nimaging, presents unique challenges, particularly when dealing with\nlarge-scale, high-resolution data. In this work, we propose a novel Multi-view\nVisual Prompt Tuning Network (MVPT-NET) for analyzing multiple screening\nmammograms. We first pretrain a robust single-view classification model on\nhigh-resolution mammograms and then innovatively adapt multi-view feature\nlearning into a task-specific prompt tuning process. This technique selectively\ntunes a minimal set of trainable parameters (7\\%) while retaining the\nrobustness of the pre-trained single-view model, enabling efficient integration\nof multi-view data without the need for aggressive downsampling. Our approach\noffers an efficient alternative to traditional feature fusion methods,\nproviding a more robust, scalable, and efficient solution for high-resolution\nmammogram analysis. Experimental results on a large multi-institution dataset\ndemonstrate that our method outperforms conventional approaches while\nmaintaining detection efficiency, achieving an AUROC of 0.852 for\ndistinguishing between Benign, DCIS, and Invasive classes. This work highlights\nthe potential of MVPT-NET for medical imaging tasks and provides a scalable\nsolution for integrating multi-view data in breast cancer detection.", "published": "2025-04-28 15:31:08", "link": "http://arxiv.org/abs/2504.19900v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "TurboQuant: Online Vector Quantization with Near-optimal Distortion Rate", "abstract": "Vector quantization, a problem rooted in Shannon's source coding theory, aims\nto quantize high-dimensional Euclidean vectors while minimizing distortion in\ntheir geometric structure. We propose TurboQuant to address both mean-squared\nerror (MSE) and inner product distortion, overcoming limitations of existing\nmethods that fail to achieve optimal distortion rates. Our data-oblivious\nalgorithms, suitable for online applications, achieve near-optimal distortion\nrates (within a small constant factor) across all bit-widths and dimensions.\nTurboQuant achieves this by randomly rotating input vectors, inducing a\nconcentrated Beta distribution on coordinates, and leveraging the\nnear-independence property of distinct coordinates in high dimensions to simply\napply optimal scalar quantizers per each coordinate. Recognizing that\nMSE-optimal quantizers introduce bias in inner product estimation, we propose a\ntwo-stage approach: applying an MSE quantizer followed by a 1-bit Quantized JL\n(QJL) transform on the residual, resulting in an unbiased inner product\nquantizer. We also provide a formal proof of the information-theoretic lower\nbounds on best achievable distortion rate by any vector quantizer,\ndemonstrating that TurboQuant closely matches these bounds, differing only by a\nsmall constant ($\\approx 2.7$) factor. Experimental results validate our\ntheoretical findings, showing that for KV cache quantization, we achieve\nabsolute quality neutrality with 3.5 bits per channel and marginal quality\ndegradation with 2.5 bits per channel. Furthermore, in nearest neighbor search\ntasks, our method outperforms existing product quantization techniques in\nrecall while reducing indexing time to virtually zero.", "published": "2025-04-28 15:05:35", "link": "http://arxiv.org/abs/2504.19874v1", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.DS"], "primary_category": "cs.LG"}
{"title": "Towards Ball Spin and Trajectory Analysis in Table Tennis Broadcast Videos via Physically Grounded Synthetic-to-Real Transfer", "abstract": "Analyzing a player's technique in table tennis requires knowledge of the\nball's 3D trajectory and spin. While, the spin is not directly observable in\nstandard broadcasting videos, we show that it can be inferred from the ball's\ntrajectory in the video. We present a novel method to infer the initial spin\nand 3D trajectory from the corresponding 2D trajectory in a video. Without\nground truth labels for broadcast videos, we train a neural network solely on\nsynthetic data. Due to the choice of our input data representation, physically\ncorrect synthetic training data, and using targeted augmentations, the network\nnaturally generalizes to real data. Notably, these simple techniques are\nsufficient to achieve generalization. No real data at all is required for\ntraining. To the best of our knowledge, we are the first to present a method\nfor spin and trajectory prediction in simple monocular broadcast videos,\nachieving an accuracy of 92.0% in spin classification and a 2D reprojection\nerror of 0.19% of the image diagonal.", "published": "2025-04-28 14:55:12", "link": "http://arxiv.org/abs/2504.19863v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks", "abstract": "Existing Visual-Language-Action (VLA) models have shown promising performance\nin zero-shot scenarios, demonstrating impressive task execution and reasoning\ncapabilities. However, a significant challenge arises from the limitations of\nvisual encoding, which can result in failures during tasks such as object\ngrasping. Moreover, these models typically suffer from high computational\noverhead due to their large sizes, often exceeding 7B parameters. While these\nmodels excel in reasoning and task planning, the substantial computational\noverhead they incur makes them impractical for real-time robotic environments,\nwhere speed and efficiency are paramount. To address the limitations of\nexisting VLA models, we propose NORA, a 3B-parameter model designed to reduce\ncomputational overhead while maintaining strong task performance. NORA adopts\nthe Qwen-2.5-VL-3B multimodal model as its backbone, leveraging its superior\nvisual-semantic understanding to enhance visual reasoning and action grounding.\nAdditionally, our \\model{} is trained on 970k real-world robot demonstrations\nand equipped with the FAST+ tokenizer for efficient action sequence generation.\nExperimental results demonstrate that NORA outperforms existing large-scale VLA\nmodels, achieving better task performance with significantly reduced\ncomputational overhead, making it a more practical solution for real-time\nrobotic autonomy.", "published": "2025-04-28 14:47:34", "link": "http://arxiv.org/abs/2504.19854v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Human-Centered AI and Autonomy in Robotics: Insights from a Bibliometric Study", "abstract": "The development of autonomous robotic systems offers significant potential\nfor performing complex tasks with precision and consistency. Recent advances in\nArtificial Intelligence (AI) have enabled more capable intelligent automation\nsystems, addressing increasingly complex challenges. However, this progress\nraises questions about human roles in such systems. Human-Centered AI (HCAI)\naims to balance human control and automation, ensuring performance enhancement\nwhile maintaining creativity, mastery, and responsibility. For real-world\napplications, autonomous robots must balance task performance with reliability,\nsafety, and trustworthiness. Integrating HCAI principles enhances human-robot\ncollaboration and ensures responsible operation.\n  This paper presents a bibliometric analysis of intelligent autonomous robotic\nsystems, utilizing SciMAT and VOSViewer to examine data from the Scopus\ndatabase. The findings highlight academic trends, emerging topics, and AI's\nrole in self-adaptive robotic behaviour, with an emphasis on HCAI architecture.\nThese insights are then projected onto the IBM MAPE-K architecture, with the\ngoal of identifying how these research results map into actual robotic\nautonomous systems development efforts for real-world scenarios.", "published": "2025-04-28 14:45:48", "link": "http://arxiv.org/abs/2504.19848v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration", "abstract": "In this work, we introduce Segmentation to Human-Object Interaction\n(\\textit{\\textbf{Seg2HOI}}) approach, a novel framework that integrates\nsegmentation-based vision foundation models with the human-object interaction\ntask, distinguished from traditional detection-based Human-Object Interaction\n(HOI) methods. Our approach enhances HOI detection by not only predicting the\nstandard triplets but also introducing quadruplets, which extend HOI triplets\nby including segmentation masks for human-object pairs. More specifically,\nSeg2HOI inherits the properties of the vision foundation model (e.g.,\npromptable and interactive mechanisms) and incorporates a decoder that applies\nthese attributes to HOI task. Despite training only for HOI, without additional\ntraining mechanisms for these properties, the framework demonstrates that such\nfeatures still operate efficiently. Extensive experiments on two public\nbenchmark datasets demonstrate that Seg2HOI achieves performance comparable to\nstate-of-the-art methods, even in zero-shot scenarios. Lastly, we propose that\nSeg2HOI can generate HOI quadruplets and interactive HOI segmentation from\nnovel text and visual prompts that were not used during training, making it\nversatile for a wide range of applications by leveraging this flexibility.", "published": "2025-04-28 14:45:26", "link": "http://arxiv.org/abs/2504.19847v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Mj\u00f6lnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density", "abstract": "Recent advances in AI-based weather forecasting models, such as FourCastNet,\nPangu-Weather, and GraphCast, have demonstrated the remarkable ability of deep\nlearning to emulate complex atmospheric dynamics. Building on this momentum, we\npropose Mj\\\"olnir, a novel deep learning-based framework for global lightning\nflash density parameterization. Trained on ERA5 atmospheric predictors and\nWorld Wide Lightning Location Network (WWLLN) observations at a daily temporal\nresolution and 1 degree spatial resolution, Mj\\\"olnir captures the nonlinear\nmapping between large-scale environmental conditions and lightning activity.\nThe model architecture is based on the InceptionNeXt backbone with SENet, and a\nmulti-task learning strategy to simultaneously predict lightning occurrence and\nmagnitude. Extensive evaluations yield that Mollnir accurately reproduces the\nglobal distribution, seasonal variability, and regional characteristics of\nlightning activity, achieving a global Pearson correlation coefficient of 0.96\nfor annual mean fields. These results suggest that Mj\\\"olnir serves not only as\nan effective data-driven global lightning parameterization but also as a\npromising AI-based scheme for next-generation Earth system models (AI-ESMs).", "published": "2025-04-28 14:22:59", "link": "http://arxiv.org/abs/2504.19822v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "physics.ao-ph"], "primary_category": "cs.LG"}
{"title": "PhenoAssistant: A Conversational Multi-Agent AI System for Automated Plant Phenotyping", "abstract": "Plant phenotyping increasingly relies on (semi-)automated image-based\nanalysis workflows to improve its accuracy and scalability. However, many\nexisting solutions remain overly complex, difficult to reimplement and\nmaintain, and pose high barriers for users without substantial computational\nexpertise. To address these challenges, we introduce PhenoAssistant: a\npioneering AI-driven system that streamlines plant phenotyping via intuitive\nnatural language interaction. PhenoAssistant leverages a large language model\nto orchestrate a curated toolkit supporting tasks including automated phenotype\nextraction, data visualisation and automated model training. We validate\nPhenoAssistant through several representative case studies and a set of\nevaluation tasks. By significantly lowering technical hurdles, PhenoAssistant\nunderscores the promise of AI-driven methodologies to democratising AI adoption\nin plant biology.", "published": "2025-04-28 14:20:30", "link": "http://arxiv.org/abs/2504.19818v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Contextures: The Mechanism of Representation Learning", "abstract": "This dissertation establishes the contexture theory to mathematically\ncharacterize the mechanism of representation learning, or pretraining. Despite\nthe remarkable empirical success of foundation models, it is not very clear\nwhat representations they learn, and why these representations are useful for\nvarious downstream tasks. A scientific understanding of representation learning\nis critical, especially at this point when scaling up the model size is\nproducing diminishing returns, and designing new pretraining methods is\nimperative for further progress.\n  Prior work treated different representation learning methods quite\ndifferently, whereas the contexture theory provides a unified framework for\nanalyzing these methods. The central argument is that a representation is\nlearned from the association between the input X and a context variable A. We\nprove that if an encoder captures the maximum information of this association,\nin which case we say that the encoder learns the contexture, then it will be\noptimal on the class of tasks that are compatible with the context. We also\nshow that a context is the most useful when the association between X and A is\nneither too strong nor too weak. The important implication of the contexture\ntheory is that increasing the model size alone will achieve diminishing\nreturns, and further advancements require better contexts.\n  We demonstrate that many pretraining objectives can learn the contexture,\nincluding supervised learning, self-supervised learning, generative models,\netc. Then, we introduce two general objectives -- SVME and KISE, for learning\nthe contexture. We also show how to mix multiple contexts together, an\neffortless way to create better contexts from existing ones. Then, we prove\nstatistical learning bounds for representation learning. Finally, we discuss\nthe effect of the data distribution shift from pretraining to the downstream\ntask.", "published": "2025-04-28 13:36:28", "link": "http://arxiv.org/abs/2504.19792v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Hybrid Approach Combining Ultrasound and Blood Test Analysis with a Voting Classifier for Accurate Liver Fibrosis and Cirrhosis Assessment", "abstract": "Liver cirrhosis is an insidious condition involving the substitution of\nnormal liver tissue with fibrous scar tissue and causing major health\ncomplications. The conventional method of diagnosis using liver biopsy is\ninvasive and, therefore, inconvenient for use in regular screening. In this\npaper,we present a hybrid model that combines machine learning techniques with\nclinical data and ultrasoundscans to improve liver fibrosis and cirrhosis\ndetection accuracy is presented. The model integrates fixed blood test\nprobabilities with deep learning model predictions (DenseNet-201) for\nultrasonic images. The combined hybrid model achieved an accuracy of 92.5%. The\nfindings establish the viability of the combined model in enhancing diagnosis\naccuracy and supporting early intervention in liver disease care.", "published": "2025-04-28 12:54:51", "link": "http://arxiv.org/abs/2504.19755v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning Efficiency Meets Symmetry Breaking", "abstract": "Learning-based planners leveraging Graph Neural Networks can learn search\nguidance applicable to large search spaces, yet their potential to address\nsymmetries remains largely unexplored. In this paper, we introduce a graph\nrepresentation of planning problems allying learning efficiency with the\nability to detect symmetries, along with two pruning methods, action pruning\nand state pruning, designed to manage symmetries during search. The integration\nof these techniques into Fast Downward achieves a first-time success over LAMA\non the latest IPC learning track dataset. Code is released at:\nhttps://github.com/bybeye/Distincter.", "published": "2025-04-28 12:33:39", "link": "http://arxiv.org/abs/2504.19738v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Model-based controller assisted domain randomization in deep reinforcement learning: application to nonlinear powertrain control", "abstract": "Complex mechanical systems such as vehicle powertrains are inherently subject\nto multiple nonlinearities and uncertainties arising from parametric\nvariations. Modeling and calibration errors are therefore unavoidable, making\nthe transfer of control systems from simulation to real-world systems a\ncritical challenge. Traditional robust controls have limitations in handling\ncertain types of nonlinearities and uncertainties, requiring a more practical\napproach capable of comprehensively compensating for these various constraints.\nThis study proposes a new robust control approach using the framework of deep\nreinforcement learning (DRL). The key strategy lies in the synergy among domain\nrandomization-based DRL, long short-term memory (LSTM)-based actor and critic\nnetworks, and model-based control (MBC). The problem setup is modeled via the\nlatent Markov decision process (LMDP), a set of vanilla MDPs, for a controlled\nsystem subject to uncertainties and nonlinearities. In LMDP, the dynamics of an\nenvironment simulator is randomized during training to improve the robustness\nof the control system to real testing environments. The randomization increases\ntraining difficulties as well as conservativeness of the resultant control\nsystem; therefore, progress is assisted by concurrent use of a model-based\ncontroller based on a nominal system model. Compared to traditional DRL-based\ncontrols, the proposed controller design is smarter in that we can achieve a\nhigh level of generalization ability with a more compact neural network\narchitecture and a smaller amount of training data. The proposed approach is\nverified via practical application to active damping for a complex powertrain\nsystem with nonlinearities and parametric variations. Comparative tests\ndemonstrate the high robustness of the proposed approach.", "published": "2025-04-28 12:09:07", "link": "http://arxiv.org/abs/2504.19715v1", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review", "abstract": "Large language models and autonomous AI agents have evolved rapidly,\nresulting in a diverse array of evaluation benchmarks, frameworks, and\ncollaboration protocols. However, the landscape remains fragmented and lacks a\nunified taxonomy or comprehensive survey. Therefore, we present a side-by-side\ncomparison of benchmarks developed between 2019 and 2025 that evaluate these\nmodels and agents across multiple domains. In addition, we propose a taxonomy\nof approximately 60 benchmarks that cover general and academic knowledge\nreasoning, mathematical problem-solving, code generation and software\nengineering, factual grounding and retrieval, domain-specific evaluations,\nmultimodal and embodied tasks, task orchestration, and interactive assessments.\nFurthermore, we review AI-agent frameworks introduced between 2023 and 2025\nthat integrate large language models with modular toolkits to enable autonomous\ndecision-making and multi-step reasoning. Moreover, we present real-world\napplications of autonomous AI agents in materials science, biomedical research,\nacademic ideation, software engineering, synthetic data generation, chemical\nreasoning, mathematical problem-solving, geographic information systems,\nmultimedia, healthcare, and finance. We then survey key agent-to-agent\ncollaboration protocols, namely the Agent Communication Protocol (ACP), the\nModel Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally,\nwe discuss recommendations for future research, focusing on advanced reasoning\nstrategies, failure modes in multi-agent LLM systems, automated scientific\ndiscovery, dynamic tool integration via reinforcement learning, integrated\nsearch capabilities, and security vulnerabilities in agent protocols.", "published": "2025-04-28 11:08:22", "link": "http://arxiv.org/abs/2504.19678v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "$\\texttt{SAGE}$: A Generic Framework for LLM Safety Evaluation", "abstract": "Safety evaluation of Large Language Models (LLMs) has made progress and\nattracted academic interest, but it remains challenging to keep pace with the\nrapid integration of LLMs across diverse applications. Different applications\nexpose users to various harms, necessitating application-specific safety\nevaluations with tailored harms and policies. Another major gap is the lack of\nfocus on the dynamic and conversational nature of LLM systems. Such potential\noversights can lead to harms that go unnoticed in standard safety benchmarks.\nThis paper identifies the above as key requirements for robust LLM safety\nevaluation and recognizing that current evaluation methodologies do not satisfy\nthese, we introduce the $\\texttt{SAGE}$ (Safety AI Generic Evaluation)\nframework. $\\texttt{SAGE}$ is an automated modular framework designed for\ncustomized and dynamic harm evaluations. It utilizes adversarial user models\nthat are system-aware and have unique personalities, enabling a holistic\nred-teaming evaluation. We demonstrate $\\texttt{SAGE}$'s effectiveness by\nevaluating seven state-of-the-art LLMs across three applications and harm\npolicies. Our experiments with multi-turn conversational evaluations revealed a\nconcerning finding that harm steadily increases with conversation length.\nFurthermore, we observe significant disparities in model behavior when exposed\nto different user personalities and scenarios. Our findings also reveal that\nsome models minimize harmful outputs by employing severe refusal tactics that\ncan hinder their usefulness. These insights highlight the necessity of adaptive\nand context-specific testing to ensure better safety alignment and safer\ndeployment of LLMs in real-world scenarios.", "published": "2025-04-28 11:01:08", "link": "http://arxiv.org/abs/2504.19674v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Generative AI in Education: Student Skills and Lecturer Roles", "abstract": "Generative Artificial Intelligence (GenAI) tools such as ChatGPT are emerging\nas a revolutionary tool in education that brings both positive aspects and\nchallenges for educators and students, reshaping how learning and teaching are\napproached. This study aims to identify and evaluate the key competencies\nstudents need to effectively engage with GenAI in education and to provide\nstrategies for lecturers to integrate GenAI into teaching practices. The study\napplied a mixed method approach with a combination of a literature review and a\nquantitative survey involving 130 students from South Asia and Europe to obtain\nits findings. The literature review identified 14 essential student skills for\nGenAI engagement, with AI literacy, critical thinking, and ethical AI practices\nemerging as the most critical. The student survey revealed gaps in prompt\nengineering, bias awareness, and AI output management. In our study of lecturer\nstrategies, we identified six key areas, with GenAI Integration and Curriculum\nDesign being the most emphasised. Our findings highlight the importance of\nincorporating GenAI into education. While literature prioritized ethics and\npolicy development, students favour hands-on, project-based learning and\npractical AI applications. To foster inclusive and responsible GenAI adoption,\ninstitutions should ensure equitable access to GenAI tools, establish clear\nacademic integrity policies, and advocate for global GenAI research\ninitiatives.", "published": "2025-04-28 10:58:30", "link": "http://arxiv.org/abs/2504.19673v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "A Tripartite Perspective on GraphRAG", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious domains, yet they struggle with knowledge-intensive tasks in areas that\ndemand factual accuracy, e.g. industrial automation and healthcare. Key\nlimitations include their tendency to hallucinate, lack of source traceability\n(provenance), and challenges in timely knowledge updates. Combining language\nmodels with knowledge graphs (GraphRAG) offers promising avenues for overcoming\nthese deficits. However, a major challenge lies in creating such a knowledge\ngraph in the first place. Here, we propose a novel approach that combines LLMs\nwith a tripartite knowledge graph representation, which is constructed by\nconnecting complex, domain-specific objects via a curated ontology of\ncorresponding, domain-specific concepts to relevant sections within chunks of\ntext through a concept-anchored pre-analysis of source documents starting from\nan initial lexical graph. As a consequence, our Tripartite-GraphRAG approach\nimplements: i) a concept-specific, information-preserving pre-compression of\ntextual chunks; ii) allows for the formation of a concept-specific relevance\nestimation of embedding similarities grounded in statistics; and iii) avoids\ncommon challenges w.r.t. continuous extendability, such as the need for entity\nresolution and deduplication. By applying a transformation to the knowledge\ngraph, we formulate LLM prompt creation as an unsupervised node classification\nproblem, drawing on ideas from Markov Random Fields. We evaluate our approach\non a healthcare use case, involving multi-faceted analyses of patient anamneses\ngiven a set of medical concepts as well as clinical literature. Experiments\nindicate that it can optimize information density, coverage, and arrangement of\nLLM prompts while reducing their lengths, which may lead to reduced costs and\nmore consistent and reliable LLM outputs.", "published": "2025-04-28 10:43:35", "link": "http://arxiv.org/abs/2504.19667v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Hardware/Software Co-Design of RISC-V Extensions for Accelerating Sparse DNNs on FPGAs", "abstract": "The customizability of RISC-V makes it an attractive choice for accelerating\ndeep neural networks (DNNs). It can be achieved through instruction set\nextensions and corresponding custom functional units. Yet, efficiently\nexploiting these opportunities requires a hardware/software co-design approach\nin which the DNN model, software, and hardware are designed together. In this\npaper, we propose novel RISC-V extensions for accelerating DNN models\ncontaining semi-structured and unstructured sparsity. While the idea of\naccelerating structured and unstructured pruning is not new, our novel design\noffers various advantages over other designs. To exploit semi-structured\nsparsity, we take advantage of the fine-grained (bit-level) configurability of\nFPGAs and suggest reserving a few bits in a block of DNN weights to encode the\ninformation about sparsity in the succeeding blocks. The proposed custom\nfunctional unit utilizes this information to skip computations. To exploit\nunstructured sparsity, we propose a variable cycle sequential\nmultiply-and-accumulate unit that performs only as many multiplications as the\nnon-zero weights. Our implementation of unstructured and semi-structured\npruning accelerators can provide speedups of up to a factor of 3 and 4,\nrespectively. We then propose a combined design that can accelerate both types\nof sparsities, providing speedups of up to a factor of 5. Our designs consume a\nsmall amount of additional FPGA resources such that the resulting co-designs\nenable the acceleration of DNNs even on small FPGAs. We benchmark our designs\non standard TinyML applications such as keyword spotting, image classification,\nand person detection.", "published": "2025-04-28 10:19:39", "link": "http://arxiv.org/abs/2504.19659v1", "categories": ["cs.LG", "cs.AI", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Transformation & Translation Occupancy Grid Mapping: 2-Dimensional Deep Learning Refined SLAM", "abstract": "SLAM (Simultaneous Localisation and Mapping) is a crucial component for\nrobotic systems, providing a map of an environment, the current location and\nprevious trajectory of a robot. While 3D LiDAR SLAM has received notable\nimprovements in recent years, 2D SLAM lags behind. Gradual drifts in odometry\nand pose estimation inaccuracies hinder modern 2D LiDAR-odometry algorithms in\nlarge complex environments. Dynamic robotic motion coupled with inherent\nestimation based SLAM processes introduce noise and errors, degrading map\nquality. Occupancy Grid Mapping (OGM) produces results that are often noisy and\nunclear. This is due to the fact that evidence based mapping represents maps\naccording to uncertain observations. This is why OGMs are so popular in\nexploration or navigation tasks. However, this also limits OGMs' effectiveness\nfor specific mapping based tasks such as floor plan creation in complex scenes.\nTo address this, we propose our novel Transformation and Translation Occupancy\nGrid Mapping (TT-OGM). We adapt and enable accurate and robust pose estimation\ntechniques from 3D SLAM to the world of 2D and mitigate errors to improve map\nquality using Generative Adversarial Networks (GANs). We introduce a novel data\ngeneration method via deep reinforcement learning (DRL) to build datasets large\nenough for training a GAN for SLAM error correction. We demonstrate our SLAM in\nreal-time on data collected at Loughborough University. We also prove its\ngeneralisability on a variety of large complex environments on a collection of\nlarge scale well-known 2D occupancy maps. Our novel approach enables the\ncreation of high quality OGMs in complex scenes, far surpassing the\ncapabilities of current SLAM algorithms in terms of quality, accuracy and\nreliability.", "published": "2025-04-28 10:13:47", "link": "http://arxiv.org/abs/2504.19654v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "GAN-SLAM: Real-Time GAN Aided Floor Plan Creation Through SLAM", "abstract": "SLAM is a fundamental component of modern autonomous systems, providing\nrobots and their operators with a deeper understanding of their environment.\nSLAM systems often encounter challenges due to the dynamic nature of robotic\nmotion, leading to inaccuracies in mapping quality, particularly in 2D\nrepresentations such as Occupancy Grid Maps. These errors can significantly\ndegrade map quality, hindering the effectiveness of specific downstream tasks\nsuch as floor plan creation. To address this challenge, we introduce our novel\n'GAN-SLAM', a new SLAM approach that leverages Generative Adversarial Networks\nto clean and complete occupancy grids during the SLAM process, reducing the\nimpact of noise and inaccuracies introduced on the output map. We adapt and\nintegrate accurate pose estimation techniques typically used for 3D SLAM into a\n2D form. This enables the quality improvement 3D LiDAR-odometry has seen in\nrecent years to be effective for 2D representations. Our results demonstrate\nsubstantial improvements in map fidelity and quality, with minimal noise and\nerrors, affirming the effectiveness of GAN-SLAM for real-world mapping\napplications within large-scale complex environments. We validate our approach\non real-world data operating in real-time, and on famous examples of 2D maps.\nThe improved quality of the output map enables new downstream tasks, such as\nfloor plan drafting, further enhancing the capabilities of autonomous systems.\nOur novel approach to SLAM offers a significant step forward in the field,\nimproving the usability for SLAM in mapping-based tasks, and offers insight\ninto the usage of GANs for OGM error correction.", "published": "2025-04-28 10:13:38", "link": "http://arxiv.org/abs/2504.19653v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search", "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\nalgorithm design. However, when integrated into search frameworks for iterative\nalgorithm search, the underlying fitness landscape--critical for understanding\nsearch behaviou--remains underexplored. In this paper, we illustrate and\nanalyze the fitness landscape of LLM-assisted Algorithm Search (LAS) using a\ngraph-based approach, where nodes represent algorithms and edges denote\ntransitions between them. We conduct extensive evaluations across six algorithm\ndesign tasks and six commonly used LLMs. Our findings reveal that LAS\nlandscapes are highly multimodal and rugged, particularly in combinatorial\noptimization tasks, with distinct structural variations across tasks and LLMs.\nFor instance, heuristic design tasks exhibit dense clusters of high-performing\nalgorithms, while symbolic regression tasks show sparse, scattered\ndistributions. Additionally, we demonstrate how population size influences\nexploration-exploitation trade-offs and the evolving trajectory of elite\nalgorithms. These insights not only advance our understanding of LAS landscapes\nbut also provide practical guidance for designing more effective LAS methods.", "published": "2025-04-28 09:52:41", "link": "http://arxiv.org/abs/2504.19636v1", "categories": ["cs.AI", "cs.NE"], "primary_category": "cs.AI"}
{"title": "From Evidence to Belief: A Bayesian Epistemology Approach to Language Models", "abstract": "This paper investigates the knowledge of language models from the perspective\nof Bayesian epistemology. We explore how language models adjust their\nconfidence and responses when presented with evidence with varying levels of\ninformativeness and reliability. To study these properties, we create a dataset\nwith various types of evidence and analyze language models' responses and\nconfidence using verbalized confidence, token probability, and sampling. We\nobserved that language models do not consistently follow Bayesian epistemology:\nlanguage models follow the Bayesian confirmation assumption well with true\nevidence but fail to adhere to other Bayesian assumptions when encountering\ndifferent evidence types. Also, we demonstrated that language models can\nexhibit high confidence when given strong evidence, but this does not always\nguarantee high accuracy. Our analysis also reveals that language models are\nbiased toward golden evidence and show varying performance depending on the\ndegree of irrelevance, helping explain why they deviate from Bayesian\nassumptions.", "published": "2025-04-28 09:28:42", "link": "http://arxiv.org/abs/2504.19622v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Image Generation Method Based on Heat Diffusion Models", "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) achieve high-quality image\ngeneration without adversarial training, but they process images as a whole.\nSince adjacent pixels are highly likely to belong to the same object, we\npropose the Heat Diffusion Model (HDM) to further preserve image details and\ngenerate more realistic images. HDM is a model that incorporates pixel-level\noperations while maintaining the same training process as DDPM. In HDM, the\ndiscrete form of the two-dimensional heat equation is integrated into the\ndiffusion and generation formulas of DDPM, enabling the model to compute\nrelationships between neighboring pixels during image processing. Our\nexperiments demonstrate that HDM can generate higher-quality samples compared\nto models such as DDPM, Consistency Diffusion Models (CDM), Latent Diffusion\nModels (LDM), and Vector Quantized Generative Adversarial Networks (VQGAN).", "published": "2025-04-28 09:03:33", "link": "http://arxiv.org/abs/2504.19600v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "GVPO: Group Variance Policy Optimization for Large Language Model Post-Training", "abstract": "Post-training plays a crucial role in refining and aligning large language\nmodels to meet specific tasks and human preferences. While recent advancements\nin post-training techniques, such as Group Relative Policy Optimization (GRPO),\nleverage increased sampling with relative reward scoring to achieve superior\nperformance, these methods often suffer from training instability that limits\ntheir practical adoption. To address this challenge, we present Group Variance\nPolicy Optimization (GVPO). GVPO incorporates the analytical solution to\nKL-constrained reward maximization directly into its gradient weights, ensuring\nalignment with the optimal policy. The method provides intuitive physical\ninterpretations: its gradient mirrors the mean squared error between the\ncentral distance of implicit rewards and that of actual rewards. GVPO offers\ntwo key advantages: (1) it guarantees a unique optimal solution, exactly the\nKL-constrained reward maximization objective, (2) it supports flexible sampling\ndistributions that avoids on-policy and importance sampling limitations. By\nunifying theoretical guarantees with practical adaptability, GVPO establishes a\nnew paradigm for reliable and versatile LLM post-training.", "published": "2025-04-28 09:02:24", "link": "http://arxiv.org/abs/2504.19599v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Lightweight Adapter Learning for More Generalized Remote Sensing Change Detection", "abstract": "Deep learning methods have shown promising performances in remote sensing\nimage change detection (CD). However, existing methods usually train a\ndataset-specific deep network for each dataset. Due to the significant\ndifferences in the data distribution and labeling between various datasets, the\ntrained dataset-specific deep network has poor generalization performances on\nother datasets. To solve this problem, this paper proposes a change adapter\nnetwork (CANet) for a more universal and generalized CD. CANet contains\ndataset-shared and dataset-specific learning modules. The former explores the\ndiscriminative features of images, and the latter designs a lightweight adapter\nmodel, to deal with the characteristics of different datasets in data\ndistribution and labeling. The lightweight adapter can quickly generalize the\ndeep network for new CD tasks with a small computation cost. Specifically, this\npaper proposes an interesting change region mask (ICM) in the adapter, which\ncan adaptively focus on interested change objects and decrease the influence of\nlabeling differences in various datasets. Moreover, CANet adopts a unique batch\nnormalization layer for each dataset to deal with data distribution\ndifferences. Compared with existing deep learning methods, CANet can achieve\nsatisfactory CD performances on various datasets simultaneously. Experimental\nresults on several public datasets have verified the effectiveness and\nadvantages of the proposed CANet on CD. CANet has a stronger generalization\nability, smaller training costs (merely updating 4.1%-7.7% parameters), and\nbetter performances under limited training datasets than other deep learning\nmethods, which also can be flexibly inserted with existing deep models.", "published": "2025-04-28 09:01:56", "link": "http://arxiv.org/abs/2504.19598v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "WILD: a new in-the-Wild Image Linkage Dataset for synthetic image attribution", "abstract": "Synthetic image source attribution is an open challenge, with an increasing\nnumber of image generators being released yearly. The complexity and the sheer\nnumber of available generative techniques, as well as the scarcity of\nhigh-quality open source datasets of diverse nature for this task, make\ntraining and benchmarking synthetic image source attribution models very\nchallenging. WILD is a new in-the-Wild Image Linkage Dataset designed to\nprovide a powerful training and benchmarking tool for synthetic image\nattribution models. The dataset is built out of a closed set of 10 popular\ncommercial generators, which constitutes the training base of attribution\nmodels, and an open set of 10 additional generators, simulating a real-world\nin-the-wild scenario. Each generator is represented by 1,000 images, for a\ntotal of 10,000 images in the closed set and 10,000 images in the open set.\nHalf of the images are post-processed with a wide range of operators. WILD\nallows benchmarking attribution models in a wide range of tasks, including\nclosed and open set identification and verification, and robust attribution\nwith respect to post-processing and adversarial attacks. Models trained on WILD\nare expected to benefit from the challenging scenario represented by the\ndataset itself. Moreover, an assessment of seven baseline methodologies on\nclosed and open set attribution is presented, including robustness tests with\nrespect to post-processing.", "published": "2025-04-28 08:58:34", "link": "http://arxiv.org/abs/2504.19595v1", "categories": ["cs.MM", "cs.AI", "cs.CV"], "primary_category": "cs.MM"}
{"title": "Mapping the Italian Telegram Ecosystem", "abstract": "Telegram has become a major space for political discourse and alternative\nmedia. However, its lack of moderation allows misinformation, extremism, and\ntoxicity to spread. While prior research focused on these particular phenomena\nor topics, these have mostly been examined separately, and a broader\nunderstanding of the Telegram ecosystem is still missing. In this work, we fill\nthis gap by conducting a large-scale analysis of the Italian Telegram sphere,\nleveraging a dataset of 186 million messages from 13,151 chats collected in\n2023. Using network analysis, Large Language Models, and toxicity detection\ntools, we examine how different thematic communities form, align ideologically,\nand engage in harmful discourse within the Italian cultural context. Results\nshow strong thematic and ideological homophily. We also identify mixed\nideological communities where far-left and far-right rhetoric coexist on\nparticular geopolitical issues. Beyond political analysis, we find that\ntoxicity, rather than being isolated in a few extreme chats, appears widely\nnormalized within highly toxic communities. Moreover, we find that Italian\ndiscourse primarily targets Black people, Jews, and gay individuals\nindependently of the topic. Finally, we uncover common trend of intra-national\nhostility, where Italians often attack other Italians, reflecting regional and\nintra-regional cultural conflicts that can be traced back to old historical\ndivisions. This study provides the first large-scale mapping of the Italian\nTelegram ecosystem, offering insights into ideological interactions, toxicity,\nand identity-targets of hate and contributing to research on online toxicity\nacross different cultural and linguistic contexts on Telegram.", "published": "2025-04-28 08:58:18", "link": "http://arxiv.org/abs/2504.19594v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "Neural network task specialization via domain constraining", "abstract": "This paper introduces a concept of neural network specialization via\ntask-specific domain constraining, aimed at enhancing network performance on\ndata subspace in which the network operates. The study presents experiments on\ntraining specialists for image classification and object detection tasks. The\nresults demonstrate that specialization can enhance a generalist's accuracy\neven without additional data or changing training regimes: solely by\nconstraining class label space in which the network performs. Theoretical and\nexperimental analyses indicate that effective specialization requires modifying\ntraditional fine-tuning methods and constraining data space to semantically\ncoherent subsets. The specialist extraction phase before tuning the network is\nproposed for maximal performance gains. We also provide analysis of the\nevolution of the feature space during specialization. This study paves way to\nfuture research for developing more advanced dynamically configurable image\nanalysis systems, where computations depend on the specific input.\nAdditionally, the proposed methods can help improve system performance in\nscenarios where certain data domains should be excluded from consideration of\nthe generalist network.", "published": "2025-04-28 08:57:01", "link": "http://arxiv.org/abs/2504.19592v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Point2Quad: Generating Quad Meshes from Point Clouds via Face Prediction", "abstract": "Quad meshes are essential in geometric modeling and computational mechanics.\nAlthough learning-based methods for triangle mesh demonstrate considerable\nadvancements, quad mesh generation remains less explored due to the challenge\nof ensuring coplanarity, convexity, and quad-only meshes. In this paper, we\npresent Point2Quad, the first learning-based method for quad-only mesh\ngeneration from point clouds. The key idea is learning to identify quad mesh\nwith fused pointwise and facewise features. Specifically, Point2Quad begins\nwith a k-NN-based candidate generation considering the coplanarity and\nsquareness. Then, two encoders are followed to extract geometric and\ntopological features that address the challenge of quad-related constraints,\nespecially by combining in-depth quadrilaterals-specific characteristics.\nSubsequently, the extracted features are fused to train the classifier with a\ndesigned compound loss. The final results are derived after the refinement by a\nquad-specific post-processing. Extensive experiments on both clear and noise\ndata demonstrate the effectiveness and superiority of Point2Quad, compared to\nbaseline methods under comprehensive metrics.", "published": "2025-04-28 07:48:17", "link": "http://arxiv.org/abs/2504.19545v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Graph Reinforcement Learning for QoS-Aware Load Balancing in Open Radio Access Networks", "abstract": "Next-generation wireless cellular networks are expected to provide\nunparalleled Quality-of-Service (QoS) for emerging wireless applications,\nnecessitating strict performance guarantees, e.g., in terms of link-level data\nrates. A critical challenge in meeting these QoS requirements is the prevention\nof cell congestion, which involves balancing the load to ensure sufficient\nradio resources are available for each cell to serve its designated User\nEquipments (UEs). In this work, a novel QoS-aware Load Balancing (LB) approach\nis developed to optimize the performance of Guaranteed Bit Rate (GBR) and Best\nEffort (BE) traffic in a multi-band Open Radio Access Network (O-RAN) under QoS\nand resource constraints. The proposed solution builds on Graph Reinforcement\nLearning (GRL), a powerful framework at the intersection of Graph Neural\nNetwork (GNN) and RL. The QoS-aware LB is modeled as a Markov Decision Process,\nwith states represented as graphs. QoS consideration are integrated into both\nstate representations and reward signal design. The LB agent is then trained\nusing an off-policy dueling Deep Q Network (DQN) that leverages a GNN-based\narchitecture. This design ensures the LB policy is invariant to the ordering of\nnodes (UE or cell), flexible in handling various network sizes, and capable of\naccounting for spatial node dependencies in LB decisions. Performance of the\nGRL-based solution is compared with two baseline methods. Results show\nsubstantial performance gains, including a $53\\%$ reduction in QoS violations\nand a fourfold increase in the 5th percentile rate for BE traffic.", "published": "2025-04-28 05:41:31", "link": "http://arxiv.org/abs/2504.19499v1", "categories": ["cs.AI", "cs.IT", "cs.LG", "cs.NI", "eess.SP", "math.IT"], "primary_category": "cs.AI"}
{"title": "DISCO: learning to DISCover an evolution Operator for multi-physics-agnostic prediction", "abstract": "We address the problem of predicting the next state of a dynamical system\ngoverned by unknown temporal partial differential equations (PDEs) using only a\nshort trajectory. While standard transformers provide a natural black-box\nsolution to this task, the presence of a well-structured evolution operator in\nthe data suggests a more tailored and efficient approach. Specifically, when\nthe PDE is fully known, classical numerical solvers can evolve the state\naccurately with only a few parameters. Building on this observation, we\nintroduce DISCO, a model that uses a large hypernetwork to process a short\ntrajectory and generate the parameters of a much smaller operator network,\nwhich then predicts the next state through time integration. Our framework\ndecouples dynamics estimation (i.e., DISCovering an evolution operator from a\nshort trajectory) from state prediction (i.e., evolving this operator).\nExperiments show that pretraining our model on diverse physics datasets\nachieves state-of-the-art performance while requiring significantly fewer\nepochs. Moreover, it generalizes well and remains competitive when fine-tuned\non downstream tasks.", "published": "2025-04-28 05:36:52", "link": "http://arxiv.org/abs/2504.19496v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Automated Reinforcement Learning Reward Design Framework with Large Language Model for Cooperative Platoon Coordination", "abstract": "Reinforcement Learning (RL) has demonstrated excellent decision-making\npotential in platoon coordination problems. However, due to the variability of\ncoordination goals, the complexity of the decision problem, and the\ntime-consumption of trial-and-error in manual design, finding a well\nperformance reward function to guide RL training to solve complex platoon\ncoordination problems remains challenging. In this paper, we formally define\nthe Platoon Coordination Reward Design Problem (PCRDP), extending the RL-based\ncooperative platoon coordination problem to incorporate automated reward\nfunction generation. To address PCRDP, we propose a Large Language Model\n(LLM)-based Platoon coordination Reward Design (PCRD) framework, which\nsystematically automates reward function discovery through LLM-driven\ninitialization and iterative optimization. In this method, LLM first\ninitializes reward functions based on environment code and task requirements\nwith an Analysis and Initial Reward (AIR) module, and then iteratively\noptimizes them based on training feedback with an evolutionary module. The AIR\nmodule guides LLM to deepen their understanding of code and tasks through a\nchain of thought, effectively mitigating hallucination risks in code\ngeneration. The evolutionary module fine-tunes and reconstructs the reward\nfunction, achieving a balance between exploration diversity and convergence\nstability for training. To validate our approach, we establish six challenging\ncoordination scenarios with varying complexity levels within the Yangtze River\nDelta transportation network simulation. Comparative experimental results\ndemonstrate that RL agents utilizing PCRD-generated reward functions\nconsistently outperform human-engineered reward functions, achieving an average\nof 10\\% higher performance metrics in all scenarios.", "published": "2025-04-28 04:41:15", "link": "http://arxiv.org/abs/2504.19480v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video", "abstract": "Robust tooling and publicly available pre-trained models have helped drive\nrecent advances in mechanistic interpretability for language models. However,\nsimilar progress in vision mechanistic interpretability has been hindered by\nthe lack of accessible frameworks and pre-trained weights. We present Prisma\n(Access the codebase here: https://github.com/Prisma-Multimodal/ViT-Prisma), an\nopen-source framework designed to accelerate vision mechanistic\ninterpretability research, providing a unified toolkit for accessing 75+ vision\nand video transformers; support for sparse autoencoder (SAE), transcoder, and\ncrosscoder training; a suite of 80+ pre-trained SAE weights; activation\ncaching, circuit analysis tools, and visualization tools; and educational\nresources. Our analysis reveals surprising findings, including that effective\nvision SAEs can exhibit substantially lower sparsity patterns than language\nSAEs, and that in some instances, SAE reconstructions can decrease model loss.\nPrisma enables new research directions for understanding vision model internals\nwhile lowering barriers to entry in this emerging field.", "published": "2025-04-28 04:31:24", "link": "http://arxiv.org/abs/2504.19475v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Real-Time Gesture-Based Control Framework", "abstract": "We introduce a real-time, human-in-the-loop gesture control framework that\ncan dynamically adapt audio and music based on human movement by analyzing live\nvideo input. By creating a responsive connection between visual and auditory\nstimuli, this system enables dancers and performers to not only respond to\nmusic but also influence it through their movements. Designed for live\nperformances, interactive installations, and personal use, it offers an\nimmersive experience where users can shape the music in real time.\n  The framework integrates computer vision and machine learning techniques to\ntrack and interpret motion, allowing users to manipulate audio elements such as\ntempo, pitch, effects, and playback sequence. With ongoing training, it\nachieves user-independent functionality, requiring as few as 50 to 80 samples\nto label simple gestures. This framework combines gesture training, cue\nmapping, and audio manipulation to create a dynamic, interactive experience.\nGestures are interpreted as input signals, mapped to sound control commands,\nand used to naturally adjust music elements, showcasing the seamless interplay\nbetween human interaction and machine response.", "published": "2025-04-28 03:57:28", "link": "http://arxiv.org/abs/2504.19460v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "CLIP-KOA: Enhancing Knee Osteoarthritis Diagnosis with Multi-Modal Learning and Symmetry-Aware Loss Functions", "abstract": "Knee osteoarthritis (KOA) is a universal chronic musculoskeletal disorders\nworldwide, making early diagnosis crucial. Currently, the Kellgren and Lawrence\n(KL) grading system is widely used to assess KOA severity. However, its high\ninter-observer variability and subjectivity hinder diagnostic consistency. To\naddress these limitations, automated diagnostic techniques using deep learning\nhave been actively explored in recent years. In this study, we propose a\nCLIP-based framework (CLIP-KOA) to enhance the consistency and reliability of\nKOA grade prediction. To achieve this, we introduce a learning approach that\nintegrates image and text information and incorporate Symmetry Loss and\nConsistency Loss to ensure prediction consistency between the original and\nflipped images. CLIP-KOA achieves state-of-the-art accuracy of 71.86\\% on KOA\nseverity prediction task, and ablation studies show that CLIP-KOA has 2.36\\%\nimprovement in accuracy over the standard CLIP model due to our contribution.\nThis study shows a novel direction for data-driven medical prediction not only\nto improve reliability of fine-grained diagnosis and but also to explore\nmultimodal methods for medical image analysis. Our code is available at\nhttps://github.com/anonymized-link.", "published": "2025-04-28 03:10:24", "link": "http://arxiv.org/abs/2504.19443v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "EarthMapper: Visual Autoregressive Models for Controllable Bidirectional Satellite-Map Translation", "abstract": "Satellite imagery and maps, as two fundamental data modalities in remote\nsensing, offer direct observations of the Earth's surface and\nhuman-interpretable geographic abstractions, respectively. The task of\nbidirectional translation between satellite images and maps (BSMT) holds\nsignificant potential for applications in urban planning and disaster response.\nHowever, this task presents two major challenges: first, the absence of precise\npixel-wise alignment between the two modalities substantially complicates the\ntranslation process; second, it requires achieving both high-level abstraction\nof geographic features and high-quality visual synthesis, which further\nelevates the technical complexity. To address these limitations, we introduce\nEarthMapper, a novel autoregressive framework for controllable bidirectional\nsatellite-map translation. EarthMapper employs geographic coordinate embeddings\nto anchor generation, ensuring region-specific adaptability, and leverages\nmulti-scale feature alignment within a geo-conditioned joint scale\nautoregression (GJSA) process to unify bidirectional translation in a single\ntraining cycle. A semantic infusion (SI) mechanism is introduced to enhance\nfeature-level consistency, while a key point adaptive guidance (KPAG) mechanism\nis proposed to dynamically balance diversity and precision during inference. We\nfurther contribute CNSatMap, a large-scale dataset comprising 302,132 precisely\naligned satellite-map pairs across 38 Chinese cities, enabling robust\nbenchmarking. Extensive experiments on CNSatMap and the New York dataset\ndemonstrate EarthMapper's superior performance, achieving significant\nimprovements in visual realism, semantic consistency, and structural fidelity\nover state-of-the-art methods. Additionally, EarthMapper excels in zero-shot\ntasks like in-painting, out-painting and coordinate-conditional generation,\nunderscoring its versatility.", "published": "2025-04-28 02:41:12", "link": "http://arxiv.org/abs/2504.19432v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Sharp higher order convergence rates for the Adam optimizer", "abstract": "Gradient descent based optimization methods are the methods of choice to\ntrain deep neural networks in machine learning. Beyond the standard gradient\ndescent method, also suitable modified variants of standard gradient descent\ninvolving acceleration techniques such as the momentum method and/or adaptivity\ntechniques such as the RMSprop method are frequently considered optimization\nmethods. These days the most popular of such sophisticated optimization schemes\nis presumably the Adam optimizer that has been proposed in 2014 by Kingma and\nBa. A highly relevant topic of research is to investigate the speed of\nconvergence of such optimization methods. In particular, in 1964 Polyak showed\nthat the standard gradient descent method converges in a neighborhood of a\nstrict local minimizer with rate (x - 1)(x + 1)^{-1} while momentum achieves\nthe (optimal) strictly faster convergence rate (\\sqrt{x} - 1)(\\sqrt{x} +\n1)^{-1} where x \\in (1,\\infty) is the condition number (the ratio of the\nlargest and the smallest eigenvalue) of the Hessian of the objective function\nat the local minimizer. It is the key contribution of this work to reveal that\nAdam also converges with the strictly faster convergence rate (\\sqrt{x} -\n1)(\\sqrt{x} + 1)^{-1} while RMSprop only converges with the convergence rate (x\n- 1)(x + 1)^{-1}.", "published": "2025-04-28 02:17:50", "link": "http://arxiv.org/abs/2504.19426v1", "categories": ["math.OC", "cs.AI", "68T05, 65K05, 90C25", "I.2.0"], "primary_category": "math.OC"}
{"title": "GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field", "abstract": "Semantic-aware 3D scene reconstruction is essential for autonomous robots to\nperform complex interactions. Semantic SLAM, an online approach, integrates\npose tracking, geometric reconstruction, and semantic mapping into a unified\nframework, shows significant potential. However, existing systems, which rely\non 2D ground truth priors for supervision, are often limited by the sparsity\nand noise of these signals in real-world environments. To address this\nchallenge, we propose GSFF-SLAM, a novel dense semantic SLAM system based on 3D\nGaussian Splatting that leverages feature fields to achieve joint rendering of\nappearance, geometry, and N-dimensional semantic features. By independently\noptimizing feature gradients, our method supports semantic reconstruction using\nvarious forms of 2D priors, particularly sparse and noisy signals. Experimental\nresults demonstrate that our approach outperforms previous methods in both\ntracking accuracy and photorealistic rendering quality. When utilizing 2D\nground truth priors, GSFF-SLAM achieves state-of-the-art semantic segmentation\nperformance with 95.03\\% mIoU, while achieving up to 2.9$\\times$ speedup with\nonly marginal performance degradation.", "published": "2025-04-28 01:21:35", "link": "http://arxiv.org/abs/2504.19409v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "CompleteMe: Reference-based Human Image Completion", "abstract": "Recent methods for human image completion can reconstruct plausible body\nshapes but often fail to preserve unique details, such as specific clothing\npatterns or distinctive accessories, without explicit reference images. Even\nstate-of-the-art reference-based inpainting approaches struggle to accurately\ncapture and integrate fine-grained details from reference images. To address\nthis limitation, we propose CompleteMe, a novel reference-based human image\ncompletion framework. CompleteMe employs a dual U-Net architecture combined\nwith a Region-focused Attention (RFA) Block, which explicitly guides the\nmodel's attention toward relevant regions in reference images. This approach\neffectively captures fine details and ensures accurate semantic correspondence,\nsignificantly improving the fidelity and consistency of completed images.\nAdditionally, we introduce a challenging benchmark specifically designed for\nevaluating reference-based human image completion tasks. Extensive experiments\ndemonstrate that our proposed method achieves superior visual quality and\nsemantic consistency compared to existing techniques. Project page:\nhttps://liagm.github.io/CompleteMe/", "published": "2025-04-28 17:59:56", "link": "http://arxiv.org/abs/2504.20042v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Streaming Video Representation via Multitask Training", "abstract": "Understanding continuous video streams plays a fundamental role in real-time\napplications including embodied AI and autonomous driving. Unlike offline video\nunderstanding, streaming video understanding requires the ability to process\nvideo streams frame by frame, preserve historical information, and make\nlow-latency decisions.To address these challenges, our main contributions are\nthree-fold. (i) We develop a novel streaming video backbone, termed as\nStreamFormer, by incorporating causal temporal attention into a pre-trained\nvision transformer. This enables efficient streaming video processing while\nmaintaining image representation capability.(ii) To train StreamFormer, we\npropose to unify diverse spatial-temporal video understanding tasks within a\nmultitask visual-language alignment framework. Hence, StreamFormer learns\nglobal semantics, temporal dynamics, and fine-grained spatial relationships\nsimultaneously. (iii) We conduct extensive experiments on online action\ndetection, online video instance segmentation, and video question answering.\nStreamFormer achieves competitive results while maintaining efficiency,\ndemonstrating its potential for real-time applications.", "published": "2025-04-28 17:59:54", "link": "http://arxiv.org/abs/2504.20041v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MP-SfM: Monocular Surface Priors for Robust Structure-from-Motion", "abstract": "While Structure-from-Motion (SfM) has seen much progress over the years,\nstate-of-the-art systems are prone to failure when facing extreme viewpoint\nchanges in low-overlap, low-parallax or high-symmetry scenarios. Because\ncapturing images that avoid these pitfalls is challenging, this severely limits\nthe wider use of SfM, especially by non-expert users. We overcome these\nlimitations by augmenting the classical SfM paradigm with monocular depth and\nnormal priors inferred by deep neural networks. Thanks to a tight integration\nof monocular and multi-view constraints, our approach significantly outperforms\nexisting ones under extreme viewpoint changes, while maintaining strong\nperformance in standard conditions. We also show that monocular priors can help\nreject faulty associations due to symmetries, which is a long-standing problem\nfor SfM. This makes our approach the first capable of reliably reconstructing\nchallenging indoor environments from few images. Through principled uncertainty\npropagation, it is robust to errors in the priors, can handle priors inferred\nby different models with little tuning, and will thus easily benefit from\nfuture progress in monocular depth and normal estimation. Our code is publicly\navailable at https://github.com/cvg/mpsfm.", "published": "2025-04-28 17:59:52", "link": "http://arxiv.org/abs/2504.20040v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Mitigating Catastrophic Forgetting in the Incremental Learning of Medical Images", "abstract": "This paper proposes an Incremental Learning (IL) approach to enhance the\naccuracy and efficiency of deep learning models in analyzing T2-weighted (T2w)\nMRI medical images prostate cancer detection using the PI-CAI dataset. We used\nmultiple health centers' artificial intelligence and radiology data, focused on\ndifferent tasks that looked at prostate cancer detection using MRI (PI-CAI). We\nutilized Knowledge Distillation (KD), as it employs generated images from past\ntasks to guide the training of models for subsequent tasks. The approach\nyielded improved performance and faster convergence of the models. To\ndemonstrate the versatility and robustness of our approach, we evaluated it on\nthe PI-CAI dataset, a diverse set of medical imaging modalities including OCT\nand PathMNIST, and the benchmark continual learning dataset CIFAR-10. Our\nresults indicate that KD can be a promising technique for IL in medical image\nanalysis in which data is sourced from individual health centers and the\nstorage of large datasets is not feasible. By using generated images from prior\ntasks, our method enables the model to retain and apply previously acquired\nknowledge without direct access to the original data.", "published": "2025-04-28 17:56:04", "link": "http://arxiv.org/abs/2504.20033v1", "categories": ["cs.CV", "I.2.6; I.2.10"], "primary_category": "cs.CV"}
{"title": "More Clear, More Flexible, More Precise: A Comprehensive Oriented Object Detection benchmark for UAV", "abstract": "Applications of unmanned aerial vehicle (UAV) in logistics, agricultural\nautomation, urban management, and emergency response are highly dependent on\noriented object detection (OOD) to enhance visual perception. Although existing\ndatasets for OOD in UAV provide valuable resources, they are often designed for\nspecific downstream tasks.Consequently, they exhibit limited generalization\nperformance in real flight scenarios and fail to thoroughly demonstrate\nalgorithm effectiveness in practical environments. To bridge this critical gap,\nwe introduce CODrone, a comprehensive oriented object detection dataset for\nUAVs that accurately reflects real-world conditions. It also serves as a new\nbenchmark designed to align with downstream task requirements, ensuring greater\napplicability and robustness in UAV-based OOD.Based on application\nrequirements, we identify four key limitations in current UAV OOD datasets-low\nimage resolution, limited object categories, single-view imaging, and\nrestricted flight altitudes-and propose corresponding improvements to enhance\ntheir applicability and robustness.Furthermore, CODrone contains a broad\nspectrum of annotated images collected from multiple cities under various\nlighting conditions, enhancing the realism of the benchmark. To rigorously\nevaluate CODrone as a new benchmark and gain deeper insights into the novel\nchallenges it presents, we conduct a series of experiments based on 22\nclassical or SOTA methods.Our evaluation not only assesses the effectiveness of\nCODrone in real-world scenarios but also highlights key bottlenecks and\nopportunities to advance OOD in UAV applications.Overall, CODrone fills the\ndata gap in OOD from UAV perspective and provides a benchmark with enhanced\ngeneralization capability, better aligning with practical applications and\nfuture algorithm development.", "published": "2025-04-28 17:56:02", "link": "http://arxiv.org/abs/2504.20032v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning", "abstract": "Recent studies in 3D spatial reasoning explore data-driven approaches and\nachieve enhanced spatial reasoning performance with reinforcement learning\n(RL). However, these methods typically perform spatial reasoning in an implicit\nmanner, and it remains underexplored whether the acquired 3D knowledge\ngeneralizes to unseen question types at any stage of the training. In this work\nwe introduce SpatialReasoner, a novel large vision-language model (LVLM) that\naddress 3D spatial reasoning with explicit 3D representations shared between\nstages -- 3D perception, computation, and reasoning. Explicit 3D\nrepresentations provide a coherent interface that supports advanced 3D spatial\nreasoning and enable us to study the factual errors made by LVLMs. Results show\nthat our SpatialReasoner achieve improved performance on a variety of spatial\nreasoning benchmarks and generalizes better when evaluating on novel 3D spatial\nreasoning questions. Our study bridges the 3D parsing capabilities of prior\nvisual foundation models with the powerful reasoning abilities of large\nlanguage models, opening new directions for 3D spatial reasoning.", "published": "2025-04-28 17:48:43", "link": "http://arxiv.org/abs/2504.20024v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mapping of Weed Management Methods in Orchards using Sentinel-2 and PlanetScope Data", "abstract": "Effective weed management is crucial for improving agricultural productivity,\nas weeds compete with crops for vital resources like nutrients and water.\nAccurate maps of weed management methods are essential for policymakers to\nassess farmer practices, evaluate impacts on vegetation health, biodiversity,\nand climate, as well as ensure compliance with policies and subsidies. However,\nmonitoring weed management methods is challenging as commonly rely on on-ground\nfield surveys, which are often costly, time-consuming and subject to delays. In\norder to tackle this problem, we leverage Earth Observation (EO) data and\nMachine Learning (ML). Specifically, we developed an ML approach for mapping\nfour distinct weed management methods (Mowing, Tillage, Chemical-spraying, and\nNo practice) in orchards using satellite image time series (SITS) data from two\ndifferent sources: Sentinel-2 (S2) and PlanetScope (PS). The findings\ndemonstrate the potential of ML-driven remote sensing to enhance the efficiency\nand accuracy of weed management mapping in orchards.", "published": "2025-04-28 17:09:10", "link": "http://arxiv.org/abs/2504.19991v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Shopformer: Transformer-Based Framework for Detecting Shoplifting via Human Pose", "abstract": "Shoplifting remains a costly issue for the retail sector, but traditional\nsurveillance systems, which are mostly based on human monitoring, are still\nlargely ineffective, with only about 2% of shoplifters being arrested. Existing\nAI-based approaches rely on pixel-level video analysis which raises privacy\nconcerns, is sensitive to environmental variations, and demands significant\ncomputational resources. To address these limitations, we introduce Shopformer,\na novel transformer-based model that detects shoplifting by analyzing pose\nsequences rather than raw video. We propose a custom tokenization strategy that\nconverts pose sequences into compact embeddings for efficient transformer\nprocessing. To the best of our knowledge, this is the first pose-sequence-based\ntransformer model for shoplifting detection. Evaluated on real-world pose data,\nour method outperforms state-of-the-art anomaly detection models, offering a\nprivacy-preserving, and scalable solution for real-time retail surveillance.\nThe code base for this work is available at\nhttps://github.com/TeCSAR-UNCC/Shopformer.", "published": "2025-04-28 16:43:01", "link": "http://arxiv.org/abs/2504.19970v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mesh-Learner: Texturing Mesh with Spherical Harmonics", "abstract": "In this paper, we present a 3D reconstruction and rendering framework termed\nMesh-Learner that is natively compatible with traditional rasterization\npipelines. It integrates mesh and spherical harmonic (SH) texture (i.e.,\ntexture filled with SH coefficients) into the learning process to learn each\nmesh s view-dependent radiance end-to-end. Images are rendered by interpolating\nsurrounding SH Texels at each pixel s sampling point using a novel\ninterpolation method. Conversely, gradients from each pixel are back-propagated\nto the related SH Texels in SH textures. Mesh-Learner exploits graphic features\nof rasterization pipeline (texture sampling, deferred rendering) to render,\nwhich makes Mesh-Learner naturally compatible with tools (e.g., Blender) and\ntasks (e.g., 3D reconstruction, scene rendering, reinforcement learning for\nrobotics) that are based on rasterization pipelines. Our system can train vast,\nunlimited scenes because we transfer only the SH textures within the frustum to\nthe GPU for training. At other times, the SH textures are stored in CPU RAM,\nwhich results in moderate GPU memory usage. The rendering results on\ninterpolation and extrapolation sequences in the Replica and FAST-LIVO2\ndatasets achieve state-of-the-art performance compared to existing\nstate-of-the-art methods (e.g., 3D Gaussian Splatting and M2-Mapping). To\nbenefit the society, the code will be available at\nhttps://github.com/hku-mars/Mesh-Learner.", "published": "2025-04-28 16:09:25", "link": "http://arxiv.org/abs/2504.19938v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Enhancing Quality for VVC Compressed Videos with Omniscient Quality Enhancement Model", "abstract": "The latest video coding standard H.266/VVC has shown its great improvement in\nterms of compression performance when compared to its predecessor HEVC\nstandard. Though VVC was implemented with many advanced techniques, it still\nmet the same challenges as its predecessor due to the need for even higher\nperceptual quality demand at the decoder side as well as the compression\nperformance at the encoder side. The advancement of Artificial Intelligence\n(AI) technology, notably the deep learning-based video quality enhancement\nmethods, was shown to be a promising approach to improving the perceptual\nquality experience. In this paper, we propose a novel Omniscient video quality\nenhancement Network for VVC compressed Videos. The Omniscient Network for\ncompressed video quality enhancement was originally designed for HEVC\ncompressed videos in which not only the spatial-temporal features but also\ncross-frequencies information were employed to augment the visual quality.\nInspired by this work, we propose a modification of the OVQE model and\nintegrate it into the lasted STD-VVC (Standard Versatile Video Coding) decoder\narchitecture. As assessed in a rich set of test conditions, the proposed\nOVQE-VVC solution is able to achieve significant PSNR improvement, notably\naround 0.74 dB and up to 1.2 dB with respect to the original STD-VVC codec.\nThis also corresponds to around 19.6% of bitrate saving while keeping a similar\nquality observation.", "published": "2025-04-28 16:08:49", "link": "http://arxiv.org/abs/2504.19935v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Accelerated 3D-3D rigid registration of echocardiographic images obtained from apical window using particle filter", "abstract": "The perfect alignment of 3D echocardiographic images captured from various\nangles has improved image quality and broadened the field of view. This study\nproposes an accelerated sequential Monte Carlo (SMC) algorithm for 3D-3D rigid\nregistration of transthoracic echocardiographic images with significant and\nlimited overlap taken from apical window that is robust to the noise and\nintensity variation in ultrasound images. The algorithm estimates the\ntranslational and rotational components of the rigid transform through an\niterative process and requires an initial approximation of the rotation and\ntranslation limits. We perform registration in two ways: the image-based\nregistration computes the transform to align the end-diastolic frame of the\napical nonstandard image to the apical standard image and applies the same\ntransform to all frames of the cardiac cycle, whereas the mask-based\nregistration approach uses the binary masks of the left ventricle in the same\nway. The SMC and exhaustive search (EX) algorithms were evaluated for 4D\ntemporal sequences recorded from 7 volunteers who participated in a study\nconducted at the Mazankowski Alberta Heart Institute. The evaluations\ndemonstrate that the mask-based approach of the accelerated SMC yielded a Dice\nscore value of 0.819 +/- 0.045 for the left ventricle and gained 16.7x speedup\ncompared to the CPU version of the SMC algorithm.", "published": "2025-04-28 16:06:24", "link": "http://arxiv.org/abs/2504.19930v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "CineVerse: Consistent Keyframe Synthesis for Cinematic Scene Composition", "abstract": "We present CineVerse, a novel framework for the task of cinematic scene\ncomposition. Similar to traditional multi-shot generation, our task emphasizes\nthe need for consistency and continuity across frames. However, our task also\nfocuses on addressing challenges inherent to filmmaking, such as multiple\ncharacters, complex interactions, and visual cinematic effects. In order to\nlearn to generate such content, we first create the CineVerse dataset. We use\nthis dataset to train our proposed two-stage approach. First, we prompt a large\nlanguage model (LLM) with task-specific instructions to take in a high-level\nscene description and generate a detailed plan for the overall setting and\ncharacters, as well as the individual shots. Then, we fine-tune a text-to-image\ngeneration model to synthesize high-quality visual keyframes. Experimental\nresults demonstrate that CineVerse yields promising improvements in generating\nvisually coherent and contextually rich movie scenes, paving the way for\nfurther exploration in cinematic video synthesis.", "published": "2025-04-28 15:28:14", "link": "http://arxiv.org/abs/2504.19894v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing breast cancer detection on screening mammogram using self-supervised learning and a hybrid deep model of Swin Transformer and Convolutional Neural Network", "abstract": "Purpose: The scarcity of high-quality curated labeled medical training data\nremains one of the major limitations in applying artificial intelligence (AI)\nsystems to breast cancer diagnosis. Deep models for mammogram analysis and mass\n(or micro-calcification) detection require training with a large volume of\nlabeled images, which are often expensive and time-consuming to collect. To\nreduce this challenge, we proposed a novel method that leverages\nself-supervised learning (SSL) and a deep hybrid model, named \\textbf{HybMNet},\nwhich combines local self-attention and fine-grained feature extraction to\nenhance breast cancer detection on screening mammograms.\n  Approach: Our method employs a two-stage learning process: (1) SSL\nPretraining: We utilize EsViT, a SSL technique, to pretrain a Swin Transformer\n(Swin-T) using a limited set of mammograms. The pretrained Swin-T then serves\nas the backbone for the downstream task. (2) Downstream Training: The proposed\nHybMNet combines the Swin-T backbone with a CNN-based network and a novel\nfusion strategy. The Swin-T employs local self-attention to identify\ninformative patch regions from the high-resolution mammogram, while the\nCNN-based network extracts fine-grained local features from the selected\npatches. A fusion module then integrates global and local information from both\nnetworks to generate robust predictions. The HybMNet is trained end-to-end,\nwith the loss function combining the outputs of the Swin-T and CNN modules to\noptimize feature extraction and classification performance.\n  Results: The proposed method was evaluated for its ability to detect breast\ncancer by distinguishing between benign (normal) and malignant mammograms.\nLeveraging SSL pretraining and the HybMNet model, it achieved AUC of 0.864 (95%\nCI: 0.852, 0.875) on the CMMD dataset and 0.889 (95% CI: 0.875, 0.903) on the\nINbreast dataset, highlighting its effectiveness.", "published": "2025-04-28 15:23:28", "link": "http://arxiv.org/abs/2504.19888v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Federated Out-of-Distribution Generalization: A Causal Augmentation View", "abstract": "Federated learning aims to collaboratively model by integrating multi-source\ninformation to obtain a model that can generalize across all client data.\nExisting methods often leverage knowledge distillation or data augmentation to\nmitigate the negative impact of data bias across clients. However, the limited\nperformance of teacher models on out-of-distribution samples and the inherent\nquality gap between augmented and original data hinder their effectiveness and\nthey typically fail to leverage the advantages of incorporating rich contextual\ninformation. To address these limitations, this paper proposes a Federated\nCausal Augmentation method, termed FedCAug, which employs causality-inspired\ndata augmentation to break the spurious correlation between attributes and\ncategories. Specifically, it designs a causal region localization module to\naccurately identify and decouple the background and objects in the image,\nproviding rich contextual information for causal data augmentation.\nAdditionally, it designs a causality-inspired data augmentation module that\nintegrates causal features and within-client context to generate counterfactual\nsamples. This significantly enhances data diversity, and the entire process\ndoes not require any information sharing between clients, thereby contributing\nto the protection of data privacy. Extensive experiments conducted on three\ndatasets reveal that FedCAug markedly reduces the model's reliance on\nbackground to predict sample labels, achieving superior performance compared to\nstate-of-the-art methods.", "published": "2025-04-28 15:13:48", "link": "http://arxiv.org/abs/2504.19882v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Using Fixed and Mobile Eye Tracking to Understand How Visitors View Art in a Museum: A Study at the Bowes Museum, County Durham, UK", "abstract": "The following paper describes a collaborative project involving researchers\nat Durham University, and professionals at the Bowes Museum, Barnard Castle,\nCounty Durham, UK, during which we used fixed and mobile eye tracking to\nunderstand how visitors view art. Our study took place during summer 2024 and\nbuilds on work presented at DH2017 (Bailey-Ross et al., 2017). Our\ninterdisciplinary team included researchers from digital humanities,\npsychology, art history and computer science, working in collaboration with\nprofessionals from the museum. We used fixed and mobile eye tracking to\nunderstand how museum visitors view art in a physical gallery setting. This\nresearch will enable us to make recommendations about how the Museum's\ncollections could be more effectively displayed, encouraging visitors to engage\nwith them more fully.", "published": "2025-04-28 15:12:30", "link": "http://arxiv.org/abs/2504.19881v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DeeCLIP: A Robust and Generalizable Transformer-Based Framework for Detecting AI-Generated Images", "abstract": "This paper introduces DeeCLIP, a novel framework for detecting AI-generated\nimages using CLIP-ViT and fusion learning. Despite significant advancements in\ngenerative models capable of creating highly photorealistic images, existing\ndetection methods often struggle to generalize across different models and are\nhighly sensitive to minor perturbations. To address these challenges, DeeCLIP\nincorporates DeeFuser, a fusion module that combines high-level and low-level\nfeatures, improving robustness against degradations such as compression and\nblurring. Additionally, we apply triplet loss to refine the embedding space,\nenhancing the model's ability to distinguish between real and synthetic\ncontent. To further enable lightweight adaptation while preserving pre-trained\nknowledge, we adopt parameter-efficient fine-tuning using low-rank adaptation\n(LoRA) within the CLIP-ViT backbone. This approach supports effective zero-shot\nlearning without sacrificing generalization. Trained exclusively on 4-class\nProGAN data, DeeCLIP achieves an average accuracy of 89.00% on 19 test subsets\ncomposed of generative adversarial network (GAN) and diffusion models. Despite\nhaving fewer trainable parameters, DeeCLIP outperforms existing methods,\ndemonstrating superior robustness against various generative models and\nreal-world distortions. The code is publicly available at\nhttps://github.com/Mamadou-Keita/DeeCLIP for research purposes.", "published": "2025-04-28 15:06:28", "link": "http://arxiv.org/abs/2504.19876v1", "categories": ["cs.CV", "cs.CR"], "primary_category": "cs.CV"}
{"title": "CoherenDream: Boosting Holistic Text Coherence in 3D Generation via Multimodal Large Language Models Feedback", "abstract": "Score Distillation Sampling (SDS) has achieved remarkable success in\ntext-to-3D content generation. However, SDS-based methods struggle to maintain\nsemantic fidelity for user prompts, particularly when involving multiple\nobjects with intricate interactions. While existing approaches often address 3D\nconsistency through multiview diffusion model fine-tuning on 3D datasets, this\nstrategy inadvertently exacerbates text-3D alignment degradation. The\nlimitation stems from SDS's inherent accumulation of view-independent biases\nduring optimization, which progressively diverges from the ideal text alignment\ndirection. To alleviate this limitation, we propose a novel SDS objective,\ndubbed as Textual Coherent Score Distillation (TCSD), which integrates\nalignment feedback from multimodal large language models (MLLMs). Our TCSD\nleverages cross-modal understanding capabilities of MLLMs to assess and guide\nthe text-3D correspondence during the optimization. We further develop\n3DLLaVA-CRITIC - a fine-tuned MLLM specialized for evaluating multiview text\nalignment in 3D generations. Additionally, we introduce an LLM-layout\ninitialization that significantly accelerates optimization convergence through\nsemantic-aware spatial configuration. Comprehensive evaluations demonstrate\nthat our framework, CoherenDream, establishes state-of-the-art performance in\ntext-aligned 3D generation across multiple benchmarks, including T$^3$Bench and\nTIFA subset. Qualitative results showcase the superior performance of\nCoherenDream in preserving textual consistency and semantic interactions. As\nthe first study to incorporate MLLMs into SDS optimization, we also conduct\nextensive ablation studies to explore optimal MLLM adaptations for 3D\ngeneration tasks.", "published": "2025-04-28 14:50:45", "link": "http://arxiv.org/abs/2504.19860v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SRMF: A Data Augmentation and Multimodal Fusion Approach for Long-Tail UHR Satellite Image Segmentation", "abstract": "The long-tail problem presents a significant challenge to the advancement of\nsemantic segmentation in ultra-high-resolution (UHR) satellite imagery. While\nprevious efforts in UHR semantic segmentation have largely focused on\nmulti-branch network architectures that emphasize multi-scale feature\nextraction and fusion, they have often overlooked the importance of addressing\nthe long-tail issue. In contrast to prior UHR methods that focused on\nindependent feature extraction, we emphasize data augmentation and multimodal\nfeature fusion to alleviate the long-tail problem. In this paper, we introduce\nSRMF, a novel framework for semantic segmentation in UHR satellite imagery. Our\napproach addresses the long-tail class distribution by incorporating a\nmulti-scale cropping technique alongside a data augmentation strategy based on\nsemantic reordering and resampling. To further enhance model performance, we\npropose a multimodal fusion-based general representation knowledge injection\nmethod, which, for the first time, fuses text and visual features without the\nneed for individual region text descriptions, extracting more robust features.\nExtensive experiments on the URUR, GID, and FBP datasets demonstrate that our\nmethod improves mIoU by 3.33\\%, 0.66\\%, and 0.98\\%, respectively, achieving\nstate-of-the-art performance. Code is available at:\nhttps://github.com/BinSpa/SRMF.git.", "published": "2025-04-28 14:39:59", "link": "http://arxiv.org/abs/2504.19839v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AnimateAnywhere: Rouse the Background in Human Image Animation", "abstract": "Human image animation aims to generate human videos of given characters and\nbackgrounds that adhere to the desired pose sequence. However, existing methods\nfocus more on human actions while neglecting the generation of background,\nwhich typically leads to static results or inharmonious movements. The\ncommunity has explored camera pose-guided animation tasks, yet preparing the\ncamera trajectory is impractical for most entertainment applications and\nordinary users. As a remedy, we present an AnimateAnywhere framework, rousing\nthe background in human image animation without requirements on camera\ntrajectories. In particular, based on our key insight that the movement of the\nhuman body often reflects the motion of the background, we introduce a\nbackground motion learner (BML) to learn background motions from human pose\nsequences. To encourage the model to learn more accurate cross-frame\ncorrespondences, we further deploy an epipolar constraint on the 3D attention\nmap. Specifically, the mask used to suppress geometrically unreasonable\nattention is carefully constructed by combining an epipolar mask and the\ncurrent 3D attention map. Extensive experiments demonstrate that our\nAnimateAnywhere effectively learns the background motion from human pose\nsequences, achieving state-of-the-art performance in generating human animation\nresults with vivid and realistic backgrounds. The source code and model will be\navailable at https://github.com/liuxiaoyu1104/AnimateAnywhere.", "published": "2025-04-28 14:35:01", "link": "http://arxiv.org/abs/2504.19834v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HOIGaze: Gaze Estimation During Hand-Object Interactions in Extended Reality Exploiting Eye-Hand-Head Coordination", "abstract": "We present HOIGaze - a novel learning-based approach for gaze estimation\nduring hand-object interactions (HOI) in extended reality (XR). HOIGaze\naddresses the challenging HOI setting by building on one key insight: The eye,\nhand, and head movements are closely coordinated during HOIs and this\ncoordination can be exploited to identify samples that are most useful for gaze\nestimator training - as such, effectively denoising the training data. This\ndenoising approach is in stark contrast to previous gaze estimation methods\nthat treated all training samples as equal. Specifically, we propose: 1) a\nnovel hierarchical framework that first recognises the hand currently visually\nattended to and then estimates gaze direction based on the attended hand; 2) a\nnew gaze estimator that uses cross-modal Transformers to fuse head and\nhand-object features extracted using a convolutional neural network and a\nspatio-temporal graph convolutional network; and 3) a novel eye-head\ncoordination loss that upgrades training samples belonging to the coordinated\neye-head movements. We evaluate HOIGaze on the HOT3D and Aria digital twin\n(ADT) datasets and show that it significantly outperforms state-of-the-art\nmethods, achieving an average improvement of 15.6% on HOT3D and 6.0% on ADT in\nmean angular error. To demonstrate the potential of our method, we further\nreport significant performance improvements for the sample downstream task of\neye-based activity recognition on ADT. Taken together, our results underline\nthe significant information content available in eye-hand-head coordination\nand, as such, open up an exciting new direction for learning-based gaze\nestimation.", "published": "2025-04-28 14:31:43", "link": "http://arxiv.org/abs/2504.19828v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Taming the Randomness: Towards Label-Preserving Cropping in Contrastive Learning", "abstract": "Contrastive learning (CL) approaches have gained great recognition as a very\nsuccessful subset of self-supervised learning (SSL) methods. SSL enables\nlearning from unlabeled data, a crucial step in the advancement of deep\nlearning, particularly in computer vision (CV), given the plethora of unlabeled\nimage data. CL works by comparing different random augmentations (e.g.,\ndifferent crops) of the same image, thus achieving self-labeling. Nevertheless,\nrandomly augmenting images and especially random cropping can result in an\nimage that is semantically very distant from the original and therefore leads\nto false labeling, hence undermining the efficacy of the methods. In this\nresearch, two novel parameterized cropping methods are introduced that increase\nthe robustness of self-labeling and consequently increase the efficacy. The\nresults show that the use of these methods significantly improves the accuracy\nof the model by between 2.7\\% and 12.4\\% on the downstream task of classifying\nCIFAR-10, depending on the crop size compared to that of the non-parameterized\nrandom cropping method.", "published": "2025-04-28 14:24:25", "link": "http://arxiv.org/abs/2504.19824v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Joint Optimization of Neural Radiance Fields and Continuous Camera Motion from a Monocular Video", "abstract": "Neural Radiance Fields (NeRF) has demonstrated its superior capability to\nrepresent 3D geometry but require accurately precomputed camera poses during\ntraining. To mitigate this requirement, existing methods jointly optimize\ncamera poses and NeRF often relying on good pose initialisation or depth\npriors. However, these approaches struggle in challenging scenarios, such as\nlarge rotations, as they map each camera to a world coordinate system. We\npropose a novel method that eliminates prior dependencies by modeling\ncontinuous camera motions as time-dependent angular velocity and velocity.\nRelative motions between cameras are learned first via velocity integration,\nwhile camera poses can be obtained by aggregating such relative motions up to a\nworld coordinate system defined at a single time step within the video.\nSpecifically, accurate continuous camera movements are learned through a\ntime-dependent NeRF, which captures local scene geometry and motion by training\nfrom neighboring frames for each time step. The learned motions enable\nfine-tuning the NeRF to represent the full scene geometry. Experiments on Co3D\nand Scannet show our approach achieves superior camera pose and depth\nestimation and comparable novel-view synthesis performance compared to\nstate-of-the-art methods. Our code is available at\nhttps://github.com/HoangChuongNguyen/cope-nerf.", "published": "2025-04-28 14:22:04", "link": "http://arxiv.org/abs/2504.19819v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Brenier Potentials with Convex Generative Adversarial Neural Networks", "abstract": "Brenier proved that under certain conditions on a source and a target\nprobability measure there exists a strictly convex function such that its\ngradient is a transport map from the source to the target distribution. This\nfunction is called the Brenier potential. Furthermore, detailed information on\nthe H\\\"older regularity of the Brenier potential is available. In this work we\ndevelop the statistical learning theory of generative adversarial neural\nnetworks that learn the Brenier potential. As by the transformation of\ndensities formula, the density of the generated measure depends on the second\nderivative of the Brenier potential, we develop the universal approximation\ntheory of ReCU networks with cubic activation $\\mathtt{ReCU}(x)=\\max\\{0,x\\}^3$\nthat combines the favorable approximation properties of H\\\"older functions with\na Lipschitz continuous density. In order to assure the convexity of such\ngeneral networks, we introduce an adversarial training procedure for a\npotential function represented by the ReCU networks that combines the classical\ndiscriminator cross entropy loss with a penalty term that enforces (strict)\nconvexity. We give a detailed decomposition of learning errors and show that\nfor a suitable high penalty parameter all networks chosen in the adversarial\nmin-max optimization problem are strictly convex. This is further exploited to\nprove the consistency of the learning procedure for (slowly) expanding network\ncapacity. We also implement the described learning algorithm and apply it to a\nnumber of standard test cases from Gaussian mixture to image data as target\ndistributions. As predicted in theory, we observe that the convexity loss\nbecomes inactive during the training process and the potentials represented by\nthe neural networks have learned convexity.", "published": "2025-04-28 13:24:52", "link": "http://arxiv.org/abs/2504.19779v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "STCOcc: Sparse Spatial-Temporal Cascade Renovation for 3D Occupancy and Scene Flow Prediction", "abstract": "3D occupancy and scene flow offer a detailed and dynamic representation of 3D\nscene. Recognizing the sparsity and complexity of 3D space, previous\nvision-centric methods have employed implicit learning-based approaches to\nmodel spatial and temporal information. However, these approaches struggle to\ncapture local details and diminish the model's spatial discriminative ability.\nTo address these challenges, we propose a novel explicit state-based modeling\nmethod designed to leverage the occupied state to renovate the 3D features.\nSpecifically, we propose a sparse occlusion-aware attention mechanism,\nintegrated with a cascade refinement strategy, which accurately renovates 3D\nfeatures with the guidance of occupied state information. Additionally, we\nintroduce a novel method for modeling long-term dynamic interactions, which\nreduces computational costs and preserves spatial information. Compared to the\nprevious state-of-the-art methods, our efficient explicit renovation strategy\nnot only delivers superior performance in terms of RayIoU and mAVE for\noccupancy and scene flow prediction but also markedly reduces GPU memory usage\nduring training, bringing it down to 8.7GB. Our code is available on\nhttps://github.com/lzzzzzm/STCOcc", "published": "2025-04-28 12:49:20", "link": "http://arxiv.org/abs/2504.19749v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EcoWikiRS: Learning Ecological Representation of Satellite Images from Weak Supervision with Species Observations and Wikipedia", "abstract": "The presence of species provides key insights into the ecological properties\nof a location such as land cover, climatic conditions or even soil properties.\nWe propose a method to predict such ecological properties directly from remote\nsensing (RS) images by aligning them with species habitat descriptions. We\nintroduce the EcoWikiRS dataset, consisting of high-resolution aerial images,\nthe corresponding geolocated species observations, and, for each species, the\ntextual descriptions of their habitat from Wikipedia. EcoWikiRS offers a\nscalable way of supervision for RS vision language models (RS-VLMs) for\necology. This is a setting with weak and noisy supervision, where, for\ninstance, some text may describe properties that are specific only to part of\nthe species' niche or is irrelevant to a specific image. We tackle this by\nproposing WINCEL, a weighted version of the InfoNCE loss. We evaluate our model\non the task of ecosystem zero-shot classification by following the habitat\ndefinitions from the European Nature Information System (EUNIS). Our results\nshow that our approach helps in understanding RS images in a more ecologically\nmeaningful manner. The code and the dataset are available at\nhttps://github.com/eceo-epfl/EcoWikiRS.", "published": "2025-04-28 12:42:18", "link": "http://arxiv.org/abs/2504.19742v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Contrastive Language-Image Learning with Augmented Textual Prompts for 3D/4D FER Using Vision-Language Model", "abstract": "In this paper, we introduce AffectVLM, a vision-language model designed to\nintegrate multiviews for a semantically rich and visually comprehensive\nunderstanding of facial emotions from 3D/4D data. To effectively capture visual\nfeatures, we propose a joint representation learning framework paired with a\nnovel gradient-friendly loss function that accelerates model convergence\ntowards optimal feature representation. Additionally, we introduce augmented\ntextual prompts to enhance the model's linguistic capabilities and employ mixed\nview augmentation to expand the visual dataset. We also develop a Streamlit app\nfor a real-time interactive inference and enable the model for distributed\nlearning. Extensive experiments validate the superior performance of AffectVLM\nacross multiple benchmarks.", "published": "2025-04-28 12:36:14", "link": "http://arxiv.org/abs/2504.19739v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CoDEx: Combining Domain Expertise for Spatial Generalization in Satellite Image Analysis", "abstract": "Global variations in terrain appearance raise a major challenge for satellite\nimage analysis, leading to poor model performance when training on locations\nthat differ from those encountered at test time. This remains true even with\nrecent large global datasets. To address this challenge, we propose a novel\ndomain-generalization framework for satellite images. Instead of trying to\nlearn a single generalizable model, we train one expert model per training\ndomain, while learning experts' similarity and encouraging similar experts to\nbe consistent. A model selection module then identifies the most suitable\nexperts for a given test sample and aggregates their predictions. Experiments\non four datasets (DynamicEarthNet, MUDS, OSCD, and FMoW) demonstrate consistent\ngains over existing domain generalization and adaptation methods. Our code is\npublicly available at https://github.com/Abhishek19009/CoDEx.", "published": "2025-04-28 12:33:39", "link": "http://arxiv.org/abs/2504.19737v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Measuring Train Driver Performance as Key to Approval of Driverless Trains", "abstract": "Points 2.1.4(b), 2.4.2(b) and 2.4.3(b) in Annex I of Implementing Regulation\n(EU) No. 402/2013 allow a simplified approach for the safety approval of\ncomputer vision systems for driverless trains, if they have 'similar' functions\nand interfaces as the replaced human driver. The human driver is not replaced\none-to-one by a technical system - only a limited set of cognitive functions\nare replaced. However, performance in the most challenging function, obstacle\ndetection, is difficult to quantify due to the deficiency of published\nmeasurement results. This article summarizes the data published so far. This\narticle also goes a long way to remedy this situation by providing a new public\nand anonymized dataset of 711 train driver performance measurements from\ncontrolled experiments. The measurements are made for different speeds,\nobstacle sizes, train protection systems and obstacle color contrasts\nrespectively. The measured values are reaction time and distance to the\nobstacle. The goal of this paper is an unbiased and exhaustive description of\nthe presented dataset for research, standardization and regulation. Further\nproject related information including the dataset and source code is available\nat https://atosense-02371c.usercontent.opencode.de/", "published": "2025-04-28 12:32:43", "link": "http://arxiv.org/abs/2504.19735v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RepText: Rendering Visual Text via Replicating", "abstract": "Although contemporary text-to-image generation models have achieved\nremarkable breakthroughs in producing visually appealing images, their capacity\nto generate precise and flexible typographic elements, especially non-Latin\nalphabets, remains constrained. To address these limitations, we start from an\nnaive assumption that text understanding is only a sufficient condition for\ntext rendering, but not a necessary condition. Based on this, we present\nRepText, which aims to empower pre-trained monolingual text-to-image generation\nmodels with the ability to accurately render, or more precisely, replicate,\nmultilingual visual text in user-specified fonts, without the need to really\nunderstand them. Specifically, we adopt the setting from ControlNet and\nadditionally integrate language agnostic glyph and position of rendered text to\nenable generating harmonized visual text, allowing users to customize text\ncontent, font and position on their needs. To improve accuracy, a text\nperceptual loss is employed along with the diffusion loss. Furthermore, to\nstabilize rendering process, at the inference phase, we directly initialize\nwith noisy glyph latent instead of random initialization, and adopt region\nmasks to restrict the feature injection to only the text region to avoid\ndistortion of the background. We conducted extensive experiments to verify the\neffectiveness of our RepText relative to existing works, our approach\noutperforms existing open-source methods and achieves comparable results to\nnative multi-language closed-source models. To be more fair, we also\nexhaustively discuss its limitations in the end.", "published": "2025-04-28 12:19:53", "link": "http://arxiv.org/abs/2504.19724v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The ATLAS of Traffic Lights: A Reliable Perception Framework for Autonomous Driving", "abstract": "Traffic light perception is an essential component of the camera-based\nperception system for autonomous vehicles, enabling accurate detection and\ninterpretation of traffic lights to ensure safe navigation through complex\nurban environments. In this work, we propose a modularized perception framework\nthat integrates state-of-the-art detection models with a novel real-time\nassociation and decision framework, enabling seamless deployment into an\nautonomous driving stack. To address the limitations of existing public\ndatasets, we introduce the ATLAS dataset, which provides comprehensive\nannotations of traffic light states and pictograms across diverse environmental\nconditions and camera setups. This dataset is publicly available at\nhttps://url.fzi.de/ATLAS. We train and evaluate several state-of-the-art\ntraffic light detection architectures on ATLAS, demonstrating significant\nperformance improvements in both accuracy and robustness. Finally, we evaluate\nthe framework in real-world scenarios by deploying it in an autonomous vehicle\nto make decisions at traffic light-controlled intersections, highlighting its\nreliability and effectiveness for real-time operation.", "published": "2025-04-28 12:15:42", "link": "http://arxiv.org/abs/2504.19722v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A computer vision method to estimate ventilation rate of Atlantic salmon in sea fish farms", "abstract": "The increasing demand for aquaculture production necessitates the development\nof innovative, intelligent tools to effectively monitor and manage fish health\nand welfare. While non-invasive video monitoring has become a common practice\nin finfish aquaculture, existing intelligent monitoring methods predominantly\nfocus on assessing body condition or fish swimming patterns and are often\ndeveloped and evaluated in controlled tank environments, without demonstrating\ntheir applicability to real-world aquaculture settings in open sea farms. This\nunderscores the necessity for methods that can monitor physiological traits\ndirectly within the production environment of sea fish farms. To this end, we\nhave developed a computer vision method for monitoring ventilation rates of\nAtlantic salmon (Salmo salar), which was specifically designed for videos\nrecorded in the production environment of commercial sea fish farms using the\nexisting infrastructure. Our approach uses a fish head detection model, which\nclassifies the mouth state as either open or closed using a convolutional\nneural network. This is followed with multiple object tracking to create\ntemporal sequences of fish swimming across the field of view of the underwater\nvideo camera to estimate ventilation rates. The method demonstrated high\nefficiency, achieving a Pearson correlation coefficient of 0.82 between ground\ntruth and predicted ventilation rates in a test set of 100 fish collected\nindependently of the training data. By accurately identifying pens where fish\nexhibit signs of respiratory distress, our method offers broad applicability\nand the potential to transform fish health and welfare monitoring in finfish\naquaculture.", "published": "2025-04-28 12:13:57", "link": "http://arxiv.org/abs/2504.19719v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pixels2Points: Fusing 2D and 3D Features for Facial Skin Segmentation", "abstract": "Face registration deforms a template mesh to closely fit a 3D face scan, the\nquality of which commonly degrades in non-skin regions (e.g., hair, beard,\naccessories), because the optimized template-to-scan distance pulls the\ntemplate mesh towards the noisy scan surface. Improving registration quality\nrequires a clean separation of skin and non-skin regions on the scan mesh.\nExisting image-based (2D) or scan-based (3D) segmentation methods however\nperform poorly. Image-based segmentation outputs multi-view inconsistent masks,\nand they cannot account for scan inaccuracies or scan-image misalignment, while\nscan-based methods suffer from lower spatial resolution compared to images. In\nthis work, we introduce a novel method that accurately separates skin from\nnon-skin geometry on 3D human head scans. For this, our method extracts\nfeatures from multi-view images using a frozen image foundation model and\naggregates these features in 3D. These lifted 2D features are then fused with\n3D geometric features extracted from the scan mesh, to then predict a\nsegmentation mask directly on the scan mesh. We show that our segmentations\nimprove the registration accuracy over pure 2D or 3D segmentation methods by\n8.89% and 14.3%, respectively. Although trained only on synthetic data, our\nmodel generalizes well to real data.", "published": "2025-04-28 12:13:12", "link": "http://arxiv.org/abs/2504.19718v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Open-set Anomaly Segmentation in Complex Scenarios", "abstract": "Precise segmentation of out-of-distribution (OoD) objects, herein referred to\nas anomalies, is crucial for the reliable deployment of semantic segmentation\nmodels in open-set, safety-critical applications, such as autonomous driving.\nCurrent anomalous segmentation benchmarks predominantly focus on favorable\nweather conditions, resulting in untrustworthy evaluations that overlook the\nrisks posed by diverse meteorological conditions in open-set environments, such\nas low illumination, dense fog, and heavy rain. To bridge this gap, this paper\nintroduces the ComsAmy, a challenging benchmark specifically designed for\nopen-set anomaly segmentation in complex scenarios. ComsAmy encompasses a wide\nspectrum of adverse weather conditions, dynamic driving environments, and\ndiverse anomaly types to comprehensively evaluate the model performance in\nrealistic open-world scenarios. Our extensive evaluation of several\nstate-of-the-art anomalous segmentation models reveals that existing methods\ndemonstrate significant deficiencies in such challenging scenarios,\nhighlighting their serious safety risks for real-world deployment. To solve\nthat, we propose a novel energy-entropy learning (EEL) strategy that integrates\nthe complementary information from energy and entropy to bolster the robustness\nof anomaly segmentation under complex open-world environments. Additionally, a\ndiffusion-based anomalous training data synthesizer is proposed to generate\ndiverse and high-quality anomalous images to enhance the existing copy-paste\ntraining data synthesizer. Extensive experimental results on both public and\nComsAmy benchmarks demonstrate that our proposed diffusion-based synthesizer\nwith energy and entropy learning (DiffEEL) serves as an effective and\ngeneralizable plug-and-play method to enhance existing models, yielding an\naverage improvement of around 4.96% in $\\rm{AUPRC}$ and 9.87% in\n$\\rm{FPR}_{95}$.", "published": "2025-04-28 12:00:10", "link": "http://arxiv.org/abs/2504.19706v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SubGrapher: Visual Fingerprinting of Chemical Structures", "abstract": "Automatic extraction of chemical structures from scientific literature plays\na crucial role in accelerating research across fields ranging from drug\ndiscovery to materials science. Patent documents, in particular, contain\nmolecular information in visual form, which is often inaccessible through\ntraditional text-based searches. In this work, we introduce SubGrapher, a\nmethod for the visual fingerprinting of chemical structure images. Unlike\nconventional Optical Chemical Structure Recognition (OCSR) models that attempt\nto reconstruct full molecular graphs, SubGrapher focuses on extracting\nmolecular fingerprints directly from chemical structure images. Using\nlearning-based instance segmentation, SubGrapher identifies functional groups\nand carbon backbones, constructing a substructure-based fingerprint that\nenables chemical structure retrieval. Our approach is evaluated against\nstate-of-the-art OCSR and fingerprinting methods, demonstrating superior\nretrieval performance and robustness across diverse molecular depictions. The\ndataset, models, and code will be made publicly available.", "published": "2025-04-28 11:45:46", "link": "http://arxiv.org/abs/2504.19695v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prompt Guiding Multi-Scale Adaptive Sparse Representation-driven Network for Low-Dose CT MAR", "abstract": "Low-dose CT (LDCT) is capable of reducing X-ray radiation exposure, but it\nwill potentially degrade image quality, even yields metal artifacts at the case\nof metallic implants. For simultaneous LDCT reconstruction and metal artifact\nreduction (LDMAR), existing deep learning-based efforts face two main\nlimitations: i) the network design neglects multi-scale and within-scale\ninformation; ii) training a distinct model for each dose necessitates\nsignificant storage space for multiple doses. To fill these gaps, we propose a\nprompt guiding multi-scale adaptive sparse representation-driven network,\nabbreviated as PMSRNet, for LDMAR task. Specifically, we construct PMSRNet\ninspired from multi-scale sparsifying frames, and it can simultaneously employ\nwithin-scale characteristics and cross-scale complementarity owing to an\nelaborated prompt guiding scale-adaptive threshold generator (PSATG) and a\nbuilt multi-scale coefficient fusion module (MSFuM). The PSATG can adaptively\ncapture multiple contextual information to generate more faithful thresholds,\nachieved by fusing features from local, regional, and global levels.\nFurthermore, we elaborate a model interpretable dual domain LDMAR framework\ncalled PDuMSRNet, and train single model with a prompt guiding strategy for\nmultiple dose levels. We build a prompt guiding module, whose input contains\ndose level, metal mask and input instance, to provide various guiding\ninformation, allowing a single model to accommodate various CT dose settings.\nExtensive experiments at various dose levels demonstrate that the proposed\nmethods outperform the state-of-the-art LDMAR methods.", "published": "2025-04-28 11:23:57", "link": "http://arxiv.org/abs/2504.19687v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ClearVision: Leveraging CycleGAN and SigLIP-2 for Robust All-Weather Classification in Traffic Camera Imagery", "abstract": "Accurate weather classification from low-quality traffic camera imagery\nremains a challenging task, particularly under adverse nighttime conditions. In\nthis study, we propose a scalable framework that combines generative domain\nadaptation with efficient contrastive learning to enhance classification\nperformance. Using CycleGAN-based domain translation, we improve the quality of\nnighttime images, enabling better feature extraction by downstream models.\nWhile the baseline EVA-02 model employing CLIP-based contrastive loss achieves\nan overall accuracy of 96.55\\%, it exhibits a significant performance gap\nbetween daytime (97.21\\%) and nighttime conditions (63.40\\%). Replacing CLIP\nwith the lightweight SigLIP-2 (Sigmoid contrastive loss) achieves a competitive\noverall accuracy of 94.00\\%, with substantial improvements in nighttime\nperformance (85.90\\% accuracy). The combination of Vision-SigLIP-2,\nText-SigLIP-2, CycleGAN, and contrastive training achieves the best nighttime\naccuracy (85.90\\%) among all models tested, while EVA-02 with CycleGAN\nmaintains the highest overall accuracy (97.01\\%) and per-class accuracies.\nThese findings demonstrate the potential of combining domain adaptation and\nefficient contrastive learning to build practical, resource-efficient weather\nclassification systems for intelligent transportation infrastructure.", "published": "2025-04-28 11:22:08", "link": "http://arxiv.org/abs/2504.19684v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Explaining Vision GNNs: A Semantic and Visual Analysis of Graph-based Image Classification", "abstract": "Graph Neural Networks (GNNs) have emerged as an efficient alternative to\nconvolutional approaches for vision tasks such as image classification,\nleveraging patch-based representations instead of raw pixels. These methods\nconstruct graphs where image patches serve as nodes, and edges are established\nbased on patch similarity or classification relevance. Despite their\nefficiency, the explainability of GNN-based vision models remains\nunderexplored, even though graphs are naturally interpretable. In this work, we\nanalyze the semantic consistency of the graphs formed at different layers of\nGNN-based image classifiers, focusing on how well they preserve object\nstructures and meaningful relationships. A comprehensive analysis is presented\nby quantifying the extent to which inter-layer graph connections reflect\nsemantic similarity and spatial coherence. Explanations from standard and\nadversarial settings are also compared to assess whether they reflect the\nclassifiers' robustness. Additionally, we visualize the flow of information\nacross layers through heatmap-based visualization techniques, thereby\nhighlighting the models' explainability. Our findings demonstrate that the\ndecision-making processes of these models can be effectively explained, while\nalso revealing that their reasoning does not necessarily align with human\nperception, especially in deeper layers.", "published": "2025-04-28 11:13:40", "link": "http://arxiv.org/abs/2504.19682v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "xEdgeFace: Efficient Cross-Spectral Face Recognition for Edge Devices", "abstract": "Heterogeneous Face Recognition (HFR) addresses the challenge of matching face\nimages across different sensing modalities, such as thermal to visible or\nnear-infrared to visible, expanding the applicability of face recognition\nsystems in real-world, unconstrained environments. While recent HFR methods\nhave shown promising results, many rely on computation-intensive architectures,\nlimiting their practicality for deployment on resource-constrained edge\ndevices. In this work, we present a lightweight yet effective HFR framework by\nadapting a hybrid CNN-Transformer architecture originally designed for face\nrecognition. Our approach enables efficient end-to-end training with minimal\npaired heterogeneous data while preserving strong performance on standard RGB\nface recognition tasks. This makes it a compelling solution for both\nhomogeneous and heterogeneous scenarios. Extensive experiments across multiple\nchallenging HFR and face recognition benchmarks demonstrate that our method\nconsistently outperforms state-of-the-art approaches while maintaining a low\ncomputational overhead.", "published": "2025-04-28 10:03:11", "link": "http://arxiv.org/abs/2504.19646v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BARIS: Boundary-Aware Refinement with Environmental Degradation Priors for Robust Underwater Instance Segmentation", "abstract": "Underwater instance segmentation is challenging due to adverse visual\nconditions such as light attenuation, scattering, and color distortion, which\ndegrade model performance. In this work, we propose BARIS-Decoder\n(Boundary-Aware Refinement Decoder for Instance Segmentation), a framework that\nenhances segmentation accuracy through feature refinement. To address\nunderwater degradations, we introduce the Environmental Robust Adapter (ERA),\nwhich efficiently models underwater degradation patterns while reducing\ntrainable parameters by over 90\\% compared to full fine-tuning. The integration\nof BARIS-Decoder with ERA-tuning, referred to as BARIS-ERA, achieves\nstate-of-the-art performance, surpassing Mask R-CNN by 3.4 mAP with a Swin-B\nbackbone and 3.8 mAP with ConvNeXt V2. Our findings demonstrate the\neffectiveness of BARIS-ERA in advancing underwater instance segmentation,\nproviding a robust and efficient solution.", "published": "2025-04-28 10:00:22", "link": "http://arxiv.org/abs/2504.19643v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Exploiting Inter-Sample Correlation and Intra-Sample Redundancy for Partially Relevant Video Retrieval", "abstract": "Partially Relevant Video Retrieval (PRVR) aims to retrieve the target video\nthat is partially relevant to the text query. The primary challenge in PRVR\narises from the semantic asymmetry between textual and visual modalities, as\nvideos often contain substantial content irrelevant to the query. Existing\nmethods coarsely align paired videos and text queries to construct the semantic\nspace, neglecting the critical cross-modal dual nature inherent in this task:\ninter-sample correlation and intra-sample redundancy. To this end, we propose a\nnovel PRVR framework to systematically exploit these two characteristics. Our\nframework consists of three core modules. First, the Inter Correlation\nEnhancement (ICE) module captures inter-sample correlation by identifying\nsemantically similar yet unpaired text queries and video moments, combining\nthem to form pseudo-positive pairs for more robust semantic space construction.\nSecond, the Intra Redundancy Mining (IRM) module mitigates intra-sample\nredundancy by mining redundant video moment features and treating them as hard\nnegative samples, thereby encouraging the model to learn more discriminative\nrepresentations. Finally, to reinforce these modules, we introduce the Temporal\nCoherence Prediction (TCP) module, which enhances feature discrimination by\ntraining the model to predict the original temporal order of randomly shuffled\nvideo frames and moments. Extensive experiments on three datasets demonstrate\nthe superiority of our approach compared to previous methods, achieving\nstate-of-the-art results.", "published": "2025-04-28 09:52:46", "link": "http://arxiv.org/abs/2504.19637v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NSegment : Noisy Segment Improves Remote Sensing Image Segmentation", "abstract": "Labeling errors in remote sensing (RS) image segmentation datasets often\nremain implicit and subtle due to ambiguous class boundaries, mixed pixels,\nshadows, complex terrain features, and subjective annotator bias. Furthermore,\nthe scarcity of annotated RS data due to high image acquisition and labeling\ncosts complicates training noise-robust models. While sophisticated mechanisms\nsuch as label selection or noise correction might address this issue, they tend\nto increase training time and add implementation complexity. In this letter, we\npropose NSegment-a simple yet effective data augmentation solution to mitigate\nthis issue. Unlike traditional methods, it applies elastic transformations only\nto segmentation labels, varying deformation intensity per sample in each\ntraining epoch to address annotation inconsistencies. Experimental results\ndemonstrate that our approach improves the performance of RS image segmentation\non various state-of-the-art models.", "published": "2025-04-28 09:49:35", "link": "http://arxiv.org/abs/2504.19634v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DiVE: Efficient Multi-View Driving Scenes Generation Based on Video Diffusion Transformer", "abstract": "Collecting multi-view driving scenario videos to enhance the performance of\n3D visual perception tasks presents significant challenges and incurs\nsubstantial costs, making generative models for realistic data an appealing\nalternative. Yet, the videos generated by recent works suffer from poor quality\nand spatiotemporal consistency, undermining their utility in advancing\nperception tasks under driving scenarios. To address this gap, we propose DiVE,\na diffusion transformer-based generative framework meticulously engineered to\nproduce high-fidelity, temporally coherent, and cross-view consistent\nmulti-view videos, aligning seamlessly with bird's-eye view layouts and textual\ndescriptions. DiVE leverages a unified cross-attention and a SketchFormer to\nexert precise control over multimodal data, while incorporating a view-inflated\nattention mechanism that adds no extra parameters, thereby guaranteeing\nconsistency across views. Despite these advancements, synthesizing\nhigh-resolution videos under multimodal constraints introduces dual challenges:\ninvestigating the optimal classifier-free guidance coniguration under intricate\nmulti-condition inputs and mitigating excessive computational latency in\nhigh-resolution rendering--both of which remain underexplored in prior\nresearches. To resolve these limitations, we introduce two innovations:\nMulti-Control Auxiliary Branch Distillation, which streamlines multi-condition\nCFG selection while circumventing high computational overhead, and Resolution\nProgressive Sampling, a training-free acceleration strategy that staggers\nresolution scaling to reduce high latency due to high resolution. These\ninnovations collectively achieve a 2.62x speedup with minimal quality\ndegradation. Evaluated on the nuScenes dataset, DiVE achieves SOTA performance\nin multi-view video generation, yielding photorealistic outputs with\nexceptional temporal and cross-view coherence.", "published": "2025-04-28 09:20:50", "link": "http://arxiv.org/abs/2504.19614v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Magnifier: A Multi-grained Neural Network-based Architecture for Burned Area Delineation", "abstract": "In crisis management and remote sensing, image segmentation plays a crucial\nrole, enabling tasks like disaster response and emergency planning by analyzing\nvisual data. Neural networks are able to analyze satellite acquisitions and\ndetermine which areas were affected by a catastrophic event. The problem in\ntheir development in this context is the data scarcity and the lack of\nextensive benchmark datasets, limiting the capabilities of training large\nneural network models. In this paper, we propose a novel methodology, namely\nMagnifier, to improve segmentation performance with limited data availability.\nThe Magnifier methodology is applicable to any existing encoder-decoder\narchitecture, as it extends a model by merging information at different\ncontextual levels through a dual-encoder approach: a local and global encoder.\nMagnifier analyzes the input data twice using the dual-encoder approach. In\nparticular, the local and global encoders extract information from the same\ninput at different granularities. This allows Magnifier to extract more\ninformation than the other approaches given the same set of input images.\nMagnifier improves the quality of the results of +2.65% on average IoU while\nleading to a restrained increase in terms of the number of trainable parameters\ncompared to the original model. We evaluated our proposed approach with\nstate-of-the-art burned area segmentation models, demonstrating, on average,\ncomparable or better performances in less than half of the GFLOPs.", "published": "2025-04-28 08:51:54", "link": "http://arxiv.org/abs/2504.19589v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "ShowMak3r: Compositional TV Show Reconstruction", "abstract": "Reconstructing dynamic radiance fields from video clips is challenging,\nespecially when entertainment videos like TV shows are given. Many challenges\nmake the reconstruction difficult due to (1) actors occluding with each other\nand having diverse facial expressions, (2) cluttered stages, and (3) small\nbaseline views or sudden shot changes. To address these issues, we present\nShowMak3r, a comprehensive reconstruction pipeline that allows the editing of\nscenes like how video clips are made in a production control room. In\nShowMak3r, a 3DLocator module locates recovered actors on the stage using depth\nprior and estimates unseen human poses via interpolation. The proposed\nShotMatcher module then tracks the actors under shot changes. Furthermore,\nShowMak3r introduces a face-fitting network that dynamically recovers the\nactors' expressions. Experiments on Sitcoms3D dataset show that our pipeline\ncan reassemble TV show scenes with new cameras at different timestamps. We also\ndemonstrate that ShowMak3r enables interesting applications such as synthetic\nshot-making, actor relocation, insertion, deletion, and pose manipulation.\nProject page : https://nstar1125.github.io/showmak3r", "published": "2025-04-28 08:44:42", "link": "http://arxiv.org/abs/2504.19584v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAMBLE: Shape-Specific Point Cloud Sampling for an Optimal Trade-Off Between Local Detail and Global Uniformity", "abstract": "Driven by the increasing demand for accurate and efficient representation of\n3D data in various domains, point cloud sampling has emerged as a pivotal\nresearch topic in 3D computer vision. Recently, learning-to-sample methods have\ngarnered growing interest from the community, particularly for their ability to\nbe jointly trained with downstream tasks. However, previous learning-based\nsampling methods either lead to unrecognizable sampling patterns by generating\na new point cloud or biased sampled results by focusing excessively on sharp\nedge details. Moreover, they all overlook the natural variations in point\ndistribution across different shapes, applying a similar sampling strategy to\nall point clouds. In this paper, we propose a Sparse Attention Map and\nBin-based Learning method (termed SAMBLE) to learn shape-specific sampling\nstrategies for point cloud shapes. SAMBLE effectively achieves an improved\nbalance between sampling edge points for local details and preserving\nuniformity in the global shape, resulting in superior performance across\nmultiple common point cloud downstream tasks, even in scenarios with few-point\nsampling.", "published": "2025-04-28 08:42:24", "link": "http://arxiv.org/abs/2504.19581v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DG-DETR: Toward Domain Generalized Detection Transformer", "abstract": "End-to-end Transformer-based detectors (DETRs) have demonstrated strong\ndetection performance. However, domain generalization (DG) research has\nprimarily focused on convolutional neural network (CNN)-based detectors, while\npaying little attention to enhancing the robustness of DETRs. In this letter,\nwe introduce a Domain Generalized DEtection TRansformer (DG-DETR), a simple,\neffective, and plug-and-play method that improves out-of-distribution (OOD)\nrobustness for DETRs. Specifically, we propose a novel domain-agnostic query\nselection strategy that removes domain-induced biases from object queries via\northogonal projection onto the instance-specific style space. Additionally, we\nleverage a wavelet decomposition to disentangle features into domain-invariant\nand domain-specific components, enabling synthesis of diverse latent styles\nwhile preserving the semantic features of objects. Experimental results\nvalidate the effectiveness of DG-DETR. Our code is available at\nhttps://github.com/sminhwang/DG-DETR.", "published": "2025-04-28 08:33:10", "link": "http://arxiv.org/abs/2504.19574v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Category-Level and Open-Set Object Pose Estimation for Robotics", "abstract": "Object pose estimation enables a variety of tasks in computer vision and\nrobotics, including scene understanding and robotic grasping. The complexity of\na pose estimation task depends on the unknown variables related to the target\nobject. While instance-level methods already excel for opaque and Lambertian\nobjects, category-level and open-set methods, where texture, shape, and size\nare partially or entirely unknown, still struggle with these basic material\nproperties. Since texture is unknown in these scenarios, it cannot be used for\ndisambiguating object symmetries, another core challenge of 6D object pose\nestimation. The complexity of estimating 6D poses with such a manifold of\nunknowns led to various datasets, accuracy metrics, and algorithmic solutions.\nThis paper compares datasets, accuracy metrics, and algorithms for solving 6D\npose estimation on the category-level. Based on this comparison, we analyze how\nto bridge category-level and open-set object pose estimation to reach\ngeneralization and provide actionable recommendations.", "published": "2025-04-28 08:31:33", "link": "http://arxiv.org/abs/2504.19572v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "CE-NPBG: Connectivity Enhanced Neural Point-Based Graphics for Novel View Synthesis in Autonomous Driving Scenes", "abstract": "Current point-based approaches encounter limitations in scalability and\nrendering quality when using large 3D point cloud maps because using them\ndirectly for novel view synthesis (NVS) leads to degraded visualizations. We\nidentify the primary issue behind these low-quality renderings as a visibility\nmismatch between geometry and appearance, stemming from using these two\nmodalities together. To address this problem, we present CE-NPBG, a new\napproach for novel view synthesis (NVS) in large-scale autonomous driving\nscenes. Our method is a neural point-based technique that leverages two\nmodalities: posed images (cameras) and synchronized raw 3D point clouds\n(LiDAR). We first employ a connectivity relationship graph between appearance\nand geometry, which retrieves points from a large 3D point cloud map observed\nfrom the current camera perspective and uses them for rendering. By leveraging\nthis connectivity, our method significantly improves rendering quality and\nenhances run-time and scalability by using only a small subset of points from\nthe large 3D point cloud map. Our approach associates neural descriptors with\nthe points and uses them to synthesize views. To enhance the encoding of these\ndescriptors and elevate rendering quality, we propose a joint adversarial and\npoint rasterization training. During training, we pair an image-synthesizer\nnetwork with a multi-resolution discriminator. At inference, we decouple them\nand use the image-synthesizer to generate novel views. We also integrate our\nproposal into the recent 3D Gaussian Splatting work to highlight its benefits\nfor improved rendering and scalability.", "published": "2025-04-28 08:02:02", "link": "http://arxiv.org/abs/2504.19557v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DEEMO: De-identity Multimodal Emotion Recognition and Reasoning", "abstract": "Emotion understanding is a critical yet challenging task. Most existing\napproaches rely heavily on identity-sensitive information, such as facial\nexpressions and speech, which raises concerns about personal privacy. To\naddress this, we introduce the De-identity Multimodal Emotion Recognition and\nReasoning (DEEMO), a novel task designed to enable emotion understanding using\nde-identified video and audio inputs. The DEEMO dataset consists of two\nsubsets: DEEMO-NFBL, which includes rich annotations of Non-Facial Body\nLanguage (NFBL), and DEEMO-MER, an instruction dataset for Multimodal Emotion\nRecognition and Reasoning using identity-free cues. This design supports\nemotion understanding without compromising identity privacy. In addition, we\npropose DEEMO-LLaMA, a Multimodal Large Language Model (MLLM) that integrates\nde-identified audio, video, and textual information to enhance both emotion\nrecognition and reasoning. Extensive experiments show that DEEMO-LLaMA achieves\nstate-of-the-art performance on both tasks, outperforming existing MLLMs by a\nsignificant margin, achieving 74.49% accuracy and 74.45% F1-score in\nde-identity emotion recognition, and 6.20 clue overlap and 7.66 label overlap\nin de-identity emotion reasoning. Our work contributes to ethical AI by\nadvancing privacy-preserving emotion understanding and promoting responsible\naffective computing.", "published": "2025-04-28 07:55:11", "link": "http://arxiv.org/abs/2504.19549v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Crowd Detection Using Very-Fine-Resolution Satellite Imagery", "abstract": "Accurate crowd detection (CD) is critical for public safety and historical\npattern analysis, yet existing methods relying on ground and aerial imagery\nsuffer from limited spatio-temporal coverage. The development of\nvery-fine-resolution (VFR) satellite sensor imagery (e.g., ~0.3 m spatial\nresolution) provides unprecedented opportunities for large-scale crowd activity\nanalysis, but it has never been considered for this task. To address this gap,\nwe proposed CrowdSat-Net, a novel point-based convolutional neural network,\nwhich features two innovative components: Dual-Context Progressive Attention\nNetwork (DCPAN) to improve feature representation of individuals by aggregating\nscene context and local individual characteristics, and High-Frequency Guided\nDeformable Upsampler (HFGDU) that recovers high-frequency information during\nupsampling through frequency-domain guided deformable convolutions. To validate\nthe effectiveness of CrowdSat-Net, we developed CrowdSat, the first VFR\nsatellite imagery dataset designed specifically for CD tasks, comprising over\n120k manually labeled individuals from multi-source satellite platforms\n(Beijing-3N, Jilin-1 Gaofen-04A and Google Earth) across China. In the\nexperiments, CrowdSat-Net was compared with five state-of-the-art point-based\nCD methods (originally designed for ground or aerial imagery) using CrowdSat\nand achieved the largest F1-score of 66.12% and Precision of 73.23%, surpassing\nthe second-best method by 1.71% and 2.42%, respectively. Moreover, extensive\nablation experiments validated the importance of the DCPAN and HFGDU modules.\nFurthermore, cross-regional evaluation further demonstrated the spatial\ngeneralizability of CrowdSat-Net. This research advances CD capability by\nproviding both a newly developed network architecture for CD and a pioneering\nbenchmark dataset to facilitate future CD development.", "published": "2025-04-28 07:51:26", "link": "http://arxiv.org/abs/2504.19546v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adversarial Shallow Watermarking", "abstract": "Recent advances in digital watermarking make use of deep neural networks for\nmessage embedding and extraction. They typically follow the ``encoder-noise\nlayer-decoder''-based architecture. By deliberately establishing a\ndifferentiable noise layer to simulate the distortion of the watermarked\nsignal, they jointly train the deep encoder and decoder to fit the noise layer\nto guarantee robustness. As a result, they are usually weak against unknown\ndistortions that are not used in their training pipeline. In this paper, we\npropose a novel watermarking framework to resist unknown distortions, namely\nAdversarial Shallow Watermarking (ASW). ASW utilizes only a shallow decoder\nthat is randomly parameterized and designed to be insensitive to distortions\nfor watermarking extraction. During the watermark embedding, ASW freezes the\nshallow decoder and adversarially optimizes a host image until its updated\nversion (i.e., the watermarked image) stably triggers the shallow decoder to\noutput the watermark message. During the watermark extraction, it accurately\nrecovers the message from the watermarked image by leveraging the insensitive\nnature of the shallow decoder against arbitrary distortions. Our ASW is\ntraining-free, encoder-free, and noise layer-free. Experiments indicate that\nthe watermarked images created by ASW have strong robustness against various\nunknown distortions. Compared to the existing ``encoder-noise layer-decoder''\napproaches, ASW achieves comparable results on known distortions and better\nrobustness on unknown distortions.", "published": "2025-04-28 07:12:20", "link": "http://arxiv.org/abs/2504.19529v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "LR-IAD:Mask-Free Industrial Anomaly Detection with Logical Reasoning", "abstract": "Industrial Anomaly Detection (IAD) is critical for ensuring product quality\nby identifying defects. Traditional methods such as feature embedding and\nreconstruction-based approaches require large datasets and struggle with\nscalability. Existing vision-language models (VLMs) and Multimodal Large\nLanguage Models (MLLMs) address some limitations but rely on mask annotations,\nleading to high implementation costs and false positives. Additionally,\nindustrial datasets like MVTec-AD and VisA suffer from severe class imbalance,\nwith defect samples constituting only 23.8% and 11.1% of total data\nrespectively. To address these challenges, we propose a reward function that\ndynamically prioritizes rare defect patterns during training to handle class\nimbalance. We also introduce a mask-free reasoning framework using Chain of\nThought (CoT) and Group Relative Policy Optimization (GRPO) mechanisms,\nenabling anomaly detection directly from raw images without annotated masks.\nThis approach generates interpretable step-by-step explanations for defect\nlocalization. Our method achieves state-of-the-art performance, outperforming\nprior approaches by 36% in accuracy on MVTec-AD and 16% on VisA. By eliminating\nmask dependency and reducing costs while providing explainable outputs, this\nwork advances industrial anomaly detection and supports scalable quality\ncontrol in manufacturing. Code to reproduce the experiment is available at\nhttps://github.com/LilaKen/LR-IAD.", "published": "2025-04-28 06:52:35", "link": "http://arxiv.org/abs/2504.19524v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FSBench: A Figure Skating Benchmark for Advancing Artistic Sports Understanding", "abstract": "Figure skating, known as the \"Art on Ice,\" is among the most artistic sports,\nchallenging to understand due to its blend of technical elements (like jumps\nand spins) and overall artistic expression. Existing figure skating datasets\nmainly focus on single tasks, such as action recognition or scoring, lacking\ncomprehensive annotations for both technical and artistic evaluation. Current\nsports research is largely centered on ball games, with limited relevance to\nartistic sports like figure skating. To address this, we introduce FSAnno, a\nlarge-scale dataset advancing artistic sports understanding through figure\nskating. FSAnno includes an open-access training and test dataset, alongside a\nbenchmark dataset, FSBench, for fair model evaluation. FSBench consists of\nFSBench-Text, with multiple-choice questions and explanations, and\nFSBench-Motion, containing multimodal data and Question and Answer (QA) pairs,\nsupporting tasks from technical analysis to performance commentary. Initial\ntests on FSBench reveal significant limitations in existing models'\nunderstanding of artistic sports. We hope FSBench will become a key tool for\nevaluating and enhancing model comprehension of figure skating.", "published": "2025-04-28 06:25:04", "link": "http://arxiv.org/abs/2504.19514v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SynergyAmodal: Deocclude Anything with Text Control", "abstract": "Image deocclusion (or amodal completion) aims to recover the invisible\nregions (\\ie, shape and appearance) of occluded instances in images. Despite\nrecent advances, the scarcity of high-quality data that balances diversity,\nplausibility, and fidelity remains a major obstacle. To address this challenge,\nwe identify three critical elements: leveraging in-the-wild image data for\ndiversity, incorporating human expertise for plausibility, and utilizing\ngenerative priors for fidelity. We propose SynergyAmodal, a novel framework for\nco-synthesizing in-the-wild amodal datasets with comprehensive shape and\nappearance annotations, which integrates these elements through a tripartite\ndata-human-model collaboration. First, we design an occlusion-grounded\nself-supervised learning algorithm to harness the diversity of in-the-wild\nimage data, fine-tuning an inpainting diffusion model into a partial completion\ndiffusion model. Second, we establish a co-synthesis pipeline to iteratively\nfilter, refine, select, and annotate the initial deocclusion results of the\npartial completion diffusion model, ensuring plausibility and fidelity through\nhuman expert guidance and prior model constraints. This pipeline generates a\nhigh-quality paired amodal dataset with extensive category and scale diversity,\ncomprising approximately 16K pairs. Finally, we train a full completion\ndiffusion model on the synthesized dataset, incorporating text prompts as\nconditioning signals. Extensive experiments demonstrate the effectiveness of\nour framework in achieving zero-shot generalization and textual\ncontrollability. Our code, dataset, and models will be made publicly available\nat https://github.com/imlixinyang/SynergyAmodal.", "published": "2025-04-28 06:04:17", "link": "http://arxiv.org/abs/2504.19506v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CasaGPT: Cuboid Arrangement and Scene Assembly for Interior Design", "abstract": "We present a novel approach for indoor scene synthesis, which learns to\narrange decomposed cuboid primitives to represent 3D objects within a scene.\nUnlike conventional methods that use bounding boxes to determine the placement\nand scale of 3D objects, our approach leverages cuboids as a straightforward\nyet highly effective alternative for modeling objects. This allows for compact\nscene generation while minimizing object intersections. Our approach, coined\nCasaGPT for Cuboid Arrangement and Scene Assembly, employs an autoregressive\nmodel to sequentially arrange cuboids, producing physically plausible scenes.\nBy applying rejection sampling during the fine-tuning stage to filter out\nscenes with object collisions, our model further reduces intersections and\nenhances scene quality. Additionally, we introduce a refined dataset,\n3DFRONT-NC, which eliminates significant noise presented in the original\ndataset, 3D-FRONT. Extensive experiments on the 3D-FRONT dataset as well as our\ndataset demonstrate that our approach consistently outperforms the\nstate-of-the-art methods, enhancing the realism of generated scenes, and\nproviding a promising direction for 3D scene synthesis.", "published": "2025-04-28 04:35:04", "link": "http://arxiv.org/abs/2504.19478v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Masked Language Prompting for Generative Data Augmentation in Few-shot Fashion Style Recognition", "abstract": "Constructing dataset for fashion style recognition is challenging due to the\ninherent subjectivity and ambiguity of style concepts. Recent advances in\ntext-to-image models have facilitated generative data augmentation by\nsynthesizing images from labeled data, yet existing methods based solely on\nclass names or reference captions often fail to balance visual diversity and\nstyle consistency. In this work, we propose \\textbf{Masked Language Prompting\n(MLP)}, a novel prompting strategy that masks selected words in a reference\ncaption and leverages large language models to generate diverse yet\nsemantically coherent completions. This approach preserves the structural\nsemantics of the original caption while introducing attribute-level variations\naligned with the intended style, enabling style-consistent and diverse image\ngeneration without fine-tuning. Experimental results on the FashionStyle14\ndataset demonstrate that our MLP-based augmentation consistently outperforms\nclass-name and caption-based baselines, validating its effectiveness for\nfashion style recognition under limited supervision.", "published": "2025-04-28 03:42:42", "link": "http://arxiv.org/abs/2504.19455v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dual Attention Driven Lumbar Magnetic Resonance Image Feature Enhancement and Automatic Diagnosis of Herniation", "abstract": "Lumbar disc herniation (LDH) is a common musculoskeletal disease that\nrequires magnetic resonance imaging (MRI) for effective clinical management.\nHowever, the interpretation of MRI images heavily relies on the expertise of\nradiologists, leading to delayed diagnosis and high costs for training\nphysicians. Therefore, this paper proposes an innovative automated LDH\nclassification framework. To address these key issues, the framework utilizes\nT1-weighted and T2-weighted MRI images from 205 people. The framework extracts\nclinically actionable LDH features and generates standardized diagnostic\noutputs by leveraging data augmentation and channel and spatial attention\nmechanisms. These outputs can help physicians make confident and time-effective\ncare decisions when needed. The proposed framework achieves an area under the\nreceiver operating characteristic curve (AUC-ROC) of 0.969 and an accuracy of\n0.9486 for LDH detection. The experimental results demonstrate the performance\nof the proposed framework. Our framework only requires a small number of\ndatasets for training to demonstrate high diagnostic accuracy. This is expected\nto be a solution to enhance the LDH detection capabilities of primary\nhospitals.", "published": "2025-04-28 02:55:59", "link": "http://arxiv.org/abs/2504.19438v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A Real-Time Event-Based Normal Flow Estimator", "abstract": "This paper presents a real-time, asynchronous, event-based normal flow\nestimator. It follows the same algorithm as Learning Normal Flow Directly From\nEvent Neighborhoods, but with a more optimized implementation. The original\nmethod treats event slices as 3D point clouds, encodes each event's local\ngeometry into a fixed-length vector, and uses a multi-layer perceptron to\npredict normal flow. It constructs representations by multiplying an adjacency\nmatrix with a feature matrix, resulting in quadratic time complexity with\nrespect to the number of events. In contrast, we leverage the fact that event\ncoordinates are integers and reformulate the representation step as a pooling\noperation. This achieves the same effect as the adjacency matrix but with much\nlower computational cost. As a result, our method supports real-time normal\nflow prediction on event cameras. Our estimator uses 1 GB of CUDA memory and\nruns at 4 million normal flows per second on an RTX 3070, or 6 million per\nsecond on an RTX A5000. We release the CUDA implementation along with a Python\ninterface at https://github.com/dhyuan99/VecKM_flow_cpp.", "published": "2025-04-28 02:06:07", "link": "http://arxiv.org/abs/2504.19417v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GMAR: Gradient-Driven Multi-Head Attention Rollout for Vision Transformer Interpretability", "abstract": "The Vision Transformer (ViT) has made significant advancements in computer\nvision, utilizing self-attention mechanisms to achieve state-of-the-art\nperformance across various tasks, including image classification, object\ndetection, and segmentation. Its architectural flexibility and capabilities\nhave made it a preferred choice among researchers and practitioners. However,\nthe intricate multi-head attention mechanism of ViT presents significant\nchallenges to interpretability, as the underlying prediction process remains\nopaque. A critical limitation arises from an observation commonly noted in\ntransformer architectures: \"Not all attention heads are equally meaningful.\"\nOverlooking the relative importance of specific heads highlights the\nlimitations of existing interpretability methods. To address these challenges,\nwe introduce Gradient-Driven Multi-Head Attention Rollout (GMAR), a novel\nmethod that quantifies the importance of each attention head using\ngradient-based scores. These scores are normalized to derive a weighted\naggregate attention score, effectively capturing the relative contributions of\nindividual heads. GMAR clarifies the role of each head in the prediction\nprocess, enabling more precise interpretability at the head level. Experimental\nresults demonstrate that GMAR consistently outperforms traditional attention\nrollout techniques. This work provides a practical contribution to\ntransformer-based architectures, establishing a robust framework for enhancing\nthe interpretability of Vision Transformer models.", "published": "2025-04-28 01:58:39", "link": "http://arxiv.org/abs/2504.19414v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UNet with Axial Transformer : A Neural Weather Model for Precipitation Nowcasting", "abstract": "Making accurate weather predictions can be particularly challenging for\nlocalized storms or events that evolve on hourly timescales, such as\nthunderstorms. Hence, our goal for the project was to model Weather Nowcasting\nfor making highly localized and accurate predictions that apply to the\nimmediate future replacing the current numerical weather models and data\nassimilation systems with Deep Learning approaches. A significant advantage of\nmachine learning is that inference is computationally cheap given an\nalready-trained model, allowing forecasts that are nearly instantaneous and in\nthe native high resolution of the input data. In this work we developed a novel\nmethod that employs Transformer-based machine learning models to forecast\nprecipitation. This approach works by leveraging axial attention mechanisms to\nlearn complex patterns and dynamics from time series frames. Moreover, it is a\ngeneric framework and can be applied to univariate and multivariate time series\ndata, as well as time series embeddings data. This paper represents an initial\nresearch on the dataset used in the domain of next frame prediciton, and hence,\nwe demonstrate state-of-the-art results in terms of metrices (PSNR = 47.67,\nSSIM = 0.9943) used for the given dataset using UNet with Axial Transformer.", "published": "2025-04-28 01:20:30", "link": "http://arxiv.org/abs/2504.19408v1", "categories": ["cs.LG", "cs.CV", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Boosting 3D Liver Shape Datasets with Diffusion Models and Implicit Neural Representations", "abstract": "While the availability of open 3D medical shape datasets is increasing,\noffering substantial benefits to the research community, we have found that\nmany of these datasets are, unfortunately, disorganized and contain artifacts.\nThese issues limit the development and training of robust models, particularly\nfor accurate 3D reconstruction tasks. In this paper, we examine the current\nstate of available 3D liver shape datasets and propose a solution using\ndiffusion models combined with implicit neural representations (INRs) to\naugment and expand existing datasets. Our approach utilizes the generative\ncapabilities of diffusion models to create realistic, diverse 3D liver shapes,\ncapturing a wide range of anatomical variations and addressing the problem of\ndata scarcity. Experimental results indicate that our method enhances dataset\ndiversity, providing a scalable solution to improve the accuracy and\nreliability of 3D liver reconstruction and generation in medical applications.\nFinally, we suggest that diffusion models can also be applied to other\ndownstream tasks in 3D medical imaging.", "published": "2025-04-28 00:56:18", "link": "http://arxiv.org/abs/2504.19402v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Innovative Integration of 4D Cardiovascular Reconstruction and Hologram: A New Visualization Tool for Coronary Artery Bypass Grafting Planning", "abstract": "Background: Coronary artery bypass grafting (CABG) planning requires advanced\nspatial visualization and consideration of coronary artery depth,\ncalcification, and pericardial adhesions. Objective: To develop and evaluate a\ndynamic cardiovascular holographic visualization tool for preoperative CABG\nplanning. Methods: Using 4D cardiac computed tomography angiography data from\n14 CABG candidates, we developed a semi-automated workflow for time-resolved\nsegmentation of cardiac structures, epicardial adipose tissue (EAT), and\ncoronary arteries with calcium scoring. The workflow incorporated methods for\ncardiac segmentation, coronary calcification quantification, visualization of\ncoronary depth within EAT, and pericardial adhesion assessment through motion\nanalysis. Dynamic cardiovascular holograms were displayed using the Looking\nGlass platform. Thirteen cardiac surgeons evaluated the tool using a Likert\nscale. Additionally, pericardial adhesion scores from holograms of 21 patients\n(including seven undergoing secondary cardiac surgeries) were compared with\nintraoperative findings. Results: Surgeons rated the visualization tool highly\nfor preoperative planning utility (mean Likert score: 4.57/5.0). Hologram-based\npericardial adhesion scoring strongly correlated with intraoperative findings\n(r=0.786, P<0.001). Conclusion: This study establishes a visualization\nframework for CABG planning that produces clinically relevant dynamic holograms\nfrom patient-specific data, with clinical feedback confirming its effectiveness\nfor preoperative planning.", "published": "2025-04-28 00:56:06", "link": "http://arxiv.org/abs/2504.19401v1", "categories": ["physics.med-ph", "cs.CV", "cs.GR", "eess.IV", "J.3; I.3.8"], "primary_category": "physics.med-ph"}
{"title": "Dynamic Arthroscopic Navigation System for Anterior Cruciate Ligament Reconstruction Based on Multi-level Memory Architecture", "abstract": "This paper presents a dynamic arthroscopic navigation system based on\nmulti-level memory architecture for anterior cruciate ligament (ACL)\nreconstruction surgery. The system extends our previously proposed markerless\nnavigation method from static image matching to dynamic video sequence\ntracking. By integrating the Atkinson-Shiffrin memory model's three-level\narchitecture (sensory memory, working memory, and long-term memory), our system\nmaintains continuous tracking of the femoral condyle throughout the surgical\nprocedure, providing stable navigation support even in complex situations\ninvolving viewpoint changes, instrument occlusion, and tissue deformation.\nUnlike existing methods, our system operates in real-time on standard\narthroscopic equipment without requiring additional tracking hardware,\nachieving 25.3 FPS with a latency of only 39.5 ms, representing a 3.5-fold\nimprovement over our previous static system. For extended sequences (1000\nframes), the dynamic system maintained an error of 5.3 plus-minus 1.5 pixels,\ncompared to the static system's 12.6 plus-minus 3.7 pixels - an improvement of\napproximately 45 percent. For medium-length sequences (500 frames) and short\nsequences (100 frames), the system achieved approximately 35 percent and 19\npercent accuracy improvements, respectively. Experimental results demonstrate\nthe system overcomes limitations of traditional static matching methods,\nproviding new technical support for improving surgical precision in ACL\nreconstruction.", "published": "2025-04-28 00:37:15", "link": "http://arxiv.org/abs/2504.19398v1", "categories": ["cs.CV", "I.4.9; I.2.10; J.3; I.4.8; I.5.4"], "primary_category": "cs.CV"}
{"title": "Compositional Square Roots of $\\exp(x)$ and $1+x^2$", "abstract": "Our work began as an effort to understand calculations by Morris & Szekeres\n(1961) and Walker (1991) regarding fractional iteration.", "published": "2025-04-28 17:19:24", "link": "http://arxiv.org/abs/2504.19999v1", "categories": ["math.GM", "cs.DM", "39B12 (Primary) 11B37, 26A18, 39-08, 39B22, 65D20 (Secondary)"], "primary_category": "math.GM"}
{"title": "Determining a graph from its reconfiguration graph", "abstract": "Given a graph $G$ and a natural number $k$, the $k$-recolouring graph\n$\\mathcal{C}_k(G)$ is the graph whose vertices are the $k$-colourings of $G$\nand whose edges link pairs of colourings which differ at exactly one vertex of\n$G$. Recently, Hogan et al. proved that $G$ can be determined from\n$\\mathcal{C}_k(G)$ provided $k$ is large enough (quadratic in the number of\nvertices of $G$). We improve this bound by showing that $k=\\chi(G)+1$ colours\nsuffice, and provide examples of families of graphs for which $k=\\chi(G)$\ncolours do not suffice.\n  We then extend this result to $k$-Kempe-recolouring graphs, whose vertices\nare again the $k$-colourings of a graph $G$ and whose edges link pairs of\ncolourings which differ by swapping the two colours in a connected component\ninduced by selecting those two colours. We show that $k=\\chi(G)+2$ colours\nsuffice to determine $G$ in this case.\n  Finally, we investigate the case of independent set reconfiguration, proving\nthat in only a few trivial cases is one guaranteed to be able to determine a\ngraph $G$.", "published": "2025-04-28 13:28:02", "link": "http://arxiv.org/abs/2504.19783v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "The frequency $K_i$s for symmetrical traveling salesman problem", "abstract": "The frequency $K_i$s ($i\\in[4,n]$) are studied for symmetrical traveling\nsalesman problem ($TSP$) to identify the edges in optimal Hamiltonian cycle\n($OHC$). A frequency $K_i$ is computed with a sort of ${{i}\\choose{2}}$ optimal\n$i$-vertex paths with given endpoints (optimal $i$-vertex path) in a\ncorresponding $K_i$ in $K_n$. In frequency $K_i$, the frequency of an edge is\nthe number of the optimal $i$-vertex paths containing the edge in the\ncorresponding $K_i$. Given an $OHC$ edge related to $K_i$, it has a frequency\nbigger than $\\frac{1}{2}{{i}\\choose{2}}$ in the corresponding frequency $K_i$,\nand that of an ordinary edge not in $OHC$ is smaller than $\\frac{i+2}{2}$. On\naverage, an $OHC$ edge in $K_i$ has a frequency bigger than\n$\\frac{i^2-4i+7}{2}$ whereas an ordinary edge has a frequency smaller than 2.\nMoreover, given a frequency $K_i$ containing an $OHC$ edge related to $K_n$,\nthe frequency of the $OHC$ edge is bigger than $\\frac{1}{2}{{i}\\choose{2}}$ in\nthe worst average case. It implies that the average frequency of an $OHC$ edge\ncomputed with frequency $K_i$s is bigger than $\\frac{1}{2}{{i}\\choose{2}}$. It\nalso found that the probability that an $OHC$ edge is contained in optimal\n$i$-vertex paths keeps stable or increases according to $i\\in [4, n]$. As the\nfrequency $K_i$s are used to compute the frequency of an edge, each $OHC$ edge\nhas its own peak frequency at $i=P_0$ where $P_0=\\frac{n}{2} + 2$ for even $n$\nor $\\frac{n+1}{2} + 1$ for odd $n$. For ordinary edges out of $OHC$, the\nprobability that they are contained in optimal $i$-vertex paths decreases\naccording to $i$. Moreover, the average frequency of an ordinary edge will be\nsmaller than $\\frac{1}{2}{{i}\\choose{2}}$ if $i \\geq [0.3660n + 1.5849]$. Based\non these findings, an algorithm is presented to find $OHC$ in\n$O(n^62^{0.3660n})$ time using dynamic programming.", "published": "2025-04-28 09:12:47", "link": "http://arxiv.org/abs/2504.19608v1", "categories": ["cs.DM", "math.CO", "math.OC", "03C50, 03D15, 05C38, 05C62, 05C75, 05C85, 68Q06, 68R05, 68R10,\n  68W05, 90B10, 90B40, 90C27", "F.2.2; G.2.2"], "primary_category": "cs.DM"}
{"title": "Chatbot Arena Meets Nuggets: Towards Explanations and Diagnostics in the Evaluation of LLM Responses", "abstract": "Battles, or side-by-side comparisons in so called arenas that elicit human\npreferences, have emerged as a popular approach to assessing the output quality\nof LLMs. Recently, this idea has been extended to retrieval-augmented\ngeneration (RAG) systems. While undoubtedly representing an advance in\nevaluation, battles have at least two drawbacks, particularly in the context of\ncomplex information-seeking queries: they are neither explanatory nor\ndiagnostic. Recently, the nugget evaluation methodology has emerged as a\npromising approach to evaluate the quality of RAG answers. Nuggets decompose\nlong-form LLM-generated answers into atomic facts, highlighting important\npieces of information necessary in a \"good\" response. In this work, we apply\nour AutoNuggetizer framework to analyze data from roughly 7K Search Arena\nbattles provided by LMArena in a fully automatic manner. Our results show a\nsignificant correlation between nugget scores and human preferences, showcasing\npromise in our approach to explainable and diagnostic system evaluations.", "published": "2025-04-28 17:24:36", "link": "http://arxiv.org/abs/2504.20006v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Hierarchical Uncertainty-Aware Graph Neural Network", "abstract": "Recent research on graph neural networks (GNNs) has explored mechanisms for\ncapturing local uncertainty and exploiting graph hierarchies to mitigate data\nsparsity and leverage structural properties. However, the synergistic\nintegration of these two approaches remains underexplored. In this work, we\nintroduce a novel architecture, the Hierarchical Uncertainty-Aware Graph Neural\nNetwork (HU-GNN), which unifies multi-scale representation learning, principled\nuncertainty estimation, and self-supervised embedding diversity within a single\nend-to-end framework. Specifically, HU-GNN adaptively forms node clusters and\nestimates uncertainty at multiple structural scales from individual nodes to\nhigher levels. These uncertainty estimates guide a robust message-passing\nmechanism and attention weighting, effectively mitigating noise and adversarial\nperturbations while preserving predictive accuracy on both node- and\ngraph-level tasks. We also offer key theoretical contributions, including a\nprobabilistic formulation, rigorous uncertainty-calibration guarantees, and\nformal robustness bounds. Finally, by incorporating recent advances in graph\ncontrastive learning, HU-GNN maintains diverse, structurally faithful\nembeddings. Extensive experiments on standard benchmarks demonstrate that our\nmodel achieves state-of-the-art robustness and interpretability.", "published": "2025-04-28 14:22:18", "link": "http://arxiv.org/abs/2504.19820v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation", "abstract": "Recently, numerous community search methods for large graphs have been\nproposed, at the core of which is defining and measuring cohesion. This paper\nexperimentally evaluates the effectiveness of these community search algorithms\nw.r.t. cohesiveness in the context of online social networks. Social\ncommunities are formed and developed under the influence of group cohesion\ntheory, which has been extensively studied in social psychology. However,\ncurrent generic methods typically measure cohesiveness using structural or\nattribute-based approaches and overlook domain-specific concepts such as group\ncohesion. We introduce five novel psychology-informed cohesiveness measures,\nbased on the concept of group cohesion from social psychology, and propose a\nnovel framework called CHASE for evaluating eight representative CS algorithms\nw.r.t.these measures on online social networks. Our analysis reveals that there\nis no clear correlation between structural and psychological cohesiveness, and\nno algorithm effectively identifies psychologically cohesive communities in\nonline social networks. This study provides new insights that could guide the\ndevelopment of future community search methods.", "published": "2025-04-28 05:08:29", "link": "http://arxiv.org/abs/2504.19489v1", "categories": ["cs.IR", "cs.SI"], "primary_category": "cs.IR"}
{"title": "Robust Federated Personalised Mean Estimation for the Gaussian Mixture Model", "abstract": "Federated learning with heterogeneous data and personalization has received\nsignificant recent attention. Separately, robustness to corrupted data in the\ncontext of federated learning has also been studied. In this paper we explore\ncombining personalization for heterogeneous data with robustness, where a\nconstant fraction of the clients are corrupted. Motivated by this broad\nproblem, we formulate a simple instantiation which captures some of its\ndifficulty. We focus on the specific problem of personalized mean estimation\nwhere the data is drawn from a Gaussian mixture model. We give an algorithm\nwhose error depends almost linearly on the ratio of corrupted to uncorrupted\nsamples, and show a lower bound with the same behavior, albeit with a gap of a\nconstant factor.", "published": "2025-04-28 16:24:54", "link": "http://arxiv.org/abs/2504.19955v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Type-Based Unsourced Multiple Access over Fading Channels with Cell-Free Massive MIMO", "abstract": "Type-based unsourced multiple access (TUMA) is a recently proposed framework\nfor type-based estimation in massive uncoordinated access networks. We extend\nthe existing design of TUMA, developed for an additive white Gaussian channel,\nto a more realistic environment with fading and multiple antennas.\nSpecifically, we consider a cell-free massive multiple-input multiple-output\nsystem and exploit spatial diversity to estimate the set of transmitted\nmessages and the number of users transmitting each message. Our solution relies\non a location-based codeword partition and on the use at the receiver of a\nmultisource approximate message passing algorithm in both centralized and\ndistributed implementations. The proposed TUMA framework results in a robust\nand scalable architecture for massive machine-type communications.", "published": "2025-04-28 16:24:46", "link": "http://arxiv.org/abs/2504.19954v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Skew generalized quasi-cyclic codes over non-chain ring $F_q+vF_q$", "abstract": "For a prime $p$, let $F_q$ be the finite field of order $q= p^d$. This paper\npresents the study on skew generalized quasi-cyclic (SGQC) codes of length $n$\nover the non-chain ring $F_q+vF_q$ where $v^2=v$ and $\\theta_t$ is the Galois\nautomorphism. Here, first, we prove the dual of an SGQC code of length $n$ is\nalso an SGQC code of the same length and derive a necessary and sufficient\ncondition for the existence of a self-dual SGQC code. Then, we discuss the\n$1$-generator polynomial and the $\\rho$-generator polynomial for skew\ngeneralized quasi-cyclic codes. Further, we determine the dimension and BCH\ntype bound for the 1-generator skew generalized quasi-cyclic codes. As a\nby-product, with the help of MAGMA software, we provide a few examples of SGQC\ncodes and obtain some $2$-generator SGQC codes of index $2$.", "published": "2025-04-28 16:00:53", "link": "http://arxiv.org/abs/2504.19926v1", "categories": ["cs.IT", "math.IT", "94B05, 94B15, 94B60"], "primary_category": "cs.IT"}
{"title": "An Achievability Bound for Type-Based Unsourced Multiple Access", "abstract": "We derive an achievability bound to quantify the performance of a type-based\nunsourced multiple access system -- an information-theoretic model for\ngrant-free multiple access with correlated messages. The bound extends\navailable achievability results for the per-user error probability in the\nunsourced multiple access framework, where, different from our setup, message\ncollisions are treated as errors. Specifically, we provide an upper bound on\nthe total variation distance between the type (i.e., the empirical probability\nmass function) of the transmitted messages and its estimate over a Gaussian\nmultiple access channel. Through numerical simulations, we illustrate that our\nbound can be used to determine the message type that is less efficient to\ntransmit, because more difficult to detect. We finally show that a practical\nscheme for type estimation, based on coded compressed sensing with approximate\nmessage passing, operates approximately 3 dB away from the bound, for the\nparameters considered in the paper.", "published": "2025-04-28 15:45:58", "link": "http://arxiv.org/abs/2504.19916v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Lossy Source Coding with Focal Loss", "abstract": "Focal loss has recently gained significant popularity, particularly in tasks\nlike object detection where it helps to address class imbalance by focusing\nmore on hard-to-classify examples. This work proposes the focal loss as a\ndistortion measure for lossy source coding. The paper provides single-shot\nconverse and achievability bounds. These bounds are then used to characterize\nthe distortion-rate trade-off in the infinite blocklength, which is shown to be\nthe same as that for the log loss case. In the non-asymptotic case, the\ndifference between focal loss and log loss is illustrated through a series of\nsimulations.", "published": "2025-04-28 15:42:34", "link": "http://arxiv.org/abs/2504.19913v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sliding Window Adversarial Channels", "abstract": "In an arbitrarily varying channel (AVC), the channel has a state which is\nunder the control of an adversarial jammer and the corresponding capacities are\noften functions of the \"power\" constraints on the transmitter and jammer. In\nthis paper we propose a model in which the constraints must hold almost surely\nover contiguous subsequences of the codeword and state, which we call a sliding\nwindow constraint. We study oblivious jammers and codes with stochastic\nencoding under maximum probability of error. We show that this extra limitation\non the jammer is beneficial for the transmitter: in some cases, the capacity\nfor unique decoding with a sliding window constraint is equal to the capacity\nfor list decoding in the standard model without sliding windows, roughly\nimplying that the addition of window constraints reduces list decoding to\nunique decoding. The list decoding capacity in the standard model can be\nstrictly larger than the unique decoding capacity.", "published": "2025-04-28 13:18:02", "link": "http://arxiv.org/abs/2504.19773v1", "categories": ["cs.IT", "math.IT", "94A40"], "primary_category": "cs.IT"}
{"title": "Lossy Beyond Diagonal Reconfigurable Intelligent Surfaces: Modeling and Optimization", "abstract": "Beyond diagonal reconfigurable intelligent surface (BD-RIS) has emerged as an\nadvancement and generalization of the conventional diagonal RIS (D-RIS) by\nintroducing tunable interconnections between RIS elements, enabling smarter\nwave manipulation and enlarged coverage. While BD-RIS has demonstrated\nadvantages over D-RIS in various aspects, most existing works rely on the\nassumption of a lossless model, leaving practical considerations unaddressed.\nThis paper thus proposes a lossy BD-RIS model and develops corresponding\noptimization algorithms for various BD-RIS-aided communication systems. First,\nby leveraging admittance parameter analysis, we model each tunable admittance\nbased on a lumped circuit with losses and derive an expression of a circle\ncharacterizing the real and imaginary parts of each tunable admittance. We then\nconsider the received signal power maximization in single-user single-input\nsingle-output (SISO) systems with the proposed lossy BD-RIS model. To solve the\noptimization problem, we design an effective algorithm by carefully exploiting\nthe problem structure. Specifically, an alternating direction method of\nmultipliers (ADMM) framework is custom-designed to deal with the complicated\nconstraints associated with lossy BD-RIS. Furthermore, we extend the proposed\nalgorithmic framework to more general multiuser multiple-input single-output\n(MU-MISO) systems, where the transmit precoder and BD-RIS scattering matrix are\njointly designed to maximize the sum-rate of the system. Finally, simulation\nresults demonstrate that all BD-RIS architectures still outperform D-RIS in the\npresence of losses, but the optimal BD-RIS architectures in the lossless case\nare not necessarily optimal in the lossy case, e.g. group-connected BD-RIS can\noutperform fully- and tree-connected BD-RISs in SISO systems with relatively\nhigh losses, whereas the opposite always holds true in the lossless case.", "published": "2025-04-28 12:45:33", "link": "http://arxiv.org/abs/2504.19744v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Characterizing the Optimal Memory-Rate Tradeoff in Secure Coded Caching for Small Buffer or Small Rate", "abstract": "We consider the secure coded caching problem proposed by Ravindrakumar et. al\nwhere no user can obtain information about files other than the one requested.\nWe first propose three new schemes for the three cases of cache size $M=1$,\n$N=2$ files and arbitrary $K$ users, delivery rate $ R=1$, arbitrary $N$ files\nand $K$ users, and the general case for arbitrary $N$ files and $K$ users,\nrespectively. Then we derive converse results by characterizing new properties\nof secure coded caching schemes. As a result, we characterize the two\nend-points of the optimal memory-rate tradeoff curve for arbitrary number of\nusers and files. Furthermore, for the case of $N=2$ files and arbitrary number\nof users, we also characterize a segment of the optimal memory-rate tradeoff\ncurve, where the cache size is relatively small.", "published": "2025-04-28 09:03:45", "link": "http://arxiv.org/abs/2504.19601v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On Weight Enumeration and Structure Characterization of Polar Codes via Group Actions", "abstract": "In this article, we provide a complete characterization of codewords in polar\ncodes with weights less than twice the minimum distance, using the group action\nof the lower triangular affine (LTA) group. We derive a closed-form formula for\nthe enumeration of such codewords. Furthermore, we introduce an enhanced\npartial order based on weight contributions, offering refined tools for code\ndesign. Our results extend previous work on Type II codewords to a full\ndescription of Type I codewords and offer new insights into the algebraic\nstructure underlying decreasing monomial codes, including polar and Reed-Muller\ncodes.", "published": "2025-04-28 07:48:17", "link": "http://arxiv.org/abs/2504.19544v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "\\textit{From Freshness to Effectiveness}: Goal-Oriented Sampling for Remote Decision Making", "abstract": "Data freshness, measured by Age of Information (AoI), is highly relevant in\nnetworked applications such as Vehicle to Everything (V2X), smart health\nsystems, and Industrial Internet of Things (IIoT). Yet, freshness alone does\nnot equate to informativeness. In decision-critical settings, some stale data\nmay prove more valuable than fresh updates. To explore this nuance, we move\nbeyond AoI-centric policies and investigate how data staleness impacts\ndecision-making under data-staleness-induced uncertainty. We pose a central\nquestion: What is the value of information, when freshness fades, and only its\npower to shape remote decisions remains? To capture this endured value, we\npropose AR-MDP, an Age-aware Remote Markov Decision Process framework, which\nco-designs optimal sampling and remote decision-making under a sampling\nfrequency constraint and random delay. To efficiently solve this problem, we\ndesign a new two-stage hierarchical algorithm namely Quick\nBellman-Linear-Program (QuickBLP), where the first stage involves solving the\nDinkelbach root of a Bellman variant and the second stage involves solving a\nstreamlined linear program (LP). For the tricky first stage, we propose a new\nOne-layer Primal-Dinkelbach Synchronous Iteration (OnePDSI) method, which\novercomes the re-convergence and non-expansive divergence present in existing\nper-sample multi-layer algorithms. Through rigorous convergence analysis of our\nproposed algorithms, we establish that the worst-case optimality gap in OnePDSI\nexhibits exponential decay with respect to iteration $K$ at a rate of\n$\\mathcal{O}(\\frac{1}{R^K})$. Through sensitivity analysis, we derive a\nthreshold for the sampling frequency, beyond which additional sampling does not\nyield further gains in decision-making. Simulation results validate our\nanalyses.", "published": "2025-04-28 06:17:09", "link": "http://arxiv.org/abs/2504.19507v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Optimal Sequential Recommendations: Exploiting User and Item Structure", "abstract": "We consider an online model for recommendation systems, with each user being\nrecommended an item at each time-step and providing 'like' or 'dislike'\nfeedback. A latent variable model specifies the user preferences: both users\nand items are clustered into types. The model captures structure in both the\nitem and user spaces, as used by item-item and user-user collaborative\nfiltering algorithms. We study the situation in which the type preference\nmatrix has i.i.d. entries. Our main contribution is an algorithm that\nsimultaneously uses both item and user structures, proved to be near-optimal\nvia corresponding information-theoretic lower bounds. In particular, our\nanalysis highlights the sub-optimality of using only one of item or user\nstructure (as is done in most collaborative filtering algorithms).", "published": "2025-04-28 04:34:17", "link": "http://arxiv.org/abs/2504.19476v1", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "primary_category": "stat.ML"}
{"title": "Provably Secure Public-Key Steganography Based on Admissible Encoding", "abstract": "The technique of hiding secret messages within seemingly harmless covertext\nto evade examination by censors with rigorous security proofs is known as\nprovably secure steganography (PSS). PSS evolves from symmetric key\nsteganography to public-key steganography, functioning without the requirement\nof a pre-shared key and enabling the extension to multi-party covert\ncommunication and identity verification mechanisms. Recently, a public-key\nsteganography method based on elliptic curves was proposed, which uses point\ncompression to eliminate the algebraic structure of curve points. However, this\nmethod has strict requirements on the curve parameters and is only available on\nhalf of the points. To overcome these limitations, this paper proposes a more\ngeneral elliptic curve public key steganography method based on admissible\nencoding. By applying the tensor square function to the known well-distributed\nencoding, we construct admissible encoding, which can create the pseudo-random\npublic-key encryption function. The theoretical analysis and experimental\nresults show that the proposed provable secure public-key steganography method\ncan be deployed on all types of curves and utilize all points on the curve.", "published": "2025-04-28 03:42:25", "link": "http://arxiv.org/abs/2504.19454v1", "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "cs.CR"}
{"title": "Age of Information Analysis for NOMA-Assisted Grant-Free Transmissions with Randomly Arrived Packets", "abstract": "This paper investigates the application of non-orthogonal multiple access\n(NOMA) to grant-free transmissions to reduce the age of information (AoI) in\nuplink status update systems, where multiple sources upload their {status\nupdates} to {a common} receiver. Unlike existing studies which {adopted} the\nidealized generate-at-will (GAW) model, {i.e., a status} update data can be\ngenerated and transmitted at any time, this paper utilizes a more practical\nmodel {to characterize} the inherent randomness of the generation of the status\nupdating data packets. A rigorous analytical framework is established to\nprecisely evaluate the average AoI achieved by the NOMA-assisted grant-free\nschemes for both {the} cases with and without retransmission. The impact of the\nchoice of the probability {of transmission} on the average AoI is investigated.\nExtensive simulation results are provided to validate the accuracy of the\ndeveloped analysis. It is shown that NOMA-assisted schemes are more superior in\nreducing AoI{, compared} to orthogonal multiple access (OMA) based schemes. In\naddition, compared to schemes without retransmission, the AoI performance {of}\nthe schemes with retransmission can {be improved} significantly when the status\nupdate generation rate is low or the user density is relatively high.", "published": "2025-04-28 03:06:46", "link": "http://arxiv.org/abs/2504.19441v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Curiosity Driven Exploration to Optimize Structure-Property Learning in Microscopy", "abstract": "Rapidly determining structure-property correlations in materials is an\nimportant challenge in better understanding fundamental mechanisms and greatly\nassists in materials design. In microscopy, imaging data provides a direct\nmeasurement of the local structure, while spectroscopic measurements provide\nrelevant functional property information. Deep kernel active learning\napproaches have been utilized to rapidly map local structure to functional\nproperties in microscopy experiments, but are computationally expensive for\nmulti-dimensional and correlated output spaces. Here, we present an alternative\nlightweight curiosity algorithm which actively samples regions with unexplored\nstructure-property relations, utilizing a deep-learning based surrogate model\nfor error prediction. We show that the algorithm outperforms random sampling\nfor predicting properties from structures, and provides a convenient tool for\nefficient mapping of structure-property relationships in materials science.", "published": "2025-04-28 17:31:29", "link": "http://arxiv.org/abs/2504.20011v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Socially-Aware Autonomous Driving: Inferring Yielding Intentions for Safer Interactions", "abstract": "Since the emergence of autonomous driving technology, it has advanced rapidly\nover the past decade. It is becoming increasingly likely that autonomous\nvehicles (AVs) would soon coexist with human-driven vehicles (HVs) on the\nroads. Currently, safety and reliable decision-making remain significant\nchallenges, particularly when AVs are navigating lane changes and interacting\nwith surrounding HVs. Therefore, precise estimation of the intentions of\nsurrounding HVs can assist AVs in making more reliable and safe lane change\ndecision-making. This involves not only understanding their current behaviors\nbut also predicting their future motions without any direct communication.\nHowever, distinguishing between the passing and yielding intentions of\nsurrounding HVs still remains ambiguous. To address the challenge, we propose a\nsocial intention estimation algorithm rooted in Directed Acyclic Graph (DAG),\ncoupled with a decision-making framework employing Deep Reinforcement Learning\n(DRL) algorithms. To evaluate the method's performance, the proposed framework\ncan be tested and applied in a lane-changing scenario within a simulated\nenvironment. Furthermore, the experiment results demonstrate how our approach\nenhances the ability of AVs to navigate lane changes safely and efficiently on\nroads.", "published": "2025-04-28 17:24:04", "link": "http://arxiv.org/abs/2504.20004v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Graph Neural Network Prediction of Nonlinear Optical Properties", "abstract": "Nonlinear optical (NLO) materials for generating lasers via second harmonic\ngeneration (SHG) are highly sought in today's technology. However, discovering\nnovel materials with considerable SHG is challenging due to the time-consuming\nand costly nature of both experimental methods and first-principles\ncalculations. In this study, we present a deep learning approach using the\nAtomistic Line Graph Neural Network (ALIGNN) to predict NLO properties.\nSourcing data from the Novel Opto-Electronic Materials Discovery (NOEMD)\ndatabase and using the Kurtz-Perry (KP) coefficient as the key target, we\ndeveloped a robust model capable of accurately estimating nonlinear optical\nresponses. Our results demonstrate that the model achieves 82.5% accuracy at a\ntolerated absolute error up to 1 pm/V and relative error not exceeding 0.5.\nThis work highlights the potential of deep learning in accelerating the\ndiscovery and design of advanced optical materials with desired properties.", "published": "2025-04-28 17:03:22", "link": "http://arxiv.org/abs/2504.19987v1", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.optics"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Emergence and scaling laws in SGD learning of shallow neural networks", "abstract": "We study the complexity of online stochastic gradient descent (SGD) for\nlearning a two-layer neural network with $P$ neurons on isotropic Gaussian\ndata: $f_*(\\boldsymbol{x}) = \\sum_{p=1}^P a_p\\cdot\n\\sigma(\\langle\\boldsymbol{x},\\boldsymbol{v}_p^*\\rangle)$, $\\boldsymbol{x} \\sim\n\\mathcal{N}(0,\\boldsymbol{I}_d)$, where the activation\n$\\sigma:\\mathbb{R}\\to\\mathbb{R}$ is an even function with information exponent\n$k_*>2$ (defined as the lowest degree in the Hermite expansion),\n$\\{\\boldsymbol{v}^*_p\\}_{p\\in[P]}\\subset \\mathbb{R}^d$ are orthonormal signal\ndirections, and the non-negative second-layer coefficients satisfy $\\sum_{p}\na_p^2=1$. We focus on the challenging ``extensive-width'' regime $P\\gg 1$ and\npermit diverging condition number in the second-layer, covering as a special\ncase the power-law scaling $a_p\\asymp p^{-\\beta}$ where\n$\\beta\\in\\mathbb{R}_{\\ge 0}$. We provide a precise analysis of SGD dynamics for\nthe training of a student two-layer network to minimize the mean squared error\n(MSE) objective, and explicitly identify sharp transition times to recover each\nsignal direction. In the power-law setting, we characterize scaling law\nexponents for the MSE loss with respect to the number of training samples and\nSGD steps, as well as the number of parameters in the student neural network.\nOur analysis entails that while the learning of individual teacher neurons\nexhibits abrupt transitions, the juxtaposition of $P\\gg 1$ emergent learning\ncurves at different timescales leads to a smooth scaling law in the cumulative\nobjective.", "published": "2025-04-28 16:58:55", "link": "http://arxiv.org/abs/2504.19983v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Accurate and Diverse LLM Mathematical Reasoning via Automated PRM-Guided GFlowNets", "abstract": "Achieving both accuracy and diverse reasoning remains challenging for Large\nLanguage Models (LLMs) in complex domains like mathematics. A key bottleneck is\nevaluating intermediate reasoning steps to guide generation without costly\nhuman annotations. To address this, we first introduce a novel Process Reward\nModel (PRM) trained automatically using Monte Carlo Tree Search coupled with a\nsimilarity-based data augmentation technique, effectively capturing step-level\nreasoning quality. Leveraging this PRM, we then adapt Generative Flow Networks\n(GFlowNets) to operate at the reasoning step level. Unlike traditional\nreinforcement learning focused on maximizing a single reward, GFlowNets\nnaturally sample diverse, high-quality solutions proportional to their rewards,\nas measured by our PRM. Empirical evaluation shows strong improvements in both\naccuracy and solution diversity on challenging mathematical benchmarks (e.g.,\n+2.59% absolute accuracy on MATH Level 5 for Llama3.2-3B), with effective\ngeneralization to unseen datasets (+9.4% absolute on SAT MATH). Our work\ndemonstrates the potential of PRM-guided, step-level GFlowNets for developing\nmore robust and versatile mathematical reasoning in LLMs.", "published": "2025-04-28 16:56:41", "link": "http://arxiv.org/abs/2504.19981v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Transfer Learning Under High-Dimensional Network Convolutional Regression Model", "abstract": "Transfer learning enhances model performance by utilizing knowledge from\nrelated domains, particularly when labeled data is scarce. While existing\nresearch addresses transfer learning under various distribution shifts in\nindependent settings, handling dependencies in networked data remains\nchallenging. To address this challenge, we propose a high-dimensional transfer\nlearning framework based on network convolutional regression (NCR), inspired by\nthe success of graph convolutional networks (GCNs). The NCR model incorporates\nrandom network structure by allowing each node's response to depend on its\nfeatures and the aggregated features of its neighbors, capturing local\ndependencies effectively. Our methodology includes a two-step transfer learning\nalgorithm that addresses domain shift between source and target networks, along\nwith a source detection mechanism to identify informative domains.\nTheoretically, we analyze the lasso estimator in the context of a random graph\nbased on the Erdos-Renyi model assumption, demonstrating that transfer learning\nimproves convergence rates when informative sources are present. Empirical\nevaluations, including simulations and a real-world application using Sina\nWeibo data, demonstrate substantial improvements in prediction accuracy,\nparticularly when labeled data in the target domain is limited.", "published": "2025-04-28 16:52:28", "link": "http://arxiv.org/abs/2504.19979v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "On Stopping Times of Power-one Sequential Tests: Tight Lower and Upper Bounds", "abstract": "We prove two lower bounds for stopping times of sequential tests between\ngeneral composite nulls and alternatives. The first lower bound is for the\nsetting where the type-1 error level $\\alpha$ approaches zero, and equals\n$\\log(1/\\alpha)$ divided by a certain infimum KL divergence, termed\n$\\operatorname{KL_{inf}}$. The second lower bound applies to the setting where\n$\\alpha$ is fixed and $\\operatorname{KL_{inf}}$ approaches 0 (meaning that the\nnull and alternative sets are not separated) and equals $c\n\\operatorname{KL_{inf}}^{-1} \\log \\log \\operatorname{KL_{inf}}^{-1}$ for a\nuniversal constant $c > 0$. We also provide a sufficient condition for matching\nthe upper bounds and show that this condition is met in several special cases.\nGiven past work, these upper and lower bounds are unsurprising in their form;\nour main contribution is the generality in which they hold, for example, not\nrequiring reference measures or compactness of the classes.", "published": "2025-04-28 16:22:54", "link": "http://arxiv.org/abs/2504.19952v1", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Accelerating Mixture-of-Experts Training with Adaptive Expert Replication", "abstract": "Mixture-of-Experts (MoE) models have become a widely adopted solution to\ncontinue scaling model sizes without a corresponding linear increase in\ncompute. During MoE model training, each input token is dynamically routed to a\nsubset of experts -- sparsely-activated feed-forward networks -- within each\ntransformer layer. The distribution of tokens assigned to each expert varies\nwidely and rapidly over the course of training. To handle the wide load\nimbalance across experts, current systems are forced to either drop tokens\nassigned to popular experts, degrading convergence, or frequently rebalance\nresources allocated to each expert based on popularity, incurring high state\nmigration overheads.\n  To break this performance-accuracy tradeoff, we introduce SwiftMoE, an\nadaptive MoE training system. The key insight of SwiftMoE is to decouple the\nplacement of expert parameters from their large optimizer state. SwiftMoE\nstatically partitions the optimizer of each expert across all training nodes.\nMeanwhile, SwiftMoE dynamically adjusts the placement of expert parameters by\nrepurposing existing weight updates, avoiding migration overheads. In doing so,\nSwiftMoE right-sizes the GPU resources allocated to each expert, on a\nper-iteration basis, with minimal overheads. Compared to state-of-the-art MoE\ntraining systems, DeepSpeed and FlexMoE, SwiftMoE is able to achieve a 30.5%\nand 25.9% faster time-to-convergence, respectively.", "published": "2025-04-28 15:58:55", "link": "http://arxiv.org/abs/2504.19925v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Convergence Analysis of Asynchronous Federated Learning with Gradient Compression for Non-Convex Optimization", "abstract": "Gradient compression is an effective technique for reducing communication\ncosts in federated learning (FL), and error feedback (EF) is usually adopted to\nremedy the compression errors. However, there remains a lack of systematic\nstudy on these techniques in asynchronous FL. In this paper, we fill this gap\nby analyzing the convergence behaviors of FL under different frameworks. We\nfirstly consider a basic asynchronous FL framework AsynFL, and provide an\nimproved convergence analysis that relies on fewer assumptions and yields a\nsuperior convergence rate than prior studies. Then, we consider a variant\nframework with gradient compression, AsynFLC. We show sufficient conditions for\nits convergence to the optimum, indicating the interaction between asynchronous\ndelay and compression rate. Our analysis also demonstrates that asynchronous\ndelay amplifies the variance caused by compression, thereby hindering\nconvergence, and such an impact is exacerbated by high data heterogeneity.\nFurthermore, we study the convergence of AsynFLC-EF, the framework that further\nintegrates EF. We prove that EF can effectively reduce the variance of gradient\nestimation despite asynchronous delay, which enables AsynFLC-EF to match the\nconvergence rate of AsynFL. We also show that the impact of asynchronous delay\non EF is limited to slowing down the higher-order convergence term.\nExperimental results substantiate our analytical findings very well.", "published": "2025-04-28 15:35:34", "link": "http://arxiv.org/abs/2504.19903v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Digital Twin-based Out-of-Distribution Detection in Autonomous Vessels", "abstract": "An autonomous vessel (AV) is a complex cyber-physical system (CPS) with\nsoftware enabling many key functionalities, e.g., navigation software enables\nan AV to autonomously or semi-autonomously follow a path to its destination.\nDigital twins of such AVs enable advanced functionalities such as running\nwhat-if scenarios, performing predictive maintenance, and enabling fault\ndiagnosis. Due to technological improvements, real-time analyses using\ncontinuous data from vessels' real-time operations have become increasingly\npossible. However, the literature has little explored developing advanced\nanalyses in real-time data in AVs with digital twins built with machine\nlearning techniques. To this end, we present a novel digital twin-based\napproach (ODDIT) to detect future out-of-distribution (OOD) states of an AV\nbefore reaching them, enabling proactive intervention. Such states may indicate\nanomalies requiring attention (e.g., manual correction by the ship master) and\nassist testers in scenario-centered testing. The digital twin consists of two\nmachine-learning models predicting future vessel states and whether the\npredicted state will be OOD. We evaluated ODDIT with five vessels across\nwaypoint and zigzag maneuvering under simulated conditions, including sensor\nand actuator noise and environmental disturbances i.e., ocean current. ODDIT\nachieved high accuracy in detecting OOD states, with AUROC and TNR@TPR95 scores\nreaching 99\\% across multiple vessels.", "published": "2025-04-28 14:12:46", "link": "http://arxiv.org/abs/2504.19816v1", "categories": ["eess.SY", "cs.LG", "cs.SE", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Dynamic Tsetlin Machine Accelerators for On-Chip Training at the Edge using FPGAs", "abstract": "The increased demand for data privacy and security in machine learning (ML)\napplications has put impetus on effective edge training on Internet-of-Things\n(IoT) nodes. Edge training aims to leverage speed, energy efficiency and\nadaptability within the resource constraints of the nodes. Deploying and\ntraining Deep Neural Networks (DNNs)-based models at the edge, although\naccurate, posit significant challenges from the back-propagation algorithm's\ncomplexity, bit precision trade-offs, and heterogeneity of DNN layers. This\npaper presents a Dynamic Tsetlin Machine (DTM) training accelerator as an\nalternative to DNN implementations. DTM utilizes logic-based on-chip inference\nwith finite-state automata-driven learning within the same Field Programmable\nGate Array (FPGA) package. Underpinned on the Vanilla and Coalesced Tsetlin\nMachine algorithms, the dynamic aspect of the accelerator design allows for a\nrun-time reconfiguration targeting different datasets, model architectures, and\nmodel sizes without resynthesis. This makes the DTM suitable for targeting\nmultivariate sensor-based edge tasks. Compared to DNNs, DTM trains with fewer\nmultiply-accumulates, devoid of derivative computation. It is a data-centric ML\nalgorithm that learns by aligning Tsetlin automata with input data to form\nlogical propositions enabling efficient Look-up-Table (LUT) mapping and frugal\nBlock RAM usage in FPGA training implementations. The proposed accelerator\noffers 2.54x more Giga operations per second per Watt (GOP/s per W) and uses 6x\nless power than the next-best comparable design.", "published": "2025-04-28 13:38:53", "link": "http://arxiv.org/abs/2504.19797v1", "categories": ["cs.AR", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Interpretable machine learning-guided design of Fe-based soft magnetic alloys", "abstract": "We present a machine-learning guided approach to predict saturation\nmagnetization (MS) and coercivity (HC) in Fe-rich soft magnetic alloys,\nparticularly Fe-Si-B systems. ML models trained on experimental data reveals\nthat increasing Si and B content reduces MS from 1.81T (DFT~2.04 T) to ~1.54 T\n(DFT~1.56T) in Fe-Si-B, which is attributed to decreased magnetic density and\nstructural modifications. Experimental validation of ML predicted magnetic\nsaturation on Fe-1Si-1B (2.09T), Fe-5Si-5B (2.01T) and Fe-10Si-10B (1.54T)\nalloy compositions further support our findings. These trends are consistent\nwith density functional theory (DFT) predictions, which link increased\nelectronic disorder and band broadening to lower MS values. Experimental\nvalidation on selected alloys confirms the predictive accuracy of the ML model,\nwith good agreement across compositions. Beyond predictive accuracy, detailed\nuncertainty quantification and model interpretability including through feature\nimportance and partial dependence analysis reveals that MS is governed by a\nnonlinear interplay between Fe content, early transition metal ratios, and\nannealing temperature, while HC is more sensitive to processing conditions such\nas ribbon thickness and thermal treatment windows. The ML framework was further\napplied to Fe-Si-B/Cr/Cu/Zr/Nb alloys in a pseudo-quaternary compositional\nspace, which shows comparable magnetic properties to NANOMET\n(Fe84.8Si0.5B9.4Cu0.8 P3.5C1), FINEMET (Fe73.5Si13.5B9 Cu1Nb3), NANOPERM\n(Fe88Zr7B4Cu1), and HITPERM (Fe44Co44Zr7B4Cu1. Our fundings demonstrate the\npotential of ML framework for accelerated search of high-performance, Co- and\nNi-free, soft magnetic materials.", "published": "2025-04-28 13:30:28", "link": "http://arxiv.org/abs/2504.19787v1", "categories": ["cond-mat.mtrl-sci", "cond-mat.other", "cs.LG"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Heterophily-informed Message Passing", "abstract": "Graph neural networks (GNNs) are known to be vulnerable to oversmoothing due\nto their implicit homophily assumption. We mitigate this problem with a novel\nscheme that regulates the aggregation of messages, modulating the type and\nextent of message passing locally thereby preserving both the low and\nhigh-frequency components of information. Our approach relies solely on learnt\nembeddings, obviating the need for auxiliary labels, thus extending the\nbenefits of heterophily-aware embeddings to broader applications, e.g.,\ngenerative modelling. Our experiments, conducted across various data sets and\nGNN architectures, demonstrate performance enhancements and reveal heterophily\npatterns across standard classification benchmarks. Furthermore, application to\nmolecular generation showcases notable performance improvements on\nchemoinformatics benchmarks.", "published": "2025-04-28 13:28:23", "link": "http://arxiv.org/abs/2504.19785v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "If Concept Bottlenecks are the Question, are Foundation Models the Answer?", "abstract": "Concept Bottleneck Models (CBMs) are neural networks designed to conjoin high\nperformance with ante-hoc interpretability. CBMs work by first mapping inputs\n(e.g., images) to high-level concepts (e.g., visible objects and their\nproperties) and then use these to solve a downstream task (e.g., tagging or\nscoring an image) in an interpretable manner. Their performance and\ninterpretability, however, hinge on the quality of the concepts they learn. The\ngo-to strategy for ensuring good quality concepts is to leverage expert\nannotations, which are expensive to collect and seldom available in\napplications. Researchers have recently addressed this issue by introducing\n\"VLM-CBM\" architectures that replace manual annotations with weak supervision\nfrom foundation models. It is however unclear what is the impact of doing so on\nthe quality of the learned concepts. To answer this question, we put\nstate-of-the-art VLM-CBMs to the test, analyzing their learned concepts\nempirically using a selection of significant metrics. Our results show that,\ndepending on the task, VLM supervision can sensibly differ from expert\nannotations, and that concept accuracy and quality are not strongly correlated.\nOur code is available at https://github.com/debryu/CQA.", "published": "2025-04-28 13:18:48", "link": "http://arxiv.org/abs/2504.19774v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "FineQ: Software-Hardware Co-Design for Low-Bit Fine-Grained Mixed-Precision Quantization of LLMs", "abstract": "Large language models (LLMs) have significantly advanced the natural language\nprocessing paradigm but impose substantial demands on memory and computational\nresources. Quantization is one of the most effective ways to reduce memory\nconsumption of LLMs. However, advanced single-precision quantization methods\nexperience significant accuracy degradation when quantizing to ultra-low bits.\nExisting mixed-precision quantization methods are quantized by groups with\ncoarse granularity. Employing high precision for group data leads to\nsubstantial memory overhead, whereas low precision severely impacts model\naccuracy. To address this issue, we propose FineQ, software-hardware co-design\nfor low-bit fine-grained mixed-precision quantization of LLMs. First, FineQ\npartitions the weights into finer-grained clusters and considers the\ndistribution of outliers within these clusters, thus achieving a balance\nbetween model accuracy and memory overhead. Then, we propose an outlier\nprotection mechanism within clusters that uses 3 bits to represent outliers and\nintroduce an encoding scheme for index and data concatenation to enable aligned\nmemory access. Finally, we introduce an accelerator utilizing temporal coding\nthat effectively supports the quantization algorithm while simplifying the\nmultipliers in the systolic array. FineQ achieves higher model accuracy\ncompared to the SOTA mixed-precision quantization algorithm at a close average\nbit-width. Meanwhile, the accelerator achieves up to 1.79x energy efficiency\nand reduces the area of the systolic array by 61.2%.", "published": "2025-04-28 12:47:23", "link": "http://arxiv.org/abs/2504.19746v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Graph Fourier Transformer with Structure-Frequency Information", "abstract": "Graph Transformers (GTs) have shown advantages in numerous graph structure\ntasks but their self-attention mechanism ignores the generalization bias of\ngraphs, with existing methods mainly compensating for this bias from aspects\nlike position encoding, attention bias and relative distance yet still having\nsub-optimal performance and being insufficient by only considering the\nstructural perspective of generalization bias. To address this, this paper\nproposes Grafourierformer, which innovatively combines GT with inductive bias\ncontaining Frequency-Structure information by applying Graph Fourier Transform\nto the Attention Matrix: specifically, eigenvalues from the Graph Laplacian\nmatrix are used to construct an Eigenvalue matrix mask (reflecting node\npositions and structural relationships with neighboring nodes to enable\nconsideration of node range structural characteristics and focus on local graph\ndetails), and inverse Fourier transform is employed to extract node\nhigh-frequency and low-frequency features, calculate low-frequency and\nhigh-frequency energy, and construct a node frequency-energy matrix to filter\nthe eigenvalue matrix mask, allowing attention heads to incorporate both graph\nstructural information and node frequency information optimization, adaptively\ndistinguish global trends from local details, and effectively suppress\nredundant information interference. Extensive experiments on various benchmarks\nshow Grafourierformer consistently outperforms GNN and GT-based models in graph\nclassification and node classification tasks, with ablation experiments further\nvalidating the effectiveness and necessity of the method. Codes are available\nat https://github.com/Arichibald/Grafourierformer.git", "published": "2025-04-28 12:38:02", "link": "http://arxiv.org/abs/2504.19740v1", "categories": ["cs.LG", "cs.GR"], "primary_category": "cs.LG"}
{"title": "Neuronal correlations shape the scaling behavior of memory capacity and nonlinear computational capability of recurrent neural networks", "abstract": "Reservoir computing is a powerful framework for real-time information\nprocessing, characterized by its high computational ability and quick learning,\nwith applications ranging from machine learning to biological systems. In this\npaper, we demonstrate that the memory capacity of a reservoir recurrent neural\nnetwork scales sublinearly with the number of readout neurons. To elucidate\nthis phenomenon, we develop a theoretical framework for analytically deriving\nmemory capacity, attributing the decaying growth of memory capacity to neuronal\ncorrelations. In addition, numerical simulations reveal that once memory\ncapacity becomes sublinear, increasing the number of readout neurons\nsuccessively enables nonlinear processing at progressively higher polynomial\norders. Furthermore, our theoretical framework suggests that neuronal\ncorrelations govern not only memory capacity but also the sequential growth of\nnonlinear computational capabilities. Our findings establish a foundation for\ndesigning scalable and cost-effective reservoir computing, providing novel\ninsights into the interplay among neuronal correlations, linear memory, and\nnonlinear processing.", "published": "2025-04-28 10:17:31", "link": "http://arxiv.org/abs/2504.19657v1", "categories": ["cond-mat.dis-nn", "cs.LG", "q-bio.NC"], "primary_category": "cond-mat.dis-nn"}
{"title": "Intelligent4DSE: Optimizing High-Level Synthesis Design Space Exploration with Graph Neural Networks and Large Language Models", "abstract": "High-level synthesis (HLS) design space exploration (DSE) is an optimization\nprocess in electronic design automation (EDA) that systematically explores\nhigh-level design configurations to achieve Pareto-optimal hardware\nimplementations balancing performance, area, and power (PPA). To optimize this\nprocess, HLS prediction tasks often employ message-passing neural networks\n(MPNNs), leveraging complex architectures to achieve high accuracy. These\npredictors serve as evaluators in the DSE process, effectively bypassing the\ntime-consuming estimations traditionally required by HLS tools. However,\nexisting models often prioritize structural complexity and minimization of\ntraining loss, overlooking task-specific characteristics. Additionally, while\nevolutionary algorithms are widely used in DSE, they typically require\nextensive domain-specific knowledge to design effective crossover and mutation\noperators. To address these limitations, we propose CoGNNs-LLMEA, a framework\nthat integrates a graph neural network with task-adaptive message passing and a\nlarge language model-enhanced evolutionary algorithm. As a predictive model,\nCoGNNs directly leverages intermediate representations generated from source\ncode after compiler front-end processing, enabling prediction of quality of\nresults (QoR) without invoking HLS tools. Due to its strong adaptability to\ntasks, CoGNNs can be tuned to predict post-HLS and post-implementation\noutcomes, effectively bridging the gap between high-level abstractions and\nphysical implementation characteristics. CoGNNs achieves state-of-the-art\nprediction accuracy in post-HLS QoR prediction, reducing mean prediction errors\nby 2.8$\\times$ for latency and 3.4$\\times$ for resource utilization compared to\nbaseline models.", "published": "2025-04-28 10:08:56", "link": "http://arxiv.org/abs/2504.19649v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "A Unified Benchmark of Federated Learning with Kolmogorov-Arnold Networks for Medical Imaging", "abstract": "Federated Learning (FL) enables model training across decentralized devices\nwithout sharing raw data, thereby preserving privacy in sensitive domains like\nhealthcare. In this paper, we evaluate Kolmogorov-Arnold Networks (KAN)\narchitectures against traditional MLP across six state-of-the-art FL algorithms\non a blood cell classification dataset. Notably, our experiments demonstrate\nthat KAN can effectively replace MLP in federated environments, achieving\nsuperior performance with simpler architectures. Furthermore, we analyze the\nimpact of key hyperparameters-grid size and network architecture-on KAN\nperformance under varying degrees of Non-IID data distribution. Additionally,\nour ablation studies reveal that optimizing KAN width while maintaining minimal\ndepth yields the best performance in federated settings. As a result, these\nfindings establish KAN as a promising alternative for privacy-preserving\nmedical imaging applications in distributed healthcare. To the best of our\nknowledge, this is the first comprehensive benchmark of KAN in FL settings for\nmedical imaging task.", "published": "2025-04-28 09:53:05", "link": "http://arxiv.org/abs/2504.19639v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "LODAP: On-Device Incremental Learning Via Lightweight Operations and Data Pruning", "abstract": "Incremental learning that learns new classes over time after the model's\ndeployment is becoming increasingly crucial, particularly for industrial edge\nsystems, where it is difficult to communicate with a remote server to conduct\ncomputation-intensive learning. As more classes are expected to learn after\ntheir execution for edge devices. In this paper, we propose LODAP, a new\non-device incremental learning framework for edge systems. The key part of\nLODAP is a new module, namely Efficient Incremental Module (EIM). EIM is\ncomposed of normal convolutions and lightweight operations. During incremental\nlearning, EIM exploits some lightweight operations, called adapters, to\neffectively and efficiently learn features for new classes so that it can\nimprove the accuracy of incremental learning while reducing model complexity as\nwell as training overhead. The efficiency of LODAP is further enhanced by a\ndata pruning strategy that significantly reduces the training data, thereby\nlowering the training overhead. We conducted extensive experiments on the\nCIFAR-100 and Tiny- ImageNet datasets. Experimental results show that LODAP\nimproves the accuracy by up to 4.32\\% over existing methods while reducing\naround 50\\% of model complexity. In addition, evaluations on real edge systems\ndemonstrate its applicability for on-device machine learning. The code is\navailable at https://github.com/duanbiqing/LODAP.", "published": "2025-04-28 09:52:53", "link": "http://arxiv.org/abs/2504.19638v1", "categories": ["cs.LG", "cs.ET"], "primary_category": "cs.LG"}
{"title": "Diffusion Stochastic Learning Over Adaptive Competing Networks", "abstract": "This paper studies a stochastic dynamic game between two competing teams,\neach consisting of a network of collaborating agents. Unlike fully cooperative\nsettings, where all agents share a common objective, each team in this game\naims to minimize its own distinct objective. In the adversarial setting, their\nobjectives could be conflicting as in zero-sum games. Throughout the\ncompetition, agents share strategic information within their own team while\nsimultaneously inferring and adapting to the strategies of the opposing team.\nWe propose diffusion learning algorithms to address two important classes of\nthis network game: i) a zero-sum game characterized by weak cross-team subgraph\ninteractions, and ii) a general non-zero-sum game exhibiting strong cross-team\nsubgraph interactions. We analyze the stability performance of the proposed\nalgorithms under reasonable assumptions and illustrate the theoretical results\nthrough experiments on Cournot team competition and decentralized GAN training.", "published": "2025-04-28 09:49:54", "link": "http://arxiv.org/abs/2504.19635v1", "categories": ["cs.MA", "cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.MA"}
{"title": "QFDNN: A Resource-Efficient Variational Quantum Feature Deep Neural Networks for Fraud Detection and Loan Prediction", "abstract": "Social financial technology focuses on trust, sustainability, and social\nresponsibility, which require advanced technologies to address complex\nfinancial tasks in the digital era. With the rapid growth in online\ntransactions, automating credit card fraud detection and loan eligibility\nprediction has become increasingly challenging. Classical machine learning (ML)\nmodels have been used to solve these challenges; however, these approaches\noften encounter scalability, overfitting, and high computational costs due to\ncomplexity and high-dimensional financial data. Quantum computing (QC) and\nquantum machine learning (QML) provide a promising solution to efficiently\nprocessing high-dimensional datasets and enabling real-time identification of\nsubtle fraud patterns. However, existing quantum algorithms lack robustness in\nnoisy environments and fail to optimize performance with reduced feature sets.\nTo address these limitations, we propose a quantum feature deep neural network\n(QFDNN), a novel, resource efficient, and noise-resilient quantum model that\noptimizes feature representation while requiring fewer qubits and simpler\nvariational circuits. The model is evaluated using credit card fraud detection\nand loan eligibility prediction datasets, achieving competitive accuracies of\n82.2% and 74.4%, respectively, with reduced computational overhead.\nFurthermore, we test QFDNN against six noise models, demonstrating its\nrobustness across various error conditions. Our findings highlight QFDNN\npotential to enhance trust and security in social financial technology by\naccurately detecting fraudulent transactions while supporting sustainability\nthrough its resource-efficient design and minimal computational overhead.", "published": "2025-04-28 09:47:28", "link": "http://arxiv.org/abs/2504.19632v1", "categories": ["quant-ph", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Rulebook: bringing co-routines to reinforcement learning environments", "abstract": "Reinforcement learning (RL) algorithms, due to their reliance on external\nsystems to learn from, require digital environments (e.g., simulators) with\nvery simple interfaces, which in turn constrain significantly the\nimplementation of such environments. In particular, these environments are\nimplemented either as separate processes or as state machines, leading to\nsynchronization and communication overheads in the first case, and to\nunstructured programming in the second.\n  We propose a new domain-specific, co-routine-based, compiled language, called\nRulebook, designed to automatically generate the state machine required to\ninteract with machine learning (ML) algorithms and similar applications, with\nno performance overhead. Rulebook allows users to express programs without\nneeding to be aware of the specific interface required by the ML components. By\ndecoupling the execution model of the program from the syntactical encoding of\nthe program, and thus without the need for manual state management, Rulebook\nallows to create larger and more sophisticated environments at a lower\ndevelopment cost.", "published": "2025-04-28 09:34:34", "link": "http://arxiv.org/abs/2504.19625v1", "categories": ["cs.PL", "cs.LG"], "primary_category": "cs.PL"}
{"title": "AI Alignment in Medical Imaging: Unveiling Hidden Biases Through Counterfactual Analysis", "abstract": "Machine learning (ML) systems for medical imaging have demonstrated\nremarkable diagnostic capabilities, but their susceptibility to biases poses\nsignificant risks, since biases may negatively impact generalization\nperformance. In this paper, we introduce a novel statistical framework to\nevaluate the dependency of medical imaging ML models on sensitive attributes,\nsuch as demographics. Our method leverages the concept of counterfactual\ninvariance, measuring the extent to which a model's predictions remain\nunchanged under hypothetical changes to sensitive attributes. We present a\npractical algorithm that combines conditional latent diffusion models with\nstatistical hypothesis testing to identify and quantify such biases without\nrequiring direct access to counterfactual data. Through experiments on\nsynthetic datasets and large-scale real-world medical imaging datasets,\nincluding \\textsc{cheXpert} and MIMIC-CXR, we demonstrate that our approach\naligns closely with counterfactual fairness principles and outperforms standard\nbaselines. This work provides a robust tool to ensure that ML diagnostic\nsystems generalize well, e.g., across demographic groups, offering a critical\nstep towards AI safety in healthcare. Code:\nhttps://github.com/Neferpitou3871/AI-Alignment-Medical-Imaging.", "published": "2025-04-28 09:28:25", "link": "http://arxiv.org/abs/2504.19621v1", "categories": ["cs.LG", "eess.IV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Soft-Label Caching and Sharpening for Communication-Efficient Federated Distillation", "abstract": "Federated Learning (FL) enables collaborative model training across\ndecentralized clients, enhancing privacy by keeping data local. Yet\nconventional FL, relying on frequent parameter-sharing, suffers from high\ncommunication overhead and limited model heterogeneity. Distillation-based FL\napproaches address these issues by sharing predictions (soft-labels) instead,\nbut they often involve redundant transmissions across communication rounds,\nreducing efficiency. We propose SCARLET, a novel framework integrating\nsynchronized soft-label caching and an enhanced Entropy Reduction Aggregation\n(Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing\ncached soft-labels, achieving up to 50% reduction in communication costs\ncompared to existing methods while maintaining accuracy. Enhanced ERA can be\ntuned to adapt to non-IID data variations, ensuring robust aggregation and\nperformance in diverse client scenarios. Experimental evaluations demonstrate\nthat SCARLET consistently outperforms state-of-the-art distillation-based FL\nmethods in terms of accuracy and communication efficiency. The implementation\nof SCARLET is publicly available at https://github.com/kitsuyaazuma/SCARLET.", "published": "2025-04-28 09:04:30", "link": "http://arxiv.org/abs/2504.19602v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Robust Multimodal Physiological Foundation Models: Handling Arbitrary Missing Modalities", "abstract": "Multimodal physiological signals, such as EEG, ECG, EOG, and EMG, are crucial\nfor healthcare and brain-computer interfaces. While existing methods rely on\nspecialized architectures and dataset-specific fusion strategies, they struggle\nto learn universal representations that generalize across datasets and handle\nmissing modalities at inference time. To address these issues, we propose\nPhysioOmni, a foundation model for multimodal physiological signal analysis\nthat models both homogeneous and heterogeneous features to decouple multimodal\nsignals and extract generic representations while maintaining compatibility\nwith arbitrary missing modalities. PhysioOmni trains a decoupled multimodal\ntokenizer, enabling masked signal pre-training via modality-invariant and\nmodality-specific objectives. To ensure adaptability to diverse and incomplete\nmodality combinations, the pre-trained encoders undergo resilient fine-tuning\nwith prototype alignment on downstream datasets. Extensive experiments on four\ndownstream tasks, emotion recognition, sleep stage classification, motor\nprediction, and mental workload detection, demonstrate that PhysioOmni achieves\nstate-of-the-art performance while maintaining strong robustness to missing\nmodalities. Our code and model weights will be released.", "published": "2025-04-28 09:00:04", "link": "http://arxiv.org/abs/2504.19596v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Quantifying Memory Utilization with Effective State-Size", "abstract": "The need to develop a general framework for architecture analysis is becoming\nincreasingly important, given the expanding design space of sequence models. To\nthis end, we draw insights from classical signal processing and control theory,\nto develop a quantitative measure of \\textit{memory utilization}: the internal\nmechanisms through which a model stores past information to produce future\noutputs. This metric, which we call \\textbf{\\textit{effective state-size}}\n(ESS), is tailored to the fundamental class of systems with\n\\textit{input-invariant} and \\textit{input-varying linear operators},\nencompassing a variety of computational units such as variants of attention,\nconvolutions, and recurrences. Unlike prior work on memory utilization, which\neither relies on raw operator visualizations (e.g. attention maps), or simply\nthe total \\textit{memory capacity} (i.e. cache size) of a model, our metrics\nprovide highly interpretable and actionable measurements. In particular, we\nshow how ESS can be leveraged to improve initialization strategies, inform\nnovel regularizers and advance the performance-efficiency frontier through\nmodel distillation. Furthermore, we demonstrate that the effect of context\ndelimiters (such as end-of-speech tokens) on ESS highlights cross-architectural\ndifferences in how large language models utilize their available memory to\nrecall information. Overall, we find that ESS provides valuable insights into\nthe dynamics that dictate memory utilization, enabling the design of more\nefficient and effective sequence models.", "published": "2025-04-28 08:12:30", "link": "http://arxiv.org/abs/2504.19561v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Faster and More Compact Foundation Models for Molecular Property Prediction", "abstract": "Advancements in machine learning for molecular property prediction have\nimproved accuracy but at the expense of higher computational cost and longer\ntraining times. Recently, the Joint Multi-domain Pre-training (JMP) foundation\nmodel has demonstrated strong performance across various downstream tasks with\nreduced training time over previous models. Despite JMP's advantages,\nfine-tuning it on molecular datasets ranging from small-scale to large-scale\nrequires considerable time and computational resources. In this work, we\ninvestigate strategies to enhance efficiency by reducing model size while\npreserving performance. To better understand the model's efficiency, we analyze\nthe layer contributions of JMP and find that later interaction blocks provide\ndiminishing returns, suggesting an opportunity for model compression. We\nexplore block reduction strategies by pruning the pre-trained model and\nevaluating its impact on efficiency and accuracy during fine-tuning. Our\nanalysis reveals that removing two interaction blocks results in a minimal\nperformance drop, reducing the model size by 32% while increasing inference\nthroughput by 1.3x. These results suggest that JMP-L is over-parameterized and\nthat a smaller, more efficient variant can achieve comparable performance with\nlower computational cost. Our study provides insights for developing lighter,\nfaster, and more scalable foundation models for molecular and materials\ndiscovery. The code is publicly available at:\nhttps://github.com/Yasir-Ghunaim/efficient-jmp.", "published": "2025-04-28 07:41:03", "link": "http://arxiv.org/abs/2504.19538v1", "categories": ["cs.LG", "q-bio.BM"], "primary_category": "cs.LG"}
{"title": "Euclidean Distance Matrix Completion via Asymmetric Projected Gradient Descent", "abstract": "This paper proposes and analyzes a gradient-type algorithm based on\nBurer-Monteiro factorization, called the Asymmetric Projected Gradient Descent\n(APGD), for reconstructing the point set configuration from partial Euclidean\ndistance measurements, known as the Euclidean Distance Matrix Completion (EDMC)\nproblem. By paralleling the incoherence matrix completion framework, we show\nfor the first time that global convergence guarantee with exact recovery of\nthis routine can be established given $\\mathcal{O}(\\mu^2 r^3 \\kappa^2 n \\log\nn)$ Bernoulli random observations without any sample splitting. Unlike\nleveraging the tangent space Restricted Isometry Property (RIP) and local\ncurvature of the low-rank embedding manifold in some very recent works, our\nproof provides new upper bounds to replace the random graph lemma under EDMC\nsetting. The APGD works surprisingly well and numerical experiments demonstrate\nexact linear convergence behavior in rich-sample regions yet deteriorates fast\nwhen compared with the performance obtained by optimizing the s-stress\nfunction, i.e., the standard but unexplained non-convex approach for EDMC, if\nthe sample size is limited. While virtually matching our theoretical\nprediction, this unusual phenomenon might indicate that: (i) the power of\nimplicit regularization is weakened when specified in the APGD case; (ii) the\nstabilization of such new gradient direction requires substantially more\nsamples than the information-theoretic limit would suggest.", "published": "2025-04-28 07:13:23", "link": "http://arxiv.org/abs/2504.19530v1", "categories": ["cs.LG", "eess.SP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Identification and Estimation of Long-Term Treatment Effects with Monotone Missing", "abstract": "Estimating long-term treatment effects has a wide range of applications in\nvarious domains. A key feature in this context is that collecting long-term\noutcomes typically involves a multi-stage process and is subject to monotone\nmissing, where individuals missing at an earlier stage remain missing at\nsubsequent stages. Despite its prevalence, monotone missing has been rarely\nexplored in previous studies on estimating long-term treatment effects. In this\npaper, we address this gap by introducing the sequential missingness assumption\nfor identification. We propose three novel estimation methods, including\ninverse probability weighting, sequential regression imputation, and sequential\nmarginal structural model (SeqMSM). Considering that the SeqMSM method may\nsuffer from high variance due to severe data sparsity caused by monotone\nmissing, we further propose a novel balancing-enhanced approach, BalanceNet, to\nimprove the stability and accuracy of the estimation methods. Extensive\nexperiments on two widely used benchmark datasets demonstrate the effectiveness\nof our proposed methods.", "published": "2025-04-28 07:07:50", "link": "http://arxiv.org/abs/2504.19527v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Negative Imaginary Neural ODEs: Learning to Control Mechanical Systems with Stability Guarantees", "abstract": "We propose a neural control method to provide guaranteed stabilization for\nmechanical systems using a novel negative imaginary neural ordinary\ndifferential equation (NINODE) controller. Specifically, we employ neural\nnetworks with desired properties as state-space function matrices within a\nHamiltonian framework to ensure the system possesses the NI property. This\nNINODE system can serve as a controller that asymptotically stabilizes an NI\nplant under certain conditions. For mechanical plants with colocated force\nactuators and position sensors, we demonstrate that all the conditions required\nfor stability can be translated into regularity constraints on the neural\nnetworks used in the controller. We illustrate the utility, effectiveness, and\nstability guarantees of the NINODE controller through an example involving a\nnonlinear mass-spring system.", "published": "2025-04-28 05:37:25", "link": "http://arxiv.org/abs/2504.19497v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "Two-parameter superposable S-curves", "abstract": "Straight line equation $y=mx$ with slope $m$, when singularly perturbed as\n$ay^3+y=mx$ with a positive parameter $a$, results in S-shaped curves or\nS-curves on a real plane. As $a\\rightarrow 0$, we get back $y=mx$ which is a\ncumulative distribution function of a continuous uniform distribution that\ndescribes the occurrence of every event in an interval to be equally probable.\nAs $a\\rightarrow\\infty$, the derivative of $y$ has finite support only at $y=0$\nresembling a degenerate distribution. Based on these arguments, in this work,\nwe propose that these S-curves can represent maximum entropy uniform\ndistribution to a zero entropy single value. We also argue that these S-curves\nare superposable as they are only parametrically nonlinear but fundamentally\nlinear. So far, the superposed forms have been used to capture the patterns of\nnatural systems such as nonlinear dynamics of biological growth and kinetics of\nenzyme reactions. Here, we attempt to use the S-curve and its superposed form\nas a statistical model. We fit the models on a classical dataset containing\nflower measurements of iris plants and analyze their usefulness in pattern\nrecognition. Based on these models, we claim that any non-uniform pattern can\nbe represented as a singular perturbation to uniform distribution. However, our\nparametric estimation procedure have some limitations such as sensitivity to\ninitial conditions depending on the data at hand.", "published": "2025-04-28 05:08:02", "link": "http://arxiv.org/abs/2504.19488v1", "categories": ["stat.ME", "cs.LG"], "primary_category": "stat.ME"}
{"title": "Model uncertainty quantification using feature confidence sets for outcome excursions", "abstract": "When implementing prediction models for high-stakes real-world applications\nsuch as medicine, finance, and autonomous systems, quantifying prediction\nuncertainty is critical for effective risk management. Traditional approaches\nto uncertainty quantification, such as confidence and prediction intervals,\nprovide probability coverage guarantees for the expected outcomes\n$f(\\boldsymbol{x})$ or the realized outcomes $f(\\boldsymbol{x})+\\epsilon$.\nInstead, this paper introduces a novel, model-agnostic framework for\nquantifying uncertainty in continuous and binary outcomes using confidence sets\nfor outcome excursions, where the goal is to identify a subset of the feature\nspace where the expected or realized outcome exceeds a specific value. The\nproposed method constructs data-dependent inner and outer confidence sets that\naim to contain the true feature subset for which the expected or realized\noutcomes of these features exceed a specified threshold. We establish\ntheoretical guarantees for the probability that these confidence sets contain\nthe true feature subset, both asymptotically and for finite sample sizes. The\nframework is validated through simulations and applied to real-world datasets,\ndemonstrating its utility in contexts such as housing price prediction and time\nto sepsis diagnosis in healthcare. This approach provides a unified method for\nuncertainty quantification that is broadly applicable across various continuous\nand binary prediction models.", "published": "2025-04-28 04:08:07", "link": "http://arxiv.org/abs/2504.19464v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Geometry-Informed Neural Operator Transformer", "abstract": "Machine-learning-based surrogate models offer significant computational\nefficiency and faster simulations compared to traditional numerical methods,\nespecially for problems requiring repeated evaluations of partial differential\nequations. This work introduces the Geometry-Informed Neural Operator\nTransformer (GINOT), which integrates the transformer architecture with the\nneural operator framework to enable forward predictions for arbitrary\ngeometries. GINOT encodes the surface points cloud of a geometry using a\nsampling and grouping mechanism combined with an attention mechanism, ensuring\ninvariance to point order and padding while maintaining robustness to\nvariations in point density. The geometry information is seamlessly integrated\nwith query points in the solution decoder through the attention mechanism. The\nperformance of GINOT is validated on multiple challenging datasets, showcasing\nits high accuracy and strong generalization capabilities for complex and\narbitrary 2D and 3D geometries.", "published": "2025-04-28 03:39:27", "link": "http://arxiv.org/abs/2504.19452v1", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "R-Sparse: Rank-Aware Activation Sparsity for Efficient LLM Inference", "abstract": "Large Language Models (LLMs), while demonstrating remarkable capabilities\nacross various applications, present significant challenges during inference\ndue to their substantial model size, especially when deployed on edge devices.\nActivation sparsity offers a promising solution to reduce computation and\nmemory movement, enabling more efficient inference, particularly for\nsmall-batch on-device applications. However, current approaches face\nlimitations with non-ReLU activation function, which are foundational to most\nadvanced LLMs, or require heavy continual training. Additionally, the\ndifficulty in predicting active channels and limited achievable sparsity ratios\nconstrain the effectiveness of activation sparsity-based methods. In this\npaper, we introduce R-Sparse, a training-free activation sparsity approach\ncapable of achieving high sparsity levels in advanced LLMs. We conducted two\npreliminary investigations into how different components contribute to the\noutput within a single linear layer and found two key observations: (i) the\nnon-sparse components of the input function can be regarded as a few bias\nterms, and (ii) The full computation can be effectively approximated by an\nappropriate combination of input channels and weight singular values. Building\non this, we replace the linear layers in LLMs with a rank-aware sparse\ninference method that leverages the sparsity of input channels and singular\nvalue components, eliminating the need for active channel prediction like the\noutput sparsity based approaches. Experiments on Llama-2/3 and Mistral models\nacross ten diverse tasks demonstrate that R-Sparse achieves comparable\nperformance at 50% model-level sparsity, resulting in a significant 43%\nend-to-end efficient improvements with customized kernels.", "published": "2025-04-28 03:30:32", "link": "http://arxiv.org/abs/2504.19449v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning High-dimensional Gaussians from Censored Data", "abstract": "We provide efficient algorithms for the problem of distribution learning from\nhigh-dimensional Gaussian data where in each sample, some of the variable\nvalues are missing. We suppose that the variables are missing not at random\n(MNAR). The missingness model, denoted by $S(y)$, is the function that maps any\npoint $y$ in $R^d$ to the subsets of its coordinates that are seen. In this\nwork, we assume that it is known. We study the following two settings:\n  (i) Self-censoring: An observation $x$ is generated by first sampling the\ntrue value $y$ from a $d$-dimensional Gaussian $N(\\mu*, \\Sigma*)$ with unknown\n$\\mu*$ and $\\Sigma*$. For each coordinate $i$, there exists a set $S_i$\nsubseteq $R^d$ such that $x_i = y_i$ if and only if $y_i$ in $S_i$. Otherwise,\n$x_i$ is missing and takes a generic value (e.g., \"?\"). We design an algorithm\nthat learns $N(\\mu*, \\Sigma*)$ up to total variation (TV) distance epsilon,\nusing $poly(d, 1/\\epsilon)$ samples, assuming only that each pair of\ncoordinates is observed with sufficiently high probability.\n  (ii) Linear thresholding: An observation $x$ is generated by first sampling\n$y$ from a $d$-dimensional Gaussian $N(\\mu*, \\Sigma)$ with unknown $\\mu*$ and\nknown $\\Sigma$, and then applying the missingness model $S$ where $S(y) = {i in\n[d] : v_i^T y <= b_i}$ for some $v_1, ..., v_d$ in $R^d$ and $b_1, ..., b_d$ in\n$R$. We design an efficient mean estimation algorithm, assuming that none of\nthe possible missingness patterns is very rare conditioned on the values of the\nobserved coordinates and that any small subset of coordinates is observed with\nsufficiently high probability.", "published": "2025-04-28 03:22:01", "link": "http://arxiv.org/abs/2504.19446v1", "categories": ["cs.LG", "cs.CC", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Graph-based Semi-supervised and Unsupervised Methods for Local Clustering", "abstract": "Local clustering aims to identify specific substructures within a large graph\nwithout requiring full knowledge of the entire graph. These substructures are\ntypically small compared to the overall graph, enabling the problem to be\napproached by finding a sparse solution to a linear system associated with the\ngraph Laplacian. In this work, we first propose a method for identifying\nspecific local clusters when very few labeled data is given, which we term\nsemi-supervised local clustering. We then extend this approach to the\nunsupervised setting when no prior information on labels is available. The\nproposed methods involve randomly sampling the graph, applying diffusion\nthrough local cluster extraction, then examining the overlap among the results\nto find each cluster. We establish the co-membership conditions for any pair of\nnodes and rigorously prove the correctness of our methods. Additionally, we\nconduct extensive experiments to demonstrate that the proposed methods achieve\nstate-of-the-arts results in the low-label rates regime.", "published": "2025-04-28 02:10:18", "link": "http://arxiv.org/abs/2504.19419v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Observational Learning with a Budget", "abstract": "We consider a model of Bayesian observational learning in which a sequence of\nagents receives a private signal about an underlying binary state of the world.\nEach agent makes a decision based on its own signal and its observations of\nprevious agents. A central planner seeks to improve the accuracy of these\nsignals by allocating a limited budget to enhance signal quality across agents.\nWe formulate and analyze the budget allocation problem and propose two optimal\nallocation strategies. At least one of these strategies is shown to maximize\nthe probability of achieving a correct information cascade.", "published": "2025-04-28 00:12:30", "link": "http://arxiv.org/abs/2504.19396v1", "categories": ["cs.LG", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Evolution of Cooperation in LLM-Agent Societies: A Preliminary Study Using Different Punishment Strategies", "abstract": "The evolution of cooperation has been extensively studied using abstract\nmathematical models and simulations. Recent advances in Large Language Models\n(LLM) and the rise of LLM agents have demonstrated their ability to perform\nsocial reasoning, thus providing an opportunity to test the emergence of norms\nin more realistic agent-based simulations with human-like reasoning using\nnatural language. In this research, we investigate whether the cooperation\ndynamics presented in Boyd and Richerson's model persist in a more realistic\nsimulation of the diner's dilemma using LLM agents compared to the abstract\nmathematical nature in the work of Boyd and Richerson. Our findings indicate\nthat agents follow the strategies defined in the Boyd and Richerson model, and\nexplicit punishment mechanisms drive norm emergence, reinforcing cooperative\nbehaviour even when the agent strategy configuration varies. Our results\nsuggest that LLM-based Multi-Agent System simulations, in fact, can replicate\nthe evolution of cooperation predicted by the traditional mathematical models.\nMoreover, our simulations extend beyond the mathematical models by integrating\nnatural language-driven reasoning and a pairwise imitation method for strategy\nadoption, making them a more realistic testbed for cooperative behaviour in\nMASs.", "published": "2025-04-28 05:07:55", "link": "http://arxiv.org/abs/2504.19487v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Symmetric Policy Design for Multi-Agent Dispatch Coordination in Supply Chains", "abstract": "We study a decentralized dispatch coordination problem in a multi-agent\nsupply chain setting with shared logistics capacity. We propose symmetric\n(identical) dispatch strategies for all agents, enabling efficient coordination\nwithout centralized control. Using a common information approach, we derive a\ndynamic programming solution that computes optimal symmetric dispatch\nstrategies by transforming the multi-agent problem into a tractable dynamic\nprogram on the agents common information state. Simulation results demonstrate\nthat our method significantly reduces coordination cost compared to baseline\nheuristics, including belief-based strategies and an always-dispatch policy.\nThese findings highlight the benefits of combining symmetric strategy design\nwith a common information-based dynamic programming framework for improving\nmulti-agent coordination performance.", "published": "2025-04-28 00:31:33", "link": "http://arxiv.org/abs/2504.19397v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Analytical solutions for the Extracellular-Membrane-Intracellular model", "abstract": "The Extracellular-Membrane-Intracellular (EMI) model is a novel mathematical\nframework for cardiac electrophysiology simulations. The EMI model provides a\nmore detailed description of the heart's electrical activity compared to\ntraditional monodomain and bidomain models, potentially making it better-suited\nfor understanding the electrical dynamics of the heart under pathological\nconditions. In this paper, we derive and verify several analytical solutions\nfor the EMI model. Specifically, we obtain a family of solutions for a single\ntwo-dimensional cell in polar coordinates and for a pair of coupled\nthree-dimensional cells in spherical coordinates. We also introduce a\nmanufactured solution for N three-dimensional cells in Cartesian coordinates.\nTo verify the analytical solutions, we conduct numerical experiments using the\nmortar finite element method combined with operator splitting. The results\ndemonstrate that the analytical solutions are effective for verifying the\naccuracy of numerical simulations of the EMI model.", "published": "2025-04-28 16:33:20", "link": "http://arxiv.org/abs/2504.19960v1", "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "math.NA"}
{"title": "Unravelling mean-field Lindblad equation", "abstract": "We propose a mean-field particle Monte Carlo method for simulating the N-body\nLindblad equation. We provide a convergence result showing that a system of\ninteracting particles converges to the corresponding nonlinear Lindblad\nequation in the large N limit.", "published": "2025-04-28 16:01:49", "link": "http://arxiv.org/abs/2504.19928v1", "categories": ["quant-ph", "cs.NA", "math.NA", "math.PR"], "primary_category": "quant-ph"}
{"title": "Some PDE results in Heston model with applications", "abstract": "We present here some results for the PDE related to the logHeston model. We\npresent different regularity results and prove a verification theorem that\nshows that the solution produced via the Feynman-Kac theorem is the unique\nviscosity solution for a wide choice of initial data (even discontinuous) and\nsource data. In addition, our techniques do not use Feller's condition at any\ntime. In the end, we prove a convergence theorem to approximate this solution\nby means of a hybrid (finite differences/tree scheme) approach.", "published": "2025-04-28 14:50:06", "link": "http://arxiv.org/abs/2504.19859v1", "categories": ["math.AP", "cs.NA", "math.NA", "q-fin.CP", "35K65, 60H35, 65C30"], "primary_category": "math.AP"}
{"title": "Hyper-differential sensitivity analysis with respect to model discrepancy: Prior Distributions", "abstract": "Hyper-differential sensitivity analysis with respect to model discrepancy was\nrecently developed to enable uncertainty quantification for optimization\nproblems. The approach consists of two primary steps: (i) Bayesian calibration\nof the discrepancy between high- and low-fidelity models, and (ii) propagating\nthe model discrepancy uncertainty through the optimization problem. When\nhigh-fidelity model evaluations are limited, as is common in practice, the\nprior discrepancy distribution plays a crucial role in the uncertainty\nanalysis. However, specification of this prior is challenging due to its\nmathematical complexity and many hyper-parameters. This article presents a\nnovel approach to specify the prior distribution. Our approach consists of two\nparts: (1) an algorithmic initialization of the prior hyper-parameters that\nuses existing data to initialize a hyper-parameter estimate, and (2) a\nvisualization framework to systematically explore properties of the prior and\nguide tuning of the hyper-parameters to ensure that the prior captures the\nappropriate range of uncertainty. We provide detailed mathematical analysis and\na collection of numerical examples that elucidate properties of the prior that\nare crucial to ensure uncertainty quantification.", "published": "2025-04-28 14:09:37", "link": "http://arxiv.org/abs/2504.19812v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Resonances and computations", "abstract": "The computation of time dynamics arising in nonlinear time-dependent partial\ndifferential equations is an ongoing challenge in numerical analysis,\nespecially once roughness comes into play. Classical numerical schemes in\ngeneral fail to resolve the oscillatory behaviour in the solution which leads\nto numerical instabilities and loss of convergence. Dispersive equations, e.g.,\nnonlinear Schr\\\"odinger, Korteweg--de Vries and wave equations, thereby pose in\nparticular a big problem as in contrast to the parabolic setting, no strong\nsmoothing can be expected, i.e., if the initial data is rough, the solution\nstays rough which makes their approximation a delicate task. In this review we\ngive an overview on a new numerical ansatz which aims to tackle the time\ndynamics of nonlinear dispersive partial differential equations even for very\nrough data. This is achieved by a resonance analysis and decorated tree\nformalism that draws its inpiration from the combinatorics used in the theory\nof regularity structures for solving singular SPDEs. One can hope to see this\nformalism applied in other contexts for dispersive PDEs and beyond.", "published": "2025-04-28 10:04:48", "link": "http://arxiv.org/abs/2504.19647v1", "categories": ["math.NA", "cs.NA", "math.AP", "math.RA"], "primary_category": "math.NA"}
{"title": "Topological derivative for a fast identification of short, linear perfectly conducting cracks with inaccurate background information", "abstract": "In this study, we consider a topological derivative-based imaging technique\nfor the fast identification of short, linear perfectly conducting cracks\ncompletely embedded in a two-dimensional homogeneous domain with smooth\nboundary. Unlike conventional approaches, we assume that the background\npermittivity and permeability are unknown due to their dependence on frequency\nand temperature, and we propose a normalized imaging function to localize\ncracks. Despite inaccuracies in background parameters, application of the\nproposed imaging function enables to recognize the existence of crack but it is\nstill impossible to identify accurate crack locations. Furthermore, the shift\nin crack localization of imaging results is significantly influenced by the\napplied background parameters. In order to theoretically explain this\nphenomenon, we show that the imaging function can be expressed in terms of the\nzero-order Bessel function of the first kind, the crack lengths, and the\napplied inaccurate background wavenumber corresponding to the applied\ninaccurate background permittivity and permeability. Various numerical\nsimulations results with synthetic data polluted by random noise validate the\ntheoretical results.", "published": "2025-04-28 05:01:12", "link": "http://arxiv.org/abs/2504.19485v1", "categories": ["math.NA", "cs.NA", "78A46"], "primary_category": "math.NA"}
{"title": "Preasymptotic error estimates of higher-order EEM for the time-harmonic Maxwell equations with large wave number", "abstract": "The time-harmonic Maxwell equations with impedance boundary condition and\nlarge wave number are discretized using the second-type N\\'{e}d\\'{e}lec's edge\nelement method (EEM). Preasymptotic error bounds are derived, showing that,\nunder the mesh condition $\\kappa^{2p+1}h^{2p}$ being sufficiently small, the\nerror of the EEM of order $p$ in the energy norm is bounded by\n$\\mathcal{O}\\big(\\kappa^{p}h^p + \\kappa^{2p+1}h^{2p}\\big)$, while the error in\nthe $\\kappa$-scaled $\\boldsymbol{L}^2$ norm is bounded by\n$\\mathcal{O}\\big((\\kappa h)^{p+1} + \\kappa^{2p+1} h^{2p}\\big)$. Here, $\\kappa$\nis the wave number and $h$ is the mesh size. Numerical tests are provided to\nillustrate our theoretical results.", "published": "2025-04-28 04:48:44", "link": "http://arxiv.org/abs/2504.19481v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Quantitative estimates for a nonlinear inverse source problem in a coupled diffusion equations with uncertain measurements", "abstract": "This work considers a nonlinear inverse source problem in a coupled diffusion\nequation from the terminal observation. Theoretically, under some conditions on\nproblem data, we build the uniqueness theorem for this inverse problem and show\ntwo Lipschitz-type stability results in $L^2$ and $(H^1(\\cdot))^*$ norms,\nrespectively. However, in practice, we could only observe the measurements at\ndiscrete sensors, which contain the noise. Hence, this work further\ninvestigates the recovery of the unknown source from the discrete noisy\nmeasurements. We propose a stable inversion scheme and provide probabilistic\nconvergence estimates between the reconstructions and exact solution in two\ncases: convergence respect to expectation and convergence with an exponential\ntail. We provide several numerical experiments to illustrate and complement our\ntheoretical analysis.", "published": "2025-04-28 02:13:06", "link": "http://arxiv.org/abs/2504.19421v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fast convolution solver based on far-field smooth approximation", "abstract": "The convolution potential arises in a wide variety of application areas, and\nits efficient and accurate evaluation encounters three challenges: singularity,\nnonlocality and anisotropy. We introduce a fast algorithm based on a far-field\nsmooth approximation of the kernel, where the bounded domain Fourier transform,\none of the most essential difficulties, is well approximated by the whole space\nFourier transform which usually admits explicit formula. The convolution is\nsplit into a regular and singular integral, and they are well resolved by\ntrapezoidal rule and Fourier spectral method respectively. The scheme is\nsimplified to a discrete convolution and is implemented efficiently with Fast\nFourier Transform (FFT). Importantly, the tensor generation procedure is quite\nsimple, highly efficient and independent of the anisotropy strength. It is easy\nto implement and achieves spectral accuracy with nearly optimal efficiency and\nminimum memory requirement. Rigorous error estimates and extensive numerical\ninvestigations, together with a comprehensive comparison, showcase its\nsuperiorities for different kernels.", "published": "2025-04-28 01:38:13", "link": "http://arxiv.org/abs/2504.19410v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Deep Declarative Risk Budgeting Portfolios", "abstract": "Recent advances in deep learning have spurred the development of end-to-end\nframeworks for portfolio optimization that utilize implicit layers. However,\nmany such implementations are highly sensitive to neural network\ninitialization, undermining performance consistency. This research introduces a\nrobust end-to-end framework tailored for risk budgeting portfolios that\neffectively reduces sensitivity to initialization. Importantly, this enhanced\nstability does not compromise portfolio performance, as our framework\nconsistently outperforms the risk parity benchmark.", "published": "2025-04-28 16:53:13", "link": "http://arxiv.org/abs/2504.19980v1", "categories": ["q-fin.PM", "q-fin.CP"], "primary_category": "q-fin.PM"}
{"title": "A high-order recombination algorithm for weak approximation of stochastic differential equations", "abstract": "The authors present an algorithm for the application of the high-order\nrecombination method first introduced by Terry Lyons and Christian Litterer in\n``high-order recombination and an application to cubature on Wiener space''\n(Ann. Appl. Probab 22(4):1301-1327, 2012), to real-world problems in\nmathematical finance. They also give numerical examples showing that the\nalgorithm presented successfully avoids the explosive increase in the number of\nsupport of the measure that achieves high-order approximations.", "published": "2025-04-28 12:12:40", "link": "http://arxiv.org/abs/2504.19717v1", "categories": ["math.PR", "q-fin.CP", "91G60, 60H35, 65C20, 65C30, 65C05, 68U20, 62P05"], "primary_category": "math.PR"}
{"title": "Multi-Horizon Echo State Network Prediction of Intraday Stock Returns", "abstract": "Stock return prediction is a problem that has received much attention in the\nfinance literature. In recent years, sophisticated machine learning methods\nhave been shown to perform significantly better than ''classical'' prediction\ntechniques. One downside of these approaches is that they are often very\nexpensive to implement, for both training and inference, because of their high\ncomplexity. We propose a return prediction framework for intraday returns at\nmultiple horizons based on Echo State Network (ESN) models, wherein a large\nportion of parameters are drawn at random and never trained. We show that this\napproach enjoys the benefits of recurrent neural network expressivity,\ninherently efficient implementation, and strong forecasting performance.", "published": "2025-04-28 09:32:10", "link": "http://arxiv.org/abs/2504.19623v1", "categories": ["q-fin.CP", "q-fin.ST"], "primary_category": "q-fin.CP"}
{"title": "Simulating integrated Volterra square-root processes and Volterra Heston models via Inverse Gaussian", "abstract": "We introduce a novel simulation scheme, iVi (integrated Volterra implicit),\nfor integrated Volterra square-root processes and Volterra Heston models based\non the Inverse Gaussian distribution. The scheme is designed to handle $L^1$\nkernels with singularities by relying solely on integrated kernel quantities,\nand it preserves the non-decreasing property of the integrated process. We\nestablish weak convergence of the iVi scheme by reformulating it as a\nstochastic Volterra equation with a measure kernel and proving a stability\nresult for this class of equations. Numerical results demonstrate that\nconvergence is achieved with very few time steps. Remarkably, for the rough\nfractional kernel, unlike existing schemes, convergence seems to improve as the\nHurst index $H$ decreases and approaches $-1/2$.", "published": "2025-04-28 15:17:37", "link": "http://arxiv.org/abs/2504.19885v1", "categories": ["q-fin.MF", "math.PR"], "primary_category": "q-fin.MF"}
{"title": "A Comparative Study on Positional Encoding for Time-frequency Domain Dual-path Transformer-based Source Separation Models", "abstract": "In this study, we investigate the impact of positional encoding (PE) on\nsource separation performance and the generalization ability to long sequences\n(length extrapolation) in Transformer-based time-frequency (TF) domain\ndual-path models. The length extrapolation capability in TF-domain dual-path\nmodels is a crucial factor, as it affects not only their performance on\nlong-duration inputs but also their generalizability to signals with unseen\nsampling rates. While PE is known to significantly impact length extrapolation,\nthere has been limited research that explores the choice of PEs for TF-domain\ndual-path models from this perspective. To address this gap, we compare various\nPE methods using a recent state-of-the-art model, TF-Locoformer, as the base\narchitecture. Our analysis yields the following key findings: (i) When handling\nsequences that are the same length as or shorter than those seen during\ntraining, models with PEs achieve better performance. (ii) However, models\nwithout PE exhibit superior length extrapolation. This trend is particularly\npronounced when the model contains convolutional layers.", "published": "2025-04-28 09:08:37", "link": "http://arxiv.org/abs/2504.19605v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Ku-Band AlScn-On-Diamond SAW Resonators with Phase Velocity above 8600 m/s", "abstract": "In this work, an Aluminum Scandium Nitride (AlScN) on Diamond Sezawa-mode\nsurface acoustic wave (SAW) platform for RF filtering at Ku-band (12-18 GHz) is\ndemonstrated. Thanks to the high acoustic velocity and low-loss diamond\nsubstrate, the prototype resonator at 12.9 GHz achieves a high phase velocity\n($v_p$) of 8671 m/s, a maximum Bode-$Q$ of 408, and coupling coefficient\n($k_{\\mathrm{eff}}^2$) of 2.1%, outperforming high-velocity substrates such as\nSiC and sapphire by more than 20% in velocity. Resonators spanning 8-18 GHz are\npresented. The platform's high power handling above 12.5 dBm is also\nexperimentally validated.", "published": "2025-04-28 16:08:55", "link": "http://arxiv.org/abs/2504.19936v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Reinforcement Learning-Based Heterogeneous Multi-Task Optimization in Semantic Broadcast Communications", "abstract": "Semantic broadcast communications (Semantic BC) for image transmission have\nachieved significant performance gains for single-task scenarios. Nevertheless,\nextending these methods to multi-task scenarios remains challenging, as\ndifferent tasks typically require distinct objective functions, leading to\npotential conflicts within the shared encoder. In this paper, we propose a\ntri-level reinforcement learning (RL)-based multi-task Semantic BC framework,\ntermed SemanticBC-TriRL, which effectively resolves such conflicts and enables\nthe simultaneous support of multiple downstream tasks at the receiver side,\nincluding image classification and content reconstruction tasks. Specifically,\nthe proposed framework employs a bottom-up tri-level alternating learning\nstrategy, formulated as a constrained multi-objective optimization problem. At\nthe first level, task-specific decoders are locally optimized using supervised\nlearning. At the second level, the shared encoder is updated via proximal\npolicy optimization (PPO), guided by task-oriented rewards. At the third level,\na multi-gradient aggregation-based task weighting module adaptively adjusts\ntask priorities and steers the encoder optimization. Through this hierarchical\nlearning process, the encoder and decoders are alternately trained, and the\nthree levels are cohesively integrated via constrained learning objective.\nBesides, the convergence of SemanticBC-TriRL is also theoretically established.\nExtensive simulation results demonstrate the superior performance of the\nproposed framework across diverse channel conditions, particularly in low SNR\nregimes, and confirm its scalability with increasing numbers of receivers.", "published": "2025-04-28 13:59:01", "link": "http://arxiv.org/abs/2504.19806v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Low-Complexity Channel Estimation Protocol for Non-Diagonal RIS-Assisted Communications", "abstract": "Non-diagonal reconfigurable intelligent surfaces (RIS) offer enhanced\nwireless signal manipulation over conventional RIS by enabling the incident\nsignal on any of its $M$ elements to be reflected from another element via an\n$M \\times M$ switch array. To fully exploit this flexible configuration, the\nacquisition of individual channel state information (CSI) is essential.\nHowever, due to the passive nature of the RIS, cascaded channel estimation is\nperformed, as the RIS itself lacks signal processing capabilities. This entails\nestimating the CSI for all $M \\times M$ switch array permutations, resulting in\na total of $M!$ possible configurations, to identify the optimal one that\nmaximizes the channel gain. This process leads to long uplink training\nintervals, which degrade spectral efficiency and increase uplink energy\nconsumption. In this paper, we propose a low-complexity channel estimation\nprotocol that substantially reduces the need for exhaustive $M!$ permutations\nby utilizing only three configurations to optimize the non-diagonal RIS switch\narray and beamforming for single-input single-output (SISO) and multiple-input\nsingle-output (MISO) systems. Specifically, our three-stage pilot-based\nprotocol estimates scaled versions of the user-RIS and RIS-base-station (BS)\nchannels in the first two stages using the least square (LS) estimator and the\ncommonly used ON/OFF protocol from conventional RIS. In the third stage, the\ncascaded user-RIS-BS channels are estimated to enable efficient beamforming\noptimization. Complexity analysis shows that our proposed protocol\nsignificantly reduces the BS computational load from $\\mathcal{O}(NM\\times M!)$\nto $\\mathcal{O}(NM)$, where $N$ is the number of BS antennas. This complexity\nis similar to the conventional ON/OFF-based LS estimation for conventional\ndiagonal RIS.", "published": "2025-04-28 13:34:21", "link": "http://arxiv.org/abs/2504.19791v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Polarized pulse pair observations during a long duration interstellar communication experiment", "abstract": "In prior work, conducted since 2017, two celestial pointing directions have\nbeen observed to be associated with the measurement of anomalous high counts of\nnarrow bandwidth, short duration, polarized radio frequency pulse pairs. The\nprior experimental work utilized up to three geographically-spaced synchronized\nradio telescopes, a single-dish radio telescope, and a radio interferometer.\nThe experimental work reported here examines full right ascension coverage at\none declination, utilizing the interferometer, during 124.1 days. Results\nsuggest the possible presence of an additional anomalous celestial pointing\ndirection. Seven standard deviations of noise-modeled shifts of mean polarized\npulse pair count were observed in three celestial directions. Indications of\ninterferometer space delay aliasing were observed. A phase noise test,\ncelestial source identification methods and associated measurements were used\nto seek potential explanations of the unusual observed phenomena.", "published": "2025-04-28 13:03:59", "link": "http://arxiv.org/abs/2504.19765v1", "categories": ["eess.SP", "astro-ph.IM"], "primary_category": "eess.SP"}
{"title": "Sum-Rate Optimisation of a Multi-User STAR-RIS-Aided System with Low Complexity", "abstract": "Reconfigurable intelligent surface (RIS) is a promising technology for future\nwireless communication systems. However, the conventional RIS can only reflect\nthe incident signal. Hence, it provides a limited coverage, as compared to a\nsimultaneously transmitting and reflecting RIS (STAR-RIS). Prior works on the\nSTAR-RIS address the power minimisation or the sum-rate maximisation problem by\nreformulating the objective problem as a convex optimisation problem and then\nemploying numerical tools like CVX to obtain the solution, which introduces\nsignificant computational complexity leading to a huge runtime, making the\nalgorithms impractical for real-world implementation. In this paper, we propose\na low complexity solution for the optimisation of a multi-user STAR-RIS system,\nwhere the non-convex optimisation problem is decomposed into multiple convex\nsub-problems with closed-form optimal solutions. The simulation results\nillustrate that our proposed algorithm achieves similar performance to\nCVX-based solutions in the literature while being computationally efficient.", "published": "2025-04-28 12:15:58", "link": "http://arxiv.org/abs/2504.19723v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Decentralization of Generative AI via Mixture of Experts for Wireless Networks: A Comprehensive Survey", "abstract": "Mixture of Experts (MoE) has emerged as a promising paradigm for scaling\nmodel capacity while preserving computational efficiency, particularly in\nlarge-scale machine learning architectures such as large language models\n(LLMs). Recent advances in MoE have facilitated its adoption in wireless\nnetworks to address the increasing complexity and heterogeneity of modern\ncommunication systems. This paper presents a comprehensive survey of the MoE\nframework in wireless networks, highlighting its potential in optimizing\nresource efficiency, improving scalability, and enhancing adaptability across\ndiverse network tasks. We first introduce the fundamental concepts of MoE,\nincluding various gating mechanisms and the integration with generative AI\n(GenAI) and reinforcement learning (RL). Subsequently, we discuss the extensive\napplications of MoE across critical wireless communication scenarios, such as\nvehicular networks, unmanned aerial vehicles (UAVs), satellite communications,\nheterogeneous networks, integrated sensing and communication (ISAC), and mobile\nedge networks. Furthermore, key applications in channel prediction, physical\nlayer signal processing, radio resource management, network optimization, and\nsecurity are thoroughly examined. Additionally, we present a detailed overview\nof open-source datasets that are widely used in MoE-based models to support\ndiverse machine learning tasks. Finally, this survey identifies crucial future\nresearch directions for MoE, emphasizing the importance of advanced training\ntechniques, resource-aware gating strategies, and deeper integration with\nemerging 6G technologies.", "published": "2025-04-28 10:20:04", "link": "http://arxiv.org/abs/2504.19660v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Semantic Packet Aggregation for Token Communication via Genetic Beam Search", "abstract": "Token communication (TC) is poised to play a pivotal role in emerging\nlanguage-driven applications such as AI-generated content (AIGC) and wireless\nlanguage models (LLMs). However, token loss caused by channel noise can\nseverely degrade task performance. To address this, in this article, we focus\non the problem of semantics-aware packetization and develop a novel algorithm,\ntermed semantic packet aggregation with genetic beam search (SemPA-GBeam),\nwhich aims to maximize the average token similarity (ATS) over erasure\nchannels. Inspired from the genetic algorithm (GA) and the beam search\nalgorithm, SemPA-GBeam iteratively optimizes token grouping for packetization\nwithin a fixed number of groups (i.e., fixed beam width in beam search) while\nrandomly swapping a fraction of tokens (i.e., mutation in GA). Experiments on\nthe MS-COCO dataset demonstrate that SemPA-GBeam achieves ATS and LPIPS scores\ncomparable to exhaustive search while reducing complexity by more than 20x.", "published": "2025-04-28 08:53:39", "link": "http://arxiv.org/abs/2504.19591v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physical-Layer Security in Mixed Near-Field and Far-Field Communication Systems", "abstract": "Extremely large-scale arrays (XL-arrays) have emerged as a promising\ntechnology to improve the spectrum efficiency and spatial resolution of future\nwireless systems. Different from existing works that mostly considered physical\nlayer security (PLS) in either the far-field or near-field, we consider in this\npaper a new and practical scenario, where legitimate users (Bobs) are located\nin the far-field of a base station (BS) while eavesdroppers (Eves) are located\nin the near-field for intercepting confidential information at short distance,\nreferred to as the mixed near-field and far-field PLS. Specifically, we\nformulate an optimization problem to maximize the sum-secrecy-rate of all Bobs\nby optimizing the power allocation of the BS, subject to the constraint on the\ntotal BS transmit power. To shed useful insights, we first consider a\none-Bob-one-Eve system and characterize the insecure-transmission region of the\nBob in closed form. Interestingly, we show that the insecure-transmission\nregion is significantly \\emph{expanded} as compared to that in conventional\nfar-field PLS systems, due to the energy-spread effect in the mixed-field\nscenario. Then, we further extend the analysis to a two-Bob-one-Eve system. It\nis revealed that as compared to the one-Bob system, the interferences from the\nother Bob can be effectively used to weaken the capability of Eve for\nintercepting signals of target Bobs, thus leading to enhanced secrecy rates.\nFurthermore, we propose an efficient algorithm to obtain a high-quality\nsolution to the formulated non-convex problem by leveraging the successive\nconvex approximation (SCA) technique. Finally, numerical results demonstrate\nthat our proposed algorithm achieves a higher sum-secrecy-rate than the\nbenchmark scheme where the power allocation is designed based on the\n(simplified) far-field channel model.", "published": "2025-04-28 08:00:36", "link": "http://arxiv.org/abs/2504.19555v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Deployment Optimization for XL-IRS Assisted Multi-User Communications", "abstract": "In this paper, we study the deployment optimization for an extremely\nlarge-scale intelligent reflecting surface (XL-IRS) assisted multi-user\ncommunication system, within which the channels between the XL-IRS and the BS\n(or user) are modeled by the near-field spherical wavefronts. To draw some\nvaluable insights, we first consider the single-user case, where an alternating\noptimization (AO) based algorithm is devised to maximize the received\nsignal-to-noise ratio (SNR) at the user. To address the high computational\ncomplexity issue incurred by the AO based algorithm, three approximate received\nSNR expressions are obtained to yield useful insights, corresponding to the\nupper bound, approximate expression, and closed-form. It is demonstrated that\nthe XL-IRS ought to be positioned near the user (rather than the BS) to obtain\na higher beamforming gain. Then, for the multi-user scenario, an efficient\nalgorithm is proposed to obtain a high-quality XL-IRS placement solution by\nusing the AO and successive convex approximation (SCA) techniques. Furthermore,\nthe effective degree of freedom (DoF) of the BS-IRS channel is provided, which\nindicates that the additional effective DoF can be leveraged to improve\nmulti-user spatial multiplexing. Last, numerical results confirm the existence\nof a trade-off between near-field beam-focusing gain and multiplexing gain.", "published": "2025-04-28 07:57:14", "link": "http://arxiv.org/abs/2504.19550v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Model-based DNN for Learning HMIMO Beamforming", "abstract": "Holographic MIMO (HMIMO) is a promising technique for large-scale MIMO\nsystems to enhance spectral efficiency while maintaining low hardware cost and\npower consumption. Existing alternating optimization algorithms can effectively\noptimize the hybrid beamforming of HMIMO to improve the system performance,\nwhile their high computational complexity hinders real-time application. In\nthis paper, we propose a model-based deep neural network (MB-DNN), which\nleverages permutation equivalent properties and the optimal beamforming\nstructure to jointly optimize the holographic and digital beamforming.\nSimulation results demonstrate that the proposed MB-DNN outperforms benchmark\nschemes and requires much less inference time than existing alternating\noptimization algorithms.", "published": "2025-04-28 06:40:41", "link": "http://arxiv.org/abs/2504.19522v1", "categories": ["eess.SP", "68T07, 90B18, 94A05"], "primary_category": "eess.SP"}
{"title": "Novel Selection Schemes for Multi-RIS-Assisted Fluid Antenna Systems", "abstract": "This paper investigates the performance of a multi-reconfigurable intelligent\nsurface (RIS)-assisted fluid antenna system (FAS). In this system, a\nsingle-antenna transmitter communicates with a receiver equipped with a planar\nFAS through multiple RISs in the absence of a direct link. To enhance the\nsystem performance, we propose two novel selection schemes: \\textit{Max-Max}\nand \\textit{Max-Sum}. In particular, the \\textit{Max-Max} scheme selects the\nbest combination of a single RIS and a single fluid antenna (FA) port that\noffers the maximum signal-to-noise ratio (SNR) at the receiver. On the other\nhand, the \\textit{Max-Sum} scheme selects one RIS while activating all FA ports\nproviding the highest overall SNR. We conduct a detailed performance analysis\nof the proposed system under Nakagami-$m$ fading channels. First, we derive the\ncumulative distribution function (CDF) of the SNR for both selection schemes.\nThe derived CDF is then used to obtain approximate theoretical expressions for\nthe outage probability (OP) and the delay outage rate (DOR). Next, a high-SNR\nasymptotic analysis is carried out to provide further insights into the system\nperformance in terms of diversity and coding gains. Finally, the analytical\nresults are validated through extensive Monte Carlo simulations, demonstrating\ntheir accuracy and providing a comprehensive understanding of the system's\nperformance.", "published": "2025-04-28 06:19:39", "link": "http://arxiv.org/abs/2504.19511v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Constrained Parameter Update Law for Adaptive Control", "abstract": "In this paper, a constrained parameter update law is derived in the context\nof adaptive control. The parameter update law is based on constrained\noptimization technique where a Lagrangian is formulated to incorporate the\nconstraints on the parameters using inverse Barrier function. The constrained\nparameter update law is used to develop a adaptive tracking controller and the\noverall stability of the adaptive controller along with the constrained\nparameter update law is shown using Lyapunov analysis and development in\nstability of constrained primal-dual dynamics. The performance of the\nconstrained parameter update law is tested in simulation for keeping the\nparameters within constraints and convergence to true parameters.", "published": "2025-04-28 01:42:57", "link": "http://arxiv.org/abs/2504.19412v1", "categories": ["math.OC", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "math.OC"}
{"title": "LLM-Generated Fake News Induces Truth Decay in News Ecosystem: A Case Study on Neural News Recommendation", "abstract": "Online fake news moderation now faces a new challenge brought by the\nmalicious use of large language models (LLMs) in fake news production. Though\nexisting works have shown LLM-generated fake news is hard to detect from an\nindividual aspect, it remains underexplored how its large-scale release will\nimpact the news ecosystem. In this study, we develop a simulation pipeline and\na dataset with ~56k generated news of diverse types to investigate the effects\nof LLM-generated fake news within neural news recommendation systems. Our\nfindings expose a truth decay phenomenon, where real news is gradually losing\nits advantageous position in news ranking against fake news as LLM-generated\nnews is involved in news recommendation. We further provide an explanation\nabout why truth decay occurs from a familiarity perspective and show the\npositive correlation between perplexity and news ranking. Finally, we discuss\nthe threats of LLM-generated fake news and provide possible countermeasures. We\nurge stakeholders to address this emerging challenge to preserve the integrity\nof news ecosystems.", "published": "2025-04-28 17:32:38", "link": "http://arxiv.org/abs/2504.20013v2", "categories": ["cs.CL", "cs.CY", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Mitigating Modality Bias in Multi-modal Entity Alignment from a Causal Perspective", "abstract": "Multi-Modal Entity Alignment (MMEA) aims to retrieve equivalent entities from\ndifferent Multi-Modal Knowledge Graphs (MMKGs), a critical information\nretrieval task. Existing studies have explored various fusion paradigms and\nconsistency constraints to improve the alignment of equivalent entities, while\noverlooking that the visual modality may not always contribute positively.\nEmpirically, entities with low-similarity images usually generate\nunsatisfactory performance, highlighting the limitation of overly relying on\nvisual features. We believe the model can be biased toward the visual modality,\nleading to a shortcut image-matching task. To address this, we propose a\ncounterfactual debiasing framework for MMEA, termed CDMEA, which investigates\nvisual modality bias from a causal perspective. Our approach aims to leverage\nboth visual and graph modalities to enhance MMEA while suppressing the direct\ncausal effect of the visual modality on model predictions. By estimating the\nTotal Effect (TE) of both modalities and excluding the Natural Direct Effect\n(NDE) of the visual modality, we ensure that the model predicts based on the\nTotal Indirect Effect (TIE), effectively utilizing both modalities and reducing\nvisual modality bias. Extensive experiments on 9 benchmark datasets show that\nCDMEA outperforms 14 state-of-the-art methods, especially in low-similarity,\nhigh-noise, and low-resource data scenarios.", "published": "2025-04-28 03:48:23", "link": "http://arxiv.org/abs/2504.19458v2", "categories": ["cs.MM", "cs.CL", "cs.IR"], "primary_category": "cs.MM"}
{"title": "Context Selection and Rewriting for Video-based Educational Question Generation", "abstract": "Educational question generation (EQG) is a crucial component of intelligent\neducational systems, significantly aiding self-assessment, active learning, and\npersonalized education. While EQG systems have emerged, existing datasets\ntypically rely on predefined, carefully edited texts, failing to represent\nreal-world classroom content, including lecture speech with a set of\ncomplementary slides. To bridge this gap, we collect a dataset of educational\nquestions based on lectures from real-world classrooms. On this realistic\ndataset, we find that current methods for EQG struggle with accurately\ngenerating questions from educational videos, particularly in aligning with\nspecific timestamps and target answers. Common challenges include selecting\ninformative contexts from extensive transcripts and ensuring generated\nquestions meaningfully incorporate the target answer. To address the\nchallenges, we introduce a novel framework utilizing large language models for\ndynamically selecting and rewriting contexts based on target timestamps and\nanswers. First, our framework selects contexts from both lecture transcripts\nand video keyframes based on answer relevance and temporal proximity. Then, we\nintegrate the contexts selected from both modalities and rewrite them into\nanswer-containing knowledge statements, to enhance the logical connection\nbetween the contexts and the desired answer. This approach significantly\nimproves the quality and relevance of the generated questions. Our dataset and\ncode are released in https://github.com/mengxiayu/COSER.", "published": "2025-04-28 01:18:08", "link": "http://arxiv.org/abs/2504.19406v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WILD: a new in-the-Wild Image Linkage Dataset for synthetic image attribution", "abstract": "Synthetic image source attribution is an open challenge, with an increasing\nnumber of image generators being released yearly. The complexity and the sheer\nnumber of available generative techniques, as well as the scarcity of\nhigh-quality open source datasets of diverse nature for this task, make\ntraining and benchmarking synthetic image source attribution models very\nchallenging. WILD is a new in-the-Wild Image Linkage Dataset designed to\nprovide a powerful training and benchmarking tool for synthetic image\nattribution models. The dataset is built out of a closed set of 10 popular\ncommercial generators, which constitutes the training base of attribution\nmodels, and an open set of 10 additional generators, simulating a real-world\nin-the-wild scenario. Each generator is represented by 1,000 images, for a\ntotal of 10,000 images in the closed set and 10,000 images in the open set.\nHalf of the images are post-processed with a wide range of operators. WILD\nallows benchmarking attribution models in a wide range of tasks, including\nclosed and open set identification and verification, and robust attribution\nwith respect to post-processing and adversarial attacks. Models trained on WILD\nare expected to benefit from the challenging scenario represented by the\ndataset itself. Moreover, an assessment of seven baseline methodologies on\nclosed and open set attribution is presented, including robustness tests with\nrespect to post-processing.", "published": "2025-04-28 08:58:34", "link": "http://arxiv.org/abs/2504.19595v2", "categories": ["cs.MM", "cs.AI", "cs.CV"], "primary_category": "cs.MM"}
{"title": "How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation", "abstract": "Recently, numerous community search methods for large graphs have been\nproposed, at the core of which is defining and measuring cohesion. This paper\nexperimentally evaluates the effectiveness of these community search algorithms\nw.r.t. cohesiveness in the context of online social networks. Social\ncommunities are formed and developed under the influence of group cohesion\ntheory, which has been extensively studied in social psychology. However,\ncurrent generic methods typically measure cohesiveness using structural or\nattribute-based approaches and overlook domain-specific concepts such as group\ncohesion. We introduce five novel psychology-informed cohesiveness measures,\nbased on the concept of group cohesion from social psychology, and propose a\nnovel framework called CHASE for evaluating eight representative CS algorithms\nw.r.t. these measures on online social networks. Our analysis reveals that\nthere is no clear correlation between structural and psychological\ncohesiveness, and no algorithm effectively identifies psychologically cohesive\ncommunities in online social networks. This study provides new insights that\ncould guide the development of future community search methods.", "published": "2025-04-28 05:08:29", "link": "http://arxiv.org/abs/2504.19489v2", "categories": ["cs.IR", "cs.SI"], "primary_category": "cs.IR"}
{"title": "On Weight Enumeration and Structure Characterization of Polar Codes via Group Actions", "abstract": "In this article, we provide a complete characterization of codewords in polar\ncodes with weights less than twice the minimum distance, using the group action\nof the lower triangular affine (LTA) group. We derive a closed-form formula for\nthe enumeration of such codewords. Furthermore, we introduce an enhanced\npartial order based on weight contributions, offering refined tools for code\ndesign. Our results extend previous work on Type II codewords to a full\ndescription of Type I codewords and offer new insights into the algebraic\nstructure underlying decreasing monomial codes, including polar and Reed-Muller\ncodes.", "published": "2025-04-28 07:48:17", "link": "http://arxiv.org/abs/2504.19544v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Transfer Learning Under High-Dimensional Network Convolutional Regression Model", "abstract": "Transfer learning enhances model performance by utilizing knowledge from\nrelated domains, particularly when labeled data is scarce. While existing\nresearch addresses transfer learning under various distribution shifts in\nindependent settings, handling dependencies in networked data remains\nchallenging. To address this challenge, we propose a high-dimensional transfer\nlearning framework based on network convolutional regression (NCR), inspired by\nthe success of graph convolutional networks (GCNs). The NCR model incorporates\nrandom network structure by allowing each node's response to depend on its\nfeatures and the aggregated features of its neighbors, capturing local\ndependencies effectively. Our methodology includes a two-step transfer learning\nalgorithm that addresses domain shift between source and target networks, along\nwith a source detection mechanism to identify informative domains.\nTheoretically, we analyze the lasso estimator in the context of a random graph\nbased on the Erdos-Renyi model assumption, demonstrating that transfer learning\nimproves convergence rates when informative sources are present. Empirical\nevaluations, including simulations and a real-world application using Sina\nWeibo data, demonstrate substantial improvements in prediction accuracy,\nparticularly when labeled data in the target domain is limited.", "published": "2025-04-28 16:52:28", "link": "http://arxiv.org/abs/2504.19979v2", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "If Concept Bottlenecks are the Question, are Foundation Models the Answer?", "abstract": "Concept Bottleneck Models (CBMs) are neural networks designed to conjoin high\nperformance with ante-hoc interpretability. CBMs work by first mapping inputs\n(e.g., images) to high-level concepts (e.g., visible objects and their\nproperties) and then use these to solve a downstream task (e.g., tagging or\nscoring an image) in an interpretable manner. Their performance and\ninterpretability, however, hinge on the quality of the concepts they learn. The\ngo-to strategy for ensuring good quality concepts is to leverage expert\nannotations, which are expensive to collect and seldom available in\napplications. Researchers have recently addressed this issue by introducing\n\"VLM-CBM\" architectures that replace manual annotations with weak supervision\nfrom foundation models. It is however unclear what is the impact of doing so on\nthe quality of the learned concepts. To answer this question, we put\nstate-of-the-art VLM-CBMs to the test, analyzing their learned concepts\nempirically using a selection of significant metrics. Our results show that,\ndepending on the task, VLM supervision can sensibly differ from expert\nannotations, and that concept accuracy and quality are not strongly correlated.\nOur code is available at https://github.com/debryu/CQA.", "published": "2025-04-28 13:18:48", "link": "http://arxiv.org/abs/2504.19774v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Geometry-Informed Neural Operator Transformer", "abstract": "Machine-learning-based surrogate models offer significant computational\nefficiency and faster simulations compared to traditional numerical methods,\nespecially for problems requiring repeated evaluations of partial differential\nequations. This work introduces the Geometry-Informed Neural Operator\nTransformer (GINOT), which integrates the transformer architecture with the\nneural operator framework to enable forward predictions for arbitrary\ngeometries. GINOT encodes the surface points cloud of a geometry using a\nsampling and grouping mechanism combined with an attention mechanism, ensuring\ninvariance to point order and padding while maintaining robustness to\nvariations in point density. The geometry information is seamlessly integrated\nwith query points in the solution decoder through the attention mechanism. The\nperformance of GINOT is validated on multiple challenging datasets, showcasing\nits high accuracy and strong generalization capabilities for complex and\narbitrary 2D and 3D geometries.", "published": "2025-04-28 03:39:27", "link": "http://arxiv.org/abs/2504.19452v2", "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "Unravelling mean-field Lindblad equation", "abstract": "We propose a mean-field particle Monte Carlo method for simulating the N-body\nLindblad equation. We provide a convergence result showing that a system of\ninteracting particles converges to the corresponding nonlinear Lindblad\nequation in the large N limit.", "published": "2025-04-28 16:01:49", "link": "http://arxiv.org/abs/2504.19928v2", "categories": ["quant-ph", "cs.NA", "math.NA", "math.PR"], "primary_category": "quant-ph"}
{"title": "UD-English-CHILDES: A Collected Resource of Gold and Silver Universal Dependencies Trees for Child Language Interactions", "abstract": "CHILDES is a widely used resource of transcribed child and child-directed\nspeech. This paper introduces UD-English-CHILDES, the first officially released\nUniversal Dependencies (UD) treebank derived from previously\ndependency-annotated CHILDES data with consistent and unified annotation\nguidelines. Our corpus harmonizes annotations from 11 children and their\ncaregivers, totaling over 48k sentences. We validate existing gold-standard\nannotations under the UD v2 framework and provide an additional 1M\nsilver-standard sentences, offering a consistent resource for computational and\nlinguistic research.", "published": "2025-04-28 23:20:36", "link": "http://arxiv.org/abs/2504.20304v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "mrCAD: Multimodal Refinement of Computer-aided Designs", "abstract": "A key feature of human collaboration is the ability to iteratively refine the\nconcepts we have communicated. In contrast, while generative AI excels at the\n\\textit{generation} of content, it often struggles to make specific\nlanguage-guided \\textit{modifications} of its prior outputs. To bridge the gap\nbetween how humans and machines perform edits, we present mrCAD, a dataset of\nmultimodal instructions in a communication game. In each game, players created\ncomputer aided designs (CADs) and refined them over several rounds to match\nspecific target designs. Only one player, the Designer, could see the target,\nand they must instruct the other player, the Maker, using text, drawing, or a\ncombination of modalities. mrCAD consists of 6,082 communication games, 15,163\ninstruction-execution rounds, played between 1,092 pairs of human players. We\nanalyze the dataset and find that generation and refinement instructions differ\nin their composition of drawing and text. Using the mrCAD task as a benchmark,\nwe find that state-of-the-art VLMs are better at following generation\ninstructions than refinement instructions. These results lay a foundation for\nanalyzing and modeling a multimodal language of refinement that is not\nrepresented in previous datasets.", "published": "2025-04-28 22:32:57", "link": "http://arxiv.org/abs/2504.20294v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Enhancing Systematic Reviews with Large Language Models: Using GPT-4 and Kimi", "abstract": "This research delved into GPT-4 and Kimi, two Large Language Models (LLMs),\nfor systematic reviews. We evaluated their performance by comparing\nLLM-generated codes with human-generated codes from a peer-reviewed systematic\nreview on assessment. Our findings suggested that the performance of LLMs\nfluctuates by data volume and question complexity for systematic reviews.", "published": "2025-04-28 21:44:08", "link": "http://arxiv.org/abs/2504.20276v1", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "A Platform for Generating Educational Activities to Teach English as a Second Language", "abstract": "We present a platform for the generation of educational activities oriented\nto teaching English as a foreign language. The different activities -- games\nand language practice exercises -- are strongly based on Natural Language\nProcessing techniques. The platform offers the possibility of playing\nout-of-the-box games, generated from resources created semi-automatically and\nthen manually curated. It can also generate games or exercises of greater\ncomplexity from texts entered by teachers, providing a stage of review and\nedition of the generated content before use. As a way of expanding the variety\nof activities in the platform, we are currently experimenting with image and\ntext generation. In order to integrate them and improve the performance of\nother neural tools already integrated, we are working on migrating the platform\nto a more powerful server. In this paper we describe the development of our\nplatform and its deployment for end users, discussing the challenges faced and\nhow we overcame them, and also detail our future work plans.", "published": "2025-04-28 20:43:40", "link": "http://arxiv.org/abs/2504.20251v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Multimodal Pipeline for Clinical Data Extraction: Applying Vision-Language Models to Scans of Transfusion Reaction Reports", "abstract": "Despite the growing adoption of electronic health records, many processes\nstill rely on paper documents, reflecting the heterogeneous real-world\nconditions in which healthcare is delivered. The manual transcription process\nis time-consuming and prone to errors when transferring paper-based data to\ndigital formats. To streamline this workflow, this study presents an\nopen-source pipeline that extracts and categorizes checkbox data from scanned\ndocuments. Demonstrated on transfusion reaction reports, the design supports\nadaptation to other checkbox-rich document types. The proposed method\nintegrates checkbox detection, multilingual optical character recognition (OCR)\nand multilingual vision-language models (VLMs). The pipeline achieves high\nprecision and recall compared against annually compiled gold-standards from\n2017 to 2024. The result is a reduction in administrative workload and accurate\nregulatory reporting. The open-source availability of this pipeline encourages\nself-hosted parsing of checkbox forms.", "published": "2025-04-28 19:40:28", "link": "http://arxiv.org/abs/2504.20220v1", "categories": ["cs.CL", "cs.CV", "68T07", "I.7.5; I.4.7; I.2.7; H.3.3; J.3"], "primary_category": "cs.CL"}
{"title": "Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains", "abstract": "Vision-language models (VLMs) achieve remarkable success in single-image\ntasks. However, real-world scenarios often involve intricate multi-image\ninputs, leading to a notable performance decline as models struggle to\ndisentangle critical information scattered across complex visual features. In\nthis work, we propose Focus-Centric Visual Chain, a novel paradigm that\nenhances VLMs'perception, comprehension, and reasoning abilities in multi-image\nscenarios. To facilitate this paradigm, we propose Focus-Centric Data\nSynthesis, a scalable bottom-up approach for synthesizing high-quality data\nwith elaborate reasoning paths. Through this approach, We construct VISC-150K,\na large-scale dataset with reasoning data in the form of Focus-Centric Visual\nChain, specifically designed for multi-image tasks. Experimental results on\nseven multi-image benchmarks demonstrate that our method achieves average\nperformance gains of 3.16% and 2.24% across two distinct model architectures,\nwithout compromising the general vision-language capabilities. our study\nrepresents a significant step toward more robust and capable vision-language\nsystems that can handle complex visual scenarios.", "published": "2025-04-28 19:02:18", "link": "http://arxiv.org/abs/2504.20199v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools", "abstract": "Tool-using agents that act in the world need to be both useful and safe.\nWell-calibrated model confidences can be used to weigh the risk versus reward\nof potential actions, but prior work shows that many models are poorly\ncalibrated. Inspired by interpretability literature exploring the internals of\nmodels, we propose a novel class of model-internal confidence estimators (MICE)\nto better assess confidence when calling tools. MICE first decodes from each\nintermediate layer of the language model using logitLens and then computes\nsimilarity scores between each layer's generation and the final output. These\nfeatures are fed into a learned probabilistic classifier to assess confidence\nin the decoded output. On the simulated trial and error (STE) tool-calling\ndataset using Llama3 models, we find that MICE beats or matches the baselines\non smoothed expected calibration error. Using MICE confidences to determine\nwhether to call a tool significantly improves over strong baselines on a new\nmetric, expected tool-calling utility. Further experiments show that MICE is\nsample-efficient, can generalize zero-shot to unseen APIs, and results in\nhigher tool-calling utility in scenarios with varying risk levels. Our code is\nopen source, available at https://github.com/microsoft/mice_for_cats.", "published": "2025-04-28 18:06:38", "link": "http://arxiv.org/abs/2504.20168v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Toward Evaluative Thinking: Meta Policy Optimization with Evolving Reward Models", "abstract": "Reward-based alignment methods for large language models (LLMs) face two key\nlimitations: vulnerability to reward hacking, where models exploit flaws in the\nreward signal; and reliance on brittle, labor-intensive prompt engineering when\nLLMs are used as reward models. We introduce Meta Policy Optimization (MPO), a\nframework that addresses these challenges by integrating a meta-reward model\nthat dynamically refines the reward model's prompt throughout training. In MPO,\nthe meta-reward model monitors the evolving training context and continuously\nadjusts the reward model's prompt to maintain high alignment, providing an\nadaptive reward signal that resists exploitation by the policy. This\nmeta-learning approach promotes a more stable policy optimization, and greatly\nreduces the need for manual reward prompt design. It yields performance on par\nwith or better than models guided by extensively hand-crafted reward prompts.\nFurthermore, we show that MPO maintains its effectiveness across diverse tasks,\nsuch as question answering and mathematical reasoning, without requiring\nspecialized reward designs. Beyond standard RLAIF, MPO's meta-learning\nformulation is readily extensible to higher-level alignment frameworks.\nOverall, this method addresses theoretical and practical challenges in\nreward-based RL alignment for LLMs, paving the way for more robust and\nadaptable alignment strategies. The code and models will be publicly shared.", "published": "2025-04-28 18:02:35", "link": "http://arxiv.org/abs/2504.20157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies", "abstract": "In this paper we introduce ResearchCodeAgent, a novel multi-agent system\nleveraging large language models (LLMs) agents to automate the codification of\nresearch methodologies described in machine learning literature. The system\nbridges the gap between high-level research concepts and their practical\nimplementation, allowing researchers auto-generating code of existing research\npapers for benchmarking or building on top-of existing methods specified in the\nliterature with availability of partial or complete starter code.\nResearchCodeAgent employs a flexible agent architecture with a comprehensive\naction suite, enabling context-aware interactions with the research\nenvironment. The system incorporates a dynamic planning mechanism, utilizing\nboth short and long-term memory to adapt its approach iteratively. We evaluate\nResearchCodeAgent on three distinct machine learning tasks with distinct task\ncomplexity and representing different parts of the ML pipeline: data\naugmentation, optimization, and data batching. Our results demonstrate the\nsystem's effectiveness and generalizability, with 46.9% of generated code being\nhigh-quality and error-free, and 25% showing performance improvements over\nbaseline implementations. Empirical analysis shows an average reduction of\n57.9% in coding time compared to manual implementation. We observe higher gains\nfor more complex tasks. ResearchCodeAgent represents a significant step towards\nautomating the research implementation process, potentially accelerating the\npace of machine learning research.", "published": "2025-04-28 07:18:45", "link": "http://arxiv.org/abs/2504.20117v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.SE"}
{"title": "Perturbation-efficient Zeroth-order Optimization for Hardware-friendly On-device Training", "abstract": "Zeroth-order (ZO) optimization is an emerging deep neural network (DNN)\ntraining paradigm that offers computational simplicity and memory savings.\nHowever, this seemingly promising approach faces a significant and long-ignored\nchallenge. ZO requires generating a substantial number of Gaussian random\nnumbers, which poses significant difficulties and even makes it infeasible for\nhardware platforms, such as FPGAs and ASICs. In this paper, we identify this\ncritical issue, which arises from the mismatch between algorithm and hardware\ndesigners. To address this issue, we proposed PeZO, a perturbation-efficient ZO\nframework. Specifically, we design random number reuse strategies to\nsignificantly reduce the demand for random number generation and introduce a\nhardware-friendly adaptive scaling method to replace the costly Gaussian\ndistribution with a uniform distribution. Our experiments show that PeZO\nreduces the required LUTs and FFs for random number generation by 48.6\\% and\n12.7\\%, and saves at maximum 86\\% power consumption, all without compromising\ntraining performance, making ZO optimization feasible for on-device training.\nTo the best of our knowledge, we are the first to explore the potential of\non-device ZO optimization, providing valuable insights for future research.", "published": "2025-04-28 23:58:07", "link": "http://arxiv.org/abs/2504.20314v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning", "abstract": "In this paper, we initiate a cryptographically inspired theoretical study of\ndetection versus mitigation of adversarial inputs produced by attackers of\nMachine Learning algorithms during inference time.\n  We formally define defense by detection (DbD) and defense by mitigation\n(DbM). Our definitions come in the form of a 3-round protocol between two\nresource-bounded parties: a trainer/defender and an attacker. The attacker aims\nto produce inference-time inputs that fool the training algorithm. We define\ncorrectness, completeness, and soundness properties to capture successful\ndefense at inference time while not degrading (too much) the performance of the\nalgorithm on inputs from the training distribution.\n  We first show that achieving DbD and achieving DbM are equivalent for ML\nclassification tasks. Surprisingly, this is not the case for ML generative\nlearning tasks, where there are many possible correct outputs that can be\ngenerated for each input. We show a separation between DbD and DbM by\nexhibiting a generative learning task for which is possible to defend by\nmitigation but is provably impossible to defend by detection under the\nassumption that the Identity-Based Fully Homomorphic Encryption (IB-FHE),\npublicly-verifiable zero-knowledge Succinct Non-Interactive Arguments of\nKnowledge (zk-SNARK) and Strongly Unforgeable Signatures exist. The mitigation\nphase uses significantly fewer samples than the initial training algorithm.", "published": "2025-04-28 23:46:45", "link": "http://arxiv.org/abs/2504.20310v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "The Dark Side of Digital Twins: Adversarial Attacks on AI-Driven Water Forecasting", "abstract": "Digital twins (DTs) are improving water distribution systems by using\nreal-time data, analytics, and prediction models to optimize operations. This\npaper presents a DT platform designed for a Spanish water supply network,\nutilizing Long Short-Term Memory (LSTM) networks to predict water consumption.\nHowever, machine learning models are vulnerable to adversarial attacks, such as\nthe Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD).\nThese attacks manipulate critical model parameters, injecting subtle\ndistortions that degrade forecasting accuracy. To further exploit these\nvulnerabilities, we introduce a Learning Automata (LA) and Random LA-based\napproach that dynamically adjusts perturbations, making adversarial attacks\nmore difficult to detect. Experimental results show that this approach\nsignificantly impacts prediction reliability, causing the Mean Absolute\nPercentage Error (MAPE) to rise from 26% to over 35%. Moreover, adaptive attack\nstrategies amplify this effect, highlighting cybersecurity risks in AI-driven\nDTs. These findings emphasize the urgent need for robust defenses, including\nadversarial training, anomaly detection, and secure data pipelines.", "published": "2025-04-28 22:34:11", "link": "http://arxiv.org/abs/2504.20295v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Deep Physics Prior for First Order Inverse Optimization", "abstract": "Inverse design optimization aims to infer system parameters from observed\nsolutions, posing critical challenges across domains such as semiconductor\nmanufacturing, structural engineering, materials science, and fluid dynamics.\nThe lack of explicit mathematical representations in many systems complicates\nthis process and makes the first order optimization impossible. Mainstream\napproaches, including generative AI and Bayesian optimization, address these\nchallenges but have limitations. Generative AI is computationally expensive,\nwhile Bayesian optimization, relying on surrogate models, suffers from\nscalability, sensitivity to priors, and noise issues, often leading to\nsuboptimal solutions. This paper introduces Deep Physics Prior (DPP), a novel\nmethod enabling first-order gradient-based inverse optimization with surrogate\nmachine learning models. By leveraging pretrained auxiliary Neural Operators,\nDPP enforces prior distribution constraints to ensure robust and meaningful\nsolutions. This approach is particularly effective when prior data and\nobservation distributions are unknown.", "published": "2025-04-28 21:48:19", "link": "http://arxiv.org/abs/2504.20278v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Smart Water Security with AI and Blockchain-Enhanced Digital Twins", "abstract": "Water distribution systems in rural areas face serious challenges such as a\nlack of real-time monitoring, vulnerability to cyberattacks, and unreliable\ndata handling. This paper presents an integrated framework that combines\nLoRaWAN-based data acquisition, a machine learning-driven Intrusion Detection\nSystem (IDS), and a blockchain-enabled Digital Twin (BC-DT) platform for secure\nand transparent water management. The IDS filters anomalous or spoofed data\nusing a Long Short-Term Memory (LSTM) Autoencoder and Isolation Forest before\nvalidated data is logged via smart contracts on a private Ethereum blockchain\nusing Proof of Authority (PoA) consensus. The verified data feeds into a\nreal-time DT model supporting leak detection, consumption forecasting, and\npredictive maintenance. Experimental results demonstrate that the system\nachieves over 80 transactions per second (TPS) with under 2 seconds of latency\nwhile remaining cost-effective and scalable for up to 1,000 smart meters. This\nwork demonstrates a practical and secure architecture for decentralized water\ninfrastructure in under-connected rural environments.", "published": "2025-04-28 21:41:23", "link": "http://arxiv.org/abs/2504.20275v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework", "abstract": "This paper investigates the logical reasoning capabilities of large language\nmodels (LLMs). For a precisely defined yet tractable formulation, we choose the\nconceptually simple but technically complex task of constructing proofs in\nBoolean logic. A trained LLM receives as input a set of assumptions and a goal,\nand produces as output a proof that formally derives the goal from the\nassumptions. Incorrect proofs are caught by an automated proof checker. A\ncritical obstacle for training is the scarcity of real-world proofs. We propose\nan efficient, randomized procedure for synthesizing valid proofs and introduce\nTemplate Transformation, a data augmentation technique that enhances the\nmodel's ability to handle complex logical expressions. The central evaluation\nquestion is whether an LLM has indeed learned to reason. We propose tests to\nmeasure the reasoning ability of a black-box LLM. By these measures,\nexperiments demonstrate strong reasoning capabilities for assertions with short\nproofs, which decline with proof complexity. Notably, template transformation\nimproves accuracy even for smaller models, suggesting its effectiveness across\nmodel scales.", "published": "2025-04-28 19:25:29", "link": "http://arxiv.org/abs/2504.20213v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Representation Learning on a Random Lattice", "abstract": "Decomposing a deep neural network's learned representations into\ninterpretable features could greatly enhance its safety and reliability. To\nbetter understand features, we adopt a geometric perspective, viewing them as a\nlearned coordinate system for mapping an embedded data distribution. We\nmotivate a model of a generic data distribution as a random lattice and analyze\nits properties using percolation theory. Learned features are categorized into\ncontext, component, and surface features. The model is qualitatively consistent\nwith recent findings in mechanistic interpretability and suggests directions\nfor future research.", "published": "2025-04-28 19:01:36", "link": "http://arxiv.org/abs/2504.20197v1", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Dynamic Contextual Attention Network: Transforming Spatial Representations into Adaptive Insights for Endoscopic Polyp Diagnosis", "abstract": "Colorectal polyps are key indicators for early detection of colorectal\ncancer. However, traditional endoscopic imaging often struggles with accurate\npolyp localization and lacks comprehensive contextual awareness, which can\nlimit the explainability of diagnoses. To address these issues, we propose the\nDynamic Contextual Attention Network (DCAN). This novel approach transforms\nspatial representations into adaptive contextual insights, using an attention\nmechanism that enhances focus on critical polyp regions without explicit\nlocalization modules. By integrating contextual awareness into the\nclassification process, DCAN improves decision interpretability and overall\ndiagnostic performance. This advancement in imaging could lead to more reliable\ncolorectal cancer detection, enabling better patient outcomes.", "published": "2025-04-28 23:32:57", "link": "http://arxiv.org/abs/2504.20306v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DeepAndes: A Self-Supervised Vision Foundation Model for Multi-Spectral Remote Sensing Imagery of the Andes", "abstract": "By mapping sites at large scales using remotely sensed data, archaeologists\ncan generate unique insights into long-term demographic trends, inter-regional\nsocial networks, and past adaptations to climate change. Remote sensing surveys\ncomplement field-based approaches, and their reach can be especially great when\ncombined with deep learning and computer vision techniques. However,\nconventional supervised deep learning methods face challenges in annotating\nfine-grained archaeological features at scale. While recent vision foundation\nmodels have shown remarkable success in learning large-scale remote sensing\ndata with minimal annotations, most off-the-shelf solutions are designed for\nRGB images rather than multi-spectral satellite imagery, such as the 8-band\ndata used in our study. In this paper, we introduce DeepAndes, a\ntransformer-based vision foundation model trained on three million\nmulti-spectral satellite images, specifically tailored for Andean archaeology.\nDeepAndes incorporates a customized DINOv2 self-supervised learning algorithm\noptimized for 8-band multi-spectral imagery, marking the first foundation model\ndesigned explicitly for the Andes region. We evaluate its image understanding\nperformance through imbalanced image classification, image instance retrieval,\nand pixel-level semantic segmentation tasks. Our experiments show that\nDeepAndes achieves superior F1 scores, mean average precision, and Dice scores\nin few-shot learning scenarios, significantly outperforming models trained from\nscratch or pre-trained on smaller datasets. This underscores the effectiveness\nof large-scale self-supervised pre-training in archaeological remote sensing.\nCodes will be available on https://github.com/geopacha/DeepAndes.", "published": "2025-04-28 23:15:09", "link": "http://arxiv.org/abs/2504.20303v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Image Interpolation with Score-based Riemannian Metrics of Diffusion Models", "abstract": "Diffusion models excel in content generation by implicitly learning the data\nmanifold, yet they lack a practical method to leverage this manifold - unlike\nother deep generative models equipped with latent spaces. This paper introduces\na novel framework that treats the data space of pre-trained diffusion models as\na Riemannian manifold, with a metric derived from the score function.\nExperiments with MNIST and Stable Diffusion show that this geometry-aware\napproach yields image interpolations that are more realistic, less noisy, and\nmore faithful to prompts than existing methods, demonstrating its potential for\nimproved content generation and editing.", "published": "2025-04-28 22:04:20", "link": "http://arxiv.org/abs/2504.20288v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Physics-Informed Diffusion Models for SAR Ship Wake Generation from Text Prompts", "abstract": "Detecting ship presence via wake signatures in SAR imagery is attracting\nconsiderable research interest, but limited annotated data availability poses\nsignificant challenges for supervised learning. Physics-based simulations are\ncommonly used to address this data scarcity, although they are slow and\nconstrain end-to-end learning. In this work, we explore a new direction for\nmore efficient and end-to-end SAR ship wake simulation using a diffusion model\ntrained on data generated by a physics-based simulator. The training dataset is\nbuilt by pairing images produced by the simulator with text prompts derived\nfrom simulation parameters. Experimental result show that the model generates\nrealistic Kelvin wake patterns and achieves significantly faster inference than\nthe physics-based simulator. These results highlight the potential of diffusion\nmodels for fast and controllable wake image generation, opening new\npossibilities for end-to-end downstream tasks in maritime SAR analysis.", "published": "2025-04-28 20:21:05", "link": "http://arxiv.org/abs/2504.20241v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Improving trajectory continuity in drone-based crowd monitoring using a set of minimal-cost techniques and deep discriminative correlation filters", "abstract": "Drone-based crowd monitoring is the key technology for applications in\nsurveillance, public safety, and event management. However, maintaining\ntracking continuity and consistency remains a significant challenge.\nTraditional detection-assignment tracking methods struggle with false\npositives, false negatives, and frequent identity switches, leading to degraded\ncounting accuracy and making in-depth analysis impossible. This paper\nintroduces a point-oriented online tracking algorithm that improves trajectory\ncontinuity and counting reliability in drone-based crowd monitoring. Our method\nbuilds on the Simple Online and Real-time Tracking (SORT) framework, replacing\nthe original bounding-box assignment with a point-distance metric. The\nalgorithm is enhanced with three cost-effective techniques: camera motion\ncompensation, altitude-aware assignment, and classification-based trajectory\nvalidation. Further, Deep Discriminative Correlation Filters (DDCF) that re-use\nspatial feature maps from localisation algorithms for increased computational\nefficiency through neural network resource sharing are integrated to refine\nobject tracking by reducing noise and handling missed detections. The proposed\nmethod is evaluated on the DroneCrowd and newly shared UP-COUNT-TRACK datasets,\ndemonstrating substantial improvements in tracking metrics, reducing counting\nerrors to 23% and 15%, respectively. The results also indicate a significant\nreduction of identity switches while maintaining high tracking accuracy,\noutperforming baseline online trackers and even an offline greedy optimisation\nmethod.", "published": "2025-04-28 20:07:42", "link": "http://arxiv.org/abs/2504.20234v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "FreBIS: Frequency-Based Stratification for Neural Implicit Surface Representations", "abstract": "Neural implicit surface representation techniques are in high demand for\nadvancing technologies in augmented reality/virtual reality, digital twins,\nautonomous navigation, and many other fields. With their ability to model\nobject surfaces in a scene as a continuous function, such techniques have made\nremarkable strides recently, especially over classical 3D surface\nreconstruction methods, such as those that use voxels or point clouds. However,\nthese methods struggle with scenes that have varied and complex surfaces\nprincipally because they model any given scene with a single encoder network\nthat is tasked to capture all of low through high-surface frequency information\nin the scene simultaneously. In this work, we propose a novel, neural implicit\nsurface representation approach called FreBIS to overcome this challenge.\nFreBIS works by stratifying the scene based on the frequency of surfaces into\nmultiple frequency levels, with each level (or a group of levels) encoded by a\ndedicated encoder. Moreover, FreBIS encourages these encoders to capture\ncomplementary information by promoting mutual dissimilarity of the encoded\nfeatures via a novel, redundancy-aware weighting module. Empirical evaluations\non the challenging BlendedMVS dataset indicate that replacing the standard\nencoder in an off-the-shelf neural surface reconstruction method with our\nfrequency-stratified encoders yields significant improvements. These\nenhancements are evident both in the quality of the reconstructed 3D surfaces\nand in the fidelity of their renderings from any viewpoint.", "published": "2025-04-28 19:45:15", "link": "http://arxiv.org/abs/2504.20222v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Remote Sensing Imagery for Flood Detection: Exploration of Augmentation Strategies", "abstract": "Floods cause serious problems around the world. Responding quickly and\neffectively requires accurate and timely information about the affected areas.\nThe effective use of Remote Sensing images for accurate flood detection\nrequires specific detection methods. Typically, Deep Neural Networks are\nemployed, which are trained on specific datasets. For the purpose of river\nflood detection in RGB imagery, we use the BlessemFlood21 dataset. We here\nexplore the use of different augmentation strategies, ranging from basic\napproaches to more complex techniques, including optical distortion. By\nidentifying effective strategies, we aim to refine the training process of\nstate-of-the-art Deep Learning segmentation networks.", "published": "2025-04-28 19:08:53", "link": "http://arxiv.org/abs/2504.20203v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Integration Flow Models", "abstract": "Ordinary differential equation (ODE) based generative models have emerged as\na powerful approach for producing high-quality samples in many applications.\nHowever, the ODE-based methods either suffer the discretization error of\nnumerical solvers of ODE, which restricts the quality of samples when only a\nfew NFEs are used, or struggle with training instability. In this paper, we\nproposed Integration Flow, which directly learns the integral of ODE-based\ntrajectory paths without solving the ODE functions. Moreover, Integration Flow\nexplicitly incorporates the target state $\\mathbf{x}_0$ as the anchor state in\nguiding the reverse-time dynamics. We have theoretically proven this can\ncontribute to both stability and accuracy. To the best of our knowledge,\nIntegration Flow is the first model with a unified structure to estimate\nODE-based generative models and the first to show the exact straightness of\n1-Rectified Flow without reflow. Through theoretical analysis and empirical\nevaluations, we show that Integration Flows achieve improved performance when\nit is applied to existing ODE-based models, such as diffusion models, Rectified\nFlows, and PFGM++. Specifically, Integration Flow achieves one-step generation\non CIFAR10 with FIDs of 2.86 for the Variance Exploding (VE) diffusion model,\n3.36 for rectified flow without reflow, and 2.91 for PFGM++; and on ImageNet\nwith FIDs of 4.09 for VE diffusion model, 4.35 for rectified flow without\nreflow and 4.15 for PFGM++.", "published": "2025-04-28 18:29:15", "link": "http://arxiv.org/abs/2504.20179v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "A Transformer-based Multimodal Fusion Model for Efficient Crowd Counting Using Visual and Wireless Signals", "abstract": "Current crowd-counting models often rely on single-modal inputs, such as\nvisual images or wireless signal data, which can result in significant\ninformation loss and suboptimal recognition performance. To address these\nshortcomings, we propose TransFusion, a novel multimodal fusion-based\ncrowd-counting model that integrates Channel State Information (CSI) with image\ndata. By leveraging the powerful capabilities of Transformer networks,\nTransFusion effectively combines these two distinct data modalities, enabling\nthe capture of comprehensive global contextual information that is critical for\naccurate crowd estimation. However, while transformers are well capable of\ncapturing global features, they potentially fail to identify finer-grained,\nlocal details essential for precise crowd counting. To mitigate this, we\nincorporate Convolutional Neural Networks (CNNs) into the model architecture,\nenhancing its ability to extract detailed local features that complement the\nglobal context provided by the Transformer. Extensive experimental evaluations\ndemonstrate that TransFusion achieves high accuracy with minimal counting\nerrors while maintaining superior efficiency.", "published": "2025-04-28 18:26:28", "link": "http://arxiv.org/abs/2504.20178v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets", "abstract": "Retrieval-Augmented Generation (RAG) has advanced significantly in recent\nyears. The complexity of RAG systems, which involve multiple components-such as\nindexing, retrieval, and generation-along with numerous other parameters, poses\nsubstantial challenges for systematic evaluation and quality enhancement.\nPrevious research highlights that evaluating RAG systems is essential for\ndocumenting advancements, comparing configurations, and identifying effective\napproaches for domain-specific applications. This study systematically reviews\n63 academic articles to provide a comprehensive overview of state-of-the-art\nRAG evaluation methodologies, focusing on four key areas: datasets, retrievers,\nindexing and databases, and the generator component. We observe the feasibility\nof an automated evaluation approach for each component of a RAG system,\nleveraging an LLM capable of both generating evaluation datasets and conducting\nevaluations. In addition, we found that further practical research is essential\nto provide companies with clear guidance on the do's and don'ts of implementing\nand evaluating RAG systems. By synthesizing evaluation approaches for key RAG\ncomponents and emphasizing the creation and adaptation of domain-specific\ndatasets for benchmarking, we contribute to the advancement of systematic\nevaluation methods and the improvement of evaluation rigor for RAG systems.\nFurthermore, by examining the interplay between automated approaches leveraging\nLLMs and human judgment, we contribute to the ongoing discourse on balancing\nautomation and human input, clarifying their respective contributions,\nlimitations, and challenges in achieving robust and reliable evaluations.", "published": "2025-04-28 08:22:19", "link": "http://arxiv.org/abs/2504.20119v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis", "abstract": "Traditional Chinese Medicine (TCM) represents a rich repository of ancient\nmedical knowledge that continues to play an important role in modern\nhealthcare. Due to the complexity and breadth of the TCM literature, the\nintegration of AI technologies is critical for its modernization and broader\naccessibility. However, this integration poses considerable challenges,\nincluding the interpretation of obscure classical Chinese texts and the\nmodeling of intricate semantic relationships among TCM concepts. In this paper,\nwe develop OpenTCM, an LLM-based system that combines a domain-specific TCM\nknowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG).\nFirst, we extract more than 3.73 million classical Chinese characters from 68\ngynecological books in the Chinese Medical Classics Database, with the help of\nTCM and gynecology experts. Second, we construct a comprehensive\nmulti-relational knowledge graph comprising more than 48,000 entities and\n152,000 interrelationships, using customized prompts and Chinese-oriented LLMs\nsuch as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last,\nwe integrate OpenTCM with this knowledge graph, enabling high-fidelity\ningredient knowledge retrieval and diagnostic question-answering without model\nfine-tuning. Experimental evaluations demonstrate that our prompt design and\nmodel selection significantly improve knowledge graph quality, achieving a\nprecision of 98. 55% and an F1 score of 99. 55%. In addition, OpenTCM achieves\nmean expert scores of 4.5 in ingredient information retrieval and 3.8 in\ndiagnostic question-answering tasks, outperforming state-of-the-art solutions\nin real-world TCM use cases.", "published": "2025-04-28 08:04:44", "link": "http://arxiv.org/abs/2504.20118v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering", "abstract": "Retrieval-augmented generation (RAG) systems face significant challenges in\nmulti-hop question answering (MHQA), where complex queries require synthesizing\ninformation across multiple document chunks. Existing approaches typically rely\non iterative LLM-based query rewriting and routing, resulting in high\ncomputational costs due to repeated LLM invocations and multi-stage processes.\nTo address these limitations, we propose TreeHop, an embedding-level framework\nwithout the need for LLMs in query refinement. TreeHop dynamically updates\nquery embeddings by fusing semantic information from prior queries and\nretrieved documents, enabling iterative retrieval through embedding-space\noperations alone. This method replaces the traditional\n\"Retrieve-Rewrite-Vectorize-Retrieve\" cycle with a streamlined\n\"Retrieve-Embed-Retrieve\" loop, significantly reducing computational overhead.\nMoreover, a rule-based stop criterion is introduced to further prune redundant\nretrievals, balancing efficiency and recall rate. Experimental results show\nthat TreeHop rivals advanced RAG methods across three open-domain MHQA\ndatasets, achieving comparable performance with only 5\\%-0.4\\% of the model\nparameter size and reducing the query latency by approximately 99\\% compared to\nconcurrent approaches. This makes TreeHop a faster and more cost-effective\nsolution for deployment in a range of knowledge-intensive applications. For\nreproducibility purposes, codes and data are available here:\nhttps://github.com/allen-li1231/TreeHop.", "published": "2025-04-28 01:56:31", "link": "http://arxiv.org/abs/2504.20114v1", "categories": ["cs.IR", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Computation of Capacity-Distortion-Cost Functions for Continuous Memoryless Channels", "abstract": "This paper aims at computing the capacity-distortion-cost (CDC) function for\ncontinuous memoryless channels, which is defined as the supremum of the mutual\ninformation between channel input and output, constrained by an input cost and\nan expected distortion of estimating channel state. Solving the optimization\nproblem is challenging because the input distribution does not lie in a\nfinite-dimensional Euclidean space and the optimal estimation function has no\nclosed form in general. We propose to adopt the Wasserstein proximal point\nmethod and parametric models such as neural networks (NNs) to update the input\ndistribution and estimation function alternately. To implement it in practice,\nthe importance sampling (IS) technique is used to calculate integrals\nnumerically, and the Wasserstein gradient descent is approximated by pushing\nforward particles. The algorithm is then applied to an integrated sensing and\ncommunications (ISAC) system, validating theoretical results at minimum and\nmaximum distortion as well as the random-deterministic trade-off.", "published": "2025-04-28 21:57:39", "link": "http://arxiv.org/abs/2504.20285v1", "categories": ["cs.IT", "eess.SP", "math.IT", "math.OC"], "primary_category": "cs.IT"}
{"title": "LZ Penalty: An information-theoretic repetition penalty for autoregressive language models", "abstract": "We introduce the LZ penalty, a penalty specialized for reducing degenerate\nrepetitions in autoregressive language models without loss of capability. The\npenalty is based on the codelengths in the LZ77 universal lossless compression\nalgorithm. Through the lens of the prediction-compression duality, decoding the\nLZ penalty has the interpretation of sampling from the residual distribution\nafter removing the information that is highly compressible. We demonstrate the\nLZ penalty enables state-of-the-art open-source reasoning models to operate\nwith greedy (temperature zero) decoding without loss of capability and without\ninstances of degenerate repetition. Both the industry-standard frequency\npenalty and repetition penalty are ineffective, incurring degenerate repetition\nrates of up to 4%.", "published": "2025-04-28 17:58:28", "link": "http://arxiv.org/abs/2504.20131v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "FigBO: A Generalized Acquisition Function Framework with Look-Ahead Capability for Bayesian Optimization", "abstract": "Bayesian optimization is a powerful technique for optimizing\nexpensive-to-evaluate black-box functions, consisting of two main components: a\nsurrogate model and an acquisition function. In recent years, myopic\nacquisition functions have been widely adopted for their simplicity and\neffectiveness. However, their lack of look-ahead capability limits their\nperformance. To address this limitation, we propose FigBO, a generalized\nacquisition function that incorporates the future impact of candidate points on\nglobal information gain. FigBO is a plug-and-play method that can integrate\nseamlessly with most existing myopic acquisition functions. Theoretically, we\nanalyze the regret bound and convergence rate of FigBO when combined with the\nmyopic base acquisition function expected improvement (EI), comparing them to\nthose of standard EI. Empirically, extensive experimental results across\ndiverse tasks demonstrate that FigBO achieves state-of-the-art performance and\nsignificantly faster convergence compared to existing methods.", "published": "2025-04-28 23:35:17", "link": "http://arxiv.org/abs/2504.20307v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Fast LDL factorization for dense and sparse symmetric matrices over an arbitrary field", "abstract": "While existing algorithms may be used to solve a linear system over a general\nfield in matrix-multiplication time, the complexity of constructing a symmetric\ntriangular factorization (LDL) has received relatively little formal study. The\nLDL factorization is a common tool for factorization of symmetric matrices,\nand, unlike orthogonal counterparts, generalizes to an arbitrary field. We\nprovide algorithms for dense and sparse LDL factorization and for dense LU\nfactorization that aim to minimize complexity for factorization over a general\nfield. For LU of an $m\\times n$ rank $R$ matrix, we obtain an algorithm with\ncomplexity $O(mnR^{\\omega-2})$, where $\\omega$ is the matrix multiplication\ncomplexity exponent. For LDL of an $n\\times n$ matrix, we give an algorithm\nwith complexity $O(n^\\omega)$ and for a sparse matrix corresponding to a graph\nwith treewidth $\\tau$, we obtain $O(n\\tau^{\\omega-1})$. Our sparse LDL\nalgorithm is based on an adaptation of the null-space method for solving saddle\npoint systems of equations, which may be of independent interest.", "published": "2025-04-28 23:26:50", "link": "http://arxiv.org/abs/2504.20305v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Entropy based lower dimension bounds for finite-time prediction of Dynamic Mode Decomposition algorithms", "abstract": "Motivated by Dynamic Mode Decomposition algorithms, we provide lower bounds\non the dimension of a finite-dimensional subspace $F \\subseteq\n\\mathrm{L}^2(\\mathrm{X})$ required for predicting the behavior of dynamical\nsystems over long time horizons. We distinguish between two cases: (i) If $F$\nis determined by a finite partition of $X$ we derive a lower bound that depends\non the dynamical measure-theoretic entropy of the partition. (ii) We consider\ngeneral finite-dimensional subspaces $F$ and establish a lower bound for the\ndimension of $F$ that is contingent on the spectral structure of the Koopman\noperator of the system, via the approximation entropy of $F$ as studied by\nVoiculescu. Furthermore, we motivate the use of delay observables to improve\nthe predictive qualities of Dynamic Mode Decomposition algorithms.", "published": "2025-04-28 21:18:27", "link": "http://arxiv.org/abs/2504.20269v1", "categories": ["math.DS", "cs.NA", "math.FA", "math.NA", "37A05, 37M10, 37M25, 65P99"], "primary_category": "math.DS"}
{"title": "Global Optimality Characterizations and Algorithms for Minimizing Quartically-Regularized Third-Order Taylor Polynomials", "abstract": "High-order methods for convex and nonconvex optimization, particularly\n$p$th-order Adaptive Regularization Methods (AR$p$), have attracted significant\nresearch interest by naturally incorporating high-order Taylor models into\nadaptive regularization frameworks, resulting in algorithms with faster global\nand local convergence rates than first- and second-order methods. This paper\nestablishes global optimality conditions for general, nonconvex cubic\npolynomials with quartic regularization. These criteria generalise existing\nresults, recovering the optimality results for regularized quadratic\npolynomials, and can be further simplified in the low-rank and diagonal tensor\ncases. Under suitable assumptions on the Taylor polynomial, we derive a lower\nbound for the regularization parameter such that the necessary and sufficient\ncriteria coincide, establishing a connection between this bound and the\nsubproblem's convexification and sum-of-squares (SoS) convexification\ntechniques. Leveraging the optimality characterization, we develop a Diagonal\nTensor Method (DTM) for minimizing quartically-regularized cubic Taylor\npolynomials by iteratively minimizing a sequence of local models that\nincorporate both diagonal cubic terms and quartic regularization (DTM model).\nWe show that the DTM algorithm is provably convergent, with a global evaluation\ncomplexity of $\\mathcal{O}(\\epsilon^{-3/2})$. Furthermore, when special\nstructure is present (such as low rank or diagonal), DTM can exactly solve the\ngiven problem (in one iteration). In our numerical experiments, we propose\npractical DTM variants that exploit local problem information for model\nconstruction, which we then show to be competitive with cubic regularization\nand other subproblem solvers, with superior performance on problems with\nspecial structure.", "published": "2025-04-28 21:03:29", "link": "http://arxiv.org/abs/2504.20259v1", "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "math.OC"}
{"title": "Optimizing Hard Thresholding for Sparse Model Discovery", "abstract": "Many model selection algorithms rely on sparse dictionary learning to provide\ninterpretable and physics-based governing equations. The optimization\nalgorithms typically use a hard thresholding process to enforce sparse\nactivations in the model coefficients by removing library elements from\nconsideration. By introducing an annealing scheme that reactivates a fraction\nof the removed terms with a cooling schedule, we are able to improve the\nperformance of these sparse learning algorithms. We concentrate on two\napproaches to the optimization, SINDy, and an alternative using hard\nthresholding pursuit. We see in both cases that annealing can improve model\naccuracy. The effectiveness of annealing is demonstrated through comparisons on\nseveral nonlinear systems pulled from convective flows, excitable systems, and\npopulation dynamics. Finally we apply these algorithms to experimental data for\nprojectile motion.", "published": "2025-04-28 21:01:07", "link": "http://arxiv.org/abs/2504.20256v1", "categories": ["math.OC", "cs.LG", "cs.NA", "math.DS", "math.NA"], "primary_category": "math.OC"}
{"title": "Financial Data Analysis with Robust Federated Logistic Regression", "abstract": "In this study, we focus on the analysis of financial data in a federated\nsetting, wherein data is distributed across multiple clients or locations, and\nthe raw data never leaves the local devices. Our primary focus is not only on\nthe development of efficient learning frameworks (for protecting user data\nprivacy) in the field of federated learning but also on the importance of\ndesigning models that are easier to interpret. In addition, we care about the\nrobustness of the framework to outliers. To achieve these goals, we propose a\nrobust federated logistic regression-based framework that strives to strike a\nbalance between these goals. To verify the feasibility of our proposed\nframework, we carefully evaluate its performance not only on independently\nidentically distributed (IID) data but also on non-IID data, especially in\nscenarios involving outliers. Extensive numerical results collected from\nmultiple public datasets demonstrate that our proposed method can achieve\ncomparable performance to those of classical centralized algorithms, such as\nLogistical Regression, Decision Tree, and K-Nearest Neighbors, in both binary\nand multi-class classification tasks.", "published": "2025-04-28 20:42:24", "link": "http://arxiv.org/abs/2504.20250v1", "categories": ["cs.LG", "q-fin.GN", "q-fin.ST", "stat.AP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Compounding Effects in Leveraged ETFs: Beyond the Volatility Drag Paradigm", "abstract": "A common belief is that leveraged ETFs (LETFs) suffer long-term performance\ndecay due to \\emph{volatility drag}. We show that this view is incomplete: LETF\nperformance depends fundamentally on return autocorrelation and return\ndynamics. In markets with independent returns, LETFs exhibit positive expected\ncompounding effects on their target multiples. In serially correlated markets,\ntrends enhance returns, while mean reversion induces underperformance. With a\nunified framework incorporating AR(1) and AR-GARCH models, continuous-time\nregime switching, and flexible rebalancing frequencies, we demonstrate that\nreturn dynamics -- including return autocorrelation, volatility clustering, and\nregime persistence -- determine whether LETFs outperform or underperform their\ntargets. Empirically, using about 20 years of SPDR S\\&P~500 ETF and Nasdaq-100\nETF data, we confirm these theoretical predictions. Daily-rebalanced LETFs\nenhance returns in momentum-driven markets, whereas infrequent rebalancing\nmitigates losses in mean-reverting regimes.", "published": "2025-04-28 06:57:18", "link": "http://arxiv.org/abs/2504.20116v1", "categories": ["q-fin.ST", "q-fin.GN", "91G80, 60G10"], "primary_category": "q-fin.ST"}
{"title": "Coreset selection for the Sinkhorn divergence and generic smooth divergences", "abstract": "We introduce CO2, an efficient algorithm to produce convexly-weighted\ncoresets with respect to generic smooth divergences. By employing a functional\nTaylor expansion, we show a local equivalence between sufficiently regular\nlosses and their second order approximations, reducing the coreset selection\nproblem to maximum mean discrepancy minimization. We apply CO2 to the Sinkhorn\ndivergence, providing a novel sampling procedure that requires logarithmically\nmany data points to match the approximation guarantees of random sampling. To\nshow this, we additionally verify several new regularity properties for\nentropically regularized optimal transport of independent interest. Our\napproach leads to a new perspective linking coreset selection and kernel\nquadrature to classical statistical methods such as moment and score matching.\nWe showcase this method with a practical application of subsampling image data,\nand highlight key directions to explore for improved algorithmic efficiency and\ntheoretical guarantees.", "published": "2025-04-28 18:54:53", "link": "http://arxiv.org/abs/2504.20194v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Causal Identification in Time Series Models", "abstract": "In this paper, we analyze the applicability of the Causal Identification\nalgorithm to causal time series graphs with latent confounders. Since these\ngraphs extend over infinitely many time steps, deciding whether causal effects\nacross arbitrary time intervals are identifiable appears to require computation\non graph segments of unbounded size. Even for deciding the identifiability of\nintervention effects on variables that are close in time, no bound is known on\nhow many time steps in the past need to be considered. We give a first bound of\nthis kind that only depends on the number of variables per time step and the\nmaximum time lag of any direct or latent causal effect. More generally, we show\nthat applying the Causal Identification algorithm to a constant-size segment of\nthe time series graph is sufficient to decide identifiability of causal\neffects, even across unbounded time intervals.", "published": "2025-04-28 18:10:39", "link": "http://arxiv.org/abs/2504.20172v1", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Generative Diffusion Models for Resource Allocation in Wireless Networks", "abstract": "This paper proposes a supervised training algorithm for learning stochastic\nresource allocation policies with generative diffusion models (GDMs). We\nformulate the allocation problem as the maximization of an ergodic utility\nfunction subject to ergodic Quality of Service (QoS) constraints. Given samples\nfrom a stochastic expert policy that yields a near-optimal solution to the\nproblem, we train a GDM policy to imitate the expert and generate new samples\nfrom the optimal distribution. We achieve near-optimal performance through\nsequential execution of the generated samples. To enable generalization to a\nfamily of network configurations, we parameterize the backward diffusion\nprocess with a graph neural network (GNN) architecture. We present numerical\nresults in a case study of power control in multi-user interference networks.", "published": "2025-04-28 21:44:31", "link": "http://arxiv.org/abs/2504.20277v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Evaluation of Switching Technologies for Reflective and Transmissive RISs at Sub-THz Frequencies", "abstract": "For the upcoming 6G wireless networks, reconfigurable intelligent surfaces\nare an essential technology, enabling dynamic beamforming and signal\nmanipulation in both reflective and transmissive modes. It is expected to\nutilize frequency bands in the millimeter-wave and THz, which presents unique\nopportunities but also significant challenges. The selection of switching\ntechnologies that can support high-frequency operation with minimal loss and\nhigh efficiency is particularly complex. In this work, we demonstrate the\npotential of advanced components such as Schottky diodes, memristor switches,\nliquid metal-based switches, phase change materials, and RF-SOI technology in\nRIS designs as an alternative to overcome limitations inherent in traditional\ntechnologies in D-band (110-170 GHz).", "published": "2025-04-28 18:20:55", "link": "http://arxiv.org/abs/2504.20175v1", "categories": ["cs.ET", "eess.SP"], "primary_category": "cs.ET"}
{"title": "Efficient Domain-adaptive Continual Pretraining for the Process Industry in the German Language", "abstract": "Domain-adaptive continual pretraining (DAPT) is a state-of-the-art technique\nthat further trains a language model (LM) on its pretraining task, e.g.,\nlanguage masking. Although popular, it requires a significant corpus of\ndomain-related data, which is difficult to obtain for specific domains in\nlanguages other than English, such as the process industry in the German\nlanguage. This paper introduces an efficient approach called ICL-augmented\npretraining or ICL-APT that leverages in-context learning (ICL) and k-nearest\nneighbors (kNN) to augment target data with domain-related and in-domain texts,\nsignificantly reducing GPU time while maintaining strong model performance. Our\nresults show that this approach performs better than traditional DAPT by 3.5\npoints of the average IR metrics (e.g., mAP, MRR, and nDCG) and requires almost\n4 times less computing time, providing a cost-effective solution for industries\nwith limited computational capacity. The findings highlight the broader\napplicability of this framework to other low-resource industries, making\nNLP-based solutions more accessible and feasible in production environments.", "published": "2025-04-28 14:49:00", "link": "http://arxiv.org/abs/2504.19856v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The frequency $K_i$s for symmetrical traveling salesman problem", "abstract": "The frequency $K_i$s ($i\\in[4,n]$) are studied for symmetrical traveling\nsalesman problem ($TSP$) to identify the edges in optimal Hamiltonian cycle\n($OHC$). A frequency $K_i$ is computed with a sort of ${{i}\\choose{2}}$ optimal\n$i$-vertex paths with given endpoints (optimal $i$-vertex path) in a\ncorresponding $K_i$ in $K_n$. In frequency $K_i$, the frequency of an edge is\nthe number of the optimal $i$-vertex paths containing the edge in the\ncorresponding $K_i$. Given an $OHC$ edge related to $K_i$, it has a frequency\nbigger than $\\frac{1}{2}{{i}\\choose{2}}$ in the corresponding frequency $K_i$,\nand that of an ordinary edge not in $OHC$ is smaller than $\\frac{i+2}{2}$. On\naverage, an $OHC$ edge in $K_i$ has a frequency bigger than\n$\\frac{i^2-4i+7}{2}$ whereas an ordinary edge has a frequency smaller than 2.\nMoreover, given a frequency $K_i$ containing an $OHC$ edge related to $K_n$,\nthe frequency of the $OHC$ edge is bigger than $\\frac{1}{2}{{i}\\choose{2}}$ in\nthe worst average case. It implies that the average frequency of an $OHC$ edge\ncomputed with frequency $K_i$s is bigger than $\\frac{1}{2}{{i}\\choose{2}}$. It\nalso found that the probability that an $OHC$ edge is contained in optimal\n$i$-vertex paths keeps stable or increases according to $i\\in [4, n]$. As the\nfrequency $K_i$s are used to compute the frequency of an edge, each $OHC$ edge\nhas its own peak frequency at $i=P_0$ where $P_0=\\frac{n}{2} + 2$ for even $n$\nor $\\frac{n+1}{2} + 1$ for odd $n$. For ordinary edges out of $OHC$, the\nprobability that they are contained in optimal $i$-vertex paths decreases\naccording to $i$. Moreover, the average frequency of an ordinary edge will be\nsmaller than $\\frac{1}{2}{{i}\\choose{2}}$ if $i \\geq [0.3660n + 1.5849]$. Based\non these findings, an algorithm is presented to find $OHC$ in\n$O(n^62^{0.3660n})$ time using dynamic programming.", "published": "2025-04-28 09:12:47", "link": "http://arxiv.org/abs/2504.19608v2", "categories": ["cs.DM", "math.CO", "math.OC", "03C50, 03D15, 05C38, 05C62, 05C75, 05C85, 68Q06, 68R05, 68R10,\n  68W05, 90B10, 90B40, 90C27", "F.2.2; G.2.2"], "primary_category": "cs.DM"}
{"title": "How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation", "abstract": "Recently, numerous community search methods for large graphs have been\nproposed, at the core of which is defining and measuring cohesion. This paper\nexperimentally evaluates the effectiveness of these community search algorithms\nw.r.t. cohesiveness in the context of online social networks. Social\ncommunities are formed and developed under the influence of group cohesion\ntheory, which has been extensively studied in social psychology. However,\ncurrent generic methods typically measure cohesiveness using structural or\nattribute-based approaches and overlook domain-specific concepts such as group\ncohesion. We introduce five novel psychology-informed cohesiveness measures,\nbased on the concept of group cohesion from social psychology, and propose a\nnovel framework called CHASE for evaluating eight representative CS algorithms\nw.r.t. these measures on online social networks. Our analysis reveals that\nthere is no clear correlation between structural and psychological\ncohesiveness, and no algorithm effectively identifies psychologically cohesive\ncommunities in online social networks. This study provides new insights that\ncould guide the development of future community search methods.", "published": "2025-04-28 05:08:29", "link": "http://arxiv.org/abs/2504.19489v3", "categories": ["cs.IR", "cs.SI"], "primary_category": "cs.IR"}
{"title": "TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering", "abstract": "Retrieval-augmented generation (RAG) systems face significant challenges in\nmulti-hop question answering (MHQA), where complex queries require synthesizing\ninformation across multiple document chunks. Existing approaches typically rely\non iterative LLM-based query rewriting and routing, resulting in high\ncomputational costs due to repeated LLM invocations and multi-stage processes.\nTo address these limitations, we propose TreeHop, an embedding-level framework\nwithout the need for LLMs in query refinement. TreeHop dynamically updates\nquery embeddings by fusing semantic information from prior queries and\nretrieved documents, enabling iterative retrieval through embedding-space\noperations alone. This method replaces the traditional\n\"Retrieve-Rewrite-Vectorize-Retrieve\" cycle with a streamlined\n\"Retrieve-Embed-Retrieve\" loop, significantly reducing computational overhead.\nMoreover, a rule-based stop criterion is introduced to further prune redundant\nretrievals, balancing efficiency and recall rate. Experimental results show\nthat TreeHop rivals advanced RAG methods across three open-domain MHQA\ndatasets, achieving comparable performance with only 5\\%-0.4\\% of the model\nparameter size and reducing the query latency by approximately 99\\% compared to\nconcurrent approaches. This makes TreeHop a faster and more cost-effective\nsolution for deployment in a range of knowledge-intensive applications. For\nreproducibility purposes, codes and data are available here:\nhttps://github.com/allen-li1231/TreeHop-RAG.", "published": "2025-04-28 01:56:31", "link": "http://arxiv.org/abs/2504.20114v2", "categories": ["cs.IR", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Fast LDL factorization for dense and sparse symmetric matrices over an arbitrary field", "abstract": "While existing algorithms may be used to solve a linear system over a general\nfield in matrix-multiplication time, the complexity of constructing a symmetric\ntriangular factorization (LDL) has received relatively little formal study. The\nLDL factorization is a common tool for factorization of symmetric matrices,\nand, unlike orthogonal counterparts, generalizes to an arbitrary field. We\nprovide algorithms for dense and sparse LDL factorization and for dense LU\nfactorization that aim to minimize complexity for factorization over a general\nfield. For LU of an $m\\times n$ rank $R$ matrix, we obtain an algorithm with\ncomplexity $O(mnR^{\\omega-2})$, where $\\omega$ is the matrix multiplication\ncomplexity exponent. For LDL of an $n\\times n$ matrix, we give an algorithm\nwith complexity $O(n^\\omega)$ and for a sparse matrix corresponding to a graph\nwith treewidth $\\tau$, we obtain $O(n\\tau^{\\omega-1})$. Our sparse LDL\nalgorithm is based on an adaptation of the null-space method for solving saddle\npoint systems of equations, which may be of independent interest.", "published": "2025-04-28 23:26:50", "link": "http://arxiv.org/abs/2504.20305v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A comparison of generative deep learning methods for multivariate angular simulation", "abstract": "With the recent development of new geometric and angular-radial frameworks\nfor multivariate extremes, reliably simulating from angular variables in\nmoderate-to-high dimensions is of increasing importance. Empirical approaches\nhave the benefit of simplicity, and work reasonably well in low dimensions, but\nas the number of variables increases, they can lack the required flexibility\nand scalability. Classical parametric models for angular variables, such as the\nvon Mises-Fisher (vMF) distribution, provide an alternative. Exploiting\nmixtures of vMF distributions increases their flexibility, but there are cases\nwhere even this is not sufficient to capture the intricate features that can\narise in data. Owing to their flexibility, generative deep learning methods are\nable to capture complex data structures; they therefore have the potential to\nbe useful in the simulation of angular variables. In this paper, we explore a\nrange of deep learning approaches for this task, including generative\nadversarial networks, normalizing flows and flow matching. We assess their\nperformance via a range of metrics and make comparisons to the more classical\napproach of using a mixture of vMF distributions. The methods are also applied\nto a metocean data set, demonstrating their applicability to real-world,\ncomplex data structures.", "published": "2025-04-28 16:38:58", "link": "http://arxiv.org/abs/2504.21505v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets", "abstract": "Retrieval-Augmented Generation (RAG) has advanced significantly in recent\nyears. The complexity of RAG systems, which involve multiple components-such as\nindexing, retrieval, and generation-along with numerous other parameters, poses\nsubstantial challenges for systematic evaluation and quality enhancement.\nPrevious research highlights that evaluating RAG systems is essential for\ndocumenting advancements, comparing configurations, and identifying effective\napproaches for domain-specific applications. This study systematically reviews\n63 academic articles to provide a comprehensive overview of state-of-the-art\nRAG evaluation methodologies, focusing on four key areas: datasets, retrievers,\nindexing and databases, and the generator component. We observe the feasibility\nof an automated evaluation approach for each component of a RAG system,\nleveraging an LLM capable of both generating evaluation datasets and conducting\nevaluations. In addition, we found that further practical research is essential\nto provide companies with clear guidance on the do's and don'ts of implementing\nand evaluating RAG systems. By synthesizing evaluation approaches for key RAG\ncomponents and emphasizing the creation and adaptation of domain-specific\ndatasets for benchmarking, we contribute to the advancement of systematic\nevaluation methods and the improvement of evaluation rigor for RAG systems.\nFurthermore, by examining the interplay between automated approaches leveraging\nLLMs and human judgment, we contribute to the ongoing discourse on balancing\nautomation and human input, clarifying their respective contributions,\nlimitations, and challenges in achieving robust and reliable evaluations.", "published": "2025-04-28 08:22:19", "link": "http://arxiv.org/abs/2504.20119v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation", "abstract": "Recently, numerous community search methods for large graphs have been\nproposed, at the core of which is defining and measuring cohesion. This paper\nexperimentally evaluates the effectiveness of these community search algorithms\nw.r.t. cohesiveness in the context of online social networks. Social\ncommunities are formed and developed under the influence of group cohesion\ntheory, which has been extensively studied in social psychology. However,\ncurrent generic methods typically measure cohesiveness using structural or\nattribute-based approaches and overlook domain-specific concepts such as group\ncohesion. We introduce five novel psychology-informed cohesiveness measures,\nbased on the concept of group cohesion from social psychology, and propose a\nnovel framework called CHASE for evaluating eight representative community\nsearch algorithms w.r.t. these measures on online social networks. Our analysis\nreveals that there is no clear correlation between structural and psychological\ncohesiveness, and no algorithm effectively identifies psychologically cohesive\ncommunities in online social networks. This study provides new insights that\ncould guide the development of future community search methods.", "published": "2025-04-28 05:08:29", "link": "http://arxiv.org/abs/2504.19489v4", "categories": ["cs.IR", "cs.SI"], "primary_category": "cs.IR"}
{"title": "Hierarchical Uncertainty-Aware Graph Neural Network", "abstract": "Recent research on graph neural networks (GNNs) has explored mechanisms for\ncapturing local uncertainty and exploiting graph hierarchies to mitigate data\nsparsity and leverage structural properties. However, the synergistic\nintegration of these two approaches remains underexplored. This work introduces\na novel architecture, the Hierarchical Uncertainty-Aware Graph Neural Network\n(HU-GNN), which unifies multi-scale representation learning, principled\nuncertainty estimation, and self-supervised embedding diversity within a single\nend-to-end framework. Specifically, HU-GNN adaptively forms node clusters and\nestimates uncertainty at multiple structural scales from individual nodes to\nhigher levels. These uncertainty estimates guide a robust message-passing\nmechanism and attention weighting, effectively mitigating noise and adversarial\nperturbations while preserving predictive accuracy on semi-supervised\nclassification tasks. We also offer key theoretical contributions, including a\nprobabilistic formulation, rigorous uncertainty-calibration guarantees, and\nformal robustness bounds. Extensive experiments on standard benchmarks\ndemonstrate that our model achieves state-of-the-art robustness and\ninterpretability.", "published": "2025-04-28 14:22:18", "link": "http://arxiv.org/abs/2504.19820v2", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "From Freshness to Effectiveness: Goal-Oriented Sampling for Remote Decision Making", "abstract": "Data freshness, measured by Age of Information (AoI), is highly relevant in\nnetworked applications such as Vehicle to Everything (V2X), smart health\nsystems, and Industrial Internet of Things (IIoT). Yet, freshness alone does\nnot equate to informativeness. In decision-critical settings, some stale data\nmay prove more valuable than fresh updates. To explore this nuance, we move\nbeyond AoI-centric policies and investigate how data staleness impacts\ndecision-making under data-staleness-induced uncertainty. We pose a central\nquestion: What is the value of information, when freshness fades, and only its\npower to shape remote decisions remains? To capture this endured value, we\npropose AR-MDP, an Age-aware Remote Markov Decision Process framework, which\nco-designs optimal sampling and remote decision-making under a sampling\nfrequency constraint and random delay. To efficiently solve this problem, we\ndesign a new two-stage hierarchical algorithm namely Quick\nBellman-Linear-Program (QuickBLP), where the first stage involves solving the\nDinkelbach root of a Bellman variant and the second stage involves solving a\nstreamlined linear program (LP). For the tricky first stage, we propose a new\nOne-layer Primal-Dinkelbach Synchronous Iteration (OnePDSI) method, which\novercomes the re-convergence and non-expansive divergence present in existing\nper-sample multi-layer algorithms. Through rigorous convergence analysis of our\nproposed algorithms, we establish that the worst-case optimality gap in OnePDSI\nexhibits exponential decay with respect to iteration $K$ at a rate of\n$\\mathcal{O}(\\frac{1}{R^K})$. Through sensitivity analysis, we derive a\nthreshold for the sampling frequency, beyond which additional sampling does not\nyield further gains in decision-making. Simulation results validate our\nanalyses.", "published": "2025-04-28 06:17:09", "link": "http://arxiv.org/abs/2504.19507v2", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies", "abstract": "In this paper we introduce ResearchCodeAgent, a novel multi-agent system\nleveraging large language models (LLMs) agents to automate the codification of\nresearch methodologies described in machine learning literature. The system\nbridges the gap between high-level research concepts and their practical\nimplementation, allowing researchers auto-generating code of existing research\npapers for benchmarking or building on top-of existing methods specified in the\nliterature with availability of partial or complete starter code.\nResearchCodeAgent employs a flexible agent architecture with a comprehensive\naction suite, enabling context-aware interactions with the research\nenvironment. The system incorporates a dynamic planning mechanism, utilizing\nboth short and long-term memory to adapt its approach iteratively. We evaluate\nResearchCodeAgent on three distinct machine learning tasks with distinct task\ncomplexity and representing different parts of the ML pipeline: data\naugmentation, optimization, and data batching. Our results demonstrate the\nsystem's effectiveness and generalizability, with 46.9% of generated code being\nhigh-quality and error-free, and 25% showing performance improvements over\nbaseline implementations. Empirical analysis shows an average reduction of\n57.9% in coding time compared to manual implementation. We observe higher gains\nfor more complex tasks. ResearchCodeAgent represents a significant step towards\nautomating the research implementation process, potentially accelerating the\npace of machine learning research.", "published": "2025-04-28 07:18:45", "link": "http://arxiv.org/abs/2504.20117v2", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.SE"}
{"title": "Compositional Square Roots of $\\exp(x)$ and $1+x^2$", "abstract": "Our work began as an effort to understand calculations by Morris & Szekeres\n(1961) and Walker (1991) regarding fractional iteration.", "published": "2025-04-28 17:19:24", "link": "http://arxiv.org/abs/2504.19999v2", "categories": ["math.GM", "cs.DM", "39B12 (Primary) 11B37, 26A18, 39-08, 39B22, 65D20 (Secondary)"], "primary_category": "math.GM"}
