{"title": "Dynamic Pricing for Real Estate", "abstract": "We study a mathematical model for the optimization of the price of real\nestate (RE). This model can be characterised by a limited amount of goods,\nfixed sales horizon and presence of intermediate sales and revenue goals. We\ndevelop it as an enhancement and upgrade of the model presented by Besbes and\nMaglaras now also taking into account variable demand, time value of money, and\ngrowth of the objective value of Real Estate with the development stage.", "published": "2024-08-22 17:08:23", "link": "http://arxiv.org/abs/2408.12553v1", "categories": ["q-fin.MF", "econ.TH", "q-fin.CP", "q-fin.TR"], "primary_category": "q-fin.MF"}
{"title": "EX-DRL: Hedging Against Heavy Losses with EXtreme Distributional Reinforcement Learning", "abstract": "Recent advancements in Distributional Reinforcement Learning (DRL) for\nmodeling loss distributions have shown promise in developing hedging strategies\nin derivatives markets. A common approach in DRL involves learning the\nquantiles of loss distributions at specified levels using Quantile Regression\n(QR). This method is particularly effective in option hedging due to its direct\nquantile-based risk assessment, such as Value at Risk (VaR) and Conditional\nValue at Risk (CVaR). However, these risk measures depend on the accurate\nestimation of extreme quantiles in the loss distribution's tail, which can be\nimprecise in QR-based DRL due to the rarity and extremity of tail data, as\nhighlighted in the literature. To address this issue, we propose EXtreme DRL\n(EX-DRL), which enhances extreme quantile prediction by modeling the tail of\nthe loss distribution with a Generalized Pareto Distribution (GPD). This method\nintroduces supplementary data to mitigate the scarcity of extreme quantile\nobservations, thereby improving estimation accuracy through QR. Comprehensive\nexperiments on gamma hedging options demonstrate that EX-DRL improves existing\nQR-based models by providing more precise estimates of extreme quantiles,\nthereby improving the computation and reliability of risk metrics for complex\nfinancial risk management.", "published": "2024-08-22 14:41:49", "link": "http://arxiv.org/abs/2408.12446v2", "categories": ["q-fin.RM", "cs.LG", "q-fin.ST"], "primary_category": "q-fin.RM"}
{"title": "Optimizing Performance: How Compact Models Match or Exceed GPT's Classification Capabilities through Fine-Tuning", "abstract": "In this paper, we demonstrate that non-generative, small-sized models such as\nFinBERT and FinDRoBERTa, when fine-tuned, can outperform GPT-3.5 and GPT-4\nmodels in zero-shot learning settings in sentiment analysis for financial news.\nThese fine-tuned models show comparable results to GPT-3.5 when it is\nfine-tuned on the task of determining market sentiment from daily financial\nnews summaries sourced from Bloomberg. To fine-tune and compare these models,\nwe created a novel database, which assigns a market score to each piece of news\nwithout human interpretation bias, systematically identifying the mentioned\ncompanies and analyzing whether their stocks have gone up, down, or remained\nneutral. Furthermore, the paper shows that the assumptions of Condorcet's Jury\nTheorem do not hold suggesting that fine-tuned small models are not independent\nof the fine-tuned GPT models, indicating behavioural similarities. Lastly, the\nresulted fine-tuned models are made publicly available on HuggingFace,\nproviding a resource for further research in financial sentiment analysis and\ntext classification.", "published": "2024-08-22 09:10:43", "link": "http://arxiv.org/abs/2409.11408v1", "categories": ["cs.CL", "q-fin.ST"], "primary_category": "cs.CL"}
{"title": "Enhancing Causal Discovery in Financial Networks with Piecewise Quantile Regression", "abstract": "Financial networks can be constructed using statistical dependencies found\nwithin the price series of speculative assets. Across the various methods used\nto infer these networks, there is a general reliance on predictive modelling to\ncapture cross-correlation effects. These methods usually model the flow of\nmean-response information, or the propagation of volatility and risk within the\nmarket. Such techniques, though insightful, don't fully capture the broader\ndistribution-level causality that is possible within speculative markets. This\npaper introduces a novel approach, combining quantile regression with a\npiecewise linear embedding scheme - allowing us to construct causality networks\nthat identify the complex tail interactions inherent to financial markets.\nApplying this method to 260 cryptocurrency return series, we uncover\nsignificant tail-tail causal effects and substantial causal asymmetry. We\nidentify a propensity for coins to be self-influencing, with comparatively\nsparse cross variable effects. Assessing all link types in conjunction, Bitcoin\nstands out as the primary influencer - a nuance that is missed in conventional\nlinear mean-response analyses. Our findings introduce a comprehensive framework\nfor modelling distributional causality, paving the way towards more holistic\nrepresentations of causality in financial markets.", "published": "2024-08-22 08:39:09", "link": "http://arxiv.org/abs/2408.12210v1", "categories": ["q-fin.ST", "econ.EM", "physics.soc-ph"], "primary_category": "q-fin.ST"}
{"title": "Preference-Guided Reflective Sampling for Aligning Language Models", "abstract": "Iterative data generation and model re-training can effectively align large\nlanguage models(LLMs) to human preferences. The process of data sampling is\ncrucial, as it significantly influences the success of policy improvement.\nRepeated random sampling is a widely used method that independently queries the\nmodel multiple times to generate outputs. In this work, we propose a more\neffective sampling method, named Preference-Guided Reflective Sampling (PRS).\nUnlike random sampling, PRS employs a tree-based generation framework to enable\nmore efficient sampling. It leverages adaptive self-refinement techniques to\nbetter explore the sampling space. By specifying user preferences in natural\nlanguage, PRS can further optimize response generation according to these\npreferences. As a result, PRS can align models to diverse user preferences. Our\nexperiments demonstrate that PRS generates higher-quality responses with\nsignificantly higher rewards. On AlpacaEval and Arena-Hard, PRS substantially\noutperforms repeated random sampling in best-of-$N$ sampling. Moreover, PRS\nshows strong performance when applied in iterative offline RL training.", "published": "2024-08-22 07:18:46", "link": "http://arxiv.org/abs/2408.12163v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FIRST: Teach A Reliable Large Language Model Through Efficient\n  Trustworthy Distillation", "abstract": "Large language models (LLMs) have become increasingly prevalent in our daily\nlives, leading to an expectation for LLMs to be trustworthy -- - both accurate\nand well-calibrated (the prediction confidence should align with its ground\ntruth correctness likelihood). Nowadays, fine-tuning has become the most\npopular method for adapting a model to practical usage by significantly\nincreasing accuracy on downstream tasks. Despite the great accuracy it\nachieves, we found fine-tuning is still far away from satisfactory\ntrustworthiness due to \"tuning-induced mis-calibration\". In this paper, we\ndelve deeply into why and how mis-calibration exists in fine-tuned models, and\nhow distillation can alleviate the issue. Then we further propose a brand new\nmethod named Efficient Trustworthy Distillation (FIRST), which utilizes a small\nportion of teacher's knowledge to obtain a reliable language model in a\ncost-efficient way. Specifically, we identify the \"concentrated knowledge\"\nphenomenon during distillation, which can significantly reduce the\ncomputational burden. Then we apply a \"trustworthy maximization\" process to\noptimize the utilization of this small portion of concentrated knowledge before\ntransferring it to the student. Experimental results demonstrate the\neffectiveness of our method, where better accuracy (+2.3%) and less\nmis-calibration (-10%) are achieved on average across both in-domain and\nout-of-domain scenarios, indicating better trustworthiness.", "published": "2024-08-22 07:31:00", "link": "http://arxiv.org/abs/2408.12168v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revisiting the Phenomenon of Syntactic Complexity Convergence on German\n  Dialogue Data", "abstract": "We revisit the phenomenon of syntactic complexity convergence in\nconversational interaction, originally found for English dialogue, which has\ntheoretical implication for dialogical concepts such as mutual understanding.\nWe use a modified metric to quantify syntactic complexity based on dependency\nparsing. The results show that syntactic complexity convergence can be\nstatistically confirmed in one of three selected German datasets that were\nanalysed. Given that the dataset which shows such convergence is much larger\nthan the other two selected datasets, the empirical results indicate a certain\ndegree of linguistic generality of syntactic complexity convergence in\nconversational interaction. We also found a different type of syntactic\ncomplexity convergence in one of the datasets while further investigation is\nstill necessary.", "published": "2024-08-22 07:49:41", "link": "http://arxiv.org/abs/2408.12177v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models as Foundations for Next-Gen Dense Retrieval: A\n  Comprehensive Empirical Assessment", "abstract": "Pretrained language models like BERT and T5 serve as crucial backbone\nencoders for dense retrieval. However, these models often exhibit limited\ngeneralization capabilities and face challenges in improving in domain\naccuracy. Recent research has explored using large language models (LLMs) as\nretrievers, achieving SOTA performance across various tasks. Despite these\nadvancements, the specific benefits of LLMs over traditional retrievers and the\nimpact of different LLM configurations, such as parameter sizes, pretraining\nduration, and alignment processes on retrieval tasks remain unclear. In this\nwork, we conduct a comprehensive empirical study on a wide range of retrieval\ntasks, including in domain accuracy, data efficiency, zero shot generalization,\nlengthy retrieval, instruction based retrieval, and multi task learning. We\nevaluate over 15 different backbone LLMs and non LLMs. Our findings reveal that\nlarger models and extensive pretraining consistently enhance in domain accuracy\nand data efficiency. Additionally, larger models demonstrate significant\npotential in zero shot generalization, lengthy retrieval, instruction based\nretrieval, and multi task learning. These results underscore the advantages of\nLLMs as versatile and effective backbone encoders in dense retrieval, providing\nvaluable insights for future research and development in this field.", "published": "2024-08-22 08:16:07", "link": "http://arxiv.org/abs/2408.12194v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Factuality in Large Language Models via Decoding-Time\n  Hallucinatory and Truthful Comparators", "abstract": "Despite their remarkable capabilities, Large Language Models (LLMs) are prone\nto generate responses that contradict verifiable facts, i.e., unfaithful\nhallucination content. Existing efforts generally focus on optimizing model\nparameters or editing semantic representations, which compromise the internal\nfactual knowledge of target LLMs. In addition, hallucinations typically exhibit\nmultifaceted patterns in downstream tasks, limiting the model's holistic\nperformance across tasks. In this paper, we propose a Comparator-driven\nDecoding-Time (CDT) framework to alleviate the response hallucination. Firstly,\nwe construct hallucinatory and truthful comparators with multi-task fine-tuning\nsamples. In this case, we present an instruction prototype-guided mixture of\nexperts strategy to enhance the ability of the corresponding comparators to\ncapture different hallucination or truthfulness patterns in distinct task\ninstructions. CDT constrains next-token predictions to factuality-robust\ndistributions by contrasting the logit differences between the target LLMs and\nthese comparators. Systematic experiments on multiple downstream tasks show\nthat our framework can significantly improve the model performance and response\nfactuality.", "published": "2024-08-22 12:00:31", "link": "http://arxiv.org/abs/2408.12325v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CLEANANERCorp: Identifying and Correcting Incorrect Labels in the\n  ANERcorp Dataset", "abstract": "Label errors are a common issue in machine learning datasets, particularly\nfor tasks such as Named Entity Recognition. Such label errors might hurt model\ntraining, affect evaluation results, and lead to an inaccurate assessment of\nmodel performance. In this study, we dived deep into one of the widely adopted\nArabic NER benchmark datasets (ANERcorp) and found a significant number of\nannotation errors, missing labels, and inconsistencies. Therefore, in this\nstudy, we conducted empirical research to understand these errors, correct them\nand propose a cleaner version of the dataset named CLEANANERCorp. CLEANANERCorp\nwill serve the research community as a more accurate and consistent benchmark.", "published": "2024-08-22 12:59:05", "link": "http://arxiv.org/abs/2408.12362v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Positional Description for Numerical Normalization", "abstract": "We present a Positional Description Scheme (PDS) tailored for digit\nsequences, integrating placeholder value information for each digit. Given the\nstructural limitations of subword tokenization algorithms, language models\nencounter critical Text Normalization (TN) challenges when handling numerical\ntasks. Our schema addresses this challenge through straightforward\npre-processing, preserving the model architecture while significantly\nsimplifying number normalization, rendering the problem tractable. This\nsimplifies the task and facilitates more compact production-ready models\ncapable of learning from smaller datasets. Furthermore, our investigations\nreveal that PDS enhances the arithmetic processing capabilities of language\nmodels, resulting in a relative accuracy improvement of 23% to 51% on complex\narithmetic tasks. We demonstrate that PDS effectively mitigates fatal numerical\nnormalization errors in neural models, requiring only a modest amount of\ntraining data without rule-based Finite State Transducers (FST). We demonstrate\nthat PDS is essential for both the Text-To-Speech and Speech Recognition text\nprocessing, enabling effective TN under production constraints.", "published": "2024-08-22 14:24:20", "link": "http://arxiv.org/abs/2408.12430v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Multi-hop Reasoning through Knowledge Erasure in Large\n  Language Model Editing", "abstract": "Large language models (LLMs) face challenges with internal knowledge\ninaccuracies and outdated information. Knowledge editing has emerged as a\npivotal approach to mitigate these issues. Although current knowledge editing\ntechniques exhibit promising performance in single-hop reasoning tasks, they\nshow limitations when applied to multi-hop reasoning. Drawing on cognitive\nneuroscience and the operational mechanisms of LLMs, we hypothesize that the\nresidual single-hop knowledge after editing causes edited models to revert to\ntheir original answers when processing multi-hop questions, thereby undermining\ntheir performance in multihop reasoning tasks. To validate this hypothesis, we\nconduct a series of experiments that empirically confirm our assumptions.\nBuilding on the validated hypothesis, we propose a novel knowledge editing\nmethod that incorporates a Knowledge Erasure mechanism for Large language model\nEditing (KELE). Specifically, we design an erasure function for residual\nknowledge and an injection function for new knowledge. Through joint\noptimization, we derive the optimal recall vector, which is subsequently\nutilized within a rank-one editing framework to update the parameters of\ntargeted model layers. Extensive experiments on GPT-J and GPT-2 XL demonstrate\nthat KELE substantially enhances the multi-hop reasoning capability of edited\nLLMs.", "published": "2024-08-22 14:53:33", "link": "http://arxiv.org/abs/2408.12456v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Evaluating and Building Versatile Large Language Models for\n  Medicine", "abstract": "In this study, we present MedS-Bench, a comprehensive benchmark designed to\nevaluate the performance of large language models (LLMs) in clinical contexts.\nUnlike existing benchmarks that focus on multiple-choice question answering,\nMedS-Bench spans 11 high-level clinical tasks, including clinical report\nsummarization, treatment recommendations, diagnosis, named entity recognition,\nand medical concept explanation, among others. We evaluated six leading LLMs,\ne.g., MEDITRON, Mistral, InternLM 2, Llama 3, GPT-4, and Claude-3.5 using\nfew-shot prompting, and found that even the most sophisticated models struggle\nwith these complex tasks. To address these limitations, we developed MedS-Ins,\na large-scale instruction tuning dataset for medicine. MedS-Ins comprises 58\nmedically oriented language corpora, totaling 13.5 million samples across 122\ntasks. To demonstrate the dataset's utility, we conducted a proof-of-concept\nexperiment by performing instruction tuning on a lightweight, open-source\nmedical language model. The resulting model, MMedIns-Llama 3, significantly\noutperformed existing models across nearly all clinical tasks. To promote\nfurther advancements in the application of LLMs to clinical challenges, we have\nmade the MedS-Ins dataset fully accessible and invite the research community to\ncontribute to its expansion.Additionally, we have launched a dynamic\nleaderboard for MedS-Bench, which we plan to regularly update the test set to\ntrack progress and enhance the adaptation of general LLMs to the medical\ndomain. Leaderboard: https://henrychur.github.io/MedS-Bench/. Github:\nhttps://github.com/MAGIC-AI4Med/MedS-Ins.", "published": "2024-08-22 17:01:34", "link": "http://arxiv.org/abs/2408.12547v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controllable Text Generation for Large Language Models: A Survey", "abstract": "In Natural Language Processing (NLP), Large Language Models (LLMs) have\ndemonstrated high text generation quality. However, in real-world applications,\nLLMs must meet increasingly complex requirements. Beyond avoiding misleading or\ninappropriate content, LLMs are also expected to cater to specific user needs,\nsuch as imitating particular writing styles or generating text with poetic\nrichness. These varied demands have driven the development of Controllable Text\nGeneration (CTG) techniques, which ensure that outputs adhere to predefined\ncontrol conditions--such as safety, sentiment, thematic consistency, and\nlinguistic style--while maintaining high standards of helpfulness, fluency, and\ndiversity.\n  This paper systematically reviews the latest advancements in CTG for LLMs,\noffering a comprehensive definition of its core concepts and clarifying the\nrequirements for control conditions and text quality. We categorize CTG tasks\ninto two primary types: content control and attribute control. The key methods\nare discussed, including model retraining, fine-tuning, reinforcement learning,\nprompt engineering, latent space manipulation, and decoding-time intervention.\nWe analyze each method's characteristics, advantages, and limitations,\nproviding nuanced insights for achieving generation control. Additionally, we\nreview CTG evaluation methods, summarize its applications across domains, and\naddress key challenges in current research, including reduced fluency and\npracticality. We also propose several appeals, such as placing greater emphasis\non real-world applications in future research. This paper aims to offer\nvaluable guidance to researchers and developers in the field. Our reference\nlist and Chinese version are open-sourced at\nhttps://github.com/IAAR-Shanghai/CTGSurvey.", "published": "2024-08-22 17:59:04", "link": "http://arxiv.org/abs/2408.12599v1", "categories": ["cs.CL", "A.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Towards Estimating Personal Values in Song Lyrics", "abstract": "Most music widely consumed in Western Countries contains song lyrics, with\nU.S. samples reporting almost all of their song libraries contain lyrics. In\nparallel, social science theory suggests that personal values - the abstract\ngoals that guide our decisions and behaviors - play an important role in\ncommunication: we share what is important to us to coordinate efforts, solve\nproblems and meet challenges. Thus, the values communicated in song lyrics may\nbe similar or different to those of the listener, and by extension affect the\nlistener's reaction to the song. This suggests that working towards automated\nestimation of values in lyrics may assist in downstream MIR tasks, in\nparticular, personalization. However, as highly subjective text, song lyrics\npresent a challenge in terms of sampling songs to be annotated, annotation\nmethods, and in choosing a method for aggregation. In this project, we take a\nperspectivist approach, guided by social science theory, to gathering\nannotations, estimating their quality, and aggregating them. We then compare\naggregated ratings to estimates based on pre-trained sentence/word embedding\nmodels by employing a validated value dictionary. We discuss conceptually\n'fuzzy' solutions to sampling and annotation challenges, promising initial\nresults in annotation quality and in automated estimations, and future\ndirections.", "published": "2024-08-22 19:22:55", "link": "http://arxiv.org/abs/2408.12694v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Macro-Queries: An Exploration into Guided Chart Generation from High\n  Level Prompts", "abstract": "This paper explores the intersection of data visualization and Large Language\nModels (LLMs). Driven by the need to make a broader range of data visualization\ntypes accessible for novice users, we present a guided LLM-based pipeline\ndesigned to transform data, guided by high-level user questions (referred to as\nmacro-queries), into a diverse set of useful visualizations. This approach\nleverages various prompting techniques, fine-tuning inspired by Abela's Chart\nTaxonomy, and integrated SQL tool usage.", "published": "2024-08-22 20:35:42", "link": "http://arxiv.org/abs/2408.12726v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Literary Texts by LLMs: A Case Study of Ancient Chinese\n  Poetry", "abstract": "The birth and rapid development of large language models (LLMs) have caused\nquite a stir in the field of literature. Once considered unattainable, AI's\nrole in literary creation is increasingly becoming a reality. In genres such as\npoetry, jokes, and short stories, numerous AI tools have emerged, offering\nrefreshing new perspectives. However, it's difficult to further improve the\nquality of these works. This is primarily because understanding and\nappreciating a good literary work involves a considerable threshold, such as\nknowledge of literary theory, aesthetic sensibility, interdisciplinary\nknowledge. Therefore, authoritative data in this area is quite lacking.\nAdditionally, evaluating literary works is often complex and hard to fully\nquantify, which directly hinders the further development of AI creation.\n  To address this issue, this paper attempts to explore the mysteries of\nliterary texts from the perspective of LLMs, using ancient Chinese poetry as an\nexample for experimentation. First, we collected a variety of ancient poems\nfrom different sources and had experts annotate a small portion of them. Then,\nwe designed a range of comprehension metrics based on LLMs to evaluate all\nthese poems. Finally, we analyzed the correlations and differences between\nvarious poem collections to identify literary patterns. Through our\nexperiments, we observed a series of enlightening phenomena that provide\ntechnical support for the future development of high-level literary creation\nbased on LLMs.", "published": "2024-08-22 04:25:06", "link": "http://arxiv.org/abs/2409.00060v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NUS-Emo at SemEval-2024 Task 3: Instruction-Tuning LLM for Multimodal\n  Emotion-Cause Analysis in Conversations", "abstract": "This paper describes the architecture of our system developed for Task 3 of\nSemEval-2024: Multimodal Emotion-Cause Analysis in Conversations. Our project\ntargets the challenges of subtask 2, dedicated to Multimodal Emotion-Cause Pair\nExtraction with Emotion Category (MECPE-Cat), and constructs a dual-component\nsystem tailored to the unique challenges of this task. We divide the task into\ntwo subtasks: emotion recognition in conversation (ERC) and emotion-cause pair\nextraction (ECPE). To address these subtasks, we capitalize on the abilities of\nLarge Language Models (LLMs), which have consistently demonstrated\nstate-of-the-art performance across various natural language processing tasks\nand domains. Most importantly, we design an approach of emotion-cause-aware\ninstruction-tuning for LLMs, to enhance the perception of the emotions with\ntheir corresponding causal rationales. Our method enables us to adeptly\nnavigate the complexities of MECPE-Cat, achieving a weighted average 34.71% F1\nscore of the task, and securing the 2nd rank on the leaderboard. The code and\nmetadata to reproduce our experiments are all made publicly available.", "published": "2024-08-22 08:34:39", "link": "http://arxiv.org/abs/2501.17261v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aligning (Medical) LLMs for (Counterfactual) Fairness", "abstract": "Large Language Models (LLMs) have emerged as promising solutions for a\nvariety of medical and clinical decision support applications. However, LLMs\nare often subject to different types of biases, which can lead to unfair\ntreatment of individuals, worsening health disparities, and reducing trust in\nAI-augmented medical tools. Aiming to address this important issue, in this\nstudy, we present a new model alignment approach for aligning LLMs using a\npreference optimization method within a knowledge distillation framework. Prior\nto presenting our proposed method, we first use an evaluation framework to\nconduct a comprehensive (largest to our knowledge) empirical evaluation to\nreveal the type and nature of existing biases in LLMs used for medical\napplications. We then offer a bias mitigation technique to reduce the unfair\npatterns in LLM outputs across different subgroups identified by the protected\nattributes. We show that our mitigation method is effective in significantly\nreducing observed biased patterns. Our code is publicly available at\n\\url{https://github.com/healthylaife/FairAlignmentLLM}.", "published": "2024-08-22 01:11:27", "link": "http://arxiv.org/abs/2408.12055v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evidence-backed Fact Checking using RAG and Few-Shot In-Context Learning\n  with LLMs", "abstract": "Given the widespread dissemination of misinformation on social media,\nimplementing fact-checking mechanisms for online claims is essential. Manually\nverifying every claim is very challenging, underscoring the need for an\nautomated fact-checking system. This paper presents our system designed to\naddress this issue. We utilize the Averitec dataset (Schlichtkrull et al.,\n2023) to assess the performance of our fact-checking system. In addition to\nveracity prediction, our system provides supporting evidence, which is\nextracted from the dataset. We develop a Retrieve and Generate (RAG) pipeline\nto extract relevant evidence sentences from a knowledge base, which are then\ninputted along with the claim into a large language model (LLM) for\nclassification. We also evaluate the few-shot In-Context Learning (ICL)\ncapabilities of multiple LLMs. Our system achieves an 'Averitec' score of 0.33,\nwhich is a 22% absolute improvement over the baseline. Our Code is publicly\navailable on\nhttps://github.com/ronit-singhal/evidence-backed-fact-checking-using-rag-and-few-shot-in-context-learning-with-llms.", "published": "2024-08-22 01:42:34", "link": "http://arxiv.org/abs/2408.12060v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ConflictBank: A Benchmark for Evaluating the Influence of Knowledge\n  Conflicts in LLM", "abstract": "Large language models (LLMs) have achieved impressive advancements across\nnumerous disciplines, yet the critical issue of knowledge conflicts, a major\nsource of hallucinations, has rarely been studied. Only a few research explored\nthe conflicts between the inherent knowledge of LLMs and the retrieved\ncontextual knowledge. However, a thorough assessment of knowledge conflict in\nLLMs is still missing. Motivated by this research gap, we present ConflictBank,\nthe first comprehensive benchmark developed to systematically evaluate\nknowledge conflicts from three aspects: (i) conflicts encountered in retrieved\nknowledge, (ii) conflicts within the models' encoded knowledge, and (iii) the\ninterplay between these conflict forms. Our investigation delves into four\nmodel families and twelve LLM instances, meticulously analyzing conflicts\nstemming from misinformation, temporal discrepancies, and semantic divergences.\nBased on our proposed novel construction framework, we create 7,453,853\nclaim-evidence pairs and 553,117 QA pairs. We present numerous findings on\nmodel scale, conflict causes, and conflict types. We hope our ConflictBank\nbenchmark will help the community better understand model behavior in conflicts\nand develop more reliable LLMs.", "published": "2024-08-22 02:33:13", "link": "http://arxiv.org/abs/2408.12076v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "High-Quality Data Augmentation for Low-Resource NMT: Combining a\n  Translation Memory, a GAN Generator, and Filtering", "abstract": "Back translation, as a technique for extending a dataset, is widely used by\nresearchers in low-resource language translation tasks. It typically translates\nfrom the target to the source language to ensure high-quality translation\nresults. This paper proposes a novel way of utilizing a monolingual corpus on\nthe source side to assist Neural Machine Translation (NMT) in low-resource\nsettings. We realize this concept by employing a Generative Adversarial Network\n(GAN), which augments the training data for the discriminator while mitigating\nthe interference of low-quality synthetic monolingual translations with the\ngenerator. Additionally, this paper integrates Translation Memory (TM) with\nNMT, increasing the amount of data available to the generator. Moreover, we\npropose a novel procedure to filter the synthetic sentence pairs during the\naugmentation process, ensuring the high quality of the data.", "published": "2024-08-22 02:35:47", "link": "http://arxiv.org/abs/2408.12079v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RoVRM: A Robust Visual Reward Model Optimized via Auxiliary Textual\n  Preference Data", "abstract": "Large vision-language models (LVLMs) often fail to align with human\npreferences, leading to issues like generating misleading content without\nproper visual context (also known as hallucination). A promising solution to\nthis problem is using human-preference alignment techniques, such as best-of-n\nsampling and reinforcement learning. However, these techniques face the\ndifficulty arising from the scarcity of visual preference data, which is\nrequired to train a visual reward model (VRM). In this work, we continue the\nline of research. We present a Robust Visual Reward Model (RoVRM) which\nimproves human-preference alignment for LVLMs. RoVRM leverages auxiliary\ntextual preference data through a three-phase progressive training and optimal\ntransport-based preference data selection to effectively mitigate the scarcity\nof visual preference data. We experiment with RoVRM on the commonly used\nvision-language tasks based on the LLaVA-1.5-7B and -13B models. Experimental\nresults demonstrate that RoVRM consistently outperforms traditional VRMs.\nFurthermore, our three-phase progressive training and preference data selection\napproaches can yield consistent performance gains over ranking-based alignment\ntechniques, such as direct preference optimization.", "published": "2024-08-22 03:49:18", "link": "http://arxiv.org/abs/2408.12109v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders\n  Synthesized via Neuro-Symbolic LLM Agents", "abstract": "The clinical diagnosis of most mental disorders primarily relies on the\nconversations between psychiatrist and patient. The creation of such diagnostic\nconversation datasets is promising to boost the AI mental healthcare community.\nHowever, directly collecting the conversations in real diagnosis scenarios is\nnear impossible due to stringent privacy and ethical considerations. To address\nthis issue, we seek to synthesize diagnostic conversation by exploiting\nanonymized patient cases that are easier to access. Specifically, we design a\nneuro-symbolic multi-agent framework for synthesizing the diagnostic\nconversation of mental disorders with large language models. It takes patient\ncase as input and is capable of generating multiple diverse conversations with\none single patient case. The framework basically involves the interaction\nbetween a doctor agent and a patient agent, and generates conversations under\nsymbolic control via a dynamic diagnosis tree. By applying the proposed\nframework, we develop the largest Chinese mental disorders diagnosis dataset\nMDD-5k. This dataset is built upon 1000 real, anonymized patient cases by\ncooperating with Shanghai Mental Health Center and comprises 5000 high-quality\nlong conversations with diagnosis results and treatment opinions as labels. To\nthe best of our knowledge, it's also the first labeled dataset for Chinese\nmental disorders diagnosis. Human evaluation demonstrates the proposed MDD-5k\ndataset successfully simulates human-like diagnostic process of mental\ndisorders.", "published": "2024-08-22 05:59:47", "link": "http://arxiv.org/abs/2408.12142v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Implicit Sentiment Analysis Based on Chain of Thought Prompting", "abstract": "Implicit Sentiment Analysis (ISA) is a crucial research area in natural\nlanguage processing. Inspired by the idea of large language model Chain of\nThought (CoT), this paper introduces a Sentiment Analysis of Thinking (SAoT)\nframework. The framework first analyzes the implicit aspects and opinions in\nthe text using common sense and thinking chain capabilities. Then, it reflects\non the process of implicit sentiment analysis and finally deduces the polarity\nof sentiment. The model is evaluated on the SemEval 2014 dataset, consisting of\n1120 restaurant reviews and 638 laptop reviews. The experimental results\ndemonstrate that the utilization of the ERNIE-Bot-4+SAoT model yields a notable\nperformance improvement. Specifically, on the restaurant dataset, the F1 score\nreaches 75.27, accompanied by an ISA score of 66.29. Similarly, on the computer\ndataset, the F1 score achieves 76.50, while the ISA score amounts to 73.46.\nComparatively, the ERNIE-Bot-4+SAoT model surpasses the BERTAsp + SCAPt\nbaseline by an average margin of 47.99%.", "published": "2024-08-22 06:55:29", "link": "http://arxiv.org/abs/2408.12157v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reasoning Factual Knowledge in Structured Data with Large Language\n  Models", "abstract": "Large language models (LLMs) have made remarkable progress in various natural\nlanguage processing tasks as a benefit of their capability to comprehend and\nreason with factual knowledge. However, a significant amount of factual\nknowledge is stored in structured data, which possesses unique characteristics\nthat differ from the unstructured texts used for pretraining. This difference\ncan introduce imperceptible inference parameter deviations, posing challenges\nfor LLMs in effectively utilizing and reasoning with structured data to\naccurately infer factual knowledge. To this end, we propose a benchmark named\nStructFact, to evaluate the structural reasoning capabilities of LLMs in\ninferring factual knowledge. StructFact comprises 8,340 factual questions\nencompassing various tasks, domains, timelines, and regions. This benchmark\nallows us to investigate the capability of LLMs across five factual tasks\nderived from the unique characteristics of structural facts. Extensive\nexperiments on a set of LLMs with different training strategies reveal the\nlimitations of current LLMs in inferring factual knowledge from structured\ndata. We present this benchmark as a compass to navigate the strengths and\nweaknesses of LLMs in reasoning with structured data for knowledge-sensitive\ntasks, and to encourage advancements in related real-world applications. Please\nfind our code at https://github.com/EganGu/StructFact.", "published": "2024-08-22 08:05:09", "link": "http://arxiv.org/abs/2408.12188v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for\n  Automated Scoring of CEFR B2 Speaking Assessment Transcripts", "abstract": "Relying on human experts to evaluate CEFR speaking assessments in an\ne-learning environment creates scalability challenges, as it limits how quickly\nand widely assessments can be conducted. We aim to automate the evaluation of\nCEFR B2 English speaking assessments in e-learning environments from\nconversation transcripts. First, we evaluate the capability of leading open\nsource and commercial Large Language Models (LLMs) to score a candidate's\nperformance across various criteria in the CEFR B2 speaking exam in both global\nand India-specific contexts. Next, we create a new expert-validated,\nCEFR-aligned synthetic conversational dataset with transcripts that are rated\nat different assessment scores. In addition, new instruction-tuned datasets are\ndeveloped from the English Vocabulary Profile (up to CEFR B2 level) and the\nCEFR-SP WikiAuto datasets. Finally, using these new datasets, we perform\nparameter efficient instruction tuning of Mistral Instruct 7B v0.2 to develop a\nfamily of models called EvalYaks. Four models in this family are for assessing\nthe four sections of the CEFR B2 speaking exam, one for identifying the CEFR\nlevel of vocabulary and generating level-specific vocabulary, and another for\ndetecting the CEFR level of text and generating level-specific text. EvalYaks\nachieved an average acceptable accuracy of 96%, a degree of variation of 0.35\nlevels, and performed 3 times better than the next best model. This\ndemonstrates that a 7B parameter LLM instruction tuned with high-quality\nCEFR-aligned assessment data can effectively evaluate and score CEFR B2 English\nspeaking assessments, offering a promising solution for scalable, automated\nlanguage proficiency evaluation.", "published": "2024-08-22 08:57:31", "link": "http://arxiv.org/abs/2408.12226v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Language-agnostic Model of Child Language Acquisition", "abstract": "This work reimplements a recent semantic bootstrapping child-language\nacquisition model, which was originally designed for English, and trains it to\nlearn a new language: Hebrew. The model learns from pairs of utterances and\nlogical forms as meaning representations, and acquires both syntax and word\nmeanings simultaneously. The results show that the model mostly transfers to\nHebrew, but that a number of factors, including the richer morphology in\nHebrew, makes the learning slower and less robust. This suggests that a clear\ndirection for future work is to enable the model to leverage the similarities\nbetween different word forms.", "published": "2024-08-22 09:48:06", "link": "http://arxiv.org/abs/2408.12254v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Self-Taught Reasoners: Enhancing LLM\n  Applications via Tailored Problem-Solving Demonstrations", "abstract": "Guiding large language models with a selected set of human-authored\ndemonstrations is a common practice for improving LLM applications. However,\nhuman effort can be costly, especially in specialized domains (e.g., clinical\ndiagnosis), and does not guarantee optimal performance due to the potential\ndiscrepancy of target skills between selected demonstrations and real test\ninstances. Motivated by these, this paper explores the automatic creation of\ncustomized demonstrations, whose target skills align with the given target\ninstance. We present SELF-TAUGHT, a problem-solving framework, which\nfacilitates demonstrations that are \"tailored\" to the target problem and\n\"filtered\" for better quality (i.e., correctness) in a zero-shot manner. In 15\ntasks of multiple-choice questions of diverse domains and the diagnosis of\nAlzheimer's disease (AD) with real-world patients, SELF-TAUGHT achieves\nsuperior performance to strong baselines (e.g., Few-shot CoT, Plan-and-Solve,\nAuto-CoT). We conduct comprehensive analyses on SELF-TAUGHT, including its\ngeneralizability to existing prompting methods and different LLMs, the quality\nof its intermediate generation, and more.", "published": "2024-08-22 11:41:35", "link": "http://arxiv.org/abs/2408.12315v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Comparative Analysis of Faithfulness Metrics and Humans in Citation\n  Evaluation", "abstract": "Large language models (LLMs) often generate content with unsupported or\nunverifiable content, known as \"hallucinations.\" To address this,\nretrieval-augmented LLMs are employed to include citations in their content,\ngrounding the content in verifiable sources. Despite such developments,\nmanually assessing how well a citation supports the associated statement\nremains a major challenge. Previous studies tackle this challenge by leveraging\nfaithfulness metrics to estimate citation support automatically. However, they\nlimit this citation support estimation to a binary classification scenario,\nneglecting fine-grained citation support in practical scenarios. To investigate\nthe effectiveness of faithfulness metrics in fine-grained scenarios, we propose\na comparative evaluation framework that assesses the metric effectiveness in\ndistinguishing citations between three-category support levels: full, partial,\nand no support. Our framework employs correlation analysis, classification\nevaluation, and retrieval evaluation to measure the alignment between metric\nscores and human judgments comprehensively. Our results indicate no single\nmetric consistently excels across all evaluations, highlighting the complexity\nof accurately evaluating fine-grained support levels. Particularly, we find\nthat the best-performing metrics struggle to distinguish partial support from\nfull or no support. Based on these findings, we provide practical\nrecommendations for developing more effective metrics.", "published": "2024-08-22 13:44:31", "link": "http://arxiv.org/abs/2408.12398v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese", "abstract": "In this report, we introduce Vintern-1B, a reliable 1-billion-parameters\nmultimodal large language model (MLLM) for Vietnamese language tasks. By\nintegrating the Qwen2-0.5B-Instruct language model with the\nInternViT-300M-448px visual model, Vintern-1B is optimized for a range of\napplications, including optical character recognition (OCR), document\nextraction, and general question-answering in Vietnamese context. The model is\nfine-tuned on an extensive dataset of over 3 million image-question-answer\npairs, achieving robust performance and reliable results across multiple\nVietnamese language benchmarks like OpenViVQA and ViTextVQA. Vintern-1B is\nsmall enough to fit into various on-device applications easily. Additionally,\nwe have open-sourced several Vietnamese vision question answering (VQA)\ndatasets for text and diagrams, created with Gemini 1.5 Flash. Our models are\navailable at: https://huggingface.co/5CD-AI/Vintern-1B-v2.", "published": "2024-08-22 15:15:51", "link": "http://arxiv.org/abs/2408.12480v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender\n  Bias in Large Language Models", "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in\nnatural language generation, but they have also been observed to magnify\nsocietal biases, particularly those related to gender. In response to this\nissue, several benchmarks have been proposed to assess gender bias in LLMs.\nHowever, these benchmarks often lack practical flexibility or inadvertently\nintroduce biases. To address these shortcomings, we introduce GenderCARE, a\ncomprehensive framework that encompasses innovative Criteria, bias Assessment,\nReduction techniques, and Evaluation metrics for quantifying and mitigating\ngender bias in LLMs. To begin, we establish pioneering criteria for gender\nequality benchmarks, spanning dimensions such as inclusivity, diversity,\nexplainability, objectivity, robustness, and realisticity. Guided by these\ncriteria, we construct GenderPair, a novel pair-based benchmark designed to\nassess gender bias in LLMs comprehensively. Our benchmark provides standardized\nand realistic evaluations, including previously overlooked gender groups such\nas transgender and non-binary individuals. Furthermore, we develop effective\ndebiasing techniques that incorporate counterfactual data augmentation and\nspecialized fine-tuning strategies to reduce gender bias in LLMs without\ncompromising their overall performance. Extensive experiments demonstrate a\nsignificant reduction in various gender bias benchmarks, with reductions\npeaking at over 90% and averaging above 35% across 17 different LLMs.\nImportantly, these reductions come with minimal variability in mainstream\nlanguage tasks, remaining below 2%. By offering a realistic assessment and\ntailored reduction of gender biases, we hope that our GenderCARE can represent\na significant step towards achieving fairness and equity in LLMs. More details\nare available at https://github.com/kstanghere/GenderCARE-ccs24.", "published": "2024-08-22 15:35:46", "link": "http://arxiv.org/abs/2408.12494v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Russian-focused embedders' exploration: ruMTEB benchmark and Russian\n  embedding model design", "abstract": "Embedding models play a crucial role in Natural Language Processing (NLP) by\ncreating text embeddings used in various tasks such as information retrieval\nand assessing semantic text similarity. This paper focuses on research related\nto embedding models in the Russian language. It introduces a new\nRussian-focused embedding model called ru-en-RoSBERTa and the ruMTEB benchmark,\nthe Russian version extending the Massive Text Embedding Benchmark (MTEB). Our\nbenchmark includes seven categories of tasks, such as semantic textual\nsimilarity, text classification, reranking, and retrieval.The research also\nassesses a representative set of Russian and multilingual models on the\nproposed benchmark. The findings indicate that the new model achieves results\nthat are on par with state-of-the-art models in Russian. We release the model\nru-en-RoSBERTa, and the ruMTEB framework comes with open-source code,\nintegration into the original framework and a public leaderboard.", "published": "2024-08-22 15:53:23", "link": "http://arxiv.org/abs/2408.12503v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Jamba-1.5: Hybrid Transformer-Mamba Models at Scale", "abstract": "We present Jamba-1.5, new instruction-tuned large language models based on\nour Jamba architecture. Jamba is a hybrid Transformer-Mamba mixture of experts\narchitecture, providing high throughput and low memory usage across context\nlengths, while retaining the same or better quality as Transformer models. We\nrelease two model sizes: Jamba-1.5-Large, with 94B active parameters, and\nJamba-1.5-Mini, with 12B active parameters. Both models are fine-tuned for a\nvariety of conversational and instruction-following capabilties, and have an\neffective context length of 256K tokens, the largest amongst open-weight\nmodels. To support cost-effective inference, we introduce ExpertsInt8, a novel\nquantization technique that allows fitting Jamba-1.5-Large on a machine with 8\n80GB GPUs when processing 256K-token contexts without loss of quality. When\nevaluated on a battery of academic and chatbot benchmarks, Jamba-1.5 models\nachieve excellent results while providing high throughput and outperforming\nother open-weight models on long-context benchmarks. The model weights for both\nsizes are publicly available under the Jamba Open Model License and we release\nExpertsInt8 as open source.", "published": "2024-08-22 17:38:59", "link": "http://arxiv.org/abs/2408.12570v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Natural Language Inference Performance with Knowledge Graph\n  for COVID-19 Automated Fact-Checking in Indonesian Language", "abstract": "Automated fact-checking is a key strategy to overcome the spread of COVID-19\nmisinformation on the internet. These systems typically leverage deep learning\napproaches through Natural Language Inference (NLI) to verify the truthfulness\nof information based on supporting evidence. However, one challenge that arises\nin deep learning is performance stagnation due to a lack of knowledge during\ntraining. This study proposes using a Knowledge Graph (KG) as external\nknowledge to enhance NLI performance for automated COVID-19 fact-checking in\nthe Indonesian language. The proposed model architecture comprises three\nmodules: a fact module, an NLI module, and a classifier module. The fact module\nprocesses information from the KG, while the NLI module handles semantic\nrelationships between the given premise and hypothesis. The representation\nvectors from both modules are concatenated and fed into the classifier module\nto produce the final result. The model was trained using the generated\nIndonesian COVID-19 fact-checking dataset and the COVID-19 KG Bahasa Indonesia.\nOur study demonstrates that incorporating KGs can significantly improve NLI\nperformance in fact-checking, achieving the best accuracy of 0,8616. This\nsuggests that KGs are a valuable component for enhancing NLI performance in\nautomated fact-checking.", "published": "2024-08-22 14:27:47", "link": "http://arxiv.org/abs/2409.00061v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Urban Mobility Assessment Using LLMs", "abstract": "Understanding urban mobility patterns and analyzing how people move around\ncities helps improve the overall quality of life and supports the development\nof more livable, efficient, and sustainable urban areas. A challenging aspect\nof this work is the collection of mobility data by means of user tracking or\ntravel surveys, given the associated privacy concerns, noncompliance, and high\ncost. This work proposes an innovative AI-based approach for synthesizing\ntravel surveys by prompting large language models (LLMs), aiming to leverage\ntheir vast amount of relevant background knowledge and text generation\ncapabilities. Our study evaluates the effectiveness of this approach across\nvarious U.S. metropolitan areas by comparing the results against existing\nsurvey data at different granularity levels. These levels include (i) pattern\nlevel, which compares aggregated metrics like the average number of locations\ntraveled and travel time, (ii) trip level, which focuses on comparing trips as\nwhole units using transition probabilities, and (iii) activity chain level,\nwhich examines the sequence of locations visited by individuals. Our work\ncovers several proprietary and open-source LLMs, revealing that open-source\nbase models like Llama-2, when fine-tuned on even a limited amount of actual\ndata, can generate synthetic data that closely mimics the actual travel survey\ndata, and as such provides an argument for using such data in mobility studies.", "published": "2024-08-22 19:17:33", "link": "http://arxiv.org/abs/2409.00063v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "uMedSum: A Unified Framework for Advancing Medical Abstractive\n  Summarization", "abstract": "Medical abstractive summarization faces the challenge of balancing\nfaithfulness and informativeness. Current methods often sacrifice key\ninformation for faithfulness or introduce confabulations when prioritizing\ninformativeness. While recent advancements in techniques like in-context\nlearning (ICL) and fine-tuning have improved medical summarization, they often\noverlook crucial aspects such as faithfulness and informativeness without\nconsidering advanced methods like model reasoning and self-improvement.\nMoreover, the field lacks a unified benchmark, hindering systematic evaluation\ndue to varied metrics and datasets. This paper addresses these gaps by\npresenting a comprehensive benchmark of six advanced abstractive summarization\nmethods across three diverse datasets using five standardized metrics. Building\non these findings, we propose uMedSum, a modular hybrid summarization framework\nthat introduces novel approaches for sequential confabulation removal followed\nby key missing information addition, ensuring both faithfulness and\ninformativeness. Our work improves upon previous GPT-4-based state-of-the-art\n(SOTA) medical summarization methods, significantly outperforming them in both\nquantitative metrics and qualitative domain expert evaluations. Notably, we\nachieve an average relative performance improvement of 11.8% in reference-free\nmetrics over the previous SOTA. Doctors prefer uMedSum's summaries 6 times more\nthan previous SOTA in difficult cases where there are chances of confabulations\nor missing information. These results highlight uMedSum's effectiveness and\ngeneralizability across various datasets and metrics, marking a significant\nadvancement in medical summarization.", "published": "2024-08-22 03:08:49", "link": "http://arxiv.org/abs/2408.12095v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extraction of Research Objectives, Machine Learning Model Names, and\n  Dataset Names from Academic Papers and Analysis of Their Interrelationships\n  Using LLM and Network Analysis", "abstract": "Machine learning is widely utilized across various industries. Identifying\nthe appropriate machine learning models and datasets for specific tasks is\ncrucial for the effective industrial application of machine learning. However,\nthis requires expertise in both machine learning and the relevant domain,\nleading to a high learning cost. Therefore, research focused on extracting\ncombinations of tasks, machine learning models, and datasets from academic\npapers is critically important, as it can facilitate the automatic\nrecommendation of suitable methods. Conventional information extraction methods\nfrom academic papers have been limited to identifying machine learning models\nand other entities as named entities. To address this issue, this study\nproposes a methodology extracting tasks, machine learning methods, and dataset\nnames from scientific papers and analyzing the relationships between these\ninformation by using LLM, embedding model, and network clustering. The proposed\nmethod's expression extraction performance, when using Llama3, achieves an\nF-score exceeding 0.8 across various categories, confirming its practical\nutility. Benchmarking results on financial domain papers have demonstrated the\neffectiveness of this method, providing insights into the use of the latest\ndatasets, including those related to ESG (Environmental, Social, and\nGovernance) data.", "published": "2024-08-22 03:10:52", "link": "http://arxiv.org/abs/2408.12097v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Tighter Complexity Analysis of SparseGPT", "abstract": "In this work, we improved the analysis of the running time of SparseGPT\n[Frantar, Alistarh ICML 2023] from $O(d^{3})$ to $O(d^{\\omega} + d^{2+a+o(1)} +\nd^{1+\\omega(1,1,a)-a})$ for any $a \\in [0, 1]$, where $\\omega$ is the exponent\nof matrix multiplication. In particular, for the current $\\omega \\approx 2.371$\n[Alman, Duan, Williams, Xu, Xu, Zhou 2024], our running time boils down to\n$O(d^{2.53})$. This running time is due to the analysis of the lazy update\nbehavior in iterative maintenance problems such as [Deng, Song, Weinstein 2022;\nBrand, Song, Zhou ICML 2024].", "published": "2024-08-22 06:40:32", "link": "http://arxiv.org/abs/2408.12151v2", "categories": ["cs.DS", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.DS"}
{"title": "Search-Based LLMs for Code Optimization", "abstract": "The code written by developers usually suffers from efficiency problems and\ncontain various performance bugs. These inefficiencies necessitate the research\nof automated refactoring methods for code optimization. Early research in code\noptimization employs rule-based methods and focuses on specific inefficiency\nissues, which are labor-intensive and suffer from the low coverage issue.\nRecent work regards the task as a sequence generation problem, and resorts to\ndeep learning (DL) techniques such as large language models (LLMs). These\nmethods typically prompt LLMs to directly generate optimized code. Although\nthese methods show state-of-the-art performance, such one-step generation\nparadigm is hard to achieve an optimal solution. First, complex optimization\nmethods such as combinatorial ones are hard to be captured by LLMs. Second, the\none-step generation paradigm poses challenge in precisely infusing the\nknowledge required for effective code optimization within LLMs, resulting in\nunder-optimized code.To address these problems, we propose to model this task\nfrom the search perspective, and propose a search-based LLMs framework named\nSBLLM that enables iterative refinement and discovery of improved optimization\nmethods. SBLLM synergistically integrate LLMs with evolutionary search and\nconsists of three key components: 1) an execution-based representative sample\nselection part that evaluates the fitness of each existing optimized code and\nprioritizes promising ones to pilot the generation of improved code; 2) an\nadaptive optimization pattern retrieval part that infuses targeted optimization\npatterns into the model for guiding LLMs towards rectifying and progressively\nenhancing their optimization methods; and 3) a genetic operator-inspired\nchain-of-thought prompting part that aids LLMs in combining different\noptimization methods and generating improved optimization methods.", "published": "2024-08-22 06:59:46", "link": "http://arxiv.org/abs/2408.12159v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction", "abstract": "Large Language Models (LLMs) are increasingly adopted for applications in\nhealthcare, reaching the performance of domain experts on tasks such as\nquestion answering and document summarisation. Despite their success on these\ntasks, it is unclear how well LLMs perform on tasks that are traditionally\npursued in the biomedical domain, such as structured information extration. To\nbreach this gap, in this paper, we systematically benchmark LLM performance in\nMedical Classification and Named Entity Recognition (NER) tasks. We aim to\ndisentangle the contribution of different factors to the performance,\nparticularly the impact of LLMs' task knowledge and reasoning capabilities,\ntheir (parametric) domain knowledge, and addition of external knowledge. To\nthis end we evaluate various open LLMs -- including BioMistral and Llama-2\nmodels -- on a diverse set of biomedical datasets, using standard prompting,\nChain-of-Thought (CoT) and Self-Consistency based reasoning as well as\nRetrieval-Augmented Generation (RAG) with PubMed and Wikipedia corpora.\nCounter-intuitively, our results reveal that standard prompting consistently\noutperforms more complex techniques across both tasks, laying bare the\nlimitations in the current application of CoT, self-consistency and RAG in the\nbiomedical domain. Our findings suggest that advanced prompting methods\ndeveloped for knowledge- or reasoning-intensive tasks, such as CoT or RAG, are\nnot easily portable to biomedical tasks where precise structured outputs are\nrequired. This highlights the need for more effective integration of external\nknowledge and reasoning mechanisms in LLMs to enhance their performance in\nreal-world biomedical applications.", "published": "2024-08-22 09:37:40", "link": "http://arxiv.org/abs/2408.12249v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Toward the Evaluation of Large Language Models Considering Score\n  Variance across Instruction Templates", "abstract": "The natural language understanding (NLU) performance of large language models\n(LLMs) has been evaluated across various tasks and datasets. The existing\nevaluation methods, however, do not take into account the variance in scores\ndue to differences in prompts, which leads to unfair evaluation and comparison\nof NLU performance. Moreover, evaluation designed for specific prompts is\ninappropriate for instruction tuning, which aims to perform well with any\nprompt. It is therefore necessary to find a way to measure NLU performance in a\nfair manner, considering score variance between different instruction\ntemplates. In this study, we provide English and Japanese cross-lingual\ndatasets for evaluating the NLU performance of LLMs, which include multiple\ninstruction templates for fair evaluation of each task, along with regular\nexpressions to constrain the output format. Furthermore, we propose the Sharpe\nscore as an evaluation metric that takes into account the variance in scores\nbetween templates. Comprehensive analysis of English and Japanese LLMs reveals\nthat the high variance among templates has a significant impact on the fair\nevaluation of LLMs.", "published": "2024-08-22 10:00:20", "link": "http://arxiv.org/abs/2408.12263v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MaVEn: An Effective Multi-granularity Hybrid Visual Encoding Framework\n  for Multimodal Large Language Model", "abstract": "This paper presents MaVEn, an innovative Multi-granularity Visual Encoding\nframework designed to enhance the capabilities of Multimodal Large Language\nModels (MLLMs) in multi-image reasoning. Current MLLMs primarily focus on\nsingle-image visual understanding, limiting their ability to interpret and\nintegrate information across multiple images. MaVEn addresses this limitation\nby combining discrete visual symbol sequences, which abstract coarse-grained\nsemantic concepts, with traditional continuous representation sequences that\nmodel fine-grained features. This dual approach bridges the semantic gap\nbetween visual and textual data, thereby improving the model's ability to\nprocess and interpret information from multiple images effectively.\nAdditionally, we design a dynamic reduction mechanism by for long-sequence\ncontinuous features to enhance multi-image processing efficiency. Experimental\nresults demonstrate that MaVEn significantly enhances MLLMs' understanding in\ncomplex multi-image scenarios, while also improving performance in single-image\ncontexts.", "published": "2024-08-22 11:57:16", "link": "http://arxiv.org/abs/2408.12321v2", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Interactive DualChecker for Mitigating Hallucinations in Distilling\n  Large Language Models", "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various machine learning (ML) tasks. Given the high costs of creating\nannotated datasets for supervised learning, LLMs offer a valuable alternative\nby enabling effective few-shot in-context learning. However, these models can\nproduce hallucinations, particularly in domains with incomplete knowledge.\nAdditionally, current methods for knowledge distillation using LLMs often\nstruggle to enhance the effectiveness of both teacher and student models. To\naddress these challenges, we introduce DualChecker, an innovative framework\ndesigned to mitigate hallucinations and improve the performance of both teacher\nand student models during knowledge distillation. DualChecker employs\nContextAligner to ensure that the context provided by teacher models aligns\nwith human labeling standards. It also features a dynamic checker system that\nenhances model interaction: one component re-prompts teacher models with more\ndetailed content when they show low confidence, and another identifies\nborderline cases from student models to refine the teaching templates. This\ninteractive process promotes continuous improvement and effective knowledge\ntransfer between the models. We evaluate DualChecker using a green innovation\ntextual dataset that includes binary, multiclass, and token classification\ntasks. The experimental results show that DualChecker significantly outperforms\nexisting state-of-the-art methods, achieving up to a 17% improvement in F1\nscore for teacher models and 10% for student models. Notably, student models\nfine-tuned with LLM predictions perform comparably to those fine-tuned with\nactual data, even in a challenging domain. We make all datasets, models, and\ncode from this research publicly available.", "published": "2024-08-22 12:04:04", "link": "http://arxiv.org/abs/2408.12326v1", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.CY"], "primary_category": "cs.CL"}
{"title": "MuMA-ToM: Multi-modal Multi-Agent Theory of Mind", "abstract": "Understanding people's social interactions in complex real-world scenarios\noften relies on intricate mental reasoning. To truly understand how and why\npeople interact with one another, we must infer the underlying mental states\nthat give rise to the social interactions, i.e., Theory of Mind reasoning in\nmulti-agent interactions. Additionally, social interactions are often\nmulti-modal -- we can watch people's actions, hear their conversations, and/or\nread about their past behaviors. For AI systems to successfully and safely\ninteract with people in real-world environments, they also need to understand\npeople's mental states as well as their inferences about each other's mental\nstates based on multi-modal information about their interactions. For this, we\nintroduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark.\nMuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluates\nmental reasoning in embodied multi-agent interactions. In MuMA-ToM, we provide\nvideo and text descriptions of people's multi-modal behavior in realistic\nhousehold environments. Based on the context, we then ask questions about\npeople's goals, beliefs, and beliefs about others' goals. We validated MuMA-ToM\nin a human experiment and provided a human baseline. We also proposed a novel\nmulti-modal, multi-agent ToM model, LIMP (Language model-based Inverse\nMulti-agent Planning). Our experimental results show that LIMP significantly\noutperforms state-of-the-art methods, including large multi-modal models (e.g.,\nGPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.", "published": "2024-08-22 17:41:45", "link": "http://arxiv.org/abs/2408.12574v4", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And\n  Model Merging", "abstract": "Recent advances in Text-to-SQL have largely focused on the SQLite dialect,\nneglecting the diverse landscape of SQL dialects like BigQuery and PostgreSQL.\nThis limitation is due to the diversity in SQL syntaxes and functions, along\nwith the high cost of collecting and curating SQL-specific training data. To\naddress this, we introduce SQL-GEN, a framework for generating high-quality\nsynthetic training data for any SQL dialect, guided by readily available\ndialect-specific tutorials. SQL-GEN significantly improves cross-dialect\nText-to-SQL performance, boosting execution accuracy by up to 20\\% over\nexisting methods. This performance gain narrows the gap with models trained on\nlarge-scale human-annotated data. Furthermore, combining synthetic data from\nSQL-GEN with human-annotated data yields additional improvements of up to\n5.6\\%. To unify multi-dialect capabilities within a single model, we propose a\nnovel Mixture-of-Experts (MoE) initialization that leverages the shared\nknowledge across dialects. Our approach merges self-attention layers from\ndialect-specific models and initializes expert gates using dialect-specific\nkeywords. This leads to a versatile model optimized for multiple SQL dialects,\noutperforming single-dialect models and significantly enhancing overall\nperformance.", "published": "2024-08-22 20:50:48", "link": "http://arxiv.org/abs/2408.12733v2", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SLM Meets LLM: Balancing Latency, Interpretability and Consistency in\n  Hallucination Detection", "abstract": "Large language models (LLMs) are highly capable but face latency challenges\nin real-time applications, such as conducting online hallucination detection.\nTo overcome this issue, we propose a novel framework that leverages a small\nlanguage model (SLM) classifier for initial detection, followed by a LLM as\nconstrained reasoner to generate detailed explanations for detected\nhallucinated content. This study optimizes the real-time interpretable\nhallucination detection by introducing effective prompting techniques that\nalign LLM-generated explanations with SLM decisions. Empirical experiment\nresults demonstrate its effectiveness, thereby enhancing the overall user\nexperience.", "published": "2024-08-22 22:13:13", "link": "http://arxiv.org/abs/2408.12748v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Assessing Modality Bias in Video Question Answering Benchmarks with\n  Multimodal Large Language Models", "abstract": "Multimodal large language models (MLLMs) can simultaneously process visual,\ntextual, and auditory data, capturing insights that complement human analysis.\nHowever, existing video question-answering (VidQA) benchmarks and datasets\noften exhibit a bias toward a single modality, despite the goal of requiring\nadvanced reasoning skills that integrate diverse modalities to answer the\nqueries. In this work, we introduce the modality importance score (MIS) to\nidentify such bias. It is designed to assess which modality embeds the\nnecessary information to answer the question. Additionally, we propose an\ninnovative method using state-of-the-art MLLMs to estimate the modality\nimportance, which can serve as a proxy for human judgments of modality\nperception. With this MIS, we demonstrate the presence of unimodal bias and the\nscarcity of genuinely multimodal questions in existing datasets. We further\nvalidate the modality importance score with multiple ablation studies to\nevaluate the performance of MLLMs on permuted feature sets. Our results\nindicate that current models do not effectively integrate information due to\nmodality imbalance in existing datasets. Our proposed MLLM-derived MIS can\nguide the curation of modality-balanced datasets that advance multimodal\nlearning and enhance MLLMs' capabilities to understand and utilize synergistic\nrelations across modalities.", "published": "2024-08-22 23:32:42", "link": "http://arxiv.org/abs/2408.12763v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Fine-tuning Smaller Language Models for Question Answering over\n  Financial Documents", "abstract": "Recent research has shown that smaller language models can acquire\nsubstantial reasoning abilities when fine-tuned with reasoning exemplars\ncrafted by a significantly larger teacher model. We explore this paradigm for\nthe financial domain, focusing on the challenge of answering questions that\nrequire multi-hop numerical reasoning over financial texts. We assess the\nperformance of several smaller models that have been fine-tuned to generate\nprograms that encode the required financial reasoning and calculations. Our\nfindings demonstrate that these fine-tuned smaller models approach the\nperformance of the teacher model.\n  To provide a granular analysis of model performance, we propose an approach\nto investigate the specific student model capabilities that are enhanced by\nfine-tuning. Our empirical analysis indicates that fine-tuning refines the\nstudent models ability to express and apply the required financial concepts\nalong with adapting the entity extraction for the specific data format. In\naddition, we hypothesize and demonstrate that comparable financial reasoning\ncapability can be induced using relatively smaller datasets.", "published": "2024-08-22 12:23:29", "link": "http://arxiv.org/abs/2408.12337v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.CL"}
{"title": "RuleAlign: Making Large Language Models Better Physicians with\n  Diagnostic Rule Alignment", "abstract": "Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieve\nperformance competitively with human experts across various medical benchmarks.\nHowever, they still face challenges in making professional diagnoses akin to\nphysicians, particularly in efficiently gathering patient information and\nreasoning the final diagnosis. To this end, we introduce the RuleAlign\nframework, designed to align LLMs with specific diagnostic rules. We develop a\nmedical dialogue dataset comprising rule-based communications between patients\nand physicians and design an alignment learning approach through preference\nlearning. Experimental results demonstrate the effectiveness of the proposed\napproach. We hope that our work can serve as an inspiration for exploring the\npotential of LLMs as AI physicians.", "published": "2024-08-22 17:44:40", "link": "http://arxiv.org/abs/2408.12579v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MultiMed: Massively Multimodal and Multitask Medical Understanding", "abstract": "Biomedical data is inherently multimodal, consisting of electronic health\nrecords, medical imaging, digital pathology, genome sequencing, wearable\nsensors, and more. The application of artificial intelligence tools to these\nmultifaceted sensing technologies has the potential to revolutionize the\nprognosis, diagnosis, and management of human health and disease. However,\ncurrent approaches to biomedical AI typically only train and evaluate with one\nor a small set of medical modalities and tasks. This limitation hampers the\ndevelopment of comprehensive tools that can leverage the rich interconnected\ninformation across many heterogeneous biomedical sensors. To address this\nchallenge, we present MultiMed, a benchmark designed to evaluate and enable\nlarge-scale learning across a wide spectrum of medical modalities and tasks.\nMultiMed consists of 2.56 million samples across ten medical modalities such as\nmedical reports, pathology, genomics, and protein data, and is structured into\neleven challenging tasks, including disease prognosis, protein structure\nprediction, and medical question answering. Using MultiMed, we conduct\ncomprehensive experiments benchmarking state-of-the-art unimodal, multimodal,\nand multitask models. Our analysis highlights the advantages of training\nlarge-scale medical models across many related modalities and tasks. Moreover,\nMultiMed enables studies of generalization across related medical concepts,\nrobustness to real-world noisy data and distribution shifts, and novel modality\ncombinations to improve prediction performance. MultiMed will be publicly\navailable and regularly updated and welcomes inputs from the community.", "published": "2024-08-22 18:41:36", "link": "http://arxiv.org/abs/2408.12682v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.LG"}
{"title": "LCM-SVC: Latent Diffusion Model Based Singing Voice Conversion with\n  Inference Acceleration via Latent Consistency Distillation", "abstract": "Any-to-any singing voice conversion (SVC) aims to transfer a target singer's\ntimbre to other songs using a short voice sample. However many diffusion model\nbased any-to-any SVC methods, which have achieved impressive results, usually\nsuffered from low efficiency caused by a mass of inference steps. In this\npaper, we propose LCM-SVC, a latent consistency distillation (LCD) based latent\ndiffusion model (LDM) to accelerate inference speed. We achieved one-step or\nfew-step inference while maintaining the high performance by distilling a\npre-trained LDM based SVC model, which had the advantages of timbre decoupling\nand sound quality. Experimental results show that our proposed method can\nsignificantly reduce the inference time and largely preserve the sound quality\nand timbre similarity comparing with other state-of-the-art SVC models. Audio\nsamples are available at https://sounddemos.github.io/lcm-svc.", "published": "2024-08-22 12:53:02", "link": "http://arxiv.org/abs/2408.12354v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Integrating Audio, Visual, and Semantic Information for Enhanced\n  Multimodal Speaker Diarization", "abstract": "Speaker diarization, the process of segmenting an audio stream or transcribed\nspeech content into homogenous partitions based on speaker identity, plays a\ncrucial role in the interpretation and analysis of human speech. Most existing\nspeaker diarization systems rely exclusively on unimodal acoustic information,\nmaking the task particularly challenging due to the innate ambiguities of audio\nsignals. Recent studies have made tremendous efforts towards audio-visual or\naudio-semantic modeling to enhance performance. However, even the incorporation\nof up to two modalities often falls short in addressing the complexities of\nspontaneous and unstructured conversations. To exploit more meaningful dialogue\npatterns, we propose a novel multimodal approach that jointly utilizes audio,\nvisual, and semantic cues to enhance speaker diarization. Our method elegantly\nformulates the multimodal modeling as a constrained optimization problem.\nFirst, we build insights into the visual connections among active speakers and\nthe semantic interactions within spoken content, thereby establishing abundant\npairwise constraints. Then we introduce a joint pairwise constraint propagation\nalgorithm to cluster speakers based on these visual and semantic constraints.\nThis integration effectively leverages the complementary strengths of different\nmodalities, refining the affinity estimation between individual speaker\nembeddings. Extensive experiments conducted on multiple multimodal datasets\ndemonstrate that our approach consistently outperforms state-of-the-art speaker\ndiarization methods.", "published": "2024-08-22 03:34:03", "link": "http://arxiv.org/abs/2408.12102v1", "categories": ["cs.LG", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "VoiceX: A Text-To-Speech Framework for Custom Voices", "abstract": "Modern TTS systems are capable of creating highly realistic and\nnatural-sounding speech. Despite these developments, the process of customizing\nTTS voices remains a complex task, mostly requiring the expertise of\nspecialists within the field. One reason for this is the utilization of deep\nlearning models, which are characterized by their expansive, non-interpretable\nparameter spaces, restricting the feasibility of manual customization. In this\npaper, we present a novel human-in-the-loop paradigm based on an evolutionary\nalgorithm for directly interacting with the parameter space of a neural TTS\nmodel. We integrated our approach into a user-friendly graphical user interface\nthat allows users to efficiently create original voices. Those voices can then\nbe used with the backbone TTS model, for which we provide a Python API.\nFurther, we present the results of a user study exploring the capabilities of\nVoiceX. We show that VoiceX is an appropriate tool for creating individual,\ncustom voices.", "published": "2024-08-22 07:32:32", "link": "http://arxiv.org/abs/2408.12170v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Developing vocal system impaired patient-aimed voice quality assessment\n  approach using ASR representation-included multiple features", "abstract": "The potential of deep learning in clinical speech processing is immense, yet\nthe hurdles of limited and imbalanced clinical data samples loom large. This\narticle addresses these challenges by showcasing the utilization of automatic\nspeech recognition and self-supervised learning representations, pre-trained on\nextensive datasets of normal speech. This innovative approach aims to estimate\nvoice quality of patients with impaired vocal systems. Experiments involve\nchecks on PVQD dataset, covering various causes of vocal system damage in\nEnglish, and a Japanese dataset focusing on patients with Parkinson's disease\nbefore and after undergoing subthalamic nucleus deep brain stimulation\n(STN-DBS) surgery. The results on PVQD reveal a notable correlation (>0.8 on\nPCC) and an extraordinary accuracy (<0.5 on MSE) in predicting Grade, Breathy,\nand Asthenic indicators. Meanwhile, progress has been achieved in predicting\nthe voice quality of patients in the context of STN-DBS.", "published": "2024-08-22 10:22:53", "link": "http://arxiv.org/abs/2408.12279v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dynamic Gated Recurrent Neural Network for Compute-efficient Speech\n  Enhancement", "abstract": "This paper introduces a new Dynamic Gated Recurrent Neural Network (DG-RNN)\nfor compute-efficient speech enhancement models running on resource-constrained\nhardware platforms. It leverages the slow evolution characteristic of RNN\nhidden states over steps, and updates only a selected set of neurons at each\nstep by adding a newly proposed select gate to the RNN model. This select gate\nallows the computation cost of the conventional RNN to be reduced during\nnetwork inference. As a realization of the DG-RNN, we further propose the\nDynamic Gated Recurrent Unit (D-GRU) which does not require additional\nparameters. Test results obtained from several state-of-the-art\ncompute-efficient RNN-based speech enhancement architectures using the DNS\nchallenge dataset, show that the D-GRU based model variants maintain similar\nspeech intelligibility and quality metrics comparable to the baseline GRU based\nmodels even with an average 50% reduction in GRU computes.", "published": "2024-08-22 14:20:11", "link": "http://arxiv.org/abs/2408.12425v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Self-Learning for Personalized Keyword Spotting on Ultra-Low-Power Audio\n  Sensors", "abstract": "This paper proposes a self-learning method to incrementally train (fine-tune)\na personalized Keyword Spotting (KWS) model after the deployment on ultra-low\npower smart audio sensors. We address the fundamental problem of the absence of\nlabeled training data by assigning pseudo-labels to the new recorded audio\nframes based on a similarity score with respect to few user recordings. By\nexperimenting with multiple KWS models with a number of parameters up to 0.5M\non two public datasets, we show an accuracy improvement of up to +19.2% and\n+16.0% vs. the initial models pretrained on a large set of generic keywords.\nThe labeling task is demonstrated on a sensor system composed of a low-power\nmicrophone and an energy-efficient Microcontroller (MCU). By efficiently\nexploiting the heterogeneous processing engines of the MCU, the always-on\nlabeling task runs in real-time with an average power cost of up to 8.2 mW. On\nthe same platform, we estimate an energy cost for on-device training 10x lower\nthan the labeling energy if sampling a new utterance every 6.1 s or 18.8 s with\na DS-CNN-S or a DS-CNN-M model. Our empirical result paves the way to\nself-adaptive personalized KWS sensors at the extreme edge.", "published": "2024-08-22 15:17:02", "link": "http://arxiv.org/abs/2408.12481v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "WhisperMask: A Noise Suppressive Mask-Type Microphone for Whisper Speech", "abstract": "Whispering is a common privacy-preserving technique in voice-based\ninteractions, but its effectiveness is limited in noisy environments. In\nconventional hardware- and software-based noise reduction approaches, isolating\nwhispered speech from ambient noise and other speech sounds remains a\nchallenge. We thus propose WhisperMask, a mask-type microphone featuring a\nlarge diaphragm with low sensitivity, making the wearer's voice significantly\nlouder than the background noise. We evaluated WhisperMask using three key\nmetrics: signal-to-noise ratio, quality of recorded voices, and speech\nrecognition rate. Across all metrics, WhisperMask consistently outperformed\ntraditional noise-suppressing microphones and software-based solutions.\nNotably, WhisperMask showed a 30% higher recognition accuracy for whispered\nspeech recorded in an environment with 80 dB background noise compared with the\npin microphone and earbuds. Furthermore, while a denoiser decreased the\nwhispered speech recognition rate of these two microphones by approximately 20%\nat 30-60 dB noise, WhisperMask maintained a high performance even without\ndenoising, surpassing the other microphones' performances by a significant\nmargin.WhisperMask's design renders the wearer's voice as the dominant input\nand effectively suppresses background noise without relying on signal\nprocessing. This device allows for reliable voice interactions, such as phone\ncalls and voice commands, in a wide range of noisy real-world scenarios while\npreserving user privacy.", "published": "2024-08-22 15:51:07", "link": "http://arxiv.org/abs/2408.12500v1", "categories": ["cs.HC", "cs.SD", "eess.AS", "H.5.2"], "primary_category": "cs.HC"}
{"title": "Modeling Time-Variant Responses of Optical Compressors with Selective\n  State Space Models", "abstract": "This paper presents a method for modeling optical dynamic range compressors\nusing deep neural networks with Selective State Space models. The proposed\napproach surpasses previous methods based on recurrent layers by employing a\nSelective State Space block to encode the input audio. It features a refined\ntechnique integrating Feature-wise Linear Modulation and Gated Linear Units to\nadjust the network dynamically, conditioning the compression's attack and\nrelease phases according to external parameters. The proposed architecture is\nwell-suited for low-latency and real-time applications, crucial in live audio\nprocessing. The method has been validated on the analog optical compressors\nTubeTech CL 1B and Teletronix LA-2A, which possess distinct characteristics.\nEvaluation is performed using quantitative metrics and subjective listening\ntests, comparing the proposed method with other state-of-the-art models.\nResults show that our black-box modeling methods outperform all others,\nachieving accurate emulation of the compression process for both seen and\nunseen settings during training. We further show a correlation between this\naccuracy and the sampling density of the control parameters in the dataset and\nidentify settings with fast attack and slow release as the most challenging to\nemulate.", "published": "2024-08-22 17:03:08", "link": "http://arxiv.org/abs/2408.12549v3", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Melody predominates over harmony in the evolution of musical scales\n  across 96 countries", "abstract": "The standard theory of musical scales since antiquity has been based on\nharmony, rather than melody. Some recent analyses support either view, and we\nlack a comparative test on cross-cultural data. We address this longstanding\nproblem through a rigorous, computational comparison of the main theories\nagainst 1,314 scales from 96 countries. There is near-universal support for\nmelodic theories, which predict step-sizes of 1-3 semitones. Harmony accounts\nfor the prevalence of some simple-integer-ratio intervals, particularly for\nmusic-theoretic scales from Eurasian societies, which may explain their\ndominance amongst Western scholars. However, harmony poorly predicts scales\nmeasured from ethnographic recordings, particularly outside of Eurasia.\nOverall, we show that the historical emphasis on harmony is misguided and that\nmelody is the primary determinant of the world's musical scales.", "published": "2024-08-22 13:51:11", "link": "http://arxiv.org/abs/2408.12633v1", "categories": ["cs.SD", "eess.AS", "physics.soc-ph"], "primary_category": "cs.SD"}
{"title": "Hierarchical Generative Modeling of Melodic Vocal Contours in Hindustani\n  Classical Music", "abstract": "Hindustani music is a performance-driven oral tradition that exhibits the\nrendition of rich melodic patterns. In this paper, we focus on generative\nmodeling of singers' vocal melodies extracted from audio recordings, as the\nvoice is musically prominent within the tradition. Prior generative work in\nHindustani music models melodies as coarse discrete symbols which fails to\ncapture the rich expressive melodic intricacies of singing. Thus, we propose to\nuse a finely quantized pitch contour, as an intermediate representation for\nhierarchical audio modeling. We propose GaMaDHaNi, a modular two-level\nhierarchy, consisting of a generative model on pitch contours, and a pitch\ncontour to audio synthesis model. We compare our approach to non-hierarchical\naudio models and hierarchical models that use a self-supervised intermediate\nrepresentation, through a listening test and qualitative analysis. We also\nevaluate audio model's ability to faithfully represent the pitch contour input\nusing Pearson correlation coefficient. By using pitch contours as an\nintermediate representation, we show that our model may be better equipped to\nlisten and respond to musicians in a human-AI collaborative setting by\nhighlighting two potential interaction use cases (1) primed generation, and (2)\ncoarse pitch conditioning.", "published": "2024-08-22 18:04:29", "link": "http://arxiv.org/abs/2408.12658v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Information and motor constraints shape melodic diversity across\n  cultures", "abstract": "The number of possible melodies is unfathomably large, yet despite this\nvirtually unlimited potential for melodic variation, melodies from different\nsocieties can be surprisingly similar. The motor constraint hypothesis accounts\nfor certain similarities, such as scalar motion and contour shape, but not for\nother major common features, such as repetition, song length, and scale size.\nHere we investigate the role of information constraints arising from\nlimitations on human memory in shaping these hallmarks of melodies. We measure\ndeterminants of information rate in 62 corpora of Folk melodies spanning\nseveral continents, finding multiple trade-offs that all act to constrain the\ninformation rate across societies. By contrast, 39 corpora of Art music from\nEurope (including Turkey) show longer, more complex melodies, and increased\ncomplexity over time, suggesting different cultural-evolutionary selection\npressures in Art and Folk music, possibly due to the use of written versus oral\ntransmission. Our parameter-free model predicts the empirical scale degree\ndistribution using information constraints on scalar motion, melody length,\nand, most importantly, information rate. This provides strong evidence that\ninformation constraints during cultural transmission of music limit the number\nof notes in a scale, and proposes that preference for intermediate melodic\ncomplexity is a fundamental constraint on the cultural evolution of melody.", "published": "2024-08-22 14:33:11", "link": "http://arxiv.org/abs/2408.12635v2", "categories": ["cs.SD", "cs.IT", "eess.AS", "math.IT", "physics.soc-ph"], "primary_category": "cs.SD"}
{"title": "Towards measuring fairness in speech recognition: Fair-Speech dataset", "abstract": "The current public datasets for speech recognition (ASR) tend not to focus\nspecifically on the fairness aspect, such as performance across different\ndemographic groups. This paper introduces a novel dataset, Fair-Speech, a\npublicly released corpus to help researchers evaluate their ASR models for\naccuracy across a diverse set of self-reported demographic information, such as\nage, gender, ethnicity, geographic variation and whether the participants\nconsider themselves native English speakers. Our dataset includes approximately\n26.5K utterances in recorded speech by 593 people in the United States, who\nwere paid to record and submit audios of themselves saying voice commands. We\nalso provide ASR baselines, including on models trained on transcribed and\nuntranscribed social media videos and open source models.", "published": "2024-08-22 20:55:17", "link": "http://arxiv.org/abs/2408.12734v1", "categories": ["cs.AI", "cs.CY", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.AI"}
