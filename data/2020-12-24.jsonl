{"title": "Cross-lingual Universal Dependency Parsing Only from One Monolingual\n  Treebank", "abstract": "Syntactic parsing is a highly linguistic processing task whose parser\nrequires training on treebanks from the expensive human annotation. As it is\nunlikely to obtain a treebank for every human language, in this work, we\npropose an effective cross-lingual UD parsing framework for transferring parser\nfrom only one source monolingual treebank to any other target languages without\ntreebank available. To reach satisfactory parsing accuracy among quite\ndifferent languages, we introduce two language modeling tasks into dependency\nparsing as multi-tasking. Assuming only unlabeled data from target languages\nplus the source treebank can be exploited together, we adopt a self-training\nstrategy for further performance improvement in terms of our multi-task\nframework. Our proposed cross-lingual parsers are implemented for English,\nChinese, and 22 UD treebanks. The empirical study shows that our cross-lingual\nparsers yield promising results for all target languages, for the first time,\napproaching the parser performance which is trained in its own target treebank.", "published": "2020-12-24 08:14:36", "link": "http://arxiv.org/abs/2012.13163v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Bias in Multilingual Neural Machine Translation: The Architecture\n  Matters", "abstract": "Multilingual Neural Machine Translation architectures mainly differ in the\namount of sharing modules and parameters among languages. In this paper, and\nfrom an algorithmic perspective, we explore if the chosen architecture, when\ntrained with the same data, influences the gender bias accuracy. Experiments in\nfour language pairs show that Language-Specific encoders-decoders exhibit less\nbias than the Shared encoder-decoder architecture. Further interpretability\nanalysis of source embeddings and the attention shows that, in the\nLanguage-Specific case, the embeddings encode more gender information, and its\nattention is more diverted. Both behaviors help in mitigating gender bias.", "published": "2020-12-24 09:27:52", "link": "http://arxiv.org/abs/2012.13176v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act\n  Recognition and Sentiment Classification", "abstract": "In a dialog system, dialog act recognition and sentiment classification are\ntwo correlative tasks to capture speakers intentions, where dialog act and\nsentiment can indicate the explicit and the implicit intentions separately. The\ndialog context information (contextual information) and the mutual interaction\ninformation are two key factors that contribute to the two related tasks.\nUnfortunately, none of the existing approaches consider the two important\nsources of information simultaneously. In this paper, we propose a\nCo-Interactive Graph Attention Network (Co-GAT) to jointly perform the two\ntasks. The core module is a proposed co-interactive graph interaction layer\nwhere a cross-utterances connection and a cross-tasks connection are\nconstructed and iteratively updated with each other, achieving to consider the\ntwo types of information simultaneously. Experimental results on two public\ndatasets show that our model successfully captures the two sources of\ninformation and achieve the state-of-the-art performance.\n  In addition, we find that the contributions from the contextual and mutual\ninteraction information do not fully overlap with contextualized word\nrepresentations (BERT, Roberta, XLNet).", "published": "2020-12-24 14:10:24", "link": "http://arxiv.org/abs/2012.13260v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Context Aware Approach for Generating Natural Language Attacks", "abstract": "We study an important task of attacking natural language processing models in\na black box setting. We propose an attack strategy that crafts semantically\nsimilar adversarial examples on text classification and entailment tasks. Our\nproposed attack finds candidate words by considering the information of both\nthe original word and its surrounding context. It jointly leverages masked\nlanguage modelling and next sentence prediction for context understanding. In\ncomparison to attacks proposed in prior literature, we are able to generate\nhigh quality adversarial examples that do significantly better both in terms of\nsuccess rate and word perturbation percentage.", "published": "2020-12-24 17:24:54", "link": "http://arxiv.org/abs/2012.13339v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "To what extent do human explanations of model behavior align with actual\n  model behavior?", "abstract": "Given the increasingly prominent role NLP models (will) play in our lives, it\nis important for human expectations of model behavior to align with actual\nmodel behavior. Using Natural Language Inference (NLI) as a case study, we\ninvestigate the extent to which human-generated explanations of models'\ninference decisions align with how models actually make these decisions. More\nspecifically, we define three alignment metrics that quantify how well natural\nlanguage explanations align with model sensitivity to input words, as measured\nby integrated gradients. Then, we evaluate eight different models (the base and\nlarge versions of BERT, RoBERTa and ELECTRA, as well as anRNN and bag-of-words\nmodel), and find that the BERT-base model has the highest alignment with\nhuman-generated explanations, for all alignment metrics. Focusing in on\ntransformers, we find that the base versions tend to have higher alignment with\nhuman-generated explanations than their larger counterparts, suggesting that\nincreasing the number of model parameters leads, in some cases, to worse\nalignment with human explanations. Finally, we find that a model's alignment\nwith human explanations is not predicted by the model's accuracy, suggesting\nthat accuracy and alignment are complementary ways to evaluate models.", "published": "2020-12-24 17:40:06", "link": "http://arxiv.org/abs/2012.13354v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ThamizhiUDp: A Dependency Parser for Tamil", "abstract": "This paper describes how we developed a neural-based dependency parser,\nnamely ThamizhiUDp, which provides a complete pipeline for the dependency\nparsing of the Tamil language text using Universal Dependency formalism. We\nhave considered the phases of the dependency parsing pipeline and identified\ntools and resources in each of these phases to improve the accuracy and to\ntackle data scarcity. ThamizhiUDp uses Stanza for tokenisation and\nlemmatisation, ThamizhiPOSt and ThamizhiMorph for generating Part of Speech\n(POS) and Morphological annotations, and uuparser with multilingual training\nfor dependency parsing. ThamizhiPOSt is our POS tagger, which is based on the\nStanza, trained with Amrita POS-tagged corpus. It is the current\nstate-of-the-art in Tamil POS tagging with an F1 score of 93.27. Our\nmorphological analyzer, ThamizhiMorph is a rule-based system with a very good\ncoverage of Tamil. Our dependency parser ThamizhiUDp was trained using\nmultilingual data. It shows a Labelled Assigned Score (LAS) of 62.39, 4 points\nhigher than the current best achieved for Tamil dependency parsing. Therefore,\nwe show that breaking up the dependency parsing pipeline to accommodate\nexisting tools and resources is a viable approach for low-resource languages.", "published": "2020-12-24 20:20:50", "link": "http://arxiv.org/abs/2012.13436v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Why Neural Machine Translation Prefers Empty Outputs", "abstract": "We investigate why neural machine translation (NMT) systems assign high\nprobability to empty translations. We find two explanations. First, label\nsmoothing makes correct-length translations less confident, making it easier\nfor the empty translation to finally outscore them. Second, NMT systems use the\nsame, high-frequency EoS word to end all target sentences, regardless of\nlength. This creates an implicit smoothing that increases zero-length\ntranslations. Using different EoS types in target sentences of different\nlengths exposes and eliminates this implicit smoothing.", "published": "2020-12-24 22:25:22", "link": "http://arxiv.org/abs/2012.13454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Disentangling semantics in language through VAEs and a certain\n  architectural choice", "abstract": "We present an unsupervised method to obtain disentangled representations of\nsentences that single out semantic content. Using modified Transformers as\nbuilding blocks, we train a Variational Autoencoder to translate the sentence\nto a fixed number of hierarchically structured latent variables. We study the\ninfluence of each latent variable in generation on the dependency structure of\nsentences, and on the predicate structure it yields when passed through an Open\nInformation Extraction model. Our model could separate verbs, subjects, direct\nobjects, and prepositional objects into latent variables we identified. We show\nthat varying the corresponding latent variables results in varying these\nelements in sentences, and that swapping them between couples of sentences\nleads to the expected partial semantic swap.", "published": "2020-12-24 00:01:40", "link": "http://arxiv.org/abs/2012.13031v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ProofWriter: Generating Implications, Proofs, and Abductive Statements\n  over Natural Language", "abstract": "Transformers have been shown to emulate logical deduction over natural\nlanguage theories (logical rules expressed in natural language), reliably\nassigning true/false labels to candidate implications. However, their ability\nto generate implications of a theory has not yet been demonstrated, and methods\nfor reconstructing proofs of answers are imperfect. In this work we show that a\ngenerative model, called ProofWriter, can reliably generate both implications\nof a theory and the natural language proof(s) that support them. In particular,\niterating a 1-step implication generator results in proofs that are highly\nreliable, and represent actual model decisions (rather than post-hoc\nrationalizations). On the RuleTaker dataset, the accuracy of ProofWriter's\nproofs exceed previous methods by +9% absolute, and in a way that generalizes\nto proof depths unseen in training and on out-of-domain problems. We also show\nthat generative techniques can perform a type of abduction with high precision:\nGiven a theory and an unprovable conclusion, identify a missing fact that\nallows the conclusion to be proved, along with a proof. These results\nsignificantly improve the viability of neural methods for systematically\nreasoning over natural language.", "published": "2020-12-24 00:55:46", "link": "http://arxiv.org/abs/2012.13048v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "REM-Net: Recursive Erasure Memory Network for Commonsense Evidence\n  Refinement", "abstract": "When answering a question, people often draw upon their rich world knowledge\nin addition to the particular context. While recent works retrieve supporting\nfacts/evidence from commonsense knowledge bases to supply additional\ninformation to each question, there is still ample opportunity to advance it on\nthe quality of the evidence. It is crucial since the quality of the evidence is\nthe key to answering commonsense questions, and even determines the upper bound\non the QA systems performance. In this paper, we propose a recursive erasure\nmemory network (REM-Net) to cope with the quality improvement of evidence. To\naddress this, REM-Net is equipped with a module to refine the evidence by\nrecursively erasing the low-quality evidence that does not explain the question\nanswering. Besides, instead of retrieving evidence from existing knowledge\nbases, REM-Net leverages a pre-trained generative model to generate candidate\nevidence customized for the question. We conduct experiments on two commonsense\nquestion answering datasets, WIQA and CosmosQA. The results demonstrate the\nperformance of REM-Net and show that the refined evidence is explainable.", "published": "2020-12-24 10:07:32", "link": "http://arxiv.org/abs/2012.13185v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Granularity of Explanations in Model Agnostic NLP\n  Interpretability", "abstract": "Current methods for Black-Box NLP interpretability, like LIME or SHAP, are\nbased on altering the text to interpret by removing words and modeling the\nBlack-Box response. In this paper, we outline limitations of this approach when\nusing complex BERT-based classifiers: The word-based sampling produces texts\nthat are out-of-distribution for the classifier and further gives rise to a\nhigh-dimensional search space, which can't be sufficiently explored when time\nor computation power is limited. Both of these challenges can be addressed by\nusing segments as elementary building blocks for NLP interpretability. As\nillustration, we show that the simple choice of sentences greatly improves on\nboth of these challenges. As a consequence, the resulting explainer attains\nmuch better fidelity on a benchmark classification task.", "published": "2020-12-24 10:32:41", "link": "http://arxiv.org/abs/2012.13189v3", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "QUACKIE: A NLP Classification Task With Ground Truth Explanations", "abstract": "NLP Interpretability aims to increase trust in model predictions. This makes\nevaluating interpretability approaches a pressing issue. There are multiple\ndatasets for evaluating NLP Interpretability, but their dependence on human\nprovided ground truths raises questions about their unbiasedness. In this work,\nwe take a different approach and formulate a specific classification task by\ndiverting question-answering datasets. For this custom classification task, the\ninterpretability ground-truth arises directly from the definition of the\nclassification problem. We use this method to propose a benchmark and lay the\ngroundwork for future research in NLP interpretability by evaluating a wide\nrange of current state of the art methods.", "published": "2020-12-24 10:43:20", "link": "http://arxiv.org/abs/2012.13190v2", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Multi-modal Identification of State-Sponsored Propaganda on Social Media", "abstract": "The prevalence of state-sponsored propaganda on the Internet has become a\ncause for concern in the recent years. While much effort has been made to\nidentify state-sponsored Internet propaganda, the problem remains far from\nbeing solved because the ambiguous definition of propaganda leads to unreliable\ndata labelling, and the huge amount of potential predictive features causes the\nmodels to be inexplicable. This paper is the first attempt to build a balanced\ndataset for this task. The dataset is comprised of propaganda by three\ndifferent organizations across two time periods. A multi-model framework for\ndetecting propaganda messages solely based on the visual and textual content is\nproposed which achieves a promising performance on detecting propaganda by the\nthree organizations both for the same time period (training and testing on data\nfrom the same time period) (F1=0.869) and for different time periods (training\non past, testing on future) (F1=0.697). To reduce the influence of false\npositive predictions, we change the threshold to test the relationship between\nthe false positive and true positive rates and provide explanations for the\npredictions made by our models with visualization tools to enhance the\ninterpretability of our framework. Our new dataset and general framework\nprovide a strong benchmark for the task of identifying state-sponsored Internet\npropaganda and point out a potential path for future work on this task.", "published": "2020-12-24 00:43:09", "link": "http://arxiv.org/abs/2012.13042v1", "categories": ["cs.CL", "cs.AI", "cs.SI"], "primary_category": "cs.CL"}
{"title": "SubICap: Towards Subword-informed Image Captioning", "abstract": "Existing Image Captioning (IC) systems model words as atomic units in\ncaptions and are unable to exploit the structural information in the words.\nThis makes representation of rare words very difficult and out-of-vocabulary\nwords impossible. Moreover, to avoid computational complexity, existing IC\nmodels operate over a modest sized vocabulary of frequent words, such that the\nidentity of rare words is lost. In this work we address this common limitation\nof IC systems in dealing with rare words in the corpora. We decompose words\ninto smaller constituent units 'subwords' and represent captions as a sequence\nof subwords instead of words. This helps represent all words in the corpora\nusing a significantly lower subword vocabulary, leading to better parameter\nlearning. Using subword language modeling, our captioning system improves\nvarious metric scores, with a training vocabulary size approximately 90% less\nthan the baseline and various state-of-the-art word-level models. Our\nquantitative and qualitative results and analysis signify the efficacy of our\nproposed approach.", "published": "2020-12-24 06:10:36", "link": "http://arxiv.org/abs/2012.13122v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "WEmbSim: A Simple yet Effective Metric for Image Captioning", "abstract": "The area of automatic image caption evaluation is still undergoing intensive\nresearch to address the needs of generating captions which can meet adequacy\nand fluency requirements. Based on our past attempts at developing highly\nsophisticated learning-based metrics, we have discovered that a simple cosine\nsimilarity measure using the Mean of Word Embeddings(MOWE) of captions can\nactually achieve a surprisingly high performance on unsupervised caption\nevaluation. This inspires our proposed work on an effective metric WEmbSim,\nwhich beats complex measures such as SPICE, CIDEr and WMD at system-level\ncorrelation with human judgments. Moreover, it also achieves the best accuracy\nat matching human consensus scores for caption pairs, against commonly used\nunsupervised methods. Therefore, we believe that WEmbSim sets a new baseline\nfor any complex metric to be justified.", "published": "2020-12-24 06:39:43", "link": "http://arxiv.org/abs/2012.13137v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Unsupervised neural adaptation model based on optimal transport for\n  spoken language identification", "abstract": "Due to the mismatch of statistical distributions of acoustic speech between\ntraining and testing sets, the performance of spoken language identification\n(SLID) could be drastically degraded. In this paper, we propose an unsupervised\nneural adaptation model to deal with the distribution mismatch problem for\nSLID. In our model, we explicitly formulate the adaptation as to reduce the\ndistribution discrepancy on both feature and classifier for training and\ntesting data sets. Moreover, inspired by the strong power of the optimal\ntransport (OT) to measure distribution discrepancy, a Wasserstein distance\nmetric is designed in the adaptation loss. By minimizing the classification\nloss on the training data set with the adaptation loss on both training and\ntesting data sets, the statistical distribution difference between training and\ntesting domains is reduced. We carried out SLID experiments on the oriental\nlanguage recognition (OLR) challenge data corpus where the training and testing\ndata sets were collected from different conditions. Our results showed that\nsignificant improvements were achieved on the cross domain test tasks.", "published": "2020-12-24 07:37:19", "link": "http://arxiv.org/abs/2012.13152v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Detecting Hateful Memes Using a Multimodal Deep Ensemble", "abstract": "While significant progress has been made using machine learning algorithms to\ndetect hate speech, important technical challenges still remain to be solved in\norder to bring their performance closer to human accuracy. We investigate\nseveral of the most recent visual-linguistic Transformer architectures and\npropose improvements to increase their performance for this task. The proposed\nmodel outperforms the baselines by a large margin and ranks 5$^{th}$ on the\nleaderboard out of 3,100+ participants.", "published": "2020-12-24 13:01:44", "link": "http://arxiv.org/abs/2012.13235v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "I like fish, especially dolphins: Addressing Contradictions in Dialogue\n  Modeling", "abstract": "To quantify how well natural language understanding models can capture\nconsistency in a general conversation, we introduce the DialoguE COntradiction\nDEtection task (DECODE) and a new conversational dataset containing both\nhuman-human and human-bot contradictory dialogues. We then compare a structured\nutterance-based approach of using pre-trained Transformer models for\ncontradiction detection with the typical unstructured approach. Results reveal\nthat: (i) our newly collected dataset is notably more effective at providing\nsupervision for the dialogue contradiction detection task than existing NLI\ndata including those aimed to cover the dialogue domain; (ii) the structured\nutterance-based approach is more robust and transferable on both analysis and\nout-of-distribution dialogues than its unstructured counterpart. We also show\nthat our best contradiction detection model correlates well with human\njudgments and further provide evidence for its usage in both automatically\nevaluating and improving the consistency of state-of-the-art generative\nchatbots.", "published": "2020-12-24 18:47:49", "link": "http://arxiv.org/abs/2012.13391v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-channel Multi-frame ADL-MVDR for Target Speech Separation", "abstract": "Many purely neural network based speech separation approaches have been\nproposed to improve objective assessment scores, but they often introduce\nnonlinear distortions that are harmful to modern automatic speech recognition\n(ASR) systems. Minimum variance distortionless response (MVDR) filters are\noften adopted to remove nonlinear distortions, however, conventional neural\nmask-based MVDR systems still result in relatively high levels of residual\nnoise. Moreover, the matrix inverse involved in the MVDR solution is sometimes\nnumerically unstable during joint training with neural networks. In this study,\nwe propose a multi-channel multi-frame (MCMF) all deep learning (ADL)-MVDR\napproach for target speech separation, which extends our preliminary\nmulti-channel ADL-MVDR approach. The proposed MCMF ADL-MVDR system addresses\nlinear and nonlinear distortions. Spatio-temporal cross correlations are also\nfully utilized in the proposed approach. The proposed systems are evaluated\nusing a Mandarin audio-visual corpus and are compared with several\nstate-of-the-art approaches. Experimental results demonstrate the superiority\nof our proposed systems under different scenarios and across several objective\nevaluation metrics, including ASR performance.", "published": "2020-12-24 20:50:09", "link": "http://arxiv.org/abs/2012.13442v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Wheel-Rail Interface Condition Estimation (W-RICE)", "abstract": "The surface roughness between the wheel and rail has a huge influence on\nrolling noise level. The presence of the third body such as frost or grease at\nwheel-rail interface contributes towards change in adhesion coefficient\nresulting in the generation of noise at various levels. Therefore, it is\npossible to estimate adhesion conditions between the wheel and rail from the\nanalysis of noise patterns originating from wheel-rail interaction. In this\nstudy, a new approach to estimate adhesion condition is proposed which takes\nrolling noise as input.", "published": "2020-12-24 04:40:27", "link": "http://arxiv.org/abs/2012.13096v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
