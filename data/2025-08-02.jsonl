{"title": "End-to-End Personalization: Unifying Recommender Systems with Large Language Models", "abstract": "Recommender systems are essential for guiding users through the vast and\ndiverse landscape of digital content by delivering personalized and relevant\nsuggestions. However, improving both personalization and interpretability\nremains a challenge, particularly in scenarios involving limited user feedback\nor heterogeneous item attributes. In this article, we propose a novel hybrid\nrecommendation framework that combines Graph Attention Networks (GATs) with\nLarge Language Models (LLMs) to address these limitations. LLMs are first used\nto enrich user and item representations by generating semantically meaningful\nprofiles based on metadata such as titles, genres, and overviews. These\nenriched embeddings serve as initial node features in a user and movie\nbipartite graph, which is processed using a GAT based collaborative filtering\nmodel. To enhance ranking accuracy, we introduce a hybrid loss function that\ncombines Bayesian Personalized Ranking (BPR), cosine similarity, and robust\nnegative sampling. Post-processing involves reranking the GAT-generated\nrecommendations using the LLM, which also generates natural-language\njustifications to improve transparency. We evaluated our model on benchmark\ndatasets, including MovieLens 100k and 1M, where it consistently outperforms\nstrong baselines. Ablation studies confirm that LLM-based embeddings and the\ncosine similarity term significantly contribute to performance gains. This work\ndemonstrates the potential of integrating LLMs to improve both the accuracy and\ninterpretability of recommender systems.", "published": "2025-08-02 22:46:50", "link": "http://arxiv.org/abs/2508.01514v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Req-Rec: Enhancing Requirements Elicitation for Increasing Stakeholder's Satisfaction Using a Collaborative Filtering Based Recommender System", "abstract": "The success or failure of a project is highly related to recognizing the\nright stakeholders and accurately finding and discovering their requirements.\nHowever, choosing the proper elicitation technique was always a considerable\nchallenge for efficient requirement engineering. As a consequence of the swift\nimprovement of digital technologies since the past decade, recommender systems\nhave become an efficient channel for making a deeply personalized interactive\ncommunication with stakeholders. In this research, a new method, called the\nReq-Rec (Requirements Recommender), is proposed. It is a hybrid recommender\nsystem based on the collaborative filtering approach and the repertory grid\ntechnique as the core component. The primary goal of Req-Rec is to increase\nstakeholder satisfaction by assisting them in the requirement elicitation\nphase. Based on the results, the method efficiently could overcome weaknesses\nof common requirement elicitation techniques, such as time limitation,\nlocation-based restrictions, and bias in requirements' elicitation process.\nTherefore, recommending related requirements assists stakeholders in becoming\nmore aware of different aspects of the project.", "published": "2025-08-02 21:53:51", "link": "http://arxiv.org/abs/2508.01502v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation", "abstract": "In recommendation systems, predicting Click-Through Rate (CTR) is crucial for\naccurately matching users with items. To improve recommendation performance for\ncold-start and long-tail items, recent studies focus on leveraging item\nmultimodal features to model users' interests. However, obtaining multimodal\nrepresentations for items relies on complex pre-trained encoders, which incurs\nunacceptable computation cost to train jointly with downstream ranking models.\nTherefore, it is important to maintain alignment between semantic and behavior\nspace in a lightweight way.\n  To address these challenges, we propose a Semantic-Behavior Alignment for\nCold-start Recommendation framework, which mainly focuses on utilizing\nmultimodal representations that align with the user behavior space to predict\nCTR. First, we leverage domain-specific knowledge to train a multimodal encoder\nto generate behavior-aware semantic representations. Second, we use residual\nquantized semantic ID to dynamically bridge the gap between multimodal\nrepresentations and the ranking model, facilitating the continuous\nsemantic-behavior alignment. We conduct our offline and online experiments on\nthe Taobao, one of the world's largest e-commerce platforms, and have achieved\nan increase of 0.83% in offline AUC, 13.21% clicks increase and 13.44% orders\nincrease in the online A/B test, emphasizing the efficacy of our method.", "published": "2025-08-02 14:09:21", "link": "http://arxiv.org/abs/2508.01375v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "MaRGen: Multi-Agent LLM Approach for Self-Directed Market Research and Analysis", "abstract": "We present an autonomous framework that leverages Large Language Models\n(LLMs) to automate end-to-end business analysis and market report generation.\nAt its core, the system employs specialized agents - Researcher, Reviewer,\nWriter, and Retriever - that collaborate to analyze data and produce\ncomprehensive reports. These agents learn from real professional consultants'\npresentation materials at Amazon through in-context learning to replicate\nprofessional analytical methodologies. The framework executes a multi-step\nprocess: querying databases, analyzing data, generating insights, creating\nvisualizations, and composing market reports. We also introduce a novel\nLLM-based evaluation system for assessing report quality, which shows alignment\nwith expert human evaluations. Building on these evaluations, we implement an\niterative improvement mechanism that optimizes report quality through automated\nreview cycles. Experimental results show that report quality can be improved by\nboth automated review cycles and consultants' unstructured knowledge. In\nexperimental validation, our framework generates detailed 6-page reports in 7\nminutes at a cost of approximately \\$1. Our work could be an important step to\nautomatically create affordable market insights.", "published": "2025-08-02 13:49:15", "link": "http://arxiv.org/abs/2508.01370v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "BioDisco: Multi-agent hypothesis generation with dual-mode evidence, iterative feedback and temporal evaluation", "abstract": "Identifying novel hypotheses is essential to scientific research, yet this\nprocess risks being overwhelmed by the sheer volume and complexity of available\ninformation. Existing automated methods often struggle to generate novel and\nevidence-grounded hypotheses, lack robust iterative refinement and rarely\nundergo rigorous temporal evaluation for future discovery potential. To address\nthis, we propose BioDisco, a multi-agent framework that draws upon language\nmodel-based reasoning and a dual-mode evidence system (biomedical knowledge\ngraphs and automated literature retrieval) for grounded novelty, integrates an\ninternal scoring and feedback loop for iterative refinement, and validates\nperformance through pioneering temporal and human evaluations and a\nBradley-Terry paired comparison model to provide statistically-grounded\nassessment. Our evaluations demonstrate superior novelty and significance over\nablated configurations representative of existing agentic architectures.\nDesigned for flexibility and modularity, BioDisco allows seamless integration\nof custom language models or knowledge graphs, and can be run with just a few\nlines of code. We anticipate researchers using this practical tool as a\ncatalyst for the discovery of new hypotheses.", "published": "2025-08-02 09:32:52", "link": "http://arxiv.org/abs/2508.01285v1", "categories": ["cs.AI", "cs.ET", "cs.IR", "stat.AP"], "primary_category": "cs.AI"}
{"title": "A Study on Enhancing User Engagement by Employing Gamified Recommender Systems", "abstract": "Providing customized products and services in the modern business world is\none of the most efficient solutions to improve users' experience and their\nengagements with the industries. To aim, recommender systems, by producing\npersonalized recommendations, have a crucial role in the digital age. As a\nconsequence of modern improvements in the internet and online-based\ntechnologies, using gamification rules also increased in various fields. Recent\nstudies showed that considering gamification concepts in implementing\nrecommendation systems not only can become helpful to overcome the cold start\nand lack of sufficient data, moreover, can effectively improve user engagement.\nGamification can motivate individuals to have more activities on the system;\nthese interactions are valuable resources of data for recommender engines.\nUnlike the past related works about using gamified recommendation systems in\ndifferent environments or studies that particularly surveyed gamification\nstrategies or recommenders separately, this work provides a comprehensive\nreview of how gamified recommender systems can enhance user engagement in\nvarious domain applications. Furthermore, comparing different approaches for\nbuilding recommender systems is followed by in-depth surveying about\ninvestigating the gamified recommender systems, including their approaches,\nlimitations, evaluation metrics, proposed achievements, datasets, domain areas,\nand their recommendation techniques. This exhaustive analysis provides a\ndetailed picture of the topic's popularity, gaps, and unexplored regions. It is\nenvisaged that the proposed research and introduced possible future directions\nwould serve as a stepping stone for researchers interested in using gamified\nrecommender systems for user satisfaction and engagement.", "published": "2025-08-02 08:49:45", "link": "http://arxiv.org/abs/2508.01265v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "CM$^3$: Calibrating Multimodal Recommendation", "abstract": "Alignment and uniformity are fundamental principles within the domain of\ncontrastive learning. In recommender systems, prior work has established that\noptimizing the Bayesian Personalized Ranking (BPR) loss contributes to the\nobjectives of alignment and uniformity. Specifically, alignment aims to draw\ntogether the representations of interacting users and items, while uniformity\nmandates a uniform distribution of user and item embeddings across a unit\nhypersphere. This study revisits the alignment and uniformity properties within\nthe context of multimodal recommender systems, revealing a proclivity among\nextant models to prioritize uniformity to the detriment of alignment. Our\nhypothesis challenges the conventional assumption of equitable item treatment\nthrough a uniformity loss, proposing a more nuanced approach wherein items with\nsimilar multimodal attributes converge toward proximal representations within\nthe hyperspheric manifold. Specifically, we leverage the inherent similarity\nbetween items' multimodal data to calibrate their uniformity distribution,\nthereby inducing a more pronounced repulsive force between dissimilar entities\nwithin the embedding space. A theoretical analysis elucidates the relationship\nbetween this calibrated uniformity loss and the conventional uniformity\nfunction. Moreover, to enhance the fusion of multimodal features, we introduce\na Spherical B\\'ezier method designed to integrate an arbitrary number of\nmodalities while ensuring that the resulting fused features are constrained to\nthe same hyperspherical manifold. Empirical evaluations conducted on five\nreal-world datasets substantiate the superiority of our approach over competing\nbaselines. We also shown that the proposed methods can achieve up to a 5.4%\nincrease in NDCG@20 performance via the integration of MLLM-extracted features.\nSource code is available at: https://github.com/enoche/CM3.", "published": "2025-08-02 06:44:59", "link": "http://arxiv.org/abs/2508.01226v1", "categories": ["cs.IR", "cs.MM"], "primary_category": "cs.IR"}
{"title": "DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance System using Knowledge Graphs", "abstract": "The operation and maintenance (O&M) of database systems is critical to\nensuring system availability and performance, typically requiring expert\nexperience (e.g., identifying metric-to-anomaly relations) for effective\ndiagnosis and recovery. However, existing automatic database O&M methods,\nincluding commercial products, cannot effectively utilize expert experience. On\nthe one hand, rule-based methods only support basic O&M tasks (e.g.,\nmetric-based anomaly detection), which are mostly numerical equations and\ncannot effectively incorporate literal O&M experience (e.g., troubleshooting\nguidance in manuals). On the other hand, LLM-based methods, which retrieve\nfragmented information (e.g., standard documents + RAG), often generate\ninaccurate or generic results. To address these limitations, we present\nDBAIOps, a novel hybrid database O&M system that combines reasoning LLMs with\nknowledge graphs to achieve DBA-style diagnosis. First, DBAIOps introduces a\nheterogeneous graph model for representing the diagnosis experience, and\nproposes a semi-automatic graph construction algorithm to build that graph from\nthousands of documents. Second, DBAIOps develops a collection of (800+)\nreusable anomaly models that identify both directly alerted metrics and\nimplicitly correlated experience and metrics. Third, for each anomaly, DBAIOps\nproposes a two-stage graph evolution mechanism to explore relevant diagnosis\npaths and identify missing relations automatically. It then leverages a\nreasoning LLM (e.g., DeepSeek-R1) to infer root causes and generate clear\ndiagnosis reports for both DBAs and common users. Our evaluation over four\nmainstream database systems (Oracle, MySQL, PostgreSQL, and DM8) demonstrates\nthat DBAIOps outperforms state-of-the-art baselines, 34.85% and 47.22% higher\nin root cause and human evaluation accuracy, respectively.", "published": "2025-08-02 01:36:57", "link": "http://arxiv.org/abs/2508.01136v1", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.DB"}
{"title": "Towards Bridging Review Sparsity in Recommendation with Textual Edge Graph Representation", "abstract": "Textual reviews enrich recommender systems with fine-grained preference\nsignals and enhanced explainability. However, in real-world scenarios, users\nrarely leave reviews, resulting in severe sparsity that undermines the\neffectiveness of existing models. A natural solution is to impute or generate\nmissing reviews to enrich the data. However, conventional imputation techniques\n-- such as matrix completion and LLM-based augmentation -- either lose\ncontextualized semantics by embedding texts into vectors, or overlook\nstructural dependencies among user-item interactions. To address these\nshortcomings, we propose TWISTER (ToWards Imputation on Sparsity with Textual\nEdge Graph Representation), a unified framework that imputes missing reviews by\njointly modeling semantic and structural signals. Specifically, we represent\nuser-item interactions as a Textual-Edge Graph (TEG), treating reviews as edge\nattributes. To capture relational context, we construct line-graph views and\nemploy a large language model as a graph-aware aggregator. For each interaction\nlacking a textual review, our model aggregates the neighborhood's\nnatural-language representations to generate a coherent and personalized\nreview. Experiments on the Amazon and Goodreads datasets show that TWISTER\nconsistently outperforms traditional numeric, graph-based, and LLM baselines,\ndelivering higher-quality imputed reviews and, more importantly, enhanced\nrecommendation performance. In summary, TWISTER generates reviews that are more\nhelpful, authentic, and specific, while smoothing structural signals for\nimproved recommendations.", "published": "2025-08-02 00:53:40", "link": "http://arxiv.org/abs/2508.01128v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Information Rates of Approximate Message Passing for Bandlimited Direct-Detection Channels", "abstract": "The capacity of bandlimited direct-detection channels is difficult to compute\nor approach because of the receiver nonlinearity. A generalized vector\napproximate message passing (GVAMP) detector is designed to achieve high rates\nwith reasonable complexity. The rates increase by using multi-level coding and\nsuccessive interference cancellation. The methods are applied to optical fiber\nchannels with long intersymbol interference, as encountered in practice.\nBipolar modulation operates within 0.3 bits per channel use (bpcu) of the\nreal-alphabet coherent capacity for optically-amplified links, improving the\nbest existing gap of 1 bpcu based on theory. Remarkably, bipolar modulation\ngains 6 decibels (dB) in power efficiency over unipolar modulation, and 3 dB\nfor unamplified links. The detector is robust to changes in channel parameters\nsuch as the fiber length. The GVAMP complexity, measured in multiplications per\ninformation bit (mpib), is proportional to the number of iterations and the\nlogarithm of the block length, and is substantially less than state-of-the-art\nneural networks. The receiver requires approximately 38 iterations to achieve a\nrate of 5 bpcu with 80 mpib.", "published": "2025-08-02 16:57:53", "link": "http://arxiv.org/abs/2508.01438v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Characterization and Evaluation of Doppler Squint in Wideband ODDM Systems", "abstract": "The recently proposed orthogonal delay-Doppler division multiplexing (ODDM)\nmodulation has been demonstrated to enjoy excellent reliability over\ndoubly-dispersive channels. However, most of the prior analysis tends to ignore\nthe interactive dispersion caused by the wideband property of ODDM signal,\nwhich possibly leads to performance degradation. To solve this problem, we\ninvestigate the input-output relation of ODDM systems considering the wideband\neffect, which is also known as the Doppler squint effect (DSE) in the\nliterature. The extra delay-Doppler (DD) dispersion caused by the DSE is first\nexplicitly explained by employing the time-variant frequency response of\nmultipath channels. Its characterization is then derived for both reduced\ncyclic prefix (RCP) and zero padded (ZP)-based wideband ODDM systems, where the\nextra DD spread and more complicated power leakage outside the peak region are\npresented theoretically. Numerical results are finally provided to confirm the\nsignificance of DSE. The derivations in this paper are beneficial for\ndeveloping accurate signal processing techniques in ODDM-based integrated\nsensing and communication systems.", "published": "2025-08-02 09:27:09", "link": "http://arxiv.org/abs/2508.01283v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "New constant-dimension subspace codes from parallel cosets of optimal Ferrers diagram rank-metric codes and multilevel inserting constructions", "abstract": "Constant-dimension subspace codes (CDCs), a special class of subspace codes,\nhave attracted significant attention due to their applications in network\ncoding. A fundamental research problem of CDCs is to determine the maximum\nnumber of codewords under the given parameters. The paper first proposes the\nconstruction of parallel cosets of optimal Ferrers diagram rank-metric codes\n(FDRMCs) by employing the list of CDCs and inverse list of CDCs. Then a new\nclass of CDCs is obtained by combining the parallel cosets of optimal FDRMCs\nwith parallel linkage construction. Next, we present a novel set of identifying\nvectors and provide a new construction of CDCs via the multilevel constuction.\nFinally, the coset construction is inserted into the multilevel construction\nand three classes of large CDCs are provided, one of which is constructed by\nusing new optimal FDRMCs. Our results establish at least 65 new lower bounds\nfor CDCs with larger sizes than the previously best known codes.", "published": "2025-08-02 08:15:44", "link": "http://arxiv.org/abs/2508.01258v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Towed Movable Antenna (ToMA) Array for Ultra Secure Airborne Communications", "abstract": "This paper proposes a novel towed movable antenna (ToMA) array architecture\nto enhance the physical layer security of airborne communication systems.\nUnlike conventional onboard arrays with fixed-position antennas (FPAs), the\nToMA array employs multiple subarrays mounted on flexible cables and towed by\ndistributed drones, enabling agile deployment in three-dimensional (3D) space\nsurrounding the central aircraft. This design significantly enlarges the\neffective array aperture and allows dynamic geometry reconfiguration, offering\nsuperior spatial resolution and beamforming flexibility. We consider a secure\ntransmission scenario where an airborne transmitter communicates with multiple\nlegitimate users in the presence of potential eavesdroppers. To ensure\nsecurity, zero-forcing beamforming is employed to nullify signal leakage toward\neavesdroppers. Based on the statistical distributions of locations of users and\neavesdroppers, the antenna position vector (APV) of the ToMA array is optimized\nto maximize the users' ergodic achievable rate. Analytical results for the case\nof a single user and a single eavesdropper reveal the optimal APV structure\nthat minimizes their channel correlation. For the general multiuser scenario,\nwe develop a low-complexity alternating optimization algorithm by leveraging\nRiemannian manifold optimization. Simulation results confirm that the proposed\nToMA array achieves significant performance gains over conventional onboard FPA\narrays, especially in scenarios where eavesdroppers are closely located to\nusers under line-of-sight (LoS)-dominant channels.", "published": "2025-08-02 06:54:24", "link": "http://arxiv.org/abs/2508.01229v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Near-Field Communication with Massive Movable Antennas: A Functional Perspective", "abstract": "The advent of massive multiple-input multiple-output (MIMO) technology has\nprovided new opportunities for capacity improvement via strategic antenna\ndeployment, especially when the near-field effect is pronounced due to antenna\nproliferation. In this paper, we investigate the optimal antenna placement for\nmaximizing the achievable rate of a point-to-point near-field channel, where\nthe transmitter is deployed with massive movable antennas. First, we propose a\nnovel design framework to explore the relationship between antenna positions\nand achievable data rate. By introducing the continuous antenna position\nfunction (APF) and antenna density function (ADF), we reformulate the antenna\nposition design problem from the discrete to the continuous domain, which\nmaximizes the achievable rate functional with respect to ADF. Leveraging\nfunctional analysis and variational methods, we derive the optimal ADF\ncondition and propose a gradient-based algorithm for numerical solutions under\ngeneral channel conditions. Furthermore, for the near-field line-of-sight (LoS)\nscenario, we present a closed-form solution for the optimal ADF, revealing the\ncritical role of edge antenna density in enhancing the achievable rate.\nFinally, we propose a flexible antenna array-based deployment method that\nensures practical implementation while mitigating mutual coupling issues.\nSimulation results demonstrate the effectiveness of the proposed framework,\nwith uniform circular arrays emerging as a promising geometry for balancing\nperformance and deployment feasibility in near-field communications.", "published": "2025-08-02 05:28:27", "link": "http://arxiv.org/abs/2508.01201v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Construction of $(n,n)$-functions with low differential-linear uniformity", "abstract": "The differential-linear connectivity table (DLCT), introduced by Bar-On et\nal. at EUROCRYPT'19, is a novel tool that captures the dependency between the\ntwo subciphers involved in differential-linear attacks. This paper is devoted\nto exploring the differential-linear properties of $(n,n)$-functions. First, by\nrefining specific exponential sums, we propose two classes of power functions\nover $\\mathbb{F}_{2^n}$ with low differential-linear uniformity (DLU). Next, we\nfurther investigate the differential-linear properties of $(n,n)$-functions\nthat are polynomials by utilizing power functions with known DLU. Specifically,\nby combining a cubic function with quadratic functions, and employing\ngeneralized cyclotomic mappings, we construct several classes of\n$(n,n)$-functions with low DLU, including some that achieve optimal or\nnear-optimal DLU compared to existing results.", "published": "2025-08-02 04:33:22", "link": "http://arxiv.org/abs/2508.01190v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Decentralized Aerial Manipulation of a Cable-Suspended Load using Multi-Agent Reinforcement Learning", "abstract": "This paper presents the first decentralized method to enable real-world 6-DoF\nmanipulation of a cable-suspended load using a team of Micro-Aerial Vehicles\n(MAVs). Our method leverages multi-agent reinforcement learning (MARL) to train\nan outer-loop control policy for each MAV. Unlike state-of-the-art controllers\nthat utilize a centralized scheme, our policy does not require global states,\ninter-MAV communications, nor neighboring MAV information. Instead, agents\ncommunicate implicitly through load pose observations alone, which enables high\nscalability and flexibility. It also significantly reduces computing costs\nduring inference time, enabling onboard deployment of the policy. In addition,\nwe introduce a new action space design for the MAVs using linear acceleration\nand body rates. This choice, combined with a robust low-level controller,\nenables reliable sim-to-real transfer despite significant uncertainties caused\nby cable tension during dynamic 3D motion. We validate our method in various\nreal-world experiments, including full-pose control under load model\nuncertainties, showing setpoint tracking performance comparable to the\nstate-of-the-art centralized method. We also demonstrate cooperation amongst\nagents with heterogeneous control policies, and robustness to the complete\nin-flight loss of one MAV. Videos of experiments:\nhttps://autonomousrobots.nl/paper_websites/aerial-manipulation-marl", "published": "2025-08-02 23:52:33", "link": "http://arxiv.org/abs/2508.01522v1", "categories": ["cs.RO", "cs.AI", "cs.MA", "I.2.9; I.2.11; I.2.6"], "primary_category": "cs.RO"}
{"title": "MARS: A Meta-Adaptive Reinforcement Learning Framework for Risk-Aware Multi-Agent Portfolio Management", "abstract": "Reinforcement Learning (RL) has shown significant promise in automated\nportfolio management; however, effectively balancing risk and return remains a\ncentral challenge, as many models fail to adapt to dynamically changing market\nconditions. In this paper, we propose Meta-controlled Agents for a Risk-aware\nSystem (MARS), a novel RL framework designed to explicitly address this\nlimitation through a multi-agent, risk-aware approach. Instead of a single\nmonolithic model, MARS employs a Heterogeneous Agent Ensemble where each agent\npossesses a unique, intrinsic risk profile. This profile is enforced by a\ndedicated Safety-Critic network and a specific risk-tolerance threshold,\nallowing agents to specialize in behaviors ranging from capital preservation to\naggressive growth. To navigate different market regimes, a high-level\nMeta-Adaptive Controller (MAC) learns to dynamically orchestrate the ensemble.\nBy adjusting its reliance on conservative versus aggressive agents, the MAC\neffectively lowers portfolio volatility during downturns and seeks higher\nreturns in bull markets, thus minimizing maximum drawdown and enhancing overall\nstability. This two-tiered structure allows MARS to generate a disciplined and\nadaptive portfolio that is robust to market fluctuations. The framework\nachieves a superior balance between risk and return by leveraging behavioral\ndiversity rather than explicit market-feature engineering. Experiments on major\ninternational stock indexes, including periods of significant financial crisis,\ndemonstrate the efficacy of our framework on risk-adjusted criteria,\nsignificantly reducing maximum drawdown and volatility while maintaining\ncompetitive returns.", "published": "2025-08-02 03:23:41", "link": "http://arxiv.org/abs/2508.01173v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "The Vanishing Gradient Problem for Stiff Neural Differential Equations", "abstract": "Gradient-based optimization of neural differential equations and other\nparameterized dynamical systems fundamentally relies on the ability to\ndifferentiate numerical solutions with respect to model parameters. In stiff\nsystems, it has been observed that sensitivities to parameters controlling\nfast-decaying modes become vanishingly small during training, leading to\noptimization difficulties. In this paper, we show that this vanishing gradient\nphenomenon is not an artifact of any particular method, but a universal feature\nof all A-stable and L-stable stiff numerical integration schemes. We analyze\nthe rational stability function for general stiff integration schemes and\ndemonstrate that the relevant parameter sensitivities, governed by the\nderivative of the stability function, decay to zero for large stiffness.\nExplicit formulas for common stiff integration schemes are provided, which\nillustrate the mechanism in detail. Finally, we rigorously prove that the\nslowest possible rate of decay for the derivative of the stability function is\n$O(|z|^{-1})$, revealing a fundamental limitation: all A-stable time-stepping\nmethods inevitably suppress parameter gradients in stiff regimes, posing a\nsignificant barrier for training and parameter identification in stiff neural\nODEs.", "published": "2025-08-02 23:44:14", "link": "http://arxiv.org/abs/2508.01519v1", "categories": ["cs.LG", "cs.AI", "cs.NA", "cs.SY", "eess.SY", "math.NA"], "primary_category": "cs.LG"}
{"title": "Extended Interface Physics-Informed Neural Networks Method for Moving Interface Problems", "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful class of\nmesh-free numerical methods for solving partial differential equations (PDEs),\nparticularly those involving complex geometries. In this work, we present an\ninnovative Extended Interface Physics-Informed Neural Network (XI-PINN)\nframework specifically designed to solve parabolic moving interface problems.\nThe proposed approach incorporates a level set function to characterize the\ninterface, which can be obtained either directly or through a neural network\nsolution. We conduct a rigorous a priori error analysis for the XI-PINN method,\nproviding error bounds for the approximation. Leveraging the Neural Tangent\nKernel (NTK) theory, we further demonstrate that XI-PINN achieves a faster\ntraining convergence rate compared to conventional PINN approaches. The\nmethod's versatility is further demonstrated by its application to the Oseen\nequations. We perform comprehensive numerical experiments to validate the\nefficacy, accuracy, and robustness of the proposed framework.", "published": "2025-08-02 18:41:58", "link": "http://arxiv.org/abs/2508.01463v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Singular values of sparse random rectangular matrices: Emergence of outliers at criticality", "abstract": "Consider the random bipartite Erd\\H{o}s-R\\'{e}nyi graph $\\mathbb{G}(n, m,\np)$, where each edge with one vertex in $V_{1}=[n]$ and the other vertex in\n$V_{2} =[m]$ is connected with probability $p$, and $n=\\lfloor \\gamma m\\rfloor$\nfor a constant aspect ratio $\\gamma \\geq 1$. It is well known that the\nempirical spectral measure of its centered and normalized adjacency matrix\nconverges to the Mar\\v{c}enko-Pastur (MP) distribution. However, largest and\nsmallest singular values may not converge to the right and left edges,\nrespectively, especially when $p = o(1)$. Notably, it was proved by Dumitriu\nand Zhu (2024) that there are almost surely no singular value outside the\ncompact support of the MP law when $np = \\omega(\\log(n))$. In this paper, we\nconsider the critical sparsity regime where $p = b\\log(n)/\\sqrt{mn}$ for some\nconstant $b>0$. We quantitatively characterize the emergence of outlier\nsingular values as follows. For explicit $b_{*}$ and $b^{*}$ functions of\n$\\gamma$, we prove that when $b > b_{*}$, there is no outlier outside the bulk;\nwhen $b^{*}< b < b_{*}$, outliers are present only outside the right edge of\nthe MP law; and when $b < b^{*}$, outliers are present on both sides, all with\nhigh probability. Moreover, locations of those outliers are precisely\ncharacterized by a function depending on the largest and smallest degree\nvertices of the random graph. We estimate the number of outliers as well. Our\nresults follow the path forged by Alt, Ducatez and Knowles (2021), and can be\nextended to sparse random rectangular matrices with bounded entries.", "published": "2025-08-02 18:14:27", "link": "http://arxiv.org/abs/2508.01456v1", "categories": ["math.PR", "cs.NA", "math.CO", "math.NA", "math.ST", "stat.TH"], "primary_category": "math.PR"}
{"title": "Accelerating Convergence in Series and Infinite Integrals: Revisiting Levin and Sidi's Contributions", "abstract": "The evaluation of slowly converging series and infinite integrals is a key\nchallenge in numerical analysis and computational mathematics. In their\ninfluential 1981 paper, the author and Avram Sidi introduced two effective\nnonlinear transformations, the d-transformation for series and the\nD-transformation for infinite integrals, aimed at speeding up their\nconvergence. This review summarizes, contextualizes, and evaluates their\ncontributions, highlighting the mathematical basis, practical significance, and\nlegacy of their work.", "published": "2025-08-02 15:24:57", "link": "http://arxiv.org/abs/2508.01406v1", "categories": ["math.NA", "cs.NA", "40A05, 40A20, 65D30"], "primary_category": "math.NA"}
{"title": "Construction of Bases in Modules over Laurent Polynomial Rings and Applications to Box Spline Prewavelets", "abstract": "We suggest a new method of basis construction for the kernel of a linear form\non the Laurent polynomial module related to multivariate wavelets, and\ndemonstrate its applications to box spline prewavelets, leading to small mask\nsupports for $C^1$ cubic and $C^2$ quartic box splines in two variables,\noutperforming previously known constructions, and to trivariate piecewise\nlinear prewavelets with at most 23 nozero mask coefficients.", "published": "2025-08-02 15:14:36", "link": "http://arxiv.org/abs/2508.01399v1", "categories": ["math.NA", "cs.NA", "math.AC", "42C40, 65T60, 13C10"], "primary_category": "math.NA"}
{"title": "PGD-based local surrogate models via overlapping domain decomposition: a computational comparison", "abstract": "An efficient strategy to construct physics-based local surrogate models for\nparametric linear elliptic problems is presented. The method relies on proper\ngeneralized decomposition (PGD) to reduce the dimensionality of the problem and\non an overlapping domain decomposition (DD) strategy to decouple the spatial\ndegrees of freedom. In the offline phase, the local surrogate model is computed\nin a non-intrusive way, exploiting the linearity of the operator and imposing\narbitrary Dirichlet conditions, independently at each node of the interface, by\nmeans of the traces of the finite element functions employed for the\ndiscretization inside the subdomain. This leads to parametric subproblems with\nreduced dimensionality, significantly decreasing the complexity of the involved\ncomputations and achieving speed-ups up to 100 times with respect to a\npreviously proposed DD-PGD algorithm that required clustering the interface\nnodes. A fully algebraic alternating Schwarz method is then formulated to\ncouple the subdomains in the online phase, leveraging the real-time (less than\nhalf a second) evaluation capabilities of the computed local surrogate models,\nthat do not require the solution of any additional low-dimensional problems. A\ncomputational comparison of different PGD-based local surrogate models is\npresented using a set of numerical benchmarks to showcase the superior\nperformance of the proposed methodology, both in the offline and in the online\nphase.", "published": "2025-08-02 11:04:21", "link": "http://arxiv.org/abs/2508.01313v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Wiener chaos expansion for stochastic Maxwell equations driven by Wiener process", "abstract": "A novel and efficient algorithm based on the Wiener chaos expansion is\nproposed for the stochastic Maxwell equations driven by Wiener process. The\nproposed algorithm can reduce the original stochastic system to the\ndeterministic case and separate the randomness in the computation. Therefore,\nit can yield a significant improvement of efficiency and lead to less\ncomputational errors compared to the Monte Carlo method, since the statistics\nof the solution can be solved directly without repeating over many\nrealizations. In particular, the proposed algorithm could inherit the\nmulti-symplecticity. Numerical experiments are dedicated to performing the\nefficiency and accuracy of the Wiener chaos expansion algorithm.", "published": "2025-08-02 09:06:13", "link": "http://arxiv.org/abs/2508.01271v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A linear, mass-conserving, multi-time-step compact block-centered finite difference method for incompressible miscible displacement problem in porous media", "abstract": "In this paper, a two-dimensional incompressible miscible displacement model\nis considered, and a novel decoupled and linearized high-order finite\ndifference scheme is developed, by utilizing the multi-time-step strategy to\ntreat the different time evolutions of concentration and velocity/pressure, and\nthe compact block-centered finite difference approximation for spatial\ndiscretization. We show that the scheme is mass-conserving, and has\nsecond-order temporal accuracy and fourth-order spatial accuracy for the\nconcentration, the velocity and the pressure simultaneously. The existence and\nuniqueness of the developed scheme under a rough time-step condition is also\nproved following the convergence results. Numerical experiments are presented\nto confirm the theoretical conclusions. Besides, some 'real' simulations are\nalso tested to show good performance of the proposed scheme, in particular, the\nviscous fingering phenomenon is verified.", "published": "2025-08-02 08:13:50", "link": "http://arxiv.org/abs/2508.01256v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Finite element conformal complexes in three dimensions", "abstract": "This paper extends the Bernstein-Gelfand-Gelfand (BGG) framework to the\nconstruction of finite element conformal Hessian complexes and conformal\nelasticity complexes in three dimensions involving conformal tensors (i.e.,\nsymmetric and traceless tensors). These complexes incorporate higher-order\ndifferential operators, including the linearized Cotton-York operator, and\nrequire conformal tensor spaces with nontrivial smoothness and trace\nconditions. A novel application of the discrete BGG framework, combined with\nthe geometric decomposition of bubble spaces and a reduction operation, to\nlocal bubble finite element complexes is introduced. This yields simpler and\nmore tractable constructions than global BGG-based approaches, and leads to the\nbubble conformal complexes. Building on these bubble conformal complexes and\nthe associated face bubble complexes, finite element conformal Hessian\ncomplexes and conformal elasticity complexes with varying degrees of smoothness\nare systematically developed. The resulting complexes support stable and\nstructure-preserving numerical methods for applications in relativity, Cosserat\nelasticity, and fluid mechanics.", "published": "2025-08-02 07:24:04", "link": "http://arxiv.org/abs/2508.01238v1", "categories": ["math.NA", "cs.NA", "65N30, 58J10, 65N12"], "primary_category": "math.NA"}
{"title": "Implementation of Worsey-Farin splines with applications to solution transfer", "abstract": "This work primarily focuses on providing full implementation details for\nWorsey-Farin (WF) spline interpolation over tetrahedral elements. While this\nspline space is not new and the theory has been covered in other works, there\nis a lack of explicit and comprehensive implementation details, which we hope\nto provide. In this paper, we also demonstrate the effectiveness of the\nWF-spline space through a simple target application: solution transfer.\nMoreover, we derive an error estimate for the WF spline-based, solution\ntransfer process. We conduct numerical experiments quantifying the conservative\nnature and order of accuracy of the transfer process, and we present a\nqualitative evaluation of the visualization properties of the smoothed\nsolution. Additionally, in our study of conservation, we demonstrate how\nadaptive numerical quadrature rules on the tetrahedron used in conjunction with\nglobal L2-projection can improve the conservation of the solution transfer\nprocess.", "published": "2025-08-02 04:48:18", "link": "http://arxiv.org/abs/2508.01193v1", "categories": ["math.NA", "cs.NA", "41A15, 65D07"], "primary_category": "math.NA"}
{"title": "From Taylor Series to Fourier Synthesis: The Periodic Linear Unit", "abstract": "The dominant paradigm in modern neural networks relies on simple,\nmonotonically-increasing activation functions like ReLU. While effective, this\nparadigm necessitates large, massively-parameterized models to approximate\ncomplex functions. In this paper, we introduce the Periodic Linear Unit (PLU),\na learnable sine-wave based activation with periodic non-monotonicity. PLU is\ndesigned for maximum expressive power and numerical stability, achieved through\nits formulation and a paired innovation we term Repulsive Reparameterization,\nwhich prevents the activation from collapsing into a non-expressive linear\nfunction. We demonstrate that a minimal MLP with only two PLU neurons can solve\nthe spiral classification task, a feat impossible for equivalent networks using\nstandard activations. This suggests a paradigm shift from networks as piecewise\nTaylor-like approximators to powerful Fourier-like function synthesizers,\nachieving exponential gains in parameter efficiency by placing intelligence in\nthe neuron itself.", "published": "2025-08-02 03:26:48", "link": "http://arxiv.org/abs/2508.01175v1", "categories": ["cs.LG", "cs.NA", "cs.NE", "math.NA", "68T07 (Primary) 42A10, 41A30, 65D15 (Secondary)", "I.5.1; G.1.2; G.1.6; I.2.6"], "primary_category": "cs.LG"}
{"title": "Error estimates of linear decoupled structure-preserving incremental viscosity splitting methods for the Cahn--Hilliard--Navier--Stokes system", "abstract": "We propose first- and second-order time discretization schemes for the\ncoupled Cahn--Hilliard--Navier--Stokes model, leveraging the incremental\nviscosity splitting (IVS) method. The schemes combine the scalar auxiliary\nvariable method and the zero-energy-contribution approach, resulting in a\nlinear, decoupled numerical framework. At each time step, they only require to\nsolve a sequence of constant-coefficient equations, along with a linear\nequation with one unknown, making the algorithms computationally efficient and\neasy to implement. In addition, the proposed schemes are proven to be uniquely\nsolvable, mass-conserving, and unconditional energy dissipation. Most\nimportantly, leveraging the mathematical induction method and the regularity\nproperties of the Stokes equation, we perform a rigorous error analysis for the\nfirst-order scheme in multiple space dimensions, establishing an unconditional\nand optimal convergence rate for all relevant variables under different norms.\nA user-defined, time-dependent parameter plays an important role in the error\nanalysis of the proposed structure-preserving IVS methods. Ample numerical\nexamples are carried out to verify the theoretical findings and to demonstrate\nthe accuracy, effectiveness and efficiency of the proposed schemes.", "published": "2025-08-02 01:48:04", "link": "http://arxiv.org/abs/2508.01141v1", "categories": ["math.NA", "cs.NA", "35Q35, 65M12, 65M15, 76D05"], "primary_category": "math.NA"}
{"title": "The essential spectrum of periodically stationary pulses in lumped models of short-pulse fiber lasers", "abstract": "In modern short pulse fiber lasers there is significant pulse breathing over\neach round trip of the laser loop. Consequently, averaged models cannot be used\nfor quantitative modeling and design. Instead, lumped models, which are\nobtained by concatenating models for the various components of the laser, are\nrequired. Since the pulses in lumped models are periodic rather than\nstationary, their linear stability is evaluated with the aid of the monodromy\noperator obtained by linearizing the round trip operator about the periodic\npulse. Conditions are given on the smoothness and decay of the periodic pulse\nwhich ensure that the monodromy operator exists on an appropriate Lebesgue\nfunction space. A formula for the essential spectrum of the monodromy operator\nis given which can be used to quantify the growth rate of continuous wave\nperturbations. This formula is established by showing that the essential\nspectrum of the monodromy operator equals that of an associated asymptotic\noperator. Since the asymptotic monodromy operator acts as a multiplication\noperator in the Fourier domain, it is possible to derive a formula for its\nspectrum. Although the main results are stated for a particular experimental\nstretched pulse laser, the analysis shows that they can be readily adapted to a\nwide range of lumped laser models.", "published": "2025-08-02 01:30:00", "link": "http://arxiv.org/abs/2508.01133v1", "categories": ["physics.optics", "cs.NA", "math.FA", "math.NA", "math.SP", "35B10, 35Q56, 37L15, 47D06, 78A60 (Primary)"], "primary_category": "physics.optics"}
{"title": "Central Limit Theorems for Transition Probabilities of Controlled Markov Chains", "abstract": "We develop a central limit theorem (CLT) for the non-parametric estimator of\nthe transition matrices in controlled Markov chains (CMCs) with finite\nstate-action spaces. Our results establish precise conditions on the logging\npolicy under which the estimator is asymptotically normal, and reveal settings\nin which no CLT can exist. We then build upon it to derive CLTs for the value,\nQ-, and advantage functions of any stationary stochastic policy, including the\noptimal policy recovered from the estimated model. Goodness-of-fit tests are\nderived as a corollary, which enable us to test whether the logged data is\nstochastic. These results provide new statistical tools for offline policy\nevaluation and optimal policy recovery, and enable hypothesis tests for\ntransition probabilities.", "published": "2025-08-02 23:33:57", "link": "http://arxiv.org/abs/2508.01517v1", "categories": ["math.ST", "math.PR", "stat.ML", "stat.TH", "Primary 60F05, Secondary 60J05, 62M05, 93E20", "G.3; I.2.6; I.2.8"], "primary_category": "math.ST"}
{"title": "NICE^k Metrics: Unified and Multidimensional Framework for Evaluating Deterministic Solar Forecasting Accuracy", "abstract": "Accurate solar energy output prediction is key for integrating renewables\ninto grids, maintaining stability, and improving energy management. However,\nstandard error metrics such as Root Mean Squared Error (RMSE), Mean Absolute\nError (MAE), and Skill Scores (SS) fail to capture the multidimensional nature\nof solar irradiance forecasting. These metrics lack sensitivity to\nforecastability, rely on arbitrary baselines (e.g., clear-sky models), and are\npoorly suited for operational use.\n  To address this, we introduce the NICEk framework (Normalized Informed\nComparison of Errors, with k = 1, 2, 3, Sigma), offering a robust and\ninterpretable evaluation of forecasting models. Each NICEk score corresponds to\nan Lk norm: NICE1 targets average errors, NICE2 emphasizes large deviations,\nNICE3 highlights outliers, and NICESigma combines all.\n  Using Monte Carlo simulations and data from 68 stations in the Spanish SIAR\nnetwork, we evaluated methods including autoregressive models, extreme\nlearning, and smart persistence. Theoretical and empirical results align when\nassumptions hold (e.g., R^2 ~ 1.0 for NICE2). Most importantly, NICESigma\nconsistently shows higher discriminative power (p < 0.05), outperforming\ntraditional metrics (p > 0.05).\n  The NICEk metrics exhibit stronger statistical significance (e.g., p-values\nfrom 10^-6 to 0.004 across horizons) and greater generalizability. They offer a\nunified and operational alternative to standard error metrics in deterministic\nsolar forecasting.", "published": "2025-08-02 18:20:12", "link": "http://arxiv.org/abs/2508.01457v1", "categories": ["physics.ao-ph", "stat.ML"], "primary_category": "physics.ao-ph"}
{"title": "Kernel-Based Sparse Additive Nonlinear Model Structure Detection through a Linearization Approach", "abstract": "The choice of parameterization in Nonlinear (NL) system models greatly\naffects the quality of the estimated model. Overly complex models can be\nimpractical and hard to interpret, necessitating data-driven methods for\nsimpler and more accurate representations. In this paper, we propose a\ndata-driven approach to simplify a class of continuous-time NL system models\nusing linear approximations around varying operating points. Specifically, for\nsparse additive NL models, our method identifies the number of NL subterms and\ntheir corresponding input spaces. Under small-signal operation, we approximate\nthe unknown NL system as a trajectory-scheduled Linear Parameter-Varying (LPV)\nsystem, with LPV coefficients representing the gradient of the NL function and\nindicating input sensitivity. Using this sensitivity measure, we determine the\nNL system's structure through LPV model reduction by identifying non-zero LPV\ncoefficients and selecting scheduling parameters. We introduce two sparse\nestimators within a vector-valued Reproducing Kernel Hilbert Space (RKHS)\nframework to estimate the LPV coefficients while preserving their structural\nrelationships. The structure of the sparse additive NL model is then determined\nby detecting non-zero elements in the gradient vector (LPV coefficients) and\nthe Hessian matrix (Jacobian of the LPV coefficients). We propose two\ncomputationally tractable RKHS-based estimators for this purpose. The\nsparsified Hessian matrix reveals the NL model's structure, with numerical\nsimulations confirming the approach's effectiveness.", "published": "2025-08-02 18:02:44", "link": "http://arxiv.org/abs/2508.01453v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "stat.ML"], "primary_category": "eess.SY"}
{"title": "Effects of Feature Correlations on Associative Memory Capacity", "abstract": "We investigate how feature correlations influence the capacity of Dense\nAssociative Memory (DAM), a Transformer attention-like model. Practical machine\nlearning scenarios involve feature-correlated data and learn representations in\nthe input space, but current capacity analyses do not account for this. We\ndevelop an empirical framework to analyze the effects of data structure on\ncapacity dynamics. Specifically, we systematically construct datasets that vary\nin feature correlation and pattern separation using Hamming distance from\ninformation theory, and compute the model's corresponding storage capacity\nusing a simple binary search algorithm. Our experiments confirm that memory\ncapacity scales exponentially with increasing separation in the input space.\nFeature correlations do not alter this relationship fundamentally, but reduce\ncapacity slightly at constant separation. This effect is amplified at higher\npolynomial degrees in the energy function, suggesting that Associative Memory\nis more limited in depicting higher-order interactions between features than\npatterns. Our findings bridge theoretical work and practical settings for DAM,\nand might inspire more data-centric methods.", "published": "2025-08-02 15:03:01", "link": "http://arxiv.org/abs/2508.01395v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Quenched large deviations for Monte Carlo integration with Coulomb gases", "abstract": "Gibbs measures, such as Coulomb gases, are popular in modelling systems of\ninteracting particles. Recently, we proposed to use Gibbs measures as\nrandomized numerical integration algorithms with respect to a target measure\n$\\pi$ on $\\mathbb R^d$, following the heuristics that repulsiveness between\nparticles should help reduce integration errors. A major issue in this approach\nis to tune the interaction kernel and confining potential of the Gibbs measure,\nso that the equilibrium measure of the system is the target distribution $\\pi$.\nDoing so usually requires another Monte Carlo approximation of the\n\\emph{potential}, i.e. the integral of the interaction kernel with respect to\n$\\pi$. Using the methodology of large deviations from Garcia--Zelada (2019), we\nshow that a random approximation of the potential preserves the fast large\ndeviation principle that guarantees the proposed integration algorithm to\noutperform independent or Markov quadratures. For non-singular interaction\nkernels, we make minimal assumptions on this random approximation, which can be\nthe result of a computationally cheap Monte Carlo preprocessing. For the\nCoulomb interaction kernel, we need the approximation to be based on another\nGibbs measure, and we prove in passing a control on the uniform convergence of\nthe approximation of the potential.", "published": "2025-08-02 14:52:06", "link": "http://arxiv.org/abs/2508.01392v1", "categories": ["cs.LG", "math.PR", "stat.ML", "65C05, 68W20, 60F10, 82B44, 82B31"], "primary_category": "cs.LG"}
{"title": "Debiasing Machine Learning Predictions for Causal Inference Without Additional Ground Truth Data: \"One Map, Many Trials\" in Satellite-Driven Poverty Analysis", "abstract": "Machine learning models trained on Earth observation data, such as satellite\nimagery, have demonstrated significant promise in predicting household-level\nwealth indices, enabling the creation of high-resolution wealth maps that can\nbe leveraged across multiple causal trials. However, because standard training\nobjectives prioritize overall predictive accuracy, these predictions inherently\nsuffer from shrinkage toward the mean, leading to attenuated estimates of\ncausal treatment effects and limiting their utility in policy. Existing\ndebiasing methods, such as Prediction-Powered Inference, can handle this\nattenuation bias but require additional fresh ground-truth data at the\ndownstream stage of causal inference, which restricts their applicability in\ndata-scarce environments. Here, we introduce and evaluate two correction\nmethods -- linear calibration correction and Tweedie's correction -- that\nsubstantially reduce prediction bias without relying on newly collected labeled\ndata. Linear calibration corrects bias through a straightforward linear\ntransformation derived from held-out calibration data, whereas Tweedie's\ncorrection leverages empirical Bayes principles to directly address\nshrinkage-induced biases by exploiting score functions derived from the model's\nlearning patterns. Through analytical exercises and experiments using\nDemographic and Health Survey data, we demonstrate that the proposed methods\nmeet or outperform existing approaches that either require (a) adjustments to\ntraining pipelines or (b) additional labeled data. These approaches may\nrepresent a promising avenue for improving the reliability of causal inference\nwhen direct outcome measures are limited or unavailable, enabling a \"one map,\nmany trials\" paradigm where a single upstream data creation team produces\npredictions usable by many downstream teams across diverse ML pipelines.", "published": "2025-08-02 12:26:26", "link": "http://arxiv.org/abs/2508.01341v1", "categories": ["stat.ML", "cs.LG", "62C12", "H.3"], "primary_category": "stat.ML"}
{"title": "Flow IV: Counterfactual Inference In Nonseparable Outcome Models Using Instrumental Variables", "abstract": "To reach human level intelligence, learning algorithms need to incorporate\ncausal reasoning. But identifying causality, and particularly counterfactual\nreasoning, remains an elusive task. In this paper, we make progress on this\ntask by utilizing instrumental variables (IVs). IVs are a classic tool for\nmitigating bias from unobserved confounders when estimating causal effects.\nWhile IV methods have been extended to non-separable structural models at the\npopulation level, existing approaches to counterfactual prediction typically\nassume additive noise in the outcome. In this paper, we show that under\nstandard IV assumptions, along with the assumptions that latent noises in\ntreatment and outcome are strictly monotonic and jointly Gaussian, the\ntreatment-outcome relationship becomes uniquely identifiable from observed\ndata. This enables counterfactual inference even in nonseparable models. We\nimplement our approach by training a normalizing flow to maximize the\nlikelihood of the observed data, demonstrating accurate recovery of the\nunderlying outcome function. We call our method Flow IV.", "published": "2025-08-02 11:24:03", "link": "http://arxiv.org/abs/2508.01321v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Inferring processes within dynamic forest models using hybrid modeling", "abstract": "Modeling forest dynamics under novel climatic conditions requires a careful\nbalance between process-based understanding and empirical flexibility. Dynamic\nVegetation Models (DVM) represent ecological processes mechanistically, but\ntheir performance is prone to misspecified assumptions about functional forms.\nInferring the structure of these processes and their functional forms correctly\nfrom data remains a major challenge because current approaches, such as plug-in\nestimators, have proven ineffective. We introduce Forest Informed Neural\nNetworks (FINN), a hybrid modeling approach that combines a forest gap model\nwith deep neural networks (DNN). FINN replaces processes with DNNs, which are\nthen calibrated alongside the other mechanistic components in one unified step.\nIn a case study on the Barro Colorado Island 50-ha plot we demonstrate that\nreplacing the growth process with a DNN improves predictive performance and\nsuccession trajectories compared to a fully mechanistic version of FINN.\nFurthermore, we discovered that the DNN learned an ecologically plausible,\nimproved functional form of growth, which we extracted from the DNN using\nexplainable AI. In conclusion, our new hybrid modeling approach offers a\nversatile opportunity to infer forest dynamics from data and to improve\nforecasts of ecosystem trajectories under unprecedented environmental change.", "published": "2025-08-02 06:46:37", "link": "http://arxiv.org/abs/2508.01228v1", "categories": ["q-bio.QM", "cs.LG", "stat.ML"], "primary_category": "q-bio.QM"}
{"title": "Uncertainty Quantification for Large-Scale Deep Networks via Post-StoNet Modeling", "abstract": "Deep learning has revolutionized modern data science. However, how to\naccurately quantify the uncertainty of predictions from large-scale deep neural\nnetworks (DNNs) remains an unresolved issue. To address this issue, we\nintroduce a novel post-processing approach. This approach feeds the output from\nthe last hidden layer of a pre-trained large-scale DNN model into a stochastic\nneural network (StoNet), then trains the StoNet with a sparse penalty on a\nvalidation dataset and constructs prediction intervals for future observations.\nWe establish a theoretical guarantee for the validity of this approach; in\nparticular, the parameter estimation consistency for the sparse StoNet is\nessential for the success of this approach. Comprehensive experiments\ndemonstrate that the proposed approach can construct honest confidence\nintervals with shorter interval lengths compared to conformal methods and\nachieves better calibration compared to other post-hoc calibration techniques.\nAdditionally, we show that the StoNet formulation provides us with a platform\nto adapt sparse learning theory and methods from linear models to DNNs.", "published": "2025-08-02 06:19:23", "link": "http://arxiv.org/abs/2508.01217v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Translation-Equivariant Self-Supervised Learning for Pitch Estimation with Optimal Transport", "abstract": "In this paper, we propose an Optimal Transport objective for learning\none-dimensional translation-equivariant systems and demonstrate its\napplicability to single pitch estimation. Our method provides a theoretically\ngrounded, more numerically stable, and simpler alternative for training\nstate-of-the-art self-supervised pitch estimators.", "published": "2025-08-02 21:31:14", "link": "http://arxiv.org/abs/2508.01493v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Multi-Granularity Adaptive Time-Frequency Attention Framework for Audio Deepfake Detection under Real-World Communication Degradations", "abstract": "The rise of highly convincing synthetic speech poses a growing threat to\naudio communications. Although existing Audio Deepfake Detection (ADD) methods\nhave demonstrated good performance under clean conditions, their effectiveness\ndrops significantly under degradations such as packet losses and speech codec\ncompression in real-world communication environments. In this work, we propose\nthe first unified framework for robust ADD under such degradations, which is\ndesigned to effectively accommodate multiple types of Time-Frequency (TF)\nrepresentations. The core of our framework is a novel Multi-Granularity\nAdaptive Attention (MGAA) architecture, which employs a set of customizable\nmulti-scale attention heads to capture both global and local receptive fields\nacross varying TF granularities. A novel adaptive fusion mechanism subsequently\nadjusts and fuses these attention branches based on the saliency of TF regions,\nallowing the model to dynamically reallocate its focus according to the\ncharacteristics of the degradation. This enables the effective localization and\namplification of subtle forgery traces. Extensive experiments demonstrate that\nthe proposed framework consistently outperforms state-of-the-art baselines\nacross various real-world communication degradation scenarios, including six\nspeech codecs and five levels of packet losses. In addition, comparative\nanalysis reveals that the MGAA-enhanced features significantly improve\nseparability between real and fake audio classes and sharpen decision\nboundaries. These results highlight the robustness and practical deployment\npotential of our framework in real-world communication environments.", "published": "2025-08-02 19:11:41", "link": "http://arxiv.org/abs/2508.01467v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Foundation Models for Bioacoustics -- a Comparative Review", "abstract": "Automated bioacoustic analysis is essential for biodiversity monitoring and\nconservation, requiring advanced deep learning models that can adapt to diverse\nbioacoustic tasks. This article presents a comprehensive review of large-scale\npretrained bioacoustic foundation models and systematically investigates their\ntransferability across multiple bioacoustic classification tasks. We overview\nbioacoustic representation learning including major pretraining data sources\nand benchmarks. On this basis, we review bioacoustic foundation models by\nthoroughly analysing design decisions such as model architecture, pretraining\nscheme, and training paradigm. Additionally, we evaluate selected foundation\nmodels on classification tasks from the BEANS and BirdSet benchmarks, comparing\nthe generalisability of learned representations under both linear and attentive\nprobing strategies. Our comprehensive experimental analysis reveals that\nBirdMAE, trained on large-scale bird song data with a self-supervised\nobjective, achieves the best performance on the BirdSet benchmark. On BEANS,\nBEATs$_{NLM}$, the extracted encoder of the NatureLM-audio large audio model,\nis slightly better. Both transformer-based models require attentive probing to\nextract the full performance of their representations. ConvNext$_{BS}$ and\nPerch models trained with supervision on large-scale bird song data remain\ncompetitive for passive acoustic monitoring classification tasks of BirdSet in\nlinear probing settings. Training a new linear classifier has clear advantages\nover evaluating these models without further training. While on BEANS, the\nbaseline model BEATs trained with self-supervision on AudioSet outperforms\nbird-specific models when evaluated with attentive probing. These findings\nprovide valuable guidance for practitioners selecting appropriate models to\nadapt them to new bioacoustic classification tasks via probing.", "published": "2025-08-02 09:15:16", "link": "http://arxiv.org/abs/2508.01277v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "q-bio.QM"], "primary_category": "cs.SD"}
{"title": "DIY hybrid SSVEP-P300 LED stimuli for BCI platform using EMOTIV EEG headset", "abstract": "A fully customisable chip-on board (COB) LED design to evoke two brain\nresponses simultaneously (steady state visual evoked potential (SSVEP) and\ntransient evoked potential, P300) is discussed in this paper. Considering\ndifferent possible modalities in braincomputer interfacing (BCI), SSVEP is\nwidely accepted as it requires a lesser number of electroencephalogram (EEG)\nelectrodes and minimal training time. The aim of this work was to produce a\nhybrid BCI hardware platform to evoke SSVEP and P300 precisely with reduced\nfatigue and improved classification performance. The system comprises of four\nindependent radial green visual stimuli controlled individually by a 32-bit\nmicrocontroller platform to evoke SSVEP and four red LEDs flashing at random\nintervals to generate P300 events. The system can also record the P300 event\ntimestamps that can be used in classification, to improve the accuracy and\nreliability. The hybrid stimulus was tested for realtime classification\naccuracy by controlling a LEGO robot to move in four directions.", "published": "2025-08-02 22:22:16", "link": "http://arxiv.org/abs/2508.01510v1", "categories": ["eess.SP", "cs.HC"], "primary_category": "eess.SP"}
{"title": "Likelihood Functions with Parameter-Dependent Support: A Survey of the Cram\u00e9r-Rao-Leibniz Lower Bound", "abstract": "Parameter estimation is a fundamental problem in science and engineering. In\nmany safety-critical applications, one is not only interested in a {\\it point}\nestimator, but also the uncertainty bound that can self-assess the accuracy of\nthe estimator. In this regard, the Cram\\'{e}r-Rao lower bound (CRLB) is of\ngreat importance, as it provides a lower bound on the variance of {\\it any}\nunbiased estimator. In many cases, it is the only way of evaluating, without\nrecourse to simulations, the expected accuracy of numerically obtainable\nestimates. For the existence of the CRLB, there have been widely accepted\nregularity conditions, one of which is that the support of the likelihood\nfunction (LF) -- the pdf of the observations conditioned on the parameter of\ninterest -- should be independent of the parameter to be estimated. This paper\nstarts from reviewing the derivations of the classical CRLB under the condition\nthat the LF has parameter-independent support. To cope with the case of\nparameter-dependent support, we generalize the CRLB to the {\\it\nCram\\'{e}r-Rao-Leibniz lower bound (CRLLB)}, by leveraging the general Leibniz\nintegral rule. Notably, the existing results on CRLLB and CRLB are unified\nunder the framework of CRLLB with multidimensional parameters. Then, we survey\nexisting examples of LFs to illustrate the usefulness of the CRLLB in providing\nvalid covariance bounds.", "published": "2025-08-02 02:04:16", "link": "http://arxiv.org/abs/2508.01145v1", "categories": ["math.ST", "eess.SP", "stat.TH"], "primary_category": "math.ST"}
{"title": "A Highly Available GTFS-RT Positions System", "abstract": "We develop a system for real-time public transportation data, deciding to use\nthe data standard GTFS-RT (GTFS Realtime), an open data format for public\ntransit data. We give an overview of the design of a physical GPS sensor\ndevice, its firmware, and processes. Next, we give the algorithms used to\ntranslate raw sensor data into a public GTFS-RT data feed. We deploy this feed\nover a highly available cluster across multiple regions to maintain high\navailability.", "published": "2025-08-02 00:10:46", "link": "http://arxiv.org/abs/2508.01121v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Advancing the Foundation Model for Music Understanding", "abstract": "The field of Music Information Retrieval (MIR) is fragmented, with\nspecialized models excelling at isolated tasks. In this work, we challenge this\nparadigm by introducing a unified foundation model named MuFun for holistic\nmusic understanding. Our model features a novel architecture that jointly\nprocesses instrumental and lyrical content, and is trained on a large-scale\ndataset covering diverse tasks such as genre classification, music tagging, and\nquestion answering. To facilitate robust evaluation, we also propose a new\nbenchmark for multi-faceted music understanding called MuCUE (Music\nComprehensive Understanding Evaluation). Experiments show our model\nsignificantly outperforms existing audio large language models across the MuCUE\ntasks, demonstrating its state-of-the-art effectiveness and generalization\nability.", "published": "2025-08-02 03:33:47", "link": "http://arxiv.org/abs/2508.01178v1", "categories": ["cs.SD", "cs.AI", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Floquet stability of periodically stationary pulses in a short-pulse fiber laser", "abstract": "The quantitative modeling and design of modern short-pulse fiber lasers\ncannot be performed with averaged models because of large variations in the\npulse parameters within each round trip. Instead, lumped models obtained by\nconcatenating models for the various components of the laser are required.\nSince the optical pulses in lumped models are periodic, their linear stability\nis investigated using the monodromy operator, which is the linearization of the\nroundtrip operator about the pulse. A gradient-based optimization method is\ndeveloped to discover periodic pulses. The computation of the gradient of the\nobjective function involves numerical computation of the action of both the\nround trip operator and the adjoint of the monodromy operator. A novel Fourier\nsplit-step method is introduced to compute solutions of the linearization of\nthe nonlinear, nonlocal, stiff equation that models optical propagation in the\nfiber amplifier. This method is derived by linearizing the two solution\noperators in a split-step method for the nonlinear equation. The spectrum of\nthe monodromy operator consists of the essential spectrum, for which there is\nan analytical formula, and the eigenvalues. There is a multiplicity two\neigenvalue at $\\lambda=1$, which is due to phase and translation invariance.\nThe remaining eigenvalues are determined from a matrix discretization of the\nmonodromy operator. Simulation results verify the accuracy of the numerical\nmethods, show examples of periodically stationary pulses, their spectra and\neigenfunctions, and discuss their stability.", "published": "2025-08-02 01:16:56", "link": "http://arxiv.org/abs/2508.02735v1", "categories": ["math.NA", "cs.NA", "math.DS", "35B10, 35Q56, 37L15, 47D06, 78A60 (Primary)"], "primary_category": "math.NA"}
{"title": "Kronos: A Foundation Model for the Language of Financial Markets", "abstract": "The success of large-scale pre-training paradigm, exemplified by Large\nLanguage Models (LLMs), has inspired the development of Time Series Foundation\nModels (TSFMs). However, their application to financial candlestick (K-line)\ndata remains limited, often underperforming non-pre-trained architectures.\nMoreover, existing TSFMs often overlook crucial downstream tasks such as\nvolatility prediction and synthetic data generation. To address these\nlimitations, we propose Kronos, a unified, scalable pre-training framework\ntailored to financial K-line modeling. Kronos introduces a specialized\ntokenizer that discretizes continuous market information into token sequences,\npreserving both price dynamics and trade activity patterns. We pre-train Kronos\nusing an autoregressive objective on a massive, multi-market corpus of over 12\nbillion K-line records from 45 global exchanges, enabling it to learn nuanced\ntemporal and cross-asset representations. Kronos excels in a zero-shot setting\nacross a diverse set of financial tasks. On benchmark datasets, Kronos boosts\nprice series forecasting RankIC by 93% over the leading TSFM and 87% over the\nbest non-pre-trained baseline. It also achieves a 9% lower MAE in volatility\nforecasting and a 22% improvement in generative fidelity for synthetic K-line\nsequences. These results establish Kronos as a robust, versatile foundation\nmodel for end-to-end financial time series analysis. Our pre-trained model is\npublicly available at https://github.com/shiyu-coder/Kronos.", "published": "2025-08-02 13:15:59", "link": "http://arxiv.org/abs/2508.02739v1", "categories": ["q-fin.ST", "cs.AI", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "CreditARF: A Framework for Corporate Credit Rating with Annual Report and Financial Feature Integration", "abstract": "Corporate credit rating serves as a crucial intermediary service in the\nmarket economy, playing a key role in maintaining economic order. Existing\ncredit rating models rely on financial metrics and deep learning. However, they\noften overlook insights from non-financial data, such as corporate annual\nreports. To address this, this paper introduces a corporate credit rating\nframework that integrates financial data with features extracted from annual\nreports using FinBERT, aiming to fully leverage the potential value of\nunstructured text data. In addition, we have developed a large-scale dataset,\nthe Comprehensive Corporate Rating Dataset (CCRD), which combines both\ntraditional financial data and textual data from annual reports. The\nexperimental results show that the proposed method improves the accuracy of the\nrating predictions by 8-12%, significantly improving the effectiveness and\nreliability of corporate credit ratings.", "published": "2025-08-02 05:56:36", "link": "http://arxiv.org/abs/2508.02738v1", "categories": ["q-fin.ST", "cs.CE", "cs.CL", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "ShrutiSense: Microtonal Modeling and Correction in Indian Classical Music", "abstract": "Indian classical music relies on a sophisticated microtonal system of 22\nshrutis (pitch intervals), which provides expressive nuance beyond the 12-tone\nequal temperament system. Existing symbolic music processing tools fail to\naccount for these microtonal distinctions and culturally specific raga grammars\nthat govern melodic movement. We present ShrutiSense, a comprehensive symbolic\npitch processing system designed for Indian classical music, addressing two\ncritical tasks: (1) correcting westernized or corrupted pitch sequences, and\n(2) completing melodic sequences with missing values. Our approach employs\ncomplementary models for different tasks: a Shruti-aware finite-state\ntransducer (FST) that performs contextual corrections within the 22-shruti\nframework and a grammar-constrained Shruti hidden Markov model (GC-SHMM) that\nincorporates raga-specific transition rules for contextual completions.\nComprehensive evaluation on simulated data across five ragas demonstrates that\nShrutiSense (FST model) achieves 91.3% shruti classification accuracy for\ncorrection tasks, with example sequences showing 86.7-90.0% accuracy at\ncorruption levels of 0.2 to 0.4. The system exhibits robust performance under\npitch noise up to +/-50 cents, maintaining consistent accuracy across ragas\n(90.7-91.8%), thus preserving the cultural authenticity of Indian classical\nmusic expression.", "published": "2025-08-02 21:42:47", "link": "http://arxiv.org/abs/2508.01498v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PESTO: Real-Time Pitch Estimation with Self-supervised Transposition-equivariant Objective", "abstract": "In this paper, we introduce PESTO, a self-supervised learning approach for\nsingle-pitch estimation using a Siamese architecture. Our model processes\nindividual frames of a Variable-$Q$ Transform (VQT) and predicts pitch\ndistributions. The neural network is designed to be equivariant to\ntranslations, notably thanks to a Toeplitz fully-connected layer. In addition,\nwe construct pitch-shifted pairs by translating and cropping the VQT frames and\ntrain our model with a novel class-based transposition-equivariant objective,\neliminating the need for annotated data. Thanks to this architecture and\ntraining objective, our model achieves remarkable performances while being very\nlightweight ($130$k parameters). Evaluations on music and speech datasets\n(MIR-1K, MDB-stem-synth, and PTDB) demonstrate that PESTO not only outperforms\nself-supervised baselines but also competes with supervised methods, exhibiting\nsuperior cross-dataset generalization. Finally, we enhance PESTO's practical\nutility by developing a streamable VQT implementation using cached\nconvolutions. Combined with our model's low latency (less than 10 ms) and\nminimal parameter count, this makes PESTO particularly suitable for real-time\napplications.", "published": "2025-08-02 21:00:55", "link": "http://arxiv.org/abs/2508.01488v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Via Score to Performance: Efficient Human-Controllable Long Song Generation with Bar-Level Symbolic Notation", "abstract": "Song generation is regarded as the most challenging problem in music AIGC;\nnonetheless, existing approaches have yet to fully overcome four persistent\nlimitations: controllability, generalizability, perceptual quality, and\nduration. We argue that these shortcomings stem primarily from the prevailing\nparadigm of attempting to learn music theory directly from raw audio, a task\nthat remains prohibitively difficult for current models. To address this, we\npresent Bar-level AI Composing Helper (BACH), the first model explicitly\ndesigned for song generation through human-editable symbolic scores. BACH\nintroduces a tokenization strategy and a symbolic generative procedure tailored\nto hierarchical song structure. Consequently, it achieves substantial gains in\nthe efficiency, duration, and perceptual quality of song generation.\nExperiments demonstrate that BACH, with a small model size, establishes a new\nSOTA among all publicly reported song generation systems, even surpassing\ncommercial solutions such as Suno. Human evaluations further confirm its\nsuperiority across multiple subjective metrics.", "published": "2025-08-02 14:58:34", "link": "http://arxiv.org/abs/2508.01394v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning", "abstract": "Despite their strong performance in multimodal emotion reasoning, existing\nMultimodal Large Language Models (MLLMs) often overlook the scenarios involving\nemotion conflicts, where emotional cues from different modalities are\ninconsistent. To fill this gap, we first introduce CA-MER, a new benchmark\ndesigned to examine MLLMs under realistic emotion conflicts. It consists of\nthree subsets: video-aligned, audio-aligned, and consistent, where only one or\nall modalities reflect the true emotion. However, evaluations on our CA-MER\nreveal that current state-of-the-art emotion MLLMs systematically over-rely on\naudio signal during emotion conflicts, neglecting critical cues from visual\nmodality. To mitigate this bias, we propose MoSEAR, a parameter-efficient\nframework that promotes balanced modality integration. MoSEAR consists of two\nmodules: (1)MoSE, modality-specific experts with a regularized gating mechanism\nthat reduces modality bias in the fine-tuning heads; and (2)AR, an attention\nreallocation mechanism that rebalances modality contributions in frozen\nbackbones during inference. Our framework offers two key advantages: it\nmitigates emotion conflicts and improves performance on consistent\nsamples-without incurring a trade-off between audio and visual modalities.\nExperiments on multiple benchmarks-including MER2023, EMER, DFEW, and our\nCA-MER-demonstrate that MoSEAR achieves state-of-the-art performance,\nparticularly under modality conflict conditions.", "published": "2025-08-02 04:03:44", "link": "http://arxiv.org/abs/2508.01181v1", "categories": ["cs.AI", "cs.CV", "cs.MM", "cs.SD", "eess.AS", "68", "I.2.10"], "primary_category": "cs.AI"}
{"title": "GeHirNet: A Gender-Aware Hierarchical Model for Voice Pathology Classification", "abstract": "AI-based voice analysis shows promise for disease diagnostics, but existing\nclassifiers often fail to accurately identify specific pathologies because of\ngender-related acoustic variations and the scarcity of data for rare diseases.\nWe propose a novel two-stage framework that first identifies gender-specific\npathological patterns using ResNet-50 on Mel spectrograms, then performs\ngender-conditioned disease classification. We address class imbalance through\nmulti-scale resampling and time warping augmentation. Evaluated on a merged\ndataset from four public repositories, our two-stage architecture with time\nwarping achieves state-of-the-art performance (97.63\\% accuracy, 95.25\\% MCC),\nwith a 5\\% MCC improvement over single-stage baseline. This work advances voice\npathology classification while reducing gender bias through hierarchical\nmodeling of vocal characteristics.", "published": "2025-08-02 03:19:44", "link": "http://arxiv.org/abs/2508.01172v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SpectrumFM: A New Paradigm for Spectrum Cognition", "abstract": "The enhancement of spectrum efficiency and the realization of secure spectrum\nutilization are critically dependent on spectrum cognition. However, existing\nspectrum cognition methods often exhibit limited generalization and suboptimal\naccuracy when deployed across diverse spectrum environments and tasks. To\novercome these challenges, we propose a spectrum foundation model, termed\nSpectrumFM, which provides a new paradigm for spectrum cognition. An innovative\nspectrum encoder that exploits the convolutional neural networks and the\nmulti-head self attention mechanisms is proposed to effectively capture both\nfine-grained local signal structures and high-level global dependencies in the\nspectrum data. To enhance its adaptability, two novel self-supervised learning\ntasks, namely masked reconstruction and next-slot signal prediction, are\ndeveloped for pre-training SpectrumFM, enabling the model to learn rich and\ntransferable representations. Furthermore, low-rank adaptation (LoRA)\nparameter-efficient fine-tuning is exploited to enable SpectrumFM to seamlessly\nadapt to various downstream spectrum cognition tasks, including spectrum\nsensing (SS), anomaly detection (AD), and wireless technology classification\n(WTC). Extensive experiments demonstrate the superiority of SpectrumFM over\nstate-of-the-art methods. Specifically, it improves detection probability in\nthe SS task by 30% at -4 dB signal-to-noise ratio (SNR), boosts the area under\nthe curve (AUC) in the AD task by over 10%, and enhances WTC accuracy by 9.6%.", "published": "2025-08-02 14:40:50", "link": "http://arxiv.org/abs/2508.02742v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
