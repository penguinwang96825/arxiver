{"title": "Words that Matter: The Impact of Negative Words on News Sentiment and\n  Stock Market Index", "abstract": "This study investigates the impact of negative words on sentiment analysis\nand its effect on the South Korean stock market index, KOSPI200. The research\nanalyzes a dataset of 45,723 South Korean daily economic news articles using\nWord2Vec, cosine similarity, and an expanded lexicon. The findings suggest that\nincorporating negative words significantly increases sentiment scores'\nnegativity in news titles, which can affect the stock market index. The study\nreveals that an augmented sentiment lexicon (Sent1000), including the top 1,000\nnegative words with high cosine similarity to 'Crisis,' more effectively\ncaptures the impact of news sentiment on the stock market index than the\noriginal sentiment lexicon (Sent0). The results underscore the importance of\nconsidering negative nuances and context when analyzing news content and its\npotential impact on market dynamics and public opinion.", "published": "2023-04-02 06:45:18", "link": "http://arxiv.org/abs/2304.00468v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Data-centric Framework for Improving Domain-specific Machine Reading\n  Comprehension Datasets", "abstract": "Low-quality data can cause downstream problems in high-stakes applications.\nData-centric approach emphasizes on improving dataset quality to enhance model\nperformance. High-quality datasets are needed for general-purpose Large\nLanguage Models (LLMs) training, as well as for domain-specific models, which\nare usually small in size as it is costly to engage a large number of domain\nexperts for their creation. Thus, it is vital to ensure high-quality\ndomain-specific training data. In this paper, we propose a framework for\nenhancing the data quality of original datasets. We applied the proposed\nframework to four biomedical datasets and showed relative improvement of up to\n33%/40% for fine-tuning of retrieval/reader models on the BioASQ dataset when\nusing back translation to enhance the original dataset quality.", "published": "2023-04-02 08:26:38", "link": "http://arxiv.org/abs/2304.00483v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PK-Chat: Pointer Network Guided Knowledge Driven Generative Dialogue\n  Model", "abstract": "In the research of end-to-end dialogue systems, using real-world knowledge to\ngenerate natural, fluent, and human-like utterances with correct answers is\ncrucial. However, domain-specific conversational dialogue systems may be\nincoherent and introduce erroneous external information to answer questions due\nto the out-of-vocabulary issue or the wrong knowledge from the parameters of\nthe neural network. In this work, we propose PK-Chat, a Pointer network guided\nKnowledge-driven generative dialogue model, incorporating a unified pretrained\nlanguage model and a pointer network over knowledge graphs. The words generated\nby PK-Chat in the dialogue are derived from the prediction of word lists and\nthe direct prediction of the external knowledge graph knowledge. Moreover,\nbased on the PK-Chat, a dialogue system is built for academic scenarios in the\ncase of geosciences. Finally, an academic dialogue benchmark is constructed to\nevaluate the quality of dialogue systems in academic scenarios and the source\ncode is available online.", "published": "2023-04-02 18:23:13", "link": "http://arxiv.org/abs/2304.00592v1", "categories": ["cs.CL", "I.2.7; F.4.1"], "primary_category": "cs.CL"}
{"title": "Classifying COVID-19 Related Tweets for Fake News Detection and\n  Sentiment Analysis with BERT-based Models", "abstract": "The present paper is about the participation of our team \"techno\" on\nCERIST'22 shared tasks. We used an available dataset \"task1.c\" related to\ncovid-19 pandemic. It comprises 4128 tweets for sentiment analysis task and\n8661 tweets for fake news detection task. We used natural language processing\ntools with the combination of the most renowned pre-trained language models\nBERT (Bidirectional Encoder Representations from Transformers). The results\nshows the efficacy of pre-trained language models as we attained an accuracy of\n0.93 for the sentiment analysis task and 0.90 for the fake news detection task.", "published": "2023-04-02 22:00:27", "link": "http://arxiv.org/abs/2304.00636v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-supervised Neural Machine Translation with Consistency\n  Regularization for Low-Resource Languages", "abstract": "The advent of deep learning has led to a significant gain in machine\ntranslation. However, most of the studies required a large parallel dataset\nwhich is scarce and expensive to construct and even unavailable for some\nlanguages. This paper presents a simple yet effective method to tackle this\nproblem for low-resource languages by augmenting high-quality sentence pairs\nand training NMT models in a semi-supervised manner. Specifically, our approach\ncombines the cross-entropy loss for supervised learning with KL Divergence for\nunsupervised fashion given pseudo and augmented target sentences derived from\nthe model. We also introduce a SentenceBERT-based filter to enhance the quality\nof augmenting data by retaining semantically similar sentence pairs.\nExperimental results show that our approach significantly improves NMT\nbaselines, especially on low-resource datasets with 0.46--2.03 BLEU scores. We\nalso demonstrate that using unsupervised training for augmented data is more\nefficient than reusing the ground-truth target sentences for supervised\nlearning.", "published": "2023-04-02 15:24:08", "link": "http://arxiv.org/abs/2304.00557v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Eight Things to Know about Large Language Models", "abstract": "The widespread public deployment of large language models (LLMs) in recent\nmonths has prompted a wave of new attention and engagement from advocates,\npolicymakers, and scholars from many fields. This attention is a timely\nresponse to the many urgent questions that this technology raises, but it can\nsometimes miss important considerations. This paper surveys the evidence for\neight potentially surprising such points:\n  1. LLMs predictably get more capable with increasing investment, even without\ntargeted innovation.\n  2. Many important LLM behaviors emerge unpredictably as a byproduct of\nincreasing investment.\n  3. LLMs often appear to learn and use representations of the outside world.\n  4. There are no reliable techniques for steering the behavior of LLMs.\n  5. Experts are not yet able to interpret the inner workings of LLMs.\n  6. Human performance on a task isn't an upper bound on LLM performance.\n  7. LLMs need not express the values of their creators nor the values encoded\nin web text.\n  8. Brief interactions with LLMs are often misleading.", "published": "2023-04-02 20:03:27", "link": "http://arxiv.org/abs/2304.00612v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Better Language Models of Code through Self-Improvement", "abstract": "Pre-trained language models for code (PLMCs) have gained attention in recent\nresearch. These models are pre-trained on large-scale datasets using\nmulti-modal objectives. However, fine-tuning them requires extensive\nsupervision and is limited by the size of the dataset provided. We aim to\nimprove this issue by proposing a simple data augmentation framework. Our\nframework utilizes knowledge gained during the pre-training and fine-tuning\nstage to generate pseudo data, which is then used as training data for the next\nstep. We incorporate this framework into the state-of-the-art language models,\nsuch as CodeT5, CodeBERT, and UnixCoder. The results show that our framework\nsignificantly improves PLMCs' performance in code-related sequence generation\ntasks, such as code summarization and code generation in the CodeXGLUE\nbenchmark.", "published": "2023-04-02 10:59:19", "link": "http://arxiv.org/abs/2304.01228v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language\n  Models", "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\nand demonstrated impressive capabilities in various tasks. Unfortunately, they\nare prone to hallucinations, where the model exposes incorrect or false\ninformation in its responses, which renders diligent evaluation approaches\nmandatory. While LLM performance in specific knowledge fields is often\nevaluated based on question and answer (Q&A) datasets, such evaluations usually\nreport only a single accuracy number for the dataset, which often covers an\nentire field. This field-based evaluation, is problematic with respect to\ntransparency and model improvement. A stratified evaluation could instead\nreveal subfields, where hallucinations are more likely to occur and thus help\nto better assess LLMs' risks and guide their further development. To support\nsuch stratified evaluations, we propose LLMMaps as a novel visualization\ntechnique that enables users to evaluate LLMs' performance with respect to Q&A\ndatasets. LLMMaps provide detailed insights into LLMs' knowledge capabilities\nin different subfields, by transforming Q&A datasets as well as LLM responses\ninto an internal knowledge structure. An extension for comparative\nvisualization furthermore, allows for the detailed comparison of multiple LLMs.\nTo assess LLMMaps we use them to conduct a comparative analysis of several\nstate-of-the-art LLMs, such as BLOOM, GPT-2, GPT-3, ChatGPT and LLaMa-13B, as\nwell as two qualitative user evaluations. All necessary source code and data\nfor generating LLMMaps to be used in scientific publications and elsewhere is\navailable on GitHub: https://github.com/viscom-ulm/LLMMaps", "published": "2023-04-02 05:47:09", "link": "http://arxiv.org/abs/2304.00457v3", "categories": ["cs.CL", "cs.AI", "cs.GR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MMT: A Multilingual and Multi-Topic Indian Social Media Dataset", "abstract": "Social media plays a significant role in cross-cultural communication. A vast\namount of this occurs in code-mixed and multilingual form, posing a significant\nchallenge to Natural Language Processing (NLP) tools for processing such\ninformation, like language identification, topic modeling, and named-entity\nrecognition. To address this, we introduce a large-scale multilingual, and\nmulti-topic dataset (MMT) collected from Twitter (1.7 million Tweets),\nencompassing 13 coarse-grained and 63 fine-grained topics in the Indian\ncontext. We further annotate a subset of 5,346 tweets from the MMT dataset with\nvarious Indian languages and their code-mixed counterparts. Also, we\ndemonstrate that the currently existing tools fail to capture the linguistic\ndiversity in MMT on two downstream tasks, i.e., topic modeling and language\nidentification. To facilitate future research, we will make the anonymized and\nannotated dataset available in the public domain.", "published": "2023-04-02 21:39:00", "link": "http://arxiv.org/abs/2304.00634v1", "categories": ["cs.CL", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Multilingual Word Error Rate Estimation: e-WER3", "abstract": "The success of the multilingual automatic speech recognition systems\nempowered many voice-driven applications. However, measuring the performance of\nsuch systems remains a major challenge, due to its dependency on manually\ntranscribed speech data in both mono- and multilingual scenarios. In this\npaper, we propose a novel multilingual framework -- eWER3 -- jointly trained on\nacoustic and lexical representation to estimate word error rate. We demonstrate\nthe effectiveness of eWER3 to (i) predict WER without using any internal states\nfrom the ASR and (ii) use the multilingual shared latent space to push the\nperformance of the close-related languages. We show our proposed multilingual\nmodel outperforms the previous monolingual word error rate estimation method\n(eWER2) by an absolute 9\\% increase in Pearson correlation coefficient (PCC),\nwith better overall estimation between the predicted and reference WER.", "published": "2023-04-02 23:08:11", "link": "http://arxiv.org/abs/2304.00649v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Healthy AI: Large Language Models Need Therapists Too", "abstract": "Recent advances in large language models (LLMs) have led to the development\nof powerful AI chatbots capable of engaging in natural and human-like\nconversations. However, these chatbots can be potentially harmful, exhibiting\nmanipulative, gaslighting, and narcissistic behaviors. We define Healthy AI to\nbe safe, trustworthy and ethical. To create healthy AI systems, we present the\nSafeguardGPT framework that uses psychotherapy to correct for these harmful\nbehaviors in AI chatbots. The framework involves four types of AI agents: a\nChatbot, a \"User,\" a \"Therapist,\" and a \"Critic.\" We demonstrate the\neffectiveness of SafeguardGPT through a working example of simulating a social\nconversation. Our results show that the framework can improve the quality of\nconversations between AI chatbots and humans. Although there are still several\nchallenges and directions to be addressed in the future, SafeguardGPT provides\na promising approach to improving the alignment between AI chatbots and human\nvalues. By incorporating psychotherapy and reinforcement learning techniques,\nthe framework enables AI chatbots to learn and adapt to human preferences and\nvalues in a safe and ethical way, contributing to the development of a more\nhuman-centric and responsible AI.", "published": "2023-04-02 00:39:12", "link": "http://arxiv.org/abs/2304.00416v1", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Improving Meeting Inclusiveness using Speech Interruption Analysis", "abstract": "Meetings are a pervasive method of communication within all types of\ncompanies and organizations, and using remote collaboration systems to conduct\nmeetings has increased dramatically since the COVID-19 pandemic. However, not\nall meetings are inclusive, especially in terms of the participation rates\namong attendees. In a recent large-scale survey conducted at Microsoft, the top\nsuggestion given by meeting participants for improving inclusiveness is to\nimprove the ability of remote participants to interrupt and acquire the floor\nduring meetings. We show that the use of the virtual raise hand (VRH) feature\ncan lead to an increase in predicted meeting inclusiveness at Microsoft. One\nchallenge is that VRH is used in less than 1% of all meetings. In order to\ndrive adoption of its usage to improve inclusiveness (and participation), we\npresent a machine learning-based system that predicts when a meeting\nparticipant attempts to obtain the floor, but fails to interrupt (termed a\n`failed interruption'). This prediction can be used to nudge the user to raise\ntheir virtual hand within the meeting. We believe this is the first failed\nspeech interruption detector, and the performance on a realistic test set has\nan area under curve (AUC) of 0.95 with a true positive rate (TPR) of 50% at a\nfalse positive rate (FPR) of <1%. To our knowledge, this is also the first\ndataset of interruption categories (including the failed interruption category)\nfor remote meetings. Finally, we believe this is the first such system designed\nto improve meeting inclusiveness through speech interruption analysis and\nactive intervention.", "published": "2023-04-02 23:52:24", "link": "http://arxiv.org/abs/2304.00658v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A Unified Compression Framework for Efficient Speech-Driven Talking-Face\n  Generation", "abstract": "Virtual humans have gained considerable attention in numerous industries,\ne.g., entertainment and e-commerce. As a core technology, synthesizing\nphotorealistic face frames from target speech and facial identity has been\nactively studied with generative adversarial networks. Despite remarkable\nresults of modern talking-face generation models, they often entail high\ncomputational burdens, which limit their efficient deployment. This study aims\nto develop a lightweight model for speech-driven talking-face synthesis. We\nbuild a compact generator by removing the residual blocks and reducing the\nchannel width from Wav2Lip, a popular talking-face generator. We also present a\nknowledge distillation scheme to stably yet effectively train the\nsmall-capacity generator without adversarial learning. We reduce the number of\nparameters and MACs by 28$\\times$ while retaining the performance of the\noriginal model. Moreover, to alleviate a severe performance drop when\nconverting the whole generator to INT8 precision, we adopt a selective\nquantization method that uses FP16 for the quantization-sensitive layers and\nINT8 for the other layers. Using this mixed precision, we achieve up to a\n19$\\times$ speedup on edge GPUs without noticeably compromising the generation\nquality.", "published": "2023-04-02 06:56:44", "link": "http://arxiv.org/abs/2304.00471v2", "categories": ["cs.SD", "cs.CV", "cs.GR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
