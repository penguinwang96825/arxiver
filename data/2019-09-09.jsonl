{"title": "Unsupervised Paraphrasing by Simulated Annealing", "abstract": "Unsupervised paraphrase generation is a promising and important research\ntopic in natural language processing. We propose UPSA, a novel approach that\naccomplishes Unsupervised Paraphrasing by Simulated Annealing. We model\nparaphrase generation as an optimization problem and propose a sophisticated\nobjective function, involving semantic similarity, expression diversity, and\nlanguage fluency of paraphrases. Then, UPSA searches the sentence space towards\nthis objective by performing a sequence of local editing. Our method is\nunsupervised and does not require parallel corpora for training, so it could be\neasily applied to different domains. We evaluate our approach on a variety of\nbenchmark datasets, namely, Quora, Wikianswers, MSCOCO, and Twitter. Extensive\nresults show that UPSA achieves the state-of-the-art performance compared with\nprevious unsupervised methods in terms of both automatic and human evaluations.\nFurther, our approach outperforms most existing domain-adapted supervised\nmodels, showing the generalizability of UPSA.", "published": "2019-09-09 01:59:31", "link": "http://arxiv.org/abs/1909.03588v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Order Matter? An Empirical Study on Generating Multiple Keyphrases\n  as a Sequence", "abstract": "Recently, concatenating multiple keyphrases as a target sequence has been\nproposed as a new learning paradigm for keyphrase generation. Existing studies\nconcatenate target keyphrases in different orders but no study has examined the\neffects of ordering on models' behavior. In this paper, we propose several\norderings for concatenation and inspect the important factors for training a\nsuccessful keyphrase generation model. By running comprehensive comparisons, we\nobserve one preferable ordering and summarize a number of empirical findings\nand challenges, which can shed light on future research on this line of work.", "published": "2019-09-09 02:04:53", "link": "http://arxiv.org/abs/1909.03590v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Matters for Neural Cross-Lingual Named Entity Recognition: An\n  Empirical Analysis", "abstract": "Building named entity recognition (NER) models for languages that do not have\nmuch training data is a challenging task. While recent work has shown promising\nresults on cross-lingual transfer from high-resource languages to low-resource\nlanguages, it is unclear what knowledge is transferred. In this paper, we first\npropose a simple and efficient neural architecture for cross-lingual NER.\nExperiments show that our model achieves competitive performance with the\nstate-of-the-art. We further analyze how transfer learning works for\ncross-lingual NER on two transferable factors: sequential order and\nmultilingual embeddings, and investigate how model performance varies across\nentity lengths. Finally, we conduct a case-study on a non-Latin language,\nBengali, which suggests that leveraging knowledge from Wikipedia will be a\npromising direction to further improve the model performances. Our results can\nshed light on future research for improving cross-lingual NER.", "published": "2019-09-09 02:45:38", "link": "http://arxiv.org/abs/1909.03598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Neural Question Generation using World Knowledge", "abstract": "In this paper, we propose a method for incorporating world knowledge (linked\nentities and fine-grained entity types) into a neural question generation\nmodel. This world knowledge helps to encode additional information related to\nthe entities present in the passage required to generate human-like questions.\nWe evaluate our models on both SQuAD and MS MARCO to demonstrate the usefulness\nof the world knowledge features. The proposed world knowledge enriched question\ngeneration model is able to outperform the vanilla neural question generation\nmodel by 1.37 and 1.59 absolute BLEU 4 score on SQuAD and MS MARCO test dataset\nrespectively.", "published": "2019-09-09 09:26:42", "link": "http://arxiv.org/abs/1909.03716v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combining SMT and NMT Back-Translated Data for Efficient NMT", "abstract": "Neural Machine Translation (NMT) models achieve their best performance when\nlarge sets of parallel data are used for training. Consequently, techniques for\naugmenting the training set have become popular recently. One of these methods\nis back-translation (Sennrich et al., 2016), which consists on generating\nsynthetic sentences by translating a set of monolingual, target-language\nsentences using a Machine Translation (MT) model.\n  Generally, NMT models are used for back-translation. In this work, we analyze\nthe performance of models when the training data is extended with synthetic\ndata using different MT approaches. In particular we investigate\nback-translated data generated not only by NMT but also by Statistical Machine\nTranslation (SMT) models and combinations of both. The results reveal that the\nmodels achieve the best performances when the training set is augmented with\nback-translated data created by merging different MT approaches.", "published": "2019-09-09 10:45:05", "link": "http://arxiv.org/abs/1909.03750v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language learning using Speech to Image retrieval", "abstract": "Humans learn language by interaction with their environment and listening to\nother humans. It should also be possible for computational models to learn\nlanguage directly from speech but so far most approaches require text. We\nimprove on existing neural network approaches to create visually grounded\nembeddings for spoken utterances. Using a combination of a multi-layer GRU,\nimportance sampling, cyclic learning rates, ensembling and vectorial\nself-attention our results show a remarkable increase in image-caption\nretrieval performance over previous work. Furthermore, we investigate which\nlayers in the model learn to recognise words in the input. We find that deeper\nnetwork layers are better at encoding word presence, although the final layer\nhas slightly lower performance. This shows that our visually grounded sentence\nencoder learns to recognise words from the input even though it is not\nexplicitly trained for word recognition.", "published": "2019-09-09 12:24:06", "link": "http://arxiv.org/abs/1909.03795v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Trumpiest Trump? Identifying a Subject's Most Characteristic Tweets", "abstract": "The sequence of documents produced by any given author varies in style and\ncontent, but some documents are more typical or representative of the source\nthan others. We quantify the extent to which a given short text is\ncharacteristic of a specific person, using a dataset of tweets from fifteen\ncelebrities. Such analysis is useful for generating excerpts of high-volume\nTwitter profiles, and understanding how representativeness relates to tweet\npopularity. We first consider the related task of binary author detection (is x\nthe author of text T?), and report a test accuracy of 90.37% for the best of\nfive approaches to this problem. We then use these models to compute\ncharacterization scores among all of an author's texts. A user study shows\nhuman evaluators agree with our characterization model for all 15 celebrities\nin our dataset, each with p-value < 0.05. We use these classifiers to show\nsurprisingly strong correlations between characterization scores and the\npopularity of the associated texts. Indeed, we demonstrate a statistically\nsignificant correlation between this score and tweet popularity\n(likes/replies/retweets) for 13 of the 15 celebrities in our study.", "published": "2019-09-09 17:28:40", "link": "http://arxiv.org/abs/1909.04002v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pretrained Language Models for Sequential Sentence Classification", "abstract": "As a step toward better document-level understanding, we explore\nclassification of a sequence of sentences into their corresponding categories,\na task that requires understanding sentences in context of the document. Recent\nsuccessful models for this task have used hierarchical models to contextualize\nsentence representations, and Conditional Random Fields (CRFs) to incorporate\ndependencies between subsequent labels. In this work, we show that pretrained\nlanguage models, BERT (Devlin et al., 2018) in particular, can be used for this\ntask to capture contextual dependencies without the need for hierarchical\nencoding nor a CRF. Specifically, we construct a joint sentence representation\nthat allows BERT Transformer layers to directly utilize contextual information\nfrom all words in all sentences. Our approach achieves state-of-the-art results\non four datasets, including a new dataset of structured scientific abstracts.", "published": "2019-09-09 18:00:05", "link": "http://arxiv.org/abs/1909.04054v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP\n  Tasks Improve Neural Language Models?", "abstract": "Natural language processing (NLP) tasks tend to suffer from a paucity of\nsuitably annotated training data, hence the recent success of transfer learning\nacross a wide variety of them. The typical recipe involves: (i) training a\ndeep, possibly bidirectional, neural network with an objective related to\nlanguage modeling, for which training data is plentiful; and (ii) using the\ntrained network to derive contextual representations that are far richer than\nstandard linear word embeddings such as word2vec, and thus result in important\ngains. In this work, we wonder whether the opposite perspective is also true:\ncan contextual representations trained for different NLP tasks improve language\nmodeling itself? Since language models (LMs) are predominantly locally\noptimized, other NLP tasks may help them make better predictions based on the\nentire semantic fabric of a document. We test the performance of several types\nof pre-trained embeddings in neural LMs, and we investigate whether it is\npossible to make the LM more aware of global semantic information through\nembeddings pre-trained with a domain classification model. Initial experiments\nsuggest that as long as the proper objective criterion is used during training,\npre-trained embeddings are likely to be beneficial for neural language\nmodeling.", "published": "2019-09-09 20:01:51", "link": "http://arxiv.org/abs/1909.04130v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Enhanced Contextual Word Representations", "abstract": "Contextual word representations, typically trained on unstructured, unlabeled\ntext, do not contain any explicit grounding to real world entities and are\noften unable to remember facts about those entities. We propose a general\nmethod to embed multiple knowledge bases (KBs) into large scale models, and\nthereby enhance their representations with structured, human-curated knowledge.\nFor each KB, we first use an integrated entity linker to retrieve relevant\nentity embeddings, then update contextual word representations via a form of\nword-to-entity attention. In contrast to previous approaches, the entity\nlinkers and self-supervised language modeling objective are jointly trained\nend-to-end in a multitask setting that combines a small amount of entity\nlinking supervision with a large amount of raw text. After integrating WordNet\nand a subset of Wikipedia into BERT, the knowledge enhanced BERT (KnowBert)\ndemonstrates improved perplexity, ability to recall facts as measured in a\nprobing task and downstream performance on relationship extraction, entity\ntyping, and word sense disambiguation. KnowBert's runtime is comparable to\nBERT's and it scales to large KBs.", "published": "2019-09-09 21:18:50", "link": "http://arxiv.org/abs/1909.04164v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Semantic Parsers from Denotations with Latent Structured\n  Alignments and Abstract Programs", "abstract": "Semantic parsing aims to map natural language utterances onto machine\ninterpretable meaning representations, aka programs whose execution against a\nreal-world environment produces a denotation. Weakly-supervised semantic\nparsers are trained on utterance-denotation pairs treating programs as latent.\nThe task is challenging due to the large search space and spuriousness of\nprograms which may execute to the correct answer but do not generalize to\nunseen examples. Our goal is to instill an inductive bias in the parser to help\nit distinguish between spurious and correct programs. We capitalize on the\nintuition that correct programs would likely respect certain structural\nconstraints were they to be aligned to the question (e.g., program fragments\nare unlikely to align to overlapping text spans) and propose to model\nalignments as structured latent variables. In order to make the\nlatent-alignment framework tractable, we decompose the parsing task into (1)\npredicting a partial \"abstract program\" and (2) refining it while modeling\nstructured alignments with differential dynamic programming. We obtain\nstate-of-the-art performance on the WIKITABLEQUESTIONS and WIKISQL datasets.\nWhen compared to a standard attention baseline, we observe that the proposed\nstructured-alignment mechanism is highly beneficial.", "published": "2019-09-09 21:20:36", "link": "http://arxiv.org/abs/1909.04165v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BERT-Based Arabic Social Media Author Profiling", "abstract": "We report our models for detecting age, language variety, and gender from\nsocial media data in the context of the Arabic author profiling and deception\ndetection shared task (APDA). We build simple models based on pre-trained\nbidirectional encoders from transformers (BERT). We first fine-tune the\npre-trained BERT model on each of the three datasets with shared task released\ndata. Then we augment shared task data with in-house data for gender and\ndialect, showing the utility of augmenting training data. Our best models on\nthe shared task test data are acquired with a majority voting of various BERT\nmodels trained under different data conditions. We acquire 54.72% accuracy for\nage, 93.75% for dialect, 81.67% for gender, and 40.97% joint accuracy across\nthe three tasks.", "published": "2019-09-09 22:08:12", "link": "http://arxiv.org/abs/1909.04181v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Graph-Based Reasoning over Heterogeneous External Knowledge for\n  Commonsense Question Answering", "abstract": "Commonsense question answering aims to answer questions which require\nbackground knowledge that is not explicitly expressed in the question. The key\nchallenge is how to obtain evidence from external knowledge and make\npredictions based on the evidence. Recent works either learn to generate\nevidence from human-annotated evidence which is expensive to collect, or\nextract evidence from either structured or unstructured knowledge bases which\nfails to take advantages of both sources. In this work, we propose to\nautomatically extract evidence from heterogeneous knowledge sources, and answer\nquestions based on the extracted evidence. Specifically, we extract evidence\nfrom both structured knowledge base (i.e. ConceptNet) and Wikipedia plain\ntexts. We construct graphs for both sources to obtain the relational structures\nof evidence. Based on these graphs, we propose a graph-based approach\nconsisting of a graph-based contextual word representation learning module and\na graph-based inference module. The first module utilizes graph structural\ninformation to re-define the distance between words for learning better\ncontextual word representations. The second module adopts graph convolutional\nnetwork to encode neighbor information into the representations of nodes, and\naggregates evidence with graph attention mechanism for predicting the final\nanswer. Experimental results on CommonsenseQA dataset illustrate that our\ngraph-based approach over both knowledge sources brings improvement over strong\nbaselines. Our approach achieves the state-of-the-art accuracy (75.3%) on the\nCommonsenseQA leaderboard.", "published": "2019-09-09 12:43:12", "link": "http://arxiv.org/abs/1909.05311v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Clickbait? Sensational Headline Generation with Auto-tuned Reinforcement\n  Learning", "abstract": "Sensational headlines are headlines that capture people's attention and\ngenerate reader interest. Conventional abstractive headline generation methods,\nunlike human writers, do not optimize for maximal reader attention. In this\npaper, we propose a model that generates sensational headlines without labeled\ndata. We first train a sensationalism scorer by classifying online headlines\nwith many comments (\"clickbait\") against a baseline of headlines generated from\na summarization model. The score from the sensationalism scorer is used as the\nreward for a reinforcement learner. However, maximizing the noisy\nsensationalism reward will generate unnatural phrases instead of sensational\nheadlines. To effectively leverage this noisy reward, we propose a novel loss\nfunction, Auto-tuned Reinforcement Learning (ARL), to dynamically balance\nreinforcement learning (RL) with maximum likelihood estimation (MLE). Human\nevaluation shows that 60.8% of samples generated by our model are sensational,\nwhich is significantly better than the Pointer-Gen baseline and other RL\nmodels.", "published": "2019-09-09 01:33:01", "link": "http://arxiv.org/abs/1909.03582v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Reasoning Over Semantic-Level Graph for Fact Checking", "abstract": "Fact checking is a challenging task because verifying the truthfulness of a\nclaim requires reasoning about multiple retrievable evidence. In this work, we\npresent a method suitable for reasoning about the semantic-level structure of\nevidence. Unlike most previous works, which typically represent evidence\nsentences with either string concatenation or fusing the features of isolated\nevidence sentences, our approach operates on rich semantic structures of\nevidence obtained by semantic role labeling. We propose two mechanisms to\nexploit the structure of evidence while leveraging the advances of pre-trained\nmodels like BERT, GPT or XLNet. Specifically, using XLNet as the backbone, we\nfirst utilize the graph structure to re-define the relative distances of words,\nwith the intuition that semantically related words should have short distances.\nThen, we adopt graph convolutional network and graph attention network to\npropagate and aggregate information from neighboring nodes on the graph. We\nevaluate our system on FEVER, a benchmark dataset for fact checking, and find\nthat rich structural information is helpful and both our graph-based mechanisms\nimprove the accuracy. Our model is the state-of-the-art system in terms of both\nofficial evaluation metrics, namely claim verification accuracy and FEVER\nscore.", "published": "2019-09-09 10:34:09", "link": "http://arxiv.org/abs/1909.03745v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Conversational QA: Learning to Reason v.s. Exploiting Patterns", "abstract": "Neural Conversational QA tasks like ShARC require systems to answer questions\nbased on the contents of a given passage. On studying recent state-of-the-art\nmodels on the ShARCQA task, we found indications that the models learn spurious\nclues/patterns in the dataset. Furthermore, we show that a heuristic-based\nprogram designed to exploit these patterns can have performance comparable to\nthat of the neural models. In this paper we share our findings about four types\nof patterns found in the ShARC corpus and describe how neural models exploit\nthem. Motivated by the aforementioned findings, we create and share a modified\ndataset that has fewer spurious patterns, consequently allowing models to learn\nbetter.", "published": "2019-09-09 11:05:15", "link": "http://arxiv.org/abs/1909.03759v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Combination of Unified Embedding Model and Observed Features for\n  Knowledge Graph Completion", "abstract": "Knowledge graphs are useful for many artificial intelligence tasks but often\nhave missing data. Hence, a method for completing knowledge graphs is required.\nExisting approaches include embedding models, the Path Ranking Algorithm, and\nrule evaluation models. However, these approaches have limitations. For\nexample, all the information is mixed and difficult to interpret in embedding\nmodels, and traditional rule evaluation models are basically slow. In this\npaper, we provide an integrated view of various approaches and combine them to\ncompensate for their limitations. We first unify state-of-the-art embedding\nmodels, such as ComplEx and TorusE, reinterpreting them as a variant of\ntranslation-based models. Then, we show that these models utilize paths for\nlink prediction and propose a method for evaluating rules based on this idea.\nFinally, we combine an embedding model and observed feature models to predict\nmissing triples. This is possible because all of these models utilize paths. We\nalso conduct experiments, including link prediction tasks, with standard\ndatasets to evaluate our method and framework. The experiments show that our\nmethod can evaluate rules faster than traditional methods and that our\nframework outperforms state-of-the-art models in terms of link prediction.", "published": "2019-09-09 12:58:16", "link": "http://arxiv.org/abs/1909.03821v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Hierarchy Parsing for Image Captioning", "abstract": "It is always well believed that parsing an image into constituent visual\npatterns would be helpful for understanding and representing an image.\nNevertheless, there has not been evidence in support of the idea on describing\nan image with a natural-language utterance. In this paper, we introduce a new\ndesign to model a hierarchy from instance level (segmentation), region level\n(detection) to the whole image to delve into a thorough image understanding for\ncaptioning. Specifically, we present a HIerarchy Parsing (HIP) architecture\nthat novelly integrates hierarchical structure into image encoder. Technically,\nan image decomposes into a set of regions and some of the regions are resolved\ninto finer ones. Each region then regresses to an instance, i.e., foreground of\nthe region. Such process naturally builds a hierarchal tree. A tree-structured\nLong Short-Term Memory (Tree-LSTM) network is then employed to interpret the\nhierarchal structure and enhance all the instance-level, region-level and\nimage-level features. Our HIP is appealing in view that it is pluggable to any\nneural captioning models. Extensive experiments on COCO image captioning\ndataset demonstrate the superiority of HIP. More remarkably, HIP plus a\ntop-down attention-based LSTM decoder increases CIDEr-D performance from 120.1%\nto 127.2% on COCO Karpathy test split. When further endowing instance-level and\nregion-level features from HIP with semantic relation learnt through Graph\nConvolutional Networks (GCN), CIDEr-D is boosted up to 130.6%.", "published": "2019-09-09 15:18:21", "link": "http://arxiv.org/abs/1909.03918v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Recommendation as a Communication Game: Self-Supervised Bot-Play for\n  Goal-oriented Dialogue", "abstract": "Traditional recommendation systems produce static rather than interactive\nrecommendations invariant to a user's specific requests, clarifications, or\ncurrent mood, and can suffer from the cold-start problem if their tastes are\nunknown. These issues can be alleviated by treating recommendation as an\ninteractive dialogue task instead, where an expert recommender can sequentially\nask about someone's preferences, react to their requests, and recommend more\nappropriate items. In this work, we collect a goal-driven recommendation\ndialogue dataset (GoRecDial), which consists of 9,125 dialogue games and 81,260\nconversation turns between pairs of human workers recommending movies to each\nother. The task is specifically designed as a cooperative game between two\nplayers working towards a quantifiable common goal. We leverage the dataset to\ndevelop an end-to-end dialogue system that can simultaneously converse and\nrecommend. Models are first trained to imitate the behavior of human players\nwithout considering the task goal itself (supervised training). We then\nfinetune our models on simulated bot-bot conversations between two paired\npre-trained models (bot-play), in order to achieve the dialogue goal. Our\nexperiments show that models finetuned with bot-play learn improved dialogue\nstrategies, reach the dialogue goal more often when paired with a human, and\nare rated as more consistent by humans compared to models trained without\nbot-play. The dataset and code are publicly available through the ParlAI\nframework.", "published": "2019-09-09 15:19:56", "link": "http://arxiv.org/abs/1909.03922v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Counterfactual Story Reasoning and Generation", "abstract": "Counterfactual reasoning requires predicting how alternative events, contrary\nto what actually happened, might have resulted in different outcomes. Despite\nbeing considered a necessary component of AI-complete systems, few resources\nhave been developed for evaluating counterfactual reasoning in narratives.\n  In this paper, we propose Counterfactual Story Rewriting: given an original\nstory and an intervening counterfactual event, the task is to minimally revise\nthe story to make it compatible with the given counterfactual event. Solving\nthis task will require deep understanding of causal narrative chains and\ncounterfactual invariance, and integration of such story reasoning capabilities\ninto conditional language generation models.\n  We present TimeTravel, a new dataset of 29,849 counterfactual rewritings,\neach with the original story, a counterfactual event, and human-generated\nrevision of the original story compatible with the counterfactual event.\nAdditionally, we include 80,115 counterfactual \"branches\" without a rewritten\nstoryline to support future work on semi- or un-supervised approaches to\ncounterfactual story rewriting.\n  Finally, we evaluate the counterfactual rewriting capacities of several\ncompetitive baselines based on pretrained language models, and assess whether\ncommon overlap and model-based automatic metrics for text generation correlate\nwell with human scores for counterfactual rewriting.", "published": "2019-09-09 18:08:35", "link": "http://arxiv.org/abs/1909.04076v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Naturalist: Generating Fine-Grained Image Comparisons", "abstract": "We introduce the new Birds-to-Words dataset of 41k sentences describing\nfine-grained differences between photographs of birds. The language collected\nis highly detailed, while remaining understandable to the everyday observer\n(e.g., \"heart-shaped face,\" \"squat body\"). Paragraph-length descriptions\nnaturally adapt to varying levels of taxonomic and visual distance---drawn from\na novel stratified sampling approach---with the appropriate level of detail. We\npropose a new model called Neural Naturalist that uses a joint image encoding\nand comparative module to generate comparative language, and evaluate the\nresults with humans who must use the descriptions to distinguish real images.\n  Our results indicate promising potential for neural models to explain\ndifferences in visual embedding space using natural language, as well as a\nconcrete path for machine learning to aid citizen scientists in their effort to\npreserve biodiversity.", "published": "2019-09-09 18:54:40", "link": "http://arxiv.org/abs/1909.04101v3", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Learning to Learn and Predict: A Meta-Learning Approach for Multi-Label\n  Classification", "abstract": "Many tasks in natural language processing can be viewed as multi-label\nclassification problems. However, most of the existing models are trained with\nthe standard cross-entropy loss function and use a fixed prediction policy\n(e.g., a threshold of 0.5) for all the labels, which completely ignores the\ncomplexity and dependencies among different labels. In this paper, we propose a\nmeta-learning method to capture these complex label dependencies. More\nspecifically, our method utilizes a meta-learner to jointly learn the training\npolicies and prediction policies for different labels. The training policies\nare then used to train the classifier with the cross-entropy loss function, and\nthe prediction policies are further implemented for prediction. Experimental\nresults on fine-grained entity typing and text classification demonstrate that\nour proposed method can obtain more accurate multi-label classification\nresults.", "published": "2019-09-09 22:00:39", "link": "http://arxiv.org/abs/1909.04176v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Gaussian Copula for Variational Autoencoder", "abstract": "Variational language models seek to estimate the posterior of latent\nvariables with an approximated variational posterior. The model often assumes\nthe variational posterior to be factorized even when the true posterior is not.\nThe learned variational posterior under this assumption does not capture the\ndependency relationships over latent variables. We argue that this would cause\na typical training problem called posterior collapse observed in all other\nvariational language models. We propose Gaussian Copula Variational Autoencoder\n(VAE) to avert this problem. Copula is widely used to model correlation and\ndependencies of high-dimensional random variables, and therefore it is helpful\nto maintain the dependency relationships that are lost in VAE. The empirical\nresults show that by modeling the correlation of latent variables explicitly\nusing a neural parametric copula, we can avert this training difficulty while\ngetting competitive results among all other VAE approaches.", "published": "2019-09-09 00:10:58", "link": "http://arxiv.org/abs/1909.03569v1", "categories": ["cs.CL", "cs.LG", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Transfer Reward Learning for Policy Gradient-Based Text Generation", "abstract": "Task-specific scores are often used to optimize for and evaluate the\nperformance of conditional text generation systems. However, such scores are\nnon-differentiable and cannot be used in the standard supervised learning\nparadigm. Hence, policy gradient methods are used since the gradient can be\ncomputed without requiring a differentiable objective.\n  However, we argue that current n-gram overlap based measures that are used as\nrewards can be improved by using model-based rewards transferred from tasks\nthat directly compare the similarity of sentence pairs. These reward models\neither output a score of sentence-level syntactic and semantic similarity\nbetween entire predicted and target sentences as the expected return, or for\nintermediate phrases as segmented accumulative rewards.\n  We demonstrate that using a \\textit{Transferable Reward Learner} leads to\nimproved results on semantical evaluation measures in policy-gradient models\nfor image captioning tasks. Our InferSent actor-critic model improves over a\nBLEU trained actor-critic model on MSCOCO when evaluated on a Word Mover's\nDistance similarity measure by 6.97 points, also improving on a Sliding Window\nCosine Similarity measure by 10.48 points. Similar performance improvements are\nalso obtained on the smaller Flickr-30k dataset, demonstrating the general\napplicability of the proposed transfer learning method.", "published": "2019-09-09 03:36:42", "link": "http://arxiv.org/abs/1909.03622v1", "categories": ["cs.LG", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known\n  Dataset Biases", "abstract": "State-of-the-art models often make use of superficial patterns in the data\nthat do not generalize well to out-of-domain or adversarial settings. For\nexample, textual entailment models often learn that particular key words imply\nentailment, irrespective of context, and visual question answering models learn\nto predict prototypical answers, without considering evidence in the image. In\nthis paper, we show that if we have prior knowledge of such biases, we can\ntrain a model to be more robust to domain shift. Our method has two stages: we\n(1) train a naive model that makes predictions exclusively based on dataset\nbiases, and (2) train a robust model as part of an ensemble with the naive one\nin order to encourage it to focus on other patterns in the data that are more\nlikely to generalize. Experiments on five datasets with out-of-domain test sets\nshow significantly improved robustness in all settings, including a 12 point\ngain on a changing priors visual question answering dataset and a 9 point gain\non an adversarial question answering test set.", "published": "2019-09-09 07:44:24", "link": "http://arxiv.org/abs/1909.03683v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Composing Knowledge Graph Embeddings via Word Embeddings", "abstract": "Learning knowledge graph embedding from an existing knowledge graph is very\nimportant to knowledge graph completion. For a fact $(h,r,t)$ with the head\nentity $h$ having a relation $r$ with the tail entity $t$, the current\napproaches aim to learn low dimensional representations\n$(\\mathbf{h},\\mathbf{r},\\mathbf{t})$, each of which corresponds to the elements\nin $(h, r, t)$, respectively. As $(\\mathbf{h},\\mathbf{r},\\mathbf{t})$ is\nlearned from the existing facts within a knowledge graph, these representations\ncan not be used to detect unknown facts (if the entities or relations never\noccur in the knowledge graph).\n  This paper proposes a new approach called TransW, aiming to go beyond the\ncurrent work by composing knowledge graph embeddings using word embeddings.\nGiven the fact that an entity or a relation contains one or more words (quite\noften), it is sensible to learn a mapping function from word embedding spaces\nto knowledge embedding spaces, which shows how entities are constructed using\nhuman words. More importantly, composing knowledge embeddings using word\nembeddings makes it possible to deal with the emerging new facts (either new\nentities or relations). Experimental results using three public datasets show\nthe consistency and outperformance of the proposed TransW.", "published": "2019-09-09 12:22:28", "link": "http://arxiv.org/abs/1909.03794v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Out-of-domain Detection for Natural Language Understanding in Dialog\n  Systems", "abstract": "Natural Language Understanding (NLU) is a vital component of dialogue\nsystems, and its ability to detect Out-of-Domain (OOD) inputs is critical in\npractical applications, since the acceptance of the OOD input that is\nunsupported by the current system may lead to catastrophic failure. However,\nmost existing OOD detection methods rely heavily on manually labeled OOD\nsamples and cannot take full advantage of unlabeled data. This limits the\nfeasibility of these models in practical applications.\n  In this paper, we propose a novel model to generate high-quality pseudo OOD\nsamples that are akin to IN-Domain (IND) input utterances, and thereby improves\nthe performance of OOD detection. To this end, an autoencoder is trained to map\nan input utterance into a latent code. and the codes of IND and OOD samples are\ntrained to be indistinguishable by utilizing a generative adversarial network.\nTo provide more supervision signals, an auxiliary classifier is introduced to\nregularize the generated OOD samples to have indistinguishable intent labels.\nExperiments show that these pseudo OOD samples generated by our model can be\nused to effectively improve OOD detection in NLU. Besides, we also demonstrate\nthat the effectiveness of these pseudo OOD data can be further improved by\nefficiently utilizing unlabeled data.", "published": "2019-09-09 13:49:10", "link": "http://arxiv.org/abs/1909.03862v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Long-form Text-to-Speech: Comparing the Ratings of Sentences\n  and Paragraphs", "abstract": "Text-to-speech systems are typically evaluated on single sentences. When\nlong-form content, such as data consisting of full paragraphs or dialogues is\nconsidered, evaluating sentences in isolation is not always appropriate as the\ncontext in which the sentences are synthesized is missing. In this paper, we\ninvestigate three different ways of evaluating the naturalness of long-form\ntext-to-speech synthesis. We compare the results obtained from evaluating\nsentences in isolation, evaluating whole paragraphs of speech, and presenting a\nselection of speech or text as context and evaluating the subsequent speech. We\nfind that, even though these three evaluations are based upon the same\nmaterial, the outcomes differ per setting, and moreover that these outcomes do\nnot necessarily correlate with each other. We show that our findings are\nconsistent between a single speaker setting of read paragraphs and a\ntwo-speaker dialogue scenario. We conclude that to evaluate the quality of\nlong-form speech, the traditional way of evaluating sentences in isolation does\nnot suffice, and that multiple evaluations are required.", "published": "2019-09-09 16:13:20", "link": "http://arxiv.org/abs/1909.03965v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Span Selection Pre-training for Question Answering", "abstract": "BERT (Bidirectional Encoder Representations from Transformers) and related\npre-trained Transformers have provided large gains across many language\nunderstanding tasks, achieving a new state-of-the-art (SOTA). BERT is\npre-trained on two auxiliary tasks: Masked Language Model and Next Sentence\nPrediction. In this paper we introduce a new pre-training task inspired by\nreading comprehension to better align the pre-training from memorization to\nunderstanding. Span Selection Pre-Training (SSPT) poses cloze-like training\ninstances, but rather than draw the answer from the model's parameters, it is\nselected from a relevant passage. We find significant and consistent\nimprovements over both BERT-BASE and BERT-LARGE on multiple reading\ncomprehension (MRC) datasets. Specifically, our proposed model has strong\nempirical evidence as it obtains SOTA results on Natural Questions, a new\nbenchmark MRC dataset, outperforming BERT-LARGE by 3 F1 points on short answer\nprediction. We also show significant impact in HotpotQA, improving answer\nprediction F1 by 4 points and supporting fact prediction F1 by 1 point and\noutperforming the previous best system. Moreover, we show that our pre-training\napproach is particularly effective when training data is limited, improving the\nlearning curve by a large amount.", "published": "2019-09-09 19:32:31", "link": "http://arxiv.org/abs/1909.04120v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Follow the Leader: Documents on the Leading Edge of Semantic Change Get\n  More Citations", "abstract": "Diachronic word embeddings -- vector representations of words over time --\noffer remarkable insights into the evolution of language and provide a tool for\nquantifying sociocultural change from text documents. Prior work has used such\nembeddings to identify shifts in the meaning of individual words. However,\nsimply knowing that a word has changed in meaning is insufficient to identify\nthe instances of word usage that convey the historical or the newer meaning. In\nthis paper, we link diachronic word embeddings to documents, by situating those\ndocuments as leaders or laggards with respect to ongoing semantic changes.\nSpecifically, we propose a novel method to quantify the degree of semantic\nprogressiveness in each word usage, and then show how these usages can be\naggregated to obtain scores for each document. We analyze two large collections\nof documents, representing legal opinions and scientific articles. Documents\nthat are scored as semantically progressive receive a larger number of\ncitations, indicating that they are especially influential. Our work thus\nprovides a new technique for identifying lexical semantic leaders and\ndemonstrates a new link between progressive use of language and influence in a\ncitation network.", "published": "2019-09-09 22:43:02", "link": "http://arxiv.org/abs/1909.04189v2", "categories": ["cs.CL", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Question Generation by Transformers", "abstract": "A machine learning model was developed to automatically generate questions\nfrom Wikipedia passages using transformers, an attention-based model eschewing\nthe paradigm of existing recurrent neural networks (RNNs). The model was\ntrained on the inverted Stanford Question Answering Dataset (SQuAD), which is a\nreading comprehension dataset consisting of 100,000+ questions posed by\ncrowdworkers on a set of Wikipedia articles. After training, the question\ngeneration model is able to generate simple questions relevant to unseen\npassages and answers containing an average of 8 words per question. The word\nerror rate (WER) was used as a metric to compare the similarity between SQuAD\nquestions and the model-generated questions. Although the high average WER\nsuggests that the questions generated differ from the original SQuAD questions,\nthe questions generated are mostly grammatically correct and plausible in their\nown right.", "published": "2019-09-09 19:48:53", "link": "http://arxiv.org/abs/1909.05017v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Quantum Search Decoder for Natural Language Processing", "abstract": "Probabilistic language models, e.g. those based on an LSTM, often face the\nproblem of finding a high probability prediction from a sequence of random\nvariables over a set of tokens. This is commonly addressed using a form of\ngreedy decoding such as beam search, where a limited number of\nhighest-likelihood paths (the beam width) of the decoder are kept, and at the\nend the maximum-likelihood path is chosen. In this work, we construct a quantum\nalgorithm to find the globally optimal parse (i.e. for infinite beam width)\nwith high constant success probability. When the input to the decoder is\ndistributed as a power-law with exponent $k>0$, our algorithm has runtime $R^{n\nf(R,k)}$, where $R$ is the alphabet size, $n$ the input length; here $f<1/2$,\nand $f\\rightarrow 0$ exponentially fast with increasing $k$, hence making our\nalgorithm always more than quadratically faster than its classical counterpart.\nWe further modify our procedure to recover a finite beam width variant, which\nenables an even stronger empirical speedup while still retaining higher\naccuracy than possible classically. Finally, we apply this quantum beam search\ndecoder to Mozilla's implementation of Baidu's DeepSpeech neural net, which we\nshow to exhibit such a power law word rank frequency.", "published": "2019-09-09 17:59:23", "link": "http://arxiv.org/abs/1909.05023v2", "categories": ["quant-ph", "cs.CL", "cs.DS", "cs.LG", "68T50, 68Q12, 68T05"], "primary_category": "quant-ph"}
{"title": "Event Representation Learning Enhanced with External Commonsense\n  Knowledge", "abstract": "Prior work has proposed effective methods to learn event representations that\ncan capture syntactic and semantic information over text corpus, demonstrating\ntheir effectiveness for downstream tasks such as script event prediction. On\nthe other hand, events extracted from raw texts lacks of commonsense knowledge,\nsuch as the intents and emotions of the event participants, which are useful\nfor distinguishing event pairs when there are only subtle differences in their\nsurface realizations. To address this issue, this paper proposes to leverage\nexternal commonsense knowledge about the intent and sentiment of the event.\nExperiments on three event-related tasks, i.e., event similarity, script event\nprediction and stock market prediction, show that our model obtains much better\nevent embeddings for the tasks, achieving 78% improvements on hard similarity\ntask, yielding more precise inferences on subsequent events under given\ncontexts, and better accuracies in predicting the volatilities of the stock\nmarket.", "published": "2019-09-09 03:00:39", "link": "http://arxiv.org/abs/1909.05190v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Self-Teaching Networks", "abstract": "We propose self-teaching networks to improve the generalization capacity of\ndeep neural networks. The idea is to generate soft supervision labels using the\noutput layer for training the lower layers of the network. During the network\ntraining, we seek an auxiliary loss that drives the lower layer to mimic the\nbehavior of the output layer. The connection between the two network layers\nthrough the auxiliary loss can help the gradient flow, which works similar to\nthe residual networks. Furthermore, the auxiliary loss also works as a\nregularizer, which improves the generalization capacity of the network. We\nevaluated the self-teaching network with deep recurrent neural networks on\nspeech recognition tasks, where we trained the acoustic model using 30 thousand\nhours of data. We tested the acoustic model using data collected from 4\nscenarios. We show that the self-teaching network can achieve consistent\nimprovements and outperform existing methods such as label smoothing and\nconfidence penalization.", "published": "2019-09-09 21:11:35", "link": "http://arxiv.org/abs/1909.04157v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Nearly-Unsupervised Hashcode Representations for Relation Extraction", "abstract": "Recently, kernelized locality sensitive hashcodes have been successfully\nemployed as representations of natural language text, especially showing high\nrelevance to biomedical relation extraction tasks. In this paper, we propose to\noptimize the hashcode representations in a nearly unsupervised manner, in which\nwe only use data points, but not their class labels, for learning. The\noptimized hashcode representations are then fed to a supervised classifier\nfollowing the prior work. This nearly unsupervised approach allows fine-grained\noptimization of each hash function, which is particularly suitable for building\nhashcode representations generalizing from a training set to a test set. We\nempirically evaluate the proposed approach for biomedical relation extraction\ntasks, obtaining significant accuracy improvements w.r.t. state-of-the-art\nsupervised and semi-supervised approaches.", "published": "2019-09-09 14:20:05", "link": "http://arxiv.org/abs/1909.03881v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Impulse Response Data Augmentation and Deep Neural Networks for Blind\n  Room Acoustic Parameter Estimation", "abstract": "The reverberation time (T60) and the direct-to-reverberant ratio (DRR) are\ncommonly used to characterize room acoustic environments. Both parameters can\nbe measured from an acoustic impulse response (AIR) or using blind estimation\nmethods that perform estimation directly from speech. When neural networks are\nused for blind estimation, however, a large realistic dataset is needed, which\nis expensive and time consuming to collect. To address this, we propose an AIR\naugmentation method that can parametrically control the T60 and DRR, allowing\nus to expand a small dataset of real AIRs into a balanced dataset orders of\nmagnitude larger. Using this method, we train a previously proposed\nconvolutional neural network (CNN) and show we can outperform past\nsingle-channel state-of-the-art methods. We then propose a more efficient,\nstraightforward baseline CNN that is 4-5x faster, which provides an additional\nimprovement and is better or comparable to all previously reported single- and\nmulti-channel state-of-the-art methods.", "published": "2019-09-09 06:13:31", "link": "http://arxiv.org/abs/1909.03642v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Real-time and interactive tools for vocal training based on an analytic\n  signal with a cosine series envelope", "abstract": "We introduce real-time and interactive tools for assisting vocal training. In\nthis presentation, we demonstrate mainly a tool based on real-time visualizer\nof fundamental frequency candidates to provide information-rich feedback to\nlearners. The visualizer uses an efficient algorithm using analytic signals for\nderiving phase-based attributes. We start using these tools in vocal training\nfor assisting learners to acquire the awareness of appropriate vocalization.\nThe first author made the MATLAB implementation of the tools open-source. The\ncode and associated video materials are accessible in the first author's GitHub\nrepository.", "published": "2019-09-09 06:30:16", "link": "http://arxiv.org/abs/1909.03650v1", "categories": ["cs.SD", "cs.HC", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "DNN-based cross-lingual voice conversion using Bottleneck Features", "abstract": "Cross-lingual voice conversion (CLVC) is a quite challenging task since the\nsource and target speakers speak different languages. This paper proposes a\nCLVC framework based on bottleneck features and deep neural network (DNN). In\nthe proposed method, the bottleneck features extracted from a deep auto-encoder\n(DAE) are used to represent speaker-independent features of speech signals from\ndifferent languages. A DNN model is trained to learn the mapping between\nbottleneck features and the corresponding spectral features of the target\nspeaker. The proposed method can capture speaker-specific characteristics of a\ntarget speaker, and hence requires no speech data from source speaker during\ntraining. The performance of the proposed method is evaluated using data from\nthree Indian languages: Telugu, Tamil and Malayalam. The experimental results\nshow that the proposed method outperforms the baseline Gaussian mixture model\n(GMM)-based CLVC approach.", "published": "2019-09-09 16:35:55", "link": "http://arxiv.org/abs/1909.03974v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Preech: A System for Privacy-Preserving Speech Transcription", "abstract": "New Advances in machine learning have made Automated Speech Recognition (ASR)\nsystems practical and more scalable. These systems, however, pose serious\nprivacy threats as speech is a rich source of sensitive acoustic and textual\ninformation. Although offline and open-source ASR eliminates the privacy risks,\nits transcription performance is inferior to that of cloud-based ASR systems,\nespecially for real-world use cases. In this paper, we propose\nPr$\\epsilon\\epsilon$ch, an end-to-end speech transcription system which lies at\nan intermediate point in the privacy-utility spectrum. It protects the acoustic\nfeatures of the speakers' voices and protects the privacy of the textual\ncontent at an improved performance relative to offline ASR. Additionally,\nPr$\\epsilon\\epsilon$ch provides several control knobs to allow customizable\nutility-usability-privacy trade-off. It relies on cloud-based services to\ntranscribe a speech file after applying a series of privacy-preserving\noperations on the user's side. We perform a comprehensive evaluation of\nPr$\\epsilon\\epsilon$ch, using diverse real-world datasets, that demonstrates\nits effectiveness. Pr$\\epsilon\\epsilon$ch provides transcriptions at a 2% to\n32.25% (mean 17.34%) relative improvement in word error rate over Deep Speech,\nwhile fully obfuscating the speakers' voice biometrics and allowing only a\ndifferentially private view of the textual content.", "published": "2019-09-09 23:59:10", "link": "http://arxiv.org/abs/1909.04198v4", "categories": ["cs.CR", "cs.SD", "eess.AS"], "primary_category": "cs.CR"}
