{"title": "EQG-RACE: Examination-Type Question Generation", "abstract": "Question Generation (QG) is an essential component of the automatic\nintelligent tutoring systems, which aims to generate high-quality questions for\nfacilitating the reading practice and assessments. However, existing QG\ntechnologies encounter several key issues concerning the biased and unnatural\nlanguage sources of datasets which are mainly obtained from the Web (e.g.\nSQuAD). In this paper, we propose an innovative Examination-type Question\nGeneration approach (EQG-RACE) to generate exam-like questions based on a\ndataset extracted from RACE. Two main strategies are employed in EQG-RACE for\ndealing with discrete answer information and reasoning among long contexts. A\nRough Answer and Key Sentence Tagging scheme is utilized to enhance the\nrepresentations of input. An Answer-guided Graph Convolutional Network (AG-GCN)\nis designed to capture structure information in revealing the inter-sentences\nand intra-sentence relations. Experimental results show a state-of-the-art\nperformance of EQG-RACE, which is apparently superior to the baselines. In\naddition, our work has established a new QG prototype with a reshaped dataset\nand QG method, which provides an important benchmark for related research in\nfuture work. We will make our data and code publicly available for further\nresearch.", "published": "2020-12-11 03:52:17", "link": "http://arxiv.org/abs/2012.06106v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Document-aligned Japanese-English Conversation Parallel Corpus", "abstract": "Sentence-level (SL) machine translation (MT) has reached acceptable quality\nfor many high-resourced languages, but not document-level (DL) MT, which is\ndifficult to 1) train with little amount of DL data; and 2) evaluate, as the\nmain methods and data sets focus on SL evaluation. To address the first issue,\nwe present a document-aligned Japanese-English conversation corpus, including\nbalanced, high-quality business conversation data for tuning and testing. As\nfor the second issue, we manually identify the main areas where SL MT fails to\nproduce adequate translations in lack of context. We then create an evaluation\nset where these phenomena are annotated to alleviate automatic evaluation of DL\nsystems. We train MT models using our corpus to demonstrate how using context\nleads to improvements.", "published": "2020-12-11 06:03:33", "link": "http://arxiv.org/abs/2012.06143v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Task-Agnostic BERT Distillation with Layer Mapping Search", "abstract": "Knowledge distillation (KD) which transfers the knowledge from a large\nteacher model to a small student model, has been widely used to compress the\nBERT model recently. Besides the supervision in the output in the original KD,\nrecent works show that layer-level supervision is crucial to the performance of\nthe student BERT model. However, previous works designed the layer mapping\nstrategy heuristically (e.g., uniform or last-layer), which can lead to\ninferior performance. In this paper, we propose to use the genetic algorithm\n(GA) to search for the optimal layer mapping automatically. To accelerate the\nsearch process, we further propose a proxy setting where a small portion of the\ntraining corpus are sampled for distillation, and three representative tasks\nare chosen for evaluation. After obtaining the optimal layer mapping, we\nperform the task-agnostic BERT distillation with it on the whole corpus to\nbuild a compact student model, which can be directly fine-tuned on downstream\ntasks. Comprehensive experiments on the evaluation benchmarks demonstrate that\n1) layer mapping strategy has a significant effect on task-agnostic BERT\ndistillation and different layer mappings can result in quite different\nperformances; 2) the optimal layer mapping strategy from the proposed search\nprocess consistently outperforms the other heuristic ones; 3) with the optimal\nlayer mapping, our student model achieves state-of-the-art performance on the\nGLUE tasks.", "published": "2020-12-11 06:29:58", "link": "http://arxiv.org/abs/2012.06153v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Zero Shot Learning Baselines with Commonsense Knowledge", "abstract": "Zero shot learning -- the problem of training and testing on a completely\ndisjoint set of classes -- relies greatly on its ability to transfer knowledge\nfrom train classes to test classes. Traditionally semantic embeddings\nconsisting of human defined attributes (HA) or distributed word embeddings\n(DWE) are used to facilitate this transfer by improving the association between\nvisual and semantic embeddings. In this paper, we take advantage of explicit\nrelations between nodes defined in ConceptNet, a commonsense knowledge graph,\nto generate commonsense embeddings of the class labels by using a graph\nconvolution network-based autoencoder. Our experiments performed on three\nstandard benchmark datasets surpass the strong baselines when we fuse our\ncommonsense embeddings with existing semantic embeddings i.e. HA and DWE.", "published": "2020-12-11 10:52:04", "link": "http://arxiv.org/abs/2012.06236v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Morphology Matters: A Multilingual Language Modeling Analysis", "abstract": "Prior studies in multilingual language modeling (e.g., Cotterell et al.,\n2018; Mielke et al., 2019) disagree on whether or not inflectional morphology\nmakes languages harder to model. We attempt to resolve the disagreement and\nextend those studies. We compile a larger corpus of 145 Bible translations in\n92 languages and a larger number of typological features. We fill in missing\ntypological data for several languages and consider corpus-based measures of\nmorphological complexity in addition to expert-produced typological features.\nWe find that several morphological measures are significantly associated with\nhigher surprisal when LSTM models are trained with BPE-segmented data. We also\ninvestigate linguistically-motivated subword segmentation strategies like\nMorfessor and Finite-State Transducers (FSTs) and find that these segmentation\nstrategies yield better performance and reduce the impact of a language's\nmorphology on language modeling.", "published": "2020-12-11 11:55:55", "link": "http://arxiv.org/abs/2012.06262v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discriminating Between Similar Nordic Languages", "abstract": "Automatic language identification is a challenging problem. Discriminating\nbetween closely related languages is especially difficult. This paper presents\na machine learning approach for automatic language identification for the\nNordic languages, which often suffer miscategorisation by existing\nstate-of-the-art tools. Concretely we will focus on discrimination between six\nNordic languages: Danish, Swedish, Norwegian (Nynorsk), Norwegian (Bokm{\\aa}l),\nFaroese and Icelandic.", "published": "2020-12-11 15:46:15", "link": "http://arxiv.org/abs/2012.06431v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Orthogonal Language and Task Adapters in Zero-Shot Cross-Lingual\n  Transfer", "abstract": "Adapter modules, additional trainable parameters that enable efficient\nfine-tuning of pretrained transformers, have recently been used for language\nspecialization of multilingual transformers, improving downstream zero-shot\ncross-lingual transfer. In this work, we propose orthogonal language and task\nadapters (dubbed orthoadapters) for cross-lingual transfer. They are trained to\nencode language- and task-specific information that is complementary (i.e.,\northogonal) to the knowledge already stored in the pretrained transformer's\nparameters. Our zero-shot cross-lingual transfer experiments, involving three\ntasks (POS-tagging, NER, NLI) and a set of 10 diverse languages, 1) point to\nthe usefulness of orthoadapters in cross-lingual transfer, especially for the\nmost complex NLI task, but also 2) indicate that the optimal adapter\nconfiguration highly depends on the task and the target language. We hope that\nour work will motivate a wider investigation of usefulness of orthogonality\nconstraints in language- and task-specific fine-tuning of pretrained\ntransformers.", "published": "2020-12-11 16:32:41", "link": "http://arxiv.org/abs/2012.06460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TF-CR: Weighting Embeddings for Text Classification", "abstract": "Text classification, as the task consisting in assigning categories to\ntextual instances, is a very common task in information science. Methods\nlearning distributed representations of words, such as word embeddings, have\nbecome popular in recent years as the features to use for text classification\ntasks. Despite the increasing use of word embeddings for text classification,\nthese are generally used in an unsupervised manner, i.e. information derived\nfrom class labels in the training data are not exploited. While word embeddings\ninherently capture the distributional characteristics of words, and contexts\nobserved around them in a large dataset, they aren't optimised to consider the\ndistributions of words across categories in the classification dataset at hand.\nTo optimise text representations based on word embeddings by incorporating\nclass distributions in the training data, we propose the use of weighting\nschemes that assign a weight to embeddings of each word based on its saliency\nin each class. To achieve this, we introduce a novel weighting scheme, Term\nFrequency-Category Ratio (TF-CR), which can weight high-frequency,\ncategory-exclusive words higher when computing word embeddings. Our experiments\non 16 classification datasets show the effectiveness of TF-CR, leading to\nimproved performance scores over existing weighting schemes, with a performance\ngap that increases as the size of the training data grows.", "published": "2020-12-11 19:23:28", "link": "http://arxiv.org/abs/2012.06606v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Complexity of Comparative Text Analysis -- \"The Gardener is always\n  the Murderer\" says the Fourth Machine", "abstract": "There is a heated debate about how far computers can map the complexity of\ntext analysis compared to the abilities of the whole team of human researchers.\nA \"deep\" analysis of a given text is still beyond the possibilities of modern\ncomputers.\n  In the heart of the existing computational text analysis algorithms there are\noperations with real numbers, such as additions and multiplications according\nto the rules of algebraic fields. However, the process of \"comparing\" has a\nvery precise mathematical structure, which is different from the structure of\nan algebraic field. The mathematical structure of \"comparing\" can be expressed\nby using Boolean rings. We build on this structure and define the corresponding\nalgebraic equations lifting algorithms of comparative text analysis onto the\n\"correct\" algebraic basis. From this point of view, we can investigate the\nquestion of {\\em computational} complexity of comparative text analysis.", "published": "2020-12-11 10:32:35", "link": "http://arxiv.org/abs/2012.07637v1", "categories": ["cs.CL", "06Exx, 13-xx, 68Txx", "J.5"], "primary_category": "cs.CL"}
{"title": "Reinforced Multi-Teacher Selection for Knowledge Distillation", "abstract": "In natural language processing (NLP) tasks, slow inference speed and huge\nfootprints in GPU usage remain the bottleneck of applying pre-trained deep\nmodels in production. As a popular method for model compression, knowledge\ndistillation transfers knowledge from one or multiple large (teacher) models to\na small (student) model. When multiple teacher models are available in\ndistillation, the state-of-the-art methods assign a fixed weight to a teacher\nmodel in the whole distillation. Furthermore, most of the existing methods\nallocate an equal weight to every teacher model. In this paper, we observe\nthat, due to the complexity of training examples and the differences in student\nmodel capability, learning differentially from teacher models can lead to\nbetter performance of student models distilled. We systematically develop a\nreinforced method to dynamically assign weights to teacher models for different\ntraining instances and optimize the performance of student model. Our extensive\nexperimental results on several NLP tasks clearly verify the feasibility and\neffectiveness of our approach.", "published": "2020-12-11 08:56:39", "link": "http://arxiv.org/abs/2012.06048v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ParsiNLU: A Suite of Language Understanding Challenges for Persian", "abstract": "Despite the progress made in recent years in addressing natural language\nunderstanding (NLU) challenges, the majority of this progress remains to be\nconcentrated on resource-rich languages like English. This work focuses on\nPersian language, one of the widely spoken languages in the world, and yet\nthere are few NLU datasets available for this rich language. The availability\nof high-quality evaluation datasets is a necessity for reliable assessment of\nthe progress on different NLU tasks and domains. We introduce ParsiNLU, the\nfirst benchmark in Persian language that includes a range of high-level tasks\n-- Reading Comprehension, Textual Entailment, etc. These datasets are collected\nin a multitude of ways, often involving manual annotations by native speakers.\nThis results in over 14.5$k$ new instances across 6 distinct NLU tasks.\nBesides, we present the first results on state-of-the-art monolingual and\nmulti-lingual pre-trained language-models on this benchmark and compare them\nwith human performance, which provides valuable insights into our ability to\ntackle natural language understanding challenges in Persian. We hope ParsiNLU\nfosters further research and advances in Persian language understanding.", "published": "2020-12-11 06:31:42", "link": "http://arxiv.org/abs/2012.06154v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improved Robustness to Disfluencies in RNN-Transducer Based Speech\n  Recognition", "abstract": "Automatic Speech Recognition (ASR) based on Recurrent Neural Network\nTransducers (RNN-T) is gaining interest in the speech community. We investigate\ndata selection and preparation choices aiming for improved robustness of RNN-T\nASR to speech disfluencies with a focus on partial words. For evaluation we use\nclean data, data with disfluencies and a separate dataset with speech affected\nby stuttering. We show that after including a small amount of data with\ndisfluencies in the training set the recognition accuracy on the tests with\ndisfluencies and stuttering improves. Increasing the amount of training data\nwith disfluencies gives additional gains without degradation on the clean data.\nWe also show that replacing partial words with a dedicated token helps to get\neven better accuracy on utterances with disfluencies and stutter. The\nevaluation of our best model shows 22.5% and 16.4% relative WER reduction on\nthose two evaluation sets.", "published": "2020-12-11 11:47:13", "link": "http://arxiv.org/abs/2012.06259v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "An End-to-End Solution for Named Entity Recognition in eCommerce Search", "abstract": "Named entity recognition (NER) is a critical step in modern search query\nunderstanding. In the domain of eCommerce, identifying the key entities, such\nas brand and product type, can help a search engine retrieve relevant products\nand therefore offer an engaging shopping experience. Recent research shows\npromising results on shared benchmark NER tasks using deep learning methods,\nbut there are still unique challenges in the industry regarding domain\nknowledge, training data, and model production. This paper demonstrates an\nend-to-end solution to address these challenges. The core of our solution is a\nnovel model training framework \"TripleLearn\" which iteratively learns from\nthree separate training datasets, instead of one training set as is\ntraditionally done. Using this approach, the best model lifts the F1 score from\n69.5 to 93.3 on the holdout test data. In our offline experiments, TripleLearn\nimproved the model performance compared to traditional training approaches\nwhich use a single set of training data. Moreover, in the online A/B test, we\nsee significant improvements in user engagement and revenue conversion. The\nmodel has been live on homedepot.com for more than 9 months, boosting search\nconversions and revenue. Beyond our application, this TripleLearn framework, as\nwell as the end-to-end process, is model-independent and problem-independent,\nso it can be generalized to more industrial applications, especially to the\neCommerce industry which has similar data foundations and problems.", "published": "2020-12-11 04:58:13", "link": "http://arxiv.org/abs/2012.07553v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An algorithm for onset detection of linguistic segments in continuous\n  electroencephalogram signals", "abstract": "A Brain Computer Interface based on imagined words can decode the word a\nsubject is thinking on through brain signals to control an external device. In\norder to build a fully asynchronous Brain Computer Interface based on imagined\nwords in electroencephalogram signals as source, we need to solve the problem\nof detecting the onset of the imagined words. Although there has been some\nresearch in this field, the problem has not been fully solved. In this paper we\npresent an approach to solve this problem by using values from statistics,\ninformation theory and chaos theory as features to correctly identify the onset\nof imagined words in a continuous signal. On detecting the onsets of imagined\nwords, the highest True Positive Rate achieved by our approach was obtained\nusing features based on the generalized Hurst exponent, this True Positive Rate\nwas 0.69 and 0.77 with a timing error tolerance region of 3 and 4 seconds\nrespectively.", "published": "2020-12-11 01:38:06", "link": "http://arxiv.org/abs/2012.06075v1", "categories": ["eess.SP", "cs.CL", "cs.LG", "q-bio.NC"], "primary_category": "eess.SP"}
{"title": "Exploring wav2vec 2.0 on speaker verification and language\n  identification", "abstract": "Wav2vec 2.0 is a recently proposed self-supervised framework for speech\nrepresentation learning. It follows a two-stage training process of\npre-training and fine-tuning, and performs well in speech recognition tasks\nespecially ultra-low resource cases. In this work, we attempt to extend\nself-supervised framework to speaker verification and language identification.\nFirst, we use some preliminary experiments to indicate that wav2vec 2.0 can\ncapture the information about the speaker and language. Then we demonstrate the\neffectiveness of wav2vec 2.0 on the two tasks respectively. For speaker\nverification, we obtain a new state-of-the-art result, Equal Error Rate (EER)\nof 3.61% on the VoxCeleb1 dataset. For language identification, we obtain an\nEER of 12.02% on 1 second condition and an EER of 3.47% on full-length\ncondition of the AP17-OLR dataset. Finally, we utilize one model to achieve the\nunified modeling by the multi-task learning for the two tasks.", "published": "2020-12-11 08:22:23", "link": "http://arxiv.org/abs/2012.06185v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Topic Coverage Approach to Evaluation of Topic Models", "abstract": "Topic models are widely used unsupervised models capable of learning topics -\nweighted lists of words and documents - from large collections of text\ndocuments. When topic models are used for discovery of topics in text\ncollections, a question that arises naturally is how well the model-induced\ntopics correspond to topics of interest to the analyst. In this paper we\nrevisit and extend a so far neglected approach to topic model evaluation based\non measuring topic coverage - computationally matching model topics with a set\nof reference topics that models are expected to uncover. The approach is well\nsuited for analyzing models' performance in topic discovery and for large-scale\nanalysis of both topic models and measures of model quality. We propose new\nmeasures of coverage and evaluate, in a series of experiments, different types\nof topic models on two distinct text domains for which interest for topic\ndiscovery exists. The experiments include evaluation of model quality, analysis\nof coverage of distinct topic categories, and the analysis of the relationship\nbetween coverage and other methods of topic model evaluation. The paper\ncontributes a new supervised measure of coverage, and the first unsupervised\nmeasure of coverage. The supervised measure achieves topic matching accuracy\nclose to human agreement. The unsupervised measure correlates highly with the\nsupervised one (Spearman's $\\rho \\geq 0.95$). Other contributions include\ninsights into both topic models and different methods of model evaluation, and\nthe datasets and code for facilitating future research on topic coverage.", "published": "2020-12-11 12:08:27", "link": "http://arxiv.org/abs/2012.06274v3", "categories": ["cs.IR", "cs.CL", "cs.LG", "H.3.3; I.5.4; I.2.7"], "primary_category": "cs.IR"}
{"title": "Comprehension and Knowledge", "abstract": "The ability of an agent to comprehend a sentence is tightly connected to the\nagent's prior experiences and background knowledge. The paper suggests to\ninterpret comprehension as a modality and proposes a complete bimodal logical\nsystem that describes an interplay between comprehension and knowledge\nmodalities.", "published": "2020-12-11 18:42:08", "link": "http://arxiv.org/abs/2012.06561v2", "categories": ["cs.AI", "cs.CL", "cs.LO"], "primary_category": "cs.AI"}
{"title": "DeCoAR 2.0: Deep Contextualized Acoustic Representations with Vector\n  Quantization", "abstract": "Recent success in speech representation learning enables a new way to\nleverage unlabeled data to train speech recognition model. In speech\nrepresentation learning, a large amount of unlabeled data is used in a\nself-supervised manner to learn a feature representation. Then a smaller amount\nof labeled data is used to train a downstream ASR system using the new feature\nrepresentations. Based on our previous work DeCoAR and inspirations from other\nspeech representation learning, we propose DeCoAR 2.0, a Deep Contextualized\nAcoustic Representation with vector quantization. We introduce several\nmodifications over the DeCoAR: first, we use Transformers in encoding module\ninstead of LSTMs; second, we introduce a vector quantization layer between\nencoder and reconstruction modules; third, we propose an objective that\ncombines the reconstructive loss with vector quantization diversity loss to\ntrain speech representations. Our experiments show consistent improvements over\nother speech representations in different data-sparse scenarios. Without\nfine-tuning, a light-weight ASR model trained on 10 hours of LibriSpeech\nlabeled data with DeCoAR 2.0 features outperforms the model trained on the full\n960-hour dataset with filterbank features.", "published": "2020-12-11 22:07:23", "link": "http://arxiv.org/abs/2012.06659v1", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Blind Monaural Source Separation on Heart and Lung Sounds Based on\n  Periodic-Coded Deep Autoencoder", "abstract": "Auscultation is the most efficient way to diagnose cardiovascular and\nrespiratory diseases. To reach accurate diagnoses, a device must be able to\nrecognize heart and lung sounds from various clinical situations. However, the\nrecorded chest sounds are mixed by heart and lung sounds. Thus, effectively\nseparating these two sounds is critical in the pre-processing stage. Recent\nadvances in machine learning have progressed on monaural source separations,\nbut most of the well-known techniques require paired mixed sounds and\nindividual pure sounds for model training. As the preparation of pure heart and\nlung sounds is difficult, special designs must be considered to derive\neffective heart and lung sound separation techniques. In this study, we\nproposed a novel periodicity-coded deep auto-encoder (PC-DAE) approach to\nseparate mixed heart-lung sounds in an unsupervised manner via the assumption\nof different periodicities between heart rate and respiration rate. The PC-DAE\nbenefits from deep-learning-based models by extracting representative features\nand considers the periodicity of heart and lung sounds to carry out the\nseparation. We evaluated PC-DAE on two datasets. The first one includes sounds\nfrom the Student Auscultation Manikin (SAM), and the second is prepared by\nrecording chest sounds in real-world conditions. Experimental results indicate\nthat PC-DAE outperforms several well-known separations works in terms of\nstandardized evaluation metrics. Moreover, waveforms and spectrograms\ndemonstrate the effectiveness of PC-DAE compared to existing approaches. It is\nalso confirmed that by using the proposed PC-DAE as a pre-processing stage, the\nheart sound recognition accuracies can be notably boosted. The experimental\nresults confirmed the effectiveness of PC-DAE and its potential to be used in\nclinical applications.", "published": "2020-12-11 12:13:46", "link": "http://arxiv.org/abs/2012.06275v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Iterative Geometry Calibration from Distance Estimates for Wireless\n  Acoustic Sensor Networks", "abstract": "In this paper we present an approach to geometry calibration in wireless\nacoustic sensor networks, whose nodes are assumed to be equipped with a compact\nmicrophone array. The proposed approach solely works with estimates of the\ndistances between acoustic sources and the nodes that record these sources. It\nconsists of an iterative weighted least squares localization procedure, which\nis initialized by multidimensional scaling. Alongside the sensor node\nlocations, also the positions of the acoustic sources are estimated.\nFurthermore, we derive the Cramer-Rao lower bound (CRLB) for source and sensor\nposition estimation, and show by simulation that the estimator is efficient.", "published": "2020-12-11 06:03:00", "link": "http://arxiv.org/abs/2012.06142v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Acoustic Leak Detection in Water Networks", "abstract": "In this work, we present a general procedure for acoustic leak detection in\nwater networks that satisfies multiple real-world constraints such as energy\nefficiency and ease of deployment. Based on recordings from seven contact\nmicrophones attached to the water supply network of a municipal suburb, we\ntrained several shallow and deep anomaly detection models. Inspired by how\nhuman experts detect leaks using electronic sounding-sticks, we use these\nmodels to repeatedly listen for leaks over a predefined decision horizon. This\nway we avoid constant monitoring of the system. While we found the detection of\nleaks in close proximity to be a trivial task for almost all models, neural\nnetwork based approaches achieve better results at the detection of distant\nleaks.", "published": "2020-12-11 12:24:15", "link": "http://arxiv.org/abs/2012.06280v2", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Analysis of Feature Representations for Anomalous Sound Detection", "abstract": "In this work, we thoroughly evaluate the efficacy of pretrained neural\nnetworks as feature extractors for anomalous sound detection. In doing so, we\nleverage the knowledge that is contained in these neural networks to extract\nsemantically rich features (representations) that serve as input to a Gaussian\nMixture Model which is used as a density estimator to model normality. We\ncompare feature extractors that were trained on data from various domains,\nnamely: images, environmental sounds and music. Our approach is evaluated on\nrecordings from factory machinery such as valves, pumps, sliders and fans. All\nof the evaluated representations outperform the autoencoder baseline with music\nbased representations yielding the best performance in most cases. These\nresults challenge the common assumption that closely matching the domain of the\nfeature extractor and the downstream task results in better downstream task\nperformance.", "published": "2020-12-11 12:31:50", "link": "http://arxiv.org/abs/2012.06282v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
