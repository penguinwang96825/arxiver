{"title": "A Dictionary-based Approach to Racism Detection in Dutch Social Media", "abstract": "We present a dictionary-based approach to racism detection in Dutch social\nmedia comments, which were retrieved from two public Belgian social media sites\nlikely to attract racist reactions. These comments were labeled as racist or\nnon-racist by multiple annotators. For our approach, three discourse\ndictionaries were created: first, we created a dictionary by retrieving\npossibly racist and more neutral terms from the training data, and then\naugmenting these with more general words to remove some bias. A second\ndictionary was created through automatic expansion using a \\texttt{word2vec}\nmodel trained on a large corpus of general Dutch text. Finally, a third\ndictionary was created by manually filtering out incorrect expansions. We\ntrained multiple Support Vector Machines, using the distribution of words over\nthe different categories in the dictionaries as features. The best-performing\nmodel used the manually cleaned dictionary and obtained an F-score of 0.46 for\nthe racist class on a test set consisting of unseen Dutch comments, retrieved\nfrom the same sites used for the training set. The automated expansion of the\ndictionary only slightly boosted the model's performance, and this increase in\nperformance was not statistically significant. The fact that the coverage of\nthe expanded dictionaries did increase indicates that the words that were\nautomatically added did occur in the corpus, but were not able to meaningfully\nimpact performance. The dictionaries, code, and the procedure for requesting\nthe corpus are available at: https://github.com/clips/hades", "published": "2016-08-31 06:28:28", "link": "http://arxiv.org/abs/1608.08738v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Demographic Dialectal Variation in Social Media: A Case Study of\n  African-American English", "abstract": "Though dialectal language is increasingly abundant on social media, few\nresources exist for developing NLP tools to handle such language. We conduct a\ncase study of dialectal language in online conversational text by investigating\nAfrican-American English (AAE) on Twitter. We propose a distantly supervised\nmodel to identify AAE-like language from demographics associated with\ngeo-located messages, and we verify that this language follows well-known AAE\nlinguistic phenomena. In addition, we analyze the quality of existing language\nidentification and dependency parsing tools on AAE-like text, demonstrating\nthat they perform poorly on such text compared to text associated with white\nspeakers. We also provide an ensemble classifier for language identification\nwhich eliminates this disparity and release a new corpus of tweets containing\nAAE-like language.", "published": "2016-08-31 14:12:01", "link": "http://arxiv.org/abs/1608.08868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring Machine Intelligence Through Visual Question Answering", "abstract": "As machines have become more intelligent, there has been a renewed interest\nin methods for measuring their intelligence. A common approach is to propose\ntasks for which a human excels, but one which machines find difficult. However,\nan ideal task should also be easy to evaluate and not be easily gameable. We\nbegin with a case study exploring the recently popular task of image captioning\nand its limitations as a task for measuring machine intelligence. An\nalternative and more promising task is Visual Question Answering that tests a\nmachine's ability to reason about language and vision. We describe a dataset\nunprecedented in size created for the task that contains over 760,000 human\ngenerated questions about images. Using around 10 million human generated\nanswers, machines may be easily evaluated.", "published": "2016-08-31 02:56:00", "link": "http://arxiv.org/abs/1608.08716v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Hash2Vec, Feature Hashing for Word Embeddings", "abstract": "In this paper we propose the application of feature hashing to create word\nembeddings for natural language processing. Feature hashing has been used\nsuccessfully to create document vectors in related tasks like document\nclassification. In this work we show that feature hashing can be applied to\nobtain word embeddings in linear time with the size of the data. The results\nshow that this algorithm, that does not need training, is able to capture the\nsemantic meaning of words. We compare the results against GloVe showing that\nthey are similar. As far as we know this is the first application of feature\nhashing to the word embeddings problem and the results indicate this is a\nscalable technique with practical results for NLP applications.", "published": "2016-08-31 17:01:09", "link": "http://arxiv.org/abs/1608.08940v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamic Allocation of Crowd Contributions for Sentiment Analysis during\n  the 2016 U.S. Presidential Election", "abstract": "Opinions about the 2016 U.S. Presidential Candidates have been expressed in\nmillions of tweets that are challenging to analyze automatically. Crowdsourcing\nthe analysis of political tweets effectively is also difficult, due to large\ninter-rater disagreements when sarcasm is involved. Each tweet is typically\nanalyzed by a fixed number of workers and majority voting. We here propose a\ncrowdsourcing framework that instead uses a dynamic allocation of the number of\nworkers. We explore two dynamic-allocation methods: (1) The number of workers\nqueried to label a tweet is computed offline based on the predicted difficulty\nof discerning the sentiment of a particular tweet. (2) The number of crowd\nworkers is determined online, during an iterative crowd sourcing process, based\non inter-rater agreements between labels.We applied our approach to 1,000\ntwitter messages about the four U.S. presidential candidates Clinton, Cruz,\nSanders, and Trump, collected during February 2016. We implemented the two\nproposed methods using decision trees that allocate more crowd efforts to\ntweets predicted to be sarcastic. We show that our framework outperforms the\ntraditional static allocation scheme. It collects opinion labels from the crowd\nat a much lower cost while maintaining labeling accuracy.", "published": "2016-08-31 17:20:09", "link": "http://arxiv.org/abs/1608.08953v2", "categories": ["cs.HC", "cs.CL", "cs.SI"], "primary_category": "cs.HC"}
{"title": "Towards Transparent AI Systems: Interpreting Visual Question Answering\n  Models", "abstract": "Deep neural networks have shown striking progress and obtained\nstate-of-the-art results in many AI research fields in the recent years.\nHowever, it is often unsatisfying to not know why they predict what they do. In\nthis paper, we address the problem of interpreting Visual Question Answering\n(VQA) models. Specifically, we are interested in finding what part of the input\n(pixels in images or words in questions) the VQA model focuses on while\nanswering the question. To tackle this problem, we use two visualization\ntechniques -- guided backpropagation and occlusion -- to find important words\nin the question and important regions in the image. We then present qualitative\nand quantitative analyses of these importance maps. We found that even without\nexplicit attention mechanisms, VQA models may sometimes be implicitly attending\nto relevant regions in the image, and often to appropriate words in the\nquestion.", "published": "2016-08-31 18:11:29", "link": "http://arxiv.org/abs/1608.08974v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Convolutional Neural Networks for Text Categorization: Shallow\n  Word-level vs. Deep Character-level", "abstract": "This paper reports the performances of shallow word-level convolutional\nneural networks (CNN), our earlier work (2015), on the eight datasets with\nrelatively large training data that were used for testing the very deep\ncharacter-level CNN in Conneau et al. (2016). Our findings are as follows. The\nshallow word-level CNNs achieve better error rates than the error rates\nreported in Conneau et al., though the results should be interpreted with some\nconsideration due to the unique pre-processing of Conneau et al. The shallow\nword-level CNN uses more parameters and therefore requires more storage than\nthe deep character-level CNN; however, the shallow word-level CNN computes much\nfaster.", "published": "2016-08-31 15:43:27", "link": "http://arxiv.org/abs/1609.00718v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "The Generalized Smallest Grammar Problem", "abstract": "The Smallest Grammar Problem -- the problem of finding the smallest\ncontext-free grammar that generates exactly one given sequence -- has never\nbeen successfully applied to grammatical inference. We investigate the reasons\nand propose an extended formulation that seeks to minimize non-recursive\ngrammars, instead of straight-line programs. In addition, we provide very\nefficient algorithms that approximate the minimization problem of this class of\ngrammars. Our empirical evaluation shows that we are able to find smaller\nmodels than the current best approximations to the Smallest Grammar Problem on\nstandard benchmarks, and that the inferred rules capture much better the\nsyntactic structure of natural language.", "published": "2016-08-31 16:23:07", "link": "http://arxiv.org/abs/1608.08927v1", "categories": ["cs.CL", "cs.AI", "cs.DS", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
