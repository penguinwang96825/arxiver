{"title": "A neural interlingua for multilingual machine translation", "abstract": "We incorporate an explicit neural interlingua into a multilingual\nencoder-decoder neural machine translation (NMT) architecture. We demonstrate\nthat our model learns a language-independent representation by performing\ndirect zero-shot translation (without using pivot translation), and by using\nthe source sentence embeddings to create an English Yelp review classifier\nthat, through the mediation of the neural interlingua, can also classify French\nand German reviews. Furthermore, we show that, despite using a smaller number\nof parameters than a pairwise collection of bilingual NMT models, our approach\nproduces comparable BLEU scores for each language pair in WMT15.", "published": "2018-04-23 00:21:37", "link": "http://arxiv.org/abs/1804.08198v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistically-Informed Self-Attention for Semantic Role Labeling", "abstract": "Current state-of-the-art semantic role labeling (SRL) uses a deep neural\nnetwork with no explicit linguistic features. However, prior work has shown\nthat gold syntax trees can dramatically improve SRL decoding, suggesting the\npossibility of increased accuracy from explicit modeling of syntax. In this\nwork, we present linguistically-informed self-attention (LISA): a neural\nnetwork model that combines multi-head self-attention with multi-task learning\nacross dependency parsing, part-of-speech tagging, predicate detection and SRL.\nUnlike previous models which require significant pre-processing to prepare\nlinguistic features, LISA can incorporate syntax using merely raw tokens as\ninput, encoding the sequence only once to simultaneously perform parsing,\npredicate detection and role labeling for all predicates. Syntax is\nincorporated by training one attention head to attend to syntactic parents for\neach token. Moreover, if a high-quality syntactic parse is already available,\nit can be beneficially injected at test time without re-training our SRL model.\nIn experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art\nperformance for a model using predicted predicates and standard word\nembeddings, attaining 2.5 F1 absolute higher than the previous state-of-the-art\non newswire and more than 3.5 F1 on out-of-domain data, nearly 10% reduction in\nerror. On ConLL-2012 English SRL we also show an improvement of more than 2.5\nF1. LISA also out-performs the state-of-the-art with contextually-encoded\n(ELMo) word representations, by nearly 1.0 F1 on news and more than 2.0 F1 on\nout-of-domain text.", "published": "2018-04-23 00:21:49", "link": "http://arxiv.org/abs/1804.08199v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Spell Once, Summon Anywhere: A Two-Level Open-Vocabulary Language Model", "abstract": "We show how the spellings of known words can help us deal with unknown words\nin open-vocabulary NLP tasks. The method we propose can be used to extend any\nclosed-vocabulary generative model, but in this paper we specifically consider\nthe case of neural language modeling. Our Bayesian generative story combines a\nstandard RNN language model (generating the word tokens in each sentence) with\nan RNN-based spelling model (generating the letters in each word type). These\ntwo RNNs respectively capture sentence structure and word structure, and are\nkept separate as in linguistics. By invoking the second RNN to generate\nspellings for novel words in context, we obtain an open-vocabulary language\nmodel. For known words, embeddings are naturally inferred by combining evidence\nfrom type spelling and token context. Comparing to baselines (including a novel\nstrong baseline), we beat previous work and establish state-of-the-art results\non multiple datasets.", "published": "2018-04-23 00:56:23", "link": "http://arxiv.org/abs/1804.08205v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Collecting Diverse Natural Language Inference Problems for Sentence\n  Representation Evaluation", "abstract": "We present a large-scale collection of diverse natural language inference\n(NLI) datasets that help provide insight into how well a sentence\nrepresentation captures distinct types of reasoning. The collection results\nfrom recasting 13 existing datasets from 7 semantic phenomena into a common NLI\nstructure, resulting in over half a million labeled context-hypothesis pairs in\ntotal. We refer to our collection as the DNC: Diverse Natural Language\nInference Collection. The DNC is available online at https://www.decomp.net,\nand will grow over time as additional resources are recast and added from novel\nsources.", "published": "2018-04-23 01:03:46", "link": "http://arxiv.org/abs/1804.08207v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End\n  Task-Oriented Dialog Systems", "abstract": "End-to-end task-oriented dialog systems usually suffer from the challenge of\nincorporating knowledge bases. In this paper, we propose a novel yet simple\nend-to-end differentiable model called memory-to-sequence (Mem2Seq) to address\nthis issue. Mem2Seq is the first neural generative model that combines the\nmulti-hop attention over memories with the idea of pointer network. We\nempirically show how Mem2Seq controls each generation step, and how its\nmulti-hop attention mechanism helps in learning correlations between memories.\nIn addition, our model is quite general without complicated task-specific\ndesigns. As a result, we show that Mem2Seq can be trained faster and attain the\nstate-of-the-art performance on three different task-oriented dialog datasets.", "published": "2018-04-23 01:46:13", "link": "http://arxiv.org/abs/1804.08217v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parsing Tweets into Universal Dependencies", "abstract": "We study the problem of analyzing tweets with Universal Dependencies. We\nextend the UD guidelines to cover special constructions in tweets that affect\ntokenization, part-of-speech tagging, and labeled dependencies. Using the\nextended guidelines, we create a new tweet treebank for English (Tweebank v2)\nthat is four times larger than the (unlabeled) Tweebank v1 introduced by Kong\net al. (2014). We characterize the disagreements between our annotators and\nshow that it is challenging to deliver consistent annotation due to ambiguity\nin understanding and explaining tweets. Nonetheless, using the new treebank, we\nbuild a pipeline system to parse raw tweets into UD. To overcome annotation\nnoise without sacrificing computational efficiency, we propose a new method to\ndistill an ensemble of 20 transition-based parsers into a single one. Our\nparser achieves an improvement of 2.2 in LAS over the un-ensembled baseline and\noutperforms parsers that are state-of-the-art on other treebanks in both\naccuracy and speed.", "published": "2018-04-23 02:38:20", "link": "http://arxiv.org/abs/1804.08228v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Diachronic Stability of Irregularity in Inflectional Morphology", "abstract": "Many languages' inflectional morphological systems are replete with\nirregulars, i.e., words that do not seem to follow standard inflectional rules.\nIn this work, we quantitatively investigate the conditions under which\nirregulars can survive in a language over the course of time. Using recurrent\nneural networks to simulate language learners, we test the diachronic relation\nbetween frequency of words and their irregularity.", "published": "2018-04-23 07:01:52", "link": "http://arxiv.org/abs/1804.08262v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NLITrans at SemEval-2018 Task 12: Transfer of Semantic Knowledge for\n  Argument Comprehension", "abstract": "The Argument Reasoning Comprehension Task requires significant language\nunderstanding and complex reasoning over world knowledge. We focus on transfer\nof a sentence encoder to bootstrap more complicated models given the small size\nof the dataset. Our best model uses a pre-trained BiLSTM to encode input\nsentences, learns task-specific features for the argument and warrants, then\nperforms independent argument-warrant matching. This model achieves mean test\nset accuracy of 64.43%. Encoder transfer yields a significant gain to our best\nmodel over random initialization. Independent warrant matching effectively\ndoubles the size of the dataset and provides additional regularization. We\ndemonstrate that regularization comes from ignoring statistical correlations\nbetween warrant features and position. We also report an experiment with our\nbest model that only matches warrants to reasons, ignoring claims. Relatively\nlow performance degradation suggests that our model is not necessarily learning\nthe intended task.", "published": "2018-04-23 07:21:21", "link": "http://arxiv.org/abs/1804.08266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PlusEmo2Vec at SemEval-2018 Task 1: Exploiting emotion knowledge from\n  emoji and #hashtags", "abstract": "This paper describes our system that has been submitted to SemEval-2018 Task\n1: Affect in Tweets (AIT) to solve five subtasks. We focus on modeling both\nsentence and word level representations of emotion inside texts through large\ndistantly labeled corpora with emojis and hashtags. We transfer the emotional\nknowledge by exploiting neural network models as feature extractors and use\nthese representations for traditional machine learning models such as support\nvector regression (SVR) and logistic regression to solve the competition tasks.\nOur system is placed among the Top3 for all subtasks we participated.", "published": "2018-04-23 08:30:46", "link": "http://arxiv.org/abs/1804.08280v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploiting Semantics in Neural Machine Translation with Graph\n  Convolutional Networks", "abstract": "Semantic representations have long been argued as potentially useful for\nenforcing meaning preservation and improving generalization performance of\nmachine translation methods. In this work, we are the first to incorporate\ninformation about predicate-argument structure of source sentences (namely,\nsemantic-role representations) into neural machine translation. We use Graph\nConvolutional Networks (GCNs) to inject a semantic bias into sentence encoders\nand achieve improvements in BLEU scores over the linguistic-agnostic and\nsyntax-aware versions on the English--German language pair.", "published": "2018-04-23 09:54:29", "link": "http://arxiv.org/abs/1804.08313v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Parsing with Syntax- and Table-Aware SQL Generation", "abstract": "We present a generative model to map natural language questions into SQL\nqueries. Existing neural network based approaches typically generate a SQL\nquery word-by-word, however, a large portion of the generated results are\nincorrect or not executable due to the mismatch between question words and\ntable contents. Our approach addresses this problem by considering the\nstructure of table and the syntax of SQL language. The quality of the generated\nSQL query is significantly improved through (1) learning to replicate content\nfrom column names, cells or SQL keywords; and (2) improving the generation of\nWHERE clause by leveraging the column-cell relation. Experiments are conducted\non WikiSQL, a recently released dataset with the largest question-SQL pairs.\nOur approach significantly improves the state-of-the-art execution accuracy\nfrom 69.0% to 74.4%.", "published": "2018-04-23 11:18:47", "link": "http://arxiv.org/abs/1804.08338v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mixing Context Granularities for Improved Entity Linking on Question\n  Answering Data across Entity Categories", "abstract": "The first stage of every knowledge base question answering approach is to\nlink entities in the input question. We investigate entity linking in the\ncontext of a question answering task and present a jointly optimized neural\narchitecture for entity mention detection and entity disambiguation that models\nthe surrounding context on different levels of granularity. We use the Wikidata\nknowledge base and available question answering datasets to create benchmarks\nfor entity linking on question answering data. Our approach outperforms the\nprevious state-of-the-art system on this data, resulting in an average 8%\nimprovement of the final score. We further demonstrate that our model delivers\na strong performance across different entity categories.", "published": "2018-04-23 14:22:21", "link": "http://arxiv.org/abs/1804.08460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ASR Performance Prediction on Unseen Broadcast Programs using\n  Convolutional Neural Networks", "abstract": "In this paper, we address a relatively new task: prediction of ASR\nperformance on unseen broadcast programs. We first propose an heterogenous\nFrench corpus dedicated to this task. Two prediction approaches are compared: a\nstate-of-the-art performance prediction based on regression (engineered\nfeatures) and a new strategy based on convolutional neural networks (learnt\nfeatures). We particularly focus on the combination of both textual (ASR\ntranscription) and signal inputs. While the joint use of textual and signal\nfeatures did not work for the regression baseline, the combination of inputs\nfor CNNs leads to the best WER prediction performance. We also show that our\nCNN prediction remarkably predicts the WER distribution on a collection of\nspeech recordings.", "published": "2018-04-23 14:42:12", "link": "http://arxiv.org/abs/1804.08477v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Aspect Extraction Approaches to Generate Review Summaries and User\n  Profiles", "abstract": "Reviews of products or services on Internet marketplace websites contain a\nrich amount of information. Users often wish to survey reviews or review\nsnippets from the perspective of a certain aspect, which has resulted in a\nlarge body of work on aspect identification and extraction from such corpora.\nIn this work, we evaluate a newly-proposed neural model for aspect extraction\non two practical tasks. The first is to extract canonical sentences of various\naspects from reviews, and is judged by human evaluators against alternatives. A\n$k$-means baseline does remarkably well in this setting. The second experiment\nfocuses on the suitability of the recovered aspect distributions to represent\nusers by the reviews they have written. Through a set of review reranking\nexperiments, we find that aspect-based profiles can largely capture notions of\nuser preferences, by showing that divergent users generate markedly different\nreview rankings.", "published": "2018-04-23 18:52:50", "link": "http://arxiv.org/abs/1804.08666v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data-Driven Investigative Journalism For Connectas Dataset", "abstract": "The following paper explores the possibility of using Machine Learning\nalgorithms to detect the cases of corruption and malpractice by governments.\nThe dataset used by the authors contains information about several government\ncontracts in Colombia from year 2007 to 2012. The authors begin with exploring\nand cleaning the data, followed by which they perform feature engineering\nbefore finally implementing Machine Learning models to detect anomalies in the\ngiven dataset.", "published": "2018-04-23 19:15:45", "link": "http://arxiv.org/abs/1804.08675v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Eye Movement Data Be Used As Ground Truth For Word Embeddings\n  Evaluation?", "abstract": "In recent years a certain success in the task of modeling lexical semantics\nwas obtained with distributional semantic models. Nevertheless, the scientific\ncommunity is still unaware what is the most reliable evaluation method for\nthese models. Some researchers argue that the only possible gold standard could\nbe obtained from neuro-cognitive resources that store information about human\ncognition. One of such resources is eye movement data on silent reading. The\ngoal of this work is to test the hypothesis of whether such data could be used\nto evaluate distributional semantic models on different languages. We propose\nexperiments with English and Russian eye movement datasets (Provo Corpus, GECO\nand Russian Sentence Corpus), word vectors (Skip-Gram models trained on\nnational corpora and Web corpora) and word similarity datasets of Russian and\nEnglish assessed by humans in order to find the existence of correlation\nbetween embeddings and eye movement data and test the hypothesis that this\ncorrelation is language independent. As a result, we found that the validity of\nthe hypothesis being tested could be questioned.", "published": "2018-04-23 21:29:30", "link": "http://arxiv.org/abs/1804.08749v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Syntactic Features of Translated Chinese", "abstract": "We present a machine learning approach to distinguish texts translated to\nChinese (by humans) from texts originally written in Chinese, with a focus on a\nwide range of syntactic features. Using Support Vector Machines (SVMs) as\nclassifier on a genre-balanced corpus in translation studies of Chinese, we\nfind that constituent parse trees and dependency triples as features without\nlexical information perform very well on the task, with an F-measure above 90%,\nclose to the results of lexical n-gram features, without the risk of learning\ntopic information rather than translation features. Thus, we claim syntactic\nfeatures alone can accurately distinguish translated from original Chinese.\nTranslated Chinese exhibits an increased use of determiners, subject position\npronouns, NP + 'de' as NP modifiers, multiple NPs or VPs conjoined by a Chinese\nspecific punctuation, among other structures. We also interpret the syntactic\nfeatures with reference to previous translation studies in Chinese,\nparticularly the usage of pronouns.", "published": "2018-04-23 21:56:11", "link": "http://arxiv.org/abs/1804.08756v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Call for Clarity in Reporting BLEU Scores", "abstract": "The field of machine translation faces an under-recognized problem because of\ninconsistency in the reporting of scores from its dominant metric. Although\npeople refer to \"the\" BLEU score, BLEU is in fact a parameterized metric whose\nvalues can vary wildly with changes to these parameters. These parameters are\noften not reported or are hard to find, and consequently, BLEU scores between\npapers cannot be directly compared. I quantify this variation, finding\ndifferences as high as 1.8 between commonly used configurations. The main\nculprit is different tokenization and normalization schemes applied to the\nreference. Pointing to the success of the parsing community, I suggest machine\ntranslation researchers settle upon the BLEU scheme used by the annual\nConference on Machine Translation (WMT), which does not allow for user-supplied\nreference processing, and provide a new tool, SacreBLEU, to facilitate this.", "published": "2018-04-23 22:54:55", "link": "http://arxiv.org/abs/1804.08771v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-based end-to-end memory networks", "abstract": "End-to-end dialog systems have become very popular because they hold the\npromise of learning directly from human to human dialog interaction. Retrieval\nand Generative methods have been explored in this area with mixed results. A\nkey element that is missing so far, is the incorporation of a-priori knowledge\nabout the task at hand. This knowledge may exist in the form of structured or\nunstructured information. As a first step towards this direction, we present a\nnovel approach, Knowledge based end-to-end memory networks (KB-memN2N), which\nallows special handling of named entities for goal-oriented dialog tasks. We\npresent results on two datasets, DSTC6 challenge dataset and dialog bAbI tasks.", "published": "2018-04-23 00:47:48", "link": "http://arxiv.org/abs/1804.08204v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bilingual Embeddings with Random Walks over Multilingual Wordnets", "abstract": "Bilingual word embeddings represent words of two languages in the same space,\nand allow to transfer knowledge from one language to the other without machine\ntranslation. The main approach is to train monolingual embeddings first and\nthen map them using bilingual dictionaries. In this work, we present a novel\nmethod to learn bilingual embeddings based on multilingual knowledge bases (KB)\nsuch as WordNet. Our method extracts bilingual information from multilingual\nwordnets via random walks and learns a joint embedding space in one go. We\nfurther reinforce cross-lingual equivalence adding bilingual con- straints in\nthe loss function of the popular skipgram model. Our experiments involve twelve\ncross-lingual word similarity and relatedness datasets in six lan- guage pairs\ncovering four languages, and show that: 1) random walks over mul- tilingual\nwordnets improve results over just using dictionaries; 2) multilingual wordnets\non their own improve over text-based systems in similarity datasets; 3) the\ngood results are consistent for large wordnets (e.g. English, Spanish), smaller\nwordnets (e.g. Basque) or loosely aligned wordnets (e.g. Italian); 4) the\ncombination of wordnets and text yields the best results, above mapping-based\napproaches. Our method can be applied to richer KBs like DBpedia or Babel- Net,\nand can be easily extended to multilingual embeddings. All software and\nresources are open source.", "published": "2018-04-23 10:02:29", "link": "http://arxiv.org/abs/1804.08316v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Analyzing and Characterizing User Intent in Information-seeking\n  Conversations", "abstract": "Understanding and characterizing how people interact in information-seeking\nconversations is crucial in developing conversational search systems. In this\npaper, we introduce a new dataset designed for this purpose and use it to\nanalyze information-seeking conversations by user intent distribution,\nco-occurrence, and flow patterns. The MSDialog dataset is a labeled dialog\ndataset of question answering (QA) interactions between information seekers and\nproviders from an online forum on Microsoft products. The dataset contains more\nthan 2,000 multi-turn QA dialogs with 10,000 utterances that are annotated with\nuser intent on the utterance level. Annotations were done using crowdsourcing.\nWith MSDialog, we find some highly recurring patterns in user intent during an\ninformation-seeking process. They could be useful for designing conversational\nsearch systems. We will make our dataset freely available to encourage\nexploration of information-seeking conversation models.", "published": "2018-04-23 22:07:28", "link": "http://arxiv.org/abs/1804.08759v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "The Future of Prosody: It's about Time", "abstract": "Prosody is usually defined in terms of the three distinct but interacting\ndomains of pitch, intensity and duration patterning, or, more generally, as\nphonological and phonetic properties of 'suprasegmentals', speech segments\nwhich are larger than consonants and vowels. Rather than taking this approach,\nthe concept of multiple time domains for prosody processing is taken up, and\nmethods of time domain analysis are discussed: annotation mining with timing\ndispersion measures, time tree induction, oscillator models in phonology and\nphonetics, and finally the use of the Amplitude Envelope Modulation Spectrum\n(AEMS). While frequency demodulation (in the form of pitch tracking) is a\ncentral issue in prosodic analysis, in the present context it is amplitude\nenvelope demodulation and frequency zones in the long time-domain spectra of\nthe demodulated envelope which are focused. A generalised view is taken of\noscillation as iteration in abstract prosodic models and as modulation and\ndemodulation of a variety of rhythms in the speech signal.", "published": "2018-04-23 20:54:43", "link": "http://arxiv.org/abs/1804.09543v4", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "PeRView: A Framework for Personalized Review Selection Using\n  Micro-Reviews", "abstract": "In the contemporary era, social media has its influence on people in making\ndecisions. The proliferation of online reviews with diversified and verbose\ncontent often causes problems inaccurate decision making. Since online reviews\nhave an impact on people of all walks of life while taking decisions, choosing\nappropriate reviews based on the podsolization consisting is very important\nsince it relies on using such micro-reviews consistency to evaluate the review\nset section. Micro-reviews are very concise and directly talk about product or\nservice instead of having unnecessary verbose content. Thus, micro-reviews can\nhelp in choosing reviews based on their personalized consistency that is\nrelated to directly or indirectly to the main profile of the reviews.\nPersonalized reviews selection that is highly relevant with high personalized\ncoverage in terms of matching with micro-reviews is the main problem that is\nconsidered in this paper. Furthermore, personalization with user preferences\nwhile making review selection is also considered based on the personalized\nusers' profile. Towards this end, we proposed a framework known as PeRView for\npersonalized review selection using micro-reviews based on the proposed\nevaluation metric approach which considering two main factors (personalized\nmatching score and subset size). Personalized Review Selection Algorithm (PRSA)\nis proposed which makes use of multiple similarity measures merged to have\nhighly efficient personalized reviews matching function for selection. The\nexperimental results based on using reviews dataset which is collected from\nYELP.COM while micro-reviews dataset is obtained from Foursqure.COM. show that\nthe personalized reviews selection is a very empirical case of study.", "published": "2018-04-23 03:07:45", "link": "http://arxiv.org/abs/1804.08234v1", "categories": ["cs.IR", "cs.CL", "cs.SI"], "primary_category": "cs.IR"}
{"title": "Clinical Assistant Diagnosis for Electronic Medical Record Based on\n  Convolutional Neural Network", "abstract": "Automatically extracting useful information from electronic medical records\nalong with conducting disease diagnoses is a promising task for both clinical\ndecision support(CDS) and neural language processing(NLP). Most of the existing\nsystems are based on artificially constructed knowledge bases, and then\nauxiliary diagnosis is done by rule matching. In this study, we present a\nclinical intelligent decision approach based on Convolutional Neural\nNetworks(CNN), which can automatically extract high-level semantic information\nof electronic medical records and then perform automatic diagnosis without\nartificial construction of rules or knowledge bases. We use collected 18,590\ncopies of the real-world clinical electronic medical records to train and test\nthe proposed model. Experimental results show that the proposed model can\nachieve 98.67\\% accuracy and 96.02\\% recall, which strongly supports that using\nconvolutional neural network to automatically learn high-level semantic\nfeatures of electronic medical records and then conduct assist diagnosis is\nfeasible and effective.", "published": "2018-04-23 06:52:13", "link": "http://arxiv.org/abs/1804.08261v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Spoofing Benchmark for the 2018 Voice Conversion Challenge: Leveraging\n  from Spoofing Countermeasures for Speech Artifact Assessment", "abstract": "Voice conversion (VC) aims at conversion of speaker characteristic without\naltering content. Due to training data limitations and modeling imperfections,\nit is difficult to achieve believable speaker mimicry without introducing\nprocessing artifacts; performance assessment of VC, therefore, usually involves\nboth speaker similarity and quality evaluation by a human panel. As a\ntime-consuming, expensive, and non-reproducible process, it hinders rapid\nprototyping of new VC technology. We address artifact assessment using an\nalternative, objective approach leveraging from prior work on spoofing\ncountermeasures (CMs) for automatic speaker verification. Therein, CMs are used\nfor rejecting `fake' inputs such as replayed, synthetic or converted speech but\ntheir potential for automatic speech artifact assessment remains unknown. This\nstudy serves to fill that gap. As a supplement to subjective results for the\n2018 Voice Conversion Challenge (VCC'18) data, we configure a standard\nconstant-Q cepstral coefficient CM to quantify the extent of processing\nartifacts. Equal error rate (EER) of the CM, a confusability index of VC\nsamples with real human speech, serves as our artifact measure. Two clusters of\nVCC'18 entries are identified: low-quality ones with detectable artifacts (low\nEERs), and higher quality ones with less artifacts. None of the VCC'18 systems,\nhowever, is perfect: all EERs are < 30 % (the `ideal' value would be 50 %). Our\npreliminary findings suggest potential of CMs outside of their original\napplication, as a supplemental optimization and benchmarking tool to enhance VC\ntechnology.", "published": "2018-04-23 13:54:47", "link": "http://arxiv.org/abs/1804.08438v2", "categories": ["eess.AS", "cs.CL", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Attention Based Natural Language Grounding by Navigating Virtual\n  Environment", "abstract": "In this work, we focus on the problem of grounding language by training an\nagent to follow a set of natural language instructions and navigate to a target\nobject in an environment. The agent receives visual information through raw\npixels and a natural language instruction telling what task needs to be\nachieved and is trained in an end-to-end way. We develop an attention mechanism\nfor multi-modal fusion of visual and textual modalities that allows the agent\nto learn to complete the task and achieve language grounding. Our experimental\nresults show that our attention mechanism outperforms the existing multi-modal\nfusion mechanisms proposed for both 2D and 3D environments in order to solve\nthe above-mentioned task in terms of both speed and success rate. We show that\nthe learnt textual representations are semantically meaningful as they follow\nvector arithmetic in the embedding space. The effectiveness of our attention\napproach over the contemporary fusion mechanisms is also highlighted from the\ntextual embeddings learnt by the different approaches. We also show that our\nmodel generalizes effectively to unseen scenarios and exhibit zero-shot\ngeneralization capabilities both in 2D and 3D environments. The code for our 2D\nenvironment as well as the models that we developed for both 2D and 3D are\navailable at https://github.com/rl-lang-grounding/rl-lang-ground.", "published": "2018-04-23 14:11:17", "link": "http://arxiv.org/abs/1804.08454v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "False Information on Web and Social Media: A Survey", "abstract": "False information can be created and spread easily through the web and social\nmedia platforms, resulting in widespread real-world impact. Characterizing how\nfalse information proliferates on social platforms and why it succeeds in\ndeceiving readers are critical to develop efficient detection algorithms and\ntools for early detection. A recent surge of research in this area has aimed to\naddress the key issues using methods based on feature engineering, graph\nmining, and information modeling. Majority of the research has primarily\nfocused on two broad categories of false information: opinion-based (e.g., fake\nreviews), and fact-based (e.g., false news and hoaxes). Therefore, in this\nwork, we present a comprehensive survey spanning diverse aspects of false\ninformation, namely (i) the actors involved in spreading false information,\n(ii) rationale behind successfully deceiving readers, (iii) quantifying the\nimpact of false information, (iv) measuring its characteristics across\ndifferent dimensions, and finally, (iv) algorithms developed to detect false\ninformation. In doing so, we create a unified framework to describe these\nrecent methods and highlight a number of important directions for future\nresearch.", "published": "2018-04-23 16:52:49", "link": "http://arxiv.org/abs/1804.08559v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.DL"], "primary_category": "cs.SI"}
{"title": "Towards an Unsupervised Entrainment Distance in Conversational Speech\n  using Deep Neural Networks", "abstract": "Entrainment is a known adaptation mechanism that causes interaction\nparticipants to adapt or synchronize their acoustic characteristics.\nUnderstanding how interlocutors tend to adapt to each other's speaking style\nthrough entrainment involves measuring a range of acoustic features and\ncomparing those via multiple signal comparison methods. In this work, we\npresent a turn-level distance measure obtained in an unsupervised manner using\na Deep Neural Network (DNN) model, which we call Neural Entrainment Distance\n(NED). This metric establishes a framework that learns an embedding from the\npopulation-wide entrainment in an unlabeled training corpus. We use the\nframework for a set of acoustic features and validate the measure\nexperimentally by showing its efficacy in distinguishing real conversations\nfrom fake ones created by randomly shuffling speaker turns. Moreover, we show\nreal world evidence of the validity of the proposed measure. We find that high\nvalue of NED is associated with high ratings of emotional bond in suicide\nassessment interviews, which is consistent with prior studies.", "published": "2018-04-23 23:45:30", "link": "http://arxiv.org/abs/1804.08782v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "QANet: Combining Local Convolution with Global Self-Attention for\n  Reading Comprehension", "abstract": "Current end-to-end machine reading and question answering (Q\\&A) models are\nprimarily based on recurrent neural networks (RNNs) with attention. Despite\ntheir success, these models are often slow for both training and inference due\nto the sequential nature of RNNs. We propose a new Q\\&A architecture called\nQANet, which does not require recurrent networks: Its encoder consists\nexclusively of convolution and self-attention, where convolution models local\ninteractions and self-attention models global interactions. On the SQuAD\ndataset, our model is 3x to 13x faster in training and 4x to 9x faster in\ninference, while achieving equivalent accuracy to recurrent models. The\nspeed-up gain allows us to train the model with much more data. We hence\ncombine our model with data generated by backtranslation from a neural machine\ntranslation model. On the SQuAD dataset, our single model, trained with\naugmented data, achieves 84.6 F1 score on the test set, which is significantly\nbetter than the best published F1 score of 81.8.", "published": "2018-04-23 11:33:43", "link": "http://arxiv.org/abs/1804.09541v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Object Counts! Bringing Explicit Detections Back into Image Captioning", "abstract": "The use of explicit object detectors as an intermediate step to image\ncaptioning - which used to constitute an essential stage in early work - is\noften bypassed in the currently dominant end-to-end approaches, where the\nlanguage model is conditioned directly on a mid-level image embedding. We argue\nthat explicit detections provide rich semantic information, and can thus be\nused as an interpretable representation to better understand why end-to-end\nimage captioning systems work well. We provide an in-depth analysis of\nend-to-end image captioning by exploring a variety of cues that can be derived\nfrom such object detections. Our study reveals that end-to-end image captioning\nsystems rely on matching image representations to generate captions, and that\nencoding the frequency, size and position of objects are complementary and all\nplay a role in forming a good image representation. It also reveals that\ndifferent object categories contribute in different ways towards image\ncaptioning.", "published": "2018-04-23 14:51:46", "link": "http://arxiv.org/abs/1805.00314v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "An Overview of Lead and Accompaniment Separation in Music", "abstract": "Popular music is often composed of an accompaniment and a lead component, the\nlatter typically consisting of vocals. Filtering such mixtures to extract one\nor both components has many applications, such as automatic karaoke and\nremixing. This particular case of source separation yields very specific\nchallenges and opportunities, including the particular complexity of musical\nstructures, but also relevant prior knowledge coming from acoustics, musicology\nor sound engineering. Due to both its importance in applications and its\nchallenging difficulty, lead and accompaniment separation has been a popular\ntopic in signal processing for decades. In this article, we provide a\ncomprehensive review of this research topic, organizing the different\napproaches according to whether they are model-based or data-centered. For\nmodel-based methods, we organize them according to whether they concentrate on\nthe lead signal, the accompaniment, or both. For data-centered approaches, we\ndiscuss the particular difficulty of obtaining data for learning lead\nseparation systems, and then review recent approaches, notably those based on\ndeep learning. Finally, we discuss the delicate problem of evaluating the\nquality of music separation through adequate metrics and present the results of\nthe largest evaluation, to-date, of lead and accompaniment separation systems.\nIn conjunction with the above, a comprehensive list of references is provided,\nalong with relevant pointers to available implementations and repositories.", "published": "2018-04-23 09:08:03", "link": "http://arxiv.org/abs/1804.08300v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Discriminative Acoustic-Prosodic Approach for Measuring Local\n  Entrainment", "abstract": "Acoustic-prosodic entrainment describes the tendency of humans to align or\nadapt their speech acoustics to each other in conversation. This alignment of\nspoken behavior has important implications for conversational success. However,\nmodeling the subtle nature of entrainment in spoken dialogue continues to pose\na challenge. In this paper, we propose a straightforward definition for local\nentrainment in the speech domain and operationalize an algorithm based on this:\nacoustic-prosodic features that capture entrainment should be maximally\ndifferent between real conversations involving two partners and sham\nconversations generated by randomly mixing the speaking turns from the original\ntwo conversational partners. We propose an approach for measuring local\nentrainment that quantifies alignment of behavior on a turn-by-turn basis,\nprojecting the differences between interlocutors' acoustic-prosodic features\nfor a given turn onto a discriminative feature subspace that maximizes the\ndifference between real and sham conversations. We evaluate the method using\nthe derived features to drive a classifier aiming to predict an objective\nmeasure of conversational success (i.e., low versus high), on a corpus of\ntask-oriented conversations. The proposed entrainment approach achieves 72%\nclassification accuracy using a Naive Bayes classifier, outperforming three\npreviously established approaches evaluated on the same conversational corpus.", "published": "2018-04-23 18:51:36", "link": "http://arxiv.org/abs/1804.08663v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
