{"title": "Extracting Alpha from Financial Analyst Networks", "abstract": "We investigate the effectiveness of a momentum trading signal based on the\ncoverage network of financial analysts. This signal builds on the key\ninformation-brokerage role financial sell-side analysts play in modern stock\nmarkets. The baskets of stocks covered by each analyst can be used to construct\na network between firms whose edge weights represent the number of analysts\njointly covering both firms. Although the link between financial analysts\ncoverage and co-movement of firms' stock prices has been investigated in the\nliterature, little effort has been made to systematically learn the most\neffective combination of signals from firms covered jointly by analysts in\norder to benefit from any spillover effect. To fill this gap, we build a\ntrading strategy which leverages the analyst coverage network using a graph\nattention network. More specifically, our model learns to aggregate information\nfrom individual firm features and signals from neighbouring firms in a\nnode-level forecasting task. We develop a portfolio based on those predictions\nwhich we demonstrate to exhibit an annualized returns of 29.44% and a Sharpe\nratio of 4.06 substantially outperforming market baselines and existing graph\nmachine learning based frameworks. We further investigate the performance and\nrobustness of this strategy through extensive empirical analysis. Our paper\nrepresents one of the first attempts in using graph machine learning to extract\nactionable knowledge from the analyst coverage network for practical financial\napplications.", "published": "2024-10-27 21:11:59", "link": "http://arxiv.org/abs/2410.20597v1", "categories": ["q-fin.CP", "q-fin.PM"], "primary_category": "q-fin.CP"}
{"title": "FIRP: Faster LLM inference via future intermediate representation\n  prediction", "abstract": "Recent advancements in Large Language Models (LLMs) have shown remarkable\nperformance across a wide range of tasks. Despite this, the auto-regressive\nnature of LLM decoding, which generates only a single token per forward\npropagation, fails to fully exploit the parallel computational power of GPUs,\nleading to considerable latency. To address this, we introduce a novel\nspeculative decoding method named FIRP which generates multiple tokens instead\nof one at each decoding step. We achieve this by predicting the intermediate\nhidden states of future tokens (tokens have not been decoded yet) and then\nusing these pseudo hidden states to decode future tokens, specifically, these\npseudo hidden states are predicted with simple linear transformation in\nintermediate layers of LLMs. Once predicted, they participate in the\ncomputation of all the following layers, thereby assimilating richer semantic\ninformation. As the layers go deeper, the semantic gap between pseudo and real\nhidden states is narrowed and it becomes feasible to decode future tokens with\nhigh accuracy. To validate the effectiveness of FIRP, we conduct extensive\nexperiments, showing a speedup ratio of 1.9x-3x in several models and datasets,\nanalytical experiments also prove our motivations.", "published": "2024-10-27 15:53:49", "link": "http://arxiv.org/abs/2410.20488v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MatViX: Multimodal Information Extraction from Visually Rich Articles", "abstract": "Multimodal information extraction (MIE) is crucial for scientific literature,\nwhere valuable data is often spread across text, figures, and tables. In\nmaterials science, extracting structured information from research articles can\naccelerate the discovery of new materials. However, the multimodal nature and\ncomplex interconnections of scientific content present challenges for\ntraditional text-based methods. We introduce \\textsc{MatViX}, a benchmark\nconsisting of $324$ full-length research articles and $1,688$ complex\nstructured JSON files, carefully curated by domain experts. These JSON files\nare extracted from text, tables, and figures in full-length documents,\nproviding a comprehensive challenge for MIE. We introduce an evaluation method\nto assess the accuracy of curve similarity and the alignment of hierarchical\nstructures. Additionally, we benchmark vision-language models (VLMs) in a\nzero-shot manner, capable of processing long contexts and multimodal inputs,\nand show that using a specialized model (DePlot) can improve performance in\nextracting curves. Our results demonstrate significant room for improvement in\ncurrent models. Our dataset and evaluation code are\navailable\\footnote{\\url{https://matvix-bench.github.io/}}.", "published": "2024-10-27 16:13:58", "link": "http://arxiv.org/abs/2410.20494v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-correction is Not An Innate Capability in Large Language Models: A\n  Case Study of Moral Self-correction", "abstract": "Though there has been intensive attention to the self-correction capability\nof Large Language Models (LLMs), conclusions regarding its effectiveness remain\nvaried. In this paper, we investigate a fundamental question: is moral\nself-correction an innate capability in LLMs? To explore this, we conduct (1) a\nmechanistic analysis of how key components of self-correction, such as\nChain-of-Thought (CoT) reasoning and external feedback, interact to enable\nmoral self-correction; and (2) a behavioral analysis of LLMs' ability to\ndistinguish between desired and undesired outputs, introducing a\nself-distinguish framework. Our mechanistic analysis reveals that LLMs struggle\nto effectively leverage helpful feedback, and conflicts can arise between\nfeedback and CoT reasoning. These limitations suggest that LLMs fail to\nidentify useful contextual information, instead prioritizing their own internal\nknowledge. Additionally, our behavioral analysis indicates that LLMs struggle\nto differentiate among their own outputs. Based on these empirical findings\nacross two analytical dimensions, mechanism and behavior, we argue that moral\nself-correction is not an innate capability of LLMs.", "published": "2024-10-27 16:52:21", "link": "http://arxiv.org/abs/2410.20513v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Response not Preference: A Stackelberg Approach for LLM\n  Detoxification using Non-parallel Data", "abstract": "Text detoxification, a variant of style transfer tasks, finds useful\napplications in online social media. This work presents a fine-tuning method\nthat only uses non-parallel data to turn large language models (LLM) into a\ndetoxification rewritter. We model the fine-tuning process as a Stackelberg\ngame between an LLM (leader) and a toxicity screener (follower), which is a\nbinary style classifier (toxic or non-toxic). The LLM aims to align its\npreference according to the screener and generate paraphases passing the\nscreening. The primary challenge of non-parallel data fine-tuning is incomplete\npreference. In the case of unsuccessful paraphrases, the classifier cannot\nestablish a preference between the input and paraphrase, as they belong to the\nsame toxic style. Hence, preference-alignment fine-tuning methods, such as\ndirect preference optimization (DPO), no longer apply. To address the challenge\nof incomplete preference, we propose Stackelberg response optimization (SRO),\nadapted from DPO, to enable the LLM to learn from the follower's response. The\ngist is that SRO decreases the likelihood of generating the paraphrase if it\nfails the follower's screening while performing DPO on the pair of the toxic\ninput and its paraphrase when the latter passes the screening. Experiments\nindicate that the SRO-fine-tunned LLM achieves satisfying performance\ncomparable to state-of-the-art models regarding style accuracy, content\nsimilarity, and fluency. The overall detoxification performance surpasses other\ncomputing methods and matches the human reference. Additional empirical\nevidence suggests that SRO is sensitive to the screener's feedback, and a\nslight perturbation leads to a significant performance drop. We release the\ncode and LLM models at \\url{https://github.com/XXXinhong/Detoxification_LLM}.", "published": "2024-10-27 00:39:54", "link": "http://arxiv.org/abs/2410.20298v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Accelerating Direct Preference Optimization with Prefix Sharing", "abstract": "Offline paired preference optimization algorithms have become a popular\napproach for fine-tuning on preference data, outperforming traditional\nsupervised fine-tuning in various tasks. However, traditional implementations\noften involve redundant computations, especially for tasks with long shared\nprompts. We introduce prefix sharing for preference tuning, a novel technique\nthat processes chosen and rejected responses as one sequence with a shared\nprefix. To prevent cross-response contamination, we use a custom block-sparse\nattention mask. Our method achieves $1.1$-$1.5\\times$ improvement in training\nthroughput on popular DPO datasets, without any effect on convergence. When\ncombined with sequence packing, we observe consistent $1.3$-$1.6\\times$\nspeedups, benefiting even datasets with smaller sequence lengths. While we\nfocus on Direct Preference Optimization (DPO), our approach is applicable to\nother paired preference tuning methods. By enhancing computational efficiency,\nour work contributes to making preference-based fine-tuning more accessible for\na wider range of applications and model sizes. We open-source our code at\nhttps://github.com/frankxwang/dpo-prefix-sharing.", "published": "2024-10-27 02:06:17", "link": "http://arxiv.org/abs/2410.20305v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Deep Learning Based Dense Retrieval: A Comparative Study", "abstract": "Dense retrievers have achieved state-of-the-art performance in various\ninformation retrieval tasks, but their robustness against tokenizer poisoning\nremains underexplored. In this work, we assess the vulnerability of dense\nretrieval systems to poisoned tokenizers by evaluating models such as BERT,\nDense Passage Retrieval (DPR), Contriever, SimCSE, and ANCE. We find that\nsupervised models like BERT and DPR experience significant performance\ndegradation when tokenizers are compromised, while unsupervised models like\nANCE show greater resilience. Our experiments reveal that even small\nperturbations can severely impact retrieval accuracy, highlighting the need for\nrobust defenses in critical applications.", "published": "2024-10-27 02:52:36", "link": "http://arxiv.org/abs/2410.20315v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Maintaining Informative Coherence: Migrating Hallucinations in Large\n  Language Models via Absorbing Markov Chains", "abstract": "Large Language Models (LLMs) are powerful tools for text generation,\ntranslation, and summarization, but they often suffer from\nhallucinations-instances where they fail to maintain the fidelity and coherence\nof contextual information during decoding, sometimes overlooking critical\ndetails due to their sampling strategies and inherent biases from training data\nand fine-tuning discrepancies. These hallucinations can propagate through the\nweb, affecting the trustworthiness of information disseminated online. To\naddress this issue, we propose a novel decoding strategy that leverages\nabsorbing Markov chains to quantify the significance of contextual information\nand measure the extent of information loss during generation. By considering\nall possible paths from the first to the last token, our approach enhances the\nreliability of model outputs without requiring additional training or external\ndata. Evaluations on datasets including TruthfulQA, FACTOR, and HaluEval\nhighlight the superior performance of our method in mitigating hallucinations,\nunderscoring the necessity of ensuring accurate information flow in web-based\napplications.", "published": "2024-10-27 04:51:18", "link": "http://arxiv.org/abs/2410.20340v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rethinking Data Synthesis: A Teacher Model Training Recipe with\n  Interpretation", "abstract": "Recent advances in large language model (LLM) training have highlighted the\nneed for diverse, high-quality instruction data. Recently, many works are\nexploring synthetic data generation using LLMs. However, they primarily focus\non prompt engineering with standard supervised instruction-finetuned models,\nwhich contains a fundamental limitation: these models are optimized for general\nquestion-answering/problem-solving rather than data generation. We propose a\nparadigm shift named \\textbf{NOMAD} by investigating how to specifically train\nmodels for data generation, demonstrating that this task differs significantly\nfrom training a classical LM. We identify two key factors: no-prompt-masked\ntraining and proper training set size selection. Our method, NOMAD, shows\nsubstantial improvements over baselines, achieving >4\\% gains in TriviaQA and\n>2\\% in GSM8K with limited training data. Finally, we offer new insights by\ninterpreting synthetic data through the lenses of \"relevance\" and \"novelty\".", "published": "2024-10-27 07:38:39", "link": "http://arxiv.org/abs/2410.20362v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AutoKaggle: A Multi-Agent Framework for Autonomous Data Science\n  Competitions", "abstract": "Data science tasks involving tabular data present complex challenges that\nrequire sophisticated problem-solving approaches. We propose AutoKaggle, a\npowerful and user-centric framework that assists data scientists in completing\ndaily data pipelines through a collaborative multi-agent system. AutoKaggle\nimplements an iterative development process that combines code execution,\ndebugging, and comprehensive unit testing to ensure code correctness and logic\nconsistency. The framework offers highly customizable workflows, allowing users\nto intervene at each phase, thus integrating automated intelligence with human\nexpertise. Our universal data science toolkit, comprising validated functions\nfor data cleaning, feature engineering, and modeling, forms the foundation of\nthis solution, enhancing productivity by streamlining common tasks. We selected\n8 Kaggle competitions to simulate data processing workflows in real-world\napplication scenarios. Evaluation results demonstrate that AutoKaggle achieves\na validation submission rate of 0.85 and a comprehensive score of 0.82 in\ntypical data science pipelines, fully proving its effectiveness and\npracticality in handling complex data science tasks.", "published": "2024-10-27 12:44:25", "link": "http://arxiv.org/abs/2410.20424v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MedGo: A Chinese Medical Large Language Model", "abstract": "Large models are a hot research topic in the field of artificial\nintelligence. Leveraging their generative capabilities has the potential to\nenhance the level and quality of medical services. In response to the\nlimitations of current large language models, which often struggle with\naccuracy and have narrow capabilities in medical applications, this paper\npresents a Chinese medical large language model, MedGo. MedGo was trained using\na combination of high quality unsupervised medical data, supervised data, and\npreference alignment data, aimed at enhancing both its versatility and\nprecision in medical tasks. The model was evaluated through the public CBLUE\nbenchmark and a manually constructed dataset ClinicalQA. The results\ndemonstrate that MedGo achieved promising performance across various Chinese\nmedical information processing tasks, achieved the first place in the CBLUE\nevaluation. Additionally, on our constructed dataset ClinicalQA, MedGo\noutperformed its base model Qwen2, highlighting its potential to improve both\nautomated medical question answering and clinical decision support. These\nexperimental results demonstrate that MedGo possesses strong information\nprocessing capabilities in the medical field. At present, we have successfully\ndeployed MedGo at Shanghai East Hospital.", "published": "2024-10-27 12:52:52", "link": "http://arxiv.org/abs/2410.20428v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Derivational ChainBank for Modern Standard Arabic", "abstract": "We introduce the new concept of an Arabic Derivational Chain Bank CHAINBANK\nto leverage the relationship between form and meaning in modeling Arabic\nderivational morphology. We constructed a knowledge graph network of abstract\npatterns and their derivational relations and aligned it with the lemmas of the\nCAMELMORPH morphological analyzer database. This process produced chains of\nderived words' lemmas linked to their corresponding lemma bases through\nderivational relations, encompassing 23,333 derivational connections.", "published": "2024-10-27 14:43:23", "link": "http://arxiv.org/abs/2410.20463v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Graph Neural Networks on Discriminative Graphs of Words", "abstract": "In light of the recent success of Graph Neural Networks (GNNs) and their\nability to perform inference on complex data structures, many studies apply\nGNNs to the task of text classification. In most previous methods, a\nheterogeneous graph, containing both word and document nodes, is constructed\nusing the entire corpus and a GNN is used to classify document nodes. In this\nwork, we explore a new Discriminative Graph of Words Graph Neural Network\n(DGoW-GNN) approach encapsulating both a novel discriminative graph\nconstruction and model to classify text. In our graph construction, containing\nonly word nodes and no document nodes, we split the training corpus into\ndisconnected subgraphs according to their labels and weight edges by the\npointwise mutual information of the represented words. Our graph construction,\nfor which we provide theoretical motivation, allows us to reformulate the task\nof text classification as the task of walk classification. We also propose a\nnew model for the graph-based classification of text, which combines a GNN and\na sequence model. We evaluate our approach on seven benchmark datasets and find\nthat it is outperformed by several state-of-the-art baseline models. We analyse\nreasons for this performance difference and hypothesise under which conditions\nit is likely to change.", "published": "2024-10-27 15:14:06", "link": "http://arxiv.org/abs/2410.20469v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "$\\textit{Who Speaks Matters}$: Analysing the Influence of the Speaker's\n  Ethnicity on Hate Classification", "abstract": "Large Language Models (LLMs) offer a lucrative promise for scalable content\nmoderation, including hate speech detection. However, they are also known to be\nbrittle and biased against marginalised communities and dialects. This requires\ntheir applications to high-stakes tasks like hate speech detection to be\ncritically scrutinized. In this work, we investigate the robustness of hate\nspeech classification using LLMs, particularly when explicit and implicit\nmarkers of the speaker's ethnicity are injected into the input. For the\nexplicit markers, we inject a phrase that mentions the speaker's identity. For\nthe implicit markers, we inject dialectal features. By analysing how frequently\nmodel outputs flip in the presence of these markers, we reveal varying degrees\nof brittleness across 4 popular LLMs and 5 ethnicities. We find that the\npresence of implicit dialect markers in inputs causes model outputs to flip\nmore than the presence of explicit markers. Further, the percentage of flips\nvaries across ethnicities. Finally, we find that larger models are more robust.\nOur findings indicate the need for exercising caution in deploying LLMs for\nhigh-stakes tasks like hate speech detection.", "published": "2024-10-27 16:06:24", "link": "http://arxiv.org/abs/2410.20490v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Llama Scope: Extracting Millions of Features from Llama-3.1-8B with\n  Sparse Autoencoders", "abstract": "Sparse Autoencoders (SAEs) have emerged as a powerful unsupervised method for\nextracting sparse representations from language models, yet scalable training\nremains a significant challenge. We introduce a suite of 256 SAEs, trained on\neach layer and sublayer of the Llama-3.1-8B-Base model, with 32K and 128K\nfeatures. Modifications to a state-of-the-art SAE variant, Top-K SAEs, are\nevaluated across multiple dimensions. In particular, we assess the\ngeneralizability of SAEs trained on base models to longer contexts and\nfine-tuned models. Additionally, we analyze the geometry of learned SAE\nlatents, confirming that \\emph{feature splitting} enables the discovery of new\nfeatures. The Llama Scope SAE checkpoints are publicly available\nat~\\url{https://huggingface.co/fnlp/Llama-Scope}, alongside our scalable\ntraining, interpretation, and visualization tools at\n\\url{https://github.com/OpenMOSS/Language-Model-SAEs}. These contributions aim\nto advance the open-source Sparse Autoencoder ecosystem and support mechanistic\ninterpretability research by reducing the need for redundant SAE training.", "published": "2024-10-27 17:33:49", "link": "http://arxiv.org/abs/2410.20526v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Guiding Through Complexity: What Makes Good Supervision for Hard Math\n  Reasoning Tasks?", "abstract": "How can \"weak teacher models\" such as average human annotators or existing AI\nsystems, effectively supervise LLMs to improve performance on hard reasoning\ntasks, especially those that challenge and requires expertise or daily practice\nfrom the teacher models? In this paper, we seek for empirical answers to this\nquestion by investigating various data-driven strategies that offer supervision\ndata at different quality levels upon tasks of varying complexity. Two\nintuitive strategies emerge for teacher models to provide supervision during\nalignment training: 1) using lower-quality supervision from complete tasks that\nmatch the difficulty of the target reasoning tasks, and 2) leveraging\nhigher-quality supervision from easier subtasks that are less challenging.\nInterestingly, we find that even when the outcome error rate for hard task\nsupervision is high (e.g., 90\\%), training on such data can outperform\nperfectly correct supervision of easier subtasks on multiple hard math\nbenchmarks. We further identify a more critical factor influencing training\nperformance: step-wise error rates, which indicate the severity of errors in\nsolutions. Specifically, training on hard task supervision with the same\noutcome error rates but disparate step-wise error rates can lead to a 30\\%\naccuracy gap on MATH benchmark. Our results also reveal that supplementing hard\ntask supervision with the corresponding subtask supervision can yield notable\nperformance improvements than simply combining rephrased hard full task\nsupervision, suggesting new avenues for data augmentation. Data and code are\nreleased at https://github.com/hexuan21/Weak-to-Strong.", "published": "2024-10-27 17:55:27", "link": "http://arxiv.org/abs/2410.20533v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM Robustness Against Misinformation in Biomedical Question Answering", "abstract": "The retrieval-augmented generation (RAG) approach is used to reduce the\nconfabulation of large language models (LLMs) for question answering by\nretrieving and providing additional context coming from external knowledge\nsources (e.g., by adding the context to the prompt). However, injecting\nincorrect information can mislead the LLM to generate an incorrect answer.\n  In this paper, we evaluate the effectiveness and robustness of four LLMs\nagainst misinformation - Gemma 2, GPT-4o-mini, Llama~3.1, and Mixtral - in\nanswering biomedical questions. We assess the answer accuracy on yes-no and\nfree-form questions in three scenarios: vanilla LLM answers (no context is\nprovided), \"perfect\" augmented generation (correct context is provided), and\nprompt-injection attacks (incorrect context is provided). Our results show that\nLlama 3.1 (70B parameters) achieves the highest accuracy in both vanilla\n(0.651) and \"perfect\" RAG (0.802) scenarios. However, the accuracy gap between\nthe models almost disappears with \"perfect\" RAG, suggesting its potential to\nmitigate the LLM's size-related effectiveness differences.\n  We further evaluate the ability of the LLMs to generate malicious context on\none hand and the LLM's robustness against prompt-injection attacks on the other\nhand, using metrics such as attack success rate (ASR), accuracy under attack,\nand accuracy drop. As adversaries, we use the same four LLMs (Gemma 2,\nGPT-4o-mini, Llama 3.1, and Mixtral) to generate incorrect context that is\ninjected in the target model's prompt. Interestingly, Llama is shown to be the\nmost effective adversary, causing accuracy drops of up to 0.48 for vanilla\nanswers and 0.63 for \"perfect\" RAG across target models. Our analysis reveals\nthat robustness rankings vary depending on the evaluation measure, highlighting\nthe complexity of assessing LLM resilience to adversarial attacks.", "published": "2024-10-27 16:23:26", "link": "http://arxiv.org/abs/2410.21330v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning and Evaluating Open-Source Large Language Models for the\n  Army Domain", "abstract": "In recent years, the widespread adoption of Large Language Models (LLMs) has\nsparked interest in their potential for application within the military domain.\nHowever, the current generation of LLMs demonstrate sub-optimal performance on\nArmy use cases, due to the prevalence of domain-specific vocabulary and jargon.\nIn order to fully leverage LLMs in-domain, many organizations have turned to\nfine-tuning to circumvent the prohibitive costs involved in training new LLMs\nfrom scratch. In light of this trend, we explore the viability of adapting\nopen-source LLMs for usage in the Army domain in order to address their\nexisting lack of domain-specificity. Our investigations have resulted in the\ncreation of three distinct generations of TRACLM, a family of LLMs fine-tuned\nby The Research and Analysis Center (TRAC), Army Futures Command (AFC). Through\ncontinuous refinement of our training pipeline, each successive iteration of\nTRACLM displayed improved capabilities when applied to Army tasks and use\ncases. Furthermore, throughout our fine-tuning experiments, we recognized the\nneed for an evaluation framework that objectively quantifies the Army\ndomain-specific knowledge of LLMs. To address this, we developed MilBench, an\nextensible software framework that efficiently evaluates the Army knowledge of\na given LLM using tasks derived from doctrine and assessments. We share\npreliminary results, models, methods, and recommendations on the creation of\nTRACLM and MilBench. Our work significantly informs the development of LLM\ntechnology across the DoD and augments senior leader decisions with respect to\nartificial intelligence integration.", "published": "2024-10-27 00:39:24", "link": "http://arxiv.org/abs/2410.20297v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Sequential Large Language Model-Based Hyper-parameter Optimization", "abstract": "This study introduces SLLMBO, an innovative framework leveraging large\nlanguage models (LLMs) for hyperparameter optimization (HPO), incorporating\ndynamic search space adaptability, enhanced parameter space exploitation, and a\nnovel LLM-tree-structured parzen estimator (LLM-TPE) sampler. By addressing\nlimitations in recent fully LLM-based methods and traditional bayesian\noptimization (BO), SLLMBO achieves more robust optimization. This comprehensive\nbenchmarking evaluates multiple LLMs, including GPT-3.5-Turbo, GPT-4o,\nClaude-Sonnet-3.5, and Gemini-1.5-Flash, extending prior work and establishing\nSLLMBO as the first framework to benchmark a diverse set of LLMs for HPO. By\nintegrating LLMs' established strengths in parameter initialization with the\nexploitation abilities demonstrated in this study, alongside TPE's exploration\ncapabilities, the LLM-TPE sampler achieves a balanced exploration-exploitation\ntrade-off, reduces API costs, and mitigates premature early stoppings for more\neffective parameter searches. Across 14 tabular tasks in classification and\nregression, the LLM-TPE sampler outperformed fully LLM-based methods and\nachieved superior results over BO methods in 9 tasks. Testing early stopping in\nbudget-constrained scenarios demonstrated competitive performance, indicating\nthat LLM-based methods generally benefit from extended iterations for optimal\nresults. This work lays the foundation for future research exploring\nopen-source LLMs, reproducibility of LLM results in HPO, and benchmarking\nSLLMBO on complex datasets, such as image classification, segmentation, and\nmachine translation.", "published": "2024-10-27 00:50:30", "link": "http://arxiv.org/abs/2410.20302v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Improving Speech-based Emotion Recognition with Contextual Utterance\n  Analysis and LLMs", "abstract": "Speech Emotion Recognition (SER) focuses on identifying emotional states from\nspoken language. The 2024 IEEE SLT-GenSEC Challenge on Post Automatic Speech\nRecognition (ASR) Emotion Recognition tasks participants to explore the\ncapabilities of large language models (LLMs) for emotion recognition using only\ntext data. We propose a novel approach that first refines all available\ntranscriptions to ensure data reliability. We then segment each complete\nconversation into smaller dialogues and use these dialogues as context to\npredict the emotion of the target utterance within the dialogue. Finally, we\ninvestigated different context lengths and prompting techniques to improve\nprediction accuracy. Our best submission exceeded the baseline by 20% in\nunweighted accuracy, achieving the best performance in the challenge. All our\nexperiments' codes, prediction results, and log files are publicly available.", "published": "2024-10-27 04:23:34", "link": "http://arxiv.org/abs/2410.20334v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Get Large Language Models Ready to Speak: A Late-fusion Approach for\n  Speech Generation", "abstract": "Large language models (LLMs) have revolutionized natural language processing\n(NLP) with impressive performance across various text-based tasks. However, the\nextension of text-dominant LLMs to with speech generation tasks remains\nunder-explored. In this work, we introduce a text-to-speech (TTS) system\npowered by a fine-tuned Llama model, named TTS-Llama, that achieves\nstate-of-the-art speech synthesis performance. Building on TTS-Llama, we\nfurther propose MoLE-Llama, a text-and-speech multimodal LLM developed through\npurely late-fusion parameter-efficient fine-tuning (PEFT) and a\nmixture-of-expert architecture. Extensive empirical results demonstrate\nMoLE-Llama's competitive performance on both text-only question-answering (QA)\nand TTS tasks, mitigating catastrophic forgetting issue in either modality.\nFinally, we further explore MoLE-Llama in text-in-speech-out QA tasks,\ndemonstrating its great potential as a multimodal dialog system capable of\nspeech generation.", "published": "2024-10-27 04:28:57", "link": "http://arxiv.org/abs/2410.20336v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Historical Test-time Prompt Tuning for Vision Foundation Models", "abstract": "Test-time prompt tuning, which learns prompts online with unlabelled test\nsamples during the inference stage, has demonstrated great potential by\nlearning effective prompts on-the-fly without requiring any task-specific\nannotations. However, its performance often degrades clearly along the tuning\nprocess when the prompts are continuously updated with the test data flow, and\nthe degradation becomes more severe when the domain of test samples changes\ncontinuously. We propose HisTPT, a Historical Test-time Prompt Tuning technique\nthat memorizes the useful knowledge of the learnt test samples and enables\nrobust test-time prompt tuning with the memorized knowledge. HisTPT introduces\nthree types of knowledge banks, namely, local knowledge bank, hard-sample\nknowledge bank, and global knowledge bank, each of which works with different\nmechanisms for effective knowledge memorization and test-time prompt\noptimization. In addition, HisTPT features an adaptive knowledge retrieval\nmechanism that regularizes the prediction of each test sample by adaptively\nretrieving the memorized knowledge. Extensive experiments show that HisTPT\nachieves superior prompt tuning performance consistently while handling\ndifferent visual recognition tasks (e.g., image classification, semantic\nsegmentation, and object detection) and test samples from continuously changing\ndomains.", "published": "2024-10-27 06:03:15", "link": "http://arxiv.org/abs/2410.20346v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Open-Vocabulary Object Detection via Language Hierarchy", "abstract": "Recent studies on generalizable object detection have attracted increasing\nattention with additional weak supervision from large-scale datasets with\nimage-level labels. However, weakly-supervised detection learning often suffers\nfrom image-to-box label mismatch, i.e., image-level labels do not convey\nprecise object information. We design Language Hierarchical Self-training\n(LHST) that introduces language hierarchy into weakly-supervised detector\ntraining for learning more generalizable detectors. LHST expands the\nimage-level labels with language hierarchy and enables co-regularization\nbetween the expanded labels and self-training. Specifically, the expanded\nlabels regularize self-training by providing richer supervision and mitigating\nthe image-to-box label mismatch, while self-training allows assessing and\nselecting the expanded labels according to the predicted reliability. In\naddition, we design language hierarchical prompt generation that introduces\nlanguage hierarchy into prompt generation which helps bridge the vocabulary\ngaps between training and testing. Extensive experiments show that the proposed\ntechniques achieve superior generalization performance consistently across 14\nwidely studied object detection datasets.", "published": "2024-10-27 08:20:03", "link": "http://arxiv.org/abs/2410.20371v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "TrajAgent: An Agent Framework for Unified Trajectory Modelling", "abstract": "Trajectory modeling, which includes research on trajectory data pattern\nmining and future prediction, has widespread applications in areas such as life\nservices, urban transportation, and public administration. Numerous methods\nhave been proposed to address specific problems within trajectory modelling.\nHowever, due to the heterogeneity of data and the diversity of trajectory\ntasks, achieving unified trajectory modelling remains an important yet\nchallenging task. In this paper, we propose TrajAgent, a large language\nmodel-based agentic framework, to unify various trajectory modelling tasks. In\nTrajAgent, we first develop UniEnv, an execution environment with a unified\ndata and model interface, to support the execution and training of various\nmodels. Building on UniEnv, we introduce TAgent, an agentic workflow designed\nfor automatic trajectory modelling across various trajectory tasks.\nSpecifically, we design AutOpt, a systematic optimization module within TAgent,\nto further improve the performance of the integrated model. With diverse\ntrajectory tasks input in natural language, TrajAgent automatically generates\ncompetitive results via training and executing appropriate models. Extensive\nexperiments on four tasks using four real-world datasets demonstrate the\neffectiveness of TrajAgent in unified trajectory modelling, achieving an\naverage performance improvement of 15.43% over baseline methods.", "published": "2024-10-27 13:51:09", "link": "http://arxiv.org/abs/2410.20445v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What Factors Affect Multi-Modal In-Context Learning? An In-Depth\n  Exploration", "abstract": "Recently, rapid advancements in Multi-Modal In-Context Learning (MM-ICL) have\nachieved notable success, which is capable of achieving superior performance\nacross various tasks without requiring additional parameter tuning. However,\nthe underlying rules for the effectiveness of MM-ICL remain under-explored. To\nfill this gap, this work aims to investigate the research question: \"What\nfactors affect the performance of MM-ICL?'' To this end, we investigate\nextensive experiments on the three core steps of MM-ICL including demonstration\nretrieval, demonstration ordering, and prompt construction using 6 vision large\nlanguage models and 20 strategies. Our findings highlight (1) the necessity of\na multi-modal retriever for demonstration retrieval, (2) the importance of\nintra-demonstration ordering over inter-demonstration ordering, and (3) the\nenhancement of task comprehension through introductory instructions in prompts.\nWe hope this study can serve as a foundational guide for optimizing MM-ICL\nstrategies in future research.", "published": "2024-10-27 15:37:51", "link": "http://arxiv.org/abs/2410.20482v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Towards an LLM-Based Speech Interface for Robot-Assisted Feeding", "abstract": "Physically assistive robots present an opportunity to significantly increase\nthe well-being and independence of individuals with motor impairments or other\nforms of disability who are unable to complete activities of daily living\n(ADLs). Speech interfaces, especially ones that utilize Large Language Models\n(LLMs), can enable individuals to effectively and naturally communicate\nhigh-level commands and nuanced preferences to robots. In this work, we\ndemonstrate an LLM-based speech interface for a commercially available\nassistive feeding robot. Our system is based on an iteratively designed\nframework, from the paper \"VoicePilot: Harnessing LLMs as Speech Interfaces for\nPhysically Assistive Robots,\" that incorporates human-centric elements for\nintegrating LLMs as interfaces for robots. It has been evaluated through a user\nstudy with 11 older adults at an independent living facility. Videos are\nlocated on our project website:\nhttps://sites.google.com/andrew.cmu.edu/voicepilot/.", "published": "2024-10-27 22:56:51", "link": "http://arxiv.org/abs/2410.20624v1", "categories": ["cs.RO", "cs.CL", "cs.HC"], "primary_category": "cs.RO"}
{"title": "LoRA Done RITE: Robust Invariant Transformation Equilibration for LoRA\n  Optimization", "abstract": "Low-rank adaption (LoRA) is a widely used parameter-efficient finetuning\nmethod for LLM that reduces memory requirements. However, current LoRA\noptimizers lack transformation invariance, meaning the actual updates to the\nweights depends on how the two LoRA factors are scaled or rotated. This\ndeficiency leads to inefficient learning and sub-optimal solutions in practice.\nThis paper introduces LoRA-RITE, a novel adaptive matrix preconditioning method\nfor LoRA optimization, which can achieve transformation invariance and remain\ncomputationally efficient. We provide theoretical analysis to demonstrate the\nbenefit of our method and conduct experiments on various LLM tasks with\ndifferent models including Gemma 2B, 7B, and mT5-XXL. The results demonstrate\nconsistent improvements against existing optimizers. For example, replacing\nAdam with LoRA-RITE during LoRA fine-tuning of Gemma-2B yielded 4.6\\% accuracy\ngain on Super-Natural Instructions and 3.5\\% accuracy gain across other four\nLLM benchmarks (HellaSwag, ArcChallenge, GSM8K, OpenBookQA).", "published": "2024-10-27 22:57:12", "link": "http://arxiv.org/abs/2410.20625v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Building, Reusing, and Generalizing Abstract Representations from\n  Concrete Sequences", "abstract": "Humans excel at learning abstract patterns across different sequences,\nfiltering out irrelevant details, and transferring these generalized concepts\nto new sequences. In contrast, many sequence learning models lack the ability\nto abstract, which leads to memory inefficiency and poor transfer. We introduce\na non-parametric hierarchical variable learning model (HVM) that learns chunks\nfrom sequences and abstracts contextually similar chunks as variables. HVM\nefficiently organizes memory while uncovering abstractions, leading to compact\nsequence representations. When learning on language datasets such as babyLM,\nHVM learns a more efficient dictionary than standard compression algorithms\nsuch as Lempel-Ziv. In a sequence recall task requiring the acquisition and\ntransfer of variables embedded in sequences, we demonstrate HVM's sequence\nlikelihood correlates with human recall times. In contrast, large language\nmodels (LLMs) struggle to transfer abstract variables as effectively as humans.\nFrom HVM's adjustable layer of abstraction, we demonstrate that the model\nrealizes a precise trade-off between compression and generalization. Our work\noffers a cognitive model that captures the learning and transfer of abstract\nrepresentations in human cognition and differentiates itself from the behavior\nof large language models.", "published": "2024-10-27 18:13:07", "link": "http://arxiv.org/abs/2410.21332v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on\n  Tasks where Thinking Makes Humans Worse", "abstract": "Chain-of-thought (CoT) prompting has become a widely used strategy for\nworking with large language and multimodal models. While CoT has been shown to\nimprove performance across many tasks, determining the settings in which it is\neffective remains an ongoing effort. In particular, it is still an open\nquestion in what settings CoT systematically reduces model performance. In this\npaper, we seek to identify the characteristics of tasks where CoT reduces\nperformance by drawing inspiration from cognitive psychology, looking at cases\nwhere (i) verbal thinking or deliberation hurts performance in humans, and (ii)\nthe constraints governing human performance generalize to language models.\nThree such cases are implicit statistical learning, visual recognition, and\nclassifying with patterns containing exceptions. In extensive experiments\nacross all three settings, we find that a diverse collection of\nstate-of-the-art models exhibit significant drop-offs in performance (e.g., up\nto 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using\ninference-time reasoning compared to zero-shot counterparts. We also identify\nthree tasks that satisfy condition (i) but not (ii), and find that while verbal\nthinking reduces human performance in these tasks, CoT retains or increases\nmodel performance. Overall, our results show that while there is not an exact\nparallel between the cognitive processes of models and those of humans,\nconsidering cases where thinking has negative consequences for human\nperformance can help us identify settings where it negatively impacts models.\nBy connecting the literature on human deliberation with evaluations of CoT, we\noffer a new tool that can be used in understanding the impact of prompt choices\nand inference-time reasoning.", "published": "2024-10-27 18:30:41", "link": "http://arxiv.org/abs/2410.21333v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "An approach to hummed-tune and song sequences matching", "abstract": "Melody stuck in your head, also known as \"earworm\", is tough to get rid of,\nunless you listen to it again or sing it out loud. But what if you can not find\nthe name of that song? It must be an intolerable feeling. Recognizing a song\nname base on humming sound is not an easy task for a human being and should be\ndone by machines. However, there is no research paper published about hum tune\nrecognition. Adapting from Hum2Song Zalo AI Challenge 2021 - a competition\nabout querying the name of a song by user's giving humming tune, which is\nsimilar to Google's Hum to Search. This paper covers details about the\npre-processed data from the original type (mp3) to usable form for training and\ninference. In training an embedding model for the feature extraction phase, we\nran experiments with some states of the art, such as ResNet, VGG, AlexNet,\nMobileNetV2. And for the inference phase, we use the Faiss module to\neffectively search for a song that matched the sequence of humming sound. The\nresult comes at nearly 94\\% in MRR@10 metric on the public test set, along with\nthe top 1 result on the public leaderboard.", "published": "2024-10-27 06:50:43", "link": "http://arxiv.org/abs/2410.20352v1", "categories": ["cs.SD", "cs.AI", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MusicFlow: Cascaded Flow Matching for Text Guided Music Generation", "abstract": "We introduce MusicFlow, a cascaded text-to-music generation model based on\nflow matching. Based on self-supervised representations to bridge between text\ndescriptions and music audios, we construct two flow matching networks to model\nthe conditional distribution of semantic and acoustic features. Additionally,\nwe leverage masked prediction as the training objective, enabling the model to\ngeneralize to other tasks such as music infilling and continuation in a\nzero-shot manner. Experiments on MusicCaps reveal that the music generated by\nMusicFlow exhibits superior quality and text coherence despite being over\n$2\\sim5$ times smaller and requiring $5$ times fewer iterative steps.\nSimultaneously, the model can perform other music generation tasks and achieves\ncompetitive performance in music infilling and continuation. Our code and model\nwill be publicly available.", "published": "2024-10-27 15:35:41", "link": "http://arxiv.org/abs/2410.20478v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Symbotunes: unified hub for symbolic music generative models", "abstract": "Implementations of popular symbolic music generative models often differ\nsignificantly in terms of the libraries utilized and overall project structure.\nTherefore, directly comparing the methods or becoming acquainted with them may\npresent challenges. To mitigate this issue we introduce Symbotunes, an\nopen-source unified hub for symbolic music generative models. Symbotunes\ncontains modern Python implementations of well-known methods for symbolic music\ngeneration, as well as a unified pipeline for generating and training.", "published": "2024-10-27 16:54:58", "link": "http://arxiv.org/abs/2410.20515v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MidiTok Visualizer: a tool for visualization and analysis of tokenized\n  MIDI symbolic music", "abstract": "Symbolic music research plays a crucial role in music-related machine\nlearning, but MIDI data can be complex for those without musical expertise. To\naddress this issue, we present MidiTok Visualizer, a web application designed\nto facilitate the exploration and visualization of various MIDI tokenization\nmethods from the MidiTok Python package. MidiTok Visualizer offers numerous\ncustomizable parameters, enabling users to upload MIDI files to visualize\ntokenized data alongside an interactive piano roll.", "published": "2024-10-27 17:00:55", "link": "http://arxiv.org/abs/2410.20518v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automatic Estimation of Singing Voice Musical Dynamics", "abstract": "Musical dynamics form a core part of expressive singing voice performances.\nHowever, automatic analysis of musical dynamics for singing voice has received\nlimited attention partly due to the scarcity of suitable datasets and a lack of\nclear evaluation frameworks. To address this challenge, we propose a\nmethodology for dataset curation. Employing the proposed methodology, we\ncompile a dataset comprising 509 musical dynamics annotated singing voice\nperformances, aligned with 163 score files, leveraging state-of-the-art source\nseparation and alignment techniques. The scores are sourced from the OpenScore\nLieder corpus of romantic-era compositions, widely known for its wealth of\nexpressive annotations. Utilizing the curated dataset, we train a multi-head\nattention based CNN model with varying window sizes to evaluate the\neffectiveness of estimating musical dynamics. We explored two distinct\nperceptually motivated input representations for the model training: log-Mel\nspectrum and bark-scale based features. For testing, we manually curate another\ndataset of 25 musical dynamics annotated performances in collaboration with a\nprofessional vocalist. We conclude through our experiments that bark-scale\nbased features outperform log-Mel-features for the task of singing voice\ndynamics prediction. The dataset along with the code is shared publicly for\nfurther research on the topic.", "published": "2024-10-27 18:15:18", "link": "http://arxiv.org/abs/2410.20540v1", "categories": ["cs.SD", "cs.IR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Using Confidence Scores to Improve Eyes-free Detection of Speech\n  Recognition Errors", "abstract": "Conversational systems rely heavily on speech recognition to interpret and\nrespond to user commands and queries. Despite progress on speech recognition\naccuracy, errors may still sometimes occur and can significantly affect the\nend-user utility of such systems. While visual feedback can help detect errors,\nit may not always be practical, especially for people who are blind or\nlow-vision. In this study, we investigate ways to improve error detection by\nmanipulating the audio output of the transcribed text based on the recognizer's\nconfidence level in its result. Our findings show that selectively slowing down\nthe audio when the recognizer exhibited uncertainty led to a 12% relative\nincrease in participants' ability to detect errors compared to uniformly\nslowing the audio. It also reduced the time it took participants to listen to\nthe recognition result and decide if there was an error by 11%.", "published": "2024-10-27 19:33:01", "link": "http://arxiv.org/abs/2410.20564v2", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Meta-Learning Approaches for Improving Detection of Unseen Speech\n  Deepfakes", "abstract": "Current speech deepfake detection approaches perform satisfactorily against\nknown adversaries; however, generalization to unseen attacks remains an open\nchallenge. The proliferation of speech deepfakes on social media underscores\nthe need for systems that can generalize to unseen attacks not observed during\ntraining. We address this problem from the perspective of meta-learning, aiming\nto learn attack-invariant features to adapt to unseen attacks with very few\nsamples available. This approach is promising since generating of a high-scale\ntraining dataset is often expensive or infeasible. Our experiments demonstrated\nan improvement in the Equal Error Rate (EER) from 21.67% to 10.42% on the\nInTheWild dataset, using just 96 samples from the unseen dataset. Continuous\nfew-shot adaptation ensures that the system remains up-to-date.", "published": "2024-10-27 20:14:32", "link": "http://arxiv.org/abs/2410.20578v2", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Conditional GAN for Enhancing Diffusion Models in Efficient and\n  Authentic Global Gesture Generation from Audios", "abstract": "Audio-driven simultaneous gesture generation is vital for human-computer\ncommunication, AI games, and film production. While previous research has shown\npromise, there are still limitations. Methods based on VAEs are accompanied by\nissues of local jitter and global instability, whereas methods based on\ndiffusion models are hampered by low generation efficiency. This is because the\ndenoising process of DDPM in the latter relies on the assumption that the noise\nadded at each step is sampled from a unimodal distribution, and the noise\nvalues are small. DDIM borrows the idea from the Euler method for solving\ndifferential equations, disrupts the Markov chain process, and increases the\nnoise step size to reduce the number of denoising steps, thereby accelerating\ngeneration. However, simply increasing the step size during the step-by-step\ndenoising process causes the results to gradually deviate from the original\ndata distribution, leading to a significant drop in the quality of the\ngenerated actions and the emergence of unnatural artifacts. In this paper, we\nbreak the assumptions of DDPM and achieves breakthrough progress in denoising\nspeed and fidelity. Specifically, we introduce a conditional GAN to capture\naudio control signals and implicitly match the multimodal denoising\ndistribution between the diffusion and denoising steps within the same sampling\nstep, aiming to sample larger noise values and apply fewer denoising steps for\nhigh-speed generation.", "published": "2024-10-27 07:25:11", "link": "http://arxiv.org/abs/2410.20359v2", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
