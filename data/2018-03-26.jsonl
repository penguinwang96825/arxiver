{"title": "StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow", "abstract": "Stack Overflow (SO) has been a great source of natural language questions and\ntheir code solutions (i.e., question-code pairs), which are critical for many\ntasks including code retrieval and annotation. In most existing research,\nquestion-code pairs were collected heuristically and tend to have low quality.\nIn this paper, we investigate a new problem of systematically mining\nquestion-code pairs from Stack Overflow (in contrast to heuristically\ncollecting them). It is formulated as predicting whether or not a code snippet\nis a standalone solution to a question. We propose a novel Bi-View Hierarchical\nNeural Network which can capture both the programming content and the textual\ncontext of a code snippet (i.e., two views) to make a prediction. On two\nmanually annotated datasets in Python and SQL domain, our framework\nsubstantially outperforms heuristic methods with at least 15% higher F1 and\naccuracy. Furthermore, we present StaQC (Stack Overflow Question-Code pairs),\nthe largest dataset to date of ~148K Python and ~120K SQL question-code pairs,\nautomatically mined from SO using our framework. Under various case studies, we\ndemonstrate that StaQC can greatly help develop data-hungry models for\nassociating natural language with programming language.", "published": "2018-03-26 00:06:57", "link": "http://arxiv.org/abs/1803.09371v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Aggression-annotated Corpus of Hindi-English Code-mixed Data", "abstract": "As the interaction over the web has increased, incidents of aggression and\nrelated events like trolling, cyberbullying, flaming, hate speech, etc. too\nhave increased manifold across the globe. While most of these behaviour like\nbullying or hate speech have predated the Internet, the reach and extent of the\nInternet has given these an unprecedented power and influence to affect the\nlives of billions of people. So it is of utmost significance and importance\nthat some preventive measures be taken to provide safeguard to the people using\nthe web such that the web remains a viable medium of communication and\nconnection, in general. In this paper, we discuss the development of an\naggression tagset and an annotated corpus of Hindi-English code-mixed data from\ntwo of the most popular social networking and social media platforms in India,\nTwitter and Facebook. The corpus is annotated using a hierarchical tagset of 3\ntop-level tags and 10 level 2 tags. The final dataset contains approximately\n18k tweets and 21k facebook comments and is being released for further research\nin the field.", "published": "2018-03-26 03:54:34", "link": "http://arxiv.org/abs/1803.09402v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Identification of Closely-related Indian Languages: Resources\n  and Experiments", "abstract": "In this paper, we discuss an attempt to develop an automatic language\nidentification system for 5 closely-related Indo-Aryan languages of India,\nAwadhi, Bhojpuri, Braj, Hindi and Magahi. We have compiled a comparable corpora\nof varying length for these languages from various resources. We discuss the\nmethod of creation of these corpora in detail. Using these corpora, a language\nidentification system was developed, which currently gives state of the art\naccuracy of 96.48\\%. We also used these corpora to study the similarity between\nthe 5 languages at the lexical level, which is the first data-based study of\nthe extent of closeness of these languages.", "published": "2018-03-26 04:02:00", "link": "http://arxiv.org/abs/1803.09405v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Attentional Acoustic Models", "abstract": "Self-attention is a method of encoding sequences of vectors by relating these\nvectors to each-other based on pairwise similarities. These models have\nrecently shown promising results for modeling discrete sequences, but they are\nnon-trivial to apply to acoustic modeling due to computational and modeling\nissues. In this paper, we apply self-attention to acoustic modeling, proposing\nseveral improvements to mitigate these issues: First, self-attention memory\ngrows quadratically in the sequence length, which we address through a\ndownsampling technique. Second, we find that previous approaches to incorporate\nposition information into the model are unsuitable and explore other\nrepresentations and hybrid models to this end. Third, to stress the importance\nof local context in the acoustic signal, we propose a Gaussian biasing approach\nthat allows explicit control over the context range. Experiments find that our\nmodel approaches a strong baseline based on LSTMs with network-in-network\nconnections while being much faster to compute. Besides speed, we find that\ninterpretability is a strength of self-attentional acoustic models, and\ndemonstrate that self-attention heads learn a linguistically plausible division\nof labor.", "published": "2018-03-26 11:36:36", "link": "http://arxiv.org/abs/1803.09519v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Separation of Transliterable and Native Words for Malayalam", "abstract": "Differentiating intrinsic language words from transliterable words is a key\nstep aiding text processing tasks involving different natural languages. We\nconsider the problem of unsupervised separation of transliterable words from\nnative words for text in Malayalam language. Outlining a key observation on the\ndiversity of characters beyond the word stem, we develop an optimization method\nto score words based on their nativeness. Our method relies on the usage of\nprobability distributions over character n-grams that are refined in step with\nthe nativeness scorings in an iterative optimization formulation. Using an\nempirical evaluation, we illustrate that our method, DTIM, provides significant\nimprovements in nativeness scoring for Malayalam, establishing DTIM as the\npreferred method for the task.", "published": "2018-03-26 15:01:52", "link": "http://arxiv.org/abs/1803.09641v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "CliCR: A Dataset of Clinical Case Reports for Machine Reading\n  Comprehension", "abstract": "We present a new dataset for machine comprehension in the medical domain. Our\ndataset uses clinical case reports with around 100,000 gap-filling queries\nabout these cases. We apply several baselines and state-of-the-art neural\nreaders to the dataset, and observe a considerable gap in performance (20% F1)\nbetween the best human and machine readers. We analyze the skills required for\nsuccessful answering and show how reader performance varies depending on the\napplicable skills. We find that inferences using domain knowledge and object\ntracking are the most frequently required skills, and that recognizing omitted\ninformation and spatio-temporal reasoning are the most difficult for the\nmachines.", "published": "2018-03-26 17:20:23", "link": "http://arxiv.org/abs/1803.09720v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Heat Kernel analysis of Syntactic Structures", "abstract": "We consider two different data sets of syntactic parameters and we discuss\nhow to detect relations between parameters through a heat kernel method\ndeveloped by Belkin-Niyogi, which produces low dimensional representations of\nthe data, based on Laplace eigenfunctions, that preserve neighborhood\ninformation. We analyze the different connectivity and clustering structures\nthat arise in the two datasets, and the regions of maximal variance in the\ntwo-parameter space of the Belkin-Niyogi construction, which identify\npreferable choices of independent variables. We compute clustering coefficients\nand their variance.", "published": "2018-03-26 20:38:31", "link": "http://arxiv.org/abs/1803.09832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HomeGuard: A Smart System to Deal with the Emergency Response of\n  Domestic Violence Victims", "abstract": "Domestic violence is a silent crisis in the developing and underdeveloped\ncountries, though developed countries also remain drowned in the curse of it.\nIn developed countries, victims can easily report and ask help on the contrary\nin developing and underdeveloped countries victims hardly report the crimes and\nwhen it's noticed by the authority it's become too late to save or support the\nvictim. If this kind of problems can be identified at the very beginning of the\nevent and proper actions can be taken, it'll not only help the victim but also\nreduce the domestic violence crimes. This paper proposed a smart system which\ncan extract victim's situation and provide help according to it. Among of the\ndeveloping and underdeveloped countries Bangladesh has been chosen though the\nrate of reporting of domestic violence is low, the extreme report collected by\nauthorities is too high. Case studies collected by different NGO's relating to\ndomestic violence have been studied and applied to extract possible condition\nfor the victims.", "published": "2018-03-26 03:45:56", "link": "http://arxiv.org/abs/1803.09401v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "English verb regularization in books and tweets", "abstract": "The English language has evolved dramatically throughout its lifespan, to the\nextent that a modern speaker of Old English would be incomprehensible without\ntranslation. One concrete indicator of this process is the movement from\nirregular to regular (-ed) forms for the past tense of verbs. In this study we\nquantify the extent of verb regularization using two vastly disparate datasets:\n(1) Six years of published books scanned by Google (2003--2008), and (2) A\ndecade of social media messages posted to Twitter (2008--2017). We find that\nthe extent of verb regularization is greater on Twitter, taken as a whole, than\nin English Fiction books. Regularization is also greater for tweets geotagged\nin the United States relative to American English books, but the opposite is\ntrue for tweets geotagged in the United Kingdom relative to British English\nbooks. We also find interesting regional variations in regularization across\ncounties in the United States. However, once differences in population are\naccounted for, we do not identify strong correlations with socio-demographic\nvariables such as education or income.", "published": "2018-03-26 18:00:00", "link": "http://arxiv.org/abs/1803.09745v2", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Empirical Analysis of Foundational Distinctions in Linked Open Data", "abstract": "The Web and its Semantic extension (i.e. Linked Open Data) contain open\nglobal-scale knowledge and make it available to potentially intelligent\nmachines that want to benefit from it. Nevertheless, most of Linked Open Data\nlack ontological distinctions and have sparse axiomatisation. For example,\ndistinctions such as whether an entity is inherently a class or an individual,\nor whether it is a physical object or not, are hardly expressed in the data,\nalthough they have been largely studied and formalised by foundational\nontologies (e.g. DOLCE, SUMO). These distinctions belong to common sense too,\nwhich is relevant for many artificial intelligence tasks such as natural\nlanguage understanding, scene recognition, and the like. There is a gap between\nfoundational ontologies, that often formalise or are inspired by pre-existing\nphilosophical theories and are developed with a top-down approach, and Linked\nOpen Data that mostly derive from existing databases or crowd-based effort\n(e.g. DBpedia, Wikidata). We investigate whether machines can learn\nfoundational distinctions over Linked Open Data entities, and if they match\ncommon sense. We want to answer questions such as \"does the DBpedia entity for\ndog refer to a class or to an instance?\". We report on a set of experiments\nbased on machine learning and crowdsourcing that show promising results.", "published": "2018-03-26 20:56:30", "link": "http://arxiv.org/abs/1803.09840v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Collaborative Filtering with Topic and Social Latent Factors\n  Incorporating Implicit Feedback", "abstract": "Recommender systems (RSs) provide an effective way of alleviating the\ninformation overload problem by selecting personalized items for different\nusers. Latent factors based collaborative filtering (CF) has become the popular\napproaches for RSs due to its accuracy and scalability. Recently, online social\nnetworks and user-generated content provide diverse sources for recommendation\nbeyond ratings. Although {\\em social matrix factorization} (Social MF) and {\\em\ntopic matrix factorization} (Topic MF) successfully exploit social relations\nand item reviews, respectively, both of them ignore some useful information. In\nthis paper, we investigate the effective data fusion by combining the\naforementioned approaches. First, we propose a novel model {\\em \\mbox{MR3}} to\njointly model three sources of information (i.e., ratings, item reviews, and\nsocial relations) effectively for rating prediction by aligning the latent\nfactors and hidden topics. Second, we incorporate the implicit feedback from\nratings into the proposed model to enhance its capability and to demonstrate\nits flexibility. We achieve more accurate rating prediction on real-life\ndatasets over various state-of-the-art methods. Furthermore, we measure the\ncontribution from each of the three data sources and the impact of implicit\nfeedback from ratings, followed by the sensitivity analysis of hyperparameters.\nEmpirical studies demonstrate the effectiveness and efficacy of our proposed\nmodel and its extension.", "published": "2018-03-26 12:46:13", "link": "http://arxiv.org/abs/1803.09551v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Why Comparing Single Performance Scores Does Not Allow to Draw\n  Conclusions About Machine Learning Approaches", "abstract": "Developing state-of-the-art approaches for specific tasks is a major driving\nforce in our research community. Depending on the prestige of the task,\npublishing it can come along with a lot of visibility. The question arises how\nreliable are our evaluation methodologies to compare approaches?\n  One common methodology to identify the state-of-the-art is to partition data\ninto a train, a development and a test set. Researchers can train and tune\ntheir approach on some part of the dataset and then select the model that\nworked best on the development set for a final evaluation on unseen test data.\nTest scores from different approaches are compared, and performance differences\nare tested for statistical significance.\n  In this publication, we show that there is a high risk that a statistical\nsignificance in this type of evaluation is not due to a superior learning\napproach. Instead, there is a high risk that the difference is due to chance.\nFor example for the CoNLL 2003 NER dataset we observed in up to 26% of the\ncases type I errors (false positives) with a threshold of p < 0.05, i.e.,\nfalsely concluding a statistically significant difference between two identical\napproaches.\n  We prove that this evaluation setup is unsuitable to compare learning\napproaches. We formalize alternative evaluation setups based on score\ndistributions.", "published": "2018-03-26 13:35:14", "link": "http://arxiv.org/abs/1803.09578v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Spectral feature mapping with mimic loss for robust speech recognition", "abstract": "For the task of speech enhancement, local learning objectives are agnostic to\nphonetic structures helpful for speech recognition. We propose to add a global\ncriterion to ensure de-noised speech is useful for downstream tasks like ASR.\nWe first train a spectral classifier on clean speech to predict senone labels.\nThen, the spectral classifier is joined with our speech enhancer as a noisy\nspeech recognizer. This model is taught to imitate the output of the spectral\nclassifier alone on clean speech. This \\textit{mimic loss} is combined with the\ntraditional local criterion to train the speech enhancer to produce de-noised\nspeech. Feeding the de-noised speech to an off-the-shelf Kaldi training recipe\nfor the CHiME-2 corpus shows significant improvements in WER.", "published": "2018-03-26 19:56:21", "link": "http://arxiv.org/abs/1803.09816v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Light Gated Recurrent Units for Speech Recognition", "abstract": "A field that has directly benefited from the recent advances in deep learning\nis Automatic Speech Recognition (ASR). Despite the great achievements of the\npast decades, however, a natural and robust human-machine speech interaction\nstill appears to be out of reach, especially in challenging environments\ncharacterized by significant noise and reverberation. To improve robustness,\nmodern speech recognizers often employ acoustic models based on Recurrent\nNeural Networks (RNNs), that are naturally able to exploit large time contexts\nand long-term speech modulations. It is thus of great interest to continue the\nstudy of proper techniques for improving the effectiveness of RNNs in\nprocessing speech signals.\n  In this paper, we revise one of the most popular RNN models, namely Gated\nRecurrent Units (GRUs), and propose a simplified architecture that turned out\nto be very effective for ASR. The contribution of this work is two-fold: First,\nwe analyze the role played by the reset gate, showing that a significant\nredundancy with the update gate occurs. As a result, we propose to remove the\nformer from the GRU design, leading to a more efficient and compact single-gate\nmodel. Second, we propose to replace hyperbolic tangent with ReLU activations.\nThis variation couples well with batch normalization and could help the model\nlearn long-term dependencies without numerical issues.\n  Results show that the proposed architecture, called Light GRU (Li-GRU), not\nonly reduces the per-epoch training time by more than 30% over a standard GRU,\nbut also consistently improves the recognition accuracy across different tasks,\ninput features, noisy conditions, as well as across different ASR paradigms,\nranging from standard DNN-HMM speech recognizers to end-to-end CTC models.", "published": "2018-03-26 17:48:18", "link": "http://arxiv.org/abs/1803.10225v1", "categories": ["eess.AS", "cs.NE", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
