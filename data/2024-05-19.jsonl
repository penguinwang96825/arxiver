{"title": "MHPP: Exploring the Capabilities and Limitations of Language Models\n  Beyond Basic Code Generation", "abstract": "Recent advancements in large language models (LLMs) have greatly improved\ncode generation, specifically at the function level. For instance, GPT-4o has\nachieved a 91.0\\% pass rate on HumanEval. However, this draws into question the\nadequacy of existing benchmarks in thoroughly assessing function-level code\ngeneration capabilities. Our study analyzed two common benchmarks, HumanEval\nand MBPP, and found that these might not thoroughly evaluate LLMs' code\ngeneration capacities due to limitations in quality, difficulty, and\ngranularity. To resolve this, we introduce the Mostly Hard Python Problems\n(MHPP) dataset, consisting of 210 unique human-curated problems. By focusing on\nthe combination of natural language and code reasoning, MHPP gauges LLMs'\nabilities to comprehend specifications and restrictions, engage in multi-step\nreasoning, and apply coding knowledge effectively. Initial evaluations of 26\nLLMs using MHPP showed many high-performing models on HumanEval failed to\nachieve similar success on MHPP. Moreover, MHPP highlighted various previously\nundiscovered limitations within various LLMs, leading us to believe that it\ncould pave the way for a better understanding of LLMs' capabilities and\nlimitations. MHPP, evaluation pipeline, and leaderboard can be found in\nhttps://github.com/SparksofAGI/MHPP.", "published": "2024-05-19 03:08:02", "link": "http://arxiv.org/abs/2405.11430v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective In-Context Example Selection through Data Compression", "abstract": "In-context learning has been extensively validated in large language models.\nHowever, the mechanism and selection strategy for in-context example selection,\nwhich is a crucial ingredient in this approach, lacks systematic and in-depth\nresearch. In this paper, we propose a data compression approach to the\nselection of in-context examples. We introduce a two-stage method that can\neffectively choose relevant examples and retain sufficient information about\nthe training dataset within the in-context examples. Our method shows a\nsignificant improvement of an average of 5.90% across five different real-world\ndatasets using four language models.", "published": "2024-05-19 06:46:28", "link": "http://arxiv.org/abs/2405.11465v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple-Sampling and Hard-Mixup with Prototypes to Rebalance Contrastive\n  Learning for Text Classification", "abstract": "Text classification is a crucial and fundamental task in natural language\nprocessing. Compared with the previous learning paradigm of pre-training and\nfine-tuning by cross entropy loss, the recently proposed supervised contrastive\nlearning approach has received tremendous attention due to its powerful feature\nlearning capability and robustness. Although several studies have incorporated\nthis technique for text classification, some limitations remain. First, many\ntext datasets are imbalanced, and the learning mechanism of supervised\ncontrastive learning is sensitive to data imbalance, which may harm the model\nperformance. Moreover, these models leverage separate classification branch\nwith cross entropy and supervised contrastive learning branch without explicit\nmutual guidance. To this end, we propose a novel model named SharpReCL for\nimbalanced text classification tasks. First, we obtain the prototype vector of\neach class in the balanced classification branch to act as a representation of\neach class. Then, by further explicitly leveraging the prototype vectors, we\nconstruct a proper and sufficient target sample set with the same size for each\nclass to perform the supervised contrastive learning procedure. The empirical\nresults show the effectiveness of our model, which even outperforms popular\nlarge language models across several datasets.", "published": "2024-05-19 11:33:49", "link": "http://arxiv.org/abs/2405.11524v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Capabilities of Prompted Large Language Models in\n  Educational and Assessment Applications", "abstract": "In the era of generative artificial intelligence (AI), the fusion of large\nlanguage models (LLMs) offers unprecedented opportunities for innovation in the\nfield of modern education. We embark on an exploration of prompted LLMs within\nthe context of educational and assessment applications to uncover their\npotential. Through a series of carefully crafted research questions, we\ninvestigate the effectiveness of prompt-based techniques in generating\nopen-ended questions from school-level textbooks, assess their efficiency in\ngenerating open-ended questions from undergraduate-level technical textbooks,\nand explore the feasibility of employing a chain-of-thought inspired\nmulti-stage prompting approach for language-agnostic multiple-choice question\n(MCQ) generation. Additionally, we evaluate the ability of prompted LLMs for\nlanguage learning, exemplified through a case study in the low-resource Indian\nlanguage Bengali, to explain Bengali grammatical errors. We also evaluate the\npotential of prompted LLMs to assess human resource (HR) spoken interview\ntranscripts. By juxtaposing the capabilities of LLMs with those of human\nexperts across various educational tasks and domains, our aim is to shed light\non the potential and limitations of LLMs in reshaping educational practices.", "published": "2024-05-19 15:13:51", "link": "http://arxiv.org/abs/2405.11579v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoding by Contrasting Knowledge: Enhancing LLMs' Confidence on Edited\n  Facts", "abstract": "The knowledge within large language models (LLMs) may become outdated\nquickly. While in-context editing (ICE) is currently the most effective method\nfor knowledge editing (KE), it is constrained by the black-box modeling of LLMs\nand thus lacks interpretability. Our work aims to elucidate the superior\nperformance of ICE on the KE by analyzing the impacts of in-context new\nknowledge on token-wise distributions. We observe that despite a significant\nboost in logits of the new knowledge, the performance of is still hindered by\nstubborn knowledge. Stubborn knowledge refers to as facts that have gained\nexcessive confidence during pretraining, making it hard to edit effectively. To\naddress this issue and further enhance the performance of ICE, we propose a\nnovel approach termed $\\textbf{De}$coding by $\\textbf{C}$ontrasting\n$\\textbf{K}$nowledge (DeCK). DeCK derives the distribution of the next token by\ncontrasting the logits obtained from the newly edited knowledge guided by ICE\nwith those from the unedited parametric knowledge. Our experiments consistently\ndemonstrate that DeCK enhances the confidence of LLMs in edited facts. For\ninstance, it improves the performance of LLaMA3-8B-instruct on MQuAKE by up to\n219%, demonstrating its capability to strengthen ICE in the editing of stubborn\nknowledge. Our work paves the way to develop the both effective and accountable\nKE methods for LLMs. (The source code is available at:\nhttps://deck-llm.meirtz.com)", "published": "2024-05-19 17:08:31", "link": "http://arxiv.org/abs/2405.11613v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Stance Detection using Contextual Data Generation with LLMs", "abstract": "Stance detection, the classification of attitudes expressed in a text towards\na specific topic, is vital for applications like fake news detection and\nopinion mining. However, the scarcity of labeled data remains a challenge for\nthis task. To address this problem, we propose Dynamic Model Adaptation with\nContextual Data Generation (DyMoAdapt) that combines Few-Shot Learning and\nLarge Language Models. In this approach, we aim to fine-tune an existing model\nat test time. We achieve this by generating new topic-specific data using\nGPT-3. This method could enhance performance by allowing the adaptation of the\nmodel to new topics. However, the results did not increase as we expected.\nFurthermore, we introduce the Multi Generated Topic VAST (MGT-VAST) dataset,\nwhich extends VAST using GPT-3. In this dataset, each context is associated\nwith multiple topics, allowing the model to understand the relationship between\ncontexts and various potential topics", "published": "2024-05-19 17:58:26", "link": "http://arxiv.org/abs/2405.11637v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cyber Risks of Machine Translation Critical Errors : Arabic Mental\n  Health Tweets as a Case Study", "abstract": "With the advent of Neural Machine Translation (NMT) systems, the MT output\nhas reached unprecedented accuracy levels which resulted in the ubiquity of MT\ntools on almost all online platforms with multilingual content. However, NMT\nsystems, like other state-of-the-art AI generative systems, are prone to errors\nthat are deemed machine hallucinations. The problem with NMT hallucinations is\nthat they are remarkably \\textit{fluent} hallucinations. Since they are trained\nto produce grammatically correct utterances, NMT systems are capable of\nproducing mistranslations that are too fluent to be recognised by both users of\nthe MT tool, as well as by automatic quality metrics that are used to gauge\ntheir performance. In this paper, we introduce an authentic dataset of machine\ntranslation critical errors to point to the ethical and safety issues involved\nin the common use of MT. The dataset comprises mistranslations of Arabic mental\nhealth postings manually annotated with critical error types. We also show how\nthe commonly used quality metrics do not penalise critical errors and highlight\nthis as a critical issue that merits further attention from researchers.", "published": "2024-05-19 20:24:51", "link": "http://arxiv.org/abs/2405.11668v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EmbSum: Leveraging the Summarization Capabilities of Large Language\n  Models for Content-Based Recommendations", "abstract": "Content-based recommendation systems play a crucial role in delivering\npersonalized content to users in the digital world. In this work, we introduce\nEmbSum, a novel framework that enables offline pre-computations of users and\ncandidate items while capturing the interactions within the user engagement\nhistory. By utilizing the pretrained encoder-decoder model and poly-attention\nlayers, EmbSum derives User Poly-Embedding (UPE) and Content Poly-Embedding\n(CPE) to calculate relevance scores between users and candidate items. EmbSum\nactively learns the long user engagement histories by generating user-interest\nsummary with supervision from large language model (LLM). The effectiveness of\nEmbSum is validated on two datasets from different domains, surpassing\nstate-of-the-art (SoTA) methods with higher accuracy and fewer parameters.\nAdditionally, the model's ability to generate summaries of user interests\nserves as a valuable by-product, enhancing its usefulness for personalized\ncontent recommendations.", "published": "2024-05-19 04:31:54", "link": "http://arxiv.org/abs/2405.11441v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "MAML-en-LLM: Model Agnostic Meta-Training of LLMs for Improved\n  In-Context Learning", "abstract": "Adapting large language models (LLMs) to unseen tasks with in-context\ntraining samples without fine-tuning remains an important research problem. To\nlearn a robust LLM that adapts well to unseen tasks, multiple meta-training\napproaches have been proposed such as MetaICL and MetaICT, which involve\nmeta-training pre-trained LLMs on a wide variety of diverse tasks. These\nmeta-training approaches essentially perform in-context multi-task fine-tuning\nand evaluate on a disjointed test set of tasks. Even though they achieve\nimpressive performance, their goal is never to compute a truly general set of\nparameters. In this paper, we propose MAML-en-LLM, a novel method for\nmeta-training LLMs, which can learn truly generalizable parameters that not\nonly perform well on disjointed tasks but also adapts to unseen tasks. We see\nan average increase of 2% on unseen domains in the performance while a massive\n4% improvement on adaptation performance. Furthermore, we demonstrate that\nMAML-en-LLM outperforms baselines in settings with limited amount of training\ndata on both seen and unseen domains by an average of 2%. Finally, we discuss\nthe effects of type of tasks, optimizers and task complexity, an avenue barely\nexplored in meta-training literature. Exhaustive experiments across 7 task\nsettings along with two data settings demonstrate that models trained with\nMAML-en-LLM outperform SOTA meta-training approaches.", "published": "2024-05-19 04:49:42", "link": "http://arxiv.org/abs/2405.11446v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MSNER: A Multilingual Speech Dataset for Named Entity Recognition", "abstract": "While extensively explored in text-based tasks, Named Entity Recognition\n(NER) remains largely neglected in spoken language understanding. Existing\nresources are limited to a single, English-only dataset. This paper addresses\nthis gap by introducing MSNER, a freely available, multilingual speech corpus\nannotated with named entities. It provides annotations to the VoxPopuli dataset\nin four languages (Dutch, French, German, and Spanish). We have also releasing\nan efficient annotation tool that leverages automatic pre-annotations for\nfaster manual refinement. This results in 590 and 15 hours of silver-annotated\nspeech for training and validation, alongside a 17-hour, manually-annotated\nevaluation set. We further provide an analysis comparing silver and gold\nannotations. Finally, we present baseline NER models to stimulate further\nresearch on this newly available dataset.", "published": "2024-05-19 11:17:00", "link": "http://arxiv.org/abs/2405.11519v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DaVinci at SemEval-2024 Task 9: Few-shot prompting GPT-3.5 for\n  Unconventional Reasoning", "abstract": "While significant work has been done in the field of NLP on vertical\nthinking, which involves primarily logical thinking, little work has been done\ntowards lateral thinking, which involves looking at problems from an\nunconventional perspective and defying existing conceptions and notions.\nTowards this direction, SemEval 2024 introduces the task of BRAINTEASER, which\ninvolves two types of questions -- Sentence Puzzles and Word Puzzles that defy\nconventional common-sense reasoning and constraints. In this paper, we tackle\nboth types of questions using few-shot prompting on GPT-3.5 and gain insights\nregarding the difference in the nature of the two types. Our prompting strategy\nplaced us 26th on the leaderboard for the Sentence Puzzle and 15th on the Word\nPuzzle task.", "published": "2024-05-19 14:21:53", "link": "http://arxiv.org/abs/2405.11559v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SEEP: Training Dynamics Grounds Latent Representation Search for\n  Mitigating Backdoor Poisoning Attacks", "abstract": "Modern NLP models are often trained on public datasets drawn from diverse\nsources, rendering them vulnerable to data poisoning attacks. These attacks can\nmanipulate the model's behavior in ways engineered by the attacker. One such\ntactic involves the implantation of backdoors, achieved by poisoning specific\ntraining instances with a textual trigger and a target class label. Several\nstrategies have been proposed to mitigate the risks associated with backdoor\nattacks by identifying and removing suspected poisoned examples. However, we\nobserve that these strategies fail to offer effective protection against\nseveral advanced backdoor attacks. To remedy this deficiency, we propose a\nnovel defensive mechanism that first exploits training dynamics to identify\npoisoned samples with high precision, followed by a label propagation step to\nimprove recall and thus remove the majority of poisoned instances. Compared\nwith recent advanced defense methods, our method considerably reduces the\nsuccess rates of several backdoor attacks while maintaining high classification\naccuracy on clean test sets.", "published": "2024-05-19 14:50:09", "link": "http://arxiv.org/abs/2405.11575v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "A Multi-Perspective Analysis of Memorization in Large Language Models", "abstract": "Large Language Models (LLMs), trained on massive corpora with billions of\nparameters, show unprecedented performance in various fields. Though surprised\nby their excellent performances, researchers also noticed some special\nbehaviors of those LLMs. One of those behaviors is memorization, in which LLMs\ncan generate the same content used to train them. Though previous research has\ndiscussed memorization, the memorization of LLMs still lacks explanation,\nespecially the cause of memorization and the dynamics of generating them. In\nthis research, we comprehensively discussed memorization from various\nperspectives and extended the discussion scope to not only just the memorized\ncontent but also less and unmemorized content. Through various studies, we\nfound that: (1) Through experiments, we revealed the relation of memorization\nbetween model size, continuation size, and context size. Further, we showed how\nunmemorized sentences transition to memorized sentences. (2) Through embedding\nanalysis, we showed the distribution and decoding dynamics across model size in\nembedding space for sentences with different memorization scores. The n-gram\nstatistics analysis presents d (3) An analysis over n-gram and entropy decoding\ndynamics discovered a boundary effect when the model starts to generate\nmemorized sentences or unmemorized sentences. (4)We trained a Transformer model\nto predict the memorization of different models, showing that it is possible to\npredict memorizations by context.", "published": "2024-05-19 15:00:50", "link": "http://arxiv.org/abs/2405.11577v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SLAB: Efficient Transformers with Simplified Linear Attention and\n  Progressive Re-parameterized Batch Normalization", "abstract": "Transformers have become foundational architectures for both natural language\nand computer vision tasks. However, the high computational cost makes it quite\nchallenging to deploy on resource-constraint devices. This paper investigates\nthe computational bottleneck modules of efficient transformer, i.e.,\nnormalization layers and attention modules. LayerNorm is commonly used in\ntransformer architectures but is not computational friendly due to statistic\ncalculation during inference. However, replacing LayerNorm with more efficient\nBatchNorm in transformer often leads to inferior performance and collapse in\ntraining. To address this problem, we propose a novel method named PRepBN to\nprogressively replace LayerNorm with re-parameterized BatchNorm in training.\nMoreover, we propose a simplified linear attention (SLA) module that is simple\nyet effective to achieve strong performance. Extensive experiments on image\nclassification as well as object detection demonstrate the effectiveness of our\nproposed method. For example, our SLAB-Swin obtains $83.6\\%$ top-1 accuracy on\nImageNet-1K with $16.2$ms latency, which is $2.4$ms less than that of\nFlatten-Swin with $0.1\\%$ higher accuracy. We also evaluated our method for\nlanguage modeling task and obtain comparable performance and lower\nlatency.Codes are publicly available at https://github.com/xinghaochen/SLAB and\nhttps://github.com/mindspore-lab/models/tree/master/research/huawei-noah/SLAB.", "published": "2024-05-19 15:22:25", "link": "http://arxiv.org/abs/2405.11582v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Language Reconstruction with Brain Predictive Coding from fMRI Data", "abstract": "Many recent studies have shown that the perception of speech can be decoded\nfrom brain signals and subsequently reconstructed as continuous language.\nHowever, there is a lack of neurological basis for how the semantic information\nembedded within brain signals can be used more effectively to guide language\nreconstruction. The theory of predictive coding suggests that human brain\nnaturally engages in continuously predicting future word representations that\nspan multiple timescales. This implies that the decoding of brain signals could\npotentially be associated with a predictable future. To explore the predictive\ncoding theory within the context of language reconstruction, this paper\nproposes a novel model \\textsc{PredFT} for jointly modeling neural decoding and\nbrain prediction. It consists of a main decoding network for language\nreconstruction and a side network for predictive coding. The side network\nobtains brain predictive coding representation from related brain regions of\ninterest with a multi-head self-attention module. This representation is fused\ninto the main decoding network with cross-attention to facilitate the language\nmodels' generation process. Experiments are conducted on the largest\nnaturalistic language comprehension fMRI dataset Narratives. \\textsc{PredFT}\nachieves current state-of-the-art decoding performance with a maximum BLEU-1\nscore of $27.8\\%$.", "published": "2024-05-19 16:06:02", "link": "http://arxiv.org/abs/2405.11597v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Continuous Predictive Modeling of Clinical Notes and ICD Codes in\n  Patient Health Records", "abstract": "Electronic Health Records (EHR) serve as a valuable source of patient\ninformation, offering insights into medical histories, treatments, and\noutcomes. Previous research has developed systems for detecting applicable ICD\ncodes that should be assigned while writing a given EHR document, mainly\nfocusing on discharge summaries written at the end of a hospital stay. In this\nwork, we investigate the potential of predicting these codes for the whole\npatient stay at different time points during their stay, even before they are\nofficially assigned by clinicians. The development of methods to predict\ndiagnoses and treatments earlier in advance could open opportunities for\npredictive medicine, such as identifying disease risks sooner, suggesting\ntreatments, and optimizing resource allocation. Our experiments show that\npredictions regarding final ICD codes can be made already two days after\nadmission and we propose a custom model that improves performance on this early\nprediction task.", "published": "2024-05-19 17:23:04", "link": "http://arxiv.org/abs/2405.11622v2", "categories": ["cs.CL", "cs.LG", "I.2.7; J.3"], "primary_category": "cs.CL"}
{"title": "ColorFoil: Investigating Color Blindness in Large Vision and Language\n  Models", "abstract": "With the utilization of Transformer architecture, large Vision and Language\n(V&L) models have shown promising performance in even zero-shot settings.\nSeveral studies, however, indicate a lack of robustness of the models when\ndealing with complex linguistics and visual attributes. In this work, we\nintroduce a novel V&L benchmark - ColorFoil, by creating color-related foils to\nassess the models' perception ability to detect colors like red, white, green,\netc. We evaluate seven state-of-the-art V&L models including CLIP, ViLT,\nGroupViT, and BridgeTower, etc. in a zero-shot setting and present intriguing\nfindings from the V&L models. The experimental evaluation indicates that ViLT\nand BridgeTower demonstrate much better color perception capabilities compared\nto CLIP and its variants and GroupViT. Moreover, CLIP-based models and GroupViT\nstruggle to distinguish colors that are visually distinct to humans with normal\ncolor perception ability.", "published": "2024-05-19 22:04:57", "link": "http://arxiv.org/abs/2405.11685v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models", "abstract": "The pretrain+fine-tune paradigm is foundational for deploying large language\nmodels (LLMs) across various downstream applications. Within this framework,\nLow-Rank Adaptation (LoRA) stands out for its parameter-efficient fine-tuning\n(PEFT), producing numerous reusable task-specific LoRA adapters. However, this\napproach requires explicit task intention selection, posing challenges for\nautonomous task sensing and switching during inference with multiple existing\nLoRA adapters embedded in a single LLM. In this work, we introduce MeteoRA\n(Multiple-tasks embedded LoRA), a scalable and efficient framework that reuses\nmultiple task-specific LoRA adapters into the base LLM via a full-mode\nMixture-of-Experts (MoE) architecture. This framework also includes novel MoE\nforward acceleration strategies to address the efficiency challenges of\ntraditional MoE implementations. Our evaluation, using the LlaMA2-13B and\nLlaMA3-8B base models equipped with 28 existing LoRA adapters through MeteoRA,\ndemonstrates equivalent performance with the traditional PEFT method. Moreover,\nthe LLM equipped with MeteoRA achieves superior performance in handling\ncomposite tasks, effectively solving ten sequential problems in a single\ninference pass, thereby demonstrating the framework's enhanced capability for\ntimely adapter switching.", "published": "2024-05-19 20:46:07", "link": "http://arxiv.org/abs/2405.13053v3", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Large Language Models are Biased Reinforcement Learners", "abstract": "In-context learning enables large language models (LLMs) to perform a variety\nof tasks, including learning to make reward-maximizing choices in simple bandit\ntasks. Given their potential use as (autonomous) decision-making agents, it is\nimportant to understand how these models perform such reinforcement learning\n(RL) tasks and the extent to which they are susceptible to biases. Motivated by\nthe fact that, in humans, it has been widely documented that the value of an\noutcome depends on how it compares to other local outcomes, the present study\nfocuses on whether similar value encoding biases apply to how LLMs encode\nrewarding outcomes. Results from experiments with multiple bandit tasks and\nmodels show that LLMs exhibit behavioral signatures of a relative value bias.\nAdding explicit outcome comparisons to the prompt produces opposing effects on\nperformance, enhancing maximization in trained choice sets but impairing\ngeneralization to new choice sets. Computational cognitive modeling reveals\nthat LLM behavior is well-described by a simple RL algorithm that incorporates\nrelative values at the outcome encoding stage. Lastly, we present preliminary\nevidence that the observed biases are not limited to fine-tuned LLMs, and that\nrelative value processing is detectable in the final hidden layer activations\nof a raw, pretrained model. These findings have important implications for the\nuse of LLMs in decision-making applications.", "published": "2024-05-19 01:43:52", "link": "http://arxiv.org/abs/2405.11422v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Metric Dimension and Resolvability of Jaccard Spaces", "abstract": "A subset of points in a metric space is said to resolve it if each point in\nthe space is uniquely characterized by its distance to each point in the\nsubset. In particular, resolving sets can be used to represent points in\nabstract metric spaces as Euclidean vectors. Importantly, due to the triangle\ninequality, points close by in the space are represented as vectors with\nsimilar coordinates, which may find applications in classification problems of\nsymbolic objects under suitably chosen metrics. In this manuscript, we address\nthe resolvability of Jaccard spaces, i.e., metric spaces of the form\n$(2^X,\\text{Jac})$, where $2^X$ is the power set of a finite set $X$, and\n$\\text{Jac}$ is the Jaccard distance between subsets of $X$. Specifically, for\ndifferent $a,b\\in 2^X$, $\\text{Jac}(a,b)=|a\\Delta b|/|a\\cup b|$, where\n$|\\cdot|$ denotes size (i.e., cardinality) and $\\Delta$ denotes the symmetric\ndifference of sets. We combine probabilistic and linear algebra arguments to\nconstruct highly likely but nearly optimal (i.e., of minimal size) resolving\nsets of $(2^X,\\text{Jac})$. In particular, we show that the metric dimension of\n$(2^X,\\text{Jac})$, i.e., the minimum size of a resolving set of this space, is\n$\\Theta(|X|/\\ln|X|)$. In addition, we show that a much smaller subset of $2^X$\nsuffices to resolve, with high probability, all different pairs of subsets of\n$X$ of cardinality at most $\\sqrt{|X|}/\\ln|X|$, up to a factor.", "published": "2024-05-19 02:09:50", "link": "http://arxiv.org/abs/2405.11424v2", "categories": ["cs.DM", "cs.CL", "math.CO", "math.PR", "05C12, 60C05, 68R05, 68R12, 46B85, 33D90, 68T50", "G.2; G.3; E.4; G.2.1; G.2.2"], "primary_category": "cs.DM"}
{"title": "Du-IN: Discrete units-guided mask modeling for decoding speech from\n  Intracranial Neural signals", "abstract": "Invasive brain-computer interfaces with Electrocorticography (ECoG) have\nshown promise for high-performance speech decoding in medical applications, but\nless damaging methods like intracranial stereo-electroencephalography (sEEG)\nremain underexplored. With rapid advances in representation learning,\nleveraging abundant recordings to enhance speech decoding is increasingly\nattractive. However, popular methods often pre-train temporal models based on\nbrain-level tokens, overlooking that brain activities in different regions are\nhighly desynchronized during tasks. Alternatively, they pre-train\nspatial-temporal models based on channel-level tokens but fail to evaluate them\non challenging tasks like speech decoding, which requires intricate processing\nin specific language-related areas. To address this issue, we collected a\nwell-annotated Chinese word-reading sEEG dataset targeting language-related\nbrain networks from 12 subjects. Using this benchmark, we developed the Du-IN\nmodel, which extracts contextual embeddings based on region-level tokens\nthrough discrete codex-guided mask modeling. Our model achieves\nstate-of-the-art performance on the 61-word classification task, surpassing all\nbaselines. Model comparisons and ablation studies reveal that our design\nchoices, including (i) temporal modeling based on region-level tokens by\nutilizing 1D depthwise convolution to fuse channels in the ventral sensorimotor\ncortex (vSMC) and superior temporal gyrus (STG) and (ii) self-supervision\nthrough discrete codex-guided mask modeling, significantly contribute to this\nperformance. Overall, our approach -- inspired by neuroscience findings and\ncapitalizing on region-level representations from specific brain regions -- is\nsuitable for invasive brain modeling and represents a promising neuro-inspired\nAI approach in brain-computer interfaces.", "published": "2024-05-19 06:00:36", "link": "http://arxiv.org/abs/2405.11459v3", "categories": ["eess.SP", "cs.CL", "q-bio.NC"], "primary_category": "eess.SP"}
{"title": "DocReLM: Mastering Document Retrieval with Language Model", "abstract": "With over 200 million published academic documents and millions of new\ndocuments being written each year, academic researchers face the challenge of\nsearching for information within this vast corpus. However, existing retrieval\nsystems struggle to understand the semantics and domain knowledge present in\nacademic papers. In this work, we demonstrate that by utilizing large language\nmodels, a document retrieval system can achieve advanced semantic understanding\ncapabilities, significantly outperforming existing systems. Our approach\ninvolves training the retriever and reranker using domain-specific data\ngenerated by large language models. Additionally, we utilize large language\nmodels to identify candidates from the references of retrieved papers to\nfurther enhance the performance. We use a test set annotated by academic\nresearchers in the fields of quantum physics and computer vision to evaluate\nour system's performance. The results show that DocReLM achieves a Top 10\naccuracy of 44.12% in computer vision, compared to Google Scholar's 15.69%, and\nan increase to 36.21% in quantum physics, while that of Google Scholar is\n12.96%.", "published": "2024-05-19 06:30:22", "link": "http://arxiv.org/abs/2405.11461v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion", "abstract": "Prompt tuning is a promising method to fine-tune a pre-trained language model\nwithout retraining its large-scale parameters. Instead, it attaches a soft\nprompt to the input text, whereby downstream tasks can be well adapted by\nmerely learning the embeddings of prompt tokens. Nevertheless, existing methods\nstill suffer from two challenges: (i) they are hard to balance accuracy and\nefficiency. A longer (shorter) soft prompt generally leads to a better(worse)\naccuracy but at the cost of more (less) training time. (ii)The performance may\nnot be consistent when adapting to different downstream tasks. We attribute it\nto the same embedding space but responsible for different requirements of\ndownstream tasks. To address these issues, we propose an Efficient Prompt\nTuning method (EPT) by multi-space projection and prompt fusion. Specifically,\nit decomposes a given soft prompt into a shorter prompt and two low-rank\nmatrices, significantly reducing the training time. Accuracy is also enhanced\nby leveraging low-rank matrices and the short prompt as additional knowledge\nsources to enrich the semantics of the original short prompt. In addition, we\nproject the soft prompt into multiple subspaces to improve the performance\nconsistency, and then adaptively learn the combination weights of different\nspaces through a gating network. Experiments on 13 natural language processing\ndownstream tasks show that our method significantly and consistently\noutperforms 11 comparison methods with the relative percentage of improvements\nup to 12.9%, and training time decreased by 14%.", "published": "2024-05-19 06:43:12", "link": "http://arxiv.org/abs/2405.11464v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Inquire, Interact, and Integrate: A Proactive Agent Collaborative\n  Framework for Zero-Shot Multimodal Medical Reasoning", "abstract": "The adoption of large language models (LLMs) in healthcare has attracted\nsignificant research interest. However, their performance in healthcare remains\nunder-investigated and potentially limited, due to i) they lack rich\ndomain-specific knowledge and medical reasoning skills; and ii) most\nstate-of-the-art LLMs are unimodal, text-only models that cannot directly\nprocess multimodal inputs. To this end, we propose a multimodal medical\ncollaborative reasoning framework \\textbf{MultiMedRes}, which incorporates a\nlearner agent to proactively gain essential information from domain-specific\nexpert models, to solve medical multimodal reasoning problems. Our method\nincludes three steps: i) \\textbf{Inquire}: The learner agent first decomposes\ngiven complex medical reasoning problems into multiple domain-specific\nsub-problems; ii) \\textbf{Interact}: The agent then interacts with\ndomain-specific expert models by repeating the ``ask-answer'' process to\nprogressively obtain different domain-specific knowledge; iii)\n\\textbf{Integrate}: The agent finally integrates all the acquired\ndomain-specific knowledge to accurately address the medical reasoning problem.\nWe validate the effectiveness of our method on the task of difference visual\nquestion answering for X-ray images. The experiments demonstrate that our\nzero-shot prediction achieves state-of-the-art performance, and even\noutperforms the fully supervised methods. Besides, our approach can be\nincorporated into various LLMs and multimodal LLMs to significantly boost their\nperformance.", "published": "2024-05-19 18:26:11", "link": "http://arxiv.org/abs/2405.11640v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Your Transformer is Secretly Linear", "abstract": "This paper reveals a novel linear characteristic exclusive to transformer\ndecoders, including models such as GPT, LLaMA, OPT, BLOOM and others. We\nanalyze embedding transformations between sequential layers, uncovering a\nnear-perfect linear relationship (Procrustes similarity score of 0.99).\nHowever, linearity decreases when the residual component is removed due to a\nconsistently low output norm of the transformer layer. Our experiments show\nthat removing or linearly approximating some of the most linear blocks of\ntransformers does not affect significantly the loss or model performance.\nMoreover, in our pretraining experiments on smaller models we introduce a\ncosine-similarity-based regularization, aimed at reducing layer linearity. This\nregularization improves performance metrics on benchmarks like Tiny Stories and\nSuperGLUE and as well successfully decreases the linearity of the models. This\nstudy challenges the existing understanding of transformer architectures,\nsuggesting that their operation may be more linear than previously assumed.", "published": "2024-05-19 22:44:00", "link": "http://arxiv.org/abs/2405.12250v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SemEval-2024 Task 3: Multimodal Emotion Cause Analysis in Conversations", "abstract": "The ability to understand emotions is an essential component of human-like\nartificial intelligence, as emotions greatly influence human cognition,\ndecision making, and social interactions. In addition to emotion recognition in\nconversations, the task of identifying the potential causes behind an\nindividual's emotional state in conversations, is of great importance in many\napplication scenarios. We organize SemEval-2024 Task 3, named Multimodal\nEmotion Cause Analysis in Conversations, which aims at extracting all pairs of\nemotions and their corresponding causes from conversations. Under different\nmodality settings, it consists of two subtasks: Textual Emotion-Cause Pair\nExtraction in Conversations (TECPE) and Multimodal Emotion-Cause Pair\nExtraction in Conversations (MECPE). The shared task has attracted 143\nregistrations and 216 successful submissions. In this paper, we introduce the\ntask, dataset and evaluation settings, summarize the systems of the top teams,\nand discuss the findings of the participants.", "published": "2024-05-19 09:59:00", "link": "http://arxiv.org/abs/2405.13049v3", "categories": ["cs.CL", "cs.AI", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Large Language Models Can Infer Personality from Free-Form User\n  Interactions", "abstract": "This study investigates the capacity of Large Language Models (LLMs) to infer\nthe Big Five personality traits from free-form user interactions. The results\ndemonstrate that a chatbot powered by GPT-4 can infer personality with moderate\naccuracy, outperforming previous approaches drawing inferences from static text\ncontent. The accuracy of inferences varied across different conversational\nsettings. Performance was highest when the chatbot was prompted to elicit\npersonality-relevant information from users (mean r=.443, range=[.245, .640]),\nfollowed by a condition placing greater emphasis on naturalistic interaction\n(mean r=.218, range=[.066, .373]). Notably, the direct focus on personality\nassessment did not result in a less positive user experience, with participants\nreporting the interactions to be equally natural, pleasant, engaging, and\nhumanlike across both conditions. A chatbot mimicking ChatGPT's default\nbehavior of acting as a helpful assistant led to markedly inferior personality\ninferences and lower user experience ratings but still captured psychologically\nmeaningful information for some of the personality traits (mean r=.117,\nrange=[-.004, .209]). Preliminary analyses suggest that the accuracy of\npersonality inferences varies only marginally across different\nsocio-demographic subgroups. Our results highlight the potential of LLMs for\npsychological profiling based on conversational interactions. We discuss\npractical implications and ethical challenges associated with these findings.", "published": "2024-05-19 20:33:36", "link": "http://arxiv.org/abs/2405.13052v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Speech-dependent Data Augmentation for Own Voice Reconstruction with\n  Hearable Microphones in Noisy Environments", "abstract": "Own voice pickup for hearables in noisy environments benefits from using both\nan outer and an in-ear microphone outside and inside the occluded ear. Due to\nenvironmental noise recorded at both microphones, and amplification of the own\nvoice at low frequencies and band-limitation at the in-ear microphone, an own\nvoice reconstruction system is needed to enable communication. A large amount\nof own voice signals is required to train a supervised deep learning-based own\nvoice reconstruction system. Training data can either be obtained by recording\na large amount of own voice signals of different talkers with a specific\ndevice, which is costly, or through augmentation of available speech data. Own\nvoice signals can be simulated by assuming a linear time-invariant relative\ntransfer function between hearable microphones for each phoneme, referred to as\nown voice transfer characteristics. In this paper, we propose data augmentation\ntechniques for training an own voice reconstruction system based on\nspeech-dependent models of own voice transfer characteristics between hearable\nmicrophones. The proposed techniques use few recorded own voice signals to\nestimate transfer characteristics and can then be used to simulate a large\namount of own voice signals based on single-channel speech signals.\nExperimental results show that the proposed speech-dependent individual data\naugmentation technique leads to better performance compared to other data\naugmentation techniques or compared to training only on the available recorded\nown voice signals, and additional fine-tuning on the available recorded signals\ncan improve performance further.", "published": "2024-05-19 15:56:03", "link": "http://arxiv.org/abs/2405.11592v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "DAC-JAX: A JAX Implementation of the Descript Audio Codec", "abstract": "We present an open-source implementation of the Descript Audio Codec (DAC)\nusing Google's JAX ecosystem of Flax, Optax, Orbax, AUX, and CLU. Our codebase\nenables the reuse of model weights from the original PyTorch DAC, and we\nconfirm that the two implementations produce equivalent token sequences and\ndecoded audio if given the same input. We provide a training and fine-tuning\nscript which supports device parallelism, although we have only verified it\nusing brief training runs with a small dataset. Even with limited GPU memory,\nthe original DAC can compress or decompress a long audio file by processing it\nas a sequence of overlapping \"chunks.\" We implement this feature in JAX and\nbenchmark the performance on two types of GPUs. On a consumer-grade GPU,\nDAC-JAX outperforms the original DAC for compression and decompression at all\nchunk sizes. However, on a high-performance, cluster-based GPU, DAC-JAX\noutperforms the original DAC for small chunk sizes but performs worse for large\nchunks.", "published": "2024-05-19 14:07:31", "link": "http://arxiv.org/abs/2405.11554v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
