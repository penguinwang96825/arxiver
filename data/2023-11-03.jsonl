{"title": "CASE: Commonsense-Augmented Score with an Expanded Answer Space", "abstract": "LLMs have demonstrated impressive zero-shot performance on NLP tasks thanks\nto the knowledge they acquired in their training. In multiple-choice QA tasks,\nthe LM probabilities are used as an imperfect measure of the plausibility of\neach answer choice. One of the major limitations of the basic score is that it\ntreats all words as equally important. We propose CASE, a Commonsense-Augmented\nScore with an Expanded Answer Space. CASE addresses this limitation by\nassigning importance weights for individual words based on their semantic\nrelations to other words in the input. The dynamic weighting approach\noutperforms basic LM scores, not only because it reduces noise from unimportant\nwords, but also because it informs the model of implicit commonsense knowledge\nthat may be useful for answering the question. We then also follow prior work\nin expanding the answer space by generating lexically-divergent answers that\nare conceptually-similar to the choices. When combined with answer space\nexpansion, our method outperforms strong baselines on 5 commonsense benchmarks.\nWe further show these two approaches are complementary and may be especially\nbeneficial when using smaller LMs.", "published": "2023-11-03 03:15:26", "link": "http://arxiv.org/abs/2311.01684v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New Korean Text Classification Benchmark for Recognizing the Political\n  Intents in Online Newspapers", "abstract": "Many users reading online articles in various magazines may suffer\nconsiderable difficulty in distinguishing the implicit intents in texts. In\nthis work, we focus on automatically recognizing the political intents of a\ngiven online newspaper by understanding the context of the text. To solve this\ntask, we present a novel Korean text classification dataset that contains\nvarious articles. We also provide deep-learning-based text classification\nbaseline models trained on the proposed dataset. Our dataset contains 12,000\nnews articles that may contain political intentions, from the politics section\nof six of the most representative newspaper organizations in South Korea. All\nthe text samples are labeled simultaneously in two aspects (1) the level of\npolitical orientation and (2) the level of pro-government. To the best of our\nknowledge, our paper is the most large-scale Korean news dataset that contains\nlong text and addresses multi-task classification problems. We also train\nrecent state-of-the-art (SOTA) language models that are based on transformer\narchitectures and demonstrate that the trained models show decent text\nclassification performance. All the codes, datasets, and trained models are\navailable at https://github.com/Kdavid2355/KoPolitic-Benchmark-Dataset.", "published": "2023-11-03 04:59:55", "link": "http://arxiv.org/abs/2311.01712v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Proto-lm: A Prototypical Network-Based Framework for Built-in\n  Interpretability in Large Language Models", "abstract": "Large Language Models (LLMs) have significantly advanced the field of Natural\nLanguage Processing (NLP), but their lack of interpretability has been a major\nconcern. Current methods for interpreting LLMs are post hoc, applied after\ninference time, and have limitations such as their focus on low-level features\nand lack of explainability at higher level text units. In this work, we\nintroduce proto-lm, a prototypical network-based white-box framework that\nallows LLMs to learn immediately interpretable embeddings during the\nfine-tuning stage while maintaining competitive performance. Our method's\napplicability and interpretability are demonstrated through experiments on a\nwide range of NLP tasks, and our results indicate a new possibility of creating\ninterpretable models without sacrificing performance. This novel approach to\ninterpretability in LLMs can pave the way for more interpretable models without\nthe need to sacrifice performance.", "published": "2023-11-03 05:55:32", "link": "http://arxiv.org/abs/2311.01732v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SAC3: Reliable Hallucination Detection in Black-Box Language Models via\n  Semantic-aware Cross-check Consistency", "abstract": "Hallucination detection is a critical step toward understanding the\ntrustworthiness of modern language models (LMs). To achieve this goal, we\nre-examine existing detection approaches based on the self-consistency of LMs\nand uncover two types of hallucinations resulting from 1) question-level and 2)\nmodel-level, which cannot be effectively identified through self-consistency\ncheck alone. Building upon this discovery, we propose a novel sampling-based\nmethod, i.e., semantic-aware cross-check consistency (SAC3) that expands on the\nprinciple of self-consistency checking. Our SAC3 approach incorporates\nadditional mechanisms to detect both question-level and model-level\nhallucinations by leveraging advances including semantically equivalent\nquestion perturbation and cross-model response consistency checking. Through\nextensive and systematic empirical analysis, we demonstrate that SAC3\noutperforms the state of the art in detecting both non-factual and factual\nstatements across multiple question-answering and open-domain generation\nbenchmarks.", "published": "2023-11-03 06:32:43", "link": "http://arxiv.org/abs/2311.01740v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EmojiLM: Modeling the New Emoji Language", "abstract": "With the rapid development of the internet, online social media welcomes\npeople with different backgrounds through its diverse content. The increasing\nusage of emoji becomes a noticeable trend thanks to emoji's rich information\nbeyond cultural or linguistic borders. However, the current study on emojis is\nlimited to single emoji prediction and there are limited data resources\navailable for further study of the interesting linguistic phenomenon. To this\nend, we synthesize a large text-emoji parallel corpus, Text2Emoji, from a large\nlanguage model. Based on the parallel corpus, we distill a sequence-to-sequence\nmodel, EmojiLM, which is specialized in the text-emoji bidirectional\ntranslation. Extensive experiments on public benchmarks and human evaluation\ndemonstrate that our proposed model outperforms strong baselines and the\nparallel corpus benefits emoji-related downstream tasks.", "published": "2023-11-03 07:06:51", "link": "http://arxiv.org/abs/2311.01751v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PPTC Benchmark: Evaluating Large Language Models for PowerPoint Task\n  Completion", "abstract": "Recent evaluations of Large Language Models (LLMs) have centered around\ntesting their zero-shot/few-shot capabilities for basic natural language tasks\nand their ability to translate instructions into tool APIs. However, the\nevaluation of LLMs utilizing complex tools to finish multi-turn, multi-modal\ninstructions in a complex multi-modal environment has not been investigated. To\naddress this gap, we introduce the PowerPoint Task Completion (PPTC) benchmark\nto assess LLMs' ability to create and edit PPT files based on user\ninstructions. It contains 279 multi-turn sessions covering diverse topics and\nhundreds of instructions involving multi-modal operations. We also propose the\nPPTX-Match Evaluation System that evaluates if LLMs finish the instruction\nbased on the prediction file rather than the label API sequence, thus it\nsupports various LLM-generated API sequences. We measure 3 closed LLMs and 6\nopen-source LLMs. The results show that GPT-4 outperforms other LLMs with\n75.1\\% accuracy in single-turn dialogue testing but faces challenges in\ncompleting entire sessions, achieving just 6\\% session accuracy. We find three\nmain error causes in our benchmark: error accumulation in the multi-turn\nsession, long PPT template processing, and multi-modality perception. These\npose great challenges for future LLM and agent systems. We release the data,\ncode, and evaluation system of PPTC at \\url{https://github.com/gydpku/PPTC}.", "published": "2023-11-03 08:06:35", "link": "http://arxiv.org/abs/2311.01767v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UP4LS: User Profile Constructed by Multiple Attributes for Enhancing\n  Linguistic Steganalysis", "abstract": "Linguistic steganalysis (LS) tasks aim to detect whether a text contains\nsecret information. Existing LS methods focus on the deep-learning model design\nand they achieve excellent results in ideal data. However, they overlook the\nunique user characteristics, leading to weak performance in social networks.\nAnd a few stegos here that further complicate detection. We propose the UP4LS,\na framework with the User Profile for enhancing LS in realistic scenarios.\nThree kinds of user attributes like writing habits are explored to build the\nprofile. For each attribute, the specific feature extraction module is\ndesigned. The extracted features are mapped to high-dimensional user features\nvia the deep-learning model of the method to be improved. The content feature\nis extracted by the language model. Then user and content features are\nintegrated. Existing methods can improve LS results by adding the UP4LS\nframework without changing their deep-learning models. Experiments show that\nUP4LS can significantly enhance the performance of LS-task baselines in\nrealistic scenarios, with the overall Acc increased by 25%, F1 increased by\n51%, and SOTA results. The improvement is especially pronounced in fewer\nstegos. Additionally, UP4LS also sets the stage for the related-task SOTA\nmethods to efficient LS.", "published": "2023-11-03 08:20:48", "link": "http://arxiv.org/abs/2311.01775v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Framing Bias with Polarity Minimization Loss", "abstract": "Framing bias plays a significant role in exacerbating political polarization\nby distorting the perception of actual events. Media outlets with divergent\npolitical stances often use polarized language in their reporting of the same\nevent. We propose a new loss function that encourages the model to minimize the\npolarity difference between the polarized input articles to reduce framing\nbias. Specifically, our loss is designed to jointly optimize the model to map\npolarity ends bidirectionally. Our experimental results demonstrate that\nincorporating the proposed polarity minimization loss leads to a substantial\nreduction in framing bias when compared to a BART-based multi-document\nsummarization model. Notably, we find that the effectiveness of this approach\nis most pronounced when the model is trained to minimize the polarity loss\nassociated with informational framing bias (i.e., skewed selection of\ninformation to report).", "published": "2023-11-03 09:50:23", "link": "http://arxiv.org/abs/2311.01817v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Minimalist Grammar: Construction without Overgeneration", "abstract": "In this paper we give instructions on how to write a minimalist grammar (MG).\nIn order to present the instructions as an algorithm, we use a variant of\ncontext free grammars (CFG) as an input format. We can exclude overgeneration,\nif the CFG has no recursion, i.e. no non-terminal can (indirectly) derive to a\nright-hand side containing itself. The constructed MGs utilize licensors/-ees\nas a special way of exception handling. A CFG format for a derivation\n$A\\_eats\\_B\\mapsto^* peter\\_eats\\_apples$, where $A$ and $B$ generate noun\nphrases, normally leads to overgeneration, e.\\,g., $i\\_eats\\_apples$. In order\nto avoid overgeneration, a CFG would need many non-terminal symbols and rules,\nthat mainly produce the same word, just to handle exceptions. In our MGs\nhowever, we can summarize CFG rules that produce the same word in one item and\nhandle exceptions by a proper distribution of licensees/-ors. The difficulty\nwith this technique is that in most generations the majority of licensees/-ors\nis not needed, but still has to be triggered somehow. We solve this problem\nwith $\\epsilon$-items called \\emph{adapters}.", "published": "2023-11-03 10:02:00", "link": "http://arxiv.org/abs/2311.01820v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Black-Box Adversarial Attacks on Neural Text Detectors", "abstract": "Neural text detectors are models trained to detect whether a given text was\ngenerated by a language model or written by a human. In this paper, we\ninvestigate three simple and resource-efficient strategies (parameter tweaking,\nprompt engineering, and character-level mutations) to alter texts generated by\nGPT-3.5 that are unsuspicious or unnoticeable for humans but cause\nmisclassification by neural text detectors. The results show that especially\nparameter tweaking and character-level mutations are effective strategies.", "published": "2023-11-03 12:29:32", "link": "http://arxiv.org/abs/2311.01873v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis through LLM Negotiations", "abstract": "A standard paradigm for sentiment analysis is to rely on a singular LLM and\nmakes the decision in a single round under the framework of in-context\nlearning. This framework suffers the key disadvantage that the single-turn\noutput generated by a single LLM might not deliver the perfect decision, just\nas humans sometimes need multiple attempts to get things right. This is\nespecially true for the task of sentiment analysis where deep reasoning is\nrequired to address the complex linguistic phenomenon (e.g., clause\ncomposition, irony, etc) in the input.\n  To address this issue, this paper introduces a multi-LLM negotiation\nframework for sentiment analysis. The framework consists of a reasoning-infused\ngenerator to provide decision along with rationale, a explanation-deriving\ndiscriminator to evaluate the credibility of the generator. The generator and\nthe discriminator iterate until a consensus is reached. The proposed framework\nnaturally addressed the aforementioned challenge, as we are able to take the\ncomplementary abilities of two LLMs, have them use rationale to persuade each\nother for correction.\n  Experiments on a wide range of sentiment analysis benchmarks (SST-2, Movie\nReview, Twitter, yelp, amazon, IMDB) demonstrate the effectiveness of proposed\napproach: it consistently yields better performances than the ICL baseline\nacross all benchmarks, and even superior performances to supervised baselines\non the Twitter and movie review datasets.", "published": "2023-11-03 12:35:29", "link": "http://arxiv.org/abs/2311.01876v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Indicative Summarization of Long Discussions", "abstract": "Online forums encourage the exchange and discussion of different stances on\nmany topics. Not only do they provide an opportunity to present one's own\narguments, but may also gather a broad cross-section of others' arguments.\nHowever, the resulting long discussions are difficult to overview. This paper\npresents a novel unsupervised approach using large language models (LLMs) to\ngenerating indicative summaries for long discussions that basically serve as\ntables of contents. Our approach first clusters argument sentences, generates\ncluster labels as abstractive summaries, and classifies the generated cluster\nlabels into argumentation frames resulting in a two-level summary. Based on an\nextensively optimized prompt engineering approach, we evaluate 19~LLMs for\ngenerative cluster labeling and frame classification. To evaluate the\nusefulness of our indicative summaries, we conduct a purpose-driven user study\nvia a new visual interface called Discussion Explorer: It shows that our\nproposed indicative summaries serve as a convenient navigation tool to explore\nlong discussions.", "published": "2023-11-03 12:44:59", "link": "http://arxiv.org/abs/2311.01882v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BoschAI @ PLABA 2023: Leveraging Edit Operations in End-to-End Neural\n  Sentence Simplification", "abstract": "Automatic simplification can help laypeople to comprehend complex scientific\ntext. Language models are frequently applied to this task by translating from\ncomplex to simple language. In this paper, we describe our system based on\nLlama 2, which ranked first in the PLABA shared task addressing the\nsimplification of biomedical text. We find that the large portion of shared\ntokens between input and output leads to weak training signals and\nconservatively editing models. To mitigate these issues, we propose\nsentence-level and token-level loss weights. They give higher weight to\nmodified tokens, indicated by edit distance and edit operations, respectively.\nWe conduct an empirical evaluation on the PLABA dataset and find that both\napproaches lead to simplifications closer to those created by human annotators\n(+1.8% / +3.5% SARI), simpler language (-1 / -1.1 FKGL) and more edits (1.6x /\n1.8x edit distance) compared to the same model fine-tuned with standard cross\nentropy. We furthermore show that the hyperparameter $\\lambda$ in token-level\nloss weights can be used to control the edit distance and the simplicity level\n(FKGL).", "published": "2023-11-03 13:34:08", "link": "http://arxiv.org/abs/2311.01907v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Constructing Temporal Dynamic Knowledge Graphs from Interactive\n  Text-based Games", "abstract": "In natural language processing, interactive text-based games serve as a test\nbed for interactive AI systems. Prior work has proposed to play text-based\ngames by acting based on discrete knowledge graphs constructed by the Discrete\nGraph Updater (DGU) to represent the game state from the natural language\ndescription. While DGU has shown promising results with high interpretability,\nit suffers from lower knowledge graph accuracy due to its lack of temporality\nand limited generalizability to complex environments with objects with the same\nlabel. In order to address DGU's weaknesses while preserving its high\ninterpretability, we propose the Temporal Discrete Graph Updater (TDGU), a\nnovel neural network model that represents dynamic knowledge graphs as a\nsequence of timestamped graph events and models them using a temporal point\nbased graph neural network. Through experiments on the dataset collected from a\ntext-based game TextWorld, we show that TDGU outperforms the baseline DGU. We\nfurther show the importance of temporal information for TDGU's performance\nthrough an ablation study and demonstrate that TDGU has the ability to\ngeneralize to more complex environments with objects with the same label. All\nthe relevant code can be found at\n\\url{https://github.com/yukw777/temporal-discrete-graph-updater}.", "published": "2023-11-03 14:09:31", "link": "http://arxiv.org/abs/2311.01928v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hint-enhanced In-Context Learning wakes Large Language Models up for\n  knowledge-intensive tasks", "abstract": "In-context learning (ICL) ability has emerged with the increasing scale of\nlarge language models (LLMs), enabling them to learn input-label mappings from\ndemonstrations and perform well on downstream tasks. However, under the\nstandard ICL setting, LLMs may sometimes neglect query-related information in\ndemonstrations, leading to incorrect predictions. To address this limitation,\nwe propose a new paradigm called Hint-enhanced In-Context Learning (HICL) to\nexplore the power of ICL in open-domain question answering, an important form\nin knowledge-intensive tasks. HICL leverages LLMs' reasoning ability to extract\nquery-related knowledge from demonstrations, then concatenates the knowledge to\nprompt LLMs in a more explicit way. Furthermore, we track the source of this\nknowledge to identify specific examples, and introduce a Hint-related Example\nRetriever (HER) to select informative examples for enhanced demonstrations. We\nevaluate HICL with HER on 3 open-domain QA benchmarks, and observe average\nperformance gains of 2.89 EM score and 2.52 F1 score on gpt-3.5-turbo, 7.62 EM\nscore and 7.27 F1 score on LLaMA-2-Chat-7B compared with standard setting.", "published": "2023-11-03 14:39:20", "link": "http://arxiv.org/abs/2311.01949v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Too Much Information: Keeping Training Simple for BabyLMs", "abstract": "This paper details the work of the University of Groningen for the BabyLM\nChallenge. We follow the idea that, like babies, language models should be\nintroduced to simpler concepts first and build off of that knowledge to\nunderstand more complex concepts. We examine this strategy of\nsimple-then-complex through a variety of lenses, namely context size,\nvocabulary, and overall linguistic complexity of the data. We find that only\none, context size, is truly beneficial to training a language model. However\nthis simple change to context size gives us improvements of 2 points on average\non (Super)GLUE tasks, 1 point on MSGS tasks, and 12\\% on average on BLiMP\ntasks. Our context-limited model outperforms the baseline that was trained on\n10$\\times$ the amount of data.", "published": "2023-11-03 14:50:00", "link": "http://arxiv.org/abs/2311.01955v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProSG: Using Prompt Synthetic Gradients to Alleviate Prompt Forgetting\n  of RNN-like Language Models", "abstract": "RNN-like language models are getting renewed attention from NLP researchers\nin recent years and several models have made significant progress, which\ndemonstrates performance comparable to traditional transformers. However, due\nto the recurrent nature of RNNs, this kind of language model can only store\ninformation in a set of fixed-length state vectors. As a consequence, they\nstill suffer from forgetfulness though after a lot of improvements and\noptimizations, when given complex instructions or prompts. As the prompted\ngeneration is the main and most concerned function of LMs, solving the problem\nof forgetting in the process of generation is no wonder of vital importance. In\nthis paper, focusing on easing the prompt forgetting during generation, we\nproposed an architecture to teach the model memorizing prompt during generation\nby synthetic gradient. To force the model to memorize the prompt, we derive the\nstates that encode the prompt, then transform it into model parameter\nmodification using low-rank gradient approximation, which hard-codes the prompt\ninto model parameters temporarily. We construct a dataset for experiments, and\nthe results have demonstrated the effectiveness of our method in solving the\nproblem of forgetfulness in the process of prompted generation. We will release\nall the code upon acceptance.", "published": "2023-11-03 15:34:02", "link": "http://arxiv.org/abs/2311.01981v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive\n  Language Detection", "abstract": "Cross-lingual transfer learning from high-resource to medium and low-resource\nlanguages has shown encouraging results. However, the scarcity of resources in\ntarget languages remains a challenge. In this work, we resort to data\naugmentation and continual pre-training for domain adaptation to improve\ncross-lingual abusive language detection. For data augmentation, we analyze two\nexisting techniques based on vicinal risk minimization and propose MIXAG, a\nnovel data augmentation method which interpolates pairs of instances based on\nthe angle of their representations. Our experiments involve seven languages\ntypologically distinct from English and three different domains. The results\nreveal that the data augmentation strategies can enhance few-shot cross-lingual\nabusive language detection. Specifically, we observe that consistently in all\ntarget languages, MIXAG improves significantly in multidomain and multilingual\nenvironments. Finally, we show through an error analysis how the domain\nadaptation can favour the class of abusive texts (reducing false negatives),\nbut at the same time, declines the precision of the abusive language detection\nmodel.", "published": "2023-11-03 16:51:07", "link": "http://arxiv.org/abs/2311.02025v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grounded Intuition of GPT-Vision's Abilities with Scientific Images", "abstract": "GPT-Vision has impressed us on a range of vision-language tasks, but it comes\nwith the familiar new challenge: we have little idea of its capabilities and\nlimitations. In our study, we formalize a process that many have instinctively\nbeen trying already to develop \"grounded intuition\" of this new model. Inspired\nby the recent movement away from benchmarking in favor of example-driven\nqualitative evaluation, we draw upon grounded theory and thematic analysis in\nsocial science and human-computer interaction to establish a rigorous framework\nfor qualitative evaluation in natural language processing. We use our technique\nto examine alt text generation for scientific figures, finding that GPT-Vision\nis particularly sensitive to prompting, counterfactual text in images, and\nrelative spatial relationships. Our method and analysis aim to help researchers\nramp up their own grounded intuitions of new models while exposing how\nGPT-Vision can be applied to make information more accessible.", "published": "2023-11-03 17:53:43", "link": "http://arxiv.org/abs/2311.02069v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Introduction to Natural Language Processing Techniques and Framework\n  for Clinical Implementation in Radiation Oncology", "abstract": "Natural Language Processing (NLP) is a key technique for developing Medical\nArtificial Intelligence (AI) systems that leverage Electronic Health Record\n(EHR) data to build diagnostic and prognostic models. NLP enables the\nconversion of unstructured clinical text into structured data that can be fed\ninto AI algorithms. The emergence of the transformer architecture and large\nlanguage models (LLMs) has led to remarkable advances in NLP for various\nhealthcare tasks, such as entity recognition, relation extraction, sentence\nsimilarity, text summarization, and question answering. In this article, we\nreview the major technical innovations that underpin modern NLP models and\npresent state-of-the-art NLP applications that employ LLMs in radiation\noncology research. However, these LLMs are prone to many errors such as\nhallucinations, biases, and ethical violations, which necessitate rigorous\nevaluation and validation before clinical deployment. As such, we propose a\ncomprehensive framework for assessing the NLP models based on their purpose and\nclinical fit, technical performance, bias and trust, legal and ethical\nimplications, and quality assurance, prior to implementation in clinical\nradiation oncology. Our article aims to provide guidance and insights for\nresearchers and clinicians who are interested in developing and using NLP\nmodels in clinical radiation oncology.", "published": "2023-11-03 19:32:35", "link": "http://arxiv.org/abs/2311.02205v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not all layers are equally as important: Every Layer Counts BERT", "abstract": "This paper introduces a novel modification of the transformer architecture,\ntailored for the data-efficient pretraining of language models. This aspect is\nevaluated by participating in the BabyLM challenge, where our solution won both\nthe strict and strict-small tracks. Our approach allows each transformer layer\nto select which outputs of previous layers to process. The empirical results\nverify the potential of this simple modification and show that not all layers\nare equally as important.", "published": "2023-11-03 23:08:50", "link": "http://arxiv.org/abs/2311.02265v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FinGPT: Large Generative Models for a Small Language", "abstract": "Large language models (LLMs) excel in many tasks in NLP and beyond, but most\nopen models have very limited coverage of smaller languages and LLM work tends\nto focus on languages where nearly unlimited data is available for pretraining.\nIn this work, we study the challenges of creating LLMs for Finnish, a language\nspoken by less than 0.1% of the world population. We compile an extensive\ndataset of Finnish combining web crawls, news, social media and eBooks. We\npursue two approaches to pretrain models: 1) we train seven monolingual models\nfrom scratch (186M to 13B parameters) dubbed FinGPT, 2) we continue the\npretraining of the multilingual BLOOM model on a mix of its original training\ndata and Finnish, resulting in a 176 billion parameter model we call BLUUMI.\nFor model evaluation, we introduce FIN-bench, a version of BIG-bench with\nFinnish tasks. We also assess other model qualities such as toxicity and bias.\nOur models and tools are openly available at https://turkunlp.org/gpt3-finnish.", "published": "2023-11-03 08:05:04", "link": "http://arxiv.org/abs/2311.05640v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plot Retrieval as an Assessment of Abstract Semantic Association", "abstract": "Retrieving relevant plots from the book for a query is a critical task, which\ncan improve the reading experience and efficiency of readers. Readers usually\nonly give an abstract and vague description as the query based on their own\nunderstanding, summaries, or speculations of the plot, which requires the\nretrieval model to have a strong ability to estimate the abstract semantic\nassociations between the query and candidate plots. However, existing\ninformation retrieval (IR) datasets cannot reflect this ability well. In this\npaper, we propose Plot Retrieval, a labeled dataset to train and evaluate the\nperformance of IR models on the novel task Plot Retrieval. Text pairs in Plot\nRetrieval have less word overlap and more abstract semantic association, which\ncan reflect the ability of the IR models to estimate the abstract semantic\nassociation, rather than just traditional lexical or semantic matching.\nExtensive experiments across various lexical retrieval, sparse retrieval, dense\nretrieval, and cross-encoder methods compared with human studies on Plot\nRetrieval show current IR models still struggle in capturing abstract semantic\nassociation between texts. Plot Retrieval can be the benchmark for further\nresearch on the semantic association modeling ability of IR models.", "published": "2023-11-03 02:02:43", "link": "http://arxiv.org/abs/2311.01666v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "DialogBench: Evaluating LLMs as Human-like Dialogue Systems", "abstract": "Large language models (LLMs) have achieved remarkable breakthroughs in new\ndialogue capabilities by leveraging instruction tuning, which refreshes human\nimpressions of dialogue systems. The long-standing goal of dialogue systems is\nto be human-like enough to establish long-term connections with users.\nTherefore, there has been an urgent need to evaluate LLMs as human-like\ndialogue systems. In this paper, we propose DialogBench, a dialogue evaluation\nbenchmark that contains 12 dialogue tasks to probe the capabilities of LLMs as\nhuman-like dialogue systems should have. Specifically, we prompt GPT-4 to\ngenerate evaluation instances for each task. We first design the basic prompt\nbased on widely used design principles and further mitigate the existing biases\nto generate higher-quality evaluation instances. Our extensive tests on English\nand Chinese DialogBench of 26 LLMs show that instruction tuning improves the\nhuman likeness of LLMs to a certain extent, but most LLMs still have much room\nfor improvement as human-like dialogue systems. Interestingly, results also\nshow that the positioning of assistant AI can make instruction tuning weaken\nthe human emotional perception of LLMs and their mastery of information about\nhuman daily life.", "published": "2023-11-03 02:59:56", "link": "http://arxiv.org/abs/2311.01677v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Data-Free Distillation of Language Model by Text-to-Text Transfer", "abstract": "Data-Free Knowledge Distillation (DFKD) plays a vital role in compressing the\nmodel when original training data is unavailable. Previous works for DFKD in\nNLP mainly focus on distilling encoder-only structures like BERT on\nclassification tasks, which overlook the notable progress of generative\nlanguage modeling. In this work, we propose a novel DFKD framework, namely\nDFKD-T$^{3}$, where the pretrained generative language model can also serve as\na controllable data generator for model compression. This novel framework\nDFKD-T$^{3}$ leads to an end-to-end learnable text-to-text framework to\ntransform the general domain corpus to compression-friendly task data,\ntargeting to improve both the \\textit{specificity} and \\textit{diversity}.\nExtensive experiments show that our method can boost the distillation\nperformance in various downstream tasks such as sentiment analysis, linguistic\nacceptability, and information extraction. Furthermore, we show that the\ngenerated texts can be directly used for distilling other language models and\noutperform the SOTA methods, making our method more appealing in a general DFKD\nsetting. Our code is available at\nhttps://gitee.com/mindspore/models/tree/master/research/nlp/DFKD\\_T3.", "published": "2023-11-03 03:31:47", "link": "http://arxiv.org/abs/2311.01689v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of Benchmarking Chinese Aspect Sentiment Quad\n  Prediction", "abstract": "Aspect sentiment quad prediction (ASQP) is a critical subtask of aspect-level\nsentiment analysis. Current ASQP datasets are characterized by their small size\nand low quadruple density, which hinders technical development. To expand\ncapacity, we construct two large Chinese ASQP datasets crawled from multiple\nonline platforms. The datasets hold several significant characteristics: larger\nsize (each with 10,000+ samples) and rich aspect categories, more words per\nsentence, and higher density than existing ASQP datasets. Moreover, we are the\nfirst to evaluate the performance of Generative Pre-trained Transformer (GPT)\nseries models on ASQP and exhibit potential issues. The experiments with\nstate-of-the-art ASQP baselines underscore the need to explore additional\ntechniques to address ASQP, as well as the importance of further investigation\ninto methods to improve the performance of GPTs.", "published": "2023-11-03 05:00:44", "link": "http://arxiv.org/abs/2311.01713v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Indo LEGO-ABSA: A Multitask Generative Aspect Based Sentiment Analysis\n  for Indonesian Language", "abstract": "Aspect-based sentiment analysis is a method in natural language processing\naimed at identifying and understanding sentiments related to specific aspects\nof an entity. Aspects are words or phrases that represent an aspect or\nattribute of a particular entity. Previous research has utilized generative\npre-trained language models to perform aspect-based sentiment analysis.\nLEGO-ABSA is one framework that has successfully employed generative\npre-trained language models in aspect-based sentiment analysis, particularly in\nEnglish. LEGO-ABSA uses a multitask learning and prompting approach to enhance\nmodel performance. However, the application of this approach has not been done\nin the context of Bahasa Indonesia. Therefore, this research aims to implement\nthe multitask learning and prompting approach in aspect-based sentiment\nanalysis for Bahasa Indonesia using generative pre-trained language models. In\nthis study, the Indo LEGO-ABSA model is developed, which is an aspect-based\nsentiment analysis model utilizing generative pre-trained language models and\ntrained with multitask learning and prompting. Indo LEGO-ABSA is trained with a\nhotel domain dataset in the Indonesian language. The obtained results include\nan f1-score of 79.55% for the Aspect Sentiment Triplet Extraction task, 86.09%\nfor Unified Aspect-based Sentiment Analysis, 79.85% for Aspect Opinion Pair\nExtraction, 87.45% for Aspect Term Extraction, and 88.09% for Opinion Term\nExtraction. Indo LEGO-ABSA adopts the LEGO-ABSA framework that employs the T5\nmodel, specifically mT5, by applying multitask learning to train all tasks\nwithin aspect-based sentiment analysis.", "published": "2023-11-03 07:28:12", "link": "http://arxiv.org/abs/2311.01757v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Support or Refute: Analyzing the Stance of Evidence to Detect\n  Out-of-Context Mis- and Disinformation", "abstract": "Mis- and disinformation online have become a major societal problem as major\nsources of online harms of different kinds. One common form of mis- and\ndisinformation is out-of-context (OOC) information, where different pieces of\ninformation are falsely associated, e.g., a real image combined with a false\ntextual caption or a misleading textual description. Although some past studies\nhave attempted to defend against OOC mis- and disinformation through external\nevidence, they tend to disregard the role of different pieces of evidence with\ndifferent stances. Motivated by the intuition that the stance of evidence\nrepresents a bias towards different detection results, we propose a stance\nextraction network (SEN) that can extract the stances of different pieces of\nmulti-modal evidence in a unified framework. Moreover, we introduce a\nsupport-refutation score calculated based on the co-occurrence relations of\nnamed entities into the textual SEN. Extensive experiments on a public\nlarge-scale dataset demonstrated that our proposed method outperformed the\nstate-of-the-art baselines, with the best model achieving a performance gain of\n3.2% in accuracy.", "published": "2023-11-03 08:05:54", "link": "http://arxiv.org/abs/2311.01766v4", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "TCM-GPT: Efficient Pre-training of Large Language Models for Domain\n  Adaptation in Traditional Chinese Medicine", "abstract": "Pre-training and fine-tuning have emerged as a promising paradigm across\nvarious natural language processing (NLP) tasks. The effectiveness of\npretrained large language models (LLM) has witnessed further enhancement,\nholding potential for applications in the field of medicine, particularly in\nthe context of Traditional Chinese Medicine (TCM). However, the application of\nthese general models to specific domains often yields suboptimal results,\nprimarily due to challenges like lack of domain knowledge, unique objectives,\nand computational efficiency. Furthermore, their effectiveness in specialized\ndomains, such as Traditional Chinese Medicine, requires comprehensive\nevaluation. To address the above issues, we propose a novel domain specific\nTCMDA (TCM Domain Adaptation) approach, efficient pre-training with\ndomain-specific corpus. Specifically, we first construct a large TCM-specific\ncorpus, TCM-Corpus-1B, by identifying domain keywords and retreving from\ngeneral corpus. Then, our TCMDA leverages the LoRA which freezes the pretrained\nmodel's weights and uses rank decomposition matrices to efficiently train\nspecific dense layers for pre-training and fine-tuning, efficiently aligning\nthe model with TCM-related tasks, namely TCM-GPT-7B. We further conducted\nextensive experiments on two TCM tasks, including TCM examination and TCM\ndiagnosis. TCM-GPT-7B archived the best performance across both datasets,\noutperforming other models by relative increments of 17% and 12% in accuracy,\nrespectively. To the best of our knowledge, our study represents the pioneering\nvalidation of domain adaptation of a large language model with 7 billion\nparameters in TCM domain. We will release both TCMCorpus-1B and TCM-GPT-7B\nmodel once accepted to facilitate interdisciplinary development in TCM and NLP,\nserving as the foundation for further study.", "published": "2023-11-03 08:54:50", "link": "http://arxiv.org/abs/2311.01786v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AFPQ: Asymmetric Floating Point Quantization for LLMs", "abstract": "Large language models (LLMs) show great performance in various tasks, but\nface deployment challenges from limited memory capacity and bandwidth. Low-bit\nweight quantization can save memory and accelerate inference. Although\nfloating-point (FP) formats show good performance in LLM quantization, they\ntend to perform poorly with small group sizes or sub-4 bits. We find the reason\nis that the absence of asymmetry in previous FP quantization makes it\nunsuitable for handling asymmetric value distribution of LLM weight tensors. In\nthis work, we propose asymmetric FP quantization (AFPQ), which sets separate\nscales for positive and negative values. Our method leads to large accuracy\nimprovements and can be easily plugged into other quantization methods,\nincluding GPTQ and AWQ, for better performance. Besides, no additional storage\nis needed compared with asymmetric integer (INT) quantization. The code is\navailable at https://github.com/zhangsichengsjtu/AFPQ.", "published": "2023-11-03 09:07:09", "link": "http://arxiv.org/abs/2311.01792v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FAME: Flexible, Scalable Analogy Mappings Engine", "abstract": "Analogy is one of the core capacities of human cognition; when faced with new\nsituations, we often transfer prior experience from other domains. Most work on\ncomputational analogy relies heavily on complex, manually crafted input. In\nthis work, we relax the input requirements, requiring only names of entities to\nbe mapped. We automatically extract commonsense representations and use them to\nidentify a mapping between the entities. Unlike previous works, our framework\ncan handle partial analogies and suggest new entities to be added. Moreover,\nour method's output is easily interpretable, allowing for users to understand\nwhy a specific mapping was chosen.\n  Experiments show that our model correctly maps 81.2% of classical 2x2 analogy\nproblems (guess level=50%). On larger problems, it achieves 77.8% accuracy\n(mean guess level=13.1%). In another experiment, we show our algorithm\noutperforms human performance, and the automatic suggestions of new entities\nresemble those suggested by humans. We hope this work will advance\ncomputational analogy by paving the way to more flexible, realistic input\nrequirements, with broader applicability.", "published": "2023-11-03 12:08:02", "link": "http://arxiv.org/abs/2311.01860v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "$R^3$-NL2GQL: A Model Coordination and Knowledge Graph Alignment\n  Approach for NL2GQL", "abstract": "While current tasks of converting natural language to SQL (NL2SQL) using\nFoundation Models have shown impressive achievements, adapting these approaches\nfor converting natural language to Graph Query Language (NL2GQL) encounters\nhurdles due to the distinct nature of GQL compared to SQL, alongside the\ndiverse forms of GQL. Moving away from traditional rule-based and slot-filling\nmethodologies, we introduce a novel approach, $R^3$-NL2GQL, integrating both\nsmall and large Foundation Models for ranking, rewriting, and refining tasks.\nThis method leverages the interpretative strengths of smaller models for\ninitial ranking and rewriting stages, while capitalizing on the superior\ngeneralization and query generation prowess of larger models for the final\ntransformation of natural language queries into GQL formats. Addressing the\nscarcity of datasets in this emerging field, we have developed a bilingual\ndataset, sourced from graph database manuals and selected open-source Knowledge\nGraphs (KGs). Our evaluation of this methodology on this dataset demonstrates\nits promising efficacy and robustness.", "published": "2023-11-03 12:11:12", "link": "http://arxiv.org/abs/2311.01862v2", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Towards Concept-Aware Large Language Models", "abstract": "Concepts play a pivotal role in various human cognitive functions, including\nlearning, reasoning and communication. However, there is very little work on\nendowing machines with the ability to form and reason with concepts. In\nparticular, state-of-the-art large language models (LLMs) work at the level of\ntokens, not concepts.\n  In this work, we analyze how well contemporary LLMs capture human concepts\nand their structure. We then discuss ways to develop concept-aware LLMs, taking\nplace at different stages of the pipeline. We sketch a method for pretraining\nLLMs using concepts, and also explore the simpler approach that uses the output\nof existing LLMs. Despite its simplicity, our proof-of-concept is shown to\nbetter match human intuition, as well as improve the robustness of predictions.\nThese preliminary results underscore the promise of concept-aware LLMs.", "published": "2023-11-03 12:19:22", "link": "http://arxiv.org/abs/2311.01866v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Don't Make Your LLM an Evaluation Benchmark Cheater", "abstract": "Large language models~(LLMs) have greatly advanced the frontiers of\nartificial intelligence, attaining remarkable improvement in model capacity. To\nassess the model performance, a typical approach is to construct evaluation\nbenchmarks for measuring the ability level of LLMs in different aspects.\nDespite that a number of high-quality benchmarks have been released, the\nconcerns about the appropriate use of these benchmarks and the fair comparison\nof different models are increasingly growing. Considering these concerns, in\nthis paper, we discuss the potential risk and impact of inappropriately using\nevaluation benchmarks and misleadingly interpreting the evaluation results.\nSpecially, we focus on a special issue that would lead to inappropriate\nevaluation, \\ie \\emph{benchmark leakage}, referring that the data related to\nevaluation sets is occasionally used for model training. This phenomenon now\nbecomes more common since pre-training data is often prepared ahead of model\ntest. We conduct extensive experiments to study the effect of benchmark\nleverage, and find that it can dramatically boost the evaluation results, which\nwould finally lead to an unreliable assessment of model performance. To improve\nthe use of existing evaluation benchmarks, we finally present several\nguidelines for both LLM developers and benchmark maintainers. We hope this work\ncan draw attention to appropriate training and evaluation of LLMs.", "published": "2023-11-03 14:59:54", "link": "http://arxiv.org/abs/2311.01964v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Post Turing: Mapping the landscape of LLM Evaluation", "abstract": "In the rapidly evolving landscape of Large Language Models (LLMs),\nintroduction of well-defined and standardized evaluation methodologies remains\na crucial challenge. This paper traces the historical trajectory of LLM\nevaluations, from the foundational questions posed by Alan Turing to the modern\nera of AI research. We categorize the evolution of LLMs into distinct periods,\neach characterized by its unique benchmarks and evaluation criteria. As LLMs\nincreasingly mimic human-like behaviors, traditional evaluation proxies, such\nas the Turing test, have become less reliable. We emphasize the pressing need\nfor a unified evaluation system, given the broader societal implications of\nthese models. Through an analysis of common evaluation methodologies, we\nadvocate for a qualitative shift in assessment approaches, underscoring the\nimportance of standardization and objective criteria. This work serves as a\ncall for the AI community to collaboratively address the challenges of LLM\nevaluation, ensuring their reliability, fairness, and societal benefit.", "published": "2023-11-03 17:24:50", "link": "http://arxiv.org/abs/2311.02049v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Exploring the Numerical Reasoning Capabilities of Language Models: A\n  Comprehensive Analysis on Tabular Data", "abstract": "Numbers are crucial for various real-world domains such as finance,\neconomics, and science. Thus, understanding and reasoning with numbers are\nessential skills for language models to solve different tasks. While different\nnumerical benchmarks have been introduced in recent years, they are limited to\nspecific numerical aspects mostly. In this paper, we propose a hierarchical\ntaxonomy for numerical reasoning skills with more than ten reasoning types\nacross four levels: representation, number sense, manipulation, and complex\nreasoning. We conduct a comprehensive evaluation of state-of-the-art models to\nidentify reasoning challenges specific to them. Henceforth, we develop a\ndiverse set of numerical probes employing a semi-automated approach. We focus\non the tabular Natural Language Inference (TNLI) task as a case study and\nmeasure models' performance shifts. Our results show that no model consistently\nexcels across all numerical reasoning types. Among the probed models, FlanT5\n(few-/zero-shot) and GPT-3.5 (few-shot) demonstrate strong overall numerical\nreasoning skills compared to other models. Label-flipping probes indicate that\nmodels often exploit dataset artifacts to predict the correct labels.", "published": "2023-11-03 20:05:30", "link": "http://arxiv.org/abs/2311.02216v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs", "abstract": "In human-written articles, we often leverage the subtleties of text style,\nsuch as bold and italics, to guide the attention of readers. These textual\nemphases are vital for the readers to grasp the conveyed information. When\ninteracting with large language models (LLMs), we have a similar need --\nsteering the model to pay closer attention to user-specified information, e.g.,\nan instruction. Existing methods, however, are constrained to process plain\ntext and do not support such a mechanism. This motivates us to introduce PASTA\n-- Post-hoc Attention STeering Approach, a method that allows LLMs to read text\nwith user-specified emphasis marks. To this end, PASTA identifies a small\nsubset of attention heads and applies precise attention reweighting on them,\ndirecting the model attention to user-specified parts. Like prompting, PASTA is\napplied at inference time and does not require changing any model parameters.\nExperiments demonstrate that PASTA can substantially enhance an LLM's ability\nto follow user instructions or integrate new knowledge from user inputs,\nleading to a significant performance improvement on a variety of tasks, e.g.,\nan average accuracy improvement of 22% for LLAMA-7B. Our code is publicly\navailable at https://github.com/QingruZhang/PASTA .", "published": "2023-11-03 22:56:43", "link": "http://arxiv.org/abs/2311.02262v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FaMeSumm: Investigating and Improving Faithfulness of Medical\n  Summarization", "abstract": "Summaries of medical text shall be faithful by being consistent and factual\nwith source inputs, which is an important but understudied topic for safety and\nefficiency in healthcare. In this paper, we investigate and improve\nfaithfulness in summarization on a broad range of medical summarization tasks.\nOur investigation reveals that current summarization models often produce\nunfaithful outputs for medical input text. We then introduce FaMeSumm, a\nframework to improve faithfulness by fine-tuning pre-trained language models\nbased on medical knowledge. FaMeSumm performs contrastive learning on designed\nsets of faithful and unfaithful summaries, and it incorporates medical terms\nand their contexts to encourage faithful generation of medical terms. We\nconduct comprehensive experiments on three datasets in two languages: health\nquestion and radiology report summarization datasets in English, and a\npatient-doctor dialogue dataset in Chinese. Results demonstrate that FaMeSumm\nis flexible and effective by delivering consistent improvements over mainstream\nlanguage models such as BART, T5, mT5, and PEGASUS, yielding state-of-the-art\nperformances on metrics for faithfulness and general quality. Human evaluation\nby doctors also shows that FaMeSumm generates more faithful outputs. Our code\nis available at https://github.com/psunlpgroup/FaMeSumm .", "published": "2023-11-03 23:25:53", "link": "http://arxiv.org/abs/2311.02271v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Successor Features for Efficient Multisubject Controlled Text Generation", "abstract": "While large language models (LLMs) have achieved impressive performance in\ngenerating fluent and realistic text, controlling the generated text so that it\nexhibits properties such as safety, factuality, and non-toxicity remains\nchallenging. % such as DExperts, GeDi, and rectification Existing\ndecoding-based methods are static in terms of the dimension of control; if the\ntarget subject is changed, they require new training. Moreover, it can quickly\nbecome prohibitive to concurrently control multiple subjects. In this work, we\nintroduce SF-GEN, which is grounded in two primary concepts: successor features\n(SFs) to decouple the LLM's dynamics from task-specific rewards, and language\nmodel rectification to proportionally adjust the probability of selecting a\ntoken based on the likelihood that the finished text becomes undesired. SF-GEN\nseamlessly integrates the two to enable dynamic steering of text generation\nwith no need to alter the LLM's parameters. Thanks to the decoupling effect\ninduced by successor features, our method proves to be memory-wise and\ncomputationally efficient for training as well as decoding, especially when\ndealing with multiple target subjects. To the best of our knowledge, our\nresearch represents the first application of successor features in text\ngeneration. In addition to its computational efficiency, the resultant language\nproduced by our method is comparable to the SOTA (and outperforms baselines) in\nboth control measures as well as language quality, which we demonstrate through\na series of experiments in various controllable text generation tasks.", "published": "2023-11-03 00:17:08", "link": "http://arxiv.org/abs/2311.04921v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Tuning-less Object Naming with a Foundation Model", "abstract": "We implement a real-time object naming system that enables learning a set of\nnamed entities never seen. Our approach employs an existing foundation model\nthat we consider ready to see anything before starting. It turns seen images\ninto relatively small feature vectors that we associate with index to a\ngradually built vocabulary without any training of fine-tuning of the model.\nOur contribution is using the association mechanism known from transformers as\nattention. It has features that support generalization from irrelevant\ninformation for distinguishing the entities and potentially enable associating\nwith much more than indices to vocabulary. As a result, the system can work in\na one-shot manner and correctly name objects named in different contents. We\nalso outline implementation details of the system modules integrated by a\nblackboard architecture. Finally, we investigate the system's quality, mainly\nhow many objects it can handle in this way.", "published": "2023-11-03 09:11:49", "link": "http://arxiv.org/abs/2311.04924v2", "categories": ["cs.CL", "cs.AI", "I.2.9"], "primary_category": "cs.CL"}
{"title": "Investigating Deep-Learning NLP for Automating the Extraction of\n  Oncology Efficacy Endpoints from Scientific Literature", "abstract": "Benchmarking drug efficacy is a critical step in clinical trial design and\nplanning. The challenge is that much of the data on efficacy endpoints is\nstored in scientific papers in free text form, so extraction of such data is\ncurrently a largely manual task. Our objective is to automate this task as much\nas possible. In this study we have developed and optimised a framework to\nextract efficacy endpoints from text in scientific papers, using a machine\nlearning approach. Our machine learning model predicts 25 classes associated\nwith efficacy endpoints and leads to high F1 scores (harmonic mean of precision\nand recall) of 96.4% on the test set, and 93.9% and 93.7% on two case studies.\nThese methods were evaluated against - and showed strong agreement with -\nsubject matter experts and show significant promise in the future of automating\nthe extraction of clinical endpoints from free text. Clinical information\nextraction from text data is currently a laborious manual task which scales\npoorly and is prone to human error. Demonstrating the ability to extract\nefficacy endpoints automatically shows great promise for accelerating clinical\ntrial design moving forwards.", "published": "2023-11-03 14:01:54", "link": "http://arxiv.org/abs/2311.04925v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve\n  Visually Diverse Images of Parsons Problems", "abstract": "The advent of large language models is reshaping computing education. Recent\nresearch has demonstrated that these models can produce better explanations\nthan students, answer multiple-choice questions at or above the class average,\nand generate code that can pass automated tests in introductory courses. These\ncapabilities have prompted instructors to rapidly adapt their courses and\nassessment methods to accommodate changes in learning objectives and the\npotential for academic integrity violations. While some scholars have advocated\nfor the integration of visual problems as a safeguard against the capabilities\nof language models, new multimodal language models now have vision and language\ncapabilities that may allow them to analyze and solve visual problems. In this\npaper, we evaluate the performance of two large multimodal models on visual\nassignments, with a specific focus on Parsons problems presented across diverse\nvisual representations. Our results show that GPT-4V solved 96.7\\% of these\nvisual problems, struggling minimally with a single Parsons problem.\nConversely, Bard performed poorly by only solving 69.2\\% of problems,\nstruggling with common issues like hallucinations and refusals. These findings\nsuggest that merely transitioning to visual programming problems might not be a\npanacea to issues of academic integrity in the generative AI era.", "published": "2023-11-03 14:47:17", "link": "http://arxiv.org/abs/2311.04926v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contextualizing the Limits of Model & Evaluation Dataset Curation on\n  Semantic Similarity Classification Tasks", "abstract": "This paper demonstrates how the limitations of pre-trained models and open\nevaluation datasets factor into assessing the performance of binary semantic\nsimilarity classification tasks. As (1) end-user-facing documentation around\nthe curation of these datasets and pre-trained model training regimes is often\nnot easily accessible and (2) given the lower friction and higher demand to\nquickly deploy such systems in real-world contexts, our study reinforces prior\nwork showing performance disparities across datasets, embedding techniques and\ndistance metrics, while highlighting the importance of understanding how data\nis collected, curated and analyzed in semantic similarity classification.", "published": "2023-11-03 17:12:07", "link": "http://arxiv.org/abs/2311.04927v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Abstraction via exemplars? A representational case study on lexical\n  category inference in BERT", "abstract": "Exemplar based accounts are often considered to be in direct opposition to\npure linguistic abstraction in explaining language learners' ability to\ngeneralize to novel expressions. However, the recent success of neural network\nlanguage models on linguistically sensitive tasks suggests that perhaps\nabstractions can arise via the encoding of exemplars. We provide empirical\nevidence for this claim by adapting an existing experiment that studies how an\nLM (BERT) generalizes the usage of novel tokens that belong to lexical\ncategories such as Noun/Verb/Adjective/Adverb from exposure to only a single\ninstance of their usage. We analyze the representational behavior of the novel\ntokens in these experiments, and find that BERT's capacity to generalize to\nunseen expressions involving the use of these novel tokens constitutes the\nmovement of novel token representations towards regions of known category\nexemplars in two-dimensional space. Our results suggest that learners' encoding\nof exemplars can indeed give rise to abstraction like behavior.", "published": "2023-11-03 18:45:19", "link": "http://arxiv.org/abs/2312.03708v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VQPy: An Object-Oriented Approach to Modern Video Analytics", "abstract": "Video analytics is widely used in contemporary systems and services. At the\nforefront of video analytics are video queries that users develop to find\nobjects of particular interest. Building upon the insight that video objects\n(e.g., human, animals, cars, etc.), the center of video analytics, are similar\nin spirit to objects modeled by traditional object-oriented languages, we\npropose to develop an object-oriented approach to video analytics. This\napproach, named VQPy, consists of a frontend$\\unicode{x2015}$a Python variant\nwith constructs that make it easy for users to express video objects and their\ninteractions$\\unicode{x2015}$as well as an extensible backend that can\nautomatically construct and optimize pipelines based on video objects. We have\nimplemented and open-sourced VQPy, which has been productized in Cisco as part\nof its DeepVision framework.", "published": "2023-11-03 16:58:10", "link": "http://arxiv.org/abs/2311.01623v4", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MARRS: Multimodal Reference Resolution System", "abstract": "Successfully handling context is essential for any dialog understanding task.\nThis context maybe be conversational (relying on previous user queries or\nsystem responses), visual (relying on what the user sees, for example, on their\nscreen), or background (based on signals such as a ringing alarm or playing\nmusic). In this work, we present an overview of MARRS, or Multimodal Reference\nResolution System, an on-device framework within a Natural Language\nUnderstanding system, responsible for handling conversational, visual and\nbackground context. In particular, we present different machine learning models\nto enable handing contextual queries; specifically, one to enable reference\nresolution, and one to handle context via query rewriting. We also describe how\nthese models complement each other to form a unified, coherent, lightweight\nsystem that can understand context while preserving user privacy.", "published": "2023-11-03 00:48:42", "link": "http://arxiv.org/abs/2311.01650v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models to the Rescue: Reducing the Complexity in\n  Scientific Workflow Development Using ChatGPT", "abstract": "Scientific workflow systems are increasingly popular for expressing and\nexecuting complex data analysis pipelines over large datasets, as they offer\nreproducibility, dependability, and scalability of analyses by automatic\nparallelization on large compute clusters. However, implementing workflows is\ndifficult due to the involvement of many black-box tools and the deep\ninfrastructure stack necessary for their execution. Simultaneously,\nuser-supporting tools are rare, and the number of available examples is much\nlower than in classical programming languages. To address these challenges, we\ninvestigate the efficiency of Large Language Models (LLMs), specifically\nChatGPT, to support users when dealing with scientific workflows. We performed\nthree user studies in two scientific domains to evaluate ChatGPT for\ncomprehending, adapting, and extending workflows. Our results indicate that\nLLMs efficiently interpret workflows but achieve lower performance for\nexchanging components or purposeful workflow extensions. We characterize their\nlimitations in these challenging scenarios and suggest future research\ndirections.", "published": "2023-11-03 10:28:53", "link": "http://arxiv.org/abs/2311.01825v2", "categories": ["cs.DC", "cs.CL", "cs.HC"], "primary_category": "cs.DC"}
{"title": "SortNet: Learning To Rank By a Neural-Based Sorting Algorithm", "abstract": "The problem of relevance ranking consists of sorting a set of objects with\nrespect to a given criterion. Since users may prefer different relevance\ncriteria, the ranking algorithms should be adaptable to the user needs. Two\nmain approaches exist in literature for the task of learning to rank: 1) a\nscore function, learned by examples, which evaluates the properties of each\nobject yielding an absolute relevance value that can be used to order the\nobjects or 2) a pairwise approach, where a \"preference function\" is learned\nusing pairs of objects to define which one has to be ranked first. In this\npaper, we present SortNet, an adaptive ranking algorithm which orders objects\nusing a neural network as a comparator. The neural network training set\nprovides examples of the desired ordering between pairs of items and it is\nconstructed by an iterative procedure which, at each iteration, adds the most\ninformative training examples. Moreover, the comparator adopts a connectionist\narchitecture that is particularly suited for implementing a preference\nfunction. We also prove that such an architecture has the universal\napproximation property and can implement a wide class of functions. Finally,\nthe proposed algorithm is evaluated on the LETOR dataset showing promising\nperformances in comparison with other state of the art algorithms.", "published": "2023-11-03 12:14:26", "link": "http://arxiv.org/abs/2311.01864v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Multi-EuP: The Multilingual European Parliament Dataset for Analysis of\n  Bias in Information Retrieval", "abstract": "We present Multi-EuP, a new multilingual benchmark dataset, comprising 22K\nmulti-lingual documents collected from the European Parliament, spanning 24\nlanguages. This dataset is designed to investigate fairness in a multilingual\ninformation retrieval (IR) context to analyze both language and demographic\nbias in a ranking context. It boasts an authentic multilingual corpus,\nfeaturing topics translated into all 24 languages, as well as cross-lingual\nrelevance judgments. Furthermore, it offers rich demographic information\nassociated with its documents, facilitating the study of demographic bias. We\nreport the effectiveness of Multi-EuP for benchmarking both monolingual and\nmultilingual IR. We also conduct a preliminary experiment on language bias\ncaused by the choice of tokenization strategy.", "published": "2023-11-03 12:29:11", "link": "http://arxiv.org/abs/2311.01870v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Large Language Models Illuminate a Progressive Pathway to Artificial\n  Healthcare Assistant: A Review", "abstract": "With the rapid development of artificial intelligence, large language models\n(LLMs) have shown promising capabilities in mimicking human-level language\ncomprehension and reasoning. This has sparked significant interest in applying\nLLMs to enhance various aspects of healthcare, ranging from medical education\nto clinical decision support. However, medicine involves multifaceted data\nmodalities and nuanced reasoning skills, presenting challenges for integrating\nLLMs. This paper provides a comprehensive review on the applications and\nimplications of LLMs in medicine. It begins by examining the fundamental\napplications of general-purpose and specialized LLMs, demonstrating their\nutilities in knowledge retrieval, research support, clinical workflow\nautomation, and diagnostic assistance. Recognizing the inherent multimodality\nof medicine, the review then focuses on multimodal LLMs, investigating their\nability to process diverse data types like medical imaging and EHRs to augment\ndiagnostic accuracy. To address LLMs' limitations regarding personalization and\ncomplex clinical reasoning, the paper explores the emerging development of\nLLM-powered autonomous agents for healthcare. Furthermore, it summarizes the\nevaluation methodologies for assessing LLMs' reliability and safety in medical\ncontexts. Overall, this review offers an extensive analysis on the\ntransformative potential of LLMs in modern medicine. It also highlights the\npivotal need for continuous optimizations and ethical oversight before these\nmodels can be effectively integrated into clinical practice. Visit\nhttps://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying\nGitHub repository containing latest papers.", "published": "2023-11-03 13:51:36", "link": "http://arxiv.org/abs/2311.01918v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling", "abstract": "Linear Recurrence has proven to be a powerful tool for modeling long\nsequences efficiently. In this work, we show that existing models fail to take\nfull advantage of its potential. Motivated by this finding, we develop\nGateLoop, a foundational sequence model that generalizes linear recurrent\nmodels such as S4, S5, LRU and RetNet, by employing data-controlled state\ntransitions. Utilizing this theoretical advance, GateLoop empirically\noutperforms existing models for auto-regressive language modeling. Our method\ncomes with a low-cost $O(l)$ recurrent mode and an efficient $O(l \\log_{2} l)$\nparallel mode making use of highly optimized associative scan implementations.\nFurthermore, we derive an $O(l^2)$ surrogate attention mode, revealing\nremarkable implications for Transformer and recently proposed architectures.\nSpecifically, we prove that our approach can be interpreted as providing\ndata-controlled relative-positional information to Attention. While many\nexisting models solely rely on data-controlled cumulative sums for context\naggregation, our findings suggest that incorporating data-controlled complex\ncumulative products may be a crucial step towards more powerful sequence\nmodels.", "published": "2023-11-03 14:08:39", "link": "http://arxiv.org/abs/2311.01927v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DS"], "primary_category": "cs.LG"}
{"title": "The language of prompting: What linguistic properties make a prompt\n  successful?", "abstract": "The latest generation of LLMs can be prompted to achieve impressive zero-shot\nor few-shot performance in many NLP tasks. However, since performance is highly\nsensitive to the choice of prompts, considerable effort has been devoted to\ncrowd-sourcing prompts or designing methods for prompt optimisation. Yet, we\nstill lack a systematic understanding of how linguistic properties of prompts\ncorrelate with task performance. In this work, we investigate how LLMs of\ndifferent sizes, pre-trained and instruction-tuned, perform on prompts that are\nsemantically equivalent, but vary in linguistic structure. We investigate both\ngrammatical properties such as mood, tense, aspect and modality, as well as\nlexico-semantic variation through the use of synonyms. Our findings contradict\nthe common assumption that LLMs achieve optimal performance on lower perplexity\nprompts that reflect language use in pretraining or instruction-tuning data.\nPrompts transfer poorly between datasets or models, and performance cannot\ngenerally be explained by perplexity, word frequency, ambiguity or prompt\nlength. Based on our results, we put forward a proposal for a more robust and\ncomprehensive evaluation standard for prompting research.", "published": "2023-11-03 15:03:36", "link": "http://arxiv.org/abs/2311.01967v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI)\n  Privacy Policy Annotations with Large Language Models", "abstract": "Identifying contextual integrity (CI) and governing knowledge commons (GKC)\nparameters in privacy policy texts can facilitate normative privacy analysis.\nHowever, GKC-CI annotation has heretofore required manual or crowdsourced\neffort. This paper demonstrates that high-accuracy GKC-CI parameter annotation\nof privacy policies can be performed automatically using large language models.\nWe fine-tune 50 open-source and proprietary models on 21,588 ground truth\nGKC-CI annotations from 16 privacy policies. Our best performing model has an\naccuracy of 90.65%, which is comparable to the accuracy of experts on the same\ntask. We apply our best performing model to 456 privacy policies from a variety\nof online services, demonstrating the effectiveness of scaling GKC-CI\nannotation for privacy policy exploration and analysis. We publicly release our\nmodel training code, training and testing data, an annotation visualizer, and\nall annotated policies for future GKC-CI research.", "published": "2023-11-03 18:49:05", "link": "http://arxiv.org/abs/2311.02192v3", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Robust Fine-Tuning of Vision-Language Models for Domain Generalization", "abstract": "Transfer learning enables the sharing of common knowledge among models for a\nvariety of downstream tasks, but traditional methods suffer in limited training\ndata settings and produce narrow models incapable of effectively generalizing\nunder distribution shifts. Foundation models have recently demonstrated\nimpressive zero-shot inference capabilities and robustness under distribution\nshifts. However, zero-shot evaluation for these models has been predominantly\nconfined to benchmarks with simple distribution shifts, limiting our\nunderstanding of their effectiveness under the more realistic shifts found in\npractice. Moreover, common fine-tuning methods for these models have yet to be\nevaluated against vision models in few-shot scenarios where training data is\nlimited. To address these gaps, we present a new recipe for few-shot\nfine-tuning of the popular vision-language foundation model CLIP and evaluate\nits performance on challenging benchmark datasets with realistic distribution\nshifts from the WILDS collection. Our experimentation demonstrates that, while\nzero-shot CLIP fails to match performance of trained vision models on more\ncomplex benchmarks, few-shot CLIP fine-tuning outperforms its vision-only\ncounterparts in terms of in-distribution and out-of-distribution accuracy at\nall levels of training data availability. This provides a strong incentive for\nadoption of foundation models within few-shot learning applications operating\nwith real-world data. Code is available at\nhttps://github.com/mit-ll/robust-vision-language-finetuning", "published": "2023-11-03 20:50:40", "link": "http://arxiv.org/abs/2311.02236v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning", "abstract": "We present a cost-effective method to integrate speech into a large language\nmodel (LLM), resulting in a Contextual Speech Model with\nInstruction-following/in-context-learning Capabilities (COSMIC) multi-modal\nLLM. Using GPT-3.5, we generate Speech Comprehension Test Question-Answer (SQA)\npairs from speech transcriptions for supervised instruction tuning. With under\n30 million trainable parameters and only 450 hours of English speech data,\nCOSMIC demonstrates emerging capabilities in instruction-following and\nin-context learning. Equipped with such capabilities, COSMIC achieves a maximum\n33.18 BLEU score in 0-shot EN-to-X speech to text translation (S2TT) and a\nsignificant boost in the 1-shot setting. Additionally, there is an average\n25.8\\% relative Word Error Rate (WER) reduction for 1-shot cross-domain\nadaptation. COSMIC exhibits a significant automatic speech recognition (ASR)\naccuracy gain in contextual biasing tasks due to its instruction-following\ncapability.", "published": "2023-11-03 21:47:03", "link": "http://arxiv.org/abs/2311.02248v2", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Are cascade dialogue state tracking models speaking out of turn in\n  spoken dialogues?", "abstract": "In Task-Oriented Dialogue (TOD) systems, correctly updating the system's\nunderstanding of the user's needs is key to a smooth interaction. Traditionally\nTOD systems are composed of several modules that interact with one another.\nWhile each of these components is the focus of active research communities,\ntheir behavior in interaction can be overlooked. This paper proposes a\ncomprehensive analysis of the errors of state of the art systems in complex\nsettings such as Dialogue State Tracking which highly depends on the dialogue\ncontext. Based on spoken MultiWoz, we identify that errors on non-categorical\nslots' values are essential to address in order to bridge the gap between\nspoken and chat-based dialogue systems. We explore potential solutions to\nimprove transcriptions and help dialogue state tracking generative models\ncorrect such errors.", "published": "2023-11-03 08:45:22", "link": "http://arxiv.org/abs/2311.04922v1", "categories": ["cs.CL", "cs.AI", "eess.AS", "eess.SP"], "primary_category": "cs.CL"}
{"title": "Is one brick enough to break the wall of spoken dialogue state tracking?", "abstract": "In Task-Oriented Dialogue (TOD) systems, correctly updating the system's\nunderstanding of the user's requests (\\textit{a.k.a} dialogue state tracking)\nis key to a smooth interaction. Traditionally, TOD systems perform this update\nin three steps: transcription of the user's utterance, semantic extraction of\nthe key concepts, and contextualization with the previously identified\nconcepts. Such cascade approaches suffer from cascading errors and separate\noptimization. End-to-End approaches have been proven helpful up to the\nturn-level semantic extraction step. This paper goes one step further and\nprovides (1) a novel approach for completely neural spoken DST, (2) an in depth\ncomparison with a state of the art cascade approach and (3) avenues towards\nbetter context propagation. Our study highlights that jointly-optimized\napproaches are also competitive for contextually dependent tasks, such as\nDialogue State Tracking (DST), especially in audio native settings. Context\npropagation in DST systems could benefit from training procedures accounting\nfor the previous' context inherent uncertainty.", "published": "2023-11-03 08:59:51", "link": "http://arxiv.org/abs/2311.04923v3", "categories": ["cs.CL", "cs.AI", "eess.AS", "eess.SP"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Collective Decision-Making", "abstract": "In various work contexts, such as meeting scheduling, collaborating, and\nproject planning, collective decision-making is essential but often challenging\ndue to diverse individual preferences, varying work focuses, and power dynamics\namong members. To address this, we propose a system leveraging Large Language\nModels (LLMs) to facilitate group decision-making by managing conversations and\nbalancing preferences among individuals. Our system aims to extract individual\npreferences from each member's conversation with the system and suggest options\nthat satisfy the preferences of the members. We specifically apply this system\nto corporate meeting scheduling. We create synthetic employee profiles and\nsimulate conversations at scale, leveraging LLMs to evaluate the system\nperformance as a novel approach to conducting a user study. Our results\nindicate efficient coordination with reduced interactions between the members\nand the LLM-based system. The system refines and improves its proposed options\nover time, ensuring that many of the members' individual preferences are\nsatisfied in an equitable way. Finally, we conduct a survey study involving\nhuman participants to assess our system's ability to aggregate preferences and\nreasoning about them. Our findings show that the system exhibits strong\nperformance in both dimensions.", "published": "2023-11-03 18:27:21", "link": "http://arxiv.org/abs/2311.04928v3", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.SI"], "primary_category": "cs.CL"}
{"title": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research", "abstract": "In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.", "published": "2023-11-03 19:41:09", "link": "http://arxiv.org/abs/2311.04929v1", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Comprehensive Assessment of Toxicity in ChatGPT", "abstract": "Moderating offensive, hateful, and toxic language has always been an\nimportant but challenging topic in the domain of safe use in NLP. The emerging\nlarge language models (LLMs), such as ChatGPT, can potentially further\naccentuate this threat. Previous works have discovered that ChatGPT can\ngenerate toxic responses using carefully crafted inputs. However, limited\nresearch has been done to systematically examine when ChatGPT generates toxic\nresponses. In this paper, we comprehensively evaluate the toxicity in ChatGPT\nby utilizing instruction-tuning datasets that closely align with real-world\nscenarios. Our results show that ChatGPT's toxicity varies based on different\nproperties and settings of the prompts, including tasks, domains, length, and\nlanguages. Notably, prompts in creative writing tasks can be 2x more likely\nthan others to elicit toxic responses. Prompting in German and Portuguese can\nalso double the response toxicity. Additionally, we discover that certain\ndeliberately toxic prompts, designed in earlier studies, no longer yield\nharmful responses. We hope our discoveries can guide model developers to better\nregulate these AI systems and the users to avoid undesirable outputs.", "published": "2023-11-03 14:37:53", "link": "http://arxiv.org/abs/2311.14685v1", "categories": ["cs.CY", "cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CY"}
{"title": "SE Territory: Monaural Speech Enhancement Meets the Fixed Virtual\n  Perceptual Space Mapping", "abstract": "Monaural speech enhancement has achieved remarkable progress recently.\nHowever, its performance has been constrained by the limited spatial cues\navailable at a single microphone. To overcome this limitation, we introduce a\nstrategy to map monaural speech into a fixed simulation space for better\ndifferentiation between target speech and noise. Concretely, we propose\nSE-TerrNet, a novel monaural speech enhancement model featuring a virtual\nbinaural speech mapping network via a two-stage multi-task learning framework.\nIn the first stage, monaural noisy input is projected into a virtual space\nusing supervised speech mapping blocks, creating binaural representations.\nThese blocks synthesize binaural noisy speech from monaural input via an ideal\nbinaural room impulse response. The synthesized output assigns speech and noise\nsources to fixed directions within the perceptual space. In the second stage,\nthe obtained binaural features from the first stage are aggregated. This\naggregation aims to decrease pattern discrepancies between the mapped binaural\nand original monaural features, achieved by implementing an intermediate fusion\nmodule. Furthermore, this stage incorporates the utilization of cross-attention\nto capture the injected virtual spatial information to improve the extraction\nof the target speech. Empirical studies highlight the effectiveness of virtual\nspatial cues in enhancing monaural speech enhancement. As a result, the\nproposed SE-TerrNet significantly surpasses the recent monaural speech\nenhancement methods in terms of both speech quality and intelligibility.", "published": "2023-11-03 03:03:47", "link": "http://arxiv.org/abs/2311.01679v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Acousto-optic reconstruction of exterior sound field based on concentric\n  circle sampling with circular harmonic expansion", "abstract": "Acousto-optic sensing provides an alternative approach to traditional\nmicrophone arrays by shedding light on the interaction of light with an\nacoustic field. Sound field reconstruction is a fascinating and advanced\ntechnique used in acousto-optics sensing. Current challenges in sound-field\nreconstruction methods pertain to scenarios in which the sound source is\nlocated within the reconstruction area, known as the exterior problem. Existing\nreconstruction algorithms, primarily designed for interior scenarios, often\nexhibit suboptimal performance when applied to exterior cases. This paper\nintroduces a novel technique for exterior sound-field reconstruction. The\nproposed method leverages concentric circle sampling and a two-dimensional\nexterior sound-field reconstruction approach based on circular harmonic\nextensions. To evaluate the efficacy of this approach, both numerical\nsimulations and practical experiments are conducted. The results highlight the\nsuperior accuracy of the proposed method when compared to conventional\nreconstruction methods, all while utilizing a minimal amount of measured\nprojection data.", "published": "2023-11-03 05:19:26", "link": "http://arxiv.org/abs/2311.01715v2", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "FiloBass: A Dataset and Corpus Based Study of Jazz Basslines", "abstract": "We present FiloBass: a novel corpus of music scores and annotations which\nfocuses on the important but often overlooked role of the double bass in jazz\naccompaniment. Inspired by recent work that sheds light on the role of the\nsoloist, we offer a collection of 48 manually verified transcriptions of\nprofessional jazz bassists, comprising over 50,000 note events, which are based\non the backing tracks used in the FiloSax dataset. For each recording we\nprovide audio stems, scores, performance-aligned MIDI and associated metadata\nfor beats, downbeats, chord symbols and markers for musical form.\n  We then use FiloBass to enrich our understanding of jazz bass lines, by\nconducting a corpus-based musical analysis with a contrastive study of existing\ninstructional methods. Together with the original FiloSax dataset, our work\nrepresents a significant step toward a fully annotated performance dataset for\na jazz quartet setting. By illuminating the critical role of the bass in jazz,\nthis work contributes to a more nuanced and comprehensive understanding of the\ngenre.", "published": "2023-11-03 16:36:52", "link": "http://arxiv.org/abs/2311.02023v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
