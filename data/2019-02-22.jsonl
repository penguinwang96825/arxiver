{"title": "Aspect-Sentiment Embeddings for Company Profiling and Employee Opinion\n  Mining", "abstract": "With the multitude of companies and organizations abound today, ranking them\nand choosing one out of the many is a difficult and cumbersome task. Although\nthere are many available metrics that rank companies, there is an inherent need\nfor a generalized metric that takes into account the different aspects that\nconstitute employee opinions of the companies. In this work, we aim to overcome\nthe aforementioned problem by generating aspect-sentiment based embedding for\nthe companies by looking into reliable employee reviews of them. We created a\ncomprehensive dataset of company reviews from the famous website Glassdoor.com\nand employed a novel ensemble approach to perform aspect-level sentiment\nanalysis. Although a relevant amount of work has been done on reviews centered\non subjects like movies, music, etc., this work is the first of its kind. We\nalso provide several insights from the collated embeddings, thus helping users\ngain a better understanding of their options as well as select companies using\ncustomized preferences.", "published": "2019-02-22 02:31:41", "link": "http://arxiv.org/abs/1902.08342v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Multilingual Sentence Embedding using Bi-directional Dual\n  Encoder with Additive Margin Softmax", "abstract": "In this paper, we present an approach to learn multilingual sentence\nembeddings using a bi-directional dual-encoder with additive margin softmax.\nThe embeddings are able to achieve state-of-the-art results on the United\nNations (UN) parallel corpus retrieval task. In all the languages tested, the\nsystem achieves P@1 of 86% or higher. We use pairs retrieved by our approach to\ntrain NMT models that achieve similar performance to models trained on gold\npairs. We explore simple document-level embeddings constructed by averaging our\nsentence embeddings. On the UN document-level retrieval task, document\nembeddings achieve around 97% on P@1 for all experimented language pairs.\nLastly, we evaluate the proposed model on the BUCC mining task. The learned\nembeddings with raw cosine similarity scores achieve competitive results\ncompared to current state-of-the-art models, and with a second-stage scorer we\nachieve a new state-of-the-art level on this task.", "published": "2019-02-22 17:11:03", "link": "http://arxiv.org/abs/1902.08564v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What makes a good conversation? How controllable attributes affect human\n  judgments", "abstract": "A good conversation requires balance -- between simplicity and detail;\nstaying on topic and changing it; asking questions and answering them. Although\ndialogue agents are commonly evaluated via human judgments of overall quality,\nthe relationship between quality and these individual factors is less\nwell-studied. In this work, we examine two controllable neural text generation\nmethods, conditional training and weighted decoding, in order to control four\nimportant attributes for chitchat dialogue: repetition, specificity,\nresponse-relatedness and question-asking. We conduct a large-scale human\nevaluation to measure the effect of these control parameters on multi-turn\ninteractive conversations on the PersonaChat task. We provide a detailed\nanalysis of their relationship to high-level aspects of conversation, and show\nthat by controlling combinations of these variables our models obtain clear\nimprovements in human quality judgments.", "published": "2019-02-22 19:59:47", "link": "http://arxiv.org/abs/1902.08654v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Clinical Concept Extraction with Contextual Embeddings", "abstract": "Neural network-based representations (\"embeddings\") have dramatically\nadvanced natural language processing (NLP) tasks, including clinical NLP tasks\nsuch as concept extraction. Recently, however, more advanced embedding methods\nand representations (e.g., ELMo, BERT) have further pushed the state-of-the-art\nin NLP, yet there are no common best practices for how to integrate these\nrepresentations into clinical tasks. The purpose of this study, then, is to\nexplore the space of possible options in utilizing these new models for\nclinical concept extraction, including comparing these to traditional word\nembedding methods (word2vec, GloVe, fastText). Both off-the-shelf open-domain\nembeddings and pre-trained clinical embeddings from MIMIC-III are evaluated. We\nexplore a battery of embedding methods consisting of traditional word\nembeddings and contextual embeddings, and compare these on four concept\nextraction corpora: i2b2 2010, i2b2 2012, SemEval 2014, and SemEval 2015. We\nalso analyze the impact of the pre-training time of a large language model like\nELMo or BERT on the extraction performance. Last, we present an intuitive way\nto understand the semantic information encoded by contextual embeddings.\nContextual embeddings pre-trained on a large clinical corpus achieves new\nstate-of-the-art performances across all concept extraction tasks. The\nbest-performing model outperforms all state-of-the-art methods with respective\nF1-measures of 90.25, 93.18 (partial), 80.74, and 81.65. We demonstrate the\npotential of contextual embeddings through the state-of-the-art performance\nthese methods achieve on clinical concept extraction. Additionally, we\ndemonstrate contextual embeddings encode valuable semantic information not\naccounted for in traditional word representations.", "published": "2019-02-22 22:24:37", "link": "http://arxiv.org/abs/1902.08691v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On How Users Edit Computer-Generated Visual Stories", "abstract": "A significant body of research in Artificial Intelligence (AI) has focused on\ngenerating stories automatically, either based on prior story plots or input\nimages. However, literature has little to say about how users would receive and\nuse these stories. Given the quality of stories generated by modern AI\nalgorithms, users will nearly inevitably have to edit these stories before\nputting them to real use. In this paper, we present the first analysis of how\nhuman users edit machine-generated stories. We obtained 962 short stories\ngenerated by one of the state-of-the-art visual storytelling models. For each\nstory, we recruited five crowd workers from Amazon Mechanical Turk to edit it.\nOur analysis of these edits shows that, on average, users (i) slightly\nshortened machine-generated stories, (ii) increased lexical diversity in these\nstories, and (iii) often replaced nouns and their determiners/articles with\npronouns. Our study provides a better understanding on how users receive and\nedit machine-generated stories,informing future researchers to create more\nusable and helpful story generation systems.", "published": "2019-02-22 01:26:05", "link": "http://arxiv.org/abs/1902.08327v2", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Learning to Learn Semantic Parsers from Natural Language Supervision", "abstract": "As humans, we often rely on language to learn language. For example, when\ncorrected in a conversation, we may learn from that correction, over time\nimproving our language fluency. Inspired by this observation, we propose a\nlearning algorithm for training semantic parsers from supervision (feedback)\nexpressed in natural language. Our algorithm learns a semantic parser from\nusers' corrections such as \"no, what I really meant was before his job, not\nafter\", by also simultaneously learning to parse this natural language feedback\nin order to leverage it as a form of supervision. Unlike supervision with\ngold-standard logical forms, our method does not require the user to be\nfamiliar with the underlying logical formalism, and unlike supervision from\ndenotation, it does not require the user to know the correct answer to their\nquery. This makes our learning algorithm naturally scalable in settings where\nexisting conversational logs are available and can be leveraged as training\ndata. We construct a novel dataset of natural language feedback in a\nconversational setting, and show that our method is effective at learning a\nsemantic parser from such natural language supervision.", "published": "2019-02-22 06:28:36", "link": "http://arxiv.org/abs/1902.08373v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Topology and dynamics of narratives on Brexit propagated by UK press\n  during 2016 and 2017", "abstract": "This article identifies and characterises political narratives regarding\nEurope and broadcasted in UK press during 2016 and 2017. A new theoretical and\noperational framework is proposed for typifying discourse narratives propagated\nin the public opinion space, based on the social constructivism and structural\nlinguistics approaches, and the mathematical theory of hypernetworks, where\nelementary units are aggregated into high-level entities. In this line of\nthought, a narrative is understood as a social construct where a related and\ncoherent aggregate of terms within public discourse is repeated and propagated\non media until it can be identified as a communication pattern, embodying\nmeaning in a way that provides individuals some interpretation of their world.\nAn inclusive methodology, with state-of-the-art technologies on natural\nlanguage processing and network theory, implements this concept of narrative. A\ncorpus from the Observatorium database, including articles from six UK\nnewspapers and incorporating far-right, right-wing, and left-wing narratives,\nis analysed. The research revealed clear distinctions between narratives along\nthe political spectrum. In 2016 far-right was particularly focused on\nemigration and refugees. Namely, during the referendum campaign, Europe was\nrelated to attacks on women and children, sexual offences, and terrorism.\nRight-wing was manly focused on internal politics, while left-wing was\nremarkably mentioning a diversity of non-political topics, such as sports, side\nby side with economics. During 2017, in general terrorism was less mentioned,\nand negotiations with EU, namely regarding economics, finance, and Ireland,\nbecame central.", "published": "2019-02-22 17:02:18", "link": "http://arxiv.org/abs/1902.08558v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "OpenKiwi: An Open Source Framework for Quality Estimation", "abstract": "We introduce OpenKiwi, a PyTorch-based open source framework for translation\nquality estimation. OpenKiwi supports training and testing of word-level and\nsentence-level quality estimation systems, implementing the winning systems of\nthe WMT 2015-18 quality estimation campaigns. We benchmark OpenKiwi on two\ndatasets from WMT 2018 (English-German SMT and NMT), yielding state-of-the-art\nperformance on the word-level tasks and near state-of-the-art in the\nsentence-level tasks.", "published": "2019-02-22 19:27:45", "link": "http://arxiv.org/abs/1902.08646v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large-Scale Answerer in Questioner's Mind for Visual Dialog Question\n  Generation", "abstract": "Answerer in Questioner's Mind (AQM) is an information-theoretic framework\nthat has been recently proposed for task-oriented dialog systems. AQM benefits\nfrom asking a question that would maximize the information gain when it is\nasked. However, due to its intrinsic nature of explicitly calculating the\ninformation gain, AQM has a limitation when the solution space is very large.\nTo address this, we propose AQM+ that can deal with a large-scale problem and\nask a question that is more coherent to the current context of the dialog. We\nevaluate our method on GuessWhich, a challenging task-oriented visual dialog\nproblem, where the number of candidate classes is near 10K. Our experimental\nresults and ablation studies show that AQM+ outperforms the state-of-the-art\nmodels by a remarkable margin with a reasonable approximation. In particular,\nthe proposed AQM+ reduces more than 60% of error as the dialog proceeds, while\nthe comparative algorithms diminish the error by less than 6%. Based on our\nresults, we argue that AQM+ is a general task-oriented dialog algorithm that\ncan be applied for non-yes-or-no responses.", "published": "2019-02-22 03:46:53", "link": "http://arxiv.org/abs/1902.08355v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Trajectories of Blocked Community Members: Redemption, Recidivism and\n  Departure", "abstract": "Community norm violations can impair constructive communication and\ncollaboration online. As a defense mechanism, community moderators often\naddress such transgressions by temporarily blocking the perpetrator. Such\nactions, however, come with the cost of potentially alienating community\nmembers. Given this tradeoff, it is essential to understand to what extent, and\nin which situations, this common moderation practice is effective in\nreinforcing community rules.\n  In this work, we introduce a computational framework for studying the future\nbehavior of blocked users on Wikipedia. After their block expires, they can\ntake several distinct paths: they can reform and adhere to the rules, but they\ncan also recidivate, or straight-out abandon the community. We reveal that\nthese trajectories are tied to factors rooted both in the characteristics of\nthe blocked individual and in whether they perceived the block to be fair and\njustified. Based on these insights, we formulate a series of prediction tasks\naiming to determine which of these paths a user is likely to take after being\nblocked for their first offense, and demonstrate the feasibility of these new\ntasks. Overall, this work builds towards a more nuanced approach to moderation\nby highlighting the tradeoffs that are in play.", "published": "2019-02-22 19:00:10", "link": "http://arxiv.org/abs/1902.08628v1", "categories": ["cs.CY", "cs.CL", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CY"}
{"title": "Saliency Learning: Teaching the Model Where to Pay Attention", "abstract": "Deep learning has emerged as a compelling solution to many NLP tasks with\nremarkable performances. However, due to their opacity, such models are hard to\ninterpret and trust. Recent work on explaining deep models has introduced\napproaches to provide insights toward the model's behaviour and predictions,\nwhich are helpful for assessing the reliability of the model's predictions.\nHowever, such methods do not improve the model's reliability. In this paper, we\naim to teach the model to make the right prediction for the right reason by\nproviding explanation training and ensuring the alignment of the model's\nexplanation with the ground truth explanation. Our experimental results on\nmultiple tasks and datasets demonstrate the effectiveness of the proposed\nmethod, which produces more reliable predictions while delivering better\nresults compared to traditionally trained models.", "published": "2019-02-22 19:38:36", "link": "http://arxiv.org/abs/1902.08649v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Non-Autoregressive Machine Translation with Auxiliary Regularization", "abstract": "As a new neural machine translation approach, Non-Autoregressive machine\nTranslation (NAT) has attracted attention recently due to its high efficiency\nin inference. However, the high efficiency has come at the cost of not\ncapturing the sequential dependency on the target side of translation, which\ncauses NAT to suffer from two kinds of translation errors: 1) repeated\ntranslations (due to indistinguishable adjacent decoder hidden states), and 2)\nincomplete translations (due to incomplete transfer of source side information\nvia the decoder hidden states).\n  In this paper, we propose to address these two problems by improving the\nquality of decoder hidden representations via two auxiliary regularization\nterms in the training process of an NAT model. First, to make the hidden states\nmore distinguishable, we regularize the similarity between consecutive hidden\nstates based on the corresponding target tokens. Second, to force the hidden\nstates to contain all the information in the source sentence, we leverage the\ndual nature of translation tasks (e.g., English to German and German to\nEnglish) and minimize a backward reconstruction error to ensure that the hidden\nstates of the NAT decoder are able to recover the source side sentence.\nExtensive experiments conducted on several benchmark datasets show that both\nregularization strategies are effective and can alleviate the issues of\nrepeated translations and incomplete translations in NAT models. The accuracy\nof NAT models is therefore improved significantly over the state-of-the-art NAT\nmodels with even better efficiency for inference.", "published": "2019-02-22 02:37:15", "link": "http://arxiv.org/abs/1902.10245v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Fast Multi-language LSTM-based Online Handwriting Recognition", "abstract": "We describe an online handwriting system that is able to support 102\nlanguages using a deep neural network architecture. This new system has\ncompletely replaced our previous Segment-and-Decode-based system and reduced\nthe error rate by 20%-40% relative for most languages. Further, we report new\nstate-of-the-art results on IAM-OnDB for both the open and closed dataset\nsetting. The system combines methods from sequence recognition with a new input\nencoding using B\\'ezier curves. This leads to up to 10x faster recognition\ntimes compared to our previous system. Through a series of experiments we\ndetermine the optimal configuration of our models and report the results of our\nsetup on a number of additional public datasets.", "published": "2019-02-22 12:33:38", "link": "http://arxiv.org/abs/1902.10525v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
