{"title": "Cutting Recursive Autoencoder Trees", "abstract": "Deep Learning models enjoy considerable success in Natural Language\nProcessing. While deep architectures produce useful representations that lead\nto improvements in various tasks, they are often difficult to interpret. This\nmakes the analysis of learned structures particularly difficult. In this paper,\nwe rely on empirical tests to see whether a particular structure makes sense.\nWe present an analysis of the Semi-Supervised Recursive Autoencoder, a\nwell-known model that produces structural representations of text. We show that\nfor certain tasks, the structure of the autoencoder can be significantly\nreduced without loss of classification accuracy and we evaluate the produced\nstructures using human judgment.", "published": "2013-01-13 19:33:31", "link": "http://arxiv.org/abs/1301.2811v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
