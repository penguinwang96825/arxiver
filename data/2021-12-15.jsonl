{"title": "Cross-Domain Generalization and Knowledge Transfer in Transformers\n  Trained on Legal Data", "abstract": "We analyze the ability of pre-trained language models to transfer knowledge\namong datasets annotated with different type systems and to generalize beyond\nthe domain and dataset they were trained on. We create a meta task, over\nmultiple datasets focused on the prediction of rhetorical roles. Prediction of\nthe rhetorical role a sentence plays in a case decision is an important and\noften studied task in AI & Law. Typically, it requires the annotation of a\nlarge number of sentences to train a model, which can be time-consuming and\nexpensive. Further, the application of the models is restrained to the same\ndataset it was trained on. We fine-tune language models and evaluate their\nperformance across datasets, to investigate the models' ability to generalize\nacross domains. Our results suggest that the approach could be helpful in\novercoming the cold-start problem in active or interactvie learning, and shows\nthe ability of the models to generalize across datasets and domains.", "published": "2021-12-15 04:23:14", "link": "http://arxiv.org/abs/2112.07870v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic Frameworks Go Toe-to-Toe at Neuro-Symbolic Language Modeling", "abstract": "We examine the extent to which, in principle, linguistic graph\nrepresentations can complement and improve neural language modeling. With an\nensemble setup consisting of a pretrained Transformer and ground-truth graphs\nfrom one of 7 different formalisms, we find that, overall, semantic\nconstituency structures are most useful to language modeling performance --\noutpacing syntactic constituency structures as well as syntactic and semantic\ndependency structures. Further, effects vary greatly depending on\npart-of-speech class. In sum, our findings point to promising tendencies in\nneuro-symbolic language modeling and invite future research quantifying the\ndesign choices made by different formalisms.", "published": "2021-12-15 04:29:02", "link": "http://arxiv.org/abs/2112.07874v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Transpile AMR into SPARQL", "abstract": "We propose a transition-based system to transpile Abstract Meaning\nRepresentation (AMR) into SPARQL for Knowledge Base Question Answering (KBQA).\nThis allows us to delegate part of the semantic representation to a strongly\npre-trained semantic parser, while learning transpiling with small amount of\npaired data. We depart from recent work relating AMR and SPARQL constructs, but\nrather than applying a set of rules, we teach a BART model to selectively use\nthese relations. Further, we avoid explicitly encoding AMR but rather encode\nthe parser state in the attention mechanism of BART, following recent semantic\nparsing works. The resulting model is simple, provides supporting text for its\ndecisions, and outperforms recent approaches in KBQA across two knowledge\nbases: DBPedia (LC-QuAD 1.0, QALD-9) and Wikidata (WebQSP, SWQ-WD).", "published": "2021-12-15 04:38:15", "link": "http://arxiv.org/abs/2112.07877v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lex Rosetta: Transfer of Predictive Models Across Languages,\n  Jurisdictions, and Legal Domains", "abstract": "In this paper, we examine the use of multi-lingual sentence embeddings to\ntransfer predictive models for functional segmentation of adjudicatory\ndecisions across jurisdictions, legal systems (common and civil law),\nlanguages, and domains (i.e. contexts). Mechanisms for utilizing linguistic\nresources outside of their original context have significant potential benefits\nin AI & Law because differences between legal systems, languages, or traditions\noften block wider adoption of research outcomes. We analyze the use of\nLanguage-Agnostic Sentence Representations in sequence labeling models using\nGated Recurrent Units (GRUs) that are transferable across languages. To\ninvestigate transfer between different contexts we developed an annotation\nscheme for functional segmentation of adjudicatory decisions. We found that\nmodels generalize beyond the contexts on which they were trained (e.g., a model\ntrained on administrative decisions from the US can be applied to criminal law\ndecisions from Italy). Further, we found that training the models on multiple\ncontexts increases robustness and improves overall performance when evaluating\non previously unseen contexts. Finally, we found that pooling the training data\nfrom all the contexts enhances the models' in-context performance.", "published": "2021-12-15 04:53:13", "link": "http://arxiv.org/abs/2112.07882v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-Rich Self-Supervision for Biomedical Entity Linking", "abstract": "Entity linking faces significant challenges such as prolific variations and\nprevalent ambiguities, especially in high-value domains with myriad entities.\nStandard classification approaches suffer from the annotation bottleneck and\ncannot effectively handle unseen entities. Zero-shot entity linking has emerged\nas a promising direction for generalizing to new entities, but it still\nrequires example gold entity mentions during training and canonical\ndescriptions for all entities, both of which are rarely available outside of\nWikipedia. In this paper, we explore Knowledge-RIch Self-Supervision ($\\tt\nKRISS$) for biomedical entity linking, by leveraging readily available domain\nknowledge. In training, it generates self-supervised mention examples on\nunlabeled text using a domain ontology and trains a contextual encoder using\ncontrastive learning. For inference, it samples self-supervised mentions as\nprototypes for each entity and conducts linking by mapping the test mention to\nthe most similar prototype. Our approach can easily incorporate entity\ndescriptions and gold mention labels if available. We conducted extensive\nexperiments on seven standard datasets spanning biomedical literature and\nclinical notes. Without using any labeled information, our method produces $\\tt\nKRISSBERT$, a universal entity linker for four million UMLS entities that\nattains new state of the art, outperforming prior self-supervised methods by as\nmuch as 20 absolute points in accuracy.", "published": "2021-12-15 05:05:12", "link": "http://arxiv.org/abs/2112.07887v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Event Linking: Grounding Event Mentions to Wikipedia", "abstract": "Comprehending an article requires understanding its constituent events.\nHowever, the context where an event is mentioned often lacks the details of\nthis event. A question arises: how can the reader obtain more knowledge about\nthis particular event in addition to what is provided by the local context in\nthe article?\n  This work defines Event Linking, a new natural language understanding task at\nthe event level. Event linking tries to link an event mention appearing in an\narticle to the most appropriate Wikipedia page. This page is expected to\nprovide rich knowledge about what the event mention refers to. To standardize\nthe research in this new direction, we contribute in four-fold. First, this is\nthe first work in the community that formally defines Event Linking task.\nSecond, we collect a dataset for this new task. Specifically, we automatically\ngather training set from Wikipedia, and then create two evaluation sets: one\nfrom the Wikipedia domain, reporting the in-domain performance, and a second\nfrom the real-world news domain, to evaluate out-of-domain performance. Third,\nwe retrain and evaluate two state-of-the-art (SOTA) entity linking models,\nshowing the challenges of event linking, and we propose an event-specific\nlinking system EVELINK to set a competitive result for the new task. Fourth, we\nconduct a detailed and insightful analysis to help understand the task and the\nlimitation of the current model. Overall, as our analysis shows, Event Linking\nis a considerably challenging and essential task requiring more effort from the\ncommunity. Data and code are available here:\nhttps://github.com/CogComp/event-linking.", "published": "2021-12-15 05:06:18", "link": "http://arxiv.org/abs/2112.07888v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences", "abstract": "Recent work has shown that either (1) increasing the input length or (2)\nincreasing model size can improve the performance of Transformer-based neural\nmodels. In this paper, we present a new model, called LongT5, with which we\nexplore the effects of scaling both the input length and model size at the same\ntime. Specifically, we integrated attention ideas from long-input transformers\n(ETC), and adopted pre-training strategies from summarization pre-training\n(PEGASUS) into the scalable T5 architecture. The result is a new attention\nmechanism we call {\\em Transient Global} (TGlobal), which mimics ETC's\nlocal/global attention mechanism, but without requiring additional side-inputs.\nWe are able to achieve state-of-the-art results on several summarization tasks\nand outperform the original T5 models on question answering tasks.", "published": "2021-12-15 06:35:29", "link": "http://arxiv.org/abs/2112.07916v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge-Grounded Dialogue Generation with a Unified Knowledge\n  Representation", "abstract": "Knowledge-grounded dialogue systems are challenging to build due to the lack\nof training data and heterogeneous knowledge sources. Existing systems perform\npoorly on unseen topics due to limited topics covered in the training data. In\naddition, heterogeneous knowledge sources make it challenging for systems to\ngeneralize to other tasks because knowledge sources in different knowledge\nrepresentations require different knowledge encoders. To address these\nchallenges, we present PLUG, a language model that homogenizes different\nknowledge sources to a unified knowledge representation for knowledge-grounded\ndialogue generation tasks. PLUG is pre-trained on a dialogue generation task\nconditioned on a unified essential knowledge representation. It can generalize\nto different downstream knowledge-grounded dialogue generation tasks with a few\ntraining examples. The empirical evaluation on two benchmarks shows that our\nmodel generalizes well across different knowledge-grounded tasks. It can\nachieve comparable performance with state-of-the-art methods under a\nfully-supervised setting and significantly outperforms other methods in\nzero-shot and few-shot settings.", "published": "2021-12-15 07:11:02", "link": "http://arxiv.org/abs/2112.07924v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Named entity recognition architecture combining contextual and global\n  features", "abstract": "Named entity recognition (NER) is an information extraction technique that\naims to locate and classify named entities (e.g., organizations, locations,...)\nwithin a document into predefined categories. Correctly identifying these\nphrases plays a significant role in simplifying information access. However, it\nremains a difficult task because named entities (NEs) have multiple forms and\nthey are context-dependent. While the context can be represented by contextual\nfeatures, global relations are often misrepresented by those models. In this\npaper, we propose the combination of contextual features from XLNet and global\nfeatures from Graph Convolution Network (GCN) to enhance NER performance.\nExperiments over a widely-used dataset, CoNLL 2003, show the benefits of our\nstrategy, with results competitive with the state of the art (SOTA).", "published": "2021-12-15 10:54:36", "link": "http://arxiv.org/abs/2112.08033v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Human Evaluation for Relative Model Comparisons", "abstract": "Collecting human judgements is currently the most reliable evaluation method\nfor natural language generation systems. Automatic metrics have reported flaws\nwhen applied to measure quality aspects of generated text and have been shown\nto correlate poorly with human judgements. However, human evaluation is time\nand cost-intensive, and we lack consensus on designing and conducting human\nevaluation experiments. Thus there is a need for streamlined approaches for\nefficient collection of human judgements when evaluating natural language\ngeneration systems. Therefore, we present a dynamic approach to measure the\nrequired number of human annotations when evaluating generated outputs in\nrelative comparison settings. We propose an agent-based framework of human\nevaluation to assess multiple labelling strategies and methods to decide the\nbetter model in a simulation and a crowdsourcing case study. The main results\nindicate that a decision about the superior model can be made with high\nprobability across different labelling strategies, where assigning a single\nrandom worker per task requires the least overall labelling effort and thus the\nleast cost.", "published": "2021-12-15 11:32:13", "link": "http://arxiv.org/abs/2112.08048v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Faster Nearest Neighbor Machine Translation", "abstract": "$k$NN based neural machine translation ($k$NN-MT) has achieved\nstate-of-the-art results in a variety of MT tasks. One significant shortcoming\nof $k$NN-MT lies in its inefficiency in identifying the $k$ nearest neighbors\nof the query representation from the entire datastore, which is prohibitively\ntime-intensive when the datastore size is large. In this work, we propose\n\\textbf{Faster $k$NN-MT} to address this issue. The core idea of Faster\n$k$NN-MT is to use a hierarchical clustering strategy to approximate the\ndistance between the query and a data point in the datastore, which is\ndecomposed into two parts: the distance between the query and the center of the\ncluster that the data point belongs to, and the distance between the data point\nand the cluster center. We propose practical ways to compute these two parts in\na significantly faster manner. Through extensive experiments on different MT\nbenchmarks, we show that \\textbf{Faster $k$NN-MT} is faster than Fast $k$NN-MT\n\\citep{meng2021fast} and only slightly (1.2 times) slower than its vanilla\ncounterpart while preserving model performance as $k$NN-MT. Faster $k$NN-MT\nenables the deployment of $k$NN-MT models on real-world MT services.", "published": "2021-12-15 14:21:26", "link": "http://arxiv.org/abs/2112.08152v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One size does not fit all: Investigating strategies for\n  differentially-private learning across NLP tasks", "abstract": "Preserving privacy in contemporary NLP models allows us to work with\nsensitive data, but unfortunately comes at a price. We know that stricter\nprivacy guarantees in differentially-private stochastic gradient descent\n(DP-SGD) generally degrade model performance. However, previous research on the\nefficiency of DP-SGD in NLP is inconclusive or even counter-intuitive. In this\nshort paper, we provide an extensive analysis of different privacy preserving\nstrategies on seven downstream datasets in five different `typical' NLP tasks\nwith varying complexity using modern neural models based on BERT and\nXtremeDistil architectures. We show that unlike standard non-private approaches\nto solving NLP tasks, where bigger is usually better, privacy-preserving\nstrategies do not exhibit a winning pattern, and each task and privacy regime\nrequires a special treatment to achieve adequate performance.", "published": "2021-12-15 14:31:32", "link": "http://arxiv.org/abs/2112.08159v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lesan -- Machine Translation for Low Resource Languages", "abstract": "Millions of people around the world can not access content on the Web because\nmost of the content is not readily available in their language. Machine\ntranslation (MT) systems have the potential to change this for many languages.\nCurrent MT systems provide very accurate results for high resource language\npairs, e.g., German and English. However, for many low resource languages, MT\nis still under active research. The key challenge is lack of datasets to build\nthese systems. We present Lesan, an MT system for low resource languages. Our\npipeline solves the key bottleneck to low resource MT by leveraging online and\noffline sources, a custom OCR system for Ethiopic and an automatic alignment\nmodule. The final step in the pipeline is a sequence to sequence model that\ntakes parallel corpus as input and gives us a translation model. Lesan's\ntranslation model is based on the Transformer architecture. After constructing\na base model, back translation, is used to leverage monolingual corpora.\nCurrently Lesan supports translation to and from Tigrinya, Amharic and English.\nWe perform extensive human evaluation and show that Lesan outperforms\nstate-of-the-art systems such as Google Translate and Microsoft Translator\nacross all six pairs. Lesan is freely available and has served more than 10\nmillion translations so far. At the moment, there are only 217 Tigrinya and\n15,009 Amharic Wikipedia articles. We believe that Lesan will contribute\ntowards democratizing access to the Web through MT for millions of people.", "published": "2021-12-15 15:11:53", "link": "http://arxiv.org/abs/2112.08191v1", "categories": ["cs.CL", "I.2.7; I.2.1"], "primary_category": "cs.CL"}
{"title": "KGR^4: Retrieval, Retrospect, Refine and Rethink for Commonsense\n  Generation", "abstract": "Generative commonsense reasoning requires machines to generate sentences\ndescribing an everyday scenario given several concepts, which has attracted\nmuch attention recently. However, existing models cannot perform as well as\nhumans, since sentences they produce are often implausible and grammatically\nincorrect. In this paper, inspired by the process of humans creating sentences,\nwe propose a novel Knowledge-enhanced Commonsense Generation framework, termed\nKGR^4, consisting of four stages: Retrieval, Retrospect, Refine, Rethink. Under\nthis framework, we first perform retrieval to search for relevant sentences\nfrom external corpus as the prototypes. Then, we train the generator that\neither edits or copies these prototypes to generate candidate sentences, of\nwhich potential errors will be fixed by an autoencoder-based refiner. Finally,\nwe select the output sentence from candidate sentences produced by generators\nwith different hyper-parameters. Experimental results and in-depth analysis on\nthe CommonGen benchmark strongly demonstrate the effectiveness of our\nframework. Particularly, KGR^4 obtains 33.56 SPICE points in the official\nleaderboard, outperforming the previously-reported best result by 2.49 SPICE\npoints and achieving state-of-the-art performance.", "published": "2021-12-15 17:00:11", "link": "http://arxiv.org/abs/2112.08266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Both Domain Robustness and Domain Adaptability in Machine\n  Translation", "abstract": "We consider two problems of NMT domain adaptation using meta-learning. First,\nwe want to reach domain robustness, i.e., we want to reach high quality on both\ndomains seen in the training data and unseen domains. Second, we want our\nsystems to be adaptive, i.e., making it possible to finetune systems with just\nhundreds of in-domain parallel sentences. We study the domain adaptability of\nmeta-learning when improving the domain robustness of the model. In this paper,\nwe propose a novel approach, RMLNMT (Robust Meta-Learning Framework for Neural\nMachine Translation Domain Adaptation), which improves the robustness of\nexisting meta-learning models. More specifically, we show how to use a domain\nclassifier in curriculum learning and we integrate the word-level domain mixing\nmodel into the meta-learning framework with a balanced sampling strategy.\nExperiments on English$\\rightarrow$German and English$\\rightarrow$Chinese\ntranslation show that RMLNMT improves in terms of both domain robustness and\ndomain adaptability in seen and unseen domains. Our source code is available at\nhttps://github.com/lavine-lmu/RMLNMT.", "published": "2021-12-15 17:34:59", "link": "http://arxiv.org/abs/2112.08288v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decomposing Natural Logic Inferences in Neural NLI", "abstract": "In the interest of interpreting neural NLI models and their reasoning\nstrategies, we carry out a systematic probing study which investigates whether\nthese models capture the crucial semantic features central to natural logic:\nmonotonicity and concept inclusion. Correctly identifying valid inferences in\ndownward-monotone contexts is a known stumbling block for NLI performance,\nsubsuming linguistic phenomena such as negation scope and generalized\nquantifiers. To understand this difficulty, we emphasize monotonicity as a\nproperty of a context and examine the extent to which models capture\nmonotonicity information in the contextual embeddings which are intermediate to\ntheir decision making process. Drawing on the recent advancement of the probing\nparadigm, we compare the presence of monotonicity features across various\nmodels. We find that monotonicity information is notably weak in the\nrepresentations of popular NLI models which achieve high scores on benchmarks,\nand observe that previous improvements to these models based on fine-tuning\nstrategies have introduced stronger monotonicity features together with their\nimproved performance on challenge sets.", "published": "2021-12-15 17:35:30", "link": "http://arxiv.org/abs/2112.08289v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Know Thy Strengths: Comprehensive Dialogue State Tracking Diagnostics", "abstract": "Recent works that revealed the vulnerability of dialogue state tracking (DST)\nmodels to distributional shifts have made holistic comparisons on robustness\nand qualitative analyses increasingly important for understanding their\nrelative performance. We present our findings from standardized and\ncomprehensive DST diagnoses, which have previously been sparse and\nuncoordinated, using our toolkit, CheckDST, a collection of robustness tests\nand failure mode analytics. We discover that different classes of DST models\nhave clear strengths and weaknesses, where generation models are more promising\nfor handling language variety while span-based classification models are more\nrobust to unseen entities. Prompted by this discovery, we also compare\ncheckpoints from the same model and find that the standard practice of\nselecting checkpoints using validation loss/accuracy is prone to overfitting\nand each model class has distinct patterns of failure. Lastly, we demonstrate\nhow our diagnoses motivate a pre-finetuning procedure with non-dialogue data\nthat offers comprehensive improvements to generation models by alleviating the\nimpact of distributional shifts through transfer learning.", "published": "2021-12-15 18:10:54", "link": "http://arxiv.org/abs/2112.08321v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is \"My Favorite New Movie\" My Favorite Movie? Probing the Understanding\n  of Recursive Noun Phrases", "abstract": "Recursive noun phrases (NPs) have interesting semantic properties. For\nexample, \"my favorite new movie\" is not necessarily my favorite movie, whereas\n\"my new favorite movie\" is. This is common sense to humans, yet it is unknown\nwhether language models have such knowledge. We introduce the Recursive Noun\nPhrase Challenge (RNPC), a dataset of three textual inference tasks involving\ntextual entailment and event plausibility comparison, precisely targeting the\nunderstanding of recursive NPs. When evaluated on RNPC, state-of-the-art\nTransformer models only perform around chance. Still, we show that such\nknowledge is learnable with appropriate data. We further probe the models for\nrelevant linguistic features that can be learned from our tasks, including\nmodifier semantic category and modifier scope. Finally, models trained on RNPC\nachieve strong zero-shot performance on an extrinsic Harm Detection evaluation\ntask, showing the usefulness of the understanding of recursive NPs in\ndownstream applications.", "published": "2021-12-15 18:20:02", "link": "http://arxiv.org/abs/2112.08326v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Pretrained Transformer Models for Entity Linking in\n  Task-Oriented Dialog", "abstract": "The wide applicability of pretrained transformer models (PTMs) for natural\nlanguage tasks is well demonstrated, but their ability to comprehend short\nphrases of text is less explored. To this end, we evaluate different PTMs from\nthe lens of unsupervised Entity Linking in task-oriented dialog across 5\ncharacteristics -- syntactic, semantic, short-forms, numeric and phonetic. Our\nresults demonstrate that several of the PTMs produce sub-par results when\ncompared to traditional techniques, albeit competitive to other neural\nbaselines. We find that some of their shortcomings can be addressed by using\nPTMs fine-tuned for text-similarity tasks, which illustrate an improved ability\nin comprehending semantic and syntactic correspondences, as well as some\nimprovements for short-forms, numeric and phonetic variations in entity\nmentions. We perform qualitative analysis to understand nuances in their\npredictions and discuss scope for further improvements. Code can be found at\nhttps://github.com/murali1996/el_tod", "published": "2021-12-15 18:20:12", "link": "http://arxiv.org/abs/2112.08327v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AllWOZ: Towards Multilingual Task-Oriented Dialog Systems for All", "abstract": "A commonly observed problem of the state-of-the-art natural language\ntechnologies, such as Amazon Alexa and Apple Siri, is that their services do\nnot extend to most developing countries' citizens due to language barriers.\nSuch populations suffer due to the lack of available resources in their\nlanguages to build NLP products. This paper presents AllWOZ, a multilingual\nmulti-domain task-oriented customer service dialog dataset covering eight\nlanguages: English, Mandarin, Korean, Vietnamese, Hindi, French, Portuguese,\nand Thai. Furthermore, we create a benchmark for our multilingual dataset by\napplying mT5 with meta-learning.", "published": "2021-12-15 18:30:51", "link": "http://arxiv.org/abs/2112.08333v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DG2: Data Augmentation Through Document Grounded Dialogue Generation", "abstract": "Collecting data for training dialog systems can be extremely expensive due to\nthe involvement of human participants and need for extensive annotation.\nEspecially in document-grounded dialog systems, human experts need to carefully\nread the unstructured documents to answer the users' questions. As a result,\nexisting document-grounded dialog datasets are relatively small-scale and\nobstruct the effective training of dialogue systems. In this paper, we propose\nan automatic data augmentation technique grounded on documents through a\ngenerative dialogue model. The dialogue model consists of a user bot and agent\nbot that can synthesize diverse dialogues given an input document, which are\nthen used to train a downstream model. When supplementing the original dataset,\nour method achieves significant improvement over traditional data augmentation\nmethods. We also achieve great performance in the low-resource setting.", "published": "2021-12-15 18:50:14", "link": "http://arxiv.org/abs/2112.08342v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt Waywardness: The Curious Case of Discretized Interpretation of\n  Continuous Prompts", "abstract": "Fine-tuning continuous prompts for target tasks has recently emerged as a\ncompact alternative to full model fine-tuning. Motivated by these promising\nresults, we investigate the feasibility of extracting a discrete (textual)\ninterpretation of continuous prompts that is faithful to the problem they\nsolve. In practice, we observe a \"wayward\" behavior between the task solved by\ncontinuous prompts and their nearest neighbor discrete projections: We can find\ncontinuous prompts that solve a task while being projected to an arbitrary text\n(e.g., definition of a different or even a contradictory task), while being\nwithin a very small (2%) margin of the best continuous prompt of the same size\nfor the task. We provide intuitions behind this odd and surprising behavior, as\nwell as extensive empirical analyses quantifying the effect of various\nparameters. For instance, for larger model sizes we observe higher waywardness,\ni.e, we can find prompts that more closely map to any arbitrary text with a\nsmaller drop in accuracy. These findings have important implications relating\nto the difficulty of faithfully interpreting continuous prompts and their\ngeneralization across models and tasks, providing guidance for future progress\nin prompting language models.", "published": "2021-12-15 18:55:05", "link": "http://arxiv.org/abs/2112.08348v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Database Search Results Disambiguation for Task-Oriented Dialog Systems", "abstract": "As task-oriented dialog systems are becoming increasingly popular in our\nlives, more realistic tasks have been proposed and explored. However, new\npractical challenges arise. For instance, current dialog systems cannot\neffectively handle multiple search results when querying a database, due to the\nlack of such scenarios in existing public datasets. In this paper, we propose\nDatabase Search Result (DSR) Disambiguation, a novel task that focuses on\ndisambiguating database search results, which enhances user experience by\nallowing them to choose from multiple options instead of just one. To study\nthis task, we augment the popular task-oriented dialog datasets (MultiWOZ and\nSGD) with turns that resolve ambiguities by (a) synthetically generating turns\nthrough a pre-defined grammar, and (b) collecting human paraphrases for a\nsubset. We find that training on our augmented dialog data improves the model's\nability to deal with ambiguous scenarios, without sacrificing performance on\nunmodified turns. Furthermore, pre-fine tuning and multi-task learning help our\nmodel to improve performance on DSR-disambiguation even in the absence of\nin-domain data, suggesting that it can be learned as a universal dialog skill.\nOur data and code will be made publicly available.", "published": "2021-12-15 18:56:18", "link": "http://arxiv.org/abs/2112.08351v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Applying SoftTriple Loss for Supervised Language Model Fine Tuning", "abstract": "We introduce a new loss function TripleEntropy, to improve classification\nperformance for fine-tuning general knowledge pre-trained language models based\non cross-entropy and SoftTriple loss. This loss function can improve the robust\nRoBERTa baseline model fine-tuned with cross-entropy loss by about (0.02% -\n2.29%). Thorough tests on popular datasets indicate a steady gain. The fewer\nsamples in the training dataset, the higher gain -- thus, for small-sized\ndataset it is 0.78%, for medium-sized -- 0.86% for large -- 0.20% and for\nextra-large 0.04%.", "published": "2021-12-15 20:21:20", "link": "http://arxiv.org/abs/2112.08462v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ErAConD : Error Annotated Conversational Dialog Dataset for Grammatical\n  Error Correction", "abstract": "Currently available grammatical error correction (GEC) datasets are compiled\nusing well-formed written text, limiting the applicability of these datasets to\nother domains such as informal writing and dialog. In this paper, we present a\nnovel parallel GEC dataset drawn from open-domain chatbot conversations; this\ndataset is, to our knowledge, the first GEC dataset targeted to a\nconversational setting. To demonstrate the utility of the dataset, we use our\nannotated data to fine-tune a state-of-the-art GEC model, resulting in a 16\npoint increase in model precision. This is of particular importance in a GEC\nmodel, as model precision is considered more important than recall in GEC tasks\nsince false positives could lead to serious confusion in language learners. We\nalso present a detailed annotation scheme which ranks errors by perceived\nimpact on comprehensibility, making our dataset both reproducible and\nextensible. Experimental results show the effectiveness of our data in\nimproving GEC model performance in conversational scenario.", "published": "2021-12-15 20:27:40", "link": "http://arxiv.org/abs/2112.08466v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Human Languages with Greater Information Density Increase Communication\n  Speed, but Decrease Conversation Breadth", "abstract": "Human languages vary widely in how they encode information within\ncircumscribed semantic domains (e.g., time, space, color, human body parts and\nactivities), but little is known about the global structure of semantic\ninformation and nothing about its relation to human communication. We first\nshow that across a sample of ~1,000 languages, there is broad variation in how\ndensely languages encode information into their words. Second, we show that\nthis language information density is associated with a denser configuration of\nsemantic information. Finally, we trace the relationship between language\ninformation density and patterns of communication, showing that informationally\ndenser languages tend toward (1) faster communication, but (2) conceptually\nnarrower conversations within which topics of conversation are discussed at\ngreater depth. These results highlight an important source of variation across\nthe human communicative channel, revealing that the structure of language\nshapes the nature and texture of human engagement, with consequences for human\nbehavior across levels of society.", "published": "2021-12-15 21:35:56", "link": "http://arxiv.org/abs/2112.08491v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DocAMR: Multi-Sentence AMR Representation and Evaluation", "abstract": "Despite extensive research on parsing of English sentences into Abstraction\nMeaning Representation (AMR) graphs, which are compared to gold graphs via the\nSmatch metric, full-document parsing into a unified graph representation lacks\nwell-defined representation and evaluation. Taking advantage of a\nsuper-sentential level of coreference annotation from previous work, we\nintroduce a simple algorithm for deriving a unified graph representation,\navoiding the pitfalls of information loss from over-merging and lack of\ncoherence from under-merging. Next, we describe improvements to the Smatch\nmetric to make it tractable for comparing document-level graphs, and use it to\nre-evaluate the best published document-level AMR parser. We also present a\npipeline approach combining the top performing AMR parser and coreference\nresolution systems, providing a strong baseline for future research.", "published": "2021-12-15 22:38:26", "link": "http://arxiv.org/abs/2112.08513v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Penn-Helsinki Parsed Corpus of Early Modern English: First Parsing\n  Results and Analysis", "abstract": "We present the first parsing results on the Penn-Helsinki Parsed Corpus of\nEarly Modern English (PPCEME), a 1.9 million word treebank that is an important\nresource for research in syntactic change. We describe key features of PPCEME\nthat make it challenging for parsing, including a larger and more varied set of\nfunction tags than in the Penn Treebank. We present results for this corpus\nusing a modified version of the Berkeley Neural Parser and the approach to\nfunction tag recovery of Gabbard et al (2006). Despite its simplicity, this\napproach works surprisingly well, suggesting it is possible to recover the\noriginal structure with sufficient accuracy to support linguistic applications\n(e.g., searching for syntactic structures of interest). However, for a subset\nof function tags (e.g., the tag indicating direct speech), additional work is\nneeded, and we discuss some further limits of this approach. The resulting\nparser will be used to parse Early English Books Online, a 1.1 billion word\ncorpus whose utility for the study of syntactic change will be greatly\nincreased with the addition of accurate parse trees.", "published": "2021-12-15 23:56:21", "link": "http://arxiv.org/abs/2112.08532v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-shot Instruction Prompts for Pretrained Language Models to Detect\n  Social Biases", "abstract": "Detecting social bias in text is challenging due to nuance, subjectivity, and\ndifficulty in obtaining good quality labeled datasets at scale, especially\ngiven the evolving nature of social biases and society. To address these\nchallenges, we propose a few-shot instruction-based method for prompting\npre-trained language models (LMs). We select a few class-balanced exemplars\nfrom a small support repository that are closest to the query to be labeled in\nthe embedding space. We then provide the LM with instruction that consists of\nthis subset of labeled exemplars, the query text to be classified, a definition\nof bias, and prompt it to make a decision. We demonstrate that large LMs used\nin a few-shot context can detect different types of fine-grained biases with\nsimilar and sometimes superior accuracy to fine-tuned models. We observe that\nthe largest 530B parameter model is significantly more effective in detecting\nsocial bias compared to smaller models (achieving at least 13% improvement in\nAUC metric compared to other models). It also maintains a high AUC (dropping\nless than 2%) when the labeled repository is reduced to as few as $100$\nsamples. Large pretrained language models thus make it easier and quicker to\nbuild new bias detectors.", "published": "2021-12-15 04:19:52", "link": "http://arxiv.org/abs/2112.07868v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning Large Neural Language Models for Biomedical Natural Language\n  Processing", "abstract": "Motivation: A perennial challenge for biomedical researchers and clinical\npractitioners is to stay abreast with the rapid growth of publications and\nmedical notes. Natural language processing (NLP) has emerged as a promising\ndirection for taming information overload. In particular, large neural language\nmodels facilitate transfer learning by pretraining on unlabeled text, as\nexemplified by the successes of BERT models in various NLP applications.\nHowever, fine-tuning such models for an end task remains challenging,\nespecially with small labeled datasets, which are common in biomedical NLP.\n  Results: We conduct a systematic study on fine-tuning stability in biomedical\nNLP. We show that finetuning performance may be sensitive to pretraining\nsettings, especially in low-resource domains. Large models have potential to\nattain better performance, but increasing model size also exacerbates\nfinetuning instability. We thus conduct a comprehensive exploration of\ntechniques for addressing fine-tuning instability. We show that these\ntechniques can substantially improve fine-tuning performance for lowresource\nbiomedical NLP applications. Specifically, freezing lower layers is helpful for\nstandard BERT-BASE models, while layerwise decay is more effective for\nBERT-LARGE and ELECTRA models. For low-resource text similarity tasks such as\nBIOSSES, reinitializing the top layer is the optimal strategy. Overall,\ndomainspecific vocabulary and pretraining facilitate more robust models for\nfine-tuning. Based on these findings, we establish new state of the art on a\nwide range of biomedical NLP applications.\n  Availability and implementation: To facilitate progress in biomedical NLP, we\nrelease our state-of-the-art pretrained and fine-tuned models:\nhttps://aka.ms/BLURB.", "published": "2021-12-15 04:20:35", "link": "http://arxiv.org/abs/2112.07869v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tracing Text Provenance via Context-Aware Lexical Substitution", "abstract": "Text content created by humans or language models is often stolen or misused\nby adversaries. Tracing text provenance can help claim the ownership of text\ncontent or identify the malicious users who distribute misleading content like\nmachine-generated fake news. There have been some attempts to achieve this,\nmainly based on watermarking techniques. Specifically, traditional text\nwatermarking methods embed watermarks by slightly altering text format like\nline spacing and font, which, however, are fragile to cross-media transmissions\nlike OCR. Considering this, natural language watermarking methods represent\nwatermarks by replacing words in original sentences with synonyms from\nhandcrafted lexical resources (e.g., WordNet), but they do not consider the\nsubstitution's impact on the overall sentence's meaning. Recently, a\ntransformer-based network was proposed to embed watermarks by modifying the\nunobtrusive words (e.g., function words), which also impair the sentence's\nlogical and semantic coherence. Besides, one well-trained network fails on\nother different types of text content. To address the limitations mentioned\nabove, we propose a natural language watermarking scheme based on context-aware\nlexical substitution (LS). Specifically, we employ BERT to suggest LS\ncandidates by inferring the semantic relatedness between the candidates and the\noriginal sentence. Based on this, a selection strategy in terms of\nsynchronicity and substitutability is further designed to test whether a word\nis exactly suitable for carrying the watermark signal. Extensive experiments\ndemonstrate that, under both objective and subjective metrics, our watermarking\nscheme can well preserve the semantic integrity of original sentences and has a\nbetter transferability than existing methods. Besides, the proposed LS approach\noutperforms the state-of-the-art approach on the Stanford Word Substitution\nBenchmark.", "published": "2021-12-15 04:27:33", "link": "http://arxiv.org/abs/2112.07873v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Large Dual Encoders Are Generalizable Retrievers", "abstract": "It has been shown that dual encoders trained on one domain often fail to\ngeneralize to other domains for retrieval tasks. One widespread belief is that\nthe bottleneck layer of a dual encoder, where the final score is simply a\ndot-product between a query vector and a passage vector, is too limited to make\ndual encoders an effective retrieval model for out-of-domain generalization. In\nthis paper, we challenge this belief by scaling up the size of the dual encoder\nmodel {\\em while keeping the bottleneck embedding size fixed.} With multi-stage\ntraining, surprisingly, scaling up the model size brings significant\nimprovement on a variety of retrieval tasks, especially for out-of-domain\ngeneralization. Experimental results show that our dual encoders,\n\\textbf{G}eneralizable \\textbf{T}5-based dense \\textbf{R}etrievers (GTR),\noutperform %ColBERT~\\cite{khattab2020colbert} and existing sparse and dense\nretrievers on the BEIR dataset~\\cite{thakur2021beir} significantly. Most\nsurprisingly, our ablation study finds that GTR is very data efficient, as it\nonly needs 10\\% of MS Marco supervised data to achieve the best out-of-domain\nperformance. All the GTR models are released at\nhttps://tfhub.dev/google/collections/gtr/1.", "published": "2021-12-15 05:33:27", "link": "http://arxiv.org/abs/2112.07899v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Cognition-aware Cognate Detection", "abstract": "Automatic detection of cognates helps downstream NLP tasks of Machine\nTranslation, Cross-lingual Information Retrieval, Computational Phylogenetics\nand Cross-lingual Named Entity Recognition. Previous approaches for the task of\ncognate detection use orthographic, phonetic and semantic similarity based\nfeatures sets. In this paper, we propose a novel method for enriching the\nfeature sets, with cognitive features extracted from human readers' gaze\nbehaviour. We collect gaze behaviour data for a small sample of cognates and\nshow that extracted cognitive features help the task of cognate detection.\nHowever, gaze data collection and annotation is a costly task. We use the\ncollected gaze behaviour data to predict cognitive features for a larger sample\nand show that predicted cognitive features, also, significantly improve the\ntask performance. We report improvements of 10% with the collected gaze\nfeatures, and 12% using the predicted gaze features, over the previously\nproposed approaches. Furthermore, we release the collected gaze behaviour data\nalong with our code and cross-lingual models.", "published": "2021-12-15 12:48:04", "link": "http://arxiv.org/abs/2112.08087v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mask-combine Decoding and Classification Approach for Punctuation\n  Prediction with real-time Inference Constraints", "abstract": "In this work, we unify several existing decoding strategies for punctuation\nprediction in one framework and introduce a novel strategy which utilises\nmultiple predictions at each word across different windows. We show that\nsignificant improvements can be achieved by optimising these strategies after\ntraining a model, only leading to a potential increase in inference time, with\nno requirement for retraining. We further use our decoding strategy framework\nfor the first comparison of tagging and classification approaches for\npunctuation prediction in a real-time setting. Our results show that a\nclassification approach for punctuation prediction can be beneficial when\nlittle or no right-side context is available.", "published": "2021-12-15 13:14:36", "link": "http://arxiv.org/abs/2112.08098v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Cross-Lingual IR from an English Retriever", "abstract": "We present DR.DECR (Dense Retrieval with Distillation-Enhanced Cross-Lingual\nRepresentation), a new cross-lingual information retrieval (CLIR) system\ntrained using multi-stage knowledge distillation (KD). The teacher of DR.DECR\nrelies on a highly effective but computationally expensive two-stage inference\nprocess consisting of query translation and monolingual IR, while the student,\nDR.DECR, executes a single CLIR step. We teach DR.DECR powerful multilingual\nrepresentations as well as CLIR by optimizing two corresponding KD objectives.\nLearning useful representations of non-English text from an English-only\nretriever is accomplished through a cross-lingual token alignment algorithm\nthat relies on the representation capabilities of the underlying multilingual\nencoders. In both in-domain and zero-shot out-of-domain evaluation, DR.DECR\ndemonstrates far superior accuracy over direct fine-tuning with labeled CLIR\ndata. It is also the best single-model retriever on the XOR-TyDi benchmark at\nthe time of this writing.", "published": "2021-12-15 15:07:54", "link": "http://arxiv.org/abs/2112.08185v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "One System to Rule them All: a Universal Intent Recognition System for\n  Customer Service Chatbots", "abstract": "Customer service chatbots are conversational systems designed to provide\ninformation to customers about products/services offered by different\ncompanies. Particularly, intent recognition is one of the core components in\nthe natural language understating capabilities of a chatbot system. Among the\ndifferent intents that a chatbot is trained to recognize, there is a set of\nthem that is universal to any customer service chatbot. Universal intents may\ninclude salutation, switch the conversation to a human agent, farewells, among\nothers. A system to recognize those universal intents will be very helpful to\noptimize the training process of specific customer service chatbots. We propose\nthe development of a universal intent recognition system, which is trained to\nrecognize a selected group of 11 intents that are common in 28 different\nchatbots. The proposed system is trained considering state-of-the-art\nword-embedding models such as word2vec and BERT, and deep classifiers based on\nconvolutional and recurrent neural networks. The proposed model is able to\ndiscriminate between those universal intents with a balanced accuracy up to\n80.4\\%. In addition, the proposed system is equally accurate to recognize\nintents expressed both in short and long text requests. At the same time,\nmisclassification errors often occurs between intents with very similar\nsemantic fields such as farewells and positive comments. The proposed system\nwill be very helpful to optimize the training process of a customer service\nchatbot because some of the intents will be already available and detected by\nour system. At the same time, the proposed approach will be a suitable base\nmodel to train more specific chatbots by applying transfer learning strategies.", "published": "2021-12-15 16:45:55", "link": "http://arxiv.org/abs/2112.08261v1", "categories": ["cs.HC", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Measure and Improve Robustness in NLP Models: A Survey", "abstract": "As NLP models achieved state-of-the-art performances over benchmarks and\ngained wide applications, it has been increasingly important to ensure the safe\ndeployment of these models in the real world, e.g., making sure the models are\nrobust against unseen or challenging scenarios. Despite robustness being an\nincreasingly studied topic, it has been separately explored in applications\nlike vision and NLP, with various definitions, evaluation and mitigation\nstrategies in multiple lines of research. In this paper, we aim to provide a\nunifying survey of how to define, measure and improve robustness in NLP. We\nfirst connect multiple definitions of robustness, then unify various lines of\nwork on identifying robustness failures and evaluating models' robustness.\nCorrespondingly, we present mitigation strategies that are data-driven,\nmodel-driven, and inductive-prior-based, with a more systematic view of how to\neffectively improve robustness in NLP models. Finally, we conclude by outlining\nopen challenges and future directions to motivate further research in this\narea.", "published": "2021-12-15 18:02:04", "link": "http://arxiv.org/abs/2112.08313v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Simple Text Detoxification by Identifying a Linear Toxic Subspace in\n  Language Model Embeddings", "abstract": "Large pre-trained language models are often trained on large volumes of\ninternet data, some of which may contain toxic or abusive language.\nConsequently, language models encode toxic information, which makes the\nreal-world usage of these language models limited. Current methods aim to\nprevent toxic features from appearing generated text. We hypothesize the\nexistence of a low-dimensional toxic subspace in the latent space of\npre-trained language models, the existence of which suggests that toxic\nfeatures follow some underlying pattern and are thus removable. To construct\nthis toxic subspace, we propose a method to generalize toxic directions in the\nlatent space. We also provide a methodology for constructing parallel datasets\nusing a context based word masking system. Through our experiments, we show\nthat when the toxic subspace is removed from a set of sentence representations,\nalmost no toxic representations remain in the result. We demonstrate\nempirically that the subspace found using our method generalizes to multiple\ntoxicity corpora, indicating the existence of a low-dimensional toxic subspace.", "published": "2021-12-15 18:54:34", "link": "http://arxiv.org/abs/2112.08346v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Design Challenges for a Multi-Perspective Search Engine", "abstract": "Many users turn to document retrieval systems (e.g. search engines) to seek\nanswers to controversial questions. Answering such user queries usually require\nidentifying responses within web documents, and aggregating the responses based\non their different perspectives.\n  Classical document retrieval systems fall short at delivering a set of direct\nand diverse responses to the users. Naturally, identifying such responses\nwithin a document is a natural language understanding task. In this paper, we\nexamine the challenges of synthesizing such language understanding objectives\nwith document retrieval, and study a new perspective-oriented document\nretrieval paradigm. We discuss and assess the inherent natural language\nunderstanding challenges in order to achieve the goal. Following the design\nchallenges and principles, we demonstrate and evaluate a practical prototype\npipeline system. We use the prototype system to conduct a user survey in order\nto assess the utility of our paradigm, as well as understanding the user\ninformation needs for controversial queries.", "published": "2021-12-15 18:59:57", "link": "http://arxiv.org/abs/2112.08357v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "DSGPT: Domain-Specific Generative Pre-Training of Transformers for Text\n  Generation in E-commerce Title and Review Summarization", "abstract": "We propose a novel domain-specific generative pre-training (DS-GPT) method\nfor text generation and apply it to the product titleand review summarization\nproblems on E-commerce mobile display.First, we adopt a decoder-only\ntransformer architecture, which fitswell for fine-tuning tasks by combining\ninput and output all to-gether. Second, we demonstrate utilizing only small\namount of pre-training data in related domains is powerful. Pre-training a\nlanguagemodel from a general corpus such as Wikipedia or the CommonCrawl\nrequires tremendous time and resource commitment, andcan be wasteful if the\ndownstream tasks are limited in variety. OurDSGPT is pre-trained on a limited\ndataset, the Chinese short textsummarization dataset (LCSTS). Third, our model\ndoes not requireproduct-related human-labeled data. For title summarization\ntask,the state of art explicitly uses additional background knowledgein\ntraining and predicting stages. In contrast, our model implic-itly captures\nthis knowledge and achieves significant improvementover other methods, after\nfine-tuning on the public Taobao.comdataset. For review summarization task, we\nutilize JD.com in-housedataset, and observe similar improvement over standard\nmachinetranslation methods which lack the flexibility of fine-tuning.\nOurproposed work can be simply extended to other domains for a widerange of\ntext generation tasks.", "published": "2021-12-15 19:02:49", "link": "http://arxiv.org/abs/2112.08414v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Insta-VAX: A Multimodal Benchmark for Anti-Vaccine and Misinformation\n  Posts Detection on Social Media", "abstract": "Sharing of anti-vaccine posts on social media, including misinformation\nposts, has been shown to create confusion and reduce the publics confidence in\nvaccines, leading to vaccine hesitancy and resistance. Recent years have\nwitnessed the fast rise of such anti-vaccine posts in a variety of linguistic\nand visual forms in online networks, posing a great challenge for effective\ncontent moderation and tracking. Extending previous work on leveraging textual\ninformation to understand vaccine information, this paper presents Insta-VAX, a\nnew multi-modal dataset consisting of a sample of 64,957 Instagram posts\nrelated to human vaccines. We applied a crowdsourced annotation procedure\nverified by two trained expert judges to this dataset. We then bench-marked\nseveral state-of-the-art NLP and computer vision classifiers to detect whether\nthe posts show anti-vaccine attitude and whether they contain misinformation.\nExtensive experiments and analyses demonstrate the multimodal models can\nclassify the posts more accurately than the uni-modal models, but still need\nimprovement especially on visual context understanding and external knowledge\ncooperation. The dataset and classifiers contribute to monitoring and tracking\nof vaccine discussions for social scientific and public health efforts in\ncombating the problem of vaccine misinformation.", "published": "2021-12-15 20:34:57", "link": "http://arxiv.org/abs/2112.08470v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Automatic Product Copywriting for E-Commerce", "abstract": "Product copywriting is a critical component of e-commerce recommendation\nplatforms. It aims to attract users' interest and improve user experience by\nhighlighting product characteristics with textual descriptions. In this paper,\nwe report our experience deploying the proposed Automatic Product Copywriting\nGeneration (APCG) system into the JD.com e-commerce product recommendation\nplatform. It consists of two main components: 1) natural language generation,\nwhich is built from a transformer-pointer network and a pre-trained\nsequence-to-sequence model based on millions of training data from our in-house\nplatform; and 2) copywriting quality control, which is based on both automatic\nevaluation and human screening. For selected domains, the models are trained\nand updated daily with the updated training data. In addition, the model is\nalso used as a real-time writing assistant tool on our live broadcast platform.\nThe APCG system has been deployed in JD.com since Feb 2021. By Sep 2021, it has\ngenerated 2.53 million product descriptions, and improved the overall averaged\nclick-through rate (CTR) and the Conversion Rate (CVR) by 4.22% and 3.61%,\ncompared to baselines, respectively on a year-on-year basis. The accumulated\nGross Merchandise Volume (GMV) made by our system is improved by 213.42%,\ncompared to the number in Feb 2021.", "published": "2021-12-15 19:06:31", "link": "http://arxiv.org/abs/2112.11915v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The exploitation of Multiple Feature Extraction Techniques for Speaker\n  Identification in Emotional States under Disguised Voices", "abstract": "Due to improvements in artificial intelligence, speaker identification (SI)\ntechnologies have brought a great direction and are now widely used in a\nvariety of sectors. One of the most important components of SI is feature\nextraction, which has a substantial impact on the SI process and performance.\nAs a result, numerous feature extraction strategies are thoroughly\ninvestigated, contrasted, and analyzed. This article exploits five distinct\nfeature extraction methods for speaker identification in disguised voices under\nemotional environments. To evaluate this work significantly, three effects are\nused: high-pitched, low-pitched, and Electronic Voice Conversion (EVC).\nExperimental results reported that the concatenated Mel-Frequency Cepstral\nCoefficients (MFCCs), MFCCs-delta, and MFCCs-delta-delta is the best feature\nextraction method.", "published": "2021-12-15 07:56:16", "link": "http://arxiv.org/abs/2112.07940v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Solving the Data Sparsity Problem in Predicting the Success of the\n  Startups with Machine Learning Methods", "abstract": "Predicting the success of startup companies is of great importance for both\nstartup companies and investors. It is difficult due to the lack of available\ndata and appropriate general methods. With data platforms like Crunchbase\naggregating the information of startup companies, it is possible to predict\nwith machine learning algorithms. Existing research suffers from the data\nsparsity problem as most early-stage startup companies do not have much data\navailable to the public. We try to leverage the recent algorithms to solve this\nproblem. We investigate several machine learning algorithms with a large\ndataset from Crunchbase. The results suggest that LightGBM and XGBoost perform\nbest and achieve 53.03% and 52.96% F1 scores. We interpret the predictions from\nthe perspective of feature contribution. We construct portfolios based on the\nmodels and achieve high success rates. These findings have substantial\nimplications on how machine learning methods can help startup companies and\ninvestors.", "published": "2021-12-15 09:21:32", "link": "http://arxiv.org/abs/2112.07985v1", "categories": ["cs.LG", "cs.CL", "econ.EM"], "primary_category": "cs.LG"}
{"title": "Improving Conversational Recommendation Systems' Quality with\n  Context-Aware Item Meta Information", "abstract": "Conversational recommendation systems (CRS) engage with users by inferring\nuser preferences from dialog history, providing accurate recommendations, and\ngenerating appropriate responses. Previous CRSs use knowledge graph (KG) based\nrecommendation modules and integrate KG with language models for response\ngeneration. Although KG-based approaches prove effective, two issues remain to\nbe solved. First, KG-based approaches ignore the information in the\nconversational context but only rely on entity relations and bag of words to\nrecommend items. Second, it requires substantial engineering efforts to\nmaintain KGs that model domain-specific relations, thus leading to less\nflexibility. In this paper, we propose a simple yet effective architecture\ncomprising a pre-trained language model (PLM) and an item metadata encoder. The\nencoder learns to map item metadata to embeddings that can reflect the semantic\ninformation in the dialog context. The PLM then consumes the semantic-aligned\nitem embeddings together with dialog context to generate high-quality\nrecommendations and responses. Instead of modeling entity relations with KGs,\nour model reduces engineering complexity by directly converting each item to an\nembedding. Experimental results on the benchmark dataset ReDial show that our\nmodel obtains state-of-the-art results on both recommendation and response\ngeneration tasks.", "published": "2021-12-15 14:12:48", "link": "http://arxiv.org/abs/2112.08140v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Est-ce que vous compute? Code-switching, cultural identity, and AI", "abstract": "Cultural code-switching concerns how we adjust our overall behaviours,\nmanners of speaking, and appearance in response to a perceived change in our\nsocial environment. We defend the need to investigate cultural code-switching\ncapacities in artificial intelligence systems. We explore a series of ethical\nand epistemic issues that arise when bringing cultural code-switching to bear\non artificial intelligence. Building upon Dotson's (2014) analysis of\ntestimonial smothering, we discuss how emerging technologies in AI can give\nrise to epistemic oppression, and specifically, a form of self-silencing that\nwe call 'cultural smothering'. By leaving the socio-dynamic features of\ncultural code-switching unaddressed, AI systems risk negatively impacting\nalready-marginalised social groups by widening opportunity gaps and further\nentrenching social inequalities.", "published": "2021-12-15 16:36:53", "link": "http://arxiv.org/abs/2112.08256v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "GenIE: Generative Information Extraction", "abstract": "Structured and grounded representation of text is typically formalized by\nclosed information extraction, the problem of extracting an exhaustive set of\n(subject, relation, object) triplets that are consistent with a predefined set\nof entities and relations from a knowledge base schema. Most existing works are\npipelines prone to error accumulation, and all approaches are only applicable\nto unrealistically small numbers of entities and relations. We introduce GenIE\n(generative information extraction), the first end-to-end autoregressive\nformulation of closed information extraction. GenIE naturally exploits the\nlanguage knowledge from the pre-trained transformer by autoregressively\ngenerating relations and entities in textual form. Thanks to a new bi-level\nconstrained generation strategy, only triplets consistent with the predefined\nknowledge base schema are produced. Our experiments show that GenIE is\nstate-of-the-art on closed information extraction, generalizes from fewer\ntraining data points than baselines, and scales to a previously unmanageable\nnumber of entities and relations. With this work, closed information extraction\nbecomes practical in realistic scenarios, providing new opportunities for\ndownstream tasks. Finally, this work paves the way towards a unified end-to-end\napproach to the core tasks of information extraction. Code, data and models\navailable at https://github.com/epfl-dlab/GenIE.", "published": "2021-12-15 18:45:14", "link": "http://arxiv.org/abs/2112.08340v3", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Textless Speech-to-Speech Translation on Real Data", "abstract": "We present a textless speech-to-speech translation (S2ST) system that can\ntranslate speech from one language into another language and can be built\nwithout the need of any text data. Different from existing work in the\nliterature, we tackle the challenge in modeling multi-speaker target speech and\ntrain the systems with real-world S2ST data. The key to our approach is a\nself-supervised unit-based speech normalization technique, which finetunes a\npre-trained speech encoder with paired audios from multiple speakers and a\nsingle reference speaker to reduce the variations due to accents, while\npreserving the lexical content. With only 10 minutes of paired data for speech\nnormalization, we obtain on average 3.2 BLEU gain when training the S2ST model\non the VoxPopuli S2ST dataset, compared to a baseline trained on un-normalized\nspeech target. We also incorporate automatically mined S2ST data and show an\nadditional 2.0 BLEU gain. To our knowledge, we are the first to establish a\ntextless S2ST technique that can be trained with real-world data and works for\nmultiple language pairs. Audio samples are available at\nhttps://facebookresearch.github.io/speech_translation/textless_s2st_real_data/index.html .", "published": "2021-12-15 18:56:35", "link": "http://arxiv.org/abs/2112.08352v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Assisted Text Annotation Using Active Learning to Achieve High Quality\n  with Little Effort", "abstract": "Large amounts of annotated data have become more important than ever,\nespecially since the rise of deep learning techniques. However, manual\nannotations are costly. We propose a tool that enables researchers to create\nlarge, high-quality, annotated datasets with only a few manual annotations,\nthus strongly reducing annotation cost and effort. For this purpose, we combine\nan active learning (AL) approach with a pre-trained language model to\nsemi-automatically identify annotation categories in the given text documents.\nTo highlight our research direction's potential, we evaluate the approach on\nthe task of identifying frames in news articles. Our preliminary results show\nthat employing AL strongly reduces the number of annotations for correct\nclassification of even these complex and subtle frames. On the framing dataset,\nthe AL approach needs only 16.3\\% of the annotations to reach the same\nperformance as a model trained on the full dataset.", "published": "2021-12-15 13:14:58", "link": "http://arxiv.org/abs/2112.11914v1", "categories": ["cs.DL", "cs.AI", "cs.CL"], "primary_category": "cs.DL"}
{"title": "RawNeXt: Speaker verification system for variable-duration utterances\n  with deep layer aggregation and extended dynamic scaling policies", "abstract": "Despite achieving satisfactory performance in speaker verification using deep\nneural networks, variable-duration utterances remain a challenge that threatens\nthe robustness of systems. To deal with this issue, we propose a speaker\nverification system called RawNeXt that can handle input raw waveforms of\narbitrary length by employing the following two components: (1) A deep layer\naggregation strategy enhances speaker information by iteratively and\nhierarchically aggregating features of various time scales and spectral\nchannels output from blocks. (2) An extended dynamic scaling policy flexibly\nprocesses features according to the length of the utterance by selectively\nmerging the activations of different resolution branches in each block. Owing\nto these two components, our proposed model can extract speaker embeddings rich\nin time-spectral information and operate dynamically on length variations.\nExperimental results on the VoxCeleb1 test set consisting of various duration\nutterances demonstrate that RawNeXt achieves state-of-the-art performance\ncompared to the recently proposed systems. Our code and trained model weights\nare available at https://github.com/wngh1187/RawNeXt.", "published": "2021-12-15 07:33:55", "link": "http://arxiv.org/abs/2112.07935v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Speech frame implementation for speech analysis and recognition", "abstract": "Distinctive features of the created speech frame are: the ability to take\ninto account the emotional state of the speaker, sup-port for working with\ndiseases of the speech-forming tract of speakers and the presence of manual\nsegmentation of a num-ber of speech signals. In addition, the system is focused\non Russian-language speech material, unlike most analogs.", "published": "2021-12-15 10:48:10", "link": "http://arxiv.org/abs/2112.08027v1", "categories": ["cs.SD", "eess.AS", "68T10", "H.2.8"], "primary_category": "cs.SD"}
{"title": "Chimpanzee voice prints? Insights from transfer learning experiments\n  from human voices", "abstract": "Individual vocal differences are ubiquitous in the animal kingdom. In humans,\nthese differences pervade the entire vocal repertoire and constitute a \"voice\nprint\". Apes, our closest-living relatives, possess individual signatures\nwithin specific call types, but the potential for a unique voice print has been\nlittle investigated. This is partially attributed to the limitations associated\nwith extracting meaningful features from small data sets. Advances in machine\nlearning have highlighted an alternative to traditional acoustic features,\nnamely pre-trained learnt extractors. Here, we present an approach building on\nthese developments: leveraging a feature extractor based on a deep neural\nnetwork trained on over 10,000 human voice prints to provide an informative\nspace over which we identify chimpanzee voice prints. We compare our results\nwith those obtained by using traditional acoustic features and discuss the\nbenefits of our methodology and the significance of our findings for the\nidentification of \"voice prints\" in non-human animals.", "published": "2021-12-15 14:40:08", "link": "http://arxiv.org/abs/2112.08165v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Expert and Crowd-Guided Affect Annotation and Prediction", "abstract": "We employ crowdsourcing to acquire time-continuous affective annotations for\nmovie clips, and refine noisy models trained from these crowd annotations\nincorporating expert information within a Multi-task Learning (MTL) framework.\nWe propose a novel \\textbf{e}xpert \\textbf{g}uided MTL (EG-MTL) algorithm,\nwhich minimizes the loss with respect to both crowd and expert labels to learn\na set of weights corresponding to each movie clip for which crowd annotations\nare acquired. We employ EG-MTL to solve two problems, namely,\n\\textbf{\\texttt{P1}}: where dynamic annotations acquired from both experts and\ncrowdworkers for the \\textbf{Validation} set are used to train a regression\nmodel with audio-visual clip descriptors as features, and predict dynamic\narousal and valence levels on 5--15 second snippets derived from the clips; and\n\\textbf{\\texttt{P2}}: where a classification model trained on the\n\\textbf{Validation} set using dynamic crowd and expert annotations (as\nfeatures) and static affective clip labels is used for binary emotion\nrecognition on the \\textbf{Evaluation} set for which only dynamic crowd\nannotations are available. Observed experimental results confirm the\neffectiveness of the EG-MTL algorithm, which is reflected via improved arousal\nand valence estimation for \\textbf{\\texttt{P1}}, and higher recognition\naccuracy for \\textbf{\\texttt{P2}}.", "published": "2021-12-15 19:20:04", "link": "http://arxiv.org/abs/2112.08432v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "EEG-Transformer: Self-attention from Transformer Architecture for\n  Decoding EEG of Imagined Speech", "abstract": "Transformers are groundbreaking architectures that have changed a flow of\ndeep learning, and many high-performance models are developing based on\ntransformer architectures. Transformers implemented only with attention with\nencoder-decoder structure following seq2seq without using RNN, but had better\nperformance than RNN. Herein, we investigate the decoding technique for\nelectroencephalography (EEG) composed of self-attention module from transformer\narchitecture during imagined speech and overt speech. We performed\nclassification of nine subjects using convolutional neural network based on\nEEGNet that captures temporal-spectral-spatial features from EEG of imagined\nspeech and overt speech. Furthermore, we applied the self-attention module to\ndecoding EEG to improve the performance and lower the number of parameters. Our\nresults demonstrate the possibility of decoding brain activities of imagined\nspeech and overt speech using attention modules. Also, only single channel EEG\nor ear-EEG can be used to decode the imagined speech for practical BCIs.", "published": "2021-12-15 15:16:40", "link": "http://arxiv.org/abs/2112.09239v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Zero-shot Audio Source Separation through Query-based Learning from\n  Weakly-labeled Data", "abstract": "Deep learning techniques for separating audio into different sound sources\nface several challenges. Standard architectures require training separate\nmodels for different types of audio sources. Although some universal separators\nemploy a single model to target multiple sources, they have difficulty\ngeneralizing to unseen sources. In this paper, we propose a three-component\npipeline to train a universal audio source separator from a large, but\nweakly-labeled dataset: AudioSet. First, we propose a transformer-based sound\nevent detection system for processing weakly-labeled training data. Second, we\ndevise a query-based audio separation model that leverages this data for model\ntraining. Third, we design a latent embedding processor to encode queries that\nspecify audio targets for separation, allowing for zero-shot generalization.\nOur approach uses a single model for source separation of multiple sound types,\nand relies solely on weakly-labeled data for training. In addition, the\nproposed audio separator can be used in a zero-shot setting, learning to\nseparate types of audio sources that were never seen in training. To evaluate\nthe separation performance, we test our model on MUSDB18, while training on the\ndisjoint AudioSet. We further verify the zero-shot performance by conducting\nanother experiment on audio source types that are held-out from training. The\nmodel achieves comparable Source-to-Distortion Ratio (SDR) performance to\ncurrent supervised models in both cases.", "published": "2021-12-15 05:13:43", "link": "http://arxiv.org/abs/2112.07891v4", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
