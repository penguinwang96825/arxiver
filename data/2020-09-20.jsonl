{"title": "Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New\n  Datasets for Bengali-English Machine Translation", "abstract": "Despite being the seventh most widely spoken language in the world, Bengali\nhas received much less attention in machine translation literature due to being\nlow in resources. Most publicly available parallel corpora for Bengali are not\nlarge enough; and have rather poor quality, mostly because of incorrect\nsentence alignments resulting from erroneous sentence segmentation, and also\nbecause of a high volume of noise present in them. In this work, we build a\ncustomized sentence segmenter for Bengali and propose two novel methods for\nparallel corpus creation on low-resource setups: aligner ensembling and batch\nfiltering. With the segmenter and the two methods combined, we compile a\nhigh-quality Bengali-English parallel corpus comprising of 2.75 million\nsentence pairs, more than 2 million of which were not available before.\nTraining on neural models, we achieve an improvement of more than 9 BLEU score\nover previous approaches to Bengali-English machine translation. We also\nevaluate on a new test set of 1000 pairs made with extensive quality control.\nWe release the segmenter, parallel corpus, and the evaluation set, thus\nelevating Bengali from its low-resource status. To the best of our knowledge,\nthis is the first ever large scale study on Bengali-English machine\ntranslation. We believe our study will pave the way for future research on\nBengali-English machine translation as well as other low-resource languages.\nOur data and code are available at https://github.com/csebuetnlp/banglanmt.", "published": "2020-09-20 06:06:27", "link": "http://arxiv.org/abs/2009.09359v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding Mention Detector-Linker Interaction in Neural Coreference\n  Resolution", "abstract": "Despite significant recent progress in coreference resolution, the quality of\ncurrent state-of-the-art systems still considerably trails behind human-level\nperformance. Using the CoNLL-2012 and PreCo datasets, we dissect the best\ninstantiation of the mainstream end-to-end coreference resolution model that\nunderlies most current best-performing coreference systems, and empirically\nanalyze the behavior of its two components: mention detector and mention\nlinker. While the detector traditionally focuses heavily on recall as a design\ndecision, we demonstrate the importance of precision, calling for their\nbalance. However, we point out the difficulty in building a precise detector\ndue to its inability to make important anaphoricity decisions. We also\nhighlight the enormous room for improving the linker and show that the rest of\nits errors mainly involve pronoun resolution. We propose promising next steps\nand hope our findings will help future research in coreference resolution.", "published": "2020-09-20 06:30:45", "link": "http://arxiv.org/abs/2009.09363v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired\n  Data", "abstract": "Recent advances in open-domain dialogue systems rely on the success of neural\nmodels that are trained on large-scale data. However, collecting large-scale\ndialogue data is usually time-consuming and labor-intensive. To address this\ndata dilemma, we propose a novel data augmentation method for training\nopen-domain dialogue models by utilizing unpaired data. Specifically, a\ndata-level distillation process is first proposed to construct augmented\ndialogues where both post and response are retrieved from the unpaired data. A\nranking module is employed to filter out low-quality dialogues. Further, a\nmodel-level distillation process is employed to distill a teacher model trained\non high-quality paired data to augmented dialogue pairs, thereby preventing\ndialogue models from being affected by the noise in the augmented data.\nAutomatic and manual evaluation indicates that our method can produce\nhigh-quality dialogue pairs with diverse contents, and the proposed data-level\nand model-level dialogue distillation can improve the performance of\ncompetitive baselines.", "published": "2020-09-20 13:06:38", "link": "http://arxiv.org/abs/2009.09427v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relation Extraction from Biomedical and Clinical Text: Unified Multitask\n  Learning Framework", "abstract": "To minimize the accelerating amount of time invested in the biomedical\nliterature search, numerous approaches for automated knowledge extraction have\nbeen proposed. Relation extraction is one such task where semantic relations\nbetween the entities are identified from the free text. In the biomedical\ndomain, extraction of regulatory pathways, metabolic processes, adverse drug\nreaction or disease models necessitates knowledge from the individual\nrelations, for example, physical or regulatory interactions between genes,\nproteins, drugs, chemical, disease or phenotype. In this paper, we study the\nrelation extraction task from three major biomedical and clinical tasks, namely\ndrug-drug interaction, protein-protein interaction, and medical concept\nrelation extraction. Towards this, we model the relation extraction problem in\nmulti-task learning (MTL) framework and introduce for the first time the\nconcept of structured self-attentive network complemented with the adversarial\nlearning approach for the prediction of relationships from the biomedical and\nclinical text. The fundamental notion of MTL is to simultaneously learn\nmultiple problems together by utilizing the concepts of the shared\nrepresentation. Additionally, we also generate the highly efficient single task\nmodel which exploits the shortest dependency path embedding learned over the\nattentive gated recurrent unit to compare our proposed MTL models. The\nframework we propose significantly improves overall the baselines (deep\nlearning techniques) and single-task models for predicting the relationships,\nwithout compromising on the performance of all the tasks.", "published": "2020-09-20 19:50:28", "link": "http://arxiv.org/abs/2009.09509v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Biomedical Event Extraction with Hierarchical Knowledge Graphs", "abstract": "Biomedical event extraction is critical in understanding biomolecular\ninteractions described in scientific corpus. One of the main challenges is to\nidentify nested structured events that are associated with non-indicative\ntrigger words. We propose to incorporate domain knowledge from Unified Medical\nLanguage System (UMLS) to a pre-trained language model via Graph\nEdge-conditioned Attention Networks (GEANet) and hierarchical graph\nrepresentation. To better recognize the trigger words, each sentence is first\ngrounded to a sentence graph based on a jointly modeled hierarchical knowledge\ngraph from UMLS. The grounded graphs are then propagated by GEANet, a novel\ngraph neural networks for enhanced capabilities in inferring complex events. On\nBioNLP 2011 GENIA Event Extraction task, our approach achieved 1.41% F1 and\n3.19% F1 improvements on all events and complex events, respectively. Ablation\nstudies confirm the importance of GEANet and hierarchical KG.", "published": "2020-09-20 02:25:05", "link": "http://arxiv.org/abs/2009.09335v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Softmax Tempering for Training Neural Machine Translation Models", "abstract": "Neural machine translation (NMT) models are typically trained using a softmax\ncross-entropy loss where the softmax distribution is compared against smoothed\ngold labels. In low-resource scenarios, NMT models tend to over-fit because the\nsoftmax distribution quickly approaches the gold label distribution. To address\nthis issue, we propose to divide the logits by a temperature coefficient, prior\nto applying softmax, during training. In our experiments on 11 language pairs\nin the Asian Language Treebank dataset and the WMT 2019 English-to-German\ntranslation task, we observed significant improvements in translation quality\nby up to 3.9 BLEU points. Furthermore, softmax tempering makes the greedy\nsearch to be as good as beam search decoding in terms of translation quality,\nenabling 1.5 to 3.5 times speed-up. We also study the impact of softmax\ntempering on multilingual NMT and recurrently stacked NMT, both of which aim to\nreduce the NMT model size by parameter sharing thereby verifying the utility of\ntemperature in developing compact NMT models. Finally, an analysis of softmax\nentropies and gradients reveal the impact of our method on the internal\nbehavior of NMT models.", "published": "2020-09-20 07:06:22", "link": "http://arxiv.org/abs/2009.09372v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Difference-aware Knowledge Selection for Knowledge-grounded Conversation\n  Generation", "abstract": "In a multi-turn knowledge-grounded dialog, the difference between the\nknowledge selected at different turns usually provides potential clues to\nknowledge selection, which has been largely neglected in previous research. In\nthis paper, we propose a difference-aware knowledge selection method. It first\ncomputes the difference between the candidate knowledge sentences provided at\nthe current turn and those chosen in the previous turns. Then, the differential\ninformation is fused with or disentangled from the contextual information to\nfacilitate final knowledge selection. Automatic, human observational, and\ninteractive evaluation shows that our method is able to select knowledge more\naccurately and generate more informative responses, significantly outperforming\nthe state-of-the-art baselines. The codes are available at\nhttps://github.com/chujiezheng/DiffKS.", "published": "2020-09-20 07:47:26", "link": "http://arxiv.org/abs/2009.09378v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "F^2-Softmax: Diversifying Neural Text Generation via Frequency\n  Factorized Softmax", "abstract": "Despite recent advances in neural text generation, encoding the rich\ndiversity in human language remains elusive. We argue that the sub-optimal text\ngeneration is mainly attributable to the imbalanced token distribution, which\nparticularly misdirects the learning model when trained with the\nmaximum-likelihood objective. As a simple yet effective remedy, we propose two\nnovel methods, F^2-Softmax and MefMax, for a balanced training even with the\nskewed frequency distribution. MefMax assigns tokens uniquely to frequency\nclasses, trying to group tokens with similar frequencies and equalize frequency\nmass between the classes. F^2-Softmax then decomposes a probability\ndistribution of the target token into a product of two conditional\nprobabilities of (i) frequency class, and (ii) token from the target frequency\nclass. Models learn more uniform probability distributions because they are\nconfined to subsets of vocabularies. Significant performance gains on seven\nrelevant metrics suggest the supremacy of our approach in improving not only\nthe diversity but also the quality of generated texts.", "published": "2020-09-20 12:03:58", "link": "http://arxiv.org/abs/2009.09417v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Persian Ezafe Recognition Using Transformers and Its Role in\n  Part-Of-Speech Tagging", "abstract": "Ezafe is a grammatical particle in some Iranian languages that links two\nwords together. Regardless of the important information it conveys, it is\nalmost always not indicated in Persian script, resulting in mistakes in reading\ncomplex sentences and errors in natural language processing tasks. In this\npaper, we experiment with different machine learning methods to achieve\nstate-of-the-art results in the task of ezafe recognition. Transformer-based\nmethods, BERT and XLMRoBERTa, achieve the best results, the latter achieving\n2.68% F1-score more than the previous state-of-the-art. We, moreover, use ezafe\ninformation to improve Persian part-of-speech tagging results and show that\nsuch information will not be useful to transformer-based methods and explain\nwhy that might be the case.", "published": "2020-09-20 17:01:43", "link": "http://arxiv.org/abs/2009.09474v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation", "abstract": "Bolukbasi et al. (2016) presents one of the first gender bias mitigation\ntechniques for word representations. Their method takes pre-trained word\nrepresentations as input and attempts to isolate a linear subspace that\ncaptures most of the gender bias in the representations. As judged by an\nanalogical evaluation task, their method virtually eliminates gender bias in\nthe representations. However, an implicit and untested assumption of their\nmethod is that the bias subspace is actually linear. In this work, we\ngeneralize their method to a kernelized, nonlinear version. We take inspiration\nfrom kernel principal component analysis and derive a nonlinear bias isolation\ntechnique. We discuss and overcome some of the practical drawbacks of our\nmethod for non-linear gender bias mitigation in word representations and\nanalyze empirically whether the bias subspace is actually linear. Our analysis\nshows that gender bias is in fact well captured by a linear subspace,\njustifying the assumption of Bolukbasi et al. (2016).", "published": "2020-09-20 14:13:45", "link": "http://arxiv.org/abs/2009.09435v4", "categories": ["cs.LG", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Energy-Based Reranking: Improving Neural Machine Translation Using\n  Energy-Based Models", "abstract": "The discrepancy between maximum likelihood estimation (MLE) and task measures\nsuch as BLEU score has been studied before for autoregressive neural machine\ntranslation (NMT) and resulted in alternative training algorithms (Ranzato et\nal., 2016; Norouzi et al., 2016; Shen et al., 2016; Wu et al., 2018). However,\nMLE training remains the de facto approach for autoregressive NMT because of\nits computational efficiency and stability. Despite this mismatch between the\ntraining objective and task measure, we notice that the samples drawn from an\nMLE-based trained NMT support the desired distribution -- there are samples\nwith much higher BLEU score comparing to the beam decoding output. To benefit\nfrom this observation, we train an energy-based model to mimic the behavior of\nthe task measure (i.e., the energy-based model assigns lower energy to samples\nwith higher BLEU score), which is resulted in a re-ranking algorithm based on\nthe samples drawn from NMT: energy-based re-ranking (EBR). We use both marginal\nenergy models (over target sentence) and joint energy models (over both source\nand target sentences). Our EBR with the joint energy model consistently\nimproves the performance of the Transformer-based NMT: +4 BLEU points on\nIWSLT'14 German-English, +3.0 BELU points on Sinhala-English, +1.2 BLEU on\nWMT'16 English-German tasks.", "published": "2020-09-20 02:50:52", "link": "http://arxiv.org/abs/2009.13267v4", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Far-Field Automatic Speech Recognition", "abstract": "The machine recognition of speech spoken at a distance from the microphones,\nknown as far-field automatic speech recognition (ASR), has received a\nsignificant increase of attention in science and industry, which caused or was\ncaused by an equally significant improvement in recognition accuracy. Meanwhile\nit has entered the consumer market with digital home assistants with a spoken\nlanguage interface being its most prominent application. Speech recorded at a\ndistance is affected by various acoustic distortions and, consequently, quite\ndifferent processing pipelines have emerged compared to ASR for close-talk\nspeech. A signal enhancement front-end for dereverberation, source separation\nand acoustic beamforming is employed to clean up the speech, and the back-end\nASR engine is robustified by multi-condition training and adaptation. We will\nalso describe the so-called end-to-end approach to ASR, which is a new\npromising architecture that has recently been extended to the far-field\nscenario. This tutorial article gives an account of the algorithms used to\nenable accurate speech recognition from a distance, and it will be seen that,\nalthough deep learning has a significant share in the technological\nbreakthroughs, a clever combination with traditional signal processing can lead\nto surprisingly effective solutions.", "published": "2020-09-20 09:31:59", "link": "http://arxiv.org/abs/2009.09395v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Accelerating Auxiliary Function-based Independent Vector Analysis", "abstract": "Independent Vector Analysis (IVA) is an effective approach for Blind Source\nSeparation (BSS) of convolutive mixtures of audio signals. As a practical\nrealization of an IVA-based BSS algorithm, the so-called AuxIVA update rules\nbased on the Majorize-Minimize (MM) principle have been proposed which allow\nfor fast and computationally efficient optimization of the IVA cost function.\nFor many real-time applications, however, update rules for IVA exhibiting even\nfaster convergence are highly desirable. To this end, we investigate techniques\nwhich accelerate the convergence of the AuxIVA update rules without extra\ncomputational cost. The efficacy of the proposed methods is verified in\nexperiments representing real-world acoustic scenarios.", "published": "2020-09-20 10:16:36", "link": "http://arxiv.org/abs/2009.09402v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
