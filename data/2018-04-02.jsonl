{"title": "Real Time Sentiment Change Detection of Twitter Data Streams", "abstract": "In the past few years, there has been a huge growth in Twitter sentiment\nanalysis having already provided a fair amount of research on sentiment\ndetection of public opinion among Twitter users. Given the fact that Twitter\nmessages are generated constantly with dizzying rates, a huge volume of\nstreaming data is created, thus there is an imperative need for accurate\nmethods for knowledge discovery and mining of this information. Although there\nexists a plethora of twitter sentiment analysis methods in the recent\nliterature, the researchers have shifted to real-time sentiment identification\non twitter streaming data, as expected. A major challenge is to deal with the\nBig Data challenges arising in Twitter streaming applications concerning both\nVolume and Velocity. Under this perspective, in this paper, a methodological\napproach based on open source tools is provided for real-time detection of\nchanges in sentiment that is ultra efficient with respect to both memory\nconsumption and computational cost. This is achieved by iteratively collecting\ntweets in real time and discarding them immediately after their process. For\nthis purpose, we employ the Lexicon approach for sentiment characterizations,\nwhile change detection is achieved through appropriate control charts that do\nnot require historical information. We believe that the proposed methodology\nprovides the trigger for a potential large-scale monitoring of threads in an\nattempt to discover fake news spread or propaganda efforts in their early\nstages. Our experimental real-time analysis based on a recent hashtag provides\nevidence that the proposed approach can detect meaningful sentiment changes\nacross a hashtags lifetime.", "published": "2018-04-02 13:31:11", "link": "http://arxiv.org/abs/1804.00482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NIHRIO at SemEval-2018 Task 3: A Simple and Accurate Neural Network\n  Model for Irony Detection in Twitter", "abstract": "This paper describes our NIHRIO system for SemEval-2018 Task 3 \"Irony\ndetection in English tweets\". We propose to use a simple neural network\narchitecture of Multilayer Perceptron with various types of input features\nincluding: lexical, syntactic, semantic and polarity features. Our system\nachieves very high performance in both subtasks of binary and multi-class irony\ndetection in tweets. In particular, we rank third using the accuracy metric and\nfifth using the F1 metric. Our code is available at\nhttps://github.com/NIHRIO/IronyDetectionInTwitter", "published": "2018-04-02 14:09:01", "link": "http://arxiv.org/abs/1804.00520v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Semantic Plausibility by Injecting World Knowledge", "abstract": "Distributional data tells us that a man can swallow candy, but not that a man\ncan swallow a paintball, since this is never attested. However both are\nphysically plausible events. This paper introduces the task of semantic\nplausibility: recognizing plausible but possibly novel events. We present a new\ncrowdsourced dataset of semantic plausibility judgments of single events such\nas \"man swallow paintball\". Simple models based on distributional\nrepresentations perform poorly on this task, despite doing well on selection\npreference, but injecting manually elicited knowledge about entity properties\nprovides a substantial performance boost. Our error analysis shows that our new\ndataset is a great testbed for semantic plausibility models: more sophisticated\nknowledge representation and propagation could address many of the remaining\nerrors.", "published": "2018-04-02 16:32:53", "link": "http://arxiv.org/abs/1804.00619v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simple and Effective Semi-Supervised Question Answering", "abstract": "Recent success of deep learning models for the task of extractive Question\nAnswering (QA) is hinged on the availability of large annotated corpora.\nHowever, large domain specific annotated corpora are limited and expensive to\nconstruct. In this work, we envision a system where the end user specifies a\nset of base documents and only a few labelled examples. Our system exploits the\ndocument structure to create cloze-style questions from these base documents;\npre-trains a powerful neural network on the cloze style questions; and further\nfine-tunes the model on the labeled examples. We evaluate our proposed system\nacross three diverse datasets from different domains, and find it to be highly\neffective with very little labeled data. We attain more than 50% F1 score on\nSQuAD and TriviaQA with less than a thousand labelled examples. We are also\nreleasing a set of 3.2M cloze-style questions for practitioners to use while\nbuilding QA systems.", "published": "2018-04-02 20:29:21", "link": "http://arxiv.org/abs/1804.00720v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "An End-to-end Neural Natural Language Interface for Databases", "abstract": "The ability to extract insights from new data sets is critical for decision\nmaking. Visual interactive tools play an important role in data exploration\nsince they provide non-technical users with an effective way to visually\ncompose queries and comprehend the results. Natural language has recently\ngained traction as an alternative query interface to databases with the\npotential to enable non-expert users to formulate complex questions and\ninformation needs efficiently and effectively. However, understanding natural\nlanguage questions and translating them accurately to SQL is a challenging\ntask, and thus Natural Language Interfaces for Databases (NLIDBs) have not yet\nmade their way into practical tools and commercial products.\n  In this paper, we present DBPal, a novel data exploration tool with a natural\nlanguage interface. DBPal leverages recent advances in deep models to make\nquery understanding more robust in the following ways: First, DBPal uses a deep\nmodel to translate natural language statements to SQL, making the translation\nprocess more robust to paraphrasing and other linguistic variations. Second, to\nsupport the users in phrasing questions without knowing the database schema and\nthe query features, DBPal provides a learned auto-completion model that\nsuggests partial query extensions to users during query formulation and thus\nhelps to write complex queries.", "published": "2018-04-02 05:36:38", "link": "http://arxiv.org/abs/1804.00401v1", "categories": ["cs.DB", "cs.CL", "cs.HC"], "primary_category": "cs.DB"}
{"title": "High-quality nonparallel voice conversion based on cycle-consistent\n  adversarial network", "abstract": "Although voice conversion (VC) algorithms have achieved remarkable success\nalong with the development of machine learning, superior performance is still\ndifficult to achieve when using nonparallel data. In this paper, we propose\nusing a cycle-consistent adversarial network (CycleGAN) for nonparallel\ndata-based VC training. A CycleGAN is a generative adversarial network (GAN)\noriginally developed for unpaired image-to-image translation. A subjective\nevaluation of inter-gender conversion demonstrated that the proposed method\nsignificantly outperformed a method based on the Merlin open source neural\nnetwork speech synthesis system (a parallel VC system adapted for our setup)\nand a GAN-based parallel VC system. This is the first research to show that the\nperformance of a nonparallel VC method can exceed that of state-of-the-art\nparallel VC methods.", "published": "2018-04-02 07:58:23", "link": "http://arxiv.org/abs/1804.00425v1", "categories": ["eess.AS", "cs.CL", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Adversarial Teacher-Student Learning for Unsupervised Domain Adaptation", "abstract": "The teacher-student (T/S) learning has been shown effective in unsupervised\ndomain adaptation [1]. It is a form of transfer learning, not in terms of the\ntransfer of recognition decisions, but the knowledge of posteriori\nprobabilities in the source domain as evaluated by the teacher model. It learns\nto handle the speaker and environment variability inherent in and restricted to\nthe speech signal in the target domain without proactively addressing the\nrobustness to other likely conditions. Performance degradation may thus ensue.\nIn this work, we advance T/S learning by proposing adversarial T/S learning to\nexplicitly achieve condition-robust unsupervised domain adaptation. In this\nmethod, a student acoustic model and a condition classifier are jointly\noptimized to minimize the Kullback-Leibler divergence between the output\ndistributions of the teacher and student models, and simultaneously, to\nmin-maximize the condition classification loss. A condition-invariant deep\nfeature is learned in the adapted student model through this procedure. We\nfurther propose multi-factorial adversarial T/S learning which suppresses\ncondition variabilities caused by multiple factors simultaneously. Evaluated\nwith the noisy CHiME-3 test set, the proposed methods achieve relative word\nerror rate improvements of 44.60% and 5.38%, respectively, over a clean source\nmodel and a strong T/S learning baseline model.", "published": "2018-04-02 17:45:57", "link": "http://arxiv.org/abs/1804.00644v2", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speaker-Invariant Training via Adversarial Learning", "abstract": "We propose a novel adversarial multi-task learning scheme, aiming at actively\ncurtailing the inter-talker feature variability while maximizing its senone\ndiscriminability so as to enhance the performance of a deep neural network\n(DNN) based ASR system. We call the scheme speaker-invariant training (SIT). In\nSIT, a DNN acoustic model and a speaker classifier network are jointly\noptimized to minimize the senone (tied triphone state) classification loss, and\nsimultaneously mini-maximize the speaker classification loss. A\nspeaker-invariant and senone-discriminative deep feature is learned through\nthis adversarial multi-task learning. With SIT, a canonical DNN acoustic model\nwith significantly reduced variance in its output probabilities is learned with\nno explicit speaker-independent (SI) transformations or speaker-specific\nrepresentations used in training or testing. Evaluated on the CHiME-3 dataset,\nthe SIT achieves 4.99% relative word error rate (WER) improvement over the\nconventional SI acoustic model. With additional unsupervised speaker\nadaptation, the speaker-adapted (SA) SIT model achieves 4.86% relative WER gain\nover the SA SI acoustic model.", "published": "2018-04-02 21:09:30", "link": "http://arxiv.org/abs/1804.00732v3", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An Event Detection Approach Based On Twitter Hashtags", "abstract": "Twitter is one of the most popular microblogging services in the world. The\ngreat amount of information within Twitter makes it an important information\nchannel for people to learn and share news. Twitter hashtag is an popular\nfeature that can be viewed as human-labeled information which people use to\nidentify the topic of a tweet. Many researchers have proposed event-detection\napproaches that can monitor Twitter data and determine whether special events,\nsuch as accidents, extreme weather, earthquakes, or crimes take place. Although\nmany approaches use hashtags as one of their features, few of them explicitly\nfocus on the effectiveness of using hashtags on event detection. In this study,\nwe proposed an event detection approach that utilizes hashtags in tweets. We\nadopted the feature extraction used in STREAMCUBE and applied a clustering\nK-means approach to it. The experiments demonstrated that the K-means approach\nperformed better than STREAMCUBE in the clustering results. A discussion on\noptimal K values for the K-means approach is also provided.", "published": "2018-04-02 19:57:29", "link": "http://arxiv.org/abs/1804.11243v1", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "Insights into End-to-End Learning Scheme for Language Identification", "abstract": "A novel interpretable end-to-end learning scheme for language identification\nis proposed. It is in line with the classical GMM i-vector methods both\ntheoretically and practically. In the end-to-end pipeline, a general encoding\nlayer is employed on top of the front-end CNN, so that it can encode the\nvariable-length input sequence into an utterance level vector automatically.\nAfter comparing with the state-of-the-art GMM i-vector methods, we give\ninsights into CNN, and reveal its role and effect in the whole pipeline. We\nfurther introduce a general encoding layer, illustrating the reason why they\nmight be appropriate for language identification. We elaborate on several\ntypical encoding layers, including a temporal average pooling layer, a\nrecurrent encoding layer and a novel learnable dictionary encoding layer. We\nconducted experiment on NIST LRE07 closed-set task, and the results show that\nour proposed end-to-end systems achieve state-of-the-art performance.", "published": "2018-04-02 03:19:44", "link": "http://arxiv.org/abs/1804.00381v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Novel Learnable Dictionary Encoding Layer for End-to-End Language\n  Identification", "abstract": "A novel learnable dictionary encoding layer is proposed in this paper for\nend-to-end language identification. It is inline with the conventional GMM\ni-vector approach both theoretically and practically. We imitate the mechanism\nof traditional GMM training and Supervector encoding procedure on the top of\nCNN. The proposed layer can accumulate high-order statistics from\nvariable-length input sequence and generate an utterance level\nfixed-dimensional vector representation. Unlike the conventional methods, our\nnew approach provides an end-to-end learning framework, where the inherent\ndictionary are learned directly from the loss function. The dictionaries and\nthe encoding representation for the classifier are learned jointly. The\nrepresentation is orderless and therefore appropriate for language\nidentification. We conducted a preliminary experiment on NIST LRE07 closed-set\ntask, and the results reveal that our proposed dictionary encoding layer\nachieves significant error reduction comparing with the simple average pooling.", "published": "2018-04-02 03:31:01", "link": "http://arxiv.org/abs/1804.00385v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Spatiotemporal Models for Robust Proprioceptive Terrain\n  Classification", "abstract": "Terrain classification is a critical component of any autonomous mobile robot\nsystem operating in unknown real-world environments. Over the years, several\nproprioceptive terrain classification techniques have been introduced to\nincrease robustness or act as a fallback for traditional vision based\napproaches. However, they lack widespread adaptation due to various factors\nthat include inadequate accuracy, robustness and slow run-times. In this paper,\nwe use vehicle-terrain interaction sounds as a proprioceptive modality and\npropose a deep Long-Short Term Memory (LSTM) based recurrent model that\ncaptures both the spatial and temporal dynamics of such a problem, thereby\novercoming these past limitations. Our model consists of a new Convolution\nNeural Network (CNN) architecture that learns deep spatial features,\ncomplemented with LSTM units that learn complex temporal dynamics. Experiments\non two extensive datasets collected with different microphones on various\nindoor and outdoor terrains demonstrate state-of-the-art performance compared\nto existing techniques. We additionally evaluate the performance in adverse\nacoustic conditions with high ambient noise and propose a noise-aware training\nscheme that enables learning of more generalizable models that are essential\nfor robust real-world deployments.", "published": "2018-04-02 21:38:56", "link": "http://arxiv.org/abs/1804.00736v1", "categories": ["cs.RO", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.RO"}
