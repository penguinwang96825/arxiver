{"title": "SciBERTSUM: Extractive Summarization for Scientific Documents", "abstract": "The summarization literature focuses on the summarization of news articles.\nThe news articles in the CNN-DailyMail are relatively short documents with\nabout 30 sentences per document on average. We introduce SciBERTSUM, our\nsummarization framework designed for the summarization of long documents like\nscientific papers with more than 500 sentences. SciBERTSUM extends BERTSUM to\nlong documents by 1) adding a section embedding layer to include section\ninformation in the sentence vector and 2) applying a sparse attention mechanism\nwhere each sentences will attend locally to nearby sentences and only a small\nnumber of sentences attend globally to all other sentences. We used slides\ngenerated by the authors of scientific papers as reference summaries since they\ncontain the technical details from the paper. The results show the superiority\nof our model in terms of ROUGE scores.", "published": "2022-01-21 00:29:48", "link": "http://arxiv.org/abs/2201.08495v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Black-box Prompt Learning for Pre-trained Language Models", "abstract": "The increasing scale of general-purpose Pre-trained Language Models (PLMs)\nnecessitates the study of more efficient adaptation across different downstream\ntasks. In this paper, we establish a Black-box Discrete Prompt Learning (BDPL)\nto resonate with pragmatic interactions between the cloud infrastructure and\nedge devices. Particularly, instead of fine-tuning the model in the cloud, we\nadapt PLMs by prompt learning, which efficiently optimizes only a few\nparameters of the discrete prompts. Moreover, we consider the scenario that we\ndo not have access to the parameters and gradients of the pre-trained models,\nexcept for its outputs given inputs. This black-box setting secures the cloud\ninfrastructure from potential attack and misuse to cause a single-point\nfailure, which is preferable to the white-box counterpart by current\ninfrastructures. Under this black-box constraint, we apply a variance-reduced\npolicy gradient algorithm to estimate the gradients of parameters in the\ncategorical distribution of each discrete prompt. In light of our method, the\nuser devices can efficiently tune their tasks by querying the PLMs bounded by a\nrange of API calls. Our experiments on RoBERTa and GPT-3 demonstrate that the\nproposed algorithm achieves significant improvement on eight benchmarks in a\ncloud-device collaboration manner. Finally, we conduct in-depth case studies to\ncomprehensively analyze our method in terms of various data sizes, prompt\nlengths, training budgets, optimization objectives, prompt transferability, and\nexplanations of the learned prompts. Our code will be available at\nhttps://github.com/shizhediao/Black-Box-Prompt-Learning.", "published": "2022-01-21 03:53:19", "link": "http://arxiv.org/abs/2201.08531v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Model Compression Improve NLP Fairness", "abstract": "Model compression techniques are receiving increasing attention; however, the\neffect of compression on model fairness is still under explored. This is the\nfirst paper to examine the effect of distillation and pruning on the toxicity\nand bias of generative language models. We test Knowledge Distillation and\nPruning methods on the GPT2 model and found a consistent pattern of toxicity\nand bias reduction after model distillation; this result can be potentially\ninterpreted by existing line of research which describes model compression as a\nregularization technique; our work not only serves as a reference for safe\ndeployment of compressed models, but also extends the discussion of\n\"compression as regularization\" into the setting of neural LMs, and hints at\nthe possibility of using compression to develop fairer models.", "published": "2022-01-21 05:14:51", "link": "http://arxiv.org/abs/2201.08542v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Taxonomy Enrichment with Text and Graph Vector Representations", "abstract": "Knowledge graphs such as DBpedia, Freebase or Wikidata always contain a\ntaxonomic backbone that allows the arrangement and structuring of various\nconcepts in accordance with the hypo-hypernym (\"class-subclass\") relationship.\nWith the rapid growth of lexical resources for specific domains, the problem of\nautomatic extension of the existing knowledge bases with new words is becoming\nmore and more widespread. In this paper, we address the problem of taxonomy\nenrichment which aims at adding new words to the existing taxonomy.\n  We present a new method that allows achieving high results on this task with\nlittle effort. It uses the resources which exist for the majority of languages,\nmaking the method universal. We extend our method by incorporating deep\nrepresentations of graph structures like node2vec, Poincar\\'e embeddings, GCN\netc. that have recently demonstrated promising results on various NLP tasks.\nFurthermore, combining these representations with word embeddings allows us to\nbeat the state of the art.\n  We conduct a comprehensive study of the existing approaches to taxonomy\nenrichment based on word and graph vector representations and their fusion\napproaches. We also explore the ways of using deep learning architectures to\nextend the taxonomic backbones of knowledge graphs. We create a number of\ndatasets for taxonomy extension for English and Russian. We achieve\nstate-of-the-art results across different datasets and provide an in-depth\nerror analysis of mistakes.", "published": "2022-01-21 09:01:12", "link": "http://arxiv.org/abs/2201.08598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Text Style Transfer for Bias Mitigation using Masked Language Modeling", "abstract": "It is well known that textual data on the internet and other digital\nplatforms contain significant levels of bias and stereotypes. Although many\nsuch texts contain stereotypes and biases that inherently exist in natural\nlanguage for reasons that are not necessarily malicious, there are crucial\nreasons to mitigate these biases. For one, these texts are being used as\ntraining corpus to train language models for salient applications like\ncv-screening, search engines, and chatbots; such applications are turning out\nto produce discriminatory results. Also, several research findings have\nconcluded that biased texts have significant effects on the target demographic\ngroups. For instance, masculine-worded job advertisements tend to be less\nappealing to female applicants.\n  In this paper, we present a text style transfer model that can be used to\nautomatically debias textual data. Our style transfer model improves on the\nlimitations of many existing style transfer techniques such as loss of content\ninformation. Our model solves such issues by combining latent content encoding\nwith explicit keyword replacement. We will show that this technique produces\nbetter content preservation whilst maintaining good style transfer accuracy.", "published": "2022-01-21 11:06:33", "link": "http://arxiv.org/abs/2201.08643v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-Tuning: Learning Contextualized Prompts for Natural Language\n  Generation", "abstract": "Recently, pretrained language models (PLMs) have had exceptional success in\nlanguage generation. To leverage the rich knowledge encoded by PLMs, a simple\nyet powerful paradigm is to use prompts in the form of either discrete tokens\nor continuous embeddings. In existing studies, these prompting methods are\ntypically independent of the inputs, lacking sufficient consideration of input\nsemantics. To address this issue, we propose a novel continuous prompting\napproach, called context-tuning, to fine-tuning PLMs for natural language\ngeneration. Firstly, the prompts are derived based on the input text to elicit\nuseful knowledge from PLMs for generation. We refer to such prompts as\ncontextualized prompts. Secondly, we use continuous inverse prompting to\nimprove the process of natural language generation by modeling an inverse\ngeneration process from output to input, making the generated text more\nrelevant to the inputs. Furthermore, we utilize a lightweight context-tuning\nmethod that fine-tunes only 0.12% of the parameters while maintaining good\nperformance. Our code is publicly available at\nhttps://github.com/RUCAIBox/Context-Tuning.", "published": "2022-01-21 12:35:28", "link": "http://arxiv.org/abs/2201.08670v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparative Study on Language Models for Task-Oriented Dialogue\n  Systems", "abstract": "The recent development of language models has shown promising results by\nachieving state-of-the-art performance on various natural language tasks by\nfine-tuning pretrained models. In task-oriented dialogue (ToD) systems,\nlanguage models can be used for end-to-end training without relying on dialogue\nstate tracking to track the dialogue history but allowing the language models\nto generate responses according to the context given as input. This paper\nconducts a comparative study to show the effectiveness and strength of using\nrecent pretrained models for fine-tuning, such as BART and T5, on endto-end ToD\nsystems. The experimental results show substantial performance improvements\nafter language model fine-tuning. The models produce more fluent responses\nafter adding knowledge to the context that guides the model to avoid\nhallucination and generate accurate entities in the generated responses.\nFurthermore, we found that BART and T5 outperform GPT-based models in BLEU and\nF1 scores and achieve state-of-the-art performance in a ToD system.", "published": "2022-01-21 13:24:25", "link": "http://arxiv.org/abs/2201.08687v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Personality Type Based on Myers-Briggs Type Indicator with Text Posting\n  Style by using Traditional and Deep Learning", "abstract": "The term personality may be expressed in terms of the individual differences\nin characteristics pattern of thinking, feeling, and behavior. This work\npresents several machine learning techniques including Naive Bayes, Support\nVector Machines, and Recurrent Neural Networks to predict people personality\nfrom text based on Myers-Briggs Type Indicator (MBTI). Furthermore, this\nproject applies CRISP-DM, which stands for Cross-Industry Standard Process for\nData Mining, to guide the learning process. Since, CRISP-DM is kind of\niterative development, we have adopted it with agile methodology, which is a\nrapid iterative software development method, in order to reduce the development\ncycle to be minimal.", "published": "2022-01-21 14:34:20", "link": "http://arxiv.org/abs/2201.08717v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gender Bias in Text: Labeled Datasets and Lexicons", "abstract": "Language has a profound impact on our thoughts, perceptions, and conceptions\nof gender roles. Gender-inclusive language is, therefore, a key tool to promote\nsocial inclusion and contribute to achieving gender equality. Consequently,\ndetecting and mitigating gender bias in texts is instrumental in halting its\npropagation and societal implications. However, there is a lack of gender bias\ndatasets and lexicons for automating the detection of gender bias using\nsupervised and unsupervised machine learning (ML) and natural language\nprocessing (NLP) techniques. Therefore, the main contribution of this work is\nto publicly provide labeled datasets and exhaustive lexicons by collecting,\nannotating, and augmenting relevant sentences to facilitate the detection of\ngender bias in English text. Towards this end, we present an updated version of\nour previously proposed taxonomy by re-formalizing its structure, adding a new\nbias type, and mapping each bias subtype to an appropriate detection\nmethodology. The released datasets and lexicons span multiple bias subtypes\nincluding: Generic He, Generic She, Explicit Marking of Sex, and Gendered\nNeologisms. We leveraged the use of word embedding models to further augment\nthe collected lexicons.", "published": "2022-01-21 12:44:51", "link": "http://arxiv.org/abs/2201.08675v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GreaseLM: Graph REASoning Enhanced Language Models for Question\n  Answering", "abstract": "Answering complex questions about textual narratives requires reasoning over\nboth stated context and the world knowledge that underlies it. However,\npretrained language models (LM), the foundation of most modern QA systems, do\nnot robustly represent latent relationships between concepts, which is\nnecessary for reasoning. While knowledge graphs (KG) are often used to augment\nLMs with structured representations of world knowledge, it remains an open\nquestion how to effectively fuse and reason over the KG representations and the\nlanguage context, which provides situational constraints and nuances. In this\nwork, we propose GreaseLM, a new model that fuses encoded representations from\npretrained LMs and graph neural networks over multiple layers of modality\ninteraction operations. Information from both modalities propagates to the\nother, allowing language context representations to be grounded by structured\nworld knowledge, and allowing linguistic nuances (e.g., negation, hedging) in\nthe context to inform the graph representations of knowledge. Our results on\nthree benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA)\nand medical question answering (i.e., MedQA-USMLE) domains demonstrate that\nGreaseLM can more reliably answer questions that require reasoning over both\nsituational constraints and structured knowledge, even outperforming models 8x\nlarger.", "published": "2022-01-21 19:00:05", "link": "http://arxiv.org/abs/2201.08860v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Description-Driven Task-Oriented Dialog Modeling", "abstract": "Task-oriented dialogue (TOD) systems are required to identify key information\nfrom conversations for the completion of given tasks. Such information is\nconventionally specified in terms of intents and slots contained in\ntask-specific ontology or schemata. Since these schemata are designed by system\ndevelopers, the naming convention for slots and intents is not uniform across\ntasks, and may not convey their semantics effectively. This can lead to models\nmemorizing arbitrary patterns in data, resulting in suboptimal performance and\ngeneralization. In this paper, we propose that schemata should be modified by\nreplacing names or notations entirely with natural language descriptions. We\nshow that a language description-driven system exhibits better understanding of\ntask specifications, higher performance on state tracking, improved data\nefficiency, and effective zero-shot transfer to unseen tasks. Following this\nparadigm, we present a simple yet effective Description-Driven Dialog State\nTracking (D3ST) model, which relies purely on schema descriptions and an\n\"index-picking\" mechanism. We demonstrate the superiority in quality, data\nefficiency and robustness of our approach as measured on the MultiWOZ\n(Budzianowski et al.,2018), SGD (Rastogi et al., 2020), and the recent SGD-X\n(Lee et al., 2021) benchmarks.", "published": "2022-01-21 22:07:41", "link": "http://arxiv.org/abs/2201.08904v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Recurrent Neural Networks with Mixed Hierarchical Structures and EM\n  Algorithm for Natural Language Processing", "abstract": "How to obtain hierarchical representations with an increasing level of\nabstraction becomes one of the key issues of learning with deep neural\nnetworks. A variety of RNN models have recently been proposed to incorporate\nboth explicit and implicit hierarchical information in modeling languages in\nthe literature. In this paper, we propose a novel approach called the latent\nindicator layer to identify and learn implicit hierarchical information (e.g.,\nphrases), and further develop an EM algorithm to handle the latent indicator\nlayer in training. The latent indicator layer further simplifies a text's\nhierarchical structure, which allows us to seamlessly integrate different\nlevels of attention mechanisms into the structure. We called the resulting\narchitecture as the EM-HRNN model. Furthermore, we develop two bootstrap\nstrategies to effectively and efficiently train the EM-HRNN model on long text\ndocuments. Simulation studies and real data applications demonstrate that the\nEM-HRNN model with bootstrap training outperforms other RNN-based models in\ndocument classification tasks. The performance of the EM-HRNN model is\ncomparable to a Transformer-based method called Bert-base, though the former is\nmuch smaller model and does not require pre-training.", "published": "2022-01-21 23:08:33", "link": "http://arxiv.org/abs/2201.08919v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Learning Two-Step Hybrid Policy for Graph-Based Interpretable\n  Reinforcement Learning", "abstract": "We present a two-step hybrid reinforcement learning (RL) policy that is\ndesigned to generate interpretable and robust hierarchical policies on the RL\nproblem with graph-based input. Unlike prior deep reinforcement learning\npolicies parameterized by an end-to-end black-box graph neural network, our\napproach disentangles the decision-making process into two steps. The first\nstep is a simplified classification problem that maps the graph input to an\naction group where all actions share a similar semantic meaning. The second\nstep implements a sophisticated rule-miner that conducts explicit one-hop\nreasoning over the graph and identifies decisive edges in the graph input\nwithout the necessity of heavy domain knowledge. This two-step hybrid policy\npresents human-friendly interpretations and achieves better performance in\nterms of generalization and robustness. Extensive experimental studies on four\nlevels of complex text-based games have demonstrated the superiority of the\nproposed method compared to the state-of-the-art.", "published": "2022-01-21 03:06:24", "link": "http://arxiv.org/abs/2201.08520v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Identifying Adversarial Attacks on Text Classifiers", "abstract": "The landscape of adversarial attacks against text classifiers continues to\ngrow, with new attacks developed every year and many of them available in\nstandard toolkits, such as TextAttack and OpenAttack. In response, there is a\ngrowing body of work on robust learning, which reduces vulnerability to these\nattacks, though sometimes at a high cost in compute time or accuracy. In this\npaper, we take an alternate approach -- we attempt to understand the attacker\nby analyzing adversarial text to determine which methods were used to create\nit. Our first contribution is an extensive dataset for attack detection and\nlabeling: 1.5~million attack instances, generated by twelve adversarial attacks\ntargeting three classifiers trained on six source datasets for sentiment\nanalysis and abuse detection in English. As our second contribution, we use\nthis dataset to develop and benchmark a number of classifiers for attack\nidentification -- determining if a given text has been adversarially\nmanipulated and by which attack. As a third contribution, we demonstrate the\neffectiveness of three classes of features for these tasks: text properties,\ncapturing content and presentation of text; language model properties,\ndetermining which tokens are more or less probable throughout the input; and\ntarget model properties, representing how the text classifier is influenced by\nthe attack, including internal node activations. Overall, this represents a\nfirst step towards forensics for adversarial attacks against text classifiers.", "published": "2022-01-21 06:16:04", "link": "http://arxiv.org/abs/2201.08555v1", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dual Contrastive Learning: Text Classification via Label-Aware Data\n  Augmentation", "abstract": "Contrastive learning has achieved remarkable success in representation\nlearning via self-supervision in unsupervised settings. However, effectively\nadapting contrastive learning to supervised learning tasks remains as a\nchallenge in practice. In this work, we introduce a dual contrastive learning\n(DualCL) framework that simultaneously learns the features of input samples and\nthe parameters of classifiers in the same space. Specifically, DualCL regards\nthe parameters of the classifiers as augmented samples associating to different\nlabels and then exploits the contrastive learning between the input samples and\nthe augmented samples. Empirical studies on five benchmark text classification\ndatasets and their low-resource version demonstrate the improvement in\nclassification accuracy and confirm the capability of learning discriminative\nrepresentations of DualCL.", "published": "2022-01-21 13:59:45", "link": "http://arxiv.org/abs/2201.08702v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Building Economic Models of Conversational Search", "abstract": "Various conceptual and descriptive models of conversational search have been\nproposed in the literature -- while useful, they do not provide insights into\nhow interaction between the agent and user would change in response to the\ncosts and benefits of the different interactions. In this paper, we develop two\neconomic models of conversational search based on patterns previously observed\nduring conversational search sessions, which we refer to as: Feedback First\nwhere the agent asks clarifying questions then presents results, and Feedback\nAfter where the agent presents results, and then asks follow up questions. Our\nmodels show that the amount of feedback given/requested depends on its\nefficiency at improving the initial or subsequent query and the relative cost\nof providing said feedback. This theoretical framework for conversational\nsearch provides a number of insights that can be used to guide and inform the\ndevelopment of conversational search agents. However, empirical work is needed\nto estimate the parameters in order to make predictions specific to a given\nconversational search setting.", "published": "2022-01-21 15:20:51", "link": "http://arxiv.org/abs/2201.08742v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Conversational Information Seeking", "abstract": "Conversational information seeking (CIS) is concerned with a sequence of\ninteractions between one or more users and an information system. Interactions\nin CIS are primarily based on natural language dialogue, while they may include\nother types of interactions, such as click, touch, and body gestures. This\nmonograph provides a thorough overview of CIS definitions, applications,\ninteractions, interfaces, design, implementation, and evaluation. This\nmonograph views CIS applications as including conversational search,\nconversational question answering, and conversational recommendation. Our aim\nis to provide an overview of past research related to CIS, introduce the\ncurrent state-of-the-art in CIS, highlight the challenges still being faced in\nthe community. and suggest future directions.", "published": "2022-01-21 18:09:23", "link": "http://arxiv.org/abs/2201.08808v2", "categories": ["cs.IR", "cs.CL", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Can Machines Generate Personalized Music? A Hybrid Favorite-aware Method\n  for User Preference Music Transfer", "abstract": "User preference music transfer (UPMT) is a new problem in music style\ntransfer that can be applied to many scenarios but remains understudied.", "published": "2022-01-21 03:24:27", "link": "http://arxiv.org/abs/2201.08526v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
