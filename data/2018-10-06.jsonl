{"title": "Personality facets recognition from text", "abstract": "Fundamental Big Five personality traits (e.g., Extraversion) and their facets\n(e.g., Activity) are known to correlate with a broad range of linguistic\nfeatures and, accordingly, the recognition of personality traits from text is a\nwell-known Natural Language Processing task. Labelling text data with facets\ninformation, however, may require the use of lengthy personality inventories,\nand perhaps for that reason existing computational models of this kind are\nusually limited to the recognition of the fundamental traits. Based on these\nobservations, this paper investigates the issue of personality facets\nrecognition from text labelled only with information available from a shorter\npersonality inventory. In doing so, we provide a low-cost model for the\nrecognition of certain personality facets, and present reference results for\nfurther studies in this field.", "published": "2018-10-06 11:09:54", "link": "http://arxiv.org/abs/1810.02980v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "When logic lays down the law", "abstract": "We analyse so-called computable laws, i.e., laws that can be enforced by\nautomatic procedures. These laws should be logically perfect and unambiguous,\nbut sometimes they are not. We use a regulation on road transport to illustrate\nthis issue, and show what some fragments of this regulation would look like if\nrewritten in the image of logic. We further propose desiderata to be fulfilled\nby computable laws, and provide a critical platform from which to assess\nexisting laws and a guideline for composing future ones.", "published": "2018-10-06 13:25:54", "link": "http://arxiv.org/abs/1810.03002v1", "categories": ["cs.AI", "cs.CL", "00A69"], "primary_category": "cs.AI"}
{"title": "FlowQA: Grasping Flow in History for Conversational Machine\n  Comprehension", "abstract": "Conversational machine comprehension requires the understanding of the\nconversation history, such as previous question/answer pairs, the document\ncontext, and the current question. To enable traditional, single-turn models to\nencode the history comprehensively, we introduce Flow, a mechanism that can\nincorporate intermediate representations generated during the process of\nanswering previous questions, through an alternating parallel processing\nstructure. Compared to approaches that concatenate previous questions/answers\nas input, Flow integrates the latent semantics of the conversation history more\ndeeply. Our model, FlowQA, shows superior performance on two recently proposed\nconversational challenges (+7.2% F1 on CoQA and +4.0% on QuAC). The\neffectiveness of Flow also shows in other tasks. By reducing sequential\ninstruction understanding to conversational machine comprehension, FlowQA\noutperforms the best models on all three domains in SCONE, with +1.8% to +4.4%\nimprovement in accuracy.", "published": "2018-10-06 20:46:49", "link": "http://arxiv.org/abs/1810.06683v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Co-Stack Residual Affinity Networks with Multi-level Attention\n  Refinement for Matching Text Sequences", "abstract": "Learning a matching function between two text sequences is a long standing\nproblem in NLP research. This task enables many potential applications such as\nquestion answering and paraphrase identification. This paper proposes Co-Stack\nResidual Affinity Networks (CSRAN), a new and universal neural architecture for\nthis problem. CSRAN is a deep architecture, involving stacked (multi-layered)\nrecurrent encoders. Stacked/Deep architectures are traditionally difficult to\ntrain, due to the inherent weaknesses such as difficulty with feature\npropagation and vanishing gradients. CSRAN incorporates two novel components to\ntake advantage of the stacked architecture. Firstly, it introduces a new\nbidirectional alignment mechanism that learns affinity weights by fusing\nsequence pairs across stacked hierarchies. Secondly, it leverages a multi-level\nattention refinement component between stacked recurrent layers. The key\nintuition is that, by leveraging information across all network hierarchies, we\ncan not only improve gradient flow but also improve overall performance. We\nconduct extensive experiments on six well-studied text sequence matching\ndatasets, achieving state-of-the-art performance on all.", "published": "2018-10-06 05:25:24", "link": "http://arxiv.org/abs/1810.02938v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Text-based Sentiment Analysis and Music Emotion Recognition", "abstract": "Sentiment polarity of tweets, blog posts or product reviews has become highly\nattractive and is utilized in recommender systems, market predictions, business\nintelligence and more. Deep learning techniques are becoming top performers on\nanalyzing such texts. There are however several problems that need to be solved\nfor efficient use of deep neural networks on text mining and text polarity\nanalysis. First, deep neural networks need to be fed with data sets that are\nbig in size as well as properly labeled. Second, there are various\nuncertainties regarding the use of word embedding vectors: should they be\ngenerated from the same data set that is used to train the model or it is\nbetter to source them from big and popular collections? Third, to simplify\nmodel creation it is convenient to have generic neural network architectures\nthat are effective and can adapt to various texts, encapsulating much of design\ncomplexity. This thesis addresses the above problems to provide methodological\nand practical insights for utilizing neural networks on sentiment analysis of\ntexts and achieving state of the art results. Regarding the first problem, the\neffectiveness of various crowdsourcing alternatives is explored and two\nmedium-sized and emotion-labeled song data sets are created utilizing social\ntags. To address the second problem, a series of experiments with large text\ncollections of various contents and domains were conducted, trying word\nembeddings of various parameters. Regarding the third problem, a series of\nexperiments involving convolution and max-pooling neural layers were conducted.\nCombining convolutions of words, bigrams, and trigrams with regional\nmax-pooling layers in a couple of stacks produced the best results. The derived\narchitecture achieves competitive performance on sentiment polarity analysis of\nmovie, business and product reviews.", "published": "2018-10-06 17:42:19", "link": "http://arxiv.org/abs/1810.03031v1", "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Performance Evaluation of VoLTE Based on Field Measurement Data", "abstract": "Voice over Long-Term Evolution (VoLTE) has been witnessing a rapid deployment\nby network carriers worldwide. During the phases of VoLTE deployments, carriers\nwould typically face challenges in understanding the factors affecting the\nVoLTE performance and then optimizing it to meet or exceed the performance of\nthe legacy circuit switched (CS) network (i.e., 2G/3G). The main challenge of\nVoLTE service quality is the LTE network optimization and the performance\naspects of the service in different LTE deployment scenarios. In this paper, we\npresent a detailed practical performance analysis of VoLTE based on\ncommercially deployed 3GPP Release-10 LTE networks. The analysis evaluates\nVoLTE performance in terms of real-time transport protocol (RTP) error rate,\nRTP jitter and delays, block error rate (BLER) in different radio conditions\nand VoLTE voice quality in terms of mean opinion score (MOS). In addition, the\npaper evaluates key VoLTE features such as RObust Header Compression (ROHC) and\ntransmission time interval (TTI) bundling. This paper provides guidelines for\nbest practices of VoLTE deployment as well as practical performance evaluation\nbased on field measurement data from commercial LTE networks.", "published": "2018-10-06 09:41:19", "link": "http://arxiv.org/abs/1810.02968v1", "categories": ["cs.NI", "cs.SD", "eess.AS"], "primary_category": "cs.NI"}
