{"title": "Log-linear Combinations of Monolingual and Bilingual Neural Machine\n  Translation Models for Automatic Post-Editing", "abstract": "This paper describes the submission of the AMU (Adam Mickiewicz University)\nteam to the Automatic Post-Editing (APE) task of WMT 2016. We explore the\napplication of neural translation models to the APE problem and achieve good\nresults by treating different models as components in a log-linear model,\nallowing for multiple inputs (the MT-output and the source) that are decoded to\nthe same target language (post-edited translations). A simple string-matching\npenalty integrated within the log-linear model is used to control for higher\nfaithfulness with regard to the raw machine translation output. To overcome the\nproblem of too little training data, we generate large amounts of artificial\ndata. Our submission improves over the uncorrected baseline on the unseen test\nset by -3.2\\% TER and +5.5\\% BLEU and outperforms any other system submitted to\nthe shared-task by a large margin.", "published": "2016-05-16 15:15:05", "link": "http://arxiv.org/abs/1605.04800v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The AMU-UEDIN Submission to the WMT16 News Translation Task:\n  Attention-based NMT Models as Feature Functions in Phrase-based SMT", "abstract": "This paper describes the AMU-UEDIN submissions to the WMT 2016 shared task on\nnews translation. We explore methods of decode-time integration of\nattention-based neural translation models with phrase-based statistical machine\ntranslation. Efficient batch-algorithms for GPU-querying are proposed and\nimplemented. For English-Russian, our system stays behind the state-of-the-art\npure neural models in terms of BLEU. Among restricted systems, manual\nevaluation places it in the first cluster tied with the pure neural model. For\nthe Russian-English task, our submission achieves the top BLEU result,\noutperforming the best pure neural system by 1.1 BLEU points and our own\nphrase-based baseline by 1.6 BLEU. After manual evaluation, this system is the\nbest restricted system in its own cluster. In follow-up experiments we improve\nresults by additional 0.8 BLEU.", "published": "2016-05-16 15:34:19", "link": "http://arxiv.org/abs/1605.04809v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Identification of promising research directions using machine learning\n  aided medical literature analysis", "abstract": "The rapidly expanding corpus of medical research literature presents major\nchallenges in the understanding of previous work, the extraction of maximum\ninformation from collected data, and the identification of promising research\ndirections. We present a case for the use of advanced machine learning\ntechniques as an aide in this task and introduce a novel methodology that is\nshown to be capable of extracting meaningful information from large\nlongitudinal corpora, and of tracking complex temporal changes within it.", "published": "2016-05-16 12:55:36", "link": "http://arxiv.org/abs/1607.04660v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Joint Learning of Sentence Embeddings for Relevance and Entailment", "abstract": "We consider the problem of Recognizing Textual Entailment within an\nInformation Retrieval context, where we must simultaneously determine the\nrelevancy as well as degree of entailment for individual pieces of evidence to\ndetermine a yes/no answer to a binary natural language question.\n  We compare several variants of neural networks for sentence embeddings in a\nsetting of decision-making based on evidence of varying relevance. We propose a\nbasic model to integrate evidence for entailment, show that joint training of\nthe sentence embeddings to model relevance and entailment is feasible even with\nno explicit per-evidence supervision, and show the importance of evaluating\nstrong baselines. We also demonstrate the benefit of carrying over text\ncomprehension model trained on an unrelated task for our small datasets.\n  Our research is motivated primarily by a new open dataset we introduce,\nconsisting of binary questions and news-based evidence snippets. We also apply\nthe proposed relevance-entailment model on a similar task of ranking\nmultiple-choice test answers, evaluating it on a preliminary dataset of school\ntest questions as well as the standard MCTest dataset, where we improve the\nneural model state-of-art.", "published": "2016-05-16 05:50:54", "link": "http://arxiv.org/abs/1605.04655v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
