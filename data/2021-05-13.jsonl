{"title": "Towards Human-Free Automatic Quality Evaluation of German Summarization", "abstract": "Evaluating large summarization corpora using humans has proven to be\nexpensive from both the organizational and the financial perspective.\nTherefore, many automatic evaluation metrics have been developed to measure the\nsummarization quality in a fast and reproducible way. However, most of the\nmetrics still rely on humans and need gold standard summaries generated by\nlinguistic experts. Since BLANC does not require golden summaries and\nsupposedly can use any underlying language model, we consider its application\nto the evaluation of summarization in German. This work demonstrates how to\nadjust the BLANC metric to a language other than English. We compare BLANC\nscores with the crowd and expert ratings, as well as with commonly used\nautomatic metrics on a German summarization data set. Our results show that\nBLANC in German is especially good in evaluating informativeness.", "published": "2021-05-13 01:29:33", "link": "http://arxiv.org/abs/2105.06027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HyKnow: End-to-End Task-Oriented Dialog Modeling with Hybrid Knowledge\n  Management", "abstract": "Task-oriented dialog (TOD) systems typically manage structured knowledge\n(e.g. ontologies and databases) to guide the goal-oriented conversations.\nHowever, they fall short of handling dialog turns grounded on unstructured\nknowledge (e.g. reviews and documents). In this paper, we formulate a task of\nmodeling TOD grounded on both structured and unstructured knowledge. To address\nthis task, we propose a TOD system with hybrid knowledge management, HyKnow. It\nextends the belief state to manage both structured and unstructured knowledge,\nand is the first end-to-end model that jointly optimizes dialog modeling\ngrounded on these two kinds of knowledge. We conduct experiments on the\nmodified version of MultiWOZ 2.1 dataset, where dialogs are grounded on hybrid\nknowledge. Experimental results show that HyKnow has strong end-to-end\nperformance compared to existing TOD systems. It also outperforms the pipeline\nknowledge management schemes, with higher unstructured knowledge retrieval\naccuracy.", "published": "2021-05-13 01:58:39", "link": "http://arxiv.org/abs/2105.06041v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thematic Fit Bits: Annotation Quality and Quantity Interplay for Event\n  Participant Representation", "abstract": "Modeling thematic fit (a verb--argument compositional semantics task)\ncurrently requires a very large burden of labeled data. We take a\nlinguistically machine-annotated large corpus and replace corpus layers with\noutput from higher-quality, more modern taggers. We compare the old and new\ncorpus versions' impact on a verb--argument fit modeling task, using a\nhigh-performing neural approach. We discover that higher annotation quality\ndramatically reduces our data requirement while demonstrating better supervised\npredicate-argument classification. But in applying the model to\npsycholinguistic tasks outside the training objective, we see clear gains at\nscale, but only in one of two thematic fit estimation tasks, and no clear gains\non the other. We also see that quality improves with training size, but perhaps\nplateauing or even declining in one task. Last, we tested the effect of role\nset size. All this suggests that the quality/quantity interplay is not all you\nneed. We replicate previous studies while modifying certain role representation\ndetails and set a new state-of-the-art in event modeling, using a fraction of\nthe data. We make the new corpus version public.", "published": "2021-05-13 06:13:44", "link": "http://arxiv.org/abs/2105.06097v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linguistic Inspired Graph Analysis", "abstract": "Isomorphisms allow human cognition to transcribe a potentially unsolvable\nproblem from one domain to a different domain where the problem might be more\neasily addressed. Current approaches only focus on transcribing structural\ninformation from the source to target structure, ignoring semantic and\npragmatic information. Functional Language Theory presents five subconstructs\nfor the classification and understanding of languages. By deriving a mapping\nbetween the metamodels in linguistics and graph theory it will be shown that\ncurrently, no constructs exist in canonical graphs for the representation of\nsemantic and pragmatic information. It is found that further work needs to be\ndone to understand how graphs can be enriched to allow for isomorphisms to\ncapture semantic and pragmatic information. This capturing of additional\ninformation could lead to understandings of the source structure and enhanced\nmanipulations and interrogations of the contained relationships. Current\nmathematical graph structures in their general definition do not allow for the\nexpression of higher information levels of a source.", "published": "2021-05-13 12:16:30", "link": "http://arxiv.org/abs/2105.06216v1", "categories": ["cs.CL", "E.1; G.2.2; F.2.2"], "primary_category": "cs.CL"}
{"title": "Shades of confusion: Lexical uncertainty modulates ad hoc coordination\n  in an interactive communication task", "abstract": "There is substantial variability in the expectations that communication\npartners bring into interactions, creating the potential for misunderstandings.\nTo directly probe these gaps and our ability to overcome them, we propose a\ncommunication task based on color-concept associations. In Experiment 1, we\nestablish several key properties of the mental representations of these\nexpectations, or lexical priors, based on recent probabilistic theories.\nAssociations are more variable for abstract concepts, variability is\nrepresented as uncertainty within each individual, and uncertainty enables\naccurate predictions about whether others are likely to share the same\nassociation. In Experiment 2, we then examine the downstream consequences of\nthese representations for communication. Accuracy is initially low when\ncommunicating about concepts with more variable associations, but rapidly\nincreases as participants form ad hoc conventions. Together, our findings\nsuggest that people cope with variability by maintaining well-calibrated\nuncertainty about their partner and appropriately adaptable representations of\ntheir own.", "published": "2021-05-13 20:42:28", "link": "http://arxiv.org/abs/2105.06546v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-Supervised Variational Reasoning for Medical Dialogue Generation", "abstract": "Medical dialogue generation aims to provide automatic and accurate responses\nto assist physicians to obtain diagnosis and treatment suggestions in an\nefficient manner. In medical dialogues two key characteristics are relevant for\nresponse generation: patient states (such as symptoms, medication) and\nphysician actions (such as diagnosis, treatments). In medical scenarios\nlarge-scale human annotations are usually not available, due to the high costs\nand privacy requirements. Hence, current approaches to medical dialogue\ngeneration typically do not explicitly account for patient states and physician\nactions, and focus on implicit representation instead. We propose an end-to-end\nvariational reasoning approach to medical dialogue generation. To be able to\ndeal with a limited amount of labeled data, we introduce both patient state and\nphysician action as latent variables with categorical priors for explicit\npatient state tracking and physician policy learning, respectively. We propose\na variational Bayesian generative approach to approximate posterior\ndistributions over patient states and physician actions. We use an efficient\nstochastic gradient variational Bayes estimator to optimize the derived\nevidence lower bound, where a 2-stage collapsed inference method is proposed to\nreduce the bias during model training. A physician policy network composed of\nan action-classifier and two reasoning detectors is proposed for augmented\nreasoning ability. We conduct experiments on three datasets collected from\nmedical platforms. Our experimental results show that the proposed method\noutperforms state-of-the-art baselines in terms of objective and subjective\nevaluation metrics. Our experiments also indicate that our proposed\nsemi-supervised reasoning method achieves a comparable performance as\nstate-of-the-art fully supervised learning baselines for physician policy\nlearning.", "published": "2021-05-13 04:14:35", "link": "http://arxiv.org/abs/2105.06071v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-Domain Contract Element Extraction with a Bi-directional Feedback\n  Clause-Element Relation Network", "abstract": "Contract element extraction (CEE) is the novel task of automatically\nidentifying and extracting legally relevant elements such as contract dates,\npayments, and legislation references from contracts. Automatic methods for this\ntask view it as a sequence labeling problem and dramatically reduce human\nlabor. However, as contract genres and element types may vary widely, a\nsignificant challenge for this sequence labeling task is how to transfer\nknowledge from one domain to another, i.e., cross-domain CEE. Cross-domain CEE\ndiffers from cross-domain named entity recognition (NER) in two important ways.\nFirst, contract elements are far more fine-grained than named entities, which\nhinders the transfer of extractors. Second, the extraction zones for\ncross-domain CEE are much larger than for cross-domain NER. As a result, the\ncontexts of elements from different domains can be more diverse. We propose a\nframework, the Bi-directional Feedback cLause-Element relaTion network\n(Bi-FLEET), for the cross-domain CEE task that addresses the above challenges.\nBi-FLEET has three main components: (1) a context encoder, (2) a clause-element\nrelation encoder, and (3) an inference layer. To incorporate invariant\nknowledge about element and clause types, a clause-element graph is constructed\nacross domains and a hierarchical graph neural network is adopted in the\nclause-element relation encoder. To reduce the influence of context variations,\na multi-task framework with a bi-directional feedback scheme is designed in the\ninference layer, conducting both clause classification and element extraction.\nThe experimental results over both cross-domain NER and CEE tasks show that\nBi-FLEET significantly outperforms state-of-the-art baselines.", "published": "2021-05-13 05:14:36", "link": "http://arxiv.org/abs/2105.06083v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with\n  Adapters", "abstract": "To diversify and enrich generated dialogue responses, knowledge-grounded\ndialogue has been investigated in recent years. The existing methods tackle the\nknowledge grounding challenge by retrieving the relevant sentences over a large\ncorpus and augmenting the dialogues with explicit extra information. Despite\ntheir success, however, the existing works have drawbacks in inference\nefficiency. This paper proposes KnowExpert, a framework to bypass the explicit\nretrieval process and inject knowledge into the pre-trained language models\nwith lightweight adapters and adapt to the knowledge-grounded dialogue task. To\nthe best of our knowledge, this is the first attempt to tackle this challenge\nwithout retrieval in this task under an open-domain chit-chat scenario. The\nexperimental results show that Knowexpert performs comparably with some\nretrieval-based baselines while being time-efficient in inference,\ndemonstrating the effectiveness of our proposed method.", "published": "2021-05-13 12:33:23", "link": "http://arxiv.org/abs/2105.06232v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Predicting Text Readability from Scrolling Interactions", "abstract": "Judging the readability of text has many important applications, for instance\nwhen performing text simplification or when sourcing reading material for\nlanguage learners. In this paper, we present a 518 participant study which\ninvestigates how scrolling behaviour relates to the readability of a text. We\nmake our dataset publicly available and show that (1) there are statistically\nsignificant differences in the way readers interact with text depending on the\ntext level, (2) such measures can be used to predict the readability of text,\nand (3) the background of a reader impacts their reading interactions and the\nfactors contributing to text difficulty.", "published": "2021-05-13 15:27:00", "link": "http://arxiv.org/abs/2105.06354v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "SaRoCo: Detecting Satire in a Novel Romanian Corpus of News Articles", "abstract": "In this work, we introduce a corpus for satire detection in Romanian news. We\ngathered 55,608 public news articles from multiple real and satirical news\nsources, composing one of the largest corpora for satire detection regardless\nof language and the only one for the Romanian language. We provide an official\nsplit of the text samples, such that training news articles belong to different\nsources than test news articles, thus ensuring that models do not achieve high\nperformance simply due to overfitting. We conduct experiments with two\nstate-of-the-art deep neural models, resulting in a set of strong baselines for\nour novel corpus. Our results show that the machine-level accuracy for satire\ndetection in Romanian is quite low (under 73% on the test set) compared to the\nhuman-level accuracy (87%), leaving enough room for improvement in future\nresearch.", "published": "2021-05-13 17:54:37", "link": "http://arxiv.org/abs/2105.06456v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Conversational AI Systems for Social Good: Opportunities and Challenges", "abstract": "Conversational artificial intelligence (ConvAI) systems have attracted much\nacademic and commercial attention recently, making significant progress on both\nfronts. However, little existing work discusses how these systems can be\ndeveloped and deployed for social good in real-world applications, with\ncomprehensive case studies and analyses of pros and cons. In this paper, we\nbriefly review the progress the community has made towards better ConvAI\nsystems and reflect on how existing technologies can help advance social good\ninitiatives from various angles that are unique for ConvAI, or not yet become\ncommon knowledge in the community. We further discuss about the challenges\nahead for ConvAI systems to better help us achieve these goals and highlight\nthe risks involved in their development and deployment in the real world.", "published": "2021-05-13 17:56:04", "link": "http://arxiv.org/abs/2105.06457v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "NLP is Not enough -- Contextualization of User Input in Chatbots", "abstract": "AI chatbots have made vast strides in technology improvement in recent years\nand are already operational in many industries. Advanced Natural Language\nProcessing techniques, based on deep networks, efficiently process user\nrequests to carry out their functions. As chatbots gain traction, their\napplicability in healthcare is an attractive proposition due to the reduced\neconomic and people costs of an overburdened system. However, healthcare bots\nrequire safe and medically accurate information capture, which deep networks\naren't yet capable of due to user text and speech variations. Knowledge in\nsymbolic structures is more suited for accurate reasoning but cannot handle\nnatural language processing directly. Thus, in this paper, we study the effects\nof combining knowledge and neural representations on chatbot safety, accuracy,\nand understanding.", "published": "2021-05-13 18:57:32", "link": "http://arxiv.org/abs/2105.06511v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Distilling BERT for low complexity network training", "abstract": "This paper studies the efficiency of transferring BERT learnings to low\ncomplexity models like BiLSTM, BiLSTM with attention and shallow CNNs using\nsentiment analysis on SST-2 dataset. It also compares the complexity of\ninference of the BERT model with these lower complexity models and underlines\nthe importance of these techniques in enabling high performance NLP models on\nedge devices like mobiles, tablets and MCU development boards like Raspberry Pi\netc. and enabling exciting new applications.", "published": "2021-05-13 19:09:22", "link": "http://arxiv.org/abs/2105.06514v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Are Larger Pretrained Language Models Uniformly Better? Comparing\n  Performance at the Instance Level", "abstract": "Larger language models have higher accuracy on average, but are they better\non every single instance (datapoint)? Some work suggests larger models have\nhigher out-of-distribution robustness, while other work suggests they have\nlower accuracy on rare subgroups. To understand these differences, we\ninvestigate these models at the level of individual instances. However, one\nmajor challenge is that individual predictions are highly sensitive to noise in\nthe randomness in training. We develop statistically rigorous methods to\naddress this, and after accounting for pretraining and finetuning noise, we\nfind that our BERT-Large is worse than BERT-Mini on at least 1-4% of instances\nacross MNLI, SST-2, and QQP, compared to the overall accuracy improvement of\n2-10%. We also find that finetuning noise increases with model size and that\ninstance-level accuracy has momentum: improvement from BERT-Mini to BERT-Medium\ncorrelates with improvement from BERT-Medium to BERT-Large. Our findings\nsuggest that instance-level predictions provide a rich source of information;\nwe therefore, recommend that researchers supplement model weights with model\npredictions.", "published": "2021-05-13 01:10:51", "link": "http://arxiv.org/abs/2105.06020v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Video Corpus Moment Retrieval with Contrastive Learning", "abstract": "Given a collection of untrimmed and unsegmented videos, video corpus moment\nretrieval (VCMR) is to retrieve a temporal moment (i.e., a fraction of a video)\nthat semantically corresponds to a given text query. As video and text are from\ntwo distinct feature spaces, there are two general approaches to address VCMR:\n(i) to separately encode each modality representations, then align the two\nmodality representations for query processing, and (ii) to adopt fine-grained\ncross-modal interaction to learn multi-modal representations for query\nprocessing. While the second approach often leads to better retrieval accuracy,\nthe first approach is far more efficient. In this paper, we propose a Retrieval\nand Localization Network with Contrastive Learning (ReLoCLNet) for VCMR. We\nadopt the first approach and introduce two contrastive learning objectives to\nrefine video encoder and text encoder to learn video and text representations\nseparately but with better alignment for VCMR. The video contrastive learning\n(VideoCL) is to maximize mutual information between query and candidate video\nat video-level. The frame contrastive learning (FrameCL) aims to highlight the\nmoment region corresponds to the query at frame-level, within a video.\nExperimental results show that, although ReLoCLNet encodes text and video\nseparately for efficiency, its retrieval accuracy is comparable with baselines\nadopting cross-modal interaction learning.", "published": "2021-05-13 12:54:39", "link": "http://arxiv.org/abs/2105.06247v1", "categories": ["cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech", "abstract": "Recently, denoising diffusion probabilistic models and generative score\nmatching have shown high potential in modelling complex data distributions\nwhile stochastic calculus has provided a unified point of view on these\ntechniques allowing for flexible inference schemes. In this paper we introduce\nGrad-TTS, a novel text-to-speech model with score-based decoder producing\nmel-spectrograms by gradually transforming noise predicted by encoder and\naligned with text input by means of Monotonic Alignment Search. The framework\nof stochastic differential equations helps us to generalize conventional\ndiffusion probabilistic models to the case of reconstructing data from noise\nwith different parameters and allows to make this reconstruction flexible by\nexplicitly controlling trade-off between sound quality and inference speed.\nSubjective human evaluation shows that Grad-TTS is competitive with\nstate-of-the-art text-to-speech approaches in terms of Mean Opinion Score. We\nwill make the code publicly available shortly.", "published": "2021-05-13 14:47:44", "link": "http://arxiv.org/abs/2105.06337v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-target DoA Estimation with an Audio-visual Fusion Mechanism", "abstract": "Most of the prior studies in the spatial \\ac{DoA} domain focus on a single\nmodality. However, humans use auditory and visual senses to detect the presence\nof sound sources. With this motivation, we propose to use neural networks with\naudio and visual signals for multi-speaker localization. The use of\nheterogeneous sensors can provide complementary information to overcome\nuni-modal challenges, such as noise, reverberation, illumination variations,\nand occlusions. We attempt to address these issues by introducing an adaptive\nweighting mechanism for audio-visual fusion. We also propose a novel video\nsimulation method that generates visual features from noisy target 3D\nannotations that are synchronized with acoustic features. Experimental results\nconfirm that audio-visual fusion consistently improves the performance of\nspeaker DoA estimation, while the adaptive weighting mechanism shows clear\nbenefits.", "published": "2021-05-13 06:55:41", "link": "http://arxiv.org/abs/2105.06107v1", "categories": ["cs.SD", "cs.RO", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio Captioning with Composition of Acoustic and Semantic Information", "abstract": "Generating audio captions is a new research area that combines audio and\nnatural language processing to create meaningful textual descriptions for audio\nclips. To address this problem, previous studies mostly use the encoder-decoder\nbased models without considering semantic information. To fill this gap, we\npresent a novel encoder-decoder architecture using bi-directional Gated\nRecurrent Units (BiGRU) with audio and semantic embeddings. We extract semantic\nembedding by obtaining subjects and verbs from the audio clip captions and\ncombine these embedding with audio embedding to feed the BiGRU-based\nencoder-decoder model. To enable semantic embeddings for the test audios, we\nintroduce a Multilayer Perceptron classifier to predict the semantic embeddings\nof those clips. We also present exhaustive experiments to show the efficiency\nof different features and datasets for our proposed model the audio captioning\ntask. To extract audio features, we use the log Mel energy features, VGGish\nembeddings, and a pretrained audio neural network (PANN) embeddings. Extensive\nexperiments on two audio captioning datasets Clotho and AudioCaps show that our\nproposed model outperforms state-of-the-art audio captioning models across\ndifferent evaluation metrics and using the semantic information improves the\ncaptioning performance. Keywords: Audio captioning; PANNs; VGGish; GRU; BiGRU.", "published": "2021-05-13 15:30:14", "link": "http://arxiv.org/abs/2105.06355v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
