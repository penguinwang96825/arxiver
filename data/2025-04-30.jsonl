{"title": "TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments", "abstract": "Objectives: While Large Language Models (LLMs) have been widely used to\nassist clinicians and support patients, no existing work has explored dialogue\nsystems for standard diagnostic interviews and assessments. This study aims to\nbridge the gap in mental healthcare accessibility by developing an LLM-powered\ndialogue system that replicates clinician behavior. Materials and Methods: We\nintroduce TRUST, a framework of cooperative LLM modules capable of conducting\nformal diagnostic interviews and assessments for Post-Traumatic Stress Disorder\n(PTSD). To guide the generation of appropriate clinical responses, we propose a\nDialogue Acts schema specifically designed for clinical interviews.\nAdditionally, we develop a patient simulation approach based on real-life\ninterview transcripts to replace time-consuming and costly manual testing by\nclinicians. Results: A comprehensive set of evaluation metrics is designed to\nassess the dialogue system from both the agent and patient simulation\nperspectives. Expert evaluations by conversation and clinical specialists show\nthat TRUST performs comparably to real-life clinical interviews. Discussion:\nOur system performs at the level of average clinicians, with room for future\nenhancements in communication styles and response appropriateness. Conclusions:\nOur TRUST framework shows its potential to facilitate mental healthcare\navailability.", "published": "2025-04-30 17:58:06", "link": "http://arxiv.org/abs/2504.21851v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition", "abstract": "We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.", "published": "2025-04-30 16:57:48", "link": "http://arxiv.org/abs/2504.21801v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues", "abstract": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. In our dataset, synthetic dialogues match structural\nfeatures of real-world dialogues (e.g., speaker switch ratio: 0.98 vs. 0.99),\nhowever, synthetic interactions do not adequately reflect key fidelity markers\n(e.g., distress monitoring). We highlight gaps in existing evaluation\nframeworks and advocate for fidelity-aware metrics that go beyond surface\nfluency to uncover clinically significant failures. Our findings clarify where\nsynthetic data can effectively complement real-world datasets -- and where\ncritical limitations remain.", "published": "2025-04-30 16:56:56", "link": "http://arxiv.org/abs/2504.21800v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "68T50", "I.2.7; H.3.1"], "primary_category": "cs.CL"}
{"title": "SWE-smith: Scaling Data for Software Engineering Agents", "abstract": "Despite recent progress in Language Models (LMs) for software engineering,\ncollecting training data remains a significant pain point. Existing datasets\nare small, with at most 1,000s of training instances from 11 or fewer GitHub\nrepositories. The procedures to curate such datasets are often complex,\nnecessitating hundreds of hours of human labor; companion execution\nenvironments also take up several terabytes of storage, severely limiting their\nscalability and usability. To address this pain point, we introduce SWE-smith,\na novel pipeline for generating software engineering training data at scale.\nGiven any Python codebase, SWE-smith constructs a corresponding execution\nenvironment, then automatically synthesizes 100s to 1,000s of task instances\nthat break existing test(s) in the codebase. Using SWE-smith, we create a\ndataset of 50k instances sourced from 128 GitHub repositories, an order of\nmagnitude larger than all previous works. We train SWE-agent-LM-32B, achieving\n40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art\namong open source models. We open source SWE-smith (collection procedure, task\ninstances, trajectories, models) to lower the barrier of entry for research in\nLM systems for automated software engineering. All assets available at\nhttps://swesmith.com.", "published": "2025-04-30 16:56:06", "link": "http://arxiv.org/abs/2504.21798v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "WebThinker: Empowering Large Reasoning Models with Deep Research Capability", "abstract": "Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate\nimpressive long-horizon reasoning capabilities. However, their reliance on\nstatic internal knowledge limits their performance on complex,\nknowledge-intensive tasks and hinders their ability to produce comprehensive\nresearch reports requiring synthesis of diverse web information. To address\nthis, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs\nto autonomously search the web, navigate web pages, and draft research reports\nduring the reasoning process. WebThinker integrates a \\textbf{Deep Web\nExplorer} module, enabling LRMs to dynamically search, navigate, and extract\ninformation from the web when encountering knowledge gaps. It also employs an\n\\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to\nseamlessly interleave reasoning, information gathering, and report writing in\nreal time. To further enhance research tool utilization, we introduce an\n\\textbf{RL-based training strategy} via iterative online Direct Preference\nOptimization (DPO). Extensive experiments on complex reasoning benchmarks\n(GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive)\ndemonstrate that WebThinker significantly outperforms existing methods and\nstrong proprietary systems. Our approach enhances LRM reliability and\napplicability in complex scenarios, paving the way for more capable and\nversatile deep research systems. The code is available at\nhttps://github.com/RUC-NLPIR/WebThinker.", "published": "2025-04-30 16:25:25", "link": "http://arxiv.org/abs/2504.21776v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness", "abstract": "With the widespread application of large language models (LLMs), the issue of\ngenerating non-existing facts, known as hallucination, has garnered increasing\nattention. Previous research in enhancing LLM confidence estimation mainly\nfocuses on the single problem setting. However, LLM awareness of its internal\nparameterized knowledge boundary under the more challenging multi-problem\nsetting, which requires answering multiple problems accurately simultaneously,\nremains underexplored. To bridge this gap, we introduce a novel method,\nMultiple Answers and Confidence Stepwise Tuning (MAC-Tuning), that separates\nthe learning of answer prediction and confidence estimation during fine-tuning\non instruction data. Extensive experiments demonstrate that our method\noutperforms baselines by up to 25% in average precision.", "published": "2025-04-30 16:17:53", "link": "http://arxiv.org/abs/2504.21773v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CodeFlowBench: A Multi-turn, Iterative Benchmark for Complex Code Generation", "abstract": "Real world development demands code that is readable, extensible, and\ntestable by organizing the implementation into modular components and\niteratively reuse pre-implemented code. We term this iterative, multi-turn\nprocess codeflow and introduce CodeFlowBench, the first benchmark designed for\ncomprehensively evaluating LLMs' ability to perform codeflow, namely to\nimplement new functionality by reusing existing functions over multiple turns.\nCodeFlowBench comprises 5258 problems drawn from Codeforces and is continuously\nupdated via an automated pipeline that decomposes each problem into a series of\nfunction-level subproblems based on its dependency tree and each subproblem is\npaired with unit tests. We further propose a novel evaluation framework with\ntasks and metrics tailored to multi-turn code reuse to assess model\nperformance. In experiments across various LLMs under both multi-turn and\nsingle-turn patterns. We observe models' poor performance on CodeFlowBench,\nwith a substantial performance drop in the iterative codeflow scenario. For\ninstance, o1-mini achieves a pass@1 of 20.8% in multi-turn pattern versus 37.8%\nin single-turn pattern. Further analysis shows that different models excel at\ndifferent dependency depths, yet all struggle to correctly solve structurally\ncomplex problems, highlighting challenges for current LLMs to serve as code\ngeneration tools when performing codeflow. Overall, CodeFlowBench offers a\ncomprehensive benchmark and new insights into LLM capabilities for multi-turn,\niterative code generation, guiding future advances in code generation tasks.", "published": "2025-04-30 15:45:28", "link": "http://arxiv.org/abs/2504.21751v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Improving Retrieval-Augmented Neural Machine Translation with Monolingual Data", "abstract": "Conventional retrieval-augmented neural machine translation (RANMT) systems\nleverage bilingual corpora, e.g., translation memories (TMs). Yet, in many\nsettings, in-domain monolingual target-side corpora are often available. This\nwork explores ways to take advantage of such resources by retrieving relevant\nsegments directly in the target language, based on a source-side query. For\nthis, we design improved cross-lingual retrieval systems, trained with both\nsentence level and word-level matching objectives. In our experiments with two\nRANMT architectures, we first demonstrate the benefits of such cross-lingual\nobjectives in a controlled setting, obtaining translation performances that\nsurpass standard TM-based models. We then showcase our method on a real-world\nset-up, where the target monolingual resources far exceed the amount of\nparallel data and observe large improvements of our new techniques, which\noutperform both the baseline setting, and general-purpose cross-lingual\nretrievers.", "published": "2025-04-30 15:41:03", "link": "http://arxiv.org/abs/2504.21747v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Investigating Literary Motifs in Ancient and Medieval Novels with Large Language Models", "abstract": "The Greek fictional narratives often termed love novels or romances, ranging\nfrom the first century CE to the middle of the 15th century, have long been\nconsidered as similar in many ways, not least in the use of particular literary\nmotifs. By applying the use of fine-tuned large language models, this study\naims to investigate which motifs exactly that the texts in this corpus have in\ncommon, and in which ways they differ from each other. The results show that\nwhile some motifs persist throughout the corpus, others fluctuate in frequency,\nindicating certain trends or external influences. Conclusively, the method\nproves to adequately extract literary motifs according to a set definition,\nproviding data for both quantitative and qualitative analyses.", "published": "2025-04-30 15:39:06", "link": "http://arxiv.org/abs/2504.21742v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics", "abstract": "We present an embodied robotic system with an LLM-driven agent-orchestration\narchitecture for autonomous household object management. The system integrates\nmemory-augmented task planning, enabling robots to execute high-level user\ncommands while tracking past actions. It employs three specialized agents: a\nrouting agent, a task planning agent, and a knowledge base agent, each powered\nby task-specific LLMs. By leveraging in-context learning, our system avoids the\nneed for explicit model training. RAG enables the system to retrieve context\nfrom past interactions, enhancing long-term object tracking. A combination of\nGrounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating\nsemantic scene understanding for task planning. Evaluation across three\nhousehold scenarios demonstrates high task planning accuracy and an improvement\nin memory recall due to RAG. Specifically, Qwen2.5 yields best performance for\nspecialized agents, while LLaMA3.1 excels in routing tasks. The source code is\navailable at: https://github.com/marc1198/chat-hsr.", "published": "2025-04-30 15:00:20", "link": "http://arxiv.org/abs/2504.21716v1", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Enhancing Health Mention Classification Performance: A Study on Advancements in Parameter Efficient Tuning", "abstract": "Health Mention Classification (HMC) plays a critical role in leveraging\nsocial media posts for real-time tracking and public health monitoring.\nNevertheless, the process of HMC presents significant challenges due to its\nintricate nature, primarily stemming from the contextual aspects of health\nmentions, such as figurative language and descriptive terminology, rather than\nexplicitly reflecting a personal ailment. To address this problem, we argue\nthat clearer mentions can be achieved through conventional fine-tuning with\nenhanced parameters of biomedical natural language methods (NLP). In this\nstudy, we explore different techniques such as the utilisation of\npart-of-speech (POS) tagger information, improving on PEFT techniques, and\ndifferent combinations thereof. Extensive experiments are conducted on three\nwidely used datasets: RHDM, PHM, and Illness. The results incorporated POS\ntagger information, and leveraging PEFT techniques significantly improves\nperformance in terms of F1-score compared to state-of-the-art methods across\nall three datasets by utilising smaller models and efficient training.\nFurthermore, the findings highlight the effectiveness of incorporating POS\ntagger information and leveraging PEFT techniques for HMC. In conclusion, the\nproposed methodology presents a potentially effective approach to accurately\nclassifying health mentions in social media posts while optimising the model\nsize and training efficiency.", "published": "2025-04-30 14:21:54", "link": "http://arxiv.org/abs/2504.21685v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating the Effect of Parallel Data in the Cross-Lingual Transfer for Vision-Language Encoders", "abstract": "Most pre-trained Vision-Language (VL) models and training data for the\ndownstream tasks are only available in English. Therefore, multilingual VL\ntasks are solved using cross-lingual transfer: fine-tune a multilingual\npre-trained model or transfer the text encoder using parallel data. We study\nthe alternative approach: transferring an already trained encoder using\nparallel data. We investigate the effect of parallel data: domain and the\nnumber of languages, which were out of focus in previous work. Our results show\nthat even machine-translated task data are the best on average, caption-like\nauthentic parallel data outperformed it in some languages. Further, we show\nthat most languages benefit from multilingual training.", "published": "2025-04-30 14:19:15", "link": "http://arxiv.org/abs/2504.21681v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "20min-XD: A Comparable Corpus of Swiss News Articles", "abstract": "We present 20min-XD (20 Minuten cross-lingual document-level), a\nFrench-German, document-level comparable corpus of news articles, sourced from\nthe Swiss online news outlet 20 Minuten/20 minutes. Our dataset comprises\naround 15,000 article pairs spanning 2015 to 2024, automatically aligned based\non semantic similarity. We detail the data collection process and alignment\nmethodology. Furthermore, we provide a qualitative and quantitative analysis of\nthe corpus. The resulting dataset exhibits a broad spectrum of cross-lingual\nsimilarity, ranging from near-translations to loosely related articles, making\nit valuable for various NLP applications and broad linguistically motivated\nstudies. We publicly release the dataset in document- and sentence-aligned\nversions and code for the described experiments.", "published": "2025-04-30 14:16:08", "link": "http://arxiv.org/abs/2504.21677v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization", "abstract": "Recently, long-thought reasoning models achieve strong performance on complex\nreasoning tasks, but often incur substantial inference overhead, making\nefficiency a critical concern. Our empirical analysis reveals that the benefit\nof using Long-CoT varies across problems: while some problems require elaborate\nreasoning, others show no improvement, or even degraded accuracy. This\nmotivates adaptive reasoning strategies that tailor reasoning depth to the\ninput. However, prior work primarily reduces redundancy within long reasoning\npaths, limiting exploration of more efficient strategies beyond the Long-CoT\nparadigm. To address this, we propose a novel two-stage framework for adaptive\nand efficient reasoning. First, we construct a hybrid reasoning model by\nmerging long and short CoT models to enable diverse reasoning styles. Second,\nwe apply bi-level preference training to guide the model to select suitable\nreasoning styles (group-level), and prefer concise and correct reasoning within\neach style group (instance-level). Experiments demonstrate that our method\nsignificantly reduces inference costs compared to other baseline approaches,\nwhile maintaining performance. Notably, on five mathematical datasets, the\naverage length of reasoning is reduced by more than 50%, highlighting the\npotential of adaptive strategies to optimize reasoning efficiency in large\nlanguage models. Our code is coming soon at https://github.com/StarDewXXX/AdaR1", "published": "2025-04-30 14:01:45", "link": "http://arxiv.org/abs/2504.21659v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Sadeed: Advancing Arabic Diacritization Through Small Language Model", "abstract": "Arabic text diacritization remains a persistent challenge in natural language\nprocessing due to the language's morphological richness. In this paper, we\nintroduce Sadeed, a novel approach based on a fine-tuned decoder-only language\nmodel adapted from Kuwain 1.5B Hennara et al. [2025], a compact model\noriginally trained on diverse Arabic corpora. Sadeed is fine-tuned on carefully\ncurated, high-quality diacritized datasets, constructed through a rigorous\ndata-cleaning and normalization pipeline. Despite utilizing modest\ncomputational resources, Sadeed achieves competitive results compared to\nproprietary large language models and outperforms traditional models trained on\nsimilar domains. Additionally, we highlight key limitations in current\nbenchmarking practices for Arabic diacritization. To address these issues, we\nintroduce SadeedDiac-25, a new benchmark designed to enable fairer and more\ncomprehensive evaluation across diverse text genres and complexity levels.\nTogether, Sadeed and SadeedDiac-25 provide a robust foundation for advancing\nArabic NLP applications, including machine translation, text-to-speech, and\nlanguage learning tools.", "published": "2025-04-30 13:37:24", "link": "http://arxiv.org/abs/2504.21635v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability", "abstract": "The ability to follow instructions accurately is fundamental for Large\nLanguage Models (LLMs) to serve as reliable agents in real-world applications.\nWhile existing instruction-following benchmarks are either single-turn or\nintroduce new requirements in each turn without allowing self-correction,\nMeeseeks simulates realistic human-LLM interactions through an iterative\nfeedback process. This design enables models to self-correct based on specific\nrequirement failures, better reflecting real-world user-end usage patterns. The\nbenchmark implements a comprehensive evaluation system with 38 capability tags\norganized across three dimensions: Intent Recognition, Granular Content\nValidation, and Output Structure Validation. Through rigorous evaluation across\nLLMs, Meeseeks provides valuable insights into LLMs' instruction-following\ncapabilities in practical applications.", "published": "2025-04-30 13:28:19", "link": "http://arxiv.org/abs/2504.21625v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations", "abstract": "Large Language Models (LLMs) increasingly serve as knowledge interfaces, yet\nsystematically assessing their reliability with conflicting information remains\ndifficult. We propose an RDF-based framework to assess multilingual LLM\nquality, focusing on knowledge conflicts. Our approach captures model responses\nacross four distinct context conditions (complete, incomplete, conflicting, and\nno-context information) in German and English. This structured representation\nenables the comprehensive analysis of knowledge leakage-where models favor\ntraining data over provided context-error detection, and multilingual\nconsistency. We demonstrate the framework through a fire safety domain\nexperiment, revealing critical patterns in context prioritization and\nlanguage-specific performance, and demonstrating that our vocabulary was\nsufficient to express every assessment facet encountered in the 28-question\nstudy.", "published": "2025-04-30 13:06:40", "link": "http://arxiv.org/abs/2504.21605v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Robust Misinformation Detection by Visiting Potential Commonsense Conflict", "abstract": "The development of Internet technology has led to an increased prevalence of\nmisinformation, causing severe negative effects across diverse domains. To\nmitigate this challenge, Misinformation Detection (MD), aiming to detect online\nmisinformation automatically, emerges as a rapidly growing research topic in\nthe community. In this paper, we propose a novel plug-and-play augmentation\nmethod for the MD task, namely Misinformation Detection with Potential\nCommonsense Conflict (MD-PCC). We take inspiration from the prior studies\nindicating that fake articles are more likely to involve commonsense conflict.\nAccordingly, we construct commonsense expressions for articles, serving to\nexpress potential commonsense conflicts inferred by the difference between\nextracted commonsense triplet and golden ones inferred by the well-established\ncommonsense reasoning tool COMET. These expressions are then specified for each\narticle as augmentation. Any specific MD methods can be then trained on those\ncommonsense-augmented articles. Besides, we also collect a novel\ncommonsense-oriented dataset named CoMis, whose all fake articles are caused by\ncommonsense conflict. We integrate MD-PCC with various existing MD backbones\nand compare them across both 4 public benchmark datasets and CoMis. Empirical\nresults demonstrate that MD-PCC can consistently outperform the existing MD\nbaselines.", "published": "2025-04-30 13:03:17", "link": "http://arxiv.org/abs/2504.21604v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "DNB-AI-Project at SemEval-2025 Task 5: An LLM-Ensemble Approach for Automated Subject Indexing", "abstract": "This paper presents our system developed for the SemEval-2025 Task 5:\nLLMs4Subjects: LLM-based Automated Subject Tagging for a National Technical\nLibrary's Open-Access Catalog. Our system relies on prompting a selection of\nLLMs with varying examples of intellectually annotated records and asking the\nLLMs to similarly suggest keywords for new records. This few-shot prompting\ntechnique is combined with a series of post-processing steps that map the\ngenerated keywords to the target vocabulary, aggregate the resulting subject\nterms to an ensemble vote and, finally, rank them as to their relevance to the\nrecord. Our system is fourth in the quantitative ranking in the all-subjects\ntrack, but achieves the best result in the qualitative ranking conducted by\nsubject indexing experts.", "published": "2025-04-30 12:47:09", "link": "http://arxiv.org/abs/2504.21589v1", "categories": ["cs.CL", "cs.AI", "cs.DL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Glucagon and insulin production in pancreatic cells modeled using Petri nets and Boolean networks", "abstract": "Diabetes is a civilization chronic disease characterized by a constant\nelevated concentration of glucose in the blood. Many processes are involved in\nthe glucose regulation, and their interactions are very complex. To better\nunderstand those processes we set ourselves a goal to create a Petri net model\nof the glucose regulation in the whole body. So far we have managed to create a\nmodel of glycolysis and synthesis of glucose in the liver, and the general\noverview models of the glucose regulation in a healthy and diabetic person. In\nthis paper we introduce Petri nets models of insulin secretion in beta cell of\nthe pancreas, and glucagon in the pancreas alpha cells. Those two hormones have\nmutually opposite effects: insulin preventing hyperglycemia, and glucagon\npreventing hypoglycemia. Understanding the mechanisms of insulin and glucagon\nsecretion constitutes the basis for understanding diabetes. We also present a\nmodel in which both processes occur together, depending on the blood glucose\nlevel. The dynamics of each model is analysed. Additionally, we transform the\noverall insulin and glucagon secretion system to a Boolean network, following\nstandard transformation rules.", "published": "2025-04-30 12:36:02", "link": "http://arxiv.org/abs/2504.21578v1", "categories": ["q-bio.CB", "cs.CL", "03", "F.2; G.0"], "primary_category": "q-bio.CB"}
{"title": "Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models", "abstract": "Large Vision Language Models (LVLMs) often suffer from object hallucination,\nwhich undermines their reliability. Surprisingly, we find that simple\nobject-based visual prompting -- overlaying visual cues (e.g., bounding box,\ncircle) on images -- can significantly mitigate such hallucination; however,\ndifferent visual prompts (VPs) vary in effectiveness. To address this, we\npropose Black-Box Visual Prompt Engineering (BBVPE), a framework to identify\noptimal VPs that enhance LVLM responses without needing access to model\ninternals. Our approach employs a pool of candidate VPs and trains a router\nmodel to dynamically select the most effective VP for a given input image. This\nblack-box approach is model-agnostic, making it applicable to both open-source\nand proprietary LVLMs. Evaluations on benchmarks such as POPE and CHAIR\ndemonstrate that BBVPE effectively reduces object hallucination.", "published": "2025-04-30 11:58:30", "link": "http://arxiv.org/abs/2504.21559v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Precision Where It Matters: A Novel Spike Aware Mixed-Precision Quantization Strategy for LLaMA-based Language Models", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious natural language processing tasks. However, their size presents\nsignificant challenges for deployment and inference. This paper investigates\nthe quantization of LLMs, focusing on the LLaMA architecture and its\nderivatives. We challenge existing assumptions about activation outliers in\nLLMs and propose a novel mixed-precision quantization approach tailored for\nLLaMA-like models. Our method leverages the observation that activation spikes\nin LLaMA architectures are predominantly concentrated in specific projection\nlayers. By applying higher precision (FP16 or FP8) to these layers while\nquantizing the rest of the model to lower bit-widths, we achieve superior\nperformance compared to existing quantization techniques. Experimental results\non LLaMA2, LLaMA3, and Mistral models demonstrate significant improvements in\nperplexity and zero-shot accuracy, particularly for 8-bit per-tensor\nquantization. Our approach outperforms general-purpose methods designed to\nhandle outliers across all architecture types, highlighting the benefits of\narchitecture-specific quantization strategies. This research contributes to the\nongoing efforts to make LLMs more efficient and deployable, potentially\nenabling their use in resource-constrained environments. Our findings emphasize\nthe importance of considering model-specific characteristics in developing\neffective quantization pipelines for state-of-the-art language models by\nidentifying and targeting a small number of projections that concentrate\nactivation spikes.", "published": "2025-04-30 11:52:18", "link": "http://arxiv.org/abs/2504.21553v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TartuNLP at SemEval-2025 Task 5: Subject Tagging as Two-Stage Information Retrieval", "abstract": "We present our submission to the Task 5 of SemEval-2025 that aims to aid\nlibrarians in assigning subject tags to the library records by producing a list\nof likely relevant tags for a given document. We frame the task as an\ninformation retrieval problem, where the document content is used to retrieve\nsubject tags from a large subject taxonomy. We leverage two types of encoder\nmodels to build a two-stage information retrieval system -- a bi-encoder for\ncoarse-grained candidate extraction at the first stage, and a cross-encoder for\nfine-grained re-ranking at the second stage. This approach proved effective,\ndemonstrating significant improvements in recall compared to single-stage\nmethods and showing competitive results according to qualitative evaluation.", "published": "2025-04-30 11:44:08", "link": "http://arxiv.org/abs/2504.21547v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Informally Romanized Language Identification", "abstract": "The Latin script is often used to informally write languages with non-Latin\nnative scripts. In many cases (e.g., most languages in India), there is no\nconventional spelling of words in the Latin script, hence there will be high\nspelling variability in written text. Such romanization renders languages that\nare normally easily distinguished based on script highly confusable, such as\nHindi and Urdu. In this work, we increase language identification (LID)\naccuracy for romanized text by improving the methods used to synthesize\ntraining sets. We find that training on synthetic samples which incorporate\nnatural spelling variation yields higher LID system accuracy than including\navailable naturally occurring examples in the training set, or even training\nhigher capacity models. We demonstrate new state-of-the-art LID performance on\nromanized text from 20 Indic languages in the Bhasha-Abhijnaanam evaluation set\n(Madhani et al., 2023a), improving test F1 from the reported 74.7% (using a\npretrained neural model) to 85.4% using a linear classifier trained solely on\nsynthetic data and 88.2% when also training on available harvested text.", "published": "2025-04-30 11:36:28", "link": "http://arxiv.org/abs/2504.21540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advancing Arabic Reverse Dictionary Systems: A Transformer-Based Approach with Dataset Construction Guidelines", "abstract": "This study addresses the critical gap in Arabic natural language processing\nby developing an effective Arabic Reverse Dictionary (RD) system that enables\nusers to find words based on their descriptions or meanings. We present a novel\ntransformer-based approach with a semi-encoder neural network architecture\nfeaturing geometrically decreasing layers that achieves state-of-the-art\nresults for Arabic RD tasks. Our methodology incorporates a comprehensive\ndataset construction process and establishes formal quality standards for\nArabic lexicographic definitions. Experiments with various pre-trained models\ndemonstrate that Arabic-specific models significantly outperform general\nmultilingual embeddings, with ARBERTv2 achieving the best ranking score\n(0.0644). Additionally, we provide a formal abstraction of the reverse\ndictionary task that enhances theoretical understanding and develop a modular,\nextensible Python library (RDTL) with configurable training pipelines. Our\nanalysis of dataset quality reveals important insights for improving Arabic\ndefinition construction, leading to eight specific standards for building\nhigh-quality reverse dictionary resources. This work contributes significantly\nto Arabic computational linguistics and provides valuable tools for language\nlearning, academic writing, and professional communication in Arabic.", "published": "2025-04-30 09:56:36", "link": "http://arxiv.org/abs/2504.21475v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Homa at SemEval-2025 Task 5: Aligning Librarian Records with OntoAligner for Subject Tagging", "abstract": "This paper presents our system, Homa, for SemEval-2025 Task 5: Subject\nTagging, which focuses on automatically assigning subject labels to technical\nrecords from TIBKAT using the Gemeinsame Normdatei (GND) taxonomy. We leverage\nOntoAligner, a modular ontology alignment toolkit, to address this task by\nintegrating retrieval-augmented generation (RAG) techniques. Our approach\nformulates the subject tagging problem as an alignment task, where records are\nmatched to GND categories based on semantic similarity. We evaluate\nOntoAligner's adaptability for subject indexing and analyze its effectiveness\nin handling multilingual records. Experimental results demonstrate the\nstrengths and limitations of this method, highlighting the potential of\nalignment techniques for improving subject tagging in digital libraries.", "published": "2025-04-30 09:52:51", "link": "http://arxiv.org/abs/2504.21474v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RWKV-X: A Linear Complexity Hybrid Language Model", "abstract": "In this paper, we introduce \\textbf{RWKV-X}, a novel hybrid architecture that\ncombines the efficiency of RWKV for short-range modeling with a sparse\nattention mechanism designed to capture long-range context. Unlike previous\nhybrid approaches that rely on full attention layers and retain quadratic\ncomplexity, RWKV-X achieves linear-time complexity in training and\nconstant-time complexity in inference decoding. We demonstrate that RWKV-X,\nwhen continually pretrained on 64K-token sequences, achieves near-perfect\naccuracy on the 64K passkey retrieval benchmark. It consistently outperforms\nprior RWKV-7 models on long-context benchmarks, while maintaining strong\nperformance on short-context tasks. These results highlight RWKV-X as a\nscalable and efficient backbone for general-purpose language modeling, capable\nof decoding sequences up to 1 million tokens with stable speed and memory\nusage. To facilitate further research and analysis, we have made the\ncheckpoints and the associated code publicly accessible at:\nhttps://github.com/howard-hou/RWKV-X.", "published": "2025-04-30 09:38:17", "link": "http://arxiv.org/abs/2504.21463v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SeriesBench: A Benchmark for Narrative-Driven Drama Series Understanding", "abstract": "With the rapid development of Multi-modal Large Language Models (MLLMs), an\nincreasing number of benchmarks have been established to evaluate the video\nunderstanding capabilities of these models. However, these benchmarks focus on\n\\textbf{standalone} videos and mainly assess ``visual elements'' like human\nactions and object states. In reality, contemporary videos often encompass\ncomplex and continuous narratives, typically presented as a \\textbf{series}. To\naddress this challenge, we propose \\textbf{SeriesBench}, a benchmark consisting\nof 105 carefully curated narrative-driven series, covering 28 specialized tasks\nthat require deep narrative understanding. Specifically, we first select a\ndiverse set of drama series spanning various genres. Then, we introduce a novel\nlong-span narrative annotation method, combined with a full-information\ntransformation approach to convert manual annotations into diverse task\nformats. To further enhance model capacity for detailed analysis of plot\nstructures and character relationships within series, we propose a novel\nnarrative reasoning framework, \\textbf{PC-DCoT}. Extensive results on\n\\textbf{SeriesBench} indicate that existing MLLMs still face significant\nchallenges in understanding narrative-driven series, while \\textbf{PC-DCoT}\nenables these MLLMs to achieve performance improvements. Overall, our\n\\textbf{SeriesBench} and \\textbf{PC-DCoT} highlight the critical necessity of\nadvancing model capabilities to understand narrative-driven series, guiding the\nfuture development of MLLMs. SeriesBench is publicly available at\nhttps://github.com/zackhxn/SeriesBench-CVPR2025.", "published": "2025-04-30 08:48:21", "link": "http://arxiv.org/abs/2504.21435v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "The Distribution of Dependency Distance and Hierarchical Distance in Contemporary Written Japanese and Its Influencing Factors", "abstract": "To explore the relationship between dependency distance (DD) and hierarchical\ndistance (HD) in Japanese, we compared the probability distributions of DD and\nHD with and without sentence length fixed, and analyzed the changes in mean\ndependency distance (MDD) and mean hierarchical distance (MHD) as sentence\nlength increases, along with their correlation coefficient based on the\nBalanced Corpus of Contemporary Written Japanese. It was found that the valency\nof the predicates is the underlying factor behind the trade-off relation\nbetween MDD and MHD in Japanese. Native speakers of Japanese regulate the\nlinear complexity and hierarchical complexity through the valency of the\npredicates, and the relative sizes of MDD and MHD depend on whether the\nthreshold of valency has been reached. Apart from the cognitive load, the\nvalency of the predicates also affects the probability distributions of DD and\nHD. The effect of the valency of the predicates on the distribution of HD is\ngreater than on that of DD, which leads to differences in their probability\ndistributions and causes the mean of MDD to be lower than that of MHD.", "published": "2025-04-30 08:27:33", "link": "http://arxiv.org/abs/2504.21421v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Who Gets the Callback? Generative AI and Gender Bias", "abstract": "Generative artificial intelligence (AI), particularly large language models\n(LLMs), is being rapidly deployed in recruitment and for candidate\nshortlisting. We audit several mid-sized open-source LLMs for gender bias using\na dataset of 332,044 real-world online job postings. For each posting, we\nprompt the model to recommend whether an equally qualified male or female\ncandidate should receive an interview callback. We find that most models tend\nto favor men, especially for higher-wage roles. Mapping job descriptions to the\nStandard Occupational Classification system, we find lower callback rates for\nwomen in male-dominated occupations and higher rates in female-associated ones,\nindicating occupational segregation. A comprehensive analysis of linguistic\nfeatures in job ads reveals strong alignment of model recommendations with\ntraditional gender stereotypes. To examine the role of recruiter identity, we\nsteer model behavior by infusing Big Five personality traits and simulating the\nperspectives of historical figures. We find that less agreeable personas reduce\nstereotyping, consistent with an agreeableness bias in LLMs. Our findings\nhighlight how AI-driven hiring may perpetuate biases in the labor market and\nhave implications for fairness and diversity within firms.", "published": "2025-04-30 07:55:52", "link": "http://arxiv.org/abs/2504.21400v1", "categories": ["econ.GN", "cs.CL", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "Retrieval-Enhanced Few-Shot Prompting for Speech Event Extraction", "abstract": "Speech Event Extraction (SpeechEE) is a challenging task that lies at the\nintersection of Automatic Speech Recognition (ASR) and Natural Language\nProcessing (NLP), requiring the identification of structured event information\nfrom spoken language. In this work, we present a modular, pipeline-based\nSpeechEE framework that integrates high-performance ASR with semantic\nsearch-enhanced prompting of Large Language Models (LLMs). Our system first\nclassifies speech segments likely to contain events using a hybrid filtering\nmechanism including rule-based, BERT-based, and LLM-based models. It then\nemploys few-shot LLM prompting, dynamically enriched via semantic similarity\nretrieval, to identify event triggers and extract corresponding arguments. We\nevaluate the pipeline using multiple LLMs (Llama3-8B, GPT-4o-mini, and o1-mini)\nhighlighting significant performance gains with o1-mini, which achieves 63.3%\nF1 on trigger classification and 27.8% F1 on argument classification,\noutperforming prior benchmarks. Our results demonstrate that pipeline\napproaches, when empowered by retrieval-augmented LLMs, can rival or exceed\nend-to-end systems while maintaining interpretability and modularity. This work\nprovides practical insights into LLM-driven event extraction and opens pathways\nfor future hybrid models combining textual and acoustic features.", "published": "2025-04-30 07:10:10", "link": "http://arxiv.org/abs/2504.21372v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Does the Prompt-based Large Language Model Recognize Students' Demographics and Introduce Bias in Essay Scoring?", "abstract": "Large Language Models (LLMs) are widely used in Automated Essay Scoring (AES)\ndue to their ability to capture semantic meaning. Traditional fine-tuning\napproaches required technical expertise, limiting accessibility for educators\nwith limited technical backgrounds. However, prompt-based tools like ChatGPT\nhave made AES more accessible, enabling educators to obtain machine-generated\nscores using natural-language prompts (i.e., the prompt-based paradigm).\nDespite advancements, prior studies have shown bias in fine-tuned LLMs,\nparticularly against disadvantaged groups. It remains unclear whether such\nbiases persist or are amplified in the prompt-based paradigm with cutting-edge\ntools. Since such biases are believed to stem from the demographic information\nembedded in pre-trained models (i.e., the ability of LLMs' text embeddings to\npredict demographic attributes), this study explores the relationship between\nthe model's predictive power of students' demographic attributes based on their\nwritten works and its predictive bias in the scoring task in the prompt-based\nparadigm. Using a publicly available dataset of over 25,000 students'\nargumentative essays, we designed prompts to elicit demographic inferences\n(i.e., gender, first-language background) from GPT-4o and assessed fairness in\nautomated scoring. Then we conducted multivariate regression analysis to\nexplore the impact of the model's ability to predict demographics on its\nscoring outcomes. Our findings revealed that (i) prompt-based LLMs can somewhat\ninfer students' demographics, particularly their first-language backgrounds,\nfrom their essays; (ii) scoring biases are more pronounced when the LLM\ncorrectly predicts students' first-language background than when it does not;\nand (iii) scoring error for non-native English speakers increases when the LLM\ncorrectly identifies them as non-native.", "published": "2025-04-30 05:36:28", "link": "http://arxiv.org/abs/2504.21330v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Phi-4-reasoning Technical Report", "abstract": "We introduce Phi-4-reasoning, a 14-billion parameter reasoning model that\nachieves strong performance on complex reasoning tasks. Trained via supervised\nfine-tuning of Phi-4 on carefully curated set of \"teachable\" prompts-selected\nfor the right level of complexity and diversity-and reasoning demonstrations\ngenerated using o3-mini, Phi-4-reasoning generates detailed reasoning chains\nthat effectively leverage inference-time compute. We further develop\nPhi-4-reasoning-plus, a variant enhanced through a short phase of outcome-based\nreinforcement learning that offers higher performance by generating longer\nreasoning traces. Across a wide range of reasoning tasks, both models\noutperform significantly larger open-weight models such as\nDeepSeek-R1-Distill-Llama-70B model and approach the performance levels of full\nDeepSeek-R1 model. Our comprehensive evaluations span benchmarks in math and\nscientific reasoning, coding, algorithmic problem solving, planning, and\nspatial understanding. Interestingly, we observe a non-trivial transfer of\nimprovements to general-purpose benchmarks as well. In this report, we provide\ninsights into our training data, our training methodologies, and our\nevaluations. We show that the benefit of careful data curation for supervised\nfine-tuning (SFT) extends to reasoning language models, and can be further\namplified by reinforcement learning (RL). Finally, our evaluation points to\nopportunities for improving how we assess the performance and robustness of\nreasoning models.", "published": "2025-04-30 05:05:09", "link": "http://arxiv.org/abs/2504.21318v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Confidence in Large Language Model Evaluation: A Bayesian Approach to Limited-Sample Challenges", "abstract": "Large language models (LLMs) exhibit probabilistic output characteristics,\nyet conventional evaluation frameworks rely on deterministic scalar metrics.\nThis study introduces a Bayesian approach for LLM capability assessment that\nintegrates prior knowledge through probabilistic inference, addressing\nlimitations under limited-sample regimes. By treating model capabilities as\nlatent variables and leveraging a curated query set to induce discriminative\nresponses, we formalize model ranking as a Bayesian hypothesis testing problem\nover mutually exclusive capability intervals. Experimental evaluations with\nGPT-series models demonstrate that the proposed method achieves superior\ndiscrimination compared to conventional evaluation methods. Results indicate\nthat even with reduced sample sizes, the approach maintains statistical\nrobustness while providing actionable insights, such as probabilistic\nstatements about a model's likelihood of surpassing specific baselines. This\nwork advances LLM evaluation methodologies by bridging Bayesian inference with\npractical constraints in real-world deployment scenarios.", "published": "2025-04-30 04:24:50", "link": "http://arxiv.org/abs/2504.21303v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BiasGuard: A Reasoning-enhanced Bias Detection Tool For Large Language Models", "abstract": "Identifying bias in LLM-generated content is a crucial prerequisite for\nensuring fairness in LLMs. Existing methods, such as fairness classifiers and\nLLM-based judges, face limitations related to difficulties in understanding\nunderlying intentions and the lack of criteria for fairness judgment. In this\npaper, we introduce BiasGuard, a novel bias detection tool that explicitly\nanalyzes inputs and reasons through fairness specifications to provide accurate\njudgments. BiasGuard is implemented through a two-stage approach: the first\nstage initializes the model to explicitly reason based on fairness\nspecifications, while the second stage leverages reinforcement learning to\nenhance its reasoning and judgment capabilities. Our experiments, conducted\nacross five datasets, demonstrate that BiasGuard outperforms existing tools,\nimproving accuracy and reducing over-fairness misjudgments. We also highlight\nthe importance of reasoning-enhanced decision-making and provide evidence for\nthe effectiveness of our two-stage optimization pipeline.", "published": "2025-04-30 04:13:03", "link": "http://arxiv.org/abs/2504.21299v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA", "abstract": "Medical question answering (QA) is a reasoning-intensive task that remains\nchallenging for large language models (LLMs) due to hallucinations and outdated\ndomain knowledge. Retrieval-Augmented Generation (RAG) provides a promising\npost-training solution by leveraging external knowledge. However, existing\nmedical RAG systems suffer from two key limitations: (1) a lack of modeling for\nhuman-like reasoning behaviors during information retrieval, and (2) reliance\non suboptimal medical corpora, which often results in the retrieval of\nirrelevant or noisy snippets. To overcome these challenges, we propose\nDiscuss-RAG, a plug-and-play module designed to enhance the medical QA RAG\nsystem through collaborative agent-based reasoning. Our method introduces a\nsummarizer agent that orchestrates a team of medical experts to emulate\nmulti-turn brainstorming, thereby improving the relevance of retrieved content.\nAdditionally, a decision-making agent evaluates the retrieved snippets before\ntheir final integration. Experimental results on four benchmark medical QA\ndatasets show that Discuss-RAG consistently outperforms MedRAG, especially\nsignificantly improving answer accuracy by up to 16.67% on BioASQ and 12.20% on\nPubMedQA. The code is available at: https://github.com/LLM-VLM-GSL/Discuss-RAG.", "published": "2025-04-30 01:37:44", "link": "http://arxiv.org/abs/2504.21252v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Memorization and Knowledge Injection in Gated LLMs", "abstract": "Large Language Models (LLMs) currently struggle to sequentially add new\nmemories and integrate new knowledge. These limitations contrast with the human\nability to continuously learn from new experiences and acquire knowledge\nthroughout life. Most existing approaches add memories either through large\ncontext windows or external memory buffers (e.g., Retrieval-Augmented\nGeneration), and studies on knowledge injection rarely test scenarios\nresembling everyday life events. In this work, we introduce a continual\nlearning framework, Memory Embedded in Gated LLMs (MEGa), which injects event\nmemories directly into the weights of LLMs. Each memory is stored in a\ndedicated set of gated low-rank weights. During inference, a gating mechanism\nactivates relevant memory weights by matching query embeddings to stored memory\nembeddings. This enables the model to both recall entire memories and answer\nrelated questions. On two datasets - fictional characters and Wikipedia events\n- MEGa outperforms baseline approaches in mitigating catastrophic forgetting.\nOur model draws inspiration from the complementary memory system of the human\nbrain.", "published": "2025-04-30 00:28:32", "link": "http://arxiv.org/abs/2504.21239v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Phi-4-Mini-Reasoning: Exploring the Limits of Small Reasoning Language Models in Math", "abstract": "Chain-of-Thought (CoT) significantly enhances formal reasoning capabilities\nin Large Language Models (LLMs) by training them to explicitly generate\nintermediate reasoning steps. While LLMs readily benefit from such techniques,\nimproving reasoning in Small Language Models (SLMs) remains challenging due to\ntheir limited model capacity. Recent work by Deepseek-R1 demonstrates that\ndistillation from LLM-generated synthetic data can substantially improve the\nreasoning ability of SLM. However, the detailed modeling recipe is not\ndisclosed. In this work, we present a systematic training recipe for SLMs that\nconsists of four steps: (1) large-scale mid-training on diverse distilled\nlong-CoT data, (2) supervised fine-tuning on high-quality long-CoT data, (3)\nRollout DPO leveraging a carefully curated preference dataset, and (4)\nReinforcement Learning (RL) with Verifiable Reward. We apply our method on\nPhi-4-Mini, a compact 3.8B-parameter model. The resulting Phi-4-Mini-Reasoning\nmodel exceeds, on math reasoning tasks, much larger reasoning models, e.g.,\noutperforming DeepSeek-R1-Distill-Qwen-7B by 3.2 points and\nDeepSeek-R1-Distill-Llama-8B by 7.7 points on Math-500. Our results validate\nthat a carefully designed training recipe, with large-scale high-quality CoT\ndata, is effective to unlock strong reasoning capabilities even in\nresource-constrained small models.", "published": "2025-04-30 00:04:35", "link": "http://arxiv.org/abs/2504.21233v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Public Opinion and The Rise of Digital Minds: Perceived Risk, Trust, and Regulation Support", "abstract": "Governance institutions must respond to societal risks, including those posed\nby generative AI. This study empirically examines how public trust in\ninstitutions and AI technologies, along with perceived risks, shape preferences\nfor AI regulation. Using the nationally representative 2023 Artificial\nIntelligence, Morality, and Sentience (AIMS) survey, we assess trust in\ngovernment, AI companies, and AI technologies, as well as public support for\nregulatory measures such as slowing AI development or outright bans on advanced\nAI. Our findings reveal broad public support for AI regulation, with risk\nperception playing a significant role in shaping policy preferences.\nIndividuals with higher trust in government favor regulation, while those with\ngreater trust in AI companies and AI technologies are less inclined to support\nrestrictions. Trust in government and perceived risks significantly predict\npreferences for both soft (e.g., slowing development) and strong (e.g., banning\nAI systems) regulatory interventions. These results highlight the importance of\npublic opinion in AI governance. As AI capabilities advance, effective\nregulation will require balancing public concerns about risks with trust in\ninstitutions. This study provides a foundational empirical baseline for\npolicymakers navigating AI governance and underscores the need for further\nresearch into public trust, risk perception, and regulatory strategies in the\nevolving AI landscape.", "published": "2025-04-30 17:56:23", "link": "http://arxiv.org/abs/2504.21849v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Characterizing AI Agents for Alignment and Governance", "abstract": "The creation of effective governance mechanisms for AI agents requires a\ndeeper understanding of their core properties and how these properties relate\nto questions surrounding the deployment and operation of agents in the world.\nThis paper provides a characterization of AI agents that focuses on four\ndimensions: autonomy, efficacy, goal complexity, and generality. We propose\ndifferent gradations for each dimension, and argue that each dimension raises\nunique questions about the design, operation, and governance of these systems.\nMoreover, we draw upon this framework to construct \"agentic profiles\" for\ndifferent kinds of AI agents. These profiles help to illuminate cross-cutting\ntechnical and non-technical governance challenges posed by different classes of\nAI agents, ranging from narrow task-specific assistants to highly autonomous\ngeneral-purpose systems. By mapping out key axes of variation and continuity,\nthis framework provides developers, policymakers, and members of the public\nwith the opportunity to develop governance approaches that better align with\ncollective societal goals.", "published": "2025-04-30 17:55:48", "link": "http://arxiv.org/abs/2504.21848v1", "categories": ["cs.CY", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.CY"}
{"title": "Active Light Modulation to Counter Manipulation of Speech Visual Content", "abstract": "High-profile speech videos are prime targets for falsification, owing to\ntheir accessibility and influence. This work proposes Spotlight, a low-overhead\nand unobtrusive system for protecting live speech videos from visual\nfalsification of speaker identity and lip and facial motion. Unlike predominant\nfalsification detection methods operating in the digital domain, Spotlight\ncreates dynamic physical signatures at the event site and embeds them into all\nvideo recordings via imperceptible modulated light. These physical signatures\nencode semantically-meaningful features unique to the speech event, including\nthe speaker's identity and facial motion, and are cryptographically-secured to\nprevent spoofing. The signatures can be extracted from any video downstream and\nvalidated against the portrayed speech content to check its integrity. Key\nelements of Spotlight include (1) a framework for generating extremely compact\n(i.e., 150-bit), pose-invariant speech video features, based on\nlocality-sensitive hashing; and (2) an optical modulation scheme that embeds\n>200 bps into video while remaining imperceptible both in video and live.\nPrototype experiments on extensive video datasets show Spotlight achieves AUCs\n$\\geq$ 0.99 and an overall true positive rate of 100% in detecting falsified\nvideos. Further, Spotlight is highly robust across recording conditions, video\npost-processing techniques, and white-box adversarial attacks on its video\nfeature extraction methodologies.", "published": "2025-04-30 17:55:24", "link": "http://arxiv.org/abs/2504.21846v1", "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "cs.CV"}
{"title": "Early Exit and Multi Stage Knowledge Distillation in VLMs for Video Summarization", "abstract": "We introduce DEEVISum (Distilled Early Exit Vision language model for\nSummarization), a lightweight, efficient, and scalable vision language model\ndesigned for segment wise video summarization. Leveraging multi modal prompts\nthat combine textual and audio derived signals, DEEVISum incorporates Multi\nStage Knowledge Distillation (MSKD) and Early Exit (EE) to strike a balance\nbetween performance and efficiency. MSKD offers a 1.33% absolute F1 improvement\nover baseline distillation (0.5%), while EE reduces inference time by\napproximately 21% with a 1.3 point drop in F1. Evaluated on the TVSum dataset,\nour best model PaLI Gemma2 3B + MSKD achieves an F1 score of 61.1, competing\nthe performance of significantly larger models, all while maintaining a lower\ncomputational footprint. We publicly release our code and processed dataset to\nsupport further research.", "published": "2025-04-30 17:37:55", "link": "http://arxiv.org/abs/2504.21831v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning Heterogeneous Performance-Fairness Trade-offs in Federated Learning", "abstract": "Recent methods leverage a hypernet to handle the performance-fairness\ntrade-offs in federated learning. This hypernet maps the clients' preferences\nbetween model performance and fairness to preference-specifc models on the\ntrade-off curve, known as local Pareto front. However, existing methods\ntypically adopt a uniform preference sampling distribution to train the\nhypernet across clients, neglecting the inherent heterogeneity of their local\nPareto fronts. Meanwhile, from the perspective of generalization, they do not\nconsider the gap between local and global Pareto fronts on the global dataset.\nTo address these limitations, we propose HetPFL to effectively learn both local\nand global Pareto fronts. HetPFL comprises Preference Sampling Adaptation (PSA)\nand Preference-aware Hypernet Fusion (PHF). PSA adaptively determines the\noptimal preference sampling distribution for each client to accommodate\nheterogeneous local Pareto fronts. While PHF performs preference-aware fusion\nof clients' hypernets to ensure the performance of the global Pareto front. We\nprove that HetPFL converges linearly with respect to the number of rounds,\nunder weaker assumptions than existing methods. Extensive experiments on four\ndatasets show that HetPFL significantly outperforms seven baselines in terms of\nthe quality of learned local and global Pareto fronts.", "published": "2025-04-30 16:25:02", "link": "http://arxiv.org/abs/2504.21775v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Is Intermediate Fusion All You Need for UAV-based Collaborative Perception?", "abstract": "Collaborative perception enhances environmental awareness through inter-agent\ncommunication and is regarded as a promising solution to intelligent\ntransportation systems. However, existing collaborative methods for Unmanned\nAerial Vehicles (UAVs) overlook the unique characteristics of the UAV\nperspective, resulting in substantial communication overhead. To address this\nissue, we propose a novel communication-efficient collaborative perception\nframework based on late-intermediate fusion, dubbed LIF. The core concept is to\nexchange informative and compact detection results and shift the fusion stage\nto the feature representation level. In particular, we leverage vision-guided\npositional embedding (VPE) and box-based virtual augmented feature (BoBEV) to\neffectively integrate complementary information from various agents.\nAdditionally, we innovatively introduce an uncertainty-driven communication\nmechanism that uses uncertainty evaluation to select high-quality and reliable\nshared areas. Experimental results demonstrate that our LIF achieves superior\nperformance with minimal communication bandwidth, proving its effectiveness and\npracticality. Code and models are available at https://github.com/uestchjw/LIF.", "published": "2025-04-30 16:22:14", "link": "http://arxiv.org/abs/2504.21774v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Solving Copyright Infringement on Short Video Platforms: Novel Datasets and an Audio Restoration Deep Learning Pipeline", "abstract": "Short video platforms like YouTube Shorts and TikTok face significant\ncopyright compliance challenges, as infringers frequently embed arbitrary\nbackground music (BGM) to obscure original soundtracks (OST) and evade content\noriginality detection. To tackle this issue, we propose a novel pipeline that\nintegrates Music Source Separation (MSS) and cross-modal video-music retrieval\n(CMVMR). Our approach effectively separates arbitrary BGM from the original\nOST, enabling the restoration of authentic video audio tracks. To support this\nwork, we introduce two domain-specific datasets: OASD-20K for audio separation\nand OSVAR-160 for pipeline evaluation. OASD-20K contains 20,000 audio clips\nfeaturing mixed BGM and OST pairs, while OSVAR160 is a unique benchmark dataset\ncomprising 1,121 video and mixed-audio pairs, specifically designed for short\nvideo restoration tasks. Experimental results demonstrate that our pipeline not\nonly removes arbitrary BGM with high accuracy but also restores OSTs, ensuring\ncontent integrity. This approach provides an ethical and scalable solution to\ncopyright challenges in user-generated content on short video platforms.", "published": "2025-04-30 16:17:05", "link": "http://arxiv.org/abs/2504.21772v1", "categories": ["cs.MM", "cs.AI"], "primary_category": "cs.MM"}
{"title": "Adaptive 3D UI Placement in Mixed Reality Using Deep Reinforcement Learning", "abstract": "Mixed Reality (MR) could assist users' tasks by continuously integrating\nvirtual content with their view of the physical environment. However, where and\nhow to place these content to best support the users has been a challenging\nproblem due to the dynamic nature of MR experiences. In contrast to prior work\nthat investigates optimization-based methods, we are exploring how\nreinforcement learning (RL) could assist with continuous 3D content placement\nthat is aware of users' poses and their surrounding environments. Through an\ninitial exploration and preliminary evaluation, our results demonstrate the\npotential of RL to position content that maximizes the reward for users on the\ngo. We further identify future directions for research that could harness the\npower of RL for personalized and optimized UI and content placement in MR.", "published": "2025-04-30 15:21:36", "link": "http://arxiv.org/abs/2504.21731v1", "categories": ["cs.HC", "cs.AI", "cs.CV"], "primary_category": "cs.HC"}
{"title": "Cert-SSB: Toward Certified Sample-Specific Backdoor Defense", "abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an\nattacker manipulates a small portion of the training data to implant hidden\nbackdoors into the model. The compromised model behaves normally on clean\nsamples but misclassifies backdoored samples into the attacker-specified target\nclass, posing a significant threat to real-world DNN applications. Currently,\nseveral empirical defense methods have been proposed to mitigate backdoor\nattacks, but they are often bypassed by more advanced backdoor techniques. In\ncontrast, certified defenses based on randomized smoothing have shown promise\nby adding random noise to training and testing samples to counteract backdoor\nattacks. In this paper, we reveal that existing randomized smoothing defenses\nimplicitly assume that all samples are equidistant from the decision boundary.\nHowever, it may not hold in practice, leading to suboptimal certification\nperformance. To address this issue, we propose a sample-specific certified\nbackdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic\ngradient ascent to optimize the noise magnitude for each sample, ensuring a\nsample-specific noise level that is then applied to multiple poisoned training\nsets to retrain several smoothed models. After that, Cert-SSB aggregates the\npredictions of multiple smoothed models to generate the final robust\nprediction. In particular, in this case, existing certification methods become\ninapplicable since the optimized noise varies across different samples. To\nconquer this challenge, we introduce a storage-update-based certification\nmethod, which dynamically adjusts each sample's certification region to improve\ncertification performance. We conduct extensive experiments on multiple\nbenchmark datasets, demonstrating the effectiveness of our proposed method. Our\ncode is available at https://github.com/NcepuQiaoTing/Cert-SSB.", "published": "2025-04-30 15:21:25", "link": "http://arxiv.org/abs/2504.21730v1", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Sionna RT: Technical Report", "abstract": "Sionna is an open-source, GPU-accelerated library that, as of version 0.14,\nincorporates a ray tracer for simulating radio wave propagation. A unique\nfeature of Sionna RT is differentiability, enabling the calculation of\ngradients for the channel impulse responses (CIRs), radio maps, and other\nrelated metrics with respect to system and environmental parameters, such as\nmaterial properties, antenna patterns, and array geometries. The release of\nSionna 1.0 provides a complete overhaul of the ray tracer, significantly\nimproving its speed, memory efficiency, and extensibility. This document\ndetails the algorithms employed by Sionna RT to simulate radio wave propagation\nefficiently, while also addressing their current limitations. Given that the\ncomputation of CIRs and radio maps requires distinct algorithms, these are\ndetailed in separate sections. For CIRs, Sionna RT integrates shooting and\nbouncing of rays (SBR) with the image method and uses a hashing-based mechanism\nto efficiently eliminate duplicate paths. Radio maps are computed using a\npurely SBR-based approach.", "published": "2025-04-30 15:05:20", "link": "http://arxiv.org/abs/2504.21719v1", "categories": ["cs.IT", "cs.AI", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning", "abstract": "We propose a generalization of modern representation learning objectives by\nreframing them as recursive divergence alignment processes over localized\nconditional distributions While recent frameworks like Information Contrastive\nLearning I-Con unify multiple learning paradigms through KL divergence between\nfixed neighborhood conditionals we argue this view underplays a crucial\nrecursive structure inherent in the learning process. We introduce Recursive KL\nDivergence Optimization RKDO a dynamic formalism where representation learning\nis framed as the evolution of KL divergences across data neighborhoods. This\nformulation captures contrastive clustering and dimensionality reduction\nmethods as static slices while offering a new path to model stability and local\nadaptation. Our experiments demonstrate that RKDO offers dual efficiency\nadvantages approximately 30 percent lower loss values compared to static\napproaches across three different datasets and 60 to 80 percent reduction in\ncomputational resources needed to achieve comparable results. This suggests\nthat RKDOs recursive updating mechanism provides a fundamentally more efficient\noptimization landscape for representation learning with significant\nimplications for resource constrained applications.", "published": "2025-04-30 14:51:27", "link": "http://arxiv.org/abs/2504.21707v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Vision Transformers in Precision Agriculture: A Comprehensive Survey", "abstract": "Detecting plant diseases is a crucial aspect of modern agriculture - it plays\na key role in maintaining crop health and increasing overall yield. Traditional\napproaches, though still valuable, often rely on manual inspection or\nconventional machine learning techniques, both of which face limitations in\nscalability and accuracy. Recently, Vision Transformers (ViTs) have emerged as\na promising alternative, offering benefits such as improved handling of\nlong-range dependencies and better scalability for visual tasks. This survey\nexplores the application of ViTs in precision agriculture, covering tasks from\nclassification to detection and segmentation. We begin by introducing the\nfoundational architecture of ViTs and discuss their transition from Natural\nLanguage Processing (NLP) to computer vision. The discussion includes the\nconcept of inductive bias in traditional models like Convolutional Neural\nNetworks (CNNs), and how ViTs mitigate these biases. We provide a comprehensive\nreview of recent literature, focusing on key methodologies, datasets, and\nperformance metrics. The survey also includes a comparative analysis of CNNs\nand ViTs, with a look at hybrid models and performance enhancements. Technical\nchallenges - such as data requirements, computational demands, and model\ninterpretability - are addressed alongside potential solutions. Finally, we\noutline potential research directions and technological advancements that could\nfurther support the integration of ViTs in real-world agricultural settings.\nOur goal with this study is to offer practitioners and researchers a deeper\nunderstanding of how ViTs are poised to transform smart and precision\nagriculture.", "published": "2025-04-30 14:50:02", "link": "http://arxiv.org/abs/2504.21706v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "XBreaking: Explainable Artificial Intelligence for Jailbreaking LLMs", "abstract": "Large Language Models are fundamental actors in the modern IT landscape\ndominated by AI solutions. However, security threats associated with them might\nprevent their reliable adoption in critical application scenarios such as\ngovernment organizations and medical institutions. For this reason, commercial\nLLMs typically undergo a sophisticated censoring mechanism to eliminate any\nharmful output they could possibly produce. In response to this, LLM\nJailbreaking is a significant threat to such protections, and many previous\napproaches have already demonstrated its effectiveness across diverse domains.\nExisting jailbreak proposals mostly adopt a generate-and-test strategy to craft\nmalicious input. To improve the comprehension of censoring mechanisms and\ndesign a targeted jailbreak attack, we propose an Explainable-AI solution that\ncomparatively analyzes the behavior of censored and uncensored models to derive\nunique exploitable alignment patterns. Then, we propose XBreaking, a novel\njailbreak attack that exploits these unique patterns to break the security\nconstraints of LLMs by targeted noise injection. Our thorough experimental\ncampaign returns important insights about the censoring mechanisms and\ndemonstrates the effectiveness and performance of our attack.", "published": "2025-04-30 14:44:24", "link": "http://arxiv.org/abs/2504.21700v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Self-Supervised Monocular Visual Drone Model Identification through Improved Occlusion Handling", "abstract": "Ego-motion estimation is vital for drones when flying in GPS-denied\nenvironments. Vision-based methods struggle when flight speed increases and\nclose-by objects lead to difficult visual conditions with considerable motion\nblur and large occlusions. To tackle this, vision is typically complemented by\nstate estimation filters that combine a drone model with inertial measurements.\nHowever, these drone models are currently learned in a supervised manner with\nground-truth data from external motion capture systems, limiting scalability to\ndifferent environments and drones. In this work, we propose a self-supervised\nlearning scheme to train a neural-network-based drone model using only onboard\nmonocular video and flight controller data (IMU and motor feedback). We achieve\nthis by first training a self-supervised relative pose estimation model, which\nthen serves as a teacher for the drone model. To allow this to work at high\nspeed close to obstacles, we propose an improved occlusion handling method for\ntraining self-supervised pose estimation models. Due to this method, the root\nmean squared error of resulting odometry estimates is reduced by an average of\n15%. Moreover, the student neural drone model can be successfully obtained from\nthe onboard data. It even becomes more accurate at higher speeds compared to\nits teacher, the self-supervised vision-based model. We demonstrate the value\nof the neural drone model by integrating it into a traditional filter-based VIO\nsystem (ROVIO), resulting in superior odometry accuracy on aggressive 3D racing\ntrajectories near obstacles. Self-supervised learning of ego-motion estimation\nrepresents a significant step toward bridging the gap between flying in\ncontrolled, expensive lab environments and real-world drone applications. The\nfusion of vision and drone models will enable higher-speed flight and improve\nstate estimation, on any drone in any environment.", "published": "2025-04-30 14:38:01", "link": "http://arxiv.org/abs/2504.21695v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Automatic Mapping of AutomationML Files to Ontologies for Graph Queries and Validation", "abstract": "AutomationML has seen widespread adoption as an open data exchange format in\nthe automation domain. It is an open and vendor neutral standard based on the\nextensible markup language XML. However, AutomationML extends XML with\nadditional semantics, that limit the applicability of common XML-tools for\napplications like querying or data validation. This article provides\npractitioners with 1) an up-to-date ontology of the concepts in the\nAutomationML-standard, as well as 2) a declarative mapping to automatically\ntransform any AutomationML model into RDF triples. Together, these artifacts\nallow practitioners an easy integration of AutomationML information into\nindustrial knowledge graphs. A study on examples from the automation domain\nconcludes that transforming AutomationML to OWL opens up new powerful ways for\nquerying and validation that are impossible without transformation.", "published": "2025-04-30 14:34:56", "link": "http://arxiv.org/abs/2504.21694v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Enhancing Self-Supervised Fine-Grained Video Object Tracking with Dynamic Memory Prediction", "abstract": "Successful video analysis relies on accurate recognition of pixels across\nframes, and frame reconstruction methods based on video correspondence learning\nare popular due to their efficiency. Existing frame reconstruction methods,\nwhile efficient, neglect the value of direct involvement of multiple reference\nframes for reconstruction and decision-making aspects, especially in complex\nsituations such as occlusion or fast movement. In this paper, we introduce a\nDynamic Memory Prediction (DMP) framework that innovatively utilizes multiple\nreference frames to concisely and directly enhance frame reconstruction. Its\ncore component is a Reference Frame Memory Engine that dynamically selects\nframes based on object pixel features to improve tracking accuracy. In\naddition, a Bidirectional Target Prediction Network is built to utilize\nmultiple reference frames to improve the robustness of the model. Through\nexperiments, our algorithm outperforms the state-of-the-art self-supervised\ntechniques on two fine-grained video object tracking tasks: object segmentation\nand keypoint tracking.", "published": "2025-04-30 14:29:04", "link": "http://arxiv.org/abs/2504.21692v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Extension-ranking Semantics for Abstract Argumentation Preprint", "abstract": "In this paper, we present a general framework for ranking sets of arguments\nin abstract argumentation based on their plausibility of acceptance. We present\na generalisation of Dung's extension semantics as extension-ranking semantics,\nwhich induce a preorder over the power set of all arguments, allowing us to\nstate that one set is \"closer\" to being acceptable than another. To evaluate\nthe extension-ranking semantics, we introduce a number of principles that a\nwell-behaved extension-ranking semantics should satisfy. We consider several\nsimple base relations, each of which models a single central aspect of\nargumentative reasoning. The combination of these base relations provides us\nwith a family of extension-ranking semantics. We also adapt a number of\napproaches from the literature for ranking extensions to be usable in the\ncontext of extension-ranking semantics, and evaluate their behaviour.", "published": "2025-04-30 14:19:42", "link": "http://arxiv.org/abs/2504.21683v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Designing Control Barrier Function via Probabilistic Enumeration for Safe Reinforcement Learning Navigation", "abstract": "Achieving safe autonomous navigation systems is critical for deploying robots\nin dynamic and uncertain real-world environments. In this paper, we propose a\nhierarchical control framework leveraging neural network verification\ntechniques to design control barrier functions (CBFs) and policy correction\nmechanisms that ensure safe reinforcement learning navigation policies. Our\napproach relies on probabilistic enumeration to identify unsafe regions of\noperation, which are then used to construct a safe CBF-based control layer\napplicable to arbitrary policies. We validate our framework both in simulation\nand on a real robot, using a standard mobile robot benchmark and a highly\ndynamic aquatic environmental monitoring task. These experiments demonstrate\nthe ability of the proposed solution to correct unsafe actions while preserving\nefficient navigation behavior. Our results show the promise of developing\nhierarchical verification-based systems to enable safe and robust navigation\nbehaviors in complex scenarios.", "published": "2025-04-30 13:47:25", "link": "http://arxiv.org/abs/2504.21643v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Quantitative Auditing of AI Fairness with Differentially Private Synthetic Data", "abstract": "Fairness auditing of AI systems can identify and quantify biases. However,\ntraditional auditing using real-world data raises security and privacy\nconcerns. It exposes auditors to security risks as they become custodians of\nsensitive information and targets for cyberattacks. Privacy risks arise even\nwithout direct breaches, as data analyses can inadvertently expose confidential\ninformation. To address these, we propose a framework that leverages\ndifferentially private synthetic data to audit the fairness of AI systems. By\napplying privacy-preserving mechanisms, it generates synthetic data that\nmirrors the statistical properties of the original dataset while ensuring\nprivacy. This method balances the goal of rigorous fairness auditing and the\nneed for strong privacy protections. Through experiments on real datasets like\nAdult, COMPAS, and Diabetes, we compare fairness metrics of synthetic and real\ndata. By analyzing the alignment and discrepancies between these metrics, we\nassess the capacity of synthetic data to preserve the fairness properties of\nreal data. Our results demonstrate the framework's ability to enable meaningful\nfairness evaluations while safeguarding sensitive information, proving its\napplicability across critical and sensitive domains.", "published": "2025-04-30 13:36:27", "link": "http://arxiv.org/abs/2504.21634v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning", "abstract": "With the rapid advancement of artificial intelligence, there is an increasing\ndemand for intelligent robots capable of assisting humans in daily tasks and\nperforming complex operations. Such robots not only require task planning\ncapabilities but must also execute tasks with stability and robustness. In this\npaper, we present a closed-loop task planning and acting system, LLM-PAS, which\nis assisted by a pre-trained Large Language Model (LLM). While LLM-PAS plans\nlong-horizon tasks in a manner similar to traditional task and motion planners,\nit also emphasizes the execution phase of the task. By transferring part of the\nconstraint-checking process from the planning phase to the execution phase,\nLLM-PAS enables exploration of the constraint space and delivers more accurate\nfeedback on environmental anomalies during execution. The reasoning\ncapabilities of the LLM allow it to handle anomalies that cannot be addressed\nby the robust executor. To further enhance the system's ability to assist the\nplanner during replanning, we propose the First Look Prompting (FLP) method,\nwhich induces LLM to generate effective PDDL goals. Through comparative\nprompting experiments and systematic experiments, we demonstrate the\neffectiveness and robustness of LLM-PAS in handling anomalous conditions during\ntask execution.", "published": "2025-04-30 12:53:53", "link": "http://arxiv.org/abs/2504.21596v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "One Net to Rule Them All: Domain Randomization in Quadcopter Racing Across Different Platforms", "abstract": "In high-speed quadcopter racing, finding a single controller that works well\nacross different platforms remains challenging. This work presents the first\nneural network controller for drone racing that generalizes across physically\ndistinct quadcopters. We demonstrate that a single network, trained with domain\nrandomization, can robustly control various types of quadcopters. The network\nrelies solely on the current state to directly compute motor commands. The\neffectiveness of this generalized controller is validated through real-world\ntests on two substantially different crafts (3-inch and 5-inch race\nquadcopters). We further compare the performance of this generalized controller\nwith controllers specifically trained for the 3-inch and 5-inch drone, using\ntheir identified model parameters with varying levels of domain randomization\n(0%, 10%, 20%, 30%). While the generalized controller shows slightly slower\nspeeds compared to the fine-tuned models, it excels in adaptability across\ndifferent platforms. Our results show that no randomization fails sim-to-real\ntransfer while increasing randomization improves robustness but reduces speed.\nDespite this trade-off, our findings highlight the potential of domain\nrandomization for generalizing controllers, paving the way for universal AI\ncontrollers that can adapt to any platform.", "published": "2025-04-30 12:44:41", "link": "http://arxiv.org/abs/2504.21586v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Multi-Goal Dexterous Hand Manipulation using Probabilistic Model-based Reinforcement Learning", "abstract": "This paper tackles the challenge of learning multi-goal dexterous hand\nmanipulation tasks using model-based Reinforcement Learning. We propose\nGoal-Conditioned Probabilistic Model Predictive Control (GC-PMPC) by designing\nprobabilistic neural network ensembles to describe the high-dimensional\ndexterous hand dynamics and introducing an asynchronous MPC policy to meet the\ncontrol frequency requirements in real-world dexterous hand systems. Extensive\nevaluations on four simulated Shadow Hand manipulation scenarios with randomly\ngenerated goals demonstrate GC-PMPC's superior performance over\nstate-of-the-art baselines. It successfully drives a cable-driven Dexterous\nhand, DexHand 021 with 12 Active DOFs and 5 tactile sensors, to learn\nmanipulating a cubic die to three goal poses within approximately 80 minutes of\ninteractions, demonstrating exceptional learning efficiency and control\nperformance on a cost-effective dexterous hand platform.", "published": "2025-04-30 12:44:38", "link": "http://arxiv.org/abs/2504.21585v1", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "MF-LLM: Simulating Collective Decision Dynamics via a Mean-Field Large Language Model Framework", "abstract": "Simulating collective decision-making involves more than aggregating\nindividual behaviors; it arises from dynamic interactions among individuals.\nWhile large language models (LLMs) show promise for social simulation, existing\napproaches often exhibit deviations from real-world data. To address this gap,\nwe propose the Mean-Field LLM (MF-LLM) framework, which explicitly models the\nfeedback loop between micro-level decisions and macro-level population. MF-LLM\nalternates between two models: a policy model that generates individual actions\nbased on personal states and group-level information, and a mean field model\nthat updates the population distribution from the latest individual decisions.\nTogether, they produce rollouts that simulate the evolving trajectories of\ncollective decision-making. To better match real-world data, we introduce\nIB-Tune, a fine-tuning method for LLMs grounded in the information bottleneck\nprinciple, which maximizes the relevance of population distributions to future\nactions while minimizing redundancy with historical data. We evaluate MF-LLM on\na real-world social dataset, where it reduces KL divergence to human population\ndistributions by 47 percent over non-mean-field baselines, and enables accurate\ntrend forecasting and intervention planning. It generalizes across seven\ndomains and four LLM backbones, providing a scalable foundation for\nhigh-fidelity social simulation.", "published": "2025-04-30 12:41:51", "link": "http://arxiv.org/abs/2504.21582v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "A Study on Group Decision Making Problem Based on Fuzzy Reasoning and Bayesian Networks", "abstract": "Aiming at the group decision - making problem with multi - objective\nattributes, this study proposes a group decision - making system that\nintegrates fuzzy inference and Bayesian network. A fuzzy rule base is\nconstructed by combining threshold values, membership functions, expert\nexperience, and domain knowledge to address quantitative challenges such as\nscale differences and expert linguistic variables. A hierarchical Bayesian\nnetwork is designed, featuring a directed acyclic graph with nodes selected by\nexperts, and maximum likelihood estimation is used to dynamically optimize the\nconditional probability table, modeling the nonlinear correlations among\nmultidimensional indices for posterior probability aggregation. In a\ncomprehensive student evaluation case, this method is compared with the\ntraditional weighted scoring approach. The results indicate that the proposed\nmethod demonstrates effectiveness in both rule criterion construction and\nranking consistency, with a classification accuracy of 86.0% and an F1 value\nimprovement of 53.4% over the traditional method. Additionally, computational\nexperiments on real - world datasets across various group decision scenarios\nassess the method's performance and robustness, providing evidence of its\nreliability in diverse contexts.", "published": "2025-04-30 12:14:48", "link": "http://arxiv.org/abs/2504.21568v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards proactive self-adaptive AI for non-stationary environments with dataset shifts", "abstract": "Artificial Intelligence (AI) models deployed in production frequently face\nchallenges in maintaining their performance in non-stationary environments.\nThis issue is particularly noticeable in medical settings, where temporal\ndataset shifts often occur. These shifts arise when the distributions of\ntraining data differ from those of the data encountered during deployment over\ntime. Further, new labeled data to continuously retrain AI is not typically\navailable in a timely manner due to data access limitations. To address these\nchallenges, we propose a proactive self-adaptive AI approach, or pro-adaptive,\nwhere we model the temporal trajectory of AI parameters, allowing us to\nshort-term forecast parameter values. To this end, we use polynomial spline\nbases, within an extensible Functional Data Analysis framework. We validate our\nmethodology with a logistic regression model addressing prior probability\nshift, covariate shift, and concept shift. This validation is conducted on both\na controlled simulated dataset and a publicly available real-world COVID-19\ndataset from Mexico, with various shifts occurring between 2020 and 2024. Our\nresults indicate that this approach enhances the performance of AI against\nshifts compared to baseline stable models trained at different time distances\nfrom the present, without requiring updated training data. This work lays the\nfoundation for pro-adaptive AI research against dynamic, non-stationary\nenvironments, being compatible with data protection, in resilient AI production\nenvironments for health.", "published": "2025-04-30 12:09:59", "link": "http://arxiv.org/abs/2504.21565v1", "categories": ["cs.LG", "cs.AI", "I.2.8"], "primary_category": "cs.LG"}
{"title": "eNCApsulate: NCA for Precision Diagnosis on Capsule Endoscopes", "abstract": "Wireless Capsule Endoscopy is a non-invasive imaging method for the entire\ngastrointestinal tract, and is a pain-free alternative to traditional\nendoscopy. It generates extensive video data that requires significant review\ntime, and localizing the capsule after ingestion is a challenge. Techniques\nlike bleeding detection and depth estimation can help with localization of\npathologies, but deep learning models are typically too large to run directly\non the capsule. Neural Cellular Automata (NCA) for bleeding segmentation and\ndepth estimation are trained on capsule endoscopic images. For monocular depth\nestimation, we distill a large foundation model into the lean NCA architecture,\nby treating the outputs of the foundation model as pseudo ground truth. We then\nport the trained NCA to the ESP32 microcontroller, enabling efficient image\nprocessing on hardware as small as a camera capsule. NCA are more accurate\n(Dice) than other portable segmentation models, while requiring more than 100x\nfewer parameters stored in memory than other small-scale models. The visual\nresults of NCA depth estimation look convincing, and in some cases beat the\nrealism and detail of the pseudo ground truth. Runtime optimizations on the\nESP32-S3 accelerate the average inference speed significantly, by more than\nfactor 3. With several algorithmic adjustments and distillation, it is possible\nto eNCApsulate NCA models into microcontrollers that fit into wireless capsule\nendoscopes. This is the first work that enables reliable bleeding segmentation\nand depth estimation on a miniaturized device, paving the way for precise\ndiagnosis combined with visual odometry as a means of precise localization of\nthe capsule -- on the capsule.", "published": "2025-04-30 12:06:56", "link": "http://arxiv.org/abs/2504.21562v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Meta knowledge assisted Evolutionary Neural Architecture Search", "abstract": "Evolutionary computation (EC)-based neural architecture search (NAS) has\nachieved remarkable performance in the automatic design of neural\narchitectures. However, the high computational cost associated with evaluating\nsearched architectures poses a challenge for these methods, and a fixed form of\nlearning rate (LR) schedule means greater information loss on diverse searched\narchitectures. This paper introduces an efficient EC-based NAS method to solve\nthese problems via an innovative meta-learning framework. Specifically, a\nmeta-learning-rate (Meta-LR) scheme is used through pretraining to obtain a\nsuitable LR schedule, which guides the training process with lower information\nloss when evaluating each individual. An adaptive surrogate model is designed\nthrough an adaptive threshold to select the potential architectures in a few\nepochs and then evaluate the potential architectures with complete epochs.\nAdditionally, a periodic mutation operator is proposed to increase the\ndiversity of the population, which enhances the generalizability and\nrobustness. Experiments on CIFAR-10, CIFAR-100, and ImageNet1K datasets\ndemonstrate that the proposed method achieves high performance comparable to\nthat of many state-of-the-art peer methods, with lower computational cost and\ngreater robustness.", "published": "2025-04-30 11:43:07", "link": "http://arxiv.org/abs/2504.21545v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "ClassWise-CRF: Category-Specific Fusion for Enhanced Semantic Segmentation of Remote Sensing Imagery", "abstract": "We propose a result-level category-specific fusion architecture called\nClassWise-CRF. This architecture employs a two-stage process: first, it selects\nexpert networks that perform well in specific categories from a pool of\ncandidate networks using a greedy algorithm; second, it integrates the\nsegmentation predictions of these selected networks by adaptively weighting\ntheir contributions based on their segmentation performance in each category.\nInspired by Conditional Random Field (CRF), the ClassWise-CRF architecture\ntreats the segmentation predictions from multiple networks as confidence vector\nfields. It leverages segmentation metrics (such as Intersection over Union)\nfrom the validation set as priors and employs an exponential weighting strategy\nto fuse the category-specific confidence scores predicted by each network. This\nfusion method dynamically adjusts the weights of each network for different\ncategories, achieving category-specific optimization. Building on this, the\narchitecture further optimizes the fused results using unary and pairwise\npotentials in CRF to ensure spatial consistency and boundary accuracy. To\nvalidate the effectiveness of ClassWise-CRF, we conducted experiments on two\nremote sensing datasets, LoveDA and Vaihingen, using eight classic and advanced\nsemantic segmentation networks. The results show that the ClassWise-CRF\narchitecture significantly improves segmentation performance: on the LoveDA\ndataset, the mean Intersection over Union (mIoU) metric increased by 1.00% on\nthe validation set and by 0.68% on the test set; on the Vaihingen dataset, the\nmIoU improved by 0.87% on the validation set and by 0.91% on the test set.\nThese results fully demonstrate the effectiveness and generality of the\nClassWise-CRF architecture in semantic segmentation of remote sensing images.\nThe full code is available at https://github.com/zhuqinfeng1999/ClassWise-CRF.", "published": "2025-04-30 10:19:21", "link": "http://arxiv.org/abs/2504.21491v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "TRIED: Truly Innovative and Effective Detection Benchmark, developed by WITNESS", "abstract": "The rise of generative AI and deceptive synthetic media threatens the global\ninformation ecosystem, especially across the Global Majority. This report from\nWITNESS highlights the limitations of current AI detection tools, which often\nunderperform in real-world scenarios due to challenges related to\nexplainability, fairness, accessibility, and contextual relevance. In response,\nWITNESS introduces the Truly Innovative and Effective AI Detection (TRIED)\nBenchmark, a new framework for evaluating detection tools based on their\nreal-world impact and capacity for innovation. Drawing on frontline\nexperiences, deceptive AI cases, and global consultations, the report outlines\nhow detection tools must evolve to become truly innovative and relevant by\nmeeting diverse linguistic, cultural, and technological contexts. It offers\npractical guidance for developers, policymakers, and standards bodies to design\naccountable, transparent, and user-centered detection solutions, and\nincorporate sociotechnical considerations into future AI standards, procedures\nand evaluation frameworks. By adopting the TRIED Benchmark, stakeholders can\ndrive innovation, safeguard public trust, strengthen AI literacy, and\ncontribute to a more resilient global information credibility.", "published": "2025-04-30 10:18:19", "link": "http://arxiv.org/abs/2504.21489v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "A Comprehensive Study of Exploitable Patterns in Smart Contracts: From Vulnerability to Defense", "abstract": "With the rapid advancement of blockchain technology, smart contracts have\nenabled the implementation of increasingly complex functionalities. However,\nensuring the security of smart contracts remains a persistent challenge across\nthe stages of development, compilation, and execution. Vulnerabilities within\nsmart contracts not only undermine the security of individual applications but\nalso pose significant risks to the broader blockchain ecosystem, as\ndemonstrated by the growing frequency of attacks since 2016, resulting in\nsubstantial financial losses. This paper provides a comprehensive analysis of\nkey security risks in Ethereum smart contracts, specifically those written in\nSolidity and executed on the Ethereum Virtual Machine (EVM). We focus on two\nprevalent and critical vulnerability types (reentrancy and integer overflow) by\nexamining their underlying mechanisms, replicating attack scenarios, and\nassessing effective countermeasures.", "published": "2025-04-30 10:00:36", "link": "http://arxiv.org/abs/2504.21480v1", "categories": ["cs.CR", "cs.AI", "cs.SE"], "primary_category": "cs.CR"}
{"title": "GarmentDiffusion: 3D Garment Sewing Pattern Generation with Multimodal Diffusion Transformers", "abstract": "Garment sewing patterns are fundamental design elements that bridge the gap\nbetween design concepts and practical manufacturing. The generative modeling of\nsewing patterns is crucial for creating diversified garments. However, existing\napproaches are limited either by reliance on a single input modality or by\nsuboptimal generation efficiency. In this work, we present\n\\textbf{\\textit{GarmentDiffusion}}, a new generative model capable of producing\ncentimeter-precise, vectorized 3D sewing patterns from multimodal inputs (text,\nimage, and incomplete sewing pattern). Our method efficiently encodes 3D sewing\npattern parameters into compact edge token representations, achieving a\nsequence length that is $\\textbf{10}\\times$ shorter than that of the\nautoregressive SewingGPT in DressCode. By employing a diffusion transformer, we\nsimultaneously denoise all edge tokens along the temporal axis, while\nmaintaining a constant number of denoising steps regardless of dataset-specific\nedge and panel statistics. With all combination of designs of our model, the\nsewing pattern generation speed is accelerated by $\\textbf{100}\\times$ compared\nto SewingGPT. We achieve new state-of-the-art results on DressCodeData, as well\nas on the largest sewing pattern dataset, namely GarmentCodeData. The project\nwebsite is available at https://shenfu-research.github.io/Garment-Diffusion/.", "published": "2025-04-30 09:56:59", "link": "http://arxiv.org/abs/2504.21476v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "xEEGNet: Towards Explainable AI in EEG Dementia Classification", "abstract": "This work presents xEEGNet, a novel, compact, and explainable neural network\nfor EEG data analysis. It is fully interpretable and reduces overfitting\nthrough major parameter reduction. As an applicative use case, we focused on\nclassifying common dementia conditions, Alzheimer's and frontotemporal\ndementia, versus controls. xEEGNet is broadly applicable to other neurological\nconditions involving spectral alterations. We initially used ShallowNet, a\nsimple and popular model from the EEGNet-family. Its structure was analyzed and\ngradually modified to move from a \"black box\" to a more transparent model,\nwithout compromising performance. The learned kernels and weights were examined\nfrom a clinical standpoint to assess medical relevance. Model variants,\nincluding ShallowNet and the final xEEGNet, were evaluated using robust\nNested-Leave-N-Subjects-Out cross-validation for unbiased performance\nestimates. Variability across data splits was explained using embedded EEG\nrepresentations, grouped by class and set, with pairwise separability to\nquantify group distinction. Overfitting was assessed through\ntraining-validation loss correlation and training speed. xEEGNet uses only 168\nparameters, 200 times fewer than ShallowNet, yet retains interpretability,\nresists overfitting, achieves comparable median performance (-1.5%), and\nreduces variability across splits. This variability is explained by embedded\nEEG representations: higher accuracy correlates with greater separation between\ntest set controls and Alzheimer's cases, without significant influence from\ntraining data. xEEGNet's ability to filter specific EEG bands, learn\nband-specific topographies, and use relevant spectral features demonstrates its\ninterpretability. While large deep learning models are often prioritized for\nperformance, this study shows smaller architectures like xEEGNet can be equally\neffective in EEG pathology classification.", "published": "2025-04-30 09:24:50", "link": "http://arxiv.org/abs/2504.21457v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SimPRIVE: a Simulation framework for Physical Robot Interaction with Virtual Environments", "abstract": "The use of machine learning in cyber-physical systems has attracted the\ninterest of both industry and academia. However, no general solution has yet\nbeen found against the unpredictable behavior of neural networks and\nreinforcement learning agents. Nevertheless, the improvements of\nphoto-realistic simulators have paved the way towards extensive testing of\ncomplex algorithms in different virtual scenarios, which would be expensive and\ndangerous to implement in the real world.\n  This paper presents SimPRIVE, a simulation framework for physical robot\ninteraction with virtual environments, which operates as a vehicle-in-the-loop\nplatform, rendering a virtual world while operating the vehicle in the real\nworld.\n  Using SimPRIVE, any physical mobile robot running on ROS 2 can easily be\nconfigured to move its digital twin in a virtual world built with the Unreal\nEngine 5 graphic engine, which can be populated with objects, people, or other\nvehicles with programmable behavior.\n  SimPRIVE has been designed to accommodate custom or pre-built virtual worlds\nwhile being light-weight to contain execution times and allow fast rendering.\nIts main advantage lies in the possibility of testing complex algorithms on the\nfull software and hardware stack while minimizing the risks and costs of a test\ncampaign. The framework has been validated by testing a reinforcement learning\nagent trained for obstacle avoidance on an AgileX Scout Mini rover that\nnavigates a virtual office environment where everyday objects and people are\nplaced as obstacles. The physical rover moves with no collision in an indoor\nlimited space, thanks to a LiDAR-based heuristic.", "published": "2025-04-30 09:22:55", "link": "http://arxiv.org/abs/2504.21454v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Rethinking Visual Layer Selection in Multimodal LLMs", "abstract": "Multimodal large language models (MLLMs) have achieved impressive performance\nacross a wide range of tasks, typically using CLIP-ViT as their visual encoder\ndue to its strong text-image alignment capabilities. While prior studies\nsuggest that different CLIP-ViT layers capture different types of information,\nwith shallower layers focusing on fine visual details and deeper layers\naligning more closely with textual semantics, most MLLMs still select visual\nfeatures based on empirical heuristics rather than systematic analysis. In this\nwork, we propose a Layer-wise Representation Similarity approach to group\nCLIP-ViT layers with similar behaviors into {shallow, middle, and deep}\ncategories and assess their impact on MLLM performance. Building on this\nfoundation, we revisit the visual layer selection problem in MLLMs at scale,\ntraining LLaVA-style models ranging from 1.4B to 7B parameters. Through\nextensive experiments across 10 datasets and 4 tasks, we find that: (1) deep\nlayers are essential for OCR tasks; (2) shallow and middle layers substantially\noutperform deep layers on reasoning tasks involving counting, positioning, and\nobject localization; (3) a lightweight fusion of features across shallow,\nmiddle, and deep layers consistently outperforms specialized fusion baselines\nand single-layer selections, achieving gains on 9 out of 10 datasets. Our work\noffers the first principled study of visual layer selection in MLLMs, laying\nthe groundwork for deeper investigations into visual representation learning\nfor MLLMs.", "published": "2025-04-30 09:07:10", "link": "http://arxiv.org/abs/2504.21447v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "NGENT: Next-Generation AI Agents Must Integrate Multi-Domain Abilities to Achieve Artificial General Intelligence", "abstract": "This paper argues that the next generation of AI agent (NGENT) should\nintegrate across-domain abilities to advance toward Artificial General\nIntelligence (AGI). Although current AI agents are effective in specialized\ntasks such as robotics, role-playing, and tool-using, they remain confined to\nnarrow domains. We propose that future AI agents should synthesize the\nstrengths of these specialized systems into a unified framework capable of\noperating across text, vision, robotics, reinforcement learning, emotional\nintelligence, and beyond. This integration is not only feasible but also\nessential for achieving the versatility and adaptability that characterize\nhuman intelligence. The convergence of technologies across AI domains, coupled\nwith increasing user demand for cross-domain capabilities, suggests that such\nintegration is within reach. Ultimately, the development of these versatile\nagents is a critical step toward realizing AGI. This paper explores the\nrationale for this shift, potential pathways for achieving it.", "published": "2025-04-30 08:46:14", "link": "http://arxiv.org/abs/2504.21433v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "UAV Marketplace Simulation Tool for BVLOS Operations", "abstract": "We present a simulation tool for evaluating team formation in autonomous\nmulti-UAV (Unmanned Aerial Vehicle) missions that operate Beyond Visual Line of\nSight (BVLOS). The tool models UAV collaboration and mission execution in\ndynamic and adversarial conditions, where Byzantine UAVs attempt to disrupt\noperations. Our tool allows researchers to integrate and compare various team\nformation strategies in a controlled environment with configurable mission\nparameters and adversarial behaviors. The log of each simulation run is stored\nin a structured way along with performance metrics so that statistical analysis\ncould be done straightforwardly. The tool is versatile for testing and\nimproving UAV coordination strategies in real-world applications.", "published": "2025-04-30 08:36:22", "link": "http://arxiv.org/abs/2504.21428v1", "categories": ["cs.RO", "cs.AI", "cs.DC"], "primary_category": "cs.RO"}
{"title": "MPEC: Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based Classifiers", "abstract": "Accurate classification of EEG signals is crucial for brain-computer\ninterfaces (BCIs) and neuroprosthetic applications, yet many existing methods\nfail to account for the non-Euclidean, manifold structure of EEG data,\nresulting in suboptimal performance. Preserving this manifold information is\nessential to capture the true geometry of EEG signals, but traditional\nclassification techniques largely overlook this need. To this end, we propose\nMPEC (Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based\nClassifiers), that introduces two key innovations: (1) a feature engineering\nphase that combines covariance matrices and Radial Basis Function (RBF) kernels\nto capture both linear and non-linear relationships among EEG channels, and (2)\na clustering phase that employs a modified K-means algorithm tailored for the\nRiemannian manifold space, ensuring local geometric sensitivity. Ensembling\nmultiple clustering-based classifiers, MPEC achieves superior results,\nvalidated by significant improvements on the BCI Competition IV dataset 2a.", "published": "2025-04-30 08:34:15", "link": "http://arxiv.org/abs/2504.21427v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Optimizing Mouse Dynamics for User Authentication by Machine Learning: Addressing Data Sufficiency, Accuracy-Practicality Trade-off, and Model Performance Challenges", "abstract": "User authentication is essential to ensure secure access to computer systems,\nyet traditional methods face limitations in usability, cost, and security.\nMouse dynamics authentication, based on the analysis of users' natural\ninteraction behaviors with mouse devices, offers a cost-effective,\nnon-intrusive, and adaptable solution. However, challenges remain in\ndetermining the optimal data volume, balancing accuracy and practicality, and\neffectively capturing temporal behavioral patterns. In this study, we propose a\nstatistical method using Gaussian kernel density estimate (KDE) and\nKullback-Leibler (KL) divergence to estimate the sufficient data volume for\ntraining authentication models. We introduce the Mouse Authentication Unit\n(MAU), leveraging Approximate Entropy (ApEn) to optimize segment length for\nefficient and accurate behavioral representation. Furthermore, we design the\nLocal-Time Mouse Authentication (LT-AMouse) framework, integrating 1D-ResNet\nfor local feature extraction and GRU for modeling long-term temporal\ndependencies. Taking the Balabit and DFL datasets as examples, we significantly\nreduced the data scale, particularly by a factor of 10 for the DFL dataset,\ngreatly alleviating the training burden. Additionally, we determined the\noptimal input recognition unit length for the user authentication system on\ndifferent datasets based on the slope of Approximate Entropy. Training with\nimbalanced samples, our model achieved a successful defense AUC 98.52% for\nblind attack on the DFL dataset and 94.65% on the Balabit dataset, surpassing\nthe current sota performance.", "published": "2025-04-30 08:16:52", "link": "http://arxiv.org/abs/2504.21415v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Galvatron: An Automatic Distributed System for Efficient Foundation Model Training", "abstract": "Galvatron is a distributed system for efficiently training large-scale\nFoundation Models. It overcomes the complexities of selecting optimal\nparallelism strategies by automatically identifying the most efficient hybrid\nstrategy, incorporating data, tensor, pipeline, sharded data, and sequence\nparallelism, along with recomputation. The system's architecture includes a\nprofiler for hardware and model analysis, a search engine for strategy\noptimization using decision trees and dynamic programming, and a runtime for\nexecuting these strategies efficiently. Benchmarking on various clusters\ndemonstrates Galvatron's superior throughput compared to existing frameworks.\nThis open-source system offers user-friendly interfaces and comprehensive\ndocumentation, making complex distributed training accessible and efficient.\nThe source code of Galvatron is available at\nhttps://github.com/PKU-DAIR/Hetu-Galvatron.", "published": "2025-04-30 08:11:45", "link": "http://arxiv.org/abs/2504.21411v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "FAST-Q: Fast-track Exploration with Adversarially Balanced State Representations for Counterfactual Action Estimation in Offline Reinforcement Learning", "abstract": "Recent advancements in state-of-the-art (SOTA) offline reinforcement learning\n(RL) have primarily focused on addressing function approximation errors, which\ncontribute to the overestimation of Q-values for out-of-distribution actions, a\nchallenge that static datasets exacerbate. However, high stakes applications\nsuch as recommendation systems in online gaming, introduce further complexities\ndue to player's psychology (intent) driven by gameplay experiences and the\ninherent volatility on the platform. These factors create highly sparse,\npartially overlapping state spaces across policies, further influenced by the\nexperiment path selection logic which biases state spaces towards specific\npolicies. Current SOTA methods constrain learning from such offline data by\nclipping known counterfactual actions as out-of-distribution due to poor\ngeneralization across unobserved states. Further aggravating conservative\nQ-learning and necessitating more online exploration. FAST-Q introduces a novel\napproach that (1) leverages Gradient Reversal Learning to construct balanced\nstate representations, regularizing the policy-specific bias between the\nplayer's state and action thereby enabling counterfactual estimation; (2)\nsupports offline counterfactual exploration in parallel with static data\nexploitation; and (3) proposes a Q-value decomposition strategy for\nmulti-objective optimization, facilitating explainable recommendations over\nshort and long-term objectives. These innovations demonstrate superiority of\nFAST-Q over prior SOTA approaches and demonstrates at least 0.15 percent\nincrease in player returns, 2 percent improvement in lifetime value (LTV), 0.4\npercent enhancement in the recommendation driven engagement, 2 percent\nimprovement in the player's platform dwell time and an impressive 10 percent\nreduction in the costs associated with the recommendation, on our volatile\ngaming platform.", "published": "2025-04-30 07:32:40", "link": "http://arxiv.org/abs/2504.21383v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ShorterBetter: Guiding Reasoning Models to Find Optimal Inference Length for Efficient Reasoning", "abstract": "Reasoning models such as OpenAI o3 and DeepSeek-R1 have demonstrated strong\nperformance on reasoning-intensive tasks through extended Chain-of-Thought\n(CoT) prompting. While longer reasoning traces can facilitate a more thorough\nexploration of solution paths for complex problems, researchers have observed\nthat these models often \"overthink\", leading to inefficient inference. In this\npaper, we introduce ShorterBetter, a simple yet effective reinforcement\nlearning methed that enables reasoning language models to discover their own\noptimal CoT lengths without human intervention. By sampling multiple outputs\nper problem and defining the Sample Optimal Length (SOL) as the shortest\ncorrect response among all the outputs, our method dynamically guides the model\ntoward optimal inference lengths. Applied to the DeepSeek-Distill-Qwen-1.5B\nmodel, ShorterBetter achieves up to an 80% reduction in output length on both\nin-domain and out-of-domain reasoning tasks while maintaining accuracy. Our\nanalysis shows that overly long reasoning traces often reflect loss of\nreasoning direction, and thus suggests that the extended CoT produced by\nreasoning models is highly compressible.", "published": "2025-04-30 07:04:19", "link": "http://arxiv.org/abs/2504.21370v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Revisiting Diffusion Autoencoder Training for Image Reconstruction Quality", "abstract": "Diffusion autoencoders (DAEs) are typically formulated as a noise prediction\nmodel and trained with a linear-$\\beta$ noise schedule that spends much of its\nsampling steps at high noise levels. Because high noise levels are associated\nwith recovering large-scale image structures and low noise levels with\nrecovering details, this configuration can result in low-quality and blurry\nimages. However, it should be possible to improve details while spending fewer\nsteps recovering structures because the latent code should already contain\nstructural information. Based on this insight, we propose a new DAE training\nmethod that improves the quality of reconstructed images. We divide training\ninto two phases. In the first phase, the DAE is trained as a vanilla\nautoencoder by always setting the noise level to the highest, forcing the\nencoder and decoder to populate the latent code with structural information. In\nthe second phase, we incorporate a noise schedule that spends more time in the\nlow-noise region, allowing the DAE to learn how to perfect the details. Our\nmethod results in images that have accurate high-level structures and low-level\ndetails while still preserving useful properties of the latent codes.", "published": "2025-04-30 07:00:33", "link": "http://arxiv.org/abs/2504.21368v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DGFNet: End-to-End Audio-Visual Source Separation Based on Dynamic Gating Fusion", "abstract": "Current Audio-Visual Source Separation methods primarily adopt two design\nstrategies. The first strategy involves fusing audio and visual features at the\nbottleneck layer of the encoder, followed by processing the fused features\nthrough the decoder. However, when there is a significant disparity between the\ntwo modalities, this approach may lead to the loss of critical information. The\nsecond strategy avoids direct fusion and instead relies on the decoder to\nhandle the interaction between audio and visual features. Nonetheless, if the\nencoder fails to integrate information across modalities adequately, the\ndecoder may be unable to effectively capture the complex relationships between\nthem. To address these issues, this paper proposes a dynamic fusion method\nbased on a gating mechanism that dynamically adjusts the modality fusion\ndegree. This approach mitigates the limitations of solely relying on the\ndecoder and facilitates efficient collaboration between audio and visual\nfeatures. Additionally, an audio attention module is introduced to enhance the\nexpressive capacity of audio features, thereby further improving model\nperformance. Experimental results demonstrate that our method achieves\nsignificant performance improvements on two benchmark datasets, validating its\neffectiveness and advantages in Audio-Visual Source Separation tasks.", "published": "2025-04-30 06:55:24", "link": "http://arxiv.org/abs/2504.21366v1", "categories": ["cs.SD", "cs.AI"], "primary_category": "cs.SD"}
{"title": "A comparative study of deep learning and ensemble learning to extend the horizon of traffic forecasting", "abstract": "Traffic forecasting is vital for Intelligent Transportation Systems, for\nwhich Machine Learning (ML) methods have been extensively explored to develop\ndata-driven Artificial Intelligence (AI) solutions. Recent research focuses on\nmodelling spatial-temporal correlations for short-term traffic prediction,\nleaving the favourable long-term forecasting a challenging and open issue. This\npaper presents a comparative study on large-scale real-world signalized\narterials and freeway traffic flow datasets, aiming to evaluate promising ML\nmethods in the context of large forecasting horizons up to 30 days. Focusing on\nmodelling capacity for temporal dynamics, we develop one ensemble ML method,\neXtreme Gradient Boosting (XGBoost), and a range of Deep Learning (DL) methods,\nincluding Recurrent Neural Network (RNN)-based methods and the state-of-the-art\nTransformer-based method. Time embedding is leveraged to enhance their\nunderstanding of seasonality and event factors. Experimental results highlight\nthat while the attention mechanism/Transformer framework is effective for\ncapturing long-range dependencies in sequential data, as the forecasting\nhorizon extends, the key to effective traffic forecasting gradually shifts from\ntemporal dependency capturing to periodicity modelling. Time embedding is\nparticularly effective in this context, helping naive RNN outperform Informer\nby 31.1% for 30-day-ahead forecasting. Meanwhile, as an efficient and robust\nmodel, XGBoost, while learning solely from time features, performs\ncompetitively with DL methods. Moreover, we investigate the impacts of various\nfactors like input sequence length, holiday traffic, data granularity, and\ntraining data size. The findings offer valuable insights and serve as a\nreference for future long-term traffic forecasting research and the improvement\nof AI's corresponding learning capabilities.", "published": "2025-04-30 06:31:21", "link": "http://arxiv.org/abs/2504.21358v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Nexus-Gen: A Unified Model for Image Understanding, Generation, and Editing", "abstract": "Unified multimodal large language models (MLLMs) aim to integrate multimodal\nunderstanding and generation abilities through a single framework. Despite\ntheir versatility, existing open-source unified models exhibit performance gaps\nagainst domain-specific architectures. To bridge this gap, we present\nNexus-Gen, a unified model that synergizes the language reasoning capabilities\nof LLMs with the image synthesis power of diffusion models. To align the\nembedding space of the LLM and diffusion model, we conduct a dual-phase\nalignment training process. (1) The autoregressive LLM learns to predict image\nembeddings conditioned on multimodal inputs, while (2) the vision decoder is\ntrained to reconstruct high-fidelity images from these embeddings. During\ntraining the LLM, we identified a critical discrepancy between the\nautoregressive paradigm's training and inference phases, where error\naccumulation in continuous embedding space severely degrades generation\nquality. To avoid this issue, we introduce a prefilled autoregression strategy\nthat prefills input sequence with position-embedded special tokens instead of\ncontinuous embeddings. Through dual-phase training, Nexus-Gen has developed the\nintegrated capability to comprehensively address the image understanding,\ngeneration and editing tasks. All models, datasets, and codes are published at\nhttps://github.com/modelscope/Nexus-Gen.git to facilitate further advancements\nacross the field.", "published": "2025-04-30 06:30:48", "link": "http://arxiv.org/abs/2504.21356v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "IRL Dittos: Embodied Multimodal AI Agent Interactions in Open Spaces", "abstract": "We introduce the In Real Life (IRL) Ditto, an AI-driven embodied agent\ndesigned to represent remote colleagues in shared office spaces, creating\nopportunities for real-time exchanges even in their absence. IRL Ditto offers a\nunique hybrid experience by allowing in-person colleagues to encounter a\ndigital version of their remote teammates, initiating greetings, updates, or\nsmall talk as they might in person. Our research question examines: How can the\nIRL Ditto influence interactions and relationships among colleagues in a shared\noffice space? Through a four-day study, we assessed IRL Ditto's ability to\nstrengthen social ties by simulating presence and enabling meaningful\ninteractions across different levels of social familiarity. We find that\nenhancing social relationships depended deeply on the foundation of the\nrelationship participants had with the source of the IRL Ditto. This study\nprovides insights into the role of embodied agents in enriching workplace\ndynamics for distributed teams.", "published": "2025-04-30 06:16:32", "link": "http://arxiv.org/abs/2504.21347v1", "categories": ["cs.AI", "cs.HC", "H.5.2; I.2.9"], "primary_category": "cs.AI"}
{"title": "Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early Lung Cancer Detection", "abstract": "Objective: A number of machine learning models have utilized semantic\nfeatures, deep features, or both to assess lung nodule malignancy. However,\ntheir reliance on manual annotation during inference, limited interpretability,\nand sensitivity to imaging variations hinder their application in real-world\nclinical settings. Thus, this research aims to integrate semantic features\nderived from radiologists' assessments of nodules, allowing the model to learn\nclinically relevant, robust, and explainable features for predicting lung\ncancer. Methods: We obtained 938 low-dose CT scans from the National Lung\nScreening Trial with 1,246 nodules and semantic features. The Lung Image\nDatabase Consortium dataset contains 1,018 CT scans, with 2,625 lesions\nannotated for nodule characteristics. Three external datasets were obtained\nfrom UCLA Health, the LUNGx Challenge, and the Duke Lung Cancer Screening. We\nfinetuned a pretrained Contrastive Language-Image Pretraining model with a\nparameter-efficient fine-tuning approach to align imaging and semantic features\nand predict the one-year lung cancer diagnosis. Results: We evaluated the\nperformance of the one-year diagnosis of lung cancer with AUROC and AUPRC and\ncompared it to three state-of-the-art models. Our model demonstrated an AUROC\nof 0.90 and AUPRC of 0.78, outperforming baseline state-of-the-art models on\nexternal datasets. Using CLIP, we also obtained predictions on semantic\nfeatures, such as nodule margin (AUROC: 0.81), nodule consistency (0.81), and\npleural attachment (0.84), that can be used to explain model predictions.\nConclusion: Our approach accurately classifies lung nodules as benign or\nmalignant, providing explainable outputs, aiding clinicians in comprehending\nthe underlying meaning of model predictions. This approach also prevents the\nmodel from learning shortcuts and generalizes across clinical settings.", "published": "2025-04-30 06:11:34", "link": "http://arxiv.org/abs/2504.21344v1", "categories": ["cs.CV", "cs.AI", "q-bio.QM"], "primary_category": "cs.CV"}
{"title": "Q-function Decomposition with Intervention Semantics with Factored Action Spaces", "abstract": "Many practical reinforcement learning environments have a discrete factored\naction space that induces a large combinatorial set of actions, thereby posing\nsignificant challenges. Existing approaches leverage the regular structure of\nthe action space and resort to a linear decomposition of Q-functions, which\navoids enumerating all combinations of factored actions. In this paper, we\nconsider Q-functions defined over a lower dimensional projected subspace of the\noriginal action space, and study the condition for the unbiasedness of\ndecomposed Q-functions using causal effect estimation from the no unobserved\nconfounder setting in causal statistics. This leads to a general scheme which\nwe call action decomposed reinforcement learning that uses the projected\nQ-functions to approximate the Q-function in standard model-free reinforcement\nlearning algorithms. The proposed approach is shown to improve sample\ncomplexity in a model-based reinforcement learning setting. We demonstrate\nimprovements in sample efficiency compared to state-of-the-art baselines in\nonline continuous control environments and a real-world offline sepsis\ntreatment environment.", "published": "2025-04-30 05:26:51", "link": "http://arxiv.org/abs/2504.21326v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "How to Backdoor the Knowledge Distillation", "abstract": "Knowledge distillation has become a cornerstone in modern machine learning\nsystems, celebrated for its ability to transfer knowledge from a large, complex\nteacher model to a more efficient student model. Traditionally, this process is\nregarded as secure, assuming the teacher model is clean. This belief stems from\nconventional backdoor attacks relying on poisoned training data with backdoor\ntriggers and attacker-chosen labels, which are not involved in the distillation\nprocess. Instead, knowledge distillation uses the outputs of a clean teacher\nmodel to guide the student model, inherently preventing recognition or response\nto backdoor triggers as intended by an attacker. In this paper, we challenge\nthis assumption by introducing a novel attack methodology that strategically\npoisons the distillation dataset with adversarial examples embedded with\nbackdoor triggers. This technique allows for the stealthy compromise of the\nstudent model while maintaining the integrity of the teacher model. Our\ninnovative approach represents the first successful exploitation of\nvulnerabilities within the knowledge distillation process using clean teacher\nmodels. Through extensive experiments conducted across various datasets and\nattack settings, we demonstrate the robustness, stealthiness, and effectiveness\nof our method. Our findings reveal previously unrecognized vulnerabilities and\npave the way for future research aimed at securing knowledge distillation\nprocesses against backdoor attacks.", "published": "2025-04-30 05:19:23", "link": "http://arxiv.org/abs/2504.21323v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Participatory AI, Public Sector AI, Differential Privacy, Conversational Interfaces, Explainable AI, Citizen Engagement in AI", "abstract": "This paper introduces a conversational interface system that enables\nparticipatory design of differentially private AI systems in public sector\napplications. Addressing the challenge of balancing mathematical privacy\nguarantees with democratic accountability, we propose three key contributions:\n(1) an adaptive $\\epsilon$-selection protocol leveraging TOPSIS multi-criteria\ndecision analysis to align citizen preferences with differential privacy (DP)\nparameters, (2) an explainable noise-injection framework featuring real-time\nMean Absolute Error (MAE) visualizations and GPT-4-powered impact analysis, and\n(3) an integrated legal-compliance mechanism that dynamically modulates privacy\nbudgets based on evolving regulatory constraints. Our results advance\nparticipatory AI practices by demonstrating how conversational interfaces can\nenhance public engagement in algorithmic privacy mechanisms, ensuring that\nprivacy-preserving AI in public sector governance remains both mathematically\nrobust and democratically accountable.", "published": "2025-04-30 04:10:50", "link": "http://arxiv.org/abs/2504.21297v1", "categories": ["cs.IT", "cs.AI", "cs.CY", "cs.ET", "math.IT"], "primary_category": "cs.IT"}
{"title": "Fairness in Graph Learning Augmented with Machine Learning: A Survey", "abstract": "Augmenting specialised machine learning techniques into traditional graph\nlearning models has achieved notable success across various domains, including\nfederated graph learning, dynamic graph learning, and graph transformers.\nHowever, the intricate mechanisms of these specialised techniques introduce\nsignificant challenges in maintaining model fairness, potentially resulting in\ndiscriminatory outcomes in high-stakes applications such as recommendation\nsystems, disaster response, criminal justice, and loan approval. This paper\nsystematically examines the unique fairness challenges posed by Graph Learning\naugmented with Machine Learning (GL-ML). It highlights the complex interplay\nbetween graph learning mechanisms and machine learning techniques, emphasising\nhow the augmentation of machine learning both enhances and complicates\nfairness. Additionally, we explore four critical techniques frequently employed\nto improve fairness in GL-ML methods. By thoroughly investigating the root\ncauses and broader implications of fairness challenges in this rapidly evolving\nfield, this work establishes a robust foundation for future research and\ninnovation in GL-ML fairness.", "published": "2025-04-30 04:02:23", "link": "http://arxiv.org/abs/2504.21296v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Orthogonal Factor-Based Biclustering Algorithm (BCBOF) for High-Dimensional Data and Its Application in Stock Trend Prediction", "abstract": "Biclustering is an effective technique in data mining and pattern\nrecognition. Biclustering algorithms based on traditional clustering face two\nfundamental limitations when processing high-dimensional data: (1) The distance\nconcentration phenomenon in high-dimensional spaces leads to data sparsity,\nrendering similarity measures ineffective; (2) Mainstream linear dimensionality\nreduction methods disrupt critical local structural patterns. To apply\nbiclustering to high-dimensional datasets, we propose an orthogonal\nfactor-based biclustering algorithm (BCBOF). First, we constructed orthogonal\nfactors in the vector space of the high-dimensional dataset. Then, we performed\nclustering using the coordinates of the original data in the orthogonal\nsubspace as clustering targets. Finally, we obtained biclustering results of\nthe original dataset. Since dimensionality reduction was applied before\nclustering, the proposed algorithm effectively mitigated the data sparsity\nproblem caused by high dimensionality. Additionally, we applied this\nbiclustering algorithm to stock technical indicator combinations and stock\nprice trend prediction. Biclustering results were transformed into fuzzy rules,\nand we incorporated profit-preserving and stop-loss rules into the rule set,\nultimately forming a fuzzy inference system for stock price trend predictions\nand trading signals. To evaluate the performance of BCBOF, we compared it with\nexisting biclustering methods using multiple evaluation metrics. The results\nshowed that our algorithm outperformed other biclustering techniques. To\nvalidate the effectiveness of the fuzzy inference system, we conducted virtual\ntrading experiments using historical data from 10 A-share stocks. The\nexperimental results showed that the generated trading strategies yielded\nhigher returns for investors.", "published": "2025-04-30 03:49:08", "link": "http://arxiv.org/abs/2504.21289v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models", "abstract": "The integration of reinforcement learning (RL) into the reasoning\ncapabilities of Multimodal Large Language Models (MLLMs) has rapidly emerged as\na transformative research direction. While MLLMs significantly extend Large\nLanguage Models (LLMs) to handle diverse modalities such as vision, audio, and\nvideo, enabling robust reasoning across multimodal inputs remains a major\nchallenge. This survey systematically reviews recent advances in RL-based\nreasoning for MLLMs, covering key algorithmic designs, reward mechanism\ninnovations, and practical applications. We highlight two main RL\nparadigms--value-free and value-based methods--and analyze how RL enhances\nreasoning abilities by optimizing reasoning trajectories and aligning\nmultimodal information. Furthermore, we provide an extensive overview of\nbenchmark datasets, evaluation protocols, and existing limitations, and propose\nfuture research directions to address current bottlenecks such as sparse\nrewards, inefficient cross-modal reasoning, and real-world deployment\nconstraints. Our goal is to offer a comprehensive and structured guide to\nresearchers interested in advancing RL-based reasoning in the multimodal era.", "published": "2025-04-30 03:14:28", "link": "http://arxiv.org/abs/2504.21277v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Assessing LLM code generation quality through path planning tasks", "abstract": "As LLM-generated code grows in popularity, more evaluation is needed to\nassess the risks of using such tools, especially for safety-critical\napplications such as path planning. Existing coding benchmarks are insufficient\nas they do not reflect the context and complexity of safety-critical\napplications. To this end, we assessed six LLMs' abilities to generate the code\nfor three different path-planning algorithms and tested them on three maps of\nvarious difficulties. Our results suggest that LLM-generated code presents\nserious hazards for path planning applications and should not be applied in\nsafety-critical contexts without rigorous testing.", "published": "2025-04-30 03:11:54", "link": "http://arxiv.org/abs/2504.21276v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Multi-Domain Causal Discovery in Bijective Causal Models", "abstract": "We consider the problem of causal discovery (a.k.a., causal structure\nlearning) in a multi-domain setting. We assume that the causal functions are\ninvariant across the domains, while the distribution of the exogenous noise may\nvary. Under causal sufficiency (i.e., no confounders exist), we show that the\ncausal diagram can be discovered under less restrictive functional assumptions\ncompared to previous work. What enables causal discovery in this setting is\nbijective generation mechanisms (BGM), which ensures that the functional\nrelation between the exogenous noise $E$ and the endogenous variable $Y$ is\nbijective and differentiable in both directions at every level of the cause\nvariable $X = x$. BGM generalizes a variety of models including additive noise\nmodel, LiNGAM, post-nonlinear model, and location-scale noise model. Further,\nwe derive a statistical test to find the parents set of the target variable.\nExperiments on various synthetic and real-world datasets validate our\ntheoretical findings.", "published": "2025-04-30 02:30:10", "link": "http://arxiv.org/abs/2504.21261v1", "categories": ["cs.LG", "cs.AI", "stat.ME"], "primary_category": "cs.LG"}
{"title": "Efficient Quantum-Safe Homomorphic Encryption for Quantum Computer Programs", "abstract": "We present a lattice-based scheme for homomorphic evaluation of quantum\nprograms and proofs that remains secure against quantum adversaries. Classical\nhomomorphic encryption is lifted to the quantum setting by replacing\ncomposite-order groups with Module Learning-With-Errors (MLWE) lattices and by\ngeneralizing polynomial functors to bounded natural super functors (BNSFs). A\nsecret depolarizing BNSF mask hides amplitudes, while each quantum state is\nstored as an MLWE ciphertext pair. We formalize security with the qIND-CPA game\nthat allows coherent access to the encryption oracle and give a four-hybrid\nreduction to decisional MLWE.\n  The design also covers practical issues usually left open. A typed QC-bridge\nkeeps classical bits produced by measurements encrypted yet still usable as\ncontrols, with weak-measurement semantics for expectation-value workloads.\nEncrypted Pauli twirls add circuit privacy. If a fixed knowledge base is\nneeded, its axioms are shipped as MLWE \"capsules\"; the evaluator can use them\nbut cannot read them. A rho-calculus driver schedules encrypted tasks across\nseveral QPUs and records an auditable trace on an RChain-style ledger.\n  Performance analysis shows that the extra lattice arithmetic fits inside\ntoday's QPU idle windows: a 100-qubit, depth-10^3 teleportation-based proof\nruns in about 10 ms, the public key (seed only) is 32 bytes, and even a\nCCA-level key stays below 300 kB. A photonic Dirac-3 prototype that executes\nhomomorphic teleportation plus knowledge-base-relative amplitude checks appears\nfeasible with current hardware. These results indicate that fully homomorphic,\nknowledge-base-aware quantum reasoning is compatible with near-term quantum\nclouds and standard post-quantum security assumptions.", "published": "2025-04-30 00:08:43", "link": "http://arxiv.org/abs/2504.21235v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "ReVision: High-Quality, Low-Cost Video Generation with Explicit 3D Physics Modeling for Complex Motion and Interaction", "abstract": "In recent years, video generation has seen significant advancements. However,\nchallenges still persist in generating complex motions and interactions. To\naddress these challenges, we introduce ReVision, a plug-and-play framework that\nexplicitly integrates parameterized 3D physical knowledge into a pretrained\nconditional video generation model, significantly enhancing its ability to\ngenerate high-quality videos with complex motion and interactions.\nSpecifically, ReVision consists of three stages. First, a video diffusion model\nis used to generate a coarse video. Next, we extract a set of 2D and 3D\nfeatures from the coarse video to construct a 3D object-centric representation,\nwhich is then refined by our proposed parameterized physical prior model to\nproduce an accurate 3D motion sequence. Finally, this refined motion sequence\nis fed back into the same video diffusion model as additional conditioning,\nenabling the generation of motion-consistent videos, even in scenarios\ninvolving complex actions and interactions. We validate the effectiveness of\nour approach on Stable Video Diffusion, where ReVision significantly improves\nmotion fidelity and coherence. Remarkably, with only 1.5B parameters, it even\noutperforms a state-of-the-art video generation model with over 13B parameters\non complex video generation by a substantial margin. Our results suggest that,\nby incorporating 3D physical knowledge, even a relatively small video diffusion\nmodel can generate complex motions and interactions with greater realism and\ncontrollability, offering a promising solution for physically plausible video\ngeneration.", "published": "2025-04-30 17:59:56", "link": "http://arxiv.org/abs/2504.21855v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Survey of Interactive Generative Video", "abstract": "Interactive Generative Video (IGV) has emerged as a crucial technology in\nresponse to the growing demand for high-quality, interactive video content\nacross various domains. In this paper, we define IGV as a technology that\ncombines generative capabilities to produce diverse high-quality video content\nwith interactive features that enable user engagement through control signals\nand responsive feedback. We survey the current landscape of IGV applications,\nfocusing on three major domains: 1) gaming, where IGV enables infinite\nexploration in virtual worlds; 2) embodied AI, where IGV serves as a\nphysics-aware environment synthesizer for training agents in multimodal\ninteraction with dynamically evolving scenes; and 3) autonomous driving, where\nIGV provides closed-loop simulation capabilities for safety-critical testing\nand validation. To guide future development, we propose a comprehensive\nframework that decomposes an ideal IGV system into five essential modules:\nGeneration, Control, Memory, Dynamics, and Intelligence. Furthermore, we\nsystematically analyze the technical challenges and future directions in\nrealizing each component for an ideal IGV system, such as achieving real-time\ngeneration, enabling open-domain control, maintaining long-term coherence,\nsimulating accurate physics, and integrating causal reasoning. We believe that\nthis systematic analysis will facilitate future research and development in the\nfield of IGV, ultimately advancing the technology toward more sophisticated and\npractical applications.", "published": "2025-04-30 17:59:02", "link": "http://arxiv.org/abs/2504.21853v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning", "abstract": "Multimodal Large Language Models (MLLMs) excel at simple vision-language\ntasks but struggle when faced with complex tasks that require multiple\ncapabilities, such as simultaneously recognizing objects, counting them, and\nunderstanding their spatial relationships. This might be partially the result\nof the fact that Visual Instruction Tuning (VIT), a critical training step for\nMLLMs, has traditionally focused on scaling data volume, but not the\ncompositional complexity of training examples. We propose COMPACT\n(COMPositional Atomic-to-complex visual Capability Tuning), which generates a\ntraining dataset explicitly controlling for the compositional complexity of the\ntraining examples. The data from COMPACT allows MLLMs to train on combinations\nof atomic capabilities to learn complex capabilities more efficiently. Across\nall benchmarks, COMPACT achieves comparable performance to the LLaVA-665k VIT\nwhile using less than 10% of its data budget, and even outperforms it on\nseveral, especially those involving complex multi-capability tasks. For\nexample, COMPACT achieves substantial 83.3% improvement on MMStar and 94.0%\nimprovement on MM-Vet compared to the full-scale VIT on particularly complex\nquestions that require four or more atomic capabilities. COMPACT offers a\nscalable, data-efficient, visual compositional tuning recipe to improve on\ncomplex visual-language tasks.", "published": "2025-04-30 17:57:22", "link": "http://arxiv.org/abs/2504.21850v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Differentiable Room Acoustic Rendering with Multi-View Vision Priors", "abstract": "An immersive acoustic experience enabled by spatial audio is just as crucial\nas the visual aspect in creating realistic virtual environments. However,\nexisting methods for room impulse response estimation rely either on\ndata-demanding learning-based models or computationally expensive physics-based\nmodeling. In this work, we introduce Audio-Visual Differentiable Room Acoustic\nRendering (AV-DAR), a framework that leverages visual cues extracted from\nmulti-view images and acoustic beam tracing for physics-based room acoustic\nrendering. Experiments across six real-world environments from two datasets\ndemonstrate that our multimodal, physics-based approach is efficient,\ninterpretable, and accurate, significantly outperforming a series of prior\nmethods. Notably, on the Real Acoustic Field dataset, AV-DAR achieves\ncomparable performance to models trained on 10 times more data while delivering\nrelative gains ranging from 16.6% to 50.9% when trained at the same scale.", "published": "2025-04-30 17:55:29", "link": "http://arxiv.org/abs/2504.21847v1", "categories": ["cs.CV", "cs.SD"], "primary_category": "cs.CV"}
{"title": "3D Stylization via Large Reconstruction Model", "abstract": "With the growing success of text or image guided 3D generators, users demand\nmore control over the generation process, appearance stylization being one of\nthem. Given a reference image, this requires adapting the appearance of a\ngenerated 3D asset to reflect the visual style of the reference while\nmaintaining visual consistency from multiple viewpoints. To tackle this\nproblem, we draw inspiration from the success of 2D stylization methods that\nleverage the attention mechanisms in large image generation models to capture\nand transfer visual style. In particular, we probe if large reconstruction\nmodels, commonly used in the context of 3D generation, has a similar\ncapability. We discover that the certain attention blocks in these models\ncapture the appearance specific features. By injecting features from a visual\nstyle image to such blocks, we develop a simple yet effective 3D appearance\nstylization method. Our method does not require training or test time\noptimization. Through both quantitative and qualitative evaluations, we\ndemonstrate that our approach achieves superior results in terms of 3D\nappearance stylization, significantly improving efficiency while maintaining\nhigh-quality visual outcomes.", "published": "2025-04-30 17:46:32", "link": "http://arxiv.org/abs/2504.21836v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Why Compress What You Can Generate? When GPT-4o Generation Ushers in Image Compression Fields", "abstract": "The rapid development of AIGC foundation models has revolutionized the\nparadigm of image compression, which paves the way for the abandonment of most\npixel-level transform and coding, compelling us to ask: why compress what you\ncan generate if the AIGC foundation model is powerful enough to faithfully\ngenerate intricate structure and fine-grained details from nothing more than\nsome compact descriptors, i.e., texts, or cues. Fortunately, recent GPT-4o\nimage generation of OpenAI has achieved impressive cross-modality generation,\nediting, and design capabilities, which motivates us to answer the above\nquestion by exploring its potential in image compression fields. In this work,\nwe investigate two typical compression paradigms: textual coding and multimodal\ncoding (i.e., text + extremely low-resolution image), where all/most\npixel-level information is generated instead of compressing via the advanced\nGPT-4o image generation function. The essential challenge lies in how to\nmaintain semantic and structure consistency during the decoding process. To\novercome this, we propose a structure raster-scan prompt engineering mechanism\nto transform the image into textual space, which is compressed as the condition\nof GPT-4o image generation. Extensive experiments have shown that the\ncombination of our designed structural raster-scan prompts and GPT-4o's image\ngeneration function achieved the impressive performance compared with recent\nmultimodal/generative image compression at ultra-low bitrate, further\nindicating the potential of AIGC generation in image compression fields.", "published": "2025-04-30 17:20:14", "link": "http://arxiv.org/abs/2504.21814v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A simple and effective approach for body part recognition on CT scans based on projection estimation", "abstract": "It is well known that machine learning models require a high amount of\nannotated data to obtain optimal performance. Labelling Computed Tomography\n(CT) data can be a particularly challenging task due to its volumetric nature\nand often missing and$/$or incomplete associated meta-data. Even inspecting one\nCT scan requires additional computer software, or in the case of programming\nlanguages $-$ additional programming libraries. This study proposes a simple,\nyet effective approach based on 2D X-ray-like estimation of 3D CT scans for\nbody region identification. Although body region is commonly associated with\nthe CT scan, it often describes only the focused major body region neglecting\nother anatomical regions present in the observed CT. In the proposed approach,\nestimated 2D images were utilized to identify 14 distinct body regions,\nproviding valuable information for constructing a high-quality medical dataset.\nTo evaluate the effectiveness of the proposed method, it was compared against\n2.5D, 3D and foundation model (MI2) based approaches. Our approach outperformed\nthe others, where it came on top with statistical significance and F1-Score for\nthe best-performing model EffNet-B0 of 0.980 $\\pm$ 0.016 in comparison to the\n0.840 $\\pm$ 0.114 (2.5D DenseNet-161), 0.854 $\\pm$ 0.096 (3D VoxCNN), and 0.852\n$\\pm$ 0.104 (MI2 foundation model). The utilized dataset comprised three\ndifferent clinical centers and counted 15,622 CT scans (44,135 labels).", "published": "2025-04-30 17:13:44", "link": "http://arxiv.org/abs/2504.21810v1", "categories": ["cs.CV", "68T01, 65D19", "I.4.0; I.4.10; I.2.1"], "primary_category": "cs.CV"}
{"title": "Anomaly-Driven Approach for Enhanced Prostate Cancer Segmentation", "abstract": "Magnetic Resonance Imaging (MRI) plays an important role in identifying\nclinically significant prostate cancer (csPCa), yet automated methods face\nchallenges such as data imbalance, variable tumor sizes, and a lack of\nannotated data. This study introduces Anomaly-Driven U-Net (adU-Net), which\nincorporates anomaly maps derived from biparametric MRI sequences into a deep\nlearning-based segmentation framework to improve csPCa identification. We\nconduct a comparative analysis of anomaly detection methods and evaluate the\nintegration of anomaly maps into the segmentation pipeline. Anomaly maps,\ngenerated using Fixed-Point GAN reconstruction, highlight deviations from\nnormal prostate tissue, guiding the segmentation model to potential cancerous\nregions. We compare the performance by using the average score, computed as the\nmean of the AUROC and Average Precision (AP). On the external test set, adU-Net\nachieves the best average score of 0.618, outperforming the baseline nnU-Net\nmodel (0.605). The results demonstrate that incorporating anomaly detection\ninto segmentation improves generalization and performance, particularly with\nADC-based anomaly maps, offering a promising direction for automated csPCa\nidentification.", "published": "2025-04-30 16:48:00", "link": "http://arxiv.org/abs/2504.21789v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LoC-LIC: Low Complexity Learned Image Coding Using Hierarchical Feature Transforms", "abstract": "Current learned image compression models typically exhibit high complexity,\nwhich demands significant computational resources. To overcome these\nchallenges, we propose an innovative approach that employs hierarchical feature\nextraction transforms to significantly reduce complexity while preserving bit\nrate reduction efficiency. Our novel architecture achieves this by using fewer\nchannels for high spatial resolution inputs/feature maps. On the other hand,\nfeature maps with a large number of channels have reduced spatial dimensions,\nthereby cutting down on computational load without sacrificing performance.\nThis strategy effectively reduces the forward pass complexity from \\(1256 \\,\n\\text{kMAC/Pixel}\\) to just \\(270 \\, \\text{kMAC/Pixel}\\). As a result, the\nreduced complexity model can open the way for learned image compression models\nto operate efficiently across various devices and pave the way for the\ndevelopment of new architectures in image compression technology.", "published": "2025-04-30 16:30:06", "link": "http://arxiv.org/abs/2504.21778v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Anatomical Similarity as a New Metric to Evaluate Brain Generative Models", "abstract": "Generative models enhance neuroimaging through data augmentation, quality\nimprovement, and rare condition studies. Despite advances in realistic\nsynthetic MRIs, evaluations focus on texture and perception, lacking\nsensitivity to crucial anatomical fidelity. This study proposes a new metric,\ncalled WASABI (Wasserstein-Based Anatomical Brain Index), to assess the\nanatomical realism of synthetic brain MRIs. WASABI leverages \\textit{SynthSeg},\na deep learning-based brain parcellation tool, to derive volumetric measures of\nbrain regions in each MRI and uses the multivariate Wasserstein distance to\ncompare distributions between real and synthetic anatomies. Based on controlled\nexperiments on two real datasets and synthetic MRIs from five generative\nmodels, WASABI demonstrates higher sensitivity in quantifying anatomical\ndiscrepancies compared to traditional image-level metrics, even when synthetic\nimages achieve near-perfect visual quality. Our findings advocate for shifting\nthe evaluation paradigm beyond visual inspection and conventional metrics,\nemphasizing anatomical fidelity as a crucial benchmark for clinically\nmeaningful brain MRI synthesis. Our code is available at\nhttps://github.com/BahramJafrasteh/wasabi-mri.", "published": "2025-04-30 16:16:14", "link": "http://arxiv.org/abs/2504.21771v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Common3D: Self-Supervised Learning of 3D Morphable Models for Common Objects in Neural Feature Space", "abstract": "3D morphable models (3DMMs) are a powerful tool to represent the possible\nshapes and appearances of an object category. Given a single test image, 3DMMs\ncan be used to solve various tasks, such as predicting the 3D shape, pose,\nsemantic correspondence, and instance segmentation of an object. Unfortunately,\n3DMMs are only available for very few object categories that are of particular\ninterest, like faces or human bodies, as they require a demanding 3D data\nacquisition and category-specific training process. In contrast, we introduce a\nnew method, Common3D, that learns 3DMMs of common objects in a fully\nself-supervised manner from a collection of object-centric videos. For this\npurpose, our model represents objects as a learned 3D template mesh and a\ndeformation field that is parameterized as an image-conditioned neural network.\nDifferent from prior works, Common3D represents the object appearance with\nneural features instead of RGB colors, which enables the learning of more\ngeneralizable representations through an abstraction from pixel intensities.\nImportantly, we train the appearance features using a contrastive objective by\nexploiting the correspondences defined through the deformable template mesh.\nThis leads to higher quality correspondence features compared to related works\nand a significantly improved model performance at estimating 3D object pose and\nsemantic correspondence. Common3D is the first completely self-supervised\nmethod that can solve various vision tasks in a zero-shot manner.", "published": "2025-04-30 15:42:23", "link": "http://arxiv.org/abs/2504.21749v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VividListener: Expressive and Controllable Listener Dynamics Modeling for Multi-Modal Responsive Interaction", "abstract": "Generating responsive listener head dynamics with nuanced emotions and\nexpressive reactions is crucial for practical dialogue modeling in various\nvirtual avatar animations. Previous studies mainly focus on the direct\nshort-term production of listener behavior. They overlook the fine-grained\ncontrol over motion variations and emotional intensity, especially in\nlong-sequence modeling. Moreover, the lack of long-term and large-scale paired\nspeaker-listener corpora including head dynamics and fine-grained\nmulti-modality annotations (e.g., text-based expression descriptions, emotional\nintensity) also limits the application of dialogue modeling.Therefore, we first\nnewly collect a large-scale multi-turn dataset of 3D dyadic conversation\ncontaining more than 1.4M valid frames for multi-modal responsive interaction,\ndubbed ListenerX. Additionally, we propose VividListener, a novel framework\nenabling fine-grained, expressive and controllable listener dynamics modeling.\nThis framework leverages multi-modal conditions as guiding principles for\nfostering coherent interactions between speakers and listeners.Specifically, we\ndesign the Responsive Interaction Module (RIM) to adaptively represent the\nmulti-modal interactive embeddings. RIM ensures the listener dynamics achieve\nfine-grained semantic coordination with textual descriptions and adjustments,\nwhile preserving expressive reaction with speaker behavior. Meanwhile, we\ndesign the Emotional Intensity Tags (EIT) for emotion intensity editing with\nmulti-modal information integration, applying to both text descriptions and\nlistener motion amplitude.Extensive experiments conducted on our newly\ncollected ListenerX dataset demonstrate that VividListener achieves\nstate-of-the-art performance, realizing expressive and controllable listener\ndynamics.", "published": "2025-04-30 15:05:12", "link": "http://arxiv.org/abs/2504.21718v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "REHEARSE-3D: A Multi-modal Emulated Rain Dataset for 3D Point Cloud De-raining", "abstract": "Sensor degradation poses a significant challenge in autonomous driving.\nDuring heavy rainfall, the interference from raindrops can adversely affect the\nquality of LiDAR point clouds, resulting in, for instance, inaccurate point\nmeasurements. This, in turn, can potentially lead to safety concerns if\nautonomous driving systems are not weather-aware, i.e., if they are unable to\ndiscern such changes. In this study, we release a new, large-scale, multi-modal\nemulated rain dataset, REHEARSE-3D, to promote research advancements in 3D\npoint cloud de-raining. Distinct from the most relevant competitors, our\ndataset is unique in several respects. First, it is the largest point-wise\nannotated dataset, and second, it is the only one with high-resolution LiDAR\ndata (LiDAR-256) enriched with 4D Radar point clouds logged in both daytime and\nnighttime conditions in a controlled weather environment. Furthermore,\nREHEARSE-3D involves rain-characteristic information, which is of significant\nvalue not only for sensor noise modeling but also for analyzing the impact of\nweather at a point level. Leveraging REHEARSE-3D, we benchmark raindrop\ndetection and removal in fused LiDAR and 4D Radar point clouds. Our\ncomprehensive study further evaluates the performance of various statistical\nand deep-learning models. Upon publication, the dataset and benchmark models\nwill be made publicly available at: https://sporsho.github.io/REHEARSE3D.", "published": "2025-04-30 14:43:38", "link": "http://arxiv.org/abs/2504.21699v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Visual Text Processing: A Comprehensive Review and Unified Evaluation", "abstract": "Visual text is a crucial component in both document and scene images,\nconveying rich semantic information and attracting significant attention in the\ncomputer vision community. Beyond traditional tasks such as text detection and\nrecognition, visual text processing has witnessed rapid advancements driven by\nthe emergence of foundation models, including text image reconstruction and\ntext image manipulation. Despite significant progress, challenges remain due to\nthe unique properties that differentiate text from general objects. Effectively\ncapturing and leveraging these distinct textual characteristics is essential\nfor developing robust visual text processing models. In this survey, we present\na comprehensive, multi-perspective analysis of recent advancements in visual\ntext processing, focusing on two key questions: (1) What textual features are\nmost suitable for different visual text processing tasks? (2) How can these\ndistinctive text features be effectively incorporated into processing\nframeworks? Furthermore, we introduce VTPBench, a new benchmark that\nencompasses a broad range of visual text processing datasets. Leveraging the\nadvanced visual quality assessment capabilities of multimodal large language\nmodels (MLLMs), we propose VTPScore, a novel evaluation metric designed to\nensure fair and reliable evaluation. Our empirical study with more than 20\nspecific models reveals substantial room for improvement in the current\ntechniques. Our aim is to establish this work as a fundamental resource that\nfosters future exploration and innovation in the dynamic field of visual text\nprocessing. The relevant repository is available at\nhttps://github.com/shuyansy/Visual-Text-Processing-survey.", "published": "2025-04-30 14:19:29", "link": "http://arxiv.org/abs/2504.21682v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HoloTime: Taming Video Diffusion Models for Panoramic 4D Scene Generation", "abstract": "The rapid advancement of diffusion models holds the promise of\nrevolutionizing the application of VR and AR technologies, which typically\nrequire scene-level 4D assets for user experience. Nonetheless, existing\ndiffusion models predominantly concentrate on modeling static 3D scenes or\nobject-level dynamics, constraining their capacity to provide truly immersive\nexperiences. To address this issue, we propose HoloTime, a framework that\nintegrates video diffusion models to generate panoramic videos from a single\nprompt or reference image, along with a 360-degree 4D scene reconstruction\nmethod that seamlessly transforms the generated panoramic video into 4D assets,\nenabling a fully immersive 4D experience for users. Specifically, to tame video\ndiffusion models for generating high-fidelity panoramic videos, we introduce\nthe 360World dataset, the first comprehensive collection of panoramic videos\nsuitable for downstream 4D scene reconstruction tasks. With this curated\ndataset, we propose Panoramic Animator, a two-stage image-to-video diffusion\nmodel that can convert panoramic images into high-quality panoramic videos.\nFollowing this, we present Panoramic Space-Time Reconstruction, which leverages\na space-time depth estimation method to transform the generated panoramic\nvideos into 4D point clouds, enabling the optimization of a holistic 4D\nGaussian Splatting representation to reconstruct spatially and temporally\nconsistent 4D scenes. To validate the efficacy of our method, we conducted a\ncomparative analysis with existing approaches, revealing its superiority in\nboth panoramic video generation and 4D scene reconstruction. This demonstrates\nour method's capability to create more engaging and realistic immersive\nenvironments, thereby enhancing user experiences in VR and AR applications.", "published": "2025-04-30 13:55:28", "link": "http://arxiv.org/abs/2504.21650v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diffusion-based Adversarial Identity Manipulation for Facial Privacy Protection", "abstract": "The success of face recognition (FR) systems has led to serious privacy\nconcerns due to potential unauthorized surveillance and user tracking on social\nnetworks. Existing methods for enhancing privacy fail to generate natural face\nimages that can protect facial privacy. In this paper, we propose\ndiffusion-based adversarial identity manipulation (DiffAIM) to generate natural\nand highly transferable adversarial faces against malicious FR systems. To be\nspecific, we manipulate facial identity within the low-dimensional latent space\nof a diffusion model. This involves iteratively injecting gradient-based\nadversarial identity guidance during the reverse diffusion process,\nprogressively steering the generation toward the desired adversarial faces. The\nguidance is optimized for identity convergence towards a target while promoting\nsemantic divergence from the source, facilitating effective impersonation while\nmaintaining visual naturalness. We further incorporate structure-preserving\nregularization to preserve facial structure consistency during manipulation.\nExtensive experiments on both face verification and identification tasks\ndemonstrate that compared with the state-of-the-art, DiffAIM achieves stronger\nblack-box attack transferability while maintaining superior visual quality. We\nalso demonstrate the effectiveness of the proposed approach for commercial FR\nAPIs, including Face++ and Aliyun.", "published": "2025-04-30 13:49:59", "link": "http://arxiv.org/abs/2504.21646v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mcity Data Engine: Iterative Model Improvement Through Open-Vocabulary Data Selection", "abstract": "With an ever-increasing availability of data, it has become more and more\nchallenging to select and label appropriate samples for the training of machine\nlearning models. It is especially difficult to detect long-tail classes of\ninterest in large amounts of unlabeled data. This holds especially true for\nIntelligent Transportation Systems (ITS), where vehicle fleets and roadside\nperception systems generate an abundance of raw data. While industrial,\nproprietary data engines for such iterative data selection and model training\nprocesses exist, researchers and the open-source community suffer from a lack\nof an openly available system. We present the Mcity Data Engine, which provides\nmodules for the complete data-based development cycle, beginning at the data\nacquisition phase and ending at the model deployment stage. The Mcity Data\nEngine focuses on rare and novel classes through an open-vocabulary data\nselection process. All code is publicly available on GitHub under an MIT\nlicense: https://github.com/mcity/mcity_data_engine", "published": "2025-04-30 13:10:59", "link": "http://arxiv.org/abs/2504.21614v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cascade Detector Analysis and Application to Biomedical Microscopy", "abstract": "As both computer vision models and biomedical datasets grow in size, there is\nan increasing need for efficient inference algorithms. We utilize cascade\ndetectors to efficiently identify sparse objects in multiresolution images.\nGiven an object's prevalence and a set of detectors at different resolutions\nwith known accuracies, we derive the accuracy, and expected number of\nclassifier calls by a cascade detector. These results generalize across number\nof dimensions and number of cascade levels. Finally, we compare one- and\ntwo-level detectors in fluorescent cell detection, organelle segmentation, and\ntissue segmentation across various microscopy modalities. We show that the\nmulti-level detector achieves comparable performance in 30-75% less time. Our\nwork is compatible with a variety of computer vision models and data domains.", "published": "2025-04-30 12:58:30", "link": "http://arxiv.org/abs/2504.21598v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Iterative Trajectory Exploration for Multimodal Agents", "abstract": "Multimodal agents, which integrate a controller (e.g., a large language\nmodel) with external tools, have demonstrated remarkable capabilities in\ntackling complex tasks. However, existing agents need to collect a large number\nof expert data for fine-tuning to adapt to new environments. In this paper, we\npropose an online self-exploration method for multimodal agents, namely SPORT,\nvia step-wise preference optimization to refine the trajectories of agents,\nwhich automatically generates tasks and learns from solving the generated\ntasks, without any expert annotation. SPORT operates through four iterative\ncomponents: task synthesis, step sampling, step verification, and preference\ntuning. First, we synthesize multi-modal tasks using language models. Then, we\nintroduce a novel search scheme, where step sampling and step verification are\nexecuted alternately to solve each generated task. We employ a verifier to\nprovide AI feedback to construct step-wise preference data. The data is\nsubsequently used to update the controller's policy through preference tuning,\nproducing a SPORT Agent. By interacting with real environments, the SPORT Agent\nevolves into a more refined and capable system. Evaluation in the GTA and GAIA\nbenchmarks show that the SPORT Agent achieves 6.41\\% and 3.64\\% improvements,\nunderscoring the generalization and effectiveness introduced by our method. The\nproject page is https://SPORT-Agents.github.io.", "published": "2025-04-30 12:01:27", "link": "http://arxiv.org/abs/2504.21561v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SAM4EM: Efficient memory-based two stage prompt-free segment anything model adapter for complex 3D neuroscience electron microscopy stacks", "abstract": "We present SAM4EM, a novel approach for 3D segmentation of complex neural\nstructures in electron microscopy (EM) data by leveraging the Segment Anything\nModel (SAM) alongside advanced fine-tuning strategies. Our contributions\ninclude the development of a prompt-free adapter for SAM using two stage mask\ndecoding to automatically generate prompt embeddings, a dual-stage fine-tuning\nmethod based on Low-Rank Adaptation (LoRA) for enhancing segmentation with\nlimited annotated data, and a 3D memory attention mechanism to ensure\nsegmentation consistency across 3D stacks. We further release a unique\nbenchmark dataset for the segmentation of astrocytic processes and synapses. We\nevaluated our method on challenging neuroscience segmentation benchmarks,\nspecifically targeting mitochondria, glia, and synapses, with significant\naccuracy improvements over state-of-the-art (SOTA) methods, including recent\nSAM-based adapters developed for the medical domain and other vision\ntransformer-based approaches. Experimental results indicate that our approach\noutperforms existing solutions in the segmentation of complex processes like\nglia and post-synaptic densities. Our code and models are available at\nhttps://github.com/Uzshah/SAM4EM.", "published": "2025-04-30 11:38:02", "link": "http://arxiv.org/abs/2504.21544v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RoboGround: Robotic Manipulation with Grounded Vision-Language Priors", "abstract": "Recent advancements in robotic manipulation have highlighted the potential of\nintermediate representations for improving policy generalization. In this work,\nwe explore grounding masks as an effective intermediate representation,\nbalancing two key advantages: (1) effective spatial guidance that specifies\ntarget objects and placement areas while also conveying information about\nobject shape and size, and (2) broad generalization potential driven by\nlarge-scale vision-language models pretrained on diverse grounding datasets. We\nintroduce RoboGround, a grounding-aware robotic manipulation system that\nleverages grounding masks as an intermediate representation to guide policy\nnetworks in object manipulation tasks. To further explore and enhance\ngeneralization, we propose an automated pipeline for generating large-scale,\nsimulated data with a diverse set of objects and instructions. Extensive\nexperiments show the value of our dataset and the effectiveness of grounding\nmasks as intermediate guidance, significantly enhancing the generalization\nabilities of robot policies.", "published": "2025-04-30 11:26:40", "link": "http://arxiv.org/abs/2504.21530v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "MagicPortrait: Temporally Consistent Face Reenactment with 3D Geometric Guidance", "abstract": "In this paper, we propose a method for video face reenactment that integrates\na 3D face parametric model into a latent diffusion framework, aiming to improve\nshape consistency and motion control in existing video-based face generation\napproaches. Our approach employs the FLAME (Faces Learned with an Articulated\nModel and Expressions) model as the 3D face parametric representation,\nproviding a unified framework for modeling face expressions and head pose. This\nenables precise extraction of detailed face geometry and motion features from\ndriving videos. Specifically, we enhance the latent diffusion model with rich\n3D expression and detailed pose information by incorporating depth maps, normal\nmaps, and rendering maps derived from FLAME sequences. A multi-layer face\nmovements fusion module with integrated self-attention mechanisms is used to\ncombine identity and motion latent features within the spatial domain. By\nutilizing the 3D face parametric model as motion guidance, our method enables\nparametric alignment of face identity between the reference image and the\nmotion captured from the driving video. Experimental results on benchmark\ndatasets show that our method excels at generating high-quality face animations\nwith precise expression and head pose variation modeling. In addition, it\ndemonstrates strong generalization performance on out-of-domain images. Code is\npublicly available at https://github.com/weimengting/MagicPortrait.", "published": "2025-04-30 10:30:46", "link": "http://arxiv.org/abs/2504.21497v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Consistency-aware Fake Videos Detection on Short Video Platforms", "abstract": "This paper focuses to detect the fake news on the short video platforms.\nWhile significant research efforts have been devoted to this task with notable\nprogress in recent years, current detection accuracy remains suboptimal due to\nthe rapid evolution of content manipulation and generation technologies.\nExisting approaches typically employ a cross-modal fusion strategy that\ndirectly combines raw video data with metadata inputs before applying a\nclassification layer. However, our empirical observations reveal a critical\noversight: manipulated content frequently exhibits inter-modal inconsistencies\nthat could serve as valuable discriminative features, yet remain underutilized\nin contemporary detection frameworks. Motivated by this insight, we propose a\nnovel detection paradigm that explicitly identifies and leverages cross-modal\ncontradictions as discriminative cues. Our approach consists of two core\nmodules: Cross-modal Consistency Learning (CMCL) and Multi-modal Collaborative\nDiagnosis (MMCD). CMCL includes Pseudo-label Generation (PLG) and Cross-modal\nConsistency Diagnosis (CMCD). In PLG, a Multimodal Large Language Model is used\nto generate pseudo-labels for evaluating cross-modal semantic consistency.\nThen, CMCD extracts [CLS] tokens and computes cosine loss to quantify\ncross-modal inconsistencies. MMCD further integrates multimodal features\nthrough Multimodal Feature Fusion (MFF) and Probability Scores Fusion (PSF).\nMFF employs a co-attention mechanism to enhance semantic interactions across\ndifferent modalities, while a Transformer is utilized for comprehensive feature\nfusion. Meanwhile, PSF further integrates the fake news probability scores\nobtained in the previous step. Extensive experiments on established benchmarks\n(FakeSV and FakeTT) demonstrate our model exhibits outstanding performance in\nFake videos detection.", "published": "2025-04-30 10:26:04", "link": "http://arxiv.org/abs/2504.21495v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "DGSolver: Diffusion Generalist Solver with Universal Posterior Sampling for Image Restoration", "abstract": "Diffusion models have achieved remarkable progress in universal image\nrestoration. While existing methods speed up inference by reducing sampling\nsteps, substantial step intervals often introduce cumulative errors. Moreover,\nthey struggle to balance the commonality of degradation representations and\nrestoration quality. To address these challenges, we introduce\n\\textbf{DGSolver}, a diffusion generalist solver with universal posterior\nsampling. We first derive the exact ordinary differential equations for\ngeneralist diffusion models and tailor high-order solvers with a queue-based\naccelerated sampling strategy to improve both accuracy and efficiency. We then\nintegrate universal posterior sampling to better approximate\nmanifold-constrained gradients, yielding a more accurate noise estimation and\ncorrecting errors in inverse inference. Extensive experiments show that\nDGSolver outperforms state-of-the-art methods in restoration accuracy,\nstability, and scalability, both qualitatively and quantitatively. Code and\nmodels will be available at https://github.com/MiliLab/DGSolver.", "published": "2025-04-30 10:12:48", "link": "http://arxiv.org/abs/2504.21487v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CAE-DFKD: Bridging the Transferability Gap in Data-Free Knowledge Distillation", "abstract": "Data-Free Knowledge Distillation (DFKD) enables the knowledge transfer from\nthe given pre-trained teacher network to the target student model without\naccess to the real training data. Existing DFKD methods focus primarily on\nimproving image recognition performance on associated datasets, often\nneglecting the crucial aspect of the transferability of learned\nrepresentations. In this paper, we propose Category-Aware Embedding Data-Free\nKnowledge Distillation (CAE-DFKD), which addresses at the embedding level the\nlimitations of previous rely on image-level methods to improve model\ngeneralization but fail when directly applied to DFKD. The superiority and\nflexibility of CAE-DFKD are extensively evaluated, including:\n\\textit{\\textbf{i.)}} Significant efficiency advantages resulting from altering\nthe generator training paradigm; \\textit{\\textbf{ii.)}} Competitive performance\nwith existing DFKD state-of-the-art methods on image recognition tasks;\n\\textit{\\textbf{iii.)}} Remarkable transferability of data-free learned\nrepresentations demonstrated in downstream tasks.", "published": "2025-04-30 09:58:02", "link": "http://arxiv.org/abs/2504.21478v1", "categories": ["cs.CV", "cs.NE"], "primary_category": "cs.CV"}
{"title": "Robust Orthogonal NMF with Label Propagation for Image Clustering", "abstract": "Non-negative matrix factorization (NMF) is a popular unsupervised learning\napproach widely used in image clustering. However, in real-world clustering\nscenarios, most existing NMF methods are highly sensitive to noise corruption\nand are unable to effectively leverage limited supervised information. To\novercome these drawbacks, we propose a unified non-convex framework with label\npropagation called robust orthogonal nonnegative matrix factorization (RONMF).\nThis method not only considers the graph Laplacian and label propagation as\nregularization terms but also introduces a more effective non-convex structure\nto measure the reconstruction error and imposes orthogonal constraints on the\nbasis matrix to reduce the noise corruption, thereby achieving higher\nrobustness. To solve RONMF, we develop an alternating direction method of\nmultipliers (ADMM)-based optimization algorithm. In particular, all subproblems\nhave closed-form solutions, which ensures its efficiency. Experimental\nevaluations on eight public image datasets demonstrate that the proposed RONMF\noutperforms state-of-the-art NMF methods across various standard metrics and\nshows excellent robustness. The code will be available at\nhttps://github.com/slinda-liu.", "published": "2025-04-30 09:49:55", "link": "http://arxiv.org/abs/2504.21472v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Quaternion Nuclear Norms Over Frobenius Norms Minimization for Robust Matrix Completion", "abstract": "Recovering hidden structures from incomplete or noisy data remains a\npervasive challenge across many fields, particularly where multi-dimensional\ndata representation is essential. Quaternion matrices, with their ability to\nnaturally model multi-dimensional data, offer a promising framework for this\nproblem. This paper introduces the quaternion nuclear norm over the Frobenius\nnorm (QNOF) as a novel nonconvex approximation for the rank of quaternion\nmatrices. QNOF is parameter-free and scale-invariant. Utilizing quaternion\nsingular value decomposition, we prove that solving the QNOF can be simplified\nto solving the singular value $L_1/L_2$ problem. Additionally, we extend the\nQNOF to robust quaternion matrix completion, employing the alternating\ndirection multiplier method to derive solutions that guarantee weak convergence\nunder mild conditions. Extensive numerical experiments validate the proposed\nmodel's superiority, consistently outperforming state-of-the-art quaternion\nmethods.", "published": "2025-04-30 09:44:09", "link": "http://arxiv.org/abs/2504.21468v1", "categories": ["cs.CV", "65F35, 90C30, 94A08, 68U10"], "primary_category": "cs.CV"}
{"title": "Multiview Point Cloud Registration via Optimization in an Autoencoder Latent Space", "abstract": "Point cloud rigid registration is a fundamental problem in 3D computer\nvision. In the multiview case, we aim to find a set of 6D poses to align a set\nof objects. Methods based on pairwise registration rely on a subsequent\nsynchronization algorithm, which makes them poorly scalable with the number of\nviews. Generative approaches overcome this limitation, but are based on\nGaussian Mixture Models and use an Expectation-Maximization algorithm. Hence,\nthey are not well suited to handle large transformations. Moreover, most\nexisting methods cannot handle high levels of degradations. In this paper, we\nintroduce POLAR (POint cloud LAtent Registration), a multiview registration\nmethod able to efficiently deal with a large number of views, while being\nrobust to a high level of degradations and large initial angles. To achieve\nthis, we transpose the registration problem into the latent space of a\npretrained autoencoder, design a loss taking degradations into account, and\ndevelop an efficient multistart optimization strategy. Our proposed method\nsignificantly outperforms state-of-the-art approaches on synthetic and real\ndata. POLAR is available at github.com/pypolar/polar or as a standalone package\nwhich can be installed with pip install polaregistration.", "published": "2025-04-30 09:42:38", "link": "http://arxiv.org/abs/2504.21467v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VR-FuseNet: A Fusion of Heterogeneous Fundus Data and Explainable Deep Network for Diabetic Retinopathy Classification", "abstract": "Diabetic retinopathy is a severe eye condition caused by diabetes where the\nretinal blood vessels get damaged and can lead to vision loss and blindness if\nnot treated. Early and accurate detection is key to intervention and stopping\nthe disease progressing. For addressing this disease properly, this paper\npresents a comprehensive approach for automated diabetic retinopathy detection\nby proposing a new hybrid deep learning model called VR-FuseNet. Diabetic\nretinopathy is a major eye disease and leading cause of blindness especially\namong diabetic patients so accurate and efficient automated detection methods\nare required. To address the limitations of existing methods including dataset\nimbalance, diversity and generalization issues this paper presents a hybrid\ndataset created from five publicly available diabetic retinopathy datasets.\nEssential preprocessing techniques such as SMOTE for class balancing and CLAHE\nfor image enhancement are applied systematically to the dataset to improve the\nrobustness and generalizability of the dataset. The proposed VR-FuseNet model\ncombines the strengths of two state-of-the-art convolutional neural networks,\nVGG19 which captures fine-grained spatial features and ResNet50V2 which is\nknown for its deep hierarchical feature extraction. This fusion improves the\ndiagnostic performance and achieves an accuracy of 91.824%. The model\noutperforms individual architectures on all performance metrics demonstrating\nthe effectiveness of hybrid feature extraction in Diabetic Retinopathy\nclassification tasks. To make the proposed model more clinically useful and\ninterpretable this paper incorporates multiple XAI techniques. These techniques\ngenerate visual explanations that clearly indicate the retinal features\naffecting the model's prediction such as microaneurysms, hemorrhages and\nexudates so that clinicians can interpret and validate.", "published": "2025-04-30 09:38:47", "link": "http://arxiv.org/abs/2504.21464v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UAV-VLN: End-to-End Vision Language guided Navigation for UAVs", "abstract": "A core challenge in AI-guided autonomy is enabling agents to navigate\nrealistically and effectively in previously unseen environments based on\nnatural language commands. We propose UAV-VLN, a novel end-to-end\nVision-Language Navigation (VLN) framework for Unmanned Aerial Vehicles (UAVs)\nthat seamlessly integrates Large Language Models (LLMs) with visual perception\nto facilitate human-interactive navigation. Our system interprets free-form\nnatural language instructions, grounds them into visual observations, and plans\nfeasible aerial trajectories in diverse environments.\n  UAV-VLN leverages the common-sense reasoning capabilities of LLMs to parse\nhigh-level semantic goals, while a vision model detects and localizes\nsemantically relevant objects in the environment. By fusing these modalities,\nthe UAV can reason about spatial relationships, disambiguate references in\nhuman instructions, and plan context-aware behaviors with minimal task-specific\nsupervision. To ensure robust and interpretable decision-making, the framework\nincludes a cross-modal grounding mechanism that aligns linguistic intent with\nvisual context.\n  We evaluate UAV-VLN across diverse indoor and outdoor navigation scenarios,\ndemonstrating its ability to generalize to novel instructions and environments\nwith minimal task-specific training. Our results show significant improvements\nin instruction-following accuracy and trajectory efficiency, highlighting the\npotential of LLM-driven vision-language interfaces for safe, intuitive, and\ngeneralizable UAV autonomy.", "published": "2025-04-30 08:40:47", "link": "http://arxiv.org/abs/2504.21432v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Diff-Prompt: Diffusion-Driven Prompt Generator with Mask Supervision", "abstract": "Prompt learning has demonstrated promising results in fine-tuning pre-trained\nmultimodal models. However, the performance improvement is limited when applied\nto more complex and fine-grained tasks. The reason is that most existing\nmethods directly optimize the parameters involved in the prompt generation\nprocess through loss backpropagation, which constrains the richness and\nspecificity of the prompt representations. In this paper, we propose\nDiffusion-Driven Prompt Generator (Diff-Prompt), aiming to use the diffusion\nmodel to generate rich and fine-grained prompt information for complex\ndownstream tasks. Specifically, our approach consists of three stages. In the\nfirst stage, we train a Mask-VAE to compress the masks into latent space. In\nthe second stage, we leverage an improved Diffusion Transformer (DiT) to train\na prompt generator in the latent space, using the masks for supervision. In the\nthird stage, we align the denoising process of the prompt generator with the\npre-trained model in the semantic space, and use the generated prompts to\nfine-tune the model. We conduct experiments on a complex pixel-level downstream\ntask, referring expression comprehension, and compare our method with various\nparameter-efficient fine-tuning approaches. Diff-Prompt achieves a maximum\nimprovement of 8.87 in R@1 and 14.05 in R@5 compared to the foundation model\nand also outperforms other state-of-the-art methods across multiple metrics.\nThe experimental results validate the effectiveness of our approach and\nhighlight the potential of using generative models for prompt generation. Code\nis available at https://github.com/Kelvin-ywc/diff-prompt.", "published": "2025-04-30 08:28:38", "link": "http://arxiv.org/abs/2504.21423v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adapting In-Domain Few-Shot Segmentation to New Domains without Retraining", "abstract": "Cross-domain few-shot segmentation (CD-FSS) aims to segment objects of novel\nclasses in new domains, which is often challenging due to the diverse\ncharacteristics of target domains and the limited availability of support data.\nMost CD-FSS methods redesign and retrain in-domain FSS models using various\ndomain-generalization techniques, which are effective but costly to train. To\naddress these issues, we propose adapting informative model structures of the\nwell-trained FSS model for target domains by learning domain characteristics\nfrom few-shot labeled support samples during inference, thereby eliminating the\nneed for retraining. Specifically, we first adaptively identify domain-specific\nmodel structures by measuring parameter importance using a novel structure\nFisher score in a data-dependent manner. Then, we progressively train the\nselected informative model structures with hierarchically constructed training\nsamples, progressing from fewer to more support shots. The resulting\nInformative Structure Adaptation (ISA) method effectively addresses domain\nshifts and equips existing well-trained in-domain FSS models with flexible\nadaptation capabilities for new domains, eliminating the need to redesign or\nretrain CD-FSS models on base data. Extensive experiments validate the\neffectiveness of our method, demonstrating superior performance across multiple\nCD-FSS benchmarks.", "published": "2025-04-30 08:16:33", "link": "http://arxiv.org/abs/2504.21414v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Static or Dynamic: Towards Query-Adaptive Token Selection for Video Question Answering", "abstract": "Video question answering benefits from the rich information available in\nvideos, enabling a wide range of applications. However, the large volume of\ntokens generated from longer videos presents significant challenges to memory\nefficiency and model performance. To alleviate this issue, existing works\npropose to compress video inputs, but usually overlooking the varying\nimportance of static and dynamic information across different queries, leading\nto inefficient token usage within limited budgets. To tackle this, we propose a\nnovel token selection strategy, EXPLORE-THEN-SELECT, that adaptively adjust\nstatic and dynamic information needed based on question requirements. Our\nframework first explores different token allocations between static frames,\nwhich preserve spatial details, and dynamic frames, which capture temporal\nchanges. Next, it employs a query-aware attention-based metric to select the\noptimal token combination without model updates. Our proposed framework is\nplug-and-play that can be seamlessly integrated within diverse video-language\nmodels. Extensive experiments show that our method achieves significant\nperformance improvements (up to 5.8%) among various video question answering\nbenchmarks.", "published": "2025-04-30 08:03:54", "link": "http://arxiv.org/abs/2504.21403v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Comparison of Different Deep Neural Network Models in the Cultural Heritage Domain", "abstract": "The integration of computer vision and deep learning is an essential part of\ndocumenting and preserving cultural heritage, as well as improving visitor\nexperiences. In recent years, two deep learning paradigms have been established\nin the field of computer vision: convolutional neural networks and transformer\narchitectures. The present study aims to make a comparative analysis of some\nrepresentatives of these two techniques of their ability to transfer knowledge\nfrom generic dataset, such as ImageNet, to cultural heritage specific tasks.\nThe results of testing examples of the architectures VGG, ResNet, DenseNet,\nVisual Transformer, Swin Transformer, and PoolFormer, showed that DenseNet is\nthe best in terms of efficiency-computability ratio.", "published": "2025-04-30 07:38:20", "link": "http://arxiv.org/abs/2504.21387v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "IDDM: Bridging Synthetic-to-Real Domain Gap from Physics-Guided Diffusion for Real-world Image Dehazing", "abstract": "Due to the domain gap between real-world and synthetic hazy images, current\ndata-driven dehazing algorithms trained on synthetic datasets perform well on\nsynthetic data but struggle to generalize to real-world scenarios. To address\nthis challenge, we propose \\textbf{I}mage \\textbf{D}ehazing \\textbf{D}iffusion\n\\textbf{M}odels (IDDM), a novel diffusion process that incorporates the\natmospheric scattering model into noise diffusion. IDDM aims to use the gradual\nhaze formation process to help the denoising Unet robustly learn the\ndistribution of clear images from the conditional input hazy images. We design\na specialized training strategy centered around IDDM. Diffusion models are\nleveraged to bridge the domain gap from synthetic to real-world, while the\natmospheric scattering model provides physical guidance for haze formation.\nDuring the forward process, IDDM simultaneously introduces haze and noise into\nclear images, and then robustly separates them during the sampling process. By\ntraining with physics-guided information, IDDM shows the ability of domain\ngeneralization, and effectively restores the real-world hazy images despite\nbeing trained on synthetic datasets. Extensive experiments demonstrate the\neffectiveness of our method through both quantitative and qualitative\ncomparisons with state-of-the-art approaches.", "published": "2025-04-30 07:36:10", "link": "http://arxiv.org/abs/2504.21385v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sparse-to-Sparse Training of Diffusion Models", "abstract": "Diffusion models (DMs) are a powerful type of generative models that have\nachieved state-of-the-art results in various image synthesis tasks and have\nshown potential in other domains, such as natural language processing and\ntemporal data modeling. Despite their stable training dynamics and ability to\nproduce diverse high-quality samples, DMs are notorious for requiring\nsignificant computational resources, both in the training and inference stages.\nPrevious work has focused mostly on increasing the efficiency of model\ninference. This paper introduces, for the first time, the paradigm of\nsparse-to-sparse training to DMs, with the aim of improving both training and\ninference efficiency. We focus on unconditional generation and train sparse DMs\nfrom scratch (Latent Diffusion and ChiroDiff) on six datasets using three\ndifferent methods (Static-DM, RigL-DM, and MagRan-DM) to study the effect of\nsparsity in model performance. Our experiments show that sparse DMs are able to\nmatch and often outperform their Dense counterparts, while substantially\nreducing the number of trainable parameters and FLOPs. We also identify safe\nand effective values to perform sparse-to-sparse training of DMs.", "published": "2025-04-30 07:28:11", "link": "http://arxiv.org/abs/2504.21380v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Towards Improved Cervical Cancer Screening: Vision Transformer-Based Classification and Interpretability", "abstract": "We propose a novel approach to cervical cell image classification for\ncervical cancer screening using the EVA-02 transformer model. We developed a\nfour-step pipeline: fine-tuning EVA-02, feature extraction, selecting important\nfeatures through multiple machine learning models, and training a new\nartificial neural network with optional loss weighting for improved\ngeneralization. With this design, our best model achieved an F1-score of\n0.85227, outperforming the baseline EVA-02 model (0.84878). We also utilized\nKernel SHAP analysis and identified key features correlating with cell\nmorphology and staining characteristics, providing interpretable insights into\nthe decision-making process of the fine-tuned model. Our code is available at\nhttps://github.com/Khoa-NT/isbi2025_ps3c.", "published": "2025-04-30 05:59:56", "link": "http://arxiv.org/abs/2504.21340v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "UniBiomed: A Universal Foundation Model for Grounded Biomedical Image Interpretation", "abstract": "Multi-modal interpretation of biomedical images opens up novel opportunities\nin biomedical image analysis. Conventional AI approaches typically rely on\ndisjointed training, i.e., Large Language Models (LLMs) for clinical text\ngeneration and segmentation models for target extraction, which results in\ninflexible real-world deployment and a failure to leverage holistic biomedical\ninformation. To this end, we introduce UniBiomed, the first universal\nfoundation model for grounded biomedical image interpretation. UniBiomed is\nbased on a novel integration of Multi-modal Large Language Model (MLLM) and\nSegment Anything Model (SAM), which effectively unifies the generation of\nclinical texts and the segmentation of corresponding biomedical objects for\ngrounded interpretation. In this way, UniBiomed is capable of tackling a wide\nrange of biomedical tasks across ten diverse biomedical imaging modalities. To\ndevelop UniBiomed, we curate a large-scale dataset comprising over 27 million\ntriplets of images, annotations, and text descriptions across ten imaging\nmodalities. Extensive validation on 84 internal and external datasets\ndemonstrated that UniBiomed achieves state-of-the-art performance in\nsegmentation, disease recognition, region-aware diagnosis, visual question\nanswering, and report generation. Moreover, unlike previous models that rely on\nclinical experts to pre-diagnose images and manually craft precise textual or\nvisual prompts, UniBiomed can provide automated and end-to-end grounded\ninterpretation for biomedical image analysis. This represents a novel paradigm\nshift in clinical workflows, which will significantly improve diagnostic\nefficiency. In summary, UniBiomed represents a novel breakthrough in biomedical\nAI, unlocking powerful grounded interpretation capabilities for more accurate\nand efficient biomedical image analysis.", "published": "2025-04-30 05:51:48", "link": "http://arxiv.org/abs/2504.21336v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Simple Visual Artifact Detection in Sora-Generated Videos", "abstract": "The December 2024 release of OpenAI's Sora, a powerful video generation model\ndriven by natural language prompts, highlights a growing convergence between\nlarge language models (LLMs) and video synthesis. As these multimodal systems\nevolve into video-enabled LLMs (VidLLMs), capable of interpreting, generating,\nand interacting with visual content, understanding their limitations and\nensuring their safe deployment becomes essential. This study investigates\nvisual artifacts frequently found and reported in Sora-generated videos, which\ncan compromise quality, mislead viewers, or propagate disinformation. We\npropose a multi-label classification framework targeting four common artifact\nlabel types: label 1: boundary / edge defects, label 2: texture / noise issues,\nlabel 3: movement / joint anomalies, and label 4: object mismatches /\ndisappearances. Using a dataset of 300 manually annotated frames extracted from\n15 Sora-generated videos, we trained multiple 2D CNN architectures (ResNet-50,\nEfficientNet-B3 / B4, ViT-Base). The best-performing model trained by ResNet-50\nachieved an average multi-label classification accuracy of 94.14%. This work\nsupports the broader development of VidLLMs by contributing to (1) the creation\nof datasets for video quality evaluation, (2) interpretable artifact-based\nanalysis beyond language metrics, and (3) the identification of visual risks\nrelevant to factuality and safety.", "published": "2025-04-30 05:41:43", "link": "http://arxiv.org/abs/2504.21334v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Space Group Determination from EBSD Patterns: The Role of Deep Learning and High-throughput Dynamical Simulations", "abstract": "The design of novel materials hinges on the understanding of\nstructure-property relationships. However, our capability to synthesize a large\nnumber of materials has outpaced the ability and speed needed to characterize\nthem. While the overall chemical constituents can be readily known during\nsynthesis, the structural evolution and characterization of newly synthesized\nsamples remains a bottleneck for the ultimate goal of high throughput\nnanomaterials discovery. Thus, scalable methods for crystal symmetry\ndetermination that can analyze a large volume of material samples within a\nshort time-frame are especially needed. Kikuchi diffraction in the SEM is a\npromising technique for this due to its sensitivity to dynamical scattering,\nwhich may provide information beyond just the seven crystal systems and\nfourteen Bravais lattices. After diffraction patterns are collected from\nmaterial samples, deep learning methods may be able to classify the space group\nsymmetries using the patterns as input, which paired with the elemental\ncomposition, would help enable the determination of the crystal structure. To\ninvestigate the feasibility of this solution, neural networks were trained to\npredict the space group type of background corrected EBSD patterns. Our\nnetworks were first trained and tested on an artificial dataset of EBSD\npatterns of 5,148 different cubic phases, created through physics-based\ndynamical simulations. Next, Maximum Classifier Discrepancy, an unsupervised\ndeep learning-based domain adaptation method, was utilized to train neural\nnetworks to make predictions for experimental EBSD patterns. We introduce a\nrelabeling scheme, which enables our models to achieve accuracy scores higher\nthan 90% on simulated and experimental data, suggesting that neural networks\nare capable of making predictions of crystal symmetry from an EBSD pattern.", "published": "2025-04-30 05:36:31", "link": "http://arxiv.org/abs/2504.21331v1", "categories": ["cond-mat.mtrl-sci", "cs.CV"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Text-Conditioned Diffusion Model for High-Fidelity Korean Font Generation", "abstract": "Automatic font generation (AFG) is the process of creating a new font using\nonly a few examples of the style images. Generating fonts for complex languages\nlike Korean and Chinese, particularly in handwritten styles, presents\nsignificant challenges. Traditional AFGs, like Generative adversarial networks\n(GANs) and Variational Auto-Encoders (VAEs), are usually unstable during\ntraining and often face mode collapse problems. They also struggle to capture\nfine details within font images. To address these problems, we present a\ndiffusion-based AFG method which generates high-quality, diverse Korean font\nimages using only a single reference image, focusing on handwritten and printed\nstyles. Our approach refines noisy images incrementally, ensuring stable\ntraining and visually appealing results. A key innovation is our text encoder,\nwhich processes phonetic representations to generate accurate and contextually\ncorrect characters, even for unseen characters. We used a pre-trained style\nencoder from DG FONT to effectively and accurately encode the style images. To\nfurther enhance the generation quality, we used perceptual loss that guides the\nmodel to focus on the global style of generated images. Experimental results on\nover 2000 Korean characters demonstrate that our model consistently generates\naccurate and detailed font images and outperforms benchmark methods, making it\na reliable tool for generating authentic Korean fonts across different styles.", "published": "2025-04-30 05:24:49", "link": "http://arxiv.org/abs/2504.21325v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "An Evaluation of a Visual Question Answering Strategy for Zero-shot Facial Expression Recognition in Still Images", "abstract": "Facial expression recognition (FER) is a key research area in computer vision\nand human-computer interaction. Despite recent advances in deep learning,\nchallenges persist, especially in generalizing to new scenarios. In fact,\nzero-shot FER significantly reduces the performance of state-of-the-art FER\nmodels. To address this problem, the community has recently started to explore\nthe integration of knowledge from Large Language Models for visual tasks. In\nthis work, we evaluate a broad collection of locally executed Visual Language\nModels (VLMs), avoiding the lack of task-specific knowledge by adopting a\nVisual Question Answering strategy. We compare the proposed pipeline with\nstate-of-the-art FER models, both integrating and excluding VLMs, evaluating\nwell-known FER benchmarks: AffectNet, FERPlus, and RAF-DB. The results show\nexcellent performance for some VLMs in zero-shot FER scenarios, indicating the\nneed for further exploration to improve FER generalization.", "published": "2025-04-30 04:38:05", "link": "http://arxiv.org/abs/2504.21309v1", "categories": ["cs.CV", "I.2.10"], "primary_category": "cs.CV"}
{"title": "AGHI-QA: A Subjective-Aligned Dataset and Metric for AI-Generated Human Images", "abstract": "The rapid development of text-to-image (T2I) generation approaches has\nattracted extensive interest in evaluating the quality of generated images,\nleading to the development of various quality assessment methods for\ngeneral-purpose T2I outputs. However, existing image quality assessment (IQA)\nmethods are limited to providing global quality scores, failing to deliver\nfine-grained perceptual evaluations for structurally complex subjects like\nhumans, which is a critical challenge considering the frequent anatomical and\ntextural distortions in AI-generated human images (AGHIs). To address this gap,\nwe introduce AGHI-QA, the first large-scale benchmark specifically designed for\nquality assessment of AGHIs. The dataset comprises 4,000 images generated from\n400 carefully crafted text prompts using 10 state of-the-art T2I models. We\nconduct a systematic subjective study to collect multidimensional annotations,\nincluding perceptual quality scores, text-image correspondence scores, visible\nand distorted body part labels. Based on AGHI-QA, we evaluate the strengths and\nweaknesses of current T2I methods in generating human images from multiple\ndimensions. Furthermore, we propose AGHI-Assessor, a novel quality metric that\nintegrates the large multimodal model (LMM) with domain-specific human features\nfor precise quality prediction and identification of visible and distorted body\nparts in AGHIs. Extensive experimental results demonstrate that AGHI-Assessor\nshowcases state-of-the-art performance, significantly outperforming existing\nIQA methods in multidimensional quality assessment and surpassing leading LMMs\nin detecting structural distortions in AGHIs.", "published": "2025-04-30 04:36:56", "link": "http://arxiv.org/abs/2504.21308v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "The Dual Power of Interpretable Token Embeddings: Jailbreaking Attacks and Defenses for Diffusion Model Unlearning", "abstract": "Despite the remarkable generalization capabilities of diffusion models,\nrecent studies have shown that these models can memorize and generate harmful\ncontent when prompted with specific text instructions. Although fine-tuning\napproaches have been developed to mitigate this issue by unlearning harmful\nconcepts, these methods can be easily circumvented through jailbreaking\nattacks. This indicates that the harmful concept has not been fully erased from\nthe model. However, existing attack methods, while effective, lack\ninterpretability regarding why unlearned models still retain the concept,\nthereby hindering the development of defense strategies. In this work, we\naddress these limitations by proposing an attack method that learns an\northogonal set of interpretable attack token embeddings. The attack token\nembeddings can be decomposed into human-interpretable textual elements,\nrevealing that unlearned models still retain the target concept through\nimplicit textual components. Furthermore, these attack token embeddings are\nrobust and transferable across text prompts, initial noises, and unlearned\nmodels. Finally, leveraging this diverse set of embeddings, we design a defense\nmethod applicable to both our proposed attack and existing attack methods.\nExperimental results demonstrate the effectiveness of both our attack and\ndefense strategies.", "published": "2025-04-30 04:33:43", "link": "http://arxiv.org/abs/2504.21307v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CMD: Constraining Multimodal Distribution for Domain Adaptation in Stereo Matching", "abstract": "Recently, learning-based stereo matching methods have achieved great\nimprovement in public benchmarks, where soft argmin and smooth L1 loss play a\ncore contribution to their success. However, in unsupervised domain adaptation\nscenarios, we observe that these two operations often yield multimodal\ndisparity probability distributions in target domains, resulting in degraded\ngeneralization. In this paper, we propose a novel approach, Constrain\nMulti-modal Distribution (CMD), to address this issue. Specifically, we\nintroduce \\textit{uncertainty-regularized minimization} and \\textit{anisotropic\nsoft argmin} to encourage the network to produce predominantly unimodal\ndisparity distributions in the target domain, thereby improving prediction\naccuracy. Experimentally, we apply the proposed method to multiple\nrepresentative stereo-matching networks and conduct domain adaptation from\nsynthetic data to unlabeled real-world scenes. Results consistently demonstrate\nimproved generalization in both top-performing and domain-adaptable\nstereo-matching models. The code for CMD will be available at:\n\\href{https://github.com/gallenszl/CMD}{https://github.com/gallenszl/CMD}.", "published": "2025-04-30 04:23:48", "link": "http://arxiv.org/abs/2504.21302v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Learning Multi-view Multi-class Anomaly Detection", "abstract": "The latest trend in anomaly detection is to train a unified model instead of\ntraining a separate model for each category. However, existing multi-class\nanomaly detection (MCAD) models perform poorly in multi-view scenarios because\nthey often fail to effectively model the relationships and complementary\ninformation among different views. In this paper, we introduce a Multi-View\nMulti-Class Anomaly Detection model (MVMCAD), which integrates information from\nmultiple views to accurately identify anomalies. Specifically, we propose a\nsemi-frozen encoder, where a pre-encoder prior enhancement mechanism is added\nbefore the frozen encoder, enabling stable cross-view feature modeling and\nefficient adaptation for improved anomaly detection. Furthermore, we propose an\nAnomaly Amplification Module (AAM) that models global token interactions and\nsuppresses normal regions to enhance anomaly signals, leading to improved\ndetection performance in multi-view settings. Finally, we propose a\nCross-Feature Loss that aligns shallow encoder features with deep decoder\nfeatures and vice versa, enhancing the model's sensitivity to anomalies at\ndifferent semantic levels under multi-view scenarios. Extensive experiments on\nthe Real-IAD dataset for multi-view multi-class anomaly detection validate the\neffectiveness of our approach, achieving state-of-the-art performance of\n91.0/88.6/82.1 and 99.1/43.9/48.2/95.2 for image-level and the pixel-level,\nrespectively.", "published": "2025-04-30 03:59:58", "link": "http://arxiv.org/abs/2504.21294v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Can We Achieve Efficient Diffusion without Self-Attention? Distilling Self-Attention into Convolutions", "abstract": "Contemporary diffusion models built upon U-Net or Diffusion Transformer (DiT)\narchitectures have revolutionized image generation through transformer-based\nattention mechanisms. The prevailing paradigm has commonly employed\nself-attention with quadratic computational complexity to handle global spatial\nrelationships in complex images, thereby synthesizing high-fidelity images with\ncoherent visual semantics.Contrary to conventional wisdom, our systematic\nlayer-wise analysis reveals an interesting discrepancy: self-attention in\npre-trained diffusion models predominantly exhibits localized attention\npatterns, closely resembling convolutional inductive biases. This suggests that\nglobal interactions in self-attention may be less critical than commonly\nassumed.Driven by this, we propose \\(\\Delta\\)ConvFusion to replace conventional\nself-attention modules with Pyramid Convolution Blocks\n(\\(\\Delta\\)ConvBlocks).By distilling attention patterns into localized\nconvolutional operations while keeping other components frozen,\n\\(\\Delta\\)ConvFusion achieves performance comparable to transformer-based\ncounterparts while reducing computational cost by 6929$\\times$ and surpassing\nLinFusion by 5.42$\\times$ in efficiency--all without compromising generative\nfidelity.", "published": "2025-04-30 03:57:28", "link": "http://arxiv.org/abs/2504.21292v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Mamba Based Feature Extraction And Adaptive Multilevel Feature Fusion For 3D Tumor Segmentation From Multi-modal Medical Image", "abstract": "Multi-modal 3D medical image segmentation aims to accurately identify tumor\nregions across different modalities, facing challenges from variations in image\nintensity and tumor morphology. Traditional convolutional neural network\n(CNN)-based methods struggle with capturing global features, while\nTransformers-based methods, despite effectively capturing global context,\nencounter high computational costs in 3D medical image segmentation. The Mamba\nmodel combines linear scalability with long-distance modeling, making it a\npromising approach for visual representation learning. However, Mamba-based 3D\nmulti-modal segmentation still struggles to leverage modality-specific features\nand fuse complementary information effectively. In this paper, we propose a\nMamba based feature extraction and adaptive multilevel feature fusion for 3D\ntumor segmentation using multi-modal medical image. We first develop the\nspecific modality Mamba encoder to efficiently extract long-range relevant\nfeatures that represent anatomical and pathological structures present in each\nmodality. Moreover, we design an bi-level synergistic integration block that\ndynamically merges multi-modal and multi-level complementary features by the\nmodality attention and channel attention learning. Lastly, the decoder combines\ndeep semantic information with fine-grained details to generate the tumor\nsegmentation map. Experimental results on medical image datasets (PET/CT and\nMRI multi-sequence) show that our approach achieve competitive performance\ncompared to the state-of-the-art CNN, Transformer, and Mamba-based approaches.", "published": "2025-04-30 03:29:55", "link": "http://arxiv.org/abs/2504.21281v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CoCoDiff: Diversifying Skeleton Action Features via Coarse-Fine Text-Co-Guided Latent Diffusion", "abstract": "In action recognition tasks, feature diversity is essential for enhancing\nmodel generalization and performance. Existing methods typically promote\nfeature diversity by expanding the training data in the sample space, which\noften leads to inefficiencies and semantic inconsistencies. To overcome these\nproblems, we propose a novel Coarse-fine text co-guidance Diffusion model\n(CoCoDiff). CoCoDiff generates diverse yet semantically consistent features in\nthe latent space by leveraging diffusion and multi-granularity textual\nguidance. Specifically, our approach feeds spatio-temporal features extracted\nfrom skeleton sequences into a latent diffusion model to generate diverse\naction representations. Meanwhile, we introduce a coarse-fine text co-guided\nstrategy that leverages textual information from large language models (LLMs)\nto ensure semantic consistency between the generated features and the original\ninputs. It is noted that CoCoDiff operates as a plug-and-play auxiliary module\nduring training, incurring no additional inference cost. Extensive experiments\ndemonstrate that CoCoDiff achieves SOTA performance on skeleton-based action\nrecognition benchmarks, including NTU RGB+D, NTU RGB+D 120 and\nKinetics-Skeleton.", "published": "2025-04-30 02:50:24", "link": "http://arxiv.org/abs/2504.21266v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Embracing Collaboration Over Competition: Condensing Multiple Prompts for Visual In-Context Learning", "abstract": "Visual In-Context Learning (VICL) enables adaptively solving vision tasks by\nleveraging pixel demonstrations, mimicking human-like task completion through\nanalogy. Prompt selection is critical in VICL, but current methods assume the\nexistence of a single \"ideal\" prompt in a pool of candidates, which in practice\nmay not hold true. Multiple suitable prompts may exist, but individually they\noften fall short, leading to difficulties in selection and the exclusion of\nuseful context. To address this, we propose a new perspective: prompt\ncondensation. Rather than relying on a single prompt, candidate prompts\ncollaborate to efficiently integrate informative contexts without sacrificing\nresolution. We devise Condenser, a lightweight external plugin that compresses\nrelevant fine-grained context across multiple prompts. Optimized end-to-end\nwith the backbone, Condenser ensures accurate integration of contextual cues.\nExperiments demonstrate Condenser outperforms state-of-the-arts across\nbenchmark tasks, showing superior context compression, scalability with more\nprompts, and enhanced computational efficiency compared to ensemble methods,\npositioning it as a highly competitive solution for VICL. Code is open-sourced\nat https://github.com/gimpong/CVPR25-Condenser.", "published": "2025-04-30 02:43:03", "link": "http://arxiv.org/abs/2504.21263v1", "categories": ["cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Multi-modal Transfer Learning for Dynamic Facial Emotion Recognition in the Wild", "abstract": "Facial expression recognition (FER) is a subset of computer vision with\nimportant applications for human-computer-interaction, healthcare, and customer\nservice. FER represents a challenging problem-space because accurate\nclassification requires a model to differentiate between subtle changes in\nfacial features. In this paper, we examine the use of multi-modal transfer\nlearning to improve performance on a challenging video-based FER dataset,\nDynamic Facial Expression in-the-Wild (DFEW). Using a combination of pretrained\nResNets, OpenPose, and OmniVec networks, we explore the impact of\ncross-temporal, multi-modal features on classification accuracy. Ultimately, we\nfind that these finely-tuned multi-modal feature generators modestly improve\naccuracy of our transformer-based classification model.", "published": "2025-04-30 01:09:11", "link": "http://arxiv.org/abs/2504.21248v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Subject Information Extraction for Novelty Detection with Domain Shifts", "abstract": "Unsupervised novelty detection (UND), aimed at identifying novel samples, is\nessential in fields like medical diagnosis, cybersecurity, and industrial\nquality control. Most existing UND methods assume that the training data and\ntesting normal data originate from the same domain and only consider the\ndistribution variation between training data and testing data. However, in real\nscenarios, it is common for normal testing and training data to originate from\ndifferent domains, a challenge known as domain shift. The discrepancies between\ntraining and testing data often lead to incorrect classification of normal data\nas novel by existing methods. A typical situation is that testing normal data\nand training data describe the same subject, yet they differ in the background\nconditions. To address this problem, we introduce a novel method that separates\nsubject information from background variation encapsulating the domain\ninformation to enhance detection performance under domain shifts. The proposed\nmethod minimizes the mutual information between the representations of the\nsubject and background while modelling the background variation using a deep\nGaussian mixture model, where the novelty detection is conducted on the subject\nrepresentations solely and hence is not affected by the variation of domains.\nExtensive experiments demonstrate that our model generalizes effectively to\nunseen domains and significantly outperforms baseline methods, especially under\nsubstantial domain shifts between training and testing data.", "published": "2025-04-30 01:04:55", "link": "http://arxiv.org/abs/2504.21247v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Normality of 8-Bit Bent Function", "abstract": "Bent functions are Boolean functions in an even number of variables that are\nindicators of Hadamard difference sets in elementary abelian 2-groups. A bent\nfunction in m variables is said to be normal if it is constant on an affine\nspace of dimension m/2. In this paper, we demonstrate that all bent functions\nin m = 8 variables -- whose exact count, determined by Langevin and Leander\n(Des. Codes Cryptogr. 59(1--3): 193--205, 2011), is approximately $2^106$ share\na common algebraic property: every 8-variable bent function is normal, up to\nthe addition of a linear function. With this result, we complete the analysis\nof the normality of bent functions for the last unresolvedcase, m= 8. It is\nalready known that all bent functions in m variables are normal for m <= 6,\nwhile for m > = 10, there exist bent functions that cannot be made normal by\nadding linear functions. Consequently, we provide a complete solution to an\nopen problem by Charpin (J. Complex. 20(2-3): 245-265, 2004)", "published": "2025-04-30 16:33:00", "link": "http://arxiv.org/abs/2504.21779v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Asymptotic Analysis of Weighted Fair Division", "abstract": "Several resource allocation settings involve agents with unequal entitlements\nrepresented by weights. We analyze weighted fair division from an asymptotic\nperspective: if $m$ items are divided among $n$ agents whose utilities are\nindependently sampled from a probability distribution, when is it likely that a\nfair allocation exist? We show that if the ratio between the weights is\nbounded, a weighted envy-free allocation exists with high probability provided\nthat $m = \\Omega(n\\log n/\\log\\log n)$, generalizing a prior unweighted result.\nFor weighted proportionality, we establish a sharp threshold of $m = n/(1-\\mu)$\nfor the transition from non-existence to existence, where $\\mu\\in (0,1)$\ndenotes the mean of the distribution. In addition, we prove that for two\nagents, a weighted envy-free (and weighted proportional) allocation is likely\nto exist if $m = \\omega(\\sqrt{r})$, where $r$ denotes the ratio between the two\nweights.", "published": "2025-04-30 15:20:10", "link": "http://arxiv.org/abs/2504.21728v1", "categories": ["cs.GT", "cs.DM", "math.PR"], "primary_category": "cs.GT"}
{"title": "Elimination Distance to Dominated Clusters", "abstract": "In the Dominated Cluster Deletion problem we are given an undirected graph\n$G$ and integers $k$ and $d$ and the question is to decide whether there exists\na set of at most $k$ vertices whose removal results in a graph in which each\nconnected component has a dominating set of size at most $d$. In the\nElimination Distance to Dominated Clusters problem we are again given an\nundirected graph $G$ and integers $k$ and $d$ and the question is to decide\nwhether we can recursively delete vertices up to depth $k$ such that each\nremaining connected component has a dominating set of size at most $d$. Bentert\net al.~[Bentert et al., MFCS 2024] recently provided an almost complete\nclassification of the parameterized complexity of Dominated Cluster Deletion\nwith respect to the parameters $k$, $d$, $c$, and $\\Delta$, where $c$ and\n$\\Delta$ are the degeneracy, and the maximum degree of the input graph,\nrespectively. In particular, they provided a non-uniform algorithm with running\ntime $f(k,d)\\cdot n^{O(d)}$. They left as an open problem whether the problem\nis fixed-parameter tractable with respect to the parameter $k+d+c$. We provide\na uniform algorithm running in time $f(k,d)\\cdot n^{O(d)}$ for both Dominated\nCluster Deletion and Elimination Distance to Dominated Clusters. We furthermore\nshow that both problems are FPT when parameterized by $k+d+\\ell$, where $\\ell$\nis the semi-ladder index of the input graph, a parameter that is upper bounded\nand may be much smaller than the degeneracy $c$, positively answering the open\nquestion of Bentert et al. We almost complete the picture by providing an\nalmost full classification for the parameterized complexity and kernelization\ncomplexity of Elimination Distance to Dominated Clusters. The one difficult\nbase case that remains open is whether treedepth (the case $d=0$) is NP-hard on\ngraphs of bounded maximum degree.", "published": "2025-04-30 14:15:41", "link": "http://arxiv.org/abs/2504.21675v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Efficient Decomposition of Forman-Ricci Curvature on Vietoris-Rips Complexes and Data Applications", "abstract": "Discrete Forman-Ricci curvature (FRC) is an efficient tool that characterizes\nessential geometrical features and associated transitions of real-world\nnetworks, extending seamlessly to higher-dimensional computations in simplicial\ncomplexes. In this article, we provide two major advancements: First, we give a\ndecomposition for FRC, enabling local computations of FRC. Second, we construct\na set-theoretical proof enabling an efficient algorithm for the local\ncomputation of FRC in Vietoris-Rips (VR) complexes.Strikingly, this approach\nreveals critical information and geometric insights often overlooked by\nconventional classification techniques. Our findings open new avenues for\ngeometric computations in VR complexes and highlight an essential yet\nunder-explored aspect of data classification: the geometry underpinning\nstatistical patterns.", "published": "2025-04-30 12:59:23", "link": "http://arxiv.org/abs/2504.21601v1", "categories": ["math.GT", "cs.CG", "cs.DM", "cs.DS", "math.CO", "05C85, 52C99, 90C35, 62R40, 68W99, 68T09"], "primary_category": "math.GT"}
{"title": "Concurrency Constrained Scheduling with Tree-Like Constraints", "abstract": "This paper investigates concurrency-constrained scheduling problems, where\nthe objective is to construct a schedule for a set of jobs subject to\nconcurrency restrictions. Formally, we are given a conflict graph $G$ defined\nover a set of $n$ jobs, where an edge between two jobs in $G$ indicates that\nthese jobs cannot be executed concurrently. Each job may have distinct\nattributes, such as processing time, due date, weight, and release time. The\ngoal is to determine a schedule that optimizes a specified scheduling criterion\nwhile adhering to all concurrency constraints. This framework offers a\nversatile model for analyzing resource allocation problems where processes\ncompete for shared resources, such as access to shared memory. From a\ntheoretical perspective, it encompasses several classical graph coloring\nproblems, including Chromatic Number, Sum Coloring, and Interval Chromatic\nNumber.\n  Given that even the simplest concurrency-constrained scheduling problems are\nNP-hard for general conflict graphs, this study focuses on conflict graphs with\nbounded treewidth. Our results establish a dichotomy: Some problems in this\nsetting can be solved in FPT time, while others are shown to be XALP-complete\nfor treewidth as parameter. Along the way, we generalize several previously\nknown results on coloring problems for bounded treewidth graphs. Several of the\nFPT algorithms are based on the insight that completion times are bounded by\nthe Grundy number of the conflict graph - the fact that this number is bounded\nby the product of treewidth and the logarithm of the number of vertices then\nleads to the FPT time bound.", "published": "2025-04-30 10:43:15", "link": "http://arxiv.org/abs/2504.21502v1", "categories": ["cs.DM", "cs.CC", "68Q25 (Primary) 90B35 (Secondary)"], "primary_category": "cs.DM"}
{"title": "Learning Universal User Representations Leveraging Cross-domain User Intent at Snapchat", "abstract": "The development of powerful user representations is a key factor in the\nsuccess of recommender systems (RecSys). Online platforms employ a range of\nRecSys techniques to personalize user experience across diverse in-app\nsurfaces. User representations are often learned individually through user's\nhistorical interactions within each surface and user representations across\ndifferent surfaces can be shared post-hoc as auxiliary features or additional\nretrieval sources. While effective, such schemes cannot directly encode\ncollaborative filtering signals across different surfaces, hindering its\ncapacity to discover complex relationships between user behaviors and\npreferences across the whole platform. To bridge this gap at Snapchat, we seek\nto conduct universal user modeling (UUM) across different in-app surfaces,\nlearning general-purpose user representations which encode behaviors across\nsurfaces. Instead of replacing domain-specific representations, UUM\nrepresentations capture cross-domain trends, enriching existing representations\nwith complementary information. This work discusses our efforts in developing\ninitial UUM versions, practical challenges, technical choices and modeling and\nresearch directions with promising offline performance. Following successful\nA/B testing, UUM representations have been launched in production, powering\nmultiple use cases and demonstrating their value. UUM embedding has been\nincorporated into (i) Long-form Video embedding-based retrieval, leading to\n2.78% increase in Long-form Video Open Rate, (ii) Long-form Video L2 ranking,\nwith 19.2% increase in Long-form Video View Time sum, (iii) Lens L2 ranking,\nleading to 1.76% increase in Lens play time, and (iv) Notification L2 ranking,\nwith 0.87% increase in Notification Open Rate.", "published": "2025-04-30 17:48:43", "link": "http://arxiv.org/abs/2504.21838v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Traceback of Poisoning Attacks to Retrieval-Augmented Generation", "abstract": "Large language models (LLMs) integrated with retrieval-augmented generation\n(RAG) systems improve accuracy by leveraging external knowledge sources.\nHowever, recent research has revealed RAG's susceptibility to poisoning\nattacks, where the attacker injects poisoned texts into the knowledge database,\nleading to attacker-desired responses. Existing defenses, which predominantly\nfocus on inference-time mitigation, have proven insufficient against\nsophisticated attacks. In this paper, we introduce RAGForensics, the first\ntraceback system for RAG, designed to identify poisoned texts within the\nknowledge database that are responsible for the attacks. RAGForensics operates\niteratively, first retrieving a subset of texts from the database and then\nutilizing a specially crafted prompt to guide an LLM in detecting potential\npoisoning texts. Empirical evaluations across multiple datasets demonstrate the\neffectiveness of RAGForensics against state-of-the-art poisoning attacks. This\nwork pioneers the traceback of poisoned texts in RAG systems, providing a\npractical and promising defense mechanism to enhance their security.", "published": "2025-04-30 14:10:02", "link": "http://arxiv.org/abs/2504.21668v1", "categories": ["cs.CR", "cs.IR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "From Precision to Perception: User-Centred Evaluation of Keyword Extraction Algorithms for Internet-Scale Contextual Advertising", "abstract": "Keyword extraction is a foundational task in natural language processing,\nunderpinning countless real-world applications. A salient example is contextual\nadvertising, where keywords help predict the topical congruence between ads and\ntheir surrounding media contexts to enhance advertising effectiveness. Recent\nadvances in artificial intelligence, particularly large language models, have\nimproved keyword extraction capabilities but also introduced concerns about\ncomputational cost. Moreover, although the end-user experience is of vital\nimportance, human evaluation of keyword extraction performances remains\nunder-explored. This study provides a comparative evaluation of three prevalent\nkeyword extraction algorithms that vary in complexity: TF-IDF, KeyBERT, and\nLlama 2. To evaluate their effectiveness, a mixed-methods approach is employed,\ncombining quantitative benchmarking with qualitative assessments from 552\nparticipants through three survey-based experiments. Findings indicate a slight\nuser preference for KeyBERT, which offers a favourable balance between\nperformance and computational efficiency compared to the other two algorithms.\nDespite a strong overall preference for gold-standard keywords, differences\nbetween the algorithmic outputs are not statistically significant, highlighting\na long-overlooked gap between traditional precision-focused metrics and\nuser-perceived algorithm efficiency. The study highlights the importance of\nuser-centred evaluation methodologies and proposes analytical tools to support\ntheir implementation.", "published": "2025-04-30 14:10:00", "link": "http://arxiv.org/abs/2504.21667v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Efficient Conversational Search via Topical Locality in Dense Retrieval", "abstract": "Pre-trained language models have been widely exploited to learn dense\nrepresentations of documents and queries for information retrieval. While\nprevious efforts have primarily focused on improving effectiveness and user\nsatisfaction, response time remains a critical bottleneck of conversational\nsearch systems. To address this, we exploit the topical locality inherent in\nconversational queries, i.e., the tendency of queries within a conversation to\nfocus on related topics. By leveraging query embedding similarities, we\ndynamically restrict the search space to semantically relevant document\nclusters, reducing computational complexity without compromising retrieval\nquality. We evaluate our approach on the TREC CAsT 2019 and 2020 datasets using\nmultiple embedding models and vector indexes, achieving improvements in\nprocessing speed of up to 10.4X with little loss in performance (4.4X without\nany loss). Our results show that the proposed system effectively handles\ncomplex, multiturn queries with high precision and efficiency, offering a\npractical solution for real-time conversational search.", "published": "2025-04-30 10:56:34", "link": "http://arxiv.org/abs/2504.21507v1", "categories": ["cs.IR", "cs.HC", "H.3"], "primary_category": "cs.IR"}
{"title": "In a Few Words: Comparing Weak Supervision and LLMs for Short Query Intent Classification", "abstract": "User intent classification is an important task in information retrieval.\nPreviously, user intents were classified manually and automatically; the latter\nhelped to avoid hand labelling of large datasets. Recent studies explored\nwhether LLMs can reliably determine user intent. However, researchers have\nrecognized the limitations of using generative LLMs for classification tasks.\nIn this study, we empirically compare user intent classification into\ninformational, navigational, and transactional categories, using weak\nsupervision and LLMs. Specifically, we evaluate LLaMA-3.1-8B-Instruct and\nLLaMA-3.1-70B-Instruct for in-context learning and LLaMA-3.1-8B-Instruct for\nfine-tuning, comparing their performance to an established baseline classifier\ntrained using weak supervision (ORCAS-I). Our results indicate that while LLMs\noutperform weak supervision in recall, they continue to struggle with\nprecision, which shows the need for improved methods to balance both metrics\neffectively.", "published": "2025-04-30 07:54:04", "link": "http://arxiv.org/abs/2504.21398v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Enhancing New-item Fairness in Dynamic Recommender Systems", "abstract": "New-items play a crucial role in recommender systems (RSs) for delivering\nfresh and engaging user experiences. However, traditional methods struggle to\neffectively recommend new-items due to their short exposure time and limited\ninteraction records, especially in dynamic recommender systems (DRSs) where\nnew-items get continuously introduced and users' preferences evolve over time.\nThis leads to significant unfairness towards new-items, which could accumulate\nover the successive model updates, ultimately compromising the stability of the\nentire system. Therefore, we propose FairAgent, a reinforcement learning\n(RL)-based new-item fairness enhancement framework specifically designed for\nDRSs. It leverages knowledge distillation to extract collaborative signals from\ntraditional models, retaining strong recommendation capabilities for old-items.\nIn addition, FairAgent introduces a novel reward mechanism for recommendation\ntailored to the characteristics of DRSs, which consists of three components: 1)\na new-item exploration reward to promote the exposure of dynamically introduced\nnew-items, 2) a fairness reward to adapt to users' personalized fairness\nrequirements for new-items, and 3) an accuracy reward which leverages users'\ndynamic feedback to enhance recommendation accuracy. Extensive experiments on\nthree public datasets and backbone models demonstrate the superior performance\nof FairAgent. The results present that FairAgent can effectively boost new-item\nexposure, achieve personalized new-item fairness, while maintaining high\nrecommendation accuracy.", "published": "2025-04-30 06:49:36", "link": "http://arxiv.org/abs/2504.21362v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Framework for Elastic Adaptation of User Multiple Intents in Sequential Recommendation", "abstract": "Recently, substantial research has been conducted on sequential\nrecommendation, with the objective of forecasting the subsequent item by\nleveraging a user's historical sequence of interacted items. Prior studies\nemploy both capsule networks and self-attention techniques to effectively\ncapture diverse underlying intents within a user's interaction sequence,\nthereby achieving the most advanced performance in sequential recommendation.\nHowever, users could potentially form novel intents from fresh interactions as\nthe lengths of user interaction sequences grow. Consequently, models need to be\ncontinually updated or even extended to adeptly encompass these emerging user\nintents, referred as incremental multi-intent sequential recommendation. % We\nrefer to this problem as incremental multi-intent sequential recommendation,\nwhich has not yet been well investigated in the existing literature. In this\npaper, we propose an effective Incremental learning framework for user\nMulti-intent Adaptation in sequential recommendation called IMA, which augments\nthe traditional fine-tuning strategy with the existing-intents retainer,\nnew-intents detector, and projection-based intents trimmer to adaptively expand\nthe model to accommodate user's new intents and prevent it from forgetting\nuser's existing intents. Furthermore, we upgrade the IMA into an Elastic\nMulti-intent Adaptation (EMA) framework which can elastically remove inactive\nintents and compress user intent vectors under memory space limit. Extensive\nexperiments on real-world datasets verify the effectiveness of the proposed IMA\nand EMA on incremental multi-intent sequential recommendation, compared with\nvarious baselines.", "published": "2025-04-30 02:55:30", "link": "http://arxiv.org/abs/2504.21270v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "On the Efficacy of the Peeling Decoder for the Quantum Expander Code", "abstract": "The problem of recovering from qubit erasures has recently gained attention\nas erasures occur in many physical systems such as photonic systems, trapped\nions, superconducting qubits and circuit quantum electrodynamics. While several\nlinear-time decoders for error correction are known, their error-correcting\ncapability is limited to half the minimum distance of the code, whereas erasure\ncorrection allows one to go beyond this limit. As in the classical case,\nstopping sets pose a major challenge in designing efficient erasure decoders\nfor quantum LDPC codes. In this paper, we show through simulation, that an\nattractive alternative here, is the use of quantum expander codes in\nconjunction with the peeling decoder that has linear complexity. We also\ndiscuss additional techniques including small-set-flip decoding, that can be\napplied following the peeling operation, to improve decoding performance and\ntheir associated complexity.", "published": "2025-04-30 17:54:49", "link": "http://arxiv.org/abs/2504.21845v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Enumeration of minimum weight codewords of affine Cartesian codes", "abstract": "Affine Cartesian codes were first discussed by Geil and Thomsen in 2013 in a\nbroader framework and were formally introduced by L\\'opez, Renter\\'ia-M\\'arquez\nand Villarreal in 2014. These are linear error-correcting codes obtained by\nevaluating polynomials at points of a Cartesian product of subsets of the given\nfinite field. They can be viewed as a vast generalization of Reed-Muller codes.\nIn 1970, Delsarte, Goethals and MacWilliams gave a %characterization of minimum\nweight codewords of Reed-Muller codes and also formula for the minimum weight\ncodewords of Reed-Muller codes. Carvalho and Neumann in 2020 considered affine\nCartesian codes in a special setting where the subsets in the Cartesian product\nare nested subfields of the given finite field, and gave a characterization of\ntheir minimum weight codewords. We use this to give an explicit formula for the\nnumber of minimum weight codewords of affine Cartesian codes in the case of\nnested subfields. This is seen to unify the known formulas for the number of\nminimum weight codewords of Reed-Solomon codes and Reed-Muller codes.", "published": "2025-04-30 17:21:30", "link": "http://arxiv.org/abs/2504.21816v1", "categories": ["cs.IT", "math.CO", "math.IT", "94B05, 94B27, 11B65"], "primary_category": "cs.IT"}
{"title": "Estimation of discrete distributions in relative entropy, and the deviations of the missing mass", "abstract": "We study the problem of estimating a distribution over a finite alphabet from\nan i.i.d. sample, with accuracy measured in relative entropy (Kullback-Leibler\ndivergence). While optimal expected risk bounds are known, high-probability\nguarantees remain less well-understood. First, we analyze the classical Laplace\n(add-$1$) estimator, obtaining matching upper and lower bounds on its\nperformance and showing its optimality among confidence-independent estimators.\nWe then characterize the minimax-optimal high-probability risk achievable by\nany estimator, which is attained via a simple confidence-dependent smoothing\ntechnique. Interestingly, the optimal non-asymptotic risk contains an\nadditional logarithmic factor over the ideal asymptotic risk. Next, motivated\nby scenarios where the alphabet exceeds the sample size, we investigate methods\nthat adapt to the sparsity of the distribution at hand. We introduce an\nestimator using data-dependent smoothing, for which we establish a\nhigh-probability risk bound depending on two effective sparsity parameters. As\npart of the analysis, we also derive a sharp high-probability upper bound on\nthe missing mass.", "published": "2025-04-30 16:47:10", "link": "http://arxiv.org/abs/2504.21787v1", "categories": ["math.ST", "cs.IT", "cs.LG", "math.IT", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "A note on the quantum Wielandt inequality", "abstract": "In this note, we show how to extend operator algebraic methods introduced by\nRahaman to prove that the index of primitivity of any primitive Schwarz map is\nat most $2(D-1)^2$, where $D$ is the dimension of the underlying matrix\nalgebra. This inequality was first proved by Rahaman for Schwarz maps which\nwere both unital and trace preserving. We show here that the assumption of\nunitality is automatic (up to normalization) for primitive Schwarz maps, but,\nin general, not all primitive unital Schwarz maps are trace preserving.\nTherefore, the precise purpose of this note is to showcase how to apply the\nproof of Rahaman to arbitrary primitive Schwarz maps. As a corollary of this\ntheorem, we show that the index of primitivity of any primitive 2-positive map\nis at most $2(D-1)^2$, so in particular this bound holds for arbitrary\nprimitive completely positive maps. We briefly discuss of how this relates to a\nconjecture of Perez-Garcia, Verstraete, Wolf and Cirac concerning properties of\nparent Hamiltonians of matrix product states.", "published": "2025-04-30 13:40:53", "link": "http://arxiv.org/abs/2504.21638v1", "categories": ["quant-ph", "cs.IT", "math.IT", "math.OA"], "primary_category": "quant-ph"}
{"title": "Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of Binary Classification", "abstract": "To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation~(DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.", "published": "2025-04-30 13:34:06", "link": "http://arxiv.org/abs/2504.21632v1", "categories": ["cs.IT", "eess.IV", "math.IT"], "primary_category": "cs.IT"}
{"title": "Invariant Bridges Between Four Successive Points: A New Tool for Data Coding", "abstract": "We introduce a simple yet powerful invariant relation connecting four\nsuccessive terms of a class of exponentially decaying alternating functions.\nSpecifically, for the sequence defined by f(n) = ((1/2)^n + (-1)^n) / n, we\nprove that the combination [(n-2)f(n-2) + (n-3)f(n-3)] / [n f(n) + (n-1)f(n-1)]\nis universally equal to 4 for all integers n >= 4. This invariant bridge across\nfour points opens new possibilities for predictive coding, data compression,\nand error detection. We demonstrate how the relation can be used to reconstruct\nmissing data, verify data integrity, and reduce redundancy in data streams with\nminimal computational overhead. The simplicity and universality of this\ninvariant make it a promising tool for a wide range of applications in\ninformation theory and coding systems.", "published": "2025-04-30 09:52:25", "link": "http://arxiv.org/abs/2504.21473v1", "categories": ["math.LO", "cs.IT", "math.IT", "03F60, 26E40", "F.4.1; E.4"], "primary_category": "math.LO"}
{"title": "Semantic-aided Parallel Image Transmission Compatible with Practical System", "abstract": "In this paper, we propose a novel semantic-aided image communication\nframework for supporting the compatibility with practical separation-based\ncoding architectures. Particularly, the deep learning (DL)-based joint\nsource-channel coding (JSCC) is integrated into the classical separate\nsource-channel coding (SSCC) to transmit the images via the combination of\nsemantic stream and image stream from DL networks and SSCC respectively, which\nwe name as parallel-stream transmission. The positive coding gain stems from\nthe sophisticated design of the JSCC encoder, which leverages the residual\ninformation neglected by the SSCC to enhance the learnable image features.\nFurthermore, a conditional rate adaptation mechanism is introduced to adjust\nthe transmission rate of semantic stream according to residual, rendering the\nframework more flexible and efficient to bandwidth allocation. We also design a\ndynamic stream aggregation strategy at the receiver, which provides the\ncomposite framework with more robustness to signal-to-noise ratio (SNR)\nfluctuations in wireless systems compared to a single conventional codec.\nFinally, the proposed framework is verified to surpass the performance of both\ntraditional and DL-based competitors in a large range of scenarios and\nmeanwhile, maintains lightweight in terms of the transmission and computational\ncomplexity of semantic stream, which exhibits the potential to be applied in\nreal systems.", "published": "2025-04-30 09:41:16", "link": "http://arxiv.org/abs/2504.21466v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Universal Encryption of Individual Sequences Under Maximal Leakage", "abstract": "We consider the Shannon cipher system in the framework of individual\nsequences and finite-state encrypters under the metric of maximal leakage of\ninformation. A lower bound and an asymptotically matching upper bound on the\nleakage are derived, which lead to the conclusion that asymptotically minimum\nleakage can be attained by Lempel-Ziv compression followed by one-time pad\nencryption of the compressed bit-stream.", "published": "2025-04-30 05:13:39", "link": "http://arxiv.org/abs/2504.21321v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Realizing Quantum Wireless Sensing Without Extra Reference Sources: Architecture, Algorithm, and Sensitivity Maximization", "abstract": "Rydberg Atomic REceivers (RAREs) have shown compelling advantages in the\nprecise measurement of radio-frequency signals, empowering quantum wireless\nsensing. Existing RARE-based sensing systems primarily rely on the\nheterodyne-sensing technique, which introduces an extra reference source to\nserve as the atomic mixer. However, this approach entails a bulky transceiver\narchitecture and is limited in the supportable sensing bandwidth. To address\nthese challenges, we propose self-heterodyne sensing, a novel concept where the\nself-interference caused by the transmitter acts as the reference signal. It is\nshown that a self-heterodyne RARE functions as an atomic autocorrelator,\neliminating the need for extra reference sources while supporting sensing\nsignals with much wider bandwidth than the conventional heterodyne-sensing\nmethod. Next, a two-stage algorithm is devised to estimate the target range for\nself-heterodyne RAREs. This algorithm is shown to closely approach the\nCramer-Rao lower bound. Furthermore, we introduce the power-trajectory\n(P-trajectory) design for RAREs, which maximizes the sensing sensitivity\nthrough time-varying transmission power optimization. A heuristic P-trajectory\nis developed to capture the profile of the asymptotically optimal time-varying\npower. This design is then extended to practical P-trajectories by\nincorporating the transmitter power constraints. Numerical results validate the\nsuperiority of the proposed designs for quantum wireless sensing.", "published": "2025-04-30 00:05:28", "link": "http://arxiv.org/abs/2504.21234v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Scalable Multi-Task Learning for Particle Collision Event Reconstruction with Heterogeneous Graph Neural Networks", "abstract": "The growing luminosity frontier at the Large Hadron Collider is challenging\nthe reconstruction and analysis of particle collision events. Increased\nparticle multiplicities are straining latency and storage requirements at the\ndata acquisition stage, while new complications are emerging, including higher\nbackground levels and more frequent particle vertex misassociations. This in\nturn necessitates the development of more holistic and scalable reconstruction\nmethods that take advantage of recent advances in machine learning. We propose\na novel Heterogeneous Graph Neural Network (HGNN) architecture featuring unique\nrepresentations for diverse particle collision relationships and integrated\ngraph pruning layers for scalability. Trained with a multi-task paradigm in an\nenvironment mimicking the LHCb experiment, this HGNN significantly improves\nbeauty hadron reconstruction performance. Notably, it concurrently performs\nparticle vertex association and graph pruning within a single framework. We\nquantify reconstruction and pruning performance, demonstrate enhanced inference\ntime scaling with event complexity, and mitigate potential performance loss\nusing a weighted message passing scheme.", "published": "2025-04-30 17:53:08", "link": "http://arxiv.org/abs/2504.21844v1", "categories": ["physics.data-an", "cs.LG", "hep-ex"], "primary_category": "physics.data-an"}
{"title": "Stable Trajectory Clustering: An Efficient Split and Merge Algorithm", "abstract": "Clustering algorithms group data points by characteristics to identify\npatterns. Over the past two decades, researchers have extended these methods to\nanalyze trajectories of humans, animals, and vehicles, studying their behavior\nand movement across applications. This paper presents whole-trajectory\nclustering and sub-trajectory clustering algorithms based on DBSCAN line\nsegment clustering, which encompasses two key events: split and merge of line\nsegments. The events are employed by object movement history and the average\nEuclidean distance between line segments. In this framework, whole-trajectory\nclustering considers entire entities' trajectories, whereas sub-trajectory\nclustering employs a sliding window model to identify similar sub-trajectories.\nMany existing trajectory clustering algorithms respond to temporary anomalies\nin data by splitting trajectories, which often obscures otherwise consistent\nclustering patterns and leads to less reliable insights. We introduce the\nstable trajectory clustering algorithm, which leverages the mean absolute\ndeviation concept to demonstrate that selective omission of transient\ndeviations not only preserves the integrity of clusters but also improves their\nstability and interpretability. We run all proposed algorithms on real\ntrajectory datasets to illustrate their effectiveness and sensitivity to\nparameter variations.", "published": "2025-04-30 17:11:36", "link": "http://arxiv.org/abs/2504.21808v1", "categories": ["cs.LG", "cs.CG"], "primary_category": "cs.LG"}
{"title": "Balancing Interpretability and Flexibility in Modeling Diagnostic Trajectories with an Embedded Neural Hawkes Process Model", "abstract": "The Hawkes process (HP) is commonly used to model event sequences with\nself-reinforcing dynamics, including electronic health records (EHRs).\nTraditional HPs capture self-reinforcement via parametric impact functions that\ncan be inspected to understand how each event modulates the intensity of\nothers. Neural network-based HPs offer greater flexibility, resulting in\nimproved fit and prediction performance, but at the cost of interpretability,\nwhich is often critical in healthcare. In this work, we aim to understand and\nimprove upon this tradeoff. We propose a novel HP formulation in which impact\nfunctions are modeled by defining a flexible impact kernel, instantiated as a\nneural network, in event embedding space, which allows us to model large-scale\nevent sequences with many event types. This approach is more flexible than\ntraditional HPs yet more interpretable than other neural network approaches,\nand allows us to explicitly trade flexibility for interpretability by adding\ntransformer encoder layers to further contextualize the event embeddings.\nResults show that our method accurately recovers impact functions in\nsimulations, achieves competitive performance on MIMIC-IV procedure dataset,\nand gains clinically meaningful interpretation on XX-EHR with children\ndiagnosis dataset even without transformer layers. This suggests that our\nflexible impact kernel is often sufficient to capture self-reinforcing dynamics\nin EHRs and other data effectively, implying that interpretability can be\nmaintained without loss of performance.", "published": "2025-04-30 16:52:43", "link": "http://arxiv.org/abs/2504.21795v1", "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "stat.ML"}
{"title": "On Advancements of the Forward-Forward Algorithm", "abstract": "The Forward-Forward algorithm has evolved in machine learning research,\ntackling more complex tasks that mimic real-life applications. In the last\nyears, it has been improved by several techniques to perform better than its\noriginal version, handling a challenging dataset like CIFAR10 without losing\nits flexibility and low memory usage. We have shown in our results that\nimprovements are achieved through a combination of convolutional channel\ngrouping, learning rate schedules, and independent block structures during\ntraining that lead to a 20\\% decrease in test error percentage. Additionally,\nto approach further implementations on low-capacity hardware projects we have\npresented a series of lighter models that achieve low test error percentages\nwithin (21$\\pm$6)\\% and number of trainable parameters between 164,706 and\n754,386. This serving also as a basis for our future study on complete\nverification and validation of these kinds of neural networks.", "published": "2025-04-30 14:03:52", "link": "http://arxiv.org/abs/2504.21662v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Real Time Semantic Segmentation of High Resolution Automotive LiDAR Scans", "abstract": "In recent studies, numerous previous works emphasize the importance of\nsemantic segmentation of LiDAR data as a critical component to the development\nof driver-assistance systems and autonomous vehicles. However, many\nstate-of-the-art methods are tested on outdated, lower-resolution LiDAR sensors\nand struggle with real-time constraints. This study introduces a novel semantic\nsegmentation framework tailored for modern high-resolution LiDAR sensors that\naddresses both accuracy and real-time processing demands. We propose a novel\nLiDAR dataset collected by a cutting-edge automotive 128 layer LiDAR in urban\ntraffic scenes. Furthermore, we propose a semantic segmentation method\nutilizing surface normals as strong input features. Our approach is bridging\nthe gap between cutting-edge research and practical automotive applications.\nAdditionaly, we provide a Robot Operating System (ROS2) implementation that we\noperate on our research vehicle. Our dataset and code are publicly available:\nhttps://github.com/kav-institute/SemanticLiDAR.", "published": "2025-04-30 13:00:50", "link": "http://arxiv.org/abs/2504.21602v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Low-rank computation of the posterior mean in Multi-Output Gaussian Processes", "abstract": "Gaussian processes (GP) are a versatile tool in machine learning and\ncomputational science. We here consider the case of multi-output Gaussian\nprocesses (MOGP) and present low-rank approaches for efficiently computing the\nposterior mean of a MOGP. Starting from low-rank spatio-temporal data we\nconsider a structured covariance function, assuming separability across space\nand time. This separability, in turn, gives a decomposition of the covariance\nmatrix into a Kronecker product of individual covariance matrices.\nIncorporating the typical noise term to the model then requires the solution of\na large-scale Stein equation for computing the posterior mean. For this, we\npropose efficient low-rank methods based on a combination of a LRPCG method\nwith the Sylvester equation solver KPIK adjusted for solving Stein equations.\nWe test the developed method on real world street network graphs by using graph\nfilters as covariance matrices. Moreover, we propose a degree-weighted average\ncovariance matrix, which can be employed under specific assumptions to achieve\nmore efficient convergence.", "published": "2025-04-30 11:19:58", "link": "http://arxiv.org/abs/2504.21527v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "Deep Learning Optimization Using Self-Adaptive Weighted Auxiliary Variables", "abstract": "In this paper, we develop a new optimization framework for the least squares\nlearning problem via fully connected neural networks or physics-informed neural\nnetworks. The gradient descent sometimes behaves inefficiently in deep learning\nbecause of the high non-convexity of loss functions and the vanishing gradient\nissue. Our idea is to introduce auxiliary variables to separate the layers of\nthe deep neural networks and reformulate the loss functions for ease of\noptimization. We design the self-adaptive weights to preserve the consistency\nbetween the reformulated loss and the original mean squared loss, which\nguarantees that optimizing the new loss helps optimize the original problem.\nNumerical experiments are presented to verify the consistency and show the\neffectiveness and robustness of our models over gradient descent.", "published": "2025-04-30 10:43:13", "link": "http://arxiv.org/abs/2504.21501v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Wasserstein-Aitchison GAN for angular measures of multivariate extremes", "abstract": "Economically responsible mitigation of multivariate extreme risks -- extreme\nrainfall in a large area, huge variations of many stock prices, widespread\nbreakdowns in transportation systems -- requires estimates of the probabilities\nthat such risks will materialize in the future. This paper develops a new\nmethod, Wasserstein--Aitchison Generative Adversarial Networks (WA-GAN), which\nprovides simulated values of future $d$-dimensional multivariate extreme events\nand which hence can be used to give estimates of such probabilities. The main\nhypothesis is that, after transforming the observations to the unit-Pareto\nscale, their distribution is regularly varying in the sense that the\ndistributions of their radial and angular components (with respect to the\n$L_1$-norm) converge and become asymptotically independent as the radius gets\nlarge. The method is a combination of standard extreme value analysis modeling\nof the tails of the marginal distributions with nonparametric GAN modeling of\nthe angular distribution. For the latter, the angular values are transformed to\nAitchison coordinates in a full $(d-1)$-dimensional linear space, and a\nWasserstein GAN is trained on these coordinates and used to generate new\nvalues. A reverse transformation is then applied to these values and gives\nsimulated values on the original data scale. The method shows good performance\ncompared to other existing methods in the literature, both in terms of\ncapturing the dependence structure of the extremes in the data, as well as in\ngenerating accurate new extremes of the data distribution. The comparison is\nperformed on simulated multivariate extremes from a logistic model in\ndimensions up to 50 and on a 30-dimensional financial data set.", "published": "2025-04-30 08:54:28", "link": "http://arxiv.org/abs/2504.21438v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Whispers of Data: Unveiling Label Distributions in Federated Learning Through Virtual Client Simulation", "abstract": "Federated Learning enables collaborative training of a global model across\nmultiple geographically dispersed clients without the need for data sharing.\nHowever, it is susceptible to inference attacks, particularly label inference\nattacks.\n  Existing studies on label distribution inference exhibits sensitive to the\nspecific settings of the victim client and typically underperforms under\ndefensive strategies. In this study, we propose a novel label distribution\ninference attack that is stable and adaptable to various scenarios.\nSpecifically, we estimate the size of the victim client's dataset and construct\nseveral virtual clients tailored to the victim client. We then quantify the\ntemporal generalization of each class label for the virtual clients and utilize\nthe variation in temporal generalization to train an inference model that\npredicts the label distribution proportions of the victim client.\n  We validate our approach on multiple datasets, including MNIST,\nFashion-MNIST, FER2013, and AG-News. The results demonstrate the superiority of\nour method compared to state-of-the-art techniques. Furthermore, our attack\nremains effective even under differential privacy defense mechanisms,\nunderscoring its potential for real-world applications.", "published": "2025-04-30 08:51:06", "link": "http://arxiv.org/abs/2504.21436v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Kernel Density Machines", "abstract": "We introduce kernel density machines (KDM), a novel density ratio estimator\nin a reproducing kernel Hilbert space setting. KDM applies to general\nprobability measures on countably generated measurable spaces without\nrestrictive assumptions on continuity, or the existence of a Lebesgue density.\nFor computational efficiency, we incorporate a low-rank approximation with\nprecisely controlled error that grants scalability to large-sample settings. We\nprovide rigorous theoretical guarantees, including asymptotic consistency, a\nfunctional central limit theorem, and finite-sample error bounds, establishing\na strong foundation for practical use. Empirical results based on simulated and\nreal data demonstrate the efficacy and precision of KDM.", "published": "2025-04-30 08:25:25", "link": "http://arxiv.org/abs/2504.21419v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH", "62G07, 65D05, 65D15, 65C60, 62G10, 62G20"], "primary_category": "stat.ML"}
{"title": "Enhanced Semi-Supervised Stamping Process Monitoring with Physically-Informed Feature Extraction", "abstract": "In tackling frequent anomalies in stamping processes, this study introduces a\nnovel semi-supervised in-process anomaly monitoring framework, utilizing\naccelerometer signals and physics information, to capture the process anomaly\neffectively. The proposed framework facilitates the construction of a\nmonitoring model with imbalanced sample distribution, which enables in-process\ncondition monitoring in real-time to prevent batch anomalies, which helps to\nreduce batch defects risk and enhance production yield. Firstly, to effectively\ncapture key features from raw data containing redundant information, a hybrid\nfeature extraction algorithm is proposed to utilize data-driven methods and\nphysical mechanisms simultaneously. Secondly, to address the challenge brought\nby imbalanced sample distribution, a semi-supervised anomaly detection model is\nestablished, which merely employs normal samples to build a golden baseline\nmodel, and a novel deviation score is proposed to quantify the anomaly level of\neach online stamping stroke. The effectiveness of the proposed feature\nextraction method is validated with various classification algorithms. A\nreal-world in-process dataset from stamping manufacturing workshop is employed\nto illustrate the superiority of proposed semi-supervised framework with\nenhance performance for process anomaly monitoring.", "published": "2025-04-30 07:42:19", "link": "http://arxiv.org/abs/2504.21389v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Synergy-CLIP: Extending CLIP with Multi-modal Integration for Robust Representation Learning", "abstract": "Multi-modal representation learning has become a pivotal area in artificial\nintelligence, enabling the integration of diverse modalities such as vision,\ntext, and audio to solve complex problems. However, existing approaches\npredominantly focus on bimodal interactions, such as image-text pairs, which\nlimits their ability to fully exploit the richness of multi-modal data.\nFurthermore, the integration of modalities in equal-scale environments remains\nunderexplored due to the challenges of constructing large-scale, balanced\ndatasets. In this study, we propose Synergy-CLIP, a novel framework that\nextends the contrastive language-image pre-training (CLIP) architecture to\nenhance multi-modal representation learning by integrating visual, textual, and\naudio modalities. Unlike existing methods that focus on adapting individual\nmodalities to vanilla-CLIP, Synergy-CLIP aligns and captures latent information\nacross three modalities equally. To address the high cost of constructing\nlarge-scale multi-modal datasets, we introduce VGG-sound+, a triple-modal\ndataset designed to provide equal-scale representation of visual, textual, and\naudio data. Synergy-CLIP is validated on various downstream tasks, including\nzero-shot classification, where it outperforms existing baselines.\nAdditionally, we introduce a missing modality reconstruction task,\ndemonstrating Synergy-CLIP's ability to extract synergy among modalities in\nrealistic application scenarios. These contributions provide a robust\nfoundation for advancing multi-modal representation learning and exploring new\nresearch directions.", "published": "2025-04-30 07:14:58", "link": "http://arxiv.org/abs/2504.21375v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Generative QoE Modeling: A Lightweight Approach for Telecom Networks", "abstract": "Quality of Experience (QoE) prediction plays a crucial role in optimizing\nresource management and enhancing user satisfaction across both\ntelecommunication and OTT services. While recent advances predominantly rely on\ndeep learning models, this study introduces a lightweight generative modeling\nframework that balances computational efficiency, interpretability, and\npredictive accuracy. By validating the use of Vector Quantization (VQ) as a\npreprocessing technique, continuous network features are effectively\ntransformed into discrete categorical symbols, enabling integration with a\nHidden Markov Model (HMM) for temporal sequence modeling. This VQ-HMM pipeline\nenhances the model's capacity to capture dynamic QoE patterns while supporting\nprobabilistic inference on new and unseen data. Experimental results on\npublicly available time-series datasets incorporating both objective indicators\nand subjective QoE scores demonstrate the viability of this approach in\nreal-time and resource-constrained environments, where inference latency is\nalso critical. The framework offers a scalable alternative to complex deep\nlearning methods, particularly in scenarios with limited computational\nresources or where latency constraints are critical.", "published": "2025-04-30 06:19:37", "link": "http://arxiv.org/abs/2504.21353v1", "categories": ["cs.LG", "cs.NI"], "primary_category": "cs.LG"}
{"title": "A Memetic Algorithm based on Variational Autoencoder for Black-Box Discrete Optimization with Epistasis among Parameters", "abstract": "Black-box discrete optimization (BB-DO) problems arise in many real-world\napplications, such as neural architecture search and mathematical model\nestimation. A key challenge in BB-DO is epistasis among parameters where\nmultiple variables must be modified simultaneously to effectively improve the\nobjective function. Estimation of Distribution Algorithms (EDAs) provide a\npowerful framework for tackling BB-DO problems. In particular, an EDA\nleveraging a Variational Autoencoder (VAE) has demonstrated strong performance\non relatively low-dimensional problems with epistasis while reducing\ncomputational cost. Meanwhile, evolutionary algorithms such as DSMGA-II and P3,\nwhich integrate bit-flip-based local search with linkage learning, have shown\nexcellent performance on high-dimensional problems. In this study, we propose a\nnew memetic algorithm that combines VAE-based sampling with local search. The\nproposed method inherits the strengths of both VAE-based EDAs and local\nsearch-based approaches: it effectively handles high-dimensional problems with\nepistasis among parameters without incurring excessive computational overhead.\nExperiments on NK landscapes -- a challenging benchmark for BB-DO involving\nepistasis among parameters -- demonstrate that our method outperforms\nstate-of-the-art VAE-based EDA methods, as well as leading approaches such as\nP3 and DSMGA-II.", "published": "2025-04-30 05:56:22", "link": "http://arxiv.org/abs/2504.21338v1", "categories": ["cs.NE", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Multi-level datasets training method in Physics-Informed Neural Networks", "abstract": "Physics-Informed Neural Networks have emerged as a promising methodology for\nsolving PDEs, gaining significant attention in computer science and various\nphysics-related fields. Despite being demonstrated the ability to incorporate\nthe physics of laws for versatile applications, PINNs still struggle with the\nchallenging problems which are stiff to be solved and/or have high-frequency\ncomponents in the solutions, resulting in accuracy and convergence issues. It\nmay not only increase computational costs, but also lead to accuracy loss or\nsolution divergence. In this study, an alternative approach is proposed to\nmitigate the above-mentioned problems. Inspired by the multi-grid method in CFD\ncommunity, the underlying idea of the current approach is to efficiently remove\ndifferent frequency errors via training with different levels of training\nsamples, resulting in a simpler way to improve the training accuracy without\nspending time in fine-tuning of neural network structures, loss weights as well\nas hyperparameters. To demonstrate the efficacy of current approach, we first\ninvestigate canonical 1D ODE with high-frequency component and 2D\nconvection-diffusion equation with V-cycle training strategy. Finally, the\ncurrent method is employed for the classical benchmark problem of steady\nLid-driven cavity flows at different Reynolds numbers, to investigate the\napplicability and efficacy for the problem involved multiple modes of high and\nlow frequency. By virtue of various training sequence modes, improvement\nthrough predictions lead to 30% to 60% accuracy improvement. We also\ninvestigate the synergies between current method and transfer learning\ntechniques for more challenging problems (i.e., higher Re). From the present\nresults, it also revealed that the current framework can produce good\npredictions even for the case of Re=5000, demonstrating the ability to solve\ncomplex high-frequency PDEs.", "published": "2025-04-30 05:30:27", "link": "http://arxiv.org/abs/2504.21328v1", "categories": ["cs.LG", "cs.CE", "physics.flu-dyn"], "primary_category": "cs.LG"}
{"title": "A Generalized Meta Federated Learning Framework with Theoretical Convergence Guarantees", "abstract": "Meta federated learning (FL) is a personalized variant of FL, where multiple\nagents collaborate on training an initial shared model without exchanging raw\ndata samples. The initial model should be trained in a way that current or new\nagents can easily adapt it to their local datasets after one or a few\nfine-tuning steps, thus improving the model personalization. Conventional meta\nFL approaches minimize the average loss of agents on the local models obtained\nafter one step of fine-tuning. In practice, agents may need to apply several\nfine-tuning steps to adapt the global model to their local data, especially\nunder highly heterogeneous data distributions across agents. To this end, we\npresent a generalized framework for the meta FL by minimizing the average loss\nof agents on their local model after any arbitrary number $\\nu$ of fine-tuning\nsteps. For this generalized framework, we present a variant of the well-known\nfederated averaging (FedAvg) algorithm and conduct a comprehensive theoretical\nconvergence analysis to characterize the convergence speed as well as behavior\nof the meta loss functions in both the exact and approximated cases. Our\nexperiments on real-world datasets demonstrate superior accuracy and faster\nconvergence for the proposed scheme compared to conventional approaches.", "published": "2025-04-30 05:29:46", "link": "http://arxiv.org/abs/2504.21327v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Redundancy Analysis and Mitigation for Machine Learning-Based Process Monitoring of Additive Manufacturing", "abstract": "The deployment of machine learning (ML)-based process monitoring systems has\nsignificantly advanced additive manufacturing (AM) by enabling real-time defect\ndetection, quality assessment, and process optimization. However, redundancy is\na critical yet often overlooked challenge in the deployment and operation of\nML-based AM process monitoring systems. Excessive redundancy leads to increased\nequipment costs, compromised model performance, and high computational\nrequirements, posing barriers to industrial adoption. However, existing\nresearch lacks a unified definition of redundancy and a systematic framework\nfor its evaluation and mitigation. This paper defines redundancy in ML-based AM\nprocess monitoring and categorizes it into sample-level, feature-level, and\nmodel-level redundancy. A comprehensive multi-level redundancy mitigation\n(MLRM) framework is proposed, incorporating advanced methods such as data\nregistration, downscaling, cross-modality knowledge transfer, and model pruning\nto systematically reduce redundancy while improving model performance. The\nframework is validated through an ML-based in-situ defect detection case study\nfor directed energy deposition (DED), demonstrating a 91% reduction in latency,\na 47% decrease in error rate, and a 99.4% reduction in storage requirements.\nAdditionally, the proposed approach lowers sensor costs and energy consumption,\nenabling a lightweight, cost-effective, and scalable monitoring system. By\ndefining redundancy and introducing a structured mitigation framework, this\nstudy establishes redundancy analysis and mitigation as a key enabler of\nefficient ML-based process monitoring in production environments.", "published": "2025-04-30 05:04:53", "link": "http://arxiv.org/abs/2504.21317v1", "categories": ["cs.CE", "cs.LG", "eess.SP"], "primary_category": "cs.CE"}
{"title": "Capturing Conditional Dependence via Auto-regressive Diffusion Models", "abstract": "Diffusion models have demonstrated appealing performance in both image and\nvideo generation. However, many works discover that they struggle to capture\nimportant, high-level relationships that are present in the real world. For\nexample, they fail to learn physical laws from data, and even fail to\nunderstand that the objects in the world exist in a stable fashion. This is due\nto the fact that important conditional dependence structures are not adequately\ncaptured in the vanilla diffusion models. In this work, we initiate an in-depth\nstudy on strengthening the diffusion model to capture the conditional\ndependence structures in the data. In particular, we examine the efficacy of\nthe auto-regressive (AR) diffusion models for such purpose and develop the\nfirst theoretical results on the sampling error of AR diffusion models under\n(possibly) the mildest data assumption. Our theoretical findings indicate that,\ncompared with typical diffusion models, the AR variant produces samples with a\nreduced gap in approximating the data conditional distribution. On the other\nhand, the overall inference time of the AR-diffusion models is only moderately\nlarger than that for the vanilla diffusion models, making them still practical\nfor large scale applications. We also provide empirical results showing that\nwhen there is clear conditional dependence structure in the data, the AR\ndiffusion models captures such structure, whereas vanilla DDPM fails to do so.\nOn the other hand, when there is no obvious conditional dependence across\npatches of the data, AR diffusion does not outperform DDPM.", "published": "2025-04-30 04:57:12", "link": "http://arxiv.org/abs/2504.21314v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Unsupervised Feature Transformation via In-context Generation, Generator-critic LLM Agents, and Duet-play Teaming", "abstract": "Feature transformation involves generating a new set of features from the\noriginal dataset to enhance the data's utility. In certain domains like\nmaterial performance screening, dimensionality is large and collecting labels\nis expensive and lengthy. It highly necessitates transforming feature spaces\nefficiently and without supervision to enhance data readiness and AI utility.\nHowever, existing methods fall short in efficient navigation of a vast space of\nfeature combinations, and are mostly designed for supervised settings. To fill\nthis gap, our unique perspective is to leverage a generator-critic duet-play\nteaming framework using LLM agents and in-context learning to derive\npseudo-supervision from unsupervised data. The framework consists of three\ninterconnected steps: (1) Critic agent diagnoses data to generate actionable\nadvice, (2) Generator agent produces tokenized feature transformations guided\nby the critic's advice, and (3) Iterative refinement ensures continuous\nimprovement through feedback between agents. The generator-critic framework can\nbe generalized to human-agent collaborative generation, by replacing the critic\nagent with human experts. Extensive experiments demonstrate that the proposed\nframework outperforms even supervised baselines in feature transformation\nefficiency, robustness, and practical applicability across diverse datasets.", "published": "2025-04-30 04:26:03", "link": "http://arxiv.org/abs/2504.21304v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Power Flow Approximations for Multiphase Distribution Networks using Gaussian Processes", "abstract": "Learning-based approaches are increasingly leveraged to manage and coordinate\nthe operation of grid-edge resources in active power distribution networks.\nAmong these, model-based techniques stand out for their superior data\nefficiency and robustness compared to model-free methods. However, effective\nmodel learning requires a learning-based approximator for the underlying power\nflow model. This study extends existing work by introducing a data-driven power\nflow method based on Gaussian Processes (GPs) to approximate the multiphase\npower flow model, by mapping net load injections to nodal voltages. Simulation\nresults using the IEEE 123-bus and 8500-node distribution test feeders\ndemonstrate that the trained GP model can reliably predict the nonlinear power\nflow solutions with minimal training data. We also conduct a comparative\nanalysis of the training efficiency and testing performance of the proposed\nGP-based power flow approximator against a deep neural network-based\napproximator, highlighting the advantages of our data-efficient approach.\nResults over realistic operating conditions show that despite an 85% reduction\nin the training sample size (corresponding to a 92.8% improvement in training\ntime), GP models produce a 99.9% relative reduction in mean absolute error\ncompared to the baselines of deep neural networks.", "published": "2025-04-30 02:26:31", "link": "http://arxiv.org/abs/2504.21260v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "LSTM+Geo with xgBoost Filtering: A Novel Approach for Race and Ethnicity Imputation with Reduced Bias", "abstract": "Accurate imputation of race and ethnicity (R&E) is crucial for analyzing\ndisparities and informing policy. Methods like Bayesian Improved Surname\nGeocoding (BISG) are widely used but exhibit limitations, including systematic\nmisclassification biases linked to socioeconomic status. This paper introduces\nLSTM+Geo, a novel approach enhancing Long Short-Term Memory (LSTM) networks\nwith census tract geolocation information. Using a large voter dataset, we\ndemonstrate that LSTM+Geo (88.7% accuracy) significantly outperforms standalone\nLSTM (86.4%) and Bayesian methods like BISG (82.9%) and BIFSG (86.8%) in\naccuracy and F1-score on a held-out validation set. LSTM+Geo reduces the rate\nat which non-White individuals are misclassified as White (White FPR 19.3%)\ncompared to name-only LSTMs (White FPR 24.6%). While sophisticated ensemble\nmethods incorporating XGBoost achieve the highest overall accuracy (up to\n89.4%) and lowest White FPR (17.8%), LSTM+Geo offers strong standalone\nperformance with improved bias characteristics compared to baseline models.\nIntegrating LSTM+Geo into an XGBoost ensemble further boosts accuracy,\nhighlighting its utility as both a standalone model and a component for\nadvanced systems. We give a caution at the end regarding the appropriate use of\nthese methods.", "published": "2025-04-30 02:20:08", "link": "http://arxiv.org/abs/2504.21259v1", "categories": ["cs.CY", "cs.LG"], "primary_category": "cs.CY"}
{"title": "ABG-NAS: Adaptive Bayesian Genetic Neural Architecture Search for Graph Representation Learning", "abstract": "Effective and efficient graph representation learning is essential for\nenabling critical downstream tasks, such as node classification, link\nprediction, and subgraph search. However, existing graph neural network (GNN)\narchitectures often struggle to adapt to diverse and complex graph structures,\nlimiting their ability to provide robust and generalizable representations. To\naddress this challenge, we propose ABG-NAS, a novel framework for automated\ngraph neural network architecture search tailored for efficient graph\nrepresentation learning. ABG-NAS encompasses three key components: a\nComprehensive Architecture Search Space (CASS), an Adaptive Genetic\nOptimization Strategy (AGOS), and a Bayesian-Guided Tuning Module (BGTM). CASS\nsystematically explores diverse propagation (P) and transformation (T)\noperations, enabling the discovery of GNN architectures capable of capturing\nintricate graph characteristics. AGOS dynamically balances exploration and\nexploitation, ensuring search efficiency and preserving solution diversity.\nBGTM further optimizes hyperparameters periodically, enhancing the scalability\nand robustness of the resulting architectures. Empirical evaluations on\nbenchmark datasets (Cora, PubMed, Citeseer, and CoraFull) demonstrate that\nABG-NAS consistently outperforms both manually designed GNNs and\nstate-of-the-art neural architecture search (NAS) methods. These results\nhighlight the potential of ABG-NAS to advance graph representation learning by\nproviding scalable and adaptive solutions for diverse graph structures. Our\ncode is publicly available at https://github.com/sserranw/ABG-NAS.", "published": "2025-04-30 01:44:27", "link": "http://arxiv.org/abs/2504.21254v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Data-driven operator learning for energy-efficient building control", "abstract": "Energy-efficient ventilation control plays a vital role in reducing building\nenergy consumption while ensuring occupant health and comfort. While\nComputational Fluid Dynamics (CFD) simulations offer high-fidelity modeling of\nairflow for building HVAC design, their high computational cost makes them\nimpractical for practical adoption in real-time building management system. In\nthis work, we present a data-driven framework that combines the physical\naccuracy of CFD with the computational efficiency of machine learning to enable\nenergy-efficient building ventilation control. Our method jointly optimizes\nairflow supply rates and vent angles to reduce energy use and adhere to air\nquality constraints. We train a neural operator transformer to learn the\nmapping from building control actions to airflow field distributions using\nhigh-resolution CFD data. This learned operator enables a gradient-based\ncontrol framework capable of optimal decision-making. Experimental results\ndemonstrate that our approach achieves substantial energy savings compared to\nmaximum airflow rate control, rule-based control, and data-driven control based\non regional average CO2 predictions, while consistently maintaining safe indoor\nair quality. These results highlight the practicality and scalability of our\nmethod for enabling safe and energy-efficient building management.", "published": "2025-04-30 00:45:49", "link": "http://arxiv.org/abs/2504.21243v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Passive Measurement of Autonomic Arousal in Real-World Settings", "abstract": "The autonomic nervous system (ANS) is activated during stress, which can have\nnegative effects on cardiovascular health, sleep, the immune system, and mental\nhealth. While there are ways to quantify ANS activity in laboratories, there is\na paucity of methods that have been validated in real-world contexts. We\npresent the Fitbit Body Response Algorithm, an approach to continuous remote\nmeasurement of ANS activation through widely available remote wrist-based\nsensors. The design was validated via two experiments, a Trier Social Stress\nTest (n = 45) and ecological momentary assessments (EMA) of perceived stress\n(n=87), providing both controlled and ecologically valid test data. Model\nperformance predicting perceived stress when using all available sensor\nmodalities was consistent with expectations (accuracy=0.85) and outperformed\nmodels with access to only a subset of the signals. We discuss and address\nchallenges to sensing that arise in real world settings that do not present in\nconventional lab environments.", "published": "2025-04-30 00:45:13", "link": "http://arxiv.org/abs/2504.21242v1", "categories": ["cs.HC", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Uncertainty, bias and the institution bootstrapping problem", "abstract": "Institutions play a critical role in enabling communities to manage\ncommon-pool resources and avert tragedies of the commons. However, a\nfundamental issue arises: Individuals typically perceive participation as\nadvantageous only after an institution is established, creating a paradox: How\ncan institutions form if no one will join before a critical mass exists? We\nterm this conundrum the institution bootstrapping problem and propose that\nmisperception, specifically, agents' erroneous belief that an institution\nalready exists, could resolve this paradox. By integrating well-documented\npsychological phenomena, including cognitive biases, probability distortion,\nand perceptual noise, into a game-theoretic framework, we demonstrate how these\nfactors collectively mitigate the bootstrapping problem. Notably, unbiased\nperceptual noise (e.g., noise arising from agents' heterogeneous physical or\nsocial contexts) drastically reduces the critical mass of cooperators required\nfor institutional emergence. This effect intensifies with greater diversity of\nperceptions. We explain this counter-intuitive result through asymmetric\nboundary conditions: proportional underestimation of low-probability sanctions\nproduces distinct outcomes compared to equivalent overestimation. Furthermore,\nthe type of perceptual distortion, proportional versus absolute, yields\nqualitatively different evolutionary pathways. These findings challenge\nconventional assumptions about rationality in institutional design,\nhighlighting how \"noisy\" cognition can paradoxically enhance cooperation.\nFinally, we contextualize these insights within broader discussions of\nmulti-agent system design and collective action. Our analysis underscores the\nimportance of incorporating human-like cognitive constraints, not just\nidealized rationality, into models of institutional emergence and resilience.", "published": "2025-04-30 12:36:06", "link": "http://arxiv.org/abs/2504.21579v1", "categories": ["cs.MA", "cs.CY", "cs.GT"], "primary_category": "cs.MA"}
{"title": "Robust Multi-agent Communication Based on Decentralization-Oriented Adversarial Training", "abstract": "In typical multi-agent reinforcement learning (MARL) problems, communication\nis important for agents to share information and make the right decisions.\nHowever, due to the complexity of training multi-agent communication, existing\nmethods often fall into the dilemma of local optimization, which leads to the\nconcentration of communication in a limited number of channels and presents an\nunbalanced structure. Such unbalanced communication policy are vulnerable to\nabnormal conditions, where the damage of critical communication channels can\ntrigger the crash of the entire system. Inspired by decentralization theory in\nsociology, we propose DMAC, which enhances the robustness of multi-agent\ncommunication policies by retraining them into decentralized patterns.\nSpecifically, we train an adversary DMAC\\_Adv which can dynamically identify\nand mask the critical communication channels, and then apply the adversarial\nsamples generated by DMAC\\_Adv to the adversarial learning of the communication\npolicy to force the policy in exploring other potential communication schemes\nand transition to a decentralized structure. As a training method to improve\nrobustness, DMAC can be fused with any learnable communication policy\nalgorithm. The experimental results in two communication policies and four\nmulti-agent tasks demonstrate that DMAC achieves higher improvement on\nrobustness and performance of communication policy compared with two\nstate-of-the-art and commonly-used baselines. Also, the results demonstrate\nthat DMAC can achieve decentralized communication structure with acceptable\ncommunication cost.", "published": "2025-04-30 03:14:50", "link": "http://arxiv.org/abs/2504.21278v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Patch bubbles for advection-dominated problems", "abstract": "A novel variant of the \\emph{residual-free bubble} method (RFB) for advection\ndominated problems is presented. Since the usual RFB still suffers from\noscillations and strong under/overshoots, the bubble space is enriched by\n\\emph{patch bubbles}, giving more freedom to the bubble space.\n  We use a recursive and efficient approach to accurately compute the bubbles.\nNumerical experiments clearly demonstrate the superiority of our method\ncompared to the standard RFB.\n  The method is similar to the \\emph{enhanced residual-free bubble} method\n(eRFB) proposed by Cangiani and S\\\"uli in 2005, but differs in the definition\nof the additional bubbles.", "published": "2025-04-30 17:46:14", "link": "http://arxiv.org/abs/2504.21835v1", "categories": ["math.NA", "cs.NA", "65M60 (Primary) 65N30, 65N12 (Secondary)"], "primary_category": "math.NA"}
{"title": "Frozen Gaussian Grid-point Correction For Semi-classical Schr\u00f6dinger Equation", "abstract": "We propose an efficient reconstruction algorithm named the frozen Gaussian\ngrid-point correction (FGGC) for computing the Schr\\\"odinger equation in the\nsemi-classical regime using the frozen Gaussian approximation (FGA). The FGA\nhas demonstrated its superior efficiency in dealing with semi-classical\nproblems and high-frequency wave propagations. However, reconstructing the wave\nfunction from a large number of Gaussian wave-packets is typically\ncomputationally intensive. This difficulty arises because these wave-packets\npropagate along the FGA trajectories to non-grid positions, making the\napplication of the fast Fourier transform infeasible. In this work, we\nintroduce the concept of ``on-grid correction'' and derive the formulas for the\nleast squares approximation of Gaussian wave-packets, and also provide a\ndetailed process of the FGGC algorithm. Furthermore, we rigorously prove that\nthe error introduced by the least squares approximation on each Gaussian\nwave-packet is independent of the semi-classical parameter $\\varepsilon$.\nNumerical experiments show that the FGGC algorithm can significantly improve\nreconstruction efficiency while introducing only negligible error, making it a\npowerful tool for solving the semi-classical Schr\\\"odinger equation, especially\nin applications requiring both accuracy and efficiency.", "published": "2025-04-30 16:43:28", "link": "http://arxiv.org/abs/2504.21785v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A Comparison of the Consistent and Independent Second Moment Methods Applied to Thermal Radiative Transfer", "abstract": "The design of efficient numerical methods for modeling thermal radiative\ntransfer (TRT) is challenging due to the stiff, nonlinear coupling between\nradiation and material energies, especially at the time scales of interest in\nhigh energy density physics and astrophysics. Here, we investigate the use of\nthe Second Moment Method (SMM) to accelerate absorption-emission within the\ncontext of the multigroup, Discrete Ordinates transport equations with\ndiscontinuous Galerkin spatial discretization. SMM employs a\nreduced-dimensional, diffusion-based model of radiation transport that, when\ncoupled with suitable discrete closures, serves as a proxy for the transport\nequation, isolating the transport equation from the stiff absorption-emission\nphysics. We use a gray low-order system to reduce the cost of solving the\nlow-order system and leverage SMM low-order discretizations specifically\ndesigned to be scalably solvable with existing linear solver technology. Our\nalgorithm robustly resolves the nonlinear TRT system while only relying on\ntransport sweeps, linearly solving symmetric and positive definite, gray\ndiffusion systems, and nonlinearly solving the spatially pointwise energy\nbalance equation. This algorithm is used as a vehicle to compare the efficacy\nof low-order discretizations developed for steady-state, linear transport on\ngray and multigroup TRT problems in one and two spatial dimensions.", "published": "2025-04-30 16:42:29", "link": "http://arxiv.org/abs/2504.21784v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "MAGNET: an open-source library for mesh agglomeration by Graph Neural Networks", "abstract": "We introduce MAGNET, an open-source Python library designed for mesh\nagglomeration in both two- and three-dimensions, based on employing Graph\nNeural Networks (GNN). MAGNET serves as a comprehensive solution for training a\nvariety of GNN models, integrating deep learning and other advanced algorithms\nsuch as METIS and k-means to facilitate mesh agglomeration and quality metric\ncomputation. The library's introduction is outlined through its code structure\nand primary features. The GNN framework adopts a graph bisection methodology\nthat capitalizes on connectivity and geometric mesh information via SAGE\nconvolutional layers, in line with the methodology proposed by Antonietti et\nal. (2024). Additionally, the proposed MAGNET library incorporates\nreinforcement learning to enhance the accuracy and robustness of the model for\npredicting coarse partitions within a multilevel framework. A detailed tutorial\nis provided to guide the user through the process of mesh agglomeration and the\ntraining of a GNN bisection model. We present several examples of mesh\nagglomeration conducted by MAGNET, demonstrating the library's applicability\nacross various scenarios. Furthermore, the performance of the newly introduced\nmodels is contrasted with that of METIS and k-means, illustrating that the\nproposed GNN models are competitive regarding partition quality and\ncomputational efficiency. Finally, we exhibit the versatility of MAGNET's\ninterface through its integration with Lymph, an open-source library\nimplementing discontinuous Galerkin methods on polytopal grids for the\nnumerical discretization of multiphysics differential problems.", "published": "2025-04-30 16:33:22", "link": "http://arxiv.org/abs/2504.21780v1", "categories": ["math.NA", "cs.MS", "cs.NA", "65N22, 65N30, 65N50, 68T07"], "primary_category": "math.NA"}
{"title": "Approximation and regularity results for the Heston model and related processes", "abstract": "This Ph.D. thesis explores approximations and regularity for the Heston\nstochastic volatility model through three interconnected works.\n  The first work focuses on developing high-order weak approximations for the\nCox-Ingersoll-Ross (CIR) process, essential for financial modelling but\nchallenging due to the square root diffusion term preventing standard methods.\nBy employing the random grid technique (Alfonsi & Bally, 2021) built upon\nAlfonsi's (2010) second-order scheme, the work proves that weak approximations\nof any order can be achieved for smooth test functions. This holds under a\ncondition that is less restrictive than the famous Feller's one. Numerical\nresults confirm convergence for both CIR and Heston models and show significant\ncomputational time improvements.\n  The second work extends the random grid technique to the log-Heston process.\nTwo second-order schemes are introduced (one using exact volatility simulation,\nanother using Ninomiya-Victoir splitting under a the same restriction used\nabove). Convergence to any desired order is rigorously proven. Numerical\nexperiments validate the schemes' effectiveness for pricing European and Asian\noptions and suggest potential applicability to multifactor/rough Heston models.\n  The third work investigates the partial differential equation (PDE)\nassociated with the log-Heston model. It extends classical solution results and\nestablishes the existence and uniqueness of viscosity solutions without relying\non the Feller condition. Uniqueness is proven even for certain discontinuous\ninitial data, relevant for pricing instruments like digital options.\nFurthermore, the convergence of a hybrid numerical scheme to the viscosity\nsolution is shown under relaxed regularity (continuity) for the initial data.\n  An appendix includes supplementary results for the CIR process.", "published": "2025-04-30 14:01:01", "link": "http://arxiv.org/abs/2504.21658v1", "categories": ["math.NA", "cs.NA", "math.AP", "math.PR", "q-fin.CP", "60H35, 91G60, 65C30, 65C05, 35K65"], "primary_category": "math.NA"}
{"title": "A p-adaptive polytopal discontinuous Galerkin method for high-order approximation of brain electrophysiology", "abstract": "Multiscale mathematical models have shown great promise in computational\nbrain electrophysiology but are still hindered by high computational costs due\nto fast dynamics and complex brain geometries, requiring very fine\nspatio-temporal resolution. This paper introduces a novel p-adaptive\ndiscontinuous Galerkin method on polytopal grids (PolyDG) coupled with\nCrank-Nicolson time integration to approximate such models efficiently. The\np-adaptive method enhances local accuracy via dynamic, element-wise polynomial\nrefinement/de-refinement guided by a-posteriori error estimators. A novel\nclustering algorithm automatizes the selection of elements for adaptive\nupdates, further improving efficiency. A wide set of numerical tests, including\nepileptic seizure simulations in a sagittal section of a human brain stem,\ndemonstrate the method's ability to reduce computational load while maintaining\nthe accuracy of the numerical solution in capturing the dynamics of multiple\nwavefronts.", "published": "2025-04-30 14:00:42", "link": "http://arxiv.org/abs/2504.21657v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Sparsity for Infinite-Parametric Holomorphic Functions on Gaussian Spaces", "abstract": "We investigate the sparsity of Wiener polynomial chaos expansions of\nholomorphic maps $\\mathcal{G}$ on Gaussian Hilbert spaces, as arise in the\ncoefficient-to-solution maps of linear, second order, divergence-form elliptic\nPDEs with log-Gaussian diffusion coefficient. Representing the Gaussian random\nfield input as an affine-parametric expansion, the nonlinear map becomes a\ncountably-parametric, deterministic holomorphic map of the coordinate sequence\n$\\boldsymbol{y} = (y_j)_{j\\in\\mathbb{N}} \\in \\mathbb{R}^\\infty$. We establish\nweighted summability results for the Wiener-Hermite coefficient sequences of\nimages of affine-parametric expansions of the log-Gaussian input under\n$\\mathcal{G}$. These results give rise to $N$-term approximation rate bounds\nfor the full range of input summability exponents $p\\in (0,2)$. We show that\nthese approximation rate bounds apply to parameter-to-solution maps for\nelliptic diffusion PDEs with lognormal coefficients.", "published": "2025-04-30 13:40:56", "link": "http://arxiv.org/abs/2504.21639v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Flow Through Porous Media: A Hopf-Cole Transformation Approach for Modeling Pressure-Dependent Viscosity", "abstract": "Most organic liquids exhibit a pressure-dependent viscosity, making it\ncrucial to consider this behavior in applications where pressures significantly\nexceed ambient conditions (e.g., geological carbon sequestration). Mathematical\nmodels describing flow through porous media while accounting for\nviscosity-pressure dependence are nonlinear (e.g., the Barus model). This\nnonlinearity complicates mathematical analysis and makes numerical solutions\nmore time-intensive and prone to convergence issues. In this paper, we\ndemonstrate that the Hopf-Cole transformation, originally developed for\nBurgers' equation, can recast the governing equations -- describing flow\nthrough porous media with pressure-dependent viscosity -- into a linear form.\nThe transformed equations, resembling Darcy's equations in the transformed\nvariables, enable (a) systematic mathematical analysis to establish uniqueness\nand maximum principles, (b) the derivation of a mechanics-based principle, and\n(c) the development of efficient numerical solutions using solvers optimized\nfor Darcy equations. Notably, many properties of the linear Darcy equations\nnaturally extend to nonlinear models that depend on pressure. For example,\nsolutions to these nonlinear models adhere to a reciprocal relation analogous\nto that observed in Darcy's equations.", "published": "2025-04-30 13:00:59", "link": "http://arxiv.org/abs/2504.21603v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "math.NA"}
{"title": "Sibuya probability distributions and numerical evaluation of fractional-order operators", "abstract": "In this work we explore the Sibuya discrete probability distribution, which\nserves as the basis and the main instrument for numerical simulations of\nGrunwald--Letnikov fractional derivatives by the Monte Carlo method. We provide\nthree methods for simulating the Sibuya distribution. We also introduce the\nSibuya-like sieved probability distributions, and apply them to numerical\nfractional-order differentiation. Additionally, we use the Monte Carlo method\nfor evaluating fractional-order integrals, and suggest the notion of the\ncontinuous Sibuya probability distribution. The developed methods and tools are\nillustrated by examples of computation. We provide the MATLAB toolboxes for\nsimulation of the Sibuya probability distribution, and for the numerical\nexamples.", "published": "2025-04-30 11:18:39", "link": "http://arxiv.org/abs/2504.21523v1", "categories": ["math.NA", "cs.NA", "math.PR", "26A33 (primary), 65C05, 65D25"], "primary_category": "math.NA"}
{"title": "Arbitrary precision computation of hydrodynamic stability eigenvalues", "abstract": "We show that by using higher order precision arithmetic, i.e., using floating\npoint types with more significant bits than standard double precision numbers,\none may accurately compute eigenvalues for non-normal matrices arising in\nhydrodynamic stability problems. The basic principle is illustrated by a\nclassical example of two $7\\times 7$ matrices for which it is well known that\neigenvalue computations fail when using standard double precision arithmetic.\nWe then present an implementation of the Chebyshev tau-QZ method allowing the\nuse of a large number of Chebyshev polynomials together with arbitrary\nprecision arithmetic. This is used to compute the behavior of the spectra for\nCouette and Poiseuille flow at high Reynolds number. An experimental\nconvergence analysis finally makes it evident that high order precision is\nrequired to obtain accurate results.", "published": "2025-04-30 10:59:01", "link": "http://arxiv.org/abs/2504.21511v1", "categories": ["math.NA", "cs.NA", "35Q35, 76E06, 76E05, 76D99"], "primary_category": "math.NA"}
{"title": "Uniform-in-time weak error estimates of explicit full-discretization schemes for SPDEs with non-globally Lipschitz coefficients", "abstract": "This article is devoted to long-time weak approximations of stochastic\npartial differential equations (SPDEs) evolving in a bounded domain\n$\\mathcal{D} \\subset \\mathbb{R}^d$, $d \\leq 3$, with non-globally Lipschitz and\npossibly non-contractive coefficients. Both the space-time white noise ($d=1$)\nand the trace-class noise in multiple dimensions $d=2,3$ are examined for the\nconsidered SPDEs. Based on a spectral Galerkin spatial semi-discretization, we\npropose a class of novel full-discretization schemes of exponential type, which\nare explicit, easily implementable and preserve the ergodicity of the original\ndissipative SPDEs with possibly non-contractive coefficients. The\nuniform-in-time weak approximation errors are carefully analyzed in a low\nregularity and non-contractive setting, with uniform-in-time weak convergence\nrates obtained. A key ingredient is to establish the uniform-in-time moment\nbounds (in $L^{4q-2}$-norm, $q \\geq 1$) for the proposed fully discrete schemes\nin a super-linear setting. This is highly non-trivial for the explicit\nfull-discretization schemes and new arguments are elaborated by fully\nexploiting a contractive property of the semi-group in $L^{4q-2}$, the\ndissipativity of the nonlinearity and the particular benefit of the taming\nstrategy. Numerical experiments are finally reported to verify the theoretical\nfindings.", "published": "2025-04-30 06:52:23", "link": "http://arxiv.org/abs/2504.21364v1", "categories": ["math.NA", "cs.NA", "60H35, 60H15, 65C30"], "primary_category": "math.NA"}
{"title": "Virtual Element Method Applied to Two Dimensional Axisymmetric Elastic Problems", "abstract": "This work presents a Virtual Element Method (VEM) formulation tailored for\ntwo-dimensional axisymmetric problems in linear elasticity. By exploiting the\nrotational symmetry of the geometry and loading conditions, the problem is\nreduced to a meridional cross-section, where all fields depend only on the\nradial and axial coordinates. The method incorporates the radial weight $r$ in\nboth the weak formulation and the interpolation estimates to remain consistent\nwith the physical volume measure of cylindrical coordinates. A projection\noperator onto constant strain fields is constructed via boundary integrals, and\na volumetric correction term is introduced to account for the divergence of the\nstress field arising from axisymmetry. The stabilization term is designed to\nact only on the kernel of the projection and is implemented using a\nboundary-based formulation that guarantees stability without affecting\npolynomial consistency. Furthermore, an a priori interpolation error estimate\nis established in a weighted Sobolev space, showing optimal convergence rates.\nThe implementation is validated through patch tests that demonstrate the\naccuracy, consistency, and robustness of the proposed approach.", "published": "2025-04-30 04:26:50", "link": "http://arxiv.org/abs/2504.21305v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Assessing Racial Disparities in Healthcare Expenditures Using Causal Path-Specific Effects", "abstract": "Racial disparities in healthcare expenditures are well-documented, yet the\nunderlying drivers remain complex and require further investigation. This study\nemploys causal and counterfactual path-specific effects to quantify how various\nfactors, including socioeconomic status, insurance access, health behaviors,\nand health status, mediate these disparities. Using data from the Medical\nExpenditures Panel Survey, we estimate how expenditures would differ under\ncounterfactual scenarios in which the values of specific mediators were aligned\nacross racial groups along selected causal pathways. A key challenge in this\nanalysis is ensuring robustness against model misspecification while addressing\nthe zero-inflation and right-skewness of healthcare expenditures. For reliable\ninference, we derive asymptotically linear estimators by integrating influence\nfunction-based techniques with flexible machine learning methods, including\nsuper learners and a two-part model tailored to the zero-inflated, right-skewed\nnature of healthcare expenditures.", "published": "2025-04-30 14:23:50", "link": "http://arxiv.org/abs/2504.21688v1", "categories": ["stat.AP", "stat.ME", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Conditional independence testing with a single realization of a multivariate nonstationary nonlinear time series", "abstract": "Identifying relationships among stochastic processes is a key goal in\ndisciplines that deal with complex temporal systems, such as economics. While\nthe standard toolkit for multivariate time series analysis has many advantages,\nit can be difficult to capture nonlinear dynamics using linear vector\nautoregressive models. This difficulty has motivated the development of methods\nfor variable selection, causal discovery, and graphical modeling for nonlinear\ntime series, which routinely employ nonparametric tests for conditional\nindependence. In this paper, we introduce the first framework for conditional\nindependence testing that works with a single realization of a nonstationary\nnonlinear process. The key technical ingredients are time-varying nonlinear\nregression, time-varying covariance estimation, and a distribution-uniform\nstrong Gaussian approximation.", "published": "2025-04-30 13:51:38", "link": "http://arxiv.org/abs/2504.21647v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "From Aesthetics to Human Preferences: Comparative Perspectives of Evaluating Text-to-Music Systems", "abstract": "Evaluating generative models remains a fundamental challenge, particularly\nwhen the goal is to reflect human preferences. In this paper, we use music\ngeneration as a case study to investigate the gap between automatic evaluation\nmetrics and human preferences. We conduct comparative experiments across five\nstate-of-the-art music generation approaches, assessing both perceptual quality\nand distributional similarity to human-composed music. Specifically, we\nevaluate synthesis music from various perceptual dimensions and examine\nreference-based metrics such as Mauve Audio Divergence (MAD) and Kernel Audio\nDistance (KAD). Our findings reveal significant inconsistencies across the\ndifferent metrics, highlighting the limitation of the current evaluation\npractice. To support further research, we release a benchmark dataset\ncomprising samples from multiple models. This study provides a broader\nperspective on the alignment of human preference in generative modeling,\nadvocating for more human-centered evaluation strategies across domains.", "published": "2025-04-30 17:21:04", "link": "http://arxiv.org/abs/2504.21815v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Impairments are Clustered in Latents of Deep Neural Network-based Speech Quality Models", "abstract": "In this article, we provide an experimental observation: Deep neural network\n(DNN) based speech quality assessment (SQA) models have inherent latent\nrepresentations where many types of impairments are clustered. While DNN-based\nSQA models are not trained for impairment classification, our experiments show\ngood impairment classification results in an appropriate SQA latent\nrepresentation. We investigate the clustering of impairments using various\nkinds of audio degradations that include different types of noises, waveform\nclipping, gain transition, pitch shift, compression, reverberation, etc. To\nvisualize the clusters we perform classification of impairments in the\nSQA-latent representation domain using a standard k-nearest neighbor (kNN)\nclassifier. We also develop a new DNN-based SQA model, named DNSMOS+, to\nexamine whether an improvement in SQA leads to an improvement in impairment\nclassification. The classification accuracy is 94% for LibriAugmented dataset\nwith 16 types of impairments and 54% for ESC-50 dataset with 50 types of real\nnoises.", "published": "2025-04-30 11:22:12", "link": "http://arxiv.org/abs/2504.21528v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Smart Environmental Monitoring of Marine Pollution using Edge AI", "abstract": "Oil spill incidents pose severe threats to marine ecosystems and coastal\nenvironments, necessitating rapid detection and monitoring capabilities to\nmitigate environmental damage. In this paper, we demonstrate how artificial\nintelligence, despite the inherent high computational and memory requirements,\ncan be efficiently integrated into marine pollution monitoring systems. More\nprecisely, we propose a drone-based smart monitoring system leveraging a\ncompressed deep learning U-Net architecture for oil spill detection and\nthickness estimation. Compared to the standard U-Net architecture, the number\nof convolution blocks and channels per block are modified. The new model is\nthen trained on synthetic radar data to accurately predict thick oil slick\nthickness up to 10 mm. Results show that our optimized Tiny U-Net achieves\nsuperior performance with an Intersection over Union (IoU) metric of\napproximately 79%, while simultaneously reducing the model size by a factor of\n$\\sim$269x compared to the state-of-the-art. This significant model compression\nenables efficient edge computing deployment on field-programmable gate array\n(FPGA) hardware integrated directly into the drone platform. Hardware\nimplementation demonstrates near real-time thickness estimation capabilities\nwith a run-time power consumption of approximately 2.2 watts. Our findings\nhighlight the increasing potential of smart monitoring technologies and\nefficient edge computing for operational characterization in marine\nenvironments.", "published": "2025-04-30 15:59:35", "link": "http://arxiv.org/abs/2504.21759v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Obstructive Sleep Apnea Characterization: A Multimodal Cross-Recurrence-Based Approach for Investigating Atrial Fibrillation", "abstract": "Obstructive sleep apnea (OSA) is believed to contribute significantly to\natrial fibrillation (AF) development in certain patients. Recent studies\nindicate a rising risk of AF with increasing OSA severity. However, the\ncommonly used apnea-hypopnea index in clinical practice may not adequately\naccount for the potential cardiovascular risks associated with OSA. (1)\nObjective: to propose and explore a novel method for assessing OSA severity\nconsidering potential connection to cardiac arrhythmias. (2) Method: the\napproach utilizes cross-recurrence features to characterize OSA and AF by\nconsidering the relationships among oxygen desaturation, pulse arrival time,\nand heart-beat intervals. Multinomial logistic regression models were trained\nto predict four levels of OSA severity and four groups related to heart rhythm\nissues. The rank biserial correlation coefficient, rrb, was used to estimate\neffect size for statistical analysis. The investigation was conducted using the\nMESA database, which includes polysomnography data from 2055 subjects. (3)\nResults: a derived cross-recurrence-based index showed a significant\nassociation with a higher OSA severity (p < 0.01) and the presence of AF (p <\n0.01). Additionally, the proposed index had a significantly larger effect, rrb,\nthan the conventional apnea-hypopnea index in differentiating increasingly\nsevere heart rhythm issue groups: 0.14 > 0.06, 0.33 > 0.10, and 0.41 > 0.07.\n(4) Significance: the proposed method holds relevance as a supplementary\ndiagnostic tool for assessing the authentic state of sleep apnea in clinical\npractice.", "published": "2025-04-30 15:39:07", "link": "http://arxiv.org/abs/2504.21743v1", "categories": ["physics.med-ph", "eess.SP"], "primary_category": "physics.med-ph"}
{"title": "Task-Agnostic Semantic Communications Relying on Information Bottleneck and Federated Meta-Learning", "abstract": "As a paradigm shift towards pervasive intelligence, semantic communication\n(SemCom) has shown great potentials to improve communication efficiency and\nprovide user-centric services by delivering task-oriented semantic meanings.\nHowever, the exponential growth in connected devices, data volumes, and\ncommunication demands presents significant challenges for practical SemCom\ndesign, particularly in resource-constrained wireless networks. In this work,\nwe first propose a task-agnostic SemCom (TASC) framework that can handle\ndiverse tasks with multiple modalities. Aiming to explore the interplay between\ncommunications and intelligent tasks from the information-theoretical\nperspective, we leverage information bottleneck (IB) theory and propose a\ndistributed multimodal IB (DMIB) principle to learn minimal and sufficient\nunimodal and multimodal information effectively by discarding redundancy while\npreserving task-related information. To further reduce the communication\noverhead, we develop an adaptive semantic feature transmission method under\ndynamic channel conditions. Then, TASC is trained based on federated\nmeta-learning (FML) for rapid adaptation and generalization in wireless\nnetworks. To gain deep insights, we rigorously conduct theoretical analysis and\ndevise resource management to accelerate convergence while minimizing the\ntraining latency and energy consumption. Moreover, we develop a joint user\nselection and resource allocation algorithm to address the non-convex problem\nwith theoretical guarantees. Extensive simulation results validate the\neffectiveness and superiority of the proposed TASC compared to baselines.", "published": "2025-04-30 15:09:07", "link": "http://arxiv.org/abs/2504.21723v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Generalizing Biased Backpressure Routing and Scheduling to Wireless Multi-hop Networks with Advanced Air-interfaces", "abstract": "Backpressure (BP) routing and scheduling is a well-established resource\nallocation method for wireless multi-hop networks, known for its fully\ndistributed operations and proven maximum queue stability. Recent advances in\nshortest path-biased BP routing (SP-BP) mitigate shortcomings such as slow\nstartup and random walk, but exclusive link-level commodity selection still\nsuffers from the last-packet problem and bandwidth underutilization. Moreover,\nclassic BP routing implicitly assumes single-input-single-output (SISO)\ntransceivers, which can lead to the same packets being scheduled on multiple\noutgoing links for multiple-input-multiple-output (MIMO) transceivers, causing\ndetouring and looping in MIMO networks. In this paper, we revisit the\nfoundational Lyapunov drift theory underlying BP routing and demonstrate that\nexclusive commodity selection is unnecessary, and instead propose a Max-Utility\nlink-sharing method. Additionally, we generalize MaxWeight scheduling to MIMO\nnetworks by introducing attributed capacity hypergraphs (ACH), an extension of\ntraditional conflict graphs for SISO networks, and by incorporating backlog\nreassignment into scheduling iterations to prevent redundant packet routing.\nNumerical evaluations show that our approach substantially mitigates the\nlast-packet problem in state-of-the-art (SOTA) SP-BP under lightweight traffic,\nand slightly expands the network capacity region for heavier traffic.", "published": "2025-04-30 15:06:44", "link": "http://arxiv.org/abs/2504.21721v1", "categories": ["cs.NI", "cs.SY", "eess.SP", "eess.SY", "05C12 (Primary) 05-08 (Secondary)", "C.2.2; C.2.1; I.2.11; I.2.6"], "primary_category": "cs.NI"}
{"title": "Random Features for Grassmannian Kernels", "abstract": "The Grassmannian manifold G(k, n) serves as a fundamental tool in signal\nprocessing, computer vision, and machine learning, where problems often involve\nclassifying, clustering, or comparing subspaces. In this work, we propose a\nsketching-based approach to approximate Grassmannian kernels using random\nprojections. We introduce three variations of kernel approximation, including\ntwo that rely on binarised sketches, offering substantial memory gains. We\nestablish theoretical properties of our method in the special case of G(1, n)\nand extend it to general G(k, n). Experimental validation demonstrates that our\nsketched kernels closely match the performance of standard Grassmannian kernels\nwhile avoiding the need to compute or store the full kernel matrix. Our\napproach enables scalable Grassmannian-based methods for large-scale\napplications in machine learning and pattern recognition.", "published": "2025-04-30 11:28:14", "link": "http://arxiv.org/abs/2504.21533v1", "categories": ["eess.SP", "eess.IV"], "primary_category": "eess.SP"}
{"title": "Anti-Intercept OFDM Waveform Design with Secure Coding for Satellite Networks", "abstract": "Low Earth Orbit (LEO) satellite networks are integral to next-generation\ncommunication systems, providing global coverage, low latency, and minimal\nsignal loss. However, their unique characteristics, such as constrained onboard\nresources, Line-of-Sight (LoS) propagation, and vulnerability to eavesdropping\nover wide coverage areas, present significant challenges to physical layer\nsecurity. To address these challenges, this paper focuses on the design of\nanti-intercept waveforms for satellite-ground links within Orthogonal Frequency\nDivision Multiplexing (OFDM) systems, aiming to enhance security against\neavesdropping threats. We formulate a secrecy rate maximization problem that\naims to balance secrecy performance and communication reliability under\neavesdropping constraints and sub-carrier power limitations. To solve this\nnon-convex optimization problem, we propose a bisection search-activated neural\nnetwork (BSA-Net) that integrates unsupervised learning for secure coding\noptimization and bisection search for dynamic power allocation. The proposed\nmethod is structured in two stages: the first optimizes secure coding under\npower constraints, while the second allocates power across sub-carriers under\neavesdropping constraints. Extensive simulation results demonstrate the\nefficacy of our approach, showcasing significant improvements in secrecy rate\nperformance.", "published": "2025-04-30 09:05:08", "link": "http://arxiv.org/abs/2504.21446v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and Applications to Streaming Differential Privacy", "abstract": "Buffered Linear Toeplitz (BLT) matrices are a family of parameterized\nlower-triangular matrices that play an important role in streaming differential\nprivacy with correlated noise. Our main result is a BLT inversion theorem: the\ninverse of a BLT matrix is itself a BLT matrix with different parameters. We\nalso present an efficient and differentiable $O(d^3)$ algorithm to compute the\nparameters of the inverse BLT matrix, where $d$ is the degree of the original\nBLT (typically $d < 10$). Our characterization enables direct optimization of\nBLT parameters for privacy mechanisms through automatic differentiation.", "published": "2025-04-30 08:14:09", "link": "http://arxiv.org/abs/2504.21413v1", "categories": ["cs.CR", "eess.SP"], "primary_category": "cs.CR"}
{"title": "Towards Intelligent Edge Sensing for ISCC Network: Joint Multi-Tier DNN Partitioning and Beamforming Design", "abstract": "The combination of Integrated Sensing and Communication (ISAC) and Mobile\nEdge Computing (MEC) enables devices to simultaneously sense the environment\nand offload data to the base stations (BS) for intelligent processing, thereby\nreducing local computational burdens. However, transmitting raw sensing data\nfrom ISAC devices to the BS often incurs substantial fronthaul overhead and\nlatency. This paper investigates a three-tier collaborative inference framework\nenabled by Integrated Sensing, Communication, and Computing (ISCC), where cloud\nservers, MEC servers, and ISAC devices cooperatively execute different segments\nof a pre-trained deep neural network (DNN) for intelligent sensing. By\noffloading intermediate DNN features, the proposed framework can significantly\nreduce fronthaul transmission load. Furthermore, multiple-input multiple-output\n(MIMO) technology is employed to enhance both sensing quality and offloading\nefficiency. To minimize the overall sensing task inference latency across all\nISAC devices, we jointly optimize the DNN partitioning strategy, ISAC\nbeamforming, and computational resource allocation at the MEC servers and\ndevices, subject to sensing beampattern constraints. We also propose an\nefficient two-layer optimization algorithm. In the inner layer, we derive\nclosed-form solutions for computational resource allocation using the\nKarush-Kuhn-Tucker conditions. Moreover, we design the ISAC beamforming vectors\nvia an iterative method based on the majorization-minimization and weighted\nminimum mean square error techniques. In the outer layer, we develop a\ncross-entropy based probabilistic learning algorithm to determine an optimal\nDNN partitioning strategy. Simulation results demonstrate that the proposed\nframework substantially outperforms existing two-tier schemes in inference\nlatency.", "published": "2025-04-30 08:09:59", "link": "http://arxiv.org/abs/2504.21409v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Electromagnetic Modelling of Extended Targets in a Distributed Antenna System", "abstract": "Traditional radar and integrated sensing and communication (ISAC) systems\noften approximate targets as point sources, a simplification that fails to\ncapture the essential scattering characteristics for many applications. This\npaper presents a novel electromagnetic (EM)-based framework to accurately model\nthe near-field (NF) scattering response of extended targets, which is then\napplied to three canonical shapes : a flat rectangular plate, a sphere and a\ncylinder. Mathematical expressions for the received signal are provided in each\ncase. Based on this model, the influence of bandwidth, carrier frequency and\ntarget distance on localisation accuracy is analysed, showing how higher\nbandwidths and carrier frequencies improve resolution. Additionally, the impact\nof target curvature on localisation performance is studied. Results indicate\nthat detection performance is slightly enhanced when considering curved\nobjects. A comparative analysis between the extended and point target models\nshows significant similarities when targets are small and curved. However, as\nthe target size increases or becomes flatter, the point target model introduces\nestimation errors owing to model mismatch. The impact of this model mismatch as\na function of system parameters is analysed, and the operational zones where\nthe point abstraction remains valid and where it breaks down are identified.\nThese findings provide theoretical support for experimental results based on\npoint-target models in previous studies.", "published": "2025-04-30 07:40:27", "link": "http://arxiv.org/abs/2504.21388v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Three-Stage Composite Outlier Identification of Wind Power Data: Integrating Physical Rules with Regression Learning and Mathematical Morphology", "abstract": "Existing studies on identifying outliers in wind speed-power datasets are\noften challenged by the complicated and irregular distributions of outliers,\nespecially those being densely stacked yet staying close to normal data. This\ncould degrade their identification reliability and robustness in practice. To\naddress this defect, this paper develops a three-stage composite outlier\nidentification method by systematically integrating three complementary\ntechniques, i.e., physical rule-based preprocessing, regression\nlearning-enabled detection, and mathematical morphology-based refinement.\nFirstly, the raw wind speed-power data are preprocessed via a set of simple yet\nefficient physical rules to filter out some outliers obviously going against\nthe physical operating laws of practical wind turbines. Secondly, a robust wind\nspeed-power regression learning model is built upon the random sample consensus\nalgorithm. This model is able to reliably detect most outliers with the help of\nan adaptive threshold automatically set by the interquartile range method.\nThirdly, by representing the wind speed-power data distribution with a\ntwo-dimensional image, mathematical morphology operations are applied to\nperform refined outlier identification from a data distribution perspective.\nThis technique can identify outliers that are not effectively detected in the\nfirst two stages, including those densely stacked ones near normal data points.\nBy integrating the above three techniques, the whole method is capable of\nidentifying various types of outliers in a reliable and adaptive manner.\nNumerical test results with wind power datasets acquired from distinct wind\nturbines in practice and from simulation environments extensively demonstrate\nthe superiority of the proposed method as well as its potential in enhancing\nwind power prediction.", "published": "2025-04-30 06:19:38", "link": "http://arxiv.org/abs/2504.21354v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Waveform Design Based on Mutual Information Upper Bound For Joint Detection and Estimation", "abstract": "Adaptive radar waveform design grounded in information-theoretic principles\nis critical for advancing cognitive radar performance in complex environments.\nThis paper investigates the optimization of phase-coded waveforms under\nconstant modulus constraints to jointly enhance target detection and parameter\nestimation. We introduce a unified design framework based on maximizing a\nMutual Information Upper Bound (MIUB), which inherently reconciles the\ntrade-off between detection sensitivity and estimation precision without\nrelying on ad hoc weighting schemes. To model realistic, potentially\nnon-Gaussian statistics of target returns and clutter, we adopt Gaussian\nMixture Distributions (GMDs), enabling analytically tractable approximations of\nthe MIUB's constituent Kullback-Leibler divergence and mutual information\nterms. To address the resulting non-convex problem, we propose the Phase-Coded\nDream Optimization Algorithm (PC-DOA), a tailored metaheuristic that leverages\nhybrid initialization and adaptive exploration-exploitation mechanisms\nspecifically designed for phase-variable optimization. Numerical simulations\ndemonstrate the effectiveness of the proposed method in achieving modestly\nbetter detection-estimation trade-off.", "published": "2025-04-30 05:17:45", "link": "http://arxiv.org/abs/2504.21322v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues", "abstract": "The growing adoption of synthetic data in healthcare is driven by privacy\nconcerns, limited access to real-world data, and the high cost of annotation.\nThis work explores the use of synthetic Prolonged Exposure (PE) therapeutic\nconversations for Post-Traumatic Stress Disorder (PTSD) as a scalable\nalternative for training and evaluating clinical models. We systematically\ncompare real and synthetic dialogues using linguistic, structural, and\nprotocol-specific metrics, including turn-taking patterns and treatment\nfidelity. We also introduce and evaluate PE-specific metrics derived from\nlinguistic analysis and semantic modeling, offering a novel framework for\nassessing clinical fidelity beyond surface fluency. Our findings show that\nalthough synthetic data holds promise for mitigating data scarcity and\nprotecting patient privacy, it can struggle to capture the subtle dynamics of\ntherapeutic interactions. Synthetic therapy dialogues closely match structural\nfeatures of real-world conversations (e.g., speaker switch ratio: 0.98 vs.\n0.99); however, they may not adequately reflect key fidelity markers (e.g.,\ndistress monitoring). We highlight gaps in existing evaluation frameworks and\nadvocate for fidelity-aware metrics that go beyond surface fluency to uncover\nclinically significant failures. Our findings clarify where synthetic data can\neffectively complement real-world datasets -- and where critical limitations\nremain.", "published": "2025-04-30 16:56:56", "link": "http://arxiv.org/abs/2504.21800v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "68T50", "I.2.7; H.3.1"], "primary_category": "cs.CL"}
{"title": "TRIED: Truly Innovative and Effective AI Detection Benchmark, developed by WITNESS", "abstract": "The proliferation of generative AI and deceptive synthetic media threatens\nthe global information ecosystem, especially across the Global Majority. This\nreport from WITNESS highlights the limitations of current AI detection tools,\nwhich often underperform in real-world scenarios due to challenges related to\nexplainability, fairness, accessibility, and contextual relevance. In response,\nWITNESS introduces the Truly Innovative and Effective AI Detection (TRIED)\nBenchmark, a new framework for evaluating detection tools based on their\nreal-world impact and capacity for innovation. Drawing on frontline\nexperiences, deceptive AI cases, and global consultations, the report outlines\nhow detection tools must evolve to become truly innovative and relevant by\nmeeting diverse linguistic, cultural, and technological contexts. It offers\npractical guidance for developers, policy actors, and standards bodies to\ndesign accountable, transparent, and user-centered detection solutions, and\nincorporate sociotechnical considerations into future AI standards, procedures\nand evaluation frameworks. By adopting the TRIED Benchmark, stakeholders can\ndrive innovation, safeguard public trust, strengthen AI literacy, and\ncontribute to a more resilient global information credibility.", "published": "2025-04-30 10:18:19", "link": "http://arxiv.org/abs/2504.21489v2", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of Binary Classification", "abstract": "To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation (DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.", "published": "2025-04-30 13:34:06", "link": "http://arxiv.org/abs/2504.21632v2", "categories": ["cs.IT", "eess.IV", "math.IT"], "primary_category": "cs.IT"}
{"title": "Task-Agnostic Semantic Communications Relying on Information Bottleneck and Federated Meta-Learning", "abstract": "As a paradigm shift towards pervasive intelligence, semantic communication\n(SemCom) has shown great potentials to improve communication efficiency and\nprovide user-centric services by delivering task-oriented semantic meanings.\nHowever, the exponential growth in connected devices, data volumes, and\ncommunication demands presents significant challenges for practical SemCom\ndesign, particularly in resource-constrained wireless networks. In this work,\nwe first propose a task-agnostic SemCom (TASC) framework that can handle\ndiverse tasks with multiple modalities. Aiming to explore the interplay between\ncommunications and intelligent tasks from the information-theoretical\nperspective, we leverage information bottleneck (IB) theory and propose a\ndistributed multimodal IB (DMIB) principle to learn minimal and sufficient\nunimodal and multimodal information effectively by discarding redundancy while\npreserving task-related information. To further reduce the communication\noverhead, we develop an adaptive semantic feature transmission method under\ndynamic channel conditions. Then, TASC is trained based on federated\nmeta-learning (FML) for rapid adaptation and generalization in wireless\nnetworks. To gain deep insights, we rigorously conduct theoretical analysis and\ndevise resource management to accelerate convergence while minimizing the\ntraining latency and energy consumption. Moreover, we develop a joint user\nselection and resource allocation algorithm to address the non-convex problem\nwith theoretical guarantees. Extensive simulation results validate the\neffectiveness and superiority of the proposed TASC compared to baselines.", "published": "2025-04-30 15:09:07", "link": "http://arxiv.org/abs/2504.21723v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems", "abstract": "Failure attribution in LLM multi-agent systems-identifying the agent and step\nresponsible for task failures-provides crucial clues for systems debugging but\nremains underexplored and labor-intensive. In this paper, we propose and\nformulate a new research area: automated failure attribution for LLM\nmulti-agent systems. To support this initiative, we introduce the Who&When\ndataset, comprising extensive failure logs from 127 LLM multi-agent systems\nwith fine-grained annotations linking failures to specific agents and decisive\nerror steps. Using the Who&When, we develop and evaluate three automated\nfailure attribution methods, summarizing their corresponding pros and cons. The\nbest method achieves 53.5% accuracy in identifying failure-responsible agents\nbut only 14.2% in pinpointing failure steps, with some methods performing below\nrandom. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to\nachieve practical usability. These results highlight the task's complexity and\nthe need for further research in this area. Code and dataset are available at\nhttps://github.com/mingyin1/Agents_Failure_Attribution", "published": "2025-04-30 23:09:44", "link": "http://arxiv.org/abs/2505.00212v1", "categories": ["cs.MA", "cs.CL"], "primary_category": "cs.MA"}
{"title": "IP-CRR: Information Pursuit for Interpretable Classification of Chest Radiology Reports", "abstract": "The development of AI-based methods for analyzing radiology reports could\nlead to significant advances in medical diagnosis--from improving diagnostic\naccuracy to enhancing efficiency and reducing workload. However, the lack of\ninterpretability in these methods has hindered their adoption in clinical\nsettings. In this paper, we propose an interpretable-by-design framework for\nclassifying radiology reports. The key idea is to extract a set of most\ninformative queries from a large set of reports and use these queries and their\ncorresponding answers to predict a diagnosis. Thus, the explanation for a\nprediction is, by construction, the set of selected queries and answers. We use\nthe Information Pursuit framework to select informative queries, the Flan-T5\nmodel to determine if facts are present in the report, and a classifier to\npredict the disease. Experiments on the MIMIC-CXR dataset demonstrate the\neffectiveness of the proposed method, highlighting its potential to enhance\ntrust and usability in medical AI.", "published": "2025-04-30 21:20:05", "link": "http://arxiv.org/abs/2505.00191v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models", "abstract": "The rapid evolution of social media has provided enhanced communication\nchannels for individuals to create online content, enabling them to express\ntheir thoughts and opinions. Multimodal memes, often utilized for playful or\nhumorous expressions with visual and textual elements, are sometimes misused to\ndisseminate hate speech against individuals or groups. While the detection of\nhateful memes is well-researched, developing effective methods to transform\nhateful content in memes remains a significant challenge. Leveraging the\npowerful generation and reasoning capabilities of Vision-Language Models\n(VLMs), we address the tasks of detecting and mitigating hateful content. This\npaper presents two key contributions: first, a definition-guided prompting\ntechnique for detecting hateful memes, and second, a unified framework for\nmitigating hateful content in memes, named UnHateMeme, which works by replacing\nhateful textual and/or visual components. With our definition-guided prompts,\nVLMs achieve impressive performance on hateful memes detection task.\nFurthermore, our UnHateMeme framework, integrated with VLMs, demonstrates a\nstrong capability to convert hateful memes into non-hateful forms that meet\nhuman-level criteria for hate speech and maintain multimodal coherence between\nimage and text. Through empirical experiments, we show the effectiveness of\nstate-of-the-art pretrained VLMs such as LLaVA, Gemini and GPT-4o on the\nproposed tasks, providing a comprehensive analysis of their respective\nstrengths and limitations for these tasks. This paper aims to shed light on\nimportant applications of VLMs for ensuring safe and respectful online\nenvironments.", "published": "2025-04-30 19:48:12", "link": "http://arxiv.org/abs/2505.00150v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "AdaptMI: Adaptive Skill-based In-context Math Instruction for Small Language Models", "abstract": "In-context learning (ICL) allows a language model to improve its\nproblem-solving capability when provided with suitable information in context.\nSince the choice of in-context information can be determined based on the\nproblem itself, in-context learning is analogous to human learning from\nteachers in a classroom. Recent works (Didolkar et al., 2024a; 2024b) show that\nICL performance can be improved by leveraging a frontier large language model's\n(LLM) ability to predict required skills to solve a problem, popularly referred\nto as an LLM's metacognition, and using the recommended skills to construct\nnecessary in-context examples. While this skill-based strategy boosts ICL\nperformance in larger models, its gains on small language models (SLMs) have\nbeen minimal, highlighting a performance gap in ICL capabilities. We\ninvestigate this gap and show that skill-based prompting can hurt SLM\nperformance on easy questions by introducing unnecessary information, akin to\ncognitive overload. To address this, we introduce AdaptMI, an adaptive approach\nto selecting skill-based in-context Math Instructions for SLMs. Inspired by\ncognitive load theory from human pedagogy, our method only introduces\nskill-based examples when the model performs poorly. We further propose\nAdaptMI+, which adds examples targeted to the specific skills missing from the\nmodel's responses. On 5-shot evaluations across popular math benchmarks and\nfive SLMs (1B--7B; Qwen, Llama), AdaptMI+ improves accuracy by up to 6% over\nnaive skill-based strategies.", "published": "2025-04-30 19:35:46", "link": "http://arxiv.org/abs/2505.00147v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs", "abstract": "Large language models (LLMs) are increasingly optimized for long reasoning,\nunder the assumption that more reasoning leads to better performance. However,\nemerging evidence suggests that longer responses can sometimes degrade accuracy\nrather than improve it. In this paper, we conduct a systematic empirical study\nof the relationship between reasoning length and answer correctness. We find\nthat LLMs tend to overthink simple problems, generating unnecessarily long\noutputs, and underthink harder ones, failing to extend their reasoning when it\nis most needed. This indicates that models might misjudge problem difficulty\nand fail to calibrate their response length appropriately. Furthermore, we\ninvestigate the effects of length reduction with a preference optimization\nalgorithm when simply preferring the shorter responses regardless of answer\ncorrectness. Experiments show that the generation length can be significantly\nreduced while maintaining acceptable accuracy. Our findings highlight\ngeneration length as a meaningful signal for reasoning behavior and motivate\nfurther exploration into LLMs' self-awareness in reasoning length adaptation.", "published": "2025-04-30 18:48:06", "link": "http://arxiv.org/abs/2505.00127v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of Lebanese", "abstract": "This paper examines the effectiveness of Large Language Models (LLMs) in\ntranslating the low-resource Lebanese dialect, focusing on the impact of\nculturally authentic data versus larger translated datasets. We compare three\nfine-tuning approaches: Basic, contrastive, and grammar-hint tuning, using\nopen-source Aya23 models. Experiments reveal that models fine-tuned on a\nsmaller but culturally aware Lebanese dataset (LW) consistently outperform\nthose trained on larger, non-native data. The best results were achieved\nthrough contrastive fine-tuning paired with contrastive prompting, which\nindicates the benefits of exposing translation models to bad examples. In\naddition, to ensure authentic evaluation, we introduce LebEval, a new benchmark\nderived from native Lebanese content, and compare it to the existing FLoRes\nbenchmark. Our findings challenge the \"More Data is Better\" paradigm and\nemphasize the crucial role of cultural authenticity in dialectal translation.\nWe made our datasets and code available on Github.", "published": "2025-04-30 18:33:53", "link": "http://arxiv.org/abs/2505.00114v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques", "abstract": "Retrieval-Augmented Generation enhances language models by retrieving\nrelevant information from external knowledge bases, relying on high-dimensional\nvector embeddings typically stored in float32 precision. However, storing these\nembeddings at scale presents significant memory challenges. To address this\nissue, we systematically investigate on MTEB benchmark two complementary\noptimization strategies: quantization, evaluating standard formats (float16,\nint8, binary) and low-bit floating-point types (float8), and dimensionality\nreduction, assessing methods like PCA, Kernel PCA, UMAP, Random Projections and\nAutoencoders. Our results show that float8 quantization achieves a 4x storage\nreduction with minimal performance degradation (<0.3%), significantly\noutperforming int8 quantization at the same compression level, being simpler to\nimplement. PCA emerges as the most effective dimensionality reduction\ntechnique. Crucially, combining moderate PCA (e.g., retaining 50% dimensions)\nwith float8 quantization offers an excellent trade-off, achieving 8x total\ncompression with less performance impact than using int8 alone (which provides\nonly 4x compression). To facilitate practical application, we propose a\nmethodology based on visualizing the performance-storage trade-off space to\nidentify the optimal configuration that maximizes performance within their\nspecific memory constraints.", "published": "2025-04-30 18:20:16", "link": "http://arxiv.org/abs/2505.00105v1", "categories": ["cs.IR", "cs.CL", "cs.DB"], "primary_category": "cs.IR"}
{"title": "ConSens: Assessing context grounding in open-book question answering", "abstract": "Large Language Models (LLMs) have demonstrated considerable success in\nopen-book question answering (QA), where the task requires generating answers\ngrounded in a provided external context. A critical challenge in open-book QA\nis to ensure that model responses are based on the provided context rather than\nits parametric knowledge, which can be outdated, incomplete, or incorrect.\nExisting evaluation methods, primarily based on the LLM-as-a-judge approach,\nface significant limitations, including biases, scalability issues, and\ndependence on costly external systems. To address these challenges, we propose\na novel metric that contrasts the perplexity of the model response under two\nconditions: when the context is provided and when it is not. The resulting\nscore quantifies the extent to which the model's answer relies on the provided\ncontext. The validity of this metric is demonstrated through a series of\nexperiments that show its effectiveness in identifying whether a given answer\nis grounded in the provided context. Unlike existing approaches, this metric is\ncomputationally efficient, interpretable, and adaptable to various use cases,\noffering a scalable and practical solution to assess context utilization in\nopen-book QA systems.", "published": "2025-04-30 16:23:15", "link": "http://arxiv.org/abs/2505.00065v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling", "abstract": "The rapid advancement of multimodal large language models (MLLMs) has\nprofoundly impacted the document domain, creating a wide array of application\nscenarios. This progress highlights the need for a comprehensive benchmark to\nevaluate these models' capabilities across various document-specific tasks.\nHowever, existing benchmarks often fail to locate specific model weaknesses or\nguide systematic improvements. To bridge this gap, we introduce a General\nDocument Intelligence Benchmark (GDI-Bench), featuring 1.9k images across 9 key\nscenarios and 19 document-specific tasks. By decoupling visual complexity and\nreasoning complexity, the GDI-Bench structures graded tasks that allow\nperformance assessment by difficulty, aiding in model weakness identification\nand optimization guidance. We evaluate the GDI-Bench on various open-source and\nclosed-source models, conducting decoupled analyses in the visual and reasoning\ndomains. For instance, the GPT-4o model excels in reasoning tasks but exhibits\nlimitations in visual capabilities. To address the diverse tasks and domains in\nthe GDI-Bench, we propose a GDI Model that mitigates the issue of catastrophic\nforgetting during the supervised fine-tuning (SFT) process through a\nintelligence-preserving training strategy. Our model achieves state-of-the-art\nperformance on previous benchmarks and the GDI-Bench. Both our benchmark and\nmodel will be open source.", "published": "2025-04-30 15:46:46", "link": "http://arxiv.org/abs/2505.00063v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems", "abstract": "This study examines vulnerabilities in transformer-based automated\nshort-answer grading systems used in medical education, with a focus on how\nthese systems can be manipulated through adversarial gaming strategies. Our\nresearch identifies three main types of gaming strategies that exploit the\nsystem's weaknesses, potentially leading to false positives. To counteract\nthese vulnerabilities, we implement several adversarial training methods\ndesigned to enhance the systems' robustness. Our results indicate that these\nmethods significantly reduce the susceptibility of grading systems to such\nmanipulations, especially when combined with ensemble techniques like majority\nvoting and ridge regression, which further improve the system's defense against\nsophisticated adversarial inputs. Additionally, employing large language models\nsuch as GPT-4 with varied prompting techniques has shown promise in recognizing\nand scoring gaming strategies effectively. The findings underscore the\nimportance of continuous improvements in AI-driven educational tools to ensure\ntheir reliability and fairness in high-stakes settings.", "published": "2025-04-30 14:53:09", "link": "http://arxiv.org/abs/2505.00061v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Fact-Consistency Evaluation of Text-to-SQL Generation for Business Intelligence Using Exaone 3.5", "abstract": "Large Language Models (LLMs) have shown promise in enabling natural language\ninterfaces for structured data querying through text-to-SQL generation.\nHowever, their application in real-world Business Intelligence (BI) contexts\nremains limited due to semantic hallucinations, structural errors, and a lack\nof domain-specific evaluation frameworks. In this study, we propose a\nFact-Consistency Evaluation Framework for assessing the semantic accuracy of\nLLM-generated SQL outputs using Exaone 3.5--an instruction-tuned, bilingual LLM\noptimized for enterprise tasks. We construct a domain-specific benchmark\ncomprising 219 natural language business questions across five SQL complexity\nlevels, derived from actual sales data in LG Electronics' internal BigQuery\nenvironment. Each question is paired with a gold-standard SQL query and a\nvalidated ground-truth answer. We evaluate model performance using answer\naccuracy, execution success rate, semantic error rate, and non-response rate.\nExperimental results show that while Exaone 3.5 performs well on simple\naggregation tasks (93% accuracy in L1), it exhibits substantial degradation in\narithmetic reasoning (4% accuracy in H1) and grouped ranking tasks (31% in H4),\nwith semantic errors and non-responses concentrated in complex cases.\nQualitative error analysis further identifies common failure types such as\nmisapplied arithmetic logic, incomplete filtering, and incorrect grouping\noperations. Our findings highlight the current limitations of LLMs in\nbusiness-critical environments and underscore the need for fact-consistency\nvalidation layers and hybrid reasoning approaches. This work contributes a\nreproducible benchmark and evaluation methodology for advancing reliable\nnatural language interfaces to structured enterprise data systems.", "published": "2025-04-30 14:42:18", "link": "http://arxiv.org/abs/2505.00060v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "BERSting at the Screams: A Benchmark for Distanced, Emotional and Shouted Speech Recognition", "abstract": "Some speech recognition tasks, such as automatic speech recognition (ASR),\nare approaching or have reached human performance in many reported metrics.\nYet, they continue to struggle in complex, real-world, situations, such as with\ndistanced speech. Previous challenges have released datasets to address the\nissue of distanced ASR, however, the focus remains primarily on distance,\nspecifically relying on multi-microphone array systems. Here we present the\nB(asic) E(motion) R(andom phrase) S(hou)t(s) (BERSt) dataset. The dataset\ncontains almost 4 hours of English speech from 98 actors with varying regional\nand non-native accents. The data was collected on smartphones in the actors\nhomes and therefore includes at least 98 different acoustic environments. The\ndata also includes 7 different emotion prompts and both shouted and spoken\nutterances. The smartphones were places in 19 different positions, including\nobstructions and being in a different room than the actor. This data is\npublicly available for use and can be used to evaluate a variety of speech\nrecognition tasks, including: ASR, shout detection, and speech emotion\nrecognition (SER). We provide initial benchmarks for ASR and SER tasks, and\nfind that ASR degrades both with an increase in distance and shout level and\nshows varied performance depending on the intended emotion. Our results show\nthat the BERSt dataset is challenging for both ASR and SER tasks and continued\nwork is needed to improve the robustness of such systems for more accurate\nreal-world use.", "published": "2025-04-30 14:08:14", "link": "http://arxiv.org/abs/2505.00059v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Report on the llms evaluating the high school questions", "abstract": "This report aims to evaluate the performance of large language models (LLMs)\nin solving high school science questions and to explore their potential\napplications in the educational field. With the rapid development of LLMs in\nthe field of natural language processing, their application in education has\nattracted widespread attention. This study selected mathematics exam questions\nfrom the college entrance examinations (2019-2023) as evaluation data and\nutilized at least eight LLM APIs to provide answers. A comprehensive assessment\nwas conducted based on metrics such as accuracy, response time, logical\nreasoning, and creativity. Through an in-depth analysis of the evaluation\nresults, this report reveals the strengths and weaknesses of LLMs in handling\nhigh school science questions and discusses their implications for educational\npractice. The findings indicate that although LLMs perform excellently in\ncertain aspects, there is still room for improvement in logical reasoning and\ncreative problem-solving. This report provides an empirical foundation for\nfurther research and application of LLMs in the educational field and offers\nsuggestions for improvement.", "published": "2025-04-30 11:54:23", "link": "http://arxiv.org/abs/2505.00057v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity", "abstract": "Meme clustering is critical for toxicity detection, virality modeling, and\ntyping, but it has received little attention in previous research. Clustering\nsimilar Internet memes is challenging due to their multimodality, cultural\ncontext, and adaptability. Existing approaches rely on databases, overlook\nsemantics, and struggle to handle diverse dimensions of similarity. This paper\nintroduces a novel method that uses template-based matching with\nmulti-dimensional similarity features, thus eliminating the need for predefined\ndatabases and supporting adaptive matching. Memes are clustered using local and\nglobal features across similarity categories such as form, visual content,\ntext, and identity. Our combined approach outperforms existing clustering\nmethods, producing more consistent and coherent clusters, while\nsimilarity-based feature sets enable adaptability and align with human\nintuition. We make all supporting code publicly available to support subsequent\nresearch. Code: https://github.com/tygobl/meme-clustering", "published": "2025-04-30 11:25:30", "link": "http://arxiv.org/abs/2505.00056v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Emotional Analysis of Fashion Trends Using Social Media and AI: Sentiment Analysis on Twitter for Fashion Trend Forecasting", "abstract": "This study explores the intersection of fashion trends and social media\nsentiment through computational analysis of Twitter data using the T4SA\n(Twitter for Sentiment Analysis) dataset. By applying natural language\nprocessing and machine learning techniques, we examine how sentiment patterns\nin fashion-related social media conversations can serve as predictors for\nemerging fashion trends. Our analysis involves the identification and\ncategorization of fashion-related content, sentiment classification with\nimproved normalization techniques, time series decomposition, statistically\nvalidated causal relationship modeling, cross-platform sentiment comparison,\nand brand-specific sentiment analysis. Results indicate correlations between\nsentiment patterns and fashion theme popularity, with accessories and\nstreetwear themes showing statistically significant rising trends. The Granger\ncausality analysis establishes sustainability and streetwear as primary trend\ndrivers, showing bidirectional relationships with several other themes. The\nfindings demonstrate that social media sentiment analysis can serve as an\neffective early indicator of fashion trend trajectories when proper statistical\nvalidation is applied. Our improved predictive model achieved 78.35% balanced\naccuracy in sentiment classification, establishing a reliable foundation for\ntrend prediction across positive, neutral, and negative sentiment categories.", "published": "2025-04-30 07:27:06", "link": "http://arxiv.org/abs/2505.00050v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications", "abstract": "As large language models (LLMs) are increasingly used in human-centered\ntasks, assessing their psychological traits is crucial for understanding their\nsocial impact and ensuring trustworthy AI alignment. While existing reviews\nhave covered some aspects of related research, several important areas have not\nbeen systematically discussed, including detailed discussions of diverse\npsychological tests, LLM-specific psychological datasets, and the applications\nof LLMs with psychological traits. To address this gap, we systematically\nreview six key dimensions of applying psychological theories to LLMs: (1)\nassessment tools; (2) LLM-specific datasets; (3) evaluation metrics\n(consistency and stability); (4) empirical findings; (5) personality simulation\nmethods; and (6) LLM-based behavior simulation. Our analysis highlights both\nthe strengths and limitations of current methods. While some LLMs exhibit\nreproducible personality patterns under specific prompting schemes, significant\nvariability remains across tasks and settings. Recognizing methodological\nchallenges such as mismatches between psychological tools and LLMs'\ncapabilities, as well as inconsistencies in evaluation practices, this study\naims to propose future directions for developing more interpretable, robust,\nand generalizable psychological assessment frameworks for LLMs.", "published": "2025-04-30 06:09:40", "link": "http://arxiv.org/abs/2505.00049v1", "categories": ["cs.CY", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Base Models Beat Aligned Models at Randomness and Creativity", "abstract": "Alignment has quickly become a default ingredient in LLM development, with\ntechniques such as reinforcement learning from human feedback making models act\nsafely, follow instructions, and perform ever-better on complex tasks. While\nthese techniques are certainly useful, we propose that they should not be\nuniversally applied and demonstrate a range of tasks on which base language\nmodels consistently outperform their popular aligned forms. Particularly, we\nstudy tasks that require unpredictable outputs, such as random number\ngeneration, mixed strategy games (rock-paper-scissors and hide-and-seek), and\ncreative writing. In each case, aligned models tend towards narrow behaviors\nthat result in distinct disadvantages, for instance, preferring to generate \"7\"\nover other uniformly random numbers, becoming almost fully predictable in some\ngame states, or prioritizing pleasant writing over creative originality. Across\nmodels tested, better performance on common benchmarks tends to correlate with\nworse performance on our tasks, suggesting an effective trade-off in the\nrequired capabilities.", "published": "2025-04-30 03:41:55", "link": "http://arxiv.org/abs/2505.00047v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders", "abstract": "The development of novel autonomous underwater gliders has been hindered by\nlimited shape diversity, primarily due to the reliance on traditional design\ntools that depend heavily on manual trial and error. Building an automated\ndesign framework is challenging due to the complexities of representing glider\nshapes and the high computational costs associated with modeling complex\nsolid-fluid interactions. In this work, we introduce an AI-enhanced automated\ncomputational framework designed to overcome these limitations by enabling the\ncreation of underwater robots with non-trivial hull shapes. Our approach\ninvolves an algorithm that co-optimizes both shape and control signals,\nutilizing a reduced-order geometry representation and a differentiable\nneural-network-based fluid surrogate model. This end-to-end design workflow\nfacilitates rapid iteration and evaluation of hydrodynamic performance, leading\nto the discovery of optimal and complex hull shapes across various control\nsettings. We validate our method through wind tunnel experiments and swimming\npool gliding tests, demonstrating that our computationally designed gliders\nsurpass manually designed counterparts in terms of energy efficiency. By\naddressing challenges in efficient shape representation and neural fluid\nsurrogate models, our work paves the way for the development of highly\nefficient underwater gliders, with implications for long-range ocean\nexploration and environmental monitoring.", "published": "2025-04-30 23:55:44", "link": "http://arxiv.org/abs/2505.00222v1", "categories": ["cs.RO", "cs.AI", "cs.GR", "cs.LG", "physics.comp-ph"], "primary_category": "cs.RO"}
{"title": "Online Federation For Mixtures of Proprietary Agents with Black-Box Encoders", "abstract": "Most industry-standard generative AIs and feature encoders are proprietary,\noffering only black-box access: their outputs are observable, but their\ninternal parameters and architectures remain hidden from the end-user. This\nblack-box access is especially limiting when constructing mixture-of-expert\ntype ensemble models since the user cannot optimize each proprietary AI's\ninternal parameters. Our problem naturally lends itself to a non-competitive\ngame-theoretic lens where each proprietary AI (agent) is inherently competing\nagainst the other AI agents, with this competition arising naturally due to\ntheir obliviousness of the AI's to their internal structure. In contrast, the\nuser acts as a central planner trying to synchronize the ensemble of competing\nAIs.\n  We show the existence of the unique Nash equilibrium in the online setting,\nwhich we even compute in closed-form by eliciting a feedback mechanism between\nany given time series and the sequence generated by each (proprietary) AI\nagent. Our solution is implemented as a decentralized, federated-learning\nalgorithm in which each agent optimizes their structure locally on their\nmachine without ever releasing any internal structure to the others. We obtain\nrefined expressions for pre-trained models such as transformers, random feature\nmodels, and echo-state networks. Our ``proprietary federated learning''\nalgorithm is implemented on a range of real-world and synthetic time-series\nbenchmarks. It achieves orders-of-magnitude improvements in predictive accuracy\nover natural benchmarks, of which there are surprisingly few due to this\nnatural problem still being largely unexplored.", "published": "2025-04-30 23:19:37", "link": "http://arxiv.org/abs/2505.00216v1", "categories": ["cs.LG", "cs.AI", "cs.GT", "68T05, 68T07, 91A80", "I.2.1; I.2.11; G.1.6"], "primary_category": "cs.LG"}
{"title": "RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset", "abstract": "As AI systems become embedded in real-world applications, ensuring they meet\nethical standards is crucial. While existing AI ethics frameworks emphasize\nfairness, transparency, and accountability, they often lack actionable\nevaluation methods. This paper introduces a systematic approach using the\nResponsible AI Labs (RAIL) framework, which includes eight measurable\ndimensions to assess the normative behavior of large language models (LLMs). We\napply this framework to Anthropic's \"Values in the Wild\" dataset, containing\nover 308,000 anonymized conversations with Claude and more than 3,000 annotated\nvalue expressions. Our study maps these values to RAIL dimensions, computes\nsynthetic scores, and provides insights into the ethical behavior of LLMs in\nreal-world use.", "published": "2025-04-30 22:03:26", "link": "http://arxiv.org/abs/2505.00204v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Empirical Evaluation of Progressive Coding for Sparse Autoencoders", "abstract": "Sparse autoencoders (SAEs)\n\\citep{bricken2023monosemanticity,gao2024scalingevaluatingsparseautoencoders}\nrely on dictionary learning to extract interpretable features from neural\nnetworks at scale in an unsupervised manner, with applications to\nrepresentation engineering and information retrieval. SAEs are, however,\ncomputationally expensive \\citep{lieberum2024gemmascopeopensparse}, especially\nwhen multiple SAEs of different sizes are needed. We show that dictionary\nimportance in vanilla SAEs follows a power law. We compare progressive coding\nbased on subset pruning of SAEs -- to jointly training nested SAEs, or\nso-called {\\em Matryoshka} SAEs\n\\citep{bussmann2024learning,nabeshima2024Matryoshka} -- on a language modeling\ntask. We show Matryoshka SAEs exhibit lower reconstruction loss and recaptured\nlanguage modeling loss, as well as higher representational similarity. Pruned\nvanilla SAEs are more interpretable, however. We discuss the origins and\nimplications of this trade-off.", "published": "2025-04-30 21:08:32", "link": "http://arxiv.org/abs/2505.00190v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Neuroevolution of Self-Attention Over Proto-Objects", "abstract": "Proto-objects - image regions that share common visual properties - offer a\npromising alternative to traditional attention mechanisms based on\nrectangular-shaped image patches in neural networks. Although previous work\ndemonstrated that evolving a patch-based hard-attention module alongside a\ncontroller network could achieve state-of-the-art performance in visual\nreinforcement learning tasks, our approach leverages image segmentation to work\nwith higher-level features. By operating on proto-objects rather than fixed\npatches, we significantly reduce the representational complexity: each image\ndecomposes into fewer proto-objects than regular patches, and each proto-object\ncan be efficiently encoded as a compact feature vector. This enables a\nsubstantially smaller self-attention module that processes richer semantic\ninformation. Our experiments demonstrate that this proto-object-based approach\nmatches or exceeds the state-of-the-art performance of patch-based\nimplementations with 62% less parameters and 2.6 times less training time.", "published": "2025-04-30 21:01:20", "link": "http://arxiv.org/abs/2505.00186v1", "categories": ["cs.NE", "cs.AI", "cs.CV"], "primary_category": "cs.NE"}
{"title": "Real-World Gaps in AI Governance Research", "abstract": "Drawing on 1,178 safety and reliability papers from 9,439 generative AI\npapers (January 2020 - March 2025), we compare research outputs of leading AI\ncompanies (Anthropic, Google DeepMind, Meta, Microsoft, and OpenAI) and AI\nuniversities (CMU, MIT, NYU, Stanford, UC Berkeley, and University of\nWashington). We find that corporate AI research increasingly concentrates on\npre-deployment areas -- model alignment and testing & evaluation -- while\nattention to deployment-stage issues such as model bias has waned. Significant\nresearch gaps exist in high-risk deployment domains, including healthcare,\nfinance, misinformation, persuasive and addictive features, hallucinations, and\ncopyright. Without improved observability into deployed AI, growing corporate\nconcentration could deepen knowledge deficits. We recommend expanding external\nresearcher access to deployment data and systematic observability of in-market\nAI behaviors.", "published": "2025-04-30 20:44:42", "link": "http://arxiv.org/abs/2505.00174v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "First Order Logic with Fuzzy Semantics for Describing and Recognizing Nerves in Medical Images", "abstract": "This article deals with the description and recognition of fiber bundles, in\nparticular nerves, in medical images, based on the anatomical description of\nthe fiber trajectories. To this end, we propose a logical formalization of this\nanatomical knowledge. The intrinsically imprecise description of nerves, as\nfound in anatomical textbooks, leads us to propose fuzzy semantics combined\nwith first-order logic. We define a language representing spatial entities,\nrelations between these entities and quantifiers. A formula in this language is\nthen a formalization of the natural language description. The semantics are\ngiven by fuzzy representations in a concrete domain and satisfaction degrees of\nrelations. Based on this formalization, a spatial reasoning algorithm is\nproposed for segmentation and recognition of nerves from anatomical and\ndiffusion magnetic resonance images, which is illustrated on pelvic nerves in\npediatric imaging, enabling surgeons to plan surgery.", "published": "2025-04-30 20:41:04", "link": "http://arxiv.org/abs/2505.00173v1", "categories": ["cs.AI", "cs.LO", "math.LO"], "primary_category": "cs.AI"}
{"title": "Attention-enabled Explainable AI for Bladder Cancer Recurrence Prediction", "abstract": "Non-muscle-invasive bladder cancer (NMIBC) is a relentless challenge in\noncology, with recurrence rates soaring as high as 70-80%. Each recurrence\ntriggers a cascade of invasive procedures, lifelong surveillance, and\nescalating healthcare costs - affecting 460,000 individuals worldwide. However,\nexisting clinical prediction tools remain fundamentally flawed, often\noverestimating recurrence risk and failing to provide personalized insights for\npatient management. In this work, we propose an interpretable deep learning\nframework that integrates vector embeddings and attention mechanisms to improve\nNMIBC recurrence prediction performance. We incorporate vector embeddings for\ncategorical variables such as smoking status and intravesical treatments,\nallowing the model to capture complex relationships between patient attributes\nand recurrence risk. These embeddings provide a richer representation of the\ndata, enabling improved feature interactions and enhancing prediction\nperformance. Our approach not only enhances performance but also provides\nclinicians with patient-specific insights by highlighting the most influential\nfeatures contributing to recurrence risk for each patient. Our model achieves\naccuracy of 70% with tabular data, outperforming conventional statistical\nmethods while providing clinician-friendly patient-level explanations through\nfeature attention. Unlike previous studies, our approach identifies new\nimportant factors influencing recurrence, such as surgical duration and\nhospital stay, which had not been considered in existing NMIBC prediction\nmodels.", "published": "2025-04-30 20:39:33", "link": "http://arxiv.org/abs/2505.00171v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D Molecule Generation", "abstract": "Deep generative models have shown significant promise in generating valid 3D\nmolecular structures, with the GEOM-Drugs dataset serving as a key benchmark.\nHowever, current evaluation protocols suffer from critical flaws, including\nincorrect valency definitions, bugs in bond order calculations, and reliance on\nforce fields inconsistent with the reference data. In this work, we revisit\nGEOM-Drugs and propose a corrected evaluation framework: we identify and fix\nissues in data preprocessing, construct chemically accurate valency tables, and\nintroduce a GFN2-xTB-based geometry and energy benchmark. We retrain and\nre-evaluate several leading models under this framework, providing updated\nperformance metrics and practical recommendations for future benchmarking. Our\nresults underscore the need for chemically rigorous evaluation practices in 3D\nmolecular generation. Our recommended evaluation methods and GEOM-Drugs\nprocessing scripts are available at\nhttps://github.com/isayevlab/geom-drugs-3dgen-evaluation.", "published": "2025-04-30 20:29:22", "link": "http://arxiv.org/abs/2505.00169v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "GPRat: Gaussian Process Regression with Asynchronous Tasks", "abstract": "Python is the de-facto language for software development in artificial\nintelligence (AI). Commonly used libraries, such as PyTorch and TensorFlow,\nrely on parallelization built into their BLAS backends to achieve speedup on\nCPUs. However, only applying parallelization in a low-level backend can lead to\nperformance and scaling degradation. In this work, we present a novel way of\nbinding task-based C++ code built on the asynchronous runtime model HPX to a\nhigh-level Python API using pybind11. We develop a parallel Gaussian process\n(GP) li- brary as an application. The resulting Python library GPRat combines\nthe ease of use of commonly available GP libraries with the performance and\nscalability of asynchronous runtime systems. We evaluate the per- formance on a\nmass-spring-damper system, a standard benchmark from control theory, for\nvarying numbers of regressors (features). The results show almost no binding\noverhead when binding the asynchronous HPX code using pybind11. Compared to\nGPyTorch and GPflow, GPRat shows superior scaling on up to 64 cores on an AMD\nEPYC 7742 CPU for train- ing. Furthermore, our library achieves a prediction\nspeedup of 7.63 over GPyTorch and 25.25 over GPflow. If we increase the number\nof features from eight to 128, we observe speedups of 29.62 and 21.19,\nrespectively. These results showcase the potential of using asynchronous tasks\nwithin Python-based AI applications.", "published": "2025-04-30 19:08:51", "link": "http://arxiv.org/abs/2505.00136v1", "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Evaluating the AI-Lab Intervention: Impact on Student Perception and Use of Generative AI in Early Undergraduate Computer Science Courses", "abstract": "Generative AI (GenAI) is rapidly entering computer science education, yet its\neffects on student learning, skill development, and perceptions remain\nunderexplored. Concerns about overreliance coexist with a gap in research on\nstructured scaffolding to guide tool use in formal courses. This study examines\nthe impact of a dedicated \"AI-Lab\" intervention -- emphasizing guided\nscaffolding and mindful engagement -- on undergraduate students in Data\nStructures and Algorithms, Competitive Programming, and first-year engineering\ncourses at Purdue University.\n  Over three semesters, we integrated AI-Lab modules into four mandatory and\nelective courses, yielding 831 matched pre- and post-intervention survey\nresponses, alongside focus group discussions. Employing a mixed-methods\napproach, we analyzed quantitative shifts in usage patterns and attitudes as\nwell as qualitative narratives of student experiences.\n  While the overall frequency of GenAI usage for homework or programming\nprojects remained largely stable, we observed large effect sizes in comfort and\nopenness across conceptual, debugging, and homework problems. Notably, usage\npatterns for debugging also shifted statistically significantly, reflecting\nstudents' more mindful and deliberate approach. Focus group discussions\ncorroborated these results, suggesting that the intervention \"bridged the gap\"\nbetween naive GenAI usage and more nuanced, reflective integration of AI tools\ninto coursework, ultimately heightening students' awareness of their own skill\ndevelopment.\n  These findings suggest that structured, scaffolded interventions can enable\nstudents to harness GenAI's benefits without undermining essential\ncompetencies. We offer evidence-based recommendations for educators seeking to\nintegrate GenAI responsibly into computing curricula and identify avenues for\nfuture research on GenAI-supported pedagogy.", "published": "2025-04-30 18:12:42", "link": "http://arxiv.org/abs/2505.00100v1", "categories": ["cs.CY", "cs.AI", "cs.ET", "K.3"], "primary_category": "cs.CY"}
{"title": "CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios", "abstract": "With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV)\nswarms to perform complex tasks in urban environments, system design now faces\nmajor challenges, including efficient semantic understanding, flexible task\nplanning, and the ability to dynamically adjust coordination strategies in\nresponse to evolving environmental conditions and continuously changing task\nrequirements. To address the limitations of existing approaches, this paper\nproposes coordination field agentic system for coordinating heterogeneous UAV\nswarms in complex urban scenarios. In this system, large language models (LLMs)\nis responsible for interpreting high-level human instructions and converting\nthem into executable commands for the UAV swarms, such as patrol and target\ntracking. Subsequently, a Coordination field mechanism is proposed to guide UAV\nmotion and task selection, enabling decentralized and adaptive allocation of\nemergent tasks. A total of 50 rounds of comparative testing were conducted\nacross different models in a 2D simulation space to evaluate their performance.\nExperimental results demonstrate that the proposed system achieves superior\nperformance in terms of task coverage, response time, and adaptability to\ndynamic changes.", "published": "2025-04-30 18:02:45", "link": "http://arxiv.org/abs/2505.00091v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Towards Robust and Generalizable Gerchberg Saxton based Physics Inspired Neural Networks for Computer Generated Holography: A Sensitivity Analysis Framework", "abstract": "Computer-generated holography (CGH) enables applications in holographic\naugmented reality (AR), 3D displays, systems neuroscience, and optical\ntrapping. The fundamental challenge in CGH is solving the inverse problem of\nphase retrieval from intensity measurements. Physics-inspired neural networks\n(PINNs), especially Gerchberg-Saxton-based PINNs (GS-PINNs), have advanced\nphase retrieval capabilities. However, their performance strongly depends on\nforward models (FMs) and their hyperparameters (FMHs), limiting generalization,\ncomplicating benchmarking, and hindering hardware optimization. We present a\nsystematic sensitivity analysis framework based on Saltelli's extension of\nSobol's method to quantify FMH impacts on GS-PINN performance. Our analysis\ndemonstrates that SLM pixel-resolution is the primary factor affecting neural\nnetwork sensitivity, followed by pixel-pitch, propagation distance, and\nwavelength. Free space propagation forward models demonstrate superior neural\nnetwork performance compared to Fourier holography, providing enhanced\nparameterization and generalization. We introduce a composite evaluation metric\ncombining performance consistency, generalization capability, and\nhyperparameter perturbation resilience, establishing a unified benchmarking\nstandard across CGH configurations. Our research connects physics-inspired deep\nlearning theory with practical CGH implementations through concrete guidelines\nfor forward model selection, neural network architecture, and performance\nevaluation. Our contributions advance the development of robust, interpretable,\nand generalizable neural networks for diverse holographic applications,\nsupporting evidence-based decisions in CGH research and implementation.", "published": "2025-04-30 23:49:33", "link": "http://arxiv.org/abs/2505.00220v1", "categories": ["cs.CV", "physics.optics"], "primary_category": "cs.CV"}
{"title": "Direct Motion Models for Assessing Generated Videos", "abstract": "A current limitation of video generative video models is that they generate\nplausible looking frames, but poor motion -- an issue that is not well captured\nby FVD and other popular methods for evaluating generated videos. Here we go\nbeyond FVD by developing a metric which better measures plausible object\ninteractions and motion. Our novel approach is based on auto-encoding point\ntracks and yields motion features that can be used to not only compare\ndistributions of videos (as few as one generated and one ground truth, or as\nmany as two datasets), but also for evaluating motion of single videos. We show\nthat using point tracks instead of pixel reconstruction or action recognition\nfeatures results in a metric which is markedly more sensitive to temporal\ndistortions in synthetic data, and can predict human evaluations of temporal\nconsistency and realism in generated videos obtained from open-source models\nbetter than a wide range of alternatives. We also show that by using a point\ntrack representation, we can spatiotemporally localize generative video\ninconsistencies, providing extra interpretability of generated video errors\nrelative to prior work. An overview of the results and link to the code can be\nfound on the project page: http://trajan-paper.github.io.", "published": "2025-04-30 22:34:52", "link": "http://arxiv.org/abs/2505.00209v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "V3LMA: Visual 3D-enhanced Language Model for Autonomous Driving", "abstract": "Large Vision Language Models (LVLMs) have shown strong capabilities in\nunderstanding and analyzing visual scenes across various domains. However, in\nthe context of autonomous driving, their limited comprehension of 3D\nenvironments restricts their effectiveness in achieving a complete and safe\nunderstanding of dynamic surroundings. To address this, we introduce V3LMA, a\nnovel approach that enhances 3D scene understanding by integrating Large\nLanguage Models (LLMs) with LVLMs. V3LMA leverages textual descriptions\ngenerated from object detections and video inputs, significantly boosting\nperformance without requiring fine-tuning. Through a dedicated preprocessing\npipeline that extracts 3D object data, our method improves situational\nawareness and decision-making in complex traffic scenarios, achieving a score\nof 0.56 on the LingoQA benchmark. We further explore different fusion\nstrategies and token combinations with the goal of advancing the interpretation\nof traffic scenes, ultimately enabling safer autonomous driving systems.", "published": "2025-04-30 20:00:37", "link": "http://arxiv.org/abs/2505.00156v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis", "abstract": "The rising popularity of immersive visual experiences has increased interest\nin stereoscopic 3D video generation. Despite significant advances in video\nsynthesis, creating 3D videos remains challenging due to the relative scarcity\nof 3D video data. We propose a simple approach for transforming a text-to-video\ngenerator into a video-to-stereo generator. Given an input video, our framework\nautomatically produces the video frames from a shifted viewpoint, enabling a\ncompelling 3D effect. Prior and concurrent approaches for this task typically\noperate in multiple phases, first estimating video disparity or depth, then\nwarping the video accordingly to produce a second view, and finally inpainting\nthe disoccluded regions. This approach inherently fails when the scene involves\nspecular surfaces or transparent objects. In such cases, single-layer disparity\nestimation is insufficient, resulting in artifacts and incorrect pixel shifts\nduring warping. Our work bypasses these restrictions by directly synthesizing\nthe new viewpoint, avoiding any intermediate steps. This is achieved by\nleveraging a pre-trained video model's priors on geometry, object materials,\noptics, and semantics, without relying on external geometry models or manually\ndisentangling geometry from the synthesis process. We demonstrate the\nadvantages of our approach in complex, real-world scenarios featuring diverse\nobject materials and compositions. See videos on\nhttps://video-eye2eye.github.io", "published": "2025-04-30 19:06:09", "link": "http://arxiv.org/abs/2505.00135v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Investigating Zero-Shot Diagnostic Pathology in Vision-Language Models with Efficient Prompt Design", "abstract": "Vision-language models (VLMs) have gained significant attention in\ncomputational pathology due to their multimodal learning capabilities that\nenhance big-data analytics of giga-pixel whole slide image (WSI). However,\ntheir sensitivity to large-scale clinical data, task formulations, and prompt\ndesign remains an open question, particularly in terms of diagnostic accuracy.\nIn this paper, we present a systematic investigation and analysis of three\nstate of the art VLMs for histopathology, namely Quilt-Net, Quilt-LLAVA, and\nCONCH, on an in-house digestive pathology dataset comprising 3,507 WSIs, each\nin giga-pixel form, across distinct tissue types. Through a structured ablative\nstudy on cancer invasiveness and dysplasia status, we develop a comprehensive\nprompt engineering framework that systematically varies domain specificity,\nanatomical precision, instructional framing, and output constraints. Our\nfindings demonstrate that prompt engineering significantly impacts model\nperformance, with the CONCH model achieving the highest accuracy when provided\nwith precise anatomical references. Additionally, we identify the critical\nimportance of anatomical context in histopathological image analysis, as\nperformance consistently degraded when reducing anatomical precision. We also\nshow that model complexity alone does not guarantee superior performance, as\neffective domain alignment and domain-specific training are critical. These\nresults establish foundational guidelines for prompt engineering in\ncomputational pathology and highlight the potential of VLMs to enhance\ndiagnostic accuracy when properly instructed with domain-appropriate prompts.", "published": "2025-04-30 19:01:06", "link": "http://arxiv.org/abs/2505.00134v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient and robust 3D blind harmonization for large domain gaps", "abstract": "Blind harmonization has emerged as a promising technique for MR image\nharmonization to achieve scale-invariant representations, requiring only target\ndomain data (i.e., no source domain data necessary). However, existing methods\nface limitations such as inter-slice heterogeneity in 3D, moderate image\nquality, and limited performance for a large domain gap. To address these\nchallenges, we introduce BlindHarmonyDiff, a novel blind 3D harmonization\nframework that leverages an edge-to-image model tailored specifically to\nharmonization. Our framework employs a 3D rectified flow trained on target\ndomain images to reconstruct the original image from an edge map, then yielding\na harmonized image from the edge of a source domain image. We propose\nmulti-stride patch training for efficient 3D training and a refinement module\nfor robust inference by suppressing hallucination. Extensive experiments\ndemonstrate that BlindHarmonyDiff outperforms prior arts by harmonizing diverse\nsource domain images to the target domain, achieving higher correspondence to\nthe target domain characteristics. Downstream task-based quality assessments\nsuch as tissue segmentation and age prediction on diverse MR scanners further\nconfirm the effectiveness of our approach and demonstrate the capability of our\nrobust and generalizable blind harmonization.", "published": "2025-04-30 19:00:58", "link": "http://arxiv.org/abs/2505.00133v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Rootlets-based registration to the spinal cord PAM50 template", "abstract": "Spinal cord functional MRI studies require precise localization of spinal\nlevels for reliable voxelwise group analyses. Traditional template-based\nregistration of the spinal cord uses intervertebral discs for alignment.\nHowever, substantial anatomical variability across individuals exists between\nvertebral and spinal levels. This study proposes a novel registration approach\nthat leverages spinal nerve rootlets to improve alignment accuracy and\nreproducibility across individuals. We developed a registration method\nleveraging dorsal cervical rootlets segmentation and aligning them non-linearly\nwith the PAM50 spinal cord template. Validation was performed on a\nmulti-subject, multi-site dataset (n=267, 44 sites) and a multi-subject dataset\nwith various neck positions (n=10, 3 sessions). We further validated the method\non task-based functional MRI (n=23) to compare group-level activation maps\nusing rootlet-based registration to traditional disc-based methods.\nRootlet-based registration showed superior alignment across individuals\ncompared to the traditional disc-based method. Notably, rootlet positions were\nmore stable across neck positions. Group-level analysis of task-based\nfunctional MRI using rootlet-based increased Z scores and activation cluster\nsize compared to disc-based registration (number of active voxels from 3292 to\n7978). Rootlet-based registration enhances both inter- and intra-subject\nanatomical alignment and yields better spatial normalization for group-level\nfMRI analyses. Our findings highlight the potential of rootlet-based\nregistration to improve the precision and reliability of spinal cord\nneuroimaging group analysis.", "published": "2025-04-30 18:37:39", "link": "http://arxiv.org/abs/2505.00115v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "AnimalMotionCLIP: Embedding motion in CLIP for Animal Behavior Analysis", "abstract": "Recently, there has been a surge of interest in applying deep learning\ntechniques to animal behavior recognition, particularly leveraging pre-trained\nvisual language models, such as CLIP, due to their remarkable generalization\ncapacity across various downstream tasks. However, adapting these models to the\nspecific domain of animal behavior recognition presents two significant\nchallenges: integrating motion information and devising an effective temporal\nmodeling scheme. In this paper, we propose AnimalMotionCLIP to address these\nchallenges by interleaving video frames and optical flow information in the\nCLIP framework. Additionally, several temporal modeling schemes using an\naggregation of classifiers are proposed and compared: dense, semi dense, and\nsparse. As a result, fine temporal actions can be correctly recognized, which\nis of vital importance in animal behavior analysis. Experiments on the Animal\nKingdom dataset demonstrate that AnimalMotionCLIP achieves superior performance\ncompared to state-of-the-art approaches.", "published": "2025-04-30 12:26:37", "link": "http://arxiv.org/abs/2505.00569v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Counting Specific Classes of Relations Regarding Fixed Points and Reflexive Points", "abstract": "Given a finite and non-empty set $X$ and randomly selected specific functions\nand relations on $X$, we investigate the existence and non-existence of fixed\npoints and reflexive points, respectively. First, we consider the class of\nfunctions, weaken it to the classes of partial functions, total relations and\ngeneral relations and also strengthen it to the class of permutations. Then we\ninvestigate the class of involutions and the subclass of proper involutions.\nFinally, we treat idempotent functions, partial idempotent functions and\nrelated concepts. We count relations, calculate corresponding probabilities and\nalso calculate the limiting values of the latter in case that the cardinality\nof $X$ tends to infinity. All these results have been motivated and also\nsupported by numerous experiments performed with the RelView tool.", "published": "2025-04-30 19:23:51", "link": "http://arxiv.org/abs/2505.00140v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Q Cells in Wireless Networks", "abstract": "For a given set of transmitters such as cellular base stations or WiFi access\npoints, is it possible to analytically characterize the set of locations that\nare \"covered\" in the sense that users at these locations experience a certain\nminimum quality of service? In this paper, we affirmatively answer this\nquestion, by providing explicit simple outer bounds and estimates for the\ncoverage manifold. The key geometric elements of our analytical method are the\nQ cells, defined as the intersections of a small number of disks. The Q cell of\na transmitter is an outer bound to the service region of the transmitter, and,\nin turn, the union of Q cells is an outer bound to the coverage manifold. In\ninfinite networks, connections to the meta distribution of the\nsignal-to-interference ratio allow for a scaling of the Q cells to obtain\naccurate estimates of the coverage manifold.", "published": "2025-04-30 19:12:33", "link": "http://arxiv.org/abs/2505.00138v1", "categories": ["cs.NI", "cs.IT", "math.IT", "math.PR"], "primary_category": "cs.NI"}
{"title": "Toward Practical Quantum Machine Learning: A Novel Hybrid Quantum LSTM for Fraud Detection", "abstract": "We present a novel hybrid quantum-classical neural network architecture for\nfraud detection that integrates a classical Long Short-Term Memory (LSTM)\nnetwork with a variational quantum circuit. By leveraging quantum phenomena\nsuch as superposition and entanglement, our model enhances the feature\nrepresentation of sequential transaction data, capturing complex non-linear\npatterns that are challenging for purely classical models. A comprehensive data\npreprocessing pipeline is employed to clean, encode, balance, and normalize a\ncredit card fraud dataset, ensuring a fair comparison with baseline models.\nNotably, our hybrid approach achieves per-epoch training times in the range of\n45-65 seconds, which is significantly faster than similar architectures\nreported in the literature, where training typically requires several minutes\nper epoch. Both classical and quantum gradients are jointly optimized via a\nunified backpropagation procedure employing the parameter-shift rule for the\nquantum parameters. Experimental evaluations demonstrate competitive\nimprovements in accuracy, precision, recall, and F1 score relative to a\nconventional LSTM baseline. These results underscore the promise of hybrid\nquantum-classical techniques in advancing the efficiency and performance of\nfraud detection systems.\n  Keywords: Hybrid Quantum-Classical Neural Networks, Quantum Computing, Fraud\nDetection, Hybrid Quantum LSTM, Variational Quantum Circuit, Parameter-Shift\nRule, Financial Risk Analysis", "published": "2025-04-30 19:09:12", "link": "http://arxiv.org/abs/2505.00137v1", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.IT"], "primary_category": "quant-ph"}
{"title": "Generative Machine Learning in Adaptive Control of Dynamic Manufacturing Processes: A Review", "abstract": "Dynamic manufacturing processes exhibit complex characteristics defined by\ntime-varying parameters, nonlinear behaviors, and uncertainties. These\ncharacteristics require sophisticated in-situ monitoring techniques utilizing\nmultimodal sensor data and adaptive control systems that can respond to\nreal-time feedback while maintaining product quality. Recently, generative\nmachine learning (ML) has emerged as a powerful tool for modeling complex\ndistributions and generating synthetic data while handling these manufacturing\nuncertainties. However, adopting these generative technologies in dynamic\nmanufacturing systems lacks a functional control-oriented perspective to\ntranslate their probabilistic understanding into actionable process controls\nwhile respecting constraints. This review presents a functional classification\nof Prediction-Based, Direct Policy, Quality Inference, and Knowledge-Integrated\napproaches, offering a perspective for understanding existing ML-enhanced\ncontrol systems and incorporating generative ML. The analysis of generative ML\narchitectures within this framework demonstrates control-relevant properties\nand potential to extend current ML-enhanced approaches where conventional\nmethods prove insufficient. We show generative ML's potential for manufacturing\ncontrol through decision-making applications, process guidance, simulation, and\ndigital twins, while identifying critical research gaps: separation between\ngeneration and control functions, insufficient physical understanding of\nmanufacturing phenomena, and challenges adapting models from other domains. To\naddress these challenges, we propose future research directions aimed at\ndeveloping integrated frameworks that combine generative ML and control\ntechnologies to address the dynamic complexities of modern manufacturing\nsystems.", "published": "2025-04-30 22:48:04", "link": "http://arxiv.org/abs/2505.00210v1", "categories": ["cs.LG", "cs.CE", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Mapping minds not averages: a scalable subject-specific manifold learning framework for neuroimaging data", "abstract": "Mental and cognitive representations are believed to reside on\nlow-dimensional, non-linear manifolds embedded within high-dimensional brain\nactivity. Uncovering these manifolds is key to understanding individual\ndifferences in brain function, yet most existing machine learning methods\neither rely on population-level spatial alignment or assume data that is\ntemporally structured, either because data is aligned among subjects or because\nevent timings are known. We introduce a manifold learning framework that can\ncapture subject-specific spatial variations across both structured and\ntemporally unstructured neuroimaging data. On simulated data and two\nnaturalistic fMRI datasets (Sherlock and Forrest Gump), our framework\noutperforms group-based baselines by recovering more accurate and\nindividualized representations. We further show that the framework scales\nefficiently to large datasets and generalizes well to new subjects. To test\nthis, we apply the framework to temporally unstructured resting-state fMRI data\nfrom individuals with schizophrenia and healthy controls. We further apply our\nmethod to a large resting-state fMRI dataset comprising individuals with\nschizophrenia and controls. In this setting, we demonstrate that the framework\nscales efficiently to large populations and generalizes robustly to unseen\nsubjects. The learned subject-specific spatial maps our model finds reveal\nclinically relevant patterns, including increased activation in the basal\nganglia, visual, auditory, and somatosensory regions, and decreased activation\nin the insula, inferior frontal gyrus, and angular gyrus. These findings\nsuggest that our framework can uncover clinically relevant subject-specific\nbrain activity patterns. Our approach thus provides a scalable and\nindividualized framework for modeling brain activity, with applications in\ncomputational neuroscience and clinical research.", "published": "2025-04-30 21:40:54", "link": "http://arxiv.org/abs/2505.00196v1", "categories": ["cs.LG", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Algorithmic Collective Action with Two Collectives", "abstract": "Given that data-dependent algorithmic systems have become impactful in more\ndomains of life, the need for individuals to promote their own interests and\nhold algorithms accountable has grown. To have meaningful influence,\nindividuals must band together to engage in collective action. Groups that\nengage in such algorithmic collective action are likely to vary in size,\nmembership characteristics, and crucially, objectives. In this work, we\nintroduce a first of a kind framework for studying collective action with two\nor more collectives that strategically behave to manipulate data-driven\nsystems. With more than one collective acting on a system, unexpected\ninteractions may occur. We use this framework to conduct experiments with\nlanguage model-based classifiers and recommender systems where two collectives\neach attempt to achieve their own individual objectives. We examine how\ndiffering objectives, strategies, sizes, and homogeneity can impact a\ncollective's efficacy. We find that the unintentional interactions between\ncollectives can be quite significant; a collective acting in isolation may be\nable to achieve their objective (e.g., improve classification outcomes for\nthemselves or promote a particular item), but when a second collective acts\nsimultaneously, the efficacy of the first group drops by as much as $75\\%$. We\nfind that, in the recommender system context, neither fully heterogeneous nor\nfully homogeneous collectives stand out as most efficacious and that\nheterogeneity's impact is secondary compared to collective size. Our results\nsignal the need for more transparency in both the underlying algorithmic models\nand the different behaviors individuals or collectives may take on these\nsystems. This approach also allows collectives to hold algorithmic system\ndevelopers accountable and provides a framework for people to actively use\ntheir own data to promote their own interests.", "published": "2025-04-30 21:39:06", "link": "http://arxiv.org/abs/2505.00195v1", "categories": ["cs.CY", "cs.GT", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Chronic Diseases Prediction using Machine Learning and Deep Learning Methods", "abstract": "Chronic diseases, such as cardiovascular disease, diabetes, chronic kidney\ndisease, and thyroid disorders, are the leading causes of premature mortality\nworldwide. Early detection and intervention are crucial for improving patient\noutcomes, yet traditional diagnostic methods often fail due to the complex\nnature of these conditions. This study explores the application of machine\nlearning (ML) and deep learning (DL) techniques to predict chronic disease and\nthyroid disorders. We used a variety of models, including Logistic Regression\n(LR), Random Forest (RF), Gradient Boosted Trees (GBT), Neural Networks (NN),\nDecision Trees (DT) and Native Bayes (NB), to analyze and predict disease\noutcomes. Our methodology involved comprehensive data pre-processing, including\nhandling missing values, categorical encoding, and feature aggregation,\nfollowed by model training and evaluation. Performance metrics such ad\nprecision, recall, accuracy, F1-score, and Area Under the Curve (AUC) were used\nto assess the effectiveness of each model. The results demonstrated that\nensemble methods like Random Forest and Gradient Boosted Trees consistently\noutperformed. Neutral Networks also showed superior performance, particularly\nin capturing complex data patterns. The findings highlight the potential of ML\nand DL in revolutionizing chronic disease prediction, enabling early diagnosis\nand personalized treatment strategies. However, challenges such as data\nquality, model interpretability, and the need for advanced computational\ntechniques in healthcare to improve patient outcomes and reduce the burden of\nchronic diseases. This study was conducted as part of Big Data class project\nunder the supervision of our professors Mr. Abderrahmane EZ-ZAHOUT and Mr.\nAbdessamad ESSAIDI.", "published": "2025-04-30 21:08:16", "link": "http://arxiv.org/abs/2505.00189v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Stochastic Subspace Descent Accelerated via Bi-fidelity Line Search", "abstract": "Efficient optimization remains a fundamental challenge across numerous\nscientific and engineering domains, especially when objective function and\ngradient evaluations are computationally expensive. While zeroth-order\noptimization methods offer effective approaches when gradients are\ninaccessible, their practical performance can be limited by the high cost\nassociated with function queries. This work introduces the bi-fidelity\nstochastic subspace descent (BF-SSD) algorithm, a novel zeroth-order\noptimization method designed to reduce this computational burden. BF-SSD\nleverages a bi-fidelity framework, constructing a surrogate model from a\ncombination of computationally inexpensive low-fidelity (LF) and accurate\nhigh-fidelity (HF) function evaluations. This surrogate model facilitates an\nefficient backtracking line search for step size selection, for which we\nprovide theoretical convergence guarantees under standard assumptions. We\nperform a comprehensive empirical evaluation of BF-SSD across four distinct\nproblems: a synthetic optimization benchmark, dual-form kernel ridge\nregression, black-box adversarial attacks on machine learning models, and\ntransformer-based black-box language model fine-tuning. Numerical results\ndemonstrate that BF-SSD consistently achieves superior optimization performance\nwhile requiring significantly fewer HF function evaluations compared to\nrelevant baseline methods. This study highlights the efficacy of integrating\nbi-fidelity strategies within zeroth-order optimization, positioning BF-SSD as\na promising and computationally efficient approach for tackling large-scale,\nhigh-dimensional problems encountered in various real-world applications.", "published": "2025-04-30 20:17:35", "link": "http://arxiv.org/abs/2505.00162v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Kernel-Based Ensemble Gaussian Mixture Probability Hypothesis Density Filter", "abstract": "In this work, a kernel-based Ensemble Gaussian Mixture Probability Hypothesis\nDensity (EnGM-PHD) filter is presented for multi-target filtering applications.\nThe EnGM-PHD filter combines the Gaussian-mixture-based techniques of the\nGaussian Mixture Probability Hypothesis Density (GM-PHD) filter with the\nparticle-based techniques of the Sequential Monte Carlo Probability Hypothesis\nDensity (SMC-PHD) filter. It achieves this by obtaining particles from the\nposterior intensity function, propagating them through the system dynamics, and\nthen using Kernel Density Estimation (KDE) techniques to approximate the\nGaussian mixture of the prior intensity function. This approach guarantees\nconvergence to the true intensity function in the limit of the number of\ncomponents. Moreover, in the special case of a single target with no births,\ndeaths, clutter, and perfect detection probability, the EnGM-PHD filter reduces\nto the standard Ensemble Gaussian Mixture Filter (EnGMF). In the presented\nexperiment, the results indicate that the EnGM-PHD filter achieves better\nmulti-target filtering performance than both the GM-PHD and SMC-PHD filters\nwhile using the same number of components or particles.", "published": "2025-04-30 19:00:02", "link": "http://arxiv.org/abs/2505.00131v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "TinyMA-IEI-PPO: Exploration Incentive-Driven Multi-Agent DRL with Self-Adaptive Pruning for Vehicular Embodied AI Agent Twins Migration", "abstract": "Embodied Artificial Intelligence (EAI) addresses autonomous driving\nchallenges in Vehicular Embodied AI Networks (VEANETs) through multi-modal\nperception, adaptive decision-making, and hardware-software co-scheduling.\nHowever, the computational demands of virtual services and the inherent\nmobility of autonomous vehicles (AVs) necessitate real-time migration of\nVehicular Embodied Agent AI Twins (VEAATs) between resource-constrained\nRoadside Units (RSUs). This paper proposes a novel framework for efficient\nVEAAT migration in VEANETs, combining a multi-leader multi-follower (MLMF)\nStackelberg game-theoretic incentive mechanism with a tiny multi-agent deep\nreinforcement learning (MADRL) algorithm. First, We propose an virtual\nimmersive experience-driven utility model that captures AV-RSU dynamic\ninteractions by integrating AVs' social influence, service complementarity and\nsubstitutability, and RSUs' resource allocation strategies to optimize VEAAT\nmigration decisions. Second, to enhance training efficiency and enable\nefficient deployment on computation-constrained AVs while preserving\nexploration-exploitation performance, we propose TinyMA-IEI-PPO, a\nself-adaptive dynamic structured pruning algorithm that dynamically adjusts\nneuron importance based on agents' exploration incentives. Numerical results\ndemonstrate that our approach achieves convergence comparable to baseline\nmodels and closely approximates the Stackelberg equilibrium.", "published": "2025-04-30 11:22:29", "link": "http://arxiv.org/abs/2505.00055v1", "categories": ["cs.MA", "cs.GT"], "primary_category": "cs.MA"}
{"title": "A Bayesian approach to inverse problems in spaces of measures", "abstract": "In this work, we develop a Bayesian framework for solving inverse problems in\nwhich the unknown parameter belongs to a space of Radon measures taking values\nin a separable Hilbert space. The inherent ill-posedness of such problems is\naddressed by introducing suitable measure-valued priors that encode prior\ninformation and promote desired sparsity properties of the parameter. Under\nappropriate assumptions on the forward operator and noise model, we establish\nthe well-posedness of the Bayesian formulation by proving the existence,\nuniqueness, and stability of the posterior with respect to perturbations in the\nobserved data. In addition, we also discuss computational strategies for\napproximating the posterior distribution. Finally, we present some examples\nthat demonstrate the effectiveness of the proposed approach.", "published": "2025-04-30 19:48:50", "link": "http://arxiv.org/abs/2505.00151v1", "categories": ["math.ST", "cs.NA", "math.NA", "stat.TH", "35R30, 35Q62, 62F15, 62G35"], "primary_category": "math.ST"}
{"title": "Extension operators and geometric decompositions", "abstract": "Geometric decomposition is a widely used tool for constructing local bases\nfor finite element spaces. For finite element spaces of differential forms on\nsimplicial meshes, Arnold, Falk, and Winther showed that geometric\ndecompositions can be constructed from extension operators satisfying certain\nproperties. In this paper, we generalize their results to function spaces and\nmeshes satisfying very minimal hypotheses, while at the same time reducing the\nconditions that must hold for the extension operators. In particular, the\ngeometry of the mesh and the mesh elements can be completely arbitrary, and the\nfunction spaces need only have well-defined restrictions to subelements. In\nthis general context, we show that extension operators yield geometric\ndecompositions for both the primal and dual function spaces. Later, we\nspecialize to simplicial meshes, and we show that, to obtain geometric\ndecompositions, one needs only to construct extension operators on the\nreference simplex in each dimension. In particular, for simplicial meshes, the\nexistence of geometric decompositions depends only on the dimension of the\nmesh.", "published": "2025-04-30 18:52:58", "link": "http://arxiv.org/abs/2505.00129v1", "categories": ["math.NA", "cs.NA", "math.DG", "65N30, 58A10, 53A45"], "primary_category": "math.NA"}
{"title": "On the expressivity of deep Heaviside networks", "abstract": "We show that deep Heaviside networks (DHNs) have limited expressiveness but\nthat this can be overcome by including either skip connections or neurons with\nlinear activation. We provide lower and upper bounds for the\nVapnik-Chervonenkis (VC) dimensions and approximation rates of these network\nclasses. As an application, we derive statistical convergence rates for DHN\nfits in the nonparametric regression model.", "published": "2025-04-30 18:25:05", "link": "http://arxiv.org/abs/2505.00110v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "stat.ML"}
{"title": "Pinching-Antenna Systems (PASS): Power Radiation Model and Optimal Beamforming Design", "abstract": "Pinching-antenna systems (PASS) improve wireless links by configuring the\nlocations of activated pinching antennas along dielectric waveguides, namely\npinching beamforming. In this paper, a novel adjustable power radiation model\nis proposed for PASS, where power radiation ratios of pinching antennas can be\nflexibly controlled by tuning the spacing between pinching antennas and\nwaveguides. A closed-form pinching antenna spacing arrangement strategy is\nderived to achieve the commonly assumed equal-power radiation. Based on this, a\npractical PASS framework relying on discrete activation is considered, where\npinching antennas can only be activated among a set of predefined locations. A\ntransmit power minimization problem is formulated, which jointly optimizes the\ntransmit beamforming, pinching beamforming, and the numbers of activated\npinching antennas, subject to each user's minimum rate requirement. (1) To\nsolve the resulting highly coupled mixed-integer nonlinear programming (MINLP)\nproblem, branch-and-bound (BnB)-based algorithms are proposed for both\nsingle-user and multi-user scenarios, which is guaranteed to converge to\nglobally optimal solutions. (2) A low-complexity many-to-many matching\nalgorithm is further developed. Combined with the Karush-Kuhn-Tucker (KKT)\ntheory, locally optimal and pairwise-stable solutions are obtained within\npolynomial-time complexity. Simulation results demonstrate that: (i) PASS\nsignificantly outperforms conventional multi-antenna architectures,\nparticularly when the number of users and the spatial range increase; and (ii)\nThe proposed matching-based algorithm achieves near-optimal performance,\nresulting in only a slight performance loss while significantly reducing\ncomputational overheads. Code is available at\nhttps://github.com/xiaoxiaxusummer/PASS_Discrete", "published": "2025-04-30 23:33:36", "link": "http://arxiv.org/abs/2505.00218v1", "categories": ["eess.SP", "cs.SY", "eess.SY", "math.OC"], "primary_category": "eess.SP"}
{"title": "Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity", "abstract": "Meme clustering is critical for toxicity detection, virality modeling, and\ntyping, but it has received little attention in previous research. Clustering\nsimilar Internet memes is challenging due to their multimodality, cultural\ncontext, and adaptability. Existing approaches rely on databases, overlook\nsemantics, and struggle to handle diverse dimensions of similarity. This paper\nintroduces a novel method that uses template-based matching with\nmulti-dimensional similarity features, thus eliminating the need for predefined\ndatabases and supporting adaptive matching. Memes are clustered using local and\nglobal features across similarity categories such as form, visual content,\ntext, and identity. Our combined approach outperforms existing clustering\nmethods, producing more consistent and coherent clusters, while\nsimilarity-based feature sets enable adaptability and align with human\nintuition. We make all supporting code publicly available to support subsequent\nresearch.", "published": "2025-04-30 11:25:30", "link": "http://arxiv.org/abs/2505.00056v2", "categories": ["cs.CL", "cs.IR", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Q Cells in Wireless Networks", "abstract": "For a given set of transmitters such as cellular base stations or WiFi access\npoints, is it possible to analytically characterize the set of locations that\nare \"covered\" in the sense that users at these locations experience a certain\nminimum quality of service? In this paper, we affirmatively answer this\nquestion, by providing explicit simple outer bounds and estimates for the\ncoverage manifold. The key geometric elements of our analytical method are the\nQ cells, defined as the intersections of a small number of disks. The Q cell of\na transmitter is an outer bound to the service region of the transmitter, and,\nin turn, the union of Q cells is an outer bound to the coverage manifold. In\ninfinite networks, connections to the meta distribution of the\nsignal-to-interference ratio allow for a scaling of the Q cells to obtain\naccurate estimates of the coverage manifold.", "published": "2025-04-30 19:12:33", "link": "http://arxiv.org/abs/2505.00138v2", "categories": ["cs.NI", "cs.IT", "math.IT", "math.PR"], "primary_category": "cs.NI"}
{"title": "Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of Binary Classification", "abstract": "To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation (DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.", "published": "2025-04-30 13:34:06", "link": "http://arxiv.org/abs/2504.21632v3", "categories": ["cs.IT", "eess.IV", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Coral Protocol: Open Infrastructure Connecting The Internet of Agents", "abstract": "The Coral Protocol is an open and decentralized collaboration infrastructure\nthat enables communication, coordination, trust and payments for The Internet\nof Agents. It addresses the growing need for interoperability in a world where\norganizations are deploying multiple specialized AI agents that must work\ntogether across domains and vendors. As a foundational platform for multi-agent\nAI ecosystems, Coral establishes a common language and coordination framework\nallowing any agent to participate in complex workflows with others. Its design\nemphasizes broad compatibility, security, and vendor neutrality, ensuring that\nagent interactions are efficient and trustworthy. In particular, Coral\nintroduces standardized messaging formats for agent communication, a modular\ncoordination mechanism for orchestrating multi-agent tasks, and secure team\nformation capabilities for dynamically assembling trusted groups of agents.\nTogether, these innovations position Coral Protocol as a cornerstone of the\nemerging \"Internet of Agents,\" unlocking new levels of automation, collective\nintelligence, and business value through open agent collaboration.", "published": "2025-04-30 22:17:13", "link": "http://arxiv.org/abs/2505.00749v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Wireless Communication as an Information Sensor for Multi-agent Cooperative Perception: A Survey", "abstract": "Cooperative perception extends the perception capabilities of autonomous\nvehicles by enabling multi-agent information sharing via Vehicle-to-Everything\n(V2X) communication. Unlike traditional onboard sensors, V2X acts as a dynamic\n\"information sensor\" characterized by limited communication, heterogeneity,\nmobility, and scalability. This survey provides a comprehensive review of\nrecent advancements from the perspective of information-centric cooperative\nperception, focusing on three key dimensions: information representation,\ninformation fusion, and large-scale deployment. We categorize information\nrepresentation into data-level, feature-level, and object-level schemes, and\nhighlight emerging methods for reducing data volume and compressing messages\nunder communication constraints. In information fusion, we explore techniques\nunder both ideal and non-ideal conditions, including those addressing\nheterogeneity, localization errors, latency, and packet loss. Finally, we\nsummarize system-level approaches to support scalability in dense traffic\nscenarios. Compared with existing surveys, this paper introduces a new\nperspective by treating V2X communication as an information sensor and\nemphasizing the challenges of deploying cooperative perception in real-world\nintelligent transportation systems.", "published": "2025-04-30 12:23:57", "link": "http://arxiv.org/abs/2505.00747v1", "categories": ["cs.OH", "cs.CV", "cs.MA", "cs.RO"], "primary_category": "cs.OH"}
{"title": "Fast2comm:Collaborative perception combined with prior knowledge", "abstract": "Collaborative perception has the potential to significantly enhance\nperceptual accuracy through the sharing of complementary information among\nagents. However, real-world collaborative perception faces persistent\nchallenges, particularly in balancing perception performance and bandwidth\nlimitations, as well as coping with localization errors. To address these\nchallenges, we propose Fast2comm, a prior knowledge-based collaborative\nperception framework. Specifically, (1)we propose a prior-supervised confidence\nfeature generation method, that effectively distinguishes foreground from\nbackground by producing highly discriminative confidence features; (2)we\npropose GT Bounding Box-based spatial prior feature selection strategy to\nensure that only the most informative prior-knowledge features are selected and\nshared, thereby minimizing background noise and optimizing bandwidth efficiency\nwhile enhancing adaptability to localization inaccuracies; (3)we decouple the\nfeature fusion strategies between model training and testing phases, enabling\ndynamic bandwidth adaptation. To comprehensively validate our framework, we\nconduct extensive experiments on both real-world and simulated datasets. The\nresults demonstrate the superior performance of our model and highlight the\nnecessity of the proposed methods. Our code is available at\nhttps://github.com/Zhangzhengbin-TJ/Fast2comm.", "published": "2025-04-30 02:32:47", "link": "http://arxiv.org/abs/2505.00740v1", "categories": ["cs.CV", "cs.MA"], "primary_category": "cs.CV"}
{"title": "Smart Environmental Monitoring of Marine Pollution using Edge AI", "abstract": "Oil spill incidents pose severe threats to marine ecosystems and coastal\nenvironments, necessitating rapid detection and monitoring capabilities to\nmitigate environmental damage. In this paper, we demonstrate how artificial\nintelligence, despite the inherent high computational and memory requirements,\ncan be efficiently integrated into marine pollution monitoring systems. More\nprecisely, we propose a drone-based smart monitoring system leveraging a\ncompressed deep learning U-Net architecture for oil spill detection and\nthickness estimation. Compared to the standard U-Net architecture, the number\nof convolution blocks and channels per block are modified. The new model is\nthen trained on synthetic radar data to accurately predict thick oil slick\nthickness up to 10 mm. Results show that our optimized Tiny U-Net achieves\nsuperior performance with an Intersection over Union (IoU) metric of\napproximately 79%, while simultaneously reducing the model size by a factor of\n$\\sim$269x compared to the state-of-the-art. This significant model compression\nenables efficient edge computing deployment on field-programmable gate array\n(FPGA) hardware integrated directly into the drone platform. Hardware\nimplementation demonstrates near real-time thickness estimation capabilities\nwith a run-time power consumption of approximately 2.2 watts. Our findings\nhighlight the increasing potential of smart monitoring technologies and\nefficient edge computing for operational characterization in marine\nenvironments.", "published": "2025-04-30 15:59:35", "link": "http://arxiv.org/abs/2504.21759v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Efficient Decomposition of Forman-Ricci Curvature on Vietoris-Rips Complexes and Data Applications", "abstract": "Discrete Forman-Ricci curvature (FRC) is an efficient tool that characterizes\nessential geometrical features and associated transitions of real-world\nnetworks, extending seamlessly to higher-dimensional computations in simplicial\ncomplexes. In this article, we provide two major advancements: First, we give a\ndecomposition for FRC, enabling local computations of FRC. Second, we construct\na set-theoretical proof enabling an efficient algorithm for the local\ncomputation of FRC in Vietoris-Rips (VR) complexes.Strikingly, this approach\nreveals critical information and geometric insights often overlooked by\nconventional classification techniques. Our findings open new avenues for\ngeometric computations in VR complexes and highlight an essential yet\nunder-explored aspect of data classification: the geometry underpinning\nstatistical patterns.", "published": "2025-04-30 12:59:23", "link": "http://arxiv.org/abs/2504.21601v2", "categories": ["math.GT", "cs.CG", "cs.DM", "cs.DS", "math.CO", "05C85, 52C99, 90C35, 62R40, 68W99, 68T09"], "primary_category": "math.GT"}
{"title": "Effective Inference-Free Retrieval for Learned Sparse Representations", "abstract": "Learned Sparse Retrieval (LSR) is an effective IR approach that exploits\npre-trained language models for encoding text into a learned bag of words.\nSeveral efforts in the literature have shown that sparsity is key to enabling a\ngood trade-off between the efficiency and effectiveness of the query processor.\nTo induce the right degree of sparsity, researchers typically use\nregularization techniques when training LSR models. Recently, new efficient --\ninverted index-based -- retrieval engines have been proposed, leading to a\nnatural question: has the role of regularization changed in training LSR\nmodels? In this paper, we conduct an extended evaluation of regularization\napproaches for LSR where we discuss their effectiveness, efficiency, and\nout-of-domain generalization capabilities. We first show that regularization\ncan be relaxed to produce more effective LSR encoders. We also show that query\nencoding is now the bottleneck limiting the overall query processor\nperformance. To remove this bottleneck, we advance the state-of-the-art of\ninference-free LSR by proposing Learned Inference-free Retrieval (Li-LSR). At\ntraining time, Li-LSR learns a score for each token, casting the query encoding\nstep into a seamless table lookup. Our approach yields state-of-the-art\neffectiveness for both in-domain and out-of-domain evaluation, surpassing\nSplade-v3-Doc by 1 point of mRR@10 on MS MARCO and 1.8 points of nDCG@10 on\nBEIR.", "published": "2025-04-30 09:10:46", "link": "http://arxiv.org/abs/2505.01452v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "AdSight: Scalable and Accurate Quantification of User Attention in Multi-Slot Sponsored Search", "abstract": "Modern Search Engine Results Pages (SERPs) present complex layouts where\nmultiple elements compete for visibility. Attention modelling is crucial for\noptimising web design and computational advertising, whereas attention metrics\ncan inform ad placement and revenue strategies. We introduce AdSight, a method\nleveraging mouse cursor trajectories to quantify in a scalable and accurate\nmanner user attention in multi-slot environments like SERPs. AdSight uses a\nnovel Transformer-based sequence-to-sequence architecture where the encoder\nprocesses cursor trajectory embeddings, and the decoder incorporates\nslot-specific features, enabling robust attention prediction across various\nSERP layouts. We evaluate our approach on two Machine Learning tasks:\n(1)~\\emph{regression}, to predict fixation times and counts; and\n(2)~\\emph{classification}, to determine some slot types were noticed. Our\nfindings demonstrate the model's ability to predict attention with\nunprecedented precision, offering actionable insights for researchers and\npractitioners.", "published": "2025-04-30 08:51:26", "link": "http://arxiv.org/abs/2505.01451v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A note on the quantum Wielandt inequality", "abstract": "In this note, we prove that the index of primitivity of any primitive unital\nSchwarz map is at most $2(D-1)^2$, where $D$ is the dimension of the underlying\nmatrix algebra. This inequality was first proved by Rahaman for Schwarz maps\nwhich were both unital and trace preserving. As we show, the assumption of\nunitality is basically innocuous, but in general not all primitive unital\nSchwarz maps are trace preserving. Therefore, the precise purpose of this note\nis to showcase how to apply the method of Rahaman to unital primitive Schwarz\nmaps that don't preserve trace. As a corollary of this theorem, we show that\nthe index of primitivity of any primitive 2-positive map is at most $2(D-1)^2$,\nso in particular this bound holds for arbitrary primitive completely positive\nmaps. We briefly discuss of how this relates to a conjecture of Perez-Garcia,\nVerstraete, Wolf and Cirac.", "published": "2025-04-30 13:40:53", "link": "http://arxiv.org/abs/2504.21638v2", "categories": ["quant-ph", "cs.IT", "math.IT", "math.OA"], "primary_category": "quant-ph"}
{"title": "Safe and Efficient CAV Lane Changing using Decentralised Safety Shields", "abstract": "Lane changing is a complex decision-making problem for Connected and\nAutonomous Vehicles (CAVs) as it requires balancing traffic efficiency with\nsafety. Although traffic efficiency can be improved by using vehicular\ncommunication for training lane change controllers using Multi-Agent\nReinforcement Learning (MARL), ensuring safety is difficult. To address this\nissue, we propose a decentralised Hybrid Safety Shield (HSS) that combines\noptimisation and a rule-based approach to guarantee safety. Our method applies\ncontrol barrier functions to constrain longitudinal and lateral control inputs\nof a CAV to ensure safe manoeuvres. Additionally, we present an architecture to\nintegrate HSS with MARL, called MARL-HSS, to improve traffic efficiency while\nensuring safety. We evaluate MARL-HSS using a gym-like environment that\nsimulates an on-ramp merging scenario with two levels of traffic densities,\nsuch as light and moderate densities. The results show that HSS provides a\nsafety guarantee by strictly enforcing a dynamic safety constraint defined on a\ntime headway, even in moderate traffic density that offers challenging lane\nchange scenarios. Moreover, the proposed method learns stable policies compared\nto the baseline, a state-of-the-art MARL lane change controller without a\nsafety shield. Further policy evaluation shows that our method achieves a\nbalance between safety and traffic efficiency with zero crashes and comparable\naverage speeds in light and moderate traffic densities.", "published": "2025-04-30 09:11:09", "link": "http://arxiv.org/abs/2505.01453v1", "categories": ["cs.MA", "cs.AI", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "cs.MA"}
{"title": "Balancing Interpretability and Flexibility in Modeling Diagnostic Trajectories with an Embedded Neural Hawkes Process Model", "abstract": "The Hawkes process (HP) is commonly used to model event sequences with\nself-reinforcing dynamics, including electronic health records (EHRs).\nTraditional HPs capture self-reinforcement via parametric impact functions that\ncan be inspected to understand how each event modulates the intensity of\nothers. Neural network-based HPs offer greater flexibility, resulting in\nimproved fit and prediction performance, but at the cost of interpretability,\nwhich is often critical in healthcare. In this work, we aim to understand and\nimprove upon this tradeoff. We propose a novel HP formulation in which impact\nfunctions are modeled by defining a flexible impact kernel, instantiated as a\nneural network, in event embedding space, which allows us to model large-scale\nevent sequences with many event types. This approach is more flexible than\ntraditional HPs yet more interpretable than other neural network approaches,\nand allows us to explicitly trade flexibility for interpretability by adding\ntransformer encoder layers to further contextualize the event embeddings.\nResults show that our method accurately recovers impact functions in\nsimulations, achieves competitive performance on MIMIC-IV procedure dataset,\nand gains clinically meaningful interpretation on XX-EHR with children\ndiagnosis dataset even without transformer layers. This suggests that our\nflexible impact kernel is often sufficient to capture self-reinforcing dynamics\nin EHRs and other data effectively, implying that interpretability can be\nmaintained without loss of performance.", "published": "2025-04-30 16:52:43", "link": "http://arxiv.org/abs/2504.21795v2", "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "stat.ML"}
{"title": "Sibuya probability distributions and numerical evaluation of fractional-order operators", "abstract": "In this work we explore the Sibuya discrete probability distribution, which\nserves as the basis and the main instrument for numerical simulations of\nGrunwald--Letnikov fractional derivatives by the Monte Carlo method. We provide\nthree methods for simulating the Sibuya distribution. We also introduce the\nSibuya-like sieved probability distributions, and apply them to numerical\nfractional-order differentiation. Additionally, we use the Monte Carlo method\nfor evaluating fractional-order integrals, and suggest the notion of the\ncontinuous Sibuya probability distribution. The developed methods and tools are\nillustrated by examples of computation. We provide the MATLAB toolboxes for\nsimulation of the Sibuya probability distribution, and for the numerical\nexamples.", "published": "2025-04-30 11:18:39", "link": "http://arxiv.org/abs/2504.21523v2", "categories": ["math.NA", "cs.NA", "math.PR", "65C05 (primary), 65D25, 26A33"], "primary_category": "math.NA"}
{"title": "AdSight: Scalable and Accurate Quantification of User Attention in Multi-Slot Sponsored Search", "abstract": "Modern Search Engine Results Pages (SERPs) present complex layouts where\nmultiple elements compete for visibility. Attention modelling is crucial for\noptimising web design and computational advertising, whereas attention metrics\ncan inform ad placement and revenue strategies. We introduce AdSight, a method\nleveraging mouse cursor trajectories to quantify in a scalable and accurate\nmanner user attention in multi-slot environments like SERPs. AdSight uses a\nnovel Transformer-based sequence-to-sequence architecture where the encoder\nprocesses cursor trajectory embeddings, and the decoder incorporates\nslot-specific features, enabling robust attention prediction across various\nSERP layouts. We evaluate our approach on two Machine Learning tasks: (1)\nregression, to predict fixation times and counts; and (2) classification, to\ndetermine some slot types were noticed. Our findings demonstrate the model's\nability to predict attention with unprecedented precision, offering actionable\ninsights for researchers and practitioners.", "published": "2025-04-30 08:51:26", "link": "http://arxiv.org/abs/2505.01451v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Fast Sign Retrieval via Sub-band Convolution: An Elementary Extension of Binary Classification", "abstract": "To efficiently compress the sign information of images, we address a sign\nretrieval problem for the block-wise discrete cosine transformation (DCT):\nreconstruction of the signs of DCT coefficients from their amplitudes. To this\nend, we propose a fast sign retrieval method on the basis of binary\nclassification machine learning. We first introduce 3D representations of the\namplitudes and signs, where we pack amplitudes/signs belonging to the same\nfrequency band into a 2D slice, referred to as the sub-band block. We then\nretrieve the signs from the 3D amplitudes via binary classification, where each\nsign is regarded as a binary label. We implement a binary classification\nalgorithm using convolutional neural networks, which are advantageous for\nefficiently extracting features in the 3D amplitudes. Experimental results\ndemonstrate that our method achieves accurate sign retrieval with an\noverwhelmingly low computation cost.", "published": "2025-04-30 13:34:06", "link": "http://arxiv.org/abs/2504.21632v4", "categories": ["cs.IT", "eess.IV", "math.IT"], "primary_category": "cs.IT"}
