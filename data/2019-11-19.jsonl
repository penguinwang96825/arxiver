{"title": "Deep Poetry: A Chinese Classical Poetry Generation System", "abstract": "In this work, we demonstrate a Chinese classical poetry generation system\ncalled Deep Poetry. Existing systems for Chinese classical poetry generation\nare mostly template-based and very few of them can accept multi-modal input.\nUnlike previous systems, Deep Poetry uses neural networks that are trained on\nover 200 thousand poems and 3 million ancient Chinese prose. Our system can\naccept plain text, images or artistic conceptions as inputs to generate Chinese\nclassical poetry. More importantly, users are allowed to participate in the\nprocess of writing poetry by our system. For the user's convenience, we deploy\nthe system at the WeChat applet platform, users can use the system on the\nmobile device whenever and wherever possible. The demo video of this paper is\navailable at https://youtu.be/jD1R_u9TA3M.", "published": "2019-11-19 11:41:02", "link": "http://arxiv.org/abs/1911.08212v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Hybrid Morpheme-Word Representation for Machine Translation of\n  Morphologically Rich Languages", "abstract": "We propose a language-independent approach for improving statistical machine\ntranslation for morphologically rich languages using a hybrid morpheme-word\nrepresentation where the basic unit of translation is the morpheme, but word\nboundaries are respected at all stages of the translation process. Our model\nextends the classic phrase-based model by means of (1) word boundary-aware\nmorpheme-level phrase extraction, (2) minimum error-rate training for a\nmorpheme-level translation model using word-level BLEU, and (3) joint scoring\nwith morpheme- and word-level language models. Further improvements are\nachieved by combining our model with the classic one. The evaluation on English\nto Finnish using Europarl (714K sentence pairs; 15.5M English words) shows\nstatistically significant improvements over the classic model based on BLEU and\nhuman judgments.", "published": "2019-11-19 06:50:59", "link": "http://arxiv.org/abs/1911.08117v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Event detection in Colombian security Twitter news using fine-grained\n  latent topic analysis", "abstract": "Cultural and social dynamics are important concepts that must be understood\nin order to grasp what a community cares about. To that end, an excellent\nsource of information on what occurs in a community is the news, especially in\nrecent years, when mass media giants use social networks to communicate and\ninteract with their audience. In this work, we use a method to discover latent\ntopics in tweets from Colombian Twitter news accounts in order to identify the\nmost prominent events in the country. We pay particular attention to security,\nviolence and crime-related tweets because of the violent environment that\nsurrounds Colombian society. The latent topic discovery method that we use\nbuilds vector representations of the tweets by using FastText and finds\nclusters of tweets through the K-means clustering algorithm. The number of\nclusters is found by measuring the $C_V$ coherence for a range of number of\ntopics of the Latent Dirichlet Allocation (LDA) model. We finally use Uniform\nManifold Approximation and Projection (UMAP) for dimensionality reduction to\nvisualise the tweets vectors. Once the clusters related to security, violence\nand crime are identified, we proceed to apply the same method within each\ncluster to perform a fine-grained analysis in which specific events mentioned\nin the news are grouped together. Our method is able to discover event-specific\nsets of news, which is the baseline to perform an extensive analysis of how\npeople engage in Twitter threads on the different types of news, with an\nemphasis on security, violence and crime-related tweets.", "published": "2019-11-19 15:58:14", "link": "http://arxiv.org/abs/1911.08370v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Deep Spiking Neural Networks for Large Vocabulary Automatic Speech\n  Recognition", "abstract": "Artificial neural networks (ANN) have become the mainstream acoustic modeling\ntechnique for large vocabulary automatic speech recognition (ASR). A\nconventional ANN features a multi-layer architecture that requires massive\namounts of computation. The brain-inspired spiking neural networks (SNN)\nclosely mimic the biological neural networks and can operate on low-power\nneuromorphic hardware with spike-based computation. Motivated by their\nunprecedented energyefficiency and rapid information processing capability, we\nexplore the use of SNNs for speech recognition. In this work, we use SNNs for\nacoustic modeling and evaluate their performance on several large vocabulary\nrecognition scenarios. The experimental results demonstrate competitive ASR\naccuracies to their ANN counterparts, while require significantly reduced\ncomputational cost and inference time. Integrating the algorithmic power of\ndeep SNNs with energy-efficient neuromorphic hardware, therefore, offer an\nattractive solution for ASR applications running locally on mobile and embedded\ndevices.", "published": "2019-11-19 16:09:02", "link": "http://arxiv.org/abs/1911.08373v1", "categories": ["cs.NE", "cs.CL"], "primary_category": "cs.NE"}
{"title": "Extended Answer and Uncertainty Aware Neural Question Generation", "abstract": "In this paper, we study automatic question generation, the task of creating\nquestions from corresponding text passages where some certain spans of the text\ncan serve as the answers. We propose an Extended Answer-aware Network (EAN)\nwhich is trained with Word-based Coverage Mechanism (WCM) and decodes with\nUncertainty-aware Beam Search (UBS). The EAN represents the target answer by\nits surrounding sentence with an encoder, and incorporates the information of\nthe extended answer into paragraph representation with gated\nparagraph-to-answer attention to tackle the problem of the inadequate\nrepresentation of the target answer. To reduce undesirable repetition, the WCM\npenalizes repeatedly attending to the same words at different time-steps in the\ntraining stage. The UBS aims to seek a better balance between the model\nconfidence in copying words from an input text paragraph and the confidence in\ngenerating words from a vocabulary. We conduct experiments on the SQuAD\ndataset, and the results show our approach achieves significant performance\nimprovement.", "published": "2019-11-19 06:38:14", "link": "http://arxiv.org/abs/1911.08112v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hunting for Troll Comments in News Community Forums", "abstract": "There are different definitions of what a troll is. Certainly, a troll can be\nsomebody who teases people to make them angry, or somebody who offends people,\nor somebody who wants to dominate any single discussion, or somebody who tries\nto manipulate people's opinion (sometimes for money), etc. The last definition\nis the one that dominates the public discourse in Bulgaria and Eastern Europe,\nand this is our focus in this paper. In our work, we examine two types of\nopinion manipulation trolls: paid trolls that have been revealed from leaked\nreputation management contracts and mentioned trolls that have been called such\nby several different people. We show that these definitions are sensible: we\nbuild two classifiers that can distinguish a post by such a paid troll from one\nby a non-troll with 81-82% accuracy; the same classifier achieves 81-82%\naccuracy on so called mentioned troll vs. non-troll posts.", "published": "2019-11-19 06:42:23", "link": "http://arxiv.org/abs/1911.08113v1", "categories": ["cs.CL", "cs.IR", "cs.SI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "In Search of Credible News", "abstract": "We study the problem of finding fake online news. This is an important\nproblem as news of questionable credibility have recently been proliferating in\nsocial media at an alarming scale. As this is an understudied problem,\nespecially for languages other than English, we first collect and release to\nthe research community three new balanced credible vs. fake news datasets\nderived from four online sources. We then propose a language-independent\napproach for automatically distinguishing credible from fake news, based on a\nrich feature set. In particular, we use linguistic (n-gram),\ncredibility-related (capitalization, punctuation, pronoun use, sentiment\npolarity), and semantic (embeddings and DBPedia data) features. Our experiments\non three different testsets show that our model can distinguish credible from\nfake news with very high accuracy.", "published": "2019-11-19 07:06:22", "link": "http://arxiv.org/abs/1911.08125v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Retrospective and Prospective Mixture-of-Generators for Task-oriented\n  Dialogue Response Generation", "abstract": "Dialogue response generation (DRG) is a critical component of task-oriented\ndialogue systems (TDSs). Its purpose is to generate proper natural language\nresponses given some context, e.g., historical utterances, system states, etc.\nState-of-the-art work focuses on how to better tackle DRG in an end-to-end way.\nTypically, such studies assume that each token is drawn from a single\ndistribution over the output vocabulary, which may not always be optimal.\nResponses vary greatly with different intents, e.g., domains, system actions.\n  We propose a novel mixture-of-generators network (MoGNet) for DRG, where we\nassume that each token of a response is drawn from a mixture of distributions.\nMoGNet consists of a chair generator and several expert generators. Each expert\nis specialized for DRG w.r.t. a particular intent. The chair coordinates\nmultiple experts and combines the output they have generated to produce more\nappropriate responses. We propose two strategies to help the chair make better\ndecisions, namely, a retrospective mixture-of-generators (RMoG) and prospective\nmixture-of-generators (PMoG). The former only considers the historical\nexpert-generated responses until the current time step while the latter also\nconsiders possible expert-generated responses in the future by encouraging\nexploration. In order to differentiate experts, we also devise a\nglobal-and-local (GL) learning scheme that forces each expert to be specialized\ntowards a particular intent using a local loss and trains the chair and all\nexperts to coordinate using a global loss.\n  We carry out extensive experiments on the MultiWOZ benchmark dataset. MoGNet\nsignificantly outperforms state-of-the-art methods in terms of both automatic\nand human evaluations, demonstrating its effectiveness for DRG.", "published": "2019-11-19 08:20:45", "link": "http://arxiv.org/abs/1911.08151v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Unsupervised Natural Question Answering with a Small Model", "abstract": "The recent (2019-02) demonstration of the power of huge language models such\nas GPT-2 to memorise the answers to factoid questions raises questions about\nthe extent to which knowledge is being embedded directly within these large\nmodels. This short paper describes an architecture through which much smaller\nmodels can also answer such questions - by making use of 'raw' external\nknowledge. The contribution of this work is that the methods presented here\nrely on unsupervised learning techniques, complementing the unsupervised\ntraining of the Language Model. The goal of this line of research is to be able\nto add knowledge explicitly, without extensive training.", "published": "2019-11-19 15:18:39", "link": "http://arxiv.org/abs/1911.08340v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Towards unstructured mortality prediction with free-text clinical notes", "abstract": "Healthcare data continues to flourish yet a relatively small portion, mostly\nstructured, is being utilized effectively for predicting clinical outcomes. The\nrich subjective information available in unstructured clinical notes can\npossibly facilitate higher discrimination but tends to be under-utilized in\nmortality prediction. This work attempts to assess the gain in performance when\nmultiple notes that have been minimally preprocessed are used as an input for\nprediction. A hierarchical architecture consisting of both convolutional and\nrecurrent layers is used to concurrently model the different notes compiled in\nan individual hospital stay. This approach is evaluated on predicting\nin-hospital mortality on the MIMIC-III dataset. On comparison to approaches\nutilizing structured data, it achieved higher metrics despite requiring less\ncleaning and preprocessing. This demonstrates the potential of unstructured\ndata in enhancing mortality prediction and signifies the need to incorporate\nmore raw unstructured data into current clinical prediction methods.", "published": "2019-11-19 18:02:06", "link": "http://arxiv.org/abs/1911.08437v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern\n  Architectures", "abstract": "We study pseudo-labeling for the semi-supervised training of ResNet,\nTime-Depth Separable ConvNets, and Transformers for speech recognition, with\neither CTC or Seq2Seq loss functions. We perform experiments on the standard\nLibriSpeech dataset, and leverage additional unlabeled data from LibriVox\nthrough pseudo-labeling. We show that while Transformer-based acoustic models\nhave superior performance with the supervised dataset alone, semi-supervision\nimproves all models across architectures and loss functions and bridges much of\nthe performance gaps between them. In doing so, we reach a new state-of-the-art\nfor end-to-end acoustic models decoded with an external language model in the\nstandard supervised learning setting, and a new absolute state-of-the-art with\nsemi-supervised training. Finally, we study the effect of leveraging different\namounts of unlabeled audio, propose several ways of evaluating the\ncharacteristics of unlabeled audio which improve acoustic modeling, and show\nthat acoustic models trained with more audio rely less on external language\nmodels.", "published": "2019-11-19 18:40:02", "link": "http://arxiv.org/abs/1911.08460v3", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Aging Memories Generate More Fluent Dialogue Responses with Memory\n  Augmented Neural Networks", "abstract": "Memory Networks have emerged as effective models to incorporate Knowledge\nBases (KB) into neural networks. By storing KB embeddings into a memory\ncomponent, these models can learn meaningful representations that are grounded\nto external knowledge. However, as the memory unit becomes full, the oldest\nmemories are replaced by newer representations.\n  In this paper, we question this approach and provide experimental evidence\nthat conventional Memory Networks store highly correlated vectors during\ntraining. While increasing the memory size mitigates this problem, this also\nleads to overfitting as the memory stores a large number of training latent\nrepresentations. To address these issues, we propose a novel regularization\nmechanism named memory dropout which 1) Samples a single latent vector from the\ndistribution of redundant memories. 2) Ages redundant memories thus increasing\ntheir probability of overwriting them during training. This fully\ndifferentiable technique allows us to achieve state-of-the-art response\ngeneration in the Stanford Multi-Turn Dialogue and Cambridge Restaurant\ndatasets.", "published": "2019-11-19 19:34:15", "link": "http://arxiv.org/abs/1911.08522v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automatic Detection of Satire in Bangla Documents: A CNN Approach Based\n  on Hybrid Feature Extraction Model", "abstract": "Widespread of satirical news in online communities is an ongoing trend. The\nnature of satires is so inherently ambiguous that sometimes it's too hard even\nfor humans to understand whether it's actually satire or not. So, research\ninterest has grown in this field. The purpose of this research is to detect\nBangla satirical news spread in online news portals as well as social media. In\nthis paper, we propose a hybrid technique for extracting features from text\ndocuments combining Word2Vec and TF-IDF. Using our proposed feature extraction\ntechnique, with standard CNN architecture we could detect whether a Bangla text\ndocument is satire or not with an accuracy of more than 96%.", "published": "2019-11-19 20:37:03", "link": "http://arxiv.org/abs/1911.11062v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "A Multi-language Platform for Generating Algebraic Mathematical Word\n  Problems", "abstract": "Existing approaches for automatically generating mathematical word problems\nare deprived of customizability and creativity due to the inherent nature of\ntemplate-based mechanisms they employ. We present a solution to this problem\nwith the use of deep neural language generation mechanisms. Our approach uses a\nCharacter Level Long Short Term Memory Network (LSTM) to generate word\nproblems, and uses POS (Part of Speech) tags to resolve the constraints found\nin the generated problems. Our approach is capable of generating Mathematics\nWord Problems in both English and Sinhala languages with an accuracy over 90%.", "published": "2019-11-19 04:50:45", "link": "http://arxiv.org/abs/1912.01110v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Towards Lingua Franca Named Entity Recognition with BERT", "abstract": "Information extraction is an important task in NLP, enabling the automatic\nextraction of data for relational database filling. Historically, research and\ndata was produced for English text, followed in subsequent years by datasets in\nArabic, Chinese (ACE/OntoNotes), Dutch, Spanish, German (CoNLL evaluations),\nand many others. The natural tendency has been to treat each language as a\ndifferent dataset and build optimized models for each. In this paper we\ninvestigate a single Named Entity Recognition model, based on a multilingual\nBERT, that is trained jointly on many languages simultaneously, and is able to\ndecode these languages with better accuracy than models trained only on one\nlanguage. To improve the initial model, we study the use of regularization\nstrategies such as multitask learning and partial gradient updates. In addition\nto being a single model that can tackle multiple languages (including code\nswitch), the model could be used to make zero-shot predictions on a new\nlanguage, even ones for which training data is not available, out of the box.\nThe results show that this model not only performs competitively with\nmonolingual models, but it also achieves state-of-the-art results on the\nCoNLL02 Dutch and Spanish datasets, OntoNotes Arabic and Chinese datasets.\nMoreover, it performs reasonably well on unseen languages, achieving\nstate-of-the-art for zero-shot on three CoNLL languages.", "published": "2019-11-19 19:48:02", "link": "http://arxiv.org/abs/1912.01389v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Neural Network based End-to-End Query by Example Spoken Term Detection", "abstract": "This paper focuses on the problem of query by example spoken term detection\n(QbE-STD) in zero-resource scenario. State-of-the-art approaches primarily rely\non dynamic time warping (DTW) based template matching techniques using phone\nposterior or bottleneck features extracted from a deep neural network (DNN). We\nuse both monolingual and multilingual bottleneck features, and show that\nmultilingual features perform increasingly better with more training languages.\nPreviously, it has been shown that the DTW based matching can be replaced with\na CNN based matching while using posterior features. Here, we show that the CNN\nbased matching outperforms DTW based matching using bottleneck features as\nwell. In this case, the feature extraction and pattern matching stages of our\nQbE-STD system are optimized independently of each other. We propose to\nintegrate these two stages in a fully neural network based end-to-end learning\nframework to enable joint optimization of those two stages simultaneously. The\nproposed approaches are evaluated on two challenging multilingual datasets:\nSpoken Web Search 2013 and Query by Example Search on Speech Task 2014,\ndemonstrating in each case significant improvements.", "published": "2019-11-19 15:07:07", "link": "http://arxiv.org/abs/1911.08332v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Partial AUC optimization based deep speaker embeddings with class-center\n  learning for text-independent speaker verification", "abstract": "Deep embedding based text-independent speaker verification has demonstrated\nsuperior performance to traditional methods in many challenging scenarios. Its\nloss functions can be generally categorized into two classes, i.e.,\nverification and identification. The verification loss functions match the\npipeline of speaker verification, but their implementations are difficult.\nThus, most state-of-the-art deep embedding methods use the identification loss\nfunctions with softmax output units or their variants. In this paper, we\npropose a verification loss function, named the maximization of partial area\nunder the Receiver-operating-characteristic (ROC) curve (pAUC), for deep\nembedding based text-independent speaker verification. We also propose a\nclass-center based training trial construction method to improve the training\nefficiency, which is critical for the proposed loss function to be comparable\nto the identification loss in performance. Experiments on the Speaker in the\nWild (SITW) and NIST SRE 2016 datasets show that the proposed pAUC loss\nfunction is highly competitive with the state-of-the-art identification loss\nfunctions.", "published": "2019-11-19 03:30:09", "link": "http://arxiv.org/abs/1911.08077v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Distributed Microphone Speech Enhancement based on Deep Learning", "abstract": "Speech-related applications deliver inferior performance in complex noise\nenvironments. Therefore, this study primarily addresses this problem by\nintroducing speech-enhancement (SE) systems based on deep neural networks\n(DNNs) applied to a distributed microphone architecture, and then investigates\nthe effectiveness of three different DNN-model structures. The first system\nconstructs a DNN model for each microphone to enhance the recorded noisy speech\nsignal, and the second system combines all the noisy recordings into a large\nfeature structure that is then enhanced through a DNN model. As for the third\nsystem, a channel-dependent DNN is first used to enhance the corresponding\nnoisy input, and all the channel-wise enhanced outputs are fed into a DNN\nfusion model to construct a nearly clean signal. All the three DNN SE systems\nare operated in the acoustic frequency domain of speech signals in a\ndiffuse-noise field environment. Evaluation experiments were conducted on the\nTaiwan Mandarin Hearing in Noise Test (TMHINT) database, and the results\nindicate that all the three DNN-based SE systems provide the original\nnoise-corrupted signals with improved speech quality and intelligibility,\nwhereas the third system delivers the highest signal-to-noise ratio (SNR)\nimprovement and optimal speech intelligibility.", "published": "2019-11-19 08:23:17", "link": "http://arxiv.org/abs/1911.08153v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
