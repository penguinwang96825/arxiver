{"title": "Evaluation of HTR models without Ground Truth Material", "abstract": "The evaluation of Handwritten Text Recognition (HTR) models during their\ndevelopment is straightforward: because HTR is a supervised problem, the usual\ndata split into training, validation, and test data sets allows the evaluation\nof models in terms of accuracy or error rates. However, the evaluation process\nbecomes tricky as soon as we switch from development to application. A\ncompilation of a new (and forcibly smaller) ground truth (GT) from a sample of\nthe data that we want to apply the model on and the subsequent evaluation of\nmodels thereon only provides hints about the quality of the recognised text, as\ndo confidence scores (if available) the models return. Moreover, if we have\nseveral models at hand, we face a model selection problem since we want to\nobtain the best possible result during the application phase. This calls for\nGT-free metrics to select the best model, which is why we (re-)introduce and\ncompare different metrics, from simple, lexicon-based to more elaborate ones\nusing standard language models and masked language models (MLM). We show that\nMLM-based evaluation can compete with lexicon-based methods, with the advantage\nthat large and multilingual transformers are readily available, thus making\ncompiling lexical resources for other metrics superfluous.", "published": "2022-01-17 01:26:09", "link": "http://arxiv.org/abs/2201.06170v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Proficiency Matters Quality Estimation in Grammatical Error Correction", "abstract": "This study investigates how supervised quality estimation (QE) models of\ngrammatical error correction (GEC) are affected by the learners' proficiency\nwith the data. QE models for GEC evaluations in prior work have obtained a high\ncorrelation with manual evaluations. However, when functioning in a real-world\ncontext, the data used for the reported results have limitations because prior\nworks were biased toward data by learners with relatively high proficiency\nlevels. To address this issue, we created a QE dataset that includes multiple\nproficiency levels and explored the necessity of performing proficiency-wise\nevaluation for QE of GEC. Our experiments demonstrated that differences in\nevaluation dataset proficiency affect the performance of QE models, and\nproficiency-wise evaluation helps create more robust models.", "published": "2022-01-17 03:47:19", "link": "http://arxiv.org/abs/2201.06199v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Korean-Specific Dataset for Table Question Answering", "abstract": "Existing question answering systems mainly focus on dealing with text data.\nHowever, much of the data produced daily is stored in the form of tables that\ncan be found in documents and relational databases, or on the web. To solve the\ntask of question answering over tables, there exist many datasets for table\nquestion answering written in English, but few Korean datasets. In this paper,\nwe demonstrate how we construct Korean-specific datasets for table question\nanswering: Korean tabular dataset is a collection of 1.4M tables with\ncorresponding descriptions for unsupervised pre-training language models.\nKorean table question answering corpus consists of 70k pairs of questions and\nanswers created by crowd-sourced workers. Subsequently, we then build a\npre-trained language model based on Transformer and fine-tune the model for\ntable question answering with these datasets. We then report the evaluation\nresults of our model. We make our datasets publicly available via our GitHub\nrepository and hope that those datasets will help further studies for question\nanswering over tables, and for the transformation of table formats.", "published": "2022-01-17 05:47:44", "link": "http://arxiv.org/abs/2201.06223v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Deep Convolutional Neural Networks Based Multi-Task Ensemble Model for\n  Aspect and Polarity Classification in Persian Reviews", "abstract": "Aspect-based sentiment analysis is of great importance and application\nbecause of its ability to identify all aspects discussed in the text. However,\naspect-based sentiment analysis will be most effective when, in addition to\nidentifying all the aspects discussed in the text, it can also identify their\npolarity. Most previous methods use the pipeline approach, that is, they first\nidentify the aspects and then identify the polarities. Such methods are\nunsuitable for practical applications since they can lead to model errors.\nTherefore, in this study, we propose a multi-task learning model based on\nConvolutional Neural Networks (CNNs), which can simultaneously detect aspect\ncategory and detect aspect category polarity. creating a model alone may not\nprovide the best predictions and lead to errors such as bias and high variance.\nTo reduce these errors and improve the efficiency of model predictions,\ncombining several models known as ensemble learning may provide better results.\nTherefore, the main purpose of this article is to create a model based on an\nensemble of multi-task deep convolutional neural networks to enhance sentiment\nanalysis in Persian reviews. We evaluated the proposed method using a Persian\nlanguage dataset in the movie domain. Jacquard index and Hamming loss measures\nwere used to evaluate the performance of the developed models. The results\nindicate that this new approach increases the efficiency of the sentiment\nanalysis model in the Persian language.", "published": "2022-01-17 09:54:35", "link": "http://arxiv.org/abs/2201.06313v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Handling Compounding in Mobile Keyboard Input", "abstract": "This paper proposes a framework to improve the typing experience of mobile\nusers in morphologically rich languages. Smartphone keyboards typically support\nfeatures such as input decoding, corrections and predictions that all rely on\nlanguage models. For latency reasons, these operations happen on device, so the\nmodels are of limited size and cannot easily cover all the words needed by\nusers for their daily tasks, especially in morphologically rich languages. In\nparticular, the compounding nature of Germanic languages makes their vocabulary\nvirtually infinite. Similarly, heavily inflecting and agglutinative languages\n(e.g. Slavic, Turkic or Finno-Ugric languages) tend to have much larger\nvocabularies than morphologically simpler languages, such as English or\nMandarin. We propose to model such languages with automatically selected\nsubword units annotated with what we call binding types, allowing the decoder\nto know when to bind subword units into words. We show that this method brings\naround 20% word error rate reduction in a variety of compounding languages.\nThis is more than twice the improvement we previously obtained with a more\nbasic approach, also described in the paper.", "published": "2022-01-17 15:28:58", "link": "http://arxiv.org/abs/2201.06469v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a Cleaner Document-Oriented Multilingual Crawled Corpus", "abstract": "The need for raw large raw corpora has dramatically increased in recent years\nwith the introduction of transfer learning and semi-supervised learning methods\nto Natural Language Processing. And while there have been some recent attempts\nto manually curate the amount of data necessary to train large language models,\nthe main way to obtain this data is still through automatic web crawling. In\nthis paper we take the existing multilingual web corpus OSCAR and its pipeline\nUngoliant that extracts and classifies data from Common Crawl at the line\nlevel, and propose a set of improvements and automatic annotations in order to\nproduce a new document-oriented version of OSCAR that could prove more suitable\nto pre-train large generative language models as well as hopefully other\napplications in Natural Language Processing and Digital Humanities.", "published": "2022-01-17 22:12:59", "link": "http://arxiv.org/abs/2201.06642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Literature Survey of Recent Advances in Chatbots", "abstract": "Chatbots are intelligent conversational computer systems designed to mimic\nhuman conversation to enable automated online guidance and support. The\nincreased benefits of chatbots led to their wide adoption by many industries in\norder to provide virtual assistance to customers. Chatbots utilise methods and\nalgorithms from two Artificial Intelligence domains: Natural Language\nProcessing and Machine Learning. However, there are many challenges and\nlimitations in their application. In this survey we review recent advances on\nchatbots, where Artificial Intelligence and Natural Language processing are\nused. We highlight the main challenges and limitations of current work and make\nrecommendations for future research investigation.", "published": "2022-01-17 23:08:58", "link": "http://arxiv.org/abs/2201.06657v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SQUIRE: A Sequence-to-sequence Framework for Multi-hop Knowledge Graph\n  Reasoning", "abstract": "Multi-hop knowledge graph (KG) reasoning has been widely studied in recent\nyears to provide interpretable predictions on missing links with evidential\npaths. Most previous works use reinforcement learning (RL) based methods that\nlearn to navigate the path towards the target entity. However, these methods\nsuffer from slow and poor convergence, and they may fail to infer a certain\npath when there is a missing edge along the path. Here we present SQUIRE, the\nfirst Sequence-to-sequence based multi-hop reasoning framework, which utilizes\nan encoder-decoder Transformer structure to translate the query to a path. Our\nframework brings about two benefits: (1) It can learn and predict in an\nend-to-end fashion, which gives better and faster convergence; (2) Our\nTransformer model does not rely on existing edges to generate the path, and has\nthe flexibility to complete missing edges along the path, especially in sparse\nKGs. Experiments on standard and sparse KGs show that our approach yields\nsignificant improvement over prior methods, while converging 4x-7x faster.", "published": "2022-01-17 04:22:54", "link": "http://arxiv.org/abs/2201.06206v3", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "An Empirical Study on the Overlapping Problem of Open-Domain Dialogue\n  Datasets", "abstract": "Open-domain dialogue systems aim to converse with humans through text, and\ndialogue research has heavily relied on benchmark datasets. In this work, we\nobserve the overlapping problem in DailyDialog and OpenSubtitles, two popular\nopen-domain dialogue benchmark datasets. Our systematic analysis then shows\nthat such overlapping can be exploited to obtain fake state-of-the-art\nperformance. Finally, we address this issue by cleaning these datasets and\nsetting up a proper data processing procedure for future research.", "published": "2022-01-17 05:12:13", "link": "http://arxiv.org/abs/2201.06219v2", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Interactive Contrastive Learning for Self-supervised Entity Alignment", "abstract": "Self-supervised entity alignment (EA) aims to link equivalent entities across\ndifferent knowledge graphs (KGs) without seed alignments. The current SOTA\nself-supervised EA method draws inspiration from contrastive learning,\noriginally designed in computer vision based on instance discrimination and\ncontrastive loss, and suffers from two shortcomings. Firstly, it puts\nunidirectional emphasis on pushing sampled negative entities far away rather\nthan pulling positively aligned pairs close, as is done in the well-established\nsupervised EA. Secondly, KGs contain rich side information (e.g., entity\ndescription), and how to effectively leverage those information has not been\nadequately investigated in self-supervised EA. In this paper, we propose an\ninteractive contrastive learning model for self-supervised EA. The model\nencodes not only structures and semantics of entities (including entity name,\nentity description, and entity neighborhood), but also conducts cross-KG\ncontrastive learning by building pseudo-aligned entity pairs. Experimental\nresults show that our approach outperforms previous best self-supervised\nresults by a large margin (over 9% average improvement) and performs on par\nwith previous SOTA supervised counterparts, demonstrating the effectiveness of\nthe interactive contrastive learning for self-supervised EA.", "published": "2022-01-17 06:04:00", "link": "http://arxiv.org/abs/2201.06225v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generalizable Neuro-symbolic Systems for Commonsense Question Answering", "abstract": "This chapter illustrates how suitable neuro-symbolic models for language\nunderstanding can enable domain generalizability and robustness in downstream\ntasks. Different methods for integrating neural language models and knowledge\ngraphs are discussed. The situations in which this combination is most\nappropriate are characterized, including quantitative evaluation and\nqualitative error analysis on a variety of commonsense question answering\nbenchmark datasets.", "published": "2022-01-17 06:13:37", "link": "http://arxiv.org/abs/2201.06230v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Context-Free Ambiguity of Emoji", "abstract": "Emojis come with prepacked semantics making them great candidates to create\nnew forms of more accessible communications. Yet, little is known about how\nmuch of this emojis semantic is agreed upon by humans, outside of textual\ncontexts. Thus, we collected a crowdsourced dataset of one-word emoji\ndescriptions for 1,289 emojis presented to participants with no surrounding\ntext. The emojis and their interpretations were then examined for ambiguity. We\nfind that with 30 annotations per emoji, 16 emojis (1.2%) are completely\nunambiguous, whereas 55 emojis (4.3%) are so ambiguous that their descriptions\nare indistinguishable from randomly chosen descriptions. Most of studied emojis\nare spread out between the two extremes. Furthermore, investigating the\nambiguity of different types of emojis, we find that an important factor is the\nextent to which an emoji has an embedded symbolical meaning drawn from an\nestablished code-book of symbols. We conclude by discussing design\nimplications.", "published": "2022-01-17 09:33:29", "link": "http://arxiv.org/abs/2201.06302v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Chatbot System Architecture", "abstract": "The conversational agents is one of the most interested topics in computer\nscience field in the recent decade. Which can be composite from more than one\nsubject in this field, which you need to apply Natural Language Processing\nConcepts and some Artificial Intelligence Techniques such as Deep Learning\nmethods to make decision about how should be the response. This paper is\ndedicated to discuss the system architecture for the conversational agent and\nexplain each component in details.", "published": "2022-01-17 11:07:58", "link": "http://arxiv.org/abs/2201.06348v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ArCovidVac: Analyzing Arabic Tweets About COVID-19 Vaccination", "abstract": "The emergence of the COVID-19 pandemic and the first global infodemic have\nchanged our lives in many different ways. We relied on social media to get the\nlatest information about the COVID-19 pandemic and at the same time to\ndisseminate information. The content in social media consisted not only health\nrelated advises, plans, and informative news from policy makers, but also\ncontains conspiracies and rumors. It became important to identify such\ninformation as soon as they are posted to make actionable decisions (e.g.,\ndebunking rumors, or taking certain measures for traveling). To address this\nchallenge, we develop and publicly release the first largest manually annotated\nArabic tweet dataset, ArCovidVac, for the COVID-19 vaccination campaign,\ncovering many countries in the Arab region. The dataset is enriched with\ndifferent layers of annotation, including, (i) Informativeness (more vs. less\nimportance of the tweets); (ii) fine-grained tweet content types (e.g., advice,\nrumors, restriction, authenticate news/information); and (iii) stance towards\nvaccination (pro-vaccination, neutral, anti-vaccination). Further, we performed\nin-depth analysis of the data, exploring the popularity of different vaccines,\ntrending hashtags, topics and presence of offensiveness in the tweets. We\nstudied the data for individual types of tweets and temporal changes in stance\ntowards vaccine. We benchmarked the ArCovidVac dataset using transformer\narchitectures for informativeness, content types, and stance detection.", "published": "2022-01-17 16:19:21", "link": "http://arxiv.org/abs/2201.06496v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Text characterization based on recurrence networks", "abstract": "Several complex systems are characterized by presenting intricate\ncharacteristics taking place at several scales of time and space. These\nmultiscale characterizations are used in various applications, including better\nunderstanding diseases, characterizing transportation systems, and comparison\nbetween cities, among others. In particular, texts are also characterized by a\nhierarchical structure that can be approached by using multi-scale concepts and\nmethods. The multiscale properties of texts constitute a subject worth further\ninvestigation. In addition, more effective approaches to text characterization\nand analysis can be obtained by emphasizing words with potentially more\ninformational content. The present work aims at developing these possibilities\nwhile focusing on mesoscopic representations of networks. More specifically, we\nadopt an extension to the mesoscopic approach to represent text narratives, in\nwhich only the recurrent relationships among tagged parts of speech (subject,\nverb and direct object) are considered to establish connections among\nsequential pieces of text (e.g., paragraphs). The characterization of the texts\nwas then achieved by considering scale-dependent complementary methods:\naccessibility, symmetry and recurrence signatures. In order to evaluate the\npotential of these concepts and methods, we approached the problem of\ndistinguishing between literary genres (fiction and non-fiction). A set of 300\nbooks organized into the two genres was considered and were compared by using\nthe aforementioned approaches. All the methods were capable of differentiating\nto some extent between the two genres. The accessibility and symmetry reflected\nthe narrative asymmetries, while the recurrence signature provided a more\ndirect indication about the non-sequential semantic connections taking place\nalong the narrative.", "published": "2022-01-17 23:33:11", "link": "http://arxiv.org/abs/2201.06665v2", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Unintended Bias in Language Model-driven Conversational Recommendation", "abstract": "Conversational Recommendation Systems (CRSs) have recently started to\nleverage pretrained language models (LM) such as BERT for their ability to\nsemantically interpret a wide range of preference statement variations.\nHowever, pretrained LMs are well-known to be prone to intrinsic biases in their\ntraining data, which may be exacerbated by biases embedded in domain-specific\nlanguage data(e.g., user reviews) used to fine-tune LMs for CRSs. We study a\nrecently introduced LM-driven recommendation backbone (termed LMRec) of a CRS\nto investigate how unintended bias i.e., language variations such as name\nreferences or indirect indicators of sexual orientation or location that should\nnot affect recommendations manifests in significantly shifted price and\ncategory distributions of restaurant recommendations. The alarming results we\nobserve strongly indicate that LMRec has learned to reinforce harmful\nstereotypes through its recommendations. For example, offhand mention of names\nassociated with the black community significantly lowers the price distribution\nof recommended restaurants, while offhand mentions of common male-associated\nnames lead to an increase in recommended alcohol-serving establishments. These\nand many related results presented in this work raise a red flag that advances\nin the language handling capability of LM-drivenCRSs do not come without\nsignificant challenges related to mitigating unintended bias in future deployed\nCRS assistants with a potential reach of hundreds of millions of end-users.", "published": "2022-01-17 05:50:14", "link": "http://arxiv.org/abs/2201.06224v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.IR"}
{"title": "MuLVE, A Multi-Language Vocabulary Evaluation Data Set", "abstract": "Vocabulary learning is vital to foreign language learning. Correct and\nadequate feedback is essential to successful and satisfying vocabulary\ntraining. However, many vocabulary and language evaluation systems perform on\nsimple rules and do not account for real-life user learning data. This work\nintroduces Multi-Language Vocabulary Evaluation Data Set (MuLVE), a data set\nconsisting of vocabulary cards and real-life user answers, labeled indicating\nwhether the user answer is correct or incorrect. The data source is user\nlearning data from the Phase6 vocabulary trainer. The data set contains\nvocabulary questions in German and English, Spanish, and French as target\nlanguage and is available in four different variations regarding pre-processing\nand deduplication. We experiment to fine-tune pre-trained BERT language models\non the downstream task of vocabulary evaluation with the proposed MuLVE data\nset. The results provide outstanding results of > 95.5 accuracy and F2-score.\nThe data set is available on the European Language Grid.", "published": "2022-01-17 09:02:59", "link": "http://arxiv.org/abs/2201.06286v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Group Gated Fusion on Attention-based Bidirectional Alignment for\n  Multimodal Emotion Recognition", "abstract": "Emotion recognition is a challenging and actively-studied research area that\nplays a critical role in emotion-aware human-computer interaction systems. In a\nmultimodal setting, temporal alignment between different modalities has not\nbeen well investigated yet. This paper presents a new model named as Gated\nBidirectional Alignment Network (GBAN), which consists of an attention-based\nbidirectional alignment network over LSTM hidden states to explicitly capture\nthe alignment relationship between speech and text, and a novel group gated\nfusion (GGF) layer to integrate the representations of different modalities. We\nempirically show that the attention-aligned representations outperform the\nlast-hidden-states of LSTM significantly, and the proposed GBAN model\noutperforms existing state-of-the-art multimodal approaches on the IEMOCAP\ndataset.", "published": "2022-01-17 09:46:59", "link": "http://arxiv.org/abs/2201.06309v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Cyberbullying Classifiers are Sensitive to Model-Agnostic Perturbations", "abstract": "A limited amount of studies investigates the role of model-agnostic\nadversarial behavior in toxic content classification. As toxicity classifiers\npredominantly rely on lexical cues, (deliberately) creative and evolving\nlanguage-use can be detrimental to the utility of current corpora and\nstate-of-the-art models when they are deployed for content moderation. The less\ntraining data is available, the more vulnerable models might become. This study\nis, to our knowledge, the first to investigate the effect of adversarial\nbehavior and augmentation for cyberbullying detection. We demonstrate that\nmodel-agnostic lexical substitutions significantly hurt classifier performance.\nMoreover, when these perturbed samples are used for augmentation, we show\nmodels become robust against word-level perturbations at a slight trade-off in\noverall task performance. Augmentations proposed in prior work on toxicity\nprove to be less effective. Our results underline the need for such evaluations\nin online harm areas with small corpora. The perturbed data, models, and code\nare available for reproduction at https://github.com/cmry/augtox", "published": "2022-01-17 12:48:27", "link": "http://arxiv.org/abs/2201.06384v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "RuMedBench: A Russian Medical Language Understanding Benchmark", "abstract": "The paper describes the open Russian medical language understanding benchmark\ncovering several task types (classification, question answering, natural\nlanguage inference, named entity recognition) on a number of novel text sets.\nGiven the sensitive nature of the data in healthcare, such a benchmark\npartially closes the problem of Russian medical dataset absence. We prepare the\nunified format labeling, data split, and evaluation metrics for new tasks. The\nremaining tasks are from existing datasets with a few modifications. A\nsingle-number metric expresses a model's ability to cope with the benchmark.\nMoreover, we implement several baseline models, from simple ones to neural\nnetworks with transformer architecture, and release the code. Expectedly, the\nmore advanced models yield better performance, but even a simple model is\nenough for a decent result in some tasks. Furthermore, for all tasks, we\nprovide a human evaluation. Interestingly the models outperform humans in the\nlarge-scale classification tasks. However, the advantage of natural\nintelligence remains in the tasks requiring more knowledge and reasoning.", "published": "2022-01-17 16:23:33", "link": "http://arxiv.org/abs/2201.06499v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PerPaDa: A Persian Paraphrase Dataset based on Implicit Crowdsourcing\n  Data Collection", "abstract": "In this paper we introduce PerPaDa, a Persian paraphrase dataset that is\ncollected from users' input in a plagiarism detection system. As an implicit\ncrowdsourcing experience, we have gathered a large collection of original and\nparaphrased sentences from Hamtajoo; a Persian plagiarism detection system, in\nwhich users try to conceal cases of text re-use in their documents by\nparaphrasing and re-submitting manuscripts for analysis. The compiled dataset\ncontains 2446 instances of paraphrasing. In order to improve the overall\nquality of the collected data, some heuristics have been used to exclude\nsentences that don't meet the proposed criteria. The introduced corpus is much\nlarger than the available datasets for the task of paraphrase identification in\nPersian. Moreover, there is less bias in the data compared to the similar\ndatasets, since the users did not try some fixed predefined rules in order to\ngenerate similar texts to their original inputs.", "published": "2022-01-17 18:48:39", "link": "http://arxiv.org/abs/2201.06573v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Data-Centric Machine Learning in the Legal Domain", "abstract": "Machine learning research typically starts with a fixed data set created\nearly in the process. The focus of the experiments is finding a model and\ntraining procedure that result in the best possible performance in terms of\nsome selected evaluation metric. This paper explores how changes in a data set\ninfluence the measured performance of a model. Using three publicly available\ndata sets from the legal domain, we investigate how changes to their size, the\ntrain/test splits, and the human labelling accuracy impact the performance of a\ntrained deep learning classifier. We assess the overall performance (weighted\naverage) as well as the per-class performance. The observed effects are\nsurprisingly pronounced, especially when the per-class performance is\nconsidered. We investigate how \"semantic homogeneity\" of a class, i.e., the\nproximity of sentences in a semantic embedding space, influences the difficulty\nof its classification. The presented results have far reaching implications for\nefforts related to data collection and curation in the field of AI & Law. The\nresults also indicate that enhancements to a data set could be considered,\nalongside the advancement of the ML models, as an additional path for\nincreasing classification performance on various tasks in AI & Law. Finally, we\ndiscuss the need for an established methodology to assess the potential effects\nof data set properties.", "published": "2022-01-17 23:05:14", "link": "http://arxiv.org/abs/2201.06653v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Demographic Confounding Causes Extreme Instances of Lifestyle Politics\n  on Facebook", "abstract": "Lifestyle politics emerge when activities that have no substantive relevance\nto ideology become politically aligned and polarized. Homophily and social\ninfluence are able generate these fault lines on their own; however, social\nidentities from demographics may serve as coordinating mechanisms through which\nlifestyle politics are mobilized are spread. Using a dataset of 137,661,886\nobservations from 299,327 Facebook interests aggregated across users of\ndifferent racial/ethnic, education, age, gender, and income demographics, we\nfind that the most extreme instances of lifestyle politics are those which are\nhighly confounded by demographics such as race/ethnicity (e.g., Black artists\nand performers). After adjusting political alignment for demographic effects,\nlifestyle politics decreased by 27.36% toward the political \"center\" and\ndemographically confounded interests were no longer among the most polarized\ninterests. Instead, after demographic deconfounding, we found that the most\nliberal interests included electric cars, Planned Parenthood, and liberal\nsatire while the most conservative interests included the Republican Party and\nconservative commentators. We validate our measures of political alignment and\nlifestyle politics using the General Social Survey and find similar demographic\nentanglements with lifestyle politics existed before social media such as\nFacebook were ubiquitous, giving us strong confidence that our results are not\ndue to echo chambers or filter bubbles. Likewise, since demographic\ncharacteristics exist prior to ideological values, we argue that the\ndemographic confounding we observe is causally responsible for the extreme\ninstances of lifestyle politics that we find among the aggregated interests. We\nconclude our paper by relating our results to Simpson's paradox, cultural\nomnivorousness, and network autocorrelation.", "published": "2022-01-17 16:48:00", "link": "http://arxiv.org/abs/2201.06517v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.IR", "physics.soc-ph", "H.1.2; H.2.8; H.3.3; H.3.4; H.3.5; H.4.3; I.2.1; I.2.6; I.2.7; I.5"], "primary_category": "cs.SI"}
{"title": "Millions of Co-purchases and Reviews Reveal the Spread of Polarization\n  and Lifestyle Politics across Online Markets", "abstract": "Polarization in America has reached a high point as markets are also becoming\npolarized. Existing research, however, focuses on specific market segments and\nproducts and has not evaluated this trend's full breadth. If such fault lines\ndo spread into other segments that are not explicitly political, it would\nindicate the presence of lifestyle politics -- when ideas and behaviors not\ninherently political become politically aligned through their connections with\nexplicitly political things. We study the pervasiveness of polarization and\nlifestyle politics over different product segments in a diverse market and test\nthe extent to which consumer- and platform-level network effects and morality\nmay explain lifestyle politics. Specifically, using graph and language data\nfrom Amazon (82.5M reviews of 9.5M products and product and category metadata\nfrom 1996-2014), we sample 234.6 million relations among 21.8 million market\nentities to find product categories that are most politically relevant,\naligned, and polarized. We then extract moral values present in reviews' text\nand use these data and other reviewer-, product-, and category-level data to\ntest whether individual- and platform- level network factors explain lifestyle\npolitics better than products' implicit morality. We find pervasive lifestyle\npolitics. Cultural products are 4 times more polarized than any other segment,\nproducts' political attributes have up to 3.7 times larger associations with\nlifestyle politics than author-level covariates, and morality has statistically\nsignificant but relatively small correlations with lifestyle politics.\nExamining lifestyle politics in these contexts helps us better understand the\nextent and root of partisan differences, why Americans may be so polarized, and\nhow this polarization affects market systems.", "published": "2022-01-17 18:16:37", "link": "http://arxiv.org/abs/2201.06556v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.IR", "physics.soc-ph", "H.1.2; H.2.8; H.3.3; H.3.4; H.3.5; H.4.3; I.2.1; I.2.6; I.2.7; I.5"], "primary_category": "cs.SI"}
{"title": "Comparative Study of Acoustic Echo Cancellation Algorithms for Speech\n  Recognition System in Noisy Environment", "abstract": "Traditionally, adaptive filters have been deployed to achieve AEC by\nestimating the acoustic echo response using algorithms such as the Normalized\nLeast-Mean-Square (NLMS) algorithm. Several approaches have been proposed over\nrecent years to improve the performance of the standard NLMS algorithm in\nvarious ways for AEC. These include algorithms based on Time Domain, Frequency\nDomain, Fourier Transform, Wavelet Transform Adaptive Schemes, Proportionate\nSchemes, Proportionate Adaptive Filters, Combination Schemes, Block Based\nCombination, Sub band Adaptive Filtering, Uniform Over Sampled DFT Filter\nBanks, Sub band Over-Sampled DFT Filter Banks, Volterra Filters, Variable\nStep-Size (VSS) algorithms, Data Reusing Techniques, Partial Update Adaptive\nFiltering Techniques and Sub band (SAF) Schemes. These approaches aim to\naddress issues in echo cancellation including the performance with noisy input\nsignals, Time-Varying echo paths and computational complexity. In contrast to\nthese approaches, Sparse Adaptive algorithms have been developed specifically\nto address the performance of adaptive filters in sparse system identification.\nIn this paper we have discussed some AEC algorithms followed by comparative\nstudy with respective to step-size, convergence and performance.", "published": "2022-01-17 04:28:30", "link": "http://arxiv.org/abs/2201.06209v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MsEmoTTS: Multi-scale emotion transfer, prediction, and control for\n  emotional speech synthesis", "abstract": "Expressive synthetic speech is essential for many human-computer interaction\nand audio broadcast scenarios, and thus synthesizing expressive speech has\nattracted much attention in recent years. Previous methods performed the\nexpressive speech synthesis either with explicit labels or with a fixed-length\nstyle embedding extracted from reference audio, both of which can only learn an\naverage style and thus ignores the multi-scale nature of speech prosody. In\nthis paper, we propose MsEmoTTS, a multi-scale emotional speech synthesis\nframework, to model the emotion from different levels. Specifically, the\nproposed method is a typical attention-based sequence-to-sequence model and\nwith proposed three modules, including global-level emotion presenting module\n(GM), utterance-level emotion presenting module (UM), and local-level emotion\npresenting module (LM), to model the global emotion category, utterance-level\nemotion variation, and syllable-level emotion strength, respectively. In\naddition to modeling the emotion from different levels, the proposed method\nalso allows us to synthesize emotional speech in different ways, i.e.,\ntransferring the emotion from reference audio, predicting the emotion from\ninput text, and controlling the emotion strength manually. Extensive\nexperiments conducted on a Chinese emotional speech corpus demonstrate that the\nproposed method outperforms the compared reference audio-based and text-based\nemotional speech synthesis methods on the emotion transfer speech synthesis and\ntext-based emotion prediction speech synthesis respectively. Besides, the\nexperiments also show that the proposed method can control the emotion\nexpressions flexibly. Detailed analysis shows the effectiveness of each module\nand the good design of the proposed method.", "published": "2022-01-17 15:13:18", "link": "http://arxiv.org/abs/2201.06460v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On Training Targets and Activation Functions for Deep Representation\n  Learning in Text-Dependent Speaker Verification", "abstract": "Deep representation learning has gained significant momentum in advancing\ntext-dependent speaker verification (TD-SV) systems. When designing deep neural\nnetworks (DNN) for extracting bottleneck features, key considerations include\ntraining targets, activation functions, and loss functions. In this paper, we\nsystematically study the impact of these choices on the performance of TD-SV.\nFor training targets, we consider speaker identity, time-contrastive learning\n(TCL) and auto-regressive prediction coding with the first being supervised and\nthe last two being self-supervised. Furthermore, we study a range of loss\nfunctions when speaker identity is used as the training target. With regard to\nactivation functions, we study the widely used sigmoid function, rectified\nlinear unit (ReLU), and Gaussian error linear unit (GELU). We experimentally\nshow that GELU is able to reduce the error rates of TD-SV significantly\ncompared to sigmoid, irrespective of training target. Among the three training\ntargets, TCL performs the best. Among the various loss functions, cross\nentropy, joint-softmax and focal loss functions outperform the others. Finally,\nscore-level fusion of different systems is also able to reduce the error rates.\nExperiments are conducted on the RedDots 2016 challenge database for TD-SV\nusing short utterances. For the speaker classifications, the well-known\nGaussian mixture model-universal background model (GMM-UBM) and i-vector\ntechniques are used.", "published": "2022-01-17 14:32:51", "link": "http://arxiv.org/abs/2201.06426v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
