{"title": "Learning Multilingual Word Representations using a Bag-of-Words\n  Autoencoder", "abstract": "Recent work on learning multilingual word representations usually relies on\nthe use of word-level alignements (e.g. infered with the help of GIZA++)\nbetween translated sentences, in order to align the word embeddings in\ndifferent languages. In this workshop paper, we investigate an autoencoder\nmodel for learning multilingual word representations that does without such\nword-level alignements. The autoencoder is trained to reconstruct the\nbag-of-word representation of given sentence from an encoded representation\nextracted from its translation. We evaluate our approach on a multilingual\ndocument classification task, where labeled data is available only for one\nlanguage (e.g. English) while classification must be performed in a different\nlanguage (e.g. French). In our experiments, we observe that our method compares\nfavorably with a previously proposed method that exploits word-level alignments\nto learn word representations.", "published": "2014-01-08 20:36:57", "link": "http://arxiv.org/abs/1401.1803v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
