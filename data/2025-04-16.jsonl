{"title": "BitNet b1.58 2B4T Technical Report", "abstract": "We introduce BitNet b1.58 2B4T, the first open-source, native 1-bit Large\nLanguage Model (LLM) at the 2-billion parameter scale. Trained on a corpus of 4\ntrillion tokens, the model has been rigorously evaluated across benchmarks\ncovering language understanding, mathematical reasoning, coding proficiency,\nand conversational ability. Our results demonstrate that BitNet b1.58 2B4T\nachieves performance on par with leading open-weight, full-precision LLMs of\nsimilar size, while offering significant advantages in computational\nefficiency, including substantially reduced memory footprint, energy\nconsumption, and decoding latency. To facilitate further research and adoption,\nthe model weights are released via Hugging Face along with open-source\ninference implementations for both GPU and CPU architectures.", "published": "2025-04-16 17:51:43", "link": "http://arxiv.org/abs/2504.12285v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dysarthria Normalization via Local Lie Group Transformations for Robust ASR", "abstract": "We present a geometry-driven method for normalizing dysarthric speech using\nlocal Lie group transformations of spectrograms. Time, frequency, and amplitude\ndistortions are modeled as smooth, invertible deformations, parameterized by\nscalar fields and applied via exponential maps. A neural network is trained to\ninfer these fields from synthetic distortions of typical speech-without using\nany pathological data. At test time, the model applies an approximate inverse\nto real dysarthric inputs. Despite zero-shot generalization, we observe\nsubstantial ASR gains, including up to 16 percentage points WER reduction on\nchallenging TORGO samples, with no degradation on clean speech. This work\nintroduces a principled, interpretable approach for robust speech recognition\nunder motor speech disorders", "published": "2025-04-16 17:41:19", "link": "http://arxiv.org/abs/2504.12279v1", "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Advancing Arabic Speech Recognition Through Large-Scale Weakly Supervised Learning", "abstract": "Automatic speech recognition (ASR) is crucial for human-machine interaction\nin diverse applications like conversational agents, industrial robotics, call\ncenter automation, and automated subtitling. However, developing\nhigh-performance ASR models remains challenging, particularly for low-resource\nlanguages like Arabic, due to the scarcity of large, labeled speech datasets,\nwhich are costly and labor-intensive to produce. In this work, we employ weakly\nsupervised learning to train an Arabic ASR model using the Conformer\narchitecture. Our model is trained from scratch on 15,000 hours of weakly\nannotated speech data covering both Modern Standard Arabic (MSA) and Dialectal\nArabic (DA), eliminating the need for costly manual transcriptions. Despite the\nabsence of human-verified labels, our approach attains state-of-the-art (SOTA)\nperformance, exceeding all previous efforts in the field of Arabic ASR on the\nstandard benchmarks. By demonstrating the effectiveness of weak supervision as\na scalable, cost-efficient alternative to traditional supervised approaches,\npaving the way for improved ASR systems in low resource settings.", "published": "2025-04-16 17:05:14", "link": "http://arxiv.org/abs/2504.12254v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Watermarking Needs Input Repetition Masking", "abstract": "Recent advancements in Large Language Models (LLMs) raised concerns over\npotential misuse, such as for spreading misinformation. In response two counter\nmeasures emerged: machine learning-based detectors that predict if text is\nsynthetic, and LLM watermarking, which subtly marks generated text for\nidentification and attribution. Meanwhile, humans are known to adjust language\nto their conversational partners both syntactically and lexically. By\nimplication, it is possible that humans or unwatermarked LLMs could\nunintentionally mimic properties of LLM generated text, making counter measures\nunreliable. In this work we investigate the extent to which such conversational\nadaptation happens. We call the concept $\\textit{mimicry}$ and demonstrate that\nboth humans and LLMs end up mimicking, including the watermarking signal even\nin seemingly improbable settings. This challenges current academic assumptions\nand suggests that for long-term watermarking to be reliable, the likelihood of\nfalse positives needs to be significantly lower, while longer word sequences\nshould be used for seeding watermarking mechanisms.", "published": "2025-04-16 16:25:26", "link": "http://arxiv.org/abs/2504.12229v1", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning", "abstract": "Recent large language models (LLMs) have demonstrated strong reasoning\ncapabilities that benefits from online reinforcement learning (RL). These\ncapabilities have primarily been demonstrated within the left-to-right\nautoregressive (AR) generation paradigm. In contrast, non-autoregressive\nparadigms based on diffusion generate text in a coarse-to-fine manner. Although\nrecent diffusion-based large language models (dLLMs) have achieved competitive\nlanguage modeling performance compared to their AR counterparts, it remains\nunclear if dLLMs can also leverage recent advances in LLM reasoning. To this\nend, we propose d1, a framework to adapt pre-trained masked dLLMs into\nreasoning models via a combination of supervised finetuning (SFT) and RL.\nSpecifically, we develop and extend techniques to improve reasoning in\npretrained dLLMs: (a) we utilize a masked SFT technique to distill knowledge\nand instill self-improvement behavior directly from existing datasets, and (b)\nwe introduce a novel critic-free, policy-gradient based RL algorithm called\ndiffu-GRPO. Through empirical studies, we investigate the performance of\ndifferent post-training recipes on multiple mathematical and logical reasoning\nbenchmarks. We find that d1 yields the best performance and significantly\nimproves performance of a state-of-the-art dLLM.", "published": "2025-04-16 16:08:45", "link": "http://arxiv.org/abs/2504.12216v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "What Do Large Language Models Know? Tacit Knowledge as a Potential Causal-Explanatory Structure", "abstract": "It is sometimes assumed that Large Language Models (LLMs) know language, or\nfor example that they know that Paris is the capital of France. But what -- if\nanything -- do LLMs actually know? In this paper, I argue that LLMs can acquire\ntacit knowledge as defined by Martin Davies (1990). Whereas Davies himself\ndenies that neural networks can acquire tacit knowledge, I demonstrate that\ncertain architectural features of LLMs satisfy the constraints of semantic\ndescription, syntactic structure, and causal systematicity. Thus, tacit\nknowledge may serve as a conceptual framework for describing, explaining, and\nintervening on LLMs and their behavior.", "published": "2025-04-16 15:42:33", "link": "http://arxiv.org/abs/2504.12187v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SALAD: Improving Robustness and Generalization through Contrastive Learning with Structure-Aware and LLM-Driven Augmented Data", "abstract": "In various natural language processing (NLP) tasks, fine-tuning Pre-trained\nLanguage Models (PLMs) often leads to the issue of spurious correlations, which\nnegatively impacts performance, particularly when dealing with\nout-of-distribution data. To address this problem, we propose SALAD}(Structure\nAware and LLM-driven Augmented Data), a novel approach designed to enhance\nmodel robustness and generalization by generating structure-aware and\ncounterfactually augmented data for contrastive learning. Our method leverages\na tagging-based approach to generate structure-aware positive samples and\nutilizes large language models (LLMs) to generate counterfactual negative\nsamples with diverse sentence patterns. By applying contrastive learning, SALAD\nenables the model to focus on learning the structural relationships between key\nsentence components while minimizing reliance on spurious correlations. We\nvalidate our approach through experiments on three tasks: Sentiment\nClassification, Sexism Detection, and Natural Language Inference. The results\ndemonstrate that SALAD not only improves model robustness and performance\nacross different environments but also enhances generalization to\nout-of-distribution datasets and cross-domain scenarios.", "published": "2025-04-16 15:40:10", "link": "http://arxiv.org/abs/2504.12185v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Trusting CHATGPT: how minor tweaks in the prompts lead to major differences in sentiment classification", "abstract": "One fundamental question for the social sciences today is: how much can we\ntrust highly complex predictive models like ChatGPT? This study tests the\nhypothesis that subtle changes in the structure of prompts do not produce\nsignificant variations in the classification results of sentiment polarity\nanalysis generated by the Large Language Model GPT-4o mini. Using a dataset of\n100.000 comments in Spanish on four Latin American presidents, the model\nclassified the comments as positive, negative, or neutral on 10 occasions,\nvarying the prompts slightly each time. The experimental methodology included\nexploratory and confirmatory analyses to identify significant discrepancies\namong classifications.\n  The results reveal that even minor modifications to prompts such as lexical,\nsyntactic, or modal changes, or even their lack of structure impact the\nclassifications. In certain cases, the model produced inconsistent responses,\nsuch as mixing categories, providing unsolicited explanations, or using\nlanguages other than Spanish. Statistical analysis using Chi-square tests\nconfirmed significant differences in most comparisons between prompts, except\nin one case where linguistic structures were highly similar.\n  These findings challenge the robustness and trust of Large Language Models\nfor classification tasks, highlighting their vulnerability to variations in\ninstructions. Moreover, it was evident that the lack of structured grammar in\nprompts increases the frequency of hallucinations. The discussion underscores\nthat trust in Large Language Models is based not only on technical performance\nbut also on the social and institutional relationships underpinning their use.", "published": "2025-04-16 15:37:09", "link": "http://arxiv.org/abs/2504.12180v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mapping Controversies Using Artificial Intelligence: An Analysis of the Hamas-Israel Conflict on YouTube", "abstract": "This article analyzes the Hamas-Israel controversy through 253,925\nSpanish-language YouTube comments posted between October 2023 and January 2024,\nfollowing the October 7 attack that escalated the conflict. Adopting an\ninterdisciplinary approach, the study combines the analysis of controversies\nfrom Science and Technology Studies (STS) with advanced computational\nmethodologies, specifically Natural Language Processing (NLP) using the BERT\n(Bidirectional Encoder Representations from Transformers) model. Using this\napproach, the comments were automatically classified into seven categories,\nreflecting pro-Palestinian, pro-Israeli, anti- Palestinian, anti-Israeli\npositions, among others. The results show a predominance of pro- Palestinian\ncomments, although pro-Israeli and anti-Palestinian comments received more\n\"likes.\" This study also applies the agenda-setting theory to demonstrate how\nmedia coverage significantly influences public perception, observing a notable\nshift in public opinion, transitioning from a pro- Palestinian stance to a more\ncritical position towards Israel. This work highlights the importance of\ncombining social science perspectives with technological tools in the analysis\nof controversies, presenting a methodological innovation by integrating\ncomputational analysis with critical social theories to address complex public\nopinion phenomena and media narratives.", "published": "2025-04-16 15:27:57", "link": "http://arxiv.org/abs/2504.12177v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Poem Meter Classification of Recited Arabic Poetry: Integrating High-Resource Systems for a Low-Resource Task", "abstract": "Arabic poetry is an essential and integral part of Arabic language and\nculture. It has been used by the Arabs to spot lights on their major events\nsuch as depicting brutal battles and conflicts. They also used it, as in many\nother languages, for various purposes such as romance, pride, lamentation, etc.\nArabic poetry has received major attention from linguistics over the decades.\nOne of the main characteristics of Arabic poetry is its special rhythmic\nstructure as opposed to prose. This structure is referred to as a meter.\nMeters, along with other poetic characteristics, are intensively studied in an\nArabic linguistic field called \"\\textit{Aroud}\". Identifying these meters for a\nverse is a lengthy and complicated process. It also requires technical\nknowledge in \\textit{Aruod}. For recited poetry, it adds an extra layer of\nprocessing. Developing systems for automatic identification of poem meters for\nrecited poems need large amounts of labelled data. In this study, we propose a\nstate-of-the-art framework to identify the poem meters of recited Arabic\npoetry, where we integrate two separate high-resource systems to perform the\nlow-resource task. To ensure generalization of our proposed architecture, we\npublish a benchmark for this task for future research.", "published": "2025-04-16 15:25:45", "link": "http://arxiv.org/abs/2504.12172v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multilingual Contextualization of Large Language Models for Document-Level Machine Translation", "abstract": "Large language models (LLMs) have demonstrated strong performance in\nsentence-level machine translation, but scaling to document-level translation\nremains challenging, particularly in modeling long-range dependencies and\ndiscourse phenomena across sentences and paragraphs. In this work, we propose a\nmethod to improve LLM-based long-document translation through targeted\nfine-tuning on high-quality document-level data, which we curate and introduce\nas DocBlocks. Our approach supports multiple translation paradigms, including\ndirect document-to-document and chunk-level translation, by integrating\ninstructions both with and without surrounding context. This enables models to\nbetter capture cross-sentence dependencies while maintaining strong\nsentence-level translation performance. Experimental results show that\nincorporating multiple translation paradigms improves document-level\ntranslation quality and inference speed compared to prompting and agent-based\nmethods.", "published": "2025-04-16 14:52:22", "link": "http://arxiv.org/abs/2504.12140v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Contrastive Decoding with Probabilistic Hallucination Detection - Mitigating Hallucinations in Large Vision Language Models -", "abstract": "Despite recent advances in Large Vision Language Models (LVLMs), these models\nstill suffer from generating hallucinatory responses that do not align with the\nvisual input provided. To mitigate such hallucinations, we introduce Efficient\nContrastive Decoding (ECD), a simple method that leverages probabilistic\nhallucination detection to shift the output distribution towards contextually\naccurate answers at inference time. By contrasting token probabilities and\nhallucination scores, ECD subtracts hallucinated concepts from the original\ndistribution, effectively suppressing hallucinations. Notably, our proposed\nmethod can be applied to any open-source LVLM and does not require additional\nLVLM training. We evaluate our method on several benchmark datasets and across\ndifferent LVLMs. Our experiments show that ECD effectively mitigates\nhallucinations, outperforming state-of-the-art methods with respect to\nperformance on LVLM benchmarks and computation time.", "published": "2025-04-16 14:50:25", "link": "http://arxiv.org/abs/2504.12137v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Entropy-Guided Watermarking for LLMs: A Test-Time Framework for Robust and Traceable Text Generation", "abstract": "The rapid development of Large Language Models (LLMs) has intensified\nconcerns about content traceability and potential misuse. Existing watermarking\nschemes for sampled text often face trade-offs between maintaining text quality\nand ensuring robust detection against various attacks. To address these issues,\nwe propose a novel watermarking scheme that improves both detectability and\ntext quality by introducing a cumulative watermark entropy threshold. Our\napproach is compatible with and generalizes existing sampling functions,\nenhancing adaptability. Experimental results across multiple LLMs show that our\nscheme significantly outperforms existing methods, achieving over 80\\%\nimprovements on widely-used datasets, e.g., MATH and GSM8K, while maintaining\nhigh detection accuracy.", "published": "2025-04-16 14:16:38", "link": "http://arxiv.org/abs/2504.12108v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gauging Overprecision in LLMs: An Empirical Study", "abstract": "Recently, overconfidence in large language models (LLMs) has garnered\nconsiderable attention due to its fundamental importance in quantifying the\ntrustworthiness of LLM generation. However, existing approaches prompt the\n\\textit{black box LLMs} to produce their confidence (\\textit{verbalized\nconfidence}), which can be subject to many biases and hallucinations. Inspired\nby a different aspect of overconfidence in cognitive science called\n\\textit{overprecision}, we designed a framework for its study in black box\nLLMs. This framework contains three main phases: 1) generation, 2) refinement\nand 3) evaluation. In the generation phase we prompt the LLM to generate\nanswers to numerical questions in the form of intervals with a certain level of\nconfidence. This confidence level is imposed in the prompt and not required for\nthe LLM to generate as in previous approaches. We use various prompting\ntechniques and use the same prompt multiple times to gauge the effects of\nrandomness in the generation process. In the refinement phase, answers from the\nprevious phase are refined to generate better answers. The LLM answers are\nevaluated and studied in the evaluation phase to understand its internal\nworkings. This study allowed us to gain various insights into LLM\noverprecision: 1) LLMs are highly uncalibrated for numerical tasks 2)\n{\\color{blue}there is no correlation between the length of the interval and the\nimposed confidence level, which can be symptomatic of a a) lack of\nunderstanding of the concept of confidence or b) inability to adjust\nself-confidence by following instructions}, {\\color{blue}3)} LLM numerical\nprecision differs depending on the task, scale of answer and prompting\ntechnique {\\color{blue}4) Refinement of answers doesn't improve precision in\nmost cases}. We believe this study offers new perspectives on LLM\noverconfidence and serves as a strong baseline for overprecision in LLMs.", "published": "2025-04-16 14:02:21", "link": "http://arxiv.org/abs/2504.12098v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Selective Demonstration Retrieval for Improved Implicit Hate Speech Detection", "abstract": "Hate speech detection is a crucial area of research in natural language\nprocessing, essential for ensuring online community safety. However, detecting\nimplicit hate speech, where harmful intent is conveyed in subtle or indirect\nways, remains a major challenge. Unlike explicit hate speech, implicit\nexpressions often depend on context, cultural subtleties, and hidden biases,\nmaking them more challenging to identify consistently. Additionally, the\ninterpretation of such speech is influenced by external knowledge and\ndemographic biases, resulting in varied detection results across different\nlanguage models. Furthermore, Large Language Models often show heightened\nsensitivity to toxic language and references to vulnerable groups, which can\nlead to misclassifications. This over-sensitivity results in false positives\n(incorrectly identifying harmless statements as hateful) and false negatives\n(failing to detect genuinely harmful content). Addressing these issues requires\nmethods that not only improve detection precision but also reduce model biases\nand enhance robustness. To address these challenges, we propose a novel method,\nwhich utilizes in-context learning without requiring model fine-tuning. By\nadaptively retrieving demonstrations that focus on similar groups or those with\nthe highest similarity scores, our approach enhances contextual comprehension.\nExperimental results show that our method outperforms current state-of-the-art\ntechniques. Implementation details and code are available at TBD.", "published": "2025-04-16 13:43:23", "link": "http://arxiv.org/abs/2504.12082v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bayesian dynamic borrowing considering semantic similarity between outcomes for disproportionality analysis in FAERS", "abstract": "We present a Bayesian dynamic borrowing (BDB) approach to enhance the\nquantitative identification of adverse events (AEs) in spontaneous reporting\nsystems (SRSs). The method embeds a robust meta-analytic predictive (MAP) prior\nwithin a Bayesian hierarchical model and incorporates semantic similarity\nmeasures (SSMs) to enable weighted information sharing from MedDRA Preferred\nTerms (PTs) that are clinical similar to the target PT. This continuous\nsimilarity-based borrowing addresses limitation of rigid hierarchical grouping\nin current disproportionality analysis (DPA).\n  Using data from the FDA Adverse Event Reporting System (FAERS) between 2015\nand 2019, we evalute this approach - termed IC SSM - against standard\nInformation Component (IC) analysis and IC with borrowing at the MedDRA\nhigh-level group term (HLGT) level. A novel references set (PVLens), derived\nfrom FDA product label updates, enabled prospective evaluation of method\nperformance in identifying AEs prior to official labeling.\n  The IC SSM approach demonstrated improved sensitivity compared to both\ntraditional IC and HLGT-based borrowing, with minor trade-offs in F1 scores and\nYouden's index. IC SSM consistently identified more true positives and detected\nsignals over 5 months sooner than traditional IC. Despite a marginally lower\naggregate Youden's index, IC SSM showed higher performance in the early\npost-marketing period, providing more stable and relevant estimates than\nHLGT-based borrowing and traditional IC.\n  These findings support the use of SSM-informed Bayesian borrowing as a\nscalable and context-aware enhancement to traditional DPA methods. Future\nresearch should validate this approach across other datasets and explore\nadditional similarity metrics and Bayesian inference strategies using\ncase-level data.", "published": "2025-04-16 13:06:24", "link": "http://arxiv.org/abs/2504.12052v1", "categories": ["cs.CL", "I.2.4; G.3; H.3.3"], "primary_category": "cs.CL"}
{"title": "Language Models as Quasi-Crystalline Thought: Structure, Constraint, and Emergence in Generative Systems", "abstract": "This essay proposes an analogy between large language models (LLMs) and\nquasicrystals: systems that exhibit global coherence without periodic\nrepetition and that are generated through local constraints. While LLMs are\noften evaluated in terms of predictive accuracy, factuality, or alignment, this\nstructural perspective suggests that their most characteristic behavior is the\nproduction of internally resonant linguistic patterns. Just as quasicrystals\nforced a redefinition of order in physical systems, viewing LLMs as generators\nof quasi-structured language opens new paths for evaluation and design:\nprivileging propagation of constraint over token-level accuracy, and coherence\nof form over fixed meaning. LLM outputs should be read not only for what they\nsay, but for the patterns of constraint and coherence that organize them. This\nshift reframes generative language as a space of emergent patterning: LLMs are\nneither fully random nor strictly rule-based, but defined by a logic of\nconstraint, resonance, and structural depth.", "published": "2025-04-16 11:27:47", "link": "http://arxiv.org/abs/2504.11986v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SemEval-2025 Task 3: Mu-SHROOM, the Multilingual Shared Task on Hallucinations and Related Observable Overgeneration Mistakes", "abstract": "We present the Mu-SHROOM shared task which is focused on detecting\nhallucinations and other overgeneration mistakes in the output of\ninstruction-tuned large language models (LLMs). Mu-SHROOM addresses\ngeneral-purpose LLMs in 14 languages, and frames the hallucination detection\nproblem as a span-labeling task. We received 2,618 submissions from 43\nparticipating teams employing diverse methodologies. The large number of\nsubmissions underscores the interest of the community in hallucination\ndetection. We present the results of the participating systems and conduct an\nempirical analysis to identify key factors contributing to strong performance\nin this task. We also emphasize relevant current challenges, notably the\nvarying degree of hallucinations across languages and the high annotator\ndisagreement when labeling hallucination spans.", "published": "2025-04-16 11:15:26", "link": "http://arxiv.org/abs/2504.11975v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-as-a-Judge: Reassessing the Performance of LLMs in Extractive QA", "abstract": "Extractive reading comprehension question answering (QA) datasets are\ntypically evaluated using Exact Match (EM) and F1-score, but these metrics\noften fail to fully capture model performance. With the success of large\nlanguage models (LLMs), they have been employed in various tasks, including\nserving as judges (LLM-as-a-judge). In this paper, we reassess the performance\nof QA models using LLM-as-a-judge across four reading comprehension QA\ndatasets. We examine different families of LLMs and various answer types to\nevaluate the effectiveness of LLM-as-a-judge in these tasks. Our results show\nthat LLM-as-a-judge is highly correlated with human judgments and can replace\ntraditional EM/F1 metrics. By using LLM-as-a-judge, the correlation with human\njudgments improves significantly, from 0.17 (EM) and 0.36 (F1-score) to 0.85.\nThese findings confirm that EM and F1 metrics underestimate the true\nperformance of the QA models. While LLM-as-a-judge is not perfect for more\ndifficult answer types (e.g., job), it still outperforms EM/F1, and we observe\nno bias issues, such as self-preference, when the same model is used for both\nthe QA and judgment tasks.", "published": "2025-04-16 11:08:46", "link": "http://arxiv.org/abs/2504.11972v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust and Fine-Grained Detection of AI Generated Texts", "abstract": "An ideal detection system for machine generated content is supposed to work\nwell on any generator as many more advanced LLMs come into existence day by\nday. Existing systems often struggle with accurately identifying AI-generated\ncontent over shorter texts. Further, not all texts might be entirely authored\nby a human or LLM, hence we focused more over partial cases i.e human-LLM\nco-authored texts. Our paper introduces a set of models built for the task of\ntoken classification which are trained on an extensive collection of\nhuman-machine co-authored texts, which performed well over texts of unseen\ndomains, unseen generators, texts by non-native speakers and those with\nadversarial inputs. We also introduce a new dataset of over 2.4M such texts\nmostly co-authored by several popular proprietary LLMs over 23 languages. We\nalso present findings of our models' performance over each texts of each domain\nand generator. Additional findings include comparison of performance against\neach adversarial method, length of input texts and characteristics of generated\ntexts compared to the original human authored texts.", "published": "2025-04-16 10:29:30", "link": "http://arxiv.org/abs/2504.11952v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ADAT: Time-Series-Aware Adaptive Transformer Architecture for Sign Language Translation", "abstract": "Current sign language machine translation systems rely on recognizing hand\nmovements, facial expressions and body postures, and natural language\nprocessing, to convert signs into text. Recent approaches use Transformer\narchitectures to model long-range dependencies via positional encoding.\nHowever, they lack accuracy in recognizing fine-grained, short-range temporal\ndependencies between gestures captured at high frame rates. Moreover, their\nhigh computational complexity leads to inefficient training. To mitigate these\nissues, we propose an Adaptive Transformer (ADAT), which incorporates\ncomponents for enhanced feature extraction and adaptive feature weighting\nthrough a gating mechanism to emphasize contextually relevant features while\nreducing training overhead and maintaining translation accuracy. To evaluate\nADAT, we introduce MedASL, the first public medical American Sign Language\ndataset. In sign-to-gloss-to-text experiments, ADAT outperforms the\nencoder-decoder transformer, improving BLEU-4 accuracy by 0.1% while reducing\ntraining time by 14.33% on PHOENIX14T and 3.24% on MedASL. In sign-to-text\nexperiments, it improves accuracy by 8.7% and reduces training time by 2.8% on\nPHOENIX14T and achieves 4.7% higher accuracy and 7.17% faster training on\nMedASL. Compared to encoder-only and decoder-only baselines in sign-to-text,\nADAT is at least 6.8% more accurate despite being up to 12.1% slower due to its\ndual-stream structure.", "published": "2025-04-16 10:20:11", "link": "http://arxiv.org/abs/2504.11942v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "I.2.6; I.2.7; I.2.10; I.4.8; I.4.9; I.4.10"], "primary_category": "cs.AI"}
{"title": "An LLM-as-a-judge Approach for Scalable Gender-Neutral Translation Evaluation", "abstract": "Gender-neutral translation (GNT) aims to avoid expressing the gender of human\nreferents when the source text lacks explicit cues about the gender of those\nreferents. Evaluating GNT automatically is particularly challenging, with\ncurrent solutions being limited to monolingual classifiers. Such solutions are\nnot ideal because they do not factor in the source sentence and require\ndedicated data and fine-tuning to scale to new languages. In this work, we\naddress such limitations by investigating the use of large language models\n(LLMs) as evaluators of GNT. Specifically, we explore two prompting approaches:\none in which LLMs generate sentence-level assessments only, and another, akin\nto a chain-of-thought approach, where they first produce detailed phrase-level\nannotations before a sentence-level judgment. Through extensive experiments on\nmultiple languages with five models, both open and proprietary, we show that\nLLMs can serve as evaluators of GNT. Moreover, we find that prompting for\nphrase-level annotations before sentence-level assessments consistently\nimproves the accuracy of all models, providing a better and more scalable\nalternative to current solutions.", "published": "2025-04-16 10:14:27", "link": "http://arxiv.org/abs/2504.11934v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Finding Flawed Fictions: Evaluating Complex Reasoning in Language Models via Plot Hole Detection", "abstract": "Stories are a fundamental aspect of human experience. Engaging deeply with\nstories and spotting plot holes -- inconsistencies in a storyline that break\nthe internal logic or rules of a story's world -- requires nuanced reasoning\nskills, including tracking entities and events and their interplay, abstract\nthinking, pragmatic narrative understanding, commonsense and social reasoning,\nand theory of mind. As Large Language Models (LLMs) increasingly generate,\ninterpret, and modify text, rigorously assessing their narrative consistency\nand deeper language understanding becomes critical. However, existing\nbenchmarks focus mainly on surface-level comprehension. In this work, we\npropose plot hole detection in stories as a proxy to evaluate language\nunderstanding and reasoning in LLMs. We introduce FlawedFictionsMaker, a novel\nalgorithm to controllably and carefully synthesize plot holes in human-written\nstories. Using this algorithm, we construct a benchmark to evaluate LLMs' plot\nhole detection abilities in stories -- FlawedFictions -- , which is robust to\ncontamination, with human filtering ensuring high quality. We find that\nstate-of-the-art LLMs struggle in accurately solving FlawedFictions regardless\nof the reasoning effort allowed, with performance significantly degrading as\nstory length increases. Finally, we show that LLM-based story summarization and\nstory generation are prone to introducing plot holes, with more than 50% and\n100% increases in plot hole detection rates with respect to human-written\noriginals.", "published": "2025-04-16 09:25:54", "link": "http://arxiv.org/abs/2504.11900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking LLM-Based Recommendations: A Query Generation-Based, Training-Free Approach", "abstract": "Existing large language model LLM-based recommendation methods face several\nchallenges, including inefficiency in handling large candidate pools,\nsensitivity to item order within prompts (\"lost in the middle\" phenomenon) poor\nscalability, and unrealistic evaluation due to random negative sampling. To\naddress these issues, we propose a Query-to-Recommendation approach that\nleverages LLMs to generate personalized queries for retrieving relevant items\nfrom the entire candidate pool, eliminating the need for candidate\npre-selection. This method can be integrated into an ID-based recommendation\nsystem without additional training, enhances recommendation performance and\ndiversity through LLMs' world knowledge, and performs well even for less\npopular item groups. Experiments on three datasets show up to 57 percent\nimprovement, with an average gain of 31 percent, demonstrating strong zero-shot\nperformance and further gains when ensembled with existing models.", "published": "2025-04-16 09:17:45", "link": "http://arxiv.org/abs/2504.11889v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Evaluating the Goal-Directedness of Large Language Models", "abstract": "To what extent do LLMs use their capabilities towards their given goal? We\ntake this as a measure of their goal-directedness. We evaluate\ngoal-directedness on tasks that require information gathering, cognitive\neffort, and plan execution, where we use subtasks to infer each model's\nrelevant capabilities. Our evaluations of LLMs from Google DeepMind, OpenAI,\nand Anthropic show that goal-directedness is relatively consistent across\ntasks, differs from task performance, and is only moderately sensitive to\nmotivational prompts. Notably, most models are not fully goal-directed. We hope\nour goal-directedness evaluations will enable better monitoring of LLM\nprogress, and enable more deliberate design choices of agentic properties in\nLLMs.", "published": "2025-04-16 08:07:08", "link": "http://arxiv.org/abs/2504.11844v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "FiSMiness: A Finite State Machine Based Paradigm for Emotional Support Conversations", "abstract": "Emotional support conversation (ESC) aims to alleviate the emotional distress\nof individuals through effective conversations. Although large language models\n(LLMs) have obtained remarkable progress on ESC, most of these studies might\nnot define the diagram from the state model perspective, therefore providing a\nsuboptimal solution for long-term satisfaction. To address such an issue, we\nleverage the Finite State Machine (FSM) on LLMs, and propose a framework called\nFiSMiness. Our framework allows a single LLM to bootstrap the planning during\nESC, and self-reason the seeker's emotion, support strategy and the final\nresponse upon each conversational turn. Substantial experiments on ESC datasets\nsuggest that FiSMiness outperforms many baselines, including direct inference,\nself-refine, chain of thought, finetuning, and external-assisted methods, even\nthose with many more parameters.", "published": "2025-04-16 07:52:06", "link": "http://arxiv.org/abs/2504.11837v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Could Thinking Multilingually Empower LLM Reasoning?", "abstract": "Previous work indicates that large language models exhibit a significant\n\"English bias\", i.e. they often perform better when tasks are presented in\nEnglish. Interestingly, we have observed that using certain other languages in\nreasoning tasks can yield better performance than English. However, this\nphenomenon remains under-explored. In this paper, we explore the upper bound of\nharnessing multilingualism in reasoning tasks, suggesting that multilingual\nreasoning promises significantly (by nearly 10 Acc@$k$ points) and robustly\n(tolerance for variations in translation quality and language choice) higher\nupper bounds than English-only reasoning. Besides analyzing the reason behind\nthe upper bound and challenges in reaching it, we also find that common answer\nselection methods cannot achieve this upper bound, due to their limitations and\nbiases. These insights could pave the way for future research aimed at fully\nharnessing the potential of multilingual reasoning in LLMs.", "published": "2025-04-16 07:45:10", "link": "http://arxiv.org/abs/2504.11833v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "D\u00e9j\u00e0 Vu: Multilingual LLM Evaluation through the Lens of Machine Translation Evaluation", "abstract": "Generation capabilities and language coverage of multilingual large language\nmodels (mLLMs) are advancing rapidly. However, evaluation practices for\ngenerative abilities of mLLMs are still lacking comprehensiveness, scientific\nrigor, and consistent adoption across research labs, which undermines their\npotential to meaningfully guide mLLM development. We draw parallels with\nmachine translation (MT) evaluation, a field that faced similar challenges and\nhas, over decades, developed transparent reporting standards and reliable\nevaluations for multilingual generative models. Through targeted experiments\nacross key stages of the generative evaluation pipeline, we demonstrate how\nbest practices from MT evaluation can deepen the understanding of quality\ndifferences between models. Additionally, we identify essential components for\nrobust meta-evaluation of mLLMs, ensuring the evaluation methods themselves are\nrigorously assessed. We distill these insights into a checklist of actionable\nrecommendations for mLLM research and development.", "published": "2025-04-16 07:38:19", "link": "http://arxiv.org/abs/2504.11829v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ARWI: Arabic Write and Improve", "abstract": "Although Arabic is spoken by over 400 million people, advanced Arabic writing\nassistance tools remain limited. To address this gap, we present ARWI, a new\nwriting assistant that helps learners improve essay writing in Modern Standard\nArabic. ARWI is the first publicly available Arabic writing assistant to\ninclude a prompt database for different proficiency levels, an Arabic text\neditor, state-of-the-art grammatical error detection and correction, and\nautomated essay scoring aligned with the Common European Framework of Reference\nstandards for language attainment. Moreover, ARWI can be used to gather a\ngrowing auto-annotated corpus, facilitating further research on Arabic grammar\ncorrection and essay scoring, as well as profiling patterns of errors made by\nnative speakers and non-native learners. A preliminary user study shows that\nARWI provides actionable feedback, helping learners identify grammatical gaps,\nassess language proficiency, and guide improvement.", "published": "2025-04-16 07:00:47", "link": "http://arxiv.org/abs/2504.11814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient and Adaptive Simultaneous Speech Translation with Fully Unidirectional Architecture", "abstract": "Simultaneous speech translation (SimulST) produces translations incrementally\nwhile processing partial speech input. Although large language models (LLMs)\nhave showcased strong capabilities in offline translation tasks, applying them\nto SimulST poses notable challenges. Existing LLM-based SimulST approaches\neither incur significant computational overhead due to repeated encoding of\nbidirectional speech encoder, or they depend on a fixed read/write policy,\nlimiting the efficiency and performance. In this work, we introduce Efficient\nand Adaptive Simultaneous Speech Translation (EASiST) with fully unidirectional\narchitecture, including both speech encoder and LLM. EASiST includes a\nmulti-latency data curation strategy to generate semantically aligned SimulST\ntraining samples and redefines SimulST as an interleaved generation task with\nexplicit read/write tokens. To facilitate adaptive inference, we incorporate a\nlightweight policy head that dynamically predicts read/write actions.\nAdditionally, we employ a multi-stage training strategy to align speech-text\nmodalities and optimize both translation and policy behavior. Experiments on\nthe MuST-C En$\\rightarrow$De and En$\\rightarrow$Es datasets demonstrate that\nEASiST offers superior latency-quality trade-offs compared to several strong\nbaselines.", "published": "2025-04-16 06:46:15", "link": "http://arxiv.org/abs/2504.11809v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Selective Attention Federated Learning: Improving Privacy and Efficiency for Clinical Text Classification", "abstract": "Federated Learning (FL) faces major challenges regarding communication\noverhead and model privacy when training large language models (LLMs),\nespecially in healthcare applications. To address these, we introduce Selective\nAttention Federated Learning (SAFL), a novel approach that dynamically\nfine-tunes only those transformer layers identified as attention-critical. By\nemploying attention patterns to determine layer importance, SAFL significantly\nreduces communication bandwidth and enhances differential privacy resilience.\nEvaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and\nMIMIC-III discharge summaries) demonstrate that SAFL achieves competitive\nperformance with centralized models while substantially improving communication\nefficiency and privacy preservation.", "published": "2025-04-16 05:59:29", "link": "http://arxiv.org/abs/2504.11793v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Web Agents with Explicit Rollback Mechanisms", "abstract": "With recent advancements in large language models, web agents have been\ngreatly improved. However, dealing with complex and dynamic web environments\nrequires more advanced planning and search abilities. Previous studies usually\nadopt a greedy one-way search strategy, which may struggle to recover from\nerroneous states. In this work, we enhance web agents with an explicit rollback\nmechanism, enabling the agent to revert back to a previous state in its\nnavigation trajectory. This mechanism gives the model the flexibility to\ndirectly control the search process, leading to an effective and efficient web\nnavigation method. We conduct experiments on two live web navigation benchmarks\nwith zero-shot and fine-tuning settings. The results demonstrate the\neffectiveness of our proposed approach.", "published": "2025-04-16 05:41:20", "link": "http://arxiv.org/abs/2504.11788v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Unsupervised Classification of English Words Based on Phonological Information: Discovery of Germanic and Latinate Clusters", "abstract": "Cross-linguistically, native words and loanwords follow different\nphonological rules. In English, for example, words of Germanic and Latinate\norigin exhibit different stress patterns, and a certain syntactic structure is\nexclusive to Germanic verbs. When seeing them as a cognitive model, however,\nsuch etymology-based generalizations face challenges in terms of learnability,\nsince the historical origins of words are presumably inaccessible information\nfor general language learners. In this study, we present computational evidence\nindicating that the Germanic-Latinate distinction in the English lexicon is\nlearnable from the phonotactic information of individual words. Specifically,\nwe performed an unsupervised clustering on corpus-extracted words, and the\nresulting word clusters largely aligned with the etymological distinction. The\nmodel-discovered clusters also recovered various linguistic generalizations\ndocumented in the previous literature regarding the corresponding etymological\nclasses. Moreover, our findings also uncovered previously unrecognized features\nof the quasi-etymological clusters, offering novel hypotheses for future\nexperimental studies.", "published": "2025-04-16 05:20:08", "link": "http://arxiv.org/abs/2504.11770v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Climbing the Ladder of Reasoning: What LLMs Can-and Still Can't-Solve after SFT?", "abstract": "Recent supervised fine-tuning (SFT) approaches have significantly improved\nlanguage models' performance on mathematical reasoning tasks, even when models\nare trained at a small scale. However, the specific capabilities enhanced\nthrough such fine-tuning remain poorly understood. In this paper, we conduct a\ndetailed analysis of model performance on the AIME24 dataset to understand how\nreasoning capabilities evolve. We discover a ladder-like structure in problem\ndifficulty, categorize questions into four tiers (Easy, Medium, Hard, and\nExtremely Hard (Exh)), and identify the specific requirements for advancing\nbetween tiers. We find that progression from Easy to Medium tier requires\nadopting an R1 reasoning style with minimal SFT (500-1K instances), while\nHard-level questions suffer from frequent model's errors at each step of the\nreasoning chain, with accuracy plateauing at around 65% despite logarithmic\nscaling. Exh-level questions present a fundamentally different challenge; they\nrequire unconventional problem-solving skills that current models uniformly\nstruggle with. Additional findings reveal that carefully curated small-scale\ndatasets offer limited advantage-scaling dataset size proves far more\neffective. Our analysis provides a clearer roadmap for advancing language model\ncapabilities in mathematical reasoning.", "published": "2025-04-16 03:39:38", "link": "http://arxiv.org/abs/2504.11741v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "The Devil is in the Prompts: Retrieval-Augmented Prompt Optimization for Text-to-Video Generation", "abstract": "The evolution of Text-to-video (T2V) generative models, trained on\nlarge-scale datasets, has been marked by significant progress. However, the\nsensitivity of T2V generative models to input prompts highlights the critical\nrole of prompt design in influencing generative outcomes. Prior research has\npredominantly relied on Large Language Models (LLMs) to align user-provided\nprompts with the distribution of training prompts, albeit without tailored\nguidance encompassing prompt vocabulary and sentence structure nuances. To this\nend, we introduce \\textbf{RAPO}, a novel \\textbf{R}etrieval-\\textbf{A}ugmented\n\\textbf{P}rompt \\textbf{O}ptimization framework. In order to address potential\ninaccuracies and ambiguous details generated by LLM-generated prompts. RAPO\nrefines the naive prompts through dual optimization branches, selecting the\nsuperior prompt for T2V generation. The first branch augments user prompts with\ndiverse modifiers extracted from a learned relational graph, refining them to\nalign with the format of training prompts via a fine-tuned LLM. Conversely, the\nsecond branch rewrites the naive prompt using a pre-trained LLM following a\nwell-defined instruction set. Extensive experiments demonstrate that RAPO can\neffectively enhance both the static and dynamic dimensions of generated videos,\ndemonstrating the significance of prompt optimization for user-provided\nprompts. Project website:\n\\href{https://whynothaha.github.io/Prompt_optimizer/RAPO.html}{GitHub}.", "published": "2025-04-16 03:33:25", "link": "http://arxiv.org/abs/2504.11739v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Higher-Order Binding of Language Model Virtual Personas: a Study on Approximating Political Partisan Misperceptions", "abstract": "Large language models (LLMs) are increasingly capable of simulating human\nbehavior, offering cost-effective ways to estimate user responses during the\nearly phases of survey design. While previous studies have examined whether\nmodels can reflect individual opinions or attitudes, we argue that a\n\\emph{higher-order} binding of virtual personas requires successfully\napproximating not only the opinions of a user as an identified member of a\ngroup, but also the nuanced ways in which that user perceives and evaluates\nthose outside the group. In particular, faithfully simulating how humans\nperceive different social groups is critical for applying LLMs to various\npolitical science studies, including timely topics on polarization dynamics,\ninter-group conflict, and democratic backsliding. To this end, we propose a\nnovel methodology for constructing virtual personas with synthetic user\n``backstories\" generated as extended, multi-turn interview transcripts. Our\ngenerated backstories are longer, rich in detail, and consistent in\nauthentically describing a singular individual, compared to previous methods.\nWe show that virtual personas conditioned on our backstories closely replicate\nhuman response distributions (up to an 87\\% improvement as measured by\nWasserstein Distance) and produce effect sizes that closely match those\nobserved in the original studies. Altogether, our work extends the\napplicability of LLMs beyond estimating individual self-opinions, enabling\ntheir use in a broader range of human studies.", "published": "2025-04-16 00:10:34", "link": "http://arxiv.org/abs/2504.11673v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adapting a World Model for Trajectory Following in a 3D Game", "abstract": "Imitation learning is a powerful tool for training agents by leveraging\nexpert knowledge, and being able to replicate a given trajectory is an integral\npart of it. In complex environments, like modern 3D video games, distribution\nshift and stochasticity necessitate robust approaches beyond simple action\nreplay. In this study, we apply Inverse Dynamics Models (IDM) with different\nencoders and policy heads to trajectory following in a modern 3D video game --\nBleeding Edge. Additionally, we investigate several future alignment strategies\nthat address the distribution shift caused by the aleatoric uncertainty and\nimperfections of the agent. We measure both the trajectory deviation distance\nand the first significant deviation point between the reference and the agent's\ntrajectory and show that the optimal configuration depends on the chosen\nsetting. Our results show that in a diverse data setting, a GPT-style policy\nhead with an encoder trained from scratch performs the best, DINOv2 encoder\nwith the GPT-style policy head gives the best results in the low data regime,\nand both GPT-style and MLP-style policy heads had comparable results when\npre-trained on a diverse setting and fine-tuned for a specific behaviour\nsetting.", "published": "2025-04-16 17:59:54", "link": "http://arxiv.org/abs/2504.12299v1", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SHeaP: Self-Supervised Head Geometry Predictor Learned via 2D Gaussians", "abstract": "Accurate, real-time 3D reconstruction of human heads from monocular images\nand videos underlies numerous visual applications. As 3D ground truth data is\nhard to come by at scale, previous methods have sought to learn from abundant\n2D videos in a self-supervised manner. Typically, this involves the use of\ndifferentiable mesh rendering, which is effective but faces limitations. To\nimprove on this, we propose SHeaP (Self-supervised Head Geometry Predictor\nLearned via 2D Gaussians). Given a source image, we predict a 3DMM mesh and a\nset of Gaussians that are rigged to this mesh. We then reanimate this rigged\nhead avatar to match a target frame, and backpropagate photometric losses to\nboth the 3DMM and Gaussian prediction networks. We find that using Gaussians\nfor rendering substantially improves the effectiveness of this self-supervised\napproach. Training solely on 2D data, our method surpasses existing\nself-supervised approaches in geometric evaluations on the NoW benchmark for\nneutral faces and a new benchmark for non-neutral expressions. Our method also\nproduces highly expressive meshes, outperforming state-of-the-art in emotion\nclassification.", "published": "2025-04-16 17:55:02", "link": "http://arxiv.org/abs/2504.12292v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "How Do I Do That? Synthesizing 3D Hand Motion and Contacts for Everyday Interactions", "abstract": "We tackle the novel problem of predicting 3D hand motion and contact maps (or\nInteraction Trajectories) given a single RGB view, action text, and a 3D\ncontact point on the object as input. Our approach consists of (1) Interaction\nCodebook: a VQVAE model to learn a latent codebook of hand poses and contact\npoints, effectively tokenizing interaction trajectories, (2) Interaction\nPredictor: a transformer-decoder module to predict the interaction trajectory\nfrom test time inputs by using an indexer module to retrieve a latent\naffordance from the learned codebook. To train our model, we develop a data\nengine that extracts 3D hand poses and contact trajectories from the diverse\nHoloAssist dataset. We evaluate our model on a benchmark that is 2.5-10X larger\nthan existing works, in terms of diversity of objects and interactions\nobserved, and test for generalization of the model across object categories,\naction categories, tasks, and scenes. Experimental results show the\neffectiveness of our approach over transformer & diffusion baselines across all\nsettings.", "published": "2025-04-16 17:48:12", "link": "http://arxiv.org/abs/2504.12284v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "HLS-Eval: A Benchmark and Framework for Evaluating LLMs on High-Level Synthesis Design Tasks", "abstract": "The rapid scaling of large language model (LLM) training and inference has\ndriven their adoption in semiconductor design across academia and industry.\nWhile most prior work evaluates LLMs on hardware description language (HDL)\ntasks, particularly Verilog, designers are increasingly using high-level\nsynthesis (HLS) to build domain-specific accelerators and complex hardware\nsystems. However, benchmarks and tooling to comprehensively evaluate LLMs for\nHLS design tasks remain scarce.\n  To address this, we introduce HLS-Eval, the first complete benchmark and\nevaluation framework for LLM-driven HLS design. HLS-Eval targets two core\ntasks: (1) generating HLS code from natural language descriptions, and (2)\nperforming HLS-specific code edits to optimize performance and hardware\nefficiency. The benchmark includes 94 unique designs drawn from standard HLS\nbenchmarks and novel sources. Each case is prepared via a semi-automated flow\nthat produces a natural language description and a paired testbench for\nC-simulation and synthesis validation, ensuring each task is \"LLM-ready.\"\n  Beyond the benchmark, HLS-Eval offers a modular Python framework for\nautomated, parallel evaluation of both local and hosted LLMs. It includes a\nparallel evaluation engine, direct HLS tool integration, and abstractions for\nto support different LLM interaction paradigms, enabling rapid prototyping of\nnew benchmarks, tasks, and LLM methods.\n  We demonstrate HLS-Eval through baseline evaluations of open-source LLMs on\nVitis HLS, measuring outputs across four key metrics - parseability,\ncompilability, runnability, and synthesizability - reflecting the iterative HLS\ndesign cycle. We also report pass@k metrics, establishing clear baselines and\nreusable infrastructure for the broader LLM-for-hardware community.\n  All benchmarks, framework code, and results are open-sourced at\nhttps://github.com/stefanpie/hls-eval.", "published": "2025-04-16 17:30:36", "link": "http://arxiv.org/abs/2504.12268v1", "categories": ["cs.AR", "cs.AI"], "primary_category": "cs.AR"}
{"title": "SCENT: Robust Spatiotemporal Learning for Continuous Scientific Data via Scalable Conditioned Neural Fields", "abstract": "Spatiotemporal learning is challenging due to the intricate interplay between\nspatial and temporal dependencies, the high dimensionality of the data, and\nscalability constraints. These challenges are further amplified in scientific\ndomains, where data is often irregularly distributed (e.g., missing values from\nsensor failures) and high-volume (e.g., high-fidelity simulations), posing\nadditional computational and modeling difficulties. In this paper, we present\nSCENT, a novel framework for scalable and continuity-informed spatiotemporal\nrepresentation learning. SCENT unifies interpolation, reconstruction, and\nforecasting within a single architecture. Built on a transformer-based\nencoder-processor-decoder backbone, SCENT introduces learnable queries to\nenhance generalization and a query-wise cross-attention mechanism to\neffectively capture multi-scale dependencies. To ensure scalability in both\ndata size and model complexity, we incorporate a sparse attention mechanism,\nenabling flexible output representations and efficient evaluation at arbitrary\nresolutions. We validate SCENT through extensive simulations and real-world\nexperiments, demonstrating state-of-the-art performance across multiple\nchallenging tasks while achieving superior scalability.", "published": "2025-04-16 17:17:31", "link": "http://arxiv.org/abs/2504.12262v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "FLIP Reasoning Challenge", "abstract": "Over the past years, advances in artificial intelligence (AI) have\ndemonstrated how AI can solve many perception and generation tasks, such as\nimage classification and text writing, yet reasoning remains a challenge. This\npaper introduces the FLIP dataset, a benchmark for evaluating AI reasoning\ncapabilities based on human verification tasks on the Idena blockchain. FLIP\nchallenges present users with two orderings of 4 images, requiring them to\nidentify the logically coherent one. By emphasizing sequential reasoning,\nvisual storytelling, and common sense, FLIP provides a unique testbed for\nmultimodal AI systems. Our experiments evaluate state-of-the-art models,\nleveraging both vision-language models (VLMs) and large language models (LLMs).\nResults reveal that even the best open-sourced and closed-sourced models\nachieve maximum accuracies of 75.5% and 77.9%, respectively, in zero-shot\nsettings, compared to human performance of 95.3%. Captioning models aid\nreasoning models by providing text descriptions of images, yielding better\nresults than when using the raw images directly, 69.6% vs. 75.2% for Gemini 1.5\nPro. Combining the predictions from 15 models in an ensemble increases the\naccuracy to 85.2%. These findings highlight the limitations of existing\nreasoning models and the need for robust multimodal benchmarks like FLIP. The\nfull codebase and dataset will be available at\nhttps://github.com/aplesner/FLIP-Reasoning-Challenge.", "published": "2025-04-16 17:07:16", "link": "http://arxiv.org/abs/2504.12256v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing", "abstract": "Reliable tumor segmentation in thoracic computed tomography (CT) remains\nchallenging due to boundary ambiguity, class imbalance, and anatomical\nvariability. We propose an uncertainty-guided, coarse-to-fine segmentation\nframework that combines full-volume tumor localization with refined\nregion-of-interest (ROI) segmentation, enhanced by anatomically aware\npost-processing. The first-stage model generates a coarse prediction, followed\nby anatomically informed filtering based on lung overlap, proximity to lung\nsurfaces, and component size. The resulting ROIs are segmented by a\nsecond-stage model trained with uncertainty-aware loss functions to improve\naccuracy and boundary calibration in ambiguous regions. Experiments on private\nand public datasets demonstrate improvements in Dice and Hausdorff scores, with\nfewer false positives and enhanced spatial interpretability. These results\nhighlight the value of combining uncertainty modeling and anatomical priors in\ncascaded segmentation pipelines for robust and clinically meaningful tumor\ndelineation. On the Orlando dataset, our framework improved Swin UNETR Dice\nfrom 0.4690 to 0.6447. Reduction in spurious components was strongly correlated\nwith segmentation gains, underscoring the value of anatomically informed\npost-processing.", "published": "2025-04-16 16:08:38", "link": "http://arxiv.org/abs/2504.12215v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Communication Optimization for Decentralized Learning atop Bandwidth-limited Edge Networks", "abstract": "Decentralized federated learning (DFL) is a promising machine learning\nparadigm for bringing artificial intelligence (AI) capabilities to the network\nedge. Running DFL on top of edge networks, however, faces severe performance\nchallenges due to the extensive parameter exchanges between agents. Most\nexisting solutions for these challenges were based on simplistic communication\nmodels, which cannot capture the case of learning over a multi-hop\nbandwidth-limited network. In this work, we address this problem by jointly\ndesigning the communication scheme for the overlay network formed by the agents\nand the mixing matrix that controls the communication demands between the\nagents. By carefully analyzing the properties of our problem, we cast each\ndesign problem into a tractable optimization and develop an efficient algorithm\nwith guaranteed performance. Our evaluations based on real topology and data\nshow that the proposed algorithm can reduce the total training time by over\n$80\\%$ compared to the baseline without sacrificing accuracy, while\nsignificantly improving the computational efficiency over the state of the art.", "published": "2025-04-16 15:56:57", "link": "http://arxiv.org/abs/2504.12210v1", "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.LG"], "primary_category": "cs.NI"}
{"title": "From Requirements to Architecture: Semi-Automatically Generating Software Architectures", "abstract": "To support junior and senior architects, I propose developing a new\narchitecture creation method that leverages LLMs' evolving capabilities to\nsupport the architect. This method involves the architect's close collaboration\nwith LLM-fueled tooling over the whole process. The architect is guided through\nDomain Model creation, Use Case specification, architectural decisions, and\narchitecture evaluation. While the architect can take complete control of the\nprocess and the results, and use the tooling as a building set, they can follow\nthe intended process for maximum tooling support. The preliminary results\nsuggest the feasibility of this process and indicate major time savings for the\narchitect.", "published": "2025-04-16 15:46:56", "link": "http://arxiv.org/abs/2504.12192v1", "categories": ["cs.SE", "cs.AI", "D.2.2"], "primary_category": "cs.SE"}
{"title": "Towards Explainable Fusion and Balanced Learning in Multimodal Sentiment Analysis", "abstract": "Multimodal Sentiment Analysis (MSA) faces two critical challenges: the lack\nof interpretability in the decision logic of multimodal fusion and modality\nimbalance caused by disparities in inter-modal information density. To address\nthese issues, we propose KAN-MCP, a novel framework that integrates the\ninterpretability of Kolmogorov-Arnold Networks (KAN) with the robustness of the\nMultimodal Clean Pareto (MCPareto) framework. First, KAN leverages its\nunivariate function decomposition to achieve transparent analysis of\ncross-modal interactions. This structural design allows direct inspection of\nfeature transformations without relying on external interpretation tools,\nthereby ensuring both high expressiveness and interpretability. Second, the\nproposed MCPareto enhances robustness by addressing modality imbalance and\nnoise interference. Specifically, we introduce the Dimensionality Reduction and\nDenoising Modal Information Bottleneck (DRD-MIB) method, which jointly denoises\nand reduces feature dimensionality. This approach provides KAN with\ndiscriminative low-dimensional inputs to reduce the modeling complexity of KAN\nwhile preserving critical sentiment-related information. Furthermore, MCPareto\ndynamically balances gradient contributions across modalities using the\npurified features output by DRD-MIB, ensuring lossless transmission of\nauxiliary signals and effectively alleviating modality imbalance. This synergy\nof interpretability and robustness not only achieves superior performance on\nbenchmark datasets such as CMU-MOSI, CMU-MOSEI, and CH-SIMS v2 but also offers\nan intuitive visualization interface through KAN's interpretable architecture.", "published": "2025-04-16 15:00:06", "link": "http://arxiv.org/abs/2504.12151v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ARCeR: an Agentic RAG for the Automated Definition of Cyber Ranges", "abstract": "The growing and evolving landscape of cybersecurity threats necessitates the\ndevelopment of supporting tools and platforms that allow for the creation of\nrealistic IT environments operating within virtual, controlled settings as\nCyber Ranges (CRs). CRs can be exploited for analyzing vulnerabilities and\nexperimenting with the effectiveness of devised countermeasures, as well as\nserving as training environments for building cyber security skills and\nabilities for IT operators. This paper proposes ARCeR as an innovative solution\nfor the automatic generation and deployment of CRs, starting from user-provided\ndescriptions in a natural language. ARCeR relies on the Agentic RAG paradigm,\nwhich allows it to fully exploit state-of-art AI technologies. Experimental\nresults show that ARCeR is able to successfully process prompts even in cases\nthat LLMs or basic RAG systems are not able to cope with. Furthermore, ARCeR is\nable to target any CR framework provided that specific knowledge is made\navailable to it.", "published": "2025-04-16 14:53:28", "link": "http://arxiv.org/abs/2504.12143v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Towards LLM Agents for Earth Observation", "abstract": "Earth Observation (EO) provides critical planetary data for environmental\nmonitoring, disaster management, climate science, and other scientific domains.\nHere we ask: Are AI systems ready for reliable Earth Observation? We introduce\n\\datasetnamenospace, a benchmark of 140 yes/no questions from NASA Earth\nObservatory articles across 13 topics and 17 satellite sensors. Using Google\nEarth Engine API as a tool, LLM agents can only achieve an accuracy of 33%\nbecause the code fails to run over 58% of the time. We improve the failure rate\nfor open models by fine-tuning synthetic data, allowing much smaller models\n(Llama-3.1-8B) to achieve comparable accuracy to much larger ones (e.g.,\nDeepSeek-R1). Taken together, our findings identify significant challenges to\nbe solved before AI agents can automate earth observation, and suggest paths\nforward. The project page is available at\nhttps://iandrover.github.io/UnivEarth.", "published": "2025-04-16 14:19:25", "link": "http://arxiv.org/abs/2504.12110v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Reasoning-Based AI for Startup Evaluation (R.A.I.S.E.): A Memory-Augmented, Multi-Step Decision Framework", "abstract": "We present a novel framework that bridges the gap between the\ninterpretability of decision trees and the advanced reasoning capabilities of\nlarge language models (LLMs) to predict startup success. Our approach leverages\nchain-of-thought prompting to generate detailed reasoning logs, which are\nsubsequently distilled into structured, human-understandable logical rules. The\npipeline integrates multiple enhancements - efficient data ingestion, a\ntwo-step refinement process, ensemble candidate sampling, simulated\nreinforcement learning scoring, and persistent memory - to ensure both stable\ndecision-making and transparent output. Experimental evaluations on curated\nstartup datasets demonstrate that our combined pipeline improves precision by\n54% from 0.225 to 0.346 and accuracy by 50% from 0.46 to 0.70 compared to a\nstandalone OpenAI o3 model. Notably, our model achieves over 2x the precision\nof a random classifier (16%). By combining state-of-the-art AI reasoning with\nexplicit rule-based explanations, our method not only augments traditional\ndecision-making processes but also facilitates expert intervention and\ncontinuous policy refinement. This work lays the foundation for the\nimplementation of interpretable LLM-powered decision frameworks in high-stakes\ninvestment environments and other domains that require transparent and\ndata-driven insights.", "published": "2025-04-16 13:53:42", "link": "http://arxiv.org/abs/2504.12090v1", "categories": ["cs.AI", "I.2.7"], "primary_category": "cs.AI"}
{"title": "AttentionDrop: A Novel Regularization Method for Transformer Models", "abstract": "Transformer-based architectures achieve state-of-the-art performance across a\nwide range of tasks in natural language processing, computer vision, and\nspeech. However, their immense capacity often leads to overfitting, especially\nwhen training data is limited or noisy. We propose AttentionDrop, a unified\nfamily of stochastic regularization techniques that operate directly on the\nself-attention distributions. We introduces three variants: 1. Hard Attention\nMasking: randomly zeroes out top-k attention logits per query to encourage\ndiverse context utilization. 2. Blurred Attention Smoothing: applies a dynamic\nGaussian convolution over attention logits to diffuse overly peaked\ndistributions. 3. Consistency-Regularized AttentionDrop: enforces output\nstability under multiple independent AttentionDrop perturbations via a KL-based\nconsistency loss.", "published": "2025-04-16 13:51:16", "link": "http://arxiv.org/abs/2504.12088v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Optimizing Compound Retrieval Systems", "abstract": "Modern retrieval systems do not rely on a single ranking model to construct\ntheir rankings. Instead, they generally take a cascading approach where a\nsequence of ranking models are applied in multiple re-ranking stages. Thereby,\nthey balance the quality of the top-K ranking with computational costs by\nlimiting the number of documents each model re-ranks. However, the cascading\napproach is not the only way models can interact to form a retrieval system.\n  We propose the concept of compound retrieval systems as a broader class of\nretrieval systems that apply multiple prediction models. This encapsulates\ncascading models but also allows other types of interactions than top-K\nre-ranking. In particular, we enable interactions with large language models\n(LLMs) which can provide relative relevance comparisons. We focus on the\noptimization of compound retrieval system design which uniquely involves\nlearning where to apply the component models and how to aggregate their\npredictions into a final ranking. This work shows how our compound approach can\ncombine the classic BM25 retrieval model with state-of-the-art (pairwise) LLM\nrelevance predictions, while optimizing a given ranking metric and efficiency\ntarget. Our experimental results show optimized compound retrieval systems\nprovide better trade-offs between effectiveness and efficiency than cascading\napproaches, even when applied in a self-supervised manner.\n  With the introduction of compound retrieval systems, we hope to inspire the\ninformation retrieval field to more out-of-the-box thinking on how prediction\nmodels can interact to form rankings.", "published": "2025-04-16 13:18:16", "link": "http://arxiv.org/abs/2504.12063v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "cs.IR"}
{"title": "RadMamba: Efficient Human Activity Recognition through Radar-based Micro-Doppler-Oriented Mamba State-Space Model", "abstract": "Radar-based HAR has emerged as a promising alternative to conventional\nmonitoring approaches, such as wearable devices and camera-based systems, due\nto its unique privacy preservation and robustness advantages. However, existing\nsolutions based on convolutional and recurrent neural networks, although\neffective, are computationally demanding during deployment. This limits their\napplicability in scenarios with constrained resources or those requiring\nmultiple sensors. Advanced architectures, such as ViT and SSM architectures,\noffer improved modeling capabilities and have made efforts toward lightweight\ndesigns. However, their computational complexity remains relatively high. To\nleverage the strengths of transformer architectures while simultaneously\nenhancing accuracy and reducing computational complexity, this paper introduces\nRadMamba, a parameter-efficient, radar micro-Doppler-oriented Mamba SSM\nspecifically tailored for radar-based HAR. Across three diverse datasets,\nRadMamba matches the top-performing previous model's 99.8% classification\naccuracy on Dataset DIAT with only 1/400 of its parameters and equals the\nleading models' 92.0% accuracy on Dataset CI4R with merely 1/10 of their\nparameters. In scenarios with continuous sequences of actions evaluated on\nDataset UoG2020, RadMamba surpasses other models with significantly higher\nparameter counts by at least 3%, achieving this with only 6.7k parameters. Our\ncode is available at: https://github.com/lab-emi/AIRHAR.", "published": "2025-04-16 12:54:11", "link": "http://arxiv.org/abs/2504.12039v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Proof-Carrying Neuro-Symbolic Code", "abstract": "This invited paper introduces the concept of \"proof-carrying neuro-symbolic\ncode\" and explains its meaning and value, from both the \"neural\" and the\n\"symbolic\" perspectives. The talk outlines the first successes and challenges\nthat this new area of research faces.", "published": "2025-04-16 12:42:18", "link": "http://arxiv.org/abs/2504.12031v1", "categories": ["cs.PL", "cs.AI", "cs.LO", "F.3.1; F.3.2; F.3.3; I.2.0"], "primary_category": "cs.PL"}
{"title": "Purposefully Induced Psychosis (PIP): Embracing Hallucination as Imagination in Large Language Models", "abstract": "Hallucinations in Large Language Models (LLMs) are widely regarded as errors\n- outputs that deviate from factual accuracy. However, in creative or\nexploratory contexts, these \"mistakes\" may represent unexpected avenues for\ninnovation. We introduce Purposefully Induced Psychosis (PIP), a novel approach\nthat amplifies LLM hallucinations for imaginative tasks such as speculative\nfiction, interactive storytelling, and mixed-reality simulations. Drawing on\nHerman Melville's Moby-Dick, where Pip's \"madness\" reveals profound insight, we\nreframe hallucinations as a source of computational imagination rather than a\nflaw. Our method fine-tunes LLMs to encourage speculative, metaphorical, and\nsurreal outputs - hallucinations that are useful when factual accuracy is not\nthe chief objective. Inspired by the consensual illusions of theater and stage\nmagic, PIP situates these creative missteps in contexts where users willingly\nsuspend disbelief, thereby transforming \"errors\" into catalysts for new ways of\nthinking. We discuss potential applications, design principles for ensuring\nuser consent, preliminary observations, and implications for broader AI ethics\nand human-AI collaboration.", "published": "2025-04-16 12:13:02", "link": "http://arxiv.org/abs/2504.12012v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Balancing Graph Embedding Smoothness in Self-Supervised Learning via Information-Theoretic Decomposition", "abstract": "Self-supervised learning (SSL) in graphs has garnered significant attention,\nparticularly in employing Graph Neural Networks (GNNs) with pretext tasks\ninitially designed for other domains, such as contrastive learning and feature\nreconstruction. However, it remains uncertain whether these methods effectively\nreflect essential graph properties, precisely representation similarity with\nits neighbors. We observe that existing methods position opposite ends of a\nspectrum driven by the graph embedding smoothness, with each end corresponding\nto outperformance on specific downstream tasks. Decomposing the SSL objective\ninto three terms via an information-theoretic framework with a neighbor\nrepresentation variable reveals that this polarization stems from an imbalance\namong the terms, which existing methods may not effectively maintain. Further\ninsights suggest that balancing between the extremes can lead to improved\nperformance across a wider range of downstream tasks. A framework, BSG\n(Balancing Smoothness in Graph SSL), introduces novel loss functions designed\nto supplement the representation quality in graph-based SSL by balancing the\nderived three terms: neighbor loss, minimal loss, and divergence loss. We\npresent a theoretical analysis of the effects of these loss functions,\nhighlighting their significance from both the SSL and graph smoothness\nperspectives. Extensive experiments on multiple real-world datasets across node\nclassification and link prediction consistently demonstrate that BSG achieves\nstate-of-the-art performance, outperforming existing methods. Our\nimplementation code is available at https://github.com/steve30572/BSG.", "published": "2025-04-16 12:09:56", "link": "http://arxiv.org/abs/2504.12011v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Generative Recommendation with Continuous-Token Diffusion", "abstract": "In recent years, there has been a significant trend toward using large\nlanguage model (LLM)-based recommender systems (RecSys). Current research\nprimarily focuses on representing complex user-item interactions within a\ndiscrete space to align with the inherent discrete nature of language models.\nHowever, this approach faces limitations due to its discrete nature: (i)\ninformation is often compressed during discretization; (ii) the tokenization\nand generation for the vast number of users and items in real-world scenarios\nare constrained by a limited vocabulary. Embracing continuous data presents a\npromising alternative to enhance expressive capabilities, though this approach\nis still in its early stages. To address this gap, we propose a novel\nframework, DeftRec, which incorporates \\textbf{de}noising di\\textbf{f}fusion\nmodels to enable LLM-based RecSys to seamlessly support continuous\n\\textbf{t}oken as input and target. First, we introduce a robust tokenizer with\na masking operation and an additive K-way architecture to index users and\nitems, capturing their complex collaborative relationships into continuous\ntokens. Crucially, we develop a denoising diffusion model to process user\npreferences within continuous domains by conditioning on reasoning content from\npre-trained large language model. During the denoising process, we reformulate\nthe objective to include negative interactions, building a comprehensive\nunderstanding of user preferences for effective and accurate recommendation\ngeneration. Finally, given a continuous token as output, recommendations can be\neasily generated through score-based retrieval. Extensive experiments\ndemonstrate the effectiveness of the proposed methods, showing that DeftRec\nsurpasses competitive benchmarks, including both traditional and emerging\nLLM-based RecSys.", "published": "2025-04-16 12:01:03", "link": "http://arxiv.org/abs/2504.12007v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "A Computationally Efficient Algorithm for Infinite-Horizon Average-Reward Linear MDPs", "abstract": "We study reinforcement learning in infinite-horizon average-reward settings\nwith linear MDPs. Previous work addresses this problem by approximating the\naverage-reward setting by discounted setting and employing a value\niteration-based algorithm that uses clipping to constrain the span of the value\nfunction for improved statistical efficiency. However, the clipping procedure\nrequires computing the minimum of the value function over the entire state\nspace, which is prohibitive since the state space in linear MDP setting can be\nlarge or even infinite. In this paper, we introduce a value iteration method\nwith efficient clipping operation that only requires computing the minimum of\nvalue functions over the set of states visited by the algorithm. Our algorithm\nenjoys the same regret bound as the previous work while being computationally\nefficient, with computational complexity that is independent of the size of the\nstate space.", "published": "2025-04-16 11:47:41", "link": "http://arxiv.org/abs/2504.11997v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Leveraging Machine Learning Models to Predict the Outcome of Digital Medical Triage Interviews", "abstract": "Many existing digital triage systems are questionnaire-based, guiding\npatients to appropriate care levels based on information (e.g., symptoms,\nmedical history, and urgency) provided by the patients answering\nquestionnaires. Such a system often uses a deterministic model with predefined\nrules to determine care levels. It faces challenges with incomplete triage\ninterviews since it can only assist patients who finish the process. In this\nstudy, we explore the use of machine learning (ML) to predict outcomes of\nunfinished interviews, aiming to enhance patient care and service quality.\nPredicting triage outcomes from incomplete data is crucial for patient safety\nand healthcare efficiency. Our findings show that decision-tree models,\nparticularly LGBMClassifier and CatBoostClassifier, achieve over 80\\% accuracy\nin predicting outcomes from complete interviews while having a linear\ncorrelation between the prediction accuracy and interview completeness degree.\nFor example, LGBMClassifier achieves 88,2\\% prediction accuracy for interviews\nwith 100\\% completeness, 79,6\\% accuracy for interviews with 80\\% completeness,\n58,9\\% accuracy for 60\\% completeness, and 45,7\\% accuracy for 40\\%\ncompleteness. The TabTransformer model demonstrated exceptional accuracy of\nover 80\\% for all degrees of completeness but required extensive training time,\nindicating a need for more powerful computational resources. The study\nhighlights the linear correlation between interview completeness and predictive\npower of the decision-tree models.", "published": "2025-04-16 11:17:23", "link": "http://arxiv.org/abs/2504.11977v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions", "abstract": "Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure\ninspection, surveillance, and related tasks, yet they also introduce critical\nsecurity challenges. This survey provides a wide-ranging examination of the\nanti-UAV domain, centering on three core objectives-classification, detection,\nand tracking-while detailing emerging methodologies such as diffusion-based\ndata synthesis, multi-modal fusion, vision-language modeling, self-supervised\nlearning, and reinforcement learning. We systematically evaluate\nstate-of-the-art solutions across both single-modality and multi-sensor\npipelines (spanning RGB, infrared, audio, radar, and RF) and discuss\nlarge-scale as well as adversarially oriented benchmarks. Our analysis reveals\npersistent gaps in real-time performance, stealth detection, and swarm-based\nscenarios, underscoring pressing needs for robust, adaptive anti-UAV systems.\nBy highlighting open research directions, we aim to foster innovation and guide\nthe development of next-generation defense strategies in an era marked by the\nextensive use of UAVs.", "published": "2025-04-16 10:58:33", "link": "http://arxiv.org/abs/2504.11967v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "VIPO: Value Function Inconsistency Penalized Offline Reinforcement Learning", "abstract": "Offline reinforcement learning (RL) learns effective policies from\npre-collected datasets, offering a practical solution for applications where\nonline interactions are risky or costly. Model-based approaches are\nparticularly advantageous for offline RL, owing to their data efficiency and\ngeneralizability. However, due to inherent model errors, model-based methods\noften artificially introduce conservatism guided by heuristic uncertainty\nestimation, which can be unreliable. In this paper, we introduce VIPO, a novel\nmodel-based offline RL algorithm that incorporates self-supervised feedback\nfrom value estimation to enhance model training. Specifically, the model is\nlearned by additionally minimizing the inconsistency between the value learned\ndirectly from the offline data and the one estimated from the model. We perform\ncomprehensive evaluations from multiple perspectives to show that VIPO can\nlearn a highly accurate model efficiently and consistently outperform existing\nmethods. It offers a general framework that can be readily integrated into\nexisting model-based offline RL algorithms to systematically enhance model\naccuracy. As a result, VIPO achieves state-of-the-art performance on almost all\ntasks in both D4RL and NeoRL benchmarks.", "published": "2025-04-16 10:23:44", "link": "http://arxiv.org/abs/2504.11944v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Rethinking the Generation of High-Quality CoT Data from the Perspective of LLM-Adaptive Question Difficulty Grading", "abstract": "Recently, DeepSeek-R1 (671B) (DeepSeek-AIet al., 2025) has demonstrated its\nexcellent reasoning ability in complex tasks and has publiclyshared its\nmethodology. This provides potentially high-quality chain-of-thought (CoT) data\nfor stimulating the reasoning abilities of small-sized large language models\n(LLMs). To generate high-quality CoT data for different LLMs, we seek an\nefficient method for generating high-quality CoT data with LLM-Adaptive\nquestiondifficulty levels. First, we grade the difficulty of the questions\naccording to the reasoning ability of the LLMs themselves and construct a\nLLM-Adaptive question database. Second, we sample the problem database based on\na distribution of difficulty levels of the questions and then use DeepSeek-R1\n(671B) (DeepSeek-AI et al., 2025) to generate the corresponding high-quality\nCoT data with correct answers. Thanks to the construction of CoT data with\nLLM-Adaptive difficulty levels, we have significantly reduced the cost of data\ngeneration and enhanced the efficiency of model supervised fine-tuning (SFT).\nFinally, we have validated the effectiveness and generalizability of the\nproposed method in the fields of complex mathematical competitions and code\ngeneration tasks. Notably, with only 2k high-quality mathematical CoT data, our\nZMath-32B surpasses DeepSeek-Distill-32B in math reasoning task. Similarly,\nwith only 2k high-quality code CoT data, our ZCode-32B surpasses\nDeepSeek-Distill-32B in code reasoning tasks.", "published": "2025-04-16 09:55:34", "link": "http://arxiv.org/abs/2504.11919v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Causality-enhanced Decision-Making for Autonomous Mobile Robots in Dynamic Environments", "abstract": "The growing integration of robots in shared environments -- such as\nwarehouses, shopping centres, and hospitals -- demands a deep understanding of\nthe underlying dynamics and human behaviours, including how, when, and where\nindividuals engage in various activities and interactions. This knowledge goes\nbeyond simple correlation studies and requires a more comprehensive causal\nanalysis. By leveraging causal inference to model cause-and-effect\nrelationships, we can better anticipate critical environmental factors and\nenable autonomous robots to plan and execute tasks more effectively. To this\nend, we propose a novel causality-based decision-making framework that reasons\nover a learned causal model to predict battery usage and human obstructions,\nunderstanding how these factors could influence robot task execution. Such\nreasoning framework assists the robot in deciding when and how to complete a\ngiven task. To achieve this, we developed also PeopleFlow, a new Gazebo-based\nsimulator designed to model context-sensitive human-robot spatial interactions\nin shared workspaces. PeopleFlow features realistic human and robot\ntrajectories influenced by contextual factors such as time, environment layout,\nand robot state, and can simulate a large number of agents. While the simulator\nis general-purpose, in this paper we focus on a warehouse-like environment as a\ncase study, where we conduct an extensive evaluation benchmarking our causal\napproach against a non-causal baseline. Our findings demonstrate the efficacy\nof the proposed solutions, highlighting how causal reasoning enables autonomous\nrobots to operate more efficiently and safely in dynamic environments shared\nwith humans.", "published": "2025-04-16 09:26:04", "link": "http://arxiv.org/abs/2504.11901v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Learning Physics-Informed Color-Aware Transforms for Low-Light Image Enhancement", "abstract": "Image decomposition offers deep insights into the imaging factors of visual\ndata and significantly enhances various advanced computer vision tasks. In this\nwork, we introduce a novel approach to low-light image enhancement based on\ndecomposed physics-informed priors. Existing methods that directly map\nlow-light to normal-light images in the sRGB color space suffer from\ninconsistent color predictions and high sensitivity to spectral power\ndistribution (SPD) variations, resulting in unstable performance under diverse\nlighting conditions. To address these challenges, we introduce a\nPhysics-informed Color-aware Transform (PiCat), a learning-based framework that\nconverts low-light images from the sRGB color space into deep\nillumination-invariant descriptors via our proposed Color-aware Transform\n(CAT). This transformation enables robust handling of complex lighting and SPD\nvariations. Complementing this, we propose the Content-Noise Decomposition\nNetwork (CNDN), which refines the descriptor distributions to better align with\nwell-lit conditions by mitigating noise and other distortions, thereby\neffectively restoring content representations to low-light images. The CAT and\nthe CNDN collectively act as a physical prior, guiding the transformation\nprocess from low-light to normal-light domains. Our proposed PiCat framework\ndemonstrates superior performance compared to state-of-the-art methods across\nfive benchmark datasets.", "published": "2025-04-16 09:23:38", "link": "http://arxiv.org/abs/2504.11896v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Seeking and leveraging alternative variable dependency concepts in gray-box-elusive bimodal land-use allocation problems", "abstract": "Solving land-use allocation problems can help us to deal with some of the\nmost urgent global environmental issues. Since these problems are NP-hard,\neffective optimizers are needed to handle them. The knowledge about variable\ndependencies allows for proposing such tools. However, in this work, we\nconsider a real-world multi-objective problem for which standard variable\ndependency discovery techniques are inapplicable. Therefore, using\nlinkage-based variation operators is unreachable. To address this issue, we\npropose a definition of problem-dedicated variable dependency. On this base, we\npropose obtaining masks of dependent variables. Using them, we construct three\nnovel crossover operators. The results concerning real-world test cases show\nthat introducing our propositions into two well-known optimizers (NSGA-II,\nMOEA/D) dedicated to multi-objective optimization significantly improves their\neffectiveness.", "published": "2025-04-16 09:06:55", "link": "http://arxiv.org/abs/2504.11882v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Moving between high-quality optima using multi-satisfiability characteristics in hard-to-solve Max3Sat instances", "abstract": "Gray-box optimization proposes effective and efficient optimizers of general\nuse. To this end, it leverages information about variable dependencies and the\nsubfunction-based problem representation. These approaches were already shown\neffective by enabling \\textit{tunnelling} between local optima even if these\nmoves require the modification of many dependent variables. Tunnelling is\nuseful in solving the maximum satisfiability problem (MaxSat), which can be\nreformulated to Max3Sat. Since many real-world problems can be brought to\nsolving the MaxSat/Max3Sat instances, it is important to solve them effectively\nand efficiently. Therefore, we focus on Max3Sat instances for which tunnelling\nfails to introduce improving moves between locally optimal high-quality\nsolutions and the region of globally optimal solutions. We analyze the features\nof such instances on the ground of phase transitions. Based on these\nobservations, we propose manipulating clause-satisfiability characteristics\nthat allow connecting high-quality solutions distant in the solution space. We\nutilize multi-satisfiability characteristics in the optimizer built from\ntypical gray-box mechanisms. The experimental study shows that the proposed\noptimizer can solve those Max3Sat instances that are out of the grasp of\nstate-of-the-art gray-box optimizers. At the same time, it remains effective\nfor instances that have already been successfully solved by gray-box.", "published": "2025-04-16 08:38:08", "link": "http://arxiv.org/abs/2504.11864v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "EngramNCA: a Neural Cellular Automaton Model of Memory Transfer", "abstract": "This study introduces EngramNCA, a neural cellular automaton (NCA) that\nintegrates both publicly visible states and private, cell-internal memory\nchannels, drawing inspiration from emerging biological evidence suggesting that\nmemory storage extends beyond synaptic modifications to include intracellular\nmechanisms. The proposed model comprises two components: GeneCA, an NCA trained\nto develop distinct morphologies from seed cells containing immutable \"gene\"\nencodings, and GenePropCA, an auxiliary NCA that modulates the private\n\"genetic\" memory of cells without altering their visible states. This\narchitecture enables the encoding and propagation of complex morphologies\nthrough the interaction of visible and private channels, facilitating the\ngrowth of diverse structures from a shared \"genetic\" substrate. EngramNCA\nsupports the emergence of hierarchical and coexisting morphologies, offering\ninsights into decentralized memory storage and transfer in artificial systems.\nThese findings have potential implications for the development of adaptive,\nself-organizing systems and may contribute to the broader understanding of\nmemory mechanisms in both biological and synthetic contexts.", "published": "2025-04-16 08:23:09", "link": "http://arxiv.org/abs/2504.11855v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Real-World Depth Recovery via Structure Uncertainty Modeling and Inaccurate GT Depth Fitting", "abstract": "The low-quality structure in raw depth maps is prevalent in real-world RGB-D\ndatasets, which makes real-world depth recovery a critical task in recent\nyears. However, the lack of paired raw-ground truth (raw-GT) data in the real\nworld poses challenges for generalized depth recovery. Existing methods\ninsufficiently consider the diversity of structure misalignment in raw depth\nmaps, which leads to poor generalization in real-world depth recovery. Notably,\nrandom structure misalignments are not limited to raw depth data but also\naffect GT depth in real-world datasets. In the proposed method, we tackle the\ngeneralization problem from both input and output perspectives. For input, we\nenrich the diversity of structure misalignment in raw depth maps by designing a\nnew raw depth generation pipeline, which helps the network avoid overfitting to\na specific condition. Furthermore, a structure uncertainty module is designed\nto explicitly identify the misaligned structure for input raw depth maps to\nbetter generalize in unseen scenarios. Notably the well-trained depth\nfoundation model (DFM) can help the structure uncertainty module estimate the\nstructure uncertainty better. For output, a robust feature alignment module is\ndesigned to precisely align with the accurate structure of RGB images avoiding\nthe interference of inaccurate GT depth. Extensive experiments on multiple\ndatasets demonstrate the proposed method achieves competitive accuracy and\ngeneralization capabilities across various challenging raw depth maps.", "published": "2025-04-16 07:14:01", "link": "http://arxiv.org/abs/2504.11820v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning Strategies in Particle Swarm Optimizer: A Critical Review and Performance Analysis", "abstract": "Nature has long inspired the development of swarm intelligence (SI), a key\nbranch of artificial intelligence that models collective behaviors observed in\nbiological systems for solving complex optimization problems. Particle swarm\noptimization (PSO) is widely adopted among SI algorithms due to its simplicity\nand efficiency. Despite numerous learning strategies proposed to enhance PSO's\nperformance in terms of convergence speed, robustness, and adaptability, no\ncomprehensive and systematic analysis of these strategies exists. We review and\nclassify various learning strategies to address this gap, assessing their\nimpact on optimization performance. Additionally, a comparative experimental\nevaluation is conducted to examine how these strategies influence PSO's search\ndynamics. Finally, we discuss open challenges and future directions,\nemphasizing the need for self-adaptive, intelligent PSO variants capable of\naddressing increasingly complex real-world problems.", "published": "2025-04-16 06:50:02", "link": "http://arxiv.org/abs/2504.11812v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Large Language Models for Drug Overdose Prediction from Longitudinal Medical Records", "abstract": "The ability to predict drug overdose risk from a patient's medical records is\ncrucial for timely intervention and prevention. Traditional machine learning\nmodels have shown promise in analyzing longitudinal medical records for this\ntask. However, recent advancements in large language models (LLMs) offer an\nopportunity to enhance prediction performance by leveraging their ability to\nprocess long textual data and their inherent prior knowledge across diverse\ntasks. In this study, we assess the effectiveness of Open AI's GPT-4o LLM in\npredicting drug overdose events using patients' longitudinal insurance claims\nrecords. We evaluate its performance in both fine-tuned and zero-shot settings,\ncomparing them to strong traditional machine learning methods as baselines. Our\nresults show that LLMs not only outperform traditional models in certain\nsettings but can also predict overdose risk in a zero-shot setting without\ntask-specific training. These findings highlight the potential of LLMs in\nclinical decision support, particularly for drug overdose risk prediction.", "published": "2025-04-16 05:52:22", "link": "http://arxiv.org/abs/2504.11792v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "ACMamba: Fast Unsupervised Anomaly Detection via An Asymmetrical Consensus State Space Model", "abstract": "Unsupervised anomaly detection in hyperspectral images (HSI), aiming to\ndetect unknown targets from backgrounds, is challenging for earth surface\nmonitoring. However, current studies are hindered by steep computational costs\ndue to the high-dimensional property of HSI and dense sampling-based training\nparadigm, constraining their rapid deployment. Our key observation is that,\nduring training, not all samples within the same homogeneous area are\nindispensable, whereas ingenious sampling can provide a powerful substitute for\nreducing costs. Motivated by this, we propose an Asymmetrical Consensus State\nSpace Model (ACMamba) to significantly reduce computational costs without\ncompromising accuracy. Specifically, we design an asymmetrical anomaly\ndetection paradigm that utilizes region-level instances as an efficient\nalternative to dense pixel-level samples. In this paradigm, a low-cost\nMamba-based module is introduced to discover global contextual attributes of\nregions that are essential for HSI reconstruction. Additionally, we develop a\nconsensus learning strategy from the optimization perspective to simultaneously\nfacilitate background reconstruction and anomaly compression, further\nalleviating the negative impact of anomaly reconstruction. Theoretical analysis\nand extensive experiments across eight benchmarks verify the superiority of\nACMamba, demonstrating a faster speed and stronger performance over the\nstate-of-the-art.", "published": "2025-04-16 05:33:42", "link": "http://arxiv.org/abs/2504.11781v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Agile Retrospectives: What went well? What didn't go well? What should we do?", "abstract": "In Agile/Scrum software development, the idea of retrospective meetings\n(retros) is one of the core elements of the project process. In this paper, we\npresent our work in progress focusing on two aspects: analysis of potential\nusage of generative AI for information interaction within retrospective\nmeetings, and visualisation of retros' information to software development\nteams. We also present our prototype tool RetroAI++, focusing on retros-related\nfunctionalities.", "published": "2025-04-16 05:33:35", "link": "http://arxiv.org/abs/2504.11780v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "PCDiff: Proactive Control for Ownership Protection in Diffusion Models with Watermark Compatibility", "abstract": "With the growing demand for protecting the intellectual property (IP) of\ntext-to-image diffusion models, we propose PCDiff -- a proactive access control\nframework that redefines model authorization by regulating generation quality.\nAt its core, PCDIFF integrates a trainable fuser module and hierarchical\nauthentication layers into the decoder architecture, ensuring that only users\nwith valid encrypted credentials can generate high-fidelity images. In the\nabsence of valid keys, the system deliberately degrades output quality,\neffectively preventing unauthorized exploitation.Importantly, while the primary\nmechanism enforces active access control through architectural intervention,\nits decoupled design retains compatibility with existing watermarking\ntechniques. This satisfies the need of model owners to actively control model\nownership while preserving the traceability capabilities provided by\ntraditional watermarking approaches.Extensive experimental evaluations confirm\na strong dependency between credential verification and image quality across\nvarious attack scenarios. Moreover, when combined with typical post-processing\noperations, PCDIFF demonstrates powerful performance alongside conventional\nwatermarking methods. This work shifts the paradigm from passive detection to\nproactive enforcement of authorization, laying the groundwork for IP management\nof diffusion models.", "published": "2025-04-16 05:28:50", "link": "http://arxiv.org/abs/2504.11774v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Shared Disk KV Cache Management for Efficient Multi-Instance Inference in RAG-Powered LLMs", "abstract": "Recent large language models (LLMs) face increasing inference latency as\ninput context length and model size continue to grow. In particular, the\nretrieval-augmented generation (RAG) technique, which enhances LLM responses by\nincorporating external knowledge, exacerbates this issue by significantly\nincreasing the number of input tokens. This expansion in token length leads to\na substantial rise in computational overhead, particularly during the prefill\nstage, resulting in prolonged time-to-first-token (TTFT). To address this\nissue, this paper proposes a method to reduce TTFT by leveraging a disk-based\nkey-value (KV) cache to lessen the computational burden during the prefill\nstage. We also introduce a disk-based shared KV cache management system, called\nShared RAG-DCache, for multi-instance LLM RAG service environments. This\nsystem, together with an optimal system configuration, improves both throughput\nand latency under given resource constraints. Shared RAG-DCache exploits the\nlocality of documents related to user queries in RAG, as well as the queueing\ndelay in LLM inference services. It proactively generates and stores disk KV\ncaches for query-related documents and shares them across multiple LLM\ninstances to enhance inference performance. In experiments on a single host\nequipped with 2 GPUs and 1 CPU, Shared RAG-DCache achieved a 15~71% increase in\nthroughput and up to a 12~65% reduction in latency, depending on the resource\nconfiguration.", "published": "2025-04-16 04:59:18", "link": "http://arxiv.org/abs/2504.11765v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "GrabS: Generative Embodied Agent for 3D Object Segmentation without Scene Supervision", "abstract": "We study the hard problem of 3D object segmentation in complex point clouds\nwithout requiring human labels of 3D scenes for supervision. By relying on the\nsimilarity of pretrained 2D features or external signals such as motion to\ngroup 3D points as objects, existing unsupervised methods are usually limited\nto identifying simple objects like cars or their segmented objects are often\ninferior due to the lack of objectness in pretrained features. In this paper,\nwe propose a new two-stage pipeline called GrabS. The core concept of our\nmethod is to learn generative and discriminative object-centric priors as a\nfoundation from object datasets in the first stage, and then design an embodied\nagent to learn to discover multiple objects by querying against the pretrained\ngenerative priors in the second stage. We extensively evaluate our method on\ntwo real-world datasets and a newly created synthetic dataset, demonstrating\nremarkable segmentation performance, clearly surpassing all existing\nunsupervised methods.", "published": "2025-04-16 04:13:53", "link": "http://arxiv.org/abs/2504.11754v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Characterizing and Optimizing LLM Inference Workloads on CPU-GPU Coupled Architectures", "abstract": "Large language model (LLM)-based inference workloads increasingly dominate\ndata center costs and resource utilization. Therefore, understanding the\ninference workload characteristics on evolving CPU-GPU coupled architectures is\ncrucial for optimization. This paper presents an in-depth analysis of LLM\ninference behavior on loosely-coupled (PCIe A100/H100) and closely-coupled\n(GH200) systems. We analyze performance dynamics using fine-grained\noperator-to-kernel trace analysis, facilitated by our novel profiler SKIP and\nmetrics like Total Kernel Launch and Queuing Time (TKLQT). Results show that\nclosely-coupled (CC) GH200 significantly outperforms loosely-coupled (LC)\nsystems at large batch sizes, achieving 1.9x-2.7x faster prefill latency for\nLlama 3.2-1B. However, our analysis also reveals that GH200 remains CPU-bound\nup to 4x larger batch sizes than LC systems. In this extended CPU-bound region,\nwe identify the performance characteristics of the Grace CPU as a key factor\ncontributing to higher inference latency at low batch sizes on GH200. We\ndemonstrate that TKLQT accurately identifies this CPU/GPU-bound transition\npoint. Based on this analysis, we further show that kernel fusion offers\nsignificant potential to mitigate GH200's low-batch latency bottleneck by\nreducing kernel launch overhead. This detailed kernel-level characterization\nprovides critical insights for optimizing diverse CPU-GPU coupling strategies.\nThis work is an initial effort, and we plan to explore other major AI/DL\nworkloads that demand different degrees of CPU-GPU heterogeneous architectures.", "published": "2025-04-16 04:02:39", "link": "http://arxiv.org/abs/2504.11750v1", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.PF"], "primary_category": "cs.DC"}
{"title": "Saga: Capturing Multi-granularity Semantics from Massive Unlabelled IMU Data for User Perception", "abstract": "Inertial measurement units (IMUs), have been prevalently used in a wide range\nof mobile perception applications such as activity recognition and user\nauthentication, where a large amount of labelled data are normally required to\ntrain a satisfactory model. However, it is difficult to label micro-activities\nin massive IMU data due to the hardness of understanding raw IMU data and the\nlack of ground truth. In this paper, we propose a novel fine-grained user\nperception approach, called Saga, which only needs a small amount of labelled\nIMU data to achieve stunning user perception accuracy. The core idea of Saga is\nto first pre-train a backbone feature extraction model, utilizing the rich\nsemantic information of different levels embedded in the massive unlabelled IMU\ndata. Meanwhile, for a specific downstream user perception application,\nBayesian Optimization is employed to determine the optimal weights for\npre-training tasks involving different semantic levels. We implement Saga on\nfive typical mobile phones and evaluate Saga on three typical tasks on three\nIMU datasets. Results show that when only using about 100 training samples per\nclass, Saga can achieve over 90% accuracy of the full-fledged model trained on\nover ten thousands training samples with no additional system overhead.", "published": "2025-04-16 03:03:42", "link": "http://arxiv.org/abs/2504.11726v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint Matching", "abstract": "We introduce Adjoint Sampling, a highly scalable and efficient algorithm for\nlearning diffusion processes that sample from unnormalized densities, or energy\nfunctions. It is the first on-policy approach that allows significantly more\ngradient updates than the number of energy evaluations and model samples,\nallowing us to scale to much larger problem settings than previously explored\nby similar methods. Our framework is theoretically grounded in stochastic\noptimal control and shares the same theoretical guarantees as Adjoint Matching,\nbeing able to train without the need for corrective measures that push samples\ntowards the target distribution. We show how to incorporate key symmetries, as\nwell as periodic boundary conditions, for modeling molecules in both cartesian\nand torsional coordinates. We demonstrate the effectiveness of our approach\nthrough extensive experiments on classical energy functions, and further scale\nup to neural network-based energy models where we perform amortized conformer\ngeneration across many molecular systems. To encourage further research in\ndeveloping highly scalable sampling methods, we plan to open source these\nchallenging benchmarks, where successful methods can directly impact progress\nin computational chemistry.", "published": "2025-04-16 02:20:06", "link": "http://arxiv.org/abs/2504.11713v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Hitchhiker's Guide to Program Analysis, Part II: Deep Thoughts by LLMs", "abstract": "Static analysis is a cornerstone for software vulnerability detection, yet it\noften struggles with the classic precision-scalability trade-off. In practice,\nsuch tools often produce high false positive rates, particularly in large\ncodebases like the Linux kernel. This imprecision can arise from simplified\nvulnerability modeling and over-approximation of path and data constraints.\nWhile large language models (LLMs) show promise in code understanding, their\nnaive application to program analysis yields unreliable results due to inherent\nreasoning limitations. We introduce BugLens, a post-refinement framework that\nsignificantly improves static analysis precision. BugLens guides an LLM to\nfollow traditional analysis steps by assessing buggy code patterns for security\nimpact and validating the constraints associated with static warnings.\nEvaluated on real-world Linux kernel bugs, BugLens raises precision from 0.10\n(raw) and 0.50 (semi-automated refinement) to 0.72, substantially reducing\nfalse positives and revealing four previously unreported vulnerabilities. Our\nresults suggest that a structured LLM-based workflow can meaningfully enhance\nthe effectiveness of static analysis tools.", "published": "2025-04-16 02:17:06", "link": "http://arxiv.org/abs/2504.11711v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Towards Safe Synthetic Image Generation On the Web: A Multimodal Robust NSFW Defense and Million Scale Dataset", "abstract": "In the past years, we have witnessed the remarkable success of Text-to-Image\n(T2I) models and their widespread use on the web. Extensive research in making\nT2I models produce hyper-realistic images has led to new concerns, such as\ngenerating Not-Safe-For-Work (NSFW) web content and polluting the web society.\nTo help prevent misuse of T2I models and create a safer web environment for\nusers features like NSFW filters and post-hoc security checks are used in these\nmodels. However, recent work unveiled how these methods can easily fail to\nprevent misuse. In particular, adversarial attacks on text and image modalities\ncan easily outplay defensive measures. %Exploiting such leads to the growing\nconcern of preventing adversarial attacks on text and image modalities.\nMoreover, there is currently no robust multimodal NSFW dataset that includes\nboth prompt and image pairs and adversarial examples. This work proposes a\nmillion-scale prompt and image dataset generated using open-source diffusion\nmodels. Second, we develop a multimodal defense to distinguish safe and NSFW\ntext and images, which is robust against adversarial attacks and directly\nalleviates current challenges. Our extensive experiments show that our model\nperforms well against existing SOTA NSFW detection methods in terms of accuracy\nand recall, drastically reducing the Attack Success Rate (ASR) in multimodal\nadversarial attack scenarios. Code:\nhttps://github.com/shahidmuneer/multimodal-nsfw-defense.", "published": "2025-04-16 02:10:42", "link": "http://arxiv.org/abs/2504.11707v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Library of LLM Intrinsics for Retrieval-Augmented Generation", "abstract": "In the developer community for large language models (LLMs), there is not yet\na clean pattern analogous to a software library, to support very large scale\ncollaboration. Even for the commonplace use case of Retrieval-Augmented\nGeneration (RAG), it is not currently possible to write a RAG application\nagainst a well-defined set of APIs that are agreed upon by different LLM\nproviders. Inspired by the idea of compiler intrinsics, we propose some\nelements of such a concept through introducing a library of LLM Intrinsics for\nRAG. An LLM intrinsic is defined as a capability that can be invoked through a\nwell-defined API that is reasonably stable and independent of how the LLM\nintrinsic itself is implemented. The intrinsics in our library are released as\nLoRA adapters on HuggingFace, and through a software interface with clear\nstructured input/output characteristics on top of vLLM as an inference\nplatform, accompanied in both places with documentation and code. This article\ndescribes the intended usage, training details, and evaluations for each\nintrinsic, as well as compositions of multiple intrinsics.", "published": "2025-04-16 02:02:22", "link": "http://arxiv.org/abs/2504.11704v1", "categories": ["cs.AI", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Progent: Programmable Privilege Control for LLM Agents", "abstract": "LLM agents are an emerging form of AI systems where large language models\n(LLMs) serve as the central component, utilizing a diverse set of tools to\ncomplete user-assigned tasks. Despite their great potential, LLM agents pose\nsignificant security risks. When interacting with the external world, they may\nencounter malicious commands from attackers, leading to the execution of\ndangerous actions. A promising way to address this is by enforcing the\nprinciple of least privilege: allowing only essential actions for task\ncompletion while blocking unnecessary ones. However, achieving this is\nchallenging, as it requires covering diverse agent scenarios while preserving\nboth security and utility.\n  We introduce Progent, the first privilege control mechanism for LLM agents.\nAt its core is a domain-specific language for flexibly expressing privilege\ncontrol policies applied during agent execution. These policies provide\nfine-grained constraints over tool calls, deciding when tool calls are\npermissible and specifying fallbacks if they are not. This enables agent\ndevelopers and users to craft suitable policies for their specific use cases\nand enforce them deterministically to guarantee security. Thanks to its modular\ndesign, integrating Progent does not alter agent internals and requires only\nminimal changes to agent implementation, enhancing its practicality and\npotential for widespread adoption. To automate policy writing, we leverage LLMs\nto generate policies based on user queries, which are then updated dynamically\nfor improved security and utility. Our extensive evaluation shows that it\nenables strong security while preserving high utility across three distinct\nscenarios or benchmarks: AgentDojo, ASB, and AgentPoison. Furthermore, we\nperform an in-depth analysis, showcasing the effectiveness of its core\ncomponents and the resilience of its automated policy generation against\nadaptive attacks.", "published": "2025-04-16 01:58:40", "link": "http://arxiv.org/abs/2504.11703v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Can GPT tell us why these images are synthesized? Empowering Multimodal Large Language Models for Forensics", "abstract": "The rapid development of generative AI facilitates content creation and makes\nimage manipulation easier and more difficult to detect. While multimodal Large\nLanguage Models (LLMs) have encoded rich world knowledge, they are not\ninherently tailored for combating AI-generated Content (AIGC) and struggle to\ncomprehend local forgery details. In this work, we investigate the application\nof multimodal LLMs in forgery detection. We propose a framework capable of\nevaluating image authenticity, localizing tampered regions, providing evidence,\nand tracing generation methods based on semantic tampering clues. Our method\ndemonstrates that the potential of LLMs in forgery analysis can be effectively\nunlocked through meticulous prompt engineering and the application of few-shot\nlearning techniques. We conduct qualitative and quantitative experiments and\nshow that GPT4V can achieve an accuracy of 92.1% in Autosplice and 86.3% in\nLaMa, which is competitive with state-of-the-art AIGC detection methods. We\nfurther discuss the limitations of multimodal LLMs in such tasks and propose\npotential improvements.", "published": "2025-04-16 01:02:46", "link": "http://arxiv.org/abs/2504.11686v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Steering Prosocial AI Agents: Computational Basis of LLM's Decision Making in Social Simulation", "abstract": "Large language models (LLMs) increasingly serve as human-like decision-making\nagents in social science and applied settings. These LLM-agents are typically\nassigned human-like characters and placed in real-life contexts. However, how\nthese characters and contexts shape an LLM's behavior remains underexplored.\nThis study proposes and tests methods for probing, quantifying, and modifying\nan LLM's internal representations in a Dictator Game -- a classic behavioral\nexperiment on fairness and prosocial behavior. We extract ``vectors of variable\nvariations'' (e.g., ``male'' to ``female'') from the LLM's internal state.\nManipulating these vectors during the model's inference can substantially alter\nhow those variables relate to the model's decision-making. This approach offers\na principled way to study and regulate how social concepts can be encoded and\nengineered within transformer-based models, with implications for alignment,\ndebiasing, and designing AI agents for social simulations in both academic and\ncommercial applications.", "published": "2025-04-16 00:02:28", "link": "http://arxiv.org/abs/2504.11671v1", "categories": ["cs.AI", "cs.CY", "cs.LG", "econ.GN", "q-fin.EC"], "primary_category": "cs.AI"}
{"title": "The Tenth NTIRE 2025 Image Denoising Challenge Report", "abstract": "This paper presents an overview of the NTIRE 2025 Image Denoising Challenge\n({\\sigma} = 50), highlighting the proposed methodologies and corresponding\nresults. The primary objective is to develop a network architecture capable of\nachieving high-quality denoising performance, quantitatively evaluated using\nPSNR, without constraints on computational complexity or model size. The task\nassumes independent additive white Gaussian noise (AWGN) with a fixed noise\nlevel of 50. A total of 290 participants registered for the challenge, with 20\nteams successfully submitting valid results, providing insights into the\ncurrent state-of-the-art in image denoising.", "published": "2025-04-16 17:35:09", "link": "http://arxiv.org/abs/2504.12276v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Reconstruction: A Physics Based Neural Deferred Shader for Photo-realistic Rendering", "abstract": "Deep learning based rendering has demonstrated major improvements for\nphoto-realistic image synthesis, applicable to various applications including\nvisual effects in movies and photo-realistic scene building in video games.\nHowever, a significant limitation is the difficulty of decomposing the\nillumination and material parameters, which limits such methods to reconstruct\nan input scene, without any possibility to control these parameters. This paper\nintroduces a novel physics based neural deferred shading pipeline to decompose\nthe data-driven rendering process, learn a generalizable shading function to\nproduce photo-realistic results for shading and relighting tasks, we also\nprovide a shadow estimator to efficiently mimic shadowing effect. Our model\nachieves improved performance compared to classical models and a state-of-art\nneural shading model, and enables generalizable photo-realistic shading from\narbitrary illumination input.", "published": "2025-04-16 17:32:50", "link": "http://arxiv.org/abs/2504.12273v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Learning to Complete Anything in Lidar", "abstract": "We propose CAL (Complete Anything in Lidar) for Lidar-based shape-completion\nin-the-wild. This is closely related to Lidar-based semantic/panoptic scene\ncompletion. However, contemporary methods can only complete and recognize\nobjects from a closed vocabulary labeled in existing Lidar datasets. Different\nto that, our zero-shot approach leverages the temporal context from multi-modal\nsensor sequences to mine object shapes and semantic features of observed\nobjects. These are then distilled into a Lidar-only instance-level completion\nand recognition model. Although we only mine partial shape completions, we find\nthat our distilled model learns to infer full object shapes from multiple such\npartial observations across the dataset. We show that our model can be prompted\non standard benchmarks for Semantic and Panoptic Scene Completion, localize\nobjects as (amodal) 3D bounding boxes, and recognize objects beyond fixed class\nvocabularies. Our project page is\nhttps://research.nvidia.com/labs/dvl/projects/complete-anything-lidar", "published": "2025-04-16 17:21:55", "link": "http://arxiv.org/abs/2504.12264v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VGDFR: Diffusion-based Video Generation with Dynamic Latent Frame Rate", "abstract": "Diffusion Transformer(DiT)-based generation models have achieved remarkable\nsuccess in video generation. However, their inherent computational demands pose\nsignificant efficiency challenges. In this paper, we exploit the inherent\ntemporal non-uniformity of real-world videos and observe that videos exhibit\ndynamic information density, with high-motion segments demanding greater detail\npreservation than static scenes. Inspired by this temporal non-uniformity, we\npropose VGDFR, a training-free approach for Diffusion-based Video Generation\nwith Dynamic Latent Frame Rate. VGDFR adaptively adjusts the number of elements\nin latent space based on the motion frequency of the latent space content,\nusing fewer tokens for low-frequency segments while preserving detail in\nhigh-frequency segments. Specifically, our key contributions are: (1) A dynamic\nframe rate scheduler for DiT video generation that adaptively assigns frame\nrates for video segments. (2) A novel latent-space frame merging method to\nalign latent representations with their denoised counterparts before merging\nthose redundant in low-resolution space. (3) A preference analysis of Rotary\nPositional Embeddings (RoPE) across DiT layers, informing a tailored RoPE\nstrategy optimized for semantic and local information capture. Experiments show\nthat VGDFR can achieve a speedup up to 3x for video generation with minimal\nquality degradation.", "published": "2025-04-16 17:09:13", "link": "http://arxiv.org/abs/2504.12259v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Human Aligned Compression for Robust Models", "abstract": "Adversarial attacks on image models threaten system robustness by introducing\nimperceptible perturbations that cause incorrect predictions. We investigate\nhuman-aligned learned lossy compression as a defense mechanism, comparing two\nlearned models (HiFiC and ELIC) against traditional JPEG across various quality\nlevels. Our experiments on ImageNet subsets demonstrate that learned\ncompression methods outperform JPEG, particularly for Vision Transformer\narchitectures, by preserving semantically meaningful content while removing\nadversarial noise. Even in white-box settings where attackers can access the\ndefense, these methods maintain substantial effectiveness. We also show that\nsequential compression--applying rounds of\ncompression/decompression--significantly enhances defense efficacy while\nmaintaining classification performance. Our findings reveal that human-aligned\ncompression provides an effective, computationally efficient defense that\nprotects the image features most relevant to human and machine understanding.\nIt offers a practical approach to improving model robustness against\nadversarial threats.", "published": "2025-04-16 17:05:58", "link": "http://arxiv.org/abs/2504.12255v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Comparative Evaluation of Radiomics and Deep Learning Models for Disease Detection in Chest Radiography", "abstract": "The application of artificial intelligence (AI) in medical imaging has\nrevolutionized diagnostic practices, enabling advanced analysis and\ninterpretation of radiological data. This study presents a comprehensive\nevaluation of radiomics-based and deep learning-based approaches for disease\ndetection in chest radiography, focusing on COVID-19, lung opacity, and viral\npneumonia. While deep learning models, particularly convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), learn directly from image data,\nradiomics-based models extract and analyze quantitative features, potentially\nproviding advantages in data-limited scenarios. This study systematically\ncompares the diagnostic accuracy and robustness of various AI models, including\nDecision Trees, Gradient Boosting, Random Forests, Support Vector Machines\n(SVM), and Multi-Layer Perceptrons (MLP) for radiomics, against\nstate-of-the-art computer vision deep learning architectures. Performance\nmetrics across varying sample sizes reveal insights into each model's efficacy,\nhighlighting the contexts in which specific AI approaches may offer enhanced\ndiagnostic capabilities. The results aim to inform the integration of AI-driven\ndiagnostic tools in clinical practice, particularly in automated and\nhigh-throughput environments where timely, reliable diagnosis is critical. This\ncomparative study addresses an essential gap, establishing guidance for the\nselection of AI models based on clinical and operational needs.", "published": "2025-04-16 16:54:37", "link": "http://arxiv.org/abs/2504.12249v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "SIDME: Self-supervised Image Demoir\u00e9ing via Masked Encoder-Decoder Reconstruction", "abstract": "Moir\\'e patterns, resulting from aliasing between object light signals and\ncamera sampling frequencies, often degrade image quality during capture.\nTraditional demoir\\'eing methods have generally treated images as a whole for\nprocessing and training, neglecting the unique signal characteristics of\ndifferent color channels. Moreover, the randomness and variability of moir\\'e\npattern generation pose challenges to the robustness of existing methods when\napplied to real-world data. To address these issues, this paper presents SIDME\n(Self-supervised Image Demoir\\'eing via Masked Encoder-Decoder Reconstruction),\na novel model designed to generate high-quality visual images by effectively\nprocessing moir\\'e patterns. SIDME combines a masked encoder-decoder\narchitecture with self-supervised learning, allowing the model to reconstruct\nimages using the inherent properties of camera sampling frequencies. A key\ninnovation is the random masked image reconstructor, which utilizes an\nencoder-decoder structure to handle the reconstruction task. Furthermore, since\nthe green channel in camera sampling has a higher sampling frequency compared\nto red and blue channels, a specialized self-supervised loss function is\ndesigned to improve the training efficiency and effectiveness. To ensure the\ngeneralization ability of the model, a self-supervised moir\\'e image generation\nmethod has been developed to produce a dataset that closely mimics real-world\nconditions. Extensive experiments demonstrate that SIDME outperforms existing\nmethods in processing real moir\\'e pattern data, showing its superior\ngeneralization performance and robustness.", "published": "2025-04-16 16:50:41", "link": "http://arxiv.org/abs/2504.12245v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Cobra: Efficient Line Art COlorization with BRoAder References", "abstract": "The comic production industry requires reference-based line art colorization\nwith high accuracy, efficiency, contextual consistency, and flexible control. A\ncomic page often involves diverse characters, objects, and backgrounds, which\ncomplicates the coloring process. Despite advancements in diffusion models for\nimage generation, their application in line art colorization remains limited,\nfacing challenges related to handling extensive reference images,\ntime-consuming inference, and flexible control. We investigate the necessity of\nextensive contextual image guidance on the quality of line art colorization. To\naddress these challenges, we introduce Cobra, an efficient and versatile method\nthat supports color hints and utilizes over 200 reference images while\nmaintaining low latency. Central to Cobra is a Causal Sparse DiT architecture,\nwhich leverages specially designed positional encodings, causal sparse\nattention, and Key-Value Cache to effectively manage long-context references\nand ensure color identity consistency. Results demonstrate that Cobra achieves\naccurate line art colorization through extensive contextual reference,\nsignificantly enhancing inference speed and interactivity, thereby meeting\ncritical industrial demands. We release our codes and models on our project\npage: https://zhuang2002.github.io/Cobra/.", "published": "2025-04-16 16:45:19", "link": "http://arxiv.org/abs/2504.12240v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Coding-Prior Guided Diffusion Network for Video Deblurring", "abstract": "While recent video deblurring methods have advanced significantly, they often\noverlook two valuable prior information: (1) motion vectors (MVs) and coding\nresiduals (CRs) from video codecs, which provide efficient inter-frame\nalignment cues, and (2) the rich real-world knowledge embedded in pre-trained\ndiffusion generative models. We present CPGDNet, a novel two-stage framework\nthat effectively leverages both coding priors and generative diffusion priors\nfor high-quality deblurring. First, our coding-prior feature propagation (CPFP)\nmodule utilizes MVs for efficient frame alignment and CRs to generate attention\nmasks, addressing motion inaccuracies and texture variations. Second, a\ncoding-prior controlled generation (CPC) module network integrates coding\npriors into a pretrained diffusion model, guiding it to enhance critical\nregions and synthesize realistic details. Experiments demonstrate our method\nachieves state-of-the-art perceptual quality with up to 30% improvement in IQA\nmetrics. Both the code and the codingprior-augmented dataset will be\nopen-sourced.", "published": "2025-04-16 16:14:43", "link": "http://arxiv.org/abs/2504.12222v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Realistic Low-Light Image Enhancement via ISP Driven Data Modeling", "abstract": "Deep neural networks (DNNs) have recently become the leading method for\nlow-light image enhancement (LLIE). However, despite significant progress,\ntheir outputs may still exhibit issues such as amplified noise, incorrect white\nbalance, or unnatural enhancements when deployed in real world applications. A\nkey challenge is the lack of diverse, large scale training data that captures\nthe complexities of low-light conditions and imaging pipelines. In this paper,\nwe propose a novel image signal processing (ISP) driven data synthesis pipeline\nthat addresses these challenges by generating unlimited paired training data.\nSpecifically, our pipeline begins with easily collected high-quality\nnormal-light images, which are first unprocessed into the RAW format using a\nreverse ISP. We then synthesize low-light degradations directly in the RAW\ndomain. The resulting data is subsequently processed through a series of ISP\nstages, including white balance adjustment, color space conversion, tone\nmapping, and gamma correction, with controlled variations introduced at each\nstage. This broadens the degradation space and enhances the diversity of the\ntraining data, enabling the generated data to capture a wide range of\ndegradations and the complexities inherent in the ISP pipeline. To demonstrate\nthe effectiveness of our synthetic pipeline, we conduct extensive experiments\nusing a vanilla UNet model consisting solely of convolutional layers, group\nnormalization, GeLU activation, and convolutional block attention modules\n(CBAMs). Extensive testing across multiple datasets reveals that the vanilla\nUNet model trained with our data synthesis pipeline delivers high fidelity,\nvisually appealing enhancement results, surpassing state-of-the-art (SOTA)\nmethods both quantitatively and qualitatively.", "published": "2025-04-16 15:53:53", "link": "http://arxiv.org/abs/2504.12204v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Modality-Independent Explainable Detection of Inaccurate Organ Segmentations Using Denoising Autoencoders", "abstract": "In radiation therapy planning, inaccurate segmentations of organs at risk can\nresult in suboptimal treatment delivery, if left undetected by the clinician.\nTo address this challenge, we developed a denoising autoencoder-based method to\ndetect inaccurate organ segmentations. We applied noise to ground truth organ\nsegmentations, and the autoencoders were tasked to denoise them. Through the\napplication of our method to organ segmentations generated on both MR and CT\nscans, we demonstrated that the method is independent of imaging modality. By\nproviding reconstructions, our method offers visual information about\ninaccurate regions of the organ segmentations, leading to more explainable\ndetection of suboptimal segmentations. We compared our method to existing\napproaches in the literature and demonstrated that it achieved superior\nperformance for the majority of organs.", "published": "2025-04-16 15:53:40", "link": "http://arxiv.org/abs/2504.12203v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Beyond Patches: Mining Interpretable Part-Prototypes for Explainable AI", "abstract": "Deep learning has provided considerable advancements for multimedia systems,\nyet the interpretability of deep models remains a challenge. State-of-the-art\npost-hoc explainability methods, such as GradCAM, provide visual interpretation\nbased on heatmaps but lack conceptual clarity. Prototype-based approaches, like\nProtoPNet and PIPNet, offer a more structured explanation but rely on fixed\npatches, limiting their robustness and semantic consistency.\n  To address these limitations, a part-prototypical concept mining network\n(PCMNet) is proposed that dynamically learns interpretable prototypes from\nmeaningful regions. PCMNet clusters prototypes into concept groups, creating\nsemantically grounded explanations without requiring additional annotations.\nThrough a joint process of unsupervised part discovery and concept activation\nvector extraction, PCMNet effectively captures discriminative concepts and\nmakes interpretable classification decisions.\n  Our extensive experiments comparing PCMNet against state-of-the-art methods\non multiple datasets show that it can provide a high level of interpretability,\nstability, and robustness under clean and occluded scenarios.", "published": "2025-04-16 15:48:21", "link": "http://arxiv.org/abs/2504.12197v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CoMotion: Concurrent Multi-person 3D Motion", "abstract": "We introduce an approach for detecting and tracking detailed 3D poses of\nmultiple people from a single monocular camera stream. Our system maintains\ntemporally coherent predictions in crowded scenes filled with difficult poses\nand occlusions. Our model performs both strong per-frame detection and a\nlearned pose update to track people from frame to frame. Rather than match\ndetections across time, poses are updated directly from a new input image,\nwhich enables online tracking through occlusion. We train on numerous image and\nvideo datasets leveraging pseudo-labeled annotations to produce a model that\nmatches state-of-the-art systems in 3D pose estimation accuracy while being\nfaster and more accurate in tracking multiple people through time. Code and\nweights are provided at https://github.com/apple/ml-comotion", "published": "2025-04-16 15:40:15", "link": "http://arxiv.org/abs/2504.12186v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Towards a General-Purpose Zero-Shot Synthetic Low-Light Image and Video Pipeline", "abstract": "Low-light conditions pose significant challenges for both human and machine\nannotation. This in turn has led to a lack of research into machine\nunderstanding for low-light images and (in particular) videos. A common\napproach is to apply annotations obtained from high quality datasets to\nsynthetically created low light versions. In addition, these approaches are\noften limited through the use of unrealistic noise models. In this paper, we\npropose a new Degradation Estimation Network (DEN), which synthetically\ngenerates realistic standard RGB (sRGB) noise without the requirement for\ncamera metadata. This is achieved by estimating the parameters of\nphysics-informed noise distributions, trained in a self-supervised manner. This\nzero-shot approach allows our method to generate synthetic noisy content with a\ndiverse range of realistic noise characteristics, unlike other methods which\nfocus on recreating the noise characteristics of the training data. We evaluate\nour proposed synthetic pipeline using various methods trained on its synthetic\ndata for typical low-light tasks including synthetic noise replication, video\nenhancement, and object detection, showing improvements of up to 24\\% KLD, 21\\%\nLPIPS, and 62\\% AP$_{50-95}$, respectively.", "published": "2025-04-16 15:19:11", "link": "http://arxiv.org/abs/2504.12169v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "RADLER: Radar Object Detection Leveraging Semantic 3D City Models and Self-Supervised Radar-Image Learning", "abstract": "Semantic 3D city models are worldwide easy-accessible, providing accurate,\nobject-oriented, and semantic-rich 3D priors. To date, their potential to\nmitigate the noise impact on radar object detection remains under-explored. In\nthis paper, we first introduce a unique dataset, RadarCity, comprising 54K\nsynchronized radar-image pairs and semantic 3D city models. Moreover, we\npropose a novel neural network, RADLER, leveraging the effectiveness of\ncontrastive self-supervised learning (SSL) and semantic 3D city models to\nenhance radar object detection of pedestrians, cyclists, and cars.\nSpecifically, we first obtain the robust radar features via a SSL network in\nthe radar-image pretext task. We then use a simple yet effective feature fusion\nstrategy to incorporate semantic-depth features from semantic 3D city models.\nHaving prior 3D information as guidance, RADLER obtains more fine-grained\ndetails to enhance radar object detection. We extensively evaluate RADLER on\nthe collected RadarCity dataset and demonstrate average improvements of 5.46%\nin mean avarage precision (mAP) and 3.51% in mean avarage recall (mAR) over\nprevious radar object detection methods. We believe this work will foster\nfurther research on semantic-guided and map-supported radar object detection.\nOur project page is publicly available\nathttps://gpp-communication.github.io/RADLER .", "published": "2025-04-16 15:18:56", "link": "http://arxiv.org/abs/2504.12167v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "CodingHomo: Bootstrapping Deep Homography With Video Coding", "abstract": "Homography estimation is a fundamental task in computer vision with\napplications in diverse fields. Recent advances in deep learning have improved\nhomography estimation, particularly with unsupervised learning approaches,\noffering increased robustness and generalizability. However, accurately\npredicting homography, especially in complex motions, remains a challenge. In\nresponse, this work introduces a novel method leveraging video coding,\nparticularly by harnessing inherent motion vectors (MVs) present in videos. We\npresent CodingHomo, an unsupervised framework for homography estimation. Our\nframework features a Mask-Guided Fusion (MGF) module that identifies and\nutilizes beneficial features among the MVs, thereby enhancing the accuracy of\nhomography prediction. Additionally, the Mask-Guided Homography Estimation\n(MGHE) module is presented for eliminating undesired features in the\ncoarse-to-fine homography refinement process. CodingHomo outperforms existing\nstate-of-the-art unsupervised methods, delivering good robustness and\ngeneralizability. The code and dataset are available at:\n\\href{github}{https://github.com/liuyike422/CodingHomo", "published": "2025-04-16 15:18:11", "link": "http://arxiv.org/abs/2504.12165v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FocusedAD: Character-centric Movie Audio Description", "abstract": "Movie Audio Description (AD) aims to narrate visual content during\ndialogue-free segments, particularly benefiting blind and visually impaired\n(BVI) audiences. Compared with general video captioning, AD demands\nplot-relevant narration with explicit character name references, posing unique\nchallenges in movie understanding.To identify active main characters and focus\non storyline-relevant regions, we propose FocusedAD, a novel framework that\ndelivers character-centric movie audio descriptions. It includes: (i) a\nCharacter Perception Module(CPM) for tracking character regions and linking\nthem to names; (ii) a Dynamic Prior Module(DPM) that injects contextual cues\nfrom prior ADs and subtitles via learnable soft prompts; and (iii) a Focused\nCaption Module(FCM) that generates narrations enriched with plot-relevant\ndetails and named characters. To overcome limitations in character\nidentification, we also introduce an automated pipeline for building character\nquery banks. FocusedAD achieves state-of-the-art performance on multiple\nbenchmarks, including strong zero-shot results on MAD-eval-Named and our newly\nproposed Cinepile-AD dataset. Code and data will be released at\nhttps://github.com/Thorin215/FocusedAD .", "published": "2025-04-16 15:04:14", "link": "http://arxiv.org/abs/2504.12157v1", "categories": ["cs.CV", "I.2.10"], "primary_category": "cs.CV"}
{"title": "Weakly Semi-supervised Whole Slide Image Classification by Two-level Cross Consistency Supervision", "abstract": "Computer-aided Whole Slide Image (WSI) classification has the potential to\nenhance the accuracy and efficiency of clinical pathological diagnosis. It is\ncommonly formulated as a Multiple Instance Learning (MIL) problem, where each\nWSI is treated as a bag and the small patches extracted from the WSI are\nconsidered instances within that bag. However, obtaining labels for a large\nnumber of bags is a costly and time-consuming process, particularly when\nutilizing existing WSIs for new classification tasks. This limitation renders\nmost existing WSI classification methods ineffective. To address this issue, we\npropose a novel WSI classification problem setting, more aligned with clinical\npractice, termed Weakly Semi-supervised Whole slide image Classification\n(WSWC). In WSWC, a small number of bags are labeled, while a significant number\nof bags remain unlabeled. The MIL nature of the WSWC problem, coupled with the\nabsence of patch labels, distinguishes it from typical semi-supervised image\nclassification problems, making existing algorithms for natural images\nunsuitable for directly solving the WSWC problem. In this paper, we present a\nconcise and efficient framework, named CroCo, to tackle the WSWC problem\nthrough two-level Cross Consistency supervision. CroCo comprises two\nheterogeneous classifier branches capable of performing both instance\nclassification and bag classification. The fundamental idea is to establish\ncross-consistency supervision at both the bag-level and instance-level between\nthe two branches during training. Extensive experiments conducted on four\ndatasets demonstrate that CroCo achieves superior bag classification and\ninstance classification performance compared to other comparative methods when\nlimited WSIs with bag labels are available. To the best of our knowledge, this\npaper presents for the first time the WSWC problem and gives a successful\nresolution.", "published": "2025-04-16 14:45:26", "link": "http://arxiv.org/abs/2504.12132v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Anti-Aesthetics: Protecting Facial Privacy against Customized Text-to-Image Synthesis", "abstract": "The rise of customized diffusion models has spurred a boom in personalized\nvisual content creation, but also poses risks of malicious misuse, severely\nthreatening personal privacy and copyright protection. Some studies show that\nthe aesthetic properties of images are highly positively correlated with human\nperception of image quality. Inspired by this, we approach the problem from a\nnovel and intriguing aesthetic perspective to degrade the generation quality of\nmaliciously customized models, thereby achieving better protection of facial\nidentity. Specifically, we propose a Hierarchical Anti-Aesthetic (HAA)\nframework to fully explore aesthetic cues, which consists of two key branches:\n1) Global Anti-Aesthetics: By establishing a global anti-aesthetic reward\nmechanism and a global anti-aesthetic loss, it can degrade the overall\naesthetics of the generated content; 2) Local Anti-Aesthetics: A local\nanti-aesthetic reward mechanism and a local anti-aesthetic loss are designed to\nguide adversarial perturbations to disrupt local facial identity. By seamlessly\nintegrating both branches, our HAA effectively achieves the goal of\nanti-aesthetics from a global to a local level during customized generation.\nExtensive experiments show that HAA outperforms existing SOTA methods largely\nin identity removal, providing a powerful tool for protecting facial privacy\nand copyright.", "published": "2025-04-16 14:44:00", "link": "http://arxiv.org/abs/2504.12129v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Remote sensing colour image semantic segmentation of trails created by large herbivorous Mammals", "abstract": "Detection of spatial areas where biodiversity is at risk is of paramount\nimportance for the conservation and monitoring of ecosystems. Large terrestrial\nmammalian herbivores are keystone species as their activity not only has deep\neffects on soils, plants, and animals, but also shapes landscapes, as large\nherbivores act as allogenic ecosystem engineers. One key landscape feature that\nindicates intense herbivore activity and potentially impacts biodiversity is\nthe formation of grazing trails. Grazing trails are formed by the continuous\ntrampling activity of large herbivores that can produce complex networks of\ntracks of bare soil. Here, we evaluated different algorithms based on machine\nlearning techniques to identify grazing trails. Our goal is to automatically\ndetect potential areas with intense herbivory activity, which might be\nbeneficial for conservation and management plans.\n  We have applied five semantic segmentation methods combined with fourteen\nencoders aimed at mapping grazing trails on aerial images. Our results indicate\nthat in most cases the chosen methodology successfully mapped the trails,\nalthough there were a few instances where the actual trail structure was\nunderestimated. The UNet architecture with the MambaOut encoder was the best\narchitecture for mapping trails. The proposed approach could be applied to\ndevelop tools for mapping and monitoring temporal changes in these landscape\nstructures to support habitat conservation and land management programs. This\nis the first time, to the best of our knowledge, that competitive image\nsegmentation results are obtained for the detection and delineation of trails\nof large herbivorous mammals.", "published": "2025-04-16 14:33:57", "link": "http://arxiv.org/abs/2504.12121v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Diffusion-Based Framework for Terrain-Aware Remote Sensing Image Reconstruction", "abstract": "Remote sensing imagery is essential for environmental monitoring,\nagricultural management, and disaster response. However, data loss due to cloud\ncover, sensor failures, or incomplete acquisition-especially in high-resolution\nand high-frequency tasks-severely limits satellite imagery's effectiveness.\nTraditional interpolation methods struggle with large missing areas and complex\nstructures. Remote sensing imagery consists of multiple bands, each with\ndistinct meanings, and ensuring consistency across bands is critical to avoid\nanomalies in the combined images. This paper proposes SatelliteMaker, a\ndiffusion-based method that reconstructs missing data across varying levels of\ndata loss while maintaining spatial, spectral, and temporal consistency. We\nalso propose Digital Elevation Model (DEM) as a conditioning input and use\ntailored prompts to generate realistic images, making diffusion models\napplicable to quantitative remote sensing tasks. Additionally, we propose a\nVGG-Adapter module based on Distribution Loss, which reduces distribution\ndiscrepancy and ensures style consistency. Extensive experiments show that\nSatelliteMaker achieves state-of-the-art performance across multiple tasks.", "published": "2025-04-16 14:19:57", "link": "http://arxiv.org/abs/2504.12112v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Logits DeConfusion with CLIP for Few-Shot Learning", "abstract": "With its powerful visual-language alignment capability, CLIP performs well in\nzero-shot and few-shot learning tasks. However, we found in experiments that\nCLIP's logits suffer from serious inter-class confusion problems in downstream\ntasks, and the ambiguity between categories seriously affects the accuracy. To\naddress this challenge, we propose a novel method called Logits DeConfusion,\nwhich effectively learns and eliminates inter-class confusion in logits by\ncombining our Multi-level Adapter Fusion (MAF) module with our Inter-Class\nDeconfusion (ICD) module. Our MAF extracts features from different levels and\nfuses them uniformly to enhance feature representation. Our ICD learnably\neliminates inter-class confusion in logits with a residual structure.\nExperimental results show that our method can significantly improve the\nclassification performance and alleviate the inter-class confusion problem. The\ncode is available at https://github.com/LiShuo1001/LDC.", "published": "2025-04-16 14:12:56", "link": "http://arxiv.org/abs/2504.12104v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Metric-Solver: Sliding Anchored Metric Depth Estimation from a Single Image", "abstract": "Accurate and generalizable metric depth estimation is crucial for various\ncomputer vision applications but remains challenging due to the diverse depth\nscales encountered in indoor and outdoor environments. In this paper, we\nintroduce Metric-Solver, a novel sliding anchor-based metric depth estimation\nmethod that dynamically adapts to varying scene scales. Our approach leverages\nan anchor-based representation, where a reference depth serves as an anchor to\nseparate and normalize the scene depth into two components: scaled near-field\ndepth and tapered far-field depth. The anchor acts as a normalization factor,\nenabling the near-field depth to be normalized within a consistent range while\nmapping far-field depth smoothly toward zero. Through this approach, any depth\nfrom zero to infinity in the scene can be represented within a unified\nrepresentation, effectively eliminating the need to manually account for scene\nscale variations. More importantly, for the same scene, the anchor can slide\nalong the depth axis, dynamically adjusting to different depth scales. A\nsmaller anchor provides higher resolution in the near-field, improving depth\nprecision for closer objects while a larger anchor improves depth estimation in\nfar regions. This adaptability enables the model to handle depth predictions at\nvarying distances and ensure strong generalization across datasets. Our design\nenables a unified and adaptive depth representation across diverse\nenvironments. Extensive experiments demonstrate that Metric-Solver outperforms\nexisting methods in both accuracy and cross-dataset generalization.", "published": "2025-04-16 14:12:25", "link": "http://arxiv.org/abs/2504.12103v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generalized Visual Relation Detection with Diffusion Models", "abstract": "Visual relation detection (VRD) aims to identify relationships (or\ninteractions) between object pairs in an image. Although recent VRD models have\nachieved impressive performance, they are all restricted to pre-defined\nrelation categories, while failing to consider the semantic ambiguity\ncharacteristic of visual relations. Unlike objects, the appearance of visual\nrelations is always subtle and can be described by multiple predicate words\nfrom different perspectives, e.g., ``ride'' can be depicted as ``race'' and\n``sit on'', from the sports and spatial position views, respectively. To this\nend, we propose to model visual relations as continuous embeddings, and design\ndiffusion models to achieve generalized VRD in a conditional generative manner,\ntermed Diff-VRD. We model the diffusion process in a latent space and generate\nall possible relations in the image as an embedding sequence. During the\ngeneration, the visual and text embeddings of subject-object pairs serve as\nconditional signals and are injected via cross-attention. After the generation,\nwe design a subsequent matching stage to assign the relation words to\nsubject-object pairs by considering their semantic similarities. Benefiting\nfrom the diffusion-based generative process, our Diff-VRD is able to generate\nvisual relations beyond the pre-defined category labels of datasets. To\nproperly evaluate this generalized VRD task, we introduce two evaluation\nmetrics, i.e., text-to-image retrieval and SPICE PR Curve inspired by image\ncaptioning. Extensive experiments in both human-object interaction (HOI)\ndetection and scene graph generation (SGG) benchmarks attest to the superiority\nand effectiveness of Diff-VRD.", "published": "2025-04-16 14:03:24", "link": "http://arxiv.org/abs/2504.12100v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Self-alignment of Large Video Language Models with Refined Regularized Preference Optimization", "abstract": "Despite recent advances in Large Video Language Models (LVLMs), they still\nstruggle with fine-grained temporal understanding, hallucinate, and often make\nsimple mistakes on even simple video question-answering tasks, all of which\npose significant challenges to their safe and reliable deployment in real-world\napplications. To address these limitations, we propose a self-alignment\nframework that enables LVLMs to learn from their own errors. Our proposed\nframework first obtains a training set of preferred and non-preferred response\npairs, where non-preferred responses are generated by incorporating common\nerror patterns that often occur due to inadequate spatio-temporal\nunderstanding, spurious correlations between co-occurring concepts, and\nover-reliance on linguistic cues while neglecting the vision modality, among\nothers. To facilitate self-alignment of LVLMs with the constructed preferred\nand non-preferred response pairs, we introduce Refined Regularized Preference\nOptimization (RRPO), a novel preference optimization method that utilizes\nsub-sequence-level refined rewards and token-wise KL regularization to address\nthe limitations of Direct Preference Optimization (DPO). We demonstrate that\nRRPO achieves more precise alignment and more stable training compared to DPO.\nOur experiments and analysis validate the effectiveness of our approach across\ndiverse video tasks, including video hallucination, short- and long-video\nunderstanding, and fine-grained temporal reasoning.", "published": "2025-04-16 13:43:56", "link": "http://arxiv.org/abs/2504.12083v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency", "abstract": "Given a single labeled example, in-context segmentation aims to segment\ncorresponding objects. This setting, known as one-shot segmentation in few-shot\nlearning, explores the segmentation model's generalization ability and has been\napplied to various vision tasks, including scene understanding and image/video\nediting. While recent Segment Anything Models have achieved state-of-the-art\nresults in interactive segmentation, these approaches are not directly\napplicable to in-context segmentation. In this work, we propose the Dual\nConsistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2\nfor in-context segmentation of both images and videos. Our key insights are to\nenhance the features of the SAM's prompt encoder in segmentation by providing\nhigh-quality visual prompts. When generating a mask prior, we fuse the SAM\nfeatures to better align the prompt encoder. Then, we design a cycle-consistent\ncross-attention on fused features and initial visual prompts. Next, a\ndual-branch design is provided by using the discriminative positive and\nnegative prompts in the prompt encoder. Furthermore, we design a simple\nmask-tube training strategy to adopt our proposed dual consistency method into\nthe mask tube. Although the proposed DC-SAM is primarily designed for images,\nit can be seamlessly extended to the video domain with the support of SAM2.\nGiven the absence of in-context segmentation in the video domain, we manually\ncurate and construct the first benchmark from existing video segmentation\ndatasets, named In-Context Video Object Segmentation (IC-VOS), to better assess\nthe in-context capability of the model. Extensive experiments demonstrate that\nour method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on\nPASCAL-5i, and a J&F score of 71.52 on the proposed IC-VOS benchmark. Our\nsource code and benchmark are available at https://github.com/zaplm/DC-SAM.", "published": "2025-04-16 13:41:59", "link": "http://arxiv.org/abs/2504.12080v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Single-shot Star-convex Polygon-based Instance Segmentation for Spatially-correlated Biomedical Objects", "abstract": "Biomedical images often contain objects known to be spatially correlated or\nnested due to their inherent properties, leading to semantic relations.\nExamples include cell nuclei being nested within eukaryotic cells and colonies\ngrowing exclusively within their culture dishes. While these semantic relations\nbear key importance, detection tasks are often formulated independently,\nrequiring multi-shot analysis pipelines. Importantly, spatial correlation could\nconstitute a fundamental prior facilitating learning of more meaningful\nrepresentations for tasks like instance segmentation. This knowledge has, thus\nfar, not been utilised by the biomedical computer vision community. We argue\nthat the instance segmentation of two or more categories of objects can be\nachieved in parallel. We achieve this via two architectures HydraStarDist (HSD)\nand the novel (HSD-WBR) based on the widely-used StarDist (SD), to take\nadvantage of the star-convexity of our target objects. HSD and HSD-WBR are\nconstructed to be capable of incorporating their interactions as constraints\ninto account. HSD implicitly incorporates spatial correlation priors based on\nobject interaction through a joint encoder. HSD-WBR further enforces the prior\nin a regularisation layer with the penalty we proposed named Within Boundary\nRegularisation Penalty (WBR). Both architectures achieve nested instance\nsegmentation in a single shot. We demonstrate their competitiveness based on\n$IoU_R$ and AP and superiority in a new, task-relevant criteria, Joint TP rate\n(JTPR) compared to their baseline SD and Cellpose. Our approach can be further\nmodified to capture partial-inclusion/-exclusion in multi-object interactions\nin fluorescent or brightfield microscopy or digital imaging. Finally, our\nstrategy suggests gains by making this learning single-shot and computationally\nefficient.", "published": "2025-04-16 13:41:02", "link": "http://arxiv.org/abs/2504.12078v1", "categories": ["cs.CV", "q-bio.QM", "J.3; I.4"], "primary_category": "cs.CV"}
{"title": "Modular-Cam: Modular Dynamic Camera-view Video Generation with LLM", "abstract": "Text-to-Video generation, which utilizes the provided text prompt to generate\nhigh-quality videos, has drawn increasing attention and achieved great success\ndue to the development of diffusion models recently. Existing methods mainly\nrely on a pre-trained text encoder to capture the semantic information and\nperform cross attention with the encoded text prompt to guide the generation of\nvideo. However, when it comes to complex prompts that contain dynamic scenes\nand multiple camera-view transformations, these methods can not decompose the\noverall information into separate scenes, as well as fail to smoothly change\nscenes based on the corresponding camera-views. To solve these problems, we\npropose a novel method, i.e., Modular-Cam. Specifically, to better understand a\ngiven complex prompt, we utilize a large language model to analyze user\ninstructions and decouple them into multiple scenes together with transition\nactions. To generate a video containing dynamic scenes that match the given\ncamera-views, we incorporate the widely-used temporal transformer into the\ndiffusion model to ensure continuity within a single scene and propose\nCamOperator, a modular network based module that well controls the camera\nmovements. Moreover, we propose AdaControlNet, which utilizes ControlNet to\nensure consistency across scenes and adaptively adjusts the color tone of the\ngenerated video. Extensive qualitative and quantitative experiments prove our\nproposed Modular-Cam's strong capability of generating multi-scene videos\ntogether with its ability to achieve fine-grained control of camera movements.\nGenerated results are available at https://modular-cam.github.io.", "published": "2025-04-16 13:04:01", "link": "http://arxiv.org/abs/2504.12048v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "pix2pockets: Shot Suggestions in 8-Ball Pool from a Single Image in the Wild", "abstract": "Computer vision models have seen increased usage in sports, and reinforcement\nlearning (RL) is famous for beating humans in strategic games such as Chess and\nGo. In this paper, we are interested in building upon these advances and\nexamining the game of classic 8-ball pool. We introduce pix2pockets, a\nfoundation for an RL-assisted pool coach. Given a single image of a pool table,\nwe first aim to detect the table and the balls and then propose the optimal\nshot suggestion. For the first task, we build a dataset with 195 diverse images\nwhere we manually annotate all balls and table dots, leading to 5748 object\nsegmentation masks. For the second task, we build a standardized RL environment\nthat allows easy development and benchmarking of any RL algorithm. Our object\ndetection model yields an AP50 of 91.2 while our ball location pipeline obtains\nan error of only 0.4 cm. Furthermore, we compare standard RL algorithms to set\na baseline for the shot suggestion task and we show that all of them fail to\npocket all balls without making a foul move. We also present a simple baseline\nthat achieves a per-shot success rate of 94.7% and clears a full game in a\nsingle turn 30% of the time.", "published": "2025-04-16 13:01:44", "link": "http://arxiv.org/abs/2504.12045v1", "categories": ["cs.CV", "cs.LG", "I.2.1; I.4.6"], "primary_category": "cs.CV"}
{"title": "Object Placement for Anything", "abstract": "Object placement aims to determine the appropriate placement (\\emph{e.g.},\nlocation and size) of a foreground object when placing it on the background\nimage. Most previous works are limited by small-scale labeled dataset, which\nhinders the real-world application of object placement. In this work, we devise\na semi-supervised framework which can exploit large-scale unlabeled dataset to\npromote the generalization ability of discriminative object placement models.\nThe discriminative models predict the rationality label for each foreground\nplacement given a foreground-background pair. To better leverage the labeled\ndata, under the semi-supervised framework, we further propose to transfer the\nknowledge of rationality variation, \\emph{i.e.}, whether the change of\nforeground placement would result in the change of rationality label, from\nlabeled data to unlabeled data. Extensive experiments demonstrate that our\nframework can effectively enhance the generalization ability of discriminative\nobject placement models.", "published": "2025-04-16 12:39:00", "link": "http://arxiv.org/abs/2504.12029v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Understanding Attention Mechanism in Video Diffusion Models", "abstract": "Text-to-video (T2V) synthesis models, such as OpenAI's Sora, have garnered\nsignificant attention due to their ability to generate high-quality videos from\na text prompt. In diffusion-based T2V models, the attention mechanism is a\ncritical component. However, it remains unclear what intermediate features are\nlearned and how attention blocks in T2V models affect various aspects of video\nsynthesis, such as image quality and temporal consistency. In this paper, we\nconduct an in-depth perturbation analysis of the spatial and temporal attention\nblocks of T2V models using an information-theoretic approach. Our results\nindicate that temporal and spatial attention maps affect not only the timing\nand layout of the videos but also the complexity of spatiotemporal elements and\nthe aesthetic quality of the synthesized videos. Notably, high-entropy\nattention maps are often key elements linked to superior video quality, whereas\nlow-entropy attention maps are associated with the video's intra-frame\nstructure. Based on our findings, we propose two novel methods to enhance video\nquality and enable text-guided video editing. These methods rely entirely on\nlightweight manipulation of the attention matrices in T2V models. The efficacy\nand effectiveness of our methods are further validated through experimental\nevaluation across multiple datasets.", "published": "2025-04-16 12:37:08", "link": "http://arxiv.org/abs/2504.12027v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Action Anticipation from SoccerNet Football Video Broadcasts", "abstract": "Artificial intelligence has revolutionized the way we analyze sports videos,\nwhether to understand the actions of games in long untrimmed videos or to\nanticipate the player's motion in future frames. Despite these efforts, little\nattention has been given to anticipating game actions before they occur. In\nthis work, we introduce the task of action anticipation for football broadcast\nvideos, which consists in predicting future actions in unobserved future\nframes, within a five- or ten-second anticipation window. To benchmark this\ntask, we release a new dataset, namely the SoccerNet Ball Action Anticipation\ndataset, based on SoccerNet Ball Action Spotting. Additionally, we propose a\nFootball Action ANticipation TRAnsformer (FAANTRA), a baseline method that\nadapts FUTR, a state-of-the-art action anticipation model, to predict\nball-related actions. To evaluate action anticipation, we introduce new\nmetrics, including mAP@$\\delta$, which evaluates the temporal precision of\npredicted future actions, as well as mAP@$\\infty$, which evaluates their\noccurrence within the anticipation window. We also conduct extensive ablation\nstudies to examine the impact of various task settings, input configurations,\nand model architectures. Experimental results highlight both the feasibility\nand challenges of action anticipation in football videos, providing valuable\ninsights into the design of predictive models for sports analytics. By\nforecasting actions before they unfold, our work will enable applications in\nautomated broadcasting, tactical analysis, and player decision-making. Our\ndataset and code are publicly available at\nhttps://github.com/MohamadDalal/FAANTRA.", "published": "2025-04-16 12:24:33", "link": "http://arxiv.org/abs/2504.12021v1", "categories": ["cs.CV", "I.2.10; I.4.8"], "primary_category": "cs.CV"}
{"title": "MixSignGraph: A Sign Sequence is Worth Mixed Graphs of Nodes", "abstract": "Recent advances in sign language research have benefited from CNN-based\nbackbones, which are primarily transferred from traditional computer vision\ntasks (\\eg object identification, image recognition). However, these CNN-based\nbackbones usually excel at extracting features like contours and texture, but\nmay struggle with capturing sign-related features. In fact, sign language tasks\nrequire focusing on sign-related regions, including the collaboration between\ndifferent regions (\\eg left hand region and right hand region) and the\neffective content in a single region. To capture such region-related features,\nwe introduce MixSignGraph, which represents sign sequences as a group of mixed\ngraphs and designs the following three graph modules for feature extraction,\n\\ie Local Sign Graph (LSG) module, Temporal Sign Graph (TSG) module and\nHierarchical Sign Graph (HSG) module. Specifically, the LSG module learns the\ncorrelation of intra-frame cross-region features within one frame, \\ie focusing\non spatial features. The TSG module tracks the interaction of inter-frame\ncross-region features among adjacent frames, \\ie focusing on temporal features.\nThe HSG module aggregates the same-region features from different-granularity\nfeature maps of a frame, \\ie focusing on hierarchical features. In addition, to\nfurther improve the performance of sign language tasks without gloss\nannotations, we propose a simple yet counter-intuitive Text-driven CTC\nPre-training (TCP) method, which generates pseudo gloss labels from text labels\nfor model pre-training. Extensive experiments conducted on current five public\nsign language datasets demonstrate the superior performance of the proposed\nmodel. Notably, our model surpasses the SOTA models on multiple sign language\ntasks across several datasets, without relying on any additional cues.", "published": "2025-04-16 12:23:30", "link": "http://arxiv.org/abs/2504.12020v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Instruction-augmented Multimodal Alignment for Image-Text and Element Matching", "abstract": "With the rapid advancement of text-to-image (T2I) generation models,\nassessing the semantic alignment between generated images and text descriptions\nhas become a significant research challenge. Current methods, including those\nbased on Visual Question Answering (VQA), still struggle with fine-grained\nassessments and precise quantification of image-text alignment. This paper\npresents an improved evaluation method named Instruction-augmented Multimodal\nAlignment for Image-Text and Element Matching (iMatch), which evaluates\nimage-text semantic alignment by fine-tuning multimodal large language models.\nWe introduce four innovative augmentation strategies: First, the QAlign\nstrategy creates a precise probabilistic mapping to convert discrete scores\nfrom multimodal large language models into continuous matching scores. Second,\na validation set augmentation strategy uses pseudo-labels from model\npredictions to expand training data, boosting the model's generalization\nperformance. Third, an element augmentation strategy integrates element\ncategory labels to refine the model's understanding of image-text matching.\nFourth, an image augmentation strategy employs techniques like random lighting\nto increase the model's robustness. Additionally, we propose prompt type\naugmentation and score perturbation strategies to further enhance the accuracy\nof element assessments. Our experimental results show that the iMatch method\nsignificantly surpasses existing methods, confirming its effectiveness and\npractical value. Furthermore, our iMatch won first place in the CVPR NTIRE 2025\nText to Image Generation Model Quality Assessment - Track 1 Image-Text\nAlignment.", "published": "2025-04-16 12:21:49", "link": "http://arxiv.org/abs/2504.12018v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Complex-valued SAR Foundation Model Based on Physically Inspired Representation Learning", "abstract": "Vision foundation models in remote sensing have been extensively studied due\nto their superior generalization on various downstream tasks. Synthetic\nAperture Radar (SAR) offers all-day, all-weather imaging capabilities,\nproviding significant advantages for Earth observation. However, establishing a\nfoundation model for SAR image interpretation inevitably encounters the\nchallenges of insufficient information utilization and poor interpretability.\nIn this paper, we propose a remote sensing foundation model based on\ncomplex-valued SAR data, which simulates the polarimetric decomposition process\nfor pre-training, i.e., characterizing pixel scattering intensity as a weighted\ncombination of scattering bases and scattering coefficients, thereby endowing\nthe foundation model with physical interpretability. Specifically, we construct\na series of scattering queries, each representing an independent and meaningful\nscattering basis, which interact with SAR features in the scattering query\ndecoder and output the corresponding scattering coefficient. To guide the\npre-training process, polarimetric decomposition loss and power\nself-supervision loss are constructed. The former aligns the predicted\ncoefficients with Yamaguchi coefficients, while the latter reconstructs power\nfrom the predicted coefficients and compares it to the input image's power. The\nperformance of our foundation model is validated on six typical downstream\ntasks, achieving state-of-the-art results. Notably, the foundation model can\nextract stable feature representations and exhibits strong generalization, even\nin data-scarce conditions.", "published": "2025-04-16 11:51:34", "link": "http://arxiv.org/abs/2504.11999v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Review of YOLOv12: Attention-Based Enhancements vs. Previous Versions", "abstract": "The YOLO (You Only Look Once) series has been a leading framework in\nreal-time object detection, consistently improving the balance between speed\nand accuracy. However, integrating attention mechanisms into YOLO has been\nchallenging due to their high computational overhead. YOLOv12 introduces a\nnovel approach that successfully incorporates attention-based enhancements\nwhile preserving real-time performance. This paper provides a comprehensive\nreview of YOLOv12's architectural innovations, including Area Attention for\ncomputationally efficient self-attention, Residual Efficient Layer Aggregation\nNetworks for improved feature aggregation, and FlashAttention for optimized\nmemory access. Additionally, we benchmark YOLOv12 against prior YOLO versions\nand competing object detectors, analyzing its improvements in accuracy,\ninference speed, and computational efficiency. Through this analysis, we\ndemonstrate how YOLOv12 advances real-time object detection by refining the\nlatency-accuracy trade-off and optimizing computational resources.", "published": "2025-04-16 11:40:55", "link": "http://arxiv.org/abs/2504.11995v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Analysis of Pseudo-Labeling for Online Source-Free Universal Domain Adaptation", "abstract": "A domain (distribution) shift between training and test data often hinders\nthe real-world performance of deep neural networks, necessitating unsupervised\ndomain adaptation (UDA) to bridge this gap. Online source-free UDA has emerged\nas a solution for practical scenarios where access to source data is restricted\nand target data is received as a continuous stream. However, the open-world\nnature of many real-world applications additionally introduces category shifts\nmeaning that the source and target label spaces may differ. Online source-free\nuniversal domain adaptation (SF-UniDA) addresses this challenge. Existing\nmethods mainly rely on self-training with pseudo-labels, yet the relationship\nbetween pseudo-labeling and adaptation outcomes has not been studied yet. To\nbridge this gap, we conduct a systematic analysis through controlled\nexperiments with simulated pseudo-labeling, offering valuable insights into\npseudo-labeling for online SF-UniDA. Our findings reveal a substantial gap\nbetween the current state-of-the-art and the upper bound of adaptation achieved\nwith perfect pseudo-labeling. Moreover, we show that a contrastive loss enables\neffective adaptation even with moderate pseudo-label accuracy, while a\ncross-entropy loss, though less robust to pseudo-label errors, achieves\nsuperior results when pseudo-labeling approaches perfection. Lastly, our\nfindings indicate that pseudo-label accuracy is in general more crucial than\nquantity, suggesting that prioritizing fewer but high-confidence pseudo-labels\nis beneficial. Overall, our study highlights the critical role of\npseudo-labeling in (online) SF-UniDA and provides actionable insights to drive\nfuture advancements in the field. Our code is available at\nhttps://github.com/pascalschlachter/PLAnalysis.", "published": "2025-04-16 11:34:18", "link": "http://arxiv.org/abs/2504.11992v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Exploring Video-Based Driver Activity Recognition under Noisy Labels", "abstract": "As an open research topic in the field of deep learning, learning with noisy\nlabels has attracted much attention and grown rapidly over the past ten years.\nLearning with label noise is crucial for driver distraction behavior\nrecognition, as real-world video data often contains mislabeled samples,\nimpacting model reliability and performance. However, label noise learning is\nbarely explored in the driver activity recognition field. In this paper, we\npropose the first label noise learning approach for the driver activity\nrecognition task. Based on the cluster assumption, we initially enable the\nmodel to learn clustering-friendly low-dimensional representations from given\nvideos and assign the resultant embeddings into clusters. We subsequently\nperform co-refinement within each cluster to smooth the classifier outputs.\nFurthermore, we propose a flexible sample selection strategy that combines two\nselection criteria without relying on any hyperparameters to filter clean\nsamples from the training dataset. We also incorporate a self-adaptive\nparameter into the sample selection process to enforce balancing across\nclasses. A comprehensive variety of experiments on the public Drive&Act dataset\nfor all granularity levels demonstrates the superior performance of our method\nin comparison with other label-denoising methods derived from the image\nclassification field. The source code is available at\nhttps://github.com/ilonafan/DAR-noisy-labels.", "published": "2025-04-16 10:55:13", "link": "http://arxiv.org/abs/2504.11966v1", "categories": ["cs.CV", "cs.LG", "cs.RO", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Novel-view X-ray Projection Synthesis through Geometry-Integrated Deep Learning", "abstract": "X-ray imaging plays a crucial role in the medical field, providing essential\ninsights into the internal anatomy of patients for diagnostics, image-guided\nprocedures, and clinical decision-making. Traditional techniques often require\nmultiple X-ray projections from various angles to obtain a comprehensive view,\nleading to increased radiation exposure and more complex clinical processes.\nThis paper explores an innovative approach using the DL-GIPS model, which\nsynthesizes X-ray projections from new viewpoints by leveraging a single\nexisting projection. The model strategically manipulates geometry and texture\nfeatures extracted from an initial projection to match new viewing angles. It\nthen synthesizes the final projection by merging these modified geometry\nfeatures with consistent texture information through an advanced image\ngeneration process. We demonstrate the effectiveness and broad applicability of\nthe DL-GIPS framework through lung imaging examples, highlighting its potential\nto revolutionize stereoscopic and volumetric imaging by minimizing the need for\nextensive data acquisition.", "published": "2025-04-16 10:30:08", "link": "http://arxiv.org/abs/2504.11953v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Flow Intelligence: Robust Feature Matching via Temporal Signature Correlation", "abstract": "Feature matching across video streams remains a cornerstone challenge in\ncomputer vision. Increasingly, robust multimodal matching has garnered interest\nin robotics, surveillance, remote sensing, and medical imaging. While\ntraditional rely on detecting and matching spatial features, they break down\nwhen faced with noisy, misaligned, or cross-modal data. Recent deep learning\nmethods have improved robustness through learned representations, but remain\nconstrained by their dependence on extensive training data and computational\ndemands. We present Flow Intelligence, a paradigm-shifting approach that moves\nbeyond spatial features by focusing on temporal motion patterns exclusively.\nInstead of detecting traditional keypoints, our method extracts motion\nsignatures from pixel blocks across consecutive frames and extract temporal\nmotion signatures between videos. These motion-based descriptors achieve\nnatural invariance to translation, rotation, and scale variations while\nremaining robust across different imaging modalities. This novel approach also\nrequires no pretraining data, eliminates the need for spatial feature\ndetection, enables cross-modal matching using only temporal motion, and it\noutperforms existing methods in challenging scenarios where traditional\napproaches fail. By leveraging motion rather than appearance, Flow Intelligence\nenables robust, real-time video feature matching in diverse environments.", "published": "2025-04-16 10:25:20", "link": "http://arxiv.org/abs/2504.11949v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "R-Meshfusion: Reinforcement Learning Powered Sparse-View Mesh Reconstruction with Diffusion Priors", "abstract": "Mesh reconstruction from multi-view images is a fundamental problem in\ncomputer vision, but its performance degrades significantly under sparse-view\nconditions, especially in unseen regions where no ground-truth observations are\navailable. While recent advances in diffusion models have demonstrated strong\ncapabilities in synthesizing novel views from limited inputs, their outputs\noften suffer from visual artifacts and lack 3D consistency, posing challenges\nfor reliable mesh optimization. In this paper, we propose a novel framework\nthat leverages diffusion models to enhance sparse-view mesh reconstruction in a\nprincipled and reliable manner. To address the instability of diffusion\noutputs, we propose a Consensus Diffusion Module that filters unreliable\ngenerations via interquartile range (IQR) analysis and performs variance-aware\nimage fusion to produce robust pseudo-supervision. Building on this, we design\nan online reinforcement learning strategy based on the Upper Confidence Bound\n(UCB) to adaptively select the most informative viewpoints for enhancement,\nguided by diffusion loss. Finally, the fused images are used to jointly\nsupervise a NeRF-based model alongside sparse-view ground truth, ensuring\nconsistency across both geometry and appearance. Extensive experiments\ndemonstrate that our method achieves significant improvements in both geometric\nquality and rendering quality.", "published": "2025-04-16 10:23:59", "link": "http://arxiv.org/abs/2504.11946v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Words: Augmenting Discriminative Richness via Diffusions in Unsupervised Prompt Learning", "abstract": "Fine-tuning vision-language models (VLMs) with large amounts of unlabeled\ndata has recently garnered significant interest. However, a key challenge\nremains the lack of high-quality pseudo-labeled data. Current pseudo-labeling\nstrategies often struggle with mismatches between semantic and visual\ninformation, leading to sub-optimal performance of unsupervised prompt learning\n(UPL) methods. In this paper, we introduce a simple yet effective approach\ncalled \\textbf{A}ugmenting D\\textbf{i}scriminative \\textbf{R}ichness via\nDiffusions (AiR), toward learning a richer discriminating way to represent the\nclass comprehensively and thus facilitate classification. Specifically, our\napproach includes a pseudo-label generation module that leverages high-fidelity\nsynthetic samples to create an auxiliary classifier, which captures richer\nvisual variation, bridging text-image-pair classification to a more robust\nimage-image-pair classification. Additionally, we exploit the diversity of\ndiffusion-based synthetic samples to enhance prompt learning, providing greater\ninformation for semantic-visual alignment. Extensive experiments on five public\nbenchmarks, including RESISC45 and Flowers102, and across three learning\nparadigms-UL, SSL, and TRZSL-demonstrate that AiR achieves substantial and\nconsistent performance improvements over state-of-the-art unsupervised prompt\nlearning methods.", "published": "2025-04-16 10:09:45", "link": "http://arxiv.org/abs/2504.11930v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SemDiff: Generating Natural Unrestricted Adversarial Examples via Semantic Attributes Optimization in Diffusion Models", "abstract": "Unrestricted adversarial examples (UAEs), allow the attacker to create\nnon-constrained adversarial examples without given clean samples, posing a\nsevere threat to the safety of deep learning models. Recent works utilize\ndiffusion models to generate UAEs. However, these UAEs often lack naturalness\nand imperceptibility due to simply optimizing in intermediate latent noises. In\nlight of this, we propose SemDiff, a novel unrestricted adversarial attack that\nexplores the semantic latent space of diffusion models for meaningful\nattributes, and devises a multi-attributes optimization approach to ensure\nattack success while maintaining the naturalness and imperceptibility of\ngenerated UAEs. We perform extensive experiments on four tasks on three\nhigh-resolution datasets, including CelebA-HQ, AFHQ and ImageNet. The results\ndemonstrate that SemDiff outperforms state-of-the-art methods in terms of\nattack success rate and imperceptibility. The generated UAEs are natural and\nexhibit semantically meaningful changes, in accord with the attributes'\nweights. In addition, SemDiff is found capable of evading different defenses,\nwhich further validates its effectiveness and threatening.", "published": "2025-04-16 09:58:04", "link": "http://arxiv.org/abs/2504.11923v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Zooming In on Fakes: A Novel Dataset for Localized AI-Generated Image Detection with Forgery Amplification Approach", "abstract": "The rise of AI-generated image editing tools has made localized forgeries\nincreasingly realistic, posing challenges for visual content integrity.\nAlthough recent efforts have explored localized AIGC detection, existing\ndatasets predominantly focus on object-level forgeries while overlooking\nbroader scene edits in regions such as sky or ground. To address these\nlimitations, we introduce \\textbf{BR-Gen}, a large-scale dataset of 150,000\nlocally forged images with diverse scene-aware annotations, which are based on\nsemantic calibration to ensure high-quality samples. BR-Gen is constructed\nthrough a fully automated Perception-Creation-Evaluation pipeline to ensure\nsemantic coherence and visual realism. In addition, we further propose\n\\textbf{NFA-ViT}, a Noise-guided Forgery Amplification Vision Transformer that\nenhances the detection of localized forgeries by amplifying forgery-related\nfeatures across the entire image. NFA-ViT mines heterogeneous regions in\nimages, \\emph{i.e.}, potential edited areas, by noise fingerprints.\nSubsequently, attention mechanism is introduced to compel the interaction\nbetween normal and abnormal features, thereby propagating the generalization\ntraces throughout the entire image, allowing subtle forgeries to influence a\nbroader context and improving overall detection robustness. Extensive\nexperiments demonstrate that BR-Gen constructs entirely new scenarios that are\nnot covered by existing methods. Take a step further, NFA-ViT outperforms\nexisting methods on BR-Gen and generalizes well across current benchmarks. All\ndata and codes are available at https://github.com/clpbc/BR-Gen.", "published": "2025-04-16 09:57:23", "link": "http://arxiv.org/abs/2504.11922v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AnomalyR1: A GRPO-based End-to-end MLLM for Industrial Anomaly Detection", "abstract": "Industrial Anomaly Detection (IAD) poses a formidable challenge due to the\nscarcity of defective samples, making it imperative to deploy models capable of\nrobust generalization to detect unseen anomalies effectively. Traditional\napproaches, often constrained by hand-crafted features or domain-specific\nexpert models, struggle to address this limitation, underscoring the need for a\nparadigm shift. We introduce AnomalyR1, a pioneering framework that leverages\nVLM-R1, a Multimodal Large Language Model (MLLM) renowned for its exceptional\ngeneralization and interpretability, to revolutionize IAD. By integrating MLLM\nwith Group Relative Policy Optimization (GRPO), enhanced by our novel Reasoned\nOutcome Alignment Metric (ROAM), AnomalyR1 achieves a fully end-to-end solution\nthat autonomously processes inputs of image and domain knowledge, reasons\nthrough analysis, and generates precise anomaly localizations and masks. Based\non the latest multimodal IAD benchmark, our compact 3-billion-parameter model\noutperforms existing methods, establishing state-of-the-art results. As MLLM\ncapabilities continue to advance, this study is the first to deliver an\nend-to-end VLM-based IAD solution that demonstrates the transformative\npotential of ROAM-enhanced GRPO, positioning our framework as a forward-looking\ncornerstone for next-generation intelligent anomaly detection systems in\nindustrial applications with limited defective data.", "published": "2025-04-16 09:48:41", "link": "http://arxiv.org/abs/2504.11914v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Search is All You Need for Few-shot Anomaly Detection", "abstract": "Few-shot anomaly detection (FSAD) has emerged as a crucial yet challenging\ntask in industrial inspection, where normal distribution modeling must be\naccomplished with only a few normal images. While existing approaches typically\nemploy multi-modal foundation models combining language and vision modalities\nfor prompt-guided anomaly detection, these methods often demand sophisticated\nprompt engineering and extensive manual tuning. In this paper, we demonstrate\nthat a straightforward nearest-neighbor search framework can surpass\nstate-of-the-art performance in both single-class and multi-class FSAD\nscenarios. Our proposed method, VisionAD, consists of four simple yet essential\ncomponents: (1) scalable vision foundation models that extract universal and\ndiscriminative features; (2) dual augmentation strategies - support\naugmentation to enhance feature matching adaptability and query augmentation to\naddress the oversights of single-view prediction; (3) multi-layer feature\nintegration that captures both low-frequency global context and high-frequency\nlocal details with minimal computational overhead; and (4) a class-aware visual\nmemory bank enabling efficient one-for-all multi-class detection. Extensive\nevaluations across MVTec-AD, VisA, and Real-IAD benchmarks demonstrate\nVisionAD's exceptional performance. Using only 1 normal images as support, our\nmethod achieves remarkable image-level AUROC scores of 97.4%, 94.8%, and 70.8%\nrespectively, outperforming current state-of-the-art approaches by significant\nmargins (+1.6%, +3.2%, and +1.4%). The training-free nature and superior\nfew-shot capabilities of VisionAD make it particularly appealing for real-world\napplications where samples are scarce or expensive to obtain. Code is available\nat https://github.com/Qiqigeww/VisionAD.", "published": "2025-04-16 09:21:34", "link": "http://arxiv.org/abs/2504.11895v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CAGS: Open-Vocabulary 3D Scene Understanding with Context-Aware Gaussian Splatting", "abstract": "Open-vocabulary 3D scene understanding is crucial for applications requiring\nnatural language-driven spatial interpretation, such as robotics and augmented\nreality. While 3D Gaussian Splatting (3DGS) offers a powerful representation\nfor scene reconstruction, integrating it with open-vocabulary frameworks\nreveals a key challenge: cross-view granularity inconsistency. This issue,\nstemming from 2D segmentation methods like SAM, results in inconsistent object\nsegmentations across views (e.g., a \"coffee set\" segmented as a single entity\nin one view but as \"cup + coffee + spoon\" in another). Existing 3DGS-based\nmethods often rely on isolated per-Gaussian feature learning, neglecting the\nspatial context needed for cohesive object reasoning, leading to fragmented\nrepresentations. We propose Context-Aware Gaussian Splatting (CAGS), a novel\nframework that addresses this challenge by incorporating spatial context into\n3DGS. CAGS constructs local graphs to propagate contextual features across\nGaussians, reducing noise from inconsistent granularity, employs mask-centric\ncontrastive learning to smooth SAM-derived features across views, and leverages\na precomputation strategy to reduce computational cost by precomputing\nneighborhood relationships, enabling efficient training in large-scale scenes.\nBy integrating spatial context, CAGS significantly improves 3D instance\nsegmentation and reduces fragmentation errors on datasets like LERF-OVS and\nScanNet, enabling robust language-guided 3D scene understanding.", "published": "2025-04-16 09:20:03", "link": "http://arxiv.org/abs/2504.11893v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Compatible Multi-Prize Subnetworks for Asymmetric Retrieval", "abstract": "Asymmetric retrieval is a typical scenario in real-world retrieval systems,\nwhere compatible models of varying capacities are deployed on platforms with\ndifferent resource configurations. Existing methods generally train pre-defined\nnetworks or subnetworks with capacities specifically designed for\npre-determined platforms, using compatible learning. Nevertheless, these\nmethods suffer from limited flexibility for multi-platform deployment. For\nexample, when introducing a new platform into the retrieval systems, developers\nhave to train an additional model at an appropriate capacity that is compatible\nwith existing models via backward-compatible learning. In this paper, we\npropose a Prunable Network with self-compatibility, which allows developers to\ngenerate compatible subnetworks at any desired capacity through post-training\npruning. Thus it allows the creation of a sparse subnetwork matching the\nresources of the new platform without additional training. Specifically, we\noptimize both the architecture and weight of subnetworks at different\ncapacities within a dense network in compatible learning. We also design a\nconflict-aware gradient integration scheme to handle the gradient conflicts\nbetween the dense network and subnetworks during compatible learning. Extensive\nexperiments on diverse benchmarks and visual backbones demonstrate the\neffectiveness of our method. Our code and model are available at\nhttps://github.com/Bunny-Black/PrunNet.", "published": "2025-04-16 08:59:47", "link": "http://arxiv.org/abs/2504.11879v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Category-Fragment Segmentation Framework for Pelvic Fracture Segmentation in X-ray Images", "abstract": "Pelvic fractures, often caused by high-impact trauma, frequently require\nsurgical intervention. Imaging techniques such as CT and 2D X-ray imaging are\nused to transfer the surgical plan to the operating room through image\nregistration, enabling quick intraoperative adjustments. Specifically,\nsegmenting pelvic fractures from 2D X-ray imaging can assist in accurately\npositioning bone fragments and guiding the placement of screws or metal plates.\nIn this study, we propose a novel deep learning-based category and fragment\nsegmentation (CFS) framework for the automatic segmentation of pelvic bone\nfragments in 2D X-ray images. The framework consists of three consecutive\nsteps: category segmentation, fragment segmentation, and post-processing. Our\nbest model achieves an IoU of 0.91 for anatomical structures and 0.78 for\nfracture segmentation. Results demonstrate that the CFS framework is effective\nand accurate.", "published": "2025-04-16 08:49:22", "link": "http://arxiv.org/abs/2504.11872v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Synthetic Data for Blood Vessel Network Extraction", "abstract": "Blood vessel networks in the brain play a crucial role in stroke research,\nwhere understanding their topology is essential for analyzing blood flow\ndynamics. However, extracting detailed topological vessel network information\nfrom microscopy data remains a significant challenge, mainly due to the\nscarcity of labeled training data and the need for high topological accuracy.\nThis work combines synthetic data generation with deep learning to\nautomatically extract vessel networks as graphs from volumetric microscopy\ndata. To combat data scarcity, we introduce a comprehensive pipeline for\ngenerating large-scale synthetic datasets that mirror the characteristics of\nreal vessel networks. Our three-stage approach progresses from abstract graph\ngeneration through vessel mask creation to realistic medical image synthesis,\nincorporating biological constraints and imaging artifacts at each stage. Using\nthis synthetic data, we develop a two-stage deep learning pipeline of 3D\nU-Net-based models for node detection and edge prediction. Fine-tuning on real\nmicroscopy data shows promising adaptation, improving edge prediction F1 scores\nfrom 0.496 to 0.626 by training on merely 5 manually labeled samples. These\nresults suggest that automated vessel network extraction is becoming\npractically feasible, opening new possibilities for large-scale vascular\nanalysis in stroke research.", "published": "2025-04-16 08:29:46", "link": "http://arxiv.org/abs/2504.11858v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Cross-Frequency Collaborative Training Network and Dataset for Semi-supervised First Molar Root Canal Segmentation", "abstract": "Root canal (RC) treatment is a highly delicate and technically complex\nprocedure in clinical practice, heavily influenced by the clinicians'\nexperience and subjective judgment. Deep learning has made significant\nadvancements in the field of computer-aided diagnosis (CAD) because it can\nprovide more objective and accurate diagnostic results. However, its\napplication in RC treatment is still relatively rare, mainly due to the lack of\npublic datasets in this field. To address this issue, in this paper, we\nestablished a First Molar Root Canal segmentation dataset called FMRC-2025.\nAdditionally, to alleviate the workload of manual annotation for dentists and\nfully leverage the unlabeled data, we designed a Cross-Frequency Collaborative\ntraining semi-supervised learning (SSL) Network called CFC-Net. It consists of\ntwo components: (1) Cross-Frequency Collaborative Mean Teacher (CFC-MT), which\nintroduces two specialized students (SS) and one comprehensive teacher (CT) for\ncollaborative multi-frequency training. The CT and SS are trained on different\nfrequency components while fully integrating multi-frequency knowledge through\ncross and full frequency consistency supervisions. (2) Uncertainty-guided\nCross-Frequency Mix (UCF-Mix) mechanism enables the network to generate\nhigh-confidence pseudo-labels while learning to integrate multi-frequency\ninformation and maintaining the structural integrity of the targets. Extensive\nexperiments on FMRC-2025 and three public dental datasets demonstrate that\nCFC-MT is effective for RC segmentation and can also exhibit strong\ngeneralizability on other dental segmentation tasks, outperforming\nstate-of-the-art SSL medical image segmentation methods. Codes and dataset will\nbe released.", "published": "2025-04-16 08:24:42", "link": "http://arxiv.org/abs/2504.11856v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ACE: Attentional Concept Erasure in Diffusion Models", "abstract": "Large text-to-image diffusion models have demonstrated remarkable image\nsynthesis capabilities, but their indiscriminate training on Internet-scale\ndata has led to learned concepts that enable harmful, copyrighted, or otherwise\nundesirable content generation. We address the task of concept erasure in\ndiffusion models, i.e., removing a specified concept from a pre-trained model\nsuch that prompting the concept (or related synonyms) no longer yields its\ndepiction, while preserving the model's ability to generate other content. We\npropose a novel method, Attentional Concept Erasure (ACE), that integrates a\nclosed-form attention manipulation with lightweight fine-tuning. Theoretically,\nwe formulate concept erasure as aligning the model's conditional distribution\non the target concept with a neutral distribution. Our approach identifies and\nnullifies concept-specific latent directions in the cross-attention modules via\na gated low-rank adaptation, followed by adversarially augmented fine-tuning to\nensure thorough erasure of the concept and its synonyms. Empirically, we\ndemonstrate on multiple benchmarks, including object classes, celebrity faces,\nexplicit content, and artistic styles, that ACE achieves state-of-the-art\nconcept removal efficacy and robustness. Compared to prior methods, ACE better\nbalances generality (erasing concept and related terms) and specificity\n(preserving unrelated content), scales to dozens of concepts, and is efficient,\nrequiring only a few seconds of adaptation per concept. We will release our\ncode to facilitate safer deployment of diffusion models.", "published": "2025-04-16 08:16:28", "link": "http://arxiv.org/abs/2504.11850v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Boosting Multi-View Stereo with Depth Foundation Model in the Absence of Real-World Labels", "abstract": "Learning-based Multi-View Stereo (MVS) methods have made remarkable progress\nin recent years. However, how to effectively train the network without using\nreal-world labels remains a challenging problem. In this paper, driven by the\nrecent advancements of vision foundation models, a novel method termed DFM-MVS,\nis proposed to leverage the depth foundation model to generate the effective\ndepth prior, so as to boost MVS in the absence of real-world labels.\nSpecifically, a depth prior-based pseudo-supervised training mechanism is\ndeveloped to simulate realistic stereo correspondences using the generated\ndepth prior, thereby constructing effective supervision for the MVS network.\nBesides, a depth prior-guided error correction strategy is presented to\nleverage the depth prior as guidance to mitigate the error propagation problem\ninherent in the widely-used coarse-to-fine network structure. Experimental\nresults on DTU and Tanks & Temples datasets demonstrate that the proposed\nDFM-MVS significantly outperforms existing MVS methods without using real-world\nlabels.", "published": "2025-04-16 08:07:09", "link": "http://arxiv.org/abs/2504.11845v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Visual RAG Pipeline for Few-Shot Fine-Grained Product Classification", "abstract": "Despite the rapid evolution of learning and computer vision algorithms,\nFine-Grained Classification (FGC) still poses an open problem in many\npractically relevant applications. In the retail domain, for example, the\nidentification of fast changing and visually highly similar products and their\nproperties are key to automated price-monitoring and product recommendation.\nThis paper presents a novel Visual RAG pipeline that combines the Retrieval\nAugmented Generation (RAG) approach and Vision Language Models (VLMs) for\nfew-shot FGC. This Visual RAG pipeline extracts product and promotion data in\nadvertisement leaflets from various retailers and simultaneously predicts\nfine-grained product ids along with price and discount information. Compared to\nprevious approaches, the key characteristic of the Visual RAG pipeline is that\nit allows the prediction of novel products without re-training, simply by\nadding a few class samples to the RAG database. Comparing several VLM back-ends\nlike GPT-4o [23], GPT-4o-mini [24], and Gemini 2.0 Flash [10], our approach\nachieves 86.8% accuracy on a diverse dataset.", "published": "2025-04-16 07:53:50", "link": "http://arxiv.org/abs/2504.11838v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TextDiffSeg: Text-guided Latent Diffusion Model for 3d Medical Images Segmentation", "abstract": "Diffusion Probabilistic Models (DPMs) have demonstrated significant potential\nin 3D medical image segmentation tasks. However, their high computational cost\nand inability to fully capture global 3D contextual information limit their\npractical applications. To address these challenges, we propose a novel\ntext-guided diffusion model framework, TextDiffSeg. This method leverages a\nconditional diffusion framework that integrates 3D volumetric data with natural\nlanguage descriptions, enabling cross-modal embedding and establishing a shared\nsemantic space between visual and textual modalities. By enhancing the model's\nability to recognize complex anatomical structures, TextDiffSeg incorporates\ninnovative label embedding techniques and cross-modal attention mechanisms,\neffectively reducing computational complexity while preserving global 3D\ncontextual integrity. Experimental results demonstrate that TextDiffSeg\nconsistently outperforms existing methods in segmentation tasks involving\nkidney and pancreas tumors, as well as multi-organ segmentation scenarios.\nAblation studies further validate the effectiveness of key components,\nhighlighting the synergistic interaction between text fusion, image feature\nextractor, and label encoder. TextDiffSeg provides an efficient and accurate\nsolution for 3D medical image segmentation, showcasing its broad applicability\nin clinical diagnosis and treatment planning.", "published": "2025-04-16 07:17:36", "link": "http://arxiv.org/abs/2504.11825v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Neighbor-Based Feature and Index Enhancement for Person Re-Identification", "abstract": "Person re-identification (Re-ID) aims to match the same pedestrian in a large\ngallery with different cameras and views. Enhancing the robustness of the\nextracted feature representations is a main challenge in Re-ID. Existing\nmethods usually improve feature representation by improving model architecture,\nbut most methods ignore the potential contextual information, which limits the\neffectiveness of feature representation and retrieval performance. Neighborhood\ninformation, especially the potential information of multi-order neighborhoods,\ncan effectively enrich feature expression and improve retrieval accuracy, but\nthis has not been fully explored in existing research. Therefore, we propose a\nnovel model DMON-ARO that leverages latent neighborhood information to enhance\nboth feature representation and index performance. Our approach is built on two\ncomplementary modules: Dynamic Multi-Order Neighbor Modeling (DMON) and\nAsymmetric Relationship Optimization (ARO). The DMON module dynamically\naggregates multi-order neighbor relationships, allowing it to capture richer\ncontextual information and enhance feature representation through adaptive\nneighborhood modeling. Meanwhile, ARO refines the distance matrix by optimizing\nquery-to-gallery relationships, improving the index accuracy. Extensive\nexperiments on three benchmark datasets demonstrate that our approach achieves\nperformance improvements against baseline models, which illustrate the\neffectiveness of our model. Specifically, our model demonstrates improvements\nin Rank-1 accuracy and mAP. Moreover, this method can also be directly extended\nto other re-identification tasks.", "published": "2025-04-16 06:13:20", "link": "http://arxiv.org/abs/2504.11798v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DART: Disease-aware Image-Text Alignment and Self-correcting Re-alignment for Trustworthy Radiology Report Generation", "abstract": "The automatic generation of radiology reports has emerged as a promising\nsolution to reduce a time-consuming task and accurately capture critical\ndisease-relevant findings in X-ray images. Previous approaches for radiology\nreport generation have shown impressive performance. However, there remains\nsignificant potential to improve accuracy by ensuring that retrieved reports\ncontain disease-relevant findings similar to those in the X-ray images and by\nrefining generated reports. In this study, we propose a Disease-aware\nimage-text Alignment and self-correcting Re-alignment for Trustworthy radiology\nreport generation (DART) framework. In the first stage, we generate initial\nreports based on image-to-text retrieval with disease-matching, embedding both\nimages and texts in a shared embedding space through contrastive learning. This\napproach ensures the retrieval of reports with similar disease-relevant\nfindings that closely align with the input X-ray images. In the second stage,\nwe further enhance the initial reports by introducing a self-correction module\nthat re-aligns them with the X-ray images. Our proposed framework achieves\nstate-of-the-art results on two widely used benchmarks, surpassing previous\napproaches in both report generation and clinical efficacy metrics, thereby\nenhancing the trustworthiness of radiology reports.", "published": "2025-04-16 05:39:08", "link": "http://arxiv.org/abs/2504.11786v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multimodal Spatio-temporal Graph Learning for Alignment-free RGBT Video Object Detection", "abstract": "RGB-Thermal Video Object Detection (RGBT VOD) can address the limitation of\ntraditional RGB-based VOD in challenging lighting conditions, making it more\npractical and effective in many applications.\n  However, similar to most RGBT fusion tasks, it still mainly relies on\nmanually aligned multimodal image pairs.\n  In this paper, we propose a novel Multimodal Spatio-temporal Graph learning\nNetwork (MSGNet) for alignment-free RGBT VOD problem by leveraging the robust\ngraph representation learning model.\n  Specifically, we first design an Adaptive Partitioning Layer (APL) to\nestimate the corresponding regions of the Thermal image within the RGB image\n(high-resolution), achieving a preliminary inexact alignment.\n  Then, we introduce the Spatial Sparse Graph Learning Module (S-SGLM) which\nemploys a sparse information passing mechanism on the estimated inexact\nalignment to achieve reliable information interaction between different\nmodalities.\n  Moreover, to fully exploit the temporal cues for RGBT VOD problem, we\nintroduce Hybrid Structured Temporal Modeling (HSTM), which involves a Temporal\nSparse Graph Learning Module (T-SGLM) and Temporal Star Block (TSB). T-SGLM\naims to filter out some redundant information between adjacent frames by\nemploying the sparse aggregation mechanism on the temporal graph. Meanwhile,\nTSB is dedicated to achieving the complementary learning of local spatial\nrelationships.\n  Extensive comparative experiments conducted on both the aligned dataset\nVT-VOD50 and the unaligned dataset UVT-VOD2024 demonstrate the effectiveness\nand superiority of our proposed method. Our project will be made available on\nour website for free public access.", "published": "2025-04-16 05:32:59", "link": "http://arxiv.org/abs/2504.11779v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bridging the Semantic Gaps: Improving Medical VQA Consistency with LLM-Augmented Question Sets", "abstract": "Medical Visual Question Answering (MVQA) systems can interpret medical images\nin response to natural language queries. However, linguistic variability in\nquestion phrasing often undermines the consistency of these systems. To address\nthis challenge, we propose a Semantically Equivalent Question Augmentation\n(SEQA) framework, which leverages large language models (LLMs) to generate\ndiverse yet semantically equivalent rephrasings of questions. Specifically,\nthis approach enriches linguistic diversity while preserving semantic meaning.\nWe further introduce an evaluation metric, Total Agreement Rate with\nSemantically Equivalent Input and Correct Answer (TAR-SC), which assesses a\nmodel's capability to generate consistent and correct responses to semantically\nequivalent linguistic variations. In addition, we also propose three other\ndiversity metrics - average number of QA items per image (ANQI), average number\nof questions per image with the same answer (ANQA), and average number of\nopen-ended questions per image with the same semantics (ANQS). Using the SEQA\nframework, we augmented the benchmarked MVQA public datasets of SLAKE, VQA-RAD,\nand PathVQA. As a result, all three datasets achieved significant improvements\nby incorporating more semantically equivalent questions: ANQI increased by an\naverage of 86.1, ANQA by 85.1, and ANQS by 46. Subsequent experiments evaluate\nthree MVQA models (M2I2, MUMC, and BiomedGPT) under both zero-shot and\nfine-tuning settings on the enhanced datasets. Experimental results in MVQA\ndatasets show that fine-tuned models achieve an average accuracy improvement of\n19.35%, while our proposed TAR-SC metric shows an average improvement of 11.\n61%, indicating a substantial enhancement in model consistency.", "published": "2025-04-16 05:31:18", "link": "http://arxiv.org/abs/2504.11777v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TacoDepth: Towards Efficient Radar-Camera Depth Estimation with One-stage Fusion", "abstract": "Radar-Camera depth estimation aims to predict dense and accurate metric depth\nby fusing input images and Radar data. Model efficiency is crucial for this\ntask in pursuit of real-time processing on autonomous vehicles and robotic\nplatforms. However, due to the sparsity of Radar returns, the prevailing\nmethods adopt multi-stage frameworks with intermediate quasi-dense depth, which\nare time-consuming and not robust. To address these challenges, we propose\nTacoDepth, an efficient and accurate Radar-Camera depth estimation model with\none-stage fusion. Specifically, the graph-based Radar structure extractor and\nthe pyramid-based Radar fusion module are designed to capture and integrate the\ngraph structures of Radar point clouds, delivering superior model efficiency\nand robustness without relying on the intermediate depth results. Moreover,\nTacoDepth can be flexible for different inference modes, providing a better\nbalance of speed and accuracy. Extensive experiments are conducted to\ndemonstrate the efficacy of our method. Compared with the previous\nstate-of-the-art approach, TacoDepth improves depth accuracy and processing\nspeed by 12.8% and 91.8%. Our work provides a new perspective on efficient\nRadar-Camera depth estimation.", "published": "2025-04-16 05:25:04", "link": "http://arxiv.org/abs/2504.11773v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Extended Short- and Long-Range Mesh Learning for Fast and Generalized Garment Simulation", "abstract": "3D garment simulation is a critical component for producing cloth-based\ngraphics. Recent advancements in graph neural networks (GNNs) offer a promising\napproach for efficient garment simulation. However, GNNs require extensive\nmessage-passing to propagate information such as physical forces and maintain\ncontact awareness across the entire garment mesh, which becomes computationally\ninefficient at higher resolutions. To address this, we devise a novel GNN-based\nmesh learning framework with two key components to extend the message-passing\nrange with minimal overhead, namely the Laplacian-Smoothed Dual Message-Passing\n(LSDMP) and the Geodesic Self-Attention (GSA) modules. LSDMP enhances\nmessage-passing with a Laplacian features smoothing process, which efficiently\npropagates the impact of each vertex to nearby vertices. Concurrently, GSA\nintroduces geodesic distance embeddings to represent the spatial relationship\nbetween vertices and utilises attention mechanisms to capture global mesh\ninformation. The two modules operate in parallel to ensure both short- and\nlong-range mesh modelling. Extensive experiments demonstrate the\nstate-of-the-art performance of our method, requiring fewer layers and lower\ninference latency.", "published": "2025-04-16 04:56:01", "link": "http://arxiv.org/abs/2504.11763v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SkeletonX: Data-Efficient Skeleton-based Action Recognition via Cross-sample Feature Aggregation", "abstract": "While current skeleton action recognition models demonstrate impressive\nperformance on large-scale datasets, their adaptation to new application\nscenarios remains challenging. These challenges are particularly pronounced\nwhen facing new action categories, diverse performers, and varied skeleton\nlayouts, leading to significant performance degeneration. Additionally, the\nhigh cost and difficulty of collecting skeleton data make large-scale data\ncollection impractical. This paper studies one-shot and limited-scale learning\nsettings to enable efficient adaptation with minimal data. Existing approaches\noften overlook the rich mutual information between labeled samples, resulting\nin sub-optimal performance in low-data scenarios. To boost the utility of\nlabeled data, we identify the variability among performers and the commonality\nwithin each action as two key attributes. We present SkeletonX, a lightweight\ntraining pipeline that integrates seamlessly with existing GCN-based skeleton\naction recognizers, promoting effective training under limited labeled data.\nFirst, we propose a tailored sample pair construction strategy on two key\nattributes to form and aggregate sample pairs. Next, we develop a concise and\neffective feature aggregation module to process these pairs. Extensive\nexperiments are conducted on NTU RGB+D, NTU RGB+D 120, and PKU-MMD with various\nGCN backbones, demonstrating that the pipeline effectively improves performance\nwhen trained from scratch with limited data. Moreover, it surpasses previous\nstate-of-the-art methods in the one-shot setting, with only 1/10 of the\nparameters and much fewer FLOPs. The code and data are available at:\nhttps://github.com/zzysteve/SkeletonX", "published": "2025-04-16 04:01:42", "link": "http://arxiv.org/abs/2504.11749v1", "categories": ["cs.CV", "I.4.9"], "primary_category": "cs.CV"}
{"title": "Recent Advance in 3D Object and Scene Generation: A Survey", "abstract": "In recent years, the demand for 3D content has grown exponentially with\nintelligent upgrading of interactive media, extended reality (XR), and\nMetaverse industries. In order to overcome the limitation of traditional manual\nmodeling approaches, such as labor-intensive workflows and prolonged production\ncycles, revolutionary advances have been achieved through the convergence of\nnovel 3D representation paradigms and artificial intelligence generative\ntechnologies. In this survey, we conduct a systematically review of the\ncutting-edge achievements in static 3D object and scene generation, as well as\nestablish a comprehensive technical framework through systematic\ncategorization. Specifically, we initiate our analysis with mainstream 3D\nobject representations, followed by in-depth exploration of two principal\ntechnical pathways in object generation: data-driven supervised learning\nmethods and deep generative model-based approaches. Regarding scene generation,\nwe focus on three dominant paradigms: layout-guided compositional synthesis, 2D\nprior-based scene generation, and rule-driven modeling. Finally, we critically\nexamine persistent challenges in 3D generation and propose potential research\ndirections for future investigation. This survey aims to provide readers with a\nstructured understanding of state-of-the-art 3D generation technologies while\ninspiring researchers to undertake more exploration in this domain.", "published": "2025-04-16 03:22:06", "link": "http://arxiv.org/abs/2504.11734v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "DVLTA-VQA: Decoupled Vision-Language Modeling with Text-Guided Adaptation for Blind Video Quality Assessment", "abstract": "Inspired by the dual-stream theory of the human visual system (HVS) - where\nthe ventral stream is responsible for object recognition and detail analysis,\nwhile the dorsal stream focuses on spatial relationships and motion perception\n- an increasing number of video quality assessment (VQA) works built upon this\nframework are proposed. Recent advancements in large multi-modal models,\nnotably Contrastive Language-Image Pretraining (CLIP), have motivated\nresearchers to incorporate CLIP into dual-stream-based VQA methods. This\nintegration aims to harness the model's superior semantic understanding\ncapabilities to replicate the object recognition and detail analysis in ventral\nstream, as well as spatial relationship analysis in dorsal stream. However,\nCLIP is originally designed for images and lacks the ability to capture\ntemporal and motion information inherent in videos. %Furthermore, existing\nfeature fusion strategies in no-reference video quality assessment (NR-VQA)\noften rely on fixed weighting schemes, which fail to adaptively adjust feature\nimportance. To address the limitation, this paper propose a Decoupled\nVision-Language Modeling with Text-Guided Adaptation for Blind Video Quality\nAssessment (DVLTA-VQA), which decouples CLIP's visual and textual components,\nand integrates them into different stages of the NR-VQA pipeline.", "published": "2025-04-16 03:20:28", "link": "http://arxiv.org/abs/2504.11733v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EgoExo-Gen: Ego-centric Video Prediction by Watching Exo-centric Videos", "abstract": "Generating videos in the first-person perspective has broad application\nprospects in the field of augmented reality and embodied intelligence. In this\nwork, we explore the cross-view video prediction task, where given an\nexo-centric video, the first frame of the corresponding ego-centric video, and\ntextual instructions, the goal is to generate futur frames of the ego-centric\nvideo. Inspired by the notion that hand-object interactions (HOI) in\nego-centric videos represent the primary intentions and actions of the current\nactor, we present EgoExo-Gen that explicitly models the hand-object dynamics\nfor cross-view video prediction. EgoExo-Gen consists of two stages. First, we\ndesign a cross-view HOI mask prediction model that anticipates the HOI masks in\nfuture ego-frames by modeling the spatio-temporal ego-exo correspondence. Next,\nwe employ a video diffusion model to predict future ego-frames using the first\nego-frame and textual instructions, while incorporating the HOI masks as\nstructural guidance to enhance prediction quality. To facilitate training, we\ndevelop an automated pipeline to generate pseudo HOI masks for both ego- and\nexo-videos by exploiting vision foundation models. Extensive experiments\ndemonstrate that our proposed EgoExo-Gen achieves better prediction performance\ncompared to previous video prediction models on the Ego-Exo4D and H2O benchmark\ndatasets, with the HOI masks significantly improving the generation of hands\nand interactive objects in the ego-centric videos.", "published": "2025-04-16 03:12:39", "link": "http://arxiv.org/abs/2504.11732v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning What NOT to Count", "abstract": "Few/zero-shot object counting methods reduce the need for extensive\nannotations but often struggle to distinguish between fine-grained categories,\nespecially when multiple similar objects appear in the same scene. To address\nthis limitation, we propose an annotation-free approach that enables the\nseamless integration of new fine-grained categories into existing few/zero-shot\ncounting models. By leveraging latent generative models, we synthesize\nhigh-quality, category-specific crowded scenes, providing a rich training\nsource for adapting to new categories without manual labeling. Our approach\nintroduces an attention prediction network that identifies fine-grained\ncategory boundaries trained using only synthetic pseudo-annotated data. At\ninference, these fine-grained attention estimates refine the output of existing\nfew/zero-shot counting networks. To benchmark our method, we further introduce\nthe FGTC dataset, a taxonomy-specific fine-grained object counting dataset for\nnatural images. Our method substantially enhances pre-trained state-of-the-art\nmodels on fine-grained taxon counting tasks, while using only synthetic data.\nCode and data to be released upon acceptance.", "published": "2025-04-16 02:05:47", "link": "http://arxiv.org/abs/2504.11705v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Non-uniform Point Cloud Upsampling via Local Manifold Distribution", "abstract": "Existing learning-based point cloud upsampling methods often overlook the\nintrinsic data distribution charac?teristics of point clouds, leading to\nsuboptimal results when handling sparse and non-uniform point clouds. We\npropose a novel approach to point cloud upsampling by imposing constraints from\nthe perspective of manifold distributions. Leveraging the strong fitting\ncapability of Gaussian functions, our method employs a network to iteratively\noptimize Gaussian components and their weights, accurately representing local\nmanifolds. By utilizing the probabilistic distribution properties of Gaussian\nfunctions, we construct a unified statistical manifold to impose distribution\nconstraints on the point cloud. Experimental results on multiple datasets\ndemonstrate that our method generates higher-quality and more uniformly\ndistributed dense point clouds when processing sparse and non-uniform inputs,\noutperforming state-of-the-art point cloud upsampling techniques.", "published": "2025-04-16 01:54:33", "link": "http://arxiv.org/abs/2504.11701v1", "categories": ["cs.CV", "math.DG"], "primary_category": "cs.CV"}
{"title": "An Online Adaptation Method for Robust Depth Estimation and Visual Odometry in the Open World", "abstract": "Recently, learning-based robotic navigation systems have gained extensive\nresearch attention and made significant progress. However, the diversity of\nopen-world scenarios poses a major challenge for the generalization of such\nsystems to practical scenarios. Specifically, learned systems for scene\nmeasurement and state estimation tend to degrade when the application scenarios\ndeviate from the training data, resulting to unreliable depth and pose\nestimation. Toward addressing this problem, this work aims to develop a visual\nodometry system that can fast adapt to diverse novel environments in an online\nmanner. To this end, we construct a self-supervised online adaptation framework\nfor monocular visual odometry aided by an online-updated depth estimation\nmodule. Firstly, we design a monocular depth estimation network with\nlightweight refiner modules, which enables efficient online adaptation. Then,\nwe construct an objective for self-supervised learning of the depth estimation\nmodule based on the output of the visual odometry system and the contextual\nsemantic information of the scene. Specifically, a sparse depth densification\nmodule and a dynamic consistency enhancement module are proposed to leverage\ncamera poses and contextual semantics to generate pseudo-depths and valid masks\nfor the online adaptation. Finally, we demonstrate the robustness and\ngeneralization capability of the proposed method in comparison with\nstate-of-the-art learning-based approaches on urban, in-house datasets and a\nrobot platform. Code is publicly available at:\nhttps://github.com/jixingwu/SOL-SLAM.", "published": "2025-04-16 01:48:10", "link": "http://arxiv.org/abs/2504.11698v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Interpreting the Linear Structure of Vision-language Model Embedding Spaces", "abstract": "Vision-language models encode images and text in a joint space, minimizing\nthe distance between corresponding image and text pairs. How are language and\nimages organized in this joint space, and how do the models encode meaning and\nmodality? To investigate this, we train and release sparse autoencoders (SAEs)\non the embedding spaces of four vision-language models (CLIP, SigLIP, SigLIP2,\nand AIMv2). SAEs approximate model embeddings as sparse linear combinations of\nlearned directions, or \"concepts\". We find that, compared to other methods of\nlinear feature learning, SAEs are better at reconstructing the real embeddings,\nwhile also able to retain the most sparsity. Retraining SAEs with different\nseeds or different data diet leads to two findings: the rare, specific concepts\ncaptured by the SAEs are liable to change drastically, but we also show that\nthe key commonly-activating concepts extracted by SAEs are remarkably stable\nacross runs. Interestingly, while most concepts are strongly unimodal in\nactivation, we find they are not merely encoding modality per se. Many lie\nclose to - but not entirely within - the subspace defining modality, suggesting\nthat they encode cross-modal semantics despite their unimodal usage. To\nquantify this bridging behavior, we introduce the Bridge Score, a metric that\nidentifies concept pairs which are both co-activated across aligned image-text\ninputs and geometrically aligned in the shared space. This reveals that even\nunimodal concepts can collaborate to support cross-modal integration. We\nrelease interactive demos of the SAEs for all models, allowing researchers to\nexplore the organization of the concept spaces. Overall, our findings uncover a\nsparse linear structure within VLM embedding spaces that is shaped by modality,\nyet stitched together through latent bridges-offering new insight into how\nmultimodal meaning is constructed.", "published": "2025-04-16 01:40:06", "link": "http://arxiv.org/abs/2504.11695v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "DM-OSVP++: One-Shot View Planning Using 3D Diffusion Models for Active RGB-Based Object Reconstruction", "abstract": "Active object reconstruction is crucial for many robotic applications. A key\naspect in these scenarios is generating object-specific view configurations to\nobtain informative measurements for reconstruction. One-shot view planning\nenables efficient data collection by predicting all views at once, eliminating\nthe need for time-consuming online replanning. Our primary insight is to\nleverage the generative power of 3D diffusion models as valuable prior\ninformation. By conditioning on initial multi-view images, we exploit the\npriors from the 3D diffusion model to generate an approximate object model,\nserving as the foundation for our view planning. Our novel approach integrates\nthe geometric and textural distributions of the object model into the view\nplanning process, generating views that focus on the complex parts of the\nobject to be reconstructed. We validate the proposed active object\nreconstruction system through both simulation and real-world experiments,\ndemonstrating the effectiveness of using 3D diffusion priors for one-shot view\nplanning.", "published": "2025-04-16 00:14:52", "link": "http://arxiv.org/abs/2504.11674v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Set families: restricted distances via restricted intersections", "abstract": "Denote by $f_D(n)$ the maximum size of a set family $\\mathcal{F}$ on $[n] =\n\\{1, \\dots, n\\}$ with distance set $D$. That is, $|A \\bigtriangleup B| \\in D$\nholds for every pair of distinct sets $A, B \\in \\mathcal{F}$. Kleitman's\ncelebrated discrete isodiametric inequality states that $f_D(n)$ is maximized\nat Hamming balls of radius $d/2$ when $D = \\{1, \\dots, d\\}$. We study the\ngeneralization where $D$ is a set of arithmetic progression and determine\n$f_D(n)$ asymptotically for all homogeneous $D$. In the special case when $D$\nis an interval, our result confirms a conjecture of Huang, Klurman, and\nPohoata. Moreover, we demonstrate a dichotomy in the growth of $f_D(n)$,\nshowing linear growth in $n$ when $D$ is a non-homogeneous arithmetic\nprogression. Different from previous combinatorial and spectral approaches, we\ndeduce our results by converting the restricted distance problems to restricted\nintersection problems.\n  Our proof ideas can be adapted to prove upper bounds on $t$-distance sets in\nHamming cubes (also known as binary $t$-codes), which has been extensively\nstudied by algebraic combinatorialists community, improving previous bounds\nfrom polynomial methods and optimization approaches.", "published": "2025-04-16 17:56:56", "link": "http://arxiv.org/abs/2504.12296v1", "categories": ["math.CO", "cs.DM", "05D05 (primary), 94B25, 05C35, 52C10"], "primary_category": "math.CO"}
{"title": "The Gray graph is pseudo 2-factor isomorphic", "abstract": "A graph is pseudo 2-factor isomorphic if all of its 2-factors have the same\nparity of number of cycles. Abreu et al. [J. Comb. Theory, Ser. B. 98 (2008)\n432--442] conjectured that $K_{3,3}$, the Heawood graph and the Pappus graph\nare the only essentially 4-edge-connected pseudo 2-factor isomorphic cubic\nbipartite graphs. This conjecture was disproved by Goedgebeur [Discr. Appl.\nMath. 193 (2015) 57--60] who constructed a counterexample $\\mathcal{G}$ (of\ngirth 6) on 30 vertices. Using a computer search, he also showed that this is\nthe only counterexample up to at least 40 vertices and that there are no\ncounterexamples of girth greater than 6 up to at least 48 vertices.\n  In this manuscript, we show that the Gray graph -- which has 54 vertices and\ngirth 8 -- is also a counterexample to the pseudo 2-factor isomorphic graph\nconjecture. Next to the graph $\\mathcal{G}$, this is the only other known\ncounterexample. Using a computer search, we show that there are no smaller\ncounterexamples of girth 8 and show that there are no other counterexamples up\nto at least 42 vertices of any girth. Moreover, we also verified that there are\nno further counterexamples among the known censuses of symmetrical graphs.\n  Recall that a graph is 2-factor Hamiltonian if all of its 2-factors are\nHamiltonian cycles. As a by-product of the computer searches performed for this\npaper, we have verified that the $2$-factor Hamiltonian conjecture of Funk et\nal. [J. Comb. Theory, Ser. B. 87(1) (2003) 138--144], which is still open,\nholds for cubic bipartite graphs of girth at least 8 up to 52 vertices, and up\nto 42 vertices for any girth.", "published": "2025-04-16 13:59:43", "link": "http://arxiv.org/abs/2504.12095v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "On the Regularity of Random 2-SAT and 3-SAT", "abstract": "We consider the random $k$-SAT problem with $n$ variables, $m=m(n)$ clauses,\nand clause density $\\alpha=\\lim_{n\\to\\infty}m/n$ for $k=2,3$. It is known that\nif $\\alpha$ is small enough, then the random $k$-SAT problem admits a solution\nwith high probability, which we interpret as the problem being\nunder-constrained. In this paper, we quantify exactly how under-constrained the\nrandom $k$-SAT problems are by determining their degrees of freedom, which we\ndefine as the threshold for the number of variables we can fix to an arbitrary\nvalue before the problem no longer is solvable with high probability. We show\nthat the random $2$-SAT and $3$-SAT problems have $n/m^{1/2}$ and $n/m^{1/3}$\ndegrees of freedom, respectively. Our main result is an explicit computation of\nthe corresponding threshold functions. Our result shows that the threshold\nfunction for the random $2$-SAT problem is regular, while it is non-regular for\nthe random $3$-SAT problem. By regular, we mean continuous and analytic on the\ninterior of its support. This result shows that the random $3$-SAT problem is\nmore sensitive to small changes in the clause density $\\alpha$ than the random\n$2$-SAT problem.", "published": "2025-04-16 11:17:56", "link": "http://arxiv.org/abs/2504.11979v1", "categories": ["math.PR", "cs.DM", "60K35 (Primary) 82B26, 68R07 (Secondary)"], "primary_category": "math.PR"}
{"title": "Dividing sums of cycles in the semiring of functional digraphs", "abstract": "Functional digraphs are unlabelled finite digraphs where each vertex has\nexactly one out-neighbor. They are isomorphic classes of finite discrete-time\ndynamical systems. Endowed with the direct sum and product, functional digraphs\nform a semiring with an interesting multiplicative structure. For instance, we\ndo not know if the following division problem can be solved in polynomial time:\ngiven two functional digraphs $A$ and $B$, does $A$ divide $B$? That $A$\ndivides $B$ means that there exists a functional digraph $X$ such that $AX$ is\nisomorphic to $B$, and many such $X$ can exist. We can thus ask for the number\nof solutions $X$. In this paper, we focus on the case where $B$ is a sum of\ncycles (a disjoint union of cycles, corresponding to the limit behavior of\nfinite discrete-time dynamical systems). There is then a na\\\"ive\nsub-exponential algorithm to compute the non-isomorphic solutions $X$, and our\nmain result is an improvement of this algorithm which has the property to be\npolynomial when $A$ is fixed. It uses a divide-and-conquer technique that\nshould be useful for further developments on the division problem.", "published": "2025-04-16 10:22:56", "link": "http://arxiv.org/abs/2504.11943v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Enumeration of Bases in Matroid with Exponentially Large Ground Set", "abstract": "When we deal with a matroid ${\\mathcal M}=(U,{\\mathcal I})$, we usually\nassume that it is implicitly given by means of the membership (MEM) oracle.\nMany existing efficient algorithms run in polynomial time with respect to $|U|$\nand the running time of the MEM-oracle. However, they are not efficient any\nmore when $U$ is exponentially large in some context. In this paper, we study\ntwo problems of enumerating bases in such matroids. First, we present an\nincremental-polynomial algorithm that enumerates all minimum-weighted bases,\nwhere the bounding polynomial does not depend on $|U|$. To design the\nalgorithm, we assume two oracles other than the MEM-oracle: the MinB-oracle\nthat returns a minimum basis and the REL-oracle that returns a relevant element\none by one in non-decreasing order of weight. The proposed algorithm is\napplicable to enumeration of minimum bases of binary matroids from cycle space,\npath space and cut space, all of which have exponentially large $U$ with\nrespect to a given graph. The highlight in this context is that, to design the\nREL-oracle for cut space, we develop the first polynomial-delay algorithm that\nenumerates all relevant cuts of a given graph in non-decreasing order of\nweight. Finally, we present a polynomial-delay algorithm that enumerates all\nsets of linearly independent $r$-dimensional $r$ vectors over $\\mathit{GF}(2)$.\nUsing the algorithm, we can enumerate all unweighted bases of a binary matroid\nsuch that elements are closed under addition, in polynomial-delay with respect\nto the matroid rank $r$.", "published": "2025-04-16 03:05:39", "link": "http://arxiv.org/abs/2504.11728v1", "categories": ["cs.DS", "cs.DM", "G.2.2"], "primary_category": "cs.DS"}
{"title": "Clarifying Ambiguities: on the Role of Ambiguity Types in Prompting Methods for Clarification Generation", "abstract": "In information retrieval (IR), providing appropriate clarifications to better\nunderstand users' information needs is crucial for building a proactive\nsearch-oriented dialogue system. Due to the strong in-context learning ability\nof large language models (LLMs), recent studies investigate prompting methods\nto generate clarifications using few-shot or Chain of Thought (CoT) prompts.\nHowever, vanilla CoT prompting does not distinguish the characteristics of\ndifferent information needs, making it difficult to understand how LLMs resolve\nambiguities in user queries. In this work, we focus on the concept of ambiguity\nfor clarification, seeking to model and integrate ambiguities in the\nclarification process. To this end, we comprehensively study the impact of\nprompting schemes based on reasoning and ambiguity for clarification. The idea\nis to enhance the reasoning abilities of LLMs by limiting CoT to predict first\nambiguity types that can be interpreted as instructions to clarify, then\ncorrespondingly generate clarifications. We name this new prompting scheme\nAmbiguity Type-Chain of Thought (AT-CoT). Experiments are conducted on various\ndatasets containing human-annotated clarifying questions to compare AT-CoT with\nmultiple baselines. We also perform user simulations to implicitly measure the\nquality of generated clarifications under various IR scenarios.", "published": "2025-04-16 14:21:02", "link": "http://arxiv.org/abs/2504.12113v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "R\u00e9sum\u00e9 abstractif \u00e0 partir d'une transcription audio", "abstract": "Currently, large language models are gaining popularity, their achievements\nare used in many areas, ranging from text translation to generating answers to\nqueries. However, the main problem with these new machine learning algorithms\nis that training such models requires large computing resources that only large\nIT companies have. To avoid this problem, a number of methods (LoRA,\nquantization) have been proposed so that existing models can be effectively\nfine-tuned for specific tasks. In this paper, we propose an E2E (end to end)\naudio summarization model using these techniques. In addition, this paper\nexamines the effectiveness of these approaches to the problem under\nconsideration and draws conclusions about the applicability of these methods.", "published": "2025-04-16 06:24:49", "link": "http://arxiv.org/abs/2504.11803v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A New Paradigm of User-Centric Wireless Communication Driven by Large Language Models", "abstract": "The next generation of wireless communications seeks to deeply integrate\nartificial intelligence (AI) with user-centric communication networks, with the\ngoal of developing AI-native networks that more accurately address user\nrequirements. The rapid development of large language models (LLMs) offers\nsignificant potential in realizing these goals. However, existing efforts that\nleverage LLMs for wireless communication often overlook the considerable gap\nbetween human natural language and the intricacies of real-world communication\nsystems, thus failing to fully exploit the capabilities of LLMs. To address\nthis gap, we propose a novel LLM-driven paradigm for wireless communication\nthat innovatively incorporates the nature language to structured query language\n(NL2SQL) tool. Specifically, in this paradigm, user personal requirements is\nthe primary focus. Upon receiving a user request, LLMs first analyze the user\nintent in terms of relevant communication metrics and system parameters.\nSubsequently, a structured query language (SQL) statement is generated to\nretrieve the specific parameter values from a high-performance real-time\ndatabase. We further utilize LLMs to formulate and solve an optimization\nproblem based on the user request and the retrieved parameters. The solution to\nthis optimization problem then drives adjustments in the communication system\nto fulfill the user's requirements. To validate the feasibility of the proposed\nparadigm, we present a prototype system. In this prototype, we consider\nuser-request centric semantic communication (URC-SC) system in which a dynamic\nsemantic representation network at the physical layer adapts its encoding depth\nto meet user requirements. Additionally, two LLMs are employed to analyze user\nrequests and generate SQL statements, respectively. Simulation results\ndemonstrate the effectiveness.", "published": "2025-04-16 01:43:36", "link": "http://arxiv.org/abs/2504.11696v1", "categories": ["cs.NI", "cs.IR", "cs.SY", "eess.SY"], "primary_category": "cs.NI"}
{"title": "Kernels for Storage Capacity and Dual Index Coding", "abstract": "The storage capacity of a graph measures the maximum amount of information\nthat can be stored across its vertices, such that the information at any vertex\ncan be recovered from the information stored at its neighborhood. The study of\nthis graph quantity is motivated by applications in distributed storage and by\nits intimate relations to the index coding problem from the area of network\ninformation theory. In the latter, one wishes to minimize the amount of\ninformation that has to be transmitted to a collection of receivers, in a way\nthat enables each of them to discover its required data using some prior side\ninformation.\n  In this paper, we initiate the study of the Storage Capacity and Index Coding\nproblems from the perspective of parameterized complexity. We prove that the\nStorage Capacity problem parameterized by the solution size admits a\nkernelization algorithm producing kernels of linear size. We also provide such\na result for the Index Coding problem, in the linear and non-linear settings,\nwhere it is parameterized by the dual value of the solution, i.e., the length\nof the transmission that can be saved using the side information. A key\ningredient in the proofs is the crown decomposition technique due to Chor,\nFellows, and Juedes (WG 2003, WG 2004). As an application, we significantly\nextend an algorithmic result of Dau, Skachek, and Chee (IEEE Trans. Inform.\nTheory, 2014).", "published": "2025-04-16 17:34:58", "link": "http://arxiv.org/abs/2504.12274v1", "categories": ["cs.DS", "cs.IT", "math.IT"], "primary_category": "cs.DS"}
{"title": "The Optimal Condition Number for ReLU Function", "abstract": "ReLU is a widely used activation function in deep neural networks. This paper\nexplores the stability properties of the ReLU map. For any weight matrix\n$\\boldsymbol{A} \\in \\mathbb{R}^{m \\times n}$ and bias vector $\\boldsymbol{b}\n\\in \\mathbb{R}^{m}$ at a given layer, we define the condition number\n$\\beta_{\\boldsymbol{A},\\boldsymbol{b}}$ as\n$\\beta_{\\boldsymbol{A},\\boldsymbol{b}} =\n\\frac{\\mathcal{U}_{\\boldsymbol{A},\\boldsymbol{b}}}{\\mathcal{L}_{\\boldsymbol{A},\\boldsymbol{b}}}$,\nwhere $\\mathcal{U}_{\\boldsymbol{A},\\boldsymbol{b}}$\n  and $\\mathcal{L}_{\\boldsymbol{A},\\boldsymbol{b}}$ are the upper and lower\nLipschitz constants, respectively. We first demonstrate that for any given\n$\\boldsymbol{A}$ and $\\boldsymbol{b}$, the condition number satisfies\n$\\beta_{\\boldsymbol{A},\\boldsymbol{b}} \\geq \\sqrt{2}$. Moreover, when the\nweights of the network at a given layer are initialized as random i.i.d.\nGaussian variables and the bias term is set to zero, the condition number\nasymptotically approaches this lower bound. This theoretical finding suggests\nthat Gaussian weight initialization is optimal for preserving distances in the\ncontext of random deep neural network weights.", "published": "2025-04-16 15:47:38", "link": "http://arxiv.org/abs/2504.12194v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Battery-aware Cyclic Scheduling in Energy-harvesting Federated Learning", "abstract": "Federated Learning (FL) has emerged as a promising framework for distributed\nlearning, but its growing complexity has led to significant energy consumption,\nparticularly from computations on the client side. This challenge is especially\ncritical in energy-harvesting FL (EHFL) systems, where device availability\nfluctuates due to limited and time-varying energy resources. We propose\nFedBacys, a battery-aware FL framework that introduces cyclic client\nparticipation based on users' battery levels to cope with these issues.\nFedBacys enables clients to save energy and strategically perform local\ntraining just before their designated transmission time by clustering clients\nand scheduling their involvement sequentially. This design minimizes redundant\ncomputation, reduces system-wide energy usage, and improves learning stability.\nOur experiments demonstrate that FedBacys outperforms existing approaches in\nterms of energy efficiency and performance consistency, exhibiting robustness\neven under non-i.i.d. training data distributions and with very infrequent\nbattery charging. This work presents the first comprehensive evaluation of\ncyclic client participation in EHFL, incorporating both communication and\ncomputation costs into a unified, resource-aware scheduling strategy.", "published": "2025-04-16 15:38:38", "link": "http://arxiv.org/abs/2504.12181v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Improvement of the square-root low bounds on the minimum distances of BCH codes and Matrix-product codes", "abstract": "The task of constructing infinite families of self-dual codes with unbounded\nlengths and minimum distances exhibiting square-root lower bounds is extremely\nchallenging, especially when it comes to cyclic codes. Recently, the first\ninfinite family of Euclidean self-dual binary and nonbinary cyclic codes, whose\nminimum distances have a square-root lower bound and have a lower bound better\nthan square-root lower bounds are constructed in \\cite{Chen23} for the lengths\nof these codes being unbounded. Let $q$ be a power of a prime number and\n$Q=q^2$. In this paper, we first improve the lower bounds on the minimum\ndistances of Euclidean and Hermitian duals of BCH codes with length\n$\\frac{q^m-1}{q^s-1}$ over $\\mathbb{F}_q$ and $\\frac{Q^m-1}{Q-1}$ over\n$\\mathbb{F}_Q$ in \\cite{Fan23,GDL21,Wang24} for the designed distances in some\nranges, respectively, where $\\frac{m}{s}\\geq 3$. Then based on matrix-product\nconstruction and some lower bounds on the minimum distances of BCH codes and\ntheir duals, we obtain several classes of Euclidean and Hermitian self-dual\ncodes, whose minimum distances have square-root lower bounds or a\nsquare-root-like lower bounds. Our lower bounds on the minimum distances of\nEuclidean and Hermitian self-dual cyclic codes improved many results in\n\\cite{Chen23}. In addition, our lower bounds on the minimum distances of the\nduals of BCH codes are almost $q^s-1$ or $q$ times that of the existing lower\nbounds.", "published": "2025-04-16 14:26:51", "link": "http://arxiv.org/abs/2504.12116v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Successive-Cancellation Flip and Perturbation Decoder of Polar Codes", "abstract": "In this paper, two decoding algorithms based on Successive Cancellation (SC)\nare proposed to improve the error-correction performance of cyclic redundancy\ncheck (CRC)-aided polar codes while aiming for a low-complexity implementation.\nComparisons with Dynamic SC Flip (DSCF) and SC Perturbation (SCP) are carried\nout since the proposed DSCF and Perturbation (DSCFP) and Perturbed DSCF (PDSCF)\nalgorithms combine both methods. The analysis includes comparisons with several\ncode lengths $N$ and various number of decoding attempts $T_{max}$. For\n$N=1024$ and the coding rate $R=\\frac{1}{2}$, the DSCFP and the SCP algorithms\nwith $T_{max}=17$ are bested by approximately $0.1$\\,dB at block error rate\n(BLER) of $0.001$. At $\\text{BLER}=10^{-6}$ and for $T_{max}=64$, the gain is\nof $0.375$ dB and $>0.5$ dB with respect to DSCF and SCP, respectively. At high\nsignal-to-noise ratio, the average computational complexity of the proposed\nalgorithms is virtually equivalent to that of SC.", "published": "2025-04-16 14:08:25", "link": "http://arxiv.org/abs/2504.12102v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Generalized Restart Mechanism for Successive-Cancellation Flip Decoding of Polar Codes", "abstract": "Polar codes are a class of linear error-correction codes that have received a\nlot of attention due to their ability to achieve channel capacity in an\narbitrary binary discrete memoryless channel (B-DMC) with low-complexity\nsuccessive-cancellation (SC) decoding. However, practical implementations often\nrequire better error-correction performance than what SC decoding provides,\nparticularly at short to moderate code lengths. Successive-cancellation flip\n(SCF) decoding algorithm was proposed to improve error-correction performance\nwith an aim to detect and correct the first wrongly estimated bit in a codeword\nbefore resuming SC decoding. At each additional SC decoding trial, i.e.,\ndecoding attempt beyond the initial unsuccessful trial, one bit estimated as\nthe least reliable is flipped. Dynamic SCF (DSCF) is a variation of SCF, where\nmultiple bits may be flipped simultaneously per trial. Despite the improved\nerror-correction performance compared to the SC decoder, SCF-based decoders\nhave variable execution time, which leads to high average execution time and\nlatency. In this work, we propose the generalized restart mechanism (GRM) that\nallows to skip decoding computations that are identical between the initial\ntrial and any additional trial. Under DSCF decoding with up to 3-bit flips per\ndecoding trial, our proposed GRM is shown to reduce the average execution time\nby 25% to 60% without any negative effect on error-correction performance. The\nproposed mechanism is adaptable to state-of-the-art latency-reduction\ntechniques. When applied to Fast-DSCF-3 decoding, the additional reduction\nbrought by the GRM is 15% to 22%. For the DSCF-3 decoder, the proposed\nmechanism requires approximately 4% additional memory.", "published": "2025-04-16 13:26:30", "link": "http://arxiv.org/abs/2504.12071v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Network-Centric Countermeasures Against Integrated Sensing Enabled Jamming Adversaries", "abstract": "Recent developments in Integrated Sensing and Communication have led to new\nadversarial models in wireless security through Integrated Sensing and Jamming\n(ISAJ) adversaries. ISAJ adversaries, owing to their sensing capabilities, are\nknown to inject jamming energy over the victim's frequency band, and also use\ngeneralized energy measurements on various network frequencies to detect the\npresence of countermeasures. Existing countermeasures against such ISAJ\nadversaries are laid under the assumption that the adversary does not have the\nknowledge of the countermeasure. However, according to Kerchoffs' principle in\ncryptography, security of a countermeasure should only rely on the secret-keys,\nnot on the obfuscation of the countermeasure. On testing the security of\nexisting countermeasures, we observe that they violate Kerchoffs' principle,\nthus motivating the need for new countermeasures. In this regard, we propose a\nnovel network-centric countermeasure against ISAJ adversaries, wherein a group\nof users in the network assist the victim to reliably communicate her messages\nin a covert manner. Firstly, we analyse the error performance of the proposed\ncountermeasure, and study its behavior on the number of assisting users in the\nnetwork. Subsequently, to validate its security against Kerchoffs' principle,\nwe study the Shannon's entropy associated with the presence of the victim's\nmessages in the network and analyse its behaviour as a function of the number\nof assisting users. Finally, to study the interplay between reliability and\ncovertness, we pose interesting optimization problems and solve them to choose\nthe underlying parameters of the countermeasure and the number of assisting\nusers.", "published": "2025-04-16 12:05:30", "link": "http://arxiv.org/abs/2504.12009v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Intersection and Composition properties of conditional independence", "abstract": "Compositional graphoids are fundamental discrete structures which appear in\nprobabilistic reasoning, particularly in the area of graphical models. They are\nsemigraphoids which satisfy the Intersection and Composition properties. These\nimportant properties, however, are not enjoyed by general probability\ndistributions. We survey what is known in terms of sufficient conditions for\nIntersection and Composition and derive a set of new sufficient conditions in\nthe context of discrete random variables based on conditional information\ninequalities for Shannon entropies.", "published": "2025-04-16 11:17:41", "link": "http://arxiv.org/abs/2504.11978v1", "categories": ["cs.IT", "math.IT", "math.ST", "stat.TH", "94A15 (primary) 62R01, 94A17 (secondary)"], "primary_category": "cs.IT"}
{"title": "On Codes from Split Metacyclic Groups", "abstract": "The paper presents a comprehensive study of group codes from non-abelian\nsplit metacyclic group algebras. We derive an explicit Wedderburn-like\ndecomposition of finite split metacyclic group algebras over fields with\ncharacteristic coprime to the group order. Utilizing this decomposition, we\ndevelop a systematic theory of metacyclic codes, providing their algebraic\ndescription and proving that they can be viewed as generalized concatenated\ncodes with cyclic inner codes and skew quasi-cyclic outer codes. We establish\nbounds on the minimum distance of metacyclic codes and investigate the class of\ninduced codes. Furthermore, we show the feasibility of constructing a partial\nkey-recovery attack against certain McEliece-type cryptosystems based on\nmetacyclic codes by exploiting their generalized concatenated structure.", "published": "2025-04-16 10:43:23", "link": "http://arxiv.org/abs/2504.11960v1", "categories": ["cs.IT", "math.IT", "math.RA", "16S34 (Primary), 94B05 (Secondary)"], "primary_category": "cs.IT"}
{"title": "DALC: Distributed Arithmetic Coding Aided by Linear Codes", "abstract": "Distributed Arithmetic Coding (DAC) has emerged as a feasible solution to the\nSlepian-Wolf problem, particularly in scenarios with non-stationary sources and\nfor data sequences with lengths ranging from small to medium. Due to the\ninherent decoding ambiguity in DAC, the number of candidate paths grows\nexponentially with the increase in source length. To select the correct\ndecoding path from the set of candidates, DAC decoders utilize the Maximum A\nPosteriori (MAP) metric to rank the decoding sequences, outputting the path\nwith the highest MAP metric as the decoding result of the decoder. However,\nthis method may still inadvertently output incorrect paths that have a MAP\nmetric higher than the correct decoding path, despite not being the correct\ndecoding path. To address the issue, we propose Distributed Arithmetic Coding\nAided by Linear Codes (DALC), which employs linear codes to constrain the\ndecoding process, thereby eliminating some incorrect paths and preserving the\ncorrect one. During the encoding phase, DALC generates the parity bits of the\nlinear code for encoding the source data. In the decoding phase, each path in\nthe set of candidate paths is verified in descending order according to the MAP\nmetric until a path that meets the verification criteria is encountered, which\nis then outputted as the decoding result. DALC enhances the decoding\nperformance of DAC by excluding candidate paths that do not meet the\nconstraints imposed by linear codes. Our experimental results demonstrate that\nDALC reduces the Bit Error Rate(BER), with especially improvements in skewed\nsource data scenarios.", "published": "2025-04-16 05:36:52", "link": "http://arxiv.org/abs/2504.11784v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sliding Block Martingale based Multi-hop Delay QoS Analysis", "abstract": "With the growing density of wireless networks and demand for multi-hop\ntransmissions, precise delay Quality of Service (QoS) analysis has become a\ncritical challenge. This paper introduces a multi-hop delay QoS analysis\nframework based on the sliding block martingale, addressing the loose boundary\nissue of prior methods that rely on service process martingales and min-plus\ntransformations. By constructing a sliding block martingale with a window, we\ncapture both long-term trends and short-term fluctuations in the backlog,\neliminating the reliance on the generalized incremental property. The framework\nredefines delay unreliability events using cascading attributes, deriving a\nmore compact Delay Unreliability Probability Boundary (DUPB). To improve the\nefficiency of solving the key parameter $\\theta$, we propose a Micrometric\nIntervals based Supermartingale Upcrossing Estimate Theorem, quantifying the\nupper bound of event occurrence frequency to constrain the solution space of\n$\\theta$. Simulations based on the 3GPP UMa/UMi channel model validate the\nframework's effectiveness. Results show that in 2-7 hop scenarios, the maximum\ndeviation between theoretical boundaries and Monte Carlo simulations is $4.116\n\\times 10^{-5}$, with a lower RMSE than existing methods. Iteration count and\nCPU time for solving $\\theta$ are reduced by $59\\%-72\\%$ and $60.6\\%-70.5\\%$,\nrespectively, improving analysis efficiency. Furthermore, the derived minimum\nservice rate for multi-hop queues offers a valuable reference for resource\nallocation. The framework demonstrates high accuracy, scalability, and\npracticality in complex multi-hop networks.", "published": "2025-04-16 05:13:53", "link": "http://arxiv.org/abs/2504.11769v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Beyond ISAC: Toward Integrated Heterogeneous Service Provisioning via Elastic Multi-Dimensional Multiple Access", "abstract": "Integrated heterogeneous service provisioning (IHSP) is a promising paradigm\nthat is designed to concurrently support a variety of heterogeneous services,\nextending beyond sensing and communication to meet the diverse needs of\nemerging applications. However, a primary challenge of IHSP is addressing the\nconflicts between multiple competing service demands under constrained\nresources. In this paper, we overcome this challenge by the joint use of two\nnovel elastic design strategies: compromised service value assessment and\nflexible multi-dimensional resource multiplexing. Consequently, we propose a\nvalue-prioritized elastic multi-dimensional multiple access (MDMA) mechanism\nfor IHSP systems. First, we modify the Value-of-Service (VoS) metric by\nincorporating elastic parameters to characterize user-specific tolerance and\ncompromise in response to various performance degradations under constrained\nresources. This VoS metric serves as the foundation for prioritizing services\nand enabling effective fairness service scheduling among concurrent competing\ndemands. Next, we adapt the MDMA to elastically multiplex services using\nappropriate multiple access schemes across different resource domains. This\nprotocol leverages user-specific interference tolerances and cancellation\ncapabilities across different domains to reduce resource-demanding conflicts\nand co-channel interference within the same domain. Then, we maximize the\nsystem's VoS by jointly optimizing MDMA design and power allocation. Since this\nproblem is non-convex, we propose a monotonic optimization-assisted dynamic\nprogramming (MODP) algorithm to obtain its optimal solution. Additionally, we\ndevelop the VoS-prioritized successive convex approximation (SCA) algorithm to\nefficiently find its suboptimal solution. Finally, simulations are presented to\nvalidate the effectiveness of the proposed designs.", "published": "2025-04-16 01:21:56", "link": "http://arxiv.org/abs/2504.11692v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Leave-One-Out Stable Conformal Prediction", "abstract": "Conformal prediction (CP) is an important tool for distribution-free\npredictive uncertainty quantification. Yet, a major challenge is to balance\ncomputational efficiency and prediction accuracy, particularly for multiple\npredictions. We propose Leave-One-Out Stable Conformal Prediction (LOO-StabCP),\na novel method to speed up full conformal using algorithmic stability without\nsample splitting. By leveraging leave-one-out stability, our method is much\nfaster in handling a large number of prediction requests compared to existing\nmethod RO-StabCP based on replace-one stability. We derived stability bounds\nfor several popular machine learning tools: regularized loss minimization (RLM)\nand stochastic gradient descent (SGD), as well as kernel method, neural\nnetworks and bagging. Our method is theoretically justified and demonstrates\nsuperior numerical performance on synthetic and real-world data. We applied our\nmethod to a screening problem, where its effective exploitation of training\ndata led to improved test power compared to state-of-the-art method based on\nsplit conformal.", "published": "2025-04-16 15:44:24", "link": "http://arxiv.org/abs/2504.12189v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Approximation Bounds for Transformer Networks with Application to Regression", "abstract": "We explore the approximation capabilities of Transformer networks for\nH\\\"older and Sobolev functions, and apply these results to address\nnonparametric regression estimation with dependent observations. First, we\nestablish novel upper bounds for standard Transformer networks approximating\nsequence-to-sequence mappings whose component functions are H\\\"older continuous\nwith smoothness index $\\gamma \\in (0,1]$. To achieve an approximation error\n$\\varepsilon$ under the $L^p$-norm for $p \\in [1, \\infty]$, it suffices to use\na fixed-depth Transformer network whose total number of parameters scales as\n$\\varepsilon^{-d_x n / \\gamma}$. This result not only extends existing findings\nto include the case $p = \\infty$, but also matches the best known upper bounds\non number of parameters previously obtained for fixed-depth FNNs and RNNs.\nSimilar bounds are also derived for Sobolev functions. Second, we derive\nexplicit convergence rates for the nonparametric regression problem under\nvarious $\\beta$-mixing data assumptions, which allow the dependence between\nobservations to weaken over time. Our bounds on the sample complexity impose no\nconstraints on weight magnitudes. Lastly, we propose a novel proof strategy to\nestablish approximation bounds, inspired by the Kolmogorov-Arnold\nrepresentation theorem. We show that if the self-attention layer in a\nTransformer can perform column averaging, the network can approximate\nsequence-to-sequence H\\\"older functions, offering new insights into the\ninterpretability of self-attention mechanisms.", "published": "2025-04-16 15:25:58", "link": "http://arxiv.org/abs/2504.12175v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Predictive Multiplicity in Survival Models: A Method for Quantifying Model Uncertainty in Predictive Maintenance Applications", "abstract": "In many applications, especially those involving prediction, models may yield\nnear-optimal performance yet significantly disagree on individual-level\noutcomes. This phenomenon, known as predictive multiplicity, has been formally\ndefined in binary, probabilistic, and multi-target classification, and\nundermines the reliability of predictive systems. However, its implications\nremain unexplored in the context of survival analysis, which involves\nestimating the time until a failure or similar event while properly handling\ncensored data. We frame predictive multiplicity as a critical concern in\nsurvival-based models and introduce formal measures -- ambiguity, discrepancy,\nand obscurity -- to quantify it. This is particularly relevant for downstream\ntasks such as maintenance scheduling, where precise individual risk estimates\nare essential. Understanding and reporting predictive multiplicity helps build\ntrust in models deployed in high-stakes environments. We apply our methodology\nto benchmark datasets from predictive maintenance, extending the notion of\nmultiplicity to survival models. Our findings show that ambiguity steadily\nincreases, reaching up to 40-45% of observations; discrepancy is lower but\nexhibits a similar trend; and obscurity remains mild and concentrated in a few\nmodels. These results demonstrate that multiple accurate survival models may\nyield conflicting estimations of failure risk and degradation progression for\nthe same equipment. This highlights the need to explicitly measure and\ncommunicate predictive multiplicity to ensure reliable decision-making in\nprocess health management.", "published": "2025-04-16 15:04:00", "link": "http://arxiv.org/abs/2504.12156v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Neural Contextual Bandits Under Delayed Feedback Constraints", "abstract": "This paper presents a new algorithm for neural contextual bandits (CBs) that\naddresses the challenge of delayed reward feedback, where the reward for a\nchosen action is revealed after a random, unknown delay. This scenario is\ncommon in applications such as online recommendation systems and clinical\ntrials, where reward feedback is delayed because the outcomes or results of a\nuser's actions (such as recommendations or treatment responses) take time to\nmanifest and be measured. The proposed algorithm, called Delayed NeuralUCB,\nuses an upper confidence bound (UCB)-based exploration strategy. Under the\nassumption of independent and identically distributed sub-exponential reward\ndelays, we derive an upper bound on the cumulative regret over a T-length\nhorizon. We further consider a variant of the algorithm, called Delayed\nNeuralTS, that uses Thompson Sampling-based exploration. Numerical experiments\non real-world datasets, such as MNIST and Mushroom, along with comparisons to\nbenchmark approaches, demonstrate that the proposed algorithms effectively\nmanage varying delays and are well-suited for complex real-world scenarios.", "published": "2025-04-16 13:47:25", "link": "http://arxiv.org/abs/2504.12086v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Generative Deep Learning Framework for Inverse Design of Fuels", "abstract": "In the present work, a generative deep learning framework combining a\nCo-optimized Variational Autoencoder (Co-VAE) architecture with quantitative\nstructure-property relationship (QSPR) techniques is developed to enable\naccelerated inverse design of fuels. The Co-VAE integrates a property\nprediction component coupled with the VAE latent space, enhancing molecular\nreconstruction and accurate estimation of Research Octane Number (RON) (chosen\nas the fuel property of interest). A subset of the GDB-13 database, enriched\nwith a curated RON database, is used for model training. Hyperparameter tuning\nis further utilized to optimize the balance among reconstruction fidelity,\nchemical validity, and RON prediction. An independent regression model is then\nused to refine RON prediction, while a differential evolution algorithm is\nemployed to efficiently navigate the VAE latent space and identify promising\nfuel molecule candidates with high RON. This methodology addresses the\nlimitations of traditional fuel screening approaches by capturing complex\nstructure-property relationships within a comprehensive latent representation.\nThe generative model provides a flexible tool for systematically exploring vast\nchemical spaces, paving the way for discovering fuels with superior anti-knock\nproperties. The demonstrated approach can be readily extended to incorporate\nadditional fuel properties and synthesizability criteria to enhance\napplicability and reliability for de novo design of new fuels.", "published": "2025-04-16 13:32:25", "link": "http://arxiv.org/abs/2504.12075v1", "categories": ["cs.LG", "physics.chem-ph"], "primary_category": "cs.LG"}
{"title": "On the calibration of Just-in-time Defect Prediction", "abstract": "Just in time defect prediction (JIT DP) leverages ML to identify defect-prone\ncode commits, enabling quality assurance (QA) teams to allocate resources more\nefficiently by focusing on commits that are most likely to contain defects.\nAlthough JIT DP techniques have introduced improvements in terms of predictive\naccuracy, they are still susceptible to misclassification errors such as false\npositives and negatives. This can lead to wasted resources or undetected\ndefects, a particularly critical concern when QA resources are limited. To\nmitigate these challenges and preserve the practical utility of JIT DP tools,\nit becomes essential to estimate the reliability of the predictions, i.e.,\ncomputing confidence scores. Such scores can help practitioners determine the\ntrustworthiness of predictions and thus prioritize them efficiently. A simple\napproach to computing confidence scores is to extract, alongside each\nprediction, the corresponding prediction probabilities and use them as\nindicators of confidence. However, for these probabilities to reliably serve as\nconfidence scores, the predictive model must be well-calibrated. This means\nthat the prediction probabilities must accurately represent the true likelihood\nof each prediction being correct. Miscalibration, common in modern ML models,\ndistorts probability scores such that they do not align with the actual\ncorrectness probability. In this study, we evaluate the calibration of three\nJIT DP techniques to determine whether and to what extent they exhibit poor\ncalibration. Furthermore, we assess whether post-calibration methods can\nimprove the calibration of existing JIT defect prediction models. Our results\nreveal that all evaluated JIT DP models exhibit some level of miscalibration,\nwith ECE ranging from 2-35%. Furthermore, post-calibration methods do not\nconsistently improve the calibration.", "published": "2025-04-16 13:06:20", "link": "http://arxiv.org/abs/2504.12051v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "FedEPA: Enhancing Personalization and Modality Alignment in Multimodal Federated Learning", "abstract": "Federated Learning (FL) enables decentralized model training across multiple\nparties while preserving privacy. However, most FL systems assume clients hold\nonly unimodal data, limiting their real-world applicability, as institutions\noften possess multimodal data. Moreover, the lack of labeled data further\nconstrains the performance of most FL methods. In this work, we propose FedEPA,\na novel FL framework for multimodal learning. FedEPA employs a personalized\nlocal model aggregation strategy that leverages labeled data on clients to\nlearn personalized aggregation weights, thereby alleviating the impact of data\nheterogeneity. We also propose an unsupervised modality alignment strategy that\nworks effectively with limited labeled data. Specifically, we decompose\nmultimodal features into aligned features and context features. We then employ\ncontrastive learning to align the aligned features across modalities, ensure\nthe independence between aligned features and context features within each\nmodality, and promote the diversity of context features. A multimodal feature\nfusion strategy is introduced to obtain a joint embedding. The experimental\nresults show that FedEPA significantly outperforms existing FL methods in\nmultimodal classification tasks under limited labeled data conditions.", "published": "2025-04-16 12:32:37", "link": "http://arxiv.org/abs/2504.12025v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Active Human Feedback Collection via Neural Contextual Dueling Bandits", "abstract": "Collecting human preference feedback is often expensive, leading recent works\nto develop principled algorithms to select them more efficiently. However,\nthese works assume that the underlying reward function is linear, an assumption\nthat does not hold in many real-life applications, such as online\nrecommendation and LLM alignment. To address this limitation, we propose\nNeural-ADB, an algorithm based on the neural contextual dueling bandit\nframework that provides a principled and practical method for collecting human\npreference feedback when the underlying latent reward function is non-linear.\nWe theoretically show that when preference feedback follows the\nBradley-Terry-Luce model, the worst sub-optimality gap of the policy learned by\nNeural-ADB decreases at a sub-linear rate as the preference dataset increases.\nOur experimental results on problem instances derived from synthetic preference\ndatasets further validate the effectiveness of Neural-ADB.", "published": "2025-04-16 12:16:10", "link": "http://arxiv.org/abs/2504.12016v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Voice Conversion with Diverse Intonation using Conditional Variational Auto-Encoder", "abstract": "Voice conversion is a task of synthesizing an utterance with target speaker's\nvoice while maintaining linguistic information of the source utterance. While a\nspeaker can produce varying utterances from a single script with different\nintonations, conventional voice conversion models were limited to producing\nonly one result per source input. To overcome this limitation, we propose a\nnovel approach for voice conversion with diverse intonations using conditional\nvariational autoencoder (CVAE). Experiments have shown that the speaker's style\nfeature can be mapped into a latent space with Gaussian distribution. We have\nalso been able to convert voices with more diverse intonation by making the\nposterior of the latent space more complex with inverse autoregressive flow\n(IAF). As a result, the converted voice not only has a diversity of\nintonations, but also has better sound quality than the model without CVAE.", "published": "2025-04-16 11:59:56", "link": "http://arxiv.org/abs/2504.12005v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Control of Rayleigh-B\u00e9nard Convection: Effectiveness of Reinforcement Learning in the Turbulent Regime", "abstract": "Data-driven flow control has significant potential for industry, energy\nsystems, and climate science. In this work, we study the effectiveness of\nReinforcement Learning (RL) for reducing convective heat transfer in the 2D\nRayleigh-B\\'enard Convection (RBC) system under increasing turbulence. We\ninvestigate the generalizability of control across varying initial conditions\nand turbulence levels and introduce a reward shaping technique to accelerate\nthe training. RL agents trained via single-agent Proximal Policy Optimization\n(PPO) are compared to linear proportional derivative (PD) controllers from\nclassical control theory. The RL agents reduced convection, measured by the\nNusselt Number, by up to 33% in moderately turbulent systems and 10% in highly\nturbulent settings, clearly outperforming PD control in all settings. The\nagents showed strong generalization performance across different initial\nconditions and to a significant extent, generalized to higher degrees of\nturbulence. The reward shaping improved sample efficiency and consistently\nstabilized the Nusselt Number to higher turbulence levels.", "published": "2025-04-16 11:51:59", "link": "http://arxiv.org/abs/2504.12000v1", "categories": ["physics.flu-dyn", "cs.LG"], "primary_category": "physics.flu-dyn"}
{"title": "Secure Transfer Learning: Training Clean Models Against Backdoor in (Both) Pre-trained Encoders and Downstream Datasets", "abstract": "Transfer learning from pre-trained encoders has become essential in modern\nmachine learning, enabling efficient model adaptation across diverse tasks.\nHowever, this combination of pre-training and downstream adaptation creates an\nexpanded attack surface, exposing models to sophisticated backdoor embeddings\nat both the encoder and dataset levels--an area often overlooked in prior\nresearch. Additionally, the limited computational resources typically available\nto users of pre-trained encoders constrain the effectiveness of generic\nbackdoor defenses compared to end-to-end training from scratch. In this work,\nwe investigate how to mitigate potential backdoor risks in resource-constrained\ntransfer learning scenarios. Specifically, we conduct an exhaustive analysis of\nexisting defense strategies, revealing that many follow a reactive workflow\nbased on assumptions that do not scale to unknown threats, novel attack types,\nor different training paradigms. In response, we introduce a proactive mindset\nfocused on identifying clean elements and propose the Trusted Core (T-Core)\nBootstrapping framework, which emphasizes the importance of pinpointing\ntrustworthy data and neurons to enhance model security. Our empirical\nevaluations demonstrate the effectiveness and superiority of T-Core,\nspecifically assessing 5 encoder poisoning attacks, 7 dataset poisoning\nattacks, and 14 baseline defenses across five benchmark datasets, addressing\nfour scenarios of 3 potential backdoor threats.", "published": "2025-04-16 11:33:03", "link": "http://arxiv.org/abs/2504.11990v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Efficient identification of linear, parameter-varying, and nonlinear systems with noise models", "abstract": "We present a general system identification procedure capable of estimating of\na broad spectrum of state-space dynamical models, including linear\ntime-invariant (LTI), linear parameter-varying} (LPV), and nonlinear (NL)\ndynamics, along with rather general classes of noise models. Similar to the LTI\ncase, we show that for this general class of model structures, including the NL\ncase, the model dynamics can be separated into a deterministic process and a\nstochastic noise part, allowing to seamlessly tune the complexity of the\ncombined model both in terms of nonlinearity and noise modeling. We\nparameterize the involved nonlinear functional relations by means of artificial\nneural-networks (ANNs), although alternative parametric nonlinear mappings can\nalso be used. To estimate the resulting model structures, we optimize a\nprediction-error-based criterion using an efficient combination of a\nconstrained quasi-Newton approach and automatic differentiation, achieving\ntraining times in the order of seconds compared to existing state-of-the-art\nANN methods which may require hours for models of similar complexity. We\nformally establish the consistency guarantees for the proposed approach and\ndemonstrate its superior estimation accuracy and computational efficiency on\nseveral benchmark LTI, LPV, and NL system identification problems.", "published": "2025-04-16 11:23:30", "link": "http://arxiv.org/abs/2504.11982v1", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "math.OC"}
{"title": "Hardware-Friendly Delayed-Feedback Reservoir for Multivariate Time-Series Classification", "abstract": "Reservoir computing (RC) is attracting attention as a machine-learning\ntechnique for edge computing. In time-series classification tasks, the number\nof features obtained using a reservoir depends on the length of the input\nseries. Therefore, the features must be converted to a constant-length\nintermediate representation (IR), such that they can be processed by an output\nlayer. Existing conversion methods involve computationally expensive matrix\ninversion that significantly increases the circuit size and requires processing\npower when implemented in hardware. In this article, we propose a simple but\neffective IR, namely, dot-product-based reservoir representation (DPRR), for RC\nbased on the dot product of data features. Additionally, we propose a\nhardware-friendly delayed-feedback reservoir (DFR) consisting of a nonlinear\nelement and delayed feedback loop with DPRR. The proposed DFR successfully\nclassified multivariate time series data that has been considered particularly\ndifficult to implement efficiently in hardware. In contrast to conventional DFR\nmodels that require analog circuits, the proposed model can be implemented in a\nfully digital manner suitable for high-level syntheses. A comparison with\nexisting machine-learning methods via field-programmable gate array\nimplementation using 12 multivariate time-series classification tasks confirmed\nthe superior accuracy and small circuit size of the proposed method.", "published": "2025-04-16 11:22:38", "link": "http://arxiv.org/abs/2504.11981v1", "categories": ["cs.LG", "cs.AR"], "primary_category": "cs.LG"}
{"title": "FedCanon: Non-Convex Composite Federated Learning with Efficient Proximal Operation on Heterogeneous Data", "abstract": "Composite federated learning offers a general framework for solving machine\nlearning problems with additional regularization terms. However, many existing\nmethods require clients to perform multiple proximal operations to handle\nnon-smooth terms and their performance are often susceptible to data\nheterogeneity. To overcome these limitations, we propose a novel composite\nfederated learning algorithm called \\textbf{FedCanon}, designed to solve the\noptimization problems comprising a possibly non-convex loss function and a\nweakly convex, potentially non-smooth regularization term. By decoupling\nproximal mappings from local updates, FedCanon requires only a single proximal\nevaluation on the server per iteration, thereby reducing the overall proximal\ncomputation cost. It also introduces control variables that incorporate global\ngradient information into client updates, which helps mitigate the effects of\ndata heterogeneity. Theoretical analysis demonstrates that FedCanon achieves\nsublinear convergence rates under general non-convex settings and linear\nconvergence under the Polyak-{\\L}ojasiewicz condition, without relying on\nbounded heterogeneity assumptions. Experiments demonstrate that FedCanon\noutperforms the state-of-the-art methods in terms of both accuracy and\ncomputational efficiency, particularly under heterogeneous data distributions.", "published": "2025-04-16 09:28:26", "link": "http://arxiv.org/abs/2504.11903v1", "categories": ["cs.LG", "cs.DC", "math.OC"], "primary_category": "cs.LG"}
{"title": "HyperSAT: Unsupervised Hypergraph Neural Networks for Weighted MaxSAT Problems", "abstract": "Graph neural networks (GNNs) have shown promising performance in solving both\nBoolean satisfiability (SAT) and Maximum Satisfiability (MaxSAT) problems due\nto their ability to efficiently model and capture the structural dependencies\nbetween literals and clauses. However, GNN methods for solving Weighted MaxSAT\nproblems remain underdeveloped. The challenges arise from the non-linear\ndependency and sensitive objective function, which are caused by the\nnon-uniform distribution of weights across clauses. In this paper, we present\nHyperSAT, a novel neural approach that employs an unsupervised hypergraph\nneural network model to solve Weighted MaxSAT problems. We propose a hypergraph\nrepresentation for Weighted MaxSAT instances and design a cross-attention\nmechanism along with a shared representation constraint loss function to\ncapture the logical interactions between positive and negative literal nodes in\nthe hypergraph. Extensive experiments on various Weighted MaxSAT datasets\ndemonstrate that HyperSAT achieves better performance than state-of-the-art\ncompetitors.", "published": "2025-04-16 09:11:16", "link": "http://arxiv.org/abs/2504.11885v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Benchmarking Mutual Information-based Loss Functions in Federated Learning", "abstract": "Federated Learning (FL) has attracted considerable interest due to growing\nprivacy concerns and regulations like the General Data Protection Regulation\n(GDPR), which stresses the importance of privacy-preserving and fair machine\nlearning approaches. In FL, model training takes place on decentralized data,\nso as to allow clients to upload a locally trained model and receive a globally\naggregated model without exposing sensitive information. However, challenges\nrelated to fairness-such as biases, uneven performance among clients, and the\n\"free rider\" issue complicates its adoption. In this paper, we examine the use\nof Mutual Information (MI)-based loss functions to address these concerns. MI\nhas proven to be a powerful method for measuring dependencies between variables\nand optimizing deep learning models. By leveraging MI to extract essential\nfeatures and minimize biases, we aim to improve both the fairness and\neffectiveness of FL systems. Through extensive benchmarking, we assess the\nimpact of MI-based losses in reducing disparities among clients while enhancing\nthe overall performance of FL.", "published": "2025-04-16 08:58:44", "link": "http://arxiv.org/abs/2504.11877v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Factor-MCLS: Multi-agent learning system with reward factor matrix and multi-critic framework for dynamic portfolio optimization", "abstract": "Typical deep reinforcement learning (DRL) agents for dynamic portfolio\noptimization learn the factors influencing portfolio return and risk by\nanalyzing the output values of the reward function while adjusting portfolio\nweights within the training environment. However, it faces a major limitation\nwhere it is difficult for investors to intervene in the training based on\ndifferent levels of risk aversion towards each portfolio asset. This difficulty\narises from another limitation: existing DRL agents may not develop a thorough\nunderstanding of the factors responsible for the portfolio return and risk by\nonly learning from the output of the reward function. As a result, the strategy\nfor determining the target portfolio weights is entirely dependent on the DRL\nagents themselves. To address these limitations, we propose a reward factor\nmatrix for elucidating the return and risk of each asset in the portfolio.\nAdditionally, we propose a novel learning system named Factor-MCLS using a\nmulti-critic framework that facilitates learning of the reward factor matrix.\nIn this way, our DRL-based learning system can effectively learn the factors\ninfluencing portfolio return and risk. Moreover, based on the critic networks\nwithin the multi-critic framework, we develop a risk constraint term in the\ntraining objective function of the policy function. This risk constraint term\nallows investors to intervene in the training of the DRL agent according to\ntheir individual levels of risk aversion towards the portfolio assets.", "published": "2025-04-16 08:51:09", "link": "http://arxiv.org/abs/2504.11874v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Transferable Deployment of Semantic Edge Inference Systems via Unsupervised Domain Adaption", "abstract": "This paper investigates deploying semantic edge inference systems for\nperforming a common image clarification task. In particular, each system\nconsists of multiple Internet of Things (IoT) devices that first locally encode\nthe sensing data into semantic features and then transmit them to an edge\nserver for subsequent data fusion and task inference. The inference accuracy is\ndetermined by efficient training of the feature encoder/decoder using labeled\ndata samples. Due to the difference in sensing data and communication channel\ndistributions, deploying the system in a new environment may induce high costs\nin annotating data labels and re-training the encoder/decoder models. To\nachieve cost-effective transferable system deployment, we propose an efficient\nDomain Adaptation method for Semantic Edge INference systems (DASEIN) that can\nmaintain high inference accuracy in a new environment without the need for\nlabeled samples. Specifically, DASEIN exploits the task-relevant data\ncorrelation between different deployment scenarios by leveraging the techniques\nof unsupervised domain adaptation and knowledge distillation. It devises an\nefficient two-step adaptation procedure that sequentially aligns the data\ndistributions and adapts to the channel variations. Numerical results show\nthat, under a substantial change in sensing data distributions, the proposed\nDASEIN outperforms the best-performing benchmark method by 7.09% and 21.33% in\ninference accuracy when the new environment has similar or 25 dB lower channel\nsignal to noise power ratios (SNRs), respectively. This verifies the\neffectiveness of the proposed method in adapting both data and channel\ndistributions in practical transfer deployment applications.", "published": "2025-04-16 08:50:51", "link": "http://arxiv.org/abs/2504.11873v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "On the Problem of Best Arm Retention", "abstract": "This paper presents a comprehensive study on the problem of Best Arm\nRetention (BAR), which has recently found applications in streaming algorithms\nfor multi-armed bandits. In the BAR problem, the goal is to retain $m$ arms\nwith the best arm included from $n$ after some trials, in stochastic\nmulti-armed bandit settings. We first investigate pure exploration for the BAR\nproblem under different criteria, and then minimize the regret with specific\nconstraints, in the context of further exploration in streaming algorithms.\n  - We begin by revisiting the lower bound for the $(\\varepsilon,\\delta)$-PAC\nalgorithm for Best Arm Identification (BAI) and adapt the classical\nKL-divergence argument to derive optimal bounds for $(\\varepsilon,\\delta)$-PAC\nalgorithms for BAR.\n  - We further study another variant of the problem, called $r$-BAR, which\nrequires the expected gap between the best arm and the optimal arm retained is\nless than $r$. We prove tight sample complexity for the problem.\n  - We explore the regret minimization problem for $r$-BAR and develop\nalgorithm beyond pure exploration. We conclude with a conjecture on the optimal\nregret in this setting.", "published": "2025-04-16 08:41:20", "link": "http://arxiv.org/abs/2504.11866v1", "categories": ["cs.LG", "cs.DS"], "primary_category": "cs.LG"}
{"title": "GT-SVQ: A Linear-Time Graph Transformer for Node Classification Using Spiking Vector Quantization", "abstract": "Graph Transformers (GTs), which simultaneously integrate message-passing and\nself-attention mechanisms, have achieved promising empirical results in some\ngraph prediction tasks. Although these approaches show the potential of\nTransformers in capturing long-range graph topology information, issues\nconcerning the quadratic complexity and high computing energy consumption\nseverely limit the scalability of GTs on large-scale graphs. Recently, as\nbrain-inspired neural networks, Spiking Neural Networks (SNNs), facilitate the\ndevelopment of graph representation learning methods with lower computational\nand storage overhead through the unique event-driven spiking neurons. Inspired\nby these characteristics, we propose a linear-time Graph Transformer using\nSpiking Vector Quantization (GT-SVQ) for node classification. GT-SVQ\nreconstructs codebooks based on rate coding outputs from spiking neurons, and\ninjects the codebooks into self-attention blocks to aggregate global\ninformation in linear complexity. Besides, spiking vector quantization\neffectively alleviates codebook collapse and the reliance on complex machinery\n(distance measure, auxiliary loss, etc.) present in previous vector\nquantization-based graph learning methods. In experiments, we compare GT-SVQ\nwith other state-of-the-art baselines on node classification datasets ranging\nfrom small to large. Experimental results show that GT-SVQ has achieved\ncompetitive performances on most datasets while maintaining up to 130x faster\ninference speed compared to other GTs.", "published": "2025-04-16 07:57:42", "link": "http://arxiv.org/abs/2504.11840v1", "categories": ["cs.NE", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Support is All You Need for Certified VAE Training", "abstract": "Variational Autoencoders (VAEs) have become increasingly popular and deployed\nin safety-critical applications. In such applications, we want to give\ncertified probabilistic guarantees on performance under adversarial attacks. We\npropose a novel method, CIVET, for certified training of VAEs. CIVET depends on\nthe key insight that we can bound worst-case VAE error by bounding the error on\ncarefully chosen support sets at the latent layer. We show this point\nmathematically and present a novel training algorithm utilizing this insight.\nWe show in an extensive evaluation across different datasets (in both the\nwireless and vision application areas), architectures, and perturbation\nmagnitudes that our method outperforms SOTA methods achieving good standard\nperformance with strong robustness guarantees.", "published": "2025-04-16 07:41:40", "link": "http://arxiv.org/abs/2504.11831v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Emergence of Computational Structure in a Neural Network Physics Simulator", "abstract": "Neural networks often have identifiable computational structures - components\nof the network which perform an interpretable algorithm or task - but the\nmechanisms by which these emerge and the best methods for detecting these\nstructures are not well understood. In this paper we investigate the emergence\nof computational structure in a transformer-like model trained to simulate the\nphysics of a particle system, where the transformer's attention mechanism is\nused to transfer information between particles. We show that (a) structures\nemerge in the attention heads of the transformer which learn to detect particle\ncollisions, (b) the emergence of these structures is associated to degenerate\ngeometry in the loss landscape, and (c) the dynamics of this emergence follows\na power law. This suggests that these components are governed by a degenerate\n\"effective potential\". These results have implications for the convergence time\nof computational structure within neural networks and suggest that the\nemergence of computational structure can be detected by studying the dynamics\nof network components.", "published": "2025-04-16 07:38:51", "link": "http://arxiv.org/abs/2504.11830v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Cost-Efficient LLM Serving in the Cloud: VM Selection with KV Cache Offloading", "abstract": "LLM inference is essential for applications like text summarization,\ntranslation, and data analysis, but the high cost of GPU instances from Cloud\nService Providers (CSPs) like AWS is a major burden. This paper proposes\nInferSave, a cost-efficient VM selection framework for cloud based LLM\ninference. InferSave optimizes KV cache offloading based on Service Level\nObjectives (SLOs) and workload charac teristics, estimating GPU memory needs,\nand recommending cost-effective VM instances. Additionally, the Compute Time\nCalibration Function (CTCF) improves instance selection accuracy by adjusting\nfor discrepancies between theoretical and actual GPU performance. Experiments\non AWS GPU instances show that selecting lower-cost instances without KV cache\noffloading improves cost efficiency by up to 73.7% for online workloads, while\nKV cache offloading saves up to 20.19% for offline workloads.", "published": "2025-04-16 07:02:38", "link": "http://arxiv.org/abs/2504.11816v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Manifold meta-learning for reduced-complexity neural system identification", "abstract": "System identification has greatly benefited from deep learning techniques,\nparticularly for modeling complex, nonlinear dynamical systems with partially\nunknown physics where traditional approaches may not be feasible. However, deep\nlearning models often require large datasets and significant computational\nresources at training and inference due to their high-dimensional\nparameterizations. To address this challenge, we propose a meta-learning\nframework that discovers a low-dimensional manifold within the parameter space\nof an over-parameterized neural network architecture. This manifold is learned\nfrom a meta-dataset of input-output sequences generated by a class of related\ndynamical systems, enabling efficient model training while preserving the\nnetwork's expressive power for the considered system class. Unlike bilevel\nmeta-learning approaches, our method employs an auxiliary neural network to map\ndatasets directly onto the learned manifold, eliminating the need for costly\nsecond-order gradient computations during meta-training and reducing the number\nof first-order updates required in inference, which could be expensive for\nlarge models. We validate our approach on a family of Bouc-Wen oscillators,\nwhich is a well-studied nonlinear system identification benchmark. We\ndemonstrate that we are able to learn accurate models even in small-data\nscenarios.", "published": "2025-04-16 06:49:56", "link": "http://arxiv.org/abs/2504.11811v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs", "abstract": "Graph Neural Network (GNN) research is rapidly advancing due to GNNs'\ncapacity to learn distributed representations from graph-structured data.\nHowever, centralizing large volumes of real-world graph data for GNN training\nis often impractical due to privacy concerns, regulatory restrictions, and\ncommercial competition. Federated learning (FL), a distributed learning\nparadigm, offers a solution by preserving data privacy with collaborative model\ntraining. Despite progress in training huge vision and language models,\nfederated learning for GNNs remains underexplored. To address this challenge,\nwe present a novel method for federated learning on GNNs based on spectral GNNs\nequipped with neural ordinary differential equations (ODE) for better\ninformation capture, showing promising results across both homophilic and\nheterophilic graphs. Our approach effectively handles non-Independent and\nIdentically Distributed (non-IID) data, while also achieving performance\ncomparable to existing methods that only operate on IID data. It is designed to\nbe privacy-preserving and bandwidth-optimized, making it suitable for\nreal-world applications such as social network analysis, recommendation\nsystems, and fraud detection, which often involve complex, non-IID, and\nheterophilic graph structures. Our results in the area of federated learning on\nnon-IID heterophilic graphs demonstrate significant improvements, while also\nachieving better performance on homophilic graphs. This work highlights the\npotential of federated learning in diverse and challenging graph settings.\nOpen-source code available on GitHub\n(https://github.com/SpringWiz11/Fed-GNODEFormer).", "published": "2025-04-16 06:43:20", "link": "http://arxiv.org/abs/2504.11808v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Discrimination-free Insurance Pricing with Privatized Sensitive Attributes", "abstract": "Fairness has emerged as a critical consideration in the landscape of machine\nlearning algorithms, particularly as AI continues to transform decision-making\nacross societal domains. To ensure that these algorithms are free from bias and\ndo not discriminate against individuals based on sensitive attributes such as\ngender and race, the field of algorithmic bias has introduced various fairness\nconcepts, along with methodologies to achieve these notions in different\ncontexts. Despite the rapid advancement, not all sectors have embraced these\nfairness principles to the same extent. One specific sector that merits\nattention in this regard is insurance. Within the realm of insurance pricing,\nfairness is defined through a distinct and specialized framework. Consequently,\nachieving fairness according to established notions does not automatically\nensure fair pricing in insurance. In particular, regulators are increasingly\nemphasizing transparency in pricing algorithms and imposing constraints on\ninsurance companies on the collection and utilization of sensitive consumer\nattributes. These factors present additional challenges in the implementation\nof fairness in pricing algorithms. To address these complexities and comply\nwith regulatory demands, we propose an efficient method for constructing fair\nmodels that are tailored to the insurance domain, using only privatized\nsensitive attributes. Notably, our approach ensures statistical guarantees,\ndoes not require direct access to sensitive attributes, and adapts to varying\ntransparency requirements, addressing regulatory demands while ensuring\nfairness in insurance pricing.", "published": "2025-04-16 05:29:11", "link": "http://arxiv.org/abs/2504.11775v1", "categories": ["stat.ML", "cs.CY", "cs.LG", "q-fin.RM"], "primary_category": "stat.ML"}
{"title": "Dynamics and Computational Principles of Echo State Networks: A Mathematical Perspective", "abstract": "Reservoir computing (RC) represents a class of state-space models (SSMs)\ncharacterized by a fixed state transition mechanism (the reservoir) and a\nflexible readout layer that maps from the state space. It is a paradigm of\ncomputational dynamical systems that harnesses the transient dynamics of\nhigh-dimensional state spaces for efficient processing of temporal data. Rooted\nin concepts from recurrent neural networks, RC achieves exceptional\ncomputational power by decoupling the training of the dynamic reservoir from\nthe linear readout layer, thereby circumventing the complexities of\ngradient-based optimization. This work presents a systematic exploration of RC,\naddressing its foundational properties such as the echo state property, fading\nmemory, and reservoir capacity through the lens of dynamical systems theory. We\nformalize the interplay between input signals and reservoir states,\ndemonstrating the conditions under which reservoirs exhibit stability and\nexpressive power. Further, we delve into the computational trade-offs and\nrobustness characteristics of RC architectures, extending the discussion to\ntheir applications in signal processing, time-series prediction, and control\nsystems. The analysis is complemented by theoretical insights into\noptimization, training methodologies, and scalability, highlighting open\nchallenges and potential directions for advancing the theoretical underpinnings\nof RC.", "published": "2025-04-16 04:28:05", "link": "http://arxiv.org/abs/2504.11757v1", "categories": ["cs.LG", "cs.NE", "37N35, 37D45, 93C10, 93C35, 93C40, 93C55", "I.2.8; I.5.2"], "primary_category": "cs.LG"}
{"title": "Unravelling Technical debt topics through Time, Programming Languages and Repository", "abstract": "This study explores the dynamic landscape of Technical Debt (TD) topics in\nsoftware engineering by examining its evolution across time, programming\nlanguages, and repositories. Despite the extensive research on identifying and\nquantifying TD, there remains a significant gap in understanding the diversity\nof TD topics and their temporal development. To address this, we have conducted\nan explorative analysis of TD data extracted from GitHub issues spanning from\n2015 to September 2023. We employed BERTopic for sophisticated topic modelling.\nThis study categorises the TD topics and tracks their progression over time.\nFurthermore, we have incorporated sentiment analysis for each identified topic,\nproviding a deeper insight into the perceptions and attitudes associated with\nthese topics. This offers a more nuanced understanding of the trends and shifts\nin TD topics through time, programming language, and repository.", "published": "2025-04-16 02:20:56", "link": "http://arxiv.org/abs/2504.11714v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Clustering and analysis of user behaviour in blockchain: A case study of Planet IX", "abstract": "Decentralised applications (dApps) that run on public blockchains have the\nbenefit of trustworthiness and transparency as every activity that happens on\nthe blockchain can be publicly traced through the transaction data. However,\nthis introduces a potential privacy problem as this data can be tracked and\nanalysed, which can reveal user-behaviour information. A user behaviour\nanalysis pipeline was proposed to present how this type of information can be\nextracted and analysed to identify separate behavioural clusters that can\ndescribe how users behave in the game. The pipeline starts with the collection\nof transaction data, involving smart contracts, that is collected from a\nblockchain-based game called Planet IX. Both the raw transaction information\nand the transaction events are considered in the data collection. From this\ndata, separate game actions can be formed and those are leveraged to present\nhow and when the users conducted their in-game activities in the form of user\nflows. An extended version of these user flows also presents how the\nNon-Fungible Tokens (NFTs) are being leveraged in the user actions. The latter\nis given as input for a Graph Neural Network (GNN) model to provide graph\nembeddings for these flows which then can be leveraged by clustering algorithms\nto cluster user behaviours into separate behavioural clusters. We benchmark and\ncompare well-known clustering algorithms as a part of the proposed method. The\nuser behaviour clusters were analysed and visualised in a graph format. It was\nfound that behavioural information can be extracted regarding the users that\nbelong to these clusters. Such information can be exploited by malicious users\nto their advantage. To demonstrate this, a privacy threat model was also\npresented based on the results that correspond to multiple potentially affected\nareas.", "published": "2025-04-16 01:57:33", "link": "http://arxiv.org/abs/2504.11702v1", "categories": ["cs.LG", "cs.CR"], "primary_category": "cs.LG"}
{"title": "H$^3$GNNs: Harmonizing Heterophily and Homophily in GNNs via Joint Structural Node Encoding and Self-Supervised Learning", "abstract": "Graph Neural Networks (GNNs) struggle to balance heterophily and homophily in\nrepresentation learning, a challenge further amplified in self-supervised\nsettings. We propose H$^3$GNNs, an end-to-end self-supervised learning\nframework that harmonizes both structural properties through two key\ninnovations: (i) Joint Structural Node Encoding. We embed nodes into a unified\nspace combining linear and non-linear feature projections with K-hop structural\nrepresentations via a Weighted Graph Convolution Network(WGCN). A\ncross-attention mechanism enhances awareness and adaptability to heterophily\nand homophily. (ii) Self-Supervised Learning Using Teacher-Student Predictive\nArchitectures with Node-Difficulty Driven Dynamic Masking Strategies. We use a\nteacher-student model, the student sees the masked input graph and predicts\nnode features inferred by the teacher that sees the full input graph in the\njoint encoding space. To enhance learning difficulty, we introduce two novel\nnode-predictive-difficulty-based masking strategies. Experiments on seven\nbenchmarks (four heterophily datasets and three homophily datasets) confirm the\neffectiveness and efficiency of H$^3$GNNs across diverse graph types. Our\nH$^3$GNNs achieves overall state-of-the-art performance on the four heterophily\ndatasets, while retaining on-par performance to previous state-of-the-art\nmethods on the three homophily datasets.", "published": "2025-04-16 01:51:25", "link": "http://arxiv.org/abs/2504.11699v1", "categories": ["cs.LG", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Traveling wave profiles for a semi-discrete Burgers equation", "abstract": "We look for traveling waves of the semi-discrete conservation law $4\\dot u_j\n+u_{j+1}^2-u_{j-1}^2 = 0$, using variational principles related to concepts of\n``hidden convexity'' appearing in recent studies of various PDE (partial\ndifferential equations). We analyze and numerically compute with two\nvariational formulations related to dual convex optimization problems\nconstrained by either the differential-difference equation (DDE) or nonlinear\nintegral equation (NIE) that wave profiles should satisfy. We prove existence\ntheorems conditional on the existence of extrema that satisfy a strict\nconvexity criterion, and numerically exhibit a variety of localized, periodic\nand non-periodic wave phenomena.", "published": "2025-04-16 15:23:43", "link": "http://arxiv.org/abs/2504.12171v1", "categories": ["math.AP", "cs.NA", "math.NA", "nlin.PS", "Primary: 49J35, 49M29 Secondary: 34K31, 70G75, 35Q70"], "primary_category": "math.AP"}
{"title": "Central-Upwind Scheme for the Phase-Transition Traffic Flow Model", "abstract": "Phase-transition models are an important family of non-equilibrium continuum\ntraffic flow models, offering properties like replicating complex traffic\nphenomena, maintaining anisotropy, and promising potentials for accommodating\nautomated vehicles. However, their complex mathematical characteristics such as\ndiscontinuous solution domains, pose numerical challenges and limit their\nexploration in traffic flow theory. This paper focuses on developing a robust\nand accurate numerical method for phase-transition traffic flow models: We\npropose a second-order semi-discrete central-upwind scheme specifically\ndesigned for discontinuous phase-transition models. This novel scheme\nincorporates the projection onto appropriate flow domains, ensuring enhanced\nhandling of discontinuities and maintaining physical consistency and accuracy.\nWe demonstrate the efficacy of the proposed scheme through extensive and\nchallenging numerical tests, showcasing their potential to facilitate further\nresearch and application in phase-transition traffic flow modeling. The ability\nof phase-transition models to embed the ``time-gap'' -- a crucial element in\nautomated traffic control -- as a conserved variable aligns seamlessly with the\ncontrol logic of automated vehicles, presenting significant potential for\nfuture applications, and the proposed numerical scheme now substantially\nfacilitates exploring such potentials.", "published": "2025-04-16 15:02:14", "link": "http://arxiv.org/abs/2504.12153v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Inclusion of an Inverse Magnetic Hysteresis Model into the Space-Time Finite Element Method for Magnetoquasistatics", "abstract": "In this note we discuss the numerical solution of the eddy current\napproximation of the Maxwell equations using the simple Pragmatic Algebraic\nModel to include hysteresis effects. In addition to the more standard\ntime-stepping approach we propose a space-time finite element method which\nallows both for parallelization and adaptivity simultaneously in space and\ntime. Numerical experiments confirm both approaches yield the same numerical\nresults.", "published": "2025-04-16 11:56:42", "link": "http://arxiv.org/abs/2504.12003v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Epstein zeta method for many-body lattice sums", "abstract": "Many-body interactions arise naturally in the perturbative treatment of\nclassical and quantum many-body systems and play a crucial role in the\ndescription of condensed matter systems. In the case of three-body\ninteractions, the Axilrod-Teller-Muto (ATM) potential is highly relevant for\nthe quantitative prediction of material properties. The computation of the\nresulting energies in d-dimensional lattice systems is challenging, as a\nhigh-dimensional lattice sum needs to be evaluated to high precision. This work\nsolves this long-standing issue. We present an efficiently computable\nrepresentation of many-body lattice sums in terms of singular integrals over\nproducts of Epstein zeta functions. For three-body interactions in 3D, this\napproach reduces the runtime for computing the ATM lattice sum from weeks to\nminutes. Our approach further extends to a broad class of n-body lattice sums.\nWe demonstrate that the computational cost of our method only increases\nlinearly with n, evading the exponential increase in complexity of direct\nsummation. The evaluation of 51-body interactions on a two-dimensional lattice,\ncorresponding to a 100-dimensional sum, can be performed within seconds on a\nlaptop. We discuss techniques for computing the arising singular integrals and\ncompare the accuracy of our results against computable benchmarks, achieving\nfull precision for exponents greater than the system dimension. Finally, we\napply our method to study the stability of a three-dimensional lattice system\nwith Lennard-Jones two-body interactions under the inclusion of an ATM\nthree-body term at finite pressure, finding a transition from the\nface-centered-cubic to the body-centered-cubic lattice structure with\nincreasing ATM coupling strength. This work establishes the mathematical\nfoundation for an ongoing investigation into the influence of many-body\ninteractions on the stability of matter.", "published": "2025-04-16 11:30:11", "link": "http://arxiv.org/abs/2504.11989v1", "categories": ["math.NA", "cond-mat.mtrl-sci", "cond-mat.str-el", "cs.NA"], "primary_category": "math.NA"}
{"title": "Strong Convergence Rates for Euler Schemes of Levy-Driven SDE using Dynamic Cutting", "abstract": "We derive strong Lp convergence rates for the Euler-Maruyama schemes of\nLevy-driven SDE using a new dynamic cutting (DC) method with a time-dependent\njump threshold. In addition, we present results from numerical simulations\ncomparing the DC and Asmussen-Rosinski (AR) approaches. These simulations\ndemonstrate the superior accuracy achieved by the DC method.", "published": "2025-04-16 11:29:14", "link": "http://arxiv.org/abs/2504.11988v1", "categories": ["math.PR", "cs.NA", "math.NA"], "primary_category": "math.PR"}
{"title": "Stochastic Quadrature Rules for Solving PDEs using Neural Networks", "abstract": "In this article, we consider issues surrounding integration when using Neural\nNetworks to solve Partial Differential Equations. We focus on the Deep Ritz\nMethod as it is of practical interest and sensitive to integration errors. We\nshow how both deterministic integration rules as well as biased, stochastic\nquadrature can lead to erroneous results, whilst high order, unbiased\nstochastic quadrature rules on integration meshes can significantly improve\nconvergence at an equivalent computational cost. Furthermore, we propose novel\nstochastic quadrature rules for triangular and tetrahedral elements, offering\ngreater flexibility when designing integration meshes in more complex\ngeometries. We highlight how the variance in the stochastic gradient limits\nconvergence, whilst quadrature rules designed to give similar errors when\nintegrating the loss function may lead to disparate results when employed in a\ngradient-based optimiser.", "published": "2025-04-16 11:15:38", "link": "http://arxiv.org/abs/2504.11976v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Dynamical reweighting for estimation of fluctuation formulas", "abstract": "We propose a variance reduction method for calculating transport coefficients\nin molecular dynamics using an importance sampling method via Girsanov's\ntheorem applied to Green--Kubo's formula. We optimize the magnitude of the\nperturbation applied to the reference dynamics by means of a scalar\nparameter~$\\alpha$ and propose an asymptotic analysis to fully characterize the\nlong-time behavior in order to evaluate the possible variance reduction.\nTheoretical results corroborated by numerical results show that this method\nallows for some reduction in variance, although rather modest in most\nsituations.", "published": "2025-04-16 11:01:20", "link": "http://arxiv.org/abs/2504.11968v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Convergence of finite elements for the Eyles-King-Styles model of tumour growth", "abstract": "This paper presents a convergence analysis of evolving surface finite element\nmethods (ESFEM) applied to the original Eyles-King-Styles model of tumour\ngrowth. The model consists of a Poisson equation in the bulk, a forced mean\ncurvature flow on the surface, and a coupled velocity law between bulk and\nsurface. Due to the non-trivial bulk-surface coupling, all previous analyses --\nwhich exclusively relied on energy-estimate based approaches -- required an\nadditional regularization term. By adopting the $\\widehat{H}^{3/2}$ theory and\nthe multilinear forms, we develop an essentially new theoretical framework that\nenables the application of PDE regularity theory to stability analysis. Based\non this framework, we provide the first rigorous convergence proof for the\noriginal model without regularization.", "published": "2025-04-16 10:00:02", "link": "http://arxiv.org/abs/2504.11926v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Lagrangian finite elements in Sobolev-like spaces of order $3/2$", "abstract": "This paper introduces a Sobolev-like space of order $3/2$, denoted as\n$\\widehat{H}^{3/2}$, for Lagrangian finite elements, especially for $C^0$\nelements. It is motivated by the limitations of current stability analysis of\nthe evolving surface finite element method (ESFEM), which relies exclusively on\nan energy estimate framework. To establish a PDE-based analysis framework for\nESFEM, we encounter a fundamental regularity mismatch: the ESFEM adopts the\n$C^0$ elements, while the PDE regularity theory requires $H^{3/2}$ regularity\nfor solutions. To overcome this difficulty, we first examine the properties of\nthe continuous $H^{3/2}$ space, then introduce a Dirichlet lift and Scott-Zhang\ntype interpolation operators to bridge to the discrete $\\widehat{H}^{3/2}$\nspace. Our new $\\widehat{H}^{3/2}$ space is shown to be compatible with the\nelliptic PDE regularity theory, the trace inequality, and the inverse\ninequality. Notably, we extend the critical domain deformation estimate in\nESFEM to the $\\widehat{H}^{3/2}$ setting. The $\\widehat{H}^{3/2}$ theory\nprovides a foundation for establishing a PDE-based convergence analysis\nframework of ESFEM.", "published": "2025-04-16 09:56:43", "link": "http://arxiv.org/abs/2504.11920v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A structure-preserving numerical method for quasi-incompressible Navier-Stokes-Maxwell-Stefan systems", "abstract": "A conforming finite element scheme with mixed explicit-implicit time\ndiscretization for quasi-incompressible Navier-Stokes-Maxwell-Stefan systems in\na bounded domain with periodic boundary conditions is presented. The system\nconsists of the Navier-Stokes equations, together with a\nquasi-incompressibility constraint, coupled with the cross-diffusion\nMaxwell-Stefan equations. The numerical scheme preserves the partial masses and\nthe quasi-incompressibility constraint and dissipates the discrete energy.\nNumerical experiments in two space dimensions illustrate the convergence of the\nscheme and the structure-preserving properties.", "published": "2025-04-16 09:19:39", "link": "http://arxiv.org/abs/2504.11892v1", "categories": ["math.NA", "cs.NA", "65M60, 65N30, 76T30, 80M10"], "primary_category": "math.NA"}
{"title": "On projection mappings and the gradient projection method on hyperbolic space forms", "abstract": "This paper presents several new properties of the intrinsic\n$\\kappa$-projection into $\\kappa$-hyperbolically convex sets of\n$\\kappa$-hyperbolic space forms, along with closed-form formulas for the\nintrinsic $\\kappa$-projection into specific $\\kappa$-hyperbolically convex\nsets. It also discusses the relationship between the intrinsic\n$\\kappa$-projection, the Euclidean orthogonal projection, and the Lorentz\nprojection. These properties lay the groundwork for analyzing the gradient\nprojection method and hold importance in their own right. Additionally, new\nproperties of the gradient projection method to solve constrained optimization\nproblems in $\\kappa$-hyperbolic space forms are established, considering both\nconstant and backtracking step sizes in the analysis. It is shown that every\naccumulation point of the sequence generated by the method for both step sizes\nis a stationary point for the given problem. Additionally, an iteration\ncomplexity bound is provided that upper bounds the number of iterations needed\nto achieve a suitable measure of stationarity for both step sizes. Finally, the\nproperties of the constrained Fermat-Weber problem are explored, demonstrating\nthat the sequence generated by the gradient projection method converges to its\nunique solution. Numerical experiments on solving the Fermat-Weber problem are\npresented, illustrating the theoretical findings and demonstrating the\neffectiveness of the proposed methods.", "published": "2025-04-16 07:01:00", "link": "http://arxiv.org/abs/2504.11815v1", "categories": ["math.OC", "cs.NA", "math.DG", "math.NA"], "primary_category": "math.OC"}
{"title": "A Technical Survey of Sparse Linear Solvers in Electronic Design Automation", "abstract": "Sparse linear system solvers ($Ax=b$) are critical computational kernels in\nElectronic Design Automation (EDA), underpinning vital simulations for modern\nIC and system design. Applications like power integrity verification and\nelectrothermal analysis fundamentally solve large-scale, sparse algebraic\nsystems from Modified Nodal Analysis (MNA) or Finite Element/Volume Method\n(FEM/FVM) discretizations of PDEs. Problem dimensions routinely reach\n$10^6-10^9$ unknowns, escalating towards $10^{10}$+ for full-chip power grids\n\\cite{Tsinghua21}, demanding stringent solver scalability, low memory\nfootprint, and efficiency. This paper surveys predominant sparse solver\nparadigms in EDA: direct factorization methods (LU, Cholesky), iterative Krylov\nsubspace methods (CG, GMRES, BiCGSTAB), and multilevel multigrid techniques. We\nexamine their mathematical foundations, convergence, conditioning sensitivity,\nimplementation aspects (storage formats CSR/CSC, fill-in mitigation via\nreordering), the critical role of preconditioning for ill-conditioned systems\n\\cite{SaadIterative, ComparisonSolversArxiv}, and multigrid's potential optimal\n$O(N)$ complexity \\cite{TrottenbergMG}. Solver choice critically depends on the\nperformance impact of frequent matrix updates (e.g., transient/non-linear),\nwhere iterative/multigrid methods often amortize costs better than direct\nmethods needing repeated factorization \\cite{SaadIterative}. We analyze\ntrade-offs in runtime complexity, memory needs, numerical robustness, parallel\nscalability (MPI, OpenMP, GPU), and precision (FP32/FP64). Integration into EDA\ntools for system-level multiphysics is discussed, with pseudocode\nillustrations. The survey concludes by emphasizing the indispensable nature and\nongoing evolution of sparse solvers for designing and verifying complex\nelectronic systems.", "published": "2025-04-16 02:34:21", "link": "http://arxiv.org/abs/2504.11716v1", "categories": ["math.NA", "cs.NA", "cs.PF"], "primary_category": "math.NA"}
{"title": "Fast Mixed-Precision Real Evaluation", "abstract": "Evaluating real-valued expressions to high precision is a key building block\nin computational mathematics, physics, and numerics. A typical implementation\nevaluates the whole expression in a uniform precision, doubling that precision\nuntil a sufficiently-accurate result is achieved. This is wasteful: usually\nonly a few operations really need to be performed at high precision, and the\nbulk of the expression could be computed much faster. However, such non-uniform\nprecision assignments have, to date, been impractical to compute. We propose a\nfast new algorithm for deriving such precision assignments. The algorithm\nleverages results computed at lower precisions to analytically determine a\nmixed-precision assignment that will result in a sufficiently-accurate result.\nOur implementation, Reval, achieves an average speed-up of 1.72x compared to\nthe state-of-the-art Sollya tool, with the speed-up increasing to 5.21x on the\nmost difficult input points. An examination of the precisions used with and\nwithout precision tuning shows that the speed-up results from assigning lower\nprecisions for the majority of operations, though additional optimizations\nenabled by the non-uniform precision assignments also play a role.", "published": "2025-04-16 02:12:20", "link": "http://arxiv.org/abs/2504.11708v1", "categories": ["math.NA", "cs.MS", "cs.NA"], "primary_category": "math.NA"}
{"title": "A method for bounding high-order finite element functions: Applications to mesh validity and bounds-preserving limiters", "abstract": "We introduce a novel method for bounding high-order multi-dimensional\npolynomials in finite element approximations. The method involves precomputing\noptimal piecewise-linear bounding boxes for polynomial basis functions, which\ncan then be used to locally bound any combination of these basis functions.\nThis approach can be applied to any element/basis type at any approximation\norder, can provide local (i.e., subcell) extremum bounds to a desired level of\naccuracy, and can be evaluated efficiently on-the-fly in simulations.\nFurthermore, we show that this approach generally yields more accurate bounds\nin comparison to traditional methods based on convex hull properties (e.g.,\nBernstein polynomials). The efficacy of this technique is shown in applications\nsuch as mesh validity checks and optimization for high-order curved meshes,\nwhere positivity of the element Jacobian determinant can be ensured throughout\nthe entire element, and continuously bounds-preserving limiters for hyperbolic\nsystems, which can enforce maximum principle bounds across the entire solution\npolynomial.", "published": "2025-04-16 01:06:48", "link": "http://arxiv.org/abs/2504.11688v1", "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "primary_category": "math.NA"}
{"title": "FEM-DtN-SIM Method for Computing Resonances of Schr\u00f6dinger Operators", "abstract": "The study of resonances of the Schr\\\"{o}dinger operator has a long-standing\ntradition in mathematical physics. Extensive theoretical investigations have\nexplored the proximity of resonances to the real axis, their distribution, and\nbounds on the counting functions. However, computational results beyond one\ndimension remain scarce due to the nonlinearity of the problem and the\nunbounded nature of the domain. We propose a novel approach that integrates\nfinite elements, Dirichlet-to-Neumann (DtN) mapping, and the spectral indicator\nmethod. The DtN mapping, imposed on the boundary of a truncated computational\ndomain, enforces the outgoing condition. Finite elements allow for the\nefficient handling of complicated potential functions. The spectral indicator\nmethod effectively computes (complex) eigenvalues of the resulting nonlinear\nalgebraic system without introducing spectral pollution. The viability of this\napproach is demonstrated through a range of numerical examples.", "published": "2025-04-16 00:34:11", "link": "http://arxiv.org/abs/2504.11680v1", "categories": ["math.NA", "cs.NA", "78M10, 65H17, 65N25"], "primary_category": "math.NA"}
{"title": "Maximum bound principle for Q-tensor gradient flow with low regularity integrators", "abstract": "We investigate low-regularity integrator (LRI) methods for the Q-tensor model\ngoverning nematic liquid-crystalline semilinear parabolic equation. First- and\nsecond-order temporal discretizations are developed using Duhamel's formula,\nand we rigorously prove that both schemes preserve the maximum bound principle\n(MBP) and energy dissipation under minimal regularity requirements. Optimal\nconvergence rates are established for the proposed methods. Numerical\nexperiments validate the theoretical findings, demonstrating that the\neigenvalues of Q remain strictly confined within the physical range\n(-1/3},2/3).", "published": "2025-04-16 00:22:05", "link": "http://arxiv.org/abs/2504.11676v1", "categories": ["math.NA", "cs.NA", "65M06", "G.1.8"], "primary_category": "math.NA"}
{"title": "Universal portfolios in continuous time: a model-free approach", "abstract": "We provide a simple and straightforward approach to a continuous-time version\nof Cover's universal portfolio strategies within the model-free context of\nF\\\"ollmer's pathwise It\\^o calculus. We establish the existence of the\nuniversal portfolio strategy and prove that its portfolio value process is the\naverage of all values of constant rebalanced strategies. This result relies on\na systematic comparison between two alternative descriptions of self-financing\ntrading strategies within pathwise It\\^o calculus. We moreover provide a\ncomparison result for the performance and the realized volatility and variance\nof constant rebalanced portfolio strategies.", "published": "2025-04-16 09:05:53", "link": "http://arxiv.org/abs/2504.11881v1", "categories": ["q-fin.MF", "q-fin.PM"], "primary_category": "q-fin.MF"}
{"title": "Trend Filtered Mixture of Experts for Automated Gating of High-Frequency Flow Cytometry Data", "abstract": "Ocean microbes are critical to both ocean ecosystems and the global climate.\nFlow cytometry, which measures cell optical properties in fluid samples, is\nroutinely used in oceanographic research. Despite decades of accumulated data,\nidentifying key microbial populations (a process known as ``gating'') remains a\nsignificant analytical challenge. To address this, we focus on gating\nmultidimensional, high-frequency flow cytometry data collected {\\it\ncontinuously} on board oceanographic research vessels, capturing time- and\nspace-wise variations in the dynamic ocean. Our paper proposes a novel\nmixture-of-experts model in which both the gating function and the experts are\ngiven by trend filtering. The model leverages two key assumptions: (1) Each\nsnapshot of flow cytometry data is a mixture of multivariate Gaussians and (2)\nthe parameters of these Gaussians vary smoothly over time. Our method uses\nregularization and a constraint to ensure smoothness and that cluster means\nmatch biologically distinct microbe types. We demonstrate, using flow cytometry\ndata from the North Pacific Ocean, that our proposed model accurately matches\nhuman-annotated gating and corrects significant errors.", "published": "2025-04-16 17:51:59", "link": "http://arxiv.org/abs/2504.12287v1", "categories": ["stat.ME", "stat.AP", "stat.ML", "62H30 (Primary) 62G08, 92B10, 62J07 (Secondary)"], "primary_category": "stat.ME"}
{"title": "Proximal Inference on Population Intervention Indirect Effect", "abstract": "The population intervention indirect effect (PIIE) is a novel mediation\neffect representing the indirect component of the population intervention\neffect. Unlike traditional mediation measures, such as the natural indirect\neffect, the PIIE holds particular relevance in observational studies involving\nunethical exposures, when hypothetical interventions that impose harmful\nexposures are inappropriate. Although prior research has identified PIIE under\nunmeasured confounders between exposure and outcome, it has not fully addressed\nthe confounding that affects the mediator. This study extends the PIIE\nidentification to settings where unmeasured confounders influence\nexposure-outcome, exposure-mediator, and mediator-outcome relationships.\nSpecifically, we leverage observed covariates as proxy variables for unmeasured\nconfounders, constructing three proximal identification frameworks.\nAdditionally, we characterize the semiparametric efficiency bound and develop\nmultiply robust and locally efficient estimators. To handle high-dimensional\nnuisance parameters, we propose a debiased machine learning approach that\nachieves $\\sqrt{n}$-consistency and asymptotic normality to estimate the true\nPIIE values, even when the machine learning estimators for the nuisance\nfunctions do not converge at $\\sqrt{n}$-rate. In simulations, our estimators\ndemonstrate higher confidence interval coverage rates than conventional methods\nacross various model misspecifications. In a real data application, our\napproaches reveal an indirect effect of alcohol consumption on depression risk\nmediated by depersonalization symptoms.", "published": "2025-04-16 08:14:55", "link": "http://arxiv.org/abs/2504.11848v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Experimental Analysis of Multipath Characteristics in Indoor Distributed Massive MIMO Channels", "abstract": "Distributed massive multiple-input multiple-output (MIMO), also known as\ncell-free massive MIMO, has emerged as a promising technology for\nsixth-generation (6G) wireless networks. This letter introduces an indoor\nchannel measurement campaign designed to explore the behavior of multipath\ncomponents (MPCs) in distributed massive MIMO channels. Fully coherent channels\nwere measured between eight distributed uniform planar arrays (128 elements in\ntotal) and a 12-meter user equipment route. Furthermore, a method is introduced\nto determine the order (single- or multi-bounce) of MPC interaction by\nleveraging map information and MPC parameters. In addition, a Kalman\nfilter-based framework is used for identifying the MPC interaction mechanisms\n(reflection or scattering/diffraction/mixed). Finally, a comprehensive\nMPC-level characterization is performed based on the measured channels,\nincluding the significance of the single-bounce MPCs, the spherical wavefront\nfeatures, the birth-and-death processes of the MPCs, and the spatial\ndistribution of reflections. The findings serve as a valuable reference for\nunderstanding MPC propagation behavior, which is necessary for accurate\nmodeling of indoor distributed massive MIMO channels.", "published": "2025-04-16 17:08:12", "link": "http://arxiv.org/abs/2504.12258v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Mobile Distributed MIMO (MD-MIMO) for NextG: Mobility Meets Cooperation in Distributed Arrays", "abstract": "Distributed multiple-input multiple-output (D\\mbox{-}MIMO) is a promising\ntechnology to realize the promise of massive MIMO gains by fiber-connecting the\ndistributed antenna arrays, thereby overcoming the form factor limitations of\nco-located MIMO. In this paper, we introduce the concept of mobile D-MIMO\n(MD-MIMO) network, a further extension of the D-MIMO technology where\ndistributed antenna arrays are connected to the base station with a wireless\nlink allowing all radio network nodes to be mobile. This approach significantly\nimproves deployment flexibility and reduces operating costs, enabling the\nnetwork to adapt to the highly dynamic nature of next-generation (NextG)\nnetworks. We discuss use cases, system design, network architecture, and the\nkey enabling technologies for MD-MIMO. Furthermore, we investigate a case study\nof MD-MIMO for vehicular networks, presenting detailed performance evaluations\nfor both downlink and uplink. The results show that an MD-MIMO network can\nprovide substantial improvements in network throughput and reliability.", "published": "2025-04-16 16:48:29", "link": "http://arxiv.org/abs/2504.12244v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Interacting Object-Enabled Clustering and Characterization of Distributed MIMO Channels", "abstract": "Distributed multiple-input multiple-output (MIMO), also known as cell-free\nmassive MIMO, emerges as a promising technology for sixth-generation (6G)\nsystems to support uniform coverage and reliable communication. For the design\nand optimization of such systems, measurement-based investigations of\nreal-world distributed MIMO channels are essential. In this paper, we present\nan indoor channel measurement campaign, featuring eight distributed antenna\narrays with 128 elements in total. Multi-link channels are measured at 50\npositions along a 12-meter user route. A clustering algorithm enabled by\ninteracting objects is proposed to identify clusters in the measured channels.\nThe algorithm jointly clusters the multipath components for all links,\neffectively capturing the dynamic contributions of common clusters to different\nlinks. In addition, a Kalman filter-based tracking framework is introduced for\ncluster prediction, tracking, and updating along the user movement. Using the\nclustering and tracking results, cluster-level characterization of the measured\nchannels is performed. First, the number of clusters and their visibility at\nboth link ends are analyzed. Next, a maximum-likelihood estimator is utilized\nto determine the entire cluster visibility region length. Finally, key\ncluster-level properties, including the common cluster ratio, cluster power,\nshadowing, spread, among others, are statistically investigated. The results\nprovide valuable insights into cluster behavior in typical multi-link channels,\nnecessary for accurate modeling of distributed MIMO channels.", "published": "2025-04-16 16:13:33", "link": "http://arxiv.org/abs/2504.12220v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Deep Generative Models for Bayesian Inference on High-Rate Sensor Data: Applications in Automotive Radar and Medical Imaging", "abstract": "Deep generative models have been studied and developed primarily in the\ncontext of natural images and computer vision. This has spurred the development\nof (Bayesian) methods that use these generative models for inverse problems in\nimage restoration, such as denoising, inpainting, and super-resolution. In\nrecent years, generative modeling for Bayesian inference on sensory data has\nalso gained traction. Nevertheless, the direct application of generative\nmodeling techniques initially designed for natural images on raw sensory data\nis not straightforward, requiring solutions that deal with high dynamic range\nsignals acquired from multiple sensors or arrays of sensors that interfere with\neach other, and that typically acquire data at a very high rate. Moreover, the\nexact physical data-generating process is often complex or unknown. As a\nconsequence, approximate models are used, resulting in discrepancies between\nmodel predictions and the observations that are non-Gaussian, in turn\ncomplicating the Bayesian inverse problem. Finally, sensor data is often used\nin real-time processing or decision-making systems, imposing stringent\nrequirements on, e.g., latency and throughput. In this paper, we will discuss\nsome of these challenges and offer approaches to address them, all in the\ncontext of high-rate real-time sensing applications in automotive radar and\nmedical imaging.", "published": "2025-04-16 15:03:01", "link": "http://arxiv.org/abs/2504.12154v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "The CAM Model: An in vivo Testbed for Molecular Communication Systems", "abstract": "Molecular communication (MC) research increasingly focuses on biomedical\napplications like health monitoring and drug delivery, demanding testing in\nrealistic living environments. Elevating MC research requires developing\nadvanced in vivo testbeds. We introduce the chorioallantoic membrane (CAM)\nmodel as the first versatile 3D in vivo MC platform. The CAM, a highly\nvascularized membrane in fertilized chicken eggs, is established in\nbioengineering, cancer research, and drug development. Its biological realism,\nreproducibility, and versatility make it ideal for next-generation MC testbeds,\nbridging proof-of-concept systems and practical applications. We\ncomprehensively characterize the CAM model's properties and MC system\nrelevance. Through experimental studies, we investigate fluorescent molecule\ndistribution in the CAM's closed-loop vascular system. We derive an analytical\nmodel using the wrapped normal distribution to describe particle propagation in\ndispersive closed-loop systems dominated by diffusion and flow. Parametric\nmodels are developed to approximate particle dynamics in the CAM, with\nparameters estimated via nonlinear least squares curve fitting. A dataset of 69\nregions from 25 eggs validates our models. We analyze parameter relationships\nand biological plausibility. Finally, we develop a parametric model for\nlong-term particle behavior and liver accumulation in chick embryos.", "published": "2025-04-16 14:35:53", "link": "http://arxiv.org/abs/2504.12123v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Mind2Matter: Creating 3D Models from EEG Signals", "abstract": "The reconstruction of 3D objects from brain signals has gained significant\nattention in brain-computer interface (BCI) research. Current research\npredominantly utilizes functional magnetic resonance imaging (fMRI) for 3D\nreconstruction tasks due to its excellent spatial resolution. Nevertheless, the\nclinical utility of fMRI is limited by its prohibitive costs and inability to\nsupport real-time operations. In comparison, electroencephalography (EEG)\npresents distinct advantages as an affordable, non-invasive, and mobile\nsolution for real-time brain-computer interaction systems. While recent\nadvances in deep learning have enabled remarkable progress in image generation\nfrom neural data, decoding EEG signals into structured 3D representations\nremains largely unexplored. In this paper, we propose a novel framework that\ntranslates EEG recordings into 3D object reconstructions by leveraging neural\ndecoding techniques and generative models. Our approach involves training an\nEEG encoder to extract spatiotemporal visual features, fine-tuning a large\nlanguage model to interpret these features into descriptive multimodal outputs,\nand leveraging generative 3D Gaussians with layout-guided control to synthesize\nthe final 3D structures. Experiments demonstrate that our model captures\nsalient geometric and semantic features, paving the way for applications in\nbrain-computer interfaces (BCIs), virtual reality, and neuroprosthetics.Our\ncode is available in https://github.com/sddwwww/Mind2Matter.", "published": "2025-04-16 10:16:03", "link": "http://arxiv.org/abs/2504.11936v1", "categories": ["cs.GR", "cs.HC", "eess.SP"], "primary_category": "cs.GR"}
{"title": "Super-LoRa: Enhancing LoRa Throughput via Payload Superposition", "abstract": "This paper presents Super-LoRa, a novel approach to enhancing the throughput\nof LoRa networks by leveraging the inherent robustness of LoRa modulation\nagainst interference. By superimposing multiple payload symbols, Super-LoRa\nsignificantly increases the data rate while maintaining lower transmitter and\nreceiver complexity. Our solution is evaluated through both simulations and\nreal-world experiments, showing a potential throughput improvement of up to 5x\ncompared to standard LoRa. This advancement positions Super-LoRa as a viable\nsolution for data-intensive IoT applications such as smart cities and precision\nagriculture, which demand higher data transmission rates.", "published": "2025-04-16 10:02:38", "link": "http://arxiv.org/abs/2504.11927v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Novel Splitter Design for RSMA Networks", "abstract": "Rate splitting multiple access (RSMA) has firmly established itself as a\npowerful methodology for multiple access, interference management, and\nmulti-user strategy for next-generation communication systems. In this paper,\nwe propose a novel channel-dependent splitter design for multi-carrier RSMA\nsystems, aimed at improving reliability performance. Specifically, the proposed\nsplitter leverages channel state information and the inherent structure of RSMA\nto intelligently replicate segments of the private stream data that are likely\nto encounter deep-faded subchannels into the common stream. Thus, the\nreliability is enhanced within the same transmission slot, minimizing the need\nfor frequent retransmissions and thereby reducing latency. To assess the\neffectiveness of our approach, we conduct comprehensive evaluations using key\nperformance metrics, including achievable sum rate, average packet delay, and\nbit error rate (BER), under both perfect and imperfect channel estimation\nscenarios.", "published": "2025-04-16 09:30:02", "link": "http://arxiv.org/abs/2504.11905v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "A Novel Approach to Secure RSMA Networks", "abstract": "This letter introduces a novel data-dependent interleaving technique designed\nto enhance the security of rate-splitting multiple access (RSMA) networks by\nprotecting the common stream from eavesdropping threats. Specifically, we\nexploit the RSMA structure by interleaving the common bits of each user based\non a sequence derived from their private bits. By decoding its private stream,\nthe legitimate receiver reconstructs the interleaving sequence set by the\ntransmitter and successfully de-interleaves the common stream. Therefore, the\ncommon part is successfully prevented from being intercepted by an eavesdropper\nwho is unable to deduce the dynamic changing interleaving permutations. To\nensure dynamic interleaving sequences, a private bit selection approach that\nbalances the trade-off between security and system efficiency is proposed.\nSimulation findings confirm the effectiveness of the suggested method, showing\nnotable security improvements while maintaining robust overall system\nreliability.", "published": "2025-04-16 08:59:10", "link": "http://arxiv.org/abs/2504.11878v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Channel-Adaptive Robust Resource Allocation for Highly Reliable IRS-Assisted V2X Communications", "abstract": "This paper addresses the challenges of resource allocation in vehicular\nnetworks enhanced by Intelligent Reflecting Surfaces (IRS), considering the\nuncertain Channel State Information (CSI) typical of vehicular environments due\nto the Doppler shift. Leveraging the 3GPP's Mode 1 cellular V2X architecture,\nour system model facilitates efficient subcarrier usage and interference\nreduction through coordinated V2I and V2V communications. Each Cellular User\nEquipment (CUE) shares its spectrum with at most one Vehicular User Equipment\n(VUE) in a one-to-one reuse pattern. We formulate a joint optimization problem\nfor vehicular transmit power, Multi-User Detection (MUD) matrices, V2V link\nspectrum reuse, and IRS reflection coefficients in IRS-aided V2X communication\nwith imperfect CSI. To tackle this, a novel robust resource allocation\nalgorithm is developed by first decomposing the problem into manageable\nsub-problems such as power allocation, MUD matrices optimization and IRS phase\nshifts, and then using the Block Coordinate Descent (BCD) method to alternately\noptimize these subproblems for optimal resource allocation. Our contributions\ninclude efficient approaches for self-learning based power allocation and phase\nshift optimization that adapt to CSI uncertainties, significantly enhancing the\nreliability and efficiency of vehicular communications. Simulation results\nvalidate the effectiveness of the proposed solutions in improving the Quality\nof Service (QoS) and managing the complex interference inherent in dense\nvehicular networks.", "published": "2025-04-16 08:48:53", "link": "http://arxiv.org/abs/2504.11871v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Scalable Multi-task Edge Sensing via Task-oriented Joint Information Gathering and Broadcast", "abstract": "The recent advance of edge computing technology enables significant sensing\nperformance improvement of Internet of Things (IoT) networks. In particular, an\nedge server (ES) is responsible for gathering sensing data from distributed\nsensing devices, and immediately executing different sensing tasks to\naccommodate the heterogeneous service demands of mobile users. However, as the\nnumber of users surges and the sensing tasks become increasingly\ncompute-intensive, the huge amount of computation workloads and data\ntransmissions may overwhelm the edge system of limited resources. Accordingly,\nwe propose in this paper a scalable edge sensing framework for multi-task\nexecution, in the sense that the computation workload and communication\noverhead of the ES do not increase with the number of downstream users or\ntasks. By exploiting the task-relevant correlations, the proposed scheme\nimplements a unified encoder at the ES, which produces a common low-dimensional\nmessage from the sensing data and broadcasts it to all users to execute their\nindividual tasks. To achieve high sensing accuracy, we extend the well-known\ninformation bottleneck theory to a multi-task scenario to jointly optimize the\ninformation gathering and broadcast processes. We also develop an efficient\ntwo-step training procedure to optimize the parameters of the neural\nnetwork-based codecs deployed in the edge sensing system. Experiment results\nshow that the proposed scheme significantly outperforms the considered\nrepresentative benchmark methods in multi-task inference accuracy. Besides, the\nproposed scheme is scalable to the network size, which maintains almost\nconstant computation delay with less than 1% degradation of inference\nperformance when the user number increases by four times.", "published": "2025-04-16 08:06:46", "link": "http://arxiv.org/abs/2504.11843v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Properties of Near Field Focusing for Cylindrical Dipole Arrays in Enclosed Array Volume", "abstract": "Motivated by large intelligent surface applications, the electric field\nproperties of near field focusing using phase conjugation method are analyzed\nfor cylindrical dipole arrays. Firstly, for the transmitting antennas featuring\nvertical polarization, the polarization characteristic is decomposed along the\nx, y, and z directions. Three typical cases are studied when the focal points\nare at (xf , 0, 0), (0, yf , 0), and (0, 0, zf ). When the length of the\ncylindrical dipole array is significantly larger compared to its radius,\ncertain unique insights emerge. When the focal point is positioned along (0, 0,\nzf ), apart from the region on both sides, the ratio between Ez and Ex/Ey\nremains {\\pi}/2. Additionally, When the focal point is located within the\ncylinder, the electric field of each polarization is approximately the same\neverywhere. In other words, beam focusing does not incur losses due to\ndifferent positions. The focusing resolution of Ez is the same in the\ntransverse and longitudinal directions. Different from the situation where the\n3 - dB focal beam depth is much smaller than the focal beam width for the most\nof arrays, the resolution in the longitudinal can be improved, respectively.\nThrough a comprehensive grasp of these design principles, we can gain a deeper\nunderstanding of the specific areas with significant potential for practical\napplications.", "published": "2025-04-16 07:16:33", "link": "http://arxiv.org/abs/2504.11822v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Virtual VNA 3.1: Non-Coherent-Detection-Based Non-Reciprocal Scattering Matrix Estimation Leveraging a Tunable Load Network", "abstract": "We refine the recently introduced \"Virtual VNA 3.0\" technique to remove the\nneed for coherent detection. The resulting \"Virtual VNA 3.1\" technique can\nunambiguously estimate the full scattering matrix of a non-reciprocal, linear,\npassive, time-invariant device under test (DUT) with $N$ monomodal ports using\nan $N_\\mathrm{A}$-channel coherent wavefront generator and an\n$N_\\mathrm{A}$-channel non-coherent detector, where $N_\\mathrm{A}<N$. Waves are\ninjected and received only via a fixed set of $N_\\mathrm{A}$ \"accessible\" DUT\nports while the remaining $N_\\mathrm{S}$ \"not-directly-accessible\" DUT ports\nare terminated by a specific tunable load network. To resolve all ambiguities,\nan additional modified setup is required in which waves are injected and\nreceived via a known $2N_\\mathrm{A}$-port system connected to the DUT's\naccessible ports. We experimentally validate our method for\n$N_\\mathrm{A}=N_\\mathrm{S}=4$ considering a non-reciprocal eight-port circuit\nas DUT. By eliminating the need for coherent detection, our work reduces the\nhardware complexity which may facilitate applications to large-scale or\nhigher-frequency systems. Additionally, our work provides fundamental insights\ninto the minimal requirements to fully and unambiguously characterize a\nnon-reciprocal DUT.", "published": "2025-04-16 05:42:51", "link": "http://arxiv.org/abs/2504.11790v1", "categories": ["physics.app-ph", "eess.SP"], "primary_category": "physics.app-ph"}
{"title": "EdgePrompt: A Distributed Key-Value Inference Framework for LLMs in 6G Networks", "abstract": "As sixth-generation (6G) networks advance, large language models (LLMs) are\nincreasingly integrated into 6G infrastructure to enhance network management\nand intelligence. However, traditional LLMs architecture struggle to meet the\nstringent latency and security requirements of 6G, especially as the increasing\nin sequence length leads to greater task complexity. This paper proposes\nEdge-Prompt, a cloud-edge collaborative framework based on a hierarchical\nattention splicing mechanism. EdgePrompt employs distributed key-value (KV)\npair optimization techniques to accelerate inference and adapt to network\nconditions. Additionally, to reduce the risk of data leakage, EdgePrompt\nincorporates a privacy preserving strategy by isolating sensitive information\nduring processing. Experiments on public dataset show that EdgePrompt\neffectively improves the inference throughput and reduces the latency, which\nprovides a reliable solution for LLMs deployment in 6G environments.", "published": "2025-04-16 03:07:07", "link": "http://arxiv.org/abs/2504.11729v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "ESC-MVQ: End-to-End Semantic Communication With Multi-Codebook Vector Quantization", "abstract": "This paper proposes a novel end-to-end digital semantic communication\nframework based on multi-codebook vector quantization (VQ), referred to as\nESC-MVQ. Unlike prior approaches that rely on end-to-end training with a\nspecific power or modulation scheme, often under a particular channel\ncondition, ESC-MVQ models a channel transfer function as parallel binary\nsymmetric channels (BSCs) with trainable bit-flip probabilities. Building on\nthis model, ESC-MVQ jointly trains multiple VQ codebooks and their associated\nbit-flip probabilities with a single encoder-decoder pair. To maximize\ninference performance when deploying ESC-MVQ in digital communication systems,\nwe devise an optimal communication strategy that jointly optimizes codebook\nassignment, adaptive modulation, and power allocation. To this end, we develop\nan iterative algorithm that selects the most suitable VQ codebook for semantic\nfeatures and flexibly allocates power and modulation schemes across the\ntransmitted symbols. Simulation results demonstrate that ESC-MVQ, using a\nsingle encoder-decoder pair, outperforms existing digital semantic\ncommunication methods in both performance and memory efficiency, offering a\nscalable and adaptive solution for realizing digital semantic communication in\ndiverse channel conditions.", "published": "2025-04-16 02:12:57", "link": "http://arxiv.org/abs/2504.11709v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Bayesian dynamic borrowing considering semantic similarity between outcomes for disproportionality analysis in FAERS", "abstract": "We present a Bayesian dynamic borrowing (BDB) approach to enhance the\nquantitative identification of adverse events (AEs) in spontaneous reporting\nsystems (SRSs). The method embeds a robust meta-analytic predictive (MAP) prior\nwithin a Bayesian hierarchical model and incorporates semantic similarity\nmeasures (SSMs) to enable weighted information sharing from MedDRA Preferred\nTerms (PTs) that are clinically similar to the target PT. This continuous\nsimilarity-based borrowing addresses limitation of rigid hierarchical grouping\nin current disproportionality analysis (DPA).\n  Using data from the FDA Adverse Event Reporting System (FAERS) between 2015\nand 2019, we evaluate this approach - termed IC SSM - against standard\nInformation Component (IC) analysis and IC with borrowing at the MedDRA\nhigh-level group term (HLGT) level. A novel references set (PVLens), derived\nfrom FDA product label updates, enabled prospective evaluation of method\nperformance in identifying AEs prior to official labeling.\n  The IC SSM approach demonstrated improved sensitivity compared to both\ntraditional IC and HLGT-based borrowing, with minor trade-offs in F1 scores and\nYouden's index. IC SSM consistently identified more true positives and detected\nsignals over 5 months sooner than traditional IC. Despite a marginally lower\naggregate Youden's index, IC SSM showed higher performance in the early\npost-marketing period, providing more stable and relevant estimates than\nHLGT-based borrowing and traditional IC.\n  These findings support the use of SSM-informed Bayesian borrowing as a\nscalable and context-aware enhancement to traditional DPA methods. Future\nresearch should validate this approach across other datasets and explore\nadditional similarity metrics and Bayesian inference strategies using\ncase-level data.", "published": "2025-04-16 13:06:24", "link": "http://arxiv.org/abs/2504.12052v2", "categories": ["cs.CL", "I.2.4; G.3; H.3.3"], "primary_category": "cs.CL"}
{"title": "Selective Attention Federated Learning: Improving Privacy and Efficiency for Clinical Text Classification", "abstract": "Federated Learning (FL) faces major challenges regarding communication\noverhead and model privacy when training large language models (LLMs),\nespecially in healthcare applications. To address these, we introduce Selective\nAttention Federated Learning (SAFL), a novel approach that dynamically\nfine-tunes only those transformer layers identified as attention-critical. By\nemploying attention patterns to determine layer importance, SAFL significantly\nreduces communication bandwidth and enhances differential privacy resilience.\nEvaluations on clinical NLP benchmarks (i2b2 Clinical Concept Extraction and\nMIMIC-III discharge summaries) demonstrate that SAFL achieves competitive\nperformance with centralized models while substantially improving communication\nefficiency and privacy preservation.", "published": "2025-04-16 05:59:29", "link": "http://arxiv.org/abs/2504.11793v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions", "abstract": "Unmanned Aerial Vehicles (UAVs) are indispensable for infrastructure\ninspection, surveillance, and related tasks, yet they also introduce critical\nsecurity challenges. This survey provides a wide-ranging examination of the\nanti-UAV domain, centering on three core objectives-classification, detection,\nand tracking-while detailing emerging methodologies such as diffusion-based\ndata synthesis, multi-modal fusion, vision-language modeling, self-supervised\nlearning, and reinforcement learning. We systematically evaluate\nstate-of-the-art solutions across both single-modality and multi-sensor\npipelines (spanning RGB, infrared, audio, radar, and RF) and discuss\nlarge-scale as well as adversarially oriented benchmarks. Our analysis reveals\npersistent gaps in real-time performance, stealth detection, and swarm-based\nscenarios, underscoring pressing needs for robust, adaptive anti-UAV systems.\nBy highlighting open research directions, we aim to foster innovation and guide\nthe development of next-generation defense strategies in an era marked by the\nextensive use of UAVs.", "published": "2025-04-16 10:58:33", "link": "http://arxiv.org/abs/2504.11967v2", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Causality-enhanced Decision-Making for Autonomous Mobile Robots in Dynamic Environments", "abstract": "The growing integration of robots in shared environments -- such as\nwarehouses, shopping centres, and hospitals -- demands a deep understanding of\nthe underlying dynamics and human behaviours, including how, when, and where\nindividuals engage in various activities and interactions. This knowledge goes\nbeyond simple correlation studies and requires a more comprehensive causal\nanalysis. By leveraging causal inference to model cause-and-effect\nrelationships, we can better anticipate critical environmental factors and\nenable autonomous robots to plan and execute tasks more effectively. To this\nend, we propose a novel causality-based decision-making framework that reasons\nover a learned causal model to predict battery usage and human obstructions,\nunderstanding how these factors could influence robot task execution. Such\nreasoning framework assists the robot in deciding when and how to complete a\ngiven task. To achieve this, we developed also PeopleFlow, a new Gazebo-based\nsimulator designed to model context-sensitive human-robot spatial interactions\nin shared workspaces. PeopleFlow features realistic human and robot\ntrajectories influenced by contextual factors such as time, environment layout,\nand robot state, and can simulate a large number of agents. While the simulator\nis general-purpose, in this paper we focus on a warehouse-like environment as a\ncase study, where we conduct an extensive evaluation benchmarking our causal\napproach against a non-causal baseline. Our findings demonstrate the efficacy\nof the proposed solutions, highlighting how causal reasoning enables autonomous\nrobots to operate more efficiently and safely in dynamic environments shared\nwith humans.", "published": "2025-04-16 09:26:04", "link": "http://arxiv.org/abs/2504.11901v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "The Hitchhiker's Guide to Program Analysis, Part II: Deep Thoughts by LLMs", "abstract": "Static analysis is a cornerstone for software vulnerability detection, yet it\noften struggles with the classic precision-scalability trade-off. In practice,\nsuch tools often produce high false positive rates, particularly in large\ncodebases like the Linux kernel. This imprecision can arise from simplified\nvulnerability modeling and over-approximation of path and data constraints.\nWhile large language models (LLMs) show promise in code understanding, their\nnaive application to program analysis yields unreliable results due to inherent\nreasoning limitations. We introduce BugLens, a post-refinement framework that\nsignificantly improves static analysis precision. BugLens guides an LLM to\nfollow traditional analysis steps by assessing buggy code patterns for security\nimpact and validating the constraints associated with static warnings.\nEvaluated on real-world Linux kernel bugs, BugLens raises precision from 0.10\n(raw) and 0.50 (semi-automated refinement) to 0.72, substantially reducing\nfalse positives and revealing four previously unreported vulnerabilities. Our\nresults suggest that a structured LLM-based workflow can meaningfully enhance\nthe effectiveness of static analysis tools.", "published": "2025-04-16 02:17:06", "link": "http://arxiv.org/abs/2504.11711v2", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "DC-SAM: In-Context Segment Anything in Images and Videos via Dual Consistency", "abstract": "Given a single labeled example, in-context segmentation aims to segment\ncorresponding objects. This setting, known as one-shot segmentation in few-shot\nlearning, explores the segmentation model's generalization ability and has been\napplied to various vision tasks, including scene understanding and image/video\nediting. While recent Segment Anything Models have achieved state-of-the-art\nresults in interactive segmentation, these approaches are not directly\napplicable to in-context segmentation. In this work, we propose the Dual\nConsistency SAM (DC-SAM) method based on prompt-tuning to adapt SAM and SAM2\nfor in-context segmentation of both images and videos. Our key insights are to\nenhance the features of the SAM's prompt encoder in segmentation by providing\nhigh-quality visual prompts. When generating a mask prior, we fuse the SAM\nfeatures to better align the prompt encoder. Then, we design a cycle-consistent\ncross-attention on fused features and initial visual prompts. Next, a\ndual-branch design is provided by using the discriminative positive and\nnegative prompts in the prompt encoder. Furthermore, we design a simple\nmask-tube training strategy to adopt our proposed dual consistency method into\nthe mask tube. Although the proposed DC-SAM is primarily designed for images,\nit can be seamlessly extended to the video domain with the support of SAM2.\nGiven the absence of in-context segmentation in the video domain, we manually\ncurate and construct the first benchmark from existing video segmentation\ndatasets, named In-Context Video Object Segmentation (IC-VOS), to better assess\nthe in-context capability of the model. Extensive experiments demonstrate that\nour method achieves 55.5 (+1.4) mIoU on COCO-20i, 73.0 (+1.1) mIoU on\nPASCAL-5i, and a J&F score of 71.52 on the proposed IC-VOS benchmark. Our\nsource code and benchmark are available at https://github.com/zaplm/DC-SAM.", "published": "2025-04-16 13:41:59", "link": "http://arxiv.org/abs/2504.12080v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Understanding Attention Mechanism in Video Diffusion Models", "abstract": "Text-to-video (T2V) synthesis models, such as OpenAI's Sora, have garnered\nsignificant attention due to their ability to generate high-quality videos from\na text prompt. In diffusion-based T2V models, the attention mechanism is a\ncritical component. However, it remains unclear what intermediate features are\nlearned and how attention blocks in T2V models affect various aspects of video\nsynthesis, such as image quality and temporal consistency. In this paper, we\nconduct an in-depth perturbation analysis of the spatial and temporal attention\nblocks of T2V models using an information-theoretic approach. Our results\nindicate that temporal and spatial attention maps affect not only the timing\nand layout of the videos but also the complexity of spatiotemporal elements and\nthe aesthetic quality of the synthesized videos. Notably, high-entropy\nattention maps are often key elements linked to superior video quality, whereas\nlow-entropy attention maps are associated with the video's intra-frame\nstructure. Based on our findings, we propose two novel methods to enhance video\nquality and enable text-guided video editing. These methods rely entirely on\nlightweight manipulation of the attention matrices in T2V models. The efficacy\nand effectiveness of our methods are further validated through experimental\nevaluation across multiple datasets.", "published": "2025-04-16 12:37:08", "link": "http://arxiv.org/abs/2504.12027v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DVLTA-VQA: Decoupled Vision-Language Modeling with Text-Guided Adaptation for Blind Video Quality Assessment", "abstract": "Inspired by the dual-stream theory of the human visual system (HVS) - where\nthe ventral stream is responsible for object recognition and detail analysis,\nwhile the dorsal stream focuses on spatial relationships and motion perception\n- an increasing number of video quality assessment (VQA) works built upon this\nframework are proposed. Recent advancements in large multi-modal models,\nnotably Contrastive Language-Image Pretraining (CLIP), have motivated\nresearchers to incorporate CLIP into dual-stream-based VQA methods. This\nintegration aims to harness the model's superior semantic understanding\ncapabilities to replicate the object recognition and detail analysis in ventral\nstream, as well as spatial relationship analysis in dorsal stream. However,\nCLIP is originally designed for images and lacks the ability to capture\ntemporal and motion information inherent in videos.To address the limitation,\nthis paper propose a Decoupled Vision-Language Modeling with Text-Guided\nAdaptation for Blind Video Quality Assessment (DVLTA-VQA), which decouples\nCLIP's visual and textual components, and integrates them into different stages\nof the NR-VQA pipeline. Specifically, a Video-Based Temporal CLIP module is\nproposed to explicitly model temporal dynamics and enhance motion perception,\naligning with the dorsal stream. Additionally, a Temporal Context Module is\ndeveloped to refine inter-frame dependencies, further improving motion\nmodeling. On the ventral stream side, a Basic Visual Feature Extraction Module\nis employed to strengthen detail analysis. Finally, a text-guided adaptive\nfusion strategy is proposed to enable dynamic weighting of features,\nfacilitating more effective integration of spatial and temporal information.", "published": "2025-04-16 03:20:28", "link": "http://arxiv.org/abs/2504.11733v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Dynamical reweighting for estimation of fluctuation formulas", "abstract": "We propose a variance reduction method for calculating transport coefficients\nin molecular dynamics using an importance sampling method via Girsanov's\ntheorem applied to Green--Kubo's formula. We optimize the magnitude of the\nperturbation applied to the reference dynamics by means of a scalar\nparameter~$\\alpha$ and propose an asymptotic analysis to fully characterize the\nlong-time behavior in order to evaluate the possible variance reduction.\nTheoretical results corroborated by numerical results show that this method\nallows for some reduction in variance, although rather modest in most\nsituations.", "published": "2025-04-16 11:01:20", "link": "http://arxiv.org/abs/2504.11968v2", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
