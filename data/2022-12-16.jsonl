{"title": "A unified information-theoretic model of EEG signatures of human\n  language processing", "abstract": "We advance an information-theoretic model of human language processing in the\nbrain, in which incoming linguistic input is processed at two levels, in terms\nof a heuristic interpretation and in terms of error correction. We propose that\nthese two kinds of information processing have distinct electroencephalographic\nsignatures, corresponding to the well-documented N400 and P600 components of\nlanguage-related event-related potentials (ERPs). Formally, we show that the\ninformation content (surprisal) of a word in context can be decomposed into two\nquantities: (A) heuristic surprise, which signals processing difficulty of word\ngiven its inferred context, and corresponds with the N400 signal; and (B)\ndiscrepancy signal, which reflects divergence between the true context and the\ninferred context, and corresponds to the P600 signal. Both of these quantities\ncan be estimated using modern NLP techniques. We validate our theory by\nsuccessfully simulating ERP patterns elicited by a variety of linguistic\nmanipulations in previously-reported experimental data from Ryskin et al.\n(2021). Our theory is in principle compatible with traditional cognitive\ntheories assuming a `good-enough' heuristic interpretation stage, but with\nprecise information-theoretic formulation.", "published": "2022-12-16 00:15:45", "link": "http://arxiv.org/abs/2212.08205v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Meeting Summarization: A Survey of the State of the Art", "abstract": "Information overloading requires the need for summarizers to extract salient\ninformation from the text. Currently, there is an overload of dialogue data due\nto the rise of virtual communication platforms. The rise of Covid-19 has led\npeople to rely on online communication platforms like Zoom, Slack, Microsoft\nTeams, Discord, etc. to conduct their company meetings. Instead of going\nthrough the entire meeting transcripts, people can use meeting summarizers to\nselect useful data. Nevertheless, there is a lack of comprehensive surveys in\nthe field of meeting summarizers. In this survey, we aim to cover recent\nmeeting summarization techniques. Our survey offers a general overview of text\nsummarization along with datasets and evaluation metrics for meeting\nsummarization. We also provide the performance of each summarizer on a\nleaderboard. We conclude our survey with different challenges in this domain\nand potential research opportunities for future researchers.", "published": "2022-12-16 00:21:30", "link": "http://arxiv.org/abs/2212.08206v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ALERT: Adapting Language Models to Reasoning Tasks", "abstract": "Current large language models can perform reasonably well on complex tasks\nthat require step-by-step reasoning with few-shot learning. Are these models\napplying reasoning skills they have learnt during pre-training and reason\noutside of their training context, or are they simply memorizing their training\ncorpus at finer granularity and have learnt to better understand their context?\nTo tease apart these possibilities, we introduce ALERT, a benchmark and suite\nof analyses for assessing language models' reasoning ability comparing\npre-trained and finetuned models on complex tasks that require reasoning skills\nto solve. ALERT provides a test bed to asses any language model on fine-grained\nreasoning skills, which spans over 20 datasets and covers 10 different\nreasoning skills. We leverage ALERT to further investigate the role of\nfinetuning. With extensive empirical analysis we find that language models\nlearn more reasoning skills such as textual entailment, abductive reasoning,\nand analogical reasoning during finetuning stage compared to pretraining state.\nWe also find that when language models are finetuned they tend to overfit to\nthe prompt template, which hurts the robustness of models causing\ngeneralization problems.", "published": "2022-12-16 05:15:41", "link": "http://arxiv.org/abs/2212.08286v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controllable Text Generation via Probability Density Estimation in the\n  Latent Space", "abstract": "Previous work on controllable text generation has explored the idea of\ncontrol from the latent space, such as optimizing a representation with\nattribute-related classifiers or sampling a representation from relevant\ndiscrete samples. However, they are not effective enough in modeling both the\nlatent space and the control, leaving controlled text with low quality and\ndiversity. In this work, we propose a novel control framework using probability\ndensity estimation in the latent space. Our method utilizes an invertible\ntransformation function, the Normalizing Flow, that maps the complex\ndistributions in the latent space to simple Gaussian distributions in the prior\nspace. Thus, we can perform sophisticated and flexible control in the prior\nspace and feed the control effects back into the latent space owing to the\none-one-mapping property of invertible transformations. Experiments on\nsingle-attribute controls and multi-attribute control reveal that our method\noutperforms several strong baselines on attribute relevance and text quality\nand achieves the SOTA. Further analysis of control strength adjustment\ndemonstrates the flexibility of our control strategy.", "published": "2022-12-16 07:11:18", "link": "http://arxiv.org/abs/2212.08307v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Law to Binary Tree -- An Formal Interpretation of Legal Natural Language", "abstract": "Knowledge representation and reasoning in law are essential to facilitate the\nautomation of legal analysis and decision-making tasks. In this paper, we\npropose a new approach based on legal science, specifically legal taxonomy, for\nrepresenting and reasoning with legal documents. Our approach interprets the\nregulations in legal documents as binary trees, which facilitates legal\nreasoning systems to make decisions and resolve logical contradictions. The\nadvantages of this approach are twofold. First, legal reasoning can be\nperformed on the basis of the binary tree representation of the regulations.\nSecond, the binary tree representation of the regulations is more\nunderstandable than the existing sentence-based representations. We provide an\nexample of how our approach can be used to interpret the regulations in a legal\ndocument.", "published": "2022-12-16 08:26:32", "link": "http://arxiv.org/abs/2212.08335v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FewFedWeight: Few-shot Federated Learning Framework across Multiple NLP\n  Tasks", "abstract": "Massively multi-task learning with large language models has recently made\nsubstantial progress on few-shot generalization. However, this is usually\nperformed in a centralized learning fashion, ignoring the privacy sensitivity\nissue of (annotated) data used in multiple tasks. To mitigate this issue, we\npropose FewFedWeight, a few-shot federated learning framework across multiple\ntasks, to achieve the best of both worlds: privacy preservation and cross-task\ngeneralization. FewFedWeight trains client models in isolated devices without\nsharing data. It broadcasts the global model in the server to each client and\nproduces pseudo data for clients so that knowledge from the global model can be\nexplored to enhance few-shot learning of each client model. An energy-based\nalgorithm is further proposed to weight pseudo samples in order to reduce the\nnegative impact of noise from the generated pseudo data. Adaptive model weights\nof client models are also tuned according to their performance. We use these\nmodel weights to dynamically aggregate client models to update the global\nmodel. Experiments on 118 NLP tasks show that FewFedWeight can significantly\nimprove the performance of client models on 61% tasks with an average\nperformance improvement rate of 30.5% over the baseline and substantially\noutperform FedAvg and other decentralized learning methods.", "published": "2022-12-16 09:01:56", "link": "http://arxiv.org/abs/2212.08354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Homonymy Information for English WordNet", "abstract": "A widely acknowledged shortcoming of WordNet is that it lacks a distinction\nbetween word meanings which are systematically related (polysemy), and those\nwhich are coincidental (homonymy). Several previous works have attempted to\nfill this gap, by inferring this information using computational methods. We\nrevisit this task, and exploit recent advances in language modelling to\nsynthesise homonymy annotation for Princeton WordNet. Previous approaches treat\nthe problem using clustering methods; by contrast, our method works by linking\nWordNet to the Oxford English Dictionary, which contains the information we\nneed. To perform this alignment, we pair definitions based on their proximity\nin an embedding space produced by a Transformer model. Despite the simplicity\nof this approach, our best model attains an F1 of .97 on an evaluation set that\nwe annotate. The outcome of our work is a high-quality homonymy annotation\nlayer for Princeton WordNet, which we release.", "published": "2022-12-16 10:23:26", "link": "http://arxiv.org/abs/2212.08388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Metaphorical Polysemy Detection: Conventional Metaphor meets Word Sense\n  Disambiguation", "abstract": "Linguists distinguish between novel and conventional metaphor, a distinction\nwhich the metaphor detection task in NLP does not take into account. Instead,\nmetaphoricity is formulated as a property of a token in a sentence, regardless\nof metaphor type. In this paper, we investigate the limitations of treating\nconventional metaphors in this way, and advocate for an alternative which we\nname 'metaphorical polysemy detection' (MPD). In MPD, only conventional\nmetaphoricity is treated, and it is formulated as a property of word senses in\na lexicon. We develop the first MPD model, which learns to identify\nconventional metaphors in the English WordNet. To train it, we present a novel\ntraining procedure that combines metaphor detection with word sense\ndisambiguation (WSD). For evaluation, we manually annotate metaphor in two\nsubsets of WordNet. Our model significantly outperforms a strong baseline based\non a state-of-the-art metaphor detection model, attaining an ROC-AUC score of\n.78 (compared to .65) on one of the sets. Additionally, when paired with a WSD\nmodel, our approach outperforms a state-of-the-art metaphor detection model at\nidentifying conventional metaphors in text (.659 F1 compared to .626).", "published": "2022-12-16 10:39:22", "link": "http://arxiv.org/abs/2212.08395v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Experiments on Generalizability of BERTopic on Multi-Domain Short Text", "abstract": "Topic modeling is widely used for analytically evaluating large collections\nof textual data. One of the most popular topic techniques is Latent Dirichlet\nAllocation (LDA), which is flexible and adaptive, but not optimal for e.g.\nshort texts from various domains. We explore how the state-of-the-art BERTopic\nalgorithm performs on short multi-domain text and find that it generalizes\nbetter than LDA in terms of topic coherence and diversity. We further analyze\nthe performance of the HDBSCAN clustering algorithm utilized by BERTopic and\nfind that it classifies a majority of the documents as outliers. This crucial,\nyet overseen problem excludes too many documents from further analysis. When we\nreplace HDBSCAN with k-Means, we achieve similar performance, but without\noutliers.", "published": "2022-12-16 13:07:39", "link": "http://arxiv.org/abs/2212.08459v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric", "abstract": "End-to-End speech-to-speech translation (S2ST) is generally evaluated with\ntext-based metrics. This means that generated speech has to be automatically\ntranscribed, making the evaluation dependent on the availability and quality of\nautomatic speech recognition (ASR) systems. In this paper, we propose a\ntext-free evaluation metric for end-to-end S2ST, named BLASER, to avoid the\ndependency on ASR systems. BLASER leverages a multilingual multimodal encoder\nto directly encode the speech segments for source input, translation output and\nreference into a shared embedding space and computes a score of the translation\nquality that can be used as a proxy to human evaluation. To evaluate our\napproach, we construct training and evaluation sets from more than 40k human\nannotations covering seven language directions. The best results of BLASER are\nachieved by training with supervision from human rating scores. We show that\nwhen evaluated at the sentence level, BLASER correlates significantly better\nwith human judgment compared to ASR-dependent metrics including ASR-SENTBLEU in\nall translation directions and ASR-COMET in five of them. Our analysis shows\ncombining speech and text as inputs to BLASER does not increase the correlation\nwith human scores, but best correlations are achieved when using speech, which\nmotivates the goal of our research. Moreover, we show that using ASR for\nreferences is detrimental for text-based metrics.", "published": "2022-12-16 14:00:26", "link": "http://arxiv.org/abs/2212.08486v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Check-worthy Claim Detection across Topics for Automated Fact-checking", "abstract": "An important component of an automated fact-checking system is the claim\ncheck-worthiness detection system, which ranks sentences by prioritising them\nbased on their need to be checked. Despite a body of research tackling the\ntask, previous research has overlooked the challenging nature of identifying\ncheck-worthy claims across different topics. In this paper, we assess and\nquantify the challenge of detecting check-worthy claims for new, unseen topics.\nAfter highlighting the problem, we propose the AraCWA model to mitigate the\nperformance deterioration when detecting check-worthy claims across topics. The\nAraCWA model enables boosting the performance for new topics by incorporating\ntwo components for few-shot learning and data augmentation. Using a publicly\navailable dataset of Arabic tweets consisting of 14 different topics, we\ndemonstrate that our proposed data augmentation strategy achieves substantial\nimprovements across topics overall, where the extent of the improvement varies\nacross topics. Further, we analyse the semantic similarities between topics,\nsuggesting that the similarity metric could be used as a proxy to determine the\ndifficulty level of an unseen topic prior to undertaking the task of labelling\nthe underlying sentences.", "published": "2022-12-16 14:54:56", "link": "http://arxiv.org/abs/2212.08514v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-grained Czech News Article Dataset: An Interdisciplinary Approach\n  to Trustworthiness Analysis", "abstract": "We present the Verifee Dataset: a novel dataset of news articles with\nfine-grained trustworthiness annotations. We develop a detailed methodology\nthat assesses the texts based on their parameters encompassing editorial\ntransparency, journalist conventions, and objective reporting while penalizing\nmanipulative techniques. We bring aboard a diverse set of researchers from\nsocial, media, and computer sciences to overcome barriers and limited framing\nof this interdisciplinary problem. We collect over $10,000$ unique articles\nfrom almost $60$ Czech online news sources. These are categorized into one of\nthe $4$ classes across the credibility spectrum we propose, raging from\nentirely trustworthy articles all the way to the manipulative ones. We produce\ndetailed statistics and study trends emerging throughout the set. Lastly, we\nfine-tune multiple popular sequence-to-sequence language models using our\ndataset on the trustworthiness classification task and report the best testing\nF-1 score of $0.52$. We open-source the dataset, annotation methodology, and\nannotators' instructions in full length at https://verifee.ai/research to\nenable easy build-up work. We believe similar methods can help prevent\ndisinformation and educate in the realm of media literacy.", "published": "2022-12-16 16:00:19", "link": "http://arxiv.org/abs/2212.08550v1", "categories": ["cs.CL", "I.2.7; K.4.0"], "primary_category": "cs.CL"}
{"title": "Detecting and Mitigating Hallucinations in Machine Translation: Model\n  Internal Workings Alone Do Well, Sentence Similarity Even Better", "abstract": "While the problem of hallucinations in neural machine translation has long\nbeen recognized, so far the progress on its alleviation is very little. Indeed,\nrecently it turned out that without artificially encouraging models to\nhallucinate, previously existing methods fall short and even the standard\nsequence log-probability is more informative. It means that characteristics\ninternal to the model can give much more information than we expect, and before\nusing external models and measures, we first need to ask: how far can we go if\nwe use nothing but the translation model itself ? We propose to use a method\nthat evaluates the percentage of the source contribution to a generated\ntranslation. Intuitively, hallucinations are translations \"detached\" from the\nsource, hence they can be identified by low source contribution. This method\nimproves detection accuracy for the most severe hallucinations by a factor of 2\nand is able to alleviate hallucinations at test time on par with the previous\nbest approach that relies on external models. Next, if we move away from\ninternal model characteristics and allow external tools, we show that using\nsentence similarity from cross-lingual embeddings further improves these\nresults.", "published": "2022-12-16 17:24:49", "link": "http://arxiv.org/abs/2212.08597v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Evaluating Step-by-Step Reasoning through Symbolic Verification", "abstract": "Pre-trained language models (LMs) have shown remarkable reasoning performance\nusing explanations or chain-of-thoughts (CoT)) for in-context learning. On the\nother hand, these reasoning tasks are usually presumed to be more approachable\nfor symbolic programming. To understand the mechanism of reasoning of LMs, we\ncurate synthetic datasets containing equivalent (natural, symbolic) data pairs,\nwhere symbolic examples contain first-order logic rules and predicates from\nnon-parametric knowledge bases (KBs), supporting automated verification of\nintermediate reasoning results. Then we revisit neuro-symbolic approaches and\npropose to learn from demonstrations containing logic rules and corresponding\nexamples to iteratively reason over KBs, recovering Prolog's backward chaining\nalgorithm and supporting automated verification of LMs' outputs. Comprehensive\nexperiments are included to systematically compare LMLP with CoT in deductive\nreasoning settings, showing that LMLP enjoys more than $25\\%$ higher accuracy\nthan CoT on length generalization benchmarks even with smaller model sizes.", "published": "2022-12-16 19:30:01", "link": "http://arxiv.org/abs/2212.08686v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text\n  Generation", "abstract": "Self-training (ST) has prospered again in language understanding by\naugmenting the fine-tuning of pre-trained language models when labeled data is\ninsufficient. However, it remains challenging to incorporate ST into\nattribute-controllable language generation. Augmented by only self-generated\npseudo text, generation models over-emphasize exploitation of the previously\nlearned space, suffering from a constrained generalization boundary. We revisit\nST and propose a novel method, DuNST to alleviate this problem. DuNST jointly\nmodels text generation and classification with a shared Variational AutoEncoder\nand corrupts the generated pseudo text by two kinds of flexible noise to\ndisturb the space. In this way, our model could construct and utilize both\npseudo text from given labels and pseudo labels from available unlabeled text,\nwhich are gradually refined during the ST process. We theoretically demonstrate\nthat DuNST can be regarded as enhancing exploration towards the potential real\ntext space, providing a guarantee of improved performance. Experiments on three\ncontrollable generation tasks show that DuNST could significantly boost control\naccuracy while maintaining comparable generation fluency and diversity against\nseveral strong baselines.", "published": "2022-12-16 21:44:34", "link": "http://arxiv.org/abs/2212.08724v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LegalRelectra: Mixed-domain Language Modeling for Long-range Legal Text\n  Comprehension", "abstract": "The application of Natural Language Processing (NLP) to specialized domains,\nsuch as the law, has recently received a surge of interest. As many legal\nservices rely on processing and analyzing large collections of documents,\nautomating such tasks with NLP tools emerges as a key challenge. Many popular\nlanguage models, such as BERT or RoBERTa, are general-purpose models, which\nhave limitations on processing specialized legal terminology and syntax. In\naddition, legal documents may contain specialized vocabulary from other\ndomains, such as medical terminology in personal injury text. Here, we propose\nLegalRelectra, a legal-domain language model that is trained on mixed-domain\nlegal and medical corpora. We show that our model improves over general-domain\nand single-domain medical and legal language models when processing\nmixed-domain (personal injury) text. Our training architecture implements the\nElectra framework, but utilizes Reformer instead of BERT for its generator and\ndiscriminator. We show that this improves the model's performance on processing\nlong passages and results in better long-range text comprehension.", "published": "2022-12-16 00:15:14", "link": "http://arxiv.org/abs/2212.08204v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "SceneGATE: Scene-Graph based co-Attention networks for TExt visual\n  question answering", "abstract": "Most TextVQA approaches focus on the integration of objects, scene texts and\nquestion words by a simple transformer encoder. But this fails to capture the\nsemantic relations between different modalities. The paper proposes a Scene\nGraph based co-Attention Network (SceneGATE) for TextVQA, which reveals the\nsemantic relations among the objects, Optical Character Recognition (OCR)\ntokens and the question words. It is achieved by a TextVQA-based scene graph\nthat discovers the underlying semantics of an image. We created a\nguided-attention module to capture the intra-modal interplay between the\nlanguage and the vision as a guidance for inter-modal interactions. To make\nexplicit teaching of the relations between the two modalities, we proposed and\nintegrated two attention modules, namely a scene graph-based semantic\nrelation-aware attention and a positional relation-aware attention. We\nconducted extensive experiments on two benchmark datasets, Text-VQA and ST-VQA.\nIt is shown that our SceneGATE method outperformed existing ones because of the\nscene graph and its attention modules.", "published": "2022-12-16 05:10:09", "link": "http://arxiv.org/abs/2212.08283v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Rich Event Modeling for Script Event Prediction", "abstract": "Script is a kind of structured knowledge extracted from texts, which contains\na sequence of events. Based on such knowledge, script event prediction aims to\npredict the subsequent event. To do so, two aspects should be considered for\nevents, namely, event description (i.e., what the events should contain) and\nevent encoding (i.e., how they should be encoded). Most existing methods\ndescribe an event by a verb together with only a few core arguments (i.e.,\nsubject, object, and indirect object), which are not precise. In addition,\nexisting event encoders are limited to a fixed number of arguments, which are\nnot flexible to deal with extra information. Thus, in this paper, we propose\nthe Rich Event Prediction (REP) framework for script event prediction.\nFundamentally, it is based on the proposed rich event description, which\nenriches the existing ones with three kinds of important information, namely,\nthe senses of verbs, extra semantic roles, and types of participants. REP\ncontains an event extractor to extract such information from texts. Based on\nthe extracted rich information, a predictor then selects the most probable\nsubsequent event. The core component of the predictor is a transformer-based\nevent encoder to flexibly deal with an arbitrary number of arguments.\nExperimental results on the widely used Gigaword Corpus show the effectiveness\nof the proposed framework.", "published": "2022-12-16 05:17:59", "link": "http://arxiv.org/abs/2212.08287v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigation of Japanese PnG BERT language model in text-to-speech\n  synthesis for pitch accent language", "abstract": "End-to-end text-to-speech synthesis (TTS) can generate highly natural\nsynthetic speech from raw text. However, rendering the correct pitch accents is\nstill a challenging problem for end-to-end TTS. To tackle the challenge of\nrendering correct pitch accent in Japanese end-to-end TTS, we adopt PnG~BERT, a\nself-supervised pretrained model in the character and phoneme domain for TTS.\nWe investigate the effects of features captured by PnG~BERT on Japanese TTS by\nmodifying the fine-tuning condition to determine the conditions helpful\ninferring pitch accents. We manipulate content of PnG~BERT features from being\ntext-oriented to speech-oriented by changing the number of fine-tuned layers\nduring TTS. In addition, we teach PnG~BERT pitch accent information by\nfine-tuning with tone prediction as an additional downstream task. Our\nexperimental results show that the features of PnG~BERT captured by pretraining\ncontain information helpful inferring pitch accent, and PnG~BERT outperforms\nbaseline Tacotron on accent correctness in a listening test.", "published": "2022-12-16 07:47:03", "link": "http://arxiv.org/abs/2212.08321v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "ReCo: Reliable Causal Chain Reasoning via Structural Causal Recurrent\n  Neural Networks", "abstract": "Causal chain reasoning (CCR) is an essential ability for many decision-making\nAI systems, which requires the model to build reliable causal chains by\nconnecting causal pairs. However, CCR suffers from two main transitive\nproblems: threshold effect and scene drift. In other words, the causal pairs to\nbe spliced may have a conflicting threshold boundary or scenario. To address\nthese issues, we propose a novel Reliable Causal chain reasoning\nframework~(ReCo), which introduces exogenous variables to represent the\nthreshold and scene factors of each causal pair within the causal chain, and\nestimates the threshold and scene contradictions across exogenous variables via\nstructural causal recurrent neural networks~(SRNN). Experiments show that ReCo\noutperforms a series of strong baselines on both Chinese and English CCR\ndatasets. Moreover, by injecting reliable causal chain knowledge distilled by\nReCo, BERT can achieve better performances on four downstream causal-related\ntasks than BERT models enhanced by other kinds of knowledge.", "published": "2022-12-16 07:48:02", "link": "http://arxiv.org/abs/2212.08322v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Lessons learned from the evaluation of Spanish Language Models", "abstract": "Given the impact of language models on the field of Natural Language\nProcessing, a number of Spanish encoder-only masked language models (aka BERTs)\nhave been trained and released. These models were developed either within large\nprojects using very large private corpora or by means of smaller scale academic\nefforts leveraging freely available data. In this paper we present a\ncomprehensive head-to-head comparison of language models for Spanish with the\nfollowing results: (i) Previously ignored multilingual models from large\ncompanies fare better than monolingual models, substantially changing the\nevaluation landscape of language models in Spanish; (ii) Results across the\nmonolingual models are not conclusive, with supposedly smaller and inferior\nmodels performing competitively. Based on these empirical results, we argue for\nthe need of more research to understand the factors underlying them. In this\nsense, the effect of corpus size, quality and pre-training techniques need to\nbe further investigated to be able to obtain Spanish monolingual models\nsignificantly better than the multilingual ones released by large private\ncompanies, specially in the face of rapid ongoing progress in the field. The\nrecent activity in the development of language technology for Spanish is to be\nwelcomed, but our results show that building language models remains an open,\nresource-heavy problem which requires to marry resources (monetary and/or\ncomputational) with the best research expertise and practice.", "published": "2022-12-16 10:33:38", "link": "http://arxiv.org/abs/2212.08390v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Utilizing distilBert transformer model for sentiment classification of\n  COVID-19's Persian open-text responses", "abstract": "The COVID-19 pandemic has caused drastic alternations in human life in all\naspects. The government's laws in this regard affected the lifestyle of all\npeople. Due to this fact studying the sentiment of individuals is essential to\nbe aware of the future impacts of the coming pandemics. To contribute to this\naim, we proposed an NLP (Natural Language Processing) model to analyze\nopen-text answers in a survey in Persian and detect positive and negative\nfeelings of the people in Iran. In this study, a distilBert transformer model\nwas applied to take on this task. We deployed three approaches to perform the\ncomparison, and our best model could gain accuracy: 0.824, Precision: 0.824,\nRecall: 0.798, and F1 score: 0.804.", "published": "2022-12-16 11:06:48", "link": "http://arxiv.org/abs/2212.08407v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Decoder Tuning: Efficient Language Understanding as Decoding", "abstract": "With the evergrowing sizes of pre-trained models (PTMs), it has been an\nemerging practice to only provide the inference APIs for users, namely\nmodel-as-a-service (MaaS) setting. To adapt PTMs with model parameters frozen,\nmost current approaches focus on the input side, seeking for powerful prompts\nto stimulate models for correct answers. However, we argue that input-side\nadaptation could be arduous due to the lack of gradient signals and they\nusually require thousands of API queries, resulting in high computation and\ntime costs. In light of this, we present Decoder Tuning (DecT), which in\ncontrast optimizes task-specific decoder networks on the output side.\nSpecifically, DecT first extracts prompt-stimulated output scores for initial\npredictions. On top of that, we train an additional decoder network on the\noutput representations to incorporate posterior data knowledge. By\ngradient-based optimization, DecT can be trained within several seconds and\nrequires only one PTM query per sample. Empirically, we conduct extensive\nnatural language understanding experiments and show that DecT significantly\noutperforms state-of-the-art algorithms with a $200\\times$ speed-up.", "published": "2022-12-16 11:15:39", "link": "http://arxiv.org/abs/2212.08408v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Teaching Small Language Models to Reason", "abstract": "Chain of thought prompting successfully improves the reasoning capabilities\nof large language models, achieving state of the art results on a range of\ndatasets. However, these reasoning capabilities only appear to emerge in models\nwith a size of over 100 billion parameters. In this paper, we explore the\ntransfer of such reasoning capabilities to models with less than 100 billion\nparameters via knowledge distillation. Specifically, we finetune a student\nmodel on the chain of thought outputs generated by a larger teacher model. Our\nexperiments show that the proposed method improves task performance across\narithmetic, commonsense and symbolic reasoning datasets. For example, the\naccuracy of T5 XXL on GSM8K improves from 8.11% to 21.99% when finetuned on\nPaLM-540B generated chains of thought.", "published": "2022-12-16 11:24:42", "link": "http://arxiv.org/abs/2212.08410v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Context-aware Fine-tuning of Self-supervised Speech Models", "abstract": "Self-supervised pre-trained transformers have improved the state of the art\non a variety of speech tasks. Due to the quadratic time and space complexity of\nself-attention, they usually operate at the level of relatively short (e.g.,\nutterance) segments. In this paper, we study the use of context, i.e.,\nsurrounding segments, during fine-tuning and propose a new approach called\ncontext-aware fine-tuning. We attach a context module on top of the last layer\nof a pre-trained model to encode the whole segment into a context embedding\nvector which is then used as an additional feature for the final prediction.\nDuring the fine-tuning stage, we introduce an auxiliary loss that encourages\nthis context embedding vector to be similar to context vectors of surrounding\nsegments. This allows the model to make predictions without access to these\nsurrounding segments at inference time and requires only a tiny overhead\ncompared to standard fine-tuned models. We evaluate the proposed approach using\nthe SLUE and Libri-light benchmarks for several downstream tasks: Automatic\nspeech recognition (ASR), named entity recognition (NER), and sentiment\nanalysis (SA). The results show that context-aware fine-tuning not only\noutperforms a standard fine-tuning baseline but also rivals a strong context\ninjection baseline that uses neighboring speech segments during inference.", "published": "2022-12-16 15:46:15", "link": "http://arxiv.org/abs/2212.08542v2", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Planting and Mitigating Memorized Content in Predictive-Text Language\n  Models", "abstract": "Language models are widely deployed to provide automatic text completion\nservices in user products. However, recent research has revealed that language\nmodels (especially large ones) bear considerable risk of memorizing private\ntraining data, which is then vulnerable to leakage and extraction by\nadversaries. In this study, we test the efficacy of a range of\nprivacy-preserving techniques to mitigate unintended memorization of sensitive\nuser text, while varying other factors such as model size and adversarial\nconditions. We test both \"heuristic\" mitigations (those without formal privacy\nguarantees) and Differentially Private training, which provides provable levels\nof privacy at the cost of some model performance. Our experiments show that\n(with the exception of L2 regularization), heuristic mitigations are largely\nineffective in preventing memorization in our test suite, possibly because they\nmake too strong of assumptions about the characteristics that define\n\"sensitive\" or \"private\" text. In contrast, Differential Privacy reliably\nprevents memorization in our experiments, despite its computational and\nmodel-performance costs.", "published": "2022-12-16 17:57:14", "link": "http://arxiv.org/abs/2212.08619v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Enhancing Multi-modal and Multi-hop Question Answering via Structured\n  Knowledge and Unified Retrieval-Generation", "abstract": "Multi-modal multi-hop question answering involves answering a question by\nreasoning over multiple input sources from different modalities. Existing\nmethods often retrieve evidences separately and then use a language model to\ngenerate an answer based on the retrieved evidences, and thus do not adequately\nconnect candidates and are unable to model the interdependent relations during\nretrieval. Moreover, the pipelined approaches of retrieval and generation might\nresult in poor generation performance when retrieval performance is low. To\naddress these issues, we propose a Structured Knowledge and Unified\nRetrieval-Generation (SKURG) approach. SKURG employs an Entity-centered Fusion\nEncoder to align sources from different modalities using shared entities. It\nthen uses a unified Retrieval-Generation Decoder to integrate intermediate\nretrieval results for answer generation and also adaptively determine the\nnumber of retrieval steps. Extensive experiments on two representative\nmulti-modal multi-hop QA datasets MultimodalQA and WebQA demonstrate that SKURG\noutperforms the state-of-the-art models in both source retrieval and answer\ngeneration performance with fewer parameters. Our code is available at\nhttps://github.com/HITsz-TMG/SKURG.", "published": "2022-12-16 18:12:04", "link": "http://arxiv.org/abs/2212.08632v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Self-Prompting Large Language Models for Zero-Shot Open-Domain QA", "abstract": "Open-Domain Question Answering (ODQA) aims to answer questions without\nexplicitly providing specific background documents. This task becomes notably\nchallenging in a zero-shot setting where no data is available to train tailored\nretrieval-reader models. While recent Large Language Models (LLMs) like GPT-3\nhave demonstrated their effectiveness in zero-shot ODQA using direct prompting\nmethods, these methods still fall short of fully harnessing the potential of\nLLMs when implicitly invoked. In this paper, we propose a Self-Prompting\nframework to explicitly utilize the massive knowledge encoded in the parameters\nof LLMs and their strong instruction understanding abilities. Concretely, we\nprompt LLMs step by step to generate multiple pseudo QA pairs with background\npassages and explanations entirely from scratch. These generated elements are\nthen utilized for in-context learning. Experimental results show that our\nmethod significantly surpasses previous state-of-the-art zero-shot methods on\nthree widely-used ODQA datasets and even achieves comparable performance with\nvarious customized fine-tuned models on full training data. Our code is\navailable at https://github.com/lockon-n/self-prompting.", "published": "2022-12-16 18:23:43", "link": "http://arxiv.org/abs/2212.08635v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Story Planning", "abstract": "Automated plot generation is the challenge of generating a sequence of events\nthat will be perceived by readers as the plot of a coherent story. Traditional\nsymbolic planners plan a story from a goal state and guarantee logical causal\nplot coherence but rely on a library of hand-crafted actions with their\npreconditions and effects. This closed world setting limits the length and\ndiversity of what symbolic planners can generate. On the other hand,\npre-trained neural language models can generate stories with great diversity,\nwhile being generally incapable of ending a story in a specified manner and can\nhave trouble maintaining coherence. In this paper, we present an approach to\nstory plot generation that unifies causal planning with neural language models.\nWe propose to use commonsense knowledge extracted from large language models to\nrecursively expand a story plot in a backward chaining fashion. Specifically,\nour system infers the preconditions for events in the story and then events\nthat will cause those conditions to become true. We performed automatic\nevaluation to measure narrative coherence as indicated by the ability to answer\nquestions about whether different events in the story are causally related to\nother events. Results indicate that our proposed method produces more coherent\nplotlines than several strong baselines.", "published": "2022-12-16 21:29:41", "link": "http://arxiv.org/abs/2212.08718v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Scales Data Augmentation Approach In Natural Language Inference\n  For Artifacts Mitigation And Pre-Trained Model Optimization", "abstract": "Machine learning models can reach high performance on benchmark natural\nlanguage processing (NLP) datasets but fail in more challenging settings. We\nstudy this issue when a pre-trained model learns dataset artifacts in natural\nlanguage inference (NLI), the topic of studying the logical relationship\nbetween a pair of text sequences. We provide a variety of techniques for\nanalyzing and locating dataset artifacts inside the crowdsourced Stanford\nNatural Language Inference (SNLI) corpus. We study the stylistic pattern of\ndataset artifacts in the SNLI. To mitigate dataset artifacts, we employ a\nunique multi-scale data augmentation technique with two distinct frameworks: a\nbehavioral testing checklist at the sentence level and lexical synonym criteria\nat the word level. Specifically, our combination method enhances our model's\nresistance to perturbation testing, enabling it to continuously outperform the\npre-trained baseline.", "published": "2022-12-16 23:37:44", "link": "http://arxiv.org/abs/2212.08756v4", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Natural Language Processing in Customer Service: A Systematic Review", "abstract": "Artificial intelligence and natural language processing (NLP) are\nincreasingly being used in customer service to interact with users and answer\ntheir questions. The goal of this systematic review is to examine existing\nresearch on the use of NLP technology in customer service, including the\nresearch domain, applications, datasets used, and evaluation methods. The\nreview also looks at the future direction of the field and any significant\nlimitations. The review covers the time period from 2015 to 2022 and includes\npapers from five major scientific databases. Chatbots and question-answering\nsystems were found to be used in 10 main fields, with the most common use in\ngeneral, social networking, and e-commerce areas. Twitter was the second most\ncommonly used dataset, with most research also using their own original\ndatasets. Accuracy, precision, recall, and F1 were the most common evaluation\nmethods. Future work aims to improve the performance and understanding of user\nbehavior and emotions, and address limitations such as the volume, diversity,\nand quality of datasets. This review includes research on different spoken\nlanguages and models and techniques.", "published": "2022-12-16 18:17:07", "link": "http://arxiv.org/abs/2212.09523v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Azimuth: Systematic Error Analysis for Text Classification", "abstract": "We present Azimuth, an open-source and easy-to-use tool to perform error\nanalysis for text classification. Compared to other stages of the ML\ndevelopment cycle, such as model training and hyper-parameter tuning, the\nprocess and tooling for the error analysis stage are less mature. However, this\nstage is critical for the development of reliable and trustworthy AI systems.\nTo make error analysis more systematic, we propose an approach comprising\ndataset analysis and model quality assessment, which Azimuth facilitates. We\naim to help AI practitioners discover and address areas where the model does\nnot generalize by leveraging and integrating a range of ML techniques, such as\nsaliency maps, similarity, uncertainty, and behavioral analyses, all in one\ntool. Our code and documentation are available at\ngithub.com/servicenow/azimuth.", "published": "2022-12-16 01:10:41", "link": "http://arxiv.org/abs/2212.08216v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion\n  Behaviors in Social Deduction Games", "abstract": "Persuasion modeling is a key building block for conversational agents.\nExisting works in this direction are limited to analyzing textual dialogue\ncorpus. We argue that visual signals also play an important role in\nunderstanding human persuasive behaviors. In this paper, we introduce the first\nmultimodal dataset for modeling persuasion behaviors. Our dataset includes 199\ndialogue transcriptions and videos captured in a multi-player social deduction\ngame setting, 26,647 utterance level annotations of persuasion strategy, and\ngame level annotations of deduction game outcomes. We provide extensive\nexperiments to show how dialogue context and visual signals benefit persuasion\nstrategy prediction. We also explore the generalization ability of language\nmodels for persuasion modeling and the role of persuasion strategies in\npredicting social deduction game outcomes. Our dataset, code, and models can be\nfound at https://persuasion-deductiongame.socialai-data.org.", "published": "2022-12-16 04:52:53", "link": "http://arxiv.org/abs/2212.08279v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Text-to-speech synthesis based on latent variable conversion using\n  diffusion probabilistic model and variational autoencoder", "abstract": "Text-to-speech synthesis (TTS) is a task to convert texts into speech. Two of\nthe factors that have been driving TTS are the advancements of probabilistic\nmodels and latent representation learning. We propose a TTS method based on\nlatent variable conversion using a diffusion probabilistic model and the\nvariational autoencoder (VAE). In our TTS method, we use a waveform model based\non VAE, a diffusion model that predicts the distribution of latent variables in\nthe waveform model from texts, and an alignment model that learns alignments\nbetween the text and speech latent sequences. Our method integrates diffusion\nwith VAE by modeling both mean and variance parameters with diffusion, where\nthe target distribution is determined by approximation from VAE. This latent\nvariable conversion framework potentially enables us to flexibly incorporate\nvarious latent feature extractors. Our experiments show that our method is\nrobust to linguistic labels with poor orthography and alignment errors.", "published": "2022-12-16 08:14:04", "link": "http://arxiv.org/abs/2212.08329v1", "categories": ["eess.AS", "cs.CL", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Convolution-enhanced Evolving Attention Networks", "abstract": "Attention-based neural networks, such as Transformers, have become ubiquitous\nin numerous applications, including computer vision, natural language\nprocessing, and time-series analysis. In all kinds of attention networks, the\nattention maps are crucial as they encode semantic dependencies between input\ntokens. However, most existing attention networks perform modeling or reasoning\nbased on representations , wherein the attention maps of different layers are\nlearned separately without explicit interactions. In this paper, we propose a\nnovel and generic evolving attention mechanism, which directly models the\nevolution of inter-token relationships through a chain of residual\nconvolutional modules. The major motivations are twofold. On the one hand, the\nattention maps in different layers share transferable knowledge, thus adding a\nresidual connection can facilitate the information flow of inter-token\nrelationships across layers. On the other hand, there is naturally an\nevolutionary trend among attention maps at different abstraction levels, so it\nis beneficial to exploit a dedicated convolution-based module to capture this\nprocess. Equipped with the proposed mechanism, the convolution-enhanced\nevolving attention networks achieve superior performance in various\napplications, including time-series representation, natural language\nunderstanding, machine translation, and image classification. Especially on\ntime-series representation tasks, Evolving Attention-enhanced Dilated\nConvolutional (EA-DC-) Transformer outperforms state-of-the-art models\nsignificantly, achieving an average of 17% improvement compared to the best\nSOTA. To the best of our knowledge, this is the first work that explicitly\nmodels the layer-wise evolution of attention maps. Our implementation is\navailable at https://github.com/pkuyym/EvolvingAttention.", "published": "2022-12-16 08:14:04", "link": "http://arxiv.org/abs/2212.08330v2", "categories": ["cs.LG", "cs.CL", "cs.CV", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Swing Distillation: A Privacy-Preserving Knowledge Distillation\n  Framework", "abstract": "Knowledge distillation (KD) has been widely used for model compression and\nknowledge transfer. Typically, a big teacher model trained on sufficient data\ntransfers knowledge to a small student model. However, despite the success of\nKD, little effort has been made to study whether KD leaks the training data of\nthe teacher model. In this paper, we experimentally reveal that KD suffers from\nthe risk of privacy leakage. To alleviate this issue, we propose a novel\nknowledge distillation method, swing distillation, which can effectively\nprotect the private information of the teacher model from flowing to the\nstudent model. In our framework, the temperature coefficient is dynamically and\nadaptively adjusted according to the degree of private information contained in\nthe data, rather than a predefined constant hyperparameter. It assigns\ndifferent temperatures to tokens according to the likelihood that a token in a\nposition contains private information. In addition, we inject noise into soft\ntargets provided to the student model, in order to avoid unshielded knowledge\ntransfer. Experiments on multiple datasets and tasks demonstrate that the\nproposed swing distillation can significantly reduce (by over 80% in terms of\ncanary exposure) the risk of privacy leakage in comparison to KD with\ncompetitive or better performance. Furthermore, swing distillation is robust\nagainst the increasing privacy budget.", "published": "2022-12-16 08:57:18", "link": "http://arxiv.org/abs/2212.08349v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "How to disagree well: Investigating the dispute tactics used on\n  Wikipedia", "abstract": "Disagreements are frequently studied from the perspective of either detecting\ntoxicity or analysing argument structure. We propose a framework of dispute\ntactics that unifies these two perspectives, as well as other dialogue acts\nwhich play a role in resolving disputes, such as asking questions and providing\nclarification. This framework includes a preferential ordering among\nrebuttal-type tactics, ranging from ad hominem attacks to refuting the central\nargument. Using this framework, we annotate 213 disagreements (3,865\nutterances) from Wikipedia Talk pages. This allows us to investigate research\nquestions around the tactics used in disagreements; for instance, we provide\nempirical validation of the approach to disagreement recommended by Wikipedia.\nWe develop models for multilabel prediction of dispute tactics in an utterance,\nachieving the best performance with a transformer-based label powerset model.\nAdding an auxiliary task to incorporate the ordering of rebuttal tactics\nfurther yields a statistically significant increase. Finally, we show that\nthese annotations can be used to provide useful additional signals to improve\nperformance on the task of predicting escalation.", "published": "2022-12-16 09:01:19", "link": "http://arxiv.org/abs/2212.08353v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Fast Rule-Based Decoding: Revisiting Syntactic Rules in Neural\n  Constituency Parsing", "abstract": "Most recent studies on neural constituency parsing focus on encoder\nstructures, while few developments are devoted to decoders. Previous research\nhas demonstrated that probabilistic statistical methods based on syntactic\nrules are particularly effective in constituency parsing, whereas syntactic\nrules are not used during the training of neural models in prior work probably\ndue to their enormous computation requirements. In this paper, we first\nimplement a fast CKY decoding procedure harnessing GPU acceleration, based on\nwhich we further derive a syntactic rule-based (rule-constrained) CKY decoding.\nIn the experiments, our method obtains 95.89 and 92.52 F1 on the datasets of\nPTB and CTB respectively, which shows significant improvements compared with\nprevious approaches. Besides, our parser achieves strong and competitive\ncross-domain performance in zero-shot settings.", "published": "2022-12-16 13:07:09", "link": "http://arxiv.org/abs/2212.08458v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Implementation of general formal translators", "abstract": "The general translator formalism and computing specific implementations are\nproposed. The implementation of specific elements necessary to process the\nsource and destination information within the translators are presented. Some\ncommon directives or instructions, such as classes and procedures, were unified\nand generalized in order to allow general translations implementations. In\norder to cover general cases, two levels of processing are required, related to\nthe source and destination information appropriate transformations, with the\nrelated control and processing instructions. The proposed general translator\nelements are useful for processing natural or artificial information described\nthrough any types of languages or systems.", "published": "2022-12-16 13:55:22", "link": "http://arxiv.org/abs/2212.08482v2", "categories": ["cs.CL", "cs.FL", "cs.PL", "cs.SC"], "primary_category": "cs.CL"}
{"title": "Effectiveness of Text, Acoustic, and Lattice-based representations in\n  Spoken Language Understanding tasks", "abstract": "In this paper, we perform an exhaustive evaluation of different\nrepresentations to address the intent classification problem in a Spoken\nLanguage Understanding (SLU) setup. We benchmark three types of systems to\nperform the SLU intent detection task: 1) text-based, 2) lattice-based, and a\nnovel 3) multimodal approach. Our work provides a comprehensive analysis of\nwhat could be the achievable performance of different state-of-the-art SLU\nsystems under different circumstances, e.g., automatically- vs.\nmanually-generated transcripts. We evaluate the systems on the publicly\navailable SLURP spoken language resource corpus. Our results indicate that\nusing richer forms of Automatic Speech Recognition (ASR) outputs, namely\nword-consensus-networks, allows the SLU system to improve in comparison to the\n1-best setup (5.5% relative improvement). However, crossmodal approaches, i.e.,\nlearning from acoustic and text embeddings, obtains performance similar to the\noracle setup, a relative improvement of 17.8% over the 1-best configuration,\nbeing a recommended alternative to overcome the limitations of working with\nautomatically generated transcripts.", "published": "2022-12-16 14:01:42", "link": "http://arxiv.org/abs/2212.08489v2", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text\n  Generation", "abstract": "Prompting large language models has enabled significant recent progress in\nmulti-step reasoning over text. However, when applied to text generation from\nsemi-structured data (e.g., graphs or tables), these methods typically suffer\nfrom low semantic coverage, hallucination, and logical inconsistency. We\npropose MURMUR, a neuro-symbolic modular approach to text generation from\nsemi-structured data with multi-step reasoning. MURMUR is a best-first search\nmethod that generates reasoning paths using: (1) neural and symbolic modules\nwith specific linguistic and logical skills, (2) a grammar whose production\nrules define valid compositions of modules, and (3) value functions that assess\nthe quality of each reasoning step. We conduct experiments on two diverse\ndata-to-text generation tasks like WebNLG and LogicNLG. These tasks differ in\ntheir data representations (graphs and tables) and span multiple linguistic and\nlogical skills. MURMUR obtains significant improvements over recent few-shot\nbaselines like direct prompting and chain-of-thought prompting, while also\nachieving comparable performance to fine-tuned GPT-2 on out-of-domain data.\nMoreover, human evaluation shows that MURMUR generates highly faithful and\ncorrect reasoning paths that lead to 26% more logically consistent summaries on\nLogicNLG, compared to direct prompting.", "published": "2022-12-16 17:36:23", "link": "http://arxiv.org/abs/2212.08607v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EffMulti: Efficiently Modeling Complex Multimodal Interactions for\n  Emotion Analysis", "abstract": "Humans are skilled in reading the interlocutor's emotion from multimodal\nsignals, including spoken words, simultaneous speech, and facial expressions.\nIt is still a challenge to effectively decode emotions from the complex\ninteractions of multimodal signals. In this paper, we design three kinds of\nmultimodal latent representations to refine the emotion analysis process and\ncapture complex multimodal interactions from different views, including a\nintact three-modal integrating representation, a modality-shared\nrepresentation, and three modality-individual representations. Then, a\nmodality-semantic hierarchical fusion is proposed to reasonably incorporate\nthese representations into a comprehensive interaction representation. The\nexperimental results demonstrate that our EffMulti outperforms the\nstate-of-the-art methods. The compelling performance benefits from its\nwell-designed framework with ease of implementation, lower computing\ncomplexity, and less trainable parameters.", "published": "2022-12-16 03:05:55", "link": "http://arxiv.org/abs/2212.08661v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Rarely a problem? Language models exhibit inverse scaling in their\n  predictions following few-type quantifiers", "abstract": "How well do language models deal with quantification? In this study, we focus\non 'few'-type quantifiers, as in 'few children like toys', which might pose a\nparticular challenge for language models because the sentence components with\nout the quantifier are likely to co-occur, and 'few'-type quantifiers are rare.\nWe present 960 English sentence stimuli from two human neurolinguistic\nexperiments to 22 autoregressive transformer models of differing sizes. Not\nonly do all the models perform poorly on 'few'-type quantifiers, but overall\nthe larger the model, the worse its performance. This inverse scaling is\nconsistent with previous work suggesting that larger models increasingly\nreflect online rather than offline human processing, and we argue that the\ndecreasing performance of larger models may challenge uses of language models\nas the basis for natural language systems.", "published": "2022-12-16 20:01:22", "link": "http://arxiv.org/abs/2212.08700v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Safe and Usable Chatbots for Promoting Voter Participation", "abstract": "Chatbots, or bots for short, are multi-modal collaborative assistants that\ncan help people complete useful tasks. Usually, when chatbots are referenced in\nconnection with elections, they often draw negative reactions due to the fear\nof mis-information and hacking. Instead, in this paper, we explore how chatbots\nmay be used to promote voter participation in vulnerable segments of society\nlike senior citizens and first-time voters. In particular, we build a system\nthat amplifies official information while personalizing it to users' unique\nneeds transparently. We discuss its design, build prototypes with frequently\nasked questions (FAQ) election information for two US states that are low on an\nease-of-voting scale, and report on its initial evaluation in a focus group.\nOur approach can be a win-win for voters, election agencies trying to fulfill\ntheir mandate and democracy at large.", "published": "2022-12-16 08:07:51", "link": "http://arxiv.org/abs/2212.11219v2", "categories": ["cs.HC", "cs.CL", "cs.CY"], "primary_category": "cs.HC"}
{"title": "Twitter's Agenda-Setting Role: A Study of Twitter Strategy for Political\n  Diversion", "abstract": "This study verified the effectiveness of Donald Trump's Twitter campaign in\nguiding agen-da-setting and deflecting political risk and examined Trump's\nTwitter communication strategy and explores the communication effects of his\ntweet content during Covid-19 pandemic. We collected all tweets posted by Trump\non the Twitter platform from January 1, 2020 to December 31, 2020.We used\nOrdinary Least Squares (OLS) regression analysis with a fixed effects model to\nanalyze the existence of the Twitter strategy. The correlation between the\nnumber of con-firmed daily Covid-19 diagnoses and the number of particular\nthematic tweets was investigated using time series analysis. Empirical analysis\nrevealed Twitter's strategy is used to divert public attention from negative\nCovid-19 reports during the epidemic, and it posts a powerful political\ncommunication effect on Twitter. However, findings suggest that Trump did not\nuse false claims to divert political risk and shape public opinion.", "published": "2022-12-16 11:34:49", "link": "http://arxiv.org/abs/2212.14672v1", "categories": ["cs.CY", "cs.CL", "cs.SI"], "primary_category": "cs.CY"}
{"title": "POTATO: The Portable Text Annotation Tool", "abstract": "We present POTATO, the Portable text annotation tool, a free, fully\nopen-sourced annotation system that 1) supports labeling many types of text and\nmultimodal data; 2) offers easy-to-configure features to maximize the\nproductivity of both deployers and annotators (convenient templates for common\nML/NLP tasks, active learning, keypress shortcuts, keyword highlights,\ntooltips); and 3) supports a high degree of customization (editable UI,\ninserting pre-screening questions, attention and qualification tests).\nExperiments over two annotation tasks suggest that POTATO improves labeling\nspeed through its specially-designed productivity features, especially for long\ndocuments and complex tasks. POTATO is available at\nhttps://github.com/davidjurgens/potato and will continue to be updated.", "published": "2022-12-16 17:57:41", "link": "http://arxiv.org/abs/2212.08620v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fast Entropy-Based Methods of Word-Level Confidence Estimation for\n  End-To-End Automatic Speech Recognition", "abstract": "This paper presents a class of new fast non-trainable entropy-based\nconfidence estimation methods for automatic speech recognition. We show how\nper-frame entropy values can be normalized and aggregated to obtain a\nconfidence measure per unit and per word for Connectionist Temporal\nClassification (CTC) and Recurrent Neural Network Transducer (RNN-T) models.\nProposed methods have similar computational complexity to the traditional\nmethod based on the maximum per-frame probability, but they are more\nadjustable, have a wider effective threshold range, and better push apart the\nconfidence distributions of correct and incorrect words. We evaluate the\nproposed confidence measures on LibriSpeech test sets, and show that they are\nup to 2 and 4 times better than confidence estimation based on the maximum\nper-frame probability at detecting incorrect words for Conformer-CTC and\nConformer-RNN-T models, respectively.", "published": "2022-12-16 20:27:40", "link": "http://arxiv.org/abs/2212.08703v1", "categories": ["eess.AS", "cs.CL", "cs.IT", "cs.LG", "math.IT"], "primary_category": "eess.AS"}
{"title": "Towards Unified All-Neural Beamforming for Time and Frequency Domain\n  Speech Separation", "abstract": "Recently, frequency domain all-neural beamforming methods have achieved\nremarkable progress for multichannel speech separation. In parallel, the\nintegration of time domain network structure and beamforming also gains\nsignificant attention. This study proposes a novel all-neural beamforming\nmethod in time domain and makes an attempt to unify the all-neural beamforming\npipelines for time domain and frequency domain multichannel speech separation.\nThe proposed model consists of two modules: separation and beamforming. Both\nmodules perform temporal-spectral-spatial modeling and are trained from\nend-to-end using a joint loss function. The novelty of this study lies in two\nfolds. Firstly, a time domain directional feature conditioned on the direction\nof the target speaker is proposed, which can be jointly optimized within the\ntime domain architecture to enhance target signal estimation. Secondly, an\nall-neural beamforming network in time domain is designed to refine the\npre-separated results. This module features with parametric time-variant\nbeamforming coefficient estimation, without explicitly following the derivation\nof optimal filters that may lead to an upper bound. The proposed method is\nevaluated on simulated reverberant overlapped speech data derived from the\nAISHELL-1 corpus. Experimental results demonstrate significant performance\nimprovements over frequency domain state-of-the-arts, ideal magnitude masks and\nexisting time domain neural beamforming methods.", "published": "2022-12-16 08:48:19", "link": "http://arxiv.org/abs/2212.08348v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Source Tracing: Detecting Voice Spoofing", "abstract": "Recent anti-spoofing systems focus on spoofing detection, where the task is\nonly to determine whether the test audio is fake. However, there are few\nstudies putting attention to identifying the methods of generating fake speech.\nCommon spoofing attack algorithms in the logical access (LA) scenario, such as\nvoice conversion and speech synthesis, can be divided into several stages:\ninput processing, conversion, waveform generation, etc. In this work, we\npropose a system for classifying different spoofing attributes, representing\ncharacteristics of different modules in the whole pipeline. Classifying\nattributes for the spoofing attack other than determining the whole spoofing\npipeline can make the system more robust when encountering complex combinations\nof different modules at different stages. In addition, our system can also be\nused as an auxiliary system for anti-spoofing against unseen spoofing methods.\nThe experiments are conducted on ASVspoof 2019 LA data set and the proposed\nmethod achieved a 20\\% relative improvement against conventional binary spoof\ndetection methods.", "published": "2022-12-16 17:29:15", "link": "http://arxiv.org/abs/2212.08601v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Feature Dropout: Revisiting the Role of Augmentations in Contrastive\n  Learning", "abstract": "What role do augmentations play in contrastive learning? Recent work suggests\nthat good augmentations are label-preserving with respect to a specific\ndownstream task. We complicate this picture by showing that label-destroying\naugmentations can be useful in the foundation model setting, where the goal is\nto learn diverse, general-purpose representations for multiple downstream\ntasks. We perform contrastive learning experiments on a range of image and\naudio datasets with multiple downstream tasks (e.g. for digits superimposed on\nphotographs, predicting the class of one vs. the other). We find that Viewmaker\nNetworks, a recently proposed model for learning augmentations for contrastive\nlearning, produce label-destroying augmentations that stochastically destroy\nfeatures needed for different downstream tasks. These augmentations are\ninterpretable (e.g. altering shapes, digits, or letters added to images) and\nsurprisingly often result in better performance compared to expert-designed\naugmentations, despite not preserving label information. To support our\nempirical results, we theoretically analyze a simple contrastive learning\nsetting with a linear model. In this setting, label-destroying augmentations\nare crucial for preventing one set of features from suppressing the learning of\nfeatures useful for another downstream task. Our results highlight the need for\nanalyzing the interaction between multiple downstream tasks when trying to\nexplain the success of foundation models.", "published": "2022-12-16 10:08:38", "link": "http://arxiv.org/abs/2212.08378v1", "categories": ["cs.LG", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
