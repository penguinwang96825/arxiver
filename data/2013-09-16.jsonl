{"title": "Using Self-Organizing Maps for Sentiment Analysis", "abstract": "Web 2.0 services have enabled people to express their opinions, experience\nand feelings in the form of user-generated content. Sentiment analysis or\nopinion mining involves identifying, classifying and aggregating opinions as\nper their positive or negative polarity. This paper investigates the efficacy\nof different implementations of Self-Organizing Maps (SOM) for sentiment based\nvisualization and classification of online reviews. Specifically, this paper\nimplements the SOM algorithm for both supervised and unsupervised learning from\ntext documents. The unsupervised SOM algorithm is implemented for sentiment\nbased visualization and classification tasks. For supervised sentiment\nanalysis, a competitive learning algorithm known as Learning Vector\nQuantization is used. Both algorithms are also compared with their respective\nmulti-pass implementations where a quick rough ordering pass is followed by a\nfine tuning pass. The experimental results on the online movie review data set\nshow that SOMs are well suited for sentiment based classification and sentiment\npolarity visualization.", "published": "2013-09-16 13:21:45", "link": "http://arxiv.org/abs/1309.3946v1", "categories": ["cs.IR", "cs.CL", "cs.NE"], "primary_category": "cs.IR"}
{"title": "Performance Investigation of Feature Selection Methods", "abstract": "Sentiment analysis or opinion mining has become an open research domain after\nproliferation of Internet and Web 2.0 social media. People express their\nattitudes and opinions on social media including blogs, discussion forums,\ntweets, etc. and, sentiment analysis concerns about detecting and extracting\nsentiment or opinion from online text. Sentiment based text classification is\ndifferent from topical text classification since it involves discrimination\nbased on expressed opinion on a topic. Feature selection is significant for\nsentiment analysis as the opinionated text may have high dimensions, which can\nadversely affect the performance of sentiment analysis classifier. This paper\nexplores applicability of feature selection methods for sentiment analysis and\ninvestigates their performance for classification in term of recall, precision\nand accuracy. Five feature selection methods (Document Frequency, Information\nGain, Gain Ratio, Chi Squared, and Relief-F) and three popular sentiment\nfeature lexicons (HM, GI and Opinion Lexicon) are investigated on movie reviews\ncorpus with a size of 2000 documents. The experimental results show that\nInformation Gain gave consistent results and Gain Ratio performs overall best\nfor sentimental feature selection while sentiment lexicons gave poor\nperformance. Furthermore, we found that performance of the classifier depends\non appropriate number of representative feature selected from text.", "published": "2013-09-16 13:27:04", "link": "http://arxiv.org/abs/1309.3949v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Domain and Function: A Dual-Space Model of Semantic Relations and\n  Compositions", "abstract": "Given appropriate representations of the semantic relations between carpenter\nand wood and between mason and stone (for example, vectors in a vector space\nmodel), a suitable algorithm should be able to recognize that these relations\nare highly similar (carpenter is to wood as mason is to stone; the relations\nare analogous). Likewise, with representations of dog, house, and kennel, an\nalgorithm should be able to recognize that the semantic composition of dog and\nhouse, dog house, is highly similar to kennel (dog house and kennel are\nsynonymous). It seems that these two tasks, recognizing relations and\ncompositions, are closely connected. However, up to now, the best models for\nrelations are significantly different from the best models for compositions. In\nthis paper, we introduce a dual-space model that unifies these two tasks. This\nmodel matches the performance of the best previous models for relations and\ncompositions. The dual-space model consists of a space for measuring domain\nsimilarity and a space for measuring function similarity. Carpenter and wood\nshare the same domain, the domain of carpentry. Mason and stone share the same\ndomain, the domain of masonry. Carpenter and mason share the same function, the\nfunction of artisans. Wood and stone share the same function, the function of\nmaterials. In the composition dog house, kennel has some domain overlap with\nboth dog and house (the domains of pets and buildings). The function of kennel\nis similar to the function of house (the function of shelters). By combining\ndomain and function similarities in various ways, we can model relations,\ncompositions, and other aspects of semantics.", "published": "2013-09-16 16:51:02", "link": "http://arxiv.org/abs/1309.4035v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "H.3.1; I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "Why SOV might be initially preferred and then lost or recovered? A\n  theoretical framework", "abstract": "Little is known about why SOV order is initially preferred and then discarded\nor recovered. Here we present a framework for understanding these and many\nrelated word order phenomena: the diversity of dominant orders, the existence\nof free words orders, the need of alternative word orders and word order\nreversions and cycles in evolution. Under that framework, word order is\nregarded as a multiconstraint satisfaction problem in which at least two\nconstraints are in conflict: online memory minimization and maximum\npredictability.", "published": "2013-09-16 18:21:54", "link": "http://arxiv.org/abs/1309.4058v1", "categories": ["cs.CL", "nlin.AO", "physics.soc-ph", "q-bio.NC"], "primary_category": "cs.CL"}
