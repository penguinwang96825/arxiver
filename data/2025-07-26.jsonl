{"title": "ModShift: Model Privacy via Designed Shifts", "abstract": "In this paper, shifts are introduced to preserve model privacy against an\neavesdropper in federated learning. Model learning is treated as a parameter\nestimation problem. This perspective allows us to derive the Fisher Information\nmatrix of the model updates from the shifted updates and drive them to\nsingularity, thus posing a hard estimation problem for Eve. The shifts are\nsecurely shared with the central server to maintain model accuracy at the\nserver and participating devices. A convergence test is proposed to detect if\nmodel updates have been tampered with and we show that our scheme passes this\ntest. Numerical results show that our scheme achieves a higher model shift when\ncompared to a noise injection scheme while requiring a lesser bandwidth secret\nchannel.", "published": "2025-07-26 21:00:56", "link": "http://arxiv.org/abs/2507.20060v1", "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Performance Analysis of Spatiotemporal 2-D Polar Codes for Massive MIMO with MMSE Receivers", "abstract": "With the evolution from 5G to 6G, ultra-reliable low-latency communication\n(URLLC) faces increasingly stringent performance requirements. Lower latency\nconstraints demand shorter channel coding lengths, which can severely degrade\ndecoding performance. The massive multiple-input multiple-output (MIMO) system\nis considered a crucial technology to address this challenge due to its\nabundant spatial degrees of freedom (DoF). While polar codes are theoretically\ncapacity-achieving in the limit of infinite code length, their practical\napplicability is limited by significant decoding latency. In this paper, we\nestablish a unified theoretical framework and propose a novel spatiotemporal\ntwo-dimensional (2-D) polar coding scheme for massive MIMO systems employing\nminimum mean square error (MMSE) receivers. The polar transform is jointly\napplied over both spatial and temporal dimensions to fully exploit the large\nspatial DoF. By leveraging the near-deterministic\nsignal-to-interference-plus-noise ratio (SINR) property of MMSE detection, the\nspatial domain is modeled as a set of parallel Gaussian sub-channels. Within\nthis framework, we perform a theoretical analysis of the 2-D polarization\nbehavior using the Gaussian approximation method, and the capacity-achieving\nproperty of the proposed scheme is proved under finite blocklength constraints\nand large spatial DoF. Simulation results further demonstrate that, compared to\ntraditional time-domain polar codes, the proposed 2-D scheme can significantly\nreduce latency while guaranteeing reliability, or alternatively improve\nreliability under the same latency constraint -- offering a capacity-achieving\nand latency-efficient channel coding solution for massive MIMO systems in\nfuture 6G URLLC scenarios.", "published": "2025-07-26 15:50:56", "link": "http://arxiv.org/abs/2507.19986v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Digital Twin Channel-Enabled Online Resource Allocation for 6G: Principle, Architecture and Application", "abstract": "Emerging applications such as holographic communication, autonomous driving,\nand the industrial Internet of Things impose stringent requirements on\nflexible, low-latency, and reliable resource allocation in 6G networks.\nConventional methods, which rely on statistical modeling, have proven effective\nin general contexts but may fail to achieve optimal performance in specific and\ndynamic environments. Furthermore, acquiring real-time channel state\ninformation (CSI) typically requires excessive pilot overhead. To address these\nchallenges, a digital twin channel (DTC)-enabled online optimization framework\nis proposed, in which DTC is employed to predict CSI based on environmental\nsensing. The predicted CSI is then utilized by lightweight game-theoretic\nalgorithms to perform online resource allocation in a timely and efficient\nmanner. Simulation results based on a digital replica of a realistic industrial\nworkshop demonstrate that the proposed method achieves throughput improvements\nof up to 11.5\\% compared with pilot-based ideal CSI schemes, validating its\neffectiveness for scalable, low-overhead, and environment-aware communication\nin future 6G networks.", "published": "2025-07-26 15:07:45", "link": "http://arxiv.org/abs/2507.19974v1", "categories": ["cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.AI"}
{"title": "Spatial Language Likelihood Grounding Network for Bayesian Fusion of Human-Robot Observations", "abstract": "Fusing information from human observations can help robots overcome sensing\nlimitations in collaborative tasks. However, an uncertainty-aware fusion\nframework requires a grounded likelihood representing the uncertainty of human\ninputs. This paper presents a Feature Pyramid Likelihood Grounding Network\n(FP-LGN) that grounds spatial language by learning relevant map image features\nand their relationships with spatial relation semantics. The model is trained\nas a probability estimator to capture aleatoric uncertainty in human language\nusing three-stage curriculum learning. Results showed that FP-LGN matched\nexpert-designed rules in mean Negative Log-Likelihood (NLL) and demonstrated\ngreater robustness with lower standard deviation. Collaborative sensing results\ndemonstrated that the grounded likelihood successfully enabled\nuncertainty-aware fusion of heterogeneous human language observations and robot\nsensor measurements, achieving significant improvements in human-robot\ncollaborative task performance.", "published": "2025-07-26 13:24:02", "link": "http://arxiv.org/abs/2507.19947v1", "categories": ["cs.RO", "cs.CL", "cs.IT", "cs.LG", "cs.SY", "eess.SY", "math.IT"], "primary_category": "cs.RO"}
{"title": "Adaptive Learned Belief Propagation for Decoding Error-Correcting Codes", "abstract": "Weighted belief propagation (WBP) for the decoding of linear block codes is\nconsidered. In WBP, the Tanner graph of the code is unrolled with respect to\nthe iterations of the belief propagation decoder. Then, weights are assigned to\nthe edges of the resulting recurrent network and optimized offline using a\ntraining dataset. The main contribution of this paper is an adaptive WBP where\nthe weights of the decoder are determined for each received word. Two variants\nof this decoder are investigated. In the parallel WBP decoders, the weights\ntake values in a discrete set. A number of WBP decoders are run in parallel to\nsearch for the best sequence- of weights in real time. In the two-stage\ndecoder, a small neural network is used to dynamically determine the weights of\nthe WBP decoder for each received word. The proposed adaptive decoders\ndemonstrate significant improvements over the static counterparts in two\napplications. In the first application, Bose--Chaudhuri--Hocquenghem, polar and\nquasi-cyclic low-density parity-check (QC-LDPC) codes are used over an additive\nwhite Gaussian noise channel. The results indicate that the adaptive WBP\nachieves bit error rates (BERs) up to an order of magnitude less than the BERs\nof the static WBP at about the same decoding complexity, depending on the code,\nits rate, and the signal-to-noise ratio. The second application is a\nconcatenated code designed for a long-haul nonlinear optical fiber channel\nwhere the inner code is a QC-LDPC code and the outer code is a spatially\ncoupled LDPC code. In this case, the inner code is decoded using an adaptive\nWBP, while the outer code is decoded using the sliding window decoder and\nstatic belief propagation. The results show that the adaptive WBP provides a\ncoding gain of 0.8 dB compared to the neural normalized min-sum decoder, with\nabout the same computational complexity and decoding latency.", "published": "2025-07-26 13:12:30", "link": "http://arxiv.org/abs/2507.19941v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "An Efficient Alternating Minimization Algorithm for Computing Quantum Rate-Distortion Function", "abstract": "We consider the computation of the entanglement-assisted quantum\nrate-distortion function, which plays a central role in quantum information\ntheory. We propose an efficient alternating minimization algorithm based on the\nLagrangian analysis. Instead of fixing the multiplier corresponding to the\ndistortion constraint, we update the multiplier in each iteration. Hence the\nalgorithm solves the original problem itself, rather than the Lagrangian\nrelaxation of it. Moreover, all the other variables are iterated in closed form\nwithout solving multi-dimensional nonlinear equations or multivariate\noptimization problems. Numerical experiments show the accuracy of our proposed\nalgorithm and its improved efficiency over existing methods.", "published": "2025-07-26 11:55:31", "link": "http://arxiv.org/abs/2507.19920v1", "categories": ["cs.IT", "math.IT", "quant-ph"], "primary_category": "cs.IT"}
{"title": "Neural Estimation of the Information Bottleneck Based on a Mapping Approach", "abstract": "The information bottleneck (IB) method is a technique designed to extract\nmeaningful information related to one random variable from another random\nvariable, and has found extensive applications in machine learning problems. In\nthis paper, neural network based estimation of the IB problem solution is\nstudied, through the lens of a novel formulation of the IB problem. Via\nexploiting the inherent structure of the IB functional and leveraging the\nmapping approach, the proposed formulation of the IB problem involves only a\nsingle variable to be optimized, and subsequently is readily amenable to\ndata-driven estimators based on neural networks. A theoretical analysis is\nconducted to guarantee that the neural estimator asymptotically solves the IB\nproblem, and the numerical experiments on both synthetic and MNIST datasets\ndemonstrate the effectiveness of the neural estimator.", "published": "2025-07-26 07:04:40", "link": "http://arxiv.org/abs/2507.19832v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Efficient Computation of Marton's Error Exponent via Constraint Decoupling", "abstract": "The error exponent in lossy source coding characterizes the asymptotic decay\nrate of error probability with respect to blocklength. The Marton's error\nexponent provides the theoretically optimal bound on this rate. However,\ncomputation methods of the Marton's error exponent remain underdeveloped due to\nits formulation as a non-convex optimization problem with limited efficient\nsolvers. While a recent grid search algorithm can compute its inverse function,\nit incurs prohibitive computational costs from two-dimensional brute-force\nparameter grid searches. This paper proposes a composite maximization approach\nthat effectively handles both Marton's error exponent and its inverse function.\nThrough a constraint decoupling technique, the resulting problem formulations\nadmit efficient solvers driven by an alternating maximization algorithm. By\nfixing one parameter via a one-dimensional line search, the remaining\nsubproblem becomes convex and can be efficiently solved by alternating variable\nupdates, thereby significantly reducing search complexity. Therefore, the\nglobal convergence of the algorithm can be guaranteed. Numerical experiments\nfor simple sources and the Ahlswede's counterexample, demonstrates the superior\nefficiency of our algorithm in contrast to existing methods.", "published": "2025-07-26 06:17:03", "link": "http://arxiv.org/abs/2507.19816v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Homotopy-aware Multi-agent Navigation via Distributed Model Predictive Control", "abstract": "Multi-agent trajectory planning requires ensuring both safety and efficiency,\nyet deadlocks remain a significant challenge, especially in obstacle-dense\nenvironments. Such deadlocks frequently occur when multiple agents attempt to\ntraverse the same long and narrow corridor simultaneously. To address this, we\npropose a novel distributed trajectory planning framework that bridges the gap\nbetween global path and local trajectory cooperation. At the global level, a\nhomotopy-aware optimal path planning algorithm is proposed, which fully\nleverages the topological structure of the environment. A reference path is\nchosen from distinct homotopy classes by considering both its spatial and\ntemporal properties, leading to improved coordination among agents globally. At\nthe local level, a model predictive control-based trajectory optimization\nmethod is used to generate dynamically feasible and collision-free\ntrajectories. Additionally, an online replanning strategy ensures its\nadaptability to dynamic environments. Simulations and experiments validate the\neffectiveness of our approach in mitigating deadlocks. Ablation studies\ndemonstrate that by incorporating time-aware homotopic properties into the\nunderlying global paths, our method can significantly reduce deadlocks and\nimprove the average success rate from 4%-13% to over 90% in randomly generated\ndense scenarios.", "published": "2025-07-26 08:26:36", "link": "http://arxiv.org/abs/2507.19860v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "VAE-GAN Based Price Manipulation in Coordinated Local Energy Markets", "abstract": "This paper introduces a model for coordinating prosumers with heterogeneous\ndistributed energy resources (DERs), participating in the local energy market\n(LEM) that interacts with the market-clearing entity. The proposed LEM scheme\nutilizes a data-driven, model-free reinforcement learning approach based on the\nmulti-agent deep deterministic policy gradient (MADDPG) framework, enabling\nprosumers to make real-time decisions on whether to buy, sell, or refrain from\nany action while facilitating efficient coordination for optimal energy trading\nin a dynamic market. In addition, we investigate a price manipulation strategy\nusing a variational auto encoder-generative adversarial network (VAE-GAN)\nmodel, which allows utilities to adjust price signals in a way that induces\nfinancial losses for the prosumers. Our results show that under adversarial\npricing, heterogeneous prosumer groups, particularly those lacking generation\ncapabilities, incur financial losses. The same outcome holds across LEMs of\ndifferent sizes. As the market size increases, trading stabilizes and fairness\nimproves through emergent cooperation among agents.", "published": "2025-07-26 07:38:27", "link": "http://arxiv.org/abs/2507.19844v1", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Solving the MIT Inverse Problem by Considering Skin and Proximity Effects in Coils", "abstract": "This paper presents an improved technique for solving the inverse problem in\nmagnetic induction tomography (MIT) by considering skin and proximity effects\nin coils. MIT is a non-contact, noninvasive, and low-cost imaging modality for\nobtaining the distribution of conductivity inside an object. Reconstruction of\nlow conductivity distribution by MIT requires more accurate techniques since\nmeasured signals are inherently weak and the reconstruction problem is highly\nnonlinear and ill-posed. Previous MIT inverse problem studies have ignored skin\nand proximity effects inside coils in the forward method. In this article, the\nimproved technique incorporates these effects in the forward method.\nFurthermore, it employs the regularized Gauss-Newton algorithm to reconstruct\nthe conductivity distribution. The regularization parameter is obtained by an\nadaptive method using the two input parameters: a coefficient and an initial\nconductivity distribution. The new Jacobian matrix is computed based on a\nstandard technique. To compare the early and improved forward methods in\npossible medical and industrial applications with low conductivity regions, a\n2D 8-coil MIT system is modeled, and image reconstruction is performed for\nsynthetic phantoms. Results show that it is crucial to use the improved forward\nmethod for the reconstruction of the absolute conductivity values.", "published": "2025-07-26 16:51:49", "link": "http://arxiv.org/abs/2507.20004v1", "categories": ["physics.med-ph", "cs.NA", "math.NA", "physics.comp-ph"], "primary_category": "physics.med-ph"}
{"title": "Geometric-Perturbation-Robust Cut-Cell Scheme for Two-Material Flows: Exact Pressure-Equilibrium Preservation and Rigorous Analysis", "abstract": "Preserving pressure equilibrium across material interfaces is critical for\nthe stability of compressible multi-material flow simulations, yet most\ninterface-fitted sharp-interface schemes are notoriously sensitive to interface\ngeometry: even slight perturbations of the captured (or tracked) interface can\ntrigger large spurious pressure oscillations. We present a cut-cell method that\nis geometric-perturbation-robust (GPR) for the compressible two-material flows.\nBy construction, the scheme provably preserves exact interfacial pressure\nequilibrium in the presence of small interface-position errors. The key is a\nstrict consistency between the conserved variables and the geometric moments\n(i.e., the integrals of monomials) of every cut cell. We formulate auxiliary\ntransport equations, whose discrete solutions furnish evolved geometric moment,\nthese geometric moments remain perfectly synchronized with the conserved\nvariables -- even on a deforming mesh. Surpassing the classical geometric\nconservation law, our approach keeps all higher-order geometric moments\nconsistent, thereby eliminating accuracy loss due to geometric mismatches. To\nprevent the reconstruction step from destroying pressure equilibrium, we\nintroduce the notion of equilibrium-compatible (EC) reconstructions. A\ncarefully designed modification equips any conventional weighted essentially\nnon-oscillatory (WENO) reconstruction with the EC property; we detail a\nthird-order EC multi-resolution WENO (EC-MRWENO) variant. The tight coupling of\nEC-MRWENO with the evolved moments yields the first cut-cell solver that is\nsimultaneously provably GPR and genuinely high-order: it attains second-order\naccuracy precisely at material interfaces, while preserving third-order\naccuracy in smooth regions. Extensive two-dimensional tests confirm the\nframework's robustness, accuracy and stability under geometric perturbations\nand topology changes.", "published": "2025-07-26 14:46:20", "link": "http://arxiv.org/abs/2507.19966v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Time-continuous strongly conservative space-time finite element methods for the dynamic Biot model", "abstract": "We consider the dynamic Biot model (see [Biot, M. A. J. Appl. Phys. 33,\n1482--1498 (1962)]) describing the interaction between fluid flow and solid\ndeformation including wave propagation phenomena in both the liquid and solid\nphases of a saturated porous medium. This model couples a hyperbolic equation\nfor momentum balance to a second-order in time dynamic Darcy law and a\nparabolic equation for the balance of mass and is here considered in\nthree-field formulation with the displacement of the elastic matrix, the fluid\nvelocity, and the fluid pressure being the physical fields of interest.\n  A family of variational space-time finite element methods is proposed, which\ncombines a continuous-in-time Galerkin ansatz of arbitrary polynomial degree\nwith $H(\\mathrm{div})$-conforming approximations of the displacement field, its\ntime derivative, and the flux field--of discontinuous Galerkin (DG) type for\ndisplacements--with a piecewise polynomial pressure approximation, providing an\ninf-sup stable strongly conservative mixed method in each case. We prove error\nestimates in a combined energy norm in space for the maximum norm in time. The\ntheoretical results are confirmed by numerical experiments for different\npolynomial orders in space and time.", "published": "2025-07-26 13:52:41", "link": "http://arxiv.org/abs/2507.19955v1", "categories": ["math.NA", "cs.NA", "74H15 65M15 65M60 74F10"], "primary_category": "math.NA"}
{"title": "A Bi-fidelity numerical method for velocity discretization of Boltzmann equations", "abstract": "In this paper, we introduce a bi-fidelity algorithm for velocity\ndiscretization of Boltzmann-type kinetic equations under multiple scales. The\nproposed method employs a simpler and computationally cheaper low-fidelity\nmodel to capture a small set of significant velocity points through the greedy\napproach, then evaluates the high-fidelity model only at these few velocity\npoints and to reconstruct a bi-fidelity surrogate. This novel method integrates\na simpler collision term of relaxation type in the low-fidelity model and an\nasymptotic-preserving scheme in the high-fidelity update step. Both linear\nBoltzmann under diffusive scaling and the nonlinear full Boltzmann in\nhyperbolic scaling are discussed. We show the weak asymptotic-preserving\nproperty and empirical error bound estimates. Extensive numerical experiments\non linear semiconductor and nonlinear Boltzmann problems with smooth or\ndiscontinuous initial conditions and under various regimes have been carefully\nstudied, which demonstrates the effectiveness and robustness of our proposed\nscheme.", "published": "2025-07-26 13:21:11", "link": "http://arxiv.org/abs/2507.19945v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Deep Uzawa for Kinetic Transport with Lagrange-Enforced Boundaries", "abstract": "We propose a neural network framework for solving stationary linear transport\nequations with inflow boundary conditions. The method represents the solution\nusing a neural network and imposes the boundary condition via a Lagrange\nmultiplier, based on a saddle-point formulation inspired by the classical Uzawa\nalgorithm. The scheme is mesh-free, compatible with automatic differentiation\nand extends naturally to problems with scattering and heterogeneous media. We\nestablish convergence of the continuum formulation and analyse the effects of\nquadrature error, neural approximation and inexact optimisation in the discrete\nimplementation. Numerical experiments show that the method captures anisotropic\ntransport, enforces boundary conditions and resolves scattering dynamics\naccurately.", "published": "2025-07-26 10:36:24", "link": "http://arxiv.org/abs/2507.19907v1", "categories": ["math.NA", "cs.NA", "math.OC", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "A Modified Dielectric Contrast based Integral Equation for 2D TE Scattering by Inhomogeneous Domains", "abstract": "This work presents a modified domain integral equation approach for the\nforward problem of TE scattering, employing a modified definition of dielectric\ncontrast and discretizing the electric field density using Rao-Wilton-Glisson\n(RWG) basis functions. The proposed formulation mitigates the numerical\nchallenges introduced by the gradient-divergence operator in traditional\nelectric field-based vector formulations. The use of RWG basis functions over\ntriangular meshes enhances geometric conformity, ensures tangential continuity\nacross dielectric interfaces, and facilitates the application of well known\nsingularity extraction techniques for numerical accuracy. Validation through\nnumerical experiments on a two-layered dielectric cylinder demonstrates\nexcellent agreement between computed and analytical scattered fields.\nConvergence studies confirm improving solution accuracy with mesh refinement\nindicating robustness with respect to discretization without increasing the\niterations.", "published": "2025-07-26 04:01:11", "link": "http://arxiv.org/abs/2507.19777v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "An inverse random diffraction grating problem for the Helmholtz equation", "abstract": "This paper investigates the inverse scattering problem of time-harmonic plane\nwaves incident on a perfectly reflecting random periodic structure. To simulate\nrandom perturbations arising from manufacturing defects and surface wear in\nreal-world grating profiles, we propose a stochastic surface modeling framework\nmotivated by the discretization of the Wiener process. Our approach introduces\nrandomness at discrete nodes and then applies linear interpolation to construct\nthe surface, marking a novel attempt to incorporate the concepts of the Wiener\nprocess into random surface representation. Under this framework, each\nrealization of the random surface generates a Lipschitz-continuous diffraction\ngrating, mathematically represented as a sum of a baseline profile and a\nweighted linear combination of local `tent' basis functions, meanwhile\npreserving key statistics of the random surface. Building on this\nrepresentation, we introduce the Recursive Parametric Smoothing Strategy (RPSS)\nto invert the key statistics of our random surfaces. Combined with Monte Carlo\nsampling and a wavenumber continuation strategy, our reconstruction scheme\ndemonstrates effectiveness across multiple benchmark scenarios. Several\nnumerical results are presented along with some discussions in the end on\nreconstruction mechanisms and future extensions.", "published": "2025-07-26 02:29:19", "link": "http://arxiv.org/abs/2507.19744v1", "categories": ["math.NA", "cs.NA", "78A46, 65N21, 65C05"], "primary_category": "math.NA"}
{"title": "Implementation and Basis Construction for Smooth Finite Element Spaces", "abstract": "The construction of $C^m$ conforming finite elements on simplicial meshes has\nrecently advanced through the groundbreaking work of Hu, Lin, and Wu (Found.\nComput. Math. 24, 2024). Their framework characterizes smoothness via moments\nof normal derivatives over subsimplices, leading to explicit degrees of freedom\nand unisolvence, unifying earlier constructions. However, the absence of\nexplicit basis functions has left these spaces largely inaccessible for\npractical computation. In parallel, multivariate spline theory (Chui and Lai,\nJ. Approx. Theory 60, 1990) enforces $C^m$ smoothness through linear\nconstraints on Bernstein--B\\'{e}zier coefficients, but stable, locally\nsupported bases remain elusive beyond low dimensions. Building on the geometric\ndecomposition of the simplicial lattice proposed by Chen and Huang (Math. Comp.\n93, 2024), this work develops an explicit, computable framework for smooth\nfinite elements. The degrees of freedom defined by moments of normal\nderivatives are modified to align with the dual basis of the Bernstein\npolynomials, yielding structured local bases on each simplex. Explicit basis\nconstruction is essential not merely for completeness, but for enabling\nefficient matrix assembly, global continuity, and scalable solution of\nhigh-order elliptic partial differential equations. This development closes the\ngap between theoretical existence and practical realization, making smooth\nfinite element methods accessible to broad computational applications.", "published": "2025-07-26 01:19:14", "link": "http://arxiv.org/abs/2507.19732v1", "categories": ["math.NA", "cs.NA", "65N30, 65N12, 31B30"], "primary_category": "math.NA"}
{"title": "Optimal mean-variance portfolio selection under regime-switching-induced stock price shocks", "abstract": "In this paper, we investigate mean-variance (MV) portfolio selection problems\nwith jumps in a regime-switching financial model. The novelty of our approach\nlies in allowing not only the market parameters -- such as the interest rate,\nappreciation rate, volatility, and jump intensity -- to depend on the market\nregime, but also in permitting stock prices to experience jumps when the market\nregime switches, in addition to the usual micro-level jumps. This modeling\nchoice is motivated by empirical observations that stock prices often exhibit\nsharp declines when the market shifts from a ``bullish'' to a ``bearish''\nregime, and vice versa. By employing the completion-of-squares technique, we\nderive the optimal portfolio strategy and the efficient frontier, both of which\nare characterized by three systems of multi-dimensional ordinary differential\nequations (ODEs). Among these, two systems are linear, while the first one is\nan $\\ell$-dimensional, fully coupled, and highly nonlinear Riccati equation. In\nthe absence of regime-switching-induced stock price shocks, these systems\nreduce to simple linear ODEs. Thus, the introduction of\nregime-switching-induced stock price shocks adds significant complexity and\nchallenges to our model. Additionally, we explore the MV problem under a\nno-shorting constraint. In this case, the corresponding Riccati equation\nbecomes a $2\\ell$-dimensional, fully coupled, nonlinear ODE, for which we\nestablish solvability. The solution is then used to explicitly express the\noptimal portfolio and the efficient frontier.", "published": "2025-07-26 06:48:11", "link": "http://arxiv.org/abs/2507.19824v1", "categories": ["q-fin.PM", "math.OC", "math.PR", "q-fin.MF"], "primary_category": "q-fin.PM"}
{"title": "Lasso Penalization for High-Dimensional Beta Regression Models: Computation, Analysis, and Inference", "abstract": "Beta regression is commonly employed when the outcome variable is a\nproportion. Since its conception, the approach has been widely used in\napplications spanning various scientific fields. A series of extensions have\nbeen proposed over time, several of which address variable selection and\npenalized estimation, e.g., with an $\\ell_1$-penalty (LASSO). However, a\ntheoretical analysis of this popular approach in the context of Beta regression\nwith high-dimensional predictors is lacking. In this paper, we aim to close\nthis gap. A particular challenge arises from the non-convexity of the\nassociated negative log-likelihood, which we address by resorting to a\nframework for analyzing stationary points in a neighborhood of the target\nparameter. Leveraging this framework, we derive a non-asymptotic bound on the\n$\\ell_1$-error of such stationary points. In addition, we propose a debiasing\napproach to construct confidence intervals for the regression parameters. A\nproximal gradient algorithm is devised for optimizing the resulting penalized\nnegative log-likelihood function. Our theoretical analysis is corroborated via\nsimulation studies, and a real data example concerning the prediction of\ncounty-level proportions of incarceration is presented to showcase the\npractical utility of our methodology.", "published": "2025-07-26 23:19:17", "link": "http://arxiv.org/abs/2507.20079v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "PERRY: Policy Evaluation with Confidence Intervals using Auxiliary Data", "abstract": "Off-policy evaluation (OPE) methods aim to estimate the value of a new\nreinforcement learning (RL) policy prior to deployment. Recent advances have\nshown that leveraging auxiliary datasets, such as those synthesized by\ngenerative models, can improve the accuracy of these value estimates.\nUnfortunately, such auxiliary datasets may also be biased, and existing methods\nfor using data augmentation for OPE in RL lack principled uncertainty\nquantification. In high stakes settings like healthcare, reliable uncertainty\nestimates are important for comparing policy value estimates. In this work, we\npropose two approaches to construct valid confidence intervals for OPE when\nusing data augmentation. The first provides a confidence interval over the\npolicy performance conditioned on a particular initial state $V^{\\pi}(s_0)$--\nsuch intervals are particularly important for human-centered applications. To\ndo so we introduce a new conformal prediction method for high dimensional state\nMDPs. Second, we consider the more common task of estimating the average policy\nperformance over many initial states; to do so we draw on ideas from doubly\nrobust estimation and prediction powered inference. Across simulators spanning\nrobotics, healthcare and inventory management, and a real healthcare dataset\nfrom MIMIC-IV, we find that our methods can use augmented data and still\nconsistently produce intervals that cover the ground truth values, unlike\npreviously proposed methods.", "published": "2025-07-26 21:51:15", "link": "http://arxiv.org/abs/2507.20068v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Predicting Parkinson's Disease Progression Using Statistical and Neural Mixed Effects Models: A Comparative Study on Longitudinal Biomarkers", "abstract": "Predicting Parkinson's Disease (PD) progression is crucial, and voice\nbiomarkers offer a non-invasive method for tracking symptom severity (UPDRS\nscores) through telemonitoring. Analyzing this longitudinal data is challenging\ndue to within-subject correlations and complex, nonlinear patient-specific\nprogression patterns. This study benchmarks LMMs against two advanced hybrid\napproaches: the Generalized Neural Network Mixed Model (GNMM) (Mandel 2021),\nwhich embeds a neural network within a GLMM structure, and the Neural Mixed\nEffects (NME) model (Wortwein 2023), allowing nonlinear subject-specific\nparameters throughout the network. Using the Oxford Parkinson's telemonitoring\nvoice dataset, we evaluate these models' performance in predicting Total UPDRS\nto offer practical guidance for PD research and clinical applications.", "published": "2025-07-26 20:56:32", "link": "http://arxiv.org/abs/2507.20058v1", "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "stat.ML"}
{"title": "Irredundant k-Fold Cross-Validation", "abstract": "In traditional k-fold cross-validation, each instance is used ($k\\!-\\!1$)\ntimes for training and once for testing, leading to redundancy that lets many\ninstances disproportionately influence the learning phase. We introduce\nIrredundant $k$--fold cross-validation, a novel method that guarantees each\ninstance is used exactly once for training and once for testing across the\nentire validation procedure. This approach ensures a more balanced utilization\nof the dataset, mitigates overfitting due to instance repetition, and enables\nsharper distinctions in comparative model analysis. The method preserves\nstratification and remains model-agnostic, i.e., compatible with any\nclassifier. Experimental results demonstrate that it delivers consistent\nperformance estimates across diverse datasets --comparable to $k$--fold\ncross-validation-- while providing less optimistic variance estimates because\ntraining partitions are non-overlapping, and significantly reducing the overall\ncomputational cost.", "published": "2025-07-26 19:59:37", "link": "http://arxiv.org/abs/2507.20048v1", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Dependency Network-Based Portfolio Design with Forecasting and VaR Constraints", "abstract": "This study proposes a novel portfolio optimization framework that integrates\nstatistical social network analysis with time series forecasting and risk\nmanagement. Using daily stock data from the S&P 500 (2020-2024), we construct\ndependency networks via Vector Autoregression (VAR) and Forecast Error Variance\nDecomposition (FEVD), transforming influence relationships into a cost-based\nnetwork. Specifically, FEVD breaks down the VAR's forecast error variance to\nquantify how much each stock's shocks contribute to another's uncertainty\ninformation we invert to form influence-based edge weights in our network. By\napplying the Minimum Spanning Tree (MST) algorithm, we extract the core\ninter-stock structure and identify central stocks through degree centrality. A\ndynamic portfolio is constructed using the top-ranked stocks, with capital\nallocated based on Value at Risk (VaR). To refine stock selection, we\nincorporate forecasts from ARIMA and Neural Network Autoregressive (NNAR)\nmodels. Trading simulations over a one-year period demonstrate that the\nMST-based strategies outperform a buy-and-hold benchmark, with the tuned\nNNAR-enhanced strategy achieving a 63.74% return versus 18.00% for the\nbenchmark. Our results highlight the potential of combining network structures,\npredictive modeling, and risk metrics to improve adaptive financial\ndecision-making.", "published": "2025-07-26 18:53:39", "link": "http://arxiv.org/abs/2507.20039v1", "categories": ["q-fin.PM", "econ.EM", "q-fin.ST", "stat.ML"], "primary_category": "q-fin.PM"}
{"title": "Discrete Gaussian Vector Fields On Meshes", "abstract": "Though the underlying fields associated with vector-valued environmental data\nare continuous, observations themselves are discrete. For example, climate\nmodels typically output grid-based representations of wind fields or ocean\ncurrents, and these are often downscaled to a discrete set of points. By\ntreating the area of interest as a two-dimensional manifold that can be\nrepresented as a triangular mesh and embedded in Euclidean space, this work\nshows that discrete intrinsic Gaussian processes for vector-valued data can be\ndeveloped from discrete differential operators defined with respect to a mesh.\nThese Gaussian processes account for the geometry and curvature of the manifold\nwhilst also providing a flexible and practical formulation that can be readily\napplied to any two-dimensional mesh. We show that these models can capture\nharmonic flows, incorporate boundary conditions, and model non-stationary data.\nFinally, we apply these models to downscaling stationary and non-stationary\ngridded wind data on the globe, and to inference of ocean currents from sparse\nobservations in bounded domains.", "published": "2025-07-26 17:43:31", "link": "http://arxiv.org/abs/2507.20024v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Extreme value theory for singular subspace estimation in the matrix denoising model", "abstract": "This paper studies fine-grained singular subspace estimation in the matrix\ndenoising model where a deterministic low-rank signal matrix is additively\nperturbed by a stochastic matrix of Gaussian noise. We establish that the\nmaximum Euclidean row norm (i.e., the two-to-infinity norm) of the aligned\ndifference between the leading sample and population singular vectors\napproaches the Gumbel distribution in the large-matrix limit, under suitable\nsignal-to-noise conditions and after appropriate centering and scaling. We\napply our novel asymptotic distributional theory to test hypotheses of low-rank\nsignal structure encoded in the leading singular vectors and their\ncorresponding principal subspace. We provide de-biased estimators for the\ncorresponding nuisance signal singular values and show that our proposed\nplug-in test statistic has desirable properties. Notably, compared to using the\nFrobenius norm subspace distance, our test statistic based on the\ntwo-to-infinity norm has higher power to detect structured alternatives that\ndiffer from the null in only a few matrix entries or rows. Our main results are\nobtained by a novel synthesis of and technical analysis involving entrywise\nmatrix perturbation analysis, extreme value theory, saddle point approximation\nmethods, and random matrix theory. Our contributions complement the existing\nliterature for matrix denoising focused on minimaxity, mean squared error\nanalysis, unitarily invariant distances between subspaces, component-wise\nasymptotic distributional theory, and row-wise uniform error bounds. Numerical\nsimulations illustrate our main results and demonstrate the robustness\nproperties of our testing procedure to non-Gaussian noise distributions.", "published": "2025-07-26 15:28:36", "link": "http://arxiv.org/abs/2507.19978v1", "categories": ["math.ST", "cs.LG", "stat.ME", "stat.ML", "stat.TH", "62H25, 62H15 (Primary) 62E20 (Secondary)"], "primary_category": "math.ST"}
{"title": "Dimer-Enhanced Optimization: A First-Order Approach to Escaping Saddle Points in Neural Network Training", "abstract": "First-order optimization methods, such as SGD and Adam, are widely used for\ntraining large-scale deep neural networks due to their computational efficiency\nand robust performance. However, relying solely on gradient information, these\nmethods often struggle to navigate complex loss landscapes with flat regions,\nplateaus, and saddle points. Second-order methods, which use curvature\ninformation from the Hessian matrix, can address these challenges but are\ncomputationally infeasible for large models. The Dimer method, a first-order\ntechnique that constructs two closely spaced points to probe the local geometry\nof a potential energy surface, efficiently estimates curvature using only\ngradient information. Inspired by its use in molecular dynamics simulations for\nlocating saddle points, we propose Dimer-Enhanced Optimization (DEO), a novel\nframework to escape saddle points in neural network training. DEO adapts the\nDimer method to explore a broader region of the loss landscape, approximating\nthe Hessian's smallest eigenvector without computing the full matrix. By\nperiodically projecting the gradient onto the subspace orthogonal to the\nminimum curvature direction, DEO guides the optimizer away from saddle points\nand flat regions, enhancing training efficiency with non-stepwise updates.\nPreliminary experiments on a Transformer toy model show DEO achieves\ncompetitive performance compared to standard first-order methods, improving\nnavigation of complex loss landscapes. Our work repurposes physics-inspired,\nfirst-order curvature estimation to enhance neural network training in\nhigh-dimensional spaces.", "published": "2025-07-26 14:57:32", "link": "http://arxiv.org/abs/2507.19968v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TS-Insight: Visualizing Thompson Sampling for Verification and XAI", "abstract": "Thompson Sampling (TS) and its variants are powerful Multi-Armed Bandit\nalgorithms used to balance exploration and exploitation strategies in active\nlearning. Yet, their probabilistic nature often turns them into a ``black\nbox'', hindering debugging and trust. We introduce TS-Insight, a visual\nanalytics tool explicitly designed to shed light on the internal decision\nmechanisms of Thompson Sampling-based algorithms, for model developers. It\ncomprises multiple plots, tracing for each arm the evolving posteriors,\nevidence counts, and sampling outcomes, enabling the verification, diagnosis,\nand explainability of exploration/exploitation dynamics. This tool aims at\nfostering trust and facilitating effective debugging and deployment in complex\nbinary decision-making scenarios especially in sensitive domains requiring\ninterpretable decision-making.", "published": "2025-07-26 09:58:26", "link": "http://arxiv.org/abs/2507.19898v1", "categories": ["cs.HC", "cs.AI", "cs.LG", "stat.ML", "I.2.6; H.5.2"], "primary_category": "cs.HC"}
{"title": "RestoreAI - Pattern-based Risk Estimation Of Remaining Explosives", "abstract": "Landmine removal is a slow, resource-intensive process affecting over 60\ncountries. While AI has been proposed to enhance explosive ordnance (EO)\ndetection, existing methods primarily focus on object recognition, with limited\nattention to prediction of landmine risk based on spatial pattern information.\nThis work aims to answer the following research question: How can AI be used to\npredict landmine risk from landmine patterns to improve clearance time\nefficiency? To that effect, we introduce RestoreAI, an AI system for\npattern-based risk estimation of remaining explosives. RestoreAI is the first\nAI system that leverages landmine patterns for risk prediction, improving the\naccuracy of estimating the residual risk of missing EO prior to land release.\nWe particularly focus on the implementation of three instances of RestoreAI,\nrespectively, linear, curved and Bayesian pattern deminers. First, the linear\npattern deminer uses linear landmine patterns from a principal component\nanalysis (PCA) for the landmine risk prediction. Second, the curved pattern\ndeminer uses curved landmine patterns from principal curves. Finally, the\nBayesian pattern deminer incorporates prior expert knowledge by using a\nBayesian pattern risk prediction. Evaluated on real-world landmine data,\nRestoreAI significantly boosts clearance efficiency. The top-performing\npattern-based deminers achieved a 14.37 percentage point increase in the\naverage share of cleared landmines per timestep and required 24.45% less time\nthan the best baseline deminer to locate all landmines. Interestingly, linear\nand curved pattern deminers showed no significant performance difference,\nsuggesting that more efficient linear patterns are a viable option for risk\nprediction.", "published": "2025-07-26 09:03:13", "link": "http://arxiv.org/abs/2507.19873v1", "categories": ["cs.LG", "cs.CY", "stat.AP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sparse-mode Dynamic Mode Decomposition for Disambiguating Local and Global Structures", "abstract": "The dynamic mode decomposition (DMD) is a data-driven approach that extracts\nthe dominant features from spatiotemporal data. In this work, we introduce\nsparse-mode DMD, a new variant of the optimized DMD framework that specifically\nleverages sparsity-promoting regularization in order to approximate DMD modes\nwhich have localized spatial structure. The algorithm maintains the\nnoise-robust properties of optimized DMD while disambiguating between modes\nwhich are spatially local versus global in nature. In many applications, such\nmodes are associated with discrete and continuous spectra respectively, thus\nallowing the algorithm to explicitly construct, in an unsupervised manner, the\ndistinct portions of the spectrum. We demonstrate this by analyzing synthetic\nand real-world systems, including examples from optical waveguides, quantum\nmechanics, and sea surface temperature data.", "published": "2025-07-26 04:24:40", "link": "http://arxiv.org/abs/2507.19787v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Bag of Coins: A Statistical Probe into Neural Confidence Structures", "abstract": "Modern neural networks, despite their high accuracy, often produce poorly\ncalibrated confidence scores, limiting their reliability in high-stakes\napplications. Existing calibration methods typically post-process model outputs\nwithout interrogating the internal consistency of the predictions themselves.\nIn this work, we introduce a novel, non-parametric statistical probe, the\nBag-of-Coins (BoC) test, that examines the internal consistency of a\nclassifier's logits. The BoC test reframes confidence estimation as a\nfrequentist hypothesis test: does the model's top-ranked class win 1-v-1\ncontests against random competitors at a rate consistent with its own stated\nsoftmax probability? When applied to modern deep learning architectures, this\nsimple probe reveals a fundamental dichotomy. On Vision Transformers (ViTs),\nthe BoC output serves as a state-of-the-art confidence score, achieving\nnear-perfect calibration with an ECE of 0.0212, an 88% improvement over a\ntemperature-scaled baseline. Conversely, on Convolutional Neural Networks\n(CNNs) like ResNet, the probe reveals a deep inconsistency between the model's\npredictions and its internal logit structure, a property missed by traditional\nmetrics. We posit that BoC is not merely a calibration method, but a new\ndiagnostic tool for understanding and exposing the differing ways that popular\narchitectures represent uncertainty.", "published": "2025-07-26 03:54:32", "link": "http://arxiv.org/abs/2507.19774v1", "categories": ["stat.ML", "cs.LG", "62M45, 62H30, 62P30"], "primary_category": "stat.ML"}
{"title": "Binaural Localization Model for Speech in Noise", "abstract": "Binaural acoustic source localization is important to human listeners for\nspatial awareness, communication and safety. In this paper, an end-to-end\nbinaural localization model for speech in noise is presented. A lightweight\nconvolutional recurrent network that localizes sound in the frontal azimuthal\nplane for noisy reverberant binaural signals is introduced. The model\nincorporates additive internal ear noise to represent the frequency-dependent\nhearing threshold of a typical listener. The localization performance of the\nmodel is compared with the steered response power algorithm, and the use of the\nmodel as a measure of interaural cue preservation for binaural speech\nenhancement methods is studied. A listening test was performed to compare the\nperformance of the model with human localization of speech in noisy conditions.", "published": "2025-07-26 18:01:45", "link": "http://arxiv.org/abs/2507.20027v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Binaural Speech Enhancement Using Complex Convolutional Recurrent Networks", "abstract": "From hearing aids to augmented and virtual reality devices, binaural speech\nenhancement algorithms have been established as state-of-the-art techniques to\nimprove speech intelligibility and listening comfort. In this paper, we present\nan end-to-end binaural speech enhancement method using a complex recurrent\nconvolutional network with an encoder-decoder architecture and a complex LSTM\nrecurrent block placed between the encoder and decoder. A loss function that\nfocuses on the preservation of spatial information in addition to speech\nintelligibility improvement and noise reduction is introduced. The network\nestimates individual complex ratio masks for the left and right-ear channels of\na binaural hearing device in the time-frequency domain. We show that, compared\nto other baseline algorithms, the proposed method significantly improves the\nestimated speech intelligibility and reduces the noise while preserving the\nspatial information of the binaural signals in acoustic situations with a\nsingle target speaker and isotropic noise of various types.", "published": "2025-07-26 17:42:53", "link": "http://arxiv.org/abs/2507.20023v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "DOA Estimation via Optimal Weighted Low-Rank Matrix Completion", "abstract": "This paper presents a novel method for estimating the direction of arrival\n(DOA) for a non-uniform and sparse linear sensor array using the weighted\nlifted structure low-rank matrix completion. The proposed method uses a single\nsnapshot sample in which a single array of data is observed. The method is\nrooted in a weighted lifted-structured low-rank matrix recovery framework. The\nmethod involves four key steps: (i) lifting the antenna samples to form a\nlow-rank stature, then (ii) designing left and right weight matrices to reflect\nthe sample informativeness, (iii) estimating a noise-free uniform array output\nthrough completion of the weighted lifted samples, and (iv) obtaining the DOAs\nfrom the restored uniform linear array samples.\n  We study the complexity of steps (i) to (iii) above, where we analyze the\nrequired sample for the array interpolation of step (iii) for DOA estimation.\nWe demonstrate that the proposed choice of weight matrices achieves a\nnear-optimal sample complexity. This complexity aligns with the problem's\ndegree of freedom, equivalent to the number of DOAs adjusted for logarithmic\nfactors. Numerical evaluations show the proposed method's superiority against\nthe non-weighted counterpart and atomic norm minimization-based methods.\nNotably, our proposed method significantly improves, with approximately a 10 dB\nreduction in normalized mean-squared error over the non-weighted method at\nlow-noise conditions.", "published": "2025-07-26 16:33:40", "link": "http://arxiv.org/abs/2507.19996v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Dependability Theory-based Statistical QoS Provisioning of Fluid Antenna Systems", "abstract": "Fluid antenna systems (FAS) have recently emerged as a promising technology\nfor next-generation wireless networks, offering real-time spatial\nreconfiguration to enhance reliability, throughput, and energy efficiency.\nNevertheless, existing studies often overlook the temporal dynamics of channel\nfading and their implications for mission-critical operations. In this paper,\nwe propose a dependability-theoretic framework for statistical\nquality-of-service (QoS) provisioning of FAS under finite blocklength (FBL)\nconstraints. Specifically, we derive new closed-form expressions for the\nlevel-crossing rate (LCR) and average fade duration (AFD) of an $N$-port FAS\nover Nakagami-$m$ fading channels. Leveraging these second-order statistics, we\ndefine two key dependability metrics such as mission reliability and mean\ntime-to-first-failure (MTTFF), to quantify the probability of uninterrupted\noperation over a defined mission duration. We further extend the classical\neffective capacity (EC) concept to incorporate mission reliability in the FBL\nregime, yielding a mission EC (mEC). To capture energy efficiency under bursty\ntraffic and latency constraints, we also develop the mission effective energy\nefficiency (mEEE) metric and formulate its maximization as a non-convex\nfractional optimization problem. This problem is then solved via a modified\nDinkelbach's method with an embedded line search. Extensive simulations uncover\ncritical trade-offs among port count, QoS exponent, signal-to-noise ratio, and\nmission duration, offering insights for the design of ultra-reliable,\nlow-latency, and energy-efficient industrial internet-of-things (IIoT) systems.", "published": "2025-07-26 15:43:31", "link": "http://arxiv.org/abs/2507.19984v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Deep Learning Based Joint Channel Estimation and Positioning for Sparse XL-MIMO OFDM Systems", "abstract": "This paper investigates joint channel estimation and positioning in\nnear-field sparse extra-large multiple-input multiple-output (XL-MIMO)\northogonal frequency division multiplexing (OFDM) systems. To achieve\ncooperative gains between channel estimation and positioning, we propose a deep\nlearning-based two-stage framework comprising positioning and channel\nestimation. In the positioning stage, the user's coordinates are predicted and\nutilized in the channel estimation stage, thereby enhancing the accuracy of\nchannel estimation. Within this framework, we propose a U-shaped Mamba\narchitecture for channel estimation and positioning, termed as CP-Mamba. This\nnetwork integrates the strengths of the Mamba model with the structural\nadvantages of U-shaped convolutional networks, enabling effective capture of\nlocal spatial features and long-range temporal dependencies of the channel.\nNumerical simulation results demonstrate that the proposed two-stage approach\nwith CP-Mamba architecture outperforms existing baseline methods. Moreover,\nsparse arrays (SA) exhibit significantly superior performance in both channel\nestimation and positioning accuracy compared to conventional compact arrays.", "published": "2025-07-26 12:47:39", "link": "http://arxiv.org/abs/2507.19936v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Toward Dual-Functional LAWN: Control-Aware System Design for Aerodynamics-Aided UAV Formations", "abstract": "Integrated sensing and communication (ISAC) has emerged as a pivotal\ntechnology for advancing low-altitude wireless networks (LAWNs), serving as a\ncritical enabler for next-generation communication systems. This paper\ninvestigates the system design for energy-saving unmanned aerial vehicle (UAV)\nformations in dual-functional LAWNs, where a ground base station (GBS)\nsimultaneously wirelessly controls multiple UAV formations and performs sensing\ntasks. To enhance flight endurance, we exploit the aerodynamic upwash effects\nand propose a distributed energy-saving formation framework based on the\nadapt-then-combine (ATC) diffusion least mean square (LMS) algorithm.\nSpecifically, each UAV updates the local position estimate by invoking the LMS\nalgorithm, followed by refining it through cooperative information exchange\nwith neighbors. This enables an optimized aerodynamic structure that minimizes\nthe formation's overall energy consumption. To ensure control stability and\nfairness, we formulate a maximum linear quadratic regulator (LQR) minimization\nproblem, which is subject to both the available power budget and the required\nsensing beam pattern gain. To address this non-convex problem, we develop a\ntwo-step approach by first deriving a closed-form expression of LQR as a\nfunction of arbitrary beamformers. Subsequently, an efficient iterative\nalgorithm that integrates successive convex approximation (SCA) and\nsemidefinite relaxation (SDR) techniques is proposed to obtain a sub-optimal\ndual-functional beamforming solution. Extensive simulation results confirm that\nthe 'V'-shaped formation is the most energy-efficient configuration and\ndemonstrate the superiority of our proposed design over benchmark schemes in\nimproving control performance.", "published": "2025-07-26 10:43:54", "link": "http://arxiv.org/abs/2507.19910v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Feature Engineering for Wireless Communications and Networking: Concepts, Methodologies, and Applications", "abstract": "AI-enabled wireless communications have attracted tremendous research\ninterest in recent years, particularly with the rise of novel paradigms such as\nlow-altitude integrated sensing and communication (ISAC) networks. Within these\nsystems, feature engineering plays a pivotal role by transforming raw wireless\ndata into structured representations suitable for AI models. Hence, this paper\noffers a comprehensive investigation of feature engineering techniques in\nAI-driven wireless communications. Specifically, we begin with a detailed\nanalysis of fundamental principles and methodologies of feature engineering.\nNext, we present its applications in wireless communication systems, with\nspecial emphasis on ISAC networks. Finally, we introduce a generative AI-based\nframework, which can reconstruct signal feature spectrum under malicious\nattacks in low-altitude ISAC networks. The case study shows that it can\neffectively reconstruct the signal spectrum, achieving an average structural\nsimilarity index improvement of 4%, thereby supporting downstream sensing and\ncommunication applications.", "published": "2025-07-26 07:21:27", "link": "http://arxiv.org/abs/2507.19837v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Debunking Optimization Myths in Federated Learning for Medical Image Classification", "abstract": "Federated Learning (FL) is a collaborative learning method that enables\ndecentralized model training while preserving data privacy. Despite its promise\nin medical imaging, recent FL methods are often sensitive to local factors such\nas optimizers and learning rates, limiting their robustness in practical\ndeployments. In this work, we revisit vanilla FL to clarify the impact of edge\ndevice configurations, benchmarking recent FL methods on colorectal pathology\nand blood cell classification task. We numerically show that the choice of\nlocal optimizer and learning rate has a greater effect on performance than the\nspecific FL method. Moreover, we find that increasing local training epochs can\neither enhance or impair convergence, depending on the FL method. These\nfindings indicate that appropriate edge-specific configuration is more crucial\nthan algorithmic complexity for achieving effective FL.", "published": "2025-07-26 06:41:17", "link": "http://arxiv.org/abs/2507.19822v1", "categories": ["cs.LG", "eess.IV", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Channel Estimation in Massive MIMO Systems with Orthogonal Delay-Doppler Division Multiplexing", "abstract": "Orthogonal delay-Doppler division multiplexing~(ODDM) modulation has recently\nbeen regarded as a promising technology to provide reliable communications in\nhigh-mobility situations. Accurate and low-complexity channel estimation is one\nof the most critical challenges for massive multiple input multiple\noutput~(MIMO) ODDM systems, mainly due to the extremely large antenna arrays\nand high-mobility environments. To overcome these challenges, this paper\naddresses the issue of channel estimation in downlink massive MIMO-ODDM systems\nand proposes a low-complexity algorithm based on memory approximate message\npassing~(MAMP) to estimate the channel state information~(CSI). Specifically,\nwe first establish the effective channel model of the massive MIMO-ODDM\nsystems, where the magnitudes of the elements in the equivalent channel vector\nfollow a Bernoulli-Gaussian distribution. Further, as the number of antennas\ngrows, the elements in the equivalent coefficient matrix tend to become\ncompletely random. Leveraging these characteristics, we utilize the MAMP method\nto determine the gains, delays, and Doppler effects of the multi-path channel,\nwhile the channel angles are estimated through the discrete Fourier transform\nmethod. Finally, numerical results show that the proposed channel estimation\nalgorithm approaches the Bayesian optimal results when the number of antennas\ntends to infinity and improves the channel estimation accuracy by about 30%\ncompared with the existing algorithms in terms of the normalized mean square\nerror.", "published": "2025-07-26 06:05:10", "link": "http://arxiv.org/abs/2507.19812v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Radar and Acoustic Sensor Fusion using a Transformer Encoder for Robust Drone Detection and Classification", "abstract": "The use of drones in a wide range of applications is steadily increasing.\nHowever, this has also raised critical security concerns such as unauthorized\ndrone intrusions into restricted zones. Therefore, robust and accurate drone\ndetection and classification mechanisms are required despite significant\nchallenges due to small size of drones, low-altitude flight, and environmental\nnoise. In this letter, we propose a multi-modal approach combining radar and\nacoustic sensing for detecting and classifying drones. We employ radar due to\nits long-range capabilities, and robustness to different weather conditions. We\nutilize raw acoustic signals without converting them to other domains such as\nspectrograms or Mel-frequency cepstral coefficients. This enables us to use\nfewer number of parameters compared to the stateof-the-art approaches.\nFurthermore, we explore the effectiveness of the transformer encoder\narchitecture in fusing these sensors. Experimental results obtained in outdoor\nsettings verify the superior performance of the proposed approach compared to\nthe state-of-the-art methods.", "published": "2025-07-26 04:21:08", "link": "http://arxiv.org/abs/2507.19785v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Coverage Probability and Average Rate Analysis of Hybrid Cellular and Cell-free Network", "abstract": "Cell-free wireless networks deploy distributed access points (APs) to\nsimultaneously serve user equipments (UEs) across the service region and are\nregarded as one of the most promising network architectural paradigms. Despite\nrecent advances in the performance analysis and optimization of cellfree\nwireless networks, it remains an open question whether large-scale deployment\nof APs in existing wireless networks can cost-effectively achieve communication\ncapacity growth. Besides, the realization of a cell-free network is considered\nto be a gradual long-term evolutionary process in which cell-free APs will be\nincrementally introduced into existing cellular networks, and form a hybrid\ncommunication network with the existing cellular base stations (BSs). Such a\ncollaboration will bridge the gap between the established cellular network and\nthe innovative cellfree network. Therefore, hybrid cellular and cell-free\nnetworks (HCCNs) emerge as a practical and feasible solution for advancing\ncell-free network development, and it is worthwhile to further explore its\nperformance limits. This paper presents a stochastic geometry-based hybrid\ncellular and cell-free network model to analyze the distributions of signal and\ninterference and reveal their mutual coupling. Specifically, in order to\nbenefit the UEs from both the cellular BSs and the cell-free APs, a conjugate\nbeamforming design is employed, and the aggregated signal is analyzed using\nmoment matching. Then, the coverage probability of the hybrid network is\ncharacterized by deriving the Laplace transforms and their higher-order\nderivatives of interference components. Furthermore, the average achievable\nrate of the hybrid network over channel fading is derived based on the\ninterference coupling analysis.", "published": "2025-07-26 03:34:30", "link": "http://arxiv.org/abs/2507.19763v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "LowKeyEMG: Electromyographic typing with a reduced keyset", "abstract": "We introduce LowKeyEMG, a real-time human-computer interface that enables\nefficient text entry using only 7 gesture classes decoded from surface\nelectromyography (sEMG). Prior work has attempted full-alphabet decoding from\nsEMG, but decoding large character sets remains unreliable, especially for\nindividuals with motor impairments. Instead, LowKeyEMG reduces the English\nalphabet to 4 gesture keys, with 3 more for space and system interaction, to\nreliably translate simple one-handed gestures into text, leveraging the\nrecurrent transformer-based language model RWKV for efficient computation. In\nreal-time experiments, participants achieved average one-handed keyboardless\ntyping speeds of 23.3 words per minute with LowKeyEMG, and improved gesture\nefficiency by 17% (relative to typed phrase length). When typing with only 7\nkeys, LowKeyEMG can achieve 98.2% top-3 word accuracy, demonstrating that this\nlow-key typing paradigm can maintain practical communication rates. Our results\nhave implications for assistive technologies and any interface where input\nbandwidth is constrained.", "published": "2025-07-26 01:41:58", "link": "http://arxiv.org/abs/2507.19736v1", "categories": ["cs.HC", "eess.SP"], "primary_category": "cs.HC"}
{"title": "The Devil is in the EOS: Sequence Training for Detailed Image Captioning", "abstract": "Despite significant advances in vision-language models (VLMs), image\ncaptioning often suffers from a lack of detail, with base models producing\nshort, generic captions. This limitation persists even though VLMs are equipped\nwith strong vision and language backbones. While supervised data and complex\nreward functions have been proposed to improve detailed image captioning, we\nidentify a simpler underlying issue: a bias towards the end-of-sequence (EOS)\ntoken, which is introduced during cross-entropy training. We propose an\nunsupervised method to debias the model's tendency to predict the EOS token\nprematurely. By reducing this bias, we encourage the generation of longer, more\ndetailed captions without the need for intricate reward functions or\nsupervision. Our approach is straightforward, effective, and easily applicable\nto any pretrained model. We demonstrate its effectiveness through experiments\nwith three VLMs and on three detailed captioning benchmarks. Our results show a\nsubstantial increase in caption length and relevant details, albeit with an\nexpected increase in the rate of hallucinations.", "published": "2025-07-26 23:00:43", "link": "http://arxiv.org/abs/2507.20077v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training", "abstract": "Inference-time alignment enables large language models (LLMs) to generate\noutputs aligned with end-user preferences without further training. Recent\npost-training methods achieve this by using small guidance models to modify\ntoken generation during inference. These methods typically optimize a reward\nfunction KL-regularized by the original LLM taken as the reference policy. A\ncritical limitation, however, is their dependence on a pre-trained reward\nmodel, which requires fitting to human preference feedback--a potentially\nunstable process. In contrast, we introduce PITA, a novel framework that\nintegrates preference feedback directly into the LLM's token generation,\neliminating the need for a reward model. PITA learns a small preference-based\nguidance policy to modify token probabilities at inference time without LLM\nfine-tuning, reducing computational cost and bypassing the pre-trained reward\nmodel dependency. The problem is framed as identifying an underlying preference\ndistribution, solved through stochastic search and iterative refinement of the\npreference-based guidance model. We evaluate PITA across diverse tasks,\nincluding mathematical reasoning and sentiment classification, demonstrating\nits effectiveness in aligning LLM outputs with user preferences.", "published": "2025-07-26 21:46:32", "link": "http://arxiv.org/abs/2507.20067v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "RAG in the Wild: On the (In)effectiveness of LLMs with Mixture-of-Knowledge Retrieval Augmentation", "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge retrieved at inference time. While RAG\ndemonstrates strong performance on benchmarks largely derived from\ngeneral-domain corpora like Wikipedia, its effectiveness under realistic,\ndiverse retrieval scenarios remains underexplored. We evaluated RAG systems\nusing MassiveDS, a large-scale datastore with mixture of knowledge, and\nidentified critical limitations: retrieval mainly benefits smaller models,\nrerankers add minimal value, and no single retrieval source consistently\nexcels. Moreover, current LLMs struggle to route queries across heterogeneous\nknowledge sources. These findings highlight the need for adaptive retrieval\nstrategies before deploying RAG in real-world settings. Our code and data can\nbe found at https://github.com/ritaranx/RAG_in_the_Wild.", "published": "2025-07-26 20:57:24", "link": "http://arxiv.org/abs/2507.20059v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Tensor-Based Compiler and a Runtime for Neuron-Level DNN Certifier Specifications", "abstract": "The uninterpretability of DNNs has led to the adoption of abstract\ninterpretation-based certification as a practical means to establish trust in\nreal-world systems that rely on DNNs. However, the current landscape supports\nonly a limited set of certifiers, and developing new ones or modifying existing\nones for different applications remains difficult. This is because the\nmathematical design of certifiers is expressed at the neuron level, while their\nimplementations are optimized and executed at the tensor level. This mismatch\ncreates a semantic gap between design and implementation, making manual\nbridging both complex and expertise-intensive -- requiring deep knowledge in\nformal methods, high-performance computing, etc.\n  We propose a compiler framework that automatically translates neuron-level\nspecifications of DNN certifiers into tensor-based, layer-level\nimplementations. This is enabled by two key innovations: a novel stack-based\nintermediate representation (IR) and a shape analysis that infers the implicit\ntensor operations needed to simulate the neuron-level semantics. During\nlifting, the shape analysis creates tensors in the minimal shape required to\nperform the corresponding operations. The IR also enables domain-specific\noptimizations as rewrites. At runtime, the resulting tensor computations\nexhibit sparsity tied to the DNN architecture. This sparsity does not align\nwell with existing formats. To address this, we introduce g-BCSR, a\ndouble-compression format that represents tensors as collections of blocks of\nvarying sizes, each possibly internally sparse.\n  Using our compiler and g-BCSR, we make it easy to develop new certifiers and\nanalyze their utility across diverse DNNs. Despite its flexibility, the\ncompiler achieves performance comparable to hand-optimized implementations.", "published": "2025-07-26 20:38:29", "link": "http://arxiv.org/abs/2507.20055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "$K^4$: Online Log Anomaly Detection Via Unsupervised Typicality Learning", "abstract": "Existing Log Anomaly Detection (LogAD) methods are often slow, dependent on\nerror-prone parsing, and use unrealistic evaluation protocols. We introduce\n$K^4$, an unsupervised and parser-independent framework for high-performance\nonline detection. $K^4$ transforms arbitrary log embeddings into compact\nfour-dimensional descriptors (Precision, Recall, Density, Coverage) using\nefficient k-nearest neighbor (k-NN) statistics. These descriptors enable\nlightweight detectors to accurately score anomalies without retraining. Using a\nmore realistic online evaluation protocol, $K^4$ sets a new state-of-the-art\n(AUROC: 0.995-0.999), outperforming baselines by large margins while being\norders of magnitude faster, with training under 4 seconds and inference as low\nas 4 $\\mu$s.", "published": "2025-07-26 20:24:51", "link": "http://arxiv.org/abs/2507.20051v1", "categories": ["cs.LG", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Infogen: Generating Complex Statistical Infographics from Documents", "abstract": "Statistical infographics are powerful tools that simplify complex data into\nvisually engaging and easy-to-understand formats. Despite advancements in AI,\nparticularly with LLMs, existing efforts have been limited to generating simple\ncharts, with no prior work addressing the creation of complex infographics from\ntext-heavy documents that demand a deep understanding of the content. We\naddress this gap by introducing the task of generating statistical infographics\ncomposed of multiple sub-charts (e.g., line, bar, pie) that are contextually\naccurate, insightful, and visually aligned. To achieve this, we define\ninfographic metadata that includes its title and textual insights, along with\nsub-chart-specific details such as their corresponding data and alignment. We\nalso present Infodat, the first benchmark dataset for text-to-infographic\nmetadata generation, where each sample links a document to its metadata. We\npropose Infogen, a two-stage framework where fine-tuned LLMs first generate\nmetadata, which is then converted into infographic code. Extensive evaluations\non Infodat demonstrate that Infogen achieves state-of-the-art performance,\noutperforming both closed and open-source LLMs in text-to-statistical\ninfographic generation.", "published": "2025-07-26 19:38:46", "link": "http://arxiv.org/abs/2507.20046v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FAEDKV: Infinite-Window Fourier Transform for Unbiased KV Cache Compression", "abstract": "The efficacy of Large Language Models (LLMs) in long-context tasks is often\nhampered by the substantial memory footprint and computational demands of the\nKey-Value (KV) cache. Current compression strategies, including token eviction\nand learned projections, frequently lead to biased representations -- either by\noveremphasizing recent/high-attention tokens or by repeatedly degrading\ninformation from earlier context -- and may require costly model retraining. We\npresent FAEDKV (Frequency-Adaptive Infinite-Window for KV cache), a novel,\ntraining-free KV cache compression framework that ensures unbiased information\nretention. FAEDKV operates by transforming the KV cache into the frequency\ndomain using a proposed Infinite-Window Fourier Transform (IWDFT). This\napproach allows for the equalized contribution of all tokens to the compressed\nrepresentation, effectively preserving both early and recent contextual\ninformation. A preliminary frequency ablation study identifies critical\nspectral components for layer-wise, targeted compression. Experiments on\nLongBench benchmark demonstrate FAEDKV's superiority over existing methods by\nup to 22\\%. In addition, our method shows superior, position-agnostic retrieval\naccuracy on the Needle-In-A-Haystack task compared to compression based\napproaches.", "published": "2025-07-26 18:20:25", "link": "http://arxiv.org/abs/2507.20030v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Anomaly Detection in Human Language via Meta-Learning: A Few-Shot Approach", "abstract": "We propose a meta learning framework for detecting anomalies in human\nlanguage across diverse domains with limited labeled data. Anomalies in\nlanguage ranging from spam and fake news to hate speech pose a major challenge\ndue to their sparsity and variability. We treat anomaly detection as a few shot\nbinary classification problem and leverage meta-learning to train models that\ngeneralize across tasks. Using datasets from domains such as SMS spam, COVID-19\nfake news, and hate speech, we evaluate model generalization on unseen tasks\nwith minimal labeled anomalies. Our method combines episodic training with\nprototypical networks and domain resampling to adapt quickly to new anomaly\ndetection tasks. Empirical results show that our method outperforms strong\nbaselines in F1 and AUC scores. We also release the code and benchmarks to\nfacilitate further research in few-shot text anomaly detection.", "published": "2025-07-26 17:23:03", "link": "http://arxiv.org/abs/2507.20019v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Carbon Cost of Conversation, Sustainability in the Age of Language Models", "abstract": "Large language models (LLMs) like GPT-3 and BERT have revolutionized natural\nlanguage processing (NLP), yet their environmental costs remain dangerously\noverlooked. This article critiques the sustainability of LLMs, quantifying\ntheir carbon footprint, water usage, and contribution to e-waste through case\nstudies of models such as GPT-4 and energy-efficient alternatives like Mistral\n7B. Training a single LLM can emit carbon dioxide equivalent to hundreds of\ncars driven annually, while data centre cooling exacerbates water scarcity in\nvulnerable regions. Systemic challenges corporate greenwashing, redundant model\ndevelopment, and regulatory voids perpetuate harm, disproportionately burdening\nmarginalized communities in the Global South. However, pathways exist for\nsustainable NLP: technical innovations (e.g., model pruning, quantum\ncomputing), policy reforms (carbon taxes, mandatory emissions reporting), and\ncultural shifts prioritizing necessity over novelty. By analysing industry\nleaders (Google, Microsoft) and laggards (Amazon), this work underscores the\nurgency of ethical accountability and global cooperation. Without immediate\naction, AIs ecological toll risks outpacing its societal benefits. The article\nconcludes with a call to align technological progress with planetary\nboundaries, advocating for equitable, transparent, and regenerative AI systems\nthat prioritize both human and environmental well-being.", "published": "2025-07-26 17:21:11", "link": "http://arxiv.org/abs/2507.20018v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "VLQA: The First Comprehensive, Large, and High-Quality Vietnamese Dataset for Legal Question Answering", "abstract": "The advent of large language models (LLMs) has led to significant\nachievements in various domains, including legal text processing. Leveraging\nLLMs for legal tasks is a natural evolution and an increasingly compelling\nchoice. However, their capabilities are often portrayed as greater than they\ntruly are. Despite the progress, we are still far from the ultimate goal of\nfully automating legal tasks using artificial intelligence (AI) and natural\nlanguage processing (NLP). Moreover, legal systems are deeply domain-specific\nand exhibit substantial variation across different countries and languages. The\nneed for building legal text processing applications for different natural\nlanguages is, therefore, large and urgent. However, there is a big challenge\nfor legal NLP in low-resource languages such as Vietnamese due to the scarcity\nof resources and annotated data. The need for labeled legal corpora for\nsupervised training, validation, and supervised fine-tuning is critical. In\nthis paper, we introduce the VLQA dataset, a comprehensive and high-quality\nresource tailored for the Vietnamese legal domain. We also conduct a\ncomprehensive statistical analysis of the dataset and evaluate its\neffectiveness through experiments with state-of-the-art models on legal\ninformation retrieval and question-answering tasks.", "published": "2025-07-26 16:26:50", "link": "http://arxiv.org/abs/2507.19995v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving the Performance of Sequential Recommendation Systems with an Extended Large Language Model", "abstract": "Recently, competition in the field of artificial intelligence (AI) has\nintensified among major technological companies, resulting in the continuous\nrelease of new large-language models (LLMs) that exhibit improved language\nunderstanding and context-based reasoning capabilities. It is expected that\nthese advances will enable more efficient personalized recommendations in\nLLM-based recommendation systems through improved quality of training data and\narchitectural design. However, many studies have not considered these recent\ndevelopments. In this study, it was proposed to improve LLM-based\nrecommendation systems by replacing Llama2 with Llama3 in the LlamaRec\nframework. To ensure a fair comparison, random seed values were set and\nidentical input data was provided during preprocessing and training. The\nexperimental results show average performance improvements of 38.65\\%, 8.69\\%,\nand 8.19\\% for the ML-100K, Beauty, and Games datasets, respectively, thus\nconfirming the practicality of this method. Notably, the significant\nimprovements achieved by model replacement indicate that the recommendation\nquality can be improved cost-effectively without the need to make structural\nchanges to the system. Based on these results, it is our contention that the\nproposed approach is a viable solution for improving the performance of current\nrecommendation systems.", "published": "2025-07-26 15:59:25", "link": "http://arxiv.org/abs/2507.19990v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "H.3.3; I.2.6; I.2.7"], "primary_category": "cs.IR"}
{"title": "Exploring LLM Autoscoring Reliability in Large-Scale Writing Assessments Using Generalizability Theory", "abstract": "This study investigates the estimation of reliability for large language\nmodels (LLMs) in scoring writing tasks from the AP Chinese Language and Culture\nExam. Using generalizability theory, the research evaluates and compares score\nconsistency between human and AI raters across two types of AP Chinese\nfree-response writing tasks: story narration and email response. These essays\nwere independently scored by two trained human raters and seven AI raters. Each\nessay received four scores: one holistic score and three analytic scores\ncorresponding to the domains of task completion, delivery, and language use.\nResults indicate that although human raters produced more reliable scores\noverall, LLMs demonstrated reasonable consistency under certain conditions,\nparticularly for story narration tasks. Composite scoring that incorporates\nboth human and AI raters improved reliability, which supports that hybrid\nscoring models may offer benefits for large-scale writing assessments.", "published": "2025-07-26 15:33:05", "link": "http://arxiv.org/abs/2507.19980v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization", "abstract": "Background: Manual extraction of pancreatic cystic lesion (PCL) features from\nradiology reports is labor-intensive, limiting large-scale studies needed to\nadvance PCL research. Purpose: To develop and evaluate large language models\n(LLMs) that automatically extract PCL features from MRI/CT reports and assign\nrisk categories based on guidelines. Materials and Methods: We curated a\ntraining dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134\npatients that described PCLs. Labels were generated by GPT-4o using\nchain-of-thought (CoT) prompting to extract PCL and main pancreatic duct\nfeatures. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated\nCoT data. Features were mapped to risk categories per institutional guideline\nbased on the 2017 ACR White Paper. Evaluation was performed on 285 held-out\nhuman-annotated reports. Model outputs for 100 cases were independently\nreviewed by three radiologists. Feature extraction was evaluated using exact\nmatch accuracy, risk categorization with macro-averaged F1 score, and\nradiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning\nimproved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79%\nto 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved\n(LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no\nstatistically significant differences. Radiologist inter-reader agreement was\nhigh (Fleiss' Kappa = 0.888) and showed no statistically significant difference\nwith the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT\n(Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels\non par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT\nsupervision enable accurate, interpretable, and efficient phenotyping for\nlarge-scale PCL research, achieving performance comparable to GPT-4o.", "published": "2025-07-26 15:02:32", "link": "http://arxiv.org/abs/2507.19973v1", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text", "abstract": "Automated data visualization plays a crucial role in simplifying data\ninterpretation, enhancing decision-making, and improving efficiency. While\nlarge language models (LLMs) have shown promise in generating visualizations\nfrom natural language, the absence of comprehensive benchmarks limits the\nrigorous evaluation of their capabilities. We introduce Text2Vis, a benchmark\ndesigned to assess text-to-visualization models, covering 20+ chart types and\ndiverse data science queries, including trend analysis, correlation, outlier\ndetection, and predictive analytics. It comprises 1,985 samples, each with a\ndata table, natural language query, short answer, visualization code, and\nannotated charts. The queries involve complex reasoning, conversational turns,\nand dynamic data retrieval. We benchmark 11 open-source and closed-source\nmodels, revealing significant performance gaps, highlighting key challenges,\nand offering insights for future advancements. To close this gap, we propose\nthe first cross-modal actor-critic agentic framework that jointly refines the\ntextual answer and visualization code, increasing GPT-4o`s pass rate from 26%\nto 42% over the direct approach and improving chart quality. We also introduce\nan automated LLM-based evaluation framework that enables scalable assessment\nacross thousands of samples without human annotation, measuring answer\ncorrectness, code execution success, visualization readability, and chart\naccuracy. We release Text2Vis at https://github.com/vis-nlp/Text2Vis.", "published": "2025-07-26 14:59:04", "link": "http://arxiv.org/abs/2507.19969v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "KLAAD: Refining Attention Mechanisms to Reduce Societal Bias in Generative Language Models", "abstract": "Large language models (LLMs) often exhibit societal biases in their outputs,\nprompting ethical concerns regarding fairness and harm. In this work, we\npropose KLAAD (KL-Attention Alignment Debiasing), an attention-based debiasing\nframework that implicitly aligns attention distributions between stereotypical\nand anti-stereotypical sentence pairs without directly modifying model weights.\nKLAAD introduces a composite training objective combining Cross-Entropy, KL\ndivergence, and Triplet losses, guiding the model to consistently attend across\nbiased and unbiased contexts while preserving fluency and coherence.\nExperimental evaluation of KLAAD demonstrates improved bias mitigation on both\nthe BBQ and BOLD benchmarks, with minimal impact on language modeling quality.\nThe results indicate that attention-level alignment offers a principled\nsolution for mitigating bias in generative language models.", "published": "2025-07-26 14:24:19", "link": "http://arxiv.org/abs/2507.19962v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Impact of Fine-tuning Large Language Models on Automated Program Repair", "abstract": "Automated Program Repair (APR) uses various tools and techniques to help\ndevelopers achieve functional and error-free code faster. In recent years,\nLarge Language Models (LLMs) have gained popularity as components in APR tool\nchains because of their performance and flexibility. However, training such\nmodels requires a significant amount of resources. Fine-tuning techniques have\nbeen developed to adapt pre-trained LLMs to specific tasks, such as APR, and\nenhance their performance at far lower computational costs than training from\nscratch. In this study, we empirically investigate the impact of various\nfine-tuning techniques on the performance of LLMs used for APR. Our experiments\nprovide insights into the performance of a selection of state-of-the-art LLMs\npre-trained on code. The evaluation is done on three popular APR benchmarks\n(i.e., QuixBugs, Defects4J and HumanEval-Java) and considers six different LLMs\nwith varying parameter sizes (resp. CodeGen, CodeT5, StarCoder, DeepSeekCoder,\nBloom, and CodeLlama-2). We consider three training regimens: no fine-tuning,\nfull fine-tuning, and parameter-efficient fine-tuning (PEFT) using LoRA and\nIA3. We observe that full fine-tuning techniques decrease the benchmarking\nperformance of various models due to different data distributions and\noverfitting. By using parameter-efficient fine-tuning methods, we restrict\nmodels in the amount of trainable parameters and achieve better results.\n  Keywords: large language models, automated program repair,\nparameter-efficient fine-tuning, AI4Code, AI4SE, ML4SE.", "published": "2025-07-26 10:42:08", "link": "http://arxiv.org/abs/2507.19909v1", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "CaliDrop: KV Cache Compression with Calibration", "abstract": "Large Language Models (LLMs) require substantial computational resources\nduring generation. While the Key-Value (KV) cache significantly accelerates\nthis process by storing attention intermediates, its memory footprint grows\nlinearly with sequence length, batch size, and model size, creating a\nbottleneck in long-context scenarios. Various KV cache compression techniques,\nincluding token eviction, quantization, and low-rank projection, have been\nproposed to mitigate this bottleneck, often complementing each other. This\npaper focuses on enhancing token eviction strategies. Token eviction leverages\nthe observation that the attention patterns are often sparse, allowing for the\nremoval of less critical KV entries to save memory. However, this reduction\nusually comes at the cost of notable accuracy degradation, particularly under\nhigh compression ratios. To address this issue, we propose \\textbf{CaliDrop}, a\nnovel strategy that enhances token eviction through calibration. Our\npreliminary experiments show that queries at nearby positions exhibit high\nsimilarity. Building on this observation, CaliDrop performs speculative\ncalibration on the discarded tokens to mitigate the accuracy loss caused by\ntoken eviction. Extensive experiments demonstrate that CaliDrop significantly\nimproves the accuracy of existing token eviction methods.", "published": "2025-07-26 10:34:53", "link": "http://arxiv.org/abs/2507.19906v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Gold Standard Dataset and Evaluation Framework for Depression Detection and Explanation in Social Media using LLMs", "abstract": "Early detection of depression from online social media posts holds promise\nfor providing timely mental health interventions. In this work, we present a\nhigh-quality, expert-annotated dataset of 1,017 social media posts labeled with\ndepressive spans and mapped to 12 depression symptom categories. Unlike prior\ndatasets that primarily offer coarse post-level labels\n\\cite{cohan-etal-2018-smhd}, our dataset enables fine-grained evaluation of\nboth model predictions and generated explanations.\n  We develop an evaluation framework that leverages this clinically grounded\ndataset to assess the faithfulness and quality of natural language explanations\ngenerated by large language models (LLMs). Through carefully designed prompting\nstrategies, including zero-shot and few-shot approaches with domain-adapted\nexamples, we evaluate state-of-the-art proprietary LLMs including GPT-4.1,\nGemini 2.5 Pro, and Claude 3.7 Sonnet.\n  Our comprehensive empirical analysis reveals significant differences in how\nthese models perform on clinical explanation tasks, with zero-shot and few-shot\nprompting. Our findings underscore the value of human expertise in guiding LLM\nbehavior and offer a step toward safer, more transparent AI systems for\npsychological well-being.", "published": "2025-07-26 10:01:55", "link": "http://arxiv.org/abs/2507.19899v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-shot Performance of Generative AI in Brazilian Portuguese Medical Exam", "abstract": "Artificial intelligence (AI) has shown the potential to revolutionize\nhealthcare by improving diagnostic accuracy, optimizing workflows, and\npersonalizing treatment plans. Large Language Models (LLMs) and Multimodal\nLarge Language Models (MLLMs) have achieved notable advancements in natural\nlanguage processing and medical applications. However, the evaluation of these\nmodels has focused predominantly on the English language, leading to potential\nbiases in their performance across different languages.\n  This study investigates the capability of six LLMs (GPT-4.0 Turbo,\nLLaMA-3-8B, LLaMA-3-70B, Mixtral 8x7B Instruct, Titan Text G1-Express, and\nCommand R+) and four MLLMs (Claude-3.5-Sonnet, Claude-3-Opus, Claude-3-Sonnet,\nand Claude-3-Haiku) to answer questions written in Brazilian spoken portuguese\nfrom the medical residency entrance exam of the Hospital das Cl\\'inicas da\nFaculdade de Medicina da Universidade de S\\~ao Paulo (HCFMUSP) - the largest\nhealth complex in South America. The performance of the models was benchmarked\nagainst human candidates, analyzing accuracy, processing time, and coherence of\nthe generated explanations.\n  The results show that while some models, particularly Claude-3.5-Sonnet and\nClaude-3-Opus, achieved accuracy levels comparable to human candidates,\nperformance gaps persist, particularly in multimodal questions requiring image\ninterpretation. Furthermore, the study highlights language disparities,\nemphasizing the need for further fine-tuning and data set augmentation for\nnon-English medical AI applications.\n  Our findings reinforce the importance of evaluating generative AI in various\nlinguistic and clinical settings to ensure a fair and reliable deployment in\nhealthcare. Future research should explore improved training methodologies,\nimproved multimodal reasoning, and real-world clinical integration of AI-driven\nmedical assistance.", "published": "2025-07-26 09:34:52", "link": "http://arxiv.org/abs/2507.19885v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Polish Vocabulary Size Test: A Novel Adaptive Test for Receptive Vocabulary Assessment", "abstract": "We present the Polish Vocabulary Size Test (PVST), a novel tool for assessing\nthe receptive vocabulary size of both native and non-native Polish speakers.\nBased on Item Response Theory and Computerized Adaptive Testing, PVST\ndynamically adjusts to each test-taker's proficiency level, ensuring high\naccuracy while keeping the test duration short. To validate the test, a pilot\nstudy was conducted with 1.475 participants. Native Polish speakers\ndemonstrated significantly larger vocabularies compared to non-native speakers.\nFor native speakers, vocabulary size showed a strong positive correlation with\nage. The PVST is available online at myvocab.info/pl.", "published": "2025-07-26 08:56:46", "link": "http://arxiv.org/abs/2507.19869v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DRIVE: Disfluency-Rich Synthetic Dialog Data Generation Framework for Intelligent Vehicle Environments", "abstract": "In-car conversational AI is becoming increasingly critical as autonomous\nvehicles and smart assistants gain widespread adoption. Yet, existing datasets\nfail to capture the spontaneous disfluencies such as hesitations, false starts,\nrepetitions, and self-corrections that characterize real driver-AI dialogs. To\naddress this, we introduce DiscoDrive, a synthetic corpus of 3500 multi-turn\ndialogs across seven automotive domains, generated using a two-stage,\nprompt-driven pipeline that dynamically integrates disfluencies during\nsynthesis. We show that DiscoDrive is effective both as a training resource,\nenabling DialoGPT-Medium and T5-Base to match or exceed KVRET-trained models on\nthe MultiWOZ 2.2 and Schema-Guided Dialogue (SGD) relevant test sets (BLEU-4\nimprovements of 0.26 to 0.61; METEOR +2.10; ROUGE-L +3.48; BERTScore F1\nimprovements of 1.35 to 3.48), and as a data augmentation resource in\nlow-resource scenarios, delivering additional gains of up to BLEU-4 +0.38,\nMETEOR +1.95, ROUGE-L +2.87, and BERTScore F1 +4.00 when combined with 10\npercent of KVRET. Human evaluations further confirm that dialogs sampled from\nDiscoDrive are rated higher than KVRET's human-collected dialogs in naturalness\n(3.8 vs 3.6) and coherence (4.1 vs 4.0), and are perceived as more\ncontext-appropriate than leading post-hoc methods (such as LARD), without\ncompromising clarity. DiscoDrive fills a critical gap in existing resources and\nserves as a versatile corpus for both training and augmenting conversational\nAI, enabling robust handling of real-world, disfluent in-car interactions.", "published": "2025-07-26 08:48:40", "link": "http://arxiv.org/abs/2507.19867v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Agentic Reinforced Policy Optimization", "abstract": "Large-scale reinforcement learning with verifiable rewards (RLVR) has\ndemonstrated its effectiveness in harnessing the potential of large language\nmodels (LLMs) for single-turn reasoning tasks. In realistic reasoning\nscenarios, LLMs can often utilize external tools to assist in task-solving\nprocesses. However, current RL algorithms inadequately balance the models'\nintrinsic long-horizon reasoning capabilities and their proficiency in\nmulti-turn tool interactions. To bridge this gap, we propose Agentic Reinforced\nPolicy Optimization (ARPO), a novel agentic RL algorithm tailored for training\nmulti-turn LLM-based agents. Through preliminary experiments, we observe that\nLLMs tend to exhibit highly uncertain behavior, characterized by an increase in\nthe entropy distribution of generated tokens, immediately following\ninteractions with external tools. Motivated by this observation, ARPO\nincorporates an entropy-based adaptive rollout mechanism, dynamically balancing\nglobal trajectory sampling and step-level sampling, thereby promoting\nexploration at steps with high uncertainty after tool usage. By integrating an\nadvantage attribution estimation, ARPO enables LLMs to internalize advantage\ndifferences in stepwise tool-use interactions. Our experiments across 13\nchallenging benchmarks in computational reasoning, knowledge reasoning, and\ndeep search domains demonstrate ARPO's superiority over trajectory-level RL\nalgorithms. Remarkably, ARPO achieves improved performance using only half of\nthe tool-use budget required by existing methods, offering a scalable solution\nfor aligning LLM-based agents with real-time dynamic environments. Our code and\ndatasets are released at https://github.com/dongguanting/ARPO", "published": "2025-07-26 07:53:11", "link": "http://arxiv.org/abs/2507.19849v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AutoSign: Direct Pose-to-Text Translation for Continuous Sign Language Recognition", "abstract": "Continuously recognizing sign gestures and converting them to glosses plays a\nkey role in bridging the gap between the hearing and hearing-impaired\ncommunities. This involves recognizing and interpreting the hands, face, and\nbody gestures of the signer, which pose a challenge as it involves a\ncombination of all these features. Continuous Sign Language Recognition (CSLR)\nmethods rely on multi-stage pipelines that first extract visual features, then\nalign variable-length sequences with target glosses using CTC or HMM-based\napproaches. However, these alignment-based methods suffer from error\npropagation across stages, overfitting, and struggle with vocabulary\nscalability due to the intermediate gloss representation bottleneck. To address\nthese limitations, we propose AutoSign, an autoregressive decoder-only\ntransformer that directly translates pose sequences to natural language text,\nbypassing traditional alignment mechanisms entirely. The use of this\ndecoder-only approach allows the model to directly map between the features and\nthe glosses without the need for CTC loss while also directly learning the\ntextual dependencies in the glosses. Our approach incorporates a temporal\ncompression module using 1D CNNs to efficiently process pose sequences,\nfollowed by AraGPT2, a pre-trained Arabic decoder, to generate text (glosses).\nThrough comprehensive ablation studies, we demonstrate that hand and body\ngestures provide the most discriminative features for signer-independent CSLR.\nBy eliminating the multi-stage pipeline, AutoSign achieves substantial\nimprovements on the Isharah-1000 dataset, achieving an improvement of up to\n6.1\\% in WER score compared to the best existing method.", "published": "2025-07-26 07:28:33", "link": "http://arxiv.org/abs/2507.19840v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "HCAttention: Extreme KV Cache Compression via Heterogeneous Attention Computing for LLMs", "abstract": "Processing long-context inputs with large language models presents a\nsignificant challenge due to the enormous memory requirements of the Key-Value\n(KV) cache during inference. Existing KV cache compression methods exhibit\nnoticeable performance degradation when memory is reduced by more than 85%.\nAdditionally, strategies that leverage GPU-CPU collaboration for approximate\nattention remain underexplored in this setting. We propose HCAttention, a\nheterogeneous attention computation framework that integrates key quantization,\nvalue offloading, and dynamic KV eviction to enable efficient inference under\nextreme memory constraints. The method is compatible with existing transformer\narchitectures and does not require model fine-tuning. Experimental results on\nthe LongBench benchmark demonstrate that our approach preserves the accuracy of\nfull-attention model while shrinking the KV cache memory footprint to 25% of\nits original size. Remarkably, it stays competitive with only 12.5% of the\ncache, setting a new state-of-the-art in LLM KV cache compression. To the best\nof our knowledge, HCAttention is the first to extend the Llama-3-8B model to\nprocess 4 million tokens on a single A100 GPU with 80GB memory.", "published": "2025-07-26 06:43:14", "link": "http://arxiv.org/abs/2507.19823v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Flora: Effortless Context Construction to Arbitrary Length and Scale", "abstract": "Effectively handling long contexts is challenging for Large Language Models\n(LLMs) due to the rarity of long texts, high computational demands, and\nsubstantial forgetting of short-context abilities. Recent approaches have\nattempted to construct long contexts for instruction tuning, but these methods\noften require LLMs or human interventions, which are both costly and limited in\nlength and diversity. Also, the drop in short-context performances of present\nlong-context LLMs remains significant. In this paper, we introduce Flora, an\neffortless (human/LLM-free) long-context construction strategy. Flora can\nmarkedly enhance the long-context performance of LLMs by arbitrarily assembling\nshort instructions based on categories and instructing LLMs to generate\nresponses based on long-context meta-instructions. This enables Flora to\nproduce contexts of arbitrary length and scale with rich diversity, while only\nslightly compromising short-context performance. Experiments on\nLlama3-8B-Instruct and QwQ-32B show that LLMs enhanced by Flora excel in three\nlong-context benchmarks while maintaining strong performances in short-context\ntasks. Our data-construction code is available at\n\\href{https://github.com/txchen-USTC/Flora}{https://github.com/txchen-USTC/Flora}.", "published": "2025-07-26 04:21:21", "link": "http://arxiv.org/abs/2507.19786v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models' Reasoning Abilities", "abstract": "Recent advances in large language models (LLMs) have highlighted the\npotential of reinforcement learning with verifiable rewards (RLVR) to enhance\nreasoning capabilities through extended output sequences. However, traditional\nRL frameworks face inefficiencies when handling ultra-long outputs due to\nlong-tail sequence distributions and entropy collapse during training. To\naddress these challenges, we propose an Ultra-Long Output Reinforcement\nLearning (UloRL) approach for advancing large language models' reasoning\nabilities. Specifically, we divide ultra long output decoding into short\nsegments, enabling efficient training by mitigating delays caused by long-tail\nsamples. Additionally, we introduce dynamic masking of well-Mastered Positive\nTokens (MPTs) to prevent entropy collapse. Experimental results demonstrate the\neffectiveness of our approach. On the Qwen3-30B-A3B model, RL with segment\nrollout achieved 2.06x increase in training speed, while RL training with\n128k-token outputs improves the model's performance on AIME2025 from 70.9\\% to\n85.1\\% and on BeyondAIME from 50.7\\% to 61.9\\%, even surpassing Qwen3-235B-A22B\nwith remarkable gains. These findings underscore the potential of our methods\nto advance the reasoning capabilities of LLMs with ultra-long sequence\ngeneration. We will release our code and model for further use by the\ncommunity.", "published": "2025-07-26 03:42:33", "link": "http://arxiv.org/abs/2507.19766v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are You There God? Lightweight Narrative Annotation of Christian Fiction with LMs", "abstract": "In addition to its more widely studied political activities, the American\nEvangelical movement has a well-developed but less externally visible cultural\nand literary side. Christian Fiction, however, has been little studied, and\nwhat scholarly attention there is has focused on the explosively popular Left\nBehind series. In this work, we use computational tools to provide both a broad\ntopical overview of Christian Fiction as a genre and a more directed\nexploration of how its authors depict divine acts. Working with human\nannotators we first developed definitions and a codebook for \"acts of God.\" We\nthen adapted those instructions designed for human annotators for use by a\nrecent, lightweight LM with the assistance of a much larger model. The\nlaptop-scale LM is capable of matching human annotations, even when the task is\nsubtle and challenging. Using these annotations, we show that significant and\nmeaningful differences exist between the Left Behind books and Christian\nFiction more broadly and between books by male and female authors.", "published": "2025-07-26 03:01:59", "link": "http://arxiv.org/abs/2507.19756v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JT-Math: A Multi-Stage Framework for Advanced Mathematical Reasoning in Large Language Models", "abstract": "Mathematical reasoning is a cornerstone of artificial general intelligence\nand a primary benchmark for evaluating the capabilities of Large Language\nModels (LLMs). While state-of-the-art models show promise, they often falter\nwhen faced with complex problems that demand deep conceptual understanding and\nintricate, multi-step deliberation. To address this challenge, we introduce\nJT-Math-8B, a series of open-source models comprising base, instruct, and\nthinking versions, built upon a systematic, multi-stage optimization framework.\nOur pre-training corpus is a high-quality, 210B-token dataset curated through a\ndedicated data pipeline that uses model-based validation to ensure quality and\ndiversity. The Instruct Model is optimized for direct, concise answers through\nSupervised Fine-Tuning (SFT) and a GRPO-based reinforcement learning (RL)\nmethod. The Thinking Model is trained for complex problem-solving using a Long\nChain-of-Thought (Long CoT) approach, combining SFT with a novel, multi-stage\nRL curriculum that progressively increases task difficulty and context length\nup to 32K tokens. JT-Math-8B achieves state-of-the-art results among\nopen-source models of similar size, surpassing prominent models like OpenAI's\nO1-mini and GPT-4o , and demonstrating superior performance on\ncompetition-level mathematics.", "published": "2025-07-26 02:45:10", "link": "http://arxiv.org/abs/2507.19748v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Basic Reading Distillation", "abstract": "Large language models (LLMs) have demonstrated remarkable abilities in\nvarious natural language processing areas, but they demand high computation\nresources which limits their deployment in real-world. Distillation is one\ntechnique to solve this problem through either knowledge distillation or task\ndistillation. Both distillation approaches train small models to imitate\nspecific features of LLMs, but they all neglect basic reading education for\nsmall models on generic texts that are \\emph{unrelated} to downstream tasks. In\nthis paper, we propose basic reading distillation (BRD) which educates a small\nmodel to imitate LLMs basic reading behaviors, such as named entity\nrecognition, question raising and answering, on each sentence. After such basic\neducation, we apply the small model on various tasks including language\ninference benchmarks and BIG-bench tasks. It shows that the small model can\noutperform or perform comparable to over 20x bigger LLMs. Analysis reveals that\nBRD effectively influences the probability distribution of the small model, and\nhas orthogonality to either knowledge distillation or task distillation.", "published": "2025-07-26 02:11:55", "link": "http://arxiv.org/abs/2507.19741v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Non-Parametric Choice Model That Learns How Users Choose Between Recommended Options", "abstract": "Choice models predict which items users choose from presented options. In\nrecommendation settings, they can infer user preferences while countering\nexposure bias. In contrast with traditional univariate recommendation models,\nchoice models consider which competitors appeared with the chosen item. This\nability allows them to distinguish whether a user chose an item due to\npreference, i.e., they liked it; or competition, i.e., it was the best\navailable option. Each choice model assumes specific user behavior, e.g., the\nmultinomial logit model. However, it is currently unclear how accurately these\nassumptions capture actual user behavior, how wrong assumptions impact\ninference, and whether better models exist.\n  In this work, we propose the learned choice model for recommendation\n(LCM4Rec), a non-parametric method for estimating the choice model. By applying\nkernel density estimation, LCM4Rec infers the most likely error distribution\nthat describes the effect of inter-item cannibalization and thereby\ncharacterizes the users' choice model. Thus, it simultaneously infers what\nusers prefer and how they make choices. Our experimental results indicate that\nour method (i) can accurately recover the choice model underlying a dataset;\n(ii) provides robust user preference inference, in contrast with existing\nchoice models that are only effective when their assumptions match user\nbehavior; and (iii) is more resistant against exposure bias than existing\nchoice models. Thereby, we show that learning choice models, instead of\nassuming them, can produce more robust predictions. We believe this work\nprovides an important step towards better understanding users' choice behavior.", "published": "2025-07-26 18:38:27", "link": "http://arxiv.org/abs/2507.20035v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Scalable and High Availability Solution for Recommending Resolutions to Problem Tickets", "abstract": "Resolution of incidents or problem tickets is a common theme in service\nindustries in any sector, including billing and charging systems in telecom\ndomain. Machine learning can help to identify patterns and suggest resolutions\nfor the problem tickets, based on patterns in the historical data of the\ntickets. However, this process may be complicated due to a variety of phenomena\nsuch as data drift and issues such as missing data, lack of data pertaining to\nresolutions of past incidents, too many similar sounding resolutions due to\nfree text and similar sounding text. This paper proposes a robust ML-driven\nsolution employing clustering, supervised learning, and advanced NLP models to\ntackle these challenges effectively. Building on previous work, we demonstrate\nclustering-based resolution identification, supervised classification with LDA,\nSiamese networks, and One-shot learning, Index embedding. Additionally, we\npresent a real-time dashboard and a highly available Kubernetes-based\nproduction deployment. Our experiments with both the open-source Bitext\ncustomer-support dataset and proprietary telecom datasets demonstrate high\nprediction accuracy.", "published": "2025-07-26 07:42:12", "link": "http://arxiv.org/abs/2507.19846v1", "categories": ["cs.LG", "cs.IR", "68T50", "I.2.7; I.2.6; H.3.3; H.4.1"], "primary_category": "cs.LG"}
{"title": "CleANN: Efficient Full Dynamism in Graph-based Approximate Nearest Neighbor Search", "abstract": "Approximate nearest neighbor search (ANNS) has become a quintessential\nalgorithmic problem for various other foundational data tasks for AI workloads.\nGraph-based ANNS indexes have superb empirical trade-offs in indexing cost,\nquery efficiency, and query approximation quality. Most existing graph-based\nindexes are designed for the static scenario, where there are no updates to the\ndata after the index is constructed. However, full dynamism (insertions,\ndeletions, and searches) is crucial to providing up-to-date responses in\napplications using vector databases. It is desirable that the index efficiently\nsupports updates and search queries concurrently. Existing dynamic graph-based\nindexes suffer from at least one of the following problems: (1) the query\nquality degrades as updates happen; and (2) the graph structure updates used to\nmaintain the index quality upon updates are global and thus expensive. To solve\nthese problems, we propose the CleANN system which consists of three main\ncomponents: (1) workload-aware linking of diverse search tree descendants to\ncombat distribution shift; (2)query-adaptive on-the-fly neighborhood\nconsolidation to efficiently handle deleted nodes; and (3) semi-lazy memory\ncleaning to clean up stale information in the data structure and reduce the\nwork spent by the first two components. We evaluate CleANN on 7 diverse\ndatasets on fully dynamic workloads and find that CleANN has query quality at\nleast as good as if the index had been built statically using the corresponding\ndata. In the in-memory setting using 56 hyper-threads, with all types of\nqueries running concurrently, at the same recall level, CleANN achieves 7-1200x\nthroughput improvement on million-scale real-world datasets. To the best of our\nknowledge, CleANN is the first concurrent ANNS index to achieve such efficiency\nwhile maintaining quality under full dynamism.", "published": "2025-07-26 05:27:32", "link": "http://arxiv.org/abs/2507.19802v1", "categories": ["cs.DB", "cs.DS", "cs.IR"], "primary_category": "cs.DB"}
{"title": "Analyzing and Mitigating Repetitions in Trip Recommendation", "abstract": "Trip recommendation has emerged as a highly sought-after service over the\npast decade. Although current studies significantly understand human intention\nconsistency, they struggle with undesired repetitive outcomes that need\nresolution. We make two pivotal discoveries using statistical analyses and\nexperimental designs: (1) The occurrence of repetitions is intricately linked\nto the models and decoding strategies. (2) During training and decoding, adding\nperturbations to logits can reduce repetition. Motivated by these observations,\nwe introduce AR-Trip (Anti Repetition for Trip Recommendation), which\nincorporates a cycle-aware predictor comprising three mechanisms to avoid\nduplicate Points-of-Interest (POIs) and demonstrates their effectiveness in\nalleviating repetition. Experiments on four public datasets illustrate that\nAR-Trip successfully mitigates repetition issues while enhancing precision.", "published": "2025-07-26 05:05:29", "link": "http://arxiv.org/abs/2507.19798v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "A Unified Framework for Interactive Visual Graph Matching via Attribute-Structure Synchronization", "abstract": "In traditional graph retrieval tools, graph matching is commonly used to\nretrieve desired graphs from extensive graph datasets according to their\nstructural similarities. However, in real applications, graph nodes have\nnumerous attributes which also contain valuable information for evaluating\nsimilarities between graphs. Thus, to achieve superior graph matching results,\nit is crucial for graph retrieval tools to make full use of the attribute\ninformation in addition to structural information. We propose a novel framework\nfor interactive visual graph matching. In the proposed framework, an\nattribute-structure synchronization method is developed for representing\nstructural and attribute features in a unified embedding space based on\nCanonical Correlation Analysis (CCA). To support fast and interactive matching,\n\\revise{our method} provides users with intuitive visual query interfaces for\ntraversing, filtering and searching for the target graph in the embedding space\nconveniently. With the designed interfaces, the users can also specify a new\ntarget graph with desired structural and semantic features. Besides, evaluation\nviews are designed for easy validation and interpretation of the matching\nresults. Case studies and quantitative comparisons on real-world datasets have\ndemonstrated the superiorities of our proposed framework in graph matching and\nlarge graph exploration.", "published": "2025-07-26 02:47:09", "link": "http://arxiv.org/abs/2507.19750v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "The Carbon Cost of Conversation, Sustainability in the Age of Language Models", "abstract": "Large language models (LLMs) like GPT-3 and BERT have revolutionized natural\nlanguage processing (NLP), yet their environmental costs remain dangerously\noverlooked. This article critiques the sustainability of LLMs, quantifying\ntheir carbon footprint, water usage, and contribution to e-waste through case\nstudies of models such as GPT-4 and energy-efficient alternatives like Mistral\n7B. Training a single LLM can emit carbon dioxide equivalent to hundreds of\ncars driven annually, while data centre cooling exacerbates water scarcity in\nvulnerable regions. Systemic challenges corporate greenwashing, redundant model\ndevelopment, and regulatory voids perpetuate harm, disproportionately burdening\nmarginalized communities in the Global South. However, pathways exist for\nsustainable NLP: technical innovations (e.g., model pruning, quantum\ncomputing), policy reforms (carbon taxes, mandatory emissions reporting), and\ncultural shifts prioritizing necessity over novelty. By analysing industry\nleaders (Google, Microsoft) and laggards (Amazon), this work underscores the\nurgency of ethical accountability and global cooperation. Without immediate\naction, AIs ecological toll risks outpacing its societal benefits. The article\nconcludes with a call to align technological progress with planetary\nboundaries, advocating for equitable, transparent, and regenerative AI systems\nthat prioritize both human and environmental well-being.", "published": "2025-07-26 17:21:11", "link": "http://arxiv.org/abs/2507.20018v2", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Exploring LLM Autoscoring Reliability in Large-Scale Writing Assessments Using Generalizability Theory", "abstract": "This study investigates the estimation of reliability for large language\nmodels (LLMs) in scoring writing tasks from the AP Chinese Language and Culture\nExam. Using generalizability theory, the research evaluates and compares score\nconsistency between human and AI raters across two types of AP Chinese\nfree-response writing tasks: story narration and email response. These essays\nwere independently scored by two trained human raters and seven AI raters. Each\nessay received four scores: one holistic score and three analytic scores\ncorresponding to the domains of task completion, delivery, and language use.\nResults indicate that although human raters produced more reliable scores\noverall, LLMs demonstrated reasonable consistency under certain conditions,\nparticularly for story narration tasks. Composite scoring that incorporates\nboth human and AI raters improved reliability, which supports that hybrid\nscoring models may offer benefits for large-scale writing assessments.", "published": "2025-07-26 15:33:05", "link": "http://arxiv.org/abs/2507.19980v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Scalable and High Availability Solution for Recommending Resolutions to Problem Tickets", "abstract": "Resolution of incidents or problem tickets is a common theme in service\nindustries in any sector, including billing and charging systems in telecom\ndomain. Machine learning can help to identify patterns and suggest resolutions\nfor the problem tickets, based on patterns in the historical data of the\ntickets. However, this process may be complicated due to a variety of phenomena\nsuch as data drift and issues such as missing data, lack of data pertaining to\nresolutions of past incidents, too many similar sounding resolutions due to\nfree text and similar sounding text. This paper proposes a robust ML-driven\nsolution employing clustering, supervised learning, and advanced NLP models to\ntackle these challenges effectively. Building on previous work, we demonstrate\nclustering-based resolution identification, supervised classification with LDA,\nSiamese networks, and One-shot learning, Index embedding. Additionally, we\npresent a real-time dashboard and a highly available Kubernetes-based\nproduction deployment. Our experiments with both the open-source Bitext\ncustomer-support dataset and proprietary telecom datasets demonstrate high\nprediction accuracy.", "published": "2025-07-26 07:42:12", "link": "http://arxiv.org/abs/2507.19846v2", "categories": ["cs.LG", "cs.IR", "68T50", "I.2.7; I.2.6; H.3.3; H.4.1"], "primary_category": "cs.LG"}
