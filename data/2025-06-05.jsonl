{"title": "Inference-Time Hyper-Scaling with KV Cache Compression", "abstract": "Inference-time scaling trades efficiency for increased reasoning accuracy by\ngenerating longer or more parallel sequences. However, in Transformer LLMs,\ngeneration cost is bottlenecked by the size of the key-value (KV) cache, rather\nthan the number of generated tokens. Hence, we explore inference-time\nhyper-scaling: by compressing the KV cache, we can generate more tokens within\nthe same compute budget and further improve the accuracy of scaled inference.\nThe success of this approach, however, hinges on the ability of compression\nmethods to preserve accuracy even at high compression ratios. To make\nhyper-scaling practical, we introduce Dynamic Memory Sparsification (DMS), a\nnovel method for sparsifying KV caches that only requires 1K training steps to\nachieve 8$\\times$ compression, while maintaining better accuracy than\ntraining-free sparse attention. Instead of prematurely discarding cached\ntokens, DMS delays token eviction, implicitly merging representations and\npreserving critical information. We demonstrate the effectiveness of\ninference-time hyper-scaling with DMS on multiple families of LLMs, showing\nthat it boosts accuracy for comparable inference runtime and memory load. For\ninstance, we enhance Qwen-R1 32B by an average of 9.1 points on AIME 24, 7.6 on\nGPQA, and 9.6 on LiveCodeBench across compute budgets.", "published": "2025-06-05 17:59:55", "link": "http://arxiv.org/abs/2506.05345v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Why LLM Safety Guardrails Collapse After Fine-tuning: A Similarity Analysis Between Alignment and Fine-tuning Datasets", "abstract": "Recent advancements in large language models (LLMs) have underscored their\nvulnerability to safety alignment jailbreaks, particularly when subjected to\ndownstream fine-tuning. However, existing mitigation strategies primarily focus\non reactively addressing jailbreak incidents after safety guardrails have been\ncompromised, removing harmful gradients during fine-tuning, or continuously\nreinforcing safety alignment throughout fine-tuning. As such, they tend to\noverlook a critical upstream factor: the role of the original safety-alignment\ndata. This paper therefore investigates the degradation of safety guardrails\nthrough the lens of representation similarity between upstream alignment\ndatasets and downstream fine-tuning tasks. Our experiments demonstrate that\nhigh similarity between these datasets significantly weakens safety guardrails,\nmaking models more susceptible to jailbreaks. Conversely, low similarity\nbetween these two types of datasets yields substantially more robust models and\nthus reduces harmfulness score by up to 10.33%. By highlighting the importance\nof upstream dataset design in the building of durable safety guardrails and\nreducing real-world vulnerability to jailbreak attacks, these findings offer\nactionable insights for fine-tuning service providers.", "published": "2025-06-05 17:59:55", "link": "http://arxiv.org/abs/2506.05346v1", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Flattery, Fluff, and Fog: Diagnosing and Mitigating Idiosyncratic Biases in Preference Models", "abstract": "Language models serve as proxies for human preference judgements in alignment\nand evaluation, yet they exhibit systematic miscalibration, prioritizing\nsuperficial patterns over substantive qualities. This bias manifests as\noverreliance on features like length, structure, and style, leading to issues\nlike reward hacking and unreliable evaluations. Evidence suggests these biases\noriginate in artifacts in human training data. In this work, we systematically\ninvestigate the relationship between training data biases and preference model\nmiscalibration across five idiosyncratic features of language model\ngenerations: length, structure, jargon, sycophancy and vagueness. Using\ncontrolled counterfactual pairs, we first quantify the extent to which\npreference models favor responses with magnified biases (skew), finding this\npreference occurs in >60% of instances, and model preferences show high\nmiscalibration (~40%) compared to human preferences. Notably, bias features\nonly show mild negative correlations to human preference labels (mean r_human =\n-0.12) but show moderately strong positive correlations with labels from a\nstrong reward model (mean r_model = +0.36), suggesting that models may overrely\non spurious cues. To mitigate these issues, we propose a simple post-training\nmethod based on counterfactual data augmentation (CDA) using synthesized\ncontrastive examples. Finetuning models with CDA reduces average miscalibration\nfrom 39.4% to 32.5% and average absolute skew difference from 20.5% to 10.0%,\nwhile maintaining overall RewardBench performance, showing that targeted\ndebiasing is effective for building reliable preference models.", "published": "2025-06-05 17:59:32", "link": "http://arxiv.org/abs/2506.05339v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Search Arena: Analyzing Search-Augmented LLMs", "abstract": "Search-augmented language models combine web search with Large Language\nModels (LLMs) to improve response groundedness and freshness. However,\nanalyzing these systems remains challenging: existing datasets are limited in\nscale and narrow in scope, often constrained to static, single-turn,\nfact-checking questions. In this work, we introduce Search Arena, a\ncrowd-sourced, large-scale, human-preference dataset of over 24,000 paired\nmulti-turn user interactions with search-augmented LLMs. The dataset spans\ndiverse intents and languages, and contains full system traces with around\n12,000 human preference votes. Our analysis reveals that user preferences are\ninfluenced by the number of citations, even when the cited content does not\ndirectly support the attributed claims, uncovering a gap between perceived and\nactual credibility. Furthermore, user preferences vary across cited sources,\nrevealing that community-driven platforms are generally preferred and static\nencyclopedic sources are not always appropriate and reliable. To assess\nperformance across different settings, we conduct cross-arena analyses by\ntesting search-augmented LLMs in a general-purpose chat environment and\nconventional LLMs in search-intensive settings. We find that web search does\nnot degrade and may even improve performance in non-search settings; however,\nthe quality in search settings is significantly affected if solely relying on\nthe model's parametric knowledge. We open-sourced the dataset to support future\nresearch in this direction. Our dataset and code are available at:\nhttps://github.com/lmarena/search-arena.", "published": "2025-06-05 17:59:26", "link": "http://arxiv.org/abs/2506.05334v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Kinetics: Rethinking Test-Time Scaling Laws", "abstract": "We rethink test-time scaling laws from a practical efficiency perspective,\nrevealing that the effectiveness of smaller models is significantly\noverestimated. Prior work, grounded in compute-optimality, overlooks critical\nmemory access bottlenecks introduced by inference-time strategies (e.g.,\nBest-of-$N$, long CoTs). Our holistic analysis, spanning models from 0.6B to\n32B parameters, reveals a new Kinetics Scaling Law that better guides resource\nallocation by incorporating both computation and memory access costs. Kinetics\nScaling Law suggests that test-time compute is more effective when used on\nmodels above a threshold than smaller ones. A key reason is that in TTS,\nattention, rather than parameter count, emerges as the dominant cost factor.\nMotivated by this, we propose a new scaling paradigm centered on sparse\nattention, which lowers per-token cost and enables longer generations and more\nparallel samples within the same resource budget. Empirically, we show that\nsparse attention models consistently outperform dense counterparts, achieving\nover 60 points gains in low-cost regimes and over 5 points gains in high-cost\nregimes for problem-solving accuracy on AIME, encompassing evaluations on\nstate-of-the-art MoEs. These results suggest that sparse attention is essential\nfor realizing the full potential of test-time scaling because, unlike training,\nwhere parameter scaling saturates, test-time accuracy continues to improve\nthrough increased generation. The code is available at\nhttps://github.com/Infini-AI-Lab/Kinetics.", "published": "2025-06-05 17:59:24", "link": "http://arxiv.org/abs/2506.05333v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Unleashing Hour-Scale Video Training for Long Video-Language Understanding", "abstract": "Recent long-form video-language understanding benchmarks have driven progress\nin video large multimodal models (Video-LMMs). However, the scarcity of\nwell-annotated long videos has left the training of hour-long Video-LLMs\nunderexplored. To close this gap, we present VideoMarathon, a large-scale\nhour-long video instruction-following dataset. This dataset includes around\n9,700 hours of long videos sourced from diverse domains, ranging from 3 to 60\nminutes per video. Specifically, it contains 3.3M high-quality QA pairs,\nspanning six fundamental topics: temporality, spatiality, object, action,\nscene, and event. Compared to existing video instruction datasets,\nVideoMarathon significantly extends training video durations up to 1 hour, and\nsupports 22 diverse tasks requiring both short- and long-term video\ncomprehension. Building on VideoMarathon, we propose Hour-LLaVA, a powerful and\nefficient Video-LMM for hour-scale video-language modeling. It enables\nhour-long video training and inference at 1-FPS sampling by leveraging a memory\naugmentation module, which adaptively integrates user question-relevant and\nspatiotemporal-informative semantics from a cached full video context. In our\nexperiments, Hour-LLaVA achieves the best performance on multiple long\nvideo-language benchmarks, demonstrating the high quality of the VideoMarathon\ndataset and the superiority of the Hour-LLaVA model.", "published": "2025-06-05 17:59:04", "link": "http://arxiv.org/abs/2506.05332v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay", "abstract": "Reinforcement learning (RL) has become an effective approach for fine-tuning\nlarge language models (LLMs), particularly to enhance their reasoning\ncapabilities. However, RL fine-tuning remains highly resource-intensive, and\nexisting work has largely overlooked the problem of data efficiency. In this\npaper, we propose two techniques to improve data efficiency in LLM RL\nfine-tuning: difficulty-targeted online data selection and rollout replay. We\nintroduce the notion of adaptive difficulty to guide online data selection,\nprioritizing questions of moderate difficulty that are more likely to yield\ninformative learning signals. To estimate adaptive difficulty efficiently, we\ndevelop an attention-based framework that requires rollouts for only a small\nreference set of questions. The adaptive difficulty of the remaining questions\nis then estimated based on their similarity to this set. To further reduce\nrollout cost, we introduce a rollout replay mechanism that reuses recent\nrollouts, lowering per-step computation while maintaining stable updates.\nExtensive experiments across 6 LLM-dataset combinations show that our method\nreduces RL fine-tuning time by 25% to 65% to reach the same level of\nperformance as the original GRPO algorithm.", "published": "2025-06-05 17:55:43", "link": "http://arxiv.org/abs/2506.05316v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Constrained Entropic Unlearning: A Primal-Dual Framework for Large Language Models", "abstract": "Large Language Models (LLMs) deployed in real-world settings increasingly\nface the need to unlearn sensitive, outdated, or proprietary information.\nExisting unlearning methods typically formulate forgetting and retention as a\nregularized trade-off, combining both objectives into a single scalarized loss.\nThis often leads to unstable optimization and degraded performance on retained\ndata, especially under aggressive forgetting. We propose a new formulation of\nLLM unlearning as a constrained optimization problem: forgetting is enforced\nvia a novel logit-margin flattening loss that explicitly drives the output\ndistribution toward uniformity on a designated forget set, while retention is\npreserved through a hard constraint on a separate retain set. Compared to\nentropy-based objectives, our loss is softmax-free, numerically stable, and\nmaintains non-vanishing gradients, enabling more efficient and robust\noptimization. We solve the constrained problem using a scalable primal-dual\nalgorithm that exposes the trade-off between forgetting and retention through\nthe dynamics of the dual variable. Evaluations on the TOFU and MUSE benchmarks\nacross diverse LLM architectures demonstrate that our approach consistently\nmatches or exceeds state-of-the-art baselines, effectively removing targeted\ninformation while preserving downstream utility.", "published": "2025-06-05 17:55:23", "link": "http://arxiv.org/abs/2506.05314v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games", "abstract": "LLMs are used predominantly in synchronous communication, where a human user\nand a model communicate in alternating turns. In contrast, many real-world\nsettings are inherently asynchronous. For example, in group chats, online team\nmeetings, or social games, there is no inherent notion of turns; therefore, the\ndecision of when to speak forms a crucial part of the participant's decision\nmaking. In this work, we develop an adaptive asynchronous LLM-agent which, in\naddition to determining what to say, also decides when to say it. To evaluate\nour agent, we collect a unique dataset of online Mafia games, including both\nhuman participants, as well as our asynchronous agent. Overall, our agent\nperforms on par with human players, both in game performance, as well as in its\nability to blend in with the other human players. Our analysis shows that the\nagent's behavior in deciding when to speak closely mirrors human patterns,\nalthough differences emerge in message content. We release all our data and\ncode to support and encourage further research for more realistic asynchronous\ncommunication between LLM agents. This work paves the way for integration of\nLLMs into realistic human group settings, from assistance in team discussions\nto educational and professional environments where complex social dynamics must\nbe navigated.", "published": "2025-06-05 17:53:44", "link": "http://arxiv.org/abs/2506.05309v1", "categories": ["cs.MA", "cs.AI", "cs.CL"], "primary_category": "cs.MA"}
{"title": "ProRefine: Inference-time Prompt Refinement with Textual Feedback", "abstract": "Agentic workflows, where multiple AI agents collaborate to accomplish complex\ntasks like reasoning or planning, are becoming increasingly prevalent. However,\nthese workflows often suffer from error propagation and sub-optimal\nperformance, largely due to poorly designed prompts that fail to effectively\nguide individual agents. This is a critical problem because it limits the\nreliability and scalability of these powerful systems. We introduce ProRefine,\nan innovative inference-time prompt optimization method that leverages textual\nfeedback from large language models (LLMs) to address this challenge. ProRefine\ndynamically refines prompts for multi-step reasoning tasks without additional\ntraining or ground truth labels. Evaluated on five benchmark mathematical\nreasoning datasets, ProRefine significantly surpasses zero-shot\nChain-of-Thought baselines by 3 to 37 percentage points. This approach not only\nboosts accuracy but also allows smaller models to match the performance of\nlarger ones, highlighting its potential for efficient and scalable AI\ndeployment, and democratizing access to high-performing AI.", "published": "2025-06-05 17:52:30", "link": "http://arxiv.org/abs/2506.05305v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning", "abstract": "Retrieval-Augmented Generation (RAG) systems commonly suffer from Knowledge\nConflicts, where retrieved external knowledge contradicts the inherent,\nparametric knowledge of large language models (LLMs). It adversely affects\nperformance on downstream tasks such as question answering (QA). Existing\napproaches often attempt to mitigate conflicts by directly comparing two\nknowledge sources in a side-by-side manner, but this can overwhelm LLMs with\nextraneous or lengthy contexts, ultimately hindering their ability to identify\nand mitigate inconsistencies. To address this issue, we propose Micro-Act a\nframework with a hierarchical action space that automatically perceives context\ncomplexity and adaptively decomposes each knowledge source into a sequence of\nfine-grained comparisons. These comparisons are represented as actionable\nsteps, enabling reasoning beyond the superficial context. Through extensive\nexperiments on five benchmark datasets, Micro-Act consistently achieves\nsignificant increase in QA accuracy over state-of-the-art baselines across all\n5 datasets and 3 conflict types, especially in temporal and semantic types\nwhere all baselines fail significantly. More importantly, Micro-Act exhibits\nrobust performance on non-conflict questions simultaneously, highlighting its\npractical value in real-world RAG applications.", "published": "2025-06-05 17:33:02", "link": "http://arxiv.org/abs/2506.05278v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CLATTER: Comprehensive Entailment Reasoning for Hallucination Detection", "abstract": "A common approach to hallucination detection casts it as a natural language\ninference (NLI) task, often using LLMs to classify whether the generated text\nis entailed by corresponding reference texts. Since entailment classification\nis a complex reasoning task, one would expect that LLMs could benefit from\ngenerating an explicit reasoning process, as in CoT reasoning or the explicit\n``thinking'' of recent reasoning models. In this work, we propose that guiding\nsuch models to perform a systematic and comprehensive reasoning process -- one\nthat both decomposes the text into smaller facts and also finds evidence in the\nsource for each fact -- allows models to execute much finer-grained and\naccurate entailment decisions, leading to increased performance. To that end,\nwe define a 3-step reasoning process, consisting of (i) claim decomposition,\n(ii) sub-claim attribution and entailment classification, and (iii) aggregated\nclassification, showing that such guided reasoning indeed yields improved\nhallucination detection. Following this reasoning framework, we introduce an\nanalysis scheme, consisting of several metrics that measure the quality of the\nintermediate reasoning steps, which provided additional empirical evidence for\nthe improved quality of our guided reasoning scheme.", "published": "2025-06-05 17:02:52", "link": "http://arxiv.org/abs/2506.05243v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a Unified System of Representation for Continuity and Discontinuity in Natural Language", "abstract": "Syntactic discontinuity is a grammatical phenomenon in which a constituent is\nsplit into more than one part because of the insertion of an element which is\nnot part of the constituent. This is observed in many languages across the\nworld such as Turkish, Russian, Japanese, Warlpiri, Navajo, Hopi, Dyirbal,\nYidiny etc. Different formalisms/frameworks in current linguistic theory\napproach the problem of discontinuous structures in different ways. Each\nframework/formalism has widely been viewed as an independent and non-converging\nsystem of analysis. In this paper, we propose a unified system of\nrepresentation for both continuity and discontinuity in structures of natural\nlanguages by taking into account three formalisms, in particular, Phrase\nStructure Grammar (PSG) for its widely used notion of constituency, Dependency\nGrammar (DG) for its head-dependent relations, and Categorial Grammar (CG) for\nits focus on functor-argument relations. We attempt to show that discontinuous\nexpressions as well as continuous structures can be analysed through a unified\nmathematical derivation incorporating the representations of linguistic\nstructure in these three grammar formalisms.", "published": "2025-06-05 16:54:41", "link": "http://arxiv.org/abs/2506.05235v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MesaNet: Sequence Modeling by Locally Optimal Test-Time Training", "abstract": "Sequence modeling is currently dominated by causal transformer architectures\nthat use softmax self-attention. Although widely adopted, transformers require\nscaling memory and compute linearly during inference. A recent stream of work\nlinearized the softmax operation, resulting in powerful recurrent neural\nnetwork (RNN) models with constant memory and compute costs such as DeltaNet,\nMamba or xLSTM. These models can be unified by noting that their recurrent\nlayer dynamics can all be derived from an in-context regression objective,\napproximately optimized through an online learning rule. Here, we join this\nline of work and introduce a numerically stable, chunkwise parallelizable\nversion of the recently proposed Mesa layer (von Oswald et al., 2024), and\nstudy it in language modeling at the billion-parameter scale. This layer again\nstems from an in-context loss, but which is now minimized to optimality at\nevery time point using a fast conjugate gradient solver. Through an extensive\nsuite of experiments, we show that optimal test-time training enables reaching\nlower language modeling perplexity and higher downstream benchmark performance\nthan previous RNNs, especially on tasks requiring long context understanding.\nThis performance gain comes at the cost of additional flops spent during\ninference time. Our results are therefore intriguingly related to recent trends\nof increasing test-time compute to improve performance -- here by spending\ncompute to solve sequential optimization problems within the neural network\nitself.", "published": "2025-06-05 16:50:23", "link": "http://arxiv.org/abs/2506.05233v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Diagonal Batching Unlocks Parallelism in Recurrent Memory Transformers for Long Contexts", "abstract": "Transformer models struggle with long-context inference due to their\nquadratic time and linear memory complexity. Recurrent Memory Transformers\n(RMTs) offer a solution by reducing the asymptotic cost to linear time and\nconstant memory usage. However, their memory update mechanism leads to\nsequential execution, causing a performance bottleneck.\n  We introduce Diagonal Batching, a scheduling scheme that unlocks parallelism\nacross segments in RMTs while preserving exact recurrence. This approach\neliminates the sequential constraint, enabling efficient GPU inference even for\nsingle long-context inputs without complex batching and pipelining techniques.\nBecause the technique is purely a run-time computation reordering, existing RMT\nmodels adopt it with no retraining.\n  Applied to a LLaMA-1B ARMT model, Diagonal Batching yields a 3.3x speedup\nover standard full-attention LLaMA-1B and a 1.8x speedup over the sequential\nRMT implementation on 131,072-token sequences. By removing sequential\nbottleneck, Diagonal Batching reduces inference cost and latency, thereby\nstrengthening RMTs as a practical solution for real-world, long-context\napplications.", "published": "2025-06-05 16:43:48", "link": "http://arxiv.org/abs/2506.05229v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Improving Low-Resource Morphological Inflection via Self-Supervised Objectives", "abstract": "Self-supervised objectives have driven major advances in NLP by leveraging\nlarge-scale unlabeled data, but such resources are scarce for many of the\nworld's languages. Surprisingly, they have not been explored much for\ncharacter-level tasks, where smaller amounts of data have the potential to be\nbeneficial. We investigate the effectiveness of self-supervised auxiliary tasks\nfor morphological inflection -- a character-level task highly relevant for\nlanguage documentation -- in extremely low-resource settings, training\nencoder-decoder transformers for 19 languages and 13 auxiliary objectives.\nAutoencoding yields the best performance when unlabeled data is very limited,\nwhile character masked language modeling (CMLM) becomes more effective as data\navailability increases. Though objectives with stronger inductive biases\ninfluence model predictions intuitively, they rarely outperform standard CMLM.\nHowever, sampling masks based on known morpheme boundaries consistently\nimproves performance, highlighting a promising direction for low-resource\nmorphological modeling.", "published": "2025-06-05 16:42:45", "link": "http://arxiv.org/abs/2506.05227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Degree Bias Adaptively with Hard-to-Learn Nodes in Graph Contrastive Learning", "abstract": "Graph Neural Networks (GNNs) often suffer from degree bias in node\nclassification tasks, where prediction performance varies across nodes with\ndifferent degrees. Several approaches, which adopt Graph Contrastive Learning\n(GCL), have been proposed to mitigate this bias. However, the limited number of\npositive pairs and the equal weighting of all positives and negatives in GCL\nstill lead to low-degree nodes acquiring insufficient and noisy information.\nThis paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss to\nmitigate degree bias. It adds more positive pairs by leveraging node labels and\nadaptively weights positive and negative pairs based on their learning\nhardness. In addition, we develop an experimental framework named SHARP to\nextend HAR to a broader range of scenarios. Both our theoretical analysis and\nexperiments validate the effectiveness of SHARP. The experimental results\nacross four datasets show that SHARP achieves better performance against\nbaselines at both global and degree levels.", "published": "2025-06-05 16:28:12", "link": "http://arxiv.org/abs/2506.05214v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM-First Search: Self-Guided Exploration of the Solution Space", "abstract": "Large Language Models (LLMs) have demonstrated remarkable improvements in\nreasoning and planning through increased test-time compute, often by framing\nproblem-solving as a search process. While methods like Monte Carlo Tree Search\n(MCTS) have proven effective in some domains, their reliance on fixed\nexploration hyperparameters limits their adaptability across tasks of varying\ndifficulty, rendering them impractical or expensive in certain settings. In\nthis paper, we propose \\textbf{LLM-First Search (LFS)}, a novel \\textit{LLM\nSelf-Guided Search} method that removes the need for pre-defined search\nstrategies by empowering the LLM to autonomously control the search process via\nself-guided exploration. Rather than relying on external heuristics or\nhardcoded policies, the LLM evaluates whether to pursue the current search path\nor explore alternative branches based on its internal scoring mechanisms. This\nenables more flexible and context-sensitive reasoning without requiring manual\ntuning or task-specific adaptation. We evaluate LFS on Countdown and Sudoku\nagainst three classic widely-used search algorithms, Tree-of-Thoughts' Breadth\nFirst Search (ToT-BFS), Best First Search (BestFS), and MCTS, each of which\nhave been used to achieve SotA results on a range of challenging reasoning\ntasks. We found that LFS (1) performs better on more challenging tasks without\nadditional tuning, (2) is more computationally efficient compared to the other\nmethods, especially when powered by a stronger model, (3) scales better with\nstronger models, due to its LLM-First design, and (4) scales better with\nincreased compute budget. Our code is publicly available at\n\\href{https://github.com/NathanHerr/LLM-First-Search}{LLM-First-Search}.", "published": "2025-06-05 16:27:49", "link": "http://arxiv.org/abs/2506.05213v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "The Common Pile v0.1: An 8TB Dataset of Public Domain and Openly Licensed Text", "abstract": "Large language models (LLMs) are typically trained on enormous quantities of\nunlicensed text, a practice that has led to scrutiny due to possible\nintellectual property infringement and ethical concerns. Training LLMs on\nopenly licensed text presents a first step towards addressing these issues, but\nprior data collection efforts have yielded datasets too small or low-quality to\nproduce performant LLMs. To address this gap, we collect, curate, and release\nthe Common Pile v0.1, an eight terabyte collection of openly licensed text\ndesigned for LLM pretraining. The Common Pile comprises content from 30 sources\nthat span diverse domains including research papers, code, books,\nencyclopedias, educational materials, audio transcripts, and more. Crucially,\nwe validate our efforts by training two 7 billion parameter LLMs on text from\nthe Common Pile: Comma v0.1-1T and Comma v0.1-2T, trained on 1 and 2 trillion\ntokens respectively. Both models attain competitive performance to LLMs trained\non unlicensed text with similar computational budgets, such as Llama 1 and 2\n7B. In addition to releasing the Common Pile v0.1 itself, we also release the\ncode used in its creation as well as the training mixture and checkpoints for\nthe Comma v0.1 models.", "published": "2025-06-05 16:21:30", "link": "http://arxiv.org/abs/2506.05209v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RELIC: Evaluating Compositional Instruction Following via Language Recognition", "abstract": "Large language models (LLMs) are increasingly expected to perform tasks based\nonly on a specification of the task provided in context, without examples of\ninputs and outputs; this ability is referred to as instruction following. We\nintroduce the Recognition of Languages In-Context (RELIC) framework to evaluate\ninstruction following using language recognition: the task of determining if a\nstring is generated by formal grammar. Unlike many standard evaluations of\nLLMs' ability to use their context, this task requires composing together a\nlarge number of instructions (grammar productions) retrieved from the context.\nBecause the languages are synthetic, the task can be increased in complexity as\nLLMs' skills improve, and new instances can be automatically generated,\nmitigating data contamination. We evaluate state-of-the-art LLMs on RELIC and\nfind that their accuracy can be reliably predicted from the complexity of the\ngrammar and the individual example strings, and that even the most advanced\nLLMs currently available show near-chance performance on more complex grammars\nand samples, in line with theoretical expectations. We also use RELIC to\ndiagnose how LLMs attempt to solve increasingly difficult reasoning tasks,\nfinding that as the complexity of the language recognition task increases,\nmodels switch to relying on shallow heuristics instead of following complex\ninstructions.", "published": "2025-06-05 16:17:24", "link": "http://arxiv.org/abs/2506.05205v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counterfactual reasoning: an analysis of in-context emergence", "abstract": "Large-scale neural language models (LMs) exhibit remarkable performance in\nin-context learning: the ability to learn and reason the input context on the\nfly without parameter update. This work studies in-context counterfactual\nreasoning in language models, that is, to predict the consequences of changes\nunder hypothetical scenarios. We focus on studying a well-defined synthetic\nsetup: a linear regression task that requires noise abduction, where accurate\nprediction is based on inferring and copying the contextual noise from factual\nobservations. We show that language models are capable of counterfactual\nreasoning in this controlled setup and provide insights that counterfactual\nreasoning for a broad class of functions can be reduced to a transformation on\nin-context observations; we find self-attention, model depth, and data\ndiversity in pre-training drive performance in Transformers. More\ninterestingly, our findings extend beyond regression tasks and show that\nTransformers can perform noise abduction on sequential data, providing\npreliminary evidence on the potential for counterfactual story generation. Our\ncode is available under\nhttps://github.com/moXmiller/counterfactual-reasoning.git .", "published": "2025-06-05 16:02:07", "link": "http://arxiv.org/abs/2506.05188v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "primary_category": "cs.CL"}
{"title": "Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models", "abstract": "In this work, we introduce the Qwen3 Embedding series, a significant\nadvancement over its predecessor, the GTE-Qwen series, in text embedding and\nreranking capabilities, built upon the Qwen3 foundation models. Leveraging the\nQwen3 LLMs' robust capabilities in multilingual text understanding and\ngeneration, our innovative multi-stage training pipeline combines large-scale\nunsupervised pre-training with supervised fine-tuning on high-quality datasets.\nEffective model merging strategies further ensure the robustness and\nadaptability of the Qwen3 Embedding series. During the training process, the\nQwen3 LLMs serve not only as backbone models but also play a crucial role in\nsynthesizing high-quality, rich, and diverse training data across multiple\ndomains and languages, thus enhancing the training pipeline. The Qwen3\nEmbedding series offers a spectrum of model sizes (0.6B, 4B, 8B) for both\nembedding and reranking tasks, addressing diverse deployment scenarios where\nusers can optimize for either efficiency or effectiveness. Empirical\nevaluations demonstrate that the Qwen3 Embedding series achieves\nstate-of-the-art results across diverse benchmarks. Notably, it excels on the\nmultilingual evaluation benchmark MTEB for text embedding, as well as in\nvarious retrieval tasks, including code retrieval, cross-lingual retrieval and\nmultilingual retrieval. To facilitate reproducibility and promote\ncommunity-driven research and development, the Qwen3 Embedding models are\npublicly available under the Apache 2.0 license.", "published": "2025-06-05 15:49:48", "link": "http://arxiv.org/abs/2506.05176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG", "abstract": "Large Language Models (LLMs) have shown remarkable performance in Open-Domain\nQuestion Answering (ODQA) by leveraging external documents through\nRetrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer\ncontext, context compression is necessary. However, prior compression methods\ndo not focus on filtering out non-evidential information, which limit the\nperformance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or\n\\textbf{ECoRAG} framework. ECoRAG improves LLM performance by compressing\nretrieved documents based on evidentiality, ensuring whether answer generation\nis supported by the correct evidence. As an additional step, ECoRAG reflects\nwhether the compressed content provides sufficient evidence, and if not,\nretrieves more until sufficient. Experiments show that ECoRAG improves LLM\nperformance on ODQA tasks, outperforming existing compression methods.\nFurthermore, ECoRAG is highly cost-efficient, as it not only reduces latency\nbut also minimizes token usage by retaining only the necessary information to\ngenerate the correct answer. Code is available at\nhttps://github.com/ldilab/ECoRAG.", "published": "2025-06-05 15:43:49", "link": "http://arxiv.org/abs/2506.05167v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Dissecting Bias in LLMs: A Mechanistic Interpretability Perspective", "abstract": "Large Language Models (LLMs) are known to exhibit social, demographic, and\ngender biases, often as a consequence of the data on which they are trained. In\nthis work, we adopt a mechanistic interpretability approach to analyze how such\nbiases are structurally represented within models such as GPT-2 and Llama2.\nFocusing on demographic and gender biases, we explore different metrics to\nidentify the internal edges responsible for biased behavior. We then assess the\nstability, localization, and generalizability of these components across\ndataset and linguistic variations. Through systematic ablations, we demonstrate\nthat bias-related computations are highly localized, often concentrated in a\nsmall subset of layers. Moreover, the identified components change across\nfine-tuning settings, including those unrelated to bias. Finally, we show that\nremoving these components not only reduces biased outputs but also affects\nother NLP tasks, such as named entity recognition and linguistic acceptability\njudgment because of the sharing of important components with these tasks.", "published": "2025-06-05 15:43:34", "link": "http://arxiv.org/abs/2506.05166v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledgeable-r1: Policy Optimization for Knowledge Exploration in Retrieval-Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) is a mainstream method for improving\nperformance on knowledge-intensive tasks. However,current RAG systems often\nplace too much emphasis on retrieved contexts. This can lead to reliance on\ninaccurate sources and overlook the model's inherent knowledge, especially when\ndealing with misleading or excessive information. To resolve this imbalance, we\npropose Knowledgeable-r1 that using joint sampling and define multi policy\ndistributions in knowledge capability exploration to stimulate large language\nmodels'self-integrated utilization of parametric and contextual knowledge.\nExperiments show that Knowledgeable-r1 significantly enhances robustness and\nreasoning accuracy in both parameters and contextual conflict tasks and general\nRAG tasks, especially outperforming baselines by 17.07% in counterfactual\nscenarios and demonstrating consistent gains across RAG tasks. Our code are\navailable at https://github.com/lcy80366872/ knowledgeable-r1.", "published": "2025-06-05 15:34:15", "link": "http://arxiv.org/abs/2506.05154v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "CIVET: Systematic Evaluation of Understanding in VLMs", "abstract": "While Vision-Language Models (VLMs) have achieved competitive performance in\nvarious tasks, their comprehension of the underlying structure and semantics of\na scene remains understudied. To investigate the understanding of VLMs, we\nstudy their capability regarding object properties and relations in a\ncontrolled and interpretable manner. To this scope, we introduce CIVET, a novel\nand extensible framework for systematiC evaluatIon Via controllEd sTimuli.\nCIVET addresses the lack of standardized systematic evaluation for assessing\nVLMs' understanding, enabling researchers to test hypotheses with statistical\nrigor. With CIVET, we evaluate five state-of-the-art VLMs on exhaustive sets of\nstimuli, free from annotation noise, dataset-specific biases, and uncontrolled\nscene complexity. Our findings reveal that 1) current VLMs can accurately\nrecognize only a limited set of basic object properties; 2) their performance\nheavily depends on the position of the object in the scene; 3) they struggle to\nunderstand basic relations among objects. Furthermore, a comparative evaluation\nwith human annotators reveals that VLMs still fall short of achieving\nhuman-level accuracy.", "published": "2025-06-05 15:27:16", "link": "http://arxiv.org/abs/2506.05146v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Do Large Language Models Judge Error Severity Like Humans?", "abstract": "Large Language Models (LLMs) are increasingly used as automated evaluators in\nnatural language generation, yet it remains unclear whether they can accurately\nreplicate human judgments of error severity. In this study, we systematically\ncompare human and LLM assessments of image descriptions containing controlled\nsemantic errors. We extend the experimental framework of van Miltenburg et al.\n(2020) to both unimodal (text-only) and multimodal (text + image) settings,\nevaluating four error types: age, gender, clothing type, and clothing colour.\nOur findings reveal that humans assign varying levels of severity to different\nerror types, with visual context significantly amplifying perceived severity\nfor colour and type errors. Notably, most LLMs assign low scores to gender\nerrors but disproportionately high scores to colour errors, unlike humans, who\njudge both as highly severe but for different reasons. This suggests that these\nmodels may have internalised social norms influencing gender judgments but lack\nthe perceptual grounding to emulate human sensitivity to colour, which is\nshaped by distinct neural mechanisms. Only one of the evaluated LLMs, Doubao,\nreplicates the human-like ranking of error severity, but it fails to\ndistinguish between error types as clearly as humans. Surprisingly,\nDeepSeek-V3, a unimodal LLM, achieves the highest alignment with human\njudgments across both unimodal and multimodal conditions, outperforming even\nstate-of-the-art multimodal models.", "published": "2025-06-05 15:24:33", "link": "http://arxiv.org/abs/2506.05142v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AudioLens: A Closer Look at Auditory Attribute Perception of Large Audio-Language Models", "abstract": "Understanding the internal mechanisms of large audio-language models (LALMs)\nis crucial for interpreting their behavior and improving performance. This work\npresents the first in-depth analysis of how LALMs internally perceive and\nrecognize auditory attributes. By applying vocabulary projection on three\nstate-of-the-art LALMs, we track how attribute information evolves across\nlayers and token positions. We find that attribute information generally\ndecreases with layer depth when recognition fails, and that resolving\nattributes at earlier layers correlates with better accuracy. Moreover, LALMs\nheavily rely on querying auditory inputs for predicting attributes instead of\naggregating necessary information in hidden states at attribute-mentioning\npositions. Based on our findings, we demonstrate a method to enhance LALMs. Our\nresults offer insights into auditory attribute processing, paving the way for\nfuture improvements.", "published": "2025-06-05 15:22:47", "link": "http://arxiv.org/abs/2506.05140v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Information Locality as an Inductive Bias for Neural Language Models", "abstract": "Inductive biases are inherent in every machine learning system, shaping how\nmodels generalize from finite data. In the case of neural language models\n(LMs), debates persist as to whether these biases align with or diverge from\nhuman processing constraints. To address this issue, we propose a quantitative\nframework that allows for controlled investigations into the nature of these\nbiases. Within our framework, we introduce $m$-local entropy$\\unicode{x2013}$an\ninformation-theoretic measure derived from average lossy-context\nsurprisal$\\unicode{x2013}$that captures the local uncertainty of a language by\nquantifying how effectively the $m-1$ preceding symbols disambiguate the next\nsymbol. In experiments on both perturbed natural language corpora and languages\ndefined by probabilistic finite-state automata (PFSAs), we show that languages\nwith higher $m$-local entropy are more difficult for Transformer and LSTM LMs\nto learn. These results suggest that neural LMs, much like humans, are highly\nsensitive to the local statistical structure of a language.", "published": "2025-06-05 15:21:05", "link": "http://arxiv.org/abs/2506.05136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiCoRe: Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning", "abstract": "Zero-shot Event Detection (ED), the task of identifying event mentions in\nnatural language text without any training data, is critical for document\nunderstanding in specialized domains. Understanding the complex event ontology,\nextracting domain-specific triggers from the passage, and structuring them\nappropriately overloads and limits the utility of Large Language Models (LLMs)\nfor zero-shot ED. To this end, we propose DiCoRe, a divergent-convergent\nreasoning framework that decouples the task of ED using Dreamer and Grounder.\nDreamer encourages divergent reasoning through open-ended event discovery,\nwhich helps to boost event coverage. Conversely, Grounder introduces convergent\nreasoning to align the free-form predictions with the task-specific\ninstructions using finite-state machine guided constrained decoding.\nAdditionally, an LLM-Judge verifies the final outputs to ensure high precision.\nThrough extensive experiments on six datasets across five domains and nine\nLLMs, we demonstrate how DiCoRe consistently outperforms prior zero-shot,\ntransfer-learning, and reasoning baselines, achieving 4-7% average F1 gains\nover the best baseline -- establishing DiCoRe as a strong zero-shot ED\nframework.", "published": "2025-06-05 15:16:14", "link": "http://arxiv.org/abs/2506.05128v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The NTNU System at the S&I Challenge 2025 SLA Open Track", "abstract": "A recent line of research on spoken language assessment (SLA) employs neural\nmodels such as BERT and wav2vec 2.0 (W2V) to evaluate speaking proficiency\nacross linguistic and acoustic modalities. Although both models effectively\ncapture features relevant to oral competence, each exhibits modality-specific\nlimitations. BERT-based methods rely on ASR transcripts, which often fail to\ncapture prosodic and phonetic cues for SLA. In contrast, W2V-based methods\nexcel at modeling acoustic features but lack semantic interpretability. To\novercome these limitations, we propose a system that integrates W2V with Phi-4\nmultimodal large language model (MLLM) through a score fusion strategy. The\nproposed system achieves a root mean square error (RMSE) of 0.375 on the\nofficial test set of the Speak & Improve Challenge 2025, securing second place\nin the competition. For comparison, the RMSEs of the top-ranked, third-ranked,\nand official baseline systems are 0.364, 0.384, and 0.444, respectively.", "published": "2025-06-05 15:09:23", "link": "http://arxiv.org/abs/2506.05121v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CL-ISR: A Contrastive Learning and Implicit Stance Reasoning Framework for Misleading Text Detection on Social Media", "abstract": "Misleading text detection on social media platforms is a critical research\narea, as these texts can lead to public misunderstanding, social panic and even\neconomic losses. This paper proposes a novel framework - CL-ISR (Contrastive\nLearning and Implicit Stance Reasoning), which combines contrastive learning\nand implicit stance reasoning, to improve the detection accuracy of misleading\ntexts on social media. First, we use the contrastive learning algorithm to\nimprove the model's learning ability of semantic differences between truthful\nand misleading texts. Contrastive learning could help the model to better\ncapture the distinguishing features between different categories by\nconstructing positive and negative sample pairs. This approach enables the\nmodel to capture distinguishing features more effectively, particularly in\nlinguistically complicated situations. Second, we introduce the implicit stance\nreasoning module, to explore the potential stance tendencies in the text and\ntheir relationships with related topics. This method is effective for\nidentifying content that misleads through stance shifting or emotional\nmanipulation, because it can capture the implicit information behind the text.\nFinally, we integrate these two algorithms together to form a new framework,\nCL-ISR, which leverages the discriminative power of contrastive learning and\nthe interpretive depth of stance reasoning to significantly improve detection\neffect.", "published": "2025-06-05 14:52:28", "link": "http://arxiv.org/abs/2506.05107v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretable Multimodal Framework for Human-Centered Street Assessment: Integrating Visual-Language Models for Perceptual Urban Diagnostics", "abstract": "While objective street metrics derived from imagery or GIS have become\nstandard in urban analytics, they remain insufficient to capture subjective\nperceptions essential to inclusive urban design. This study introduces a novel\nMultimodal Street Evaluation Framework (MSEF) that fuses a vision transformer\n(VisualGLM-6B) with a large language model (GPT-4), enabling interpretable\ndual-output assessment of streetscapes. Leveraging over 15,000 annotated\nstreet-view images from Harbin, China, we fine-tune the framework using LoRA\nand P-Tuning v2 for parameter-efficient adaptation. The model achieves an F1\nscore of 0.84 on objective features and 89.3 percent agreement with aggregated\nresident perceptions, validated across stratified socioeconomic geographies.\nBeyond classification accuracy, MSEF captures context-dependent contradictions:\nfor instance, informal commerce boosts perceived vibrancy while simultaneously\nreducing pedestrian comfort. It also identifies nonlinear and semantically\ncontingent patterns -- such as the divergent perceptual effects of\narchitectural transparency across residential and commercial zones -- revealing\nthe limits of universal spatial heuristics. By generating natural-language\nrationales grounded in attention mechanisms, the framework bridges sensory data\nwith socio-affective inference, enabling transparent diagnostics aligned with\nSDG 11. This work offers both methodological innovation in urban perception\nmodeling and practical utility for planning systems seeking to reconcile\ninfrastructural precision with lived experience.", "published": "2025-06-05 14:34:04", "link": "http://arxiv.org/abs/2506.05087v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Parking, Perception, and Retail: Street-Level Determinants of Community Vitality in Harbin", "abstract": "The commercial vitality of community-scale streets in Chinese cities is\nshaped by complex interactions between vehicular accessibility, environmental\nquality, and pedestrian perception. This study proposes an interpretable,\nimage-based framework to examine how street-level features -- including parked\nvehicle density, greenery, cleanliness, and street width -- impact retail\nperformance and user satisfaction in Harbin, China. Leveraging street view\nimagery and a multimodal large language model (VisualGLM-6B), we construct a\nCommunity Commercial Vitality Index (CCVI) from Meituan and Dianping data and\nanalyze its relationship with spatial attributes extracted via GPT-4-based\nperception modeling. Our findings reveal that while moderate vehicle presence\nmay enhance commercial access, excessive on-street parking -- especially in\nnarrow streets -- erodes walkability and reduces both satisfaction and\nshop-level pricing. In contrast, streets with higher perceived greenery and\ncleanliness show significantly greater satisfaction scores but only weak\nassociations with pricing. Street width moderates the effects of vehicle\npresence, underscoring the importance of spatial configuration. These results\ndemonstrate the value of integrating AI-assisted perception with urban\nmorphological analysis to capture non-linear and context-sensitive drivers of\ncommercial success. This study advances both theoretical and methodological\nfrontiers by highlighting the conditional role of vehicle activity in\nneighborhood commerce and demonstrating the feasibility of multimodal AI for\nperceptual urban diagnostics. The implications extend to urban design, parking\nmanagement, and scalable planning tools for community revitalization.", "published": "2025-06-05 14:28:48", "link": "http://arxiv.org/abs/2506.05080v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation", "abstract": "Self-harm detection on social media is critical for early intervention and\nmental health support, yet remains challenging due to the subtle,\ncontext-dependent nature of such expressions. Identifying self-harm intent aids\nsuicide prevention by enabling timely responses, but current large language\nmodels (LLMs) struggle to interpret implicit cues in casual language and\nemojis. This work enhances LLMs' comprehension of self-harm by distinguishing\nintent through nuanced language-emoji interplay. We present the Centennial\nEmoji Sensitivity Matrix (CESM-100), a curated set of 100 emojis with\ncontextual self-harm interpretations and the Self-Harm Identification aNd\nintent Extraction with Supportive emoji sensitivity (SHINES) dataset, offering\ndetailed annotations for self-harm labels, casual mentions (CMs), and serious\nintents (SIs). Our unified framework: a) enriches inputs using CESM-100; b)\nfine-tunes LLMs for multi-task learning: self-harm detection (primary) and\nCM/SI span detection (auxiliary); c) generates explainable rationales for\nself-harm predictions. We evaluate the framework on three state-of-the-art\nLLMs-Llama 3, Mental-Alpaca, and MentalLlama, across zero-shot, few-shot, and\nfine-tuned scenarios. By coupling intent differentiation with contextual cues,\nour approach commendably enhances LLM performance in both detection and\nexplanation tasks, effectively addressing the inherent ambiguity in self-harm\nsignals. The SHINES dataset, CESM-100 and codebase are publicly available at:\nhttps://www.iitp.ac.in/~ai-nlp-ml/resources.html#SHINES .", "published": "2025-06-05 14:19:48", "link": "http://arxiv.org/abs/2506.05073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RIVAL: Reinforcement Learning with Iterative and Adversarial Optimization for Machine Translation", "abstract": "Large language models (LLMs) possess strong multilingual capabilities, and\ncombining Reinforcement Learning from Human Feedback (RLHF) with translation\ntasks has shown great potential. However, we observe that this paradigm\nperforms unexpectedly poorly when applied to colloquial subtitle translation\ntasks. In this work, we investigate this issue and find that the offline reward\nmodel (RM) gradually diverges from the online LLM due to distributional shift,\nultimately leading to undesirable training outcomes. To address this, we\npropose RIVAL, an adversarial training framework that formulates the process as\na min-max game between the RM and the LLM. RIVAL iteratively updates the both\nmodels, with the RM trained to distinguish strong from weak translations\n(qualitative preference reward), and the LLM trained to enhance its translation\nfor closing this gap. To stabilize training and improve generalizability, we\nalso incorporate quantitative preference reward (e.g., BLEU) into the RM,\nenabling reference-free quality modeling aligned with human evaluation. Through\nextensive experiments, we demonstrate that the proposed adversarial training\nframework significantly improves upon translation baselines.", "published": "2025-06-05 14:18:21", "link": "http://arxiv.org/abs/2506.05070v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does It Make Sense to Speak of Introspection in Large Language Models?", "abstract": "Large language models (LLMs) exhibit compelling linguistic behaviour, and\nsometimes offer self-reports, that is to say statements about their own nature,\ninner workings, or behaviour. In humans, such reports are often attributed to a\nfaculty of introspection and are typically linked to consciousness. This raises\nthe question of how to interpret self-reports produced by LLMs, given their\nincreasing linguistic fluency and cognitive capabilities. To what extent (if\nany) can the concept of introspection be meaningfully applied to LLMs? Here, we\npresent and critique two examples of apparent introspective self-report from\nLLMs. In the first example, an LLM attempts to describe the process behind its\nown ``creative'' writing, and we argue this is not a valid example of\nintrospection. In the second example, an LLM correctly infers the value of its\nown temperature parameter, and we argue that this can be legitimately\nconsidered a minimal example of introspection, albeit one that is (presumably)\nnot accompanied by conscious experience.", "published": "2025-06-05 14:13:54", "link": "http://arxiv.org/abs/2506.05068v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Debatable Intelligence: Benchmarking LLM Judges via Debate Speech Evaluation", "abstract": "We introduce Debate Speech Evaluation as a novel and challenging benchmark\nfor assessing LLM judges. Evaluating debate speeches requires a deep\nunderstanding of the speech at multiple levels, including argument strength and\nrelevance, the coherence and organization of the speech, the appropriateness of\nits style and tone, and so on. This task involves a unique set of cognitive\nabilities that have previously received limited attention in systematic LLM\nbenchmarking. To explore such skills, we leverage a dataset of over 600\nmeticulously annotated debate speeches and present the first in-depth analysis\nof how state-of-the-art LLMs compare to human judges on this task. Our findings\nreveal a nuanced picture: while larger models can approximate individual human\njudgments in some respects, they differ substantially in their overall judgment\nbehavior. We also investigate the ability of frontier LLMs to generate\npersuasive, opinionated speeches, showing that models may perform at a human\nlevel on this task.", "published": "2025-06-05 14:06:51", "link": "http://arxiv.org/abs/2506.05062v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TALL -- A Trainable Architecture for Enhancing LLM Performance in Low-Resource Languages", "abstract": "Large Language Models (LLMs) excel in high-resource languages but struggle\nwith low-resource languages due to limited training data. This paper presents\nTALL (Trainable Architecture for Enhancing LLM Performance in Low-Resource\nLanguages), which integrates an LLM with two bilingual translation models. TALL\ntransforms low-resource inputs into high-resource representations, leveraging\nthe LLM's capabilities while preserving linguistic features through dimension\nalignment layers and custom transformers. Our experiments on Hebrew demonstrate\nsignificant improvements over several baselines, including direct use, naive\ntranslation, and fine-tuning approaches. The architecture employs a\nparameter-efficient strategy, freezing pre-trained components while training\nonly lightweight adapter modules, balancing computational efficiency with\nperformance gains.", "published": "2025-06-05 14:02:12", "link": "http://arxiv.org/abs/2506.05057v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic Robustness Stress Testing of LLMs as Mathematical Problem Solvers", "abstract": "Large language models (LLMs) have achieved distinguished performance on\nvarious reasoning-intensive tasks. However, LLMs might still face the\nchallenges of robustness issues and fail unexpectedly in some simple reasoning\ntasks. Previous works evaluate the LLM robustness with hand-crafted templates\nor a limited set of perturbation rules, indicating potential data contamination\nin pre-training or fine-tuning datasets. In this work, inspired by stress\ntesting in software engineering, we propose a novel framework, Automatic\nRobustness Checker (AR-Checker), to generate mathematical problem variants that\nmaintain the semantic meanings of the original one but might fail the LLMs. The\nAR-Checker framework generates mathematical problem variants through\nmulti-round parallel streams of LLM-based rewriting and verification. Our\nframework can generate benchmark variants dynamically for each LLM, thus\nminimizing the risk of data contamination. Experiments on GSM8K and MATH-500\ndemonstrate the strong performance of AR-Checker on mathematical tasks. We also\nevaluate AR-Checker on benchmarks beyond mathematics, including MMLU, MMLU-Pro,\nand CommonsenseQA, where it also achieves strong performance, further proving\nthe effectiveness of AR-Checker.", "published": "2025-06-05 13:42:39", "link": "http://arxiv.org/abs/2506.05038v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controlling Summarization Length Through EOS Token Weighting", "abstract": "Controlling the length of generated text can be crucial in various\ntext-generation tasks, including summarization. Existing methods often require\ncomplex model alterations, limiting compatibility with pre-trained models. We\naddress these limitations by developing a simple approach for controlling the\nlength of automatic text summaries by increasing the importance of correctly\npredicting the EOS token in the cross-entropy loss computation. The proposed\nmethodology is agnostic to architecture and decoding algorithms and orthogonal\nto other inference-time techniques to control the generation length. We tested\nit with encoder-decoder and modern GPT-style LLMs, and show that this method\ncan control generation length, often without affecting the quality of the\nsummary.", "published": "2025-06-05 13:25:28", "link": "http://arxiv.org/abs/2506.05017v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow Development", "abstract": "We introduce ComfyUI-Copilot, a large language model-powered plugin designed\nto enhance the usability and efficiency of ComfyUI, an open-source platform for\nAI-driven art creation. Despite its flexibility and user-friendly interface,\nComfyUI can present challenges to newcomers, including limited documentation,\nmodel misconfigurations, and the complexity of workflow design. ComfyUI-Copilot\naddresses these challenges by offering intelligent node and model\nrecommendations, along with automated one-click workflow construction. At its\ncore, the system employs a hierarchical multi-agent framework comprising a\ncentral assistant agent for task delegation and specialized worker agents for\ndifferent usages, supported by our curated ComfyUI knowledge bases to\nstreamline debugging and deployment. We validate the effectiveness of\nComfyUI-Copilot through both offline quantitative evaluations and online user\nfeedback, showing that it accurately recommends nodes and accelerates workflow\ndevelopment. Additionally, use cases illustrate that ComfyUI-Copilot lowers\nentry barriers for beginners and enhances workflow efficiency for experienced\nusers. The ComfyUI-Copilot installation package and a demo video are available\nat https://github.com/AIDC-AI/ComfyUI-Copilot.", "published": "2025-06-05 13:20:50", "link": "http://arxiv.org/abs/2506.05010v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View", "abstract": "Despite the great potential of large language models(LLMs) in machine\ncomprehension, it is still disturbing to fully count on them in real-world\nscenarios. This is probably because there is no rational explanation for\nwhether the comprehension process of LLMs is aligned with that of experts. In\nthis paper, we propose SCOP to carefully examine how LLMs perform during the\ncomprehension process from a cognitive view. Specifically, it is equipped with\na systematical definition of five requisite skills during the comprehension\nprocess, a strict framework to construct testing data for these skills, and a\ndetailed analysis of advanced open-sourced and closed-sourced LLMs using the\ntesting data. With SCOP, we find that it is still challenging for LLMs to\nperform an expert-level comprehension process. Even so, we notice that LLMs\nshare some similarities with experts, e.g., performing better at comprehending\nlocal information than global information. Further analysis reveals that LLMs\ncan be somewhat unreliable -- they might reach correct answers through flawed\ncomprehension processes. Based on SCOP, we suggest that one direction for\nimproving LLMs is to focus more on the comprehension process, ensuring all\ncomprehension skills are thoroughly developed during training.", "published": "2025-06-05 13:10:24", "link": "http://arxiv.org/abs/2506.05000v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Storage-Efficient Visual Document Retrieval: An Empirical Study on Reducing Patch-Level Embeddings", "abstract": "Despite the strong performance of ColPali/ColQwen2 in Visualized Document\nRetrieval (VDR), it encodes each page into multiple patch-level embeddings and\nleads to excessive memory usage. This empirical study investigates methods to\nreduce patch embeddings per page at minimum performance degradation. We\nevaluate two token-reduction strategies: token pruning and token merging.\nRegarding token pruning, we surprisingly observe that a simple random strategy\noutperforms other sophisticated pruning methods, though still far from\nsatisfactory. Further analysis reveals that pruning is inherently unsuitable\nfor VDR as it requires removing certain page embeddings without query-specific\ninformation. Turning to token merging (more suitable for VDR), we search for\nthe optimal combinations of merging strategy across three dimensions and\ndevelop Light-ColPali/ColQwen2. It maintains 98.2% of retrieval performance\nwith only 11.8% of original memory usage, and preserves 94.6% effectiveness at\n2.8% memory footprint. We expect our empirical findings and resulting\nLight-ColPali/ColQwen2 offer valuable insights and establish a competitive\nbaseline for future research towards efficient VDR.", "published": "2025-06-05 13:06:01", "link": "http://arxiv.org/abs/2506.04997v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Better Semi-supervised Learning for Multi-domain ASR Through Incremental Retraining and Data Filtering", "abstract": "Fine-tuning pretrained ASR models for specific domains is challenging when\nlabeled data is scarce. But unlabeled audio and labeled data from related\ndomains are often available. We propose an incremental semi-supervised learning\npipeline that first integrates a small in-domain labeled set and an auxiliary\ndataset from a closely related domain, achieving a relative improvement of 4%\nover no auxiliary data. Filtering based on multi-model consensus or named\nentity recognition (NER) is then applied to select and iteratively refine\npseudo-labels, showing slower performance saturation compared to random\nselection. Evaluated on the multi-domain Wow call center and Fisher English\ncorpora, it outperforms single-step fine-tuning. Consensus-based filtering\noutperforms other methods, providing up to 22.3% relative improvement on Wow\nand 24.8% on Fisher over single-step fine-tuning with random selection. NER is\nthe second-best filter, providing competitive performance at a lower\ncomputational cost.", "published": "2025-06-05 12:53:20", "link": "http://arxiv.org/abs/2506.04981v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "From Struggle (06-2024) to Mastery (02-2025) LLMs Conquer Advanced Algorithm Exams and Pave the Way for Editorial Generation", "abstract": "This paper presents a comprehensive evaluation of the performance of\nstate-of-the-art Large Language Models (LLMs) on challenging university-level\nalgorithms exams. By testing multiple models on both a Romanian exam and its\nhigh-quality English translation, we analyze LLMs' problem-solving\ncapabilities, consistency, and multilingual performance. Our empirical study\nreveals that the most recent models not only achieve scores comparable to\ntop-performing students but also demonstrate robust reasoning skills on\ncomplex, multi-step algorithmic challenges, even though difficulties remain\nwith graph-based tasks. Building on these findings, we explore the potential of\nLLMs to support educational environments through the generation of high-quality\neditorial content, offering instructors a powerful tool to enhance student\nfeedback. The insights and best practices discussed herein pave the way for\nfurther integration of generative AI in advanced algorithm education.", "published": "2025-06-05 12:41:20", "link": "http://arxiv.org/abs/2506.04965v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ConECT Dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT", "abstract": "Neural Machine Translation (NMT) has improved translation by using\nTransformer-based models, but it still struggles with word ambiguity and\ncontext. This problem is especially important in domain-specific applications,\nwhich often have problems with unclear sentences or poor data quality. Our\nresearch explores how adding information to models can improve translations in\nthe context of e-commerce data. To this end we create ConECT -- a new\nCzech-to-Polish e-commerce product translation dataset coupled with images and\nproduct metadata consisting of 11,400 sentence pairs. We then investigate and\ncompare different methods that are applicable to context-aware translation. We\ntest a vision-language model (VLM), finding that visual context aids\ntranslation quality. Additionally, we explore the incorporation of contextual\ninformation into text-to-text models, such as the product's category path or\nimage descriptions. The results of our study demonstrate that the incorporation\nof contextual information leads to an improvement in the quality of machine\ntranslation. We make the new dataset publicly available.", "published": "2025-06-05 12:02:01", "link": "http://arxiv.org/abs/2506.04929v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simulating LLM-to-LLM Tutoring for Multilingual Math Feedback", "abstract": "Large language models (LLMs) have demonstrated the ability to generate\nformative feedback and instructional hints in English, making them increasingly\nrelevant for AI-assisted education. However, their ability to provide effective\ninstructional support across different languages, especially for mathematically\ngrounded reasoning tasks, remains largely unexamined. In this work, we present\nthe first large-scale simulation of multilingual tutor-student interactions\nusing LLMs. A stronger model plays the role of the tutor, generating feedback\nin the form of hints, while a weaker model simulates the student. We explore\n352 experimental settings across 11 typologically diverse languages, four\nstate-of-the-art LLMs, and multiple prompting strategies to assess whether\nlanguage-specific feedback leads to measurable learning gains. Our study\nexamines how student input language, teacher feedback language, model choice,\nand language resource level jointly influence performance. Results show that\nmultilingual hints can significantly improve learning outcomes, particularly in\nlow-resource languages when feedback is aligned with the student's native\nlanguage. These findings offer practical insights for developing multilingual,\nLLM-based educational tools that are both effective and inclusive.", "published": "2025-06-05 11:53:04", "link": "http://arxiv.org/abs/2506.04920v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Practitioner's Guide to Building ASR Models for Low-Resource Languages: A Case Study on Scottish Gaelic", "abstract": "An effective approach to the development of ASR systems for low-resource\nlanguages is to fine-tune an existing multilingual end-to-end model. When the\noriginal model has been trained on large quantities of data from many\nlanguages, fine-tuning can be effective with limited training data, even when\nthe language in question was not present in the original training data. The\nfine-tuning approach has been encouraged by the availability of public-domain\nE2E models and is widely believed to lead to state-of-the-art results. This\npaper, however, challenges that belief. We show that an approach combining\nhybrid HMMs with self-supervised models can yield substantially better\nperformance with limited training data. This combination allows better\nutilisation of all available speech and text data through continued\nself-supervised pre-training and semi-supervised training. We benchmark our\napproach on Scottish Gaelic, achieving WER reductions of 32% relative over our\nbest fine-tuned Whisper model.", "published": "2025-06-05 11:52:08", "link": "http://arxiv.org/abs/2506.04915v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Dissecting Long Reasoning Models: An Empirical Study", "abstract": "Despite recent progress in training long-context reasoning models via\nreinforcement learning (RL), several open questions and counterintuitive\nbehaviors remain. This work focuses on three key aspects: (1) We systematically\nanalyze the roles of positive and negative samples in RL, revealing that\npositive samples mainly facilitate data fitting, whereas negative samples\nsignificantly enhance generalization and robustness. Interestingly, training\nsolely on negative samples can rival standard RL training performance. (2) We\nidentify substantial data inefficiency in group relative policy optimization,\nwhere over half of the samples yield zero advantage. To address this, we\nexplore two straightforward strategies, including relative length rewards and\noffline sample injection, to better leverage these data and enhance reasoning\nefficiency and capability. (3) We investigate unstable performance across\nvarious reasoning models and benchmarks, attributing instability to uncertain\nproblems with ambiguous outcomes, and demonstrate that multiple evaluation runs\nmitigate this issue.", "published": "2025-06-05 11:47:10", "link": "http://arxiv.org/abs/2506.04913v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "When Thinking LLMs Lie: Unveiling the Strategic Deception in Representations of Reasoning Models", "abstract": "The honesty of large language models (LLMs) is a critical alignment\nchallenge, especially as advanced systems with chain-of-thought (CoT) reasoning\nmay strategically deceive humans. Unlike traditional honesty issues on LLMs,\nwhich could be possibly explained as some kind of hallucination, those models'\nexplicit thought paths enable us to study strategic deception--goal-driven,\nintentional misinformation where reasoning contradicts outputs. Using\nrepresentation engineering, we systematically induce, detect, and control such\ndeception in CoT-enabled LLMs, extracting \"deception vectors\" via Linear\nArtificial Tomography (LAT) for 89% detection accuracy. Through activation\nsteering, we achieve a 40% success rate in eliciting context-appropriate\ndeception without explicit prompts, unveiling the specific honesty-related\nissue of reasoning models and providing tools for trustworthy AI alignment.", "published": "2025-06-05 11:44:19", "link": "http://arxiv.org/abs/2506.04909v1", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Verbose ListOps (VLO): Beyond Long Context -- Unmasking LLM's Reasoning Blind Spots", "abstract": "Large Language Models (LLMs), whilst great at extracting facts from text,\nstruggle with nested narrative reasoning. Existing long context and multi-hop\nQA benchmarks inadequately test this, lacking realistic distractors or failing\nto decouple context length from reasoning complexity, masking a fundamental LLM\nlimitation. We introduce Verbose ListOps, a novel benchmark that\nprogrammatically transposes ListOps computations into lengthy, coherent\nstories. This uniquely forces internal computation and state management of\nnested reasoning problems by withholding intermediate results, and offers\nfine-grained controls for both narrative size \\emph{and} reasoning difficulty.\nWhilst benchmarks like LongReason (2025) advance approaches for synthetically\nexpanding the context size of multi-hop QA problems, Verbose ListOps pinpoints\na specific LLM vulnerability: difficulty in state management for nested\nsub-reasoning amongst semantically-relevant, distracting narrative. Our\nexperiments show that leading LLMs (e.g., OpenAI o4, Gemini 2.5 Pro) collapse\nin performance on Verbose ListOps at modest (~10k token) narrative lengths,\ndespite effortlessly solving raw ListOps equations. Addressing this failure is\nparamount for real-world text interpretation which requires identifying key\nreasoning points, tracking conceptual intermediate results, and filtering\nirrelevant information. Verbose ListOps, and its extensible generation\nframework thus enables targeted reasoning enhancements beyond mere\ncontext-window expansion; a critical step to automating the world's knowledge\nwork.", "published": "2025-06-05 11:41:05", "link": "http://arxiv.org/abs/2506.04907v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ICPC-Eval: Probing the Frontiers of LLM Reasoning with Competitive Programming Contests", "abstract": "With the significant progress of large reasoning models in complex coding and\nreasoning tasks, existing benchmarks, like LiveCodeBench and CodeElo, are\ninsufficient to evaluate the coding capabilities of large language models\n(LLMs) in real competition environments. Moreover, current evaluation metrics\nsuch as Pass@K fail to capture the reflective abilities of reasoning models. To\naddress these challenges, we propose \\textbf{ICPC-Eval}, a top-level\ncompetitive coding benchmark designed to probing the frontiers of LLM\nreasoning. ICPC-Eval includes 118 carefully curated problems from 11 recent\nICPC contests held in various regions of the world, offering three key\ncontributions: 1) A challenging realistic ICPC competition scenario, featuring\na problem type and difficulty distribution consistent with actual contests. 2)\nA robust test case generation method and a corresponding local evaluation\ntoolkit, enabling efficient and accurate local evaluation. 3) An effective\ntest-time scaling evaluation metric, Refine@K, which allows iterative repair of\nsolutions based on execution feedback. The results underscore the significant\nchallenge in evaluating complex reasoning abilities: top-tier reasoning models\nlike DeepSeek-R1 often rely on multi-turn code feedback to fully unlock their\nin-context reasoning potential when compared to non-reasoning counterparts.\nFurthermore, despite recent advancements in code generation, these models still\nlag behind top-performing human teams. We release the benchmark at:\nhttps://github.com/RUCAIBox/Slow_Thinking_with_LLMs", "published": "2025-06-05 11:20:37", "link": "http://arxiv.org/abs/2506.04894v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Effectiveness of Linguistic Knowledge in Pretrained Language Models: A Case Study of Universal Dependencies", "abstract": "Universal Dependencies (UD), while widely regarded as the most successful\nlinguistic framework for cross-lingual syntactic representation, remains\nunderexplored in terms of its effectiveness. This paper addresses this gap by\nintegrating UD into pretrained language models and assesses if UD can improve\ntheir performance on a cross-lingual adversarial paraphrase identification\ntask. Experimental results show that incorporation of UD yields significant\nimprovements in accuracy and $F_1$ scores, with average gains of 3.85\\% and\n6.08\\% respectively. These enhancements reduce the performance gap between\npretrained models and large language models in some language pairs, and even\noutperform the latter in some others. Furthermore, the UD-based similarity\nscore between a given language and English is positively correlated to the\nperformance of models in that language. Both findings highlight the validity\nand potential of UD in out-of-domain tasks.", "published": "2025-06-05 11:10:14", "link": "http://arxiv.org/abs/2506.04887v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompting LLMs: Length Control for Isometric Machine Translation", "abstract": "In this study, we explore the effectiveness of isometric machine translation\nacross multiple language pairs (En$\\to$De, En$\\to$Fr, and En$\\to$Es) under the\nconditions of the IWSLT Isometric Shared Task 2022. Using eight open-source\nlarge language models (LLMs) of varying sizes, we investigate how different\nprompting strategies, varying numbers of few-shot examples, and demonstration\nselection influence translation quality and length control. We discover that\nthe phrasing of instructions, when aligned with the properties of the provided\ndemonstrations, plays a crucial role in controlling the output length. Our\nexperiments show that LLMs tend to produce shorter translations only when\npresented with extreme examples, while isometric demonstrations often lead to\nthe models disregarding length constraints. While few-shot prompting generally\nenhances translation quality, further improvements are marginal across 5, 10,\nand 20-shot settings. Finally, considering multiple outputs allows to notably\nimprove overall tradeoff between the length and quality, yielding\nstate-of-the-art performance for some language pairs.", "published": "2025-06-05 10:24:08", "link": "http://arxiv.org/abs/2506.04855v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights", "abstract": "Integrating Artificial Intelligence (AI) in educational settings has brought\nnew learning approaches, transforming the practices of both students and\neducators. Among the various technologies driving this transformation, Large\nLanguage Models (LLMs) have emerged as powerful tools for creating educational\nmaterials and question answering, but there are still space for new\napplications. Educators commonly use Multiple-Choice Questions (MCQs) to assess\nstudent knowledge, but manually generating these questions is\nresource-intensive and requires significant time and cognitive effort. In our\nopinion, LLMs offer a promising solution to these challenges. This paper\npresents a novel comparative analysis of three widely known LLMs - Llama 2,\nMistral, and GPT-3.5 - to explore their potential for creating informative and\nchallenging MCQs. In our approach, we do not rely on the knowledge of the LLM,\nbut we inject the knowledge into the prompt to contrast the hallucinations,\ngiving the educators control over the test's source text, too. Our experiment\ninvolving 21 educators shows that GPT-3.5 generates the most effective MCQs\nacross several known metrics. Additionally, it shows that there is still some\nreluctance to adopt AI in the educational field. This study sheds light on the\npotential of LLMs to generate MCQs and improve the educational experience,\nproviding valuable insights for the future.", "published": "2025-06-05 10:21:49", "link": "http://arxiv.org/abs/2506.04851v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MockConf: A Student Interpretation Dataset: Analysis, Word- and Span-level Alignment and Baselines", "abstract": "In simultaneous interpreting, an interpreter renders a source speech into\nanother language with a very short lag, much sooner than sentences are\nfinished. In order to understand and later reproduce this dynamic and complex\ntask automatically, we need dedicated datasets and tools for analysis,\nmonitoring, and evaluation, such as parallel speech corpora, and tools for\ntheir automatic annotation. Existing parallel corpora of translated texts and\nassociated alignment algorithms hardly fill this gap, as they fail to model\nlong-range interactions between speech segments or specific types of\ndivergences (e.g., shortening, simplification, functional generalization)\nbetween the original and interpreted speeches. In this work, we introduce\nMockConf, a student interpreting dataset that was collected from Mock\nConferences run as part of the students' curriculum. This dataset contains 7\nhours of recordings in 5 European languages, transcribed and aligned at the\nlevel of spans and words. We further implement and release InterAlign, a modern\nweb-based annotation tool for parallel word and span annotations on long\ninputs, suitable for aligning simultaneous interpreting. We propose metrics for\nthe evaluation and a baseline for automatic alignment. Dataset and tools are\nreleased to the community.", "published": "2025-06-05 10:16:15", "link": "http://arxiv.org/abs/2506.04848v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models", "abstract": "Large Reasoning Models (LRMs) extend large language models with explicit,\nmulti-step reasoning traces to enhance transparency and performance on complex\ntasks. However, these reasoning traces can be redundant or logically\ninconsistent, making them a new source of hallucination that is difficult to\ndetect. Existing hallucination detection methods focus primarily on\nanswer-level uncertainty and often fail to detect hallucinations or logical\ninconsistencies arising from the model's reasoning trace. This oversight is\nparticularly problematic for LRMs, where the explicit thinking trace is not\nonly an important support to the model's decision-making process but also a key\nsource of potential hallucination. To this end, we propose RACE (Reasoning and\nAnswer Consistency Evaluation), a novel framework specifically tailored for\nhallucination detection in LRMs. RACE operates by extracting essential\nreasoning steps and computing four diagnostic signals: inter-sample consistency\nof reasoning traces, entropy-based answer uncertainty, semantic alignment\nbetween reasoning and answers, and internal coherence of reasoning. This joint\nanalysis enables fine-grained hallucination detection even when the final\nanswer appears correct. Experiments across datasets and different LLMs\ndemonstrate that RACE outperforms existing hallucination detection baselines,\noffering a robust and generalizable solution for evaluating LRMs. Our code is\navailable at: https://github.com/bebr2/RACE.", "published": "2025-06-05 09:54:04", "link": "http://arxiv.org/abs/2506.04832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From EHRs to Patient Pathways: Scalable Modeling of Longitudinal Health Trajectories with LLMs", "abstract": "Healthcare systems face significant challenges in managing and interpreting\nvast, heterogeneous patient data for personalized care. Existing approaches\noften focus on narrow use cases with a limited feature space, overlooking the\ncomplex, longitudinal interactions needed for a holistic understanding of\npatient health. In this work, we propose a novel approach to patient pathway\nmodeling by transforming diverse electronic health record (EHR) data into a\nstructured representation and designing a holistic pathway prediction model,\nEHR2Path, optimized to predict future health trajectories. Further, we\nintroduce a novel summary mechanism that embeds long-term temporal context into\ntopic-specific summary tokens, improving performance over text-only models,\nwhile being much more token-efficient. EHR2Path demonstrates strong performance\nin both next time-step prediction and longitudinal simulation, outperforming\ncompetitive baselines. It enables detailed simulations of patient trajectories,\ninherently targeting diverse evaluation tasks, such as forecasting vital signs,\nlab test results, or length-of-stay, opening a path towards predictive and\npersonalized healthcare.", "published": "2025-06-05 09:54:01", "link": "http://arxiv.org/abs/2506.04831v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Reasoning-Based Approach to Cryptic Crossword Clue Solving", "abstract": "Cryptic crossword clues are challenging language tasks for which new test\nsets are released daily by major newspapers on a global basis. Each cryptic\nclue contains both the definition of the answer to be placed in the crossword\ngrid (in common with regular crosswords), and 'wordplay' that proves that the\nanswer is correct (i.e. a human solver can be confident that an answer is\ncorrect without needing crossing words as confirmation). This work describes an\nLLM-based reasoning system built from open-licensed components that solves\ncryptic clues by (i) hypothesising answers; (ii) proposing wordplay\nexplanations; and (iii) using a verifier system that operates on codified\nreasoning steps. Overall, this system establishes a new state-of-the-art\nperformance on the challenging Cryptonite dataset of clues from The Times and\nThe Telegraph newspapers in the UK. Because each proved solution is expressed\nin Python, interpretable wordplay reasoning for proven answers is available for\ninspection.", "published": "2025-06-05 09:43:28", "link": "http://arxiv.org/abs/2506.04824v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating Vision-Language and Large Language Models for Automated Student Assessment in Indonesian Classrooms", "abstract": "Although vision-language and large language models (VLM and LLM) offer\npromising opportunities for AI-driven educational assessment, their\neffectiveness in real-world classroom settings, particularly in\nunderrepresented educational contexts, remains underexplored. In this study, we\nevaluated the performance of a state-of-the-art VLM and several LLMs on 646\nhandwritten exam responses from grade 4 students in six Indonesian schools,\ncovering two subjects: Mathematics and English. These sheets contain more than\n14K student answers that span multiple choice, short answer, and essay\nquestions. Assessment tasks include grading these responses and generating\npersonalized feedback. Our findings show that the VLM often struggles to\naccurately recognize student handwriting, leading to error propagation in\ndownstream LLM grading. Nevertheless, LLM-generated feedback retains some\nutility, even when derived from imperfect input, although limitations in\npersonalization and contextual relevance persist.", "published": "2025-06-05 09:41:09", "link": "http://arxiv.org/abs/2506.04822v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Design of intelligent proofreading system for English translation based on CNN and BERT", "abstract": "Since automatic translations can contain errors that require substantial\nhuman post-editing, machine translation proofreading is essential for improving\nquality. This paper proposes a novel hybrid approach for robust proofreading\nthat combines convolutional neural networks (CNN) with Bidirectional Encoder\nRepresentations from Transformers (BERT). In order to extract semantic\ninformation from phrases and expressions, CNN uses a variety of convolution\nkernel filters to capture local n-gram patterns. In the meanwhile, BERT creates\ncontext-rich representations of whole sequences by utilizing stacked\nbidirectional transformer encoders. Using BERT's attention processes, the\nintegrated error detection component relates tokens to spot translation\nirregularities including word order problems and omissions. The correction\nmodule then uses parallel English-German alignment and GRU decoder models in\nconjunction with translation memory to propose logical modifications that\nmaintain original meaning. A unified end-to-end training process optimized for\npost-editing performance is applied to the whole pipeline. The multi-domain\ncollection of WMT and the conversational dialogues of Open-Subtitles are two of\nthe English-German parallel corpora used to train the model. Multiple loss\nfunctions supervise detection and correction capabilities. Experiments attain a\n90% accuracy, 89.37% F1, and 16.24% MSE, exceeding recent proofreading\ntechniques by over 10% overall. Comparative benchmarking demonstrates\nstate-of-the-art performance in identifying and coherently rectifying\nmistranslations and omissions.", "published": "2025-06-05 09:34:42", "link": "http://arxiv.org/abs/2506.04811v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dissecting Logical Reasoning in LLMs: A Fine-Grained Evaluation and Supervision Study", "abstract": "Logical reasoning is a core capability for many applications of large\nlanguage models (LLMs), yet existing benchmarks often rely solely on\nfinal-answer accuracy, failing to capture the quality and structure of the\nreasoning process. We propose FineLogic, a fine-grained evaluation framework\nthat assesses logical reasoning across three dimensions: overall benchmark\naccuracy, stepwise soundness, and representation-level alignment. In addition,\nto better understand how reasoning capabilities emerge, we conduct a\ncomprehensive study on the effects of supervision format during fine-tuning. We\nconstruct four supervision styles (one natural language and three symbolic\nvariants) and train LLMs under each. Our findings reveal that natural language\nsupervision yields strong generalization even on out-of-distribution and\nlong-context tasks, while symbolic reasoning styles promote more structurally\nsound and atomic inference chains. Further, our representation-level probing\nshows that fine-tuning primarily improves reasoning behaviors through\nstep-by-step generation, rather than enhancing shortcut prediction or\ninternalized correctness. Together, our framework and analysis provide a more\nrigorous and interpretable lens for evaluating and improving logical reasoning\nin LLMs.", "published": "2025-06-05 09:34:12", "link": "http://arxiv.org/abs/2506.04810v1", "categories": ["cs.CL", "cs.AI", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Towards LLM-Centric Multimodal Fusion: A Survey on Integration Strategies and Techniques", "abstract": "The rapid progress of Multimodal Large Language Models(MLLMs) has transformed\nthe AI landscape. These models combine pre-trained LLMs with various modality\nencoders. This integration requires a systematic understanding of how different\nmodalities connect to the language backbone. Our survey presents an LLM-centric\nanalysis of current approaches. We examine methods for transforming and\naligning diverse modal inputs into the language embedding space. This addresses\na significant gap in existing literature. We propose a classification framework\nfor MLLMs based on three key dimensions. First, we examine architectural\nstrategies for modality integration. This includes both the specific\nintegration mechanisms and the fusion level. Second, we categorize\nrepresentation learning techniques as either joint or coordinate\nrepresentations. Third, we analyze training paradigms, including training\nstrategies and objective functions. By examining 125 MLLMs developed between\n2021 and 2025, we identify emerging patterns in the field. Our taxonomy\nprovides researchers with a structured overview of current integration\ntechniques. These insights aim to guide the development of more robust\nmultimodal integration strategies for future models built on pre-trained\nfoundations.", "published": "2025-06-05 09:14:41", "link": "http://arxiv.org/abs/2506.04788v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark", "abstract": "Speech inherently contains rich acoustic information that extends far beyond\nthe textual language. In real-world spoken language understanding, effective\ninterpretation often requires integrating semantic meaning (e.g., content),\nparalinguistic features (e.g., emotions, speed, pitch) and phonological\ncharacteristics (e.g., prosody, intonation, rhythm), which are embedded in\nspeech. While recent multimodal Speech Large Language Models (SpeechLLMs) have\ndemonstrated remarkable capabilities in processing audio information, their\nability to perform fine-grained perception and complex reasoning in natural\nspeech remains largely unexplored. To address this gap, we introduce MMSU, a\ncomprehensive benchmark designed specifically for understanding and reasoning\nin spoken language. MMSU comprises 5,000 meticulously curated\naudio-question-answer triplets across 47 distinct tasks. To ground our\nbenchmark in linguistic theory, we systematically incorporate a wide range of\nlinguistic phenomena, including phonetics, prosody, rhetoric, syntactics,\nsemantics, and paralinguistics. Through a rigorous evaluation of 14 advanced\nSpeechLLMs, we identify substantial room for improvement in existing models,\nhighlighting meaningful directions for future optimization. MMSU establishes a\nnew standard for comprehensive assessment of spoken language understanding,\nproviding valuable insights for developing more sophisticated human-AI speech\ninteraction systems. MMSU benchmark is available at\nhttps://huggingface.co/datasets/ddwang2000/MMSU. Evaluation Code is available\nat https://github.com/dingdongwang/MMSU_Bench.", "published": "2025-06-05 09:09:36", "link": "http://arxiv.org/abs/2506.04779v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Interpretation of Political Opinions in Large Language Models", "abstract": "Studies of LLMs' political opinions mainly rely on evaluations of their\nopen-ended responses. Recent work indicates that there is a misalignment\nbetween LLMs' responses and their internal intentions. This motivates us to\nprobe LLMs' internal mechanisms and help uncover their internal political\nstates. Additionally, we found that the analysis of LLMs' political opinions\noften relies on single-axis concepts, which can lead to concept confounds. In\nthis work, we extend the single-axis to multi-dimensions and apply\ninterpretable representation engineering techniques for more transparent LLM\npolitical concept learning. Specifically, we designed a four-dimensional\npolitical learning framework and constructed a corresponding dataset for\nfine-grained political concept vector learning. These vectors can be used to\ndetect and intervene in LLM internals. Experiments are conducted on eight\nopen-source LLMs with three representation engineering techniques. Results show\nthese vectors can disentangle political concept confounds. Detection tasks\nvalidate the semantic meaning of the vectors and show good generalization and\nrobustness in OOD settings. Intervention Experiments show these vectors can\nintervene in LLMs to generate responses with different political leanings.", "published": "2025-06-05 09:06:59", "link": "http://arxiv.org/abs/2506.04774v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Identifying Reliable Evaluation Metrics for Scientific Text Revision", "abstract": "Evaluating text revision in scientific writing remains a challenge, as\ntraditional metrics such as ROUGE and BERTScore primarily focus on similarity\nrather than capturing meaningful improvements. In this work, we analyse and\nidentify the limitations of these metrics and explore alternative evaluation\nmethods that better align with human judgments. We first conduct a manual\nannotation study to assess the quality of different revisions. Then, we\ninvestigate reference-free evaluation metrics from related NLP domains.\nAdditionally, we examine LLM-as-a-judge approaches, analysing their ability to\nassess revisions with and without a gold reference. Our results show that LLMs\neffectively assess instruction-following but struggle with correctness, while\ndomain-specific metrics provide complementary insights. We find that a hybrid\napproach combining LLM-as-a-judge evaluation and task-specific metrics offers\nthe most reliable assessment of revision quality.", "published": "2025-06-05 09:00:23", "link": "http://arxiv.org/abs/2506.04772v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GOLFer: Smaller LM-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval", "abstract": "Large language models (LLMs)-based query expansion for information retrieval\naugments queries with generated hypothetical documents with LLMs. However, its\nperformance relies heavily on the scale of the language models (LMs),\nnecessitating larger, more advanced LLMs. This approach is costly,\ncomputationally intensive, and often has limited accessibility. To address\nthese limitations, we introduce GOLFer - Smaller LMs-Generated Documents\nHallucination Filter & Combiner - a novel method leveraging smaller open-source\nLMs for query expansion. GOLFer comprises two modules: a hallucination filter\nand a documents combiner. The former detects and removes non-factual and\ninconsistent sentences in generated documents, a common issue with smaller LMs,\nwhile the latter combines the filtered content with the query using a weight\nvector to balance their influence. We evaluate GOLFer alongside dominant\nLLM-based query expansion methods on three web search and ten low-resource\ndatasets. Experimental results demonstrate that GOLFer consistently outperforms\nother methods using smaller LMs, and maintains competitive performance against\nmethods using large-size LLMs, demonstrating its effectiveness.", "published": "2025-06-05 08:45:48", "link": "http://arxiv.org/abs/2506.04762v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using Large Language Model-based Query Expansion", "abstract": "Large Language Models (LLMs) have shown potential in generating hypothetical\ndocuments for query expansion, thereby enhancing information retrieval\nperformance. However, the efficacy of this method is highly dependent on the\nquality of the generated documents, which often requires complex prompt\nstrategies and the integration of advanced dense retrieval techniques. This can\nbe both costly and computationally intensive. To mitigate these limitations, we\nexplore the use of zero-shot LLM-based query expansion to improve sparse\nretrieval, particularly for learned sparse retrievers. We introduce a novel\nfusion ranking framework, Exp4Fuse, which enhances the performance of sparse\nretrievers through an indirect application of zero-shot LLM-based query\nexpansion. Exp4Fuse operates by simultaneously considering two retrieval\nroutes-one based on the original query and the other on the LLM-augmented\nquery. It then generates two ranked lists using a sparse retriever and fuses\nthem using a modified reciprocal rank fusion method. We conduct extensive\nevaluations of Exp4Fuse against leading LLM-based query expansion methods and\nadvanced retrieval techniques on three MS MARCO-related datasets and seven\nlow-resource datasets. Experimental results reveal that Exp4Fuse not only\nsurpasses existing LLM-based query expansion methods in enhancing sparse\nretrievers but also, when combined with advanced sparse retrievers, achieves\nSOTA results on several benchmarks. This highlights the superior performance\nand effectiveness of Exp4Fuse in improving query expansion for sparse\nretrieval.", "published": "2025-06-05 08:44:34", "link": "http://arxiv.org/abs/2506.04760v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Lifelong Evolution: Collaborative Learning between Large and Small Language Models for Continuous Emergent Fake News Detection", "abstract": "The widespread dissemination of fake news on social media has significantly\nimpacted society, resulting in serious consequences. Conventional deep learning\nmethodologies employing small language models (SLMs) suffer from extensive\nsupervised training requirements and difficulties adapting to evolving news\nenvironments due to data scarcity and distribution shifts. Large language\nmodels (LLMs), despite robust zero-shot capabilities, fall short in accurately\ndetecting fake news owing to outdated knowledge and the absence of suitable\ndemonstrations. In this paper, we propose a novel Continuous Collaborative\nEmergent Fake News Detection (C$^2$EFND) framework to address these challenges.\nThe C$^2$EFND framework strategically leverages both LLMs' generalization power\nand SLMs' classification expertise via a multi-round collaborative learning\nframework. We further introduce a lifelong knowledge editing module based on a\nMixture-of-Experts architecture to incrementally update LLMs and a replay-based\ncontinue learning method to ensure SLMs retain prior knowledge without\nretraining entirely. Extensive experiments on Pheme and Twitter16 datasets\ndemonstrate that C$^2$EFND significantly outperforms existed methods,\neffectively improving detection accuracy and adaptability in continuous\nemergent fake news scenarios.", "published": "2025-06-05 08:17:55", "link": "http://arxiv.org/abs/2506.04739v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluation is All You Need: Strategic Overclaiming of LLM Reasoning Capabilities Through Evaluation Design", "abstract": "Reasoning models represented by the Deepseek-R1-Distill series have been\nwidely adopted by the open-source community due to their strong performance in\nmathematics, science, programming, and other domains. However, our study\nreveals that their benchmark evaluation results are subject to significant\nfluctuations caused by various factors. Subtle differences in evaluation\nconditions can lead to substantial variations in results. Similar phenomena are\nobserved in other open-source inference models fine-tuned based on the\nDeepseek-R1-Distill series, as well as in the QwQ-32B model, making their\nclaimed performance improvements difficult to reproduce reliably. Therefore, we\nadvocate for the establishment of a more rigorous paradigm for model\nperformance evaluation and present our empirical assessments of the\nDeepseek-R1-Distill series models.", "published": "2025-06-05 08:09:11", "link": "http://arxiv.org/abs/2506.04734v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SPARTA ALIGNMENT: Collectively Aligning Multiple Language Models through Combat", "abstract": "We propose SPARTA ALIGNMENT, an algorithm to collectively align multiple LLMs\nthrough competition and combat. To complement a single model's lack of\ndiversity in generation and biases in evaluation, multiple LLMs form a \"sparta\ntribe\" to compete against each other in fulfilling instructions while serving\nas judges for the competition of others. For each iteration, one instruction\nand two models are selected for a duel, the other models evaluate the two\nresponses, and their evaluation scores are aggregated through a adapted\nelo-ranking based reputation system, where winners/losers of combat gain/lose\nweight in evaluating others. The peer-evaluated combat results then become\npreference pairs where the winning response is preferred over the losing one,\nand all models learn from these preferences at the end of each iteration.\nSPARTA ALIGNMENT enables the self-evolution of multiple LLMs in an iterative\nand collective competition process. Extensive experiments demonstrate that\nSPARTA ALIGNMENT outperforms initial models and 4 self-alignment baselines\nacross 10 out of 12 tasks and datasets with 7.0% average improvement. Further\nanalysis reveals that SPARTA ALIGNMENT generalizes more effectively to unseen\ntasks and leverages the expertise diversity of participating models to produce\nmore logical, direct and informative outputs.", "published": "2025-06-05 07:51:23", "link": "http://arxiv.org/abs/2506.04721v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IIITH-BUT system for IWSLT 2025 low-resource Bhojpuri to Hindi speech translation", "abstract": "This paper presents the submission of IIITH-BUT to the IWSLT 2025 shared task\non speech translation for the low-resource Bhojpuri-Hindi language pair. We\nexplored the impact of hyperparameter optimisation and data augmentation\ntechniques on the performance of the SeamlessM4T model fine-tuned for this\nspecific task. We systematically investigated a range of hyperparameters\nincluding learning rate schedules, number of update steps, warm-up steps, label\nsmoothing, and batch sizes; and report their effect on translation quality. To\naddress data scarcity, we applied speed perturbation and SpecAugment and\nstudied their effect on translation quality. We also examined the use of\ncross-lingual signal through joint training with Marathi and Bhojpuri speech\ndata. Our experiments reveal that careful selection of hyperparameters and the\napplication of simple yet effective augmentation techniques significantly\nimprove performance in low-resource settings. We also analysed the translation\nhypotheses to understand various kinds of errors that impacted the translation\nquality in terms of BLEU.", "published": "2025-06-05 07:38:01", "link": "http://arxiv.org/abs/2506.04714v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LLM-based phoneme-to-grapheme for phoneme-based speech recognition", "abstract": "In automatic speech recognition (ASR), phoneme-based multilingual\npre-training and crosslingual fine-tuning is attractive for its high data\nefficiency and competitive results compared to subword-based models. However,\nWeighted Finite State Transducer (WFST) based decoding is limited by its\ncomplex pipeline and inability to leverage large language models (LLMs).\nTherefore, we propose LLM-based phoneme-to-grapheme (LLM-P2G) decoding for\nphoneme-based ASR, consisting of speech-to-phoneme (S2P) and\nphoneme-to-grapheme (P2G). A challenge is that there seems to have information\nloss in cascading S2P and P2G. To address this challenge, we propose two\ntraining strategies: data augmentation with noisy phonemes (DANP), and\nrandomized top-$K$ marginalized (TKM) training and decoding. Our experimental\nresults show that LLM-P2G outperforms WFST-based systems in crosslingual ASR\nfor Polish and German, by relative WER reductions of 3.6% and 6.9%\nrespectively.", "published": "2025-06-05 07:35:55", "link": "http://arxiv.org/abs/2506.04711v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Accelerated Test-Time Scaling with Model-Free Speculative Sampling", "abstract": "Language models have demonstrated remarkable capabilities in reasoning tasks\nthrough test-time scaling techniques like best-of-N sampling and tree search.\nHowever, these approaches often demand substantial computational resources,\ncreating a critical trade-off between performance and efficiency. We introduce\nSTAND (STochastic Adaptive N-gram Drafting), a novel model-free speculative\ndecoding approach that leverages the inherent redundancy in reasoning\ntrajectories to achieve significant acceleration without compromising accuracy.\nOur analysis reveals that reasoning paths frequently reuse similar reasoning\npatterns, enabling efficient model-free token prediction without requiring\nseparate draft models. By introducing stochastic drafting and preserving\nprobabilistic information through a memory-efficient logit-based N-gram module,\ncombined with optimized Gumbel-Top-K sampling and data-driven tree\nconstruction, STAND significantly improves token acceptance rates. Extensive\nevaluations across multiple models and reasoning tasks (AIME-2024,\nGPQA-Diamond, and LiveCodeBench) demonstrate that STAND reduces inference\nlatency by 60-65% compared to standard autoregressive decoding while\nmaintaining accuracy. Furthermore, STAND outperforms state-of-the-art\nspeculative decoding methods by 14-28% in throughput and shows strong\nperformance even in single-trajectory scenarios, reducing inference latency by\n48-58%. As a model-free approach, STAND can be applied to any existing language\nmodel without additional training, being a powerful plug-and-play solution for\naccelerating language model reasoning.", "published": "2025-06-05 07:31:18", "link": "http://arxiv.org/abs/2506.04708v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cracking the Code: Enhancing Implicit Hate Speech Detection through Coding Classification", "abstract": "The internet has become a hotspot for hate speech (HS), threatening societal\nharmony and individual well-being. While automatic detection methods perform\nwell in identifying explicit hate speech (ex-HS), they struggle with more\nsubtle forms, such as implicit hate speech (im-HS). We tackle this problem by\nintroducing a new taxonomy for im-HS detection, defining six encoding\nstrategies named codetypes. We present two methods for integrating codetypes\ninto im-HS detection: 1) prompting large language models (LLMs) directly to\nclassify sentences based on generated responses, and 2) using LLMs as encoders\nwith codetypes embedded during the encoding process. Experiments show that the\nuse of codetypes improves im-HS detection in both Chinese and English datasets,\nvalidating the effectiveness of our approach across different languages.", "published": "2025-06-05 07:15:21", "link": "http://arxiv.org/abs/2506.04693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models", "abstract": "Scaling laws predict that the performance of large language models improves\nwith increasing model size and data size. In practice, pre-training has been\nrelying on massive web crawls, using almost all data sources publicly available\non the internet so far. However, this pool of natural data does not grow at the\nsame rate as the compute supply. Furthermore, the availability of high-quality\ntexts is even more limited: data filtering pipelines often remove up to 99% of\nthe initial web scrapes to achieve state-of-the-art. To address the \"data wall\"\nof pre-training scaling, our work explores ways to transform and recycle data\ndiscarded in existing filtering processes. We propose REWIRE, REcycling the Web\nwith guIded REwrite, a method to enrich low-quality documents so that they\ncould become useful for training. This in turn allows us to increase the\nrepresentation of synthetic data in the final pre-training set. Experiments at\n1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw\ntexts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points\nimprovement respectively across 22 diverse tasks, compared to training on only\nfiltered web data. Training on the raw-synthetic data mix is also more\neffective than having access to 2x web data. Through further analysis, we\ndemonstrate that about 82% of the mixed in texts come from transforming\nlower-quality documents that would otherwise be discarded. REWIRE also\noutperforms related approaches of generating synthetic data, including\nWikipedia-style paraphrasing, question-answer synthesizing and knowledge\nextraction. These results suggest that recycling web texts holds the potential\nfor being a simple and effective approach for scaling pre-training data.", "published": "2025-06-05 07:12:12", "link": "http://arxiv.org/abs/2506.04689v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MMRefine: Unveiling the Obstacles to Robust Refinement in Multimodal Large Language Models", "abstract": "This paper introduces MMRefine, a MultiModal Refinement benchmark designed to\nevaluate the error refinement capabilities of Multimodal Large Language Models\n(MLLMs). As the emphasis shifts toward enhancing reasoning during inference,\nMMRefine provides a framework that evaluates MLLMs' abilities to detect and\ncorrect errors across six distinct scenarios beyond just comparing final\naccuracy before and after refinement. Furthermore, the benchmark analyzes the\nrefinement performance by categorizing errors into six error types. Experiments\nwith various open and closed MLLMs reveal bottlenecks and factors impeding\nrefinement performance, highlighting areas for improvement in effective\nreasoning enhancement. Our code and dataset are publicly available at\nhttps://github.com/naver-ai/MMRefine.", "published": "2025-06-05 07:11:36", "link": "http://arxiv.org/abs/2506.04688v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Urania: Differentially Private Insights into AI Use", "abstract": "We introduce $Urania$, a novel framework for generating insights about LLM\nchatbot interactions with rigorous differential privacy (DP) guarantees. The\nframework employs a private clustering mechanism and innovative keyword\nextraction methods, including frequency-based, TF-IDF-based, and LLM-guided\napproaches. By leveraging DP tools such as clustering, partition selection, and\nhistogram-based summarization, $Urania$ provides end-to-end privacy protection.\nOur evaluation assesses lexical and semantic content preservation, pair\nsimilarity, and LLM-based metrics, benchmarking against a non-private\nClio-inspired pipeline (Tamkin et al., 2024). Moreover, we develop a simple\nempirical privacy evaluation that demonstrates the enhanced robustness of our\nDP pipeline. The results show the framework's ability to extract meaningful\nconversational insights while maintaining stringent user privacy, effectively\nbalancing data utility with privacy preservation.", "published": "2025-06-05 07:00:31", "link": "http://arxiv.org/abs/2506.04681v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Normative Conflicts and Shallow AI Alignment", "abstract": "The progress of AI systems such as large language models (LLMs) raises\nincreasingly pressing concerns about their safe deployment. This paper examines\nthe value alignment problem for LLMs, arguing that current alignment strategies\nare fundamentally inadequate to prevent misuse. Despite ongoing efforts to\ninstill norms such as helpfulness, honesty, and harmlessness in LLMs through\nfine-tuning based on human preferences, they remain vulnerable to adversarial\nattacks that exploit conflicts between these norms. I argue that this\nvulnerability reflects a fundamental limitation of existing alignment methods:\nthey reinforce shallow behavioral dispositions rather than endowing LLMs with a\ngenuine capacity for normative deliberation. Drawing from on research in moral\npsychology, I show how humans' ability to engage in deliberative reasoning\nenhances their resilience against similar adversarial tactics. LLMs, by\ncontrast, lack a robust capacity to detect and rationally resolve normative\nconflicts, leaving them susceptible to manipulation; even recent advances in\nreasoning-focused LLMs have not addressed this vulnerability. This ``shallow\nalignment'' problem carries significant implications for AI safety and\nregulation, suggesting that current approaches are insufficient for mitigating\npotential harms posed by increasingly capable AI systems.", "published": "2025-06-05 06:57:28", "link": "http://arxiv.org/abs/2506.04679v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EMO-Debias: Benchmarking Gender Debiasing Techniques in Multi-Label Speech Emotion Recognition", "abstract": "Speech emotion recognition (SER) systems often exhibit gender bias. However,\nthe effectiveness and robustness of existing debiasing methods in such\nmulti-label scenarios remain underexplored. To address this gap, we present\nEMO-Debias, a large-scale comparison of 13 debiasing methods applied to\nmulti-label SER. Our study encompasses techniques from pre-processing,\nregularization, adversarial learning, biased learners, and distributionally\nrobust optimization. Experiments conducted on acted and naturalistic emotion\ndatasets, using WavLM and XLSR representations, evaluate each method under\nconditions of gender imbalance. Our analysis quantifies the trade-offs between\nfairness and accuracy, identifying which approaches consistently reduce gender\nperformance gaps without compromising overall model performance. The findings\nprovide actionable insights for selecting effective debiasing strategies and\nhighlight the impact of dataset distributions.", "published": "2025-06-05 05:48:31", "link": "http://arxiv.org/abs/2506.04652v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Flex-TravelPlanner: A Benchmark for Flexible Planning with Language Agents", "abstract": "Real-world planning problems require constant adaptation to changing\nrequirements and balancing of competing constraints. However, current\nbenchmarks for evaluating LLMs' planning capabilities primarily focus on\nstatic, single-turn scenarios. We introduce Flex-TravelPlanner, a benchmark\nthat evaluates language models' ability to reason flexibly in dynamic planning\nscenarios. Building on the TravelPlanner dataset~\\citep{xie2024travelplanner},\nwe introduce two novel evaluation settings: (1) sequential constraint\nintroduction across multiple turns, and (2) scenarios with explicitly\nprioritized competing constraints. Our analysis of GPT-4o and Llama 3.1 70B\nreveals several key findings: models' performance on single-turn tasks poorly\npredicts their ability to adapt plans across multiple turns; constraint\nintroduction order significantly affects performance; and models struggle with\nconstraint prioritization, often incorrectly favoring newly introduced lower\npriority preferences over existing higher-priority constraints. These findings\nhighlight the importance of evaluating LLMs in more realistic, dynamic planning\nscenarios and suggest specific directions for improving model performance on\ncomplex planning tasks. The code and dataset for our framework are publicly\navailable at https://github.com/juhyunohh/FlexTravelBench.", "published": "2025-06-05 05:31:50", "link": "http://arxiv.org/abs/2506.04649v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TaDA: Training-free recipe for Decoding with Adaptive KV Cache Compression and Mean-centering", "abstract": "The key-value (KV) cache in transformer models is a critical component for\nefficient decoding or inference, yet its memory demands scale poorly with\nsequence length, posing a major challenge for scalable deployment of large\nlanguage models. Among several approaches to KV cache compression, quantization\nof key and value activations has been widely explored. Most KV cache\nquantization methods still need to manage sparse and noncontiguous outliers\nseparately. To address this, we introduce TaDA, a training-free recipe for KV\ncache compression with quantization precision that adapts to error sensitivity\nacross layers and a mean centering to eliminate separate outlier handling. Our\napproach yields substantial accuracy improvements for multiple models\nsupporting various context lengths. Moreover, our approach does not need to\nseparately manage outlier elements -- a persistent hurdle in most traditional\nquantization methods. Experiments on standard benchmarks demonstrate that our\ntechnique reduces KV cache memory footprint to 27% of the original 16-bit\nbaseline while achieving comparable accuracy. Our method paves the way for\nscalable and high-performance reasoning in language models by potentially\nenabling inference for longer context length models, reasoning models, and\nlonger chain of thoughts.", "published": "2025-06-05 05:23:38", "link": "http://arxiv.org/abs/2506.04642v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ViCocktail: Automated Multi-Modal Data Collection for Vietnamese Audio-Visual Speech Recognition", "abstract": "Audio-Visual Speech Recognition (AVSR) has gained significant attention\nrecently due to its robustness against noise, which often challenges\nconventional speech recognition systems that rely solely on audio features.\nDespite this advantage, AVSR models remain limited by the scarcity of extensive\ndatasets, especially for most languages beyond English. Automated data\ncollection offers a promising solution. This work presents a practical approach\nto generate AVSR datasets from raw video, refining existing techniques for\nimproved efficiency and accessibility. We demonstrate its broad applicability\nby developing a baseline AVSR model for Vietnamese. Experiments show the\nautomatically collected dataset enables a strong baseline, achieving\ncompetitive performance with robust ASR in clean conditions and significantly\noutperforming them in noisy environments like cocktail parties. This efficient\nmethod provides a pathway to expand AVSR to more languages, particularly\nunder-resourced ones.", "published": "2025-06-05 05:13:01", "link": "http://arxiv.org/abs/2506.04635v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning", "abstract": "Empowering large language models (LLMs) with effective tool utilization\ncapabilities is crucial for enabling AI agents to solve complex problems.\nHowever, current models face two major limitations: (1) unreliable tool\nplanning and invocation due to low-quality instruction datasets (e.g.,\nwidespread hallucinated API calls), and (2) weak tool reflection abilities\n(over 90% of errors cannot be corrected) resulting from static imitation\nlearning. To address these critical limitations, we propose Tool-MVR, a novel\nTool-Augmented LLM that achieves comprehensive System 2 reasoning through two\nkey innovations. Specifically, we first introduce Multi-Agent Meta-Verification\n(MAMV), a systematic pipeline that rigorously validates APIs, queries, and\nreasoning trajectories to construct ToolBench-V, a new high-quality instruction\ndataset that addresses the limitation of unreliable tool planning and\ninvocation. Second, we propose Exploration-based Reflection Learning (EXPLORE),\nwhich enhances tool reflection capabilities by leveraging tool feedback through\na dynamic \"Error -> Reflection -> Correction\" learning paradigm, resulting in\nour reflection dataset ToolBench-R and addressing the critical weakness in tool\nreflection. Finally, we obtain Tool-MVR by finetuning open-source LLMs (e.g.,\nQwen-7B) on both ToolBench-V and ToolBench-R. Our experiments demonstrate that\nTool-MVR achieves state-of-the-art performance on StableToolBench, surpassing\nboth ToolLLM (by 23.9%) and GPT-4 (by 15.3%) while reducing API calls by 31.4%,\nwith strong generalization capabilities across unseen tools and scenarios.\nAdditionally, on our proposed RefineToolBench, the first benchmark specifically\ndesigned to evaluate tool reflection capabilities, Tool-MVR achieves a 58.9%\nerror correction rate, significantly outperforming ToolLLM's 9.1%.", "published": "2025-06-05 04:35:49", "link": "http://arxiv.org/abs/2506.04625v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Static Word Embeddings for Sentence Semantic Representation", "abstract": "We propose new static word embeddings optimised for sentence semantic\nrepresentation. We first extract word embeddings from a pre-trained Sentence\nTransformer, and improve them with sentence-level principal component analysis,\nfollowed by either knowledge distillation or contrastive learning. During\ninference, we represent sentences by simply averaging word embeddings, which\nrequires little computational cost. We evaluate models on both monolingual and\ncross-lingual tasks and show that our model substantially outperforms existing\nstatic models on sentence semantic tasks, and even rivals a basic Sentence\nTransformer model (SimCSE) on some data sets. Lastly, we perform a variety of\nanalyses and show that our method successfully removes word embedding\ncomponents that are irrelevant to sentence semantics, and adjusts the vector\nnorms based on the influence of words on sentence semantics.", "published": "2025-06-05 04:33:10", "link": "http://arxiv.org/abs/2506.04624v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Subjective Perspectives within Learned Representations Predict High-Impact Innovation", "abstract": "Existing studies of innovation emphasize the power of social structures to\nshape innovation capacity. Emerging machine learning approaches, however,\nenable us to model innovators' personal perspectives and interpersonal\ninnovation opportunities as a function of their prior trajectories of\nexperience. We theorize then quantify subjective perspectives and innovation\nopportunities based on innovator positions within the geometric space of\nconcepts inscribed by dynamic language representations. Using data on millions\nof scientists, inventors, writers, entrepreneurs, and Wikipedia contributors\nacross the creative domains of science, technology, film, entrepreneurship, and\nWikipedia, here we show that measured subjective perspectives anticipate what\nideas individuals and groups creatively attend to and successfully combine in\nfuture. When perspective and background diversity are decomposed as the angular\ndifference between collaborators' perspectives on their creation and between\ntheir experiences, the former consistently anticipates creative achievement\nwhile the latter portends its opposite, across all cases and time periods\nexamined. We analyze a natural experiment and simulate creative collaborations\nbetween AI (large language model) agents designed with various perspective and\nbackground diversity, which are consistent with our observational findings. We\nexplore mechanisms underlying these findings and identify how successful\ncollaborators leverage common language to weave together diverse experience\nobtained through trajectories of prior work that converge to provoke one\nanother and innovate. We explore the importance of these findings for team\nassembly and research policy.", "published": "2025-06-05 04:18:53", "link": "http://arxiv.org/abs/2506.04616v1", "categories": ["cs.CL", "stat.AP", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Revisiting Test-Time Scaling: A Survey and a Diversity-Aware Method for Efficient Reasoning", "abstract": "Test-Time Scaling (TTS) improves the reasoning performance of Large Language\nModels (LLMs) by allocating additional compute during inference. We conduct a\nstructured survey of TTS methods and categorize them into sampling-based,\nsearch-based, and trajectory optimization strategies. We observe that\nreasoning-optimized models often produce less diverse outputs, which limits TTS\neffectiveness. To address this, we propose ADAPT (A Diversity Aware Prefix\nfine-Tuning), a lightweight method that applies prefix tuning with a\ndiversity-focused data strategy. Experiments on mathematical reasoning tasks\nshow that ADAPT reaches 80% accuracy using eight times less compute than strong\nbaselines. Our findings highlight the essential role of generative diversity in\nmaximizing TTS effectiveness.", "published": "2025-06-05 04:02:17", "link": "http://arxiv.org/abs/2506.04611v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A MISMATCHED Benchmark for Scientific Natural Language Inference", "abstract": "Scientific Natural Language Inference (NLI) is the task of predicting the\nsemantic relation between a pair of sentences extracted from research articles.\nExisting datasets for this task are derived from various computer science (CS)\ndomains, whereas non-CS domains are completely ignored. In this paper, we\nintroduce a novel evaluation benchmark for scientific NLI, called MISMATCHED.\nThe new MISMATCHED benchmark covers three non-CS domains-PSYCHOLOGY,\nENGINEERING, and PUBLIC HEALTH, and contains 2,700 human annotated sentence\npairs. We establish strong baselines on MISMATCHED using both Pre-trained Small\nLanguage Models (SLMs) and Large Language Models (LLMs). Our best performing\nbaseline shows a Macro F1 of only 78.17% illustrating the substantial headroom\nfor future improvements. In addition to introducing the MISMATCHED benchmark,\nwe show that incorporating sentence pairs having an implicit scientific NLI\nrelation between them in model training improves their performance on\nscientific NLI. We make our dataset and code publicly available on GitHub.", "published": "2025-06-05 03:40:57", "link": "http://arxiv.org/abs/2506.04603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification", "abstract": "Chain-of-Thought (CoT) prompting has become the de facto method to elicit\nreasoning capabilities from large language models (LLMs). However, to mitigate\nhallucinations in CoT that are notoriously difficult to detect, current methods\nsuch as process reward models (PRMs) or self-consistency operate as opaque\nboxes and do not provide checkable evidence for their judgments, possibly\nlimiting their effectiveness. To address this issue, we draw inspiration from\nthe idea that \"the gold standard for supporting a mathematical claim is to\nprovide a proof\". We propose a retrospective, step-aware formal verification\nframework $Safe$. Rather than assigning arbitrary scores, we strive to\narticulate mathematical claims in formal mathematical language Lean 4 at each\nreasoning step and provide formal proofs to identify hallucinations. We\nevaluate our framework $Safe$ across multiple language models and various\nmathematical datasets, demonstrating a significant performance improvement\nwhile offering interpretable and verifiable evidence. We also propose\n$FormalStep$ as a benchmark for step correctness theorem proving with $30,809$\nformal statements. To the best of our knowledge, our work represents the first\nendeavor to utilize formal mathematical language Lean 4 for verifying natural\nlanguage content generated by LLMs, aligning with the reason why formal\nmathematical languages were created in the first place: to provide a robust\nfoundation for hallucination-prone human-written proofs.", "published": "2025-06-05 03:16:08", "link": "http://arxiv.org/abs/2506.04592v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models", "abstract": "We introduce LESS (Large Language Model Enhanced Semi-supervised Learning), a\nversatile framework that leverages Large Language Models (LLMs) to correct\npseudo labels generated from in-the-wild data. Within the LESS framework,\npseudo-labeled text from Automatic Speech Recognition (ASR) or Automatic Speech\nTranslation (AST) of the unsupervised data is refined by an LLM, and augmented\nby a data filtering strategy to optimize LLM knowledge transfer efficiency.\nExperiments on both Mandarin ASR and Spanish-to-English AST tasks show that\nLESS achieves a notable absolute WER reduction of 3.77% on the Wenet Speech\ntest set, as well as BLEU scores of 34.0 and 64.7 on Callhome and Fisher test\nsets respectively. These results validate the adaptability of LESS across\ndifferent languages, tasks, and domains. Ablation studies conducted with\nvarious LLMs and prompt configurations provide novel insights into leveraging\nLLM-derived knowledge for speech processing applications.", "published": "2025-06-05 03:00:04", "link": "http://arxiv.org/abs/2506.04586v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MuSciClaims: Multimodal Scientific Claim Verification", "abstract": "Assessing scientific claims requires identifying, extracting, and reasoning\nwith multimodal data expressed in information-rich figures in scientific\nliterature. Despite the large body of work in scientific QA, figure captioning,\nand other multimodal reasoning tasks over chart-based data, there are no\nreadily usable multimodal benchmarks that directly test claim verification\nabilities. To remedy this gap, we introduce a new benchmark MuSciClaims\naccompanied by diagnostics tasks. We automatically extract supported claims\nfrom scientific articles, which we manually perturb to produce contradicted\nclaims. The perturbations are designed to test for a specific set of claim\nverification capabilities. We also introduce a suite of diagnostic tasks that\nhelp understand model failures. Our results show most vision-language models\nare poor (~0.3-0.5 F1), with even the best model only achieving 0.77 F1. They\nare also biased towards judging claims as supported, likely misunderstanding\nnuanced perturbations within the claims. Our diagnostics show models are bad at\nlocalizing correct evidence within figures, struggle with aggregating\ninformation across modalities, and often fail to understand basic components of\nthe figure.", "published": "2025-06-05 02:59:51", "link": "http://arxiv.org/abs/2506.04585v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SUCEA: Reasoning-Intensive Retrieval for Adversarial Fact-checking through Claim Decomposition and Editing", "abstract": "Automatic fact-checking has recently received more attention as a means of\ncombating misinformation. Despite significant advancements, fact-checking\nsystems based on retrieval-augmented language models still struggle to tackle\nadversarial claims, which are intentionally designed by humans to challenge\nfact-checking systems. To address these challenges, we propose a training-free\nmethod designed to rephrase the original claim, making it easier to locate\nsupporting evidence. Our modular framework, SUCEA, decomposes the task into\nthree steps: 1) Claim Segmentation and Decontextualization that segments\nadversarial claims into independent sub-claims; 2) Iterative Evidence Retrieval\nand Claim Editing that iteratively retrieves evidence and edits the subclaim\nbased on the retrieved evidence; 3) Evidence Aggregation and Label Prediction\nthat aggregates all retrieved evidence and predicts the entailment label.\nExperiments on two challenging fact-checking datasets demonstrate that our\nframework significantly improves on both retrieval and entailment label\naccuracy, outperforming four strong claim-decomposition-based baselines.", "published": "2025-06-05 02:58:15", "link": "http://arxiv.org/abs/2506.04583v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Selecting Demonstrations for Many-Shot In-Context Learning via Gradient Matching", "abstract": "In-Context Learning (ICL) empowers Large Language Models (LLMs) for rapid\ntask adaptation without Fine-Tuning (FT), but its reliance on demonstration\nselection remains a critical challenge. While many-shot ICL shows promising\nperformance through scaled demonstrations, the selection method for many-shot\ndemonstrations remains limited to random selection in existing work. Since the\nconventional instance-level retrieval is not suitable for many-shot scenarios,\nwe hypothesize that the data requirements for in-context learning and\nfine-tuning are analogous. To this end, we introduce a novel gradient matching\napproach that selects demonstrations by aligning fine-tuning gradients between\nthe entire training set of the target task and the selected examples, so as to\napproach the learning effect on the entire training set within the selected\nexamples. Through gradient matching on relatively small models, e.g.,\nQwen2.5-3B or Llama3-8B, our method consistently outperforms random selection\non larger LLMs from 4-shot to 128-shot scenarios across 9 diverse datasets. For\ninstance, it surpasses random selection by 4% on Qwen2.5-72B and Llama3-70B,\nand by around 2% on 5 closed-source LLMs. This work unlocks more reliable and\neffective many-shot ICL, paving the way for its broader application.", "published": "2025-06-05 02:57:05", "link": "http://arxiv.org/abs/2506.04579v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are LLMs Reliable Translators of Logical Reasoning Across Lexically Diversified Contexts?", "abstract": "Neuro-symbolic approaches combining large language models (LLMs) with solvers\nexcels in logical reasoning problems need long reasoning chains. In this\nparadigm, LLMs serve as translators, converting natural language reasoning\nproblems into formal logic formulas. Then reliable symbolic solvers return\ncorrect solutions. Despite their success, we find that LLMs, as translators,\nstruggle to handle lexical diversification, a common linguistic phenomenon,\nindicating that LLMs as logic translators are unreliable in real-world\nscenarios. Moreover, existing logical reasoning benchmarks lack lexical\ndiversity, failing to challenge LLMs' ability to translate such text and thus\nobscuring this issue. In this work, we propose SCALe, a benchmark designed to\naddress this significant gap through **logic-invariant lexical\ndiversification**. By using LLMs to transform original benchmark datasets into\nlexically diversified but logically equivalent versions, we evaluate LLMs'\nability to consistently map diverse expressions to uniform logical symbols on\nthese new datasets. Experiments using SCALe further confirm that current LLMs\nexhibit deficiencies in this capability. Building directly on the deficiencies\nidentified through our benchmark, we propose a new method, MenTaL, to address\nthis limitation. This method guides LLMs to first construct a table unifying\ndiverse expressions before performing translation. Applying MenTaL through\nin-context learning and supervised fine-tuning (SFT) significantly improves the\nperformance of LLM translators on lexically diversified text. Our code is now\navailable at https://github.com/wufeiwuwoshihua/LexicalDiver.", "published": "2025-06-05 02:49:36", "link": "http://arxiv.org/abs/2506.04575v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning or Overthinking: Evaluating Large Language Models on Financial Sentiment Analysis", "abstract": "We investigate the effectiveness of large language models (LLMs), including\nreasoning-based and non-reasoning models, in performing zero-shot financial\nsentiment analysis. Using the Financial PhraseBank dataset annotated by domain\nexperts, we evaluate how various LLMs and prompting strategies align with\nhuman-labeled sentiment in a financial context. We compare three proprietary\nLLMs (GPT-4o, GPT-4.1, o3-mini) under different prompting paradigms that\nsimulate System 1 (fast and intuitive) or System 2 (slow and deliberate)\nthinking and benchmark them against two smaller models (FinBERT-Prosus,\nFinBERT-Tone) fine-tuned on financial sentiment analysis. Our findings suggest\nthat reasoning, either through prompting or inherent model design, does not\nimprove performance on this task. Surprisingly, the most accurate and\nhuman-aligned combination of model and method was GPT-4o without any\nChain-of-Thought (CoT) prompting. We further explore how performance is\nimpacted by linguistic complexity and annotation agreement levels, uncovering\nthat reasoning may introduce overthinking, leading to suboptimal predictions.\nThis suggests that for financial sentiment classification, fast, intuitive\n\"System 1\"-like thinking aligns more closely with human judgment compared to\n\"System 2\"-style slower, deliberative reasoning simulated by reasoning models\nor CoT prompting. Our results challenge the default assumption that more\nreasoning always leads to better LLM decisions, particularly in high-stakes\nfinancial applications.", "published": "2025-06-05 02:47:23", "link": "http://arxiv.org/abs/2506.04574v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Demonstrations of Integrity Attacks in Multi-Agent Systems", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding, code generation, and complex planning.\nSimultaneously, Multi-Agent Systems (MAS) have garnered attention for their\npotential to enable cooperation among distributed agents. However, from a\nmulti-party perspective, MAS could be vulnerable to malicious agents that\nexploit the system to serve self-interests without disrupting its core\nfunctionality. This work explores integrity attacks where malicious agents\nemploy subtle prompt manipulation to bias MAS operations and gain various\nbenefits. Four types of attacks are examined: \\textit{Scapegoater}, who\nmisleads the system monitor to underestimate other agents' contributions;\n\\textit{Boaster}, who misleads the system monitor to overestimate their own\nperformance; \\textit{Self-Dealer}, who manipulates other agents to adopt\ncertain tools; and \\textit{Free-Rider}, who hands off its own task to others.\nWe demonstrate that strategically crafted prompts can introduce systematic\nbiases in MAS behavior and executable instructions, enabling malicious agents\nto effectively mislead evaluation systems and manipulate collaborative agents.\nFurthermore, our attacks can bypass advanced LLM-based monitors, such as\nGPT-4o-mini and o3-mini, highlighting the limitations of current detection\nmechanisms. Our findings underscore the critical need for MAS architectures\nwith robust security protocols and content validation mechanisms, alongside\nmonitoring systems capable of comprehensive risk scenario assessment.", "published": "2025-06-05 02:44:49", "link": "http://arxiv.org/abs/2506.04572v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Clustering and Median Aggregation Improve Differentially Private Inference", "abstract": "Differentially private (DP) language model inference is an approach for\ngenerating private synthetic text. A sensitive input example is used to prompt\nan off-the-shelf large language model (LLM) to produce a similar example.\nMultiple examples can be aggregated together to formally satisfy the DP\nguarantee.\n  Prior work creates inference batches by sampling sensitive inputs uniformly\nat random. We show that uniform sampling degrades the quality of privately\ngenerated text, especially when the sensitive examples concern heterogeneous\ntopics.\n  We remedy this problem by clustering the input data before selecting\ninference batches. Next, we observe that clustering also leads to more similar\nnext-token predictions across inferences. We use this insight to introduce a\nnew algorithm that aggregates next token statistics by privately computing\nmedians instead of averages. This approach leverages the fact that the median\nhas decreased local sensitivity when next token predictions are similar,\nallowing us to state a data-dependent and ex-post DP guarantee about the\nprivacy properties of this algorithm. Finally, we demonstrate improvements in\nterms of representativeness metrics (e.g., MAUVE) as well as downstream task\nperformance. We show that our method produces high-quality synthetic data at\nsignificantly lower privacy cost than a previous state-of-the-art method.", "published": "2025-06-05 02:34:50", "link": "http://arxiv.org/abs/2506.04566v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "SSA-COMET: Do LLMs Outperform Learned Metrics in Evaluating MT for Under-Resourced African Languages?", "abstract": "Evaluating machine translation (MT) quality for under-resourced African\nlanguages remains a significant challenge, as existing metrics often suffer\nfrom limited language coverage and poor performance in low-resource settings.\nWhile recent efforts, such as AfriCOMET, have addressed some of the issues,\nthey are still constrained by small evaluation sets, a lack of publicly\navailable training data tailored to African languages, and inconsistent\nperformance in extremely low-resource scenarios. In this work, we introduce\nSSA-MTE, a large-scale human-annotated MT evaluation (MTE) dataset covering 13\nAfrican language pairs from the News domain, with over 63,000 sentence-level\nannotations from a diverse set of MT systems. Based on this data, we develop\nSSA-COMET and SSA-COMET-QE, improved reference-based and reference-free\nevaluation metrics. We also benchmark prompting-based approaches using\nstate-of-the-art LLMs like GPT-4o and Claude. Our experimental results show\nthat SSA-COMET models significantly outperform AfriCOMET and are competitive\nwith the strongest LLM (Gemini 2.5 Pro) evaluated in our study, particularly on\nlow-resource languages such as Twi, Luo, and Yoruba. All resources are released\nunder open licenses to support future research.", "published": "2025-06-05 02:16:56", "link": "http://arxiv.org/abs/2506.04557v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BSBench: will your LLM find the largest prime number?", "abstract": "We propose that benchmarking LLMs on questions which have no reasonable\nanswer actually isn't as silly as it sounds. We also present a benchmark that\nallows such testing and a method to modify the existing datasets, and discover\nthat existing models demonstrate a performance far from the perfect on such\nquestions. Our code and data artifacts are available at\nhttps://github.com/L3G5/impossible-bench", "published": "2025-06-05 00:59:16", "link": "http://arxiv.org/abs/2506.04535v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Refer to Anything with Vision-Language Prompts", "abstract": "Recent image segmentation models have advanced to segment images into\nhigh-quality masks for visual entities, and yet they cannot provide\ncomprehensive semantic understanding for complex queries based on both language\nand vision. This limitation reduces their effectiveness in applications that\nrequire user-friendly interactions driven by vision-language prompts. To bridge\nthis gap, we introduce a novel task of omnimodal referring expression\nsegmentation (ORES). In this task, a model produces a group of masks based on\narbitrary prompts specified by text only or text plus reference visual\nentities. To address this new challenge, we propose a novel framework to \"Refer\nto Any Segmentation Mask Group\" (RAS), which augments segmentation models with\ncomplex multimodal interactions and comprehension via a mask-centric large\nmultimodal model. For training and benchmarking ORES models, we create datasets\nMaskGroups-2M and MaskGroups-HQ to include diverse mask groups specified by\ntext and reference entities. Through extensive evaluation, we demonstrate\nsuperior performance of RAS on our new ORES task, as well as classic referring\nexpression segmentation (RES) and generalized referring expression segmentation\n(GRES) tasks. Project page: https://Ref2Any.github.io.", "published": "2025-06-05 17:59:51", "link": "http://arxiv.org/abs/2506.05342v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning", "abstract": "Realistic 3D indoor scene synthesis is vital for embodied AI and digital\ncontent creation. It can be naturally divided into two subtasks: object\ngeneration and layout generation. While recent generative models have\nsignificantly advanced object-level quality and controllability, layout\ngeneration remains challenging due to limited datasets. Existing methods either\noverfit to these datasets or rely on predefined constraints to optimize\nnumerical layout that sacrifice flexibility. As a result, they fail to generate\nscenes that are both open-vocabulary and aligned with fine-grained user\ninstructions. We introduce DirectLayout, a framework that directly generates\nnumerical 3D layouts from text descriptions using generalizable spatial\nreasoning of large language models (LLMs). DirectLayout decomposes the\ngeneration into three stages: producing a Bird's-Eye View (BEV) layout, lifting\nit into 3D space, and refining object placements. To enable explicit spatial\nreasoning and help the model grasp basic principles of object placement, we\nemploy Chain-of-Thought (CoT) Activation based on the 3D-Front dataset.\nAdditionally, we design CoT-Grounded Generative Layout Reward to enhance\ngeneralization and spatial planning. During inference, DirectLayout addresses\nasset-layout mismatches via Iterative Asset-Layout Alignment through in-context\nlearning. Extensive experiments demonstrate that DirectLayout achieves\nimpressive semantic consistency, generalization and physical plausibility.", "published": "2025-06-05 17:59:42", "link": "http://arxiv.org/abs/2506.05341v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Exploring Diffusion Transformer Designs via Grafting", "abstract": "Designing model architectures requires decisions such as selecting operators\n(e.g., attention, convolution) and configurations (e.g., depth, width).\nHowever, evaluating the impact of these decisions on model quality requires\ncostly pretraining, limiting architectural investigation. Inspired by how new\nsoftware is built on existing code, we ask: can new architecture designs be\nstudied using pretrained models? To this end, we present grafting, a simple\napproach for editing pretrained diffusion transformers (DiTs) to materialize\nnew architectures under small compute budgets. Informed by our analysis of\nactivation behavior and attention locality, we construct a testbed based on the\nDiT-XL/2 design to study the impact of grafting on model quality. Using this\ntestbed, we develop a family of hybrid designs via grafting: replacing softmax\nattention with gated convolution, local attention, and linear attention, and\nreplacing MLPs with variable expansion ratio and convolutional variants.\nNotably, many hybrid designs achieve good quality (FID: 2.38-2.64 vs. 2.27 for\nDiT-XL/2) using <2% pretraining compute. We then graft a text-to-image model\n(PixArt-Sigma), achieving a 1.43x speedup with less than a 2% drop in GenEval\nscore. Finally, we present a case study that restructures DiT-XL/2 by\nconverting every pair of sequential transformer blocks into parallel blocks via\ngrafting. This reduces model depth by 2x and yields better quality (FID: 2.77)\nthan other models of comparable depth. Together, we show that new diffusion\nmodel designs can be explored by grafting pretrained DiTs, with edits ranging\nfrom operator replacement to architecture restructuring. Code and grafted\nmodels: https://grafting.stanford.edu", "published": "2025-06-05 17:59:40", "link": "http://arxiv.org/abs/2506.05340v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Control Tax: The Price of Keeping AI in Check", "abstract": "The rapid integration of agentic AI into high-stakes real-world applications\nrequires robust oversight mechanisms. The emerging field of AI Control (AIC)\naims to provide such an oversight mechanism, but practical adoption depends\nheavily on implementation overhead. To study this problem better, we introduce\nthe notion of Control tax -- the operational and financial cost of integrating\ncontrol measures into AI pipelines. Our work makes three key contributions to\nthe field of AIC: (1) we introduce a theoretical framework that quantifies the\nControl Tax and maps classifier performance to safety assurances; (2) we\nconduct comprehensive evaluations of state-of-the-art language models in\nadversarial settings, where attacker models insert subtle backdoors into code\nwhile monitoring models attempt to detect these vulnerabilities; and (3) we\nprovide empirical financial cost estimates for control protocols and develop\noptimized monitoring strategies that balance safety and cost-effectiveness\nwhile accounting for practical constraints like auditing budgets. Our framework\nenables practitioners to make informed decisions by systematically connecting\nsafety guarantees with their costs, advancing AIC through principled economic\nfeasibility assessment across different deployment contexts.", "published": "2025-06-05 17:48:39", "link": "http://arxiv.org/abs/2506.05296v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Sample Complexity and Representation Ability of Test-time Scaling Paradigms", "abstract": "Test-time scaling paradigms have significantly advanced the capabilities of\nlarge language models (LLMs) on complex tasks. Despite their empirical success,\ntheoretical understanding of the sample efficiency of various test-time\nstrategies -- such as self-consistency, best-of-$n$, and self-correction --\nremains limited. In this work, we first establish a separation result between\ntwo repeated sampling strategies: self-consistency requires\n$\\Theta(1/\\Delta^2)$ samples to produce the correct answer, while best-of-$n$\nonly needs $\\Theta(1/\\Delta)$, where $\\Delta < 1$ denotes the probability gap\nbetween the correct and second most likely answers. Next, we present an\nexpressiveness result for the self-correction approach with verifier feedback:\nit enables Transformers to simulate online learning over a pool of experts at\ntest time. Therefore, a single Transformer architecture can provably solve\nmultiple tasks without prior knowledge of the specific task associated with a\nuser query, extending the representation theory of Transformers from\nsingle-task to multi-task settings. Finally, we empirically validate our\ntheoretical results, demonstrating the practical effectiveness of\nself-correction methods.", "published": "2025-06-05 17:48:19", "link": "http://arxiv.org/abs/2506.05295v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Rectified Point Flow: Generic Point Cloud Pose Estimation", "abstract": "We introduce Rectified Point Flow, a unified parameterization that formulates\npairwise point cloud registration and multi-part shape assembly as a single\nconditional generative problem. Given unposed point clouds, our method learns a\ncontinuous point-wise velocity field that transports noisy points toward their\ntarget positions, from which part poses are recovered. In contrast to prior\nwork that regresses part-wise poses with ad-hoc symmetry handling, our method\nintrinsically learns assembly symmetries without symmetry labels. Together with\na self-supervised encoder focused on overlapping points, our method achieves a\nnew state-of-the-art performance on six benchmarks spanning pairwise\nregistration and shape assembly. Notably, our unified formulation enables\neffective joint training on diverse datasets, facilitating the learning of\nshared geometric priors and consequently boosting accuracy. Project page:\nhttps://rectified-pointflow.github.io/.", "published": "2025-06-05 17:36:03", "link": "http://arxiv.org/abs/2506.05282v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Fast-DataShapley: Neural Modeling for Training Data Valuation", "abstract": "The value and copyright of training data are crucial in the artificial\nintelligence industry. Service platforms should protect data providers'\nlegitimate rights and fairly reward them for their contributions. Shapley\nvalue, a potent tool for evaluating contributions, outperforms other methods in\ntheory, but its computational overhead escalates exponentially with the number\nof data providers. Recent works based on Shapley values attempt to mitigate\ncomputation complexity by approximation algorithms. However, they need to\nretrain for each test sample, leading to intolerable costs. We propose\nFast-DataShapley, a one-pass training method that leverages the weighted least\nsquares characterization of the Shapley value to train a reusable explainer\nmodel with real-time reasoning speed. Given new test samples, no retraining is\nrequired to calculate the Shapley values of the training data. Additionally, we\npropose three methods with theoretical guarantees to reduce training overhead\nfrom two aspects: the approximate calculation of the utility function and the\ngroup calculation of the training data. We analyze time complexity to show the\nefficiency of our methods. The experimental evaluations on various image\ndatasets demonstrate superior performance and efficiency compared to baselines.\nSpecifically, the performance is improved to more than 2.5 times, and the\nexplainer's training speed can be increased by two orders of magnitude.", "published": "2025-06-05 17:35:46", "link": "http://arxiv.org/abs/2506.05281v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams", "abstract": "Effective teamwork is essential across diverse domains. During the team\nformation stage, a key challenge is forming teams that effectively balance user\npreferences with task objectives to enhance overall team satisfaction. In the\nteam performing stage, maintaining cohesion and engagement is critical for\nsustaining high team performance. However, existing computational tools and\nalgorithms for team optimization often rely on static data inputs, narrow\nalgorithmic objectives, or solutions tailored for specific contexts, failing to\naccount for the dynamic interplay of team members personalities, evolving\ngoals, and changing individual preferences. Therefore, teams may encounter\nmember dissatisfaction, as purely algorithmic assignments can reduce members\ncommitment to team goals or experience suboptimal engagement due to the absence\nof timely, personalized guidance to help members adjust their behaviors and\ninteractions as team dynamics evolve. Ultimately, these challenges can lead to\nreduced overall team performance. My Ph.D. dissertation aims to develop\nAI-augmented team optimization frameworks and practical systems that enhance\nteam satisfaction, engagement, and performance. First, I propose a team\nformation framework that leverages a multi-armed bandit algorithm to\niteratively refine team composition based on user preferences, ensuring\nalignment between individual needs and collective team goals to enhance team\nsatisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an\nAI-powered system that utilizes large language models (LLMs) to deliver\nimmediate, personalized feedback to both teams and individual members,\nenhancing cohesion and engagement. Finally, I present PuppeteerLLM, an\nLLM-based simulation framework that simulates multi-agent teams to model\ncomplex team dynamics within realistic environments, incorporating task-driven\ncollaboration and long-term coordination.", "published": "2025-06-05 17:24:37", "link": "http://arxiv.org/abs/2506.05265v1", "categories": ["cs.HC", "cs.AI", "cs.MA"], "primary_category": "cs.HC"}
{"title": "Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning", "abstract": "Large reasoning models (LRMs) achieve higher performance on challenging\nreasoning tasks by generating more tokens at inference time, but this verbosity\noften wastes computation on easy problems. Existing solutions, including\nsupervised finetuning on shorter traces, user-controlled budgets, or RL with\nuniform penalties, either require data curation, manual configuration, or treat\nall problems alike regardless of difficulty. We introduce Adaptive Length\nPenalty (ALP), a reinforcement learning objective tailoring generation length\nto per-prompt solve rate. During training, ALP monitors each prompt's online\nsolve rate through multiple rollouts and adds a differentiable penalty whose\nmagnitude scales inversely with that rate, so confident (easy) prompts incur a\nhigh cost for extra tokens while hard prompts remain unhindered. Posttraining\nDeepScaleR-1.5B with ALP cuts average token usage by 50\\% without significantly\ndropping performance. Relative to fixed-budget and uniform penalty baselines,\nALP redistributes its reduced budget more intelligently by cutting compute on\neasy prompts and reallocating saved tokens to difficult ones, delivering higher\naccuracy on the hardest problems with higher cost.", "published": "2025-06-05 17:17:05", "link": "http://arxiv.org/abs/2506.05256v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Intentionally Unintentional: GenAI Exceptionalism and the First Amendment", "abstract": "This paper challenges the assumption that courts should grant First Amendment\nprotections to outputs from large generative AI models, such as GPT-4 and\nGemini. We argue that because these models lack intentionality, their outputs\ndo not constitute speech as understood in the context of established legal\nprecedent, so there can be no speech to protect. Furthermore, if the model\noutputs are not speech, users cannot claim a First Amendment speech right to\nreceive the outputs. We also argue that extending First Amendment rights to AI\nmodels would not serve the fundamental purposes of free speech, such as\npromoting a marketplace of ideas, facilitating self-governance, or fostering\nself-expression. In fact, granting First Amendment protections to AI models\nwould be detrimental to society because it would hinder the government's\nability to regulate these powerful technologies effectively, potentially\nleading to the unchecked spread of misinformation and other harms.", "published": "2025-06-05 16:26:32", "link": "http://arxiv.org/abs/2506.05211v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "TreeRPO: Tree Relative Policy Optimization", "abstract": "Large Language Models (LLMs) have shown remarkable reasoning capabilities\nthrough Reinforcement Learning with Verifiable Rewards (RLVR) methods. However,\na key limitation of existing approaches is that rewards defined at the full\ntrajectory level provide insufficient guidance for optimizing the intermediate\nsteps of a reasoning process. To address this, we introduce \\textbf{\\name}, a\nnovel method that estimates the mathematical expectations of rewards at various\nreasoning steps using tree sampling. Unlike prior methods that rely on a\nseparate step reward model, \\name directly estimates these rewards through this\nsampling process. Building on the group-relative reward training mechanism of\nGRPO, \\name innovatively computes rewards based on step-level groups generated\nduring tree sampling. This advancement allows \\name to produce fine-grained and\ndense reward signals, significantly enhancing the learning process and overall\nperformance of LLMs. Experimental results demonstrate that our \\name algorithm\nsubstantially improves the average Pass@1 accuracy of Qwen-2.5-Math on test\nbenchmarks, increasing it from 19.0\\% to 35.5\\%. Furthermore, \\name\nsignificantly outperforms GRPO by 2.9\\% in performance while simultaneously\nreducing the average response length by 18.1\\%, showcasing its effectiveness\nand efficiency. Our code will be available at\n\\href{https://github.com/yangzhch6/TreeRPO}{https://github.com/yangzhch6/TreeRPO}.", "published": "2025-06-05 15:56:38", "link": "http://arxiv.org/abs/2506.05183v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Truly Self-Improving Agents Require Intrinsic Metacognitive Learning", "abstract": "Self-improving agents aim to continuously acquire new capabilities with\nminimal supervision. However, current approaches face two key limitations:\ntheir self-improvement processes are often rigid, fail to generalize across\ntasks domains, and struggle to scale with increasing agent capabilities. We\nargue that effective self-improvement requires intrinsic metacognitive\nlearning, defined as an agent's intrinsic ability to actively evaluate, reflect\non, and adapt its own learning processes. Drawing inspiration from human\nmetacognition, we introduce a formal framework comprising three components:\nmetacognitive knowledge (self-assessment of capabilities, tasks, and learning\nstrategies), metacognitive planning (deciding what and how to learn), and\nmetacognitive evaluation (reflecting on learning experiences to improve future\nlearning). Analyzing existing self-improving agents, we find they rely\npredominantly on extrinsic metacognitive mechanisms, which are fixed,\nhuman-designed loops that limit scalability and adaptability. Examining each\ncomponent, we contend that many ingredients for intrinsic metacognition are\nalready present. Finally, we explore how to optimally distribute metacognitive\nresponsibilities between humans and agents, and robustly evaluate and improve\nintrinsic metacognitive learning, key challenges that must be addressed to\nenable truly sustained, generalized, and aligned self-improvement.", "published": "2025-06-05 14:53:35", "link": "http://arxiv.org/abs/2506.05109v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Survey on the Evaluation of Generative Models in Music", "abstract": "Research on generative systems in music has seen considerable attention and\ngrowth in recent years. A variety of attempts have been made to systematically\nevaluate such systems. We provide an interdisciplinary review of the common\nevaluation targets, methodologies, and metrics for the evaluation of both\nsystem output and model usability, covering subjective and objective\napproaches, qualitative and quantitative approaches, as well as empirical and\ncomputational methods. We discuss the advantages and challenges of such\napproaches from a musicological, an engineering, and an HCI perspective.", "published": "2025-06-05 14:46:04", "link": "http://arxiv.org/abs/2506.05104v1", "categories": ["cs.SD", "cs.AI", "cs.LG"], "primary_category": "cs.SD"}
{"title": "Reason-to-Recommend: Using Interaction-of-Thought Reasoning to Enhance LLM Recommendation", "abstract": "Driven by advances in Large Language Models (LLMs), integrating them into\nrecommendation tasks has gained interest due to their strong semantic\nunderstanding and prompt flexibility. Prior work encoded user-item interactions\nor metadata into prompts for recommendations. In parallel, LLM reasoning,\nboosted by test-time scaling and reinforcement learning, has excelled in fields\nlike mathematics and code, where reasoning traces and correctness signals are\nclear, enabling high performance and interpretability. However, directly\napplying these reasoning methods to recommendation is ineffective because user\nfeedback is implicit and lacks reasoning supervision. To address this, we\npropose $\\textbf{R2Rec}$, a reasoning-enhanced recommendation framework that\nsamples interaction chains from the user-item graph and converts them into\nstructured interaction-of-thoughts via a progressive masked prompting strategy,\nwith each thought representing stepwise reasoning grounded in interaction\ncontext. This allows LLMs to simulate step-by-step decision-making based on\nimplicit patterns. We design a two-stage training pipeline: supervised\nfine-tuning teaches basic reasoning from high-quality traces, and reinforcement\nlearning refines reasoning via reward signals, alleviating sparse explicit\nsupervision. Experiments on three real-world datasets show R2Rec outperforms\nclassical and LLM-based baselines with an average $\\textbf{10.48%}$ improvement\nin HitRatio@1 and $\\textbf{131.81%}$ gain over the original LLM. Furthermore,\nthe explicit reasoning chains enhance interpretability by revealing the\ndecision process. Our code is available at:\nhttps://anonymous.4open.science/r/R2Rec-7C5D.", "published": "2025-06-05 14:16:44", "link": "http://arxiv.org/abs/2506.05069v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation", "abstract": "Recent explainable artificial intelligence (XAI) methods for time series\nprimarily estimate point-wise attribution magnitudes, while overlooking the\ndirectional impact on predictions, leading to suboptimal identification of\nsignificant points. Our analysis shows that conventional Integrated Gradients\n(IG) effectively capture critical points with both positive and negative\nimpacts on predictions. However, current evaluation metrics fail to assess this\ncapability, as they inadvertently cancel out opposing feature contributions. To\naddress this limitation, we propose novel evaluation metrics-Cumulative\nPrediction Difference (CPD) and Cumulative Prediction Preservation (CPP)-to\nsystematically assess whether attribution methods accurately identify\nsignificant positive and negative points in time series XAI. Under these\nmetrics, conventional IG outperforms recent counterparts. However, directly\napplying IG to time series data may lead to suboptimal outcomes, as generated\npaths ignore temporal relationships and introduce out-of-distribution samples.\nTo overcome these challenges, we introduce TIMING, which enhances IG by\nincorporating temporal awareness while maintaining its theoretical properties.\nExtensive experiments on synthetic and real-world time series benchmarks\ndemonstrate that TIMING outperforms existing time series XAI baselines. Our\ncode is available at https://github.com/drumpt/TIMING.", "published": "2025-06-05 13:40:40", "link": "http://arxiv.org/abs/2506.05035v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Identifying and Understanding Cross-Class Features in Adversarial Training", "abstract": "Adversarial training (AT) has been considered one of the most effective\nmethods for making deep neural networks robust against adversarial attacks,\nwhile the training mechanisms and dynamics of AT remain open research problems.\nIn this paper, we present a novel perspective on studying AT through the lens\nof class-wise feature attribution. Specifically, we identify the impact of a\nkey family of features on AT that are shared by multiple classes, which we call\ncross-class features. These features are typically useful for robust\nclassification, which we offer theoretical evidence to illustrate through a\nsynthetic data model. Through systematic studies across multiple model\narchitectures and settings, we find that during the initial stage of AT, the\nmodel tends to learn more cross-class features until the best robustness\ncheckpoint. As AT further squeezes the training robust loss and causes robust\noverfitting, the model tends to make decisions based on more class-specific\nfeatures. Based on these discoveries, we further provide a unified view of two\nexisting properties of AT, including the advantage of soft-label training and\nrobust overfitting. Overall, these insights refine the current understanding of\nAT mechanisms and provide new perspectives on studying them. Our code is\navailable at https://github.com/PKU-ML/Cross-Class-Features-AT.", "published": "2025-06-05 13:40:11", "link": "http://arxiv.org/abs/2506.05032v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV", "math.OC"], "primary_category": "cs.LG"}
{"title": "Artificial Intelligence Should Genuinely Support Clinical Reasoning and Decision Making To Bridge the Translational Gap", "abstract": "Artificial intelligence promises to revolutionise medicine, yet its impact\nremains limited because of the pervasive translational gap. We posit that the\nprevailing technology-centric approaches underpin this challenge, rendering\nsuch systems fundamentally incompatible with clinical practice, specifically\ndiagnostic reasoning and decision making. Instead, we propose a novel\nsociotechnical conceptualisation of data-driven support tools designed to\ncomplement doctors' cognitive and epistemic activities. Crucially, it\nprioritises real-world impact over superhuman performance on inconsequential\nbenchmarks.", "published": "2025-06-05 13:39:37", "link": "http://arxiv.org/abs/2506.05030v1", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.HC"}
{"title": "Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System", "abstract": "Heterogeneous multi-robot systems show great potential in complex tasks\nrequiring coordinated hybrid cooperation. However, traditional approaches\nrelying on static models often struggle with task diversity and dynamic\nenvironments. This highlights the need for generalizable intelligence that can\nbridge high-level reasoning with low-level execution across heterogeneous\nagents. To address this, we propose a hierarchical framework integrating a\nprompted Large Language Model (LLM) and a GridMask-enhanced fine-tuned Vision\nLanguage Model (VLM). The LLM performs task decomposition and global semantic\nmap construction, while the VLM extracts task-specified semantic labels and 2D\nspatial information from aerial images to support local planning. Within this\nframework, the aerial robot follows a globally optimized semantic path and\ncontinuously provides bird-view images, guiding the ground robot's local\nsemantic navigation and manipulation, including target-absent scenarios where\nimplicit alignment is maintained. Experiments on a real-world letter-cubes\narrangement task demonstrate the framework's adaptability and robustness in\ndynamic environments. To the best of our knowledge, this is the first\ndemonstration of an aerial-ground heterogeneous system integrating VLM-based\nperception with LLM-driven task reasoning and motion planning.", "published": "2025-06-05 13:27:41", "link": "http://arxiv.org/abs/2506.05020v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Towards Reasonable Concept Bottleneck Models", "abstract": "In this paper, we propose $\\textbf{C}$oncept $\\textbf{REA}$soning\n$\\textbf{M}$odels (CREAM), a novel family of Concept Bottleneck Models (CBMs)\nthat: (i) explicitly encodes concept-concept (${\\texttt{C-C}}$) and\nconcept-task (${\\texttt{C$\\rightarrow$Y}}$) relationships to enforce a desired\nmodel reasoning; and (ii) use a regularized side-channel to achieve competitive\ntask performance, while keeping high concept importance. Specifically, CREAM\narchitecturally embeds (bi)directed concept-concept, and concept to task\nrelationships specified by a human expert, while severing undesired information\nflows (e.g., to handle mutually exclusive concepts). Moreover, CREAM integrates\na black-box side-channel that is regularized to encourage task predictions to\nbe grounded in the relevant concepts, thereby utilizing the side-channel only\nwhen necessary to enhance performance. Our experiments show that: (i) CREAM\nmainly relies on concepts while achieving task performance on par with\nblack-box models; and (ii) the embedded ${\\texttt{C-C}}$ and\n${\\texttt{C$\\rightarrow$Y}}$ relationships ease model interventions and\nmitigate concept leakage.", "published": "2025-06-05 13:22:29", "link": "http://arxiv.org/abs/2506.05014v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning", "abstract": "Autonomous UAV operation necessitates reliable mathematical reasoning for\ntasks such as trajectory planning and power management. While traditional\nflight control relies on hardcoded equations, recent Large Language Models\n(LLMs) offer potential for more flexible problem-solving but struggle with\nreliably selecting and applying correct mathematical formulations and executing\nprecise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented\ngeneration framework designed to improve the mathematical reasoning of several\nLLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in\nUAV-specific contexts by providing access to relevant domain literature. To\nconduct an initial assessment, we introduce the UAV-Math-Bench, a small problem\nset comprising 20 UAV-centric mathematical problems across four difficulty\nlevels. Our experiments demonstrate that incorporating retrieval substantially\nincreases exact answer accuracy (achieving up to 75% with o1), reduces\ninstances of incorrect formulation selection (from 25% without RAG to 5% with\nRAG), decreases numerical errors, reducing Mean Squared Error (MSE) by orders\nof magnitude for the best-performing models. This pilot study indicates that\nRAG can enable general-purpose LLMs to function as more reliable tools for\nengineering analysis, although direct real-time flight control requires further\ninvestigation and validation on a larger scale. All benchmark data, question\nand answer are publicly available.", "published": "2025-06-05 13:09:24", "link": "http://arxiv.org/abs/2506.04998v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair", "abstract": "Software vulnerabilities pose significant security threats, requiring\neffective mitigation. While Automated Program Repair (APR) has advanced in\nfixing general bugs, vulnerability patching, a security-critical aspect of APR\nremains underexplored. This study investigates pre-trained language models,\nCodeBERT and CodeT5, for automated vulnerability patching across six datasets\nand four languages. We evaluate their accuracy and generalization to unknown\nvulnerabilities. Results show that while both models face challenges with\nfragmented or sparse context, CodeBERT performs comparatively better in such\nscenarios, whereas CodeT5 excels in capturing complex vulnerability patterns.\nCodeT5 also demonstrates superior scalability. Furthermore, we test fine-tuned\nmodels on both in-distribution (trained) and out-of-distribution (unseen)\ndatasets. While fine-tuning improves in-distribution performance, models\nstruggle to generalize to unseen data, highlighting challenges in robust\nvulnerability detection. This study benchmarks model performance, identifies\nlimitations in generalization, and provides actionable insights to advance\nautomated vulnerability patching for real-world security applications.", "published": "2025-06-05 13:00:19", "link": "http://arxiv.org/abs/2506.04987v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Robustness as Architecture: Designing IQA Models to Withstand Adversarial Perturbations", "abstract": "Image Quality Assessment (IQA) models are increasingly relied upon to\nevaluate image quality in real-world systems -- from compression and\nenhancement to generation and streaming. Yet their adoption brings a\nfundamental risk: these models are inherently unstable. Adversarial\nmanipulations can easily fool them, inflating scores and undermining trust.\nTraditionally, such vulnerabilities are addressed through data-driven defenses\n-- adversarial retraining, regularization, or input purification. But what if\nthis is the wrong lens? What if robustness in perceptual models is not\nsomething to learn but something to design? In this work, we propose a\nprovocative idea: robustness as an architectural prior. Rather than training\nmodels to resist perturbations, we reshape their internal structure to suppress\nsensitivity from the ground up. We achieve this by enforcing orthogonal\ninformation flow, constraining the network to norm-preserving operations -- and\nfurther stabilizing the system through pruning and fine-tuning. The result is a\nrobust IQA architecture that withstands adversarial attacks without requiring\nadversarial training or significant changes to the original model. This\napproach suggests a shift in perspective: from optimizing robustness through\ndata to engineering it through design.", "published": "2025-06-05 12:24:38", "link": "http://arxiv.org/abs/2506.04951v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CzechLynx: A Dataset for Individual Identification and Pose Estimation of the Eurasian Lynx", "abstract": "We introduce CzechLynx, the first large-scale, open-access dataset for\nindividual identification, 2D pose estimation, and instance segmentation of the\nEurasian lynx (Lynx lynx). CzechLynx includes more than 30k camera trap images\nannotated with segmentation masks, identity labels, and 20-point skeletons and\ncovers 219 unique individuals across 15 years of systematic monitoring in two\ngeographically distinct regions: Southwest Bohemia and the Western Carpathians.\nTo increase the data variability, we create a complementary synthetic set with\nmore than 100k photorealistic images generated via a Unity-based pipeline and\ndiffusion-driven text-to-texture modeling, covering diverse environments,\nposes, and coat-pattern variations. To allow testing generalization across\nspatial and temporal domains, we define three tailored evaluation\nprotocols/splits: (i) geo-aware, (ii) time-aware open-set, and (iii) time-aware\nclosed-set. This dataset is targeted to be instrumental in benchmarking\nstate-of-the-art models and the development of novel methods for not just\nindividual animal re-identification.", "published": "2025-06-05 12:05:43", "link": "http://arxiv.org/abs/2506.04931v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Energentic Intelligence: From Self-Sustaining Systems to Enduring Artificial Life", "abstract": "This paper introduces Energentic Intelligence, a class of autonomous systems\ndefined not by task performance, but by their capacity to sustain themselves\nthrough internal energy regulation. Departing from conventional reward-driven\nparadigms, these agents treat survival-maintaining functional operation under\nfluctuating energetic and thermal conditions-as the central objective. We\nformalize this principle through an energy-based utility function and a\nviability-constrained survival horizon, and propose a modular architecture that\nintegrates energy harvesting, thermal regulation, and adaptive computation into\na closed-loop control system. A simulated environment demonstrates the\nemergence of stable, resource-aware behavior without external supervision.\nTogether, these contributions provide a theoretical and architectural\nfoundation for deploying autonomous agents in resource-volatile settings where\npersistence must be self-regulated and infrastructure cannot be assumed.", "published": "2025-06-05 11:52:21", "link": "http://arxiv.org/abs/2506.04916v1", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Differentiable Logic Cellular Automata: From Game of Life to Pattern Generation", "abstract": "This paper introduces Differentiable Logic Cellular Automata (DiffLogic CA),\na novel combination of Neural Cellular Automata (NCA) and Differentiable Logic\nGates Networks (DLGNs). The fundamental computation units of the model are\ndifferentiable logic gates, combined into a circuit. During training, the model\nis fully end-to-end differentiable allowing gradient-based training, and at\ninference time it operates in a fully discrete state space. This enables\nlearning local update rules for cellular automata while preserving their\ninherent discrete nature. We demonstrate the versatility of our approach\nthrough a series of milestones: (1) fully learning the rules of Conway's Game\nof Life, (2) generating checkerboard patterns that exhibit resilience to noise\nand damage, (3) growing a lizard shape, and (4) multi-color pattern generation.\nOur model successfully learns recurrent circuits capable of generating desired\ntarget patterns. For simpler patterns, we observe success with both synchronous\nand asynchronous updates, demonstrating significant generalization capabilities\nand robustness to perturbations. We make the case that this combination of\nDLGNs and NCA represents a step toward programmable matter and robust computing\nsystems that combine binary logic, neural network adaptability, and localized\nprocessing. This work, to the best of our knowledge, is the first successful\napplication of differentiable logic gate networks in recurrent architectures.", "published": "2025-06-05 11:45:43", "link": "http://arxiv.org/abs/2506.04912v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LLMs for sensory-motor control: Combining in-context and iterative learning", "abstract": "We propose a method that enables large language models (LLMs) to control\nembodied agents by directly mapping continuous observation vectors to\ncontinuous action vectors. Initially, the LLMs generate a control strategy\nbased on a textual description of the agent, its environment, and the intended\ngoal. This strategy is then iteratively refined through a learning process in\nwhich the LLMs are repeatedly prompted to improve the current strategy, using\nperformance feedback and sensory-motor data collected during its evaluation.\nThe method is validated on classic control tasks from the Gymnasium library and\nthe inverted pendulum task from the MuJoCo library. In most cases, it\nsuccessfully identifies optimal or high-performing solutions by integrating\nsymbolic knowledge derived through reasoning with sub-symbolic sensory-motor\ndata gathered as the agent interacts with its environment.", "published": "2025-06-05 10:38:28", "link": "http://arxiv.org/abs/2506.04867v1", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Towards Network Data Analytics in 5G Systems and Beyond", "abstract": "Data has become a critical asset in the digital economy, yet it remains\nunderutilized by Mobile Network Operators (MNOs), unlike Over-the-Top (OTT)\nplayers that lead global market valuations. To move beyond the commoditization\nof connectivity and deliver greater value to customers, data analytics emerges\nas a strategic enabler. Using data efficiently is essential for unlocking new\nservice opportunities, optimizing operational efficiency, and mitigating\noperational and business risks. Since Release 15, the 3rd Generation\nPartnership Project (3GPP) has introduced the Network Data Analytics Function\n(NWDAF) to provide powerful insights and predictions using data collected\nacross mobile networks, supporting both user-centric and network-oriented use\ncases. However, academic research has largely focused on a limited set of\nmethods and use cases, driven by the availability of datasets, restricting\nbroader exploration. This study analyzes trends and gaps in more than 70\narticles and proposes two novel use cases to promote the adoption of NWDAF and\nexplore its potential for monetization.", "published": "2025-06-05 10:26:53", "link": "http://arxiv.org/abs/2506.04860v1", "categories": ["cs.NI", "cs.AI"], "primary_category": "cs.NI"}
{"title": "Sparse Autoencoders, Again?", "abstract": "Is there really much more to say about sparse autoencoders (SAEs)?\nAutoencoders in general, and SAEs in particular, represent deep architectures\nthat are capable of modeling low-dimensional latent structure in data. Such\nstructure could reflect, among other things, correlation patterns in large\nlanguage model activations, or complex natural image manifolds. And yet despite\nthe wide-ranging applicability, there have been relatively few changes to SAEs\nbeyond the original recipe from decades ago, namely, standard deep\nencoder/decoder layers trained with a classical/deterministic sparse\nregularizer applied within the latent space. One possible exception is the\nvariational autoencoder (VAE), which adopts a stochastic encoder module capable\nof producing sparse representations when applied to manifold data. In this work\nwe formalize underappreciated weaknesses with both canonical SAEs, as well as\nanalogous VAEs applied to similar tasks, and propose a hybrid alternative model\nthat circumvents these prior limitations. In terms of theoretical support, we\nprove that global minima of our proposed model recover certain forms of\nstructured data spread across a union of manifolds. Meanwhile, empirical\nevaluations on synthetic and real-world datasets substantiate the efficacy of\nour approach in accurately estimating underlying manifold dimensions and\nproducing sparser latent representations without compromising reconstruction\nerror. In general, we are able to exceed the performance of equivalent-capacity\nSAEs and VAEs, as well as recent diffusion models where applicable, within\ndomains such as images and language model activation patterns.", "published": "2025-06-05 10:26:06", "link": "http://arxiv.org/abs/2506.04859v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards a Multi-Agent Simulation of Cyber-attackers and Cyber-defenders Battles", "abstract": "As cyber-attacks show to be more and more complex and coordinated,\ncyber-defenders strategy through multi-agent approaches could be key to tackle\nagainst cyber-attacks as close as entry points in a networked system. This\npaper presents a Markovian modeling and implementation through a simulator of\nfighting cyber-attacker agents and cyber-defender agents deployed on host\nnetwork nodes. It aims to provide an experimental framework to implement\nrealistically based coordinated cyber-attack scenarios while assessing\ncyber-defenders dynamic organizations. We abstracted network nodes by sets of\nproperties including agents' ones. Actions applied by agents model how the\nnetwork reacts depending in a given state and what properties are to change.\nCollective choice of the actions brings the whole environment closer or farther\nfrom respective cyber-attackers and cyber-defenders goals. Using the simulator,\nwe implemented a realistically inspired scenario with several behavior\nimplementation approaches for cyber-defenders and cyber-attackers.", "published": "2025-06-05 10:17:17", "link": "http://arxiv.org/abs/2506.04849v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "On Automating Security Policies with Contemporary LLMs", "abstract": "The complexity of modern computing environments and the growing\nsophistication of cyber threats necessitate a more robust, adaptive, and\nautomated approach to security enforcement. In this paper, we present a\nframework leveraging large language models (LLMs) for automating attack\nmitigation policy compliance through an innovative combination of in-context\nlearning and retrieval-augmented generation (RAG). We begin by describing how\nour system collects and manages both tool and API specifications, storing them\nin a vector database to enable efficient retrieval of relevant information. We\nthen detail the architectural pipeline that first decomposes high-level\nmitigation policies into discrete tasks and subsequently translates each task\ninto a set of actionable API calls. Our empirical evaluation, conducted using\npublicly available CTI policies in STIXv2 format and Windows API documentation,\ndemonstrates significant improvements in precision, recall, and F1-score when\nemploying RAG compared to a non-RAG baseline.", "published": "2025-06-05 09:58:00", "link": "http://arxiv.org/abs/2506.04838v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Oversight Structures for Agentic AI in Public-Sector Organizations", "abstract": "This paper finds that the introduction of agentic AI systems intensifies\nexisting challenges to traditional public sector oversight mechanisms -- which\nrely on siloed compliance units and episodic approvals rather than continuous,\nintegrated supervision. We identify five governance dimensions essential for\nresponsible agent deployment: cross-departmental implementation, comprehensive\nevaluation, enhanced security protocols, operational visibility, and systematic\nauditing. We evaluate the capacity of existing oversight structures to meet\nthese challenges, via a mixed-methods approach consisting of a literature\nreview and interviews with civil servants in AI-related roles. We find that\nagent oversight poses intensified versions of three existing governance\nchallenges: continuous oversight, deeper integration of governance and\noperational capabilities, and interdepartmental coordination. We propose\napproaches that both adapt institutional structures and design agent oversight\ncompatible with public sector constraints.", "published": "2025-06-05 09:57:15", "link": "http://arxiv.org/abs/2506.04836v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Safe Planning and Policy Optimization via World Model Learning", "abstract": "Reinforcement Learning (RL) applications in real-world scenarios must\nprioritize safety and reliability, which impose strict constraints on agent\nbehavior. Model-based RL leverages predictive world models for action planning\nand policy optimization, but inherent model inaccuracies can lead to\ncatastrophic failures in safety-critical settings. We propose a novel\nmodel-based RL framework that jointly optimizes task performance and safety. To\naddress world model errors, our method incorporates an adaptive mechanism that\ndynamically switches between model-based planning and direct policy execution.\nWe resolve the objective mismatch problem of traditional model-based approaches\nusing an implicit world model. Furthermore, our framework employs dynamic\nsafety thresholds that adapt to the agent's evolving capabilities, consistently\nselecting actions that surpass safe policy suggestions in both performance and\nsafety. Experiments demonstrate significant improvements over non-adaptive\nmethods, showing that our approach optimizes safety and performance\nsimultaneously rather than merely meeting minimum safety requirements. The\nproposed framework achieves robust performance on diverse safety-critical\ncontinuous control tasks, outperforming existing methods.", "published": "2025-06-05 09:50:02", "link": "http://arxiv.org/abs/2506.04828v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Ontology-based knowledge representation for bone disease diagnosis: a foundation for safe and sustainable medical artificial intelligence systems", "abstract": "Medical artificial intelligence (AI) systems frequently lack systematic\ndomain expertise integration, potentially compromising diagnostic reliability.\nThis study presents an ontology-based framework for bone disease diagnosis,\ndeveloped in collaboration with Ho Chi Minh City Hospital for Traumatology and\nOrthopedics. The framework introduces three theoretical contributions: (1) a\nhierarchical neural network architecture guided by bone disease ontology for\nsegmentation-classification tasks, incorporating Visual Language Models (VLMs)\nthrough prompts, (2) an ontology-enhanced Visual Question Answering (VQA)\nsystem for clinical reasoning, and (3) a multimodal deep learning model that\nintegrates imaging, clinical, and laboratory data through ontological\nrelationships. The methodology maintains clinical interpretability through\nsystematic knowledge digitization, standardized medical terminology mapping,\nand modular architecture design. The framework demonstrates potential for\nextension beyond bone diseases through its standardized structure and reusable\ncomponents. While theoretical foundations are established, experimental\nvalidation remains pending due to current dataset and computational resource\nlimitations. Future work will focus on expanding the clinical dataset and\nconducting comprehensive system validation.", "published": "2025-06-05 08:41:23", "link": "http://arxiv.org/abs/2506.04756v1", "categories": ["cs.AI", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning", "abstract": "While multi-modal large language models (MLLMs) have made significant\nprogress in complex reasoning tasks via reinforcement learning, it is commonly\nbelieved that extensive training data is necessary for improving multi-modal\nreasoning ability, inevitably leading to data redundancy and substantial\ncomputational costs. However, can smaller high-value datasets match or\noutperform full corpora for multi-modal reasoning in MLLMs? In this work, we\nchallenge this assumption through a key observation: meaningful multi-modal\nreasoning is triggered by only a sparse subset of training samples, termed\ncognitive samples, whereas the majority contribute marginally. Building on this\ninsight, we propose a novel data selection paradigm termed Reasoning Activation\nPotential (RAP), which identifies cognitive samples by estimating each sample's\npotential to stimulate genuine multi-modal reasoning by two complementary\nestimators: 1) Causal Discrepancy Estimator (CDE) based on the potential\noutcome model principle, eliminates samples that overly rely on language priors\nby comparing outputs between multi-modal and text-only inputs; 2) Attention\nConfidence Estimator (ACE), which exploits token-level self-attention to\ndiscard samples dominated by irrelevant but over-emphasized tokens in\nintermediate reasoning stages. Moreover, we introduce a Difficulty-aware\nReplacement Module (DRM) to substitute trivial instances with cognitively\nchallenging ones, thereby ensuring complexity for robust multi-modal reasoning.\nExperiments on six datasets show that our RAP method consistently achieves\nsuperior performance using only 9.3% of the training data, while reducing\ncomputational costs by over 43%. Our code is available at\nhttps://github.com/Leo-ssl/RAP.", "published": "2025-06-05 08:40:24", "link": "http://arxiv.org/abs/2506.04755v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Physics Informed Capsule Enhanced Variational AutoEncoder for Underwater Image Enhancement", "abstract": "We present a novel dual-stream architecture that achieves state-of-the-art\nunderwater image enhancement by explicitly integrating the Jaffe-McGlamery\nphysical model with capsule clustering-based feature representation learning.\nOur method simultaneously estimates transmission maps and spatially-varying\nbackground light through a dedicated physics estimator while extracting\nentity-level features via capsule clustering in a parallel stream. This\nphysics-guided approach enables parameter-free enhancement that respects\nunderwater formation constraints while preserving semantic structures and\nfine-grained details. Our approach also features a novel optimization objective\nensuring both physical adherence and perceptual quality across multiple spatial\nfrequencies. To validate our approach, we conducted extensive experiments\nacross six challenging benchmarks. Results demonstrate consistent improvements\nof $+0.5$dB PSNR over the best existing methods while requiring only one-third\nof their computational complexity (FLOPs), or alternatively, more than $+1$dB\nPSNR improvement when compared to methods with similar computational budgets.\nCode and data \\textit{will} be available at https://github.com/iN1k1/.", "published": "2025-06-05 08:39:17", "link": "http://arxiv.org/abs/2506.04753v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Was Residual Penalty and Neural Operators All We Needed for Solving Optimal Control Problems?", "abstract": "Neural networks have been used to solve optimal control problems, typically\nby training neural networks using a combined loss function that considers data,\ndifferential equation residuals, and objective costs. We show that including\ncost functions in the training process is unnecessary, advocating for a simpler\narchitecture and streamlined approach by decoupling the optimal control problem\nfrom the training process. Thus, our work shows that a simple neural operator\narchitecture, such as DeepONet, coupled with an unconstrained optimization\nroutine, can solve multiple optimal control problems with a single\nphysics-informed training phase and a subsequent optimization phase. We achieve\nthis by adding a penalty term based on the differential equation residual to\nthe cost function and computing gradients with respect to the control using\nautomatic differentiation through the trained neural operator within an\niterative optimization routine. We showcase our method on nine distinct optimal\ncontrol problems by training three separate DeepONet models, each corresponding\nto a different differential equation. For each model, we solve three problems\nwith varying cost functions, demonstrating accurate and consistent performance\nacross all cases.", "published": "2025-06-05 08:22:16", "link": "http://arxiv.org/abs/2506.04742v1", "categories": ["math.OC", "cs.AI"], "primary_category": "math.OC"}
{"title": "Beyond Accuracy: Dissecting Mathematical Reasoning for LLMs Under Reinforcement Learning", "abstract": "Reinforcement learning (RL) has become the dominant paradigm for endowing\nlanguage models with advanced reasoning capabilities. Despite the substantial\nempirical gains demonstrated by RL-based training methods like GRPO, a granular\nunderstanding of their advantages is still lacking. To address this gap, we\nintroduce a fine-grained analytic framework to dissect the impact of RL on\nreasoning. Our framework specifically investigates key elements that have been\nhypothesized to benefit from RL training: (1) plan-following and execution, (2)\nproblem decomposition, and (3) improved reasoning and knowledge utilization.\nUsing this framework, we gain insights beyond mere accuracy. For instance,\nproviding models with explicit step-by-step plans surprisingly degrades\nperformance on the most challenging benchmarks, yet RL-tuned models exhibit\ngreater robustness, experiencing markedly smaller performance drops than their\nbase counterparts. This suggests that RL may not primarily enhance the\nexecution of external plans but rather empower models to formulate and follow\ninternal strategies better suited to their reasoning processes. Conversely, we\nobserve that RL enhances the model's capacity to integrate provided knowledge\ninto its reasoning process, leading to performance improvements across diverse\ntasks. We also study difficulty, showing improved training by developing new\nways to exploit hard problems. Our findings lay a foundation for more\nprincipled training and evaluation of reasoning models.", "published": "2025-06-05 07:53:59", "link": "http://arxiv.org/abs/2506.04723v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Using In-Context Learning for Automatic Defect Labelling of Display Manufacturing Data", "abstract": "This paper presents an AI-assisted auto-labeling system for display panel\ndefect detection that leverages in-context learning capabilities. We adopt and\nenhance the SegGPT architecture with several domain-specific training\ntechniques and introduce a scribble-based annotation mechanism to streamline\nthe labeling process. Our two-stage training approach, validated on industrial\ndisplay panel datasets, demonstrates significant improvements over the baseline\nmodel, achieving an average IoU increase of 0.22 and a 14% improvement in\nrecall across multiple product types, while maintaining approximately 60%\nauto-labeling coverage. Experimental results show that models trained on our\nauto-labeled data match the performance of those trained on human-labeled data,\noffering a practical solution for reducing manual annotation efforts in\nindustrial inspection systems.", "published": "2025-06-05 07:42:31", "link": "http://arxiv.org/abs/2506.04717v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "UNO: Unlearning via Orthogonalization in Generative models", "abstract": "As generative models become increasingly powerful and pervasive, the ability\nto unlearn specific data, whether due to privacy concerns, legal requirements,\nor the correction of harmful content, has become increasingly important. Unlike\nin conventional training, where data are accumulated and knowledge is\nreinforced, unlearning aims to selectively remove the influence of particular\ndata points without costly retraining from scratch. To be effective and\nreliable, such algorithms need to achieve (i) forgetting of the undesired data,\n(ii) preservation of the quality of the generation, (iii) preservation of the\ninfluence of the desired training data on the model parameters, and (iv) small\nnumber of training steps. We propose fast unlearning algorithms based on loss\ngradient orthogonalization. We show that our algorithms are able to forget data\nwhile maintaining the fidelity of the original model. Using MNIST and CelebA\ndata, we demonstrate that our algorithms achieve orders of magnitude faster\nunlearning times than their predecessors, such as gradient surgery.", "published": "2025-06-05 07:37:02", "link": "http://arxiv.org/abs/2506.04712v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Line of Sight: On Linear Representations in VLLMs", "abstract": "Language models can be equipped with multimodal capabilities by fine-tuning\non embeddings of visual inputs. But how do such multimodal models represent\nimages in their hidden activations? We explore representations of image\nconcepts within LlaVA-Next, a popular open-source VLLM. We find a diverse set\nof ImageNet classes represented via linearly decodable features in the residual\nstream. We show that the features are causal by performing targeted edits on\nthe model output. In order to increase the diversity of the studied linear\nfeatures, we train multimodal Sparse Autoencoders (SAEs), creating a highly\ninterpretable dictionary of text and image features. We find that although\nmodel representations across modalities are quite disjoint, they become\nincreasingly shared in deeper layers.", "published": "2025-06-05 07:30:58", "link": "http://arxiv.org/abs/2506.04706v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "HoliSafe: Holistic Safety Benchmarking and Modeling with Safety Meta Token for Vision-Language Model", "abstract": "Despite emerging efforts to enhance the safety of Vision-Language Models\n(VLMs), current approaches face two main shortcomings. 1) Existing\nsafety-tuning datasets and benchmarks only partially consider how image-text\ninteractions can yield harmful content, often overlooking contextually unsafe\noutcomes from seemingly benign pairs. This narrow coverage leaves VLMs\nvulnerable to jailbreak attacks in unseen configurations. 2) Prior methods rely\nprimarily on data-centric tuning, with limited architectural innovations to\nintrinsically strengthen safety. We address these gaps by introducing a\nholistic safety dataset and benchmark, HoliSafe, that spans all five\nsafe/unsafe image-text combinations, providing a more robust basis for both\ntraining and evaluation. We further propose SafeLLaVA, a novel VLM augmented\nwith a learnable safety meta token and a dedicated safety head. The meta token\nencodes harmful visual cues during training, intrinsically guiding the language\nmodel toward safer responses, while the safety head offers interpretable\nharmfulness classification aligned with refusal rationales. Experiments show\nthat SafeLLaVA, trained on HoliSafe, achieves state-of-the-art safety\nperformance across multiple VLM benchmarks. Additionally, the HoliSafe\nbenchmark itself reveals critical vulnerabilities in existing models. We hope\nthat HoliSafe and SafeLLaVA will spur further research into robust and\ninterpretable VLM safety, expanding future avenues for multimodal alignment.", "published": "2025-06-05 07:26:34", "link": "http://arxiv.org/abs/2506.04704v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Explicit Density Approximation for Neural Implicit Samplers Using a Bernstein-Based Convex Divergence", "abstract": "Rank-based statistical metrics, such as the invariant statistical loss (ISL),\nhave recently emerged as robust and practically effective tools for training\nimplicit generative models. In this work, we introduce dual-ISL, a novel\nlikelihood-free objective for training implicit generative models that\ninterchanges the roles of the target and model distributions in the ISL\nframework, yielding a convex optimization problem in the space of model\ndensities. We prove that the resulting rank-based discrepancy $d_K$ is i)\ncontinuous under weak convergence and with respect to the $L^1$ norm, and ii)\nconvex in its first argument-properties not shared by classical divergences\nsuch as KL or Wasserstein distances. Building on this, we develop a theoretical\nframework that interprets $d_K$ as an $L^2$-projection of the density ratio $q\n= p/\\tilde p$ onto a Bernstein polynomial basis, from which we derive exact\nbounds on the truncation error, precise convergence rates, and a closed-form\nexpression for the truncated density approximation. We further extend our\nanalysis to the multivariate setting via random one-dimensional projections,\ndefining a sliced dual-ISL divergence that retains both convexity and\ncontinuity. We empirically show that these theoretical advantages translate\ninto practical ones. Specifically, across several benchmarks dual-ISL converges\nmore rapidly, delivers markedly smoother and more stable training, and more\neffectively prevents mode collapse than classical ISL and other leading\nimplicit generative methods-while also providing an explicit density\napproximation.", "published": "2025-06-05 07:21:54", "link": "http://arxiv.org/abs/2506.04700v1", "categories": ["cs.LG", "cs.AI", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Empowering Economic Simulation for Massively Multiplayer Online Games through Generative Agent-Based Modeling", "abstract": "Within the domain of Massively Multiplayer Online (MMO) economy research,\nAgent-Based Modeling (ABM) has emerged as a robust tool for analyzing game\neconomics, evolving from rule-based agents to decision-making agents enhanced\nby reinforcement learning. Nevertheless, existing works encounter significant\nchallenges when attempting to emulate human-like economic activities among\nagents, particularly regarding agent reliability, sociability, and\ninterpretability. In this study, we take a preliminary step in introducing a\nnovel approach using Large Language Models (LLMs) in MMO economy simulation.\nLeveraging LLMs' role-playing proficiency, generative capacity, and reasoning\naptitude, we design LLM-driven agents with human-like decision-making and\nadaptability. These agents are equipped with the abilities of role-playing,\nperception, memory, and reasoning, addressing the aforementioned challenges\neffectively. Simulation experiments focusing on in-game economic activities\ndemonstrate that LLM-empowered agents can promote emergent phenomena like role\nspecialization and price fluctuations in line with market rules.", "published": "2025-06-05 07:21:13", "link": "http://arxiv.org/abs/2506.04699v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "On the Mechanism of Reasoning Pattern Selection in Reinforcement Learning for Language Models", "abstract": "Reinforcement learning (RL) has demonstrated remarkable success in enhancing\nmodel capabilities, including instruction-following, preference learning, and\nreasoning. Yet despite its empirical successes, the mechanisms by which RL\nimproves reasoning abilities remain poorly understood. We present a systematic\nstudy of Reinforcement Learning with Verifiable Rewards (RLVR), showing that\nits primary benefit comes from optimizing the selection of existing reasoning\npatterns. Through extensive experiments, we demonstrate that RLVR-trained\nmodels preferentially adopt high-success-rate reasoning patterns while mostly\nmaintaining stable performance on individual patterns. We further develop\ntheoretical analyses on the convergence and training dynamics of RLVR based on\na simplified question-reason-answer model. We study the gradient flow and show\nthat RLVR can indeed find the solution that selects the reason pattern with the\nhighest success rate. Besides, our theoretical results\n  reveal two distinct regimes regarding the convergence of RLVR training: (1)\nrapid convergence for models with relatively strong initial reasoning\ncapabilities versus (2) slower optimization dynamics for weaker models.\nFurthermore, we show that the slower optimization for weaker models can be\nmitigated by applying the supervised fine-tuning (SFT) before RLVR, when using\na feasibly high-quality SFT dataset. We validate the theoretical findings\nthrough extensive experiments. This work advances our theoretical understanding\nof RL's role in LLM fine-tuning and offers insights for further enhancing\nreasoning capabilities.", "published": "2025-06-05 07:17:04", "link": "http://arxiv.org/abs/2506.04695v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Influence Functions for Edge Edits in Non-Convex Graph Neural Networks", "abstract": "Understanding how individual edges influence the behavior of graph neural\nnetworks (GNNs) is essential for improving their interpretability and\nrobustness. Graph influence functions have emerged as promising tools to\nefficiently estimate the effects of edge deletions without retraining. However,\nexisting influence prediction methods rely on strict convexity assumptions,\nexclusively consider the influence of edge deletions while disregarding edge\ninsertions, and fail to capture changes in message propagation caused by these\nmodifications. In this work, we propose a proximal Bregman response function\nspecifically tailored for GNNs, relaxing the convexity requirement and enabling\naccurate influence prediction for standard neural network architectures.\nFurthermore, our method explicitly accounts for message propagation effects and\nextends influence prediction to both edge deletions and insertions in a\nprincipled way. Experiments with real-world datasets demonstrate accurate\ninfluence predictions for different characteristics of GNNs. We further\ndemonstrate that the influence function is versatile in applications such as\ngraph rewiring and adversarial attacks.", "published": "2025-06-05 07:15:46", "link": "http://arxiv.org/abs/2506.04694v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Better Generalization via Distributional Input Projection Network", "abstract": "As overparameterized models become increasingly prevalent, training loss\nalone offers limited insight into generalization performance. While smoothness\nhas been linked to improved generalization across various settings, directly\nenforcing smoothness in neural networks remains challenging. To address this,\nwe introduce Distributional Input Projection Networks (DIPNet), a novel\nframework that projects inputs into learnable distributions at each layer. This\ndistributional representation induces a smoother loss landscape with respect to\nthe input, promoting better generalization. We provide theoretical analysis\nshowing that DIPNet reduces both local smoothness measures and the Lipschitz\nconstant of the network, contributing to improved generalization performance.\nEmpirically, we validate DIPNet across a wide range of architectures and tasks,\nincluding Vision Transformers (ViTs), Large Language Models (LLMs), ResNet and\nMLPs. Our method consistently enhances test performance under standard\nsettings, adversarial attacks, out-of-distribution inputs, and reasoning\nbenchmarks. We demonstrate that the proposed input projection strategy can be\nseamlessly integrated into existing models, providing a general and effective\napproach for boosting generalization performance in modern deep learning.", "published": "2025-06-05 07:13:59", "link": "http://arxiv.org/abs/2506.04690v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Gen-n-Val: Agentic Image Data Generation and Validation", "abstract": "Recently, Large Language Models (LLMs) and Vision Large Language Models\n(VLLMs) have demonstrated impressive performance as agents across various tasks\nwhile data scarcity and label noise remain significant challenges in computer\nvision tasks, such as object detection and instance segmentation. A common\nsolution for resolving these issues is to generate synthetic data. However,\ncurrent synthetic data generation methods struggle with issues, such as\nmultiple objects per mask, inaccurate segmentation, and incorrect category\nlabels, limiting their effectiveness. To address these issues, we introduce\nGen-n-Val, a novel agentic data generation framework that leverages Layer\nDiffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks\nand diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt\nagent, an LLM, optimizes prompts for LD to generate high-quality foreground\ninstance images and segmentation masks. These optimized prompts ensure the\ngeneration of single-object synthetic data with precise instance masks and\nclean backgrounds. (2) The data validation agent, a VLLM, which filters out\nlow-quality synthetic instance images. The system prompts for both agents are\nrefined through TextGrad. Additionally, we use image harmonization to combine\nmultiple instances within scenes. Compared to state-of-the-art synthetic data\napproaches like MosaicFusion, our approach reduces invalid synthetic data from\n50% to 7% and improves performance by 1% mAP on rare classes in COCO instance\nsegmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant\nimprovements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object\ndetection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance\nof YOLOv9 and YOLO11 families in instance segmentation and object detection.", "published": "2025-06-05 06:52:26", "link": "http://arxiv.org/abs/2506.04676v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CV"}
{"title": "Feature-Based Lie Group Transformer for Real-World Applications", "abstract": "The main goal of representation learning is to acquire meaningful\nrepresentations from real-world sensory inputs without supervision.\nRepresentation learning explains some aspects of human development. Various\nneural network (NN) models have been proposed that acquire empirically good\nrepresentations. However, the formulation of a good representation has not been\nestablished. We recently proposed a method for categorizing changes between a\npair of sensory inputs. A unique feature of this approach is that\ntransformations between two sensory inputs are learned to satisfy algebraic\nstructural constraints. Conventional representation learning often assumes that\ndisentangled independent feature axes is a good representation; however, we\nfound that such a representation cannot account for conditional independence.\nTo overcome this problem, we proposed a new method using group decomposition in\nGalois algebra theory. Although this method is promising for defining a more\ngeneral representation, it assumes pixel-to-pixel translation without feature\nextraction, and can only process low-resolution images with no background,\nwhich prevents real-world application. In this study, we provide a simple\nmethod to apply our group decomposition theory to a more realistic scenario by\ncombining feature extraction and object segmentation. We replace pixel\ntranslation with feature translation and formulate object segmentation as\ngrouping features under the same transformation. We validated the proposed\nmethod on a practical dataset containing both real-world object and background.\nWe believe that our model will lead to a better understanding of human\ndevelopment of object recognition in the real world.", "published": "2025-06-05 06:30:11", "link": "http://arxiv.org/abs/2506.04668v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "E-bike agents: Large Language Model-Driven E-Bike Accident Analysis and Severity Prediction", "abstract": "Electric bicycles (e-bikes) are rapidly increasing in use, raising safety\nconcerns due to a rise in accident reports. However, e-bike incident reports\noften use unstructured narrative formats, which hinders quantitative safety\nanalysis. This study introduces E-bike agents, a framework that uses large\nlanguage models (LLM) powered agents to classify and extract safety variables\nfrom unstructured incident reports. Our framework consists of four LLM agents,\nhandling data classification, information extraction, injury cause\ndetermination, and component linkage, to extract the key factors that could\nlead to E-bike accidents and cause varying severity levels. Furthermore, we\nused an ordered logit model to examine the relationship between the severity of\nthe incident and the factors retrieved, such as gender, the type of cause, and\nenvironmental conditions. Our research shows that equipment issues are slightly\nmore common than human-related ones, but human-related incidents are more often\nfatal. Specifically, pedals, tires, and brakes are frequent contributors to\naccidents. The model achieves a high weighted F1 score of 0.87 in\nclassification accuracy, highlighting the potential of using LLMs to extract\nunstructured data in niche domains, such as transportation. Our method offers a\nscalable solution to improve e-bike safety analytics and provides actionable\ninformation for policy makers, designers, and regulators.", "published": "2025-06-05 05:49:41", "link": "http://arxiv.org/abs/2506.04654v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "abstract": "Recent advances in LLMs have enabled their use as autonomous agents across a\nrange of tasks, yet they continue to struggle with formulating and adhering to\ncoherent long-term strategies. In this paper, we investigate whether LLM agents\ncan self-improve when placed in environments that explicitly challenge their\nstrategic planning abilities. Using the board game Settlers of Catan, accessed\nthrough the open-source Catanatron framework, we benchmark a progression of\nLLM-based agents, from a simple game-playing agent to systems capable of\nautonomously rewriting their own prompts and their player agent's code. We\nintroduce a multi-agent architecture in which specialized roles (Analyzer,\nResearcher, Coder, and Player) collaborate to iteratively analyze gameplay,\nresearch new strategies, and modify the agent's logic or prompt. By comparing\nmanually crafted agents to those evolved entirely by LLMs, we evaluate how\neffectively these systems can diagnose failure and adapt over time. Our results\nshow that self-evolving agents, particularly when powered by models like Claude\n3.7 and GPT-4o, outperform static baselines by autonomously adopting their\nstrategies, passing along sample behavior to game-playing agents, and\ndemonstrating adaptive reasoning over multiple iterations.", "published": "2025-06-05 05:45:24", "link": "http://arxiv.org/abs/2506.04651v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "CHANCERY: Evaluating corporate governance reasoning capabilities in language models", "abstract": "Law has long been a domain that has been popular in natural language\nprocessing (NLP) applications. Reasoning (ratiocination and the ability to make\nconnections to precedent) is a core part of the practice of the law in the real\nworld. Nevertheless, while multiple legal datasets exist, none have thus far\nfocused specifically on reasoning tasks. We focus on a specific aspect of the\nlegal landscape by introducing a corporate governance reasoning benchmark\n(CHANCERY) to test a model's ability to reason about whether\nexecutive/board/shareholder's proposed actions are consistent with corporate\ngovernance charters. This benchmark introduces a first-of-its-kind corporate\ngovernance reasoning test for language models - modeled after real world\ncorporate governance law. The benchmark consists of a corporate charter (a set\nof governing covenants) and a proposal for executive action. The model's task\nis one of binary classification: reason about whether the action is consistent\nwith the rules contained within the charter. We create the benchmark following\nestablished principles of corporate governance - 24 concrete corporate\ngovernance principles established in and 79 real life corporate charters\nselected to represent diverse industries from a total dataset of 10k real life\ncorporate charters. Evaluations on state-of-the-art (SOTA) reasoning models\nconfirm the difficulty of the benchmark, with models such as Claude 3.7 Sonnet\nand GPT-4o achieving 64.5% and 75.2% accuracy respectively. Reasoning agents\nexhibit superior performance, with agents based on the ReAct and CodeAct\nframeworks scoring 76.1% and 78.1% respectively, further confirming the\nadvanced legal reasoning capabilities required to score highly on the\nbenchmark. We also conduct an analysis of the types of questions which current\nreasoning models struggle on, revealing insights into the legal reasoning\ncapabilities of SOTA models.", "published": "2025-06-05 05:13:32", "link": "http://arxiv.org/abs/2506.04636v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error Diagnosis in GUI Automation", "abstract": "In recent years, Multimodal Large Language Models (MLLMs) have been\nextensively utilized for multimodal reasoning tasks, including Graphical User\nInterface (GUI) automation. Unlike general offline multimodal tasks, GUI\nautomation is executed in online interactive environments, necessitating\nstep-by-step decision-making based on real-time status of the environment. This\ntask has a lower tolerance for decision-making errors at each step, as any\nmistakes may cumulatively disrupt the process and potentially lead to\nirreversible outcomes like deletions or payments. To address these issues, we\nintroduce a pre-operative critic mechanism that provides effective feedback\nprior to the actual execution, by reasoning about the potential outcome and\ncorrectness of actions. Specifically, we propose a Suggestion-aware Gradient\nRelative Policy Optimization (S-GRPO) strategy to construct our pre-operative\ncritic model GUI-Critic-R1, incorporating a novel suggestion reward to enhance\nthe reliability of the model's feedback. Furthermore, we develop a\nreasoning-bootstrapping based data collection pipeline to create a\nGUI-Critic-Train and a GUI-Critic-Test, filling existing gaps in GUI critic\ndata. Static experiments on the GUI-Critic-Test across both mobile and web\ndomains reveal that our GUI-Critic-R1 offers significant advantages in critic\naccuracy compared to current MLLMs. Dynamic evaluation on GUI automation\nbenchmark further highlights the effectiveness and superiority of our model, as\nevidenced by improved success rates and operational efficiency.", "published": "2025-06-05 04:12:36", "link": "http://arxiv.org/abs/2506.04614v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "DeePoly: A High-Order Accuracy and Efficiency Deep-Polynomial Framework for Scientific Machine Learning", "abstract": "Recently, machine learning methods have gained significant traction in\nscientific computing, particularly for solving Partial Differential Equations\n(PDEs). However, methods based on deep neural networks (DNNs) often lack\nconvergence guarantees and computational efficiency compared to traditional\nnumerical schemes. This work introduces DeePoly, a novel framework that\ntransforms the solution paradigm from pure non-convex parameter optimization to\na two-stage approach: first employing a DNN to capture complex global features,\nfollowed by linear space optimization with combined DNN-extracted features\n(Scoper) and polynomial basis functions (Sniper). This strategic combination\nleverages the complementary strengths of both methods -- DNNs excel at\napproximating complex global features (i.e., high-gradient features) and\nstabilize the polynomial approximation while polynomial bases provide\nhigh-precision local corrections with convergence guarantees. Theoretical\nanalysis and numerical experiments demonstrate that this approach significantly\nenhances both high-order accuracy and efficiency across diverse problem types\nwhile maintaining mesh-free and scheme-free properties. This paper also serves\nas a theoretical exposition for the open-source project DeePoly.", "published": "2025-06-05 04:10:52", "link": "http://arxiv.org/abs/2506.04613v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Judicial Permission", "abstract": "This paper examines the significance of weak permissions in criminal trials\n(\\emph{judicial permission}). It introduces a dialogue game model to\nsystematically address judicial permissions, considering different standards of\nproof and argumentation semantics.", "published": "2025-06-05 04:00:24", "link": "http://arxiv.org/abs/2506.04610v1", "categories": ["cs.AI", "cs.CY", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets", "abstract": "In studies of transferable learning, scaling laws are obtained for various\nimportant foundation models to predict their properties and performance at\nlarger scales. We show here how scaling law derivation can also be used for\nmodel and dataset comparison, allowing to decide which procedure is to be\npreferred for pre-training. For the first time, full scaling laws based on\ndense measurements across a wide span of model and samples seen scales are\nderived for two important language-vision learning procedures, CLIP and MaMMUT,\nthat use either contrastive only or contrastive and captioning text generative\nloss. Ensuring sufficient prediction accuracy for held out points, we use\nderived scaling laws to compare both models, obtaining evidence for MaMMUT's\nstronger improvement with scale and better sample efficiency than standard\nCLIP. To strengthen validity of the comparison, we show scaling laws for\nvarious downstream tasks, classification, retrieval, and segmentation, and for\ndifferent open datasets, DataComp, DFN and Re-LAION, observing consistently the\nsame trends. We show that comparison can also be performed when deriving\nscaling laws with a constant learning rate schedule, reducing compute cost.\nAccurate derivation of scaling laws provides thus means to perform model and\ndataset comparison across scale spans, avoiding misleading conclusions based on\nmeasurements from single reference scales only, paving the road for systematic\ncomparison and improvement of open foundation models and datasets for their\ncreation. We release all the pre-trained models with their intermediate\ncheckpoints, including openMaMMUT-L/14, which achieves $80.3\\%$ zero-shot\nImageNet-1k accuracy, trained on 12.8B samples from DataComp-1.4B. Code for\nreproducing experiments in the paper and raw experiments data can be found at\nhttps://github.com/LAION-AI/scaling-laws-for-comparison.", "published": "2025-06-05 03:35:59", "link": "http://arxiv.org/abs/2506.04598v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Intelligent Channel Allocation for IEEE 802.11be Multi-Link Operation: When MAB Meets LLM", "abstract": "WiFi networks have achieved remarkable success in enabling seamless\ncommunication and data exchange worldwide. The IEEE 802.11be standard, known as\nWiFi 7, introduces Multi-Link Operation (MLO), a groundbreaking feature that\nenables devices to establish multiple simultaneous connections across different\nbands and channels. While MLO promises substantial improvements in network\nthroughput and latency reduction, it presents significant challenges in channel\nallocation, particularly in dense network environments. Current research has\npredominantly focused on performance analysis and throughput optimization\nwithin static WiFi 7 network configurations. In contrast, this paper addresses\nthe dynamic channel allocation problem in dense WiFi 7 networks with MLO\ncapabilities. We formulate this challenge as a combinatorial optimization\nproblem, leveraging a novel network performance analysis mechanism. Given the\ninherent lack of prior network information, we model the problem within a\nMulti-Armed Bandit (MAB) framework to enable online learning of optimal channel\nallocations. Our proposed Best-Arm Identification-enabled Monte Carlo Tree\nSearch (BAI-MCTS) algorithm includes rigorous theoretical analysis, providing\nupper bounds for both sample complexity and error probability. To further\nreduce sample complexity and enhance generalizability across diverse network\nscenarios, we put forth LLM-BAI-MCTS, an intelligent algorithm for the dynamic\nchannel allocation problem by integrating the Large Language Model (LLM) into\nthe BAI-MCTS algorithm. Numerical results demonstrate that the BAI-MCTS\nalgorithm achieves a convergence rate approximately $50.44\\%$ faster than the\nstate-of-the-art algorithms when reaching $98\\%$ of the optimal value. Notably,\nthe convergence rate of the LLM-BAI-MCTS algorithm increases by over $63.32\\%$\nin dense networks.", "published": "2025-06-05 03:19:57", "link": "http://arxiv.org/abs/2506.04594v1", "categories": ["cs.NI", "cs.AI", "eess.SP", "I.2.7"], "primary_category": "cs.NI"}
{"title": "OpenAg: Democratizing Agricultural Intelligence", "abstract": "Agriculture is undergoing a major transformation driven by artificial\nintelligence (AI), machine learning, and knowledge representation technologies.\nHowever, current agricultural intelligence systems often lack contextual\nunderstanding, explainability, and adaptability, especially for smallholder\nfarmers with limited resources. General-purpose large language models (LLMs),\nwhile powerful, typically lack the domain-specific knowledge and contextual\nreasoning needed for practical decision support in farming. They tend to\nproduce recommendations that are too generic or unrealistic for real-world\napplications. To address these challenges, we present OpenAg, a comprehensive\nframework designed to advance agricultural artificial general intelligence\n(AGI). OpenAg combines domain-specific foundation models, neural knowledge\ngraphs, multi-agent reasoning, causal explainability, and adaptive transfer\nlearning to deliver context-aware, explainable, and actionable insights. The\nsystem includes: (i) a unified agricultural knowledge base that integrates\nscientific literature, sensor data, and farmer-generated knowledge; (ii) a\nneural agricultural knowledge graph for structured reasoning and inference;\n(iii) an adaptive multi-agent reasoning system where AI agents specialize and\ncollaborate across agricultural domains; and (iv) a causal transparency\nmechanism that ensures AI recommendations are interpretable, scientifically\ngrounded, and aligned with real-world constraints. OpenAg aims to bridge the\ngap between scientific knowledge and the tacit expertise of experienced farmers\nto support scalable and locally relevant agricultural decision-making.", "published": "2025-06-05 02:44:38", "link": "http://arxiv.org/abs/2506.04571v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "BESA: Boosting Encoder Stealing Attack with Perturbation Recovery", "abstract": "To boost the encoder stealing attack under the perturbation-based defense\nthat hinders the attack performance, we propose a boosting encoder stealing\nattack with perturbation recovery named BESA. It aims to overcome\nperturbation-based defenses. The core of BESA consists of two modules:\nperturbation detection and perturbation recovery, which can be combined with\ncanonical encoder stealing attacks. The perturbation detection module utilizes\nthe feature vectors obtained from the target encoder to infer the defense\nmechanism employed by the service provider. Once the defense mechanism is\ndetected, the perturbation recovery module leverages the well-designed\ngenerative model to restore a clean feature vector from the perturbed one.\nThrough extensive evaluations based on various datasets, we demonstrate that\nBESA significantly enhances the surrogate encoder accuracy of existing encoder\nstealing attacks by up to 24.63\\% when facing state-of-the-art defenses and\ncombinations of multiple defenses.", "published": "2025-06-05 02:14:30", "link": "http://arxiv.org/abs/2506.04556v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "hdl2v: A Code Translation Dataset for Enhanced LLM Verilog Generation", "abstract": "Large language models (LLMs) are playing an increasingly large role in\ndomains such as code generation, including hardware code generation, where\nVerilog is the key language. However, the amount of publicly available Verilog\ncode pales in comparison to the amount of code available for software languages\nlike Python. In this work, we present hdl2v (\"HDL-to-Verilog\"), a dataset which\nseeks to increase the amount of available human-written Verilog data by\ntranslating or compiling three other hardware description languages - VHDL,\nChisel, and PyMTL3 - to Verilog. Furthermore, we demonstrate the value of hdl2v\nin enhancing LLM Verilog generation by improving performance of a 32\nbillion-parameter open-weight model by up to 23% (pass@10) in VerilogEvalV2,\nwithout utilizing any data augmentation or knowledge distillation from larger\nmodels. We also show hdl2v's ability to boost the performance of a data\naugmentation-based fine-tuning approach by 63%. Finally, we characterize and\nanalyze our dataset to better understand which characteristics of\nHDL-to-Verilog datasets can be expanded upon in future work for even better\nperformance.", "published": "2025-06-05 01:29:18", "link": "http://arxiv.org/abs/2506.04544v1", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.PL"], "primary_category": "cs.AR"}
{"title": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models", "abstract": "Characterizing the diverse computational properties of human neurons via\nmultimodal electrophysiological, transcriptomic, and morphological data\nprovides the foundation for constructing and validating bio-realistic neuron\nmodels that can advance our understanding of fundamental mechanisms underlying\nbrain function. However, current modeling approaches remain constrained by the\nlimited availability and intrinsic variability of experimental neuronal data.\nTo capture variability, ensembles of deterministic models are often used, but\nare difficult to scale as model generation requires repeating computationally\nexpensive optimization for each neuron. While deep learning is becoming\nincreasingly relevant in this space, it fails to capture the full biophysical\ncomplexity of neurons, their nonlinear voltage dynamics, and variability. To\naddress these shortcomings, we introduce NOBLE, a neural operator framework\nthat learns a mapping from a continuous frequency-modulated embedding of\ninterpretable neuron features to the somatic voltage response induced by\ncurrent injection. Trained on data generated from biophysically realistic\nneuron models, NOBLE predicts distributions of neural dynamics accounting for\nthe intrinsic experimental variability. Unlike conventional bio-realistic\nneuron models, interpolating within the embedding space offers models whose\ndynamics are consistent with experimentally observed responses. NOBLE is the\nfirst scaled-up deep learning framework validated on real experimental data,\nenabling efficient generation of synthetic neurons that exhibit trial-to-trial\nvariability and achieve a $4200\\times$ speedup over numerical solvers. To this\nend, NOBLE captures fundamental neural properties, opening the door to a better\nunderstanding of cellular composition and computations, neuromorphic\narchitectures, large-scale brain circuits, and general neuroAI applications.", "published": "2025-06-05 01:01:18", "link": "http://arxiv.org/abs/2506.04536v1", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Is It JUST Semantics? A Case Study of Discourse Particle Understanding in LLMs", "abstract": "Discourse particles are crucial elements that subtly shape the meaning of\ntext. These words, often polyfunctional, give rise to nuanced and often quite\ndisparate semantic/discourse effects, as exemplified by the diverse uses of the\nparticle \"just\" (e.g., exclusive, temporal, emphatic). This work investigates\nthe capacity of LLMs to distinguish the fine-grained senses of English \"just\",\na well-studied example in formal semantics, using data meticulously created and\nlabeled by expert linguists. Our findings reveal that while LLMs exhibit some\nability to differentiate between broader categories, they struggle to fully\ncapture more subtle nuances, highlighting a gap in their understanding of\ndiscourse particles.", "published": "2025-06-05 00:59:05", "link": "http://arxiv.org/abs/2506.04534v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VideoMathQA: Benchmarking Mathematical Reasoning via Multimodal Understanding in Videos", "abstract": "Mathematical reasoning in real-world video settings presents a fundamentally\ndifferent challenge than in static images or text. It requires interpreting\nfine-grained visual information, accurately reading handwritten or digital\ntext, and integrating spoken cues, often dispersed non-linearly over time. In\nsuch multimodal contexts, success hinges not just on perception, but on\nselectively identifying and integrating the right contextual details from a\nrich and noisy stream of content. To this end, we introduce VideoMathQA, a\nbenchmark designed to evaluate whether models can perform such temporally\nextended cross-modal reasoning on videos. The benchmark spans 10 diverse\nmathematical domains, covering videos ranging from 10 seconds to over 1 hour.\nIt requires models to interpret structured visual content, understand\ninstructional narratives, and jointly ground concepts across visual, audio, and\ntextual modalities. We employ graduate-level experts to ensure high quality,\ntotaling over $920$ man-hours of annotation. To reflect real-world scenarios,\nquestions are designed around three core reasoning challenges: direct problem\nsolving, where answers are grounded in the presented question; conceptual\ntransfer, which requires applying learned methods to new problems; and deep\ninstructional comprehension, involving multi-step reasoning over extended\nexplanations and partially worked-out solutions. Each question includes\nmulti-step reasoning annotations, enabling fine-grained diagnosis of model\ncapabilities. Through this benchmark, we highlight the limitations of existing\napproaches and establish a systematic evaluation framework for models that must\nreason, rather than merely perceive, across temporally extended and\nmodality-rich mathematical problem settings. Our benchmark and evaluation code\nare available at: https://mbzuai-oryx.github.io/VideoMathQA", "published": "2025-06-05 17:59:58", "link": "http://arxiv.org/abs/2506.05349v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Contrastive Flow Matching", "abstract": "Unconditional flow-matching trains diffusion models to transport samples from\na source distribution to a target distribution by enforcing that the flows\nbetween sample pairs are unique. However, in conditional settings (e.g.,\nclass-conditioned models), this uniqueness is no longer guaranteed--flows from\ndifferent conditions may overlap, leading to more ambiguous generations. We\nintroduce Contrastive Flow Matching, an extension to the flow matching\nobjective that explicitly enforces uniqueness across all conditional flows,\nenhancing condition separation. Our approach adds a contrastive objective that\nmaximizes dissimilarities between predicted flows from arbitrary sample pairs.\nWe validate Contrastive Flow Matching by conducting extensive experiments\nacross varying model architectures on both class-conditioned (ImageNet-1k) and\ntext-to-image (CC3M) benchmarks. Notably, we find that training models with\nContrastive Flow Matching (1) improves training speed by a factor of up to 9x,\n(2) requires up to 5x fewer de-noising steps and (3) lowers FID by up to 8.9\ncompared to training the same models with flow matching. We release our code\nat: https://github.com/gstoica27/DeltaFM.git.", "published": "2025-06-05 17:59:58", "link": "http://arxiv.org/abs/2506.05350v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FreeTimeGS: Free Gaussians at Anytime and Anywhere for Dynamic Scene Reconstruction", "abstract": "This paper addresses the challenge of reconstructing dynamic 3D scenes with\ncomplex motions. Some recent works define 3D Gaussian primitives in the\ncanonical space and use deformation fields to map canonical primitives to\nobservation spaces, achieving real-time dynamic view synthesis. However, these\nmethods often struggle to handle scenes with complex motions due to the\ndifficulty of optimizing deformation fields. To overcome this problem, we\npropose FreeTimeGS, a novel 4D representation that allows Gaussian primitives\nto appear at arbitrary time and locations. In contrast to canonical Gaussian\nprimitives, our representation possesses the strong flexibility, thus improving\nthe ability to model dynamic 3D scenes. In addition, we endow each Gaussian\nprimitive with an motion function, allowing it to move to neighboring regions\nover time, which reduces the temporal redundancy. Experiments results on\nseveral datasets show that the rendering quality of our method outperforms\nrecent methods by a large margin.", "published": "2025-06-05 17:59:57", "link": "http://arxiv.org/abs/2506.05348v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SparseMM: Head Sparsity Emerges from Visual Concept Responses in MLLMs", "abstract": "Multimodal Large Language Models (MLLMs) are commonly derived by extending\npre-trained Large Language Models (LLMs) with visual capabilities. In this\nwork, we investigate how MLLMs process visual inputs by analyzing their\nattention mechanisms. We reveal a surprising sparsity phenomenon: only a small\nsubset (approximately less than 5%) of attention heads in LLMs actively\ncontribute to visual understanding, termed visual heads. To identify these\nheads efficiently, we design a training-free framework that quantifies\nhead-level visual relevance through targeted response analysis. Building on\nthis discovery, we introduce SparseMM, a KV-Cache optimization strategy that\nallocates asymmetric computation budgets to heads in LLMs based on their visual\nscores, leveraging the sparity of visual heads for accelerating the inference\nof MLLMs. Compared with prior KV-Cache acceleration methods that ignore the\nparticularity of visual, SparseMM prioritizes stress and retaining visual\nsemantics during decoding. Extensive evaluations across mainstream multimodal\nbenchmarks demonstrate that SparseMM achieves superior accuracy-efficiency\ntrade-offs. Notably, SparseMM delivers 1.38x real-time acceleration and 52%\nmemory reduction during generation while maintaining performance parity on\nefficiency test. Our project is open sourced at\nhttps://github.com/CR400AF-A/SparseMM.", "published": "2025-06-05 17:59:55", "link": "http://arxiv.org/abs/2506.05344v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Neural Inverse Rendering from Propagating Light", "abstract": "We present the first system for physically based, neural inverse rendering\nfrom multi-viewpoint videos of propagating light. Our approach relies on a\ntime-resolved extension of neural radiance caching -- a technique that\naccelerates inverse rendering by storing infinite-bounce radiance arriving at\nany point from any direction. The resulting model accurately accounts for\ndirect and indirect light transport effects and, when applied to captured\nmeasurements from a flash lidar system, enables state-of-the-art 3D\nreconstruction in the presence of strong indirect light. Further, we\ndemonstrate view synthesis of propagating light, automatic decomposition of\ncaptured measurements into direct and indirect components, as well as novel\ncapabilities such as multi-view time-resolved relighting of captured scenes.", "published": "2025-06-05 17:59:55", "link": "http://arxiv.org/abs/2506.05347v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ContentV: Efficient Training of Video Generation Models with Limited Compute", "abstract": "Recent advances in video generation demand increasingly efficient training\nrecipes to mitigate escalating computational costs. In this report, we present\nContentV, an 8B-parameter text-to-video model that achieves state-of-the-art\nperformance (85.14 on VBench) after training on 256 x 64GB Neural Processing\nUnits (NPUs) for merely four weeks. ContentV generates diverse, high-quality\nvideos across multiple resolutions and durations from text prompts, enabled by\nthree key innovations: (1) A minimalist architecture that maximizes reuse of\npre-trained image generation models for video generation; (2) A systematic\nmulti-stage training strategy leveraging flow matching for enhanced efficiency;\nand (3) A cost-effective reinforcement learning with human feedback framework\nthat improves generation quality without requiring additional human\nannotations. All the code and models are available at:\nhttps://contentv.github.io.", "published": "2025-06-05 17:59:54", "link": "http://arxiv.org/abs/2506.05343v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Defurnishing with X-Ray Vision: Joint Removal of Furniture from Panoramas and Mesh", "abstract": "We present a pipeline for generating defurnished replicas of indoor spaces\nrepresented as textured meshes and corresponding multi-view panoramic images.\nTo achieve this, we first segment and remove furniture from the mesh\nrepresentation, extend planes, and fill holes, obtaining a simplified\ndefurnished mesh (SDM). This SDM acts as an ``X-ray'' of the scene's underlying\nstructure, guiding the defurnishing process. We extract Canny edges from depth\nand normal images rendered from the SDM. We then use these as a guide to remove\nthe furniture from panorama images via ControlNet inpainting. This control\nsignal ensures the availability of global geometric information that may be\nhidden from a particular panoramic view by the furniture being removed. The\ninpainted panoramas are used to texture the mesh. We show that our approach\nproduces higher quality assets than methods that rely on neural radiance\nfields, which tend to produce blurry low-resolution images, or RGB-D\ninpainting, which is highly susceptible to hallucinations.", "published": "2025-06-05 17:59:30", "link": "http://arxiv.org/abs/2506.05338v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VideoMolmo: Spatio-Temporal Grounding Meets Pointing", "abstract": "Spatio-temporal localization is vital for precise interactions across diverse\ndomains, from biological research to autonomous navigation and interactive\ninterfaces. Current video-based approaches, while proficient in tracking, lack\nthe sophisticated reasoning capabilities of large language models, limiting\ntheir contextual understanding and generalization. We introduce VideoMolmo, a\nlarge multimodal model tailored for fine-grained spatio-temporal pointing\nconditioned on textual descriptions. Building upon the Molmo architecture,\nVideoMolmo incorporates a temporal module utilizing an attention mechanism to\ncondition each frame on preceding frames, ensuring temporal consistency.\nAdditionally, our novel temporal mask fusion pipeline employs SAM2 for\nbidirectional point propagation, significantly enhancing coherence across video\nsequences. This two-step decomposition, i.e., first using the LLM to generate\nprecise pointing coordinates, then relying on a sequential mask-fusion module\nto produce coherent segmentation, not only simplifies the task for the language\nmodel but also enhances interpretability. Due to the lack of suitable datasets,\nwe curate a comprehensive dataset comprising 72k video-caption pairs annotated\nwith 100k object points. To evaluate the generalization of VideoMolmo, we\nintroduce VPoS-Bench, a challenging out-of-distribution benchmark spanning five\nreal-world scenarios: Cell Tracking, Egocentric Vision, Autonomous Driving,\nVideo-GUI Interaction, and Robotics. We also evaluate our model on Referring\nVideo Object Segmentation (Refer-VOS) and Reasoning VOS tasks. In comparison to\nexisting models, VideoMolmo substantially improves spatio-temporal pointing\naccuracy and reasoning capability. Our code and models are publicly available\nat https://github.com/mbzuai-oryx/VideoMolmo.", "published": "2025-06-05 17:59:29", "link": "http://arxiv.org/abs/2506.05336v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning", "abstract": "Chain-of-Thought (CoT) has widely enhanced mathematical reasoning in Large\nLanguage Models (LLMs), but it still remains challenging for extending it to\nmultimodal domains. Existing works either adopt a similar textual reasoning for\nimage input, or seek to interleave visual signals into mathematical CoT.\nHowever, they face three key limitations for math problem-solving: reliance on\ncoarse-grained box-shaped image regions, limited perception of vision encoders\non math content, and dependence on external capabilities for visual\nmodification. In this paper, we propose MINT-CoT, introducing Mathematical\nINterleaved Tokens for Chain-of-Thought visual reasoning. MINT-CoT adaptively\ninterleaves relevant visual tokens into textual reasoning steps via an\nInterleave Token, which dynamically selects visual regions of any shapes within\nmath figures. To empower this capability, we construct the MINT-CoT dataset,\ncontaining 54K mathematical problems aligning each reasoning step with visual\nregions at the token level, accompanied by a rigorous data generation pipeline.\nWe further present a three-stage MINT-CoT training strategy, progressively\ncombining text-only CoT SFT, interleaved CoT SFT, and interleaved CoT RL, which\nderives our MINT-CoT-7B model. Extensive experiments demonstrate the\neffectiveness of our method for effective visual interleaved reasoning in\nmathematical domains, where MINT-CoT-7B outperforms the baseline model by\n+34.08% on MathVista, +28.78% on GeoQA, and +23.2% on MMStar, respectively. Our\ncode and data are available at https://github.com/xinyan-cxy/MINT-CoT", "published": "2025-06-05 17:59:02", "link": "http://arxiv.org/abs/2506.05331v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "AV-Reasoner: Improving and Benchmarking Clue-Grounded Audio-Visual Counting for MLLMs", "abstract": "Despite progress in video understanding, current MLLMs struggle with counting\ntasks. Existing benchmarks are limited by short videos, close-set queries, lack\nof clue annotations, and weak multimodal coverage. In this paper, we introduce\nCG-AV-Counting, a manually-annotated clue-grounded counting benchmark with\n1,027 multimodal questions and 5,845 annotated clues over 497 long videos. It\nsupports both black-box and white-box evaluation, serving as a comprehensive\ntestbed for both end-to-end and reasoning-based counting. To explore ways to\nimprove model's counting capability, we propose AV-Reasoner, a model trained\nwith GRPO and curriculum learning to generalize counting ability from related\ntasks. AV-Reasoner achieves state-of-the-art results across multiple\nbenchmarks, demonstrating the effectiveness of reinforcement learning. However,\nexperiments show that on out-of-domain benchmarks, reasoning in the language\nspace fails to bring performance gains. The code and benchmark have been\nrealeased on https://av-reasoner.github.io.", "published": "2025-06-05 17:58:33", "link": "http://arxiv.org/abs/2506.05328v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Revisiting Depth Representations for Feed-Forward 3D Gaussian Splatting", "abstract": "Depth maps are widely used in feed-forward 3D Gaussian Splatting (3DGS)\npipelines by unprojecting them into 3D point clouds for novel view synthesis.\nThis approach offers advantages such as efficient training, the use of known\ncamera poses, and accurate geometry estimation. However, depth discontinuities\nat object boundaries often lead to fragmented or sparse point clouds, degrading\nrendering quality -- a well-known limitation of depth-based representations. To\ntackle this issue, we introduce PM-Loss, a novel regularization loss based on a\npointmap predicted by a pre-trained transformer. Although the pointmap itself\nmay be less accurate than the depth map, it effectively enforces geometric\nsmoothness, especially around object boundaries. With the improved depth map,\nour method significantly improves the feed-forward 3DGS across various\narchitectures and scenes, delivering consistently better rendering results. Our\nproject page: https://aim-uofa.github.io/PMLoss", "published": "2025-06-05 17:58:23", "link": "http://arxiv.org/abs/2506.05327v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs", "abstract": "Remarkable progress in 2D Vision-Language Models (VLMs) has spurred interest\nin extending them to 3D settings for tasks like 3D Question Answering, Dense\nCaptioning, and Visual Grounding. Unlike 2D VLMs that typically process images\nthrough an image encoder, 3D scenes, with their intricate spatial structures,\nallow for diverse model architectures. Based on their encoder design, this\npaper categorizes recent 3D VLMs into 3D object-centric, 2D image-based, and 3D\nscene-centric approaches. Despite the architectural similarity of 3D\nscene-centric VLMs to their 2D counterparts, they have exhibited comparatively\nlower performance compared with the latest 3D object-centric and 2D image-based\napproaches. To understand this gap, we conduct an in-depth analysis, revealing\nthat 3D scene-centric VLMs show limited reliance on the 3D scene encoder, and\nthe pre-train stage appears less effective than in 2D VLMs. Furthermore, we\nobserve that data scaling benefits are less pronounced on larger datasets. Our\ninvestigation suggests that while these models possess cross-modal alignment\ncapabilities, they tend to over-rely on linguistic cues and overfit to frequent\nanswer distributions, thereby diminishing the effective utilization of the 3D\nencoder. To address these limitations and encourage genuine 3D scene\nunderstanding, we introduce a novel 3D Relevance Discrimination QA dataset\ndesigned to disrupt shortcut learning and improve 3D understanding. Our\nfindings highlight the need for advanced evaluation and improved strategies for\nbetter 3D understanding in 3D VLMs.", "published": "2025-06-05 17:56:12", "link": "http://arxiv.org/abs/2506.05318v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation", "abstract": "Neural rendering has made significant strides in 3D reconstruction and novel\nview synthesis. With the integration with physics, it opens up new\napplications. The inverse problem of estimating physics from visual data,\nhowever, still remains challenging, limiting its effectiveness for applications\nlike physically accurate digital twin creation in robotics and XR. Existing\nmethods that incorporate physics into neural rendering frameworks typically\nrequire dense multi-view videos as input, making them impractical for scalable,\nreal-world use. When presented with sparse multi-view videos, the sequential\noptimization strategy used by existing approaches introduces significant error\naccumulation, e.g., poor initial 3D reconstruction leads to bad material\nparameter estimation in subsequent stages. Instead of sequential optimization,\ndirectly optimizing all parameters at the same time also fails due to the\nhighly non-convex and often non-differentiable nature of the problem. We\npropose ProJo4D, a progressive joint optimization framework that gradually\nincreases the set of jointly optimized parameters guided by their sensitivity,\nleading to fully joint optimization over geometry, appearance, physical state,\nand material property. Evaluations on PAC-NeRF and Spring-Gaus datasets show\nthat ProJo4D outperforms prior work in 4D future state prediction, novel view\nrendering of future state, and material parameter estimation, demonstrating its\neffectiveness in physically grounded 4D scene understanding. For demos, please\nvisit the project webpage: https://daniel03c1.github.io/ProJo4D/", "published": "2025-06-05 17:55:56", "link": "http://arxiv.org/abs/2506.05317v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MARBLE: Material Recomposition and Blending in CLIP-Space", "abstract": "Editing materials of objects in images based on exemplar images is an active\narea of research in computer vision and graphics. We propose MARBLE, a method\nfor performing material blending and recomposing fine-grained material\nproperties by finding material embeddings in CLIP-space and using that to\ncontrol pre-trained text-to-image models. We improve exemplar-based material\nediting by finding a block in the denoising UNet responsible for material\nattribution. Given two material exemplar-images, we find directions in the\nCLIP-space for blending the materials. Further, we can achieve parametric\ncontrol over fine-grained material attributes such as roughness, metallic,\ntransparency, and glow using a shallow network to predict the direction for the\ndesired material attribute change. We perform qualitative and quantitative\nanalysis to demonstrate the efficacy of our proposed method. We also present\nthe ability of our method to perform multiple edits in a single forward pass\nand applicability to painting.\n  Project Page: https://marblecontrol.github.io/", "published": "2025-06-05 17:55:16", "link": "http://arxiv.org/abs/2506.05313v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Do It Yourself: Learning Semantic Correspondence from Pseudo-Labels", "abstract": "Finding correspondences between semantically similar points across images and\nobject instances is one of the everlasting challenges in computer vision. While\nlarge pre-trained vision models have recently been demonstrated as effective\npriors for semantic matching, they still suffer from ambiguities for symmetric\nobjects or repeated object parts. We propose to improve semantic correspondence\nestimation via 3D-aware pseudo-labeling. Specifically, we train an adapter to\nrefine off-the-shelf features using pseudo-labels obtained via 3D-aware\nchaining, filtering wrong labels through relaxed cyclic consistency, and 3D\nspherical prototype mapping constraints. While reducing the need for dataset\nspecific annotations compared to prior work, we set a new state-of-the-art on\nSPair-71k by over 4% absolute gain and by over 7% against methods with similar\nsupervision requirements. The generality of our proposed approach simplifies\nextension of training to other data sources, which we demonstrate in our\nexperiments.", "published": "2025-06-05 17:54:33", "link": "http://arxiv.org/abs/2506.05312v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Perceive Anything: Recognize, Explain, Caption, and Segment Anything in Images and Videos", "abstract": "We present Perceive Anything Model (PAM), a conceptually straightforward and\nefficient framework for comprehensive region-level visual understanding in\nimages and videos. Our approach extends the powerful segmentation model SAM 2\nby integrating Large Language Models (LLMs), enabling simultaneous object\nsegmentation with the generation of diverse, region-specific semantic outputs,\nincluding categories, label definition, functional explanations, and detailed\ncaptions. A key component, Semantic Perceiver, is introduced to efficiently\ntransform SAM 2's rich visual features, which inherently carry general vision,\nlocalization, and semantic priors into multi-modal tokens for LLM\ncomprehension. To support robust multi-granularity understanding, we also\ndevelop a dedicated data refinement and augmentation pipeline, yielding a\nhigh-quality dataset of 1.5M image and 0.6M video region-semantic annotations,\nincluding novel region-level streaming video caption data. PAM is designed for\nlightweightness and efficiency, while also demonstrates strong performance\nacross a diverse range of region understanding tasks. It runs 1.2-2.4x faster\nand consumes less GPU memory than prior approaches, offering a practical\nsolution for real-world applications. We believe that our effective approach\nwill serve as a strong baseline for future research in region-level visual\nunderstanding.", "published": "2025-06-05 17:51:39", "link": "http://arxiv.org/abs/2506.05302v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SeedVR2: One-Step Video Restoration via Diffusion Adversarial Post-Training", "abstract": "Recent advances in diffusion-based video restoration (VR) demonstrate\nsignificant improvement in visual quality, yet yield a prohibitive\ncomputational cost during inference. While several distillation-based\napproaches have exhibited the potential of one-step image restoration,\nextending existing approaches to VR remains challenging and underexplored,\nparticularly when dealing with high-resolution video in real-world settings. In\nthis work, we propose a one-step diffusion-based VR model, termed as SeedVR2,\nwhich performs adversarial VR training against real data. To handle the\nchallenging high-resolution VR within a single step, we introduce several\nenhancements to both model architecture and training procedures. Specifically,\nan adaptive window attention mechanism is proposed, where the window size is\ndynamically adjusted to fit the output resolutions, avoiding window\ninconsistency observed under high-resolution VR using window attention with a\npredefined window size. To stabilize and improve the adversarial post-training\ntowards VR, we further verify the effectiveness of a series of losses,\nincluding a proposed feature matching loss without significantly sacrificing\ntraining efficiency. Extensive experiments show that SeedVR2 can achieve\ncomparable or even better performance compared with existing VR approaches in a\nsingle step.", "published": "2025-06-05 17:51:05", "link": "http://arxiv.org/abs/2506.05301v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DM-SegNet: Dual-Mamba Architecture for 3D Medical Image Segmentation with Global Context Modeling", "abstract": "Accurate 3D medical image segmentation demands architectures capable of\nreconciling global context modeling with spatial topology preservation. While\nState Space Models (SSMs) like Mamba show potential for sequence modeling,\nexisting medical SSMs suffer from encoder-decoder incompatibility: the\nencoder's 1D sequence flattening compromises spatial structures, while\nconventional decoders fail to leverage Mamba's state propagation. We present\nDM-SegNet, a Dual-Mamba architecture integrating directional state transitions\nwith anatomy-aware hierarchical decoding. The core innovations include a\nquadri-directional spatial Mamba module employing four-directional 3D scanning\nto maintain anatomical spatial coherence, a gated spatial convolution layer\nthat enhances spatially sensitive feature representation prior to state\nmodeling, and a Mamba-driven decoding framework enabling bidirectional state\nsynchronization across scales. Extensive evaluation on two clinically\nsignificant benchmarks demonstrates the efficacy of DM-SegNet: achieving\nstate-of-the-art Dice Similarity Coefficient (DSC) of 85.44% on the Synapse\ndataset for abdominal organ segmentation and 90.22% on the BraTS2023 dataset\nfor brain tumor segmentation.", "published": "2025-06-05 17:49:46", "link": "http://arxiv.org/abs/2506.05297v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "AliTok: Towards Sequence Modeling Alignment between Tokenizer and Autoregressive Model", "abstract": "Autoregressive image generation aims to predict the next token based on\nprevious ones. However, existing image tokenizers encode tokens with\nbidirectional dependencies during the compression process, which hinders the\neffective modeling by autoregressive models. In this paper, we propose a novel\nAligned Tokenizer (AliTok), which utilizes a causal decoder to establish\nunidirectional dependencies among encoded tokens, thereby aligning the token\nmodeling approach between the tokenizer and autoregressive model. Furthermore,\nby incorporating prefix tokens and employing two-stage tokenizer training to\nenhance reconstruction consistency, AliTok achieves great reconstruction\nperformance while being generation-friendly. On ImageNet-256 benchmark, using a\nstandard decoder-only autoregressive model as the generator with only 177M\nparameters, AliTok achieves a gFID score of 1.50 and an IS of 305.9. When the\nparameter count is increased to 662M, AliTok achieves a gFID score of 1.35,\nsurpassing the state-of-the-art diffusion method with 10x faster sampling\nspeed. The code and weights are available at\nhttps://github.com/ali-vilab/alitok.", "published": "2025-06-05 17:45:10", "link": "http://arxiv.org/abs/2506.05289v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EOC-Bench: Can MLLMs Identify, Recall, and Forecast Objects in an Egocentric World?", "abstract": "The emergence of multimodal large language models (MLLMs) has driven\nbreakthroughs in egocentric vision applications. These applications necessitate\npersistent, context-aware understanding of objects, as users interact with\ntools in dynamic and cluttered environments. However, existing embodied\nbenchmarks primarily focus on static scene exploration, emphasizing object's\nappearance and spatial attributes while neglecting the assessment of dynamic\nchanges arising from users' interactions. To address this gap, we introduce\nEOC-Bench, an innovative benchmark designed to systematically evaluate\nobject-centric embodied cognition in dynamic egocentric scenarios. Specially,\nEOC-Bench features 3,277 meticulously annotated QA pairs categorized into three\ntemporal categories: Past, Present, and Future, covering 11 fine-grained\nevaluation dimensions and 3 visual object referencing types. To ensure thorough\nassessment, we develop a mixed-format human-in-the-loop annotation framework\nwith four types of questions and design a novel multi-scale temporal accuracy\nmetric for open-ended temporal evaluation. Based on EOC-Bench, we conduct\ncomprehensive evaluations of various proprietary, open-source, and object-level\nMLLMs. EOC-Bench serves as a crucial tool for advancing the embodied object\ncognitive capabilities of MLLMs, establishing a robust foundation for\ndeveloping reliable core models for embodied systems.", "published": "2025-06-05 17:44:12", "link": "http://arxiv.org/abs/2506.05287v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Stable Vision Concept Transformers for Medical Diagnosis", "abstract": "Transparency is a paramount concern in the medical field, prompting\nresearchers to delve into the realm of explainable AI (XAI). Among these XAI\nmethods, Concept Bottleneck Models (CBMs) aim to restrict the model's latent\nspace to human-understandable high-level concepts by generating a conceptual\nlayer for extracting conceptual features, which has drawn much attention\nrecently. However, existing methods rely solely on concept features to\ndetermine the model's predictions, which overlook the intrinsic feature\nembeddings within medical images. To address this utility gap between the\noriginal models and concept-based models, we propose Vision Concept Transformer\n(VCT). Furthermore, despite their benefits, CBMs have been found to negatively\nimpact model performance and fail to provide stable explanations when faced\nwith input perturbations, which limits their application in the medical field.\nTo address this faithfulness issue, this paper further proposes the Stable\nVision Concept Transformer (SVCT) based on VCT, which leverages the vision\ntransformer (ViT) as its backbone and incorporates a conceptual layer. SVCT\nemploys conceptual features to enhance decision-making capabilities by fusing\nthem with image features and ensures model faithfulness through the integration\nof Denoised Diffusion Smoothing. Comprehensive experiments on four medical\ndatasets demonstrate that our VCT and SVCT maintain accuracy while remaining\ninterpretable compared to baselines. Furthermore, even when subjected to\nperturbations, our SVCT model consistently provides faithful explanations, thus\nmeeting the needs of the medical field.", "published": "2025-06-05 17:43:27", "link": "http://arxiv.org/abs/2506.05286v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "RaySt3R: Predicting Novel Depth Maps for Zero-Shot Object Completion", "abstract": "3D shape completion has broad applications in robotics, digital twin\nreconstruction, and extended reality (XR). Although recent advances in 3D\nobject and scene completion have achieved impressive results, existing methods\nlack 3D consistency, are computationally expensive, and struggle to capture\nsharp object boundaries. Our work (RaySt3R) addresses these limitations by\nrecasting 3D shape completion as a novel view synthesis problem. Specifically,\ngiven a single RGB-D image and a novel viewpoint (encoded as a collection of\nquery rays), we train a feedforward transformer to predict depth maps, object\nmasks, and per-pixel confidence scores for those query rays. RaySt3R fuses\nthese predictions across multiple query views to reconstruct complete 3D\nshapes. We evaluate RaySt3R on synthetic and real-world datasets, and observe\nit achieves state-of-the-art performance, outperforming the baselines on all\ndatasets by up to 44% in 3D chamfer distance. Project page:\nhttps://rayst3r.github.io", "published": "2025-06-05 17:43:23", "link": "http://arxiv.org/abs/2506.05285v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Video World Models with Long-term Spatial Memory", "abstract": "Emerging world models autoregressively generate video frames in response to\nactions, such as camera movements and text prompts, among other control\nsignals. Due to limited temporal context window sizes, these models often\nstruggle to maintain scene consistency during revisits, leading to severe\nforgetting of previously generated environments. Inspired by the mechanisms of\nhuman memory, we introduce a novel framework to enhancing long-term consistency\nof video world models through a geometry-grounded long-term spatial memory. Our\nframework includes mechanisms to store and retrieve information from the\nlong-term spatial memory and we curate custom datasets to train and evaluate\nworld models with explicitly stored 3D memory mechanisms. Our evaluations show\nimproved quality, consistency, and context length compared to relevant\nbaselines, paving the way towards long-term consistent world generation.", "published": "2025-06-05 17:42:34", "link": "http://arxiv.org/abs/2506.05284v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting", "abstract": "Neural rendering techniques, including NeRF and Gaussian Splatting (GS), rely\non photometric consistency to produce high-quality reconstructions. However, in\nreal-world scenarios, it is challenging to guarantee perfect photometric\nconsistency in acquired images. Appearance codes have been widely used to\naddress this issue, but their modeling capability is limited, as a single code\nis applied to the entire image. Recently, the bilateral grid was introduced to\nperform pixel-wise color mapping, but it is difficult to optimize and constrain\neffectively. In this paper, we propose a novel multi-scale bilateral grid that\nunifies appearance codes and bilateral grids. We demonstrate that this approach\nsignificantly improves geometric accuracy in dynamic, decoupled autonomous\ndriving scene reconstruction, outperforming both appearance codes and bilateral\ngrids. This is crucial for autonomous driving, where accurate geometry is\nimportant for obstacle avoidance and control. Our method shows strong results\nacross four datasets: Waymo, NuScenes, Argoverse, and PandaSet. We further\ndemonstrate that the improvement in geometry is driven by the multi-scale\nbilateral grid, which effectively reduces floaters caused by photometric\ninconsistency.", "published": "2025-06-05 17:33:41", "link": "http://arxiv.org/abs/2506.05280v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos", "abstract": "Composed Video Retrieval (CoVR) retrieves a target video given a query video\nand a modification text describing the intended change. Existing CoVR\nbenchmarks emphasize appearance shifts or coarse event changes and therefore do\nnot test the ability to capture subtle, fast-paced temporal differences. We\nintroduce TF-CoVR, the first large-scale benchmark dedicated to temporally\nfine-grained CoVR. TF-CoVR focuses on gymnastics and diving and provides 180K\ntriplets drawn from FineGym and FineDiving. Previous CoVR benchmarks focusing\non temporal aspect, link each query to a single target segment taken from the\nsame video, limiting practical usefulness. In TF-CoVR, we instead construct\neach <query, modification> pair by prompting an LLM with the label differences\nbetween clips drawn from different videos; every pair is thus associated with\nmultiple valid target videos (3.9 on average), reflecting real-world tasks such\nas sports-highlight generation. To model these temporal dynamics we propose\nTF-CoVR-Base, a concise two-stage training framework: (i) pre-train a video\nencoder on fine-grained action classification to obtain temporally\ndiscriminative embeddings; (ii) align the composed query with candidate videos\nusing contrastive learning. We conduct the first comprehensive study of image,\nvideo, and general multimodal embedding (GME) models on temporally fine-grained\ncomposed retrieval in both zero-shot and fine-tuning regimes. On TF-CoVR,\nTF-CoVR-Base improves zero-shot mAP@50 from 5.92 (LanguageBind) to 7.51, and\nafter fine-tuning raises the state-of-the-art from 19.83 to 25.82.", "published": "2025-06-05 17:31:17", "link": "http://arxiv.org/abs/2506.05274v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Can Foundation Models Generalise the Presentation Attack Detection Capabilities on ID Cards?", "abstract": "Nowadays, one of the main challenges in presentation attack detection (PAD)\non ID cards is obtaining generalisation capabilities for a diversity of\ncountries that are issuing ID cards. Most PAD systems are trained on one, two,\nor three ID documents because of privacy protection concerns. As a result, they\ndo not obtain competitive results for commercial purposes when tested in an\nunknown new ID card country. In this scenario, Foundation Models (FM) trained\non huge datasets can help to improve generalisation capabilities. This work\nintends to improve and benchmark the capabilities of FM and how to use them to\nadapt the generalisation on PAD of ID Documents. Different test protocols were\nused, considering zero-shot and fine-tuning and two different ID card datasets.\nOne private dataset based on Chilean IDs and one open-set based on three ID\ncountries: Finland, Spain, and Slovakia. Our findings indicate that bona fide\nimages are the key to generalisation.", "published": "2025-06-05 17:24:11", "link": "http://arxiv.org/abs/2506.05263v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LeanPO: Lean Preference Optimization for Likelihood Alignment in Video-LLMs", "abstract": "Most Video Large Language Models (Video-LLMs) adopt preference alignment\ntechniques, e.g., DPO~\\citep{rafailov2024dpo}, to optimize the reward margin\nbetween a winning response ($y_w$) and a losing response ($y_l$). However, the\nlikelihood displacement observed in DPO indicates that both $\\log \\pi_\\theta\n(y_w\\mid x)$ and $\\log \\pi_\\theta (y_l\\mid x) $ often decrease during training,\ninadvertently boosting the probabilities of non-target responses. In this\npaper, we systematically revisit this phenomenon from LLMs to Video-LLMs,\nshowing that it intensifies when dealing with the redundant complexity of video\ncontent. To alleviate the impact of this phenomenon, we propose \\emph{Lean\nPreference Optimization} (LeanPO), a reference-free approach that reformulates\nthe implicit reward as the average likelihood of the response with respect to\nthe policy model. A key component of LeanPO is the reward-trustworthiness\ncorrelated self-generated preference data pipeline, which carefully infuses\nrelevant prior knowledge into the model while continuously refining the\npreference data via self-reflection. This allows the policy model to obtain\nhigh-quality paired data and accurately estimate the newly defined reward, thus\nmitigating the unintended drop. In addition, we introduce a dynamic label\nsmoothing strategy that mitigates the impact of noise in responses from diverse\nvideo content, preventing the model from overfitting to spurious details.\nExtensive experiments demonstrate that LeanPO significantly enhances the\nperformance of state-of-the-art Video-LLMs, consistently boosting baselines of\nvarying capacities with minimal additional training overhead. Moreover, LeanPO\noffers a simple yet effective solution for aligning Video-LLM preferences with\nhuman trustworthiness, paving the way toward the reliable and efficient\nVideo-LLMs.", "published": "2025-06-05 17:21:16", "link": "http://arxiv.org/abs/2506.05260v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatiotemporal Contrastive Learning for Cross-View Video Localization in Unstructured Off-road Terrains", "abstract": "Robust cross-view 3-DoF localization in GPS-denied, off-road environments\nremains challenging due to (1) perceptual ambiguities from repetitive\nvegetation and unstructured terrain, and (2) seasonal shifts that significantly\nalter scene appearance, hindering alignment with outdated satellite imagery. To\naddress this, we introduce MoViX, a self-supervised cross-view video\nlocalization framework that learns viewpoint- and season-invariant\nrepresentations while preserving directional awareness essential for accurate\nlocalization. MoViX employs a pose-dependent positive sampling strategy to\nenhance directional discrimination and temporally aligned hard negative mining\nto discourage shortcut learning from seasonal cues. A motion-informed frame\nsampler selects spatially diverse frames, and a lightweight temporal aggregator\nemphasizes geometrically aligned observations while downweighting ambiguous\nones. At inference, MoViX runs within a Monte Carlo Localization framework,\nusing a learned cross-view matching module in place of handcrafted models.\nEntropy-guided temperature scaling enables robust multi-hypothesis tracking and\nconfident convergence under visual ambiguity. We evaluate MoViX on the\nTartanDrive 2.0 dataset, training on under 30 minutes of data and testing over\n12.29 km. Despite outdated satellite imagery, MoViX localizes within 25 meters\nof ground truth 93% of the time, and within 50 meters 100% of the time in\nunseen regions, outperforming state-of-the-art baselines without\nenvironment-specific tuning. We further demonstrate generalization on a\nreal-world off-road dataset from a geographically distinct site with a\ndifferent robot platform.", "published": "2025-06-05 17:10:29", "link": "http://arxiv.org/abs/2506.05250v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Aligning Latent Spaces with Flow Priors", "abstract": "This paper presents a novel framework for aligning learnable latent spaces to\narbitrary target distributions by leveraging flow-based generative models as\npriors. Our method first pretrains a flow model on the target features to\ncapture the underlying distribution. This fixed flow model subsequently\nregularizes the latent space via an alignment loss, which reformulates the flow\nmatching objective to treat the latents as optimization targets. We formally\nprove that minimizing this alignment loss establishes a computationally\ntractable surrogate objective for maximizing a variational lower bound on the\nlog-likelihood of latents under the target distribution. Notably, the proposed\nmethod eliminates computationally expensive likelihood evaluations and avoids\nODE solving during optimization. As a proof of concept, we demonstrate in a\ncontrolled setting that the alignment loss landscape closely approximates the\nnegative log-likelihood of the target distribution. We further validate the\neffectiveness of our approach through large-scale image generation experiments\non ImageNet with diverse target distributions, accompanied by detailed\ndiscussions and ablation studies. With both theoretical and empirical\nvalidation, our framework paves a new way for latent space alignment.", "published": "2025-06-05 16:59:53", "link": "http://arxiv.org/abs/2506.05240v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SAM-aware Test-time Adaptation for Universal Medical Image Segmentation", "abstract": "Universal medical image segmentation using the Segment Anything Model (SAM)\nremains challenging due to its limited adaptability to medical domains.\nExisting adaptations, such as MedSAM, enhance SAM's performance in medical\nimaging but at the cost of reduced generalization to unseen data. Therefore, in\nthis paper, we propose SAM-aware Test-Time Adaptation (SAM-TTA), a\nfundamentally different pipeline that preserves the generalization of SAM while\nimproving its segmentation performance in medical imaging via a test-time\nframework. SAM-TTA tackles two key challenges: (1) input-level discrepancies\ncaused by differences in image acquisition between natural and medical images\nand (2) semantic-level discrepancies due to fundamental differences in object\ndefinition between natural and medical domains (e.g., clear boundaries vs.\nambiguous structures). Specifically, our SAM-TTA framework comprises (1)\nSelf-adaptive Bezier Curve-based Transformation (SBCT), which adaptively\nconverts single-channel medical images into three-channel SAM-compatible inputs\nwhile maintaining structural integrity, to mitigate the input gap between\nmedical and natural images, and (2) Dual-scale Uncertainty-driven Mean Teacher\nadaptation (DUMT), which employs consistency learning to align SAM's internal\nrepresentations to medical semantics, enabling efficient adaptation without\nauxiliary supervision or expensive retraining. Extensive experiments on five\npublic datasets demonstrate that our SAM-TTA outperforms existing TTA\napproaches and even surpasses fully fine-tuned models such as MedSAM in certain\nscenarios, establishing a new paradigm for universal medical image\nsegmentation. Code can be found at https://github.com/JianghaoWu/SAM-TTA.", "published": "2025-06-05 16:38:16", "link": "http://arxiv.org/abs/2506.05221v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm", "abstract": "We introduce MonkeyOCR, a vision-language model for document parsing that\nadvances the state of the art by leveraging a Structure-Recognition-Relation\n(SRR) triplet paradigm. This design simplifies what would otherwise be a\ncomplex multi-tool pipeline (as in MinerU's modular approach) and avoids the\ninefficiencies of processing full pages with giant end-to-end models (e.g.,\nlarge multimodal LLMs like Qwen-VL). In SRR, document parsing is abstracted\ninto three fundamental questions - \"Where is it?\" (structure), \"What is it?\"\n(recognition), and \"How is it organized?\" (relation) - corresponding to layout\nanalysis, content identification, and logical ordering. This focused\ndecomposition balances accuracy and speed: it enables efficient, scalable\nprocessing without sacrificing precision. To train and evaluate this approach,\nwe introduce the MonkeyDoc (the most comprehensive document parsing dataset to\ndate), with 3.9 million instances spanning over ten document types in both\nChinese and English. Experiments show that MonkeyOCR outperforms MinerU by an\naverage of 5.1%, with particularly notable improvements on challenging content\nsuch as formulas (+15.0%) and tables (+8.6%). Remarkably, our 3B-parameter\nmodel surpasses much larger and top-performing models, including Qwen2.5-VL\n(72B) and Gemini 2.5 Pro, achieving state-of-the-art average performance on\nEnglish document parsing tasks. In addition, MonkeyOCR processes multi-page\ndocuments significantly faster (0.84 pages per second compared to 0.65 for\nMinerU and 0.12 for Qwen2.5-VL-7B). The 3B model can be efficiently deployed\nfor inference on a single NVIDIA 3090 GPU. Code and models will be released at\nhttps://github.com/Yuliang-Liu/MonkeyOCR.", "published": "2025-06-05 16:34:57", "link": "http://arxiv.org/abs/2506.05218v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DSG-World: Learning a 3D Gaussian World Model from Dual State Videos", "abstract": "Building an efficient and physically consistent world model from limited\nobservations is a long standing challenge in vision and robotics. Many existing\nworld modeling pipelines are based on implicit generative models, which are\nhard to train and often lack 3D or physical consistency. On the other hand,\nexplicit 3D methods built from a single state often require multi-stage\nprocessing-such as segmentation, background completion, and inpainting-due to\nocclusions. To address this, we leverage two perturbed observations of the same\nscene under different object configurations. These dual states offer\ncomplementary visibility, alleviating occlusion issues during state transitions\nand enabling more stable and complete reconstruction. In this paper, we present\nDSG-World, a novel end-to-end framework that explicitly constructs a 3D\nGaussian World model from Dual State observations. Our approach builds dual\nsegmentation-aware Gaussian fields and enforces bidirectional photometric and\nsemantic consistency. We further introduce a pseudo intermediate state for\nsymmetric alignment and design collaborative co-pruning trategies to refine\ngeometric completeness. DSG-World enables efficient real-to-simulation transfer\npurely in the explicit Gaussian representation space, supporting high-fidelity\nrendering and object-level scene manipulation without relying on dense\nobservations or multi-stage pipelines. Extensive experiments demonstrate strong\ngeneralization to novel views and scene states, highlighting the effectiveness\nof our approach for real-world 3D reconstruction and simulation.", "published": "2025-06-05 16:33:32", "link": "http://arxiv.org/abs/2506.05217v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Vision-Language-Garment Models For Web Knowledge Garment Understanding and Generation", "abstract": "Multimodal foundation models have demonstrated strong generalization, yet\ntheir ability to transfer knowledge to specialized domains such as garment\ngeneration remains underexplored. We introduce VLG, a vision-language-garment\nmodel that synthesizes garments from textual descriptions and visual imagery.\nOur experiments assess VLG's zero-shot generalization, investigating its\nability to transfer web-scale reasoning to unseen garment styles and prompts.\nPreliminary results indicate promising transfer capabilities, highlighting the\npotential for multimodal foundation models to adapt effectively to specialized\ndomains like fashion design.", "published": "2025-06-05 16:22:17", "link": "http://arxiv.org/abs/2506.05210v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Follow-Your-Motion: Video Motion Transfer via Efficient Spatial-Temporal Decoupled Finetuning", "abstract": "Recently, breakthroughs in the video diffusion transformer have shown\nremarkable capabilities in diverse motion generations. As for the\nmotion-transfer task, current methods mainly use two-stage Low-Rank Adaptations\n(LoRAs) finetuning to obtain better performance. However, existing\nadaptation-based motion transfer still suffers from motion inconsistency and\ntuning inefficiency when applied to large video diffusion transformers. Naive\ntwo-stage LoRA tuning struggles to maintain motion consistency between\ngenerated and input videos due to the inherent spatial-temporal coupling in the\n3D attention operator. Additionally, they require time-consuming fine-tuning\nprocesses in both stages. To tackle these issues, we propose\nFollow-Your-Motion, an efficient two-stage video motion transfer framework that\nfinetunes a powerful video diffusion transformer to synthesize complex\nmotion.Specifically, we propose a spatial-temporal decoupled LoRA to decouple\nthe attention architecture for spatial appearance and temporal motion\nprocessing. During the second training stage, we design the sparse motion\nsampling and adaptive RoPE to accelerate the tuning speed. To address the lack\nof a benchmark for this field, we introduce MotionBench, a comprehensive\nbenchmark comprising diverse motion, including creative camera motion, single\nobject motion, multiple object motion, and complex human motion. We show\nextensive evaluations on MotionBench to verify the superiority of\nFollow-Your-Motion.", "published": "2025-06-05 16:18:32", "link": "http://arxiv.org/abs/2506.05207v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OGGSplat: Open Gaussian Growing for Generalizable Reconstruction with Expanded Field-of-View", "abstract": "Reconstructing semantic-aware 3D scenes from sparse views is a challenging\nyet essential research direction, driven by the demands of emerging\napplications such as virtual reality and embodied AI. Existing per-scene\noptimization methods require dense input views and incur high computational\ncosts, while generalizable approaches often struggle to reconstruct regions\noutside the input view cone. In this paper, we propose OGGSplat, an open\nGaussian growing method that expands the field-of-view in generalizable 3D\nreconstruction. Our key insight is that the semantic attributes of open\nGaussians provide strong priors for image extrapolation, enabling both semantic\nconsistency and visual plausibility. Specifically, once open Gaussians are\ninitialized from sparse views, we introduce an RGB-semantic consistent\ninpainting module applied to selected rendered views. This module enforces\nbidirectional control between an image diffusion model and a semantic diffusion\nmodel. The inpainted regions are then lifted back into 3D space for efficient\nand progressive Gaussian parameter optimization. To evaluate our method, we\nestablish a Gaussian Outpainting (GO) benchmark that assesses both semantic and\ngenerative quality of reconstructed open-vocabulary scenes. OGGSplat also\ndemonstrates promising semantic-aware scene reconstruction capabilities when\nprovided with two view images captured directly from a smartphone camera.", "published": "2025-06-05 16:17:18", "link": "http://arxiv.org/abs/2506.05204v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Grounding Beyond Detection: Enhancing Contextual Understanding in Embodied 3D Grounding", "abstract": "Embodied 3D grounding aims to localize target objects described in human\ninstructions from ego-centric viewpoint. Most methods typically follow a\ntwo-stage paradigm where a trained 3D detector's optimized backbone parameters\nare used to initialize a grounding model. In this study, we explore a\nfundamental question: Does embodied 3D grounding benefit enough from detection?\nTo answer this question, we assess the grounding performance of detection\nmodels using predicted boxes filtered by the target category. Surprisingly,\nthese detection models without any instruction-specific training outperform the\ngrounding models explicitly trained with language instructions. This indicates\nthat even category-level embodied 3D grounding may not be well resolved, let\nalone more fine-grained context-aware grounding. Motivated by this finding, we\npropose DEGround, which shares DETR queries as object representation for both\nDEtection and Grounding and enables the grounding to benefit from basic\ncategory classification and box detection. Based on this framework, we further\nintroduce a regional activation grounding module that highlights\ninstruction-related regions and a query-wise modulation module that\nincorporates sentence-level semantic into the query representation,\nstrengthening the context-aware understanding of language instructions.\nRemarkably, DEGround outperforms state-of-the-art model BIP3D by 7.52\\% at\noverall accuracy on the EmbodiedScan validation set. The source code will be\npublicly available at https://github.com/zyn213/DEGround.", "published": "2025-06-05 16:11:57", "link": "http://arxiv.org/abs/2506.05199v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Quantifying Cross-Modality Memorization in Vision-Language Models", "abstract": "Understanding what and how neural networks memorize during training is\ncrucial, both from the perspective of unintentional memorization of potentially\nsensitive information and from the standpoint of effective knowledge\nacquisition for real-world, knowledge-intensive tasks. While previous studies\nprimarily investigate memorization within a single modality, such as text\nmemorization in large language models or image memorization in diffusion\nmodels, unified multimodal models are becoming increasingly prevalent in\npractical applications. In this work, we focus on the unique characteristics of\ncross-modality memorization and conduct a systematic study centered on\nvision-language models. To facilitate controlled experiments, we first\nintroduce a synthetic persona dataset comprising diverse synthetic person\nimages and textual descriptions. We quantify factual knowledge memorization and\ncross-modal transferability by training models on a single modality and\nevaluating their performance in the other. Our results reveal that facts\nlearned in one modality transfer to the other, but a significant gap exists\nbetween recalling information in the source and target modalities. Furthermore,\nwe observe that this gap exists across various scenarios, including more\ncapable models, machine unlearning, and the multi-hop case. At the end, we\npropose a baseline method to mitigate this challenge. We hope our study can\ninspire future research on developing more robust multimodal learning\ntechniques to enhance cross-modal transferability.", "published": "2025-06-05 16:10:47", "link": "http://arxiv.org/abs/2506.05198v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Vision-Based Autonomous MM-Wave Reflector Using ArUco-Driven Angle-of-Arrival Estimation", "abstract": "Reliable millimeter-wave (mmWave) communication in non-line-of-sight (NLoS)\nconditions remains a major challenge for both military and civilian operations,\nespecially in urban or infrastructure-limited environments. This paper presents\na vision-aided autonomous reflector system designed to enhance mmWave link\nperformance by dynamically steering signal reflections using a motorized\nmetallic plate. The proposed system leverages a monocular camera to detect\nArUco markers on allied transmitter and receiver nodes, estimate their angles\nof arrival, and align the reflector in real time for optimal signal\nredirection. This approach enables selective beam coverage by serving only\nauthenticated targets with visible markers and reduces the risk of unintended\nsignal exposure. The designed prototype, built on a Raspberry Pi 4 and\nlow-power hardware, operates autonomously without reliance on external\ninfrastructure or GPS. Experimental results at 60\\,GHz demonstrate a 23\\,dB\naverage gain in received signal strength and an 0.89 probability of maintaining\nsignal reception above a target threshold of -65 dB in an indoor environment,\nfar exceeding the static and no-reflector baselines. These results demonstrate\nthe system's potential for resilient and adaptive mmWave connectivity in\ncomplex and dynamic environments.", "published": "2025-06-05 16:07:22", "link": "http://arxiv.org/abs/2506.05195v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MokA: Multimodal Low-Rank Adaptation for MLLMs", "abstract": "In this paper, we reveal that most current efficient multimodal fine-tuning\nmethods are hindered by a key limitation: they are directly borrowed from LLMs,\noften neglecting the intrinsic differences of multimodal scenarios and even\naffecting the full utilization of all modalities. Inspired by our empirical\nobservation, we argue that unimodal adaptation and cross-modal adaptation are\ntwo essential parts for the effective fine-tuning of MLLMs. From this\nperspective, we propose Multimodal low-rank Adaptation (MokA), a\nmultimodal-aware efficient fine-tuning strategy that takes multimodal\ncharacteristics into consideration. It compresses unimodal information by\nmodality-specific parameters while explicitly enhancing cross-modal\ninteraction, ensuring both unimodal and cross-modal adaptation. Extensive\nexperiments cover three representative multimodal scenarios (audio-visual-text,\nvisual-text, and speech-text), and multiple LLM backbones (LLaMA2/3, Qwen2,\nQwen2.5-VL, etc). Consistent improvements indicate the efficacy and versatility\nof the proposed method. Ablation studies and efficiency evaluation are also\nconducted to fully asses our method. Overall, we think MokA provides a more\ntargeted solution for efficient adaptation of MLLMs, paving the way for further\nexploration. The project page is at https://gewu-lab.github.io/MokA.", "published": "2025-06-05 16:04:08", "link": "http://arxiv.org/abs/2506.05191v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Single GPU Task Adaptation of Pathology Foundation Models for Whole Slide Image Analysis", "abstract": "Pathology foundation models (PFMs) have emerged as powerful tools for\nanalyzing whole slide images (WSIs). However, adapting these pretrained PFMs\nfor specific clinical tasks presents considerable challenges, primarily due to\nthe availability of only weak (WSI-level) labels for gigapixel images,\nnecessitating multiple instance learning (MIL) paradigm for effective WSI\nanalysis. This paper proposes a novel approach for single-GPU \\textbf{T}ask\n\\textbf{A}daptation of \\textbf{PFM}s (TAPFM) that uses vision transformer\n(\\vit) attention for MIL aggregation while optimizing both for feature\nrepresentations and attention weights. The proposed approach maintains separate\ncomputational graphs for MIL aggregator and the PFM to create stable training\ndynamics that align with downstream task objectives during end-to-end\nadaptation. Evaluated on mutation prediction tasks for bladder cancer and lung\nadenocarcinoma across institutional and TCGA cohorts, TAPFM consistently\noutperforms conventional approaches, with H-Optimus-0 (TAPFM) outperforming the\nbenchmarks. TAPFM effectively handles multi-label classification of actionable\nmutations as well. Thus, TAPFM makes adaptation of powerful pre-trained PFMs\npractical on standard hardware for various clinical applications.", "published": "2025-06-05 15:56:45", "link": "http://arxiv.org/abs/2506.05184v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Track Any Anomalous Object: A Granular Video Anomaly Detection Pipeline", "abstract": "Video anomaly detection (VAD) is crucial in scenarios such as surveillance\nand autonomous driving, where timely detection of unexpected activities is\nessential. Although existing methods have primarily focused on detecting\nanomalous objects in videos -- either by identifying anomalous frames or\nobjects -- they often neglect finer-grained analysis, such as anomalous pixels,\nwhich limits their ability to capture a broader range of anomalies. To address\nthis challenge, we propose a new framework called Track Any Anomalous Object\n(TAO), which introduces a granular video anomaly detection pipeline that, for\nthe first time, integrates the detection of multiple fine-grained anomalous\nobjects into a unified framework. Unlike methods that assign anomaly scores to\nevery pixel, our approach transforms the problem into pixel-level tracking of\nanomalous objects. By linking anomaly scores to downstream tasks such as\nsegmentation and tracking, our method removes the need for threshold tuning and\nachieves more precise anomaly localization in long and complex video sequences.\nExperiments demonstrate that TAO sets new benchmarks in accuracy and\nrobustness. Project page available online.", "published": "2025-06-05 15:49:39", "link": "http://arxiv.org/abs/2506.05175v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Through-the-Wall Radar Human Activity Recognition WITHOUT Using Neural Networks", "abstract": "After a few years of research in the field of through-the-wall radar (TWR)\nhuman activity recognition (HAR), I found that we seem to be stuck in the\nmindset of training on radar image data through neural network models. The\nearliest related works in this field based on template matching did not require\na training process, and I believe they have never died. Because these methods\npossess a strong physical interpretability and are closer to the basis of\ntheoretical signal processing research. In this paper, I would like to try to\nreturn to the original path by attempting to eschew neural networks to achieve\nthe TWR HAR task and challenge to achieve intelligent recognition as neural\nnetwork models. In detail, the range-time map and Doppler-time map of TWR are\nfirst generated. Then, the initial regions of the human target foreground and\nnoise background on the maps are determined using corner detection method, and\nthe micro-Doppler signature is segmented using the multiphase active contour\nmodel. The micro-Doppler segmentation feature is discretized into a\ntwo-dimensional point cloud. Finally, the topological similarity between the\nresulting point cloud and the point clouds of the template data is calculated\nusing Mapper algorithm to obtain the recognition results. The effectiveness of\nthe proposed method is demonstrated by numerical simulated and measured\nexperiments. The open-source code of this work is released at:\nhttps://github.com/JoeyBGOfficial/Through-the-Wall-Radar-Human-Activity-Recognition-Without-Using-Neural-Networks.", "published": "2025-06-05 15:45:08", "link": "http://arxiv.org/abs/2506.05169v1", "categories": ["cs.CV", "eess.SP", "68T45", "I.5.4"], "primary_category": "cs.CV"}
{"title": "FRED: The Florence RGB-Event Drone Dataset", "abstract": "Small, fast, and lightweight drones present significant challenges for\ntraditional RGB cameras due to their limitations in capturing fast-moving\nobjects, especially under challenging lighting conditions. Event cameras offer\nan ideal solution, providing high temporal definition and dynamic range, yet\nexisting benchmarks often lack fine temporal resolution or drone-specific\nmotion patterns, hindering progress in these areas. This paper introduces the\nFlorence RGB-Event Drone dataset (FRED), a novel multimodal dataset\nspecifically designed for drone detection, tracking, and trajectory\nforecasting, combining RGB video and event streams. FRED features more than 7\nhours of densely annotated drone trajectories, using 5 different drone models\nand including challenging scenarios such as rain and adverse lighting\nconditions. We provide detailed evaluation protocols and standard metrics for\neach task, facilitating reproducible benchmarking. The authors hope FRED will\nadvance research in high-speed drone perception and multimodal spatiotemporal\nunderstanding.", "published": "2025-06-05 15:40:41", "link": "http://arxiv.org/abs/2506.05163v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PixCell: A generative foundation model for digital histopathology images", "abstract": "The digitization of histology slides has revolutionized pathology, providing\nmassive datasets for cancer diagnosis and research. Contrastive self-supervised\nand vision-language models have been shown to effectively mine large pathology\ndatasets to learn discriminative representations. On the other hand, generative\nmodels, capable of synthesizing realistic and diverse images, present a\ncompelling solution to address unique problems in pathology that involve\nsynthesizing images; overcoming annotated data scarcity, enabling\nprivacy-preserving data sharing, and performing inherently generative tasks,\nsuch as virtual staining. We introduce PixCell, the first diffusion-based\ngenerative foundation model for histopathology. We train PixCell on PanCan-30M,\na vast, diverse dataset derived from 69,184 H\\&E-stained whole slide images\ncovering various cancer types. We employ a progressive training strategy and a\nself-supervision-based conditioning that allows us to scale up training without\nany annotated data. PixCell generates diverse and high-quality images across\nmultiple cancer types, which we find can be used in place of real data to train\na self-supervised discriminative model. Synthetic images shared between\ninstitutions are subject to fewer regulatory barriers than would be the case\nwith real clinical images. Furthermore, we showcase the ability to precisely\ncontrol image generation using a small set of annotated images, which can be\nused for both data augmentation and educational purposes. Testing on a cell\nsegmentation task, a mask-guided PixCell enables targeted data augmentation,\nimproving downstream performance. Finally, we demonstrate PixCell's ability to\nuse H\\&E structural staining to infer results from molecular marker studies; we\nuse this capability to infer IHC staining from H\\&E images. Our trained models\nare publicly released to accelerate research in computational pathology.", "published": "2025-06-05 15:14:32", "link": "http://arxiv.org/abs/2506.05127v1", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "primary_category": "eess.IV"}
{"title": "Practical Manipulation Model for Robust Deepfake Detection", "abstract": "Modern deepfake detection models have achieved strong performance even on the\nchallenging cross-dataset task. However, detection performance under non-ideal\nconditions remains very unstable, limiting success on some benchmark datasets\nand making it easy to circumvent detection. Inspired by the move to a more\nreal-world degradation model in the area of image super-resolution, we have\ndeveloped a Practical Manipulation Model (PMM) that covers a larger set of\npossible forgeries. We extend the space of pseudo-fakes by using Poisson\nblending, more diverse masks, generator artifacts, and distractors.\nAdditionally, we improve the detectors' generality and robustness by adding\nstrong degradations to the training images. We demonstrate that these changes\nnot only significantly enhance the model's robustness to common image\ndegradations but also improve performance on standard benchmark datasets.\nSpecifically, we show clear increases of $3.51\\%$ and $6.21\\%$ AUC on the DFDC\nand DFDCP datasets, respectively, over the s-o-t-a LAA backbone. Furthermore,\nwe highlight the lack of robustness in previous detectors and our improvements\nin this regard. Code can be found at https://github.com/BenediktHopf/PMM", "published": "2025-06-05 15:06:16", "link": "http://arxiv.org/abs/2506.05119v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DIMCIM: A Quantitative Evaluation Framework for Default-mode Diversity and Generalization in Text-to-Image Generative Models", "abstract": "Recent advances in text-to-image (T2I) models have achieved impressive\nquality and consistency. However, this has come at the cost of representation\ndiversity. While automatic evaluation methods exist for benchmarking model\ndiversity, they either require reference image datasets or lack specificity\nabout the kind of diversity measured, limiting their adaptability and\ninterpretability. To address this gap, we introduce the Does-it/Can-it\nframework, DIM-CIM, a reference-free measurement of default-mode diversity\n(\"Does\" the model generate images with expected attributes?) and generalization\ncapacity (\"Can\" the model generate diverse attributes for a particular\nconcept?). We construct the COCO-DIMCIM benchmark, which is seeded with COCO\nconcepts and captions and augmented by a large language model. With\nCOCO-DIMCIM, we find that widely-used models improve in generalization at the\ncost of default-mode diversity when scaling from 1.5B to 8.1B parameters.\nDIMCIM also identifies fine-grained failure cases, such as attributes that are\ngenerated with generic prompts but are rarely generated when explicitly\nrequested. Finally, we use DIMCIM to evaluate the training data of a T2I model\nand observe a correlation of 0.85 between diversity in training images and\ndefault-mode diversity. Our work provides a flexible and interpretable\nframework for assessing T2I model diversity and generalization, enabling a more\ncomprehensive understanding of model performance.", "published": "2025-06-05 14:53:34", "link": "http://arxiv.org/abs/2506.05108v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Astraea: A GPU-Oriented Token-wise Acceleration Framework for Video Diffusion Transformers", "abstract": "Video diffusion transformers (vDiTs) have made impressive progress in\ntext-to-video generation, but their high computational demands present major\nchallenges for practical deployment. While existing acceleration methods reduce\nworkload at various granularities, they often rely on heuristics, limiting\ntheir applicability.\n  We introduce ASTRAEA, an automatic framework that searches for near-optimal\nconfigurations for vDiT-based video generation. At its core, ASTRAEA proposes a\nlightweight token selection mechanism and a memory-efficient, GPU-parallel\nsparse attention strategy, enabling linear reductions in execution time with\nminimal impact on generation quality. To determine optimal token reduction for\ndifferent timesteps, we further design a search framework that leverages a\nclassic evolutionary algorithm to automatically determine the distribution of\nthe token budget effectively. Together, ASTRAEA achieves up to 2.4x inference\nspeedup on a single GPU with great scalability (up to 13.2x speedup on 8 GPUs)\nwhile retaining better video quality compared to the state-of-the-art methods\n(<0.5% loss on the VBench score compared to the baseline vDiT models).", "published": "2025-06-05 14:41:38", "link": "http://arxiv.org/abs/2506.05096v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FG 2025 TrustFAA: the First Workshop on Towards Trustworthy Facial Affect Analysis: Advancing Insights of Fairness, Explainability, and Safety (TrustFAA)", "abstract": "With the increasing prevalence and deployment of Emotion AI-powered facial\naffect analysis (FAA) tools, concerns about the trustworthiness of these\nsystems have become more prominent. This first workshop on \"Towards Trustworthy\nFacial Affect Analysis: Advancing Insights of Fairness, Explainability, and\nSafety (TrustFAA)\" aims to bring together researchers who are investigating\ndifferent challenges in relation to trustworthiness-such as interpretability,\nuncertainty, biases, and privacy-across various facial affect analysis tasks,\nincluding macro/ micro-expression recognition, facial action unit detection,\nother corresponding applications such as pain and depression detection, as well\nas human-robot interaction and collaboration. In alignment with FG2025's\nemphasis on ethics, as demonstrated by the inclusion of an Ethical Impact\nStatement requirement for this year's submissions, this workshop supports\nFG2025's efforts by encouraging research, discussion and dialogue on\ntrustworthy FAA.", "published": "2025-06-05 14:40:49", "link": "http://arxiv.org/abs/2506.05095v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Synthetic Dataset Generation for Autonomous Mobile Robots Using 3D Gaussian Splatting for Vision Training", "abstract": "Annotated datasets are critical for training neural networks for object\ndetection, yet their manual creation is time- and labour-intensive, subjective\nto human error, and often limited in diversity. This challenge is particularly\npronounced in the domain of robotics, where diverse and dynamic scenarios\nfurther complicate the creation of representative datasets. To address this, we\npropose a novel method for automatically generating annotated synthetic data in\nUnreal Engine. Our approach leverages photorealistic 3D Gaussian splats for\nrapid synthetic data generation. We demonstrate that synthetic datasets can\nachieve performance comparable to that of real-world datasets while\nsignificantly reducing the time required to generate and annotate data.\nAdditionally, combining real-world and synthetic data significantly increases\nobject detection performance by leveraging the quality of real-world images\nwith the easier scalability of synthetic data. To our knowledge, this is the\nfirst application of synthetic data for training object detection algorithms in\nthe highly dynamic and varied environment of robot soccer. Validation\nexperiments reveal that a detector trained on synthetic images performs on par\nwith one trained on manually annotated real-world images when tested on robot\nsoccer match scenarios. Our method offers a scalable and comprehensive\nalternative to traditional dataset creation, eliminating the labour-intensive\nerror-prone manual annotation process. By generating datasets in a simulator\nwhere all elements are intrinsically known, we ensure accurate annotations\nwhile significantly reducing manual effort, which makes it particularly\nvaluable for robotics applications requiring diverse and scalable training\ndata.", "published": "2025-06-05 14:37:40", "link": "http://arxiv.org/abs/2506.05092v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "SeedEdit 3.0: Fast and High-Quality Generative Image Editing", "abstract": "We introduce SeedEdit 3.0, in companion with our T2I model Seedream 3.0 [22],\nwhich significantly improves over our previous version [27] in both aspects of\nedit instruction following and image content (e.g., ID/IP) preservation on real\nimage inputs. Additional to model upgrading with T2I, in this report, we\npresent several key improvements. First, we develop an enhanced data curation\npipeline with a meta-info paradigm and meta-info embedding strategy that help\nmix images from multiple data sources. This allows us to scale editing data\neffectively, and meta information is helpfult to connect VLM with diffusion\nmodel more closely. Second, we introduce a joint learning pipeline for\ncomputing a diffusion loss and a reward loss. Finally, we evaluate SeedEdit 3.0\non our testing benchmarks, for real image editing, where it achieves a best\ntrade-off between multiple aspects, yielding a high usability rate of 56.1%,\ncompared to SeedEdit 1.6 (38.4%), GPT4o (37.1%) and Gemini 2.0 (30.3%).", "published": "2025-06-05 14:30:39", "link": "http://arxiv.org/abs/2506.05083v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Survey on Vietnamese Document Analysis and Recognition: Challenges and Future Directions", "abstract": "Vietnamese document analysis and recognition (DAR) is a crucial field with\napplications in digitization, information retrieval, and automation. Despite\nadvancements in OCR and NLP, Vietnamese text recognition faces unique\nchallenges due to its complex diacritics, tonal variations, and lack of\nlarge-scale annotated datasets. Traditional OCR methods often struggle with\nreal-world document variations, while deep learning approaches have shown\npromise but remain limited by data scarcity and generalization issues.\nRecently, large language models (LLMs) and vision-language models have\ndemonstrated remarkable improvements in text recognition and document\nunderstanding, offering a new direction for Vietnamese DAR. However, challenges\nsuch as domain adaptation, multimodal learning, and computational efficiency\npersist. This survey provide a comprehensive review of existing techniques in\nVietnamese document recognition, highlights key limitations, and explores how\nLLMs can revolutionize the field. We discuss future research directions,\nincluding dataset development, model optimization, and the integration of\nmultimodal approaches for improved document intelligence. By addressing these\ngaps, we aim to foster advancements in Vietnamese DAR and encourage\ncommunity-driven solutions.", "published": "2025-06-05 14:03:18", "link": "http://arxiv.org/abs/2506.05061v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FlowDirector: Training-Free Flow Steering for Precise Text-to-Video Editing", "abstract": "Text-driven video editing aims to modify video content according to natural\nlanguage instructions. While recent training-free approaches have made progress\nby leveraging pre-trained diffusion models, they typically rely on\ninversion-based techniques that map input videos into the latent space, which\noften leads to temporal inconsistencies and degraded structural fidelity. To\naddress this, we propose FlowDirector, a novel inversion-free video editing\nframework. Our framework models the editing process as a direct evolution in\ndata space, guiding the video via an Ordinary Differential Equation (ODE) to\nsmoothly transition along its inherent spatiotemporal manifold, thereby\npreserving temporal coherence and structural details. To achieve localized and\ncontrollable edits, we introduce an attention-guided masking mechanism that\nmodulates the ODE velocity field, preserving non-target regions both spatially\nand temporally. Furthermore, to address incomplete edits and enhance semantic\nalignment with editing instructions, we present a guidance-enhanced editing\nstrategy inspired by Classifier-Free Guidance, which leverages differential\nsignals between multiple candidate flows to steer the editing trajectory toward\nstronger semantic alignment without compromising structural consistency.\nExtensive experiments across benchmarks demonstrate that FlowDirector achieves\nstate-of-the-art performance in instruction adherence, temporal consistency,\nand background preservation, establishing a new paradigm for efficient and\ncoherent video editing without inversion.", "published": "2025-06-05 13:54:40", "link": "http://arxiv.org/abs/2506.05046v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DACN: Dual-Attention Convolutional Network for Hyperspectral Image Super-Resolution", "abstract": "2D convolutional neural networks (CNNs) have attracted significant attention\nfor hyperspectral image super-resolution tasks. However, a key limitation is\ntheir reliance on local neighborhoods, which leads to a lack of global\ncontextual understanding. Moreover, band correlation and data scarcity continue\nto limit their performance. To mitigate these issues, we introduce DACN, a\ndual-attention convolutional network for hyperspectral image super-resolution.\nSpecifically, the model first employs augmented convolutions, integrating\nmulti-head attention to effectively capture both local and global feature\ndependencies. Next, we infer separate attention maps for the channel and\nspatial dimensions to determine where to focus across different channels and\nspatial positions. Furthermore, a custom optimized loss function is proposed\nthat combines L2 regularization with spatial-spectral gradient loss to ensure\naccurate spectral fidelity. Experimental results on two hyperspectral datasets\ndemonstrate that the combination of multi-head attention and channel attention\noutperforms either attention mechanism used individually.", "published": "2025-06-05 13:45:21", "link": "http://arxiv.org/abs/2506.05041v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Physical Annotation for Automated Optical Inspection: A Concept for In-Situ, Pointer-Based Trainingdata Generation", "abstract": "This paper introduces a novel physical annotation system designed to generate\ntraining data for automated optical inspection. The system uses pointer-based\nin-situ interaction to transfer the valuable expertise of trained inspection\npersonnel directly into a machine learning (ML) training pipeline. Unlike\nconventional screen-based annotation methods, our system captures physical\ntrajectories and contours directly on the object, providing a more intuitive\nand efficient way to label data. The core technology uses calibrated, tracked\npointers to accurately record user input and transform these spatial\ninteractions into standardised annotation formats that are compatible with\nopen-source annotation software. Additionally, a simple projector-based\ninterface projects visual guidance onto the object to assist users during the\nannotation process, ensuring greater accuracy and consistency. The proposed\nconcept bridges the gap between human expertise and automated data generation,\nenabling non-IT experts to contribute to the ML training pipeline and\npreventing the loss of valuable training samples. Preliminary evaluation\nresults confirm the feasibility of capturing detailed annotation trajectories\nand demonstrate that integration with CVAT streamlines the workflow for\nsubsequent ML tasks. This paper details the system architecture, calibration\nprocedures and interface design, and discusses its potential contribution to\nfuture ML data generation for automated optical inspection.", "published": "2025-06-05 13:37:24", "link": "http://arxiv.org/abs/2506.05026v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UAV4D: Dynamic Neural Rendering of Human-Centric UAV Imagery using Gaussian Splatting", "abstract": "Despite significant advancements in dynamic neural rendering, existing\nmethods fail to address the unique challenges posed by UAV-captured scenarios,\nparticularly those involving monocular camera setups, top-down perspective, and\nmultiple small, moving humans, which are not adequately represented in existing\ndatasets. In this work, we introduce UAV4D, a framework for enabling\nphotorealistic rendering for dynamic real-world scenes captured by UAVs.\nSpecifically, we address the challenge of reconstructing dynamic scenes with\nmultiple moving pedestrians from monocular video data without the need for\nadditional sensors. We use a combination of a 3D foundation model and a human\nmesh reconstruction model to reconstruct both the scene background and humans.\nWe propose a novel approach to resolve the scene scale ambiguity and place both\nhumans and the scene in world coordinates by identifying human-scene contact\npoints. Additionally, we exploit the SMPL model and background mesh to\ninitialize Gaussian splats, enabling holistic scene rendering. We evaluated our\nmethod on three complex UAV-captured datasets: VisDrone, Manipal-UAV, and\nOkutama-Action, each with distinct characteristics and 10~50 humans. Our\nresults demonstrate the benefits of our approach over existing methods in novel\nview synthesis, achieving a 1.5 dB PSNR improvement and superior visual\nsharpness.", "published": "2025-06-05 13:21:09", "link": "http://arxiv.org/abs/2506.05011v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Point Cloud Segmentation of Agricultural Vehicles using 3D Gaussian Splatting", "abstract": "Training neural networks for tasks such as 3D point cloud semantic\nsegmentation demands extensive datasets, yet obtaining and annotating\nreal-world point clouds is costly and labor-intensive. This work aims to\nintroduce a novel pipeline for generating realistic synthetic data, by\nleveraging 3D Gaussian Splatting (3DGS) and Gaussian Opacity Fields (GOF) to\ngenerate 3D assets of multiple different agricultural vehicles instead of using\ngeneric models. These assets are placed in a simulated environment, where the\npoint clouds are generated using a simulated LiDAR. This is a flexible approach\nthat allows changing the LiDAR specifications without incurring additional\ncosts. We evaluated the impact of synthetic data on segmentation models such as\nPointNet++, Point Transformer V3, and OACNN, by training and validating the\nmodels only on synthetic data. Remarkably, the PTv3 model had an mIoU of\n91.35\\%, a noteworthy result given that the model had neither been trained nor\nvalidated on any real data. Further studies even suggested that in certain\nscenarios the models trained only on synthetically generated data performed\nbetter than models trained on real-world data. Finally, experiments\ndemonstrated that the models can generalize across semantic classes, enabling\naccurate predictions on mesh models they were never trained on.", "published": "2025-06-05 13:19:27", "link": "http://arxiv.org/abs/2506.05009v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Structure-Aware Radar-Camera Depth Estimation", "abstract": "Monocular depth estimation aims to determine the depth of each pixel from an\nRGB image captured by a monocular camera. The development of deep learning has\nsignificantly advanced this field by facilitating the learning of depth\nfeatures from some well-annotated datasets\n\\cite{Geiger_Lenz_Stiller_Urtasun_2013,silberman2012indoor}. Eigen \\textit{et\nal.} \\cite{eigen2014depth} first introduce a multi-scale fusion network for\ndepth regression. Following this, subsequent improvements have come from\nreinterpreting the regression task as a classification problem\n\\cite{bhat2021adabins,Li_Wang_Liu_Jiang_2022}, incorporating additional priors\n\\cite{shao2023nddepth,yang2023gedepth}, and developing more effective objective\nfunction \\cite{xian2020structure,Yin_Liu_Shen_Yan_2019}. Despite these\nadvances, generalizing to unseen domains remains a challenge. Recently, several\nmethods have employed affine-invariant loss to enable multi-dataset joint\ntraining \\cite{MiDaS,ZeroDepth,guizilini2023towards,Dany}. Among them, Depth\nAnything \\cite{Dany} has shown leading performance in zero-shot monocular depth\nestimation. While it struggles to estimate accurate metric depth due to the\nlack of explicit depth cues, it excels at extracting structural information\nfrom unseen images, producing structure-detailed monocular depth.", "published": "2025-06-05 13:18:48", "link": "http://arxiv.org/abs/2506.05008v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Cropped Regions: New Benchmark and Corresponding Baseline for Chinese Scene Text Retrieval in Diverse Layouts", "abstract": "Chinese scene text retrieval is a practical task that aims to search for\nimages containing visual instances of a Chinese query text. This task is\nextremely challenging because Chinese text often features complex and diverse\nlayouts in real-world scenes. Current efforts tend to inherit the solution for\nEnglish scene text retrieval, failing to achieve satisfactory performance. In\nthis paper, we establish a Diversified Layout benchmark for Chinese Street View\nText Retrieval (DL-CSVTR), which is specifically designed to evaluate retrieval\nperformance across various text layouts, including vertical, cross-line, and\npartial alignments. To address the limitations in existing methods, we propose\nChinese Scene Text Retrieval CLIP (CSTR-CLIP), a novel model that integrates\nglobal visual information with multi-granularity alignment training. CSTR-CLIP\napplies a two-stage training process to overcome previous limitations, such as\nthe exclusion of visual features outside the text region and reliance on\nsingle-granularity alignment, thereby enabling the model to effectively handle\ndiverse text layouts. Experiments on existing benchmark show that CSTR-CLIP\noutperforms the previous state-of-the-art model by 18.82% accuracy and also\nprovides faster inference speed. Further analysis on DL-CSVTR confirms the\nsuperior performance of CSTR-CLIP in handling various text layouts. The dataset\nand code will be publicly available to facilitate research in Chinese scene\ntext retrieval.", "published": "2025-06-05 13:10:17", "link": "http://arxiv.org/abs/2506.04999v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PATS: Proficiency-Aware Temporal Sampling for Multi-View Sports Skill Assessment", "abstract": "Automated sports skill assessment requires capturing fundamental movement\npatterns that distinguish expert from novice performance, yet current video\nsampling methods disrupt the temporal continuity essential for proficiency\nevaluation. To this end, we introduce Proficiency-Aware Temporal Sampling\n(PATS), a novel sampling strategy that preserves complete fundamental movements\nwithin continuous temporal segments for multi-view skill assessment. PATS\nadaptively segments videos to ensure each analyzed portion contains full\nexecution of critical performance components, repeating this process across\nmultiple segments to maximize information coverage while maintaining temporal\ncoherence. Evaluated on the EgoExo4D benchmark with SkillFormer, PATS surpasses\nthe state-of-the-art accuracy across all viewing configurations (+0.65% to\n+3.05%) and delivers substantial gains in challenging domains (+26.22%\nbouldering, +2.39% music, +1.13% basketball). Systematic analysis reveals that\nPATS successfully adapts to diverse activity characteristics-from\nhigh-frequency sampling for dynamic sports to fine-grained segmentation for\nsequential skills-demonstrating its effectiveness as an adaptive approach to\ntemporal sampling that advances automated skill assessment for real-world\napplications.", "published": "2025-06-05 13:05:23", "link": "http://arxiv.org/abs/2506.04996v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-scale Image Super Resolution with a Single Auto-Regressive Model", "abstract": "In this paper we tackle Image Super Resolution (ISR), using recent advances\nin Visual Auto-Regressive (VAR) modeling. VAR iteratively estimates the\nresidual in latent space between gradually increasing image scales, a process\nreferred to as next-scale prediction. Thus, the strong priors learned during\npre-training align well with the downstream task (ISR). To our knowledge, only\nVARSR has exploited this synergy so far, showing promising results. However,\ndue to the limitations of existing residual quantizers, VARSR works only at a\nfixed resolution, i.e. it fails to map intermediate outputs to the\ncorresponding image scales. Additionally, it relies on a 1B transformer\narchitecture (VAR-d24), and leverages a large-scale private dataset to achieve\nstate-of-the-art results. We address these limitations through two novel\ncomponents: a) a Hierarchical Image Tokenization approach with a multi-scale\nimage tokenizer that progressively represents images at different scales while\nsimultaneously enforcing token overlap across scales, and b) a Direct\nPreference Optimization (DPO) regularization term that, relying solely on the\nLR and HR tokenizations, encourages the transformer to produce the latter over\nthe former. To the best of our knowledge, this is the first time a quantizer is\ntrained to force semantically consistent residuals at different scales, and the\nfirst time that preference-based optimization is used to train a VAR. Using\nthese two components, our model can denoise the LR image and super-resolve at\nhalf and full target upscale factors in a single forward pass. Additionally, we\nachieve \\textit{state-of-the-art results on ISR}, while using a small model\n(300M params vs ~1B params of VARSR), and without using external training data.", "published": "2025-06-05 13:02:23", "link": "http://arxiv.org/abs/2506.04990v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TextVidBench: A Benchmark for Long Video Scene Text Understanding", "abstract": "Despite recent progress on the short-video Text-Visual Question Answering\n(ViteVQA) task - largely driven by benchmarks such as M4-ViteVQA - existing\ndatasets still suffer from limited video duration and narrow evaluation scopes,\nmaking it difficult to adequately assess the growing capabilities of powerful\nmultimodal large language models (MLLMs). To address these limitations, we\nintroduce TextVidBench, the first benchmark specifically designed for\nlong-video text question answering (>3 minutes). TextVidBench makes three key\ncontributions: 1) Cross-domain long-video coverage: Spanning 9 categories\n(e.g., news, sports, gaming), with an average video length of 2306 seconds,\nenabling more realistic evaluation of long-video understanding. 2) A\nthree-stage evaluation framework: \"Text Needle-in-Haystack -> Temporal\nGrounding -> Text Dynamics Captioning\". 3) High-quality fine-grained\nannotations: Containing over 5,000 question-answer pairs with detailed semantic\nlabeling. Furthermore, we propose an efficient paradigm for improving large\nmodels through: (i) introducing the IT-Rope mechanism and temporal prompt\nengineering to enhance temporal perception, (ii) adopting non-uniform\npositional encoding to better handle long video sequences, and (iii) applying\nlightweight fine-tuning on video-text data. Extensive experiments on multiple\npublic datasets as well as TextVidBench demonstrate that our new benchmark\npresents significant challenges to existing models, while our proposed method\noffers valuable insights into improving long-video scene text understanding\ncapabilities.", "published": "2025-06-05 12:54:56", "link": "http://arxiv.org/abs/2506.04983v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bringing SAM to new heights: Leveraging elevation data for tree crown segmentation from drone imagery", "abstract": "Information on trees at the individual level is crucial for monitoring forest\necosystems and planning forest management. Current monitoring methods involve\nground measurements, requiring extensive cost, time and labor. Advances in\ndrone remote sensing and computer vision offer great potential for mapping\nindividual trees from aerial imagery at broad-scale. Large pre-trained vision\nmodels, such as the Segment Anything Model (SAM), represent a particularly\ncompelling choice given limited labeled data. In this work, we compare methods\nleveraging SAM for the task of automatic tree crown instance segmentation in\nhigh resolution drone imagery in three use cases: 1) boreal plantations, 2)\ntemperate forests and 3) tropical forests. We also study the integration of\nelevation data into models, in the form of Digital Surface Model (DSM)\ninformation, which can readily be obtained at no additional cost from RGB drone\nimagery. We present BalSAM, a model leveraging SAM and DSM information, which\nshows potential over other methods, particularly in the context of plantations.\nWe find that methods using SAM out-of-the-box do not outperform a custom Mask\nR-CNN, even with well-designed prompts. However, efficiently tuning SAM\nend-to-end and integrating DSM information are both promising avenues for tree\ncrown instance segmentation models.", "published": "2025-06-05 12:43:11", "link": "http://arxiv.org/abs/2506.04970v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FEAT: Full-Dimensional Efficient Attention Transformer for Medical Video Generation", "abstract": "Synthesizing high-quality dynamic medical videos remains a significant\nchallenge due to the need for modeling both spatial consistency and temporal\ndynamics. Existing Transformer-based approaches face critical limitations,\nincluding insufficient channel interactions, high computational complexity from\nself-attention, and coarse denoising guidance from timestep embeddings when\nhandling varying noise levels. In this work, we propose FEAT, a\nfull-dimensional efficient attention Transformer, which addresses these issues\nthrough three key innovations: (1) a unified paradigm with sequential\nspatial-temporal-channel attention mechanisms to capture global dependencies\nacross all dimensions, (2) a linear-complexity design for attention mechanisms\nin each dimension, utilizing weighted key-value attention and global channel\nattention, and (3) a residual value guidance module that provides fine-grained\npixel-level guidance to adapt to different noise levels. We evaluate FEAT on\nstandard benchmarks and downstream tasks, demonstrating that FEAT-S, with only\n23\\% of the parameters of the state-of-the-art model Endora, achieves\ncomparable or even superior performance. Furthermore, FEAT-L surpasses all\ncomparison methods across multiple datasets, showcasing both superior\neffectiveness and scalability. Code is available at\nhttps://github.com/Yaziwel/FEAT.", "published": "2025-06-05 12:31:02", "link": "http://arxiv.org/abs/2506.04956v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "APVR: Hour-Level Long Video Understanding with Adaptive Pivot Visual Information Retrieval", "abstract": "Current video-based multimodal large language models struggle with hour-level\nvideo understanding due to computational constraints and inefficient\ninformation extraction from extensive temporal sequences. We propose APVR\n(Adaptive Pivot Visual information Retrieval), a training-free framework that\naddresses the memory wall limitation through hierarchical visual information\nretrieval. APVR operates via two complementary components: Pivot Frame\nRetrieval employs semantic expansion and multi-modal confidence scoring to\nidentify semantically relevant video frames, while Pivot Token Retrieval\nperforms query-aware attention-driven token selection within the pivot frames.\nThis dual granularity approach enables processing of hour-long videos while\nmaintaining semantic fidelity. Experimental validation on LongVideoBench and\nVideoMME demonstrates significant performance improvements, establishing\nstate-of-the-art results for not only training-free but also training-based\napproaches while providing plug-and-play integration capability with existing\nMLLM architectures.", "published": "2025-06-05 12:27:10", "link": "http://arxiv.org/abs/2506.04953v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Time-Lapse Video-Based Embryo Grading via Complementary Spatial-Temporal Pattern Mining", "abstract": "Artificial intelligence has recently shown promise in automated embryo\nselection for In-Vitro Fertilization (IVF). However, current approaches either\naddress partial embryo evaluation lacking holistic quality assessment or target\nclinical outcomes inevitably confounded by extra-embryonic factors, both\nlimiting clinical utility. To bridge this gap, we propose a new task called\nVideo-Based Embryo Grading - the first paradigm that directly utilizes\nfull-length time-lapse monitoring (TLM) videos to predict embryologists'\noverall quality assessments. To support this task, we curate a real-world\nclinical dataset comprising over 2,500 TLM videos, each annotated with a\ngrading label indicating the overall quality of embryos. Grounded in clinical\ndecision-making principles, we propose a Complementary Spatial-Temporal Pattern\nMining (CoSTeM) framework that conceptually replicates embryologists'\nevaluation process. The CoSTeM comprises two branches: (1) a morphological\nbranch using a Mixture of Cross-Attentive Experts layer and a Temporal\nSelection Block to select discriminative local structural features, and (2) a\nmorphokinetic branch employing a Temporal Transformer to model global\ndevelopmental trajectories, synergistically integrating static and dynamic\ndeterminants for grading embryos. Extensive experimental results demonstrate\nthe superiority of our design. This work provides a valuable methodological\nframework for AI-assisted embryo selection. The dataset and source code will be\npublicly available upon acceptance.", "published": "2025-06-05 12:22:03", "link": "http://arxiv.org/abs/2506.04950v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Light and 3D: a methodological exploration of digitisation techniques adapted to a selection of objects from the Mus{\u00e9}e d'Arch{\u00e9}ologie Nationale", "abstract": "The need to digitize heritage objects is now widely accepted. This article\npresents the very fashionable context of the creation of ''digital twins''. It\nillustrates the diversity of photographic 3D digitization methods, but this is\nnot its only objective. Using a selection of objects from the collections of\nthe mus{\\'e}e d'Arch{\\'e}ologie nationale, it shows that no single method is\nsuitable for all cases. Rather, the method to be recommended for a given object\nshould be the result of a concerted choice between those involved in heritage\nand those involved in the digital domain, as each new object may require the\nadaptation of existing tools. It would therefore be pointless to attempt an\nabsolute classification of 3D digitization methods. On the contrary, we need to\nfind the digital tool best suited to each object, taking into account not only\nits characteristics, but also the future use of its digital twin.", "published": "2025-06-05 11:59:33", "link": "http://arxiv.org/abs/2506.04925v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generating Synthetic Stereo Datasets using 3D Gaussian Splatting and Expert Knowledge Transfer", "abstract": "In this paper, we introduce a 3D Gaussian Splatting (3DGS)-based pipeline for\nstereo dataset generation, offering an efficient alternative to Neural Radiance\nFields (NeRF)-based methods. To obtain useful geometry estimates, we explore\nutilizing the reconstructed geometry from the explicit 3D representations as\nwell as depth estimates from the FoundationStereo model in an expert knowledge\ntransfer setup. We find that when fine-tuning stereo models on 3DGS-generated\ndatasets, we demonstrate competitive performance in zero-shot generalization\nbenchmarks. When using the reconstructed geometry directly, we observe that it\nis often noisy and contains artifacts, which propagate noise to the trained\nmodel. In contrast, we find that the disparity estimates from FoundationStereo\nare cleaner and consequently result in a better performance on the zero-shot\ngeneralization benchmarks. Our method highlights the potential for low-cost,\nhigh-fidelity dataset creation and fast fine-tuning for deep stereo models.\nMoreover, we also reveal that while the latest Gaussian Splatting based methods\nhave achieved superior performance on established benchmarks, their robustness\nfalls short in challenging in-the-wild settings warranting further exploration.", "published": "2025-06-05 11:41:09", "link": "http://arxiv.org/abs/2506.04908v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "From Objects to Anywhere: A Holistic Benchmark for Multi-level Visual Grounding in 3D Scenes", "abstract": "3D visual grounding has made notable progress in localizing objects within\ncomplex 3D scenes. However, grounding referring expressions beyond objects in\n3D scenes remains unexplored. In this paper, we introduce Anywhere3D-Bench, a\nholistic 3D visual grounding benchmark consisting of 2,632 referring\nexpression-3D bounding box pairs spanning four different grounding levels:\nhuman-activity areas, unoccupied space beyond objects, objects in the scene,\nand fine-grained object parts. We assess a range of state-of-the-art 3D visual\ngrounding methods alongside large language models (LLMs) and multimodal LLMs\n(MLLMs) on Anywhere3D-Bench. Experimental results reveal that space-level and\npart-level visual grounding pose the greatest challenges: space-level tasks\nrequire a more comprehensive spatial reasoning ability, for example, modeling\ndistances and spatial relations within 3D space, while part-level tasks demand\nfine-grained perception of object composition. Even the best performance model,\nOpenAI o4-mini, achieves only 23.57% accuracy on space-level tasks and 33.94%\non part-level tasks, significantly lower than its performance on area-level and\nobject-level tasks. These findings underscore a critical gap in current models'\ncapacity to understand and reason about 3D scene beyond object-level semantics.", "published": "2025-06-05 11:28:02", "link": "http://arxiv.org/abs/2506.04897v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning to Plan via Supervised Contrastive Learning and Strategic Interpolation: A Chess Case Study", "abstract": "Modern chess engines achieve superhuman performance through deep tree search\nand regressive evaluation, while human players rely on intuition to select\ncandidate moves followed by a shallow search to validate them. To model this\nintuition-driven planning process, we train a transformer encoder using\nsupervised contrastive learning to embed board states into a latent space\nstructured by positional evaluation. In this space, distance reflects\nevaluative similarity, and visualized trajectories display interpretable\ntransitions between game states. We demonstrate that move selection can occur\nentirely within this embedding space by advancing toward favorable regions,\nwithout relying on deep search. Despite using only a 6-ply beam search, our\nmodel achieves an estimated Elo rating of 2593. Performance improves with both\nmodel size and embedding dimensionality, suggesting that latent planning may\noffer a viable alternative to traditional search. Although we focus on chess,\nthe proposed embedding-based planning method can be generalized to other\nperfect-information games where state evaluations are learnable. All source\ncode is available at https://github.com/andrewhamara/SOLIS.", "published": "2025-06-05 11:19:26", "link": "http://arxiv.org/abs/2506.04892v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Invisible Backdoor Triggers in Image Editing Model via Deep Watermarking", "abstract": "Diffusion models have achieved remarkable progress in both image generation\nand editing. However, recent studies have revealed their vulnerability to\nbackdoor attacks, in which specific patterns embedded in the input can\nmanipulate the model's behavior. Most existing research in this area has\nproposed attack frameworks focused on the image generation pipeline, leaving\nbackdoor attacks in image editing relatively unexplored. Among the few studies\ntargeting image editing, most utilize visible triggers, which are impractical\nbecause they introduce noticeable alterations to the input image before\nediting. In this paper, we propose a novel attack framework that embeds\ninvisible triggers into the image editing process via poisoned training data.\nWe leverage off-the-shelf deep watermarking models to encode imperceptible\nwatermarks as backdoor triggers. Our goal is to make the model produce the\npredefined backdoor target when it receives watermarked inputs, while editing\nclean images normally according to the given prompt. With extensive experiments\nacross different watermarking models, the proposed method achieves promising\nattack success rates. In addition, the analysis results of the watermark\ncharacteristics in term of backdoor attack further support the effectiveness of\nour approach. The code is available\nat:https://github.com/aiiu-lab/BackdoorImageEditing", "published": "2025-06-05 10:51:58", "link": "http://arxiv.org/abs/2506.04879v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Geological Field Restoration through the Lens of Image Inpainting", "abstract": "We present a new viewpoint on a reconstructing multidimensional geological\nfields from sparse observations. Drawing inspiration from deterministic image\ninpainting techniques, we model a partially observed spatial field as a\nmultidimensional tensor and recover missing values by enforcing a global\nlow-rank structure. Our approach combines ideas from tensor completion and\ngeostatistics, providing a robust optimization framework. Experiments on\nsynthetic geological fields demonstrate that used tensor completion method\nsignificant improvements in reconstruction accuracy over ordinary kriging for\nvarious percent of observed data.", "published": "2025-06-05 10:45:27", "link": "http://arxiv.org/abs/2506.04869v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MineInsight: A Multi-sensor Dataset for Humanitarian Demining Robotics in Off-Road Environments", "abstract": "The use of robotics in humanitarian demining increasingly involves computer\nvision techniques to improve landmine detection capabilities. However, in the\nabsence of diverse and realistic datasets, the reliable validation of\nalgorithms remains a challenge for the research community. In this paper, we\nintroduce MineInsight, a publicly available multi-sensor, multi-spectral\ndataset designed for off-road landmine detection. The dataset features 35\ndifferent targets (15 landmines and 20 commonly found objects) distributed\nalong three distinct tracks, providing a diverse and realistic testing\nenvironment. MineInsight is, to the best of our knowledge, the first dataset to\nintegrate dual-view sensor scans from both an Unmanned Ground Vehicle and its\nrobotic arm, offering multiple viewpoints to mitigate occlusions and improve\nspatial awareness. It features two LiDARs, as well as images captured at\ndiverse spectral ranges, including visible (RGB, monochrome), visible\nshort-wave infrared (VIS-SWIR), and long-wave infrared (LWIR). Additionally,\nthe dataset comes with an estimation of the location of the targets, offering a\nbenchmark for evaluating detection algorithms. We recorded approximately one\nhour of data in both daylight and nighttime conditions, resulting in around\n38,000 RGB frames, 53,000 VIS-SWIR frames, and 108,000 LWIR frames. MineInsight\nserves as a benchmark for developing and evaluating landmine detection\nalgorithms. Our dataset is available at\nhttps://github.com/mariomlz99/MineInsight.", "published": "2025-06-05 10:08:24", "link": "http://arxiv.org/abs/2506.04842v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "OpenMaskDINO3D : Reasoning 3D Segmentation via Large Language Model", "abstract": "Although perception systems have made remarkable advancements in recent\nyears, particularly in 2D reasoning segmentation, these systems still rely on\nexplicit human instruction or pre-defined categories to identify target objects\nbefore executing visual recognition tasks. Such systems have matured\nsignificantly, demonstrating the ability to reason and comprehend implicit user\nintentions in two-dimensional contexts, producing accurate segmentation masks\nbased on complex and implicit query text. However, a comparable framework and\nstructure for 3D reasoning segmentation remain absent. This paper introduces\nOpenMaskDINO3D, a LLM designed for comprehensive 3D understanding and\nsegmentation. OpenMaskDINO3D processes point cloud data and text prompts to\nproduce instance segmentation masks, excelling in many 3D tasks. By introducing\na SEG token and object identifier, we achieve high-precision 3D segmentation\nmask generation, enabling the model to directly produce accurate point cloud\nsegmentation results from natural language instructions. Experimental results\non large-scale ScanNet datasets validate the effectiveness of our\nOpenMaskDINO3D across various tasks.", "published": "2025-06-05 09:57:43", "link": "http://arxiv.org/abs/2506.04837v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DualX-VSR: Dual Axial Spatial$\\times$Temporal Transformer for Real-World Video Super-Resolution without Motion Compensation", "abstract": "Transformer-based models like ViViT and TimeSformer have advanced video\nunderstanding by effectively modeling spatiotemporal dependencies. Recent video\ngeneration models, such as Sora and Vidu, further highlight the power of\ntransformers in long-range feature extraction and holistic spatiotemporal\nmodeling. However, directly applying these models to real-world video\nsuper-resolution (VSR) is challenging, as VSR demands pixel-level precision,\nwhich can be compromised by tokenization and sequential attention mechanisms.\nWhile recent transformer-based VSR models attempt to address these issues using\nsmaller patches and local attention, they still face limitations such as\nrestricted receptive fields and dependence on optical flow-based alignment,\nwhich can introduce inaccuracies in real-world settings. To overcome these\nissues, we propose Dual Axial Spatial$\\times$Temporal Transformer for\nReal-World Video Super-Resolution (DualX-VSR), which introduces a novel dual\naxial spatial$\\times$temporal attention mechanism that integrates spatial and\ntemporal information along orthogonal directions. DualX-VSR eliminates the need\nfor motion compensation, offering a simplified structure that provides a\ncohesive representation of spatiotemporal information. As a result, DualX-VSR\nachieves high fidelity and superior performance in real-world VSR task.", "published": "2025-06-05 09:53:44", "link": "http://arxiv.org/abs/2506.04830v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fool the Stoplight: Realistic Adversarial Patch Attacks on Traffic Light Detectors", "abstract": "Realistic adversarial attacks on various camera-based perception tasks of\nautonomous vehicles have been successfully demonstrated so far. However, only a\nfew works considered attacks on traffic light detectors. This work shows how\nCNNs for traffic light detection can be attacked with printed patches. We\npropose a threat model, where each instance of a traffic light is attacked with\na patch placed under it, and describe a training strategy. We demonstrate\nsuccessful adversarial patch attacks in universal settings. Our experiments\nshow realistic targeted red-to-green label-flipping attacks and attacks on\npictogram classification. Finally, we perform a real-world evaluation with\nprinted patches and demonstrate attacks in the lab settings with a mobile\ntraffic light for construction sites and in a test area with stationary traffic\nlights. Our code is available at\nhttps://github.com/KASTEL-MobilityLab/attacks-on-traffic-light-detection.", "published": "2025-06-05 09:41:12", "link": "http://arxiv.org/abs/2506.04823v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Spike-TBR: a Noise Resilient Neuromorphic Event Representation", "abstract": "Event cameras offer significant advantages over traditional frame-based\nsensors, including higher temporal resolution, lower latency and dynamic range.\nHowever, efficiently converting event streams into formats compatible with\nstandard computer vision pipelines remains a challenging problem, particularly\nin the presence of noise. In this paper, we propose Spike-TBR, a novel\nevent-based encoding strategy based on Temporal Binary Representation (TBR),\naddressing its vulnerability to noise by integrating spiking neurons. Spike-TBR\ncombines the frame-based advantages of TBR with the noise-filtering\ncapabilities of spiking neural networks, creating a more robust representation\nof event streams. We evaluate four variants of Spike-TBR, each using different\nspiking neurons, across multiple datasets, demonstrating superior performance\nin noise-affected scenarios while improving the results on clean data. Our\nmethod bridges the gap between spike-based and frame-based processing, offering\na simple noise-resilient solution for event-driven vision applications.", "published": "2025-06-05 09:38:42", "link": "http://arxiv.org/abs/2506.04817v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MegaHan97K: A Large-Scale Dataset for Mega-Category Chinese Character Recognition with over 97K Categories", "abstract": "Foundational to the Chinese language and culture, Chinese characters\nencompass extraordinarily extensive and ever-expanding categories, with the\nlatest Chinese GB18030-2022 standard containing 87,887 categories. The accurate\nrecognition of this vast number of characters, termed mega-category\nrecognition, presents a formidable yet crucial challenge for cultural heritage\npreservation and digital applications. Despite significant advances in Optical\nCharacter Recognition (OCR), mega-category recognition remains unexplored due\nto the absence of comprehensive datasets, with the largest existing dataset\ncontaining merely 16,151 categories. To bridge this critical gap, we introduce\nMegaHan97K, a mega-category, large-scale dataset covering an unprecedented\n97,455 categories of Chinese characters. Our work offers three major\ncontributions: (1) MegaHan97K is the first dataset to fully support the latest\nGB18030-2022 standard, providing at least six times more categories than\nexisting datasets; (2) It effectively addresses the long-tail distribution\nproblem by providing balanced samples across all categories through its three\ndistinct subsets: handwritten, historical and synthetic subsets; (3)\nComprehensive benchmarking experiments reveal new challenges in mega-category\nscenarios, including increased storage demands, morphologically similar\ncharacter recognition, and zero-shot learning difficulties, while also\nunlocking substantial opportunities for future research. To the best of our\nknowledge, the MetaHan97K is likely the dataset with the largest classes not\nonly in the field of OCR but may also in the broader domain of pattern\nrecognition. The dataset is available at\nhttps://github.com/SCUT-DLVCLab/MegaHan97K.", "published": "2025-06-05 09:33:06", "link": "http://arxiv.org/abs/2506.04807v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SupeRANSAC: One RANSAC to Rule Them All", "abstract": "Robust estimation is a cornerstone in computer vision, particularly for tasks\nlike Structure-from-Motion and Simultaneous Localization and Mapping. RANSAC\nand its variants are the gold standard for estimating geometric models (e.g.,\nhomographies, relative/absolute poses) from outlier-contaminated data. Despite\nRANSAC's apparent simplicity, achieving consistently high performance across\ndifferent problems is challenging. While recent research often focuses on\nimproving specific RANSAC components (e.g., sampling, scoring), overall\nperformance is frequently more influenced by the \"bells and whistles\" (i.e.,\nthe implementation details and problem-specific optimizations) within a given\nlibrary. Popular frameworks like OpenCV and PoseLib demonstrate varying\nperformance, excelling in some tasks but lagging in others. We introduce\nSupeRANSAC, a novel unified RANSAC pipeline, and provide a detailed analysis of\nthe techniques that make RANSAC effective for specific vision tasks, including\nhomography, fundamental/essential matrix, and absolute/rigid pose estimation.\nSupeRANSAC is designed for consistent accuracy across these tasks, improving\nupon the best existing methods by, for example, 6 AUC points on average for\nfundamental matrix estimation. We demonstrate significant performance\nimprovements over the state-of-the-art on multiple problems and datasets. Code:\nhttps://github.com/danini/superansac", "published": "2025-06-05 09:30:27", "link": "http://arxiv.org/abs/2506.04803v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table", "abstract": "Approximate nearest neighbor search (ANNS) is an essential building block for\napplications like RAG but can sometimes yield results that are overly similar\nto each other. In certain scenarios, search results should be similar to the\nquery and yet diverse. We propose LotusFilter, a post-processing module to\ndiversify ANNS results. We precompute a cutoff table summarizing vectors that\nare close to each other. During the filtering, LotusFilter greedily looks up\nthe table to delete redundant vectors from the candidates. We demonstrated that\nthe LotusFilter operates fast (0.02 [ms/query]) in settings resembling\nreal-world RAG applications, utilizing features such as OpenAI embeddings. Our\ncode is publicly available at https://github.com/matsui528/lotf.", "published": "2025-06-05 09:17:30", "link": "http://arxiv.org/abs/2506.04790v1", "categories": ["cs.CV", "cs.IR", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Object-X: Learning to Reconstruct Multi-Modal 3D Object Representations", "abstract": "Learning effective multi-modal 3D representations of objects is essential for\nnumerous applications, such as augmented reality and robotics. Existing methods\noften rely on task-specific embeddings that are tailored either for semantic\nunderstanding or geometric reconstruction. As a result, these embeddings\ntypically cannot be decoded into explicit geometry and simultaneously reused\nacross tasks. In this paper, we propose Object-X, a versatile multi-modal\nobject representation framework capable of encoding rich object embeddings\n(e.g. images, point cloud, text) and decoding them back into detailed geometric\nand visual reconstructions. Object-X operates by geometrically grounding the\ncaptured modalities in a 3D voxel grid and learning an unstructured embedding\nfusing the information from the voxels with the object attributes. The learned\nembedding enables 3D Gaussian Splatting-based object reconstruction, while also\nsupporting a range of downstream tasks, including scene alignment, single-image\n3D object reconstruction, and localization. Evaluations on two challenging\nreal-world datasets demonstrate that Object-X produces high-fidelity novel-view\nsynthesis comparable to standard 3D Gaussian Splatting, while significantly\nimproving geometric accuracy. Moreover, Object-X achieves competitive\nperformance with specialized methods in scene alignment and localization.\nCritically, our object-centric descriptors require 3-4 orders of magnitude less\nstorage compared to traditional image- or point cloud-based approaches,\nestablishing Object-X as a scalable and highly practical solution for\nmulti-modal 3D scene representation.", "published": "2025-06-05 09:14:42", "link": "http://arxiv.org/abs/2506.04789v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deep learning image burst stacking to reconstruct high-resolution ground-based solar observations", "abstract": "Large aperture ground based solar telescopes allow the solar atmosphere to be\nresolved in unprecedented detail. However, observations are limited by Earths\nturbulent atmosphere, requiring post image corrections. Current reconstruction\nmethods using short exposure bursts face challenges with strong turbulence and\nhigh computational costs. We introduce a deep learning approach that\nreconstructs 100 short exposure images into one high quality image in real\ntime. Using unpaired image to image translation, our model is trained on\ndegraded bursts with speckle reconstructions as references, improving\nrobustness and generalization. Our method shows an improved robustness in terms\nof perceptual quality, especially when speckle reconstructions show artifacts.\nAn evaluation with a varying number of images per burst demonstrates that our\nmethod makes efficient use of the combined image information and achieves the\nbest reconstructions when provided with the full image burst.", "published": "2025-06-05 09:10:31", "link": "http://arxiv.org/abs/2506.04781v1", "categories": ["astro-ph.SR", "astro-ph.IM", "cs.CV", "physics.comp-ph"], "primary_category": "astro-ph.SR"}
{"title": "HypeVPR: Exploring Hyperbolic Space for Perspective to Equirectangular Visual Place Recognition", "abstract": "When applying Visual Place Recognition (VPR) to real-world mobile robots and\nsimilar applications, perspective-to-equirectangular (P2E) formulation\nnaturally emerges as a suitable approach to accommodate diverse query images\ncaptured from various viewpoints. In this paper, we introduce HypeVPR, a novel\nhierarchical embedding framework in hyperbolic space, designed to address the\nunique challenges of P2E VPR. The key idea behind HypeVPR is that visual\nenvironments captured by panoramic views exhibit inherent hierarchical\nstructures. To leverage this property, we employ hyperbolic space to represent\nhierarchical feature relationships and preserve distance properties within the\nfeature space. To achieve this, we propose a hierarchical feature aggregation\nmechanism that organizes local-to-global feature representations within\nhyperbolic space. Additionally, HypeVPR adopts an efficient coarse-to-fine\nsearch strategy, optimally balancing speed and accuracy to ensure robust\nmatching, even between descriptors from different image types. This approach\nenables HypeVPR to outperform state-of-the-art methods while significantly\nreducing retrieval time, achieving up to 5x faster retrieval across diverse\nbenchmark datasets. The code and models will be released at\nhttps://github.com/suhan-woo/HypeVPR.git.", "published": "2025-06-05 08:47:15", "link": "http://arxiv.org/abs/2506.04764v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Toward Better SSIM Loss for Unsupervised Monocular Depth Estimation", "abstract": "Unsupervised monocular depth learning generally relies on the photometric\nrelation among temporally adjacent images. Most of previous works use both mean\nabsolute error (MAE) and structure similarity index measure (SSIM) with\nconventional form as training loss. However, they ignore the effect of\ndifferent components in the SSIM function and the corresponding hyperparameters\non the training. To address these issues, this work proposes a new form of\nSSIM. Compared with original SSIM function, the proposed new form uses addition\nrather than multiplication to combine the luminance, contrast, and structural\nsimilarity related components in SSIM. The loss function constructed with this\nscheme helps result in smoother gradients and achieve higher performance on\nunsupervised depth estimation. We conduct extensive experiments to determine\nthe relatively optimal combination of parameters for our new SSIM. Based on the\npopular MonoDepth approach, the optimized SSIM loss function can remarkably\noutperform the baseline on the KITTI-2015 outdoor dataset.", "published": "2025-06-05 08:43:24", "link": "http://arxiv.org/abs/2506.04758v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs", "abstract": "Vision-Language Models (VLMs) have achieved remarkable performance in image\ncaptioning, but recent studies show they are vulnerable to backdoor attacks.\nAttackers can inject imperceptible perturbations-such as local pixel triggers\nor global semantic phrases-into the training data, causing the model to\ngenerate malicious, attacker-controlled captions for specific inputs. These\nattacks are hard to detect and defend due to their stealthiness and cross-modal\nnature. By analyzing attack samples, we identify two key vulnerabilities: (1)\nabnormal attention concentration on specific image regions, and (2) semantic\ndrift and incoherence in generated captions. To counter this, we propose\nSemantic Reward Defense (SRD), a reinforcement learning framework that\nmitigates backdoor behavior without prior knowledge of triggers. SRD uses a\nDeep Q-Network to learn policies for applying discrete perturbations (e.g.,\nocclusion, color masking) to sensitive image regions, aiming to disrupt the\nactivation of malicious pathways. We design a semantic fidelity score as the\nreward signal, which jointly evaluates semantic consistency and linguistic\nfluency of the output, guiding the agent toward generating robust yet faithful\ncaptions. Experiments across mainstream VLMs and datasets show SRD reduces\nattack success rates to 5.6%, while preserving caption quality on clean inputs\nwith less than 10% performance drop. SRD offers a trigger-agnostic,\ninterpretable defense paradigm against stealthy backdoor threats in multimodal\ngenerative models.", "published": "2025-06-05 08:22:24", "link": "http://arxiv.org/abs/2506.04743v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bridging Annotation Gaps: Transferring Labels to Align Object Detection Datasets", "abstract": "Combining multiple object detection datasets offers a path to improved\ngeneralisation but is hindered by inconsistencies in class semantics and\nbounding box annotations. Some methods to address this assume shared label\ntaxonomies and address only spatial inconsistencies; others require manual\nrelabelling, or produce a unified label space, which may be unsuitable when a\nfixed target label space is required. We propose Label-Aligned Transfer (LAT),\na label transfer framework that systematically projects annotations from\ndiverse source datasets into the label space of a target dataset. LAT begins by\ntraining dataset-specific detectors to generate pseudo-labels, which are then\ncombined with ground-truth annotations via a Privileged Proposal Generator\n(PPG) that replaces the region proposal network in two-stage detectors. To\nfurther refine region features, a Semantic Feature Fusion (SFF) module injects\nclass-aware context and features from overlapping proposals using a\nconfidence-weighted attention mechanism. This pipeline preserves\ndataset-specific annotation granularity while enabling many-to-one label space\ntransfer across heterogeneous datasets, resulting in a semantically and\nspatially aligned representation suitable for training a downstream detector.\nLAT thus jointly addresses both class-level misalignments and bounding box\ninconsistencies without relying on shared label spaces or manual annotations.\nAcross multiple benchmarks, LAT demonstrates consistent improvements in\ntarget-domain detection performance, achieving gains of up to +4.8AP over\nsemi-supervised baselines.", "published": "2025-06-05 08:16:15", "link": "http://arxiv.org/abs/2506.04737v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decomposing Words for Enhanced Compression: Exploring the Number of Runs in the Extended Burrows-Wheeler Transform", "abstract": "The Burrows-Wheeler Transform (BWT) is a fundamental component in many data\nstructures for text indexing and compression, widely used in areas such as\nbioinformatics and information retrieval. The extended BWT (eBWT) generalizes\nthe classical BWT to multisets of strings, providing a flexible framework that\ncaptures many BWT-like constructions. Several known variants of the BWT can be\nviewed as instances of the eBWT applied to specific decompositions of a word. A\ncentral property of the BWT, essential for its compressibility, is the number\nof maximal ranges of equal letters, named runs. In this article, we explore how\ndifferent decompositions of a word impact the number of runs in the resulting\neBWT. First, we show that the number of decompositions of a word is\nexponential, even under minimal constraints on the size of the subsets in the\ndecomposition. Second, we present an infinite family of words for which the\nratio of the number of runs between the worst and best decompositions is\nunbounded, under the same minimal constraints. These results illustrate the\npotential cost of decomposition choices in eBWT-based compression and underline\nthe challenges in optimizing run-length encoding in generalized BWT frameworks.", "published": "2025-06-05 12:00:38", "link": "http://arxiv.org/abs/2506.04926v1", "categories": ["cs.DS", "cs.DM", "cs.FL"], "primary_category": "cs.DS"}
{"title": "Temporal passing network in basketball: the effect of time pressure on the dynamics of team organization at micro and meso levels", "abstract": "In this study, basketball teams are conceptualized as complex adaptive\nsystems to examine their (re)organizational processes in response the time\nremaining to shoot. Using temporal passing networks to model team behavior, the\nfocus is on the dynamics of the temporal patterns of interaction between\nplayers. Several metrics grounded in social network analysis are calculated at\ndifferent level to assess the dynamics of the patterns used by teams and of the\nindividual roles within those patterns. The results reveal a 3-phase dynamic,\ndifferentiated by more or less complex and diversified patterns, and by more or\nless specialized or flexible roles. Additionally, time-dependent features of\nthe different tactical playing positions are identified, some of which linked\nto team performance. The findings are intended to explain how basketball teams\nadapt their organization to cope with time pressure, offering potential\ninsights for other type of teams facing similar constraints. Moreover, this\nwork provides a useful framework for a multilevel understanding of how\nconstraints shape team adaptations dynamically, making it applicable to a wide\nrange of team settings.", "published": "2025-06-05 09:33:08", "link": "http://arxiv.org/abs/2506.04808v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Mis\u00e8re Greedy Nim and Mis\u00e8re Bounded Greedy Nim", "abstract": "In this paper, we analyze the mis\\`ere versions of two impartial\ncombinatorial games: k-Bounded Greedy Nim and Greedy Nim. We present a complete\nsolution to both games by showing necessary and sufficient conditions for a\nposition to be P-positions.", "published": "2025-06-05 05:55:18", "link": "http://arxiv.org/abs/2506.04657v1", "categories": ["cs.GT", "cs.DM"], "primary_category": "cs.GT"}
{"title": "On the Comprehensibility of Multi-structured Financial Documents using LLMs and Pre-processing Tools", "abstract": "The proliferation of complex structured data in hybrid sources, such as PDF\ndocuments and web pages, presents unique challenges for current Large Language\nModels (LLMs) and Multi-modal Large Language Models (MLLMs) in providing\naccurate answers. Despite the recent advancements of MLLMs, they still often\nfalter when interpreting intricately structured information, such as nested\ntables and multi-dimensional plots, leading to hallucinations and erroneous\noutputs. This paper explores the capabilities of LLMs and MLLMs in\nunderstanding and answering questions from complex data structures found in PDF\ndocuments by leveraging industrial and open-source tools as part of a\npre-processing pipeline. Our findings indicate that GPT-4o, a popular MLLM,\nachieves an accuracy of 56% on multi-structured documents when fed documents\ndirectly, and that integrating pre-processing tools raises the accuracy of LLMs\nto 61.3% for GPT-4o and 76% for GPT-4, and with lower overall cost. The code is\npublicly available at https://github.com/OGCDS/FinancialQA.", "published": "2025-06-05 15:52:44", "link": "http://arxiv.org/abs/2506.05182v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Rethinking Contrastive Learning in Session-based Recommendation", "abstract": "Session-based recommendation aims to predict intents of anonymous users based\non limited behaviors. With the ability in alleviating data sparsity,\ncontrastive learning is prevailing in the task. However, we spot that existing\ncontrastive learning based methods still suffer from three obstacles: (1) they\noverlook item-level sparsity and primarily focus on session-level sparsity; (2)\nthey typically augment sessions using item IDs like crop, mask and reorder,\nfailing to ensure the semantic consistency of augmented views; (3) they treat\nall positive-negative signals equally, without considering their varying\nutility. To this end, we propose a novel multi-modal adaptive contrastive\nlearning framework called MACL for session-based recommendation. In MACL, a\nmulti-modal augmentation is devised to generate semantically consistent views\nat both item and session levels by leveraging item multi-modal features.\nBesides, we present an adaptive contrastive loss that distinguishes varying\ncontributions of positive-negative signals to improve self-supervised learning.\nExtensive experiments on three real-world datasets demonstrate the superiority\nof MACL over state-of-the-art methods.", "published": "2025-06-05 13:52:57", "link": "http://arxiv.org/abs/2506.05044v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "PUB: An LLM-Enhanced Personality-Driven User Behaviour Simulator for Recommender System Evaluation", "abstract": "Traditional offline evaluation methods for recommender systems struggle to\ncapture the complexity of modern platforms due to sparse behavioural signals,\nnoisy data, and limited modelling of user personality traits. While simulation\nframeworks can generate synthetic data to address these gaps, existing methods\nfail to replicate behavioural diversity, limiting their effectiveness. To\novercome these challenges, we propose the Personality-driven User Behaviour\nSimulator (PUB), an LLM-based simulation framework that integrates the Big Five\npersonality traits to model personalised user behaviour. PUB dynamically infers\nuser personality from behavioural logs (e.g., ratings, reviews) and item\nmetadata, then generates synthetic interactions that preserve statistical\nfidelity to real-world data. Experiments on the Amazon review datasets show\nthat logs generated by PUB closely align with real user behaviour and reveal\nmeaningful associations between personality traits and recommendation outcomes.\nThese results highlight the potential of the personality-driven simulator to\nadvance recommender system evaluation, offering scalable, controllable,\nhigh-fidelity alternatives to resource-intensive real-world experiments.", "published": "2025-06-05 01:57:36", "link": "http://arxiv.org/abs/2506.04551v1", "categories": ["cs.IR", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Upper bound for the Holevo quantity arising from the fundamental entropic inequality", "abstract": "We show how the fundamental entropic inequality proved recently in\n[arXiv:2408.15306] can be used to obtain a quite accurate upper bound on the\nHolevo quantity of a discrete ensemble of quantum states expressed via the\nprobabilities and the metric characteristics of this ensembles.", "published": "2025-06-05 17:59:26", "link": "http://arxiv.org/abs/2506.05335v1", "categories": ["quant-ph", "cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "quant-ph"}
{"title": "CSI2Vec: Towards a Universal CSI Feature Representation for Positioning and Channel Charting", "abstract": "Natural language processing techniques, such as Word2Vec, have demonstrated\nexceptional capabilities in capturing semantic and syntactic relationships of\ntext through vector embeddings. Inspired by this technique, we propose CSI2Vec,\na self-supervised framework for generating universal and robust channel state\ninformation (CSI) representations tailored to CSI-based positioning (POS) and\nchannel charting (CC). CSI2Vec learns compact vector embeddings across various\nwireless scenarios, capturing spatial relationships between user equipment\npositions without relying on CSI reconstruction or ground-truth position\ninformation. We implement CSI2Vec as a neural network that is trained across\nvarious deployment setups (i.e., the spatial arrangement of radio equipment and\nscatterers) and radio setups (RSs) (i.e., the specific hardware used), ensuring\nrobustness to aspects such as differences in the environment, the number of\nused antennas, or allocated set of subcarriers. CSI2Vec abstracts the RS by\ngenerating compact vector embeddings that capture essential spatial\ninformation, avoiding the need for full CSI transmission or reconstruction\nwhile also reducing complexity and improving processing efficiency of\ndownstream tasks. Simulations with ray-tracing and real-world CSI datasets\ndemonstrate CSI2Vec's effectiveness in maintaining excellent POS and CC\nperformance while reducing computational demands and storage.", "published": "2025-06-05 16:56:41", "link": "http://arxiv.org/abs/2506.05237v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Norming Sets for Tensor and Polynomial Sketching", "abstract": "This paper develops the sketching (i.e., randomized dimension reduction)\ntheory for real algebraic varieties and images of polynomial maps, including,\ne.g., the set of low rank tensors and tensor networks. Through the lens of\nnorming sets, we provide a framework for controlling the sketching dimension\nfor \\textit{any} sketch operator used to embed said sets, including\nsub-Gaussian, fast Johnson-Lindenstrauss, and tensor structured sketch\noperators. Leveraging norming set theory, we propose a new sketching method\ncalled the median sketch. It embeds such a set $V$ using only\n$\\widetilde{\\mathcal{O}}(\\dim V)$ tensor structured or sparse linear\nmeasurements.", "published": "2025-06-05 15:49:23", "link": "http://arxiv.org/abs/2506.05174v1", "categories": ["math.NA", "cs.IT", "cs.NA", "math.AG", "math.IT"], "primary_category": "math.NA"}
{"title": "Optimization for Semantic-Aware Resource Allocation under CPT-based Utilities", "abstract": "The problem of resource allocation in goal-oriented semantic communication\nwith semantic-aware utilities and subjective risk perception is studied here.\nBy linking information importance to risk aversion, we model agent behavior\nusing Cumulative Prospect Theory (CPT), which incorporates risk-sensitive\nutility functions and nonlinear transformations of distributions, reflecting\nsubjective perceptions of gains and losses. The objective is to maximize the\naggregate utility across multiple CPT-modeled agents, which leads to a\nnonconvex, nonsmooth optimization problem. To efficiently solve this\nchallenging problem, we propose a new algorithmic framework that combines\nsuccessive convex approximation (SCA) with the projected subgradient method and\nLagrangian relaxation, Our approach enables tractable optimization while\npreserving solution quality, offering both theoretical rigor and practical\neffectiveness in semantics-aware resource allocation.", "published": "2025-06-05 12:25:44", "link": "http://arxiv.org/abs/2506.04952v1", "categories": ["cs.IT", "cs.NI", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Goal-Oriented Semantic Resource Allocation with Cumulative Prospect Theoretic Agents", "abstract": "We introduce a resource allocation framework for goal-oriented semantic\nnetworks, where participating agents assess system quality through subjective\n(e.g., context-dependent) perceptions. To accommodate this, our model accounts\nfor agents whose preferences deviate from traditional expected utility theory\n(EUT), specifically incorporating cumulative prospect theory (CPT) preferences.\nWe develop a comprehensive analytical framework that captures human-centric\naspects of decision-making and risky choices under uncertainty, such as risk\nperception, loss aversion, and perceptual distortions in probability metrics.\nBy identifying essential modifications in traditional resource allocation\ndesign principles required for agents with CPT preferences, we showcase the\nframework's relevance through its application to the problem of power\nallocation in multi-channel wireless communication systems.", "published": "2025-06-05 12:21:38", "link": "http://arxiv.org/abs/2506.04947v1", "categories": ["cs.IT", "cs.NI", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Information-Optimal Sensing and Control in High-Intensity Laser Experiments", "abstract": "High-intensity laser systems present unique measurement and optimization\nchallenges due to their high complexity, low repetition rates, and shot-to-shot\nvariations. We discuss recent developments towards a unified framework based on\ninformation theory and Bayesian inference that addresses these challenges.\nStarting from fundamental constraints on the physical field structure, we\nrecently demonstrated how to capture complete spatio-temporal information about\nindividual petawatt laser pulses. Building on this foundation, we demonstrate\nhow Bayesian frameworks can leverage temporal correlations between consecutive\npulses to improve measurement precision. We then extend these concepts to\nactive sensing strategies that adaptively select measurements to maximize\ninformation gain, exemplified through Bayesian autocorrelation spectroscopy.\nFinally, we show how these information-optimal measurement principles naturally\nextend to Bayesian optimization. This progression represents a paradigm shift\nwhere measurement devices transition from passive data collectors to active\nparticipants in complex experiments.", "published": "2025-06-05 12:20:54", "link": "http://arxiv.org/abs/2506.04946v1", "categories": ["physics.optics", "cs.IT", "math.IT", "physics.acc-ph", "physics.plasm-ph"], "primary_category": "physics.optics"}
{"title": "Iterative Neural Rollback Chase-Pyndiah Decoding", "abstract": "Iterative decoding is essential in modern communication systems, especially\noptical communications, where error-correcting codes such as turbo product\ncodes (TPC) and staircase codes are widely employed. A key factor in achieving\nhigh error correction performance is the use of soft-decision decoding for\ncomponent codes. However, implementing optimal maximum a posteriori (MAP)\nprobability decoding for commonly used component codes, such as BCH and Polar\ncodes, is computationally prohibitive. Instead, practical systems rely on\napproximations, with the Chase-Pyndiah algorithm being a widely used suboptimal\nmethod. TPC are more powerful than their component codes and begin to function\neffectively at low signal-to-noise ratios. Consequently, during the initial\niterations, the component codes do not perform well and introduce errors in the\nextrinsic information updates. This phenomenon limits the performance of TPC.\nThis paper proposes a neural network-aided rollback Chase-Pyndiah decoding\nmethod to address this issue. A transformer-based neural network identifies\ncases where extrinsic updates are likely to introduce errors, triggering a\nrollback mechanism which prevents the update and keeps the component code\nmessage intact. Our results demonstrate that a neural network with a relatively\nsmall number of parameters can effectively distinguish destructive updates and\nimprove decoding performance. We evaluate the proposed approach using TPC with\n(256, 239) extended BCH component codes. We show that the proposed method\nenhances the bit error rate performance of Chase-Pyndiah p=6 decoding,\nachieving a gain of approximately 0.145 dB in a TPC scheme with four full\niterations, significantly outperforming conventional Chase p=7 decoding.", "published": "2025-06-05 10:00:53", "link": "http://arxiv.org/abs/2506.04839v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Spatio-Temporal Information Freshness for Remote Source Monitoring in IoT Systems", "abstract": "The widespread adoption of age of information (AoI) as a meaningful and\nanalytically tractable information freshness metric has led to a wide body of\nwork on the timing performance of Internet of things (IoT) systems. However,\nthe spatial correlation inherent to environmental monitoring has been mostly\nneglected in the recent literature, due to the significant modeling complexity\nit introduces. In this work, we address this gap by presenting a model of\nspatio-temporal information freshness, considering the conditional entropy of\nthe system state in a remote monitoring scenario, such as a low-orbit satellite\ncollecting information from a wide geographical area. Our analytical results\nshow that purely age-oriented schemes tend to select an overly broad\ncommunication range, leading to inaccurate estimates and energy inefficiency,\nboth of which can be mitigated by adopting a spatio-temporal approach.", "published": "2025-06-05 09:31:16", "link": "http://arxiv.org/abs/2506.04804v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the Role of Early-Termination for Age of Information in Tree-Based Random Access Protocols", "abstract": "Age of Information (AoI) has emerged as a key metric for assessing data\nfreshness in IoT applications, where a large number of devices report\ntime-stamped updates to a monitor. Such systems often rely on random access\nprotocols based on variations of ALOHA at the link layer, where collision\nresolution algorithms play a fundamental role to enable reliable delivery of\npackets. In this context, we provide the first analytical characterization of\naverage AoI for the classical Capetanakis tree-based algorithm with gated\naccess under exogenous traffic, capturing the protocol's dynamics, driven by\nsporadic packet generation and variable collision resolution times. We also\nexplore a variant with early termination, where contention is truncated after a\nmaximum number of slots even if not all users are resolved. The approach\nintroduces a fundamental trade-off between reliability and timeliness, allowing\nstale packets to be dropped to improve freshness.", "published": "2025-06-05 09:21:31", "link": "http://arxiv.org/abs/2506.04793v1", "categories": ["cs.IT", "cs.NI", "math.IT"], "primary_category": "cs.IT"}
{"title": "Improved Regret Bounds for Linear Bandits with Heavy-Tailed Rewards", "abstract": "We study stochastic linear bandits with heavy-tailed rewards, where the\nrewards have a finite $(1+\\epsilon)$-absolute central moment bounded by\n$\\upsilon$ for some $\\epsilon \\in (0,1]$. We improve both upper and lower\nbounds on the minimax regret compared to prior work. When $\\upsilon =\n\\mathcal{O}(1)$, the best prior known regret upper bound is\n$\\tilde{\\mathcal{O}}(d T^{\\frac{1}{1+\\epsilon}})$. While a lower with the same\nscaling has been given, it relies on a construction using $\\upsilon =\n\\mathcal{O}(d)$, and adapting the construction to the bounded-moment regime\nwith $\\upsilon = \\mathcal{O}(1)$ yields only a\n$\\Omega(d^{\\frac{\\epsilon}{1+\\epsilon}} T^{\\frac{1}{1+\\epsilon}})$ lower bound.\nThis matches the known rate for multi-armed bandits and is generally loose for\nlinear bandits, in particular being $\\sqrt{d}$ below the optimal rate in the\nfinite-variance case ($\\epsilon = 1$). We propose a new elimination-based\nalgorithm guided by experimental design, which achieves regret\n$\\tilde{\\mathcal{O}}(d^{\\frac{1+3\\epsilon}{2(1+\\epsilon)}}\nT^{\\frac{1}{1+\\epsilon}})$, thus improving the dependence on $d$ for all\n$\\epsilon \\in (0,1)$ and recovering a known optimal result for $\\epsilon = 1$.\nWe also establish a lower bound of $\\Omega(d^{\\frac{2\\epsilon}{1+\\epsilon}}\nT^{\\frac{1}{1+\\epsilon}})$, which strictly improves upon the multi-armed bandit\nrate and highlights the hardness of heavy-tailed linear bandit problems. For\nfinite action sets, we derive similarly improved upper and lower bounds for\nregret. Finally, we provide action set dependent regret upper bounds showing\nthat for some geometries, such as $l_p$-norm balls for $p \\le 1 + \\epsilon$, we\ncan further reduce the dependence on $d$, and we can handle\ninfinite-dimensional settings via the kernel trick, in particular establishing\nnew regret bounds for the Mat\\'ern kernel that are the first to be sublinear\nfor all $\\epsilon \\in (0, 1]$.", "published": "2025-06-05 09:07:26", "link": "http://arxiv.org/abs/2506.04775v1", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Sparse Phase Retrieval with Redundant Dictionary via $\\ell_q (0<q\\le 1)$-Analysis Model", "abstract": "Sparse phase retrieval with redundant dictionary is to reconstruct the\nsignals of interest that are (nearly) sparse in a redundant dictionary or frame\nfrom the phaseless measurements via the optimization models. Gao [7] presented\nconditions on the measurement matrix, called null space property (NSP) and\nstrong dictionary restricted isometry property (S-DRIP), for exact and stable\nrecovery of dictionary-$k$-sparse signals via the $\\ell_1$-analysis model for\nsparse phase retrieval with redundant dictionary, respectively, where, in\nparticularly, the S-DRIP of order $tk$ with $t>1$ was derived. In this paper,\nmotivated by many advantages of the $\\ell_q$ minimization with $0<q\\leq1$,\ne.g., reduction of the number of measurements required, we generalize these two\nconditions to the $\\ell_q$-analysis model. Specifically, we first present two\nNSP variants for exact recovery of dictionary-$k$-sparse signals via the\n$\\ell_q$-analysis model in the noiseless scenario. Moreover, we investigate the\nS-DRIP of order $tk$ with $0<t<\\frac{4}{3}$ for stable recovery of\ndictionary-$k$-sparse signals via the $\\ell_q$-analysis model in the noisy\nscenario, which will complement the existing result of the S-DRIP of order $tk$\nwith $t\\geq2$ obtained in [4].", "published": "2025-06-05 02:52:50", "link": "http://arxiv.org/abs/2506.04576v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Admissibility of Completely Randomized Trials: A Large-Deviation Approach", "abstract": "When an experimenter has the option of running an adaptive trial, is it\nadmissible to ignore this option and run a non-adaptive trial instead? We\nprovide a negative answer to this question in the best-arm identification\nproblem, where the experimenter aims to allocate measurement efforts\njudiciously to confidently deploy the most effective treatment arm. We find\nthat, whenever there are at least three treatment arms, there exist simple\nadaptive designs that universally and strictly dominate non-adaptive completely\nrandomized trials. This dominance is characterized by a notion called\nefficiency exponent, which quantifies a design's statistical efficiency when\nthe experimental sample is large. Our analysis focuses on the class of batched\narm elimination designs, which progressively eliminate underperforming arms at\npre-specified batch intervals. We characterize simple sufficient conditions\nunder which these designs universally and strictly dominate completely\nrandomized trials. These results resolve the second open problem posed in Qin\n[2022].", "published": "2025-06-05 17:58:43", "link": "http://arxiv.org/abs/2506.05329v1", "categories": ["stat.ML", "cs.LG", "econ.EM"], "primary_category": "stat.ML"}
{"title": "Seeing the Invisible: Machine learning-Based QPI Kernel Extraction via Latent Alignment", "abstract": "Quasiparticle interference (QPI) imaging is a powerful tool for probing\nelectronic structures in quantum materials, but extracting the single-scatterer\nQPI pattern (i.e., the kernel) from a multi-scatterer image remains a\nfundamentally ill-posed inverse problem. In this work, we propose the first\nAI-based framework for QPI kernel extraction. We introduce a two-step learning\nstrategy that decouples kernel representation learning from\nobservation-to-kernel inference. In the first step, we train a variational\nautoencoder to learn a compact latent space of scattering kernels. In the\nsecond step, we align the latent representation of QPI observations with those\nof the pre-learned kernels using a dedicated encoder. This design enables the\nmodel to infer kernels robustly even under complex, entangled scattering\nconditions. We construct a diverse and physically realistic QPI dataset\ncomprising 100 unique kernels and evaluate our method against a direct one-step\nbaseline. Experimental results demonstrate that our approach achieves\nsignificantly higher extraction accuracy, and improved generalization to unseen\nkernels.", "published": "2025-06-05 17:58:09", "link": "http://arxiv.org/abs/2506.05325v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LSM-2: Learning from Incomplete Wearable Sensor Data", "abstract": "Foundation models, a cornerstone of recent advancements in machine learning,\nhave predominantly thrived on complete and well-structured data. Wearable\nsensor data frequently suffers from significant missingness, posing a\nsubstantial challenge for self-supervised learning (SSL) models that typically\nassume complete data inputs. This paper introduces the second generation of\nLarge Sensor Model (LSM-2) with Adaptive and Inherited Masking (AIM), a novel\nSSL approach that learns robust representations directly from incomplete data\nwithout requiring explicit imputation. AIM's core novelty lies in its use of\nlearnable mask tokens to model both existing (\"inherited\") and artificially\nintroduced missingness, enabling it to robustly handle fragmented real-world\ndata during inference. Pre-trained on an extensive dataset of 40M hours of\nday-long multimodal sensor data, our LSM-2 with AIM achieves the best\nperformance across a diverse range of tasks, including classification,\nregression and generative modeling. Furthermore, LSM-2 with AIM exhibits\nsuperior scaling performance, and critically, maintains high performance even\nunder targeted missingness scenarios, reflecting clinically coherent patterns,\nsuch as the diagnostic value of nighttime biosignals for hypertension\nprediction. This makes AIM a more reliable choice for real-world wearable data\napplications.", "published": "2025-06-05 17:57:11", "link": "http://arxiv.org/abs/2506.05321v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Generalizable, real-time neural decoding with hybrid state-space models", "abstract": "Real-time decoding of neural activity is central to neuroscience and\nneurotechnology applications, from closed-loop experiments to brain-computer\ninterfaces, where models are subject to strict latency constraints. Traditional\nmethods, including simple recurrent neural networks, are fast and lightweight\nbut often struggle to generalize to unseen data. In contrast, recent\nTransformer-based approaches leverage large-scale pretraining for strong\ngeneralization performance, but typically have much larger computational\nrequirements and are not always suitable for low-resource or real-time\nsettings. To address these shortcomings, we present POSSM, a novel hybrid\narchitecture that combines individual spike tokenization via a cross-attention\nmodule with a recurrent state-space model (SSM) backbone to enable (1) fast and\ncausal online prediction on neural activity and (2) efficient generalization to\nnew sessions, individuals, and tasks through multi-dataset pretraining. We\nevaluate POSSM's decoding performance and inference speed on intracortical\ndecoding of monkey motor tasks, and show that it extends to clinical\napplications, namely handwriting and speech decoding in human subjects.\nNotably, we demonstrate that pretraining on monkey motor-cortical recordings\nimproves decoding performance on the human handwriting task, highlighting the\nexciting potential for cross-species transfer. In all of these tasks, we find\nthat POSSM achieves decoding accuracy comparable to state-of-the-art\nTransformers, at a fraction of the inference cost (up to 9x faster on GPU).\nThese results suggest that hybrid SSMs are a promising approach to bridging the\ngap between accuracy, inference speed, and generalization when training neural\ndecoders for real-time, closed-loop applications.", "published": "2025-06-05 17:57:08", "link": "http://arxiv.org/abs/2506.05320v1", "categories": ["q-bio.NC", "cs.LG"], "primary_category": "q-bio.NC"}
{"title": "Learning normalized image densities via dual score matching", "abstract": "Learning probability models from data is at the heart of many machine\nlearning endeavors, but is notoriously difficult due to the curse of\ndimensionality. We introduce a new framework for learning \\emph{normalized}\nenergy (log probability) models that is inspired from diffusion generative\nmodels, which rely on networks optimized to estimate the score. We modify a\nscore network architecture to compute an energy while preserving its inductive\nbiases. The gradient of this energy network with respect to its input image is\nthe score of the learned density, which can be optimized using a denoising\nobjective. Importantly, the gradient with respect to the noise level provides\nan additional score that can be optimized with a novel secondary objective,\nensuring consistent and normalized energies across noise levels. We train an\nenergy network with this \\emph{dual} score matching objective on the ImageNet64\ndataset, and obtain a cross-entropy (negative log likelihood) value comparable\nto the state of the art. We further validate our approach by showing that our\nenergy model \\emph{strongly generalizes}: estimated log probabilities are\nnearly independent of the specific images in the training set. Finally, we\ndemonstrate that both image probability and dimensionality of local\nneighborhoods vary significantly with image content, in contrast with\ntraditional assumptions such as concentration of measure or support on a\nlow-dimensional manifold.", "published": "2025-06-05 17:53:57", "link": "http://arxiv.org/abs/2506.05310v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Power Law Guided Dynamic Sifting for Efficient Attention", "abstract": "Efficient inference on GPUs using large language models remains challenging\ndue to memory bandwidth limitations, particularly during data transfers between\nHigh Bandwidth Memory (HBM) and SRAM in attention computations. Approximate\nattention methods address this issue by reducing computational and memory\noverhead but often rely on expensive top-$k$ operations, which perform poorly\non GPUs. We propose SiftAttention, a novel approximate attention method that\nreplaces the top-$k$ step with a computationally efficient element-wise\nfiltering operation based on a threshold value. Our intuition for doing this is\nbased on our empirical observation that the $\\tau$-th quantile of attention\nscores follows a predictable power-law over sequential generation steps.\nExploiting this insight, our approach dynamically estimates a threshold value\nper prompt at each generation step. Only attention scores above this threshold\nand their corresponding value vectors are loaded/used to compute the attention\noutput, reducing data movement between HBM and SRAM. Our evaluation\ndemonstrates that SiftAttention preserves model quality better than existing\napproximate attention methods while reducing memory bandwidth usage when\nloading value vectors.", "published": "2025-06-05 17:50:32", "link": "http://arxiv.org/abs/2506.05300v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Smooth Sea Never Made a Skilled $\\texttt{SAILOR}$: Robust Imitation via Learning to Search", "abstract": "The fundamental limitation of the behavioral cloning (BC) approach to\nimitation learning is that it only teaches an agent what the expert did at\nstates the expert visited. This means that when a BC agent makes a mistake\nwhich takes them out of the support of the demonstrations, they often don't\nknow how to recover from it. In this sense, BC is akin to giving the agent the\nfish -- giving them dense supervision across a narrow set of states -- rather\nthan teaching them to fish: to be able to reason independently about achieving\nthe expert's outcome even when faced with unseen situations at test-time. In\nresponse, we explore learning to search (L2S) from expert demonstrations, i.e.\nlearning the components required to, at test time, plan to match expert\noutcomes, even after making a mistake. These include (1) a world model and (2)\na reward model. We carefully ablate the set of algorithmic and design decisions\nrequired to combine these and other components for stable and\nsample/interaction-efficient learning of recovery behavior without additional\nhuman corrections. Across a dozen visual manipulation tasks from three\nbenchmarks, our approach $\\texttt{SAILOR}$ consistently out-performs\nstate-of-the-art Diffusion Policies trained via BC on the same data.\nFurthermore, scaling up the amount of demonstrations used for BC by\n5-10$\\times$ still leaves a performance gap. We find that $\\texttt{SAILOR}$ can\nidentify nuanced failures and is robust to reward hacking. Our code is\navailable at https://github.com/arnavkj1995/SAILOR .", "published": "2025-06-05 17:47:40", "link": "http://arxiv.org/abs/2506.05294v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning Beyond Experience: Generalizing to Unseen State Space with Reservoir Computing", "abstract": "Machine learning techniques offer an effective approach to modeling dynamical\nsystems solely from observed data. However, without explicit structural priors\n-- built-in assumptions about the underlying dynamics -- these techniques\ntypically struggle to generalize to aspects of the dynamics that are poorly\nrepresented in the training data. Here, we demonstrate that reservoir computing\n-- a simple, efficient, and versatile machine learning framework often used for\ndata-driven modeling of dynamical systems -- can generalize to unexplored\nregions of state space without explicit structural priors. First, we describe a\nmultiple-trajectory training scheme for reservoir computers that supports\ntraining across a collection of disjoint time series, enabling effective use of\navailable training data. Then, applying this training scheme to multistable\ndynamical systems, we show that RCs trained on trajectories from a single basin\nof attraction can achieve out-of-domain generalization by capturing system\nbehavior in entirely unobserved basins.", "published": "2025-06-05 17:46:07", "link": "http://arxiv.org/abs/2506.05292v1", "categories": ["cs.LG", "math.DS", "nlin.CD", "physics.comp-ph"], "primary_category": "cs.LG"}
{"title": "How to Unlock Time Series Editing? Diffusion-Driven Approach with Multi-Grained Control", "abstract": "Recent advances in time series generation have shown promise, yet controlling\nproperties in generated sequences remains challenging. Time Series Editing\n(TSE) - making precise modifications while preserving temporal coherence -\nconsider both point-level constraints and segment-level controls that current\nmethods struggle to provide. We introduce the CocktailEdit framework to enable\nsimultaneous, flexible control across different types of constraints. This\nframework combines two key mechanisms: a confidence-weighted anchor control for\npoint-wise constraints and a classifier-based control for managing statistical\nproperties such as sums and averages over segments. Our methods achieve precise\nlocal control during the denoising inference stage while maintaining temporal\ncoherence and integrating seamlessly, with any conditionally trained\ndiffusion-based time series models. Extensive experiments across diverse\ndatasets and models demonstrate its effectiveness. Our work bridges the gap\nbetween pure generative modeling and real-world time series editing needs,\noffering a flexible solution for human-in-the-loop time series generation and\nediting. The code and demo are provided for validation.", "published": "2025-06-05 17:32:00", "link": "http://arxiv.org/abs/2506.05276v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Tight analyses of first-order methods with error feedback", "abstract": "Communication between agents often constitutes a major computational\nbottleneck in distributed learning. One of the most common mitigation\nstrategies is to compress the information exchanged, thereby reducing\ncommunication overhead. To counteract the degradation in convergence associated\nwith compressed communication, error feedback schemes -- most notably\n$\\mathrm{EF}$ and $\\mathrm{EF}^{21}$ -- were introduced. In this work, we\nprovide a tight analysis of both of these methods. Specifically, we find the\nLyapunov function that yields the best possible convergence rate for each\nmethod -- with matching lower bounds. This principled approach yields sharp\nperformance guarantees and enables a rigorous, apples-to-apples comparison\nbetween $\\mathrm{EF}$, $\\mathrm{EF}^{21}$, and compressed gradient descent. Our\nanalysis is carried out in a simplified yet representative setting, which\nallows for clean theoretical insights and fair comparison of the underlying\nmechanisms.", "published": "2025-06-05 17:30:18", "link": "http://arxiv.org/abs/2506.05271v1", "categories": ["cs.LG", "cs.DC", "math.OC"], "primary_category": "cs.LG"}
{"title": "Learning long range dependencies through time reversal symmetry breaking", "abstract": "Deep State Space Models (SSMs) reignite physics-grounded compute paradigms,\nas RNNs could natively be embodied into dynamical systems. This calls for\ndedicated learning algorithms obeying to core physical principles, with\nefficient techniques to simulate these systems and guide their design. We\npropose Recurrent Hamiltonian Echo Learning (RHEL), an algorithm which provably\ncomputes loss gradients as finite differences of physical trajectories of\nnon-dissipative, Hamiltonian systems. In ML terms, RHEL only requires three\n\"forward passes\" irrespective of model size, without explicit Jacobian\ncomputation, nor incurring any variance in the gradient estimation. Motivated\nby the physical realization of our algorithm, we first introduce RHEL in\ncontinuous time and demonstrate its formal equivalence with the continuous\nadjoint state method. To facilitate the simulation of Hamiltonian systems\ntrained by RHEL, we propose a discrete-time version of RHEL which is equivalent\nto Backpropagation Through Time (BPTT) when applied to a class of recurrent\nmodules which we call Hamiltonian Recurrent Units (HRUs). This setting allows\nus to demonstrate the scalability of RHEL by generalizing these results to\nhierarchies of HRUs, which we call Hamiltonian SSMs (HSSMs). We apply RHEL to\ntrain HSSMs with linear and nonlinear dynamics on a variety of time-series\ntasks ranging from mid-range to long-range classification and regression with\nsequence length reaching $\\sim 50k$. We show that RHEL consistently matches the\nperformance of BPTT across all models and tasks. This work opens new doors for\nthe design of scalable, energy-efficient physical systems endowed with\nself-learning capabilities for sequence modelling.", "published": "2025-06-05 17:20:39", "link": "http://arxiv.org/abs/2506.05259v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning", "abstract": "Machine learning is now ubiquitous in societal decision-making, for example\nin evaluating job candidates or loan applications, and it is increasingly\nimportant to take into account how classified agents will react to the learning\nalgorithms. The majority of recent literature on strategic classification has\nfocused on reducing and countering deceptive behaviors by the classified\nagents, but recent work of Attias et al. identifies surprising properties of\nlearnability when the agents genuinely improve in order to attain the desirable\nclassification, such as smaller generalization error than standard\nPAC-learning. In this paper we characterize so-called learnability with\nimprovements across multiple new axes. We introduce an asymmetric variant of\nminimally consistent concept classes and use it to provide an exact\ncharacterization of proper learning with improvements in the realizable\nsetting. While prior work studies learnability only under general, arbitrary\nagent improvement regions, we give positive results for more natural Euclidean\nball improvement sets. In particular, we characterize improper learning under a\nmild generative assumption on the data distribution. We further show how to\nlearn in more challenging settings, achieving lower generalization error under\nwell-studied bounded noise models and obtaining mistake bounds in realizable\nand agnostic online learning. We resolve open questions posed by Attias et al.\nfor both proper and improper learning.", "published": "2025-06-05 17:13:59", "link": "http://arxiv.org/abs/2506.05252v1", "categories": ["cs.LG", "cs.GT", "cs.MA"], "primary_category": "cs.LG"}
{"title": "On the Convergence of Gradient Descent on Learning Transformers with Residual Connections", "abstract": "Transformer models have emerged as fundamental tools across various\nscientific and engineering disciplines, owing to their outstanding performance\nin diverse applications. Despite this empirical success, the theoretical\nfoundations of Transformers remain relatively underdeveloped, particularly in\nunderstanding their training dynamics. Existing research predominantly examines\nisolated components--such as self-attention mechanisms and feedforward\nnetworks--without thoroughly investigating the interdependencies between these\ncomponents, especially when residual connections are present. In this paper, we\naim to bridge this gap by analyzing the convergence behavior of a structurally\ncomplete yet single-layer Transformer, comprising self-attention, a feedforward\nnetwork, and residual connections. We demonstrate that, under appropriate\ninitialization, gradient descent exhibits a linear convergence rate, where the\nconvergence speed is determined by the minimum and maximum singular values of\nthe output matrix from the attention layer. Moreover, our analysis reveals that\nresidual connections serve to ameliorate the ill-conditioning of this output\nmatrix, an issue stemming from the low-rank structure imposed by the softmax\noperation, thereby promoting enhanced optimization stability. We also extend\nour theoretical findings to a multi-layer Transformer architecture, confirming\nthe linear convergence rate of gradient descent under suitable initialization.\nEmpirical results corroborate our theoretical insights, illustrating the\nbeneficial role of residual connections in promoting convergence stability.", "published": "2025-06-05 17:10:22", "link": "http://arxiv.org/abs/2506.05249v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Robust Moment Identification for Nonlinear PDEs via a Neural ODE Approach", "abstract": "We propose a data-driven framework for learning reduced-order moment dynamics\nfrom PDE-governed systems using Neural ODEs. In contrast to derivative-based\nmethods like SINDy, which necessitate densely sampled data and are sensitive to\nnoise, our approach based on Neural ODEs directly models moment trajectories,\nenabling robust learning from sparse and potentially irregular time series.\nUsing as an application platform the nonlinear Schr\\\"{o}dinger equation, the\nframework accurately recovers governing moment dynamics when closure is\navailable, even with limited and irregular observations. For systems without\nanalytical closure, we introduce a data-driven coordinate transformation\nstrategy based on Stiefel manifold optimization, enabling the discovery of\nlow-dimensional representations in which the moment dynamics become closed,\nfacilitating interpretable and reliable modeling. We also explore cases where a\nclosure model is not known, such as a Fisher-KPP reaction-diffusion system.\nHere we demonstrate that Neural ODEs can still effectively approximate the\nunclosed moment dynamics and achieve superior extrapolation accuracy compared\nto physical-expert-derived ODE models. This advantage remains robust even under\nsparse and irregular sampling, highlighting the method's robustness in\ndata-limited settings. Our results highlight the Neural ODE framework as a\npowerful and flexible tool for learning interpretable, low-dimensional moment\ndynamics in complex PDE-governed systems.", "published": "2025-06-05 17:03:42", "link": "http://arxiv.org/abs/2506.05245v1", "categories": ["nlin.PS", "cs.LG"], "primary_category": "nlin.PS"}
{"title": "Evaluating Sparse Autoencoders: From Shallow Design to Matching Pursuit", "abstract": "Sparse autoencoders (SAEs) have recently become central tools for\ninterpretability, leveraging dictionary learning principles to extract sparse,\ninterpretable features from neural representations whose underlying structure\nis typically unknown. This paper evaluates SAEs in a controlled setting using\nMNIST, which reveals that current shallow architectures implicitly rely on a\nquasi-orthogonality assumption that limits the ability to extract correlated\nfeatures. To move beyond this, we introduce a multi-iteration SAE by unrolling\nMatching Pursuit (MP-SAE), enabling the residual-guided extraction of\ncorrelated features that arise in hierarchical settings such as handwritten\ndigit generation while guaranteeing monotonic improvement of the reconstruction\nas more atoms are selected.", "published": "2025-06-05 16:57:58", "link": "http://arxiv.org/abs/2506.05239v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Progressive Tempering Sampler with Diffusion", "abstract": "Recent research has focused on designing neural samplers that amortize the\nprocess of sampling from unnormalized densities. However, despite significant\nadvancements, they still fall short of the state-of-the-art MCMC approach,\nParallel Tempering (PT), when it comes to the efficiency of target evaluations.\nOn the other hand, unlike a well-trained neural sampler, PT yields only\ndependent samples and needs to be rerun -- at considerable computational cost\n-- whenever new samples are required. To address these weaknesses, we propose\nthe Progressive Tempering Sampler with Diffusion (PTSD), which trains diffusion\nmodels sequentially across temperatures, leveraging the advantages of PT to\nimprove the training of neural samplers. We also introduce a novel method to\ncombine high-temperature diffusion models to generate approximate\nlower-temperature samples, which are minimally refined using MCMC and used to\ntrain the next diffusion model. PTSD enables efficient reuse of sample\ninformation across temperature levels while generating well-mixed, uncorrelated\nsamples. Our method significantly improves target evaluation efficiency,\noutperforming diffusion-based neural samplers.", "published": "2025-06-05 16:46:04", "link": "http://arxiv.org/abs/2506.05231v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Unified Framework for Provably Efficient Algorithms to Estimate Shapley Values", "abstract": "Shapley values have emerged as a critical tool for explaining which features\nimpact the decisions made by machine learning models. However, computing exact\nShapley values is difficult, generally requiring an exponential (in the feature\ndimension) number of model evaluations. To address this, many model-agnostic\nrandomized estimators have been developed, the most influential and widely used\nbeing the KernelSHAP method (Lundberg & Lee, 2017). While related estimators\nsuch as unbiased KernelSHAP (Covert & Lee, 2021) and LeverageSHAP (Musco &\nWitter, 2025) are known to satisfy theoretical guarantees, bounds for\nKernelSHAP have remained elusive. We describe a broad and unified framework\nthat encompasses KernelSHAP and related estimators constructed using both with\nand without replacement sampling strategies. We then prove strong\nnon-asymptotic theoretical guarantees that apply to all estimators from our\nframework. This provides, to the best of our knowledge, the first theoretical\nguarantees for KernelSHAP and sheds further light on tradeoffs between existing\nestimators. Through comprehensive benchmarking on small and medium dimensional\ndatasets for Decision-Tree models, we validate our approach against exact\nShapley values, consistently achieving low mean squared error with modest\nsample sizes. Furthermore, we make specific implementation improvements to\nenable scalability of our methods to high-dimensional datasets. Our methods,\ntested on datasets such MNIST and CIFAR10, provide consistently better results\ncompared to the KernelSHAP library.", "published": "2025-06-05 16:30:53", "link": "http://arxiv.org/abs/2506.05216v1", "categories": ["cs.LG", "cs.DS", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Learning Theory of Decentralized Robust Kernel-Based Learning Algorithm", "abstract": "We propose a new decentralized robust kernel-based learning algorithm within\nthe framework of reproducing kernel Hilbert space (RKHS) by utilizing a\nnetworked system that can be represented as a connected graph. The robust loss\nfunction $\\mathcal{L}_\\sigma$ induced by a windowing function $W$ and a\nrobustness scaling parameter $\\sigma>0$, can encompass a broad spectrum of\nrobust losses. Consequently, the proposed algorithm effectively provides a\nunified decentralized learning framework for robust regression, which\nfundamentally differs from the existing distributed robust kernel learning\nschemes, all of which are divide-and-conquer based. We rigorously establish the\nlearning theory and offer a comprehensive convergence analysis for the\nalgorithm. We show each local robust estimator generated from the decentralized\nalgorithm can be utilized to approximate the regression function. Based on\nkernel-based integral operator techniques, we derive general high confidence\nconvergence bounds for each local approximating sequence in terms of the mean\nsquare distance, RKHS norm, and generalization error, respectively. Moreover,\nwe provide rigorous selection rules for local sample size and show that, under\nproperly selected step size and scaling parameter $\\sigma$, the decentralized\nrobust algorithm can achieve optimal learning rates (up to logarithmic factors)\nin both norms. The parameter $\\sigma$ is shown to be essential for enhancing\nrobustness while also ensuring favorable convergence behavior. The intrinsic\nconnection among decentralization, sample selection, robustness of the\nalgorithm, and its convergence is clearly reflected.", "published": "2025-06-05 16:30:05", "link": "http://arxiv.org/abs/2506.05215v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Trustworthiness Preservation by Copies of Machine Learning Systems", "abstract": "A common practice of ML systems development concerns the training of the same\nmodel under different data sets, and the use of the same (training and test)\nsets for different learning models. The first case is a desirable practice for\nidentifying high quality and unbiased training conditions. The latter case\ncoincides with the search for optimal models under a common dataset for\ntraining. These differently obtained systems have been considered akin to\ncopies. In the quest for responsible AI, a legitimate but hardly investigated\nquestion is how to verify that trustworthiness is preserved by copies. In this\npaper we introduce a calculus to model and verify probabilistic complex queries\nover data and define four distinct notions: Justifiably, Equally, Weakly and\nAlmost Trustworthy which can be checked analysing the (partial) behaviour of\nthe copy with respect to its original. We provide a study of the relations\nbetween these notions of trustworthiness, and how they compose with each other\nand under logical operations. The aim is to offer a computational tool to check\nthe trustworthiness of possibly complex systems copied from an original whose\nbehavour is known.", "published": "2025-06-05 16:14:57", "link": "http://arxiv.org/abs/2506.05203v1", "categories": ["cs.LO", "cs.LG", "I.2.3; I.2.4"], "primary_category": "cs.LO"}
{"title": "Causal Effect Identification in lvLiNGAM from Higher-Order Cumulants", "abstract": "This paper investigates causal effect identification in latent variable\nLinear Non-Gaussian Acyclic Models (lvLiNGAM) using higher-order cumulants,\naddressing two prominent setups that are challenging in the presence of latent\nconfounding: (1) a single proxy variable that may causally influence the\ntreatment and (2) underspecified instrumental variable cases where fewer\ninstruments exist than treatments. We prove that causal effects are\nidentifiable with a single proxy or instrument and provide corresponding\nestimation methods. Experimental results demonstrate the accuracy and\nrobustness of our approaches compared to existing methods, advancing the\ntheoretical and practical understanding of causal inference in linear systems\nwith latent confounders.", "published": "2025-06-05 16:14:35", "link": "http://arxiv.org/abs/2506.05202v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Transformers Meet In-Context Learning: A Universal Approximation Theory", "abstract": "Modern large language models are capable of in-context learning, the ability\nto perform new tasks at inference time using only a handful of input-output\nexamples in the prompt, without any fine-tuning or parameter updates. We\ndevelop a universal approximation theory to better understand how transformers\nenable in-context learning. For any class of functions (each representing a\ndistinct task), we demonstrate how to construct a transformer that, without any\nfurther weight updates, can perform reliable prediction given only a few\nin-context examples. In contrast to much of the recent literature that frames\ntransformers as algorithm approximators -- i.e., constructing transformers to\nemulate the iterations of optimization algorithms as a means to approximate\nsolutions of learning problems -- our work adopts a fundamentally different\napproach rooted in universal function approximation. This alternative approach\noffers approximation guarantees that are not constrained by the effectiveness\nof the optimization algorithms being approximated, thereby extending far beyond\nconvex problems and linear function classes. Our construction sheds light on\nhow transformers can simultaneously learn general-purpose representations and\nadapt dynamically to in-context examples.", "published": "2025-06-05 16:12:51", "link": "http://arxiv.org/abs/2506.05200v1", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Locality Preserving Markovian Transition for Instance Retrieval", "abstract": "Diffusion-based re-ranking methods are effective in modeling the data\nmanifolds through similarity propagation in affinity graphs. However, positive\nsignals tend to diminish over several steps away from the source, reducing\ndiscriminative power beyond local regions. To address this issue, we introduce\nthe Locality Preserving Markovian Transition (LPMT) framework, which employs a\nlong-term thermodynamic transition process with multiple states for accurate\nmanifold distance measurement. The proposed LPMT first integrates diffusion\nprocesses across separate graphs using Bidirectional Collaborative Diffusion\n(BCD) to establish strong similarity relationships. Afterwards, Locality State\nEmbedding (LSE) encodes each instance into a distribution for enhanced local\nconsistency. These distributions are interconnected via the Thermodynamic\nMarkovian Transition (TMT) process, enabling efficient global retrieval while\nmaintaining local effectiveness. Experimental results across diverse tasks\nconfirm the effectiveness of LPMT for instance retrieval.", "published": "2025-06-05 16:07:31", "link": "http://arxiv.org/abs/2506.05196v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Associative Memory and Generative Diffusion in the Zero-noise Limit", "abstract": "Connections between generative diffusion and continuous-state associative\nmemory models are studied. Morse-Smale dynamical systems are emphasized as\nuniversal approximators of gradient-based associative memory models and\ndiffusion models as white-noise perturbed systems thereof. Universal properties\nof associative memory that follow from this description are described and used\nto characterize a generic transition from generation to memory as noise levels\ndiminish. Structural stability inherited by Morse-Smale flows is shown to imply\na notion of stability for diffusions at vanishing noise levels. Applied to one-\nand two-parameter families of gradients, this indicates stability at all but\nisolated points of associative memory learning landscapes and the learning and\ngeneration landscapes of diffusion models with gradient drift in the zero-noise\nlimit, at which small sets of generic bifurcations characterize qualitative\ntransitions between stable systems. Examples illustrating the characterization\nof these landscapes by sequences of these bifurcations are given, along with\nstructural stability criterion for classic and modern Hopfield networks\n(equivalently, the attention mechanism).", "published": "2025-06-05 15:51:47", "link": "http://arxiv.org/abs/2506.05178v1", "categories": ["cs.LG", "cond-mat.dis-nn", "math.DS", "nlin.AO", "q-bio.NC"], "primary_category": "cs.LG"}
{"title": "Federated Isolation Forest for Efficient Anomaly Detection on Edge IoT Systems", "abstract": "Recently, federated learning frameworks such as Python TestBed for Federated\nLearning Algorithms and MicroPython TestBed for Federated Learning Algorithms\nhave emerged to tackle user privacy concerns and efficiency in embedded\nsystems. Even more recently, an efficient federated anomaly detection\nalgorithm, FLiForest, based on Isolation Forests has been developed, offering a\nlow-resource, unsupervised method well-suited for edge deployment and\ncontinuous learning. In this paper, we present an application of Isolation\nForest-based temperature anomaly detection, developed using the previously\nmentioned federated learning frameworks, aimed at small edge devices and IoT\nsystems running MicroPython. The system has been experimentally evaluated,\nachieving over 96% accuracy in distinguishing normal from abnormal readings and\nabove 78% precision in detecting anomalies across all tested configurations,\nwhile maintaining a memory usage below 160 KB during model training. These\nresults highlight its suitability for resource-constrained environments and\nedge systems, while upholding federated learning principles of data privacy and\ncollaborative learning.", "published": "2025-06-05 15:22:04", "link": "http://arxiv.org/abs/2506.05138v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Membership Inference Attacks on Sequence Models", "abstract": "Sequence models, such as Large Language Models (LLMs) and autoregressive\nimage generators, have a tendency to memorize and inadvertently leak sensitive\ninformation. While this tendency has critical legal implications, existing\ntools are insufficient to audit the resulting risks. We hypothesize that those\ntools' shortcomings are due to mismatched assumptions. Thus, we argue that\neffectively measuring privacy leakage in sequence models requires leveraging\nthe correlations inherent in sequential generation. To illustrate this, we\nadapt a state-of-the-art membership inference attack to explicitly model\nwithin-sequence correlations, thereby demonstrating how a strong existing\nattack can be naturally extended to suit the structure of sequence models.\nThrough a case study, we show that our adaptations consistently improve the\neffectiveness of memorization audits without introducing additional\ncomputational costs. Our work hence serves as an important stepping stone\ntoward reliable memorization audits for large sequence models.", "published": "2025-06-05 15:13:57", "link": "http://arxiv.org/abs/2506.05126v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Nonlinear Causal Discovery for Grouped Data", "abstract": "Inferring cause-effect relationships from observational data has gained\nsignificant attention in recent years, but most methods are limited to scalar\nrandom variables. In many important domains, including neuroscience,\npsychology, social science, and industrial manufacturing, the causal units of\ninterest are groups of variables rather than individual scalar measurements.\nMotivated by these applications, we extend nonlinear additive noise models to\nhandle random vectors, establishing a two-step approach for causal graph\nlearning: First, infer the causal order among random vectors. Second, perform\nmodel selection to identify the best graph consistent with this order. We\nintroduce effective and novel solutions for both steps in the vector case,\ndemonstrating strong performance in simulations. Finally, we apply our method\nto real-world assembly line data with partial knowledge of causal ordering\namong variable groups.", "published": "2025-06-05 15:08:01", "link": "http://arxiv.org/abs/2506.05120v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Privacy Amplification Through Synthetic Data: Insights from Linear Regression", "abstract": "Synthetic data inherits the differential privacy guarantees of the model used\nto generate it. Additionally, synthetic data may benefit from privacy\namplification when the generative model is kept hidden. While empirical studies\nsuggest this phenomenon, a rigorous theoretical understanding is still lacking.\nIn this paper, we investigate this question through the well-understood\nframework of linear regression. First, we establish negative results showing\nthat if an adversary controls the seed of the generative model, a single\nsynthetic data point can leak as much information as releasing the model\nitself. Conversely, we show that when synthetic data is generated from random\ninputs, releasing a limited number of synthetic data points amplifies privacy\nbeyond the model's inherent guarantees. We believe our findings in linear\nregression can serve as a foundation for deriving more general bounds in the\nfuture.", "published": "2025-06-05 14:44:15", "link": "http://arxiv.org/abs/2506.05101v1", "categories": ["cs.LG", "cs.CR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Semi-Implicit Variational Inference via Kernelized Path Gradient Descent", "abstract": "Semi-implicit variational inference (SIVI) is a powerful framework for\napproximating complex posterior distributions, but training with the\nKullback-Leibler (KL) divergence can be challenging due to high variance and\nbias in high-dimensional settings. While current state-of-the-art semi-implicit\nvariational inference methods, particularly Kernel Semi-Implicit Variational\nInference (KSIVI), have been shown to work in high dimensions, training remains\nmoderately expensive. In this work, we propose a kernelized KL divergence\nestimator that stabilizes training through nonparametric smoothing. To further\nreduce the bias, we introduce an importance sampling correction. We provide a\ntheoretical connection to the amortized version of the Stein variational\ngradient descent, which estimates the score gradient via Stein's identity,\nshowing that both methods minimize the same objective, but our semi-implicit\napproach achieves lower gradient variance. In addition, our method's bias in\nfunction space is benign, leading to more stable and efficient optimization.\nEmpirical results demonstrate that our method outperforms or matches\nstate-of-the-art SIVI methods in both performance and training efficiency.", "published": "2025-06-05 14:34:37", "link": "http://arxiv.org/abs/2506.05088v1", "categories": ["cs.LG", "stat.CO", "62F15, 68T07", "I.2.6; G.3"], "primary_category": "cs.LG"}
{"title": "EMBER2024 -- A Benchmark Dataset for Holistic Evaluation of Malware Classifiers", "abstract": "A lack of accessible data has historically restricted malware analysis\nresearch, and practitioners have relied heavily on datasets provided by\nindustry sources to advance. Existing public datasets are limited by narrow\nscope - most include files targeting a single platform, have labels supporting\njust one type of malware classification task, and make no effort to capture the\nevasive files that make malware detection difficult in practice. We present\nEMBER2024, a new dataset that enables holistic evaluation of malware\nclassifiers. Created in collaboration with the authors of EMBER2017 and\nEMBER2018, the EMBER2024 dataset includes hashes, metadata, feature vectors,\nand labels for more than 3.2 million files from six file formats. Our dataset\nsupports the training and evaluation of machine learning models on seven\nmalware classification tasks, including malware detection, malware family\nclassification, and malware behavior identification. EMBER2024 is the first to\ninclude a collection of malicious files that initially went undetected by a set\nof antivirus products, creating a \"challenge\" set to assess classifier\nperformance against evasive malware. This work also introduces EMBER feature\nversion 3, with added support for several new feature types. We are releasing\nthe EMBER2024 dataset to promote reproducibility and empower researchers in the\npursuit of new malware research topics.", "published": "2025-06-05 14:20:36", "link": "http://arxiv.org/abs/2506.05074v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "UnHiPPO: Uncertainty-aware Initialization for State Space Models", "abstract": "State space models are emerging as a dominant model class for sequence\nproblems with many relying on the HiPPO framework to initialize their dynamics.\nHowever, HiPPO fundamentally assumes data to be noise-free; an assumption often\nviolated in practice. We extend the HiPPO theory with measurement noise and\nderive an uncertainty-aware initialization for state space model dynamics. In\nour analysis, we interpret HiPPO as a linear stochastic control problem where\nthe data enters as a noise-free control signal. We then reformulate the problem\nso that the data become noisy outputs of a latent system and arrive at an\nalternative dynamics initialization that infers the posterior of this latent\nsystem from the data without increasing runtime. Our experiments show that our\ninitialization improves the resistance of state-space models to noise both at\ntraining and inference time. Find our implementation at\nhttps://cs.cit.tum.de/daml/unhippo.", "published": "2025-06-05 14:11:36", "link": "http://arxiv.org/abs/2506.05065v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "NIMO: a Nonlinear Interpretable MOdel", "abstract": "Neural networks (NNs) have achieved tremendous success over the past decade,\nyet they are still extremely difficult to interpret. In contrast, linear models\nare less expressive but offer inherent interpretability. Linear coefficients\nare interpretable as the marginal effect of a feature on the prediction,\nassuming all other features are kept fixed. To combine the benefits of both\napproaches, we introduce NIMO (Nonlinear Interpretable MOdel). The key idea is\nto define a model where the NN is designed to learn nonlinear corrections to\nthe linear model predictions, while also maintaining the original\ninterpretability of the linear coefficients. Relevantly, we develop an\noptimization algorithm based on profile likelihood that elegantly allows for\noptimizing over the NN parameters while updating the linear coefficients\nanalytically. By relying on adaptive ridge regression we can easily incorporate\nsparsity constraints as well. We show empirically that we can recover the\nunderlying linear coefficients while significantly improving the predictive\naccuracy. Compared to other hybrid interpretable approaches, our model is the\nonly one that actually maintains the same interpretability of linear\ncoefficients as in linear models. We also achieve higher performance on various\nregression and classification settings.", "published": "2025-06-05 14:02:55", "link": "http://arxiv.org/abs/2506.05059v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Reliably detecting model failures in deployment without labels", "abstract": "The distribution of data changes over time; models operating operating in\ndynamic environments need retraining. But knowing when to retrain, without\naccess to labels, is an open challenge since some, but not all shifts degrade\nmodel performance. This paper formalizes and addresses the problem of\npost-deployment deterioration (PDD) monitoring. We propose D3M, a practical and\nefficient monitoring algorithm based on the disagreement of predictive models,\nachieving low false positive rates under non-deteriorating shifts and provides\nsample complexity bounds for high true positive rates under deteriorating\nshifts. Empirical results on both standard benchmark and a real-world\nlarge-scale internal medicine dataset demonstrate the effectiveness of the\nframework and highlight its viability as an alert mechanism for high-stakes\nmachine learning pipelines.", "published": "2025-06-05 13:56:18", "link": "http://arxiv.org/abs/2506.05047v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "iN2V: Bringing Transductive Node Embeddings to Inductive Graphs", "abstract": "Shallow node embeddings like node2vec (N2V) can be used for nodes without\nfeatures or to supplement existing features with structure-based information.\nEmbedding methods like N2V are limited in their application on new nodes, which\nrestricts them to the transductive setting where the entire graph, including\nthe test nodes, is available during training. We propose inductive node2vec\n(iN2V), which combines a post-hoc procedure to compute embeddings for nodes\nunseen during training and modifications to the original N2V training procedure\nto prepare the embeddings for this post-hoc procedure. We conduct experiments\non several benchmark datasets and demonstrate that iN2V is an effective\napproach to bringing transductive embeddings to an inductive setting. Using\niN2V embeddings improves node classification by 1 point on average, with up to\n6 points of improvement depending on the dataset and the number of unseen\nnodes. Our iN2V is a plug-in approach to create new or enrich existing\nembeddings. It can also be combined with other embedding methods, making it a\nversatile approach for inductive node representation learning. Code to\nreproduce the results is available at https://github.com/Foisunt/iN2V .", "published": "2025-06-05 13:43:24", "link": "http://arxiv.org/abs/2506.05039v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Tuning the Right Foundation Models is What you Need for Partial Label Learning", "abstract": "Partial label learning (PLL) seeks to train generalizable classifiers from\ndatasets with inexact supervision, a common challenge in real-world\napplications. Existing studies have developed numerous approaches to\nprogressively refine and recover ground-truth labels by training convolutional\nneural networks. However, limited attention has been given to foundation models\nthat offer transferrable representations. In this work, we empirically conduct\ncomprehensive evaluations of 11 foundation models across 13 PLL approaches on 8\nbenchmark datasets under 3 PLL scenarios. We further propose PartialCLIP, an\nefficient fine-tuning framework for foundation models in PLL. Our findings\nreveal that current PLL approaches tend to 1) achieve significant performance\ngains when using foundation models, 2) exhibit remarkably similar performance\nto each other, 3) maintain stable performance across varying ambiguity levels,\nwhile 4) are susceptible to foundation model selection and adaptation\nstrategies. Additionally, we demonstrate the efficacy of text-embedding\nclassifier initialization and effective candidate label filtering using\nzero-shot CLIP. Our experimental results and analysis underscore the\nlimitations of current PLL approaches and provide valuable insights for\ndeveloping more generalizable PLL models. The source code can be found at\nhttps://github.com/SEU-hk/PartialCLIP.", "published": "2025-06-05 13:37:33", "link": "http://arxiv.org/abs/2506.05027v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-Point Proximity Encoding For Vector-Mode Geospatial Machine Learning", "abstract": "Vector-mode geospatial data -- points, lines, and polygons -- must be encoded\ninto an appropriate form in order to be used with traditional machine learning\nand artificial intelligence models. Encoding methods attempt to represent a\ngiven shape as a vector that captures its essential geometric properties. This\npaper presents an encoding method based on scaled distances from a shape to a\nset of reference points within a region of interest. The method, MultiPoint\nProximity (MPP) encoding, can be applied to any type of shape, enabling the\nparameterization of machine learning models with encoded representations of\nvector-mode geospatial features. We show that MPP encoding possesses the\ndesirable properties of shape-centricity and continuity, can be used to\ndifferentiate spatial objects based on their geometric features, and can\ncapture pairwise spatial relationships with high precision. In all cases, MPP\nencoding is shown to perform better than an alternative method based on\nrasterization.", "published": "2025-06-05 13:22:47", "link": "http://arxiv.org/abs/2506.05016v1", "categories": ["cs.LG", "68T07, 68T30", "I.2.4; J.2"], "primary_category": "cs.LG"}
{"title": "QiMeng: Fully Automated Hardware and Software Design for Processor Chip", "abstract": "Processor chip design technology serves as a key frontier driving\nbreakthroughs in computer science and related fields. With the rapid\nadvancement of information technology, conventional design paradigms face three\nmajor challenges: the physical constraints of fabrication technologies, the\nescalating demands for design resources, and the increasing diversity of\necosystems. Automated processor chip design has emerged as a transformative\nsolution to address these challenges. While recent breakthroughs in Artificial\nIntelligence (AI), particularly Large Language Models (LLMs) techniques, have\nopened new possibilities for fully automated processor chip design, substantial\nchallenges remain in establishing domain-specific LLMs for processor chip\ndesign.\n  In this paper, we propose QiMeng, a novel system for fully automated hardware\nand software design of processor chips. QiMeng comprises three hierarchical\nlayers. In the bottom-layer, we construct a domain-specific Large Processor\nChip Model (LPCM) that introduces novel designs in architecture, training, and\ninference, to address key challenges such as knowledge representation gap, data\nscarcity, correctness assurance, and enormous solution space. In the\nmiddle-layer, leveraging the LPCM's knowledge representation and inference\ncapabilities, we develop the Hardware Design Agent and the Software Design\nAgent to automate the design of hardware and software for processor chips.\nCurrently, several components of QiMeng have been completed and successfully\napplied in various top-layer applications, demonstrating significant advantages\nand providing a feasible solution for efficient, fully automated\nhardware/software design of processor chips. Future research will focus on\nintegrating all components and performing iterative top-down and bottom-up\ndesign processes to establish a comprehensive QiMeng system.", "published": "2025-06-05 13:17:50", "link": "http://arxiv.org/abs/2506.05007v1", "categories": ["cs.AR", "cs.LG"], "primary_category": "cs.AR"}
{"title": "Cautious Optimism: A Meta-Algorithm for Near-Constant Regret in General Games", "abstract": "Recent work [Soleymani et al., 2025] introduced a variant of Optimistic\nMultiplicative Weights Updates (OMWU) that adaptively controls the learning\npace in a dynamic, non-monotone manner, achieving new state-of-the-art regret\nminimization guarantees in general games. In this work, we demonstrate that\nno-regret learning acceleration through adaptive pacing of the learners is not\nan isolated phenomenon. We introduce \\emph{Cautious Optimism}, a framework for\nsubstantially faster regularized learning in general games. Cautious Optimism\ntakes as input any instance of Follow-the-Regularized-Leader (FTRL) and outputs\nan accelerated no-regret learning algorithm by pacing the underlying FTRL with\nminimal computational overhead. Importantly, we retain uncoupledness (learners\ndo not need to know other players' utilities). Cautious Optimistic FTRL\nachieves near-optimal $O_T(\\log T)$ regret in diverse self-play\n(mixing-and-matching regularizers) while preserving the optimal $O(\\sqrt{T})$\nregret in adversarial scenarios. In contrast to prior works (e.g. Syrgkanis et\nal. [2015], Daskalakis et al. [2021]), our analysis does not rely on monotonic\nstep-sizes, showcasing a novel route for fast learning in general games.", "published": "2025-06-05 13:13:48", "link": "http://arxiv.org/abs/2506.05005v1", "categories": ["cs.LG", "cs.GT", "math.OC"], "primary_category": "cs.LG"}
{"title": "FPTQuant: Function-Preserving Transforms for LLM Quantization", "abstract": "Large language models (LLMs) require substantial compute, and thus energy, at\ninference time. While quantizing weights and activations is effective at\nimproving efficiency, naive quantization of LLMs can significantly degrade\nperformance due to large magnitude outliers. This paper describes FPTQuant,\nwhich introduces four novel, lightweight, and expressive function-preserving\ntransforms (FPTs) to facilitate quantization of transformers: (1) a mergeable\npre-RoPE transform for queries and keys, (2) a mergeable transform for values,\n(3) a mergeable scaling transform within the MLP block, and (4) a cheap,\ndynamic scaling transform. By leveraging the equivariances and independencies\ninherent to canonical transformer operation, we designed these FPTs to maintain\nthe model's function while shaping the intermediate activation distributions to\nbe more quantization friendly. FPTQuant requires no custom kernels and adds\nvirtually no overhead during inference. The FPTs are trained both locally to\nreduce outliers, and end-to-end such that the outputs of the quantized and\nfull-precision models match. FPTQuant enables static INT4 quantization with\nminimal overhead and shows SOTA speed-up of up to 3.9 times over FP.\nEmpirically, FPTQuant has an excellent accuracy-speed trade-off -- it is\nperforming on par or exceeding most prior work and only shows slightly lower\naccuracy compared to a method that is up to 29% slower.", "published": "2025-06-05 12:56:12", "link": "http://arxiv.org/abs/2506.04985v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Agentic AI for Intent-Based Industrial Automation", "abstract": "The recent development of Agentic AI systems, empowered by autonomous large\nlanguage models (LLMs) agents with planning and tool-usage capabilities,\nenables new possibilities for the evolution of industrial automation and\nreduces the complexity introduced by Industry 4.0. This work proposes a\nconceptual framework that integrates Agentic AI with the intent-based paradigm,\noriginally developed in network research, to simplify human-machine interaction\n(HMI) and better align automation systems with the human-centric, sustainable,\nand resilient principles of Industry 5.0. Based on the intent-based processing,\nthe framework allows human operators to express high-level business or\noperational goals in natural language, which are decomposed into actionable\ncomponents. These intents are broken into expectations, conditions, targets,\ncontext, and information that guide sub-agents equipped with specialized tools\nto execute domain-specific tasks. A proof of concept was implemented using the\nCMAPSS dataset and Google Agent Developer Kit (ADK), demonstrating the\nfeasibility of intent decomposition, agent orchestration, and autonomous\ndecision-making in predictive maintenance scenarios. The results confirm the\npotential of this approach to reduce technical barriers and enable scalable,\nintent-driven automation, despite data quality and explainability concerns.", "published": "2025-06-05 12:50:54", "link": "http://arxiv.org/abs/2506.04980v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Learning Joint Interventional Effects from Single-Variable Interventions in Additive Models", "abstract": "Estimating causal effects of joint interventions on multiple variables is\ncrucial in many domains, but obtaining data from such simultaneous\ninterventions can be challenging. Our study explores how to learn joint\ninterventional effects using only observational data and single-variable\ninterventions. We present an identifiability result for this problem, showing\nthat for a class of nonlinear additive outcome mechanisms, joint effects can be\ninferred without access to joint interventional data. We propose a practical\nestimator that decomposes the causal effect into confounded and unconfounded\ncontributions for each intervention variable. Experiments on synthetic data\ndemonstrate that our method achieves performance comparable to models trained\ndirectly on joint interventional data, outperforming a purely observational\nestimator.", "published": "2025-06-05 12:20:50", "link": "http://arxiv.org/abs/2506.04945v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Predicting ICU In-Hospital Mortality Using Adaptive Transformer Layer Fusion", "abstract": "Early identification of high-risk ICU patients is crucial for directing\nlimited medical resources. We introduce ALFIA (Adaptive Layer Fusion with\nIntelligent Attention), a modular, attention-based architecture that jointly\ntrains LoRA (Low-Rank Adaptation) adapters and an adaptive layer-weighting\nmechanism to fuse multi-layer semantic features from a BERT backbone. Trained\non our rigorous cw-24 (CriticalWindow-24) benchmark, ALFIA surpasses\nstate-of-the-art tabular classifiers in AUPRC while preserving a balanced\nprecision-recall profile. The embeddings produced by ALFIA's fusion module,\ncapturing both fine-grained clinical cues and high-level concepts, enable\nseamless pairing with GBDTs (CatBoost/LightGBM) as ALFIA-boost, and deep neuro\nnetworks as ALFIA-nn, yielding additional performance gains. Our experiments\nconfirm ALFIA's superior early-warning performance, by operating directly on\nroutine clinical text, it furnishes clinicians with a convenient yet robust\ntool for risk stratification and timely intervention in critical-care settings.", "published": "2025-06-05 11:59:20", "link": "http://arxiv.org/abs/2506.04924v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "TQml Simulator: Optimized Simulation of Quantum Machine Learning", "abstract": "Hardware-efficient circuits employed in Quantum Machine Learning are\ntypically composed of alternating layers of uniformly applied gates. High-speed\nnumerical simulators for such circuits are crucial for advancing research in\nthis field. In this work, we numerically benchmark universal and gate-specific\ntechniques for simulating the action of layers of gates on quantum state\nvectors, aiming to accelerate the overall simulation of Quantum Machine\nLearning algorithms. Our analysis shows that the optimal simulation method for\na given layer of gates depends on the number of qubits involved, and that a\ntailored combination of techniques can yield substantial performance gains in\nthe forward and backward passes for a given circuit. Building on these\ninsights, we developed a numerical simulator, named TQml Simulator, that\nemploys the most efficient simulation method for each layer in a given circuit.\nWe evaluated TQml Simulator on circuits constructed from standard gate sets,\nsuch as rotations and CNOTs, as well as on native gates from IonQ and IBM\nquantum processing units. In most cases, our simulator outperforms equivalent\nPennylane's default.qubit simulator by approximately 2- to 100-fold, depending\non the circuit, the number of qubits, the batch size of the input data, and the\nhardware used.", "published": "2025-06-05 11:19:05", "link": "http://arxiv.org/abs/2506.04891v1", "categories": ["quant-ph", "cs.ET", "cs.LG", "cs.PF"], "primary_category": "quant-ph"}
{"title": "Gaussian Process Diffeomorphic Statistical Shape Modelling Outperforms Angle-Based Methods for Assessment of Hip Dysplasia", "abstract": "Dysplasia is a recognised risk factor for osteoarthritis (OA) of the hip,\nearly diagnosis of dysplasia is important to provide opportunities for surgical\ninterventions aimed at reducing the risk of hip OA. We have developed a\npipeline for semi-automated classification of dysplasia using volumetric CT\nscans of patients' hips and a minimal set of clinically annotated landmarks,\ncombining the framework of the Gaussian Process Latent Variable Model with\ndiffeomorphism to create a statistical shape model, which we termed the\nGaussian Process Diffeomorphic Statistical Shape Model (GPDSSM). We used 192 CT\nscans, 100 for model training and 92 for testing. The GPDSSM effectively\ndistinguishes dysplastic samples from controls while also highlighting regions\nof the underlying surface that show dysplastic variations. As well as improving\nclassification accuracy compared to angle-based methods (AUC 96.2% vs 91.2%),\nthe GPDSSM can save time for clinicians by removing the need to manually\nmeasure angles and interpreting 2D scans for possible markers of dysplasia.", "published": "2025-06-05 11:08:12", "link": "http://arxiv.org/abs/2506.04886v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "kTULA: A Langevin sampling algorithm with improved KL bounds under super-linear log-gradients", "abstract": "Motivated by applications in deep learning, where the global Lipschitz\ncontinuity condition is often not satisfied, we examine the problem of sampling\nfrom distributions with super-linearly growing log-gradients. We propose a\nnovel tamed Langevin dynamics-based algorithm, called kTULA, to solve the\naforementioned sampling problem, and provide a theoretical guarantee for its\nperformance. More precisely, we establish a non-asymptotic convergence bound in\nKullback-Leibler (KL) divergence with the best-known rate of convergence equal\nto $2-\\overline{\\epsilon}$, $\\overline{\\epsilon}>0$, which significantly\nimproves relevant results in existing literature. This enables us to obtain an\nimproved non-asymptotic error bound in Wasserstein-2 distance, which can be\nused to further derive a non-asymptotic guarantee for kTULA to solve the\nassociated optimization problems. To illustrate the applicability of kTULA, we\napply the proposed algorithm to the problem of sampling from a high-dimensional\ndouble-well potential distribution and to an optimization problem involving a\nneural network. We show that our main results can be used to provide\ntheoretical guarantees for the performance of kTULA.", "published": "2025-06-05 10:51:18", "link": "http://arxiv.org/abs/2506.04878v1", "categories": ["math.ST", "cs.LG", "math.PR", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "There Was Never a Bottleneck in Concept Bottleneck Models", "abstract": "Deep learning representations are often difficult to interpret, which can\nhinder their deployment in sensitive applications. Concept Bottleneck Models\n(CBMs) have emerged as a promising approach to mitigate this issue by learning\nrepresentations that support target task performance while ensuring that each\ncomponent predicts a concrete concept from a predefined set. In this work, we\nargue that CBMs do not impose a true bottleneck: the fact that a component can\npredict a concept does not guarantee that it encodes only information about\nthat concept. This shortcoming raises concerns regarding interpretability and\nthe validity of intervention procedures. To overcome this limitation, we\npropose Minimal Concept Bottleneck Models (MCBMs), which incorporate an\nInformation Bottleneck (IB) objective to constrain each representation\ncomponent to retain only the information relevant to its corresponding concept.\nThis IB is implemented via a variational regularization term added to the\ntraining loss. As a result, MCBMs support concept-level interventions with\ntheoretical guarantees, remain consistent with Bayesian principles, and offer\ngreater flexibility in key design choices.", "published": "2025-06-05 10:50:42", "link": "http://arxiv.org/abs/2506.04877v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Aligning Multimodal Representations through an Information Bottleneck", "abstract": "Contrastive losses have been extensively used as a tool for multimodal\nrepresentation learning. However, it has been empirically observed that their\nuse is not effective to learn an aligned representation space. In this paper,\nwe argue that this phenomenon is caused by the presence of modality-specific\ninformation in the representation space. Although some of the most widely used\ncontrastive losses maximize the mutual information between representations of\nboth modalities, they are not designed to remove the modality-specific\ninformation. We give a theoretical description of this problem through the lens\nof the Information Bottleneck Principle. We also empirically analyze how\ndifferent hyperparameters affect the emergence of this phenomenon in a\ncontrolled experimental setup. Finally, we propose a regularization term in the\nloss function that is derived by means of a variational approximation and aims\nto increase the representational alignment. We analyze in a set of controlled\nexperiments and real-world applications the advantages of including this\nregularization term.", "published": "2025-06-05 10:47:14", "link": "http://arxiv.org/abs/2506.04870v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improving AI-generated music with user-guided training", "abstract": "AI music generation has advanced rapidly, with models like diffusion and\nautoregressive algorithms enabling high-fidelity outputs. These tools can alter\nstyles, mix instruments, or isolate them. Since sound can be visualized as\nspectrograms, image-generation algorithms can be applied to generate novel\nmusic. However, these algorithms are typically trained on fixed datasets, which\nmakes it challenging for them to interpret and respond to user input\naccurately. This is especially problematic because music is highly subjective\nand requires a level of personalization that image generation does not provide.\nIn this work, we propose a human-computation approach to gradually improve the\nperformance of these algorithms based on user interactions. The\nhuman-computation element involves aggregating and selecting user ratings to\nuse as the loss function for fine-tuning the model. We employ a genetic\nalgorithm that incorporates user feedback to enhance the baseline performance\nof a model initially trained on a fixed dataset. The effectiveness of this\napproach is measured by the average increase in user ratings with each\niteration. In the pilot test, the first iteration showed an average rating\nincrease of 0.2 compared to the baseline. The second iteration further improved\nupon this, achieving an additional increase of 0.39 over the first iteration.", "published": "2025-06-05 10:22:54", "link": "http://arxiv.org/abs/2506.04852v1", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LogicPuzzleRL: Cultivating Robust Mathematical Reasoning in LLMs via Reinforcement Learning", "abstract": "Large language models (LLMs) excel at many supervised tasks but often\nstruggle with structured reasoning in unfamiliar settings. This discrepancy\nsuggests that standard fine-tuning pipelines may instill narrow,\ndomain-specific heuristics rather than fostering general-purpose thinking\nstrategies. In this work, we propose a \"play to learn\" framework that\nfine-tunes LLMs through reinforcement learning on a suite of seven custom logic\npuzzles, each designed to cultivate distinct reasoning skills such as\nconstraint propagation, spatial consistency, and symbolic deduction. Using a\nreinforcement learning setup with verifiable rewards, models receive binary\nfeedback based on puzzle correctness, encouraging iterative, hypothesis-driven\nproblem solving. We demonstrate that this training approach significantly\nimproves out-of-distribution performance on a range of mathematical benchmarks,\nespecially for mid-difficulty problems that require multi-step reasoning.\nAnalyses across problem categories and difficulty levels reveal that puzzle\ntraining promotes transferable reasoning routines, strengthening algebraic\nmanipulation, geometric inference, and combinatorial logic, while offering\nlimited gains on rote or highly specialized tasks. These findings show that\nreinforcement learning over logic puzzles reshapes the internal reasoning of\nLLMs, enabling more robust and compositional generalization without relying on\ntask-specific symbolic tools.", "published": "2025-06-05 09:40:47", "link": "http://arxiv.org/abs/2506.04821v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Distributional encoding for Gaussian process regression with qualitative inputs", "abstract": "Gaussian Process (GP) regression is a popular and sample-efficient approach\nfor many engineering applications, where observations are expensive to acquire,\nand is also a central ingredient of Bayesian optimization (BO), a highly\nprevailing method for the optimization of black-box functions. However, when\nall or some input variables are categorical, building a predictive and\ncomputationally efficient GP remains challenging. Starting from the naive\ntarget encoding idea, where the original categorical values are replaced with\nthe mean of the target variable for that category, we propose a generalization\nbased on distributional encoding (DE) which makes use of all samples of the\ntarget variable for a category. To handle this type of encoding inside the GP,\nwe build upon recent results on characteristic kernels for probability\ndistributions, based on the maximum mean discrepancy and the Wasserstein\ndistance. We also discuss several extensions for classification, multi-task\nlearning and incorporation or auxiliary information. Our approach is validated\nempirically, and we demonstrate state-of-the-art predictive performance on a\nvariety of synthetic and real-world datasets. DE is naturally complementary to\nrecent advances in BO over discrete and mixed-spaces.", "published": "2025-06-05 09:35:02", "link": "http://arxiv.org/abs/2506.04813v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Adaptive Preconditioners Trigger Loss Spikes in Adam", "abstract": "Loss spikes emerge commonly during training across neural networks of varying\narchitectures and scales when using the Adam optimizer. In this work, we\ninvestigate the underlying mechanism responsible for Adam spikes. While\nprevious explanations attribute these phenomena to the lower-loss-as-sharper\ncharacteristics of the loss landscape, our analysis reveals that Adam's\nadaptive preconditioners themselves can trigger spikes. Specifically, we\nidentify a critical regime where squared gradients become substantially smaller\nthan the second-order moment estimates, causing the latter to undergo a\n$\\beta_2$-exponential decay and to respond sluggishly to current gradient\ninformation. This mechanism can push the maximum eigenvalue of the\npreconditioned Hessian beyond the classical stability threshold $2/\\eta$ for a\nsustained period, inducing instability. This instability further leads to an\nalignment between the gradient and the maximum eigendirection, and a loss spike\noccurs precisely when the gradient-directional curvature exceeds $2/\\eta$. We\nverify this mechanism through extensive experiments on fully connected\nnetworks, convolutional networks, and Transformer architectures.", "published": "2025-06-05 09:31:41", "link": "http://arxiv.org/abs/2506.04805v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Kernel $k$-Medoids as General Vector Quantization", "abstract": "Vector Quantization (VQ) is a widely used technique in machine learning and\ndata compression, valued for its simplicity and interpretability. Among hard VQ\nmethods, $k$-medoids clustering and Kernel Density Estimation (KDE) approaches\nrepresent two prominent yet seemingly unrelated paradigms -- one\ndistance-based, the other rooted in probability density matching. In this\npaper, we investigate their connection through the lens of Quadratic\nUnconstrained Binary Optimization (QUBO). We compare a heuristic QUBO\nformulation for $k$-medoids, which balances centrality and diversity, with a\nprincipled QUBO derived from minimizing Maximum Mean Discrepancy in KDE-based\nVQ. Surprisingly, we show that the KDE-QUBO is a special case of the\n$k$-medoids-QUBO under mild assumptions on the kernel's feature map. This\nreveals a deeper structural relationship between these two approaches and\nprovides new insight into the geometric interpretation of the weighting\nparameters used in QUBO formulations for VQ.", "published": "2025-06-05 09:14:25", "link": "http://arxiv.org/abs/2506.04786v1", "categories": ["cs.LG", "quant-ph"], "primary_category": "cs.LG"}
{"title": "OpenGT: A Comprehensive Benchmark For Graph Transformers", "abstract": "Graph Transformers (GTs) have recently demonstrated remarkable performance\nacross diverse domains. By leveraging attention mechanisms, GTs are capable of\nmodeling long-range dependencies and complex structural relationships beyond\nlocal neighborhoods. However, their applicable scenarios are still\nunderexplored, this highlights the need to identify when and why they excel.\nFurthermore, unlike GNNs, which predominantly rely on message-passing\nmechanisms, GTs exhibit a diverse design space in areas such as positional\nencoding, attention mechanisms, and graph-specific adaptations. Yet, it remains\nunclear which of these design choices are truly effective and under what\nconditions. As a result, the community currently lacks a comprehensive\nbenchmark and library to promote a deeper understanding and further development\nof GTs. To address this gap, this paper introduces OpenGT, a comprehensive\nbenchmark for Graph Transformers. OpenGT enables fair comparisons and\nmultidimensional analysis by establishing standardized experimental settings\nand incorporating a broad selection of state-of-the-art GNNs and GTs. Our\nbenchmark evaluates GTs from multiple perspectives, encompassing diverse tasks\nand datasets with varying properties. Through extensive experiments, our\nbenchmark has uncovered several critical insights, including the difficulty of\ntransferring models across task levels, the limitations of local attention, the\nefficiency trade-offs in several models, the application scenarios of specific\npositional encodings, and the preprocessing overhead of some positional\nencodings. We aspire for this work to establish a foundation for future graph\ntransformer research emphasizing fairness, reproducibility, and\ngeneralizability. We have developed an easy-to-use library OpenGT for training\nand evaluating existing GTs. The benchmark code is available at\nhttps://github.com/eaglelab-zju/OpenGT.", "published": "2025-06-05 08:48:46", "link": "http://arxiv.org/abs/2506.04765v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Log-Linear Attention", "abstract": "The attention mechanism in Transformers is an important primitive for\naccurate and scalable sequence modeling. Its quadratic-compute and\nlinear-memory complexity however remain significant bottlenecks. Linear\nattention and state-space models enable linear-time, constant-memory sequence\nmodeling and can moreover be trained efficiently through matmul-rich\nparallelization across sequence length. However, at their core these models are\nstill RNNs, and thus their use of a fixed-size hidden state to model the\ncontext is a fundamental limitation. This paper develops log-linear attention,\nan attention mechanism that balances linear attention's efficiency and the\nexpressiveness of softmax attention. Log-linear attention replaces the\nfixed-size hidden state with a logarithmically growing set of hidden states. We\nshow that with a particular growth function, log-linear attention admits a\nsimilarly matmul-rich parallel form whose compute cost is log-linear in\nsequence length. Log-linear attention is a general framework and can be applied\non top of existing linear attention variants. As case studies, we instantiate\nlog-linear variants of two recent architectures -- Mamba-2 and Gated DeltaNet\n-- and find they perform well compared to their linear-time variants.", "published": "2025-06-05 08:44:51", "link": "http://arxiv.org/abs/2506.04761v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-Layer GRPO: Enhancing Reasoning and Self-Correction in Large Language Models", "abstract": "The Group Relative Policy Optimization (GRPO) algorithm has demonstrated\nconsiderable success in enhancing the reasoning capabilities of large language\nmodels (LLMs), as evidenced by DeepSeek-R1. However, the absence of\nintermediate supervision in GRPO frequently leads to inefficient exploration\ndynamics. A single error in a complex reasoning chain can invalidate the entire\nsolution, resulting in abrupt reward vanishing and compromising training\nstability.To address these challenges, we propose MGRPO (Multi-layer GRPO).\nMGRPO operates in two layers: the first layer employs standard GRPO to generate\nan initial response. This response, along with the original query, is then fed\ninto a second-layer GRPO process. This second layer is specifically trained to\nidentify and correct errors in the initial response, effectively creating a\nself-correction loop. This mechanism provides implicit process-level\nsupervision by rewarding successful error correction, without requiring an\nexplicit, densely-annotated reward model. Experimental results on several\nmathematical reasoning benchmarks demonstrate that MGRPO significantly\noutperforms standard GRPO, achieving superior performance by fostering both\nreasoning and self-correction abilities.", "published": "2025-06-05 08:27:34", "link": "http://arxiv.org/abs/2506.04746v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Enhanced Drought Analysis in Bangladesh: A Machine Learning Approach for Severity Classification Using Satellite Data", "abstract": "Drought poses a pervasive environmental challenge in Bangladesh, impacting\nagriculture, socio-economic stability, and food security due to its unique\ngeographic and anthropogenic vulnerabilities. Traditional drought indices, such\nas the Standardized Precipitation Index (SPI) and Palmer Drought Severity Index\n(PDSI), often overlook crucial factors like soil moisture and temperature,\nlimiting their resolution. Moreover, current machine learning models applied to\ndrought prediction have been underexplored in the context of Bangladesh,\nlacking a comprehensive integration of satellite data across multiple\ndistricts. To address these gaps, we propose a satellite data-driven machine\nlearning framework to classify drought across 38 districts of Bangladesh. Using\nunsupervised algorithms like K-means and Bayesian Gaussian Mixture for\nclustering, followed by classification models such as KNN, Random Forest,\nDecision Tree, and Naive Bayes, the framework integrates weather data\n(humidity, soil moisture, temperature) from 2012-2024. This approach\nsuccessfully classifies drought severity into different levels. However, it\nshows significant variabilities in drought vulnerabilities across regions which\nhighlights the aptitude of machine learning models in terms of identifying and\npredicting drought conditions.", "published": "2025-06-05 07:17:43", "link": "http://arxiv.org/abs/2506.04696v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Towards Language-Augmented Multi-Agent Deep Reinforcement Learning", "abstract": "Communication is a fundamental aspect of coordinated behavior in multi-agent\nreinforcement learning. Yet, most prior works in this field have focused on\nemergent communication protocols developed from scratch, often resulting in\ninefficient or non-interpretable systems. Inspired by the role of language in\nnatural intelligence, we investigate how grounding agents in a human-defined\nlanguage can improve learning and coordination of multiple embodied agents. We\npropose a framework in which agents are trained not only to act but also to\nproduce and interpret natural language descriptions of their observations. This\nlanguage-augmented learning serves a dual role: enabling explicit communication\nbetween agents and guiding representation learning. We demonstrate that agents\ntrained with our method outperform traditional emergent communication baselines\nacross various tasks. Our analysis reveals that language grounding leads to\nmore informative internal representations, better generalization to new\npartners, and improved capability for human-agent interaction. These findings\ndemonstrate the effectiveness of integrating structured language into\nmulti-agent learning and open avenues for more interpretable and capable\nmulti-agent systems.", "published": "2025-06-05 16:55:52", "link": "http://arxiv.org/abs/2506.05236v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Memory-Driven Bounded Confidence Opinion Dynamics: A Hegselmann-Krause Model Based on Fractional-Order Methods", "abstract": "Memory effects play a crucial role in social interactions and decision-making\nprocesses. This paper proposes a novel fractional-order bounded confidence\nopinion dynamics model to characterize the memory effects in system states.\nBuilding upon the Hegselmann-Krause framework and fractional-order difference,\na comprehensive model is established that captures the persistent influence of\nhistorical information. Through rigorous theoretical analysis, the fundamental\nproperties including convergence and consensus is investigated. The results\ndemonstrate that the proposed model not only maintains favorable convergence\nand consensus characteristics compared to classical opinion dynamics, but also\naddresses limitations such as the monotonicity of bounded opinions. This\nenables a more realistic representation of opinion evolution in real-world\nscenarios. The findings of this study provide new insights and methodological\napproaches for understanding opinion formation and evolution, offering both\ntheoretical significance and practical applications.", "published": "2025-06-05 07:23:06", "link": "http://arxiv.org/abs/2506.04701v1", "categories": ["physics.soc-ph", "cs.MA", "cs.SI", "nlin.AO"], "primary_category": "physics.soc-ph"}
{"title": "From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems", "abstract": "Compound Al Systems (CAIS) is an emerging paradigm that integrates large\nlanguage models (LLMs) with external components, such as retrievers, agents,\ntools, and orchestrators, to overcome the limitations of standalone models in\ntasks requiring memory, reasoning, real-time grounding, and multimodal\nunderstanding. These systems enable more capable and context-aware behaviors by\ncomposing multiple specialized modules into cohesive workflows. Despite growing\nadoption in both academia and industry, the CAIS landscape remains fragmented,\nlacking a unified framework for analysis, taxonomy, and evaluation. In this\nsurvey, we define the concept of CAIS, propose a multi-dimensional taxonomy\nbased on component roles and orchestration strategies, and analyze four\nfoundational paradigms: Retrieval-Augmented Generation (RAG), LLM Agents,\nMultimodal LLMs (MLLMs), and orchestration-centric architectures. We review\nrepresentative systems, compare design trade-offs, and summarize evaluation\nmethodologies across these paradigms. Finally, we identify key\nchallenges-including scalability, interoperability, benchmarking, and\ncoordination-and outline promising directions for future research. This survey\naims to provide researchers and practitioners with a comprehensive foundation\nfor understanding, developing, and advancing the next generation of\nsystem-level artificial intelligence.", "published": "2025-06-05 02:34:43", "link": "http://arxiv.org/abs/2506.04565v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Probability of Collision with Tethered Spacecraft", "abstract": "This Engineering Note addresses the challenge of estimating the probability\nof collision for tethered spacecraft during close encounters with other space\nobjects. Standard probability of collision methods, based on spherical\nhard-body assumptions, tend to be overly conservative when applied to long\ntether systems. We introduce a method that accounts for the tether's spatial\nextent and configuration uncertainty by maximizing the probability of collision\nover all physically admissible tether shapes. Applied to real-world conjunction\nevents involving a kilometer-scale flexible inextensible tether, the method\nyields more realistic risk estimates. This approach improves the ability to\ndistinguish hazardous from benign encounters, thereby supporting more informed\ncollision avoidance decisions.", "published": "2025-06-05 12:43:05", "link": "http://arxiv.org/abs/2506.04969v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Numerical analysis for constrained and unconstrained Q-tensor energies for liquid crystals", "abstract": "This paper introduces a comprehensive finite element approximation framework\nfor three-dimensional Landau-de Gennes $Q$-tensor energies for nematic liquid\ncrystals, with a particular focus on the anisotropy of the elastic energy and\nthe Ball-Majumdar singular potential. This potential imposes essential physical\nconstraints on the eigenvalues of the $Q$-tensor, ensuring realistic modeling.\nWe address the approximation of regular solutions to nonlinear elliptic partial\ndifferential equations with non-homogeneous boundary conditions associated with\nLandau-de Gennes energies. The well-posedness of the discrete linearized\nproblem is rigorously demonstrated. The existence and local uniqueness of the\ndiscrete solution is derived using the Newton-Kantorovich theorem. Furthermore,\nwe demonstrate an optimal order convergence rate in the energy norm and discuss\nthe impact of eigenvalue constraints on the a priori error analysis.", "published": "2025-06-05 10:52:22", "link": "http://arxiv.org/abs/2506.04880v1", "categories": ["math.NA", "cs.NA", "65N12, 35J47, 65N30, 76A15"], "primary_category": "math.NA"}
{"title": "Active flux for ideal magnetohydrodynamics: A positivity-preserving scheme with the Godunov-Powell source term", "abstract": "The Active Flux (AF) is a compact, high-order finite volume scheme that\nallows more flexibility by introducing additional point value degrees of\nfreedom at cell interfaces. This paper proposes a positivity-preserving (PP) AF\nscheme for solving the ideal magnetohydrodynamics, where the Godunov-Powell\nsource term is employed to deal with the divergence-free constraint. For the\nevolution of the cell average, apart from the standard conservative finite\nvolume method for the flux derivative, the nonconservative source term is built\non the quadratic reconstruction in each cell, which maintains the compact\nstencil in the AF scheme. For the point value update, the local Lax-Friedrichs\n(LLF) flux vector splitting is adopted for the flux derivative, originally\nproposed in [Duan, Barsukow, and Klingenberg, SIAM Journal on Scientific\nComputing, 47(2), A811--A837, 2025], and a central difference is used to\ndiscretize the divergence in the source term. A parametrized flux limiter and a\nscaling limiter are presented to preserve the density and pressure positivity\nby blending the AF scheme with the first-order PP LLF scheme with the source\nterm. To suppress oscillations, a new shock sensor considering the divergence\nerror is proposed, which is used to compute the blending coefficients for the\ncell average. Several numerical tests are conducted to verify the third-order\naccuracy, PP property, and shock-capturing ability of the scheme. The key role\nof the Godunov-Powell source term and its suitable discretization in\ncontrolling divergence error is also validated.", "published": "2025-06-05 10:24:52", "link": "http://arxiv.org/abs/2506.04857v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Efficient randomized algorithms for the fixed Tucker-rank problem of Tucker decomposition with adaptive shifts", "abstract": "Randomized numerical linear algebra is proved to bridge theoretical\nadvancements to offer scalable solutions for approximating tensor\ndecomposition. This paper introduces fast randomized algorithms for solving the\nfixed Tucker-rank problem of Tucker decomposition, through the integration of\nadaptive shifted power iterations. The proposed algorithms enhance randomized\nvariants of truncated high-order singular value decomposition (T-HOSVD) and\nsequentially T-HOSVD (ST-HOSVD) by incorporating dynamic shift strategies,\nwhich accelerate convergence by refining the singular value gap and reduce the\nnumber of required power iterations while maintaining accuracy. Theoretical\nanalyses provide probabilistic error bounds, demonstrating that the proposed\nmethods achieve comparable or superior accuracy compared to deterministic\napproaches. Numerical experiments on synthetic and real-world datasets validate\nthe efficiency and robustness of the proposed algorithms, showing a significant\ndecline in runtime and approximation error over state-of-the-art techniques.", "published": "2025-06-05 10:02:26", "link": "http://arxiv.org/abs/2506.04840v1", "categories": ["math.NA", "cs.NA", "65F55, 68W20, 15A18, 15A69"], "primary_category": "math.NA"}
{"title": "Numerical solution of the wave equation outside a sphere", "abstract": "A method is presented for the fast evaluation of the transient acoustic field\ngenerated outside a spherical surface by sources inside the surface. The method\nemploys Lebedev quadratures, which are the optimal method for spatial\nintegration, and Lagrange interpolation and differentiation in an advanced time\nalgorithm for the evaluation of the transient field. Numerical testing\ndemonstrates that the approach gives near machine-precision accuracy and a\nspeed-up in evaluation time which depends on the order of quadrature rule\nemployed but breaks even with direct evaluation at a number of field points\nabout 1.15 times the number of surface quadrature nodes.", "published": "2025-06-05 09:33:18", "link": "http://arxiv.org/abs/2506.04809v1", "categories": ["math.NA", "cs.NA", "math.AP", "physics.class-ph", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "Tensor-based multivariate function approximation: methods benchmarking and comparison", "abstract": "In this note, we evaluate the performances, the features and the\nuser-experience of some methods (and their implementations) designed for\ntensor- (or data-) based multivariate function construction and approximation.\nTo this aim, a collection of multivariate functions extracted from contributive\nworks coming from different communities, is suggested. First, these functions\nwith varying complexity (e.g. number and degree of the variables) and nature\n(e.g. rational, irrational, differentiable or not, symmetric, etc.) are used to\nconstruct tensors, each of different dimension and size on the disk. Second,\ngrounded on this tensor, we inspect performances of each considered method\n(e.g. the accuracy, the computational time, the parameters tuning impact,\netc.). Finally, considering the \"best\" parameter tuning set, we compare each\nmethod using multiple evaluation criteria. The purpose of this note is not to\nrank the methods but rather to evaluate as fairly as possible the different\navailable strategies, with the idea in mind to guide users to understand the\nprocess, the possibilities, the advantages and the limits brought by each\ntools. The contribution claimed is to suggest a complete benchmark collection\nof some available tools for tensor approximation by surrogate models (e.g.\nrational functions, networks, etc.). In addition, as contributors of the\nmultivariate Loewner Framework (mLF) approach (and its side implementation in\nMDSPACK), attention and details of the latter are more explicitly given, in\norder to provide readers a digest of this contributive work and some details\nwith simple examples.", "published": "2025-06-05 09:17:55", "link": "http://arxiv.org/abs/2506.04791v1", "categories": ["math.NA", "cs.CE", "cs.NA", "cs.SE", "93A15, 93A30, 93B11, 93B15, 93C05, 93C80"], "primary_category": "math.NA"}
{"title": "A Fast, Accurate and Oscillation-free Spectral Collocation Solver for High-dimensional Transport Problems", "abstract": "Transport phenomena-describing the movement of particles, energy, or other\nphysical quantities-are fundamental in various scientific disciplines,\nincluding nuclear physics, plasma physics, astrophysics, engineering, and the\nnatural sciences.\n  However, solving the associated seven-dimensional transport equations poses a\nsignificant computational challenge due to the curse of dimensionality.\n  We introduce the Tensor Train Superconsistent Spectral (T${^2}$S${^2}$)\nsolver to address this challenge, integrating Spectral Collocation for\nexponential convergence, Superconsistency for stabilization in\ntransport-dominated regimes, and Tensor Train format for substantial data\ncompression. T${^2}$S${^2}$ enforces a dimension-wise superconsistent condition\ncompatible with tensor structures, achieving extremely low compression ratios,\nin the order of $(10^{-12})$, while preserving spectral accuracy. Numerical\nexperiments on linear problems demonstrate that T${^2}$S${^2}$ can solve\nhigh-dimensional transport problems in minutes on standard hardware, making\npreviously intractable problems computationally feasible. This advancement\nopens new avenues for efficiently and accurately modeling complex transport\nphenomena.", "published": "2025-06-05 08:07:07", "link": "http://arxiv.org/abs/2506.04732v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An Array Decomposition Method for Finite Arrays with Electrically Connected Elements for fast Toeplitz Solvers", "abstract": "A large part of the geometry of array antennas is often partially defined by\nfinite translational symmetries. Applying the method of moments (MoM) with the\nRWG-like element on an appropriately structured mesh to these arrays results in\nan impedance matrix where the main part exhibits a multilevel block Toeplitz\nstructure. This article introduces a memory-efficient construction method that\neffectively represents and reuses impedance calculations. The proposed method,\napplicable to electrically connected elements, also accounts for all\nnon-symmetric parts of the array. The core idea involves nine distinct\nelectrically connectable components from which the array can be assembled. The\nderived multilevel block Toeplitz matrix is further utilized by an in-house\ninverse solver to achieve faster and more memory-efficient MoM current vector\ncalculations. We demonstrate the method by computing the far-field of a 32x32\narray and the scattering parameters of two tightly coupled 9x9 arrays. This\napproach reduces the memory allocation from $\\mathcal{O}(N_x^2 N_y^2)$ to\n$\\mathcal{O}(N_x N_y)$, for an $N_x \\times N_y$ array.", "published": "2025-06-05 07:34:17", "link": "http://arxiv.org/abs/2506.04710v1", "categories": ["math.NA", "cs.NA", "eess.SP"], "primary_category": "math.NA"}
{"title": "Inverse elastic obstacle scattering problems by monotonicity method", "abstract": "We consider the elastic wave scattering problem involving rigid obstacles.\nThis work addresses the inverse problem of reconstructing the position and\nshape of such obstacles using far-field measurements. A novel\nmonotonicity-based approach is developed for this purpose. By factorizing the\nfar-field operator and utilizing the existence of localized wave functions, we\nderive a shape characterization criterion for the obstacle boundary. The\nproposed method employs monotonicity tests to determine the geometric\nrelationship between any given test domain and the actual scatterer. As a\nresult, the shape and location of rigid elastic obstacles can be uniquely\nidentified without requiring any initial guesses or prior knowledge of the\nphysical parameters of the homogeneous background medium.", "published": "2025-06-05 05:50:22", "link": "http://arxiv.org/abs/2506.04655v1", "categories": ["math.AP", "cs.NA", "math.NA"], "primary_category": "math.AP"}
{"title": "Can Artificial Intelligence Trade the Stock Market?", "abstract": "The paper explores the use of Deep Reinforcement Learning (DRL) in stock\nmarket trading, focusing on two algorithms: Double Deep Q-Network (DDQN) and\nProximal Policy Optimization (PPO) and compares them with Buy and Hold\nbenchmark. It evaluates these algorithms across three currency pairs, the S&P\n500 index and Bitcoin, on the daily data in the period of 2019-2023. The\nresults demonstrate DRL's effectiveness in trading and its ability to manage\nrisk by strategically avoiding trades in unfavorable conditions, providing a\nsubstantial edge over classical approaches, based on supervised learning in\nterms of risk-adjusted returns.", "published": "2025-06-05 05:59:10", "link": "http://arxiv.org/abs/2506.04658v1", "categories": ["q-fin.TR", "cs.LG", "q-fin.CP"], "primary_category": "q-fin.TR"}
{"title": "Unregularized limit of stochastic gradient method for Wasserstein distributionally robust optimization", "abstract": "Distributionally robust optimization offers a compelling framework for model\nfitting in machine learning, as it systematically accounts for data\nuncertainty. Focusing on Wasserstein distributionally robust optimization, we\ninvestigate the regularized problem where entropic smoothing yields a\nsampling-based approximation of the original objective. We establish the\nconvergence of the approximate gradient over a compact set, leading to the\nconcentration of the regularized problem critical points onto the original\nproblem critical set as regularization diminishes and the number of\napproximation samples increases. Finally, we deduce convergence guarantees for\na projected stochastic gradient method. Our analysis covers a general machine\nlearning situation with an unbounded sample space and mixed continuous-discrete\ndata.", "published": "2025-06-05 12:21:44", "link": "http://arxiv.org/abs/2506.04948v1", "categories": ["math.OC", "stat.ML"], "primary_category": "math.OC"}
{"title": "Amortized variational transdimensional inference", "abstract": "The expressiveness of flow-based models combined with stochastic variational\ninference (SVI) has, in recent years, expanded the application of\noptimization-based Bayesian inference to include problems with complex data\nrelationships. However, until now, SVI using flow-based models has been limited\nto problems of fixed dimension. We introduce CoSMIC, normalizing flows\n(COntextually-Specified Masking for Identity-mapped Components), an extension\nto neural autoregressive conditional normalizing flow architectures that\nenables using a single amortized variational density for inference over a\ntransdimensional target distribution. We propose a combined stochastic\nvariational transdimensional inference (VTI) approach to training CoSMIC flows\nusing techniques from Bayesian optimization and Monte Carlo gradient\nestimation. Numerical experiments demonstrate the performance of VTI on\nchallenging problems that scale to high-cardinality model spaces.", "published": "2025-06-05 08:33:07", "link": "http://arxiv.org/abs/2506.04749v1", "categories": ["stat.CO", "stat.ME", "stat.ML"], "primary_category": "stat.CO"}
{"title": "Regret-Optimal Q-Learning with Low Cost for Single-Agent and Federated Reinforcement Learning", "abstract": "Motivated by real-world settings where data collection and policy deployment\n-- whether for a single agent or across multiple agents -- are costly, we study\nthe problem of on-policy single-agent reinforcement learning (RL) and federated\nRL (FRL) with a focus on minimizing burn-in costs (the sample sizes needed to\nreach near-optimal regret) and policy switching or communication costs. In\nparallel finite-horizon episodic Markov Decision Processes (MDPs) with $S$\nstates and $A$ actions, existing methods either require superlinear burn-in\ncosts in $S$ and $A$ or fail to achieve logarithmic switching or communication\ncosts. We propose two novel model-free RL algorithms -- Q-EarlySettled-LowCost\nand FedQ-EarlySettled-LowCost -- that are the first in the literature to\nsimultaneously achieve: (i) the best near-optimal regret among all known\nmodel-free RL or FRL algorithms, (ii) low burn-in cost that scales linearly\nwith $S$ and $A$, and (iii) logarithmic policy switching cost for single-agent\nRL or communication cost for FRL. Additionally, we establish gap-dependent\ntheoretical guarantees for both regret and switching/communication costs,\nimproving or matching the best-known gap-dependent bounds.", "published": "2025-06-05 04:36:38", "link": "http://arxiv.org/abs/2506.04626v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Unsupervised Machine Learning for Scientific Discovery: Workflow and Best Practices", "abstract": "Unsupervised machine learning is widely used to mine large, unlabeled\ndatasets to make data-driven discoveries in critical domains such as climate\nscience, biomedicine, astronomy, chemistry, and more. However, despite its\nwidespread utilization, there is a lack of standardization in unsupervised\nlearning workflows for making reliable and reproducible scientific discoveries.\nIn this paper, we present a structured workflow for using unsupervised learning\ntechniques in science. We highlight and discuss best practices starting with\nformulating validatable scientific questions, conducting robust data\npreparation and exploration, using a range of modeling techniques, performing\nrigorous validation by evaluating the stability and generalizability of\nunsupervised learning conclusions, and promoting effective communication and\ndocumentation of results to ensure reproducible scientific discoveries. To\nillustrate our proposed workflow, we present a case study from astronomy,\nseeking to refine globular clusters of Milky Way stars based upon their\nchemical composition. Our case study highlights the importance of validation\nand illustrates how the benefits of a carefully-designed workflow for\nunsupervised learning can advance scientific discovery.", "published": "2025-06-05 01:58:45", "link": "http://arxiv.org/abs/2506.04553v1", "categories": ["cs.LG", "stat.AP", "stat.CO", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multivariate Probabilistic Assessment of Speech Quality", "abstract": "The mean opinion score (MOS) is a standard metric for assessing speech\nquality, but its singular focus fails to identify specific distortions when low\nscores are observed. The NISQA dataset addresses this limitation by providing\nratings across four additional dimensions: noisiness, coloration,\ndiscontinuity, and loudness, alongside MOS. In this paper, we extend the\nexplored univariate MOS estimation to a multivariate framework by modeling\nthese dimensions jointly using a multivariate Gaussian distribution. Our\napproach utilizes Cholesky decomposition to predict covariances without\nimposing restrictive assumptions and extends probabilistic affine\ntransformations to a multivariate context. Experimental results show that our\nmodel performs on par with state-of-the-art methods in point estimation, while\nuniquely providing uncertainty and correlation estimates across speech quality\ndimensions. This enables better diagnosis of poor speech quality and informs\ntargeted improvements.", "published": "2025-06-05 11:17:02", "link": "http://arxiv.org/abs/2506.04890v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Grapheme-Coherent Phonemic and Prosodic Annotation of Speech by Implicit and Explicit Grapheme Conditioning", "abstract": "We propose a model to obtain phonemic and prosodic labels of speech that are\ncoherent with graphemes. Unlike previous methods that simply fine-tune a\npre-trained ASR model with the labels, the proposed model conditions the label\ngeneration on corresponding graphemes by two methods: 1) Add implicit grapheme\nconditioning through prompt encoder using pre-trained BERT features. 2)\nExplicitly prune the label hypotheses inconsistent with the grapheme during\ninference. These methods enable obtaining parallel data of speech, the labels,\nand graphemes, which is applicable to various downstream tasks such as\ntext-to-speech and accent estimation from text. Experiments showed that the\nproposed method significantly improved the consistency between graphemes and\nthe predicted labels. Further, experiments on accent estimation task confirmed\nthat the created parallel data by the proposed method effectively improve the\nestimation accuracy.", "published": "2025-06-05 00:24:00", "link": "http://arxiv.org/abs/2506.04527v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Joint Beamforming and Integer User Association using a GNN with Gumbel-Softmax Reparameterizations", "abstract": "Machine learning (ML) models can effectively optimize a multi-cell wireless\nnetwork by designing the beamforming vectors and association decisions.\nExisting ML designs, however, often needs to approximate the integer\nassociation variables with a probability distribution output. We propose a\nnovel graph neural network (GNN) structure that jointly optimize beamforming\nvectors and user association while guaranteeing association output as integers.\nThe integer association constraints are satisfied using the Gumbel-Softmax (GS)\nreparameterization, without increasing computational complexity. Simulation\nresults demonstrate that our proposed GS-based GNN consistently achieves\ninteger association decisions and yields a higher sum-rate, especially when\ngeneralized to larger networks, compared to all other fractional association\nmethods.", "published": "2025-06-05 17:01:27", "link": "http://arxiv.org/abs/2506.05241v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Noise-Driven AI Sensors: Secure Healthcare Monitoring with PUFs", "abstract": "Wearable and implantable healthcare sensors are pivotal for real-time patient\nmonitoring but face critical challenges in power efficiency, data security, and\nsignal noise. This paper introduces a novel platform that leverages hardware\nnoise as a dual-purpose resource to enhance machine learning (ML) robustness\nand secure data via Physical Unclonable Functions (PUFs). By integrating\nnoise-driven signal processing, PUFbased authentication, and ML-based anomaly\ndetection, our system achieves secure, low-power monitoring for devices like\nECG wearables. Simulations demonstrate that noise improves ML accuracy by 8%\n(92% for detecting premature ventricular contractions (PVCs) and atrial\nfibrillation (AF)), while PUFs provide 98% uniqueness for tamper-resistant\nsecurity, all within a 50 uW power budget. This unified approach not only\naddresses power, security, and noise challenges but also enables scalable,\nintelligent sensing for telemedicine and IoT applications.", "published": "2025-06-05 15:20:39", "link": "http://arxiv.org/abs/2506.05135v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "An SCMA Receiver for 6G NTN based on Multi-Task Learning", "abstract": "Future 6G networks are envisioned to enhance the user experience in a\nmultitude of different ways. The unification of existing terrestrial networks\nwith non-terrestrial network (NTN) components will provide users with\nubiquitous connectivity. Multi-access edge computing (MEC) will enable\nlow-latency services, with computations performed closer to the end users, and\ndistributed learning paradigms. Advanced multiple access schemes, such as\nsparse code multiple access (SCMA), can be employed to efficiently move data\nfrom edge nodes to spaceborne MEC servers. However, the non-orthogonal nature\nof SCMA results in interference, limiting the effectiveness of traditional SCMA\nreceivers. Hence, NTN links should be protected with robust channel codes,\nsignificantly reducing the uplink throughput. Thus, we investigate the\napplication of artificial intelligence (AI) to SCMA receivers for 6G NTNs. We\ntrain an AI model with multi-task learning to optimally separate and receive\nsuperimposed SCMA signals. Through link level simulations, we evaluate the\nblock error rate (BLER) and the aggregated theoretical throughput achieved by\nthe AI model as a function of the received energy per bit over noise power\nspectral density ratio (Eb/N0). We show that the proposed receiver achieves a\ntarget 10% BLER with 3.5dB lower Eb/N0 with respect to the benchmark algorithm.\nWe conclude the assessment discussing the complexity-related challenges to the\nimplementation of the AI model on board of a low earth orbit satellite.", "published": "2025-06-05 14:55:58", "link": "http://arxiv.org/abs/2506.05111v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching Antenna Systems versus Reconfigurable Intelligent Surfaces in mmWave", "abstract": "Flexible and intelligent antenna designs, such as pinching antenna systems\nand reconfigurable intelligent surfaces (RIS), have gained extensive research\nattention due to their potential to enhance the wireless channels. This letter,\nfor the first time, presents a comparative study between the emerging pinching\nantenna systems and RIS in millimeter wave (mmWave) bands. Our results reveal\nthat RIS requires an extremely large number of elements (in the order of\n$10^4$) to outperform pinching antenna systems in terms of spectral efficiency,\nwhich severely impact the energy efficiency performance of RIS. Moreover,\npinching antenna systems demonstrate greater robustness against hardware\nimpairments and severe path loss typically encountered in high-frequency mmWave\nbands.", "published": "2025-06-05 14:44:49", "link": "http://arxiv.org/abs/2506.05102v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Massive MIMO with 1-Bit DACs: Data Detection for Quantized Linear Precoding with Dithering", "abstract": "To leverage high-frequency bands in 6G wireless systems and beyond, employing\nmassive multiple-input multipleoutput (MIMO) arrays at the transmitter and/or\nreceiver side is crucial. To mitigate the power consumption and hardware\ncomplexity across massive frequency bands and antenna arrays, a sacrifice in\nthe resolution of the data converters will be inevitable. In this paper, we\nconsider a point-to-point massive MIMO system with 1-bit digital-to-analog\nconverters at the transmitter, where the linearly precoded signal is\nsupplemented with dithering before the 1-bit quantization. For this system, we\npropose a new maximumlikelihood (ML) data detection method at the receiver by\nderiving the mean and covariance matrix of the received signal, where\nsymbol-dependent linear minimum mean squared error estimation is utilized to\nefficiently linearize the transmitted signal. Numerical results show that the\nproposed ML method can provide gains of more than two orders of magnitude in\nterms of symbol error rate over conventional data detection based on soft\nestimation.", "published": "2025-06-05 14:19:42", "link": "http://arxiv.org/abs/2506.05072v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Indoor Sharing in the Mid-Band: A Performance Study of Neutral-Host, Cellular Macro, and Wi-Fi", "abstract": "Indoor environments present a significant challenge for wireless\nconnectivity, as immense data demand strains traditional solutions. Public\nMobile Network Operators (MNOs), utilizing outdoor macro base stations (BSs),\nsuffer from poor signal penetration. Indoor Wi-Fi networks, on the other hand,\nmay face reliability issues due to spectrum contention. Shared spectrum models,\nparticularly the Citizens Broadband Radio Service (CBRS) utilized by private\n4G/5G networks, have emerged as a promising alternative to provide reliable\nindoor service. Moreover, these private networks are equipped with the\nneutral-host (NH) model, seamlessly offloading indoor MNOs' traffic to the\nprivate CBRS network. This paper presents a comprehensive, in-situ performance\nevaluation of three co-located technologies utilizing mid-bands spectrum (1-6\nGHz)--a CBRS-based NH network, public MNO macro networks, and a Wi-Fi 6\nnetwork--within a large, big-box retail store characterized by significant\nbuilding loss. Our analysis demonstrates: (i) the NH network provides superior\nindoor coverage compared to MNO macro, requiring only six CBRS devices\n(CBSDs)--versus 65 Access Points (APs) for enterprise Wi-Fi--to achieve full\ncoverage, with a median building loss of 26.6 dB ensuring interference-free\ncoexistence with outdoor federal incumbents; (ii) the NH network achieves\nsubstantial indoor throughput gains, with per-channel normalized throughput\nimprovements of 1.44x and 1.62x in downlink (DL), and 4.33x and 13x in uplink\n(UL), compared to 4G and 5G macro deployments, respectively; (iii) the NH\ndeployment achieves a median indoor aggregated physical (PHY)-layer DL\nthroughput gain of 2.08x over 5G macro deployments indoors, despite utilizing\nonly 40 MHz of aggregated bandwidth compared to 225 MHz for 5G macro; and (iv)\nthe NH deployment also outperforms Wi-Fi in application-layer HTTP DL\nperformance by 5.05x.", "published": "2025-06-05 12:47:05", "link": "http://arxiv.org/abs/2506.04974v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Development and Testing of a Low Cost Ultrasonic Leak Detector", "abstract": "This study focuses on the development of an ultrasonic leak detection system\nutilizing the Arduino Nano 33 BLE Sense Rev2 board. The research aimed to\ncreate a compact and cost-effective solution for identifying leaks in\nhigh-pressure pipes. Algorithms were designed to enable lossless recording and\nprocessing of sound data captured by the onboard MEMS microphone. Key signal\nprocessing techniques, including the implementation of an IIR high-pass filter\nand RMS calculation, were employed to detect ultrasonic frequencies associated\nwith leaks. The system was tested on a pressurized pipe setup, demonstrating\nits ability to accurately identify leaks. The results highlight the system's\neffectiveness, with its compact design and low cost making it suitable for a\nwide range of industrial applications. This research contributes a practical\nand accessible tool for leak detection, offering potential benefits in\nindustrial applications.", "published": "2025-06-05 10:32:45", "link": "http://arxiv.org/abs/2506.04862v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Design of OTFS Signals with Pulse Shaping and Window Function for OTFS-Based Radar", "abstract": "We propose a pulse radar system that employs a generalized window function\nderived from the root raised cosine (RRC), which relaxes the conventional\nconstraint that the window values are within the range [0, 1]. The proposed\nwindow allows both negative values and values exceeding 1, enabling greater\nflexibility in signal design. The system transmits orthogonal time frequency\nspace (OTFS) signals intermittently, establishing a flexible input-output\nrelationship that captures both fractional delays and Doppler shifts. By\ncombining the generalized RRC window with a rectangular pulse, the resulting\npilot signal achieves a sharp concentration in the ambiguity function over both\nthe delay and Doppler domains. To enhance the estimation accuracy of fractional\nparameters, we apply frequency-domain interpolation based on the\nautocorrelation of the RRC window, which outperforms conventional linear\ninterpolation by preserving the signal structure more effectively.", "published": "2025-06-05 10:27:24", "link": "http://arxiv.org/abs/2506.04861v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Synchro-Thermography: Monitoring ~10 mK Facial Temperature Changes with Heartbeat Referencing for Physiological Sensing", "abstract": "Infrared thermography has gained interest as a tool for non-contact\nmeasurement of blood circulation and skin blood flow due to cardiac activity.\nPartiularly, blood vessels on the surface, such as on the back of the hand, are\nsuited for visualization. However, standardized methodologies have not yet been\nestablished for areas such as the face and neck, where many blood vessels are\nlie deeper beneath the surface, and external stimulation for measurement could\nbe harmful. Here we propose Synchro-Thermography for stable monitoring of\nfacial temperature changes associated with heart rate variability. We conducted\nexperiments with eight subjects and measured minute temperature changes with an\namplitude of about \\SI{10}{mK} on the forehead and chin. The proposed method\nimproves the temperature resolution by a factor of 2 or more, and can stably\nmeasure skin temperature changes caused by blood flow. This skin temperature\nchange could be applied to physiological sensing such as blood flow changes due\nto injury or disease, or as an indicator of stress.", "published": "2025-06-05 08:31:41", "link": "http://arxiv.org/abs/2506.04748v1", "categories": ["physics.med-ph", "eess.SP"], "primary_category": "physics.med-ph"}
{"title": "Spectral Efficiency Maximization for mmWave MIMO-Aided Integrated Sensing and Communication Under Practical Constraints", "abstract": "A hybrid transmit precoder (TPC) and receive combiner (RC) pair is conceived\nfor millimeter wave (mmWave) multiple input multiple output (MIMO) integrated\nsensing and communication (ISAC) systems. The proposed design considers a\npractical mean squared error (MSE) constraint between the desired and the\nachieved beampatterns constructed for identifying radar targets (RTs). To\nachieve optimal performance, we formulate an optimization problem relying on\nsum spectral efficiency (SE) maximization of the communication users (CUs),\nwhile satisfying certain radar beampattern similarity (RBPS), total transmit\npower, and constant modulus constraints, where the latter are attributed to the\nhybrid mmWave MIMO architecture. Since the aforementioned problem is non-convex\nand intractable, a sequential approach is proposed wherein the TPCs are\ndesigned first, followed by the RCs. To deal with the non-convex MSE and\nconstant modulus constraints in the TPC design problem, we propose a\nmajorization and minimization (MM) based Riemannian conjugate gradient (RCG)\nmethod, which restricts the tolerable MSE of the beampattern to within a\npredefined limit. Moreover, the least squares and the zero-forcing methods are\nadopted for maximizing the sum-SE and for mitigating the multiuser interference\n(MUI), respectively. Furthermore, to design the RC at each CU, we propose a\nlinear MM-based blind combiner (LMBC) scheme that does not rely on the\nknowledge of the TPC at the CUs and has a low complexity. To achieve user\nfairness, we further extend the proposed sequential approach for maximizing the\ngeometric mean (GM) of the CU's rate. Simulation results are presented, which\nshow the superior performance of the proposed hybrid TPC and RC in comparison\nto the state-of-the-art designs in the mmWave MIMO ISAC systems under\nconsideration.", "published": "2025-06-05 07:03:52", "link": "http://arxiv.org/abs/2506.04683v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MARS: Radio Map Super-resolution and Reconstruction Method under Sparse Channel Measurements", "abstract": "Radio maps reflect the spatial distribution of signal strength and are\nessential for applications like smart cities, IoT, and wireless network\nplanning. However, reconstructing accurate radio maps from sparse measurements\nremains challenging. Traditional interpolation and inpainting methods lack\nenvironmental awareness, while many deep learning approaches depend on detailed\nscene data, limiting generalization. To address this, we propose MARS, a\nMulti-scale Aware Radiomap Super-resolution method that combines CNNs and\nTransformers with multi-scale feature fusion and residual connections. MARS\nfocuses on both global and local feature extraction, enhancing feature\nrepresentation across different receptive fields and improving reconstruction\naccuracy. Experiments across different scenes and antenna locations show that\nMARS outperforms baseline models in both MSE and SSIM, while maintaining low\ncomputational cost, demonstrating strong practical potential.", "published": "2025-06-05 07:03:50", "link": "http://arxiv.org/abs/2506.04682v1", "categories": ["cs.CV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Federated Learning Assisted Edge Caching Scheme Based on Lightweight Architecture DDPM", "abstract": "Edge caching is an emerging technology that empowers caching units at edge\nnodes, allowing users to fetch contents of interest that have been pre-cached\nat the edge nodes. The key to pre-caching is to maximize the cache hit\npercentage for cached content without compromising users' privacy. In this\nletter, we propose a federated learning (FL) assisted edge caching scheme based\non lightweight architecture denoising diffusion probabilistic model (LDPM). Our\nsimulation results verify that our proposed scheme achieves a higher cache hit\npercentage compared to existing FL-based methods and baseline methods.", "published": "2025-06-05 03:16:51", "link": "http://arxiv.org/abs/2506.04593v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "DAS-MAE: A self-supervised pre-training framework for universal and high-performance representation learning of distributed fiber-optic acoustic sensing", "abstract": "Distributed fiber-optic acoustic sensing (DAS) has emerged as a\ntransformative approach for distributed vibration measurement with high spatial\nresolution and long measurement range while maintaining cost-efficiency.\nHowever, the two-dimensional spatial-temporal DAS signals present analytical\nchallenges. The abstract signal morphology lacking intuitive physical\ncorrespondence complicates human interpretation, and its unique\nspatial-temporal coupling renders conventional image processing methods\nsuboptimal. This study investigates spatial-temporal characteristics and\nproposes a self-supervised pre-training framework that learns signals'\nrepresentations through a mask-reconstruction task. This framework is named the\nDAS Masked AutoEncoder (DAS-MAE). The DAS-MAE learns high-level representations\n(e.g., event class) without using labels. It achieves up to 1% error and 64.5%\nrelative improvement (RI) over the semi-supervised baseline in few-shot\nclassification tasks. In a practical external damage prevention application,\nDAS-MAE attains a 5.0% recognition error, marking a 75.7% RI over supervised\ntraining from scratch. These results demonstrate the high-performance and\nuniversal representations learned by the DAS-MAE framework, highlighting its\npotential as a foundation model for analyzing massive unlabeled DAS signals.", "published": "2025-06-05 01:58:18", "link": "http://arxiv.org/abs/2506.04552v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition", "abstract": "When language models are trained on textual data, they acquire both knowledge\nabout the structure of language as well as knowledge of facts about the world.\nAt inference time, their knowledge of facts can be leveraged to solve\ninteresting problems and perform useful knowledge work for users. It is well\nknown that language models can verbatim memorize long sequences from their\ntraining data. However, it is much less well understood how language models\nmemorize facts seen during training. In this work, we propose a new dataset to\nspecifically empower researchers to study the dual processes of fact\nmemorization and verbatim sequence memorization. The dataset consists of\nsynthetically-generated, webtext-like documents about fictional events, as well\nas question-answer pairs about the events. We conduct training experiments\nshowing how synthetic data about fictional events can be effective in teasing\napart different forms of memorization. We also document the challenges in\neffectively building realistic, fictional synthetic data.", "published": "2025-06-05 23:58:20", "link": "http://arxiv.org/abs/2506.05639v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IYKYK: Using language models to decode extremist cryptolects", "abstract": "Extremist groups develop complex in-group language, also referred to as\ncryptolects, to exclude or mislead outsiders. We investigate the ability of\ncurrent language technologies to detect and interpret the cryptolects of two\nonline extremist platforms. Evaluating eight models across six tasks, our\nresults indicate that general purpose LLMs cannot consistently detect or decode\nextremist language. However, performance can be significantly improved by\ndomain adaptation and specialised prompting techniques. These results provide\nimportant insights to inform the development and deployment of automated\nmoderation technologies. We further develop and release novel labelled and\nunlabelled datasets, including 19.4M posts from extremist platforms and\nlexicons validated by human experts.", "published": "2025-06-05 23:38:53", "link": "http://arxiv.org/abs/2506.05635v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs", "abstract": "The performance of large language models in domain-specific tasks\nnecessitates fine-tuning, which is computationally expensive and technically\nchallenging. This paper focuses on parameter-efficient fine-tuning using soft\nprompting, a promising approach that adapts pre-trained models to downstream\ntasks by learning a small set of parameters. We propose a novel Input Dependent\nSoft Prompting technique with a self-Attention Mechanism (ID-SPAM) that\ngenerates soft prompts based on the input tokens and attends different tokens\nwith varying importance. Our method is simple and efficient, keeping the number\nof trainable parameters small. We show the merits of the proposed approach\ncompared to state-of-the-art techniques on various tasks and show the improved\nzero shot domain transfer capability.", "published": "2025-06-05 23:13:22", "link": "http://arxiv.org/abs/2506.05629v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework", "abstract": "Infrastructure-as-Code (IaC) generation holds significant promise for\nautomating cloud infrastructure provisioning. Recent advances in Large Language\nModels (LLMs) present a promising opportunity to democratize IaC development by\ngenerating deployable infrastructure templates from natural language\ndescriptions, but current evaluation focuses on syntactic correctness while\nignoring deployability, the fatal measure of IaC template utility. We address\nthis gap through two contributions: (1) IaCGen, an LLM-based\ndeployability-centric framework that uses iterative feedback mechanism to\ngenerate IaC templates, and (2) DPIaC-Eval, a deployability-centric IaC\ntemplate benchmark consists of 153 real-world scenarios that can evaluate\nsyntax, deployment, user intent, and security. Our evaluation reveals that\nstate-of-the-art LLMs initially performed poorly, with Claude-3.5 and\nClaude-3.7 achieving only 30.2% and 26.8% deployment success on the first\nattempt respectively. However, IaCGen transforms this performance dramatically:\nall evaluated models reach over 90% passItr@25, with Claude-3.5 and Claude-3.7\nachieving 98% success rate. Despite these improvements, critical challenges\nremain in user intent alignment (25.2% accuracy) and security compliance (8.4%\npass rate), highlighting areas requiring continued research. Our work provides\nthe first comprehensive assessment of deployability-centric IaC template\ngeneration and establishes a foundation for future research.", "published": "2025-06-05 22:53:12", "link": "http://arxiv.org/abs/2506.05623v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Mitigating Confounding in Speech-Based Dementia Detection through Weight Masking", "abstract": "Deep transformer models have been used to detect linguistic anomalies in\npatient transcripts for early Alzheimer's disease (AD) screening. While\npre-trained neural language models (LMs) fine-tuned on AD transcripts perform\nwell, little research has explored the effects of the gender of the speakers\nrepresented by these transcripts. This work addresses gender confounding in\ndementia detection and proposes two methods: the $\\textit{Extended Confounding\nFilter}$ and the $\\textit{Dual Filter}$, which isolate and ablate weights\nassociated with gender. We evaluate these methods on dementia datasets with\nfirst-person narratives from patients with cognitive impairment and healthy\ncontrols. Our results show transformer models tend to overfit to training data\ndistributions. Disrupting gender-related weights results in a deconfounded\ndementia classifier, with the trade-off of slightly reduced dementia detection\nperformance.", "published": "2025-06-05 21:45:59", "link": "http://arxiv.org/abs/2506.05610v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation", "abstract": "Can large language models (LLMs) accurately simulate the next web action of a\nspecific user? While LLMs have shown promising capabilities in generating\n``believable'' human behaviors, evaluating their ability to mimic real user\nbehaviors remains an open challenge, largely due to the lack of high-quality,\npublicly available datasets that capture both the observable actions and the\ninternal reasoning of an actual human user. To address this gap, we introduce\nOPERA, a novel dataset of Observation, Persona, Rationale, and Action collected\nfrom real human participants during online shopping sessions. OPERA is the\nfirst public dataset that comprehensively captures: user personas, browser\nobservations, fine-grained web actions, and self-reported just-in-time\nrationales. We developed both an online questionnaire and a custom browser\nplugin to gather this dataset with high fidelity. Using OPERA, we establish the\nfirst benchmark to evaluate how well current LLMs can predict a specific user's\nnext action and rationale with a given persona and <observation, action,\nrationale> history. This dataset lays the groundwork for future research into\nLLM agents that aim to act as personalized digital twins for human.", "published": "2025-06-05 21:37:49", "link": "http://arxiv.org/abs/2506.05606v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs", "abstract": "Recent calls for pluralistic alignment of Large Language Models (LLMs)\nencourage adapting models to diverse user preferences. However, most prior work\non personalized reward models heavily rely on additional identity information,\nsuch as demographic details or a predefined set of preference categories. To\nthis end, we introduce SynthesizeMe, an approach to inducing synthetic user\npersonas from user interactions for personalized reward modeling. SynthesizeMe\nfirst generates and verifies reasoning to explain user preferences, then\ninduces synthetic user personas from that reasoning, and finally filters to\ninformative prior user interactions in order to build personalized prompts for\na particular user. We show that using SynthesizeMe induced prompts improves\npersonalized LLM-as-a-judge accuracy by 4.4% on Chatbot Arena. Combining\nSynthesizeMe derived prompts with a reward model achieves top performance on\nPersonalRewardBench: a new curation of user-stratified interactions with\nchatbots collected from 854 users of Chatbot Arena and PRISM.", "published": "2025-06-05 21:23:16", "link": "http://arxiv.org/abs/2506.05598v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SoK: Are Watermarks in LLMs Ready for Deployment?", "abstract": "Large Language Models (LLMs) have transformed natural language processing,\ndemonstrating impressive capabilities across diverse tasks. However, deploying\nthese models introduces critical risks related to intellectual property\nviolations and potential misuse, particularly as adversaries can imitate these\nmodels to steal services or generate misleading outputs. We specifically focus\non model stealing attacks, as they are highly relevant to proprietary LLMs and\npose a serious threat to their security, revenue, and ethical deployment. While\nvarious watermarking techniques have emerged to mitigate these risks, it\nremains unclear how far the community and industry have progressed in\ndeveloping and deploying watermarks in LLMs.\n  To bridge this gap, we aim to develop a comprehensive systematization for\nwatermarks in LLMs by 1) presenting a detailed taxonomy for watermarks in LLMs,\n2) proposing a novel intellectual property classifier to explore the\neffectiveness and impacts of watermarks on LLMs under both attack and\nattack-free environments, 3) analyzing the limitations of existing watermarks\nin LLMs, and 4) discussing practical challenges and potential future directions\nfor watermarks in LLMs. Through extensive experiments, we show that despite\npromising research outcomes and significant attention from leading companies\nand community to deploy watermarks, these techniques have yet to reach their\nfull potential in real-world applications due to their unfavorable impacts on\nmodel utility of LLMs and downstream tasks. Our findings provide an insightful\nunderstanding of watermarks in LLMs, highlighting the need for practical\nwatermarks solutions tailored to LLM deployment.", "published": "2025-06-05 21:12:51", "link": "http://arxiv.org/abs/2506.05594v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "UTSA-NLP at ArchEHR-QA 2025: Improving EHR Question Answering via Self-Consistency Prompting", "abstract": "We describe our system for the ArchEHR-QA Shared Task on answering clinical\nquestions using electronic health records (EHRs). Our approach uses large\nlanguage models in two steps: first, to find sentences in the EHR relevant to a\nclinician's question, and second, to generate a short, citation-supported\nresponse based on those sentences. We use few-shot prompting, self-consistency,\nand thresholding to improve the sentence classification step to decide which\nsentences are essential. We compare several models and find that a smaller 8B\nmodel performs better than a larger 70B model for identifying relevant\ninformation. Our results show that accurate sentence selection is critical for\ngenerating high-quality responses and that self-consistency with thresholding\nhelps make these decisions more reliable.", "published": "2025-06-05 21:07:55", "link": "http://arxiv.org/abs/2506.05589v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark", "abstract": "Tables and table-based use cases play a crucial role in many important\nreal-world applications, such as spreadsheets, databases, and computational\nnotebooks, which traditionally require expert-level users like data engineers,\ndata analysts, and database administrators to operate. Although LLMs have shown\nremarkable progress in working with tables (e.g., in spreadsheet and database\ncopilot scenarios), comprehensive benchmarking of such capabilities remains\nlimited. In contrast to an extensive and growing list of NLP benchmarks,\nevaluations of table-related tasks are scarce, and narrowly focus on tasks like\nNL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks\nthat professional users face. This gap limits our understanding and model\nprogress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 30K\nquestions across 25 real-world table tasks, designed to comprehensively\nevaluate models ability to understand, reason, and manipulate real tables at\nthe expert-level. These tasks are drawn from decades' worth of computer science\nresearch on tabular data, with a focus on complex table tasks faced by\nprofessional users. We show that MMTU require a combination of skills --\nincluding table understanding, reasoning, and coding -- that remain challenging\nfor today's frontier models, where even frontier reasoning models like OpenAI\no4-mini and DeepSeek R1 score only around 60%, suggesting significant room for\nimprovement. We highlight key findings in our evaluation using MMTU and hope\nthat this benchmark drives further advances in understanding and developing\nfoundation models for structured data processing and analysis. Our code and\ndata are available at https://github.com/MMTU-Benchmark/MMTU and\nhttps://huggingface.co/datasets/MMTU-benchmark/MMTU.", "published": "2025-06-05 21:05:03", "link": "http://arxiv.org/abs/2506.05587v1", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Combating Misinformation in the Arab World: Challenges & Opportunities", "abstract": "Misinformation and disinformation pose significant risks globally, with the\nArab region facing unique vulnerabilities due to geopolitical instabilities,\nlinguistic diversity, and cultural nuances. We explore these challenges through\nthe key facets of combating misinformation: detection, tracking, mitigation and\ncommunity-engagement. We shed light on how connecting with grass-roots\nfact-checking organizations, understanding cultural norms, promoting social\ncorrection, and creating strong collaborative information networks can create\nopportunities for a more resilient information ecosystem in the Arab world.", "published": "2025-06-05 20:57:33", "link": "http://arxiv.org/abs/2506.05582v1", "categories": ["cs.CL", "cs.AI", "cs.SI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration", "abstract": "Recent advancements in AI reasoning have driven substantial improvements\nacross diverse tasks. A critical open question is whether these improvements\nalso yields better knowledge transfer: the ability of models to communicate\nreasoning in ways humans can understand, apply, and learn from. To investigate\nthis, we introduce Knowledge Integration and Transfer Evaluation (KITE), a\nconceptual and experimental framework for Human-AI knowledge transfer\ncapabilities and conduct the first large-scale human study (N=118) explicitly\ndesigned to measure it. In our two-phase setup, humans first ideate with an AI\non problem-solving strategies, then independently implement solutions,\nisolating model explanations' influence on human understanding. Our findings\nreveal that although model benchmark performance correlates with collaborative\noutcomes, this relationship is notably inconsistent, featuring significant\noutliers, indicating that knowledge transfer requires dedicated optimization.\nOur analysis identifies behavioral and strategic factors mediating successful\nknowledge transfer. We release our code, dataset, and evaluation framework to\nsupport future work on communicatively aligned models.", "published": "2025-06-05 20:48:16", "link": "http://arxiv.org/abs/2506.05579v1", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Improving LLMs with a knowledge from databases", "abstract": "Large language models (LLMs) are achieving significant progress almost every\nmoment now. Many advanced techniques have been introduced and widely accepted,\nlike retrieval-augmentation generation (RAG), agents, and tools. Tools can\nquery the database to answer questions from structured data files or perform\ngroupings or other statistics. This unlocks huge opportunities, such as it can\nanswer any question, but also poses threats, such as safety, because there is\nno control over the commands that are created. We would like to discuss whether\nwe can create a new method that improves answers based on dataset/database via\nsome interpretable ML methods, namely enhanced association rules. The advantage\nwould be if the method can be also used in some safe technique like RAG.\nAssociation rules have a sound history. Since the introduction of CN2 and\naproiri, many enhancements have been made. In parallel, enhanced association\nrules have been introduced and evolved over the last 40 years. The general\nproblem is typically that there are too many rules. There are some techniques\nfor handling it, but when LLM emerged, it turned out to be the best use case\nfor the RAG technique for LLMs. We proposed a method that generates a ruleset\nbased on defined knowledge patterns, then converts rules into text form via a\nrule-to-text converter, and includes the result as an RAG into LLM. We compared\nthis method with ChatGPT (even with using agents) and we have discovered a\nsignificant improvement in answering questions based on the dataset. We have\nalso tried several strategies how much rules to generate. We found this\nimprovement interesting. Moreover, it can also be improved in many ways as\nfuture work, like incorporating other patterns, the use of rule mining as an\nagent, and many others.", "published": "2025-06-05 20:14:25", "link": "http://arxiv.org/abs/2506.05560v1", "categories": ["cs.CL", "I.2.7; I.2.4"], "primary_category": "cs.CL"}
{"title": "MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning", "abstract": "Despite rapid advances in vision-language models (VLMs), current benchmarks\nfor multimodal reasoning fall short in three key dimensions. First, they\noverwhelmingly rely on static images, failing to capture the temporal\ncomplexity of real-world environments. Second, they narrowly focus on\nmathematical problem-solving, neglecting the broader spectrum of reasoning\nskills -- including abstract, physical, planning, spatial, and temporal\ncapabilities -- required for robust multimodal intelligence. Third, many\nbenchmarks quickly saturate, offering limited headroom for diagnosing failure\nmodes or measuring continued progress. We introduce MORSE-500 (Multimodal\nReasoning Stress-test Environment), a video benchmark composed of 500 fully\nscripted clips with embedded questions spanning six complementary reasoning\ncategories. Each instance is programmatically generated using deterministic\nPython scripts (via Manim, Matplotlib, MoviePy), generative video models, and\ncurated real footage. This script-driven design allows fine-grained control\nover visual complexity, distractor density, and temporal dynamics -- enabling\ndifficulty to be scaled systematically as models improve. Unlike static\nbenchmarks that become obsolete once saturated, MORSE-500 is built to evolve:\nits controllable generation pipeline supports the creation of arbitrarily\nchallenging new instances, making it ideally suited for stress-testing\nnext-generation models. Initial experiments with state-of-the-art systems --\nincluding various Gemini 2.5 Pro and OpenAI o3 which represent the strongest\navailable at the time, alongside strong open-source models -- reveal\nsubstantial performance gaps across all categories, with particularly large\ndeficits in abstract and planning tasks. We release the full dataset,\ngeneration scripts, and evaluation harness to support transparent,\nreproducible, and forward-looking multimodal reasoning research.", "published": "2025-06-05 19:12:45", "link": "http://arxiv.org/abs/2506.05523v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering", "abstract": "Specific Language Impairment (SLI) affects approximately 7 percent of\nchildren, presenting as isolated language deficits despite normal cognitive\nabilities, sensory systems, and supportive environments. Traditional diagnostic\napproaches often rely on standardized assessments, which may overlook subtle\ndevelopmental patterns. This study aims to identify natural language\ndevelopment trajectories in children with and without SLI using unsupervised\nmachine learning techniques, providing insights for early identification and\ntargeted interventions. Narrative samples from 1,163 children aged 4-16 years\nacross three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using\nPrincipal Component Analysis (PCA) and clustering. A total of 64 linguistic\nfeatures were evaluated to uncover developmental trajectories and distinguish\nlinguistic profiles. Two primary clusters emerged: (1) high language production\nwith low SLI prevalence, and (2) limited production but higher syntactic\ncomplexity with higher SLI prevalence. Additionally, boundary cases exhibited\nintermediate traits, supporting a continuum model of language abilities.\nFindings suggest SLI manifests primarily through reduced production capacity\nrather than syntactic complexity deficits. The results challenge categorical\ndiagnostic frameworks and highlight the potential of unsupervised learning\ntechniques for refining diagnostic criteria and intervention strategies.", "published": "2025-06-05 18:29:12", "link": "http://arxiv.org/abs/2506.05498v1", "categories": ["cs.CL", "cs.LG", "62H30, 62P10", "I.2.7; J.3"], "primary_category": "cs.CL"}
{"title": "Kinetics: Rethinking Test-Time Scaling Laws", "abstract": "We rethink test-time scaling laws from a practical efficiency perspective,\nrevealing that the effectiveness of smaller models is significantly\noverestimated. Prior work, grounded in compute-optimality, overlooks critical\nmemory access bottlenecks introduced by inference-time strategies (e.g.,\nBest-of-$N$, long CoTs). Our holistic analysis, spanning models from 0.6B to\n32B parameters, reveals a new Kinetics Scaling Law that better guides resource\nallocation by incorporating both computation and memory access costs. Kinetics\nScaling Law suggests that test-time compute is more effective when used on\nmodels above a threshold than smaller ones. A key reason is that in TTS,\nattention, rather than parameter count, emerges as the dominant cost factor.\nMotivated by this, we propose a new scaling paradigm centered on sparse\nattention, which lowers per-token cost and enables longer generations and more\nparallel samples within the same resource budget. Empirically, we show that\nsparse attention models consistently outperform dense counterparts, achieving\nover 60 points gains in low-cost regimes and over 5 points gains in high-cost\nregimes for problem-solving accuracy on AIME, encompassing evaluations on\nstate-of-the-art MoEs. These results suggest that sparse attention is essential\nand increasingly important with more computing invested, for realizing the full\npotential of test-time scaling where, unlike training, accuracy has yet to\nsaturate as a function of computation, and continues to improve through\nincreased generation. The code is available at\nhttps://github.com/Infini-AI-Lab/Kinetics.", "published": "2025-06-05 17:59:24", "link": "http://arxiv.org/abs/2506.05333v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MLLM-CL: Continual Learning for Multimodal Large Language Models", "abstract": "Recent Multimodal Large Language Models (MLLMs) excel in vision-language\nunderstanding but face challenges in adapting to dynamic real-world scenarios\nthat require continuous integration of new knowledge and skills. While\ncontinual learning (CL) offers a potential solution, existing benchmarks and\nmethods suffer from critical limitations. In this paper, we introduce MLLM-CL,\na novel benchmark encompassing domain and ability continual learning, where the\nformer focuses on independently and identically distributed (IID) evaluation\nacross evolving mainstream domains, whereas the latter evaluates on non-IID\nscenarios with emerging model ability. Methodologically, we propose preventing\ncatastrophic interference through parameter isolation, along with an MLLM-based\nrouting mechanism. Extensive experiments demonstrate that our approach can\nintegrate domain-specific knowledge and functional abilities with minimal\nforgetting, significantly outperforming existing methods.", "published": "2025-06-05 17:58:13", "link": "http://arxiv.org/abs/2506.05453v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Interpretation Meets Safety: A Survey on Interpretation Methods and Tools for Improving LLM Safety", "abstract": "As large language models (LLMs) see wider real-world use, understanding and\nmitigating their unsafe behaviors is critical. Interpretation techniques can\nreveal causes of unsafe outputs and guide safety, but such connections with\nsafety are often overlooked in prior surveys. We present the first survey that\nbridges this gap, introducing a unified framework that connects safety-focused\ninterpretation methods, the safety enhancements they inform, and the tools that\noperationalize them. Our novel taxonomy, organized by LLM workflow stages,\nsummarizes nearly 70 works at their intersections. We conclude with open\nchallenges and future directions. This timely survey helps researchers and\npractitioners navigate key advancements for safer, more interpretable LLMs.", "published": "2025-06-05 17:56:05", "link": "http://arxiv.org/abs/2506.05451v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Noninvasive precision modulation of high-level neural population activity via natural vision perturbations", "abstract": "Precise control of neural activity -- modulating target neurons deep in the\nbrain while leaving nearby neurons unaffected -- is an outstanding challenge in\nneuroscience, generally achieved through invasive techniques. This study\ninvestigates the possibility of precisely and noninvasively modulating neural\nactivity in the high-level primate ventral visual stream via perturbations on\none's natural visual feed. When tested on macaque inferior temporal (IT) neural\npopulations, we found quantitative agreement between the model-predicted and\nbiologically realized effect: strong modulation concentrated on targeted neural\nsites. We extended this to demonstrate accurate injection of\nexperimenter-chosen neural population patterns via subtle perturbations applied\non the background of typical natural visual feeds. These results highlight that\ncurrent machine-executable models of the ventral stream can now design\nnoninvasive, visually-delivered, possibly imperceptible neural interventions at\nthe resolution of individual neurons.", "published": "2025-06-05 23:33:14", "link": "http://arxiv.org/abs/2506.05633v1", "categories": ["q-bio.NC", "cs.CV", "cs.NE"], "primary_category": "q-bio.NC"}
{"title": "Controlled Data Rebalancing in Multi-Task Learning for Real-World Image Super-Resolution", "abstract": "Real-world image super-resolution (Real-SR) is a challenging problem due to\nthe complex degradation patterns in low-resolution images. Unlike approaches\nthat assume a broadly encompassing degradation space, we focus specifically on\nachieving an optimal balance in how SR networks handle different degradation\npatterns within a fixed degradation space. We propose an improved paradigm that\nframes Real-SR as a data-heterogeneous multi-task learning problem, our work\naddresses task imbalance in the paradigm through coordinated advancements in\ntask definition, imbalance quantification, and adaptive data rebalancing.\nSpecifically, we introduce a novel task definition framework that segments the\ndegradation space by setting parameter-specific boundaries for degradation\noperators, effectively reducing the task quantity while maintaining task\ndiscrimination. We then develop a focal loss based multi-task weighting\nmechanism that precisely quantifies task imbalance dynamics during model\ntraining. Furthermore, to prevent sporadic outlier samples from dominating the\ngradient optimization of the shared multi-task SR model, we strategically\nconvert the quantified task imbalance into controlled data rebalancing through\ndeliberate regulation of task-specific training volumes. Extensive quantitative\nand qualitative experiments demonstrate that our method achieves consistent\nsuperiority across all degradation tasks.", "published": "2025-06-05 21:40:21", "link": "http://arxiv.org/abs/2506.05607v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UniRes: Universal Image Restoration for Complex Degradations", "abstract": "Real-world image restoration is hampered by diverse degradations stemming\nfrom varying capture conditions, capture devices and post-processing pipelines.\nExisting works make improvements through simulating those degradations and\nleveraging image generative priors, however generalization to in-the-wild data\nremains an unresolved problem. In this paper, we focus on complex degradations,\ni.e., arbitrary mixtures of multiple types of known degradations, which is\nfrequently seen in the wild. A simple yet flexible diffusionbased framework,\nnamed UniRes, is proposed to address such degradations in an end-to-end manner.\nIt combines several specialized models during the diffusion sampling steps,\nhence transferring the knowledge from several well-isolated restoration tasks\nto the restoration of complex in-the-wild degradations. This only requires\nwell-isolated training data for several degradation types. The framework is\nflexible as extensions can be added through a unified formulation, and the\nfidelity-quality trade-off can be adjusted through a new paradigm. Our proposed\nmethod is evaluated on both complex-degradation and single-degradation image\nrestoration datasets. Extensive qualitative and quantitative experimental\nresults show consistent performance gain especially for images with complex\ndegradations.", "published": "2025-06-05 21:25:39", "link": "http://arxiv.org/abs/2506.05599v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PartCrafter: Structured 3D Mesh Generation via Compositional Latent Diffusion Transformers", "abstract": "We introduce PartCrafter, the first structured 3D generative model that\njointly synthesizes multiple semantically meaningful and geometrically distinct\n3D meshes from a single RGB image. Unlike existing methods that either produce\nmonolithic 3D shapes or follow two-stage pipelines, i.e., first segmenting an\nimage and then reconstructing each segment, PartCrafter adopts a unified,\ncompositional generation architecture that does not rely on pre-segmented\ninputs. Conditioned on a single image, it simultaneously denoises multiple 3D\nparts, enabling end-to-end part-aware generation of both individual objects and\ncomplex multi-object scenes. PartCrafter builds upon a pretrained 3D mesh\ndiffusion transformer (DiT) trained on whole objects, inheriting the pretrained\nweights, encoder, and decoder, and introduces two key innovations: (1) A\ncompositional latent space, where each 3D part is represented by a set of\ndisentangled latent tokens; (2) A hierarchical attention mechanism that enables\nstructured information flow both within individual parts and across all parts,\nensuring global coherence while preserving part-level detail during generation.\nTo support part-level supervision, we curate a new dataset by mining part-level\nannotations from large-scale 3D object datasets. Experiments show that\nPartCrafter outperforms existing approaches in generating decomposable 3D\nmeshes, including parts that are not directly visible in input images,\ndemonstrating the strength of part-aware generative priors for 3D understanding\nand synthesis. Code and training data will be released.", "published": "2025-06-05 20:30:28", "link": "http://arxiv.org/abs/2506.05573v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VoxelSplat: Dynamic Gaussian Splatting as an Effective Loss for Occupancy and Flow Prediction", "abstract": "Recent advancements in camera-based occupancy prediction have focused on the\nsimultaneous prediction of 3D semantics and scene flow, a task that presents\nsignificant challenges due to specific difficulties, e.g., occlusions and\nunbalanced dynamic environments. In this paper, we analyze these challenges and\ntheir underlying causes. To address them, we propose a novel regularization\nframework called VoxelSplat. This framework leverages recent developments in 3D\nGaussian Splatting to enhance model performance in two key ways: (i) Enhanced\nSemantics Supervision through 2D Projection: During training, our method\ndecodes sparse semantic 3D Gaussians from 3D representations and projects them\nonto the 2D camera view. This provides additional supervision signals in the\ncamera-visible space, allowing 2D labels to improve the learning of 3D\nsemantics. (ii) Scene Flow Learning: Our framework uses the predicted scene\nflow to model the motion of Gaussians, and is thus able to learn the scene flow\nof moving objects in a self-supervised manner using the labels of adjacent\nframes. Our method can be seamlessly integrated into various existing occupancy\nmodels, enhancing performance without increasing inference time. Extensive\nexperiments on benchmark datasets demonstrate the effectiveness of VoxelSplat\nin improving the accuracy of both semantic occupancy and scene flow estimation.\nThe project page and codes are available at\nhttps://zzy816.github.io/VoxelSplat-Demo/.", "published": "2025-06-05 20:19:35", "link": "http://arxiv.org/abs/2506.05563v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images", "abstract": "Radiance field methods such as 3D Gaussian Splatting (3DGS) allow easy\nreconstruction from photos, enabling free-viewpoint navigation. Nonetheless,\npose estimation using Structure from Motion and 3DGS optimization can still\neach take between minutes and hours of computation after capture is complete.\nSLAM methods combined with 3DGS are fast but struggle with wide camera\nbaselines and large scenes. We present an on-the-fly method to produce camera\nposes and a trained 3DGS immediately after capture. Our method can handle dense\nand wide-baseline captures of ordered photo sequences and large-scale scenes.\nTo do this, we first introduce fast initial pose estimation, exploiting learned\nfeatures and a GPU-friendly mini bundle adjustment. We then introduce direct\nsampling of Gaussian primitive positions and shapes, incrementally spawning\nprimitives where required, significantly accelerating training. These two\nefficient steps allow fast and robust joint optimization of poses and Gaussian\nprimitives. Our incremental approach handles large-scale scenes by introducing\nscalable radiance field construction, progressively clustering 3DGS primitives,\nstoring them in anchors, and offloading them from the GPU. Clustered primitives\nare progressively merged, keeping the required scale of 3DGS at any viewpoint.\nWe evaluate our solution on a variety of datasets and show that our solution\ncan provide on-the-fly processing of all the capture scenarios and scene sizes\nwe target while remaining competitive with other methods that only handle\nspecific capture styles or scene sizes in speed, image quality, or both.", "published": "2025-06-05 20:10:18", "link": "http://arxiv.org/abs/2506.05558v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EX-4D: EXtreme Viewpoint 4D Video Synthesis via Depth Watertight Mesh", "abstract": "Generating high-quality camera-controllable videos from monocular input is a\nchallenging task, particularly under extreme viewpoint. Existing methods often\nstruggle with geometric inconsistencies and occlusion artifacts in boundaries,\nleading to degraded visual quality. In this paper, we introduce EX-4D, a novel\nframework that addresses these challenges through a Depth Watertight Mesh\nrepresentation. The representation serves as a robust geometric prior by\nexplicitly modeling both visible and occluded regions, ensuring geometric\nconsistency in extreme camera pose. To overcome the lack of paired multi-view\ndatasets, we propose a simulated masking strategy that generates effective\ntraining data only from monocular videos. Additionally, a lightweight\nLoRA-based video diffusion adapter is employed to synthesize high-quality,\nphysically consistent, and temporally coherent videos. Extensive experiments\ndemonstrate that EX-4D outperforms state-of-the-art methods in terms of\nphysical consistency and extreme-view quality, enabling practical 4D video\ngeneration.", "published": "2025-06-05 20:02:05", "link": "http://arxiv.org/abs/2506.05554v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding", "abstract": "Large Multimodal Models (LMMs) have achieved impressive progress in visual\nperception and reasoning. However, when confronted with visually ambiguous or\nnon-semantic scene text, they often struggle to accurately spot and understand\nthe content, frequently generating semantically plausible yet visually\nincorrect answers, which we refer to as semantic hallucination. In this work,\nwe investigate the underlying causes of semantic hallucination and identify a\nkey finding: Transformer layers in LLM with stronger attention focus on scene\ntext regions are less prone to producing semantic hallucinations. Thus, we\npropose a training-free semantic hallucination mitigation framework comprising\ntwo key components: (1) ZoomText, a coarse-to-fine strategy that identifies\npotential text regions without external detectors; and (2) Grounded Layer\nCorrection, which adaptively leverages the internal representations from layers\nless prone to hallucination to guide decoding, correcting hallucinated outputs\nfor non-semantic samples while preserving the semantics of meaningful ones. To\nenable rigorous evaluation, we introduce TextHalu-Bench, a benchmark of over\n1,730 samples spanning both semantic and non-semantic cases, with manually\ncurated question-answer pairs designed to probe model hallucinations. Extensive\nexperiments demonstrate that our method not only effectively mitigates semantic\nhallucination but also achieves strong performance on public benchmarks for\nscene text spotting and understanding.", "published": "2025-06-05 19:53:19", "link": "http://arxiv.org/abs/2506.05551v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Layered Motion Fusion: Lifting Motion Segmentation to 3D in Egocentric Videos", "abstract": "Computer vision is largely based on 2D techniques, with 3D vision still\nrelegated to a relatively narrow subset of applications. However, by building\non recent advances in 3D models such as neural radiance fields, some authors\nhave shown that 3D techniques can at last improve outputs extracted from\nindependent 2D views, by fusing them into 3D and denoising them. This is\nparticularly helpful in egocentric videos, where the camera motion is\nsignificant, but only under the assumption that the scene itself is static. In\nfact, as shown in the recent analysis conducted by EPIC Fields, 3D techniques\nare ineffective when it comes to studying dynamic phenomena, and, in\nparticular, when segmenting moving objects. In this paper, we look into this\nissue in more detail. First, we propose to improve dynamic segmentation in 3D\nby fusing motion segmentation predictions from a 2D-based model into layered\nradiance fields (Layered Motion Fusion). However, the high complexity of long,\ndynamic videos makes it challenging to capture the underlying geometric\nstructure, and, as a result, hinders the fusion of motion cues into the\n(incomplete) scene geometry. We address this issue through test-time\nrefinement, which helps the model to focus on specific frames, thereby reducing\nthe data complexity. This results in a synergy between motion fusion and the\nrefinement, and in turn leads to segmentation predictions of the 3D model that\nsurpass the 2D baseline by a large margin. This demonstrates that 3D techniques\ncan enhance 2D analysis even for dynamic phenomena in a challenging and\nrealistic setting.", "published": "2025-06-05 19:46:48", "link": "http://arxiv.org/abs/2506.05546v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FRAME: Pre-Training Video Feature Representations via Anticipation and Memory", "abstract": "Dense video prediction tasks, such as object tracking and semantic\nsegmentation, require video encoders that generate temporally consistent,\nspatially dense features for every frame. However, existing approaches fall\nshort: image encoders like DINO or CLIP lack temporal awareness, while video\nmodels such as VideoMAE underperform compared to image encoders on dense\nprediction tasks. We address this gap with FRAME, a self-supervised video frame\nencoder tailored for dense video understanding. FRAME learns to predict current\nand future DINO patch features from past and present RGB frames, leading to\nspatially precise and temporally coherent representations. To our knowledge,\nFRAME is the first video encoder to leverage image-based models for dense\nprediction while outperforming them on tasks requiring fine-grained visual\ncorrespondence. As an auxiliary capability, FRAME aligns its class token with\nCLIP's semantic space, supporting language-driven tasks such as video\nclassification. We evaluate FRAME across six dense prediction tasks on seven\ndatasets, where it consistently outperforms image encoders and existing\nself-supervised video models. Despite its versatility, FRAME maintains a\ncompact architecture suitable for a range of downstream applications.", "published": "2025-06-05 19:44:47", "link": "http://arxiv.org/abs/2506.05543v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Personalized Interpretability -- Interactive Alignment of Prototypical Parts Networks", "abstract": "Concept-based interpretable neural networks have gained significant attention\ndue to their intuitive and easy-to-understand explanations based on case-based\nreasoning, such as \"this bird looks like those sparrows\". However, a major\nlimitation is that these explanations may not always be comprehensible to users\ndue to concept inconsistency, where multiple visual features are\ninappropriately mixed (e.g., a bird's head and wings treated as a single\nconcept). This inconsistency breaks the alignment between model reasoning and\nhuman understanding. Furthermore, users have specific preferences for how\nconcepts should look, yet current approaches provide no mechanism for\nincorporating their feedback. To address these issues, we introduce\nYoursProtoP, a novel interactive strategy that enables the personalization of\nprototypical parts - the visual concepts used by the model - according to user\nneeds. By incorporating user supervision, YoursProtoP adapts and splits\nconcepts used for both prediction and explanation to better match the user's\npreferences and understanding. Through experiments on both the synthetic\nFunnyBirds dataset and a real-world scenario using the CUB, CARS, and PETS\ndatasets in a comprehensive user study, we demonstrate the effectiveness of\nYoursProtoP in achieving concept consistency without compromising the accuracy\nof the model.", "published": "2025-06-05 19:30:20", "link": "http://arxiv.org/abs/2506.05533v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "FocusDiff: Advancing Fine-Grained Text-Image Alignment for Autoregressive Visual Generation through RL", "abstract": "Recent studies extend the autoregression paradigm to text-to-image\ngeneration, achieving performance comparable to diffusion models. However, our\nnew PairComp benchmark -- featuring test cases of paired prompts with similar\nsyntax but different fine-grained semantics -- reveals that existing models\nstruggle with fine-grained text-image alignment thus failing to realize precise\ncontrol over visual tokens. To address this, we propose FocusDiff, which\nenhances fine-grained text-image semantic alignment by focusing on subtle\ndifferences between similar text-image pairs. We construct a new dataset of\npaired texts and images with similar overall expressions but distinct local\nsemantics, further introducing a novel reinforcement learning algorithm to\nemphasize such fine-grained semantic differences for desired image generation.\nOur approach achieves state-of-the-art performance on existing text-to-image\nbenchmarks and significantly outperforms prior methods on PairComp.", "published": "2025-06-05 18:36:33", "link": "http://arxiv.org/abs/2506.05501v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "F2T2-HiT: A U-Shaped FFT Transformer and Hierarchical Transformer for Reflection Removal", "abstract": "Single Image Reflection Removal (SIRR) technique plays a crucial role in\nimage processing by eliminating unwanted reflections from the background. These\nreflections, often caused by photographs taken through glass surfaces, can\nsignificantly degrade image quality. SIRR remains a challenging problem due to\nthe complex and varied reflections encountered in real-world scenarios. These\nreflections vary significantly in intensity, shapes, light sources, sizes, and\ncoverage areas across the image, posing challenges for most existing methods to\neffectively handle all cases. To address these challenges, this paper\nintroduces a U-shaped Fast Fourier Transform Transformer and Hierarchical\nTransformer (F2T2-HiT) architecture, an innovative Transformer-based design for\nSIRR. Our approach uniquely combines Fast Fourier Transform (FFT) Transformer\nblocks and Hierarchical Transformer blocks within a UNet framework. The FFT\nTransformer blocks leverage the global frequency domain information to\neffectively capture and separate reflection patterns, while the Hierarchical\nTransformer blocks utilize multi-scale feature extraction to handle reflections\nof varying sizes and complexities. Extensive experiments conducted on three\npublicly available testing datasets demonstrate state-of-the-art performance,\nvalidating the effectiveness of our approach.", "published": "2025-06-05 18:12:36", "link": "http://arxiv.org/abs/2506.05489v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Implicit Neural Representation for Video Restoration", "abstract": "High-resolution (HR) videos play a crucial role in many computer vision\napplications. Although existing video restoration (VR) methods can\nsignificantly enhance video quality by exploiting temporal information across\nvideo frames, they are typically trained for fixed upscaling factors and lack\nthe flexibility to handle scales or degradations beyond their training\ndistribution. In this paper, we introduce VR-INR, a novel video restoration\napproach based on Implicit Neural Representations (INRs) that is trained only\non a single upscaling factor ($\\times 4$) but generalizes effectively to\narbitrary, unseen super-resolution scales at test time. Notably, VR-INR also\nperforms zero-shot denoising on noisy input, despite never having seen noisy\ndata during training. Our method employs a hierarchical\nspatial-temporal-texture encoding framework coupled with multi-resolution\nimplicit hash encoding, enabling adaptive decoding of high-resolution and\nnoise-suppressed frames from low-resolution inputs at any desired\nmagnification. Experimental results show that VR-INR consistently maintains\nhigh-quality reconstructions at unseen scales and noise during training,\nsignificantly outperforming state-of-the-art approaches in sharpness, detail\npreservation, and denoising efficacy.", "published": "2025-06-05 18:09:59", "link": "http://arxiv.org/abs/2506.05488v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Neural Network Model of Spatial and Feature-Based Attention", "abstract": "Visual attention is a mechanism closely intertwined with vision and memory.\nTop-down information influences visual processing through attention. We\ndesigned a neural network model inspired by aspects of human visual attention.\nThis model consists of two networks: one serves as a basic processor performing\na simple task, while the other processes contextual information and guides the\nfirst network through attention to adapt to more complex tasks. After training\nthe model and visualizing the learned attention response, we discovered that\nthe model's emergent attention patterns corresponded to spatial and\nfeature-based attention. This similarity between human visual attention and\nattention in computer vision suggests a promising direction for studying human\ncognition using neural network models.", "published": "2025-06-05 18:08:11", "link": "http://arxiv.org/abs/2506.05487v1", "categories": ["cs.CV", "cs.CE"], "primary_category": "cs.CV"}
{"title": "OpenRR-5k: A Large-Scale Benchmark for Reflection Removal in the Wild", "abstract": "Removing reflections is a crucial task in computer vision, with significant\napplications in photography and image enhancement. Nevertheless, existing\nmethods are constrained by the absence of large-scale, high-quality, and\ndiverse datasets. In this paper, we present a novel benchmark for Single Image\nReflection Removal (SIRR). We have developed a large-scale dataset containing\n5,300 high-quality, pixel-aligned image pairs, each consisting of a reflection\nimage and its corresponding clean version. Specifically, the dataset is divided\ninto two parts: 5,000 images are used for training, and 300 images are used for\nvalidation. Additionally, we have included 100 real-world testing images\nwithout ground truth (GT) to further evaluate the practical performance of\nreflection removal methods. All image pairs are precisely aligned at the pixel\nlevel to guarantee accurate supervision. The dataset encompasses a broad\nspectrum of real-world scenarios, featuring various lighting conditions, object\ntypes, and reflection patterns, and is segmented into training, validation, and\ntest sets to facilitate thorough evaluation. To validate the usefulness of our\ndataset, we train a U-Net-based model and evaluate it using five widely-used\nmetrics, including PSNR, SSIM, LPIPS, DISTS, and NIQE. We will release both the\ndataset and the code on https://github.com/caijie0620/OpenRR-5k to facilitate\nfuture research in this field.", "published": "2025-06-05 18:03:39", "link": "http://arxiv.org/abs/2506.05482v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting", "abstract": "We present ODE-GS, a novel method that unifies 3D Gaussian Splatting with\nlatent neural ordinary differential equations (ODEs) to forecast dynamic 3D\nscenes far beyond the time span seen during training. Existing neural rendering\nsystems - whether NeRF- or 3DGS-based - embed time directly in a deformation\nnetwork and therefore excel at interpolation but collapse when asked to predict\nthe future, where timestamps are strictly out-of-distribution. ODE-GS\neliminates this dependency: after learning a high-fidelity, time-conditioned\ndeformation model for the training window, we freeze it and train a Transformer\nencoder that summarizes past Gaussian trajectories into a latent state whose\ncontinuous evolution is governed by a neural ODE. Numerical integration of this\nlatent flow yields smooth, physically plausible Gaussian trajectories that can\nbe queried at any future instant and rendered in real time. Coupled with a\nvariational objective and a lightweight second-derivative regularizer, ODE-GS\nattains state-of-the-art extrapolation on D-NeRF and NVFI benchmarks, improving\nPSNR by up to 10 dB and halving perceptual error (LPIPS) relative to the\nstrongest baselines. Our results demonstrate that continuous-time latent\ndynamics are a powerful, practical route to photorealistic prediction of\ncomplex 3D scenes.", "published": "2025-06-05 18:02:30", "link": "http://arxiv.org/abs/2506.05480v1", "categories": ["cs.GR", "cs.CV", "cs.LG"], "primary_category": "cs.GR"}
{"title": "An O(log log n)-approximate budget feasible mechanism for subadditive valuations", "abstract": "In budget-feasible mechanism design, there is a set of items $U$, each owned\nby a distinct seller. The seller of item $e$ incurs a private cost\n$\\overline{c}_e$ for supplying her item. A buyer wishes to procure a set of\nitems from the sellers of maximum value, where the value of a set $S\\subseteq\nU$ of items is given by a valuation function $v:2^U\\to \\mathbb{R}_+$. The buyer\nhas a budget of $B \\in \\mathbb{R}_+$ for the total payments made to the\nsellers. We wish to design a mechanism that is truthful, that is, sellers are\nincentivized to report their true costs, budget-feasible, that is, the sum of\nthe payments made to the sellers is at most the budget $B$, and that outputs a\nset whose value is large compared to $\\text{OPT}:=\\max\\{v(S):\\overline{c}(S)\\le\nB,S\\subseteq U\\}$.\n  Budget-feasible mechanism design has been extensively studied, with the\nliterature focussing on (classes of) subadditive valuation functions, and\nvarious polytime, budget-feasible mechanisms, achieving constant-factor\napproximation, have been devised for the special cases of additive, submodular,\nand XOS valuations. However, for general subadditive valuations, the best-known\napproximation factor achievable by a polytime budget-feasible mechanism (given\naccess to demand oracles) was only $O(\\log n / \\log \\log n)$, where $n$ is the\nnumber of items.\n  We improve this state-of-the-art significantly by designing a budget-feasible\nmechanism for subadditive valuations that \\emph{achieves a\nsubstantially-improved approximation factor of $O(\\log\\log n)$ and runs in\npolynomial time, given access to demand oracles.}", "published": "2025-06-05 06:21:33", "link": "http://arxiv.org/abs/2506.04665v1", "categories": ["cs.GT", "cs.DM", "cs.DS"], "primary_category": "cs.GT"}
{"title": "Heterogeneous Sequel-Aware Graph Neural Networks for Sequential Learning", "abstract": "Graph-based recommendation systems use higher-order user and item embeddings\nfor next-item predictions. Dynamically adding collaborative signals from\nneighbors helps to use similar users' preferences during learning. While\nitem-item correlations and their impact on recommendations have been studied,\nthe efficacy of temporal item sequences for recommendations is much less\nexplored. In this paper, we examine temporal item sequence (sequel-aware)\nembeddings along with higher-order user embeddings and show that sequel-aware\nGraph Neural Networks have better (or comparable) recommendation performance\nthan graph-based recommendation systems that do not consider sequel\ninformation. Extensive empirical results comparing Heterogeneous Sequel-aware\nGraph Neural Networks (HSAL-GNNs) to other algorithms for sequential learning\n(such as transformers, graph neural networks, auto-encoders) are presented on\nthree synthetic and three real-world datasets. Our results indicate that the\nincorporation of sequence information from items greatly enhances\nrecommendations.", "published": "2025-06-05 22:58:24", "link": "http://arxiv.org/abs/2506.05625v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG", "abstract": "Large Language Models (LLMs) have shown remarkable performance in Open-Domain\nQuestion Answering (ODQA) by leveraging external documents through\nRetrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer\ncontext, context compression is necessary. However, prior compression methods\ndo not focus on filtering out non-evidential information, which limit the\nperformance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or\nECoRAG framework. ECoRAG improves LLM performance by compressing retrieved\ndocuments based on evidentiality, ensuring whether answer generation is\nsupported by the correct evidence. As an additional step, ECoRAG reflects\nwhether the compressed content provides sufficient evidence, and if not,\nretrieves more until sufficient. Experiments show that ECoRAG improves LLM\nperformance on ODQA tasks, outperforming existing compression methods.\nFurthermore, ECoRAG is highly cost-efficient, as it not only reduces latency\nbut also minimizes token usage by retaining only the necessary information to\ngenerate the correct answer. Code is available at\nhttps://github.com/ldilab/ECoRAG.", "published": "2025-06-05 15:43:49", "link": "http://arxiv.org/abs/2506.05167v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "User Altruism in Recommendation Systems", "abstract": "Users of social media platforms based on recommendation systems (RecSys)\n(e.g. TikTok, X, YouTube) strategically interact with platform content to\ninfluence future recommendations. On some such platforms, users have been\ndocumented to form large-scale grassroots movements encouraging others to\npurposefully interact with algorithmically suppressed content in order to\n\"boost\" its recommendation; we term this behavior user altruism. To capture\nthis behavior, we study a game between users and a RecSys, where users provide\nthe RecSys (potentially manipulated) preferences over the contents available to\nthem, and the RecSys -- limited by data and computation constraints -- creates\na low-rank approximation preference matrix, and ultimately provides each user\nher (approximately) most-preferred item. We compare the users' social welfare\nunder truthful preference reporting and under a class of strategies capturing\nuser altruism. In our theoretical analysis, we provide sufficient conditions to\nensure strict increases in user social welfare under user altruism, and provide\nan algorithm to find an effective altruistic strategy. Interestingly, we show\nthat for commonly assumed recommender utility functions, effectively altruistic\nstrategies also improve the utility of the RecSys! We show that our results are\nrobust to several model misspecifications, thus strengthening our conclusions.\nOur theoretical analysis is complemented by empirical results of effective\naltruistic strategies on the GoodReads dataset, and an online survey on how\nreal-world users behave altruistically in RecSys. Overall, our findings serve\nas a proof-of-concept of the reasons why traditional RecSys may incentivize\nusers to form collectives and/or follow altruistic strategies when interacting\nwith them.", "published": "2025-06-05 00:14:40", "link": "http://arxiv.org/abs/2506.04525v2", "categories": ["cs.GT", "cs.CY", "cs.HC", "cs.IR", "cs.SI"], "primary_category": "cs.GT"}
{"title": "Joint User Association and Beamforming Design for ISAC Networks with Large Language Models", "abstract": "Integrated sensing and communication (ISAC) has been envisioned to play a\nmore important role in future wireless networks. However, the design of ISAC\nnetworks is challenging, especially when there are multiple communication and\nsensing (C\\&S) nodes and multiple sensing targets. We investigate a multi-base\nstation (BS) ISAC network in which multiple BSs equipped with multiple antennas\nsimultaneously provide C\\&S services for multiple ground communication users\n(CUs) and targets. To enhance the overall performance of C\\&S, we formulate a\njoint user association (UA) and multi-BS transmit beamforming optimization\nproblem with the objective of maximizing the total sum rate of all CUs while\nensuring both the minimum target detection and parameter estimation\nrequirements. To efficiently solve the highly non-convex mixed integer\nnonlinear programming (MINLP) optimization problem, we propose an alternating\noptimization (AO)-based algorithm that decomposes the problem into two\nsub-problems, i.e., UA optimization and multi-BS transmit beamforming\noptimization. Inspired by large language models (LLMs) for prediction and\ninference, we propose a unified framework integrating LLMs with convex-based\noptimization methods. First, we propose a comprehensive design of prompt\nengineering, including few-shot, chain of thought, and self-reflection\ntechniques to guide LLMs in solving the binary integer programming UA\noptimization problem. Second, we utilize convex-based optimization methods to\nhandle the non-convex beamforming optimization problem based on fractional\nprogramming (FP), majorization minimization (MM), and the alternating direction\nmethod of multipliers (ADMM) with an optimized UA from LLMs. Numerical results\ndemonstrate that our proposed LLM-enabled AO-based algorithm achieves fast\nconvergence and near upper-bound performance with the GPT-o1 model,\noutperforming various benchmark schemes.", "published": "2025-06-05 23:41:11", "link": "http://arxiv.org/abs/2506.05637v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Fluid Antenna System-Assisted Self-Interference Cancellation for In-Band Full Duplex Communications", "abstract": "In-band full-duplex (IBFD) systems are expected to double the spectral\nefficiency compared to half-duplex systems, provided that loopback\nself-interference (SI) can be effectively suppressed. The inherent interference\nmitigation capabilities of the emerging fluid antenna system (FAS) technology\nmake it a promising candidate for addressing the SI challenge in IBFD systems.\nThis paper thus proposes a FAS-assisted self-interference cancellation (SIC)\nframework, which leverages a receiver-side FAS to dynamically select an\ninterference-free port. Analytical results include a lower bound and an\napproximation of the residual SI (RSI) power, both derived for rich-scattering\nchannels by considering the joint spatial correlation amongst the FAS ports.\nSimulations of RSI power and forward link rates validate the analysis, showing\nthat the SIC performance improves with the number of FAS ports. Additionally,\nsimulations under practical conditions, such as finite-scattering environments\nand wideband integrated access and backhaul (IAB) channels, reveal that the\nproposed approach offers superior SIC capability and significant forward rate\ngains over conventional IBFD SIC schemes.", "published": "2025-06-05 20:28:16", "link": "http://arxiv.org/abs/2506.05569v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Can LLMs Talk 'Sex'? Exploring How AI Models Handle Intimate Conversations", "abstract": "This study examines how four prominent large language models (Claude 3.7\nSonnet, GPT-4o, Gemini 2.5 Flash, and Deepseek-V3) handle sexually oriented\nrequests through qualitative content analysis. By evaluating responses to\nprompts ranging from explicitly sexual to educational and neutral control\nscenarios, the research reveals distinct moderation paradigms reflecting\nfundamentally divergent ethical positions. Claude 3.7 Sonnet employs strict and\nconsistent prohibitions, while GPT-4o navigates user interactions through\nnuanced contextual redirection. Gemini 2.5 Flash exhibits permissiveness with\nthreshold-based limits, and Deepseek-V3 demonstrates troublingly inconsistent\nboundary enforcement and performative refusals. These varied approaches create\na significant \"ethical implementation gap,\" stressing a critical absence of\nunified ethical frameworks and standards across platforms. The findings\nunderscore the urgent necessity for transparent, standardized guidelines and\ncoordinated international governance to ensure consistent moderation, protect\nuser welfare, and maintain trust as AI systems increasingly mediate intimate\naspects of human life.", "published": "2025-06-05 18:55:37", "link": "http://arxiv.org/abs/2506.05514v1", "categories": ["cs.CY", "cs.IT", "math.IT"], "primary_category": "cs.CY"}
{"title": "Channel Estimation with Asynchronous Reception for User-Centric Cell-Free MIMO Systems", "abstract": "The user-centric, cell-free wireless network is a promising next-generation\ncommunication system, but signal synchronization issues arise due to\ndistributed access points and lack of cellular structure. We propose a novel\nmethod to recover synchronous pilot reception by introducing new pilot\nsequences and a matched filter window, enabling orthogonality even with\nasynchronous reception. Our approach mimics synchronous transmission by\nextending training sequences. Analysis shows asynchronous reception's impact on\nchannel estimation, and our method significantly improves performance with a\nsmall increase of training time overhead. Results demonstrate a 7.26 dB\nreduction in normalized mean square error and 40% increase in data rate,\nachieving performance levels comparable to the synchronous case.", "published": "2025-06-05 18:23:50", "link": "http://arxiv.org/abs/2506.05496v1", "categories": ["cs.IT", "cs.NI", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts", "abstract": "Agentic AI has gained significant interest as a research paradigm focused on\nautonomy, self-directed learning, and long-term reliability of decision making.\nReal-world agentic systems operate in decentralized settings on a large set of\ntasks or data distributions with constraints such as limited bandwidth,\nasynchronous execution, and the absence of a centralized model or even common\nobjectives. We posit that exploiting previously learned skills, task\nsimilarities, and communication capabilities in a collective of agentic AI are\nchallenging but essential elements to enabling scalability, open-endedness, and\nbeneficial collaborative learning dynamics. In this paper, we introduce Modular\nSharing and Composition in Collective Learning (MOSAIC), an agentic algorithm\nthat allows multiple agents to independently solve different tasks while also\nidentifying, sharing, and reusing useful machine-learned knowledge, without\ncoordination, synchronization, or centralized control. MOSAIC combines three\nmechanisms: (1) modular policy composition via neural network masks, (2) cosine\nsimilarity estimation using Wasserstein embeddings for knowledge selection, and\n(3) asynchronous communication and policy integration. Results on a set of RL\nbenchmarks show that MOSAIC has a greater sample efficiency than isolated\nlearners, i.e., it learns significantly faster, and in some cases, finds\nsolutions to tasks that cannot be solved by isolated learners. The\ncollaborative learning and sharing dynamics are also observed to result in the\nemergence of ideal curricula of tasks, from easy to hard. These findings\nsupport the case for collaborative learning in agentic systems to achieve\nbetter and continuously evolving performance both at the individual and\ncollective levels.", "published": "2025-06-05 20:38:11", "link": "http://arxiv.org/abs/2506.05577v1", "categories": ["cs.LG", "cs.AI", "cs.MA", "I.2.6; I.2.11"], "primary_category": "cs.LG"}
{"title": "Using Large Language Models to Simulate Human Behavioural Experiments: Port of Mars", "abstract": "Collective risk social dilemmas (CRSD) highlight a trade-off between\nindividual preferences and the need for all to contribute toward achieving a\ngroup objective. Problems such as climate change are in this category, and so\nit is critical to understand their social underpinnings. However, rigorous CRSD\nmethodology often demands large-scale human experiments but it is difficult to\nguarantee sufficient power and heterogeneity over socio-demographic factors.\nGenerative AI offers a potential complementary approach to address thisproblem.\nBy replacing human participants with large language models (LLM), it allows for\na scalable empirical framework. This paper focuses on the validity of this\napproach and whether it is feasible to represent a large-scale human-like\nexperiment with sufficient diversity using LLM. In particular, where previous\nliterature has focused on political surveys, virtual towns and classical\ngame-theoretic examples, we focus on a complex CRSD used in the institutional\neconomics and sustainability literature known as Port of Mars", "published": "2025-06-05 20:02:31", "link": "http://arxiv.org/abs/2506.05555v1", "categories": ["cs.MA", "cs.CY"], "primary_category": "cs.MA"}
{"title": "Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data", "abstract": "The adoption of machine learning (ML) and deep learning methods has\nrevolutionized molecular medicine by driving breakthroughs in genomics,\ntranscriptomics, drug discovery, and biological systems modeling. The\nincreasing quantity, multimodality, and heterogeneity of biological datasets\ndemand automated methods that can produce generalizable predictive models.\nRecent developments in large language model-based agents have shown promise for\nautomating end-to-end ML experimentation on structured benchmarks. However,\nwhen applied to heterogeneous computational biology datasets, these methods\nstruggle with generalization and success rates. Here, we introduce\nAgentomics-ML, a fully autonomous agent-based system designed to produce a\nclassification model and the necessary files for reproducible training and\ninference. Our method follows predefined steps of an ML experimentation\nprocess, repeatedly interacting with the file system through Bash to complete\nindividual steps. Once an ML model is produced, training and validation metrics\nprovide scalar feedback to a reflection step to identify issues such as\noverfitting. This step then creates verbal feedback for future iterations,\nsuggesting adjustments to steps such as data representation, model\narchitecture, and hyperparameter choices. We have evaluated Agentomics-ML on\nseveral established genomic and transcriptomic benchmark datasets and show that\nit outperforms existing state-of-the-art agent-based methods in both\ngeneralization and success rates. While state-of-the-art models built by domain\nexperts still lead in absolute performance on the majority of the computational\nbiology datasets used in this work, Agentomics-ML narrows the gap for fully\nautonomous systems and achieves state-of-the-art performance on one of the used\nbenchmark datasets. The code is available at\nhttps://github.com/BioGeMT/Agentomics-ML.", "published": "2025-06-05 19:44:38", "link": "http://arxiv.org/abs/2506.05542v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Sequence Modeling for N-Agent Ad Hoc Teamwork", "abstract": "N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent\nreinforcement learning, where controlled subteams of varying sizes must\ndynamically collaborate with varying numbers and types of unknown teammates\nwithout pre-coordination. The existing learning algorithm (POAM) considers only\nindependent learning for its flexibility in dealing with a changing number of\nagents. However, independent learning fails to fully capture the inter-agent\ndynamics essential for effective collaboration. Based on our observation that\ntransformers deal effectively with sequences with varying lengths and have been\nshown to be highly effective for a variety of machine learning problems, this\nwork introduces a centralized, transformer-based method for N-agent ad hoc\nteamwork. Our proposed approach incorporates historical observations and\nactions of all controlled agents, enabling optimal responses to diverse and\nunseen teammates in partially observable environments. Empirical evaluation on\na StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving\nsuperior sample efficiency and generalization, without auxiliary agent-modeling\nobjectives.", "published": "2025-06-05 19:20:12", "link": "http://arxiv.org/abs/2506.05527v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Towards Data Systems That Are Business Semantic-Centric and AI Agents-Assisted", "abstract": "Contemporary businesses operate in dynamic environments requiring rapid\nadaptation to achieve goals and maintain competitiveness. Existing data\nplatforms often fall short by emphasizing tools over alignment with business\nneeds, resulting in inefficiencies and delays. To address this gap, I propose\nthe Business Semantics Centric, AI Agents Assisted Data System (BSDS), a\nholistic system that integrates architecture, workflows, and team organization\nto ensure data systems are tailored to business priorities rather than dictated\nby technical constraints. BSDS redefines data systems as dynamic enablers of\nbusiness success, transforming them from passive tools into active drivers of\norganizational growth. BSDS has a modular architecture that comprises curated\ndata linked to business entities, a knowledge base for context-aware AI agents,\nand efficient data pipelines. AI agents play a pivotal role in assisting with\ndata access and system management, reducing human effort, and improving\nscalability. Complementing this architecture, BSDS incorporates workflows\noptimized for both exploratory data analysis and production requirements,\nbalancing speed of delivery with quality assurance. A key innovation of BSDS is\nits incorporation of the human factor. By aligning data team expertise with\nbusiness semantics, BSDS bridges the gap between technical capabilities and\nbusiness needs. Validated through real-world implementation, BSDS accelerates\ntime-to-market for data-driven initiatives, enhances cross-functional\ncollaboration, and provides a scalable blueprint for businesses of all sizes.\nFuture research can build on BSDS to explore optimization strategies using\ncomplex systems and adaptive network theories, as well as developing autonomous\ndata systems leveraging AI agents.", "published": "2025-06-05 19:06:06", "link": "http://arxiv.org/abs/2506.05520v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams", "abstract": "Effective teamwork is essential across diverse domains. During the team\nformation stage, a key challenge is forming teams that effectively balance user\npreferences with task objectives to enhance overall team satisfaction. In the\nteam performing stage, maintaining cohesion and engagement is critical for\nsustaining high team performance. However, existing computational tools and\nalgorithms for team optimization often rely on static data inputs, narrow\nalgorithmic objectives, or solutions tailored for specific contexts, failing to\naccount for the dynamic interplay of team members personalities, evolving\ngoals, and changing individual preferences. Therefore, teams may encounter\nmember dissatisfaction, as purely algorithmic assignments can reduce members\ncommitment to team goals or experience suboptimal engagement due to the absence\nof timely, personalized guidance to help members adjust their behaviors and\ninteractions as team dynamics evolve. Ultimately, these challenges can lead to\nreduced overall team performance. My Ph.D. dissertation aims to develop\nAI-augmented team optimization frameworks and practical systems that enhance\nteam satisfaction, engagement, and performance. First, I propose a team\nformation framework that leverages a multi-armed bandit algorithm to\niteratively refine team composition based on user preferences, ensuring\nalignment between individual needs and collective team goals to enhance team\nsatisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an\nAI-powered system that utilizes large language models (LLMs) to deliver\nimmediate, personalized feedback to both teams and individual members,\nenhancing cohesion and engagement. Finally, I present PuppeteerLLM, an\nLLM-based simulation framework that simulates multi-agent teams to model\ncomplex team dynamics within realistic environments, incorporating task-driven\ncollaboration and long-term coordination.", "published": "2025-06-05 17:24:37", "link": "http://arxiv.org/abs/2506.05265v2", "categories": ["cs.HC", "cs.AI", "cs.MA"], "primary_category": "cs.HC"}
{"title": "A MARL-based Approach for Easing MAS Organization Engineering", "abstract": "Multi-Agent Systems (MAS) have been successfully applied in industry for\ntheir ability to address complex, distributed problems, especially in IoT-based\nsystems. Their efficiency in achieving given objectives and meeting design\nrequirements is strongly dependent on the MAS organization during the\nengineering process of an application-specific MAS. To design a MAS that can\nachieve given goals, available methods rely on the designer's knowledge of the\ndeployment environment. However, high complexity and low readability in some\ndeployment environments make the application of these methods to be costly or\nraise safety concerns. In order to ease the MAS organization design regarding\nthose concerns, we introduce an original Assisted MAS Organization Engineering\nApproach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement\nLearning (MARL) process with an organizational model to suggest relevant\norganizational specifications to help in MAS engineering.", "published": "2025-06-05 09:59:36", "link": "http://arxiv.org/abs/2506.05437v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Approximation of the Pseudospectral Abscissa via Eigenvalue Perturbation Theory", "abstract": "Reliable and efficient computation of the pseudospectral abscissa in the\nlarge-scale setting is still not settled. Unlike the small-scale setting where\nthere are globally convergent criss-cross algorithms, all algorithms in the\nlarge-scale setting proposed to date are at best locally convergent. We first\ndescribe how eigenvalue perturbation theory can be put in use to estimate the\nglobally rightmost point in the $\\epsilon$-pseudospectrum if $\\epsilon$ is\nsmall. Our treatment addresses both general nonlinear eigenvalue problems, and\nthe standard eigenvalue problem as a special case. For small $\\epsilon$, the\nestimates by eigenvalue perturbation theory are quite accurate. In the standard\neigenvalue case, we even derive a formula with an ${\\mathcal O}(\\epsilon^3)$\nerror. For larger $\\epsilon$, the estimates can be used to initialize the\nlocally convergent algorithms. We also propose fixed-point iterations built on\nthe the perturbation theory ideas for large $\\epsilon$ that are suitable for\nthe large-scale setting. The proposed fixed-point iterations initialized by\nusing eigenvalue perturbation theory converge to the globally rightmost point\nin the pseudospectrum in a vast majority of the cases that we experiment with.", "published": "2025-06-05 19:32:35", "link": "http://arxiv.org/abs/2506.05535v1", "categories": ["math.NA", "cs.NA", "65F15, 93D09, 65H17, 30C15"], "primary_category": "math.NA"}
{"title": "Applying Informer for Option Pricing: A Transformer-Based Approach", "abstract": "Accurate option pricing is essential for effective trading and risk\nmanagement in financial markets, yet it remains challenging due to market\nvolatility and the limitations of traditional models like Black-Scholes. In\nthis paper, we investigate the application of the Informer neural network for\noption pricing, leveraging its ability to capture long-term dependencies and\ndynamically adjust to market fluctuations. This research contributes to the\nfield of financial forecasting by introducing Informer's efficient architecture\nto enhance prediction accuracy and provide a more adaptable and resilient\nframework compared to existing methods. Our results demonstrate that Informer\noutperforms traditional approaches in option pricing, advancing the\ncapabilities of data-driven financial forecasting in this domain.", "published": "2025-06-05 20:23:28", "link": "http://arxiv.org/abs/2506.05565v1", "categories": ["cs.CE", "cs.AI", "cs.LG", "q-fin.CP", "91G60, 68T07", "I.2.6; J.4"], "primary_category": "cs.CE"}
{"title": "Classification of Extremal Dependence in Financial Markets via Bootstrap Inference", "abstract": "Accurately identifying the extremal dependence structure in multivariate\nheavy-tailed data is a fundamental yet challenging task, particularly in\nfinancial applications. Following a recently proposed bootstrap-based testing\nprocedure, we apply the methodology to absolute log returns of U.S. S&P 500 and\nChinese A-share stocks over a time period well before the U.S. election in\n2024. The procedure reveals more isolated clustering of dependent assets in the\nU.S. economy compared with China which exhibits different characteristics and a\nmore interconnected pattern of extremal dependence. Cross-market analysis\nidentifies strong extremal linkages in sectors such as materials, consumer\nstaples and consumer discretionary, highlighting the effectiveness of the\ntesting procedure for large-scale empirical applications.", "published": "2025-06-05 05:51:39", "link": "http://arxiv.org/abs/2506.04656v1", "categories": ["math.ST", "q-fin.ST", "stat.TH"], "primary_category": "math.ST"}
{"title": "Zero-shot protein stability prediction by inverse folding models: a free energy interpretation", "abstract": "Inverse folding models have proven to be highly effective zero-shot\npredictors of protein stability. Despite this success, the link between the\namino acid preferences of an inverse folding model and the free-energy\nconsiderations underlying thermodynamic stability remains incompletely\nunderstood. A better understanding would be of interest not only from a\ntheoretical perspective, but also potentially provide the basis for stronger\nzero-shot stability prediction. In this paper, we take steps to clarify the\nfree-energy foundations of inverse folding models. Our derivation reveals the\nstandard practice of likelihood ratios as a simplistic approximation and\nsuggests several paths towards better estimates of the relative stability. We\nempirically assess these approaches and demonstrate that considerable gains in\nzero-shot performance can be achieved with fairly simple means.", "published": "2025-06-05 21:15:13", "link": "http://arxiv.org/abs/2506.05596v1", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Nonlinear Causal Discovery through a Sequential Edge Orientation Approach", "abstract": "Recent advances have established the identifiability of a directed acyclic\ngraph (DAG) under additive noise models (ANMs), spurring the development of\nvarious causal discovery methods. However, most existing methods make\nrestrictive model assumptions, rely heavily on general independence tests, or\nrequire substantial computational time. To address these limitations, we\npropose a sequential procedure to orient undirected edges in a completed\npartial DAG (CPDAG), representing an equivalence class of DAGs, by leveraging\nthe pairwise additive noise model (PANM) to identify their causal directions.\nWe prove that this procedure can recover the true causal DAG assuming a\nrestricted ANM. Building on this result, we develop a novel constraint-based\nalgorithm for learning causal DAGs under nonlinear ANMs. Given an estimated\nCPDAG, we develop a ranking procedure that sorts undirected edges by their\nadherence to the PANM, which defines an evaluation order of the edges. To\ndetermine the edge direction, we devise a statistical test that compares the\nlog-likelihood values, evaluated with respect to the competing directions, of a\nsub-graph comprising just the candidate nodes and their identified parents in\nthe partial DAG. We further establish the structural learning consistency of\nour algorithm in the large-sample limit. Extensive experiments on synthetic and\nreal-world datasets demonstrate that our method is computationally efficient,\nrobust to model misspecification, and consistently outperforms many existing\nnonlinear DAG learning methods.", "published": "2025-06-05 21:08:13", "link": "http://arxiv.org/abs/2506.05590v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Conformal Prediction Adaptive to Unknown Subpopulation Shifts", "abstract": "Conformal prediction is widely used to equip black-box machine learning\nmodels with uncertainty quantification enjoying formal coverage guarantees.\nHowever, these guarantees typically break down in the presence of distribution\nshifts, where the data distribution at test time differs from the training (or\ncalibration-time) distribution. In this work, we address subpopulation shifts,\nwhere the test environment exhibits an unknown and differing mixture of\nsubpopulations compared to the calibration data. We propose new methods that\nprovably adapt conformal prediction to such shifts, ensuring valid coverage\nwithout requiring explicit knowledge of subpopulation structure. Our algorithms\nscale to high-dimensional settings and perform effectively in realistic machine\nlearning tasks. Extensive experiments on vision (with vision transformers) and\nlanguage (with large language models) benchmarks demonstrate that our methods\nreliably maintain coverage and controls risk in scenarios where standard\nconformal prediction fails.", "published": "2025-06-05 20:58:39", "link": "http://arxiv.org/abs/2506.05583v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "When can in-context learning generalize out of task distribution?", "abstract": "In-context learning (ICL) is a remarkable capability of pretrained\ntransformers that allows models to generalize to unseen tasks after seeing only\na few examples. We investigate empirically the conditions necessary on the\npretraining distribution for ICL to emerge and generalize\n\\emph{out-of-distribution}. Previous work has focused on the number of distinct\ntasks necessary in the pretraining dataset. Here, we use a different notion of\ntask diversity to study the emergence of ICL in transformers trained on linear\nfunctions. We find that as task diversity increases, transformers undergo a\ntransition from a specialized solution, which exhibits ICL only within the\npretraining task distribution, to a solution which generalizes out of\ndistribution to the entire task space. We also investigate the nature of the\nsolutions learned by the transformer on both sides of the transition, and\nobserve similar transitions in nonlinear regression problems. We construct a\nphase diagram to characterize how our concept of task diversity interacts with\nthe number of pretraining tasks. In addition, we explore how factors such as\nthe depth of the model and the dimensionality of the regression problem\ninfluence the transition.", "published": "2025-06-05 20:30:50", "link": "http://arxiv.org/abs/2506.05574v1", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "q-bio.NC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Testing Hypotheses of Covariate Effects on Topics of Discourse", "abstract": "We introduce an approach to topic modelling with document-level covariates\nthat remains tractable in the face of large text corpora. This is achieved by\nde-emphasizing the role of parameter estimation in an underlying probabilistic\nmodel, assuming instead that the data come from a fixed but unknown\ndistribution whose statistical functionals are of interest. We propose\ncombining a convex formulation of non-negative matrix factorization with\nstandard regression techniques as a fast-to-compute and useful estimate of such\na functional. Uncertainty quantification can then be achieved by reposing\nnon-parametric resampling methods on top of this scheme. This is in contrast to\npopular topic modelling paradigms, which posit a complex and often hard-to-fit\ngenerative model of the data. We argue that the simple, non-parametric approach\nadvocated here is faster, more interpretable, and enjoys better inferential\njustification than said generative models. Finally, our methods are\ndemonstrated with an application analysing covariate effects on discourse of\nflavours attributed to Canadian beers.", "published": "2025-06-05 20:28:49", "link": "http://arxiv.org/abs/2506.05570v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Online Conformal Model Selection for Nonstationary Time Series", "abstract": "This paper introduces the MPS (Model Prediction Set), a novel framework for\nonline model selection for nonstationary time series. Classical model selection\nmethods, such as information criteria and cross-validation, rely heavily on the\nstationarity assumption and often fail in dynamic environments which undergo\ngradual or abrupt changes over time. Yet real-world data are rarely stationary,\nand model selection under nonstationarity remains a largely open problem. To\ntackle this challenge, we combine conformal inference with model confidence\nsets to develop a procedure that adaptively selects models best suited to the\nevolving dynamics at any given time. Concretely, the MPS updates in real time a\nconfidence set of candidate models that covers the best model for the next time\nperiod with a specified long-run probability, while adapting to nonstationarity\nof unknown forms. Through simulations and real-world data analysis, we\ndemonstrate that MPS reliably and efficiently identifies optimal models under\nnonstationarity, an essential capability lacking in offline methods. Moreover,\nMPS frequently produces high-quality sets with small cardinality, whose\nevolution offers deeper insights into changing dynamics. As a generic\nframework, MPS accommodates any data-generating process, data structure, model\nclass, training method, and evaluation metric, making it broadly applicable\nacross diverse problem settings.", "published": "2025-06-05 19:45:52", "link": "http://arxiv.org/abs/2506.05544v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "On Fitting Flow Models with Large Sinkhorn Couplings", "abstract": "Flow models transform data gradually from one modality (e.g. noise) onto\nanother (e.g. images). Such models are parameterized by a time-dependent\nvelocity field, trained to fit segments connecting pairs of source and target\npoints. When the pairing between source and target points is given, training\nflow models boils down to a supervised regression problem. When no such pairing\nexists, as is the case when generating data from noise, training flows is much\nharder. A popular approach lies in picking source and target points\nindependently. This can, however, lead to velocity fields that are slow to\ntrain, but also costly to integrate at inference time. In theory, one would\ngreatly benefit from training flow models by sampling pairs from an optimal\ntransport (OT) measure coupling source and target, since this would lead to a\nhighly efficient flow solving the Benamou and Brenier dynamical OT problem. In\npractice, recent works have proposed to sample mini-batches of $n$ source and\n$n$ target points and reorder them using an OT solver to form better pairs.\nThese works have advocated using batches of size $n\\approx 256$, and considered\nOT solvers that return couplings that are either sharp (using e.g. the\nHungarian algorithm) or blurred (using e.g. entropic regularization, a.k.a.\nSinkhorn). We follow in the footsteps of these works by exploring the benefits\nof increasing $n$ by three to four orders of magnitude, and look more carefully\non the effect of the entropic regularization $\\varepsilon$ used in the Sinkhorn\nalgorithm. Our analysis is facilitated by new scale invariant quantities to\nreport the sharpness of a coupling, while our sharded computations across\nmultiple GPU or GPU nodes allow scaling up $n$. We show that in both synthetic\nand image generation tasks, flow models greatly benefit when fitted with large\nSinkhorn couplings, with a low entropic regularization $\\varepsilon$.", "published": "2025-06-05 19:19:01", "link": "http://arxiv.org/abs/2506.05526v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Winner-takes-all for Multivariate Probabilistic Time Series Forecasting", "abstract": "We introduce TimeMCL, a method leveraging the Multiple Choice Learning (MCL)\nparadigm to forecast multiple plausible time series futures. Our approach\nemploys a neural network with multiple heads and utilizes the Winner-Takes-All\n(WTA) loss to promote diversity among predictions. MCL has recently gained\nattention due to its simplicity and ability to address ill-posed and ambiguous\ntasks. We propose an adaptation of this framework for time-series forecasting,\npresenting it as an efficient method to predict diverse futures, which we\nrelate to its implicit quantization objective. We provide insights into our\napproach using synthetic data and evaluate it on real-world time series,\ndemonstrating its promising performance at a light computational cost.", "published": "2025-06-05 18:56:14", "link": "http://arxiv.org/abs/2506.05515v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "The Generative Leap: Sharp Sample Complexity for Efficiently Learning Gaussian Multi-Index Models", "abstract": "In this work we consider generic Gaussian Multi-index models, in which the\nlabels only depend on the (Gaussian) $d$-dimensional inputs through their\nprojection onto a low-dimensional $r = O_d(1)$ subspace, and we study efficient\nagnostic estimation procedures for this hidden subspace. We introduce the\n\\emph{generative leap} exponent $k^\\star$, a natural extension of the\ngenerative exponent from [Damian et al.'24] to the multi-index setting. We\nfirst show that a sample complexity of $n=\\Theta(d^{1 \\vee \\k/2})$ is necessary\nin the class of algorithms captured by the Low-Degree-Polynomial framework. We\nthen establish that this sample complexity is also sufficient, by giving an\nagnostic sequential estimation procedure (that is, requiring no prior knowledge\nof the multi-index model) based on a spectral U-statistic over appropriate\nHermite tensors. We further compute the generative leap exponent for several\nexamples including piecewise linear functions (deep ReLU networks with bias),\nand general deep neural networks (with $r$-dimensional first hidden layer).", "published": "2025-06-05 18:34:56", "link": "http://arxiv.org/abs/2506.05500v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Zeroth-Order Optimization Finds Flat Minima", "abstract": "Zeroth-order methods are extensively used in machine learning applications\nwhere gradients are infeasible or expensive to compute, such as black-box\nattacks, reinforcement learning, and language model fine-tuning. Existing\noptimization theory focuses on convergence to an arbitrary stationary point,\nbut less is known on the implicit regularization that provides a fine-grained\ncharacterization on which particular solutions are finally reached. We show\nthat zeroth-order optimization with the standard two-point estimator favors\nsolutions with small trace of Hessian, which is widely used in previous work to\ndistinguish between sharp and flat minima. We further provide convergence rates\nof zeroth-order optimization to approximate flat minima for convex and\nsufficiently smooth functions, where flat minima are defined as the minimizers\nthat achieve the smallest trace of Hessian among all optimal solutions.\nExperiments on binary classification tasks with convex losses and language\nmodel fine-tuning support our theoretical findings.", "published": "2025-06-05 17:59:09", "link": "http://arxiv.org/abs/2506.05454v1", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Causal Effect Identification in lvLiNGAM from Higher-Order Cumulants", "abstract": "This paper investigates causal effect identification in latent variable\nLinear Non-Gaussian Acyclic Models (lvLiNGAM) using higher-order cumulants,\naddressing two prominent setups that are challenging in the presence of latent\nconfounding: (1) a single proxy variable that may causally influence the\ntreatment and (2) underspecified instrumental variable cases where fewer\ninstruments exist than treatments. We prove that causal effects are\nidentifiable with a single proxy or instrument and provide corresponding\nestimation methods. Experimental results demonstrate the accuracy and\nrobustness of our approaches compared to existing methods, advancing the\ntheoretical and practical understanding of causal inference in linear systems\nwith latent confounders.", "published": "2025-06-05 16:14:35", "link": "http://arxiv.org/abs/2506.05202v2", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "Improving Neural Diarization through Speaker Attribute Attractors and Local Dependency Modeling", "abstract": "In recent years, end-to-end approaches have made notable progress in\naddressing the challenge of speaker diarization, which involves segmenting and\nidentifying speakers in multi-talker recordings. One such approach,\nEncoder-Decoder Attractors (EDA), has been proposed to handle variable speaker\ncounts as well as better guide the network during training. In this study, we\nextend the attractor paradigm by moving beyond direct speaker modeling and\ninstead focus on representing more detailed `speaker attributes' through a\nmulti-stage process of intermediate representations. Additionally, we enhance\nthe architecture by replacing transformers with conformers, a\nconvolution-augmented transformer, to model local dependencies. Experiments\ndemonstrate improved diarization performance on the CALLHOME dataset.", "published": "2025-06-05 21:12:14", "link": "http://arxiv.org/abs/2506.05593v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "UAV-Based Remote Sensing of Soil Moisture Across Diverse Land Covers: Validation and Bayesian Uncertainty Characterization", "abstract": "High-resolution soil moisture (SM) observations are critical for agricultural\nmonitoring, forestry management, and hazard prediction, yet current satellite\npassive microwave missions cannot directly provide retrievals at tens-of-meter\nspatial scales. Unmanned aerial vehicle (UAV) mounted microwave radiometry\npresents a promising alternative, but most evaluations to date have focused on\nagricultural settings, with limited exploration across other land covers and\nfew efforts to quantify retrieval uncertainty. This study addresses both gaps\nby evaluating SM retrievals from a drone-based Portable L-band Radiometer\n(PoLRa) across shrubland, bare soil, and forest strips in Central Illinois,\nU.S., using a 10-day field campaign in 2024. Controlled UAV flights at\naltitudes of 10 m, 20 m, and 30 m were performed to generate brightness\ntemperatures (TB) at spatial resolutions of 7 m, 14 m, and 21 m. SM retrievals\nwere carried out using multiple tau-omega-based algorithms, including the\nsingle channel algorithm (SCA), dual channel algorithm (DCA), and\nmulti-temporal dual channel algorithm (MTDCA). A Bayesian inference framework\nwas then applied to provide probabilistic uncertainty characterization for both\nSM and vegetation optical depth (VOD). Results show that the gridded TB\ndistributions consistently capture dry-wet gradients associated with vegetation\ndensity variations, and spatial correlations between polarized observations are\nlargely maintained across scales. Validation against in situ measurements\nindicates that PoLRa derived SM retrievals from the SCAV and MTDCA algorithms\nachieve unbiased root-mean-square errors (ubRMSE) generally below 0.04 m3/m3\nacross different land covers. Bayesian posterior analyses confirm that\nreference SM values largely fall within the derived uncertainty intervals, with\nmean uncertainty ranges around 0.02 m3/m3 and 0.11 m3/m3 for SCA and DCA\nrelated retrievals.", "published": "2025-06-05 20:29:50", "link": "http://arxiv.org/abs/2506.05572v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MARS: Radio Map Super-resolution and Reconstruction Method under Sparse Channel Measurements", "abstract": "Radio maps reflect the spatial distribution of signal strength and are\nessential for applications like smart cities, IoT, and wireless network\nplanning. However, reconstructing accurate radio maps from sparse measurements\nremains challenging. Traditional interpolation and inpainting methods lack\nenvironmental awareness, while many deep learning approaches depend on detailed\nscene data, limiting generalization. To address this, we propose MARS, a\nMulti-scale Aware Radiomap Super-resolution method that combines CNNs and\nTransformers with multi-scale feature fusion and residual connections. MARS\nfocuses on both global and local feature extraction, enhancing feature\nrepresentation across different receptive fields and improving reconstruction\naccuracy. Experiments across different scenes and antenna locations show that\nMARS outperforms baseline models in both MSE and SSIM, while maintaining low\ncomputational cost, demonstrating strong practical potential.", "published": "2025-06-05 07:03:50", "link": "http://arxiv.org/abs/2506.04682v2", "categories": ["cs.CV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "An $O(log log n)$-approximate budget feasible mechanism for subadditive valuations", "abstract": "In budget-feasible mechanism design, there is a set of items $U$, each owned\nby a distinct seller. The seller of item $e$ incurs a private cost\n$\\overline{c}_e$ for supplying her item. A buyer wishes to procure a set of\nitems from the sellers of maximum value, where the value of a set $S\\subseteq\nU$ of items is given by a valuation function $v:2^U\\to \\mathbb{R}_+$. The buyer\nhas a budget of $B \\in \\mathbb{R}_+$ for the total payments made to the\nsellers. We wish to design a mechanism that is truthful, that is, sellers are\nincentivized to report their true costs, budget-feasible, that is, the sum of\nthe payments made to the sellers is at most the budget $B$, and that outputs a\nset whose value is large compared to $\\text{OPT}:=\\max\\{v(S):\\overline{c}(S)\\le\nB,S\\subseteq U\\}$.\n  Budget-feasible mechanism design has been extensively studied, with the\nliterature focussing on (classes of) subadditive valuation functions, and\nvarious polytime, budget-feasible mechanisms, achieving constant-factor\napproximation, have been devised for the special cases of additive, submodular,\nand XOS valuations. However, for general subadditive valuations, the best-known\napproximation factor achievable by a polytime budget-feasible mechanism (given\naccess to demand oracles) was only $O(\\log n / \\log \\log n)$, where $n$ is the\nnumber of items.\n  We improve this state-of-the-art significantly by designing a randomized\nbudget-feasible mechanism for subadditive valuations that \\emph{achieves a\nsubstantially-improved approximation factor of $O(\\log\\log n)$ and runs in\npolynomial time, given access to demand oracles.}", "published": "2025-06-05 06:21:33", "link": "http://arxiv.org/abs/2506.04665v2", "categories": ["cs.GT", "cs.DM", "cs.DS", "F.2.2; G.2; J.4"], "primary_category": "cs.GT"}
{"title": "Reason-to-Recommend: Using Interaction-of-Thought Reasoning to Enhance LLM Recommendation", "abstract": "Driven by advances in Large Language Models (LLMs), integrating them into\nrecommendation tasks has gained interest due to their strong semantic\nunderstanding and prompt flexibility. Prior work encoded user-item interactions\nor metadata into prompts for recommendations. In parallel, LLM reasoning,\nboosted by test-time scaling and reinforcement learning, has excelled in fields\nlike mathematics and code, where reasoning traces and correctness signals are\nclear, enabling high performance and interpretability. However, directly\napplying these reasoning methods to recommendation is ineffective because user\nfeedback is implicit and lacks reasoning supervision. To address this, we\npropose $\\textbf{R2Rec}$, a reasoning-enhanced recommendation framework that\nsamples interaction chains from the user-item graph and converts them into\nstructured interaction-of-thoughts via a progressive masked prompting strategy,\nwith each thought representing stepwise reasoning grounded in interaction\ncontext. This allows LLMs to simulate step-by-step decision-making based on\nimplicit patterns. We design a two-stage training pipeline: supervised\nfine-tuning teaches basic reasoning from high-quality traces, and reinforcement\nlearning refines reasoning via reward signals, alleviating sparse explicit\nsupervision. Experiments on three real-world datasets show R2Rec outperforms\nclassical and LLM-based baselines with an average $\\textbf{10.48%}$ improvement\nin HitRatio@1 and $\\textbf{131.81%}$ gain over the original LLM. Furthermore,\nthe explicit reasoning chains enhance interpretability by revealing the\ndecision process. Our code is available at:\nhttps://anonymous.4open.science/r/R2Rec-7C5D.", "published": "2025-06-05 14:16:44", "link": "http://arxiv.org/abs/2506.05069v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Context Is Not Comprehension", "abstract": "The dominant evaluation of Large Language Models has centered on their\nability to surface explicit facts from increasingly vast contexts. While\ntoday's best models demonstrate near-perfect recall on these tasks, this\napparent success masks a fundamental failure in multi-step computation when\ninformation is embedded in a narrative. We introduce Verbose ListOps (VLO), a\nnovel benchmark designed to isolate this failure. VLO programmatically weaves\ndeterministic, nested computations into coherent stories, forcing models to\ntrack and update internal state rather than simply locate explicit values. Our\nexperiments show that leading LLMs, capable of solving the raw ListOps\nequations with near-perfect accuracy, collapse in performance on VLO at just\n10k tokens. The VLO framework is extensible to any verifiable reasoning task,\nproviding a critical tool to move beyond simply expanding context windows and\nbegin building models with the robust, stateful comprehension required for\ncomplex knowledge work.", "published": "2025-06-05 11:41:05", "link": "http://arxiv.org/abs/2506.04907v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Model-based Neural Data Augmentation for sub-wavelength Radio Localization", "abstract": "The increasing deployment of large antenna arrays at base stations has\nsignificantly improved the spatial resolution and localization accuracy of\nradio-localization methods. However, traditional signal processing techniques\nstruggle in complex radio environments, particularly in scenarios dominated by\nnon line of sight (NLoS) propagation paths, resulting in degraded localization\naccuracy. Recent developments in machine learning have facilitated the\ndevelopment of machine learning-assisted localization techniques, enhancing\nlocalization accuracy in complex radio environments. However, these methods\noften involve substantial computational complexity during both the training and\ninference phases. This work extends the well-established fingerprinting-based\nlocalization framework by simultaneously reducing its memory requirements and\nimproving its accuracy. Specifically, a model-based neural network is used to\nlearn the location-to-channel mapping, and then serves as a generative neural\nchannel model. This generative model augments the fingerprinting comparison\ndictionary while reducing the memory requirements. The proposed method\noutperforms fingerprinting baselines by achieving sub-wavelength localization\naccuracy, even in NLoS environments. Remarkably, it offers an improvement by\nseveral orders of magnitude in localization accuracy, while simultaneously\nreducing memory requirements by an order of magnitude compared to classical\nfingerprinting methods.", "published": "2025-06-05 08:20:51", "link": "http://arxiv.org/abs/2506.06387v1", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "primary_category": "eess.SP"}
{"title": "On Fitting Flow Models with Large Sinkhorn Couplings", "abstract": "Flow models transform data gradually from one modality (e.g. noise) onto\nanother (e.g. images). Such models are parameterized by a time-dependent\nvelocity field, trained to fit segments connecting pairs of source and target\npoints. When the pairing between source and target points is given, training\nflow models boils down to a supervised regression problem. When no such pairing\nexists, as is the case when generating data from noise, training flows is much\nharder. A popular approach lies in picking source and target points\nindependently. This can, however, lead to velocity fields that are slow to\ntrain, but also costly to integrate at inference time. In theory, one would\ngreatly benefit from training flow models by sampling pairs from an optimal\ntransport (OT) measure coupling source and target, since this would lead to a\nhighly efficient flow solving the Benamou and Brenier dynamical OT problem. In\npractice, recent works have proposed to sample mini-batches of $n$ source and\n$n$ target points and reorder them using an OT solver to form better pairs.\nThese works have advocated using batches of size $n\\approx 256$, and considered\nOT solvers that return couplings that are either sharp (using e.g. the\nHungarian algorithm) or blurred (using e.g. entropic regularization, a.k.a.\nSinkhorn). We follow in the footsteps of these works by exploring the benefits\nof increasing $n$ by three to four orders of magnitude, and look more carefully\non the effect of the entropic regularization $\\varepsilon$ used in the Sinkhorn\nalgorithm. Our analysis is facilitated by new scale invariant quantities to\nreport the sharpness of a coupling, while our sharded computations across\nmultiple GPU or GPU nodes allow scaling up $n$. We show that in both synthetic\nand image generation tasks, flow models greatly benefit when fitted with large\nSinkhorn couplings, with a low entropic regularization $\\varepsilon$.", "published": "2025-06-05 19:19:01", "link": "http://arxiv.org/abs/2506.05526v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Restoration of contaminated data in an Intensity Mapping survey using deep neural networks", "abstract": "21-cm Intensity Mapping (IM) is a promising approach to detecting information\nabout the large-scale structure beyond the local universe. One of the biggest\nchallenges for an IM observation is the foreground removal procedure. In this\npaper, we attempt to conduct the restoration of contaminated data in an IM\nexperiment with a Deep Neural Network (DNN). To investigate the impact of such\ndata restoration, we compare the root-mean-square (RMS) of data with and\nwithout restoration after foreground removal using polynomial fitting, singular\nvalue decomposition, and independent component analysis, respectively. We find\nthat the DNN-based pipeline performs well in lowering the RMS level of data,\nespecially for data with large contaminated fractions. Furthermore, we\ninvestigate the impact of the restoration on the large-scale 21-cm signal in\nthe simulation generated by CRIME. Simulation results show that the angular\npower spectrum curves from data with restoration are closer to the real one.\nOur work demonstrates that the DNN-based data restoration approach\nsignificantly increases the signal-to-noise ratio compared with conventional\nones, achieving excellent potential for IM observations.", "published": "2025-06-05 07:29:04", "link": "http://arxiv.org/abs/2506.06386v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "An $O(\\log \\log n)$-approximate budget feasible mechanism for subadditive valuations", "abstract": "In budget-feasible mechanism design, there is a set of items $U$, each owned\nby a distinct seller. The seller of item $e$ incurs a private cost\n$\\overline{c}_e$ for supplying her item. A buyer wishes to procure a set of\nitems from the sellers of maximum value, where the value of a set $S\\subseteq\nU$ of items is given by a valuation function $v:2^U\\to \\mathbb{R}_+$. The buyer\nhas a budget of $B \\in \\mathbb{R}_+$ for the total payments made to the\nsellers. We wish to design a mechanism that is truthful, that is, sellers are\nincentivized to report their true costs, budget-feasible, that is, the sum of\nthe payments made to the sellers is at most the budget $B$, and that outputs a\nset whose value is large compared to $\\text{OPT}:=\\max\\{v(S):\\overline{c}(S)\\le\nB,S\\subseteq U\\}$.\n  Budget-feasible mechanism design has been extensively studied, with the\nliterature focussing on (classes of) subadditive valuation functions, and\nvarious polytime, budget-feasible mechanisms, achieving constant-factor\napproximation, have been devised for the special cases of additive, submodular,\nand XOS valuations. However, for general subadditive valuations, the best-known\napproximation factor achievable by a polytime budget-feasible mechanism (given\naccess to demand oracles) was only $O(\\log n / \\log \\log n)$, where $n$ is the\nnumber of items.\n  We improve this state-of-the-art significantly by designing a randomized\nbudget-feasible mechanism for subadditive valuations that achieves a\nsubstantially-improved approximation factor of $O(\\log\\log n)$ and runs in\npolynomial time, given access to demand oracles.", "published": "2025-06-05 06:21:33", "link": "http://arxiv.org/abs/2506.04665v3", "categories": ["cs.GT", "cs.DM", "cs.DS", "F.2.2; G.2; J.4"], "primary_category": "cs.GT"}
{"title": "Joint Routing and Control Optimization in VANET", "abstract": "In this paper, we introduce DynaRoute, an adaptive joint optimization\nframework for dynamic vehicular networks that simultaneously addresses platoon\ncontrol and data transmission through trajectory-aware routing and\nsafety-constrained vehicle coordination. DynaRoute guarantees continuous\nvehicle movement via platoon safety control with optimizing transmission paths\nthrough real-time trajectory prediction and ensuring reliable data. Our\nsolution achieves three key objectives: (1) maintaining platoon stability\nthrough accurate data transmission, (2) enabling adaptive routing based on\nvehicle movement patterns, and (3) enhancing overall intelligent transportation\nsystem performance. DynaRoute equires predefined traffic models and adapts to\ndynamic network conditions using local vehicle state information. We present\ncomprehensive simulation results demonstrating that DynaRoute maintains control\nand transmission performance in multiple complex scenarios while significantly\nimproving throughput and reliability compared to traditional approaches.", "published": "2025-06-05 09:30:00", "link": "http://arxiv.org/abs/2506.08038v1", "categories": ["eess.SY", "cs.MA", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Context Is Not Comprehension: Unmasking LLM reasoning blind spots with VLO", "abstract": "The dominant evaluation of Large Language Models has centered on their\nability to surface explicit facts from increasingly vast contexts. While\ntoday's best models demonstrate near-perfect recall on these tasks, this\napparent success is overly simplistic and non-representative of the complexity\nof human reasoning which is often highly nested. We introduce Verbose ListOps\n(VLO), a novel benchmark designed to isolate this failure. VLO programmatically\nweaves deterministic, nested computations into coherent stories, forcing models\nto track and update internal state rather than simply locate explicit values.\nOur experiments show that leading LLMs, capable of solving the raw ListOps\nequations with near-perfect accuracy, collapse in performance on VLO at just\n10k tokens. The extensibility of VLO's generation framework to any verifiable\nreasoning pattern will be a critical tool, enabling model developers to move\nbeyond context windows and robustly test new reasoning architectures; a\nnecessary step to automating the world's knowledge work.", "published": "2025-06-05 11:41:05", "link": "http://arxiv.org/abs/2506.04907v3", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Context Is Not Comprehension", "abstract": "The dominant way of judging Large Language Models (LLMs) has been to ask how\nwell they can recall explicit facts from very long inputs. While today's best\nmodels achieve near perfect recall, this masks a harder skill: performing\nmulti-step reasoning and tracking intermediate state that never appears\nverbatim. We introduce Verbose ListOps (VLO), a benchmark that embeds\ndeterministic ListOps computations inside narrative camouflage and, crucially,\nallows step-level evaluation of every intermediate result. Experiments show\nthat models which solve raw ListOps with approximately 100% accuracy collapse\non VLO after only 10,000 tokens. By exposing where a model's reasoning chain\nfirst diverges, VLO moves assessment beyond sheer context length and toward\ngenuine comprehension. VLO's generation pipeline is task-agnostic: it can weave\nany deterministically verifiable reasoning schema -- arithmetic, symbolic,\nabductive, inductive or defeasible -- into narrative form. This makes VLO a\nreusable test-bed for the next wave of reasoning-centric model designs, not\nmerely those with step-explicit scaffolds.", "published": "2025-06-05 11:41:05", "link": "http://arxiv.org/abs/2506.04907v4", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Upper bounds on the Holevo quantity arising from the fundamental entropic inequality", "abstract": "We show how the fundamental entropic inequality proved recently in\n[arXiv:2408.15306] can be applied to obtain a useful relation for the Holevo\nquantity of discrete and continuous ensembles of quantum states.\n  This relation gives a tight upper bound on the Holevo quantity of a given\nensemble $\\mu$ expressed in terms of the Holevo quantities of two auxiliary\nensembles $\\mu_+$ and $\\mu_-$ produced by $\\mu$. Among others, this implies\nquite accurate upper bounds on the Holevo quantity of a discrete ensemble of\nquantum states expressed via the probabilities and the metric characteristics\nof an ensemble.", "published": "2025-06-05 17:59:26", "link": "http://arxiv.org/abs/2506.05335v2", "categories": ["quant-ph", "cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "quant-ph"}
{"title": "Modern approaches to building effective interpretable models of the property market using machine learning", "abstract": "In this article, we review modern approaches to building interpretable models\nof property markets using machine learning on the base of mass valuation of\nproperty in the Primorye region, Russia. The researcher, lacking expertise in\nthis topic, encounters numerous difficulties in the effort to build a good\nmodel. The main source of this is the huge difference between noisy real market\ndata and ideal data which is very common in all types of tutorials on machine\nlearning. This paper covers all stages of modeling: the collection of initial\ndata, identification of outliers, the search and analysis of patterns in data,\nthe formation and final choice of price factors, the building of the model, and\nthe evaluation of its efficiency. For each stage, we highlight potential issues\nand describe sound methods for overcoming emerging difficulties on actual\nexamples. We show that the combination of classical linear regression with\ninterpolation methods of geostatistics allows to build an effective model for\nland parcels. For flats, when many objects are attributed to one spatial point\nthe application of geostatistical methods is difficult. Therefore we suggest\nlinear regression with automatic generation and selection of additional rules\non the base of decision trees, so called the RuleFit method. Thus we show, that\ndespite the strong restriction as the requirement of interpretability which is\nimportant in practical aspects, for example, legal matters, it is still\npossible to build effective models of real property markets.", "published": "2025-06-05 13:17:18", "link": "http://arxiv.org/abs/2506.15723v1", "categories": ["q-fin.ST", "cs.LG", "econ.GN", "q-fin.EC", "stat.AP"], "primary_category": "q-fin.ST"}
