{"title": "MCI-GRU: Stock Prediction Model Based on Multi-Head Cross-Attention and Improved GRU", "abstract": "As financial markets grow increasingly complex in the big data era, accurate\nstock prediction has become more critical. Traditional time series models, such\nas GRUs, have been widely used but often struggle to capture the intricate\nnonlinear dynamics of markets, particularly in the flexible selection and\neffective utilization of key historical information. Recently, methods like\nGraph Neural Networks and Reinforcement Learning have shown promise in stock\nprediction but require high data quality and quantity, and they tend to exhibit\ninstability when dealing with data sparsity and noise. Moreover, the training\nand inference processes for these models are typically complex and\ncomputationally expensive, limiting their broad deployment in practical\napplications. Existing approaches also generally struggle to capture\nunobservable latent market states effectively, such as market sentiment and\nexpectations, microstructural factors, and participant behavior patterns,\nleading to an inadequate understanding of market dynamics and subsequently\nimpact prediction accuracy. To address these challenges, this paper proposes a\nstock prediction model, MCI-GRU, based on a multi-head cross-attention\nmechanism and an improved GRU. First, we enhance the GRU model by replacing the\nreset gate with an attention mechanism, thereby increasing the model's\nflexibility in selecting and utilizing historical information. Second, we\ndesign a multi-head cross-attention mechanism for learning unobservable latent\nmarket state representations, which are further enriched through interactions\nwith both temporal features and cross-sectional features. Finally, extensive\nexperiments on four main stock markets show that the proposed method\noutperforms SOTA techniques across multiple metrics. Additionally, its\nsuccessful application in real-world fund management operations confirms its\neffectiveness and practicality.", "published": "2024-09-25 14:37:49", "link": "http://arxiv.org/abs/2410.20679v2", "categories": ["q-fin.ST", "cs.LG", "q-fin.CP"], "primary_category": "q-fin.ST"}
{"title": "Interlacing Eigenvectors of Large Gaussian Matrices", "abstract": "We consider the eigenvectors of the principal minor of dimension $n< N$ of\nthe Dyson Brownian motion in $\\mathbb{R}^{N}$ and investigate their asymptotic\noverlaps with the eigenvectors of the full matrix in the limit of large\ndimension. We explicitly compute the limiting rescaled mean squared overlaps in\nthe large $n\\,, N$ limit with $n\\,/\\,N$ tending to a fixed ratio $q\\,$, for any\ninitial symmetric matrix $A\\,$. This is accomplished using a Burgers-type\nevolution equation for a specific resolvent. In the GOE case, our formula\nsimplifies, and we identify an eigenvector analogue of the well-known\ninterlacing of eigenvalues. We investigate in particular the case where $A$ has\nisolated eigenvalues. Our method is based on analysing the eigenvector flow\nunder the Dyson Brownian motion.", "published": "2024-09-25 16:49:43", "link": "http://arxiv.org/abs/2409.17086v1", "categories": ["math.PR", "cond-mat.stat-mech", "q-fin.MF"], "primary_category": "math.PR"}
{"title": "Trading through Earnings Seasons using Self-Supervised Contrastive Representation Learning", "abstract": "Earnings release is a key economic event in the financial markets and crucial\nfor predicting stock movements. Earnings data gives a glimpse into how a\ncompany is doing financially and can hint at where its stock might go next.\nHowever, the irregularity of its release cycle makes it a challenge to\nincorporate this data in a medium-frequency algorithmic trading model and the\nusefulness of this data fades fast after it is released, making it tough for\nmodels to stay accurate over time. Addressing this challenge, we introduce the\nContrastive Earnings Transformer (CET) model, a self-supervised learning\napproach rooted in Contrastive Predictive Coding (CPC), aiming to optimise the\nutilisation of earnings data. To ascertain its effectiveness, we conduct a\ncomparative study of CET against benchmark models across diverse sectors. Our\nresearch delves deep into the intricacies of stock data, evaluating how various\nmodels, and notably CET, handle the rapidly changing relevance of earnings data\nover time and over different sectors. The research outcomes shed light on CET's\ndistinct advantage in extrapolating the inherent value of earnings data over\ntime. Its foundation on CPC allows for a nuanced understanding, facilitating\nconsistent stock predictions even as the earnings data ages. This finding about\nCET presents a fresh approach to better use earnings data in algorithmic\ntrading for predicting stock price trends.", "published": "2024-09-25 22:09:59", "link": "http://arxiv.org/abs/2409.17392v1", "categories": ["cs.LG", "q-fin.TR"], "primary_category": "cs.LG"}
{"title": "The Impact of Designated Market Makers on Market Liquidity and Competition: A Simulation Approach", "abstract": "This paper conducts an empirical investigation into the effects of Designated\nMarket Makers (DMMs) on key market quality indicators, such as liquidity,\nbid-ask spreads, and order fulfillment ratios. Through agent-based simulations,\nthis study explores the impact of varying competition levels and incentive\nstructures among DMMs on market dynamics. It aims to demonstrate that DMMs are\ncrucial for enhancing market liquidity and stabilizing price spreads, thereby\naffirming their essential role in promoting market efficiency. Our findings\nconfirm the impact of the number of Designated Market Makers (DMMs) and asset\ndiversity on market liquidity. The result also suggests that an optimal level\nof competition among DMMs can maximize liquidity benefits while minimizing\nnegative impacts on price discovery. Additionally, the research indicates that\nthe benefits of increased number of DMMs diminish beyond a certain threshold,\nimplying that excessive incentives may not further improve market quality\nmetrics.", "published": "2024-09-25 03:32:50", "link": "http://arxiv.org/abs/2409.16589v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
