{"title": "DeFi Arbitrage in Hedged Liquidity Tokens", "abstract": "Empirically, the prevailing market prices for liquidity tokens of the\nconstant product market maker (CPMM) -- as offered in practice by companies\nsuch as Uniswap -- readily permit arbitrage opportunities by delta hedging the\nrisk of the position. Herein, we investigate this arbitrage opportunity by\ntreating the liquidity token as a derivative position in the prices of the\nunderlying assets for the CPMM. In doing so, not dissimilar to the\nBlack-Scholes result, we deduce risk-neutral pricing and hedging formulas for\nthese liquidity tokens. Furthermore, with our novel pricing formula, we\nconstruct a method to calibrate a volatility to data which provides an updated\n(non-market) price which would not permit arbitrage if quoted by the CPMM. We\nconclude with a discussion of novel AMM designs which would bring the pricing\nof liquidity tokens into the modern financial era.", "published": "2024-09-17 16:41:58", "link": "http://arxiv.org/abs/2409.11339v2", "categories": ["q-fin.MF", "q-fin.PR", "q-fin.RM"], "primary_category": "q-fin.MF"}
{"title": "Unlocking NACE Classification Embeddings with OpenAI for Enhanced Analysis and Processing", "abstract": "The Statistical Classification of Economic Activities in the European\nCommunity (NACE) is the standard classification system for the categorization\nof economic and industrial activities within the European Union. This paper\nproposes a novel approach to transform the NACE classification into\nlow-dimensional embeddings, using state-of-the-art models and dimensionality\nreduction techniques. The primary challenge is the preservation of the\nhierarchical structure inherent within the original NACE classification while\nreducing the number of dimensions. To address this issue, we introduce custom\nmetrics designed to quantify the retention of hierarchical relationships\nthroughout the embedding and reduction processes. The evaluation of these\nmetrics demonstrates the effectiveness of the proposed methodology in retaining\nthe structural information essential for insightful analysis. This approach not\nonly facilitates the visual exploration of economic activity relationships, but\nalso increases the efficacy of downstream tasks, including clustering,\nclassification, integration with other classifications, and others. Through\nexperimental validation, the utility of our proposed framework in preserving\nhierarchical structures within the NACE classification is showcased, thereby\nproviding a valuable tool for researchers and policymakers to understand and\nleverage any hierarchical data.", "published": "2024-09-17 19:49:46", "link": "http://arxiv.org/abs/2409.11524v1", "categories": ["cs.LG", "econ.GN", "q-fin.EC", "q-fin.ST", "62M45, 91G40", "G.3; I.2"], "primary_category": "cs.LG"}
{"title": "Value of Information in the Mean-Square Case and its Application to the Analysis of Financial Time-Series Forecast", "abstract": "The advances and development of various machine learning techniques has lead\nto practical solutions in various areas of science, engineering, medicine and\nfinance. The great choice of algorithms, their implementations and libraries\nhas resulted in another challenge of selecting the right algorithm and tuning\ntheir parameters in order to achieve optimal or satisfactory performance in\nspecific applications. Here we show how the value of information (V(I)) can be\nused in this task to guide the algorithm choice and parameter tuning process.\nAfter estimating the amount of Shannon's mutual information between the\npredictor and response variables, V(I) can define theoretical upper bound of\nperformance of any algorithm. The inverse function I(V) defines the lower\nfrontier of the minimum amount of information required to achieve the desired\nperformance. In this paper, we illustrate the value of information for the\nmean-square error minimization and apply it to forecasts of cryptocurrency\nlog-returns.", "published": "2024-09-17 17:53:54", "link": "http://arxiv.org/abs/2410.01831v1", "categories": ["q-fin.ST", "94A15, 94A17, 94A34, 62J12, 62M45, 60G25"], "primary_category": "q-fin.ST"}
{"title": "Macroscopic properties of equity markets: stylized facts and portfolio performance", "abstract": "Macroscopic properties of equity markets affect the performance of active\nequity strategies but many are not adequately captured by conventional models\nof financial mathematics and econometrics. Using the CRSP Database of the US\nequity market, we study empirically several macroscopic properties defined in\nterms of market capitalizations and returns, and highlight a list of stylized\nfacts and open questions motivated in part by stochastic portfolio theory.\nAdditionally, we present a systematic backtest of the diversity-weighted\nportfolio under various configurations and study its performance in relation to\nmacroscopic quantities. All of our results can be replicated using codes made\navailable on our online repository.", "published": "2024-09-17 02:49:20", "link": "http://arxiv.org/abs/2409.10859v3", "categories": ["q-fin.ST"], "primary_category": "q-fin.ST"}
{"title": "ReXErr: Synthesizing Clinically Meaningful Errors in Diagnostic\n  Radiology Reports", "abstract": "Accurately interpreting medical images and writing radiology reports is a\ncritical but challenging task in healthcare. Both human-written and\nAI-generated reports can contain errors, ranging from clinical inaccuracies to\nlinguistic mistakes. To address this, we introduce ReXErr, a methodology that\nleverages Large Language Models to generate representative errors within chest\nX-ray reports. Working with board-certified radiologists, we developed error\ncategories that capture common mistakes in both human and AI-generated reports.\nOur approach uses a novel sampling scheme to inject diverse errors while\nmaintaining clinical plausibility. ReXErr demonstrates consistency across error\ncategories and produces errors that closely mimic those found in real-world\nscenarios. This method has the potential to aid in the development and\nevaluation of report correction algorithms, potentially enhancing the quality\nand reliability of radiology reporting.", "published": "2024-09-17 01:42:39", "link": "http://arxiv.org/abs/2409.10829v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "American Sign Language to Text Translation using Transformer and Seq2Seq\n  with LSTM", "abstract": "Sign language translation is one of the important issues in communication\nbetween deaf and hearing people, as it expresses words through hand, body, and\nmouth movements. American Sign Language is one of the sign languages used, one\nof which is the alphabetic sign. The development of neural machine translation\ntechnology is moving towards sign language translation. Transformer became the\nstate-of-the-art in natural language processing. This study compares the\nTransformer with the Sequence-to-Sequence (Seq2Seq) model in translating sign\nlanguage to text. In addition, an experiment was conducted by adding Residual\nLong Short-Term Memory (ResidualLSTM) in the Transformer. The addition of\nResidualLSTM to the Transformer reduces the performance of the Transformer\nmodel by 23.37% based on the BLEU Score value. In comparison, the Transformer\nitself increases the BLEU Score value by 28.14 compared to the Seq2Seq model.", "published": "2024-09-17 04:00:33", "link": "http://arxiv.org/abs/2409.10874v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CREAM: Comparison-Based Reference-Free ELO-Ranked Automatic Evaluation\n  for Meeting Summarization", "abstract": "Large Language Models (LLMs) have spurred interest in automatic evaluation\nmethods for summarization, offering a faster, more cost-effective alternative\nto human evaluation. However, existing methods often fall short when applied to\ncomplex tasks like long-context summarizations and dialogue-based meeting\nsummarizations. In this paper, we introduce CREAM (Comparison-Based\nReference-Free Elo-Ranked Automatic Evaluation for Meeting Summarization), a\nnovel framework that addresses the unique challenges of evaluating meeting\nsummaries. CREAM leverages a combination of chain-of-thought reasoning and key\nfacts alignment to assess conciseness and completeness of model-generated\nsummaries without requiring reference. By employing an ELO ranking system, our\napproach provides a robust mechanism for comparing the quality of different\nmodels or prompt configurations.", "published": "2024-09-17 04:39:20", "link": "http://arxiv.org/abs/2409.10883v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Propulsion: Steering LLM with Tiny Fine-Tuning", "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\nnatural language processing (NLP) and related fields. However, fine-tuning\nthese models for specific tasks remains computationally expensive and risks\ndegrading pre-learned features. To address these challenges, we propose\nPropulsion, a novel parameter efficient fine-tuning (PEFT) method designed to\noptimize task-specific performance while drastically reducing computational\noverhead. Inspired by the concept of controlled adjustments in physical motion,\nPropulsion selectively re-scales specific dimensions of a pre-trained model,\nguiding output predictions toward task objectives without modifying the model's\nparameters. By introducing lightweight, trainable Propulsion parameters at the\npre-trained layer, we minimize the number of parameters updated during\nfine-tuning, preventing overfitting or overwriting of existing knowledge. Our\ntheoretical analysis, supported by Neural Tangent Kernel (NTK) theory, shows\nthat Propulsion approximates the performance of full fine-tuning with far fewer\ntrainable parameters. Empirically, Propulsion reduces the parameter count from\n355.3 million to just 0.086 million, achieving over a 10x reduction compared to\nstandard approaches like LoRA while maintaining competitive performance across\nbenchmarks.", "published": "2024-09-17 06:51:59", "link": "http://arxiv.org/abs/2409.10927v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Contextual Breach: Assessing the Robustness of Transformer-based QA\n  Models", "abstract": "Contextual question-answering models are susceptible to adversarial\nperturbations to input context, commonly observed in real-world scenarios.\nThese adversarial noises are designed to degrade the performance of the model\nby distorting the textual input. We introduce a unique dataset that\nincorporates seven distinct types of adversarial noise into the context, each\napplied at five different intensity levels on the SQuAD dataset. To quantify\nthe robustness, we utilize robustness metrics providing a standardized measure\nfor assessing model performance across varying noise types and levels.\nExperiments on transformer-based question-answering models reveal robustness\nvulnerabilities and important insights into the model's performance in\nrealistic textual input.", "published": "2024-09-17 09:00:11", "link": "http://arxiv.org/abs/2409.10997v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Narrative Analysis: Unraveling Perceptions of Generative AI", "abstract": "Written texts reflect an author's perspective, making the thorough analysis\nof literature a key research method in fields such as the humanities and social\nsciences. However, conventional text mining techniques like sentiment analysis\nand topic modeling are limited in their ability to capture the hierarchical\nnarrative structures that reveal deeper argumentative patterns. To address this\ngap, we propose a method that leverages large language models (LLMs) to extract\nand organize these structures into a hierarchical framework. We validate this\napproach by analyzing public opinions on generative AI collected by Japan's\nAgency for Cultural Affairs, comparing the narratives of supporters and\ncritics. Our analysis provides clearer visualization of the factors influencing\ndivergent opinions on generative AI, offering deeper insights into the\nstructures of agreement and disagreement.", "published": "2024-09-17 09:56:12", "link": "http://arxiv.org/abs/2409.11032v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards No-Code Programming of Cobots: Experiments with Code Synthesis\n  by Large Code Models for Conversational Programming", "abstract": "While there has been a lot of research recently on robots in household\nenvironments, at the present time, most robots in existence can be found on\nshop floors, and most interactions between humans and robots happen there.\n``Collaborative robots'' (cobots) designed to work alongside humans on assembly\nlines traditionally require expert programming, limiting ability to make\nchanges, or manual guidance, limiting expressivity of the resulting programs.\nTo address these limitations, we explore using Large Language Models (LLMs),\nand in particular, their abilities of doing in-context learning, for\nconversational code generation. As a first step, we define RATS, the\n``Repetitive Assembly Task'', a 2D building task designed to lay the foundation\nfor simulating industry assembly scenarios. In this task, a `programmer'\ninstructs a cobot, using natural language, on how a certain assembly is to be\nbuilt; that is, the programmer induces a program, through natural language. We\ncreate a dataset that pairs target structures with various example instructions\n(human-authored, template-based, and model-generated) and example code. With\nthis, we systematically evaluate the capabilities of state-of-the-art LLMs for\nsynthesising this kind of code, given in-context examples. Evaluating in a\nsimulated environment, we find that LLMs are capable of generating accurate\n`first order code' (instruction sequences), but have problems producing\n`higher-order code' (abstractions such as functions, or use of loops).", "published": "2024-09-17 10:04:50", "link": "http://arxiv.org/abs/2409.11041v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models are Good Multi-lingual Learners : When LLMs Meet\n  Cross-lingual Prompts", "abstract": "With the advent of Large Language Models (LLMs), generating rule-based data\nfor real-world applications has become more accessible. Due to the inherent\nambiguity of natural language and the complexity of rule sets, especially in\nlong contexts, LLMs often struggle to follow all specified rules, frequently\nomitting at least one. To enhance the reasoning and understanding of LLMs on\nlong and complex contexts, we propose a novel prompting strategy Multi-Lingual\nPrompt, namely MLPrompt, which automatically translates the error-prone rule\nthat an LLM struggles to follow into another language, thus drawing greater\nattention to it. Experimental results on public datasets across various tasks\nhave shown MLPrompt can outperform state-of-the-art prompting methods such as\nChain of Thought, Tree of Thought, and Self-Consistency. Additionally, we\nintroduce a framework integrating MLPrompt with an auto-checking mechanism for\nstructured data generation, with a specific case study in text-to-MIP\ninstances. Further, we extend the proposed framework for text-to-SQL to\ndemonstrate its generation ability towards structured data synthesis.", "published": "2024-09-17 10:33:27", "link": "http://arxiv.org/abs/2409.11056v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KVPruner: Structural Pruning for Faster and Memory-Efficient Large\n  Language Models", "abstract": "The bottleneck associated with the key-value(KV) cache presents a significant\nchallenge during the inference processes of large language models. While depth\npruning accelerates inference, it requires extensive recovery training, which\ncan take up to two weeks. On the other hand, width pruning retains much of the\nperformance but offers slight speed gains. To tackle these challenges, we\npropose KVPruner to improve model efficiency while maintaining performance. Our\nmethod uses global perplexity-based analysis to determine the importance ratio\nfor each block and provides multiple strategies to prune non-essential KV\nchannels within blocks. Compared to the original model, KVPruner reduces\nruntime memory usage by 50% and boosts throughput by over 35%. Additionally,\nour method requires only two hours of LoRA fine-tuning on small datasets to\nrecover most of the performance.", "published": "2024-09-17 10:35:30", "link": "http://arxiv.org/abs/2409.11057v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semformer: Transformer Language Models with Semantic Planning", "abstract": "Next-token prediction serves as the dominant component in current neural\nlanguage models. During the training phase, the model employs teacher forcing,\nwhich predicts tokens based on all preceding ground truth tokens. However, this\napproach has been found to create shortcuts, utilizing the revealed prefix to\nspuriously fit future tokens, potentially compromising the accuracy of the\nnext-token predictor. In this paper, we introduce Semformer, a novel method of\ntraining a Transformer language model that explicitly models the semantic\nplanning of response. Specifically, we incorporate a sequence of planning\ntokens into the prefix, guiding the planning token representations to predict\nthe latent semantic representations of the response, which are induced by an\nautoencoder. In a minimal planning task (i.e., graph path-finding), our model\nexhibits near-perfect performance and effectively mitigates shortcut learning,\na feat that standard training methods and baseline models have been unable to\naccomplish. Furthermore, we pretrain Semformer from scratch with 125M\nparameters, demonstrating its efficacy through measures of perplexity,\nin-context learning, and fine-tuning on summarization tasks.", "published": "2024-09-17 12:54:34", "link": "http://arxiv.org/abs/2409.11143v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reasoning Graph Enhanced Exemplars Retrieval for In-Context Learning", "abstract": "Large language models (LLMs) have exhibited remarkable few-shot learning\ncapabilities and unified the paradigm of NLP tasks through the in-context\nlearning (ICL) technique. Despite the success of ICL, the quality of the\nexemplar demonstrations can significantly influence the LLM's performance.\nExisting exemplar selection methods mainly focus on the semantic similarity\nbetween queries and candidate exemplars. On the other hand, the logical\nconnections between reasoning steps can be beneficial to depict the\nproblem-solving process as well. In this paper, we proposes a novel method\nnamed Reasoning Graph-enhanced Exemplar Retrieval (RGER). RGER first quires LLM\nto generate an initial response, then expresses intermediate problem-solving\nsteps to a graph structure. After that, it employs graph kernel to select\nexemplars with semantic and structural similarity. Extensive experiments\ndemonstrate the structural relationship is helpful to the alignment of queries\nand candidate exemplars. The efficacy of RGER on math and logit reasoning tasks\nshowcases its superiority over state-of-the-art retrieval-based approaches. Our\ncode is released at https://github.com/Yukang-Lin/RGER.", "published": "2024-09-17 12:58:29", "link": "http://arxiv.org/abs/2409.11147v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SAGED: A Holistic Bias-Benchmarking Pipeline for Language Models with\n  Customisable Fairness Calibration", "abstract": "The development of unbiased large language models is widely recognized as\ncrucial, yet existing benchmarks fall short in detecting biases due to limited\nscope, contamination, and lack of a fairness baseline. SAGED(bias) is the first\nholistic benchmarking pipeline to address these problems. The pipeline\nencompasses five core stages: scraping materials, assembling benchmarks,\ngenerating responses, extracting numeric features, and diagnosing with\ndisparity metrics. SAGED includes metrics for max disparity, such as impact\nratio, and bias concentration, such as Max Z-scores. Noticing that metric tool\nbias and contextual bias in prompts can distort evaluation, SAGED implements\ncounterfactual branching and baseline calibration for mitigation. For\ndemonstration, we use SAGED on G20 Countries with popular 8b-level models\nincluding Gemma2, Llama3.1, Mistral, and Qwen2. With sentiment analysis, we\nfind that while Mistral and Qwen2 show lower max disparity and higher bias\nconcentration than Gemma2 and Llama3.1, all models are notably biased against\ncountries like Russia and (except for Qwen2) China. With further experiments to\nhave models role-playing U.S. presidents, we see bias amplifies and shifts in\nheterogeneous directions. Moreover, we see Qwen2 and Mistral not engage in\nrole-playing, while Llama3.1 and Gemma2 role-play Trump notably more\nintensively than Biden and Harris, indicating role-playing performance bias in\nthese models.", "published": "2024-09-17 13:03:12", "link": "http://arxiv.org/abs/2409.11149v7", "categories": ["cs.CL", "68T50", "I.2.7; F.4.2"], "primary_category": "cs.CL"}
{"title": "Self-Evolutionary Large Language Models through Uncertainty-Enhanced\n  Preference Optimization", "abstract": "Iterative preference optimization has recently become one of the de-facto\ntraining paradigms for large language models (LLMs), but the performance is\nstill underwhelming due to too much noisy preference data yielded in the loop.\nTo combat this issue, we present an \\textbf{U}ncertainty-enhanced\n\\textbf{P}reference \\textbf{O}ptimization (UPO) framework to make the LLM\nself-evolve with reliable feedback. The key idea is mitigating the noisy\npreference data derived from the current policy and reward models by performing\npair-wise uncertainty estimation and judiciously reliable feedback sampling. To\nreach this goal, we thus introduce an estimator model, which incorporates Monte\nCarlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty\nestimation for the preference data derived from the LLM policy. Compared to the\nexisting methods that directly filter generated responses based on the reward\nscore, the estimator focuses on the model uncertainty in a pair-wise manner and\neffectively bypasses the confirmation bias problem of the reward model.\nAdditionally, we also propose an uncertainty-enhanced self-evolution algorithm\nto improve the robustness of preference optimization and encourage the LLM to\ngenerate responses with both high reward and certainty. Extensive experiments\nover multiple benchmarks demonstrate that our framework substantially\nalleviates the noisy problem and improves the performance of iterative\npreference optimization.", "published": "2024-09-17 14:05:58", "link": "http://arxiv.org/abs/2409.11212v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring ChatGPT-based Augmentation Strategies for Contrastive\n  Aspect-based Sentiment Analysis", "abstract": "Aspect-based sentiment analysis (ABSA) involves identifying sentiment towards\nspecific aspect terms in a sentence and allows us to uncover nuanced\nperspectives and attitudes on particular aspects of a product, service, or\ntopic. However, the scarcity of labeled data poses a significant challenge to\ntraining high-quality models. To address this issue, we explore the potential\nof data augmentation using ChatGPT, a well-performing large language model\n(LLM), to enhance the sentiment classification performance towards aspect\nterms. Specifically, we explore three data augmentation strategies based on\nChatGPT: context-focused, aspect-focused, and context-aspect data augmentation\ntechniques. Context-focused data augmentation focuses on changing the word\nexpression of context words in the sentence while keeping aspect terms\nunchanged. In contrast, aspect-focused data augmentation aims to change aspect\nterms but keep context words unchanged. Context-Aspect data augmentation\nintegrates the above two data augmentations to generate augmented samples.\nFurthermore, we incorporate contrastive learning into the ABSA tasks to improve\nperformance. Extensive experiments show that all three data augmentation\ntechniques lead to performance improvements, with the context-aspect data\naugmentation strategy performing best and surpassing the performance of the\nbaseline models.", "published": "2024-09-17 14:12:08", "link": "http://arxiv.org/abs/2409.11218v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Impact of Compression Techniques on Task-Specific\n  Performance of Large Language Models", "abstract": "Large language models (LLMs) offer powerful capabilities but incur\nsubstantial computational costs, driving the need for efficient compression\ntechniques. This study evaluates the impact of popular compression methods -\nMagnitude Pruning, SparseGPT, and Wanda - on the LLaMA-2-7B model, focusing on\nthe trade-offs between model size reduction, downstream task performance, and\nthe role of calibration data. Our findings reveal that while SparseGPT and\nWanda preserve perplexity even at 50% sparsity, they suffer significant\ndegradation on downstream tasks, highlighting the inadequacy of perplexity as\nthe sole evaluation metric. To address this, we introduce Jensen-Shannon (JS)\nDivergence as a more comprehensive metric that captures nuanced changes in\nmodel behavior post-compression. We further demonstrate that task-specific\ncalibration data significantly enhances the downstream performance of\ncompressed models compared to general calibration data. This research\nunderscores the necessity for diverse evaluation metrics and careful\ncalibration data selection to fully understand the complexities of LLM\ncompression and its implications for practical applications.", "published": "2024-09-17 14:34:11", "link": "http://arxiv.org/abs/2409.11233v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-as-a-Judge & Reward Model: What They Can and Cannot Do", "abstract": "LLM-as-a-Judge and reward models are widely used alternatives of\nmultiple-choice questions or human annotators for large language model (LLM)\nevaluation. Their efficacy shines in evaluating long-form responses, serving a\ncritical role as evaluators of leaderboards and as proxies to align LLMs via\nreinforcement learning. However, despite their popularity, their effectiveness\nin diverse contexts, such as non-English prompts, factual verification, or\nchallenging questions, remains unexplored. In this paper, we conduct a\ncomprehensive analysis of automated evaluators, reporting several key findings\non their behavior. First, we discover that English evaluation capabilities\nsignificantly influence language-specific evaluation capabilities, often more\nthan the language proficiency itself, enabling evaluators trained in English to\neasily transfer their skills to other languages. Second, we identify critical\nshortcomings, where LLMs fail to detect and penalize errors, such as factual\ninaccuracies, cultural misrepresentations, and the presence of unwanted\nlanguage. Finally, we find that state-of-the-art evaluators struggle with\nchallenging prompts, in either English or Korean, underscoring their\nlimitations in assessing or generating complex reasoning questions. We release\nthe dataset and codes used.", "published": "2024-09-17 14:40:02", "link": "http://arxiv.org/abs/2409.11239v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded\n  Attributions and Learning to Refuse", "abstract": "LLMs are an integral component of retrieval-augmented generation (RAG)\nsystems. While many studies focus on evaluating the overall quality of\nend-to-end RAG systems, there is a gap in understanding the appropriateness of\nLLMs for the RAG task. To address this, we introduce Trust-Score, a holistic\nmetric that evaluates the trustworthiness of LLMs within the RAG framework. Our\nresults show that various prompting methods, such as in-context learning, fail\nto effectively adapt LLMs to the RAG task as measured by Trust-Score.\nConsequently, we propose Trust-Align, a method to align LLMs for improved\nTrust-Score performance. 26 out of 27 models aligned using Trust-Align\nsubstantially outperform competitive baselines on ASQA, QAMPARI, and ELI5.\nSpecifically, in LLaMA-3-8b, Trust-Align outperforms FRONT on ASQA (up 12.56),\nQAMPARI (up 36.04), and ELI5 (up 17.69). Trust-Align also significantly\nenhances models' ability to correctly refuse and provide quality citations. We\nalso demonstrate the effectiveness of Trust-Align across different open-weight\nmodels, including the LLaMA series (1b to 8b), Qwen-2.5 series (0.5b to 7b),\nand Phi3.5 (3.8b). We release our code at\nhttps://github.com/declare-lab/trust-align.", "published": "2024-09-17 14:47:33", "link": "http://arxiv.org/abs/2409.11242v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Linear Recency Bias During Training Improves Transformers' Fit to\n  Reading Times", "abstract": "Recent psycholinguistic research has compared human reading times to\nsurprisal estimates from language models to study the factors shaping human\nsentence processing difficulty. Previous studies have shown a strong fit\nbetween surprisal values from Transformers and reading times. However, standard\nTransformers work with a lossless representation of the entire previous\nlinguistic context, unlike models of human language processing that include\nmemory decay. To bridge this gap, this paper evaluates a modification of the\nTransformer model that uses ALiBi (Press et al., 2022), a recency bias added to\nattention scores. Surprisal estimates with ALiBi show an improved fit to human\nreading times compared to a standard Transformer baseline. A subsequent\nanalysis of attention heads suggests that ALiBi's mixture of slopes -- which\ndetermine the rate of memory decay in each attention head -- may play a role in\nthe improvement by helping models with ALiBi to track different kinds of\nlinguistic dependencies.", "published": "2024-09-17 14:57:51", "link": "http://arxiv.org/abs/2409.11250v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Norm of Mean Contextualized Embeddings Determines their Variance", "abstract": "Contextualized embeddings vary by context, even for the same token, and form\na distribution in the embedding space. To analyze this distribution, we focus\non the norm of the mean embedding and the variance of the embeddings. In this\nstudy, we first demonstrate that these values follow the well-known formula for\nvariance in statistics and provide an efficient sequential computation method.\nThen, by observing embeddings from intermediate layers of several Transformer\nmodels, we found a strong trade-off relationship between the norm and the\nvariance: as the mean embedding becomes closer to the origin, the variance\nincreases. This trade-off is likely influenced by the layer normalization\nmechanism used in Transformer models. Furthermore, when the sets of token\nembeddings are treated as clusters, we show that the variance of the entire\nembedding set can theoretically be decomposed into the within-cluster variance\nand the between-cluster variance. We found experimentally that as the layers of\nTransformer models deepen, the embeddings move farther from the origin, the\nbetween-cluster variance relatively decreases, and the within-cluster variance\nrelatively increases. These results are consistent with existing studies on the\nanisotropy of the embedding spaces across layers.", "published": "2024-09-17 15:02:23", "link": "http://arxiv.org/abs/2409.11253v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Art of Storytelling: Multi-Agent Generative AI for Dynamic\n  Multimodal Narratives", "abstract": "This paper introduces the concept of an education tool that utilizes\nGenerative Artificial Intelligence (GenAI) to enhance storytelling for\nchildren. The system combines GenAI-driven narrative co-creation,\ntext-to-speech conversion, and text-to-video generation to produce an engaging\nexperience for learners. We describe the co-creation process, the adaptation of\nnarratives into spoken words using text-to-speech models, and the\ntransformation of these narratives into contextually relevant visuals through\ntext-to-video technology. Our evaluation covers the linguistics of the\ngenerated stories, the text-to-speech conversion quality, and the accuracy of\nthe generated visuals.", "published": "2024-09-17 15:10:23", "link": "http://arxiv.org/abs/2409.11261v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SpMis: An Investigation of Synthetic Spoken Misinformation Detection", "abstract": "In recent years, speech generation technology has advanced rapidly, fueled by\ngenerative models and large-scale training techniques. While these developments\nhave enabled the production of high-quality synthetic speech, they have also\nraised concerns about the misuse of this technology, particularly for\ngenerating synthetic misinformation. Current research primarily focuses on\ndistinguishing machine-generated speech from human-produced speech, but the\nmore urgent challenge is detecting misinformation within spoken content. This\ntask requires a thorough analysis of factors such as speaker identity, topic,\nand synthesis. To address this need, we conduct an initial investigation into\nsynthetic spoken misinformation detection by introducing an open-source\ndataset, SpMis. SpMis includes speech synthesized from over 1,000 speakers\nacross five common topics, utilizing state-of-the-art text-to-speech systems.\nAlthough our results show promising detection capabilities, they also reveal\nsubstantial challenges for practical implementation, underscoring the\nimportance of ongoing research in this critical area.", "published": "2024-09-17 16:05:09", "link": "http://arxiv.org/abs/2409.11308v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "THaMES: An End-to-End Tool for Hallucination Mitigation and Evaluation\n  in Large Language Models", "abstract": "Hallucination, the generation of factually incorrect content, is a growing\nchallenge in Large Language Models (LLMs). Existing detection and mitigation\nmethods are often isolated and insufficient for domain-specific needs, lacking\na standardized pipeline. This paper introduces THaMES (Tool for Hallucination\nMitigations and EvaluationS), an integrated framework and library addressing\nthis gap. THaMES offers an end-to-end solution for evaluating and mitigating\nhallucinations in LLMs, featuring automated test set generation, multifaceted\nbenchmarking, and adaptable mitigation strategies. It automates test set\ncreation from any corpus, ensuring high data quality, diversity, and\ncost-efficiency through techniques like batch processing, weighted sampling,\nand counterfactual validation. THaMES assesses a model's ability to detect and\nreduce hallucinations across various tasks, including text generation and\nbinary classification, applying optimal mitigation strategies like In-Context\nLearning (ICL), Retrieval Augmented Generation (RAG), and Parameter-Efficient\nFine-tuning (PEFT). Evaluations of state-of-the-art LLMs using a knowledge base\nof academic papers, political news, and Wikipedia reveal that commercial models\nlike GPT-4o benefit more from RAG than ICL, while open-weight models like\nLlama-3.1-8B-Instruct and Mistral-Nemo gain more from ICL. Additionally, PEFT\nsignificantly enhances the performance of Llama-3.1-8B-Instruct in both\nevaluation tasks.", "published": "2024-09-17 16:55:25", "link": "http://arxiv.org/abs/2409.11353v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoCA: Regaining Safety-awareness of Multimodal Large Language Models\n  with Constitutional Calibration", "abstract": "The deployment of multimodal large language models (MLLMs) has demonstrated\nremarkable success in engaging in conversations involving visual inputs, thanks\nto the superior power of large language models (LLMs). Those MLLMs are\ntypically built based on the LLMs, with an image encoder to process images into\nthe token embedding space of the LLMs. However, the integration of visual\nmodality has introduced a unique vulnerability: the MLLM becomes susceptible to\nmalicious visual inputs and prone to generating sensitive or harmful responses,\neven though the LLM has been trained on textual dataset to align with human\nvalue. In this paper, we first raise the question: ``Do the MLLMs possess\nsafety-awareness against malicious image inputs?\". We find that after adding a\nprinciple that specifies the safety requirement into the input of the MLLM, the\nmodel's safety awareness becomes boosted. This phenomenon verifies the\nexistence of MLLM's safety-awareness against image inputs, it is only weakened\nby the modality gap. We then introduce a simple yet effective technique termed\nCoCA, which amplifies the safety-awareness of the MLLM by calibrating its\noutput distribution. Our proposed strategy helps the model reclaim its original\nsafety awareness without losing its original capabilities. We verify the\neffectiveness of our approach on both multimodal safety and understanding\nbenchmarks.", "published": "2024-09-17 17:14:41", "link": "http://arxiv.org/abs/2409.11365v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enriching Datasets with Demographics through Large Language Models:\n  What's in a Name?", "abstract": "Enriching datasets with demographic information, such as gender, race, and\nage from names, is a critical task in fields like healthcare, public policy,\nand social sciences. Such demographic insights allow for more precise and\neffective engagement with target populations. Despite previous efforts\nemploying hidden Markov models and recurrent neural networks to predict\ndemographics from names, significant limitations persist: the lack of\nlarge-scale, well-curated, unbiased, publicly available datasets, and the lack\nof an approach robust across datasets. This scarcity has hindered the\ndevelopment of traditional supervised learning approaches. In this paper, we\ndemonstrate that the zero-shot capabilities of Large Language Models (LLMs) can\nperform as well as, if not better than, bespoke models trained on specialized\ndata. We apply these LLMs to a variety of datasets, including a real-life,\nunlabelled dataset of licensed financial professionals in Hong Kong, and\ncritically assess the inherent demographic biases in these models. Our work not\nonly advances the state-of-the-art in demographic enrichment but also opens\navenues for future research in mitigating biases in LLMs.", "published": "2024-09-17 18:40:49", "link": "http://arxiv.org/abs/2409.11491v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain-of-Thought Prompting for Speech Translation", "abstract": "Large language models (LLMs) have demonstrated remarkable advancements in\nlanguage understanding and generation. Building on the success of text-based\nLLMs, recent research has adapted these models to use speech embeddings for\nprompting, resulting in Speech-LLM models that exhibit strong performance in\nautomatic speech recognition (ASR) and automatic speech translation (AST). In\nthis work, we propose a novel approach to leverage ASR transcripts as prompts\nfor AST in a Speech-LLM built on an encoder-decoder text LLM. The Speech-LLM\nmodel consists of a speech encoder and an encoder-decoder structure\nMegatron-T5. By first decoding speech to generate ASR transcripts and\nsubsequently using these transcripts along with encoded speech for prompting,\nwe guide the speech translation in a two-step process like chain-of-thought\n(CoT) prompting. Low-rank adaptation (LoRA) is used for the T5 LLM for model\nadaptation and shows superior performance to full model fine-tuning.\nExperimental results show that the proposed CoT prompting significantly\nimproves AST performance, achieving an average increase of 2.4 BLEU points\nacross 6 En->X or X->En AST tasks compared to speech prompting alone.\nAdditionally, compared to a related CoT prediction method that predicts a\nconcatenated sequence of ASR and AST transcripts, our method performs better by\nan average of 2 BLEU points.", "published": "2024-09-17 20:16:43", "link": "http://arxiv.org/abs/2409.11538v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HEARTS: A Holistic Framework for Explainable, Sustainable and Robust\n  Text Stereotype Detection", "abstract": "Stereotypes are generalised assumptions about societal groups, and even\nstate-of-the-art LLMs using in-context learning struggle to identify them\naccurately. Due to the subjective nature of stereotypes, where what constitutes\na stereotype can vary widely depending on cultural, social, and individual\nperspectives, robust explainability is crucial. Explainable models ensure that\nthese nuanced judgments can be understood and validated by human users,\npromoting trust and accountability. We address these challenges by introducing\nHEARTS (Holistic Framework for Explainable, Sustainable, and Robust Text\nStereotype Detection), a framework that enhances model performance, minimises\ncarbon footprint, and provides transparent, interpretable explanations. We\nestablish the Expanded Multi-Grain Stereotype Dataset (EMGSD), comprising\n57,201 labelled texts across six groups, including under-represented\ndemographics like LGBTQ+ and regional stereotypes. Ablation studies confirm\nthat BERT models fine-tuned on EMGSD outperform those trained on individual\ncomponents. We then analyse a fine-tuned, carbon-efficient ALBERT-V2 model\nusing SHAP to generate token-level importance values, ensuring alignment with\nhuman understanding, and calculate explainability confidence scores by\ncomparing SHAP and LIME outputs...", "published": "2024-09-17 22:06:46", "link": "http://arxiv.org/abs/2409.11579v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Surveying the MLLM Landscape: A Meta-Review of Current Surveys", "abstract": "The rise of Multimodal Large Language Models (MLLMs) has become a\ntransformative force in the field of artificial intelligence, enabling machines\nto process and generate content across multiple modalities, such as text,\nimages, audio, and video. These models represent a significant advancement over\ntraditional unimodal systems, opening new frontiers in diverse applications\nranging from autonomous agents to medical diagnostics. By integrating multiple\nmodalities, MLLMs achieve a more holistic understanding of information, closely\nmimicking human perception. As the capabilities of MLLMs expand, the need for\ncomprehensive and accurate performance evaluation has become increasingly\ncritical. This survey aims to provide a systematic review of benchmark tests\nand evaluation methods for MLLMs, covering key topics such as foundational\nconcepts, applications, evaluation methodologies, ethical concerns, security,\nefficiency, and domain-specific applications. Through the classification and\nanalysis of existing literature, we summarize the main contributions and\nmethodologies of various surveys, conduct a detailed comparative analysis, and\nexamine their impact within the academic community. Additionally, we identify\nemerging trends and underexplored areas in MLLM research, proposing potential\ndirections for future studies. This survey is intended to offer researchers and\npractitioners a comprehensive understanding of the current state of MLLM\nevaluation, thereby facilitating further progress in this rapidly evolving\nfield.", "published": "2024-09-17 14:35:38", "link": "http://arxiv.org/abs/2409.18991v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attention-Seeker: Dynamic Self-Attention Scoring for Unsupervised\n  Keyphrase Extraction", "abstract": "This paper proposes Attention-Seeker, an unsupervised keyphrase extraction\nmethod that leverages self-attention maps from a Large Language Model to\nestimate the importance of candidate phrases. Our approach identifies specific\ncomponents - such as layers, heads, and attention vectors - where the model\npays significant attention to the key topics of the text. The attention weights\nprovided by these components are then used to score the candidate phrases.\nUnlike previous models that require manual tuning of parameters (e.g.,\nselection of heads, prompts, hyperparameters), Attention-Seeker dynamically\nadapts to the input text without any manual adjustments, enhancing its\npractical applicability. We evaluate Attention-Seeker on four publicly\navailable datasets: Inspec, SemEval2010, SemEval2017, and Krapivin. Our results\ndemonstrate that, even without parameter tuning, Attention-Seeker outperforms\nmost baseline models, achieving state-of-the-art performance on three out of\nfour datasets, particularly excelling in extracting keyphrases from long\ndocuments.", "published": "2024-09-17 05:54:25", "link": "http://arxiv.org/abs/2409.10907v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Investigating Context-Faithfulness in Large Language Models: The Roles\n  of Memory Strength and Evidence Style", "abstract": "Retrieval-augmented generation (RAG) improves Large Language Models (LLMs) by\nincorporating external information into the response generation process.\nHowever, how context-faithful LLMs are and what factors influence LLMs'\ncontext-faithfulness remain largely unexplored. In this study, we investigate\nthe impact of memory strength and evidence presentation on LLMs' receptiveness\nto external evidence. We introduce a method to quantify the memory strength of\nLLMs by measuring the divergence in LLMs' responses to different paraphrases of\nthe same question, which is not considered by previous works. We also generate\nevidence in various styles to evaluate the effects of evidence in different\nstyles. Two datasets are used for evaluation: Natural Questions (NQ) with\npopular questions and popQA featuring long-tail questions. Our results show\nthat for questions with high memory strength, LLMs are more likely to rely on\ninternal memory, particularly for larger LLMs such as GPT-4. On the other hand,\npresenting paraphrased evidence significantly increases LLMs' receptiveness\ncompared to simple repetition or adding details.", "published": "2024-09-17 07:44:06", "link": "http://arxiv.org/abs/2409.10955v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-lingual transfer of multilingual models on low resource African\n  Languages", "abstract": "Large multilingual models have significantly advanced natural language\nprocessing (NLP) research. However, their high resource demands and potential\nbiases from diverse data sources have raised concerns about their effectiveness\nacross low-resource languages. In contrast, monolingual models, trained on a\nsingle language, may better capture the nuances of the target language,\npotentially providing more accurate results. This study benchmarks the\ncross-lingual transfer capabilities from a high-resource language to a\nlow-resource language for both, monolingual and multilingual models, focusing\non Kinyarwanda and Kirundi, two Bantu languages. We evaluate the performance of\ntransformer based architectures like Multilingual BERT (mBERT), AfriBERT, and\nBantuBERTa against neural-based architectures such as BiGRU, CNN, and char-CNN.\nThe models were trained on Kinyarwanda and tested on Kirundi, with fine-tuning\napplied to assess the extent of performance improvement and catastrophic\nforgetting. AfriBERT achieved the highest cross-lingual accuracy of 88.3% after\nfine-tuning, while BiGRU emerged as the best-performing neural model with 83.3%\naccuracy. We also analyze the degree of forgetting in the original language\npost-fine-tuning. While monolingual models remain competitive, this study\nhighlights that multilingual models offer strong cross-lingual transfer\ncapabilities in resource limited settings.", "published": "2024-09-17 08:05:40", "link": "http://arxiv.org/abs/2409.10965v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GOSt-MT: A Knowledge Graph for Occupation-related Gender Biases in\n  Machine Translation", "abstract": "Gender bias in machine translation (MT) systems poses significant challenges\nthat often result in the reinforcement of harmful stereotypes. Especially in\nthe labour domain where frequently occupations are inaccurately associated with\nspecific genders, such biases perpetuate traditional gender stereotypes with a\nsignificant impact on society. Addressing these issues is crucial for ensuring\nequitable and accurate MT systems. This paper introduces a novel approach to\nstudying occupation-related gender bias through the creation of the GOSt-MT\n(Gender and Occupation Statistics for Machine Translation) Knowledge Graph.\nGOSt-MT integrates comprehensive gender statistics from real-world labour data\nand textual corpora used in MT training. This Knowledge Graph allows for a\ndetailed analysis of gender bias across English, French, and Greek,\nfacilitating the identification of persistent stereotypes and areas requiring\nintervention. By providing a structured framework for understanding how\noccupations are gendered in both labour markets and MT systems, GOSt-MT\ncontributes to efforts aimed at making MT systems more equitable and reducing\ngender biases in automated translations.", "published": "2024-09-17 08:44:20", "link": "http://arxiv.org/abs/2409.10989v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CAST: Cross-modal Alignment Similarity Test for Vision Language Models", "abstract": "Vision Language Models (VLMs) are typically evaluated with Visual Question\nAnswering (VQA) tasks which assess a model's understanding of scenes. Good VQA\nperformance is taken as evidence that the model will perform well on a broader\nrange of tasks that require both visual and language inputs. However,\nscene-aware VQA does not fully capture input biases or assess hallucinations\ncaused by a misalignment between modalities. To address this, we propose a\nCross-modal Alignment Similarity Test (CAST) to probe VLMs for self-consistency\nacross modalities. This test involves asking the models to identify\nsimilarities between two scenes through text-only, image-only, or both and then\nassess the truthfulness of the similarities they generate. Since there is no\nground-truth to compare against, this evaluation does not focus on objective\naccuracy but rather on whether VLMs are internally consistent in their outputs.\nWe argue that while not all self-consistent models are capable or accurate, all\ncapable VLMs must be self-consistent.", "published": "2024-09-17 09:14:45", "link": "http://arxiv.org/abs/2409.11007v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "DynamicNER: A Dynamic, Multilingual, and Fine-Grained Dataset for\n  LLM-based Named Entity Recognition", "abstract": "With the advancement of Large Language Models (LLMs), more and more\nresearchers apply LLMs for Named Entity Recognition (NER) methods, bringing\nvitality to this classical Natural Language Processing task. However, existing\ndatasets are designed for traditional machine learning methods, inadequate for\nLLM-based methods in terms of corpus selection, entity categorization, and\ndesign logic. This limitation leads to less effective evaluation and model\nfine-tuning. To address this issue, we propose DynamicNER, the first NER\ndataset specifically designed for LLMs and with dynamic categorization,\ntranscending the limitations of fixed categorization in existing datasets. It\nis also multi-lingual and multi-granular, covering 8 languages and 155 entity\ntypes, with corpus spanning multiple specialized domains. Furthermore, in\nresponse to the limitations demonstrated by existing LLM-based methods during\nDynamicNER testing, we develop CascadeNER, a novel NER method based on a\ntwo-stage strategy and lightweight LLMs, addressing the problems in current\nmethods. Experiments show that DynamicNER is an effective benchmark for\nLLM-based NER methods, and CascadeNER outperforms existing methods with fewer\ncomputational resources. Our work is opened at\nhttps://github.com/CascadeNER/CascadeNER.", "published": "2024-09-17 09:32:12", "link": "http://arxiv.org/abs/2409.11022v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Evaluation of Quantized Instruction-Tuned Large Language\n  Models: An Experimental Analysis up to 405B", "abstract": "Prior research works have evaluated quantized LLMs using limited metrics such\nas perplexity or a few basic knowledge tasks and old datasets. Additionally,\nrecent large-scale models such as Llama 3.1 with up to 405B have not been\nthoroughly examined. This paper evaluates the performance of instruction-tuned\nLLMs across various quantization methods (GPTQ, AWQ, SmoothQuant, and FP8) on\nmodels ranging from 7B to 405B. Using 13 benchmarks, we assess performance\nacross six task types: commonsense Q\\&A, knowledge and language understanding,\ninstruction following, hallucination detection, mathematics, and dialogue. Our\nkey findings reveal that (1) quantizing a larger LLM to a similar size as a\nsmaller FP16 LLM generally performs better across most benchmarks, except for\nhallucination detection and instruction following; (2) performance varies\nsignificantly with different quantization methods, model size, and bit-width,\nwith weight-only methods often yielding better results in larger models; (3)\ntask difficulty does not significantly impact accuracy degradation due to\nquantization; and (4) the MT-Bench evaluation method has limited discriminatory\npower among recent high-performing LLMs.", "published": "2024-09-17 10:31:37", "link": "http://arxiv.org/abs/2409.11055v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RoMath: A Mathematical Reasoning Benchmark in Romanian", "abstract": "Mathematics has long been conveyed through natural language, primarily for\nhuman understanding. With the rise of mechanized mathematics and proof\nassistants, there is a growing need to understand informal mathematical text,\nyet most existing benchmarks focus solely on English, overlooking other\nlanguages. This paper introduces RoMath, a Romanian mathematical reasoning\nbenchmark suite comprising three datasets: RoMath-Baccalaureate,\nRoMath-Competitions and RoMath-Synthetic, which cover a range of mathematical\ndomains and difficulty levels, aiming to improve non-English language models\nand promote multilingual AI development. By focusing on Romanian, a\nlow-resource language with unique linguistic features, RoMath addresses the\nlimitations of Anglo-centric models and emphasizes the need for dedicated\nresources beyond simple automatic translation. We benchmark several open-weight\nlanguage models, highlighting the importance of creating resources for\nunderrepresented languages. We make the code and dataset available.", "published": "2024-09-17 11:03:46", "link": "http://arxiv.org/abs/2409.11074v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Strategic Insights in Human and Large Language Model Tactics at Word\n  Guessing Games", "abstract": "At the beginning of 2022, a simplistic word-guessing game took the world by\nstorm and was further adapted to many languages beyond the original English\nversion. In this paper, we examine the strategies of daily word-guessing game\nplayers that have evolved during a period of over two years. A survey gathered\nfrom 25% of frequent players reveals their strategies and motivations for\ncontinuing the daily journey. We also explore the capability of several popular\nopen-access large language model systems and open-source models at\ncomprehending and playing the game in two different languages. Results\nhighlight the struggles of certain models to maintain correct guess length and\ngenerate repetitions, as well as hallucinations of non-existent words and\ninflections.", "published": "2024-09-17 12:06:05", "link": "http://arxiv.org/abs/2409.11112v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Diversity-grounded Channel Prototypical Learning for Out-of-Distribution\n  Intent Detection", "abstract": "In the realm of task-oriented dialogue systems, a robust intent detection\nmechanism must effectively handle malformed utterances encountered in\nreal-world scenarios. This study presents a novel fine-tuning framework for\nlarge language models (LLMs) aimed at enhancing in-distribution (ID) intent\nclassification and out-of-distribution (OOD) intent detection, which utilizes\nsemantic matching with prototypes derived from ID class names. By harnessing\nthe highly distinguishable representations of LLMs, we construct semantic\nprototypes for each ID class using a diversity-grounded prompt tuning approach.\nWe rigorously test our framework in a challenging OOD context, where ID and OOD\nclasses are semantically close yet distinct, referred to as \\emph{near} OOD\ndetection. For a thorough assessment, we benchmark our method against the\nprevalent fine-tuning approaches. The experimental findings reveal that our\nmethod demonstrates superior performance in both few-shot ID intent\nclassification and near-OOD intent detection tasks.", "published": "2024-09-17 12:07:17", "link": "http://arxiv.org/abs/2409.11114v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving the Efficiency of Visually Augmented Language Models", "abstract": "Despite the impressive performance of autoregressive Language Models (LM) it\nhas been shown that due to reporting bias, LMs lack visual knowledge, i.e. they\ndo not know much about the visual world and its properties. To augment LMs with\nvisual knowledge, existing solutions often rely on explicit images, requiring\ntime-consuming retrieval or image generation systems. This paper shows that\nexplicit images are not necessary to visually augment an LM. Instead, we use\nvisually-grounded text representations obtained from the well-known CLIP\nmultimodal system. For a fair comparison, we modify VALM, a visually-augmented\nLM which uses image retrieval and representation, to work directly with\nvisually-grounded text representations. We name this new model BLIND-VALM. We\nshow that BLIND-VALM performs on par with VALM for Visual Language\nUnderstanding (VLU), Natural Language Understanding (NLU) and Language Modeling\ntasks, despite being significantly more efficient and simpler. We also show\nthat scaling up our model within the compute budget of VALM, either increasing\nthe model or pre-training corpus size, we outperform VALM for all the\nevaluation tasks.", "published": "2024-09-17 13:02:19", "link": "http://arxiv.org/abs/2409.11148v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Bio-Inspired Mamba: Temporal Locality and Bioplausible Learning in\n  Selective State Space Models", "abstract": "This paper introduces Bio-Inspired Mamba (BIM), a novel online learning\nframework for selective state space models that integrates biological learning\nprinciples with the Mamba architecture. BIM combines Real-Time Recurrent\nLearning (RTRL) with Spike-Timing-Dependent Plasticity (STDP)-like local\nlearning rules, addressing the challenges of temporal locality and biological\nplausibility in training spiking neural networks. Our approach leverages the\ninherent connection between backpropagation through time and STDP, offering a\ncomputationally efficient alternative that maintains the ability to capture\nlong-range dependencies. We evaluate BIM on language modeling, speech\nrecognition, and biomedical signal analysis tasks, demonstrating competitive\nperformance against traditional methods while adhering to biological learning\nprinciples. Results show improved energy efficiency and potential for\nneuromorphic hardware implementation. BIM not only advances the field of\nbiologically plausible machine learning but also provides insights into the\nmechanisms of temporal information processing in biological neural networks.", "published": "2024-09-17 15:11:39", "link": "http://arxiv.org/abs/2409.11263v1", "categories": ["cs.NE", "cs.CL"], "primary_category": "cs.NE"}
{"title": "Task Arithmetic for Language Expansion in Speech Translation", "abstract": "Recent advances in large language models (LLMs) have gained interest in\nspeech-text multimodal foundation models, achieving strong performance on\ninstruction-based speech translation (ST). However, expanding language pairs\nfrom an existing instruction-tuned ST system is costly due to the necessity of\nre-training on a combination of new and previous datasets. We propose to expand\nnew language pairs by merging the model trained on new language pairs and the\nexisting model, using task arithmetic. We find that the direct application of\ntask arithmetic for ST causes the merged model to fail to follow instructions;\nthus, generating translation in incorrect languages. To eliminate language\nconfusion, we propose an augmented task arithmetic method that merges an\nadditional language control model. It is trained to generate the correct target\nlanguage token following the instructions. Our experiments demonstrate that our\nproposed language control model can achieve language expansion by eliminating\nlanguage confusion. In our MuST-C and CoVoST-2 experiments, it shows up to 4.66\nand 4.92 BLEU scores improvement, respectively. In addition, we demonstrate the\nuse of our task arithmetic framework can expand to a language pair where\nneither paired ST training data nor a pre-trained ST model is available. We\nfirst synthesize the ST system from machine translation (MT) systems via task\nanalogy, then merge the synthesized ST system to the existing ST model.", "published": "2024-09-17 15:25:11", "link": "http://arxiv.org/abs/2409.11274v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Distillation Techniques for Document Understanding: A Case\n  Study with FLAN-T5", "abstract": "The surge of digital documents in various formats, including less\nstandardized documents such as business reports and environmental assessments,\nunderscores the growing importance of Document Understanding. While Large\nLanguage Models (LLMs) have showcased prowess across diverse natural language\nprocessing tasks, their direct application to Document Understanding remains a\nchallenge. Previous research has demonstrated the utility of LLMs in this\ndomain, yet their significant computational demands make them challenging to\ndeploy effectively. Additionally, proprietary Blackbox LLMs often outperform\ntheir open-source counterparts, posing a barrier to widespread accessibility.\nIn this paper, we delve into the realm of document understanding, leveraging\ndistillation methods to harness the power of large LLMs while accommodating\ncomputational limitations. Specifically, we present a novel approach wherein we\ndistill document understanding knowledge from the proprietary LLM ChatGPT into\nFLAN-T5. Our methodology integrates labeling and curriculum-learning mechanisms\nto facilitate efficient knowledge transfer. This work contributes to the\nadvancement of document understanding methodologies by offering a scalable\nsolution that bridges the gap between resource-intensive LLMs and practical\napplications. Our findings underscore the potential of distillation techniques\nin facilitating the deployment of sophisticated language models in real-world\nscenarios, thereby fostering advancements in natural language processing and\ndocument comprehension domains.", "published": "2024-09-17 15:37:56", "link": "http://arxiv.org/abs/2409.11282v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-resource Hallucination Detection for Text Generation via\n  Graph-based Contextual Knowledge Triples Modeling", "abstract": "LLMs obtain remarkable performance but suffer from hallucinations. Most\nresearch on detecting hallucination focuses on the questions with short and\nconcrete correct answers that are easy to check the faithfulness. Hallucination\ndetections for text generation with open-ended answers are more challenging.\nSome researchers use external knowledge to detect hallucinations in generated\ntexts, but external resources for specific scenarios are hard to access. Recent\nstudies on detecting hallucinations in long text without external resources\nconduct consistency comparison among multiple sampled outputs. To handle long\ntexts, researchers split long texts into multiple facts and individually\ncompare the consistency of each pairs of facts. However, these methods (1)\nhardly achieve alignment among multiple facts; (2) overlook dependencies\nbetween multiple contextual facts. In this paper, we propose a graph-based\ncontext-aware (GCA) hallucination detection for text generations, which aligns\nknowledge facts and considers the dependencies between contextual knowledge\ntriples in consistency comparison. Particularly, to align multiple facts, we\nconduct a triple-oriented response segmentation to extract multiple knowledge\ntriples. To model dependencies among contextual knowledge triple (facts), we\nconstruct contextual triple into a graph and enhance triples' interactions via\nmessage passing and aggregating via RGCN. To avoid the omission of knowledge\ntriples in long text, we conduct a LLM-based reverse verification via\nreconstructing the knowledge triples. Experiments show that our model enhances\nhallucination detection and excels all baselines.", "published": "2024-09-17 15:38:36", "link": "http://arxiv.org/abs/2409.11283v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Diversify and Conquer: Diversity-Centric Data Selection with Iterative\n  Refinement", "abstract": "Finetuning large language models on instruction data is crucial for enhancing\npre-trained knowledge and improving instruction-following capabilities. As\ninstruction datasets proliferate, selecting optimal data for effective training\nbecomes increasingly important. This work addresses the question: How can we\ndetermine the optimal subset of data for effective training? While existing\nresearch often emphasizes local criteria like instance quality for subset\nselection, we argue that a global approach focused on data diversity is more\ncritical. Our method employs k-means clustering to ensure the selected subset\neffectively represents the full dataset. We propose an iterative refinement\nmethod inspired by active learning techniques to resample instances from\nclusters, reassessing each cluster's importance and sampling weight in every\ntraining iteration. This approach reduces the effect of outliers and\nautomatically filters out clusters containing low-quality data. Through\nextensive evaluation across natural language reasoning, general world\nknowledge, code and math reasoning tasks, and by fine-tuning models from\nvarious families, we observe consistent improvements, achieving a 7% increase\nover random selection and a 3.8% improvement over state-of-the-art sampling\nmethods. Our work highlights the significance of diversity-first sampling when\nfinetuning LLMs to enhance performance across a broad array of evaluation\ntasks. Our code is available at\nhttps://github.com/for-ai/iterative-data-selection.", "published": "2024-09-17 17:25:31", "link": "http://arxiv.org/abs/2409.11378v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Says Who? Effective Zero-Shot Annotation of Focalization", "abstract": "Focalization, the perspective through which narrative is presented, is\nencoded via a wide range of lexico-grammatical features and is subject to\nreader interpretation. Even trained annotators frequently disagree on correct\nlabels, suggesting this task is both qualitatively and computationally\nchallenging. In this work, we test how well five contemporary large language\nmodel (LLM) families and two baselines perform when annotating short literary\nexcerpts for focalization. Despite the challenging nature of the task, we find\nthat LLMs show comparable performance to trained human annotators, with GPT-4o\nachieving an average F1 of 84.79%. Further, we demonstrate that the log\nprobabilities output by GPT-family models frequently reflect the difficulty of\nannotating particular excerpts. Finally, we provide a case study analyzing\nsixteen Stephen King novels, demonstrating the usefulness of this approach for\ncomputational literary studies and the insights gleaned from examining\nfocalization at scale.", "published": "2024-09-17 17:50:15", "link": "http://arxiv.org/abs/2409.11390v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AraDiCE: Benchmarks for Dialectal and Cultural Capabilities in LLMs", "abstract": "Arabic, with its rich diversity of dialects, remains significantly\nunderrepresented in Large Language Models, particularly in dialectal\nvariations. We address this gap by introducing seven synthetic datasets in\ndialects alongside Modern Standard Arabic (MSA), created using Machine\nTranslation (MT) combined with human post-editing. We present AraDiCE, a\nbenchmark for Arabic Dialect and Cultural Evaluation. We evaluate LLMs on\ndialect comprehension and generation, focusing specifically on low-resource\nArabic dialects. Additionally, we introduce the first-ever fine-grained\nbenchmark designed to evaluate cultural awareness across the Gulf, Egypt, and\nLevant regions, providing a novel dimension to LLM evaluation. Our findings\ndemonstrate that while Arabic-specific models like Jais and AceGPT outperform\nmultilingual models on dialectal tasks, significant challenges persist in\ndialect identification, generation, and translation. This work contributes\n$\\approx$45K post-edited samples, a cultural benchmark, and highlights the\nimportance of tailored training to improve LLM performance in capturing the\nnuances of diverse Arabic dialects and cultural contexts. We have released the\ndialectal translation models and benchmarks developed in this study\n(https://huggingface.co/datasets/QCRI/AraDiCE).", "published": "2024-09-17 17:59:25", "link": "http://arxiv.org/abs/2409.11404v3", "categories": ["cs.CL", "cs.AI", "68T50", "F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Multi-Document Grounded Multi-Turn Synthetic Dialog Generation", "abstract": "We introduce a technique for multi-document grounded multi-turn synthetic\ndialog generation that incorporates three main ideas. First, we control the\noverall dialog flow using taxonomy-driven user queries that are generated with\nChain-of-Thought (CoT) prompting. Second, we support the generation of\nmulti-document grounded dialogs by mimicking real-world use of retrievers to\nupdate the grounding documents after every user-turn in the dialog. Third, we\napply LLM-as-a-Judge to filter out queries with incorrect answers. Human\nevaluation of the synthetic dialog data suggests that the data is diverse,\ncoherent, and includes mostly correct answers. Both human and automatic\nevaluations of answerable queries indicate that models fine-tuned on synthetic\ndialogs consistently out-perform those fine-tuned on existing human generated\ntraining data across four publicly available multi-turn document grounded\nbenchmark test sets.", "published": "2024-09-17 19:02:39", "link": "http://arxiv.org/abs/2409.11500v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Egalitarian Language Representation in Language Models: It All Begins\n  with Tokenizers", "abstract": "Tokenizers act as a bridge between human language and the latent space of\nlanguage models, influencing how language is represented in these models. Due\nto the immense popularity of English-Centric Large Language Models (LLMs),\nefforts are being made to adapt them for other languages. However, we\ndemonstrate that, from a tokenization standpoint, not all tokenizers offer fair\nrepresentation for complex script languages such as Tamil, Sinhala, and Hindi,\nprimarily due to the choice of pre-tokenization methods. We go further to show\nthat pre-tokenization plays a more critical role than the tokenization\nalgorithm itself in achieving an egalitarian representation of these complex\nscript languages. To address this, we introduce an improvement to the Byte Pair\nEncoding (BPE) algorithm by incorporating graphemes, which we term Grapheme\nPair Encoding (GPE). Our experiments show that grapheme-based character\nextraction outperforms byte-level tokenizers for complex scripts. We validate\nthis approach through experiments on Tamil, Sinhala, and Hindi.", "published": "2024-09-17 19:05:37", "link": "http://arxiv.org/abs/2409.11501v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Small Language Models can Outperform Humans in Short Creative Writing: A\n  Study Comparing SLMs with Humans and LLMs", "abstract": "In this paper, we evaluate the creative fiction writing abilities of a\nfine-tuned small language model (SLM), BART-large, and compare its performance\nto human writers and two large language models (LLMs): GPT-3.5 and GPT-4o. Our\nevaluation consists of two experiments: (i) a human study in which 68\nparticipants rated short stories from humans and the SLM on grammaticality,\nrelevance, creativity, and attractiveness, and (ii) a qualitative linguistic\nanalysis examining the textual characteristics of stories produced by each\nmodel. In the first experiment, BART-large outscored average human writers\noverall (2.11 vs. 1.85), a 14% relative improvement, though the slight human\nadvantage in creativity was not statistically significant. In the second\nexperiment, qualitative analysis showed that while GPT-4o demonstrated\nnear-perfect coherence and used less cliche phrases, it tended to produce more\npredictable language, with only 3% of its synopses featuring surprising\nassociations (compared to 15% for BART). These findings highlight how model\nsize and fine-tuning influence the balance between creativity, fluency, and\ncoherence in creative writing tasks, and demonstrate that smaller models can,\nin certain contexts, rival both humans and larger models.", "published": "2024-09-17 20:40:02", "link": "http://arxiv.org/abs/2409.11547v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ProSLM : A Prolog Synergized Language Model for explainable Domain\n  Specific Knowledge Based Question Answering", "abstract": "Neurosymbolic approaches can add robustness to opaque neural systems by\nincorporating explainable symbolic representations. However, previous\napproaches have not used formal logic to contextualize queries to and validate\noutputs of large language models (LLMs). We propose \\systemname{}, a novel\nneurosymbolic framework, to improve the robustness and reliability of LLMs in\nquestion-answering tasks. We provide \\systemname{} with a domain-specific\nknowledge base, a logical reasoning system, and an integration to an existing\nLLM. This framework has two capabilities (1) context gathering: generating\nexplainable and relevant context for a given query, and (2) validation:\nconfirming and validating the factual accuracy of a statement in accordance\nwith a knowledge base (KB). Our work opens a new area of neurosymbolic\ngenerative AI text validation and user personalization.", "published": "2024-09-17 22:34:33", "link": "http://arxiv.org/abs/2409.11589v1", "categories": ["cs.CL", "cs.AI", "I.2"], "primary_category": "cs.CL"}
{"title": "REAL: Response Embedding-based Alignment for LLMs", "abstract": "Aligning large language models (LLMs) to human preferences is a crucial step\nin building helpful and safe AI tools, which usually involve training on\nsupervised datasets. Popular algorithms such as Direct Preference Optimization\nrely on pairs of AI-generated responses ranked according to human feedback. The\nresponse pair annotation process is the most labor-intensive and costly part of\nthe alignment pipeline, and improving its efficiency and annotation quality\nwould have a meaningful impact on AI development. We propose REAL: Response\nEmbedding-based Alignment for LLMs, a strategy for constructing a high-quality\ntraining dataset that focuses on acquiring the most informative response pairs\nfor labeling out of a set of response candidates. Our selection process is\nbased on embedding responses independently of prompts. Experimental results on\nreal-world dataset SHP2 and synthetic HH-RLHF benchmarks indicate that choosing\ndissimilar response pairs enhances the direct alignment of LLMs while reducing\ninherited labeling errors. The model aligned on dissimilar response pairs\nobtained a better margin and win rate on the dialogue task. Our findings\nsuggest that focusing on distinct pairs can reduce the label error to improve\nthe efficiency of LLM alignment, saving up to 65% of annotators' work.", "published": "2024-09-17 22:40:54", "link": "http://arxiv.org/abs/2409.17169v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SC-Phi2: A Fine-tuned Small Language Model for StarCraft II\n  Macromanagement Tasks", "abstract": "This paper introduces SC-Phi2, a fine-tuned StarCraft II small language model\nfor macromanagement tasks. Small language models, like Phi2, Gemma, and\nDistilBERT, are streamlined versions of large language models (LLMs) with fewer\nparameters that require less power and memory to run. To teach Microsoft's Phi2\nmodel about StarCraft, we create a new SC2 text dataset with information about\nStarCraft races, roles, and actions and use it to fine-tune Phi-2 with\nself-supervised learning. We pair this language model with a Vision Transformer\n(ViT) from the pre-trained BLIP-2 (Bootstrapping Language Image Pre-training)\nmodel, fine-tuning it on the MSC replay dataset. This enables us to construct\ndynamic prompts that include visual game state information. Unlike the large\nmodels used in StarCraft LLMs such as GPT-3.5, Phi2 is trained primarily on\ntextbook data and contains little inherent knowledge of StarCraft II beyond\nwhat is provided by our training process. By using LoRA (Low-rank Adaptation)\nand quantization, our model can be trained on a single GPU. We demonstrate that\nour model performs well at micromanagement tasks such as build order and global\nstate prediction with a small number of parameters.", "published": "2024-09-17 12:50:32", "link": "http://arxiv.org/abs/2409.18989v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BAD: Bidirectional Auto-regressive Diffusion for Text-to-Motion\n  Generation", "abstract": "Autoregressive models excel in modeling sequential dependencies by enforcing\ncausal constraints, yet they struggle to capture complex bidirectional patterns\ndue to their unidirectional nature. In contrast, mask-based models leverage\nbidirectional context, enabling richer dependency modeling. However, they often\nassume token independence during prediction, which undermines the modeling of\nsequential dependencies. Additionally, the corruption of sequences through\nmasking or absorption can introduce unnatural distortions, complicating the\nlearning process. To address these issues, we propose Bidirectional\nAutoregressive Diffusion (BAD), a novel approach that unifies the strengths of\nautoregressive and mask-based generative models. BAD utilizes a\npermutation-based corruption technique that preserves the natural sequence\nstructure while enforcing causal dependencies through randomized ordering,\nenabling the effective capture of both sequential and bidirectional\nrelationships. Comprehensive experiments show that BAD outperforms\nautoregressive and mask-based models in text-to-motion generation, suggesting a\nnovel pre-training strategy for sequence modeling. The codebase for BAD is\navailable on https://github.com/RohollahHS/BAD.", "published": "2024-09-17 02:28:19", "link": "http://arxiv.org/abs/2409.10847v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GenCRF: Generative Clustering and Reformulation Framework for Enhanced\n  Intent-Driven Information Retrieval", "abstract": "Query reformulation is a well-known problem in Information Retrieval (IR)\naimed at enhancing single search successful completion rate by automatically\nmodifying user's input query. Recent methods leverage Large Language Models\n(LLMs) to improve query reformulation, but often generate limited and redundant\nexpansions, potentially constraining their effectiveness in capturing diverse\nintents. In this paper, we propose GenCRF: a Generative Clustering and\nReformulation Framework to capture diverse intentions adaptively based on\nmultiple differentiated, well-generated queries in the retrieval phase for the\nfirst time. GenCRF leverages LLMs to generate variable queries from the initial\nquery using customized prompts, then clusters them into groups to distinctly\nrepresent diverse intents. Furthermore, the framework explores to combine\ndiverse intents query with innovative weighted aggregation strategies to\noptimize retrieval performance and crucially integrates a novel Query\nEvaluation Rewarding Model (QERM) to refine the process through feedback loops.\nEmpirical experiments on the BEIR benchmark demonstrate that GenCRF achieves\nstate-of-the-art performance, surpassing previous query reformulation SOTAs by\nup to 12% on nDCG@10. These techniques can be adapted to various LLMs,\nsignificantly boosting retriever performance and advancing the field of\nInformation Retrieval.", "published": "2024-09-17 05:59:32", "link": "http://arxiv.org/abs/2409.10909v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Enhancing Multilingual Speech Generation and Recognition Abilities in\n  LLMs with Constructed Code-switched Data", "abstract": "While large language models (LLMs) have been explored in the speech domain\nfor both generation and recognition tasks, their applications are predominantly\nconfined to the monolingual scenario, with limited exploration in multilingual\nand code-switched (CS) contexts. Additionally, speech generation and\nrecognition tasks are often handled separately, such as VALL-E and Qwen-Audio.\nIn this paper, we propose a MutltiLingual MultiTask (MLMT) model, integrating\nmultilingual speech generation and recognition tasks within the single LLM.\nFurthermore, we develop an effective data construction approach that splits and\nconcatenates words from different languages to equip LLMs with CS synthesis\nability without relying on CS data. The experimental results demonstrate that\nour model outperforms other baselines with a comparable data scale.\nFurthermore, our data construction approach not only equips LLMs with CS speech\nsynthesis capability with comparable speaker consistency and similarity to any\ngiven speaker, but also improves the performance of LLMs in multilingual speech\ngeneration and recognition tasks.", "published": "2024-09-17 08:11:07", "link": "http://arxiv.org/abs/2409.10969v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Speech Emotion Recognition in Under-Resourced Languages via\n  Speech-to-Speech Translation with Bootstrapping Data Selection", "abstract": "Speech Emotion Recognition (SER) is a crucial component in developing\ngeneral-purpose AI agents capable of natural human-computer interaction.\nHowever, building robust multilingual SER systems remains challenging due to\nthe scarcity of labeled data in languages other than English and Chinese. In\nthis paper, we propose an approach to enhance SER performance in low SER\nresource languages by leveraging data from high-resource languages.\nSpecifically, we employ expressive Speech-to-Speech translation (S2ST) combined\nwith a novel bootstrapping data selection pipeline to generate labeled data in\nthe target language. Extensive experiments demonstrate that our method is both\neffective and generalizable across different upstream models and languages. Our\nresults suggest that this approach can facilitate the development of more\nscalable and robust multilingual SER systems.", "published": "2024-09-17 08:36:45", "link": "http://arxiv.org/abs/2409.10985v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Less is More: A Simple yet Effective Token Reduction Method for\n  Efficient Multi-modal LLMs", "abstract": "The rapid advancement of Multimodal Large Language Models (MLLMs) has led to\nremarkable performances across various domains. However, this progress is\naccompanied by a substantial surge in the resource consumption of these models.\nWe address this pressing issue by introducing a new approach, Token Reduction\nusing CLIP Metric (TRIM), aimed at improving the efficiency of MLLMs without\nsacrificing their performance. Inspired by human attention patterns in Visual\nQuestion Answering (VQA) tasks, TRIM presents a fresh perspective on the\nselection and reduction of image tokens. The TRIM method has been extensively\ntested across 12 datasets, and the results demonstrate a significant reduction\nin computational overhead while maintaining a consistent level of performance.\nThis research marks a critical stride in efficient MLLM development, promoting\ngreater accessibility and sustainability of high-performing models.", "published": "2024-09-17 08:56:27", "link": "http://arxiv.org/abs/2409.10994v3", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Enhancing Low-Resource Language and Instruction Following Capabilities\n  of Audio Language Models", "abstract": "Audio language models can understand audio inputs and perform a range of\naudio-related tasks based on instructions, such as speech recognition and audio\ncaptioning, where the instructions are usually textual prompts. Audio language\nmodels are mostly initialized from pre-trained audio encoders and large\nlanguage models (LLMs). Although these pre-trained components were developed to\nsupport multiple languages, audio-language models are trained predominantly on\nEnglish data, which may limit their usability to only English instructions or\nEnglish speech inputs. First, this paper examines the performance of existing\naudio language models in an underserved language using Thai as an example. This\npaper demonstrates that, despite being built on multilingual backbones, audio\nlanguage models do not exhibit cross-lingual emergent abilities to low-resource\nlanguages. Second, this paper studies data mixture for developing audio\nlanguage models that are optimized for a target language as well as English. In\naddition. this paper integrates audio comprehension and speech\ninstruction-following capabilities into a single unified model. Our experiments\nprovide insights into data mixture for enhancing instruction-following\ncapabilities in both a low-resource language and English. Our model,\nTyphoon-Audio, outperforms existing open-source audio language models by a\nconsiderable margin, and it is comparable to state-of-the-art Gemini-1.5-Pro in\nboth English and Thai languages.", "published": "2024-09-17 09:04:03", "link": "http://arxiv.org/abs/2409.10999v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Promptriever: Instruction-Trained Retrievers Can Be Prompted Like\n  Language Models", "abstract": "Instruction-tuned language models (LM) are able to respond to imperative\ncommands, providing a more natural user interface compared to their base\ncounterparts. In this work, we present Promptriever, the first retrieval model\nable to be prompted like an LM. To train Promptriever, we curate and release a\nnew instance-level instruction training set from MS MARCO, spanning nearly 500k\ninstances. Promptriever not only achieves strong performance on standard\nretrieval tasks, but also follows instructions. We observe: (1) large gains\n(reaching SoTA) on following detailed relevance instructions (+14.3 p-MRR /\n+3.1 nDCG on FollowIR), (2) significantly increased robustness to lexical\nchoices/phrasing in the query+instruction (+12.9 Robustness@10 on InstructIR),\nand (3) the ability to perform hyperparameter search via prompting to reliably\nimprove retrieval performance (+1.4 average increase on BEIR). Promptriever\ndemonstrates that retrieval models can be controlled with prompts on a\nper-query basis, setting the stage for future work aligning LM prompting\ntechniques with information retrieval.", "published": "2024-09-17 12:42:55", "link": "http://arxiv.org/abs/2409.11136v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Capturing Differences in Character Representations Between Communities:\n  An Initial Study with Fandom", "abstract": "Sociolinguistic theories have highlighted how narratives are often retold,\nco-constructed and reconceptualized in collaborative settings. This working\npaper focuses on the re-interpretation of characters, an integral part of the\nnarrative story-world, and attempts to study how this may be computationally\ncompared between online communities. Using online fandom - a highly communal\nphenomenon that has been largely studied qualitatively - as data, computational\nmethods were applied to explore shifts in character representations between two\ncommunities and the original text. Specifically, text from the Harry Potter\nnovels, r/HarryPotter subreddit, and fanfiction on Archive of Our Own were\nanalyzed for changes in character mentions, centrality measures from\nco-occurrence networks, and semantic associations. While fandom elevates\nsecondary characters as found in past work, the two fan communities prioritize\ndifferent subsets of characters. Word embedding tests reveal starkly different\nassociations of the same characters between communities on the gendered\nconcepts of femininity/masculinity, cruelty, and beauty. Furthermore,\nfanfiction descriptions of a male character analyzed between romance pairings\nscored higher for feminine-coded characteristics in male-male romance, matching\npast qualitative theorizing. The results high-light the potential for\ncomputational methods to assist in capturing the re-conceptualization of\nnarrative elements across communities and in supporting qualitative research on\nfandom.", "published": "2024-09-17 13:24:29", "link": "http://arxiv.org/abs/2409.11170v1", "categories": ["cs.CY", "cs.CL", "cs.SI"], "primary_category": "cs.CY"}
{"title": "Fast Analysis of the OpenAI O1-Preview Model in Solving Random K-SAT\n  Problem: Does the LLM Solve the Problem Itself or Call an External SAT\n  Solver?", "abstract": "In this manuscript, I present an analysis on the performance of OpenAI\nO1-preview model in solving random K-SAT instances for K$\\in {2,3,4}$ as a\nfunction of $\\alpha=M/N$ where $M$ is the number of clauses and $N$ is the\nnumber of variables of the satisfiable problem. I show that the model can call\nan external SAT solver to solve the instances, rather than solving them\ndirectly. Despite using external solvers, the model reports incorrect\nassignments as output. Moreover, I propose and present an analysis to quantify\nwhether the OpenAI O1-preview model demonstrates a spark of intelligence or\nmerely makes random guesses when outputting an assignment for a Boolean\nsatisfiability problem.", "published": "2024-09-17 14:29:03", "link": "http://arxiv.org/abs/2409.11232v2", "categories": ["cs.CL", "cond-mat.dis-nn", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WER We Stand: Benchmarking Urdu ASR Models", "abstract": "This paper presents a comprehensive evaluation of Urdu Automatic Speech\nRecognition (ASR) models. We analyze the performance of three ASR model\nfamilies: Whisper, MMS, and Seamless-M4T using Word Error Rate (WER), along\nwith a detailed examination of the most frequent wrong words and error types\nincluding insertions, deletions, and substitutions. Our analysis is conducted\nusing two types of datasets, read speech and conversational speech. Notably, we\npresent the first conversational speech dataset designed for benchmarking Urdu\nASR models. We find that seamless-large outperforms other ASR models on the\nread speech dataset, while whisper-large performs best on the conversational\nspeech dataset. Furthermore, this evaluation highlights the complexities of\nassessing ASR models for low-resource languages like Urdu using quantitative\nmetrics alone and emphasizes the need for a robust Urdu text normalization\nsystem. Our findings contribute valuable insights for developing robust ASR\nsystems for low-resource languages like Urdu.", "published": "2024-09-17 15:00:31", "link": "http://arxiv.org/abs/2409.11252v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LOLA -- An Open-Source Massively Multilingual Large Language Model", "abstract": "This paper presents LOLA, a massively multilingual large language model\ntrained on more than 160 languages using a sparse Mixture-of-Experts\nTransformer architecture. Our architectural and implementation choices address\nthe challenge of harnessing linguistic diversity while maintaining efficiency\nand avoiding the common pitfalls of multilinguality. Our analysis of the\nevaluation results shows competitive performance in natural language generation\nand understanding tasks. Additionally, we demonstrate how the learned\nexpert-routing mechanism exploits implicit phylogenetic linguistic patterns to\npotentially alleviate the curse of multilinguality. We provide an in-depth look\nat the training process, an analysis of the datasets, and a balanced\nexploration of the model's strengths and limitations. As an open-source model,\nLOLA promotes reproducibility and serves as a robust foundation for future\nresearch. Our findings enable the development of compute-efficient multilingual\nmodels with strong, scalable performance across languages.", "published": "2024-09-17 15:23:08", "link": "http://arxiv.org/abs/2409.11272v7", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "P-RAG: Progressive Retrieval Augmented Generation For Planning on\n  Embodied Everyday Task", "abstract": "Embodied Everyday Task is a popular task in the embodied AI community,\nrequiring agents to make a sequence of actions based on natural language\ninstructions and visual observations. Traditional learning-based approaches\nface two challenges. Firstly, natural language instructions often lack explicit\ntask planning. Secondly, extensive training is required to equip models with\nknowledge of the task environment. Previous works based on Large Language Model\n(LLM) either suffer from poor performance due to the lack of task-specific\nknowledge or rely on ground truth as few-shot samples. To address the above\nlimitations, we propose a novel approach called Progressive Retrieval Augmented\nGeneration (P-RAG), which not only effectively leverages the powerful language\nprocessing capabilities of LLMs but also progressively accumulates\ntask-specific knowledge without ground-truth. Compared to the conventional RAG\nmethods, which retrieve relevant information from the database in a one-shot\nmanner to assist generation, P-RAG introduces an iterative approach to\nprogressively update the database. In each iteration, P-RAG retrieves the\nlatest database and obtains historical information from the previous\ninteraction as experiential references for the current interaction. Moreover,\nwe also introduce a more granular retrieval scheme that not only retrieves\nsimilar tasks but also incorporates retrieval of similar situations to provide\nmore valuable reference experiences. Extensive experiments reveal that P-RAG\nachieves competitive results without utilizing ground truth and can even\nfurther improve performance through self-iterations.", "published": "2024-09-17 15:29:34", "link": "http://arxiv.org/abs/2409.11279v1", "categories": ["cs.RO", "cs.CL", "cs.IR"], "primary_category": "cs.RO"}
{"title": "EIA: Environmental Injection Attack on Generalist Web Agents for Privacy\n  Leakage", "abstract": "Generalist web agents have demonstrated remarkable potential in autonomously\ncompleting a wide range of tasks on real websites, significantly boosting human\nproductivity. However, web tasks, such as booking flights, usually involve\nusers' PII, which may be exposed to potential privacy risks if web agents\naccidentally interact with compromised websites, a scenario that remains\nlargely unexplored in the literature. In this work, we narrow this gap by\nconducting the first study on the privacy risks of generalist web agents in\nadversarial environments. First, we present a realistic threat model for\nattacks on the website, where we consider two adversarial targets: stealing\nusers' specific PII or the entire user request. Then, we propose a novel attack\nmethod, termed Environmental Injection Attack (EIA). EIA injects malicious\ncontent designed to adapt well to environments where the agents operate and our\nwork instantiates EIA specifically for privacy scenarios in web environments.\nWe collect 177 action steps that involve diverse PII categories on realistic\nwebsites from the Mind2Web, and conduct experiments using one of the most\ncapable generalist web agent frameworks to date. The results demonstrate that\nEIA achieves up to 70% ASR in stealing specific PII and 16% ASR for full user\nrequest. Additionally, by accessing the stealthiness and experimenting with a\ndefensive system prompt, we indicate that EIA is hard to detect and mitigate.\nNotably, attacks that are not well adapted for a webpage can be detected via\nhuman inspection, leading to our discussion about the trade-off between\nsecurity and autonomy. However, extra attackers' efforts can make EIA\nseamlessly adapted, rendering such supervision ineffective. Thus, we further\ndiscuss the defenses at the pre- and post-deployment stages of the websites\nwithout relying on human supervision and call for more advanced defense\nstrategies.", "published": "2024-09-17 15:49:44", "link": "http://arxiv.org/abs/2409.11295v5", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "CORE-Bench: Fostering the Credibility of Published Research Through a\n  Computational Reproducibility Agent Benchmark", "abstract": "AI agents have the potential to aid users on a variety of consequential\ntasks, including conducting scientific research. To spur the development of\nuseful agents, we need benchmarks that are challenging, but more crucially,\ndirectly correspond to real-world tasks of interest. This paper introduces such\na benchmark, designed to measure the accuracy of AI agents in tackling a\ncrucial yet surprisingly challenging aspect of scientific research:\ncomputational reproducibility. This task, fundamental to the scientific\nprocess, involves reproducing the results of a study using the provided code\nand data. We introduce CORE-Bench (Computational Reproducibility Agent\nBenchmark), a benchmark consisting of 270 tasks based on 90 scientific papers\nacross three disciplines (computer science, social science, and medicine).\nTasks in CORE-Bench consist of three difficulty levels and include both\nlanguage-only and vision-language tasks. We provide an evaluation system to\nmeasure the accuracy of agents in a fast and parallelizable way, saving days of\nevaluation time for each run compared to a sequential implementation. We\nevaluated two baseline agents: the general-purpose AutoGPT and a task-specific\nagent called CORE-Agent. We tested both variants using two underlying language\nmodels: GPT-4o and GPT-4o-mini. The best agent achieved an accuracy of 21% on\nthe hardest task, showing the vast scope for improvement in automating routine\nscientific tasks. Having agents that can reproduce existing work is a necessary\nstep towards building agents that can conduct novel research and could verify\nand improve the performance of other research agents. We hope that CORE-Bench\ncan improve the state of reproducibility and spur the development of future\nresearch agents.", "published": "2024-09-17 17:13:19", "link": "http://arxiv.org/abs/2409.11363v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Jailbreaking Large Language Models with Symbolic Mathematics", "abstract": "Recent advancements in AI safety have led to increased efforts in training\nand red-teaming large language models (LLMs) to mitigate unsafe content\ngeneration. However, these safety mechanisms may not be comprehensive, leaving\npotential vulnerabilities unexplored. This paper introduces MathPrompt, a novel\njailbreaking technique that exploits LLMs' advanced capabilities in symbolic\nmathematics to bypass their safety mechanisms. By encoding harmful natural\nlanguage prompts into mathematical problems, we demonstrate a critical\nvulnerability in current AI safety measures. Our experiments across 13\nstate-of-the-art LLMs reveal an average attack success rate of 73.6\\%,\nhighlighting the inability of existing safety training mechanisms to generalize\nto mathematically encoded inputs. Analysis of embedding vectors shows a\nsubstantial semantic shift between original and encoded prompts, helping\nexplain the attack's success. This work emphasizes the importance of a holistic\napproach to AI safety, calling for expanded red-teaming efforts to develop\nrobust safeguards across all potential input types and their associated risks.", "published": "2024-09-17 03:39:45", "link": "http://arxiv.org/abs/2409.11445v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Augment, Drop & Swap: Improving Diversity in LLM Captions for Efficient\n  Music-Text Representation Learning", "abstract": "Audio-text contrastive models have become a powerful approach in music\nrepresentation learning. Despite their empirical success, however, little is\nknown about the influence of key design choices on the quality of music-text\nrepresentations learnt through this framework. In this work, we expose these\ndesign choices within the constraints of limited data and computation budgets,\nand establish a more solid understanding of their impact grounded in empirical\nobservations along three axes: the choice of base encoders, the level of\ncuration in training data, and the use of text augmentation. We find that data\ncuration is the single most important factor for music-text contrastive\ntraining in resource-constrained scenarios. Motivated by this insight, we\nintroduce two novel techniques, Augmented View Dropout and TextSwap, which\nincrease the diversity and descriptiveness of text inputs seen in training.\nThrough our experiments we demonstrate that these are effective at boosting\nperformance across different pre-training regimes, model architectures, and\ndownstream data distributions, without incurring higher computational costs or\nrequiring additional training data.", "published": "2024-09-17 19:00:21", "link": "http://arxiv.org/abs/2409.11498v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented\n  Generation", "abstract": "Modern language models frequently include retrieval components to improve\ntheir outputs, giving rise to a growing number of retrieval-augmented\ngeneration (RAG) systems. Yet, most existing work in RAG has underemphasized\nfair ranking techniques and neglected the diverse interests of all\nstakeholders. In this paper, we present the first comprehensive study of RAG\nsystems that incorporate fairness-aware rankings, focusing on both ranking\nfairness and attribution fairness - ensuring equitable exposure of sources\ncited in the final text. We specifically examine item-side fairness, i.e.,\nwhether retrieved documents receive balanced exposure, and assess how this\naffects both the system's overall performance and the eventual distribution of\ncited sources. Across twelve RAG models and seven tasks, we find that\nfairness-aware retrieval frequently retains or even improves ranking\neffectiveness and generation quality, countering the widespread belief that\nfairness compromises system performance. Moreover, we show that fair retrieval\nleads to more balanced attribution in the final responses, ensuring that the\ncited sources are credited more equitably. Our results underscore the\nimportance of item-side fairness throughout both retrieval and generation\nphases, offering key insights for building more responsible and equitable RAG\nsystems and illustrating promising avenues for future exploration in fair\nranking and source attribution.", "published": "2024-09-17 23:10:04", "link": "http://arxiv.org/abs/2409.11598v3", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "A Joint Spectro-Temporal Relational Thinking Based Acoustic Modeling\n  Framework", "abstract": "Relational thinking refers to the inherent ability of humans to form mental\nimpressions about relations between sensory signals and prior knowledge, and\nsubsequently incorporate them into their model of their world. Despite the\ncrucial role relational thinking plays in human understanding of speech, it has\nyet to be leveraged in any artificial speech recognition systems. Recently,\nthere have been some attempts to correct this oversight, but these have been\nlimited to coarse utterance-level models that operate exclusively in the time\ndomain. In an attempt to narrow the gap between artificial systems and human\nabilities, this paper presents a novel spectro-temporal relational thinking\nbased acoustic modeling framework. Specifically, it first generates numerous\nprobabilistic graphs to model the relationships among speech segments across\nboth time and frequency domains. The relational information rooted in every\npair of nodes within these graphs is then aggregated and embedded into latent\nrepresentations that can be utilized by downstream tasks. Models built upon\nthis framework outperform state-of-the-art systems with a 7.82\\% improvement in\nphoneme recognition tasks over the TIMIT dataset. In-depth analyses further\nreveal that our proposed relational thinking modeling mainly improves the\nmodel's ability to recognize vowels, which are the most likely to be confused\nby phoneme recognizers.", "published": "2024-09-17 05:45:33", "link": "http://arxiv.org/abs/2409.15357v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Watch Your Steps: Observable and Modular Chains of Thought", "abstract": "We propose a variant of chain of thought (CoT) prompting called Program Trace\nPrompting that makes explanations more observable while preserving the power,\ngenerality and flexibility of CoT. In our approach, few-shot CoT demonstrations\nare wrapped in a formal syntax based on Python, and each prompt: identifies and\nnames steps; defines the input/output behavior of steps; and replaces CoT\nexplanations of in-context examples with chains of these formalized steps on\nthe same examples. Program Trace Prompting is applicable to many tasks,\nachieving strong results on the 23 diverse tasks in the BIG-Bench Hard\nbenchmark. More importantly, by instrumenting explanations in this way, we\nenable new types of analysis. In particular, we identify \"non-local errors\"\n(which correspond to incorrectly learning the reasoning method illustrated in\nthe demonstrations) as an unaddressed issue in CoT learning, and we present\nmethods for verifying the modularity of steps in a CoT explanation.", "published": "2024-09-17 23:47:20", "link": "http://arxiv.org/abs/2409.15359v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient and Personalized Mobile Health Event Prediction via Small\n  Language Models", "abstract": "Healthcare monitoring is crucial for early detection, timely intervention,\nand the ongoing management of health conditions, ultimately improving\nindividuals' quality of life. Recent research shows that Large Language Models\n(LLMs) have demonstrated impressive performance in supporting healthcare tasks.\nHowever, existing LLM-based healthcare solutions typically rely on cloud-based\nsystems, which raise privacy concerns and increase the risk of personal\ninformation leakage. As a result, there is growing interest in running these\nmodels locally on devices like mobile phones and wearables to protect users'\nprivacy. Small Language Models (SLMs) are potential candidates to solve privacy\nand computational issues, as they are more efficient and better suited for\nlocal deployment. However, the performance of SLMs in healthcare domains has\nnot yet been investigated. This paper examines the capability of SLMs to\naccurately analyze health data, such as steps, calories, sleep minutes, and\nother vital statistics, to assess an individual's health status. Our results\nshow that, TinyLlama, which has 1.1 billion parameters, utilizes 4.31 GB\nmemory, and has 0.48s latency, showing the best performance compared other four\nstate-of-the-art (SOTA) SLMs on various healthcare applications. Our results\nindicate that SLMs could potentially be deployed on wearable or mobile devices\nfor real-time health monitoring, providing a practical solution for efficient\nand privacy-preserving healthcare.", "published": "2024-09-17 01:57:57", "link": "http://arxiv.org/abs/2409.18987v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Unified Framework to Classify Business Activities into International\n  Standard Industrial Classification through Large Language Models for Circular\n  Economy", "abstract": "Effective information gathering and knowledge codification are pivotal for\ndeveloping recommendation systems that promote circular economy practices. One\npromising approach involves the creation of a centralized knowledge repository\ncataloguing historical waste-to-resource transactions, which subsequently\nenables the generation of recommendations based on past successes. However, a\nsignificant barrier to constructing such a knowledge repository lies in the\nabsence of a universally standardized framework for representing business\nactivities across disparate geographical regions. To address this challenge,\nthis paper leverages Large Language Models (LLMs) to classify textual data\ndescribing economic activities into the International Standard Industrial\nClassification (ISIC), a globally recognized economic activity classification\nframework. This approach enables any economic activity descriptions provided by\nbusinesses worldwide to be categorized into the unified ISIC standard,\nfacilitating the creation of a centralized knowledge repository. Our approach\nachieves a 95% accuracy rate on a 182-label test dataset with fine-tuned GPT-2\nmodel. This research contributes to the global endeavour of fostering\nsustainable circular economy practices by providing a standardized foundation\nfor knowledge codification and recommendation systems deployable across\nregions.", "published": "2024-09-17 05:30:08", "link": "http://arxiv.org/abs/2409.18988v1", "categories": ["cs.CL", "cs.AI", "econ.GN", "q-fin.EC"], "primary_category": "cs.CL"}
{"title": "A Review of Mechanistic Models of Event Comprehension", "abstract": "This review examines theoretical assumptions and computational models of\nevent comprehension, tracing the evolution from discourse comprehension\ntheories to contemporary event cognition frameworks. The review covers key\ndiscourse comprehension accounts, including Construction-Integration, Event\nIndexing, Causal Network, and Resonance models, highlighting their\ncontributions to understanding cognitive processes in comprehension. I then\ndiscuss contemporary theoretical frameworks of event comprehension, including\nEvent Segmentation Theory (Zacks et al., 2007), the Event Horizon Model\n(Radvansky & Zacks, 2014), and Hierarchical Generative Framework (Kuperberg,\n2021), which emphasize prediction, causality, and multilevel representations in\nevent understanding. Building on these theories, I evaluate five computational\nmodels of event comprehension: REPRISE (Butz et al., 2019), Structured Event\nMemory (SEM; Franklin et al., 2020), the Lu model (Lu et al., 2022), the\nGumbsch model (Gumbsch et al., 2022), and the Elman and McRae model (2019). The\nanalysis focuses on their approaches to hierarchical processing, prediction\nmechanisms, and representation learning. Key themes that emerge include the use\nof hierarchical structures as inductive biases, the importance of prediction in\ncomprehension, and diverse strategies for learning event dynamics. The review\nidentifies critical areas for future research, including the need for more\nsophisticated approaches to learning structured representations, integrating\nepisodic memory mechanisms, and developing adaptive updating algorithms for\nworking event models. By synthesizing insights from both theoretical frameworks\nand computational implementations, this review aims to advance our\nunderstanding of human event comprehension and guide future modeling efforts in\ncognitive science.", "published": "2024-09-17 22:10:05", "link": "http://arxiv.org/abs/2409.18992v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Mind the Uncertainty in Human Disagreement: Evaluating Discrepancies\n  between Model Predictions and Human Responses in VQA", "abstract": "Large vision-language models frequently struggle to accurately predict\nresponses provided by multiple human annotators, particularly when those\nresponses exhibit human uncertainty. In this study, we focus on the Visual\nQuestion Answering (VQA) task, and we comprehensively evaluate how well the\nstate-of-the-art vision-language models correlate with the distribution of\nhuman responses. To do so, we categorize our samples based on their levels\n(low, medium, high) of human uncertainty in disagreement (HUD) and employ not\nonly accuracy but also three new human-correlated metrics in VQA, to\ninvestigate the impact of HUD. To better align models with humans, we also\nverify the effect of common calibration and human calibration. Our results show\nthat even BEiT3, currently the best model for this task, struggles to capture\nthe multi-label distribution inherent in diverse human responses. Additionally,\nwe observe that the commonly used accuracy-oriented calibration technique\nadversely affects BEiT3's ability to capture HUD, further widening the gap\nbetween model predictions and human distributions. In contrast, we show the\nbenefits of calibrating models towards human distributions for VQA, better\naligning model confidence with human uncertainty. Our findings highlight that\nfor VQA, the consistent alignment between human responses and model predictions\nis understudied and should become the next crucial target of future studies.", "published": "2024-09-17 13:44:25", "link": "http://arxiv.org/abs/2410.02773v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Learning variant product relationship and variation attributes from\n  e-commerce website structures", "abstract": "We introduce VARM, variant relationship matcher strategy, to identify pairs\nof variant products in e-commerce catalogs. Traditional definitions of entity\nresolution are concerned with whether product mentions refer to the same\nunderlying product. However, this fails to capture product relationships that\nare critical for e-commerce applications, such as having similar, but not\nidentical, products listed on the same webpage or share reviews. Here, we\nformulate a new type of entity resolution in variant product relationships to\ncapture these similar e-commerce product links. In contrast with the\ntraditional definition, the new definition requires both identifying if two\nproducts are variant matches of each other and what are the attributes that\nvary between them. To satisfy these two requirements, we developed a strategy\nthat leverages the strengths of both encoding and generative AI models. First,\nwe construct a dataset that captures webpage product links, and therefore\nvariant product relationships, to train an encoding LLM to predict variant\nmatches for any given pair of products. Second, we use RAG prompted generative\nLLMs to extract variation and common attributes amongst groups of variant\nproducts. To validate our strategy, we evaluated model performance using real\ndata from one of the world's leading e-commerce retailers. The results showed\nthat our strategy outperforms alternative solutions and paves the way to\nexploiting these new type of product relationships.", "published": "2024-09-17 18:24:27", "link": "http://arxiv.org/abs/2410.02779v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.IR"}
{"title": "Adaptive Large Language Models By Layerwise Attention Shortcuts", "abstract": "Transformer architectures are the backbone of the modern AI revolution.\nHowever, they are based on simply stacking the same blocks in dozens of layers\nand processing information sequentially from one block to another. In this\npaper, we propose to challenge this and introduce adaptive computations for\nLLM-like setups, which allow the final layer to attend to all of the\nintermediate layers as it deems fit through the attention mechanism, thereby\nintroducing computational \\textbf{attention shortcuts}. These shortcuts can\nthus make the architecture depth and context adaptive. We showcase four\ndifferent datasets, namely acoustic tokens, natural language, and symbolic\nmusic, and we achieve superior performance for GPT-like architecture. We give\nevidence via attention maps that the models learn complex dependencies across\nlayers that are adaptive in context and depth depending on the input tokens.", "published": "2024-09-17 03:46:01", "link": "http://arxiv.org/abs/2409.10870v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Spontaneous Informal Speech Dataset for Punctuation Restoration", "abstract": "Presently, punctuation restoration models are evaluated almost solely on\nwell-structured, scripted corpora. On the other hand, real-world ASR systems\nand post-processing pipelines typically apply towards spontaneous speech with\nsignificant irregularities, stutters, and deviations from perfect grammar. To\naddress this discrepancy, we introduce SponSpeech, a punctuation restoration\ndataset derived from informal speech sources, which includes punctuation and\ncasing information. In addition to publicly releasing the dataset, we\ncontribute a filtering pipeline that can be used to generate more data. Our\nfiltering pipeline examines the quality of both speech audio and transcription\ntext. We also carefully construct a ``challenging\" test set, aimed at\nevaluating models' ability to leverage audio information to predict otherwise\ngrammatically ambiguous punctuation. SponSpeech is available at\nhttps://github.com/GitHubAccountAnonymous/PR, along with all code for dataset\nbuilding and model runs.", "published": "2024-09-17 14:43:14", "link": "http://arxiv.org/abs/2409.11241v1", "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "NVLM: Open Frontier-Class Multimodal LLMs", "abstract": "We introduce NVLM 1.0, a family of frontier-class multimodal large language\nmodels (LLMs) that achieve state-of-the-art results on vision-language tasks,\nrivaling the leading proprietary models (e.g., GPT-4o) and open-access models\n(e.g., Llama 3-V 405B and InternVL 2). Remarkably, NVLM 1.0 shows improved\ntext-only performance over its LLM backbone after multimodal training. In terms\nof model design, we perform a comprehensive comparison between decoder-only\nmultimodal LLMs (e.g., LLaVA) and cross-attention-based models (e.g.,\nFlamingo). Based on the strengths and weaknesses of both approaches, we propose\na novel architecture that enhances both training efficiency and multimodal\nreasoning capabilities. Furthermore, we introduce a 1-D tile-tagging design for\ntile-based dynamic high-resolution images, which significantly boosts\nperformance on multimodal reasoning and OCR-related tasks. Regarding training\ndata, we meticulously curate and provide detailed information on our multimodal\npretraining and supervised fine-tuning datasets. Our findings indicate that\ndataset quality and task diversity are more important than scale, even during\nthe pretraining phase, across all architectures. Notably, we develop\nproduction-grade multimodality for the NVLM-1.0 models, enabling them to excel\nin vision-language tasks while maintaining and even improving text-only\nperformance compared to their LLM backbones. To achieve this, we craft and\nintegrate a high-quality text-only dataset into multimodal training, alongside\na substantial amount of multimodal math and reasoning data, leading to enhanced\nmath and coding capabilities across modalities. To advance research in the\nfield, we release the model weights at https://huggingface.co/nvidia/NVLM-D-72B\nand will open-source the training code for the community soon.", "published": "2024-09-17 17:59:06", "link": "http://arxiv.org/abs/2409.11402v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Preference Tuning with Human Feedback on Language, Speech, and Vision\n  Tasks: A Survey", "abstract": "Preference tuning is a crucial process for aligning deep generative models\nwith human preferences. This survey offers a thorough overview of recent\nadvancements in preference tuning and the integration of human feedback. The\npaper is organized into three main sections: 1) introduction and preliminaries:\nan introduction to reinforcement learning frameworks, preference tuning tasks,\nmodels, and datasets across various modalities: language, speech, and vision,\nas well as different policy approaches, 2) in-depth exploration of each\npreference tuning approach: a detailed analysis of the methods used in\npreference tuning, and 3) applications, discussion, and future directions: an\nexploration of the applications of preference tuning in downstream tasks,\nincluding evaluation methods for different modalities, and an outlook on future\nresearch directions. Our objective is to present the latest methodologies in\npreference tuning and model alignment, enhancing the understanding of this\nfield for researchers and practitioners. We hope to encourage further\nengagement and innovation in this area.", "published": "2024-09-17 21:28:51", "link": "http://arxiv.org/abs/2409.11564v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Moshi: a speech-text foundation model for real-time dialogue", "abstract": "We introduce Moshi, a speech-text foundation model and full-duplex spoken\ndialogue framework. Current systems for spoken dialogue rely on pipelines of\nindependent components, namely voice activity detection, speech recognition,\ntextual dialogue and text-to-speech. Such frameworks cannot emulate the\nexperience of real conversations. First, their complexity induces a latency of\nseveral seconds between interactions. Second, text being the intermediate\nmodality for dialogue, non-linguistic information that modifies meaning -- such\nas emotion or non-speech sounds -- is lost in the interaction. Finally, they\nrely on a segmentation into speaker turns, which does not take into account\noverlapping speech, interruptions and interjections. Moshi solves these\nindependent issues altogether by casting spoken dialogue as speech-to-speech\ngeneration. Starting from a text language model backbone, Moshi generates\nspeech as tokens from the residual quantizer of a neural audio codec, while\nmodeling separately its own speech and that of the user into parallel streams.\nThis allows for the removal of explicit speaker turns, and the modeling of\narbitrary conversational dynamics. We moreover extend the hierarchical\nsemantic-to-acoustic token generation of previous work to first predict\ntime-aligned text tokens as a prefix to audio tokens. Not only this \"Inner\nMonologue\" method significantly improves the linguistic quality of generated\nspeech, but we also illustrate how it can provide streaming speech recognition\nand text-to-speech. Our resulting model is the first real-time full-duplex\nspoken large language model, with a theoretical latency of 160ms, 200ms in\npractice, and is available at https://github.com/kyutai-labs/moshi.", "published": "2024-09-17 17:55:39", "link": "http://arxiv.org/abs/2410.00037v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "EzAudio: Enhancing Text-to-Audio Generation with Efficient Diffusion\n  Transformer", "abstract": "Latent diffusion models have shown promising results in text-to-audio (T2A)\ngeneration tasks, yet previous models have encountered difficulties in\ngeneration quality, computational cost, diffusion sampling, and data\npreparation. In this paper, we introduce EzAudio, a transformer-based T2A\ndiffusion model, to handle these challenges. Our approach includes several key\ninnovations: (1) We build the T2A model on the latent space of a 1D waveform\nVariational Autoencoder (VAE), avoiding the complexities of handling 2D\nspectrogram representations and using an additional neural vocoder. (2) We\ndesign an optimized diffusion transformer architecture specifically tailored\nfor audio latent representations and diffusion modeling, which enhances\nconvergence speed, training stability, and memory usage, making the training\nprocess easier and more efficient. (3) To tackle data scarcity, we adopt a\ndata-efficient training strategy that leverages unlabeled data for learning\nacoustic dependencies, audio caption data annotated by audio-language models\nfor text-to-audio alignment learning, and human-labeled data for fine-tuning.\n(4) We introduce a classifier-free guidance (CFG) rescaling method that\nsimplifies EzAudio by achieving strong prompt alignment while preserving great\naudio quality when using larger CFG scores, eliminating the need to struggle\nwith finding the optimal CFG score to balance this trade-off. EzAudio surpasses\nexisting open-source models in both objective metrics and subjective\nevaluations, delivering realistic listening experiences while maintaining a\nstreamlined model structure, low training costs, and an easy-to-follow training\npipeline. Code, data, and pre-trained models are released at:\nhttps://haidog-yaqub.github.io/EzAudio-Page/.", "published": "2024-09-17 01:27:28", "link": "http://arxiv.org/abs/2409.10819v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speech Recognition for Analysis of Police Radio Communication", "abstract": "Police departments around the world use two-way radio for coordination. These\nbroadcast police communications (BPC) are a unique source of information about\neveryday police activity and emergency response. Yet BPC are not transcribed,\nand their naturalistic audio properties make automatic transcription\nchallenging. We collect a corpus of roughly 62,000 manually transcribed radio\ntransmissions (~46 hours of audio) to evaluate the feasibility of automatic\nspeech recognition (ASR) using modern recognition models. We evaluate the\nperformance of off-the-shelf speech recognizers, models fine-tuned on BPC data,\nand customized end-to-end models. We find that both human and machine\ntranscription is challenging in this domain. Large off-the-shelf ASR models\nperform poorly, but fine-tuned models can reach the approximate range of human\nperformance. Our work suggests directions for future work, including analysis\nof short utterances and potential miscommunication in police radio\ninteractions. We make our corpus and data annotation pipeline available to\nother researchers, to enable further research on recognition and analysis of\npolice communication.", "published": "2024-09-17 02:46:45", "link": "http://arxiv.org/abs/2409.10858v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An Explainable Probabilistic Attribute Embedding Approach for Spoofed\n  Speech Characterization", "abstract": "We propose a novel approach for spoofed speech characterization through\nexplainable probabilistic attribute embeddings. In contrast to high-dimensional\nraw embeddings extracted from a spoofing countermeasure (CM) whose dimensions\nare not easy to interpret, the probabilistic attributes are designed to gauge\nthe presence or absence of sub-components that make up a specific spoofing\nattack. These attributes are then applied to two downstream tasks: spoofing\ndetection and attack attribution. To enforce interpretability also to the\nback-end, we adopt a decision tree classifier. Our experiments on the\nASVspoof2019 dataset with spoof CM embeddings extracted from three models\n(AASIST, Rawboost-AASIST, SSL-AASIST) suggest that the performance of the\nattribute embeddings are on par with the original raw spoof CM embeddings for\nboth tasks. The best performance achieved with the proposed approach for\nspoofing detection and attack attribution, in terms of accuracy, is 99.7% and\n99.2%, respectively, compared to 99.7% and 94.7% using the raw CM embeddings.\nTo analyze the relative contribution of each attribute, we estimate their\nShapley values. Attributes related to acoustic feature prediction, waveform\ngeneration (vocoder), and speaker modeling are found important for spoofing\ndetection; while duration modeling, vocoder, and input type play a role in\nspoofing attack attribution.", "published": "2024-09-17 09:47:10", "link": "http://arxiv.org/abs/2409.11027v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Zero Shot Text to Speech Augmentation for Automatic Speech Recognition\n  on Low-Resource Accented Speech Corpora", "abstract": "In recent years, automatic speech recognition (ASR) models greatly improved\ntranscription performance both in clean, low noise, acoustic conditions and in\nreverberant environments. However, all these systems rely on the availability\nof hundreds of hours of labelled training data in specific acoustic conditions.\nWhen such a training dataset is not available, the performance of the system is\nheavily impacted. For example, this happens when a specific acoustic\nenvironment or a particular population of speakers is under-represented in the\ntraining dataset. Specifically, in this paper we investigate the effect of\naccented speech data on an off-the-shelf ASR system. Furthermore, we suggest a\nstrategy based on zero-shot text-to-speech to augment the accented speech\ncorpora. We show that this augmentation method is able to mitigate the loss in\nperformance of the ASR system on accented data up to 5% word error rate\nreduction (WERR). In conclusion, we demonstrate that by incorporating a modest\nfraction of real with synthetically generated data, the ASR system exhibits\nsuperior performance compared to a model trained exclusively on authentic\naccented speech with up to 14% WERR.", "published": "2024-09-17 12:02:32", "link": "http://arxiv.org/abs/2409.11107v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Ideal-LLM: Integrating Dual Encoders and Language-Adapted LLM for\n  Multilingual Speech-to-Text", "abstract": "Integrating audio encoders with LLMs through connectors has enabled these\nmodels to process and comprehend audio modalities, significantly enhancing\nspeech-to-text tasks, including automatic speech recognition (ASR) and\nautomatic speech translation (AST). However, these methods often overlook the\ncritical aspect of language adaptation in multilingual settings, relying\ninstead on multilingual data without adequately addressing language\ndifferences. To address this gap, we propose the Ideal-LLM model, which employs\ndual multilingual encoders to enrich language feature information and utilizes\na language-adapted connector to target the adaptation of each language\nspecifically. By leveraging the complementary strengths of Whisper and MMS\nencoders, our approach ensures richer multilingual representations.\nAdditionally, the language-adapted connector enhances modal transformation via\na language weight selector tailored for each language. Experimental results\ndemonstrate that Ideal-LLM significantly improves ASR performance, achieving a\n32.6% relative reduction in average word error rates compared to the standard\nspeech encoder integrated with LLMs and yields an average BLEU score of 36.78\nfor AST task.", "published": "2024-09-17 14:10:57", "link": "http://arxiv.org/abs/2409.11214v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "M-BEST-RQ: A Multi-Channel Speech Foundation Model for Smart Glasses", "abstract": "The growing popularity of multi-channel wearable devices, such as smart\nglasses, has led to a surge of applications such as targeted speech recognition\nand enhanced hearing. However, current approaches to solve these tasks use\nindependently trained models, which may not benefit from large amounts of\nunlabeled data. In this paper, we propose M-BEST-RQ, the first multi-channel\nspeech foundation model for smart glasses, which is designed to leverage\nlarge-scale self-supervised learning (SSL) in an array-geometry agnostic\napproach. While prior work on multi-channel speech SSL only evaluated on\nsimulated settings, we curate a suite of real downstream tasks to evaluate our\nmodel, namely (i) conversational automatic speech recognition (ASR), (ii)\nspherical active source localization, and (iii) glasses wearer voice activity\ndetection, which are sourced from the MMCSG and EasyCom datasets. We show that\na general-purpose M-BEST-RQ encoder is able to match or surpass supervised\nmodels across all tasks. For the conversational ASR task in particular, using\nonly 8 hours of labeled speech, our model outperforms a supervised ASR baseline\nthat is trained on 2000 hours of labeled data, which demonstrates the\neffectiveness of our approach.", "published": "2024-09-17 18:48:47", "link": "http://arxiv.org/abs/2409.11494v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SynthSOD: Developing an Heterogeneous Dataset for Orchestra Music Source\n  Separation", "abstract": "Recent advancements in music source separation have significantly progressed,\nparticularly in isolating vocals, drums, and bass elements from mixed tracks.\nThese developments owe much to the creation and use of large-scale, multitrack\ndatasets dedicated to these specific components. However, the challenge of\nextracting similarly sounding sources from orchestra recordings has not been\nextensively explored, largely due to a scarcity of comprehensive and clean (i.e\nbleed-free) multitrack datasets. In this paper, we introduce a novel multitrack\ndataset called SynthSOD, developed using a set of simulation techniques to\ncreate a realistic (i.e. using high-quality soundfonts), musically motivated,\nand heterogeneous training set comprising different dynamics, natural tempo\nchanges, styles, and conditions. Moreover, we demonstrate the application of a\nwidely used baseline music separation model trained on our synthesized dataset\nw.r.t to the well-known EnsembleSet, and evaluate its performance under both\nsynthetic and real-world conditions.", "published": "2024-09-17 08:58:33", "link": "http://arxiv.org/abs/2409.10995v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Single-stage TTS with Masked Audio Token Modeling and Semantic Knowledge\n  Distillation", "abstract": "Audio token modeling has become a powerful framework for speech synthesis,\nwith two-stage approaches employing semantic tokens remaining prevalent. In\nthis paper, we aim to simplify this process by introducing a semantic knowledge\ndistillation method that enables high-quality speech generation in a single\nstage. Our proposed model improves speech quality, intelligibility, and speaker\nsimilarity compared to a single-stage baseline. Although two-stage systems\nstill lead in intelligibility, our model significantly narrows the gap while\ndelivering comparable speech quality. These findings showcase the potential of\nsingle-stage models to achieve efficient, high-quality TTS with a more compact\nand streamlined architecture.", "published": "2024-09-17 09:08:43", "link": "http://arxiv.org/abs/2409.11003v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "High-Resolution Speech Restoration with Latent Diffusion Model", "abstract": "Traditional speech enhancement methods often oversimplify the task of\nrestoration by focusing on a single type of distortion. Generative models that\nhandle multiple distortions frequently struggle with phone reconstruction and\nhigh-frequency harmonics, leading to breathing and gasping artifacts that\nreduce the intelligibility of reconstructed speech. These models are also\ncomputationally demanding, and many solutions are restricted to producing\noutputs in the wide-band frequency range, which limits their suitability for\nprofessional applications. To address these challenges, we propose Hi-ResLDM, a\nnovel generative model based on latent diffusion designed to remove multiple\ndistortions and restore speech recordings to studio quality, sampled at 48kHz.\nWe benchmark Hi-ResLDM against state-of-the-art methods that leverage GAN and\nConditional Flow Matching (CFM) components, demonstrating superior performance\nin regenerating high-frequency-band details. Hi-ResLDM not only excels in\nnon-instrusive metrics but is also consistently preferred in human evaluation\nand performs competitively on intrusive evaluations, making it ideal for\nhigh-resolution speech restoration.", "published": "2024-09-17 12:55:23", "link": "http://arxiv.org/abs/2409.11145v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Source Disentanglement in Neural Audio Codec", "abstract": "Neural audio codecs have significantly advanced audio compression by\nefficiently converting continuous audio signals into discrete tokens. These\ncodecs preserve high-quality sound and enable sophisticated sound generation\nthrough generative models trained on these tokens. However, existing neural\ncodec models are typically trained on large, undifferentiated audio datasets,\nneglecting the essential discrepancies between sound domains like speech,\nmusic, and environmental sound effects. This oversight complicates data\nmodeling and poses additional challenges to the controllability of sound\ngeneration. To tackle these issues, we introduce the Source-Disentangled Neural\nAudio Codec (SD-Codec), a novel approach that combines audio coding and source\nseparation. By jointly learning audio resynthesis and separation, SD-Codec\nexplicitly assigns audio signals from different domains to distinct codebooks,\nsets of discrete representations. Experimental results indicate that SD-Codec\nnot only maintains competitive resynthesis quality but also, supported by the\nseparation results, demonstrates successful disentanglement of different\nsources in the latent space, thereby enhancing interpretability in audio codec\nand providing potential finer control over the audio generation process.", "published": "2024-09-17 14:21:02", "link": "http://arxiv.org/abs/2409.11228v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Sounds of Home: A Speech-Removed Residential Audio Dataset for Sound\n  Event Detection", "abstract": "This paper presents a residential audio dataset to support sound event\ndetection research for smart home applications aimed at promoting wellbeing for\nolder adults. The dataset is constructed by deploying audio recording systems\nin the homes of 8 participants aged 55-80 years for a 7-day period. Acoustic\ncharacteristics are documented through detailed floor plans and construction\nmaterial information to enable replication of the recording environments for AI\nmodel deployment. A novel automated speech removal pipeline is developed, using\npre-trained audio neural networks to detect and remove segments containing\nspoken voice, while preserving segments containing other sound events. The\nresulting dataset consists of privacy-compliant audio recordings that\naccurately capture the soundscapes and activities of daily living within\nresidential spaces. The paper details the dataset creation methodology, the\nspeech removal pipeline utilizing cascaded model architectures, and an analysis\nof the vocal label distribution to validate the speech removal process. This\ndataset enables the development and benchmarking of sound event detection\nmodels tailored specifically for in-home applications.", "published": "2024-09-17 15:10:36", "link": "http://arxiv.org/abs/2409.11262v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "LC-Protonets: Multi-Label Few-Shot Learning for World Music Audio\n  Tagging", "abstract": "We introduce Label-Combination Prototypical Networks (LC-Protonets) to\naddress the problem of multi-label few-shot classification, where a model must\ngeneralize to new classes based on only a few available examples. Extending\nPrototypical Networks, LC-Protonets generate one prototype per label\ncombination, derived from the power set of labels present in the limited\ntraining items, rather than one prototype per label. Our method is applied to\nautomatic audio tagging across diverse music datasets, covering various\ncultures and including both modern and traditional music, and is evaluated\nagainst existing approaches in the literature. The results demonstrate a\nsignificant performance improvement in almost all domains and training setups\nwhen using LC-Protonets for multi-label classification. In addition to training\na few-shot learning model from scratch, we explore the use of a pre-trained\nmodel, obtained via supervised learning, to embed items in the feature space.\nFine-tuning improves the generalization ability of all methods, yet\nLC-Protonets achieve high-level performance even without fine-tuning, in\ncontrast to the comparative approaches. We finally analyze the scalability of\nthe proposed method, providing detailed quantitative metrics from our\nexperiments. The implementation and experimental setup are made publicly\navailable, offering a benchmark for future research.", "published": "2024-09-17 15:13:07", "link": "http://arxiv.org/abs/2409.11264v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Spatially-Aware Language and Audio Embeddings", "abstract": "Humans can picture a sound scene given an imprecise natural language\ndescription. For example, it is easy to imagine an acoustic environment given a\nphrase like \"the lion roar came from right behind me!\". For a machine to have\nthe same degree of comprehension, the machine must know what a lion is\n(semantic attribute), what the concept of \"behind\" is (spatial attribute) and\nhow these pieces of linguistic information align with the semantic and spatial\nattributes of the sound (what a roar sounds like when its coming from behind).\nState-of-the-art audio foundation models which learn to map between audio\nscenes and natural textual descriptions, are trained on non-spatial audio and\ntext pairs, and hence lack spatial awareness. In contrast, sound event\nlocalization and detection models are limited to recognizing sounds from a\nfixed number of classes, and they localize the source to absolute position\n(e.g., 0.2m) rather than a position described using natural language (e.g.,\n\"next to me\"). To address these gaps, we present ELSA a spatially aware-audio\nand text embedding model trained using multimodal contrastive learning. ELSA\nsupports non-spatial audio, spatial audio, and open vocabulary text captions\ndescribing both the spatial and semantic components of sound. To train ELSA:\n(a) we spatially augment the audio and captions of three open-source audio\ndatasets totaling 4,738 hours of audio, and (b) we design an encoder to capture\nthe semantics of non-spatial audio, and the semantics and spatial attributes of\nspatial audio using contrastive learning. ELSA is competitive with\nstate-of-the-art for both semantic retrieval and 3D source localization. In\nparticular, ELSA achieves +2.8% mean audio-to-text and text-to-audio R@1 above\nthe baseline, and outperforms by -11.6{\\deg} mean-absolute-error in 3D source\nlocalization over the baseline.", "published": "2024-09-17 17:17:25", "link": "http://arxiv.org/abs/2409.11369v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Discrete Unit based Masking for Improving Disentanglement in Voice\n  Conversion", "abstract": "Voice conversion (VC) aims to modify the speaker's identity while preserving\nthe linguistic content. Commonly, VC methods use an encoder-decoder\narchitecture, where disentangling the speaker's identity from linguistic\ninformation is crucial. However, the disentanglement approaches used in these\nmethods are limited as the speaker features depend on the phonetic content of\nthe utterance, compromising disentanglement. This dependency is amplified with\nattention-based methods. To address this, we introduce a novel masking\nmechanism in the input before speaker encoding, masking certain discrete speech\nunits that correspond highly with phoneme classes. Our work aims to reduce the\nphonetic dependency of speaker features by restricting access to some phonetic\ninformation. Furthermore, since our approach is at the input level, it is\napplicable to any encoder-decoder based VC framework. Our approach improves\ndisentanglement and conversion performance across multiple VC methods, showing\nsignificant effectiveness, particularly in attention-based method, with 44%\nrelative improvement in objective intelligibility.", "published": "2024-09-17 21:17:59", "link": "http://arxiv.org/abs/2409.11560v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "PDMX: A Large-Scale Public Domain MusicXML Dataset for Symbolic Music\n  Processing", "abstract": "The recent explosion of generative AI-Music systems has raised numerous\nconcerns over data copyright, licensing music from musicians, and the conflict\nbetween open-source AI and large prestige companies. Such issues highlight the\nneed for publicly available, copyright-free musical data, in which there is a\nlarge shortage, particularly for symbolic music data. To alleviate this issue,\nwe present PDMX: a large-scale open-source dataset of over 250K public domain\nMusicXML scores collected from the score-sharing forum MuseScore, making it the\nlargest available copyright-free symbolic music dataset to our knowledge. PDMX\nadditionally includes a wealth of both tag and user interaction metadata,\nallowing us to efficiently analyze the dataset and filter for high quality\nuser-generated scores. Given the additional metadata afforded by our data\ncollection process, we conduct multitrack music generation experiments\nevaluating how different representative subsets of PDMX lead to different\nbehaviors in downstream models, and how user-rating statistics can be used as\nan effective measure of data quality. Examples can be found at\nhttps://pnlong.github.io/PDMX.demo/.", "published": "2024-09-17 01:48:42", "link": "http://arxiv.org/abs/2409.10831v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Evaluation of pretrained language models on music understanding", "abstract": "Music-text multimodal systems have enabled new approaches to Music\nInformation Research (MIR) applications such as audio-to-text and text-to-audio\nretrieval, text-based song generation, and music captioning. Despite the\nreported success, little effort has been put into evaluating the musical\nknowledge of Large Language Models (LLM). In this paper, we demonstrate that\nLLMs suffer from 1) prompt sensitivity, 2) inability to model negation (e.g.\n'rock song without guitar'), and 3) sensitivity towards the presence of\nspecific words. We quantified these properties as a triplet-based accuracy,\nevaluating the ability to model the relative similarity of labels in a\nhierarchical ontology. We leveraged the Audioset ontology to generate triplets\nconsisting of an anchor, a positive (relevant) label, and a negative (less\nrelevant) label for the genre and instruments sub-tree. We evaluated the\ntriplet-based musical knowledge for six general-purpose Transformer-based\nmodels. The triplets obtained through this methodology required filtering, as\nsome were difficult to judge and therefore relatively uninformative for\nevaluation purposes. Despite the relatively high accuracy reported,\ninconsistencies are evident in all six models, suggesting that off-the-shelf\nLLMs need adaptation to music before use.", "published": "2024-09-17 14:44:49", "link": "http://arxiv.org/abs/2409.11449v1", "categories": ["cs.LG", "cs.AI", "cs.IR", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "3DFacePolicy: Speech-Driven 3D Facial Animation with Diffusion Policy", "abstract": "Audio-driven 3D facial animation has made immersive progress both in research\nand application developments. The newest approaches focus on Transformer-based\nmethods and diffusion-based methods, however, there is still gap in the\nvividness and emotional expression between the generated animation and real\nhuman face. To tackle this limitation, we propose 3DFacePolicy, a diffusion\npolicy model for 3D facial animation prediction. This method generates variable\nand realistic human facial movements by predicting the 3D vertex trajectory on\nthe 3D facial template with diffusion policy instead of facial generation for\nevery frame. It takes audio and vertex states as observations to predict the\nvertex trajectory and imitate real human facial expressions, which keeps the\ncontinuous and natural flow of human emotions. The experiments show that our\napproach is effective in variable and dynamic facial motion synthesizing.", "published": "2024-09-17 02:30:34", "link": "http://arxiv.org/abs/2409.10848v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
