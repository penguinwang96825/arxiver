{"title": "EmojiNet: Building a Machine Readable Sense Inventory for Emoji", "abstract": "Emoji are a contemporary and extremely popular way to enhance electronic\ncommunication. Without rigid semantics attached to them, emoji symbols take on\ndifferent meanings based on the context of a message. Thus, like the word sense\ndisambiguation task in natural language processing, machines also need to\ndisambiguate the meaning or sense of an emoji. In a first step toward achieving\nthis goal, this paper presents EmojiNet, the first machine readable sense\ninventory for emoji. EmojiNet is a resource enabling systems to link emoji with\ntheir context-specific meaning. It is automatically constructed by integrating\nmultiple emoji resources with BabelNet, which is the most comprehensive\nmultilingual sense inventory available to date. The paper discusses its\nconstruction, evaluates the automatic resource creation process, and presents a\nuse case where EmojiNet disambiguates emoji usage in tweets. EmojiNet is\navailable online for use at http://emojinet.knoesis.org.", "published": "2016-10-25 02:36:52", "link": "http://arxiv.org/abs/1610.07710v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Still not there? Comparing Traditional Sequence-to-Sequence Models to\n  Encoder-Decoder Neural Networks on Monotone String Translation Tasks", "abstract": "We analyze the performance of encoder-decoder neural models and compare them\nwith well-known established methods. The latter represent different classes of\ntraditional approaches that are applied to the monotone sequence-to-sequence\ntasks OCR post-correction, spelling correction, grapheme-to-phoneme conversion,\nand lemmatization. Such tasks are of practical relevance for various\nhigher-level research fields including digital humanities, automatic text\ncorrection, and speech recognition. We investigate how well generic\ndeep-learning approaches adapt to these tasks, and how they perform in\ncomparison with established and more specialized methods, including our own\nadaptation of pruned CRFs.", "published": "2016-10-25 09:14:05", "link": "http://arxiv.org/abs/1610.07796v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Document Pre-processing affects Keyphrase Extraction Performance", "abstract": "The SemEval-2010 benchmark dataset has brought renewed attention to the task\nof automatic keyphrase extraction. This dataset is made up of scientific\narticles that were automatically converted from PDF format to plain text and\nthus require careful preprocessing so that irrevelant spans of text do not\nnegatively affect keyphrase extraction performance. In previous work, a wide\nrange of document preprocessing techniques were described but their impact on\nthe overall performance of keyphrase extraction models is still unexplored.\nHere, we re-assess the performance of several keyphrase extraction models and\nmeasure their robustness against increasingly sophisticated levels of document\npreprocessing.", "published": "2016-10-25 09:59:13", "link": "http://arxiv.org/abs/1610.07809v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving historical spelling normalization with bi-directional LSTMs\n  and multi-task learning", "abstract": "Natural-language processing of historical documents is complicated by the\nabundance of variant spellings and lack of annotated data. A common approach is\nto normalize the spelling of historical words to modern forms. We explore the\nsuitability of a deep neural network architecture for this task, particularly a\ndeep bi-LSTM network applied on a character level. Our model compares well to\npreviously established normalization algorithms when evaluated on a diverse set\nof texts from Early New High German. We show that multi-task learning with\nadditional normalization data can improve our model's performance further.", "published": "2016-10-25 12:30:26", "link": "http://arxiv.org/abs/1610.07844v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sequence Segmentation Using Joint RNN and Structured Prediction Models", "abstract": "We describe and analyze a simple and effective algorithm for sequence\nsegmentation applied to speech processing tasks. We propose a neural\narchitecture that is composed of two modules trained jointly: a recurrent\nneural network (RNN) module and a structured prediction model. The RNN outputs\nare considered as feature functions to the structured model. The overall model\nis trained with a structured loss function which can be designed to the given\nsegmentation task. We demonstrate the effectiveness of our method by applying\nit to two simple tasks commonly used in phonetic studies: word segmentation and\nvoice onset time segmentation. Results sug- gest the proposed model is superior\nto previous methods, ob- taining state-of-the-art results on the tested\ndatasets.", "published": "2016-10-25 15:21:25", "link": "http://arxiv.org/abs/1610.07918v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Statistical Machine Translation for Indian Languages: Mission Hindi 2", "abstract": "This paper presents Centre for Development of Advanced Computing Mumbai's\n(CDACM) submission to NLP Tools Contest on Statistical Machine Translation in\nIndian Languages (ILSMT) 2015 (collocated with ICON 2015). The aim of the\ncontest was to collectively explore the effectiveness of Statistical Machine\nTranslation (SMT) while translating within Indian languages and between English\nand Indian languages. In this paper, we report our work on all five language\npairs, namely Bengali-Hindi (\\bnhi), Marathi-Hindi (\\mrhi), Tamil-Hindi\n(\\tahi), Telugu-Hindi (\\tehi), and English-Hindi (\\enhi) for Health, Tourism,\nand General domains. We have used suffix separation, compound splitting and\npreordering prior to SMT training and testing.", "published": "2016-10-25 18:20:08", "link": "http://arxiv.org/abs/1610.08000v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge will Propel Machine Understanding of Content: Extrapolating\n  from Current Examples", "abstract": "Machine Learning has been a big success story during the AI resurgence. One\nparticular stand out success relates to unsupervised learning from a massive\namount of data, albeit much of it relates to one modality/type of data at a\ntime. In spite of early assertions of the unreasonable effectiveness of data,\nthere is increasing recognition of utilizing knowledge whenever it is available\nor can be created purposefully. In this paper, we focus on discussing the\nindispensable role of knowledge for deeper understanding of complex text and\nmultimodal data in situations where (i) large amounts of training data\n(labeled/unlabeled) are not available or labor intensive to create, (ii) the\nobjects (particularly text) to be recognized are complex (i.e., beyond simple\nentity-person/location/organization names), such as implicit entities and\nhighly subjective content, and (iii) applications need to use complementary or\nrelated data in multiple modalities/media. What brings us to the cusp of rapid\nprogress is our ability to (a) create knowledge, varying from comprehensive or\ncross domain to domain or application specific, and (b) carefully exploit the\nknowledge to further empower or extend the applications of ML/NLP techniques.\nUsing the early results in several diverse situations - both in data types and\napplications - we seek to foretell unprecedented progress in our ability for\ndeeper understanding and exploitation of multimodal data.", "published": "2016-10-25 02:13:53", "link": "http://arxiv.org/abs/1610.07708v2", "categories": ["cs.AI", "cs.CL", "I.2"], "primary_category": "cs.AI"}
{"title": "Dis-S2V: Discourse Informed Sen2Vec", "abstract": "Vector representation of sentences is important for many text processing\ntasks that involve clustering, classifying, or ranking sentences. Recently,\ndistributed representation of sentences learned by neural models from unlabeled\ndata has been shown to outperform the traditional bag-of-words representation.\nHowever, most of these learning methods consider only the content of a sentence\nand disregard the relations among sentences in a discourse by and large.\n  In this paper, we propose a series of novel models for learning latent\nrepresentations of sentences (Sen2Vec) that consider the content of a sentence\nas well as inter-sentence relations. We first represent the inter-sentence\nrelations with a language network and then use the network to induce contextual\ninformation into the content-based Sen2Vec models. Two different approaches are\nintroduced to exploit the information in the network. Our first approach\nretrofits (already trained) Sen2Vec vectors with respect to the network in two\ndifferent ways: (1) using the adjacency relations of a node, and (2) using a\nstochastic sampling method which is more flexible in sampling neighbors of a\nnode. The second approach uses a regularizer to encode the information in the\nnetwork into the existing Sen2Vec model. Experimental results show that our\nproposed models outperform existing methods in three fundamental information\nsystem tasks demonstrating the effectiveness of our approach. The models\nleverage the computational power of multi-core CPUs to achieve fine-grained\ncomputational efficiency. We make our code publicly available upon acceptance.", "published": "2016-10-25 20:19:35", "link": "http://arxiv.org/abs/1610.08078v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Modeling Ambiguity, Subjectivity, and Diverging Viewpoints in Opinion\n  Question Answering Systems", "abstract": "Product review websites provide an incredible lens into the wide variety of\nopinions and experiences of different people, and play a critical role in\nhelping users discover products that match their personal needs and\npreferences. To help address questions that can't easily be answered by reading\nothers' reviews, some review websites also allow users to pose questions to the\ncommunity via a question-answering (QA) system. As one would expect, just as\nopinions diverge among different reviewers, answers to such questions may also\nbe subjective, opinionated, and divergent. This means that answering such\nquestions automatically is quite different from traditional QA tasks, where it\nis assumed that a single `correct' answer is available. While recent work\nintroduced the idea of question-answering using product reviews, it did not\naccount for two aspects that we consider in this paper: (1) Questions have\nmultiple, often divergent, answers, and this full spectrum of answers should\nsomehow be used to train the system; and (2) What makes a `good' answer depends\non the asker and the answerer, and these factors should be incorporated in\norder for the system to be more personalized. Here we build a new QA dataset\nwith 800 thousand questions---and over 3.1 million answers---and show that\nexplicitly accounting for personalization and ambiguity leads both to\nquantitatively better answers, but also a more nuanced view of the range of\nsupporting, but subjective, opinions.", "published": "2016-10-25 21:08:15", "link": "http://arxiv.org/abs/1610.08095v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
