{"title": "Frequency-Aware Contrastive Learning for Neural Machine Translation", "abstract": "Low-frequency word prediction remains a challenge in modern neural machine\ntranslation (NMT) systems. Recent adaptive training methods promote the output\nof infrequent words by emphasizing their weights in the overall training\nobjectives. Despite the improved recall of low-frequency words, their\nprediction precision is unexpectedly hindered by the adaptive objectives.\nInspired by the observation that low-frequency words form a more compact\nembedding space, we tackle this challenge from a representation learning\nperspective. Specifically, we propose a frequency-aware token-level contrastive\nlearning method, in which the hidden state of each decoding step is pushed away\nfrom the counterparts of other target words, in a soft contrastive way based on\nthe corresponding word frequencies. We conduct experiments on widely used NIST\nChinese-English and WMT14 English-German translation tasks. Empirical results\nshow that our proposed methods can not only significantly improve the\ntranslation quality but also enhance lexical diversity and optimize word\nrepresentation space. Further investigation reveals that, comparing with\nrelated adaptive training strategies, the superiority of our method on\nlow-frequency word prediction lies in the robustness of token-level recall\nacross different frequencies without sacrificing precision.", "published": "2021-12-29 10:10:10", "link": "http://arxiv.org/abs/2112.14484v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LeSICiN: A Heterogeneous Graph-based Approach for Automatic Legal\n  Statute Identification from Indian Legal Documents", "abstract": "The task of Legal Statute Identification (LSI) aims to identify the legal\nstatutes that are relevant to a given description of Facts or evidence of a\nlegal case. Existing methods only utilize the textual content of Facts and\nlegal articles to guide such a task. However, the citation network among case\ndocuments and legal statutes is a rich source of additional information, which\nis not considered by existing models. In this work, we take the first step\ntowards utilising both the text and the legal citation network for the LSI\ntask. We curate a large novel dataset for this task, including Facts of cases\nfrom several major Indian Courts of Law, and statutes from the Indian Penal\nCode (IPC). Modeling the statutes and training documents as a heterogeneous\ngraph, our proposed model LeSICiN can learn rich textual and graphical\nfeatures, and can also tune itself to correlate these features. Thereafter, the\nmodel can be used to inductively predict links between test documents (new\nnodes whose graphical features are not available to the model) and statutes\n(existing nodes). Extensive experiments on the dataset show that our model\ncomfortably outperforms several state-of-the-art baselines, by exploiting the\ngraphical structure along with textual features. The dataset and our codes are\navailable at https://github.com/Law-AI/LeSICiN.", "published": "2021-12-29 18:39:35", "link": "http://arxiv.org/abs/2112.14731v1", "categories": ["cs.CL", "I.2.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "Attention-based Bidirectional LSTM for Deceptive Opinion Spam\n  Classification", "abstract": "Online Reviews play a vital role in e commerce for decision making. Much of\nthe population makes the decision of which places, restaurant to visit, what to\nbuy and from where to buy based on the reviews posted on the respective\nplatforms. A fraudulent review or opinion spam is categorized as an untruthful\nor deceptive review. Positive reviews of a product or a restaurant helps\nattract customers and thereby lead to an increase in sales whereas negative\nreviews may hamper the progress of a restaurant or sales of a product and\nthereby lead to defamed reputation and loss. Fraudulent reviews are\ndeliberately posted on various online review platforms to trick customers to\nbuy, visit or distract against a product or a restaurant. They are also written\nto commend or discredit the product's repute. The work aims at detecting and\nclassifying the reviews as deceptive or truthful. It involves use of various\ndeep learning techniques for classifying the reviews and an overview of\nproposed approach involving Attention based Bidirectional LSTM to tackle issues\nrelated to semantic information in reviews and a comparative study over\nbaseline machine learning techniques for review classification.", "published": "2021-12-29 19:02:04", "link": "http://arxiv.org/abs/2112.14789v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Materialized Knowledge Bases from Commonsense Transformers", "abstract": "Starting from the COMET methodology by Bosselut et al. (2019), generating\ncommonsense knowledge directly from pre-trained language models has recently\nreceived significant attention. Surprisingly, up to now no materialized\nresource of commonsense knowledge generated this way is publicly available.\nThis paper fills this gap, and uses the materialized resources to perform a\ndetailed analysis of the potential of this approach in terms of precision and\nrecall. Furthermore, we identify common problem cases, and outline use cases\nenabled by materialized resources. We posit that the availability of these\nresources is important for the advancement of the field, as it enables an\noff-the-shelf-use of the resulting knowledge, as well as further analyses on\nits strengths and weaknesses.", "published": "2021-12-29 20:22:05", "link": "http://arxiv.org/abs/2112.14815v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fake or Genuine? Contextualised Text Representation for Fake Review\n  Detection", "abstract": "Online reviews have a significant influence on customers' purchasing\ndecisions for any products or services. However, fake reviews can mislead both\nconsumers and companies. Several models have been developed to detect fake\nreviews using machine learning approaches. Many of these models have some\nlimitations resulting in low accuracy in distinguishing between fake and\ngenuine reviews. These models focused only on linguistic features to detect\nfake reviews and failed to capture the semantic meaning of the reviews. To deal\nwith this, this paper proposes a new ensemble model that employs transformer\narchitecture to discover the hidden patterns in a sequence of fake reviews and\ndetect them precisely. The proposed approach combines three transformer models\nto improve the robustness of fake and genuine behaviour profiling and modelling\nto detect fake reviews. The experimental results using semi-real benchmark\ndatasets showed the superiority of the proposed model over state-of-the-art\nmodels.", "published": "2021-12-29 00:54:47", "link": "http://arxiv.org/abs/2112.14343v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Variational Learning for the Inverted Beta-Liouville Mixture Model and\n  Its Application to Text Categorization", "abstract": "The finite invert Beta-Liouville mixture model (IBLMM) has recently gained\nsome attention due to its positive data modeling capability. Under the\nconventional variational inference (VI) framework, the analytically tractable\nsolution to the optimization of the variational posterior distribution cannot\nbe obtained, since the variational object function involves evaluation of\nintractable moments. With the recently proposed extended variational inference\n(EVI) framework, a new function is proposed to replace the original variational\nobject function in order to avoid intractable moment computation, so that the\nanalytically tractable solution of the IBLMM can be derived in an elegant way.\nThe good performance of the proposed approach is demonstrated by experiments\nwith both synthesized data and a real-world application namely text\ncategorization.", "published": "2021-12-29 03:03:44", "link": "http://arxiv.org/abs/2112.14375v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Application of Hierarchical Temporal Memory Theory for Document\n  Categorization", "abstract": "The current work intends to study the performance of the Hierarchical\nTemporal Memory(HTM) theory for automated classification of text as well as\ndocuments. HTM is a biologically inspired theory based on the working\nprinciples of the human neocortex. The current study intends to provide an\nalternative framework for document categorization using the Spatial Pooler\nlearning algorithm in the HTM Theory. As HTM accepts only a stream of binary\ndata as input, Latent Semantic Indexing(LSI) technique is used for extracting\nthe top features from the input and converting them into binary format. The\nSpatial Pooler algorithm converts the binary input into sparse patterns with\nsimilar input text having overlapping spatial patterns making it easy for\nclassifying the patterns into categories. The results obtained prove that HTM\ntheory, although is in its nascent stages, performs at par with most of the\npopular machine learning based classifiers.", "published": "2021-12-29 20:34:03", "link": "http://arxiv.org/abs/2112.14820v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Repairing Adversarial Texts through Perturbation", "abstract": "It is known that neural networks are subject to attacks through adversarial\nperturbations, i.e., inputs which are maliciously crafted through perturbations\nto induce wrong predictions. Furthermore, such attacks are impossible to\neliminate, i.e., the adversarial perturbation is still possible after applying\nmitigation methods such as adversarial training. Multiple approaches have been\ndeveloped to detect and reject such adversarial inputs, mostly in the image\ndomain. Rejecting suspicious inputs however may not be always feasible or\nideal. First, normal inputs may be rejected due to false alarms generated by\nthe detection algorithm. Second, denial-of-service attacks may be conducted by\nfeeding such systems with adversarial inputs. To address the gap, in this work,\nwe propose an approach to automatically repair adversarial texts at runtime.\nGiven a text which is suspected to be adversarial, we novelly apply multiple\nadversarial perturbation methods in a positive way to identify a repair, i.e.,\na slightly mutated but semantically equivalent text that the neural network\ncorrectly classifies. Our approach has been experimented with multiple models\ntrained for natural language processing tasks and the results show that our\napproach is effective, i.e., it successfully repairs about 80\\% of the\nadversarial texts. Furthermore, depending on the applied perturbation method,\nan adversarial text could be repaired in as short as one second on average.", "published": "2021-12-29 03:57:02", "link": "http://arxiv.org/abs/2201.02504v1", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Fine-Tuning Transformers: Vocabulary Transfer", "abstract": "Transformers are responsible for the vast majority of recent advances in\nnatural language processing. The majority of practical natural language\nprocessing applications of these models are typically enabled through transfer\nlearning. This paper studies if corpus-specific tokenization used for\nfine-tuning improves the resulting performance of the model. Through a series\nof experiments, we demonstrate that such tokenization combined with the\ninitialization and fine-tuning strategy for the vocabulary tokens speeds up the\ntransfer and boosts the performance of the fine-tuned model. We call this\naspect of transfer facilitation vocabulary transfer.", "published": "2021-12-29 14:22:42", "link": "http://arxiv.org/abs/2112.14569v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50, 91F20", "I.2.7"], "primary_category": "cs.CL"}
