{"title": "Anchor Prediction: A Topic Modeling Approach", "abstract": "Networks of documents connected by hyperlinks, such as Wikipedia, are\nubiquitous. Hyperlinks are inserted by the authors to enrich the text and\nfacilitate the navigation through the network. However, authors tend to insert\nonly a fraction of the relevant hyperlinks, mainly because this is a time\nconsuming task. In this paper we address an annotation, which we refer to as\nanchor prediction. Even though it is conceptually close to link prediction or\nentity linking, it is a different task that require developing a specific\nmethod to solve it. Given a source document and a target document, this task\nconsists in automatically identifying anchors in the source document, i.e words\nor terms that should carry a hyperlink pointing towards the target document. We\npropose a contextualized relational topic model, CRTM, that models directed\nlinks between documents as a function of the local context of the anchor in the\nsource document and the whole content of the target document. The model can be\nused to predict anchors in a source document, given the target document,\nwithout relying on a dictionary of previously seen mention or title, nor any\nexternal knowledge graph. Authors can benefit from CRTM, by letting it\nautomatically suggest hyperlinks, given a new document and the set of target\ndocument to connect to. It can also benefit to readers, by dynamically\ninserting hyperlinks between the documents they're reading. Experiments\nconducted on several Wikipedia corpora (in English, Italian and German)\nhighlight the practical usefulness of anchor prediction and demonstrate the\nrelevancy of our approach.", "published": "2022-05-29 11:26:52", "link": "http://arxiv.org/abs/2205.14631v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SFE-AI at SemEval-2022 Task 11: Low-Resource Named Entity Recognition\n  using Large Pre-trained Language Models", "abstract": "Large scale pre-training models have been widely used in named entity\nrecognition (NER) tasks. However, model ensemble through parameter averaging or\nvoting can not give full play to the differentiation advantages of different\nmodels, especially in the open domain. This paper describes our NER system in\nthe SemEval 2022 task11: MultiCoNER. We proposed an effective system to\nadaptively ensemble pre-trained language models by a Transformer layer. By\nassigning different weights to each model for different inputs, we adopted the\nTransformer layer to integrate the advantages of diverse models effectively.\nExperimental results show that our method achieves superior performances in\nFarsi and Dutch.", "published": "2022-05-29 13:40:14", "link": "http://arxiv.org/abs/2205.14660v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoNT: Contrastive Neural Text Generation", "abstract": "Recently, contrastive learning attracts increasing interests in neural text\ngeneration as a new solution to alleviate the exposure bias problem. It\nintroduces a sequence-level training signal which is crucial to generation\ntasks that always rely on auto-regressive decoding. However, previous methods\nusing contrastive learning in neural text generation usually lead to inferior\nperformance. In this paper, we analyse the underlying reasons and propose a new\nContrastive Neural Text generation framework, CoNT. CoNT addresses bottlenecks\nthat prevent contrastive learning from being widely adopted in generation tasks\nfrom three aspects -- the construction of contrastive examples, the choice of\nthe contrastive loss, and the strategy in decoding. We validate CoNT on five\ngeneration tasks with ten benchmarks, including machine translation,\nsummarization, code comment generation, data-to-text generation and commonsense\ngeneration. Experimental results show that CoNT clearly outperforms the\nconventional training framework on all the ten benchmarks with a convincing\nmargin. Especially, CoNT surpasses previous the most competitive contrastive\nlearning method for text generation, by 1.50 BLEU on machine translation and\n1.77 ROUGE-1 on summarization, respectively. It achieves new state-of-the-art\non summarization, code comment generation (without external data) and\ndata-to-text generation.", "published": "2022-05-29 15:18:37", "link": "http://arxiv.org/abs/2205.14690v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VD-PCR: Improving Visual Dialog with Pronoun Coreference Resolution", "abstract": "The visual dialog task requires an AI agent to interact with humans in\nmulti-round dialogs based on a visual environment. As a common linguistic\nphenomenon, pronouns are often used in dialogs to improve the communication\nefficiency. As a result, resolving pronouns (i.e., grounding pronouns to the\nnoun phrases they refer to) is an essential step towards understanding dialogs.\nIn this paper, we propose VD-PCR, a novel framework to improve Visual Dialog\nunderstanding with Pronoun Coreference Resolution in both implicit and explicit\nways. First, to implicitly help models understand pronouns, we design novel\nmethods to perform the joint training of the pronoun coreference resolution and\nvisual dialog tasks. Second, after observing that the coreference relationship\nof pronouns and their referents indicates the relevance between dialog rounds,\nwe propose to explicitly prune the irrelevant history rounds in visual dialog\nmodels' input. With pruned input, the models can focus on relevant dialog\nhistory and ignore the distraction in the irrelevant one. With the proposed\nimplicit and explicit methods, VD-PCR achieves state-of-the-art experimental\nresults on the VisDial dataset.", "published": "2022-05-29 15:29:50", "link": "http://arxiv.org/abs/2205.14693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning as Conversation: Dialogue Systems Reinforced for Information\n  Acquisition", "abstract": "We propose novel AI-empowered chat bots for learning as conversation where a\nuser does not read a passage but gains information and knowledge through\nconversation with a teacher bot. Our information-acquisition-oriented dialogue\nsystem employs a novel adaptation of reinforced self-play so that the system\ncan be transferred to various domains without in-domain dialogue data, and can\ncarry out conversations both informative and attentive to users. Our extensive\nsubjective and objective evaluations on three large public data corpora\ndemonstrate the effectiveness of our system to deliver knowledge-intensive and\nattentive conversations and help end users substantially gain knowledge without\nreading passages. Our code and datasets are publicly available for follow-up\nresearch.", "published": "2022-05-29 19:42:25", "link": "http://arxiv.org/abs/2205.14748v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MiniDisc: Minimal Distillation Schedule for Language Model Compression", "abstract": "Recent studies have uncovered that language model distillation is less\neffective when facing a large capacity gap between the teacher and the student,\nand introduced teacher assistant-based distillation to bridge the gap. As a\nconnection, the scale and the performance of the teacher assistant is of vital\nimportance to bring the knowledge from the teacher to the student. However,\nexisting teacher assistant-based methods require maximally many trials before\nscheduling an optimal teacher assistant. To this end, we propose a minimal\ndistillation schedule (MiniDisc) for scheduling the optimal teacher assistant\nin minimally one trial. In particular, motivated by the finding that the\nperformance of the student is positively correlated to the scale-performance\ntradeoff of the teacher assistant, MiniDisc is designed with a\n$\\lambda$-tradeoff to measure the optimality of the teacher assistant without\ntrial distillation to the student. MiniDisc then can schedule the optimal\nteacher assistant with the best $\\lambda$-tradeoff in a sandwich framework.\nMiniDisc is evaluated with an extensive set of experiments on GLUE.\nExperimental results demonstrate the improved efficiency our MiniDisc compared\nto several state-of-the-art baselines. We further apply MiniDisc to a language\nmodel with billions of parameters and show its scalability.", "published": "2022-05-29 04:22:48", "link": "http://arxiv.org/abs/2205.14570v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models,\n  and Library", "abstract": "Despite being the third most popular language in India, the Marathi language\nlacks useful NLP resources. Moreover, popular NLP libraries do not have support\nfor the Marathi language. With L3Cube-MahaNLP, we aim to build resources and a\nlibrary for Marathi natural language processing. We present datasets and\ntransformer models for supervised tasks like sentiment analysis, named entity\nrecognition, and hate speech detection. We have also published a monolingual\nMarathi corpus for unsupervised language modeling tasks. Overall we present\nMahaCorpus, MahaSent, MahaNER, and MahaHate datasets and their corresponding\nMahaBERT models fine-tuned on these datasets. We aim to move ahead of benchmark\ndatasets and prepare useful resources for Marathi. The resources are available\nat https://github.com/l3cube-pune/MarathiNLP.", "published": "2022-05-29 17:51:00", "link": "http://arxiv.org/abs/2205.14728v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UPB at SemEval-2022 Task 5: Enhancing UNITER with Image Sentiment and\n  Graph Convolutional Networks for Multimedia Automatic Misogyny Identification", "abstract": "In recent times, the detection of hate-speech, offensive, or abusive language\nin online media has become an important topic in NLP research due to the\nexponential growth of social media and the propagation of such messages, as\nwell as their impact. Misogyny detection, even though it plays an important\npart in hate-speech detection, has not received the same attention. In this\npaper, we describe our classification systems submitted to the SemEval-2022\nTask 5: MAMI - Multimedia Automatic Misogyny Identification. The shared task\naimed to identify misogynous content in a multi-modal setting by analysing meme\nimages together with their textual captions. To this end, we propose two models\nbased on the pre-trained UNITER model, one enhanced with an image sentiment\nclassifier, whereas the second leverages a Vocabulary Graph Convolutional\nNetwork (VGCN). Additionally, we explore an ensemble using the aforementioned\nmodels. Our best model reaches an F1-score of 71.4% in Sub-task A and 67.3% for\nSub-task B positioning our team in the upper third of the leaderboard. We\nrelease the code and experiments for our models on GitHub", "published": "2022-05-29 21:12:36", "link": "http://arxiv.org/abs/2205.14769v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "COVID-19 Literature Mining and Retrieval using Text Mining Approaches", "abstract": "The novel coronavirus disease (COVID-19) began in Wuhan, China, in late 2019\nand to date has infected over 148M people worldwide, resulting in 3.12M deaths.\nOn March 10, 2020, the World Health Organisation (WHO) declared it as a global\npandemic. Many academicians and researchers started to publish papers\ndescribing the latest discoveries on covid-19. The large influx of publications\nmade it hard for other researchers to go through a large amount of data and\nfind the appropriate one that helps their research. So, the proposed model\nattempts to extract relavent titles from the large corpus of research\npublications which makes the job easy for the researchers. Allen Institute for\nAI released the CORD-19 dataset, which consists of 2,00,000 journal articles\nrelated to coronavirus-related research publications from PubMed's PMC, WHO\n(World Health Organization), bioRxiv, and medRxiv pre-prints. Along with this\ndocument corpus, they have also provided a topics dataset named topics-rnd3\nconsisting of a list of topics. Each topic has three types of representations\nlike query, question, and narrative. These Datasets are made open for research,\nand also they released a TREC-COVID competition on Kaggle. Using these topics\nlike queries, our goal is to find out the relevant documents in the CORD-19\ndataset. In this research, relevant documents should be recognized for the\nposed topics in topics-rnd3 data set. The proposed model uses Natural Language\nProcessing(NLP) techniques like Bag-of-Words, Average Word-2-Vec, Average BERT\nBase model and Tf-Idf weighted Word2Vec model to fabricate vectors for query,\nquestion, narrative, and combinations of them. Similarly, fabricate vectors for\ntitles in the CORD-19 dataset. After fabricating vectors, cosine similarity is\nused for finding similarities between every two vectors. Cosine similarity\nhelps us to find relevant documents for the given topic.", "published": "2022-05-29 22:34:19", "link": "http://arxiv.org/abs/2205.14781v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "BN-HTRd: A Benchmark Dataset for Document Level Offline Bangla\n  Handwritten Text Recognition (HTR) and Line Segmentation", "abstract": "We introduce a new dataset for offline Handwritten Text Recognition (HTR)\nfrom images of Bangla scripts comprising words, lines, and document-level\nannotations. The BN-HTRd dataset is based on the BBC Bangla News corpus, meant\nto act as ground truth texts. These texts were subsequently used to generate\nthe annotations that were filled out by people with their handwriting. Our\ndataset includes 788 images of handwritten pages produced by approximately 150\ndifferent writers. It can be adopted as a basis for various handwriting\nclassification tasks such as end-to-end document recognition, word-spotting,\nword or line segmentation, and so on. We also propose a scheme to segment\nBangla handwritten document images into corresponding lines in an unsupervised\nmanner. Our line segmentation approach takes care of the variability involved\nin different writing styles, accurately segmenting complex handwritten text\nlines of curvilinear nature. Along with a bunch of pre-processing and\nmorphological operations, both Hough line and circle transforms were employed\nto distinguish different linear components. In order to arrange those\ncomponents into their corresponding lines, we followed an unsupervised\nclustering approach. The average success rate of our segmentation technique is\n81.57% in terms of FM metrics (similar to F-measure) with a mean Average\nPrecision (mAP) of 0.547.", "published": "2022-05-29 22:56:26", "link": "http://arxiv.org/abs/2206.08977v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Generalizing Multimodal Pre-training into Multilingual via Language\n  Acquisition", "abstract": "English-based Vision-Language Pre-training (VLP) has achieved great success\nin various downstream tasks. Some efforts have been taken to generalize this\nsuccess to non-English languages through Multilingual Vision-Language\nPre-training (M-VLP). However, due to the large number of languages, M-VLP\nmodels often require huge computing resources and cannot be flexibly extended\nto new languages. In this work, we propose a \\textbf{M}ulti\\textbf{L}ingual\n\\textbf{A}cquisition (MLA) framework that can easily generalize a monolingual\nVision-Language Pre-training model into multilingual. Specifically, we design a\nlightweight language acquisition encoder based on state-of-the-art monolingual\nVLP models. We further propose a two-stage training strategy to optimize the\nlanguage acquisition encoder, namely the Native Language Transfer stage and the\nLanguage Exposure stage. With much less multilingual training data and\ncomputing resources, our model achieves state-of-the-art performance on\nmultilingual image-text and video-text retrieval benchmarks.", "published": "2022-05-29 08:53:22", "link": "http://arxiv.org/abs/2206.11091v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning Locality and Isotropy in Dialogue Modeling", "abstract": "Existing dialogue modeling methods have achieved promising performance on\nvarious dialogue tasks with the aid of Transformer and the large-scale\npre-trained language models. However, some recent studies revealed that the\ncontext representations produced by these methods suffer the problem of\nanisotropy. In this paper, we find that the generated representations are also\nnot conversational, losing the conversation structure information during the\ncontext modeling stage. To this end, we identify two properties in dialogue\nmodeling, i.e., locality and isotropy, and present a simple method for dialogue\nrepresentation calibration, namely SimDRC, to build isotropic and\nconversational feature spaces. Experimental results show that our approach\nsignificantly outperforms the current state-of-the-art models on three dialogue\ntasks across the automatic and human evaluation metrics. More in-depth analyses\nfurther confirm the effectiveness of our proposed approach.", "published": "2022-05-29 06:48:53", "link": "http://arxiv.org/abs/2205.14583v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Decoupling Knowledge from Memorization: Retrieval-augmented Prompt\n  Learning", "abstract": "Prompt learning approaches have made waves in natural language processing by\ninducing better few-shot performance while they still follow a parametric-based\nlearning paradigm; the oblivion and rote memorization problems in learning may\nencounter unstable generalization issues. Specifically, vanilla prompt learning\nmay struggle to utilize atypical instances by rote during fully-supervised\ntraining or overfit shallow patterns with low-shot data. To alleviate such\nlimitations, we develop RetroPrompt with the motivation of decoupling knowledge\nfrom memorization to help the model strike a balance between generalization and\nmemorization. In contrast with vanilla prompt learning, RetroPrompt constructs\nan open-book knowledge-store from training instances and implements a retrieval\nmechanism during the process of input, training and inference, thus equipping\nthe model with the ability to retrieve related contexts from the training\ncorpus as cues for enhancement. Extensive experiments demonstrate that\nRetroPrompt can obtain better performance in both few-shot and zero-shot\nsettings. Besides, we further illustrate that our proposed RetroPrompt can\nyield better generalization abilities with new datasets. Detailed analysis of\nmemorization indeed reveals RetroPrompt can reduce the reliance of language\nmodels on memorization; thus, improving generalization for downstream tasks.\nCode is available in\nhttps://github.com/zjunlp/PromptKG/tree/main/research/RetroPrompt.", "published": "2022-05-29 16:07:30", "link": "http://arxiv.org/abs/2205.14704v5", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset\n  for Conversational AI", "abstract": "Human language expression is based on the subjective construal of the\nsituation instead of the objective truth conditions, which means that speakers'\npersonalities and emotions after cognitive processing have an important\ninfluence on conversation. However, most existing datasets for conversational\nAI ignore human personalities and emotions, or only consider part of them. It's\ndifficult for dialogue systems to understand speakers' personalities and\nemotions although large-scale pre-training language models have been widely\nused. In order to consider both personalities and emotions in the process of\nconversation generation, we propose CPED, a large-scale Chinese personalized\nand emotional dialogue dataset, which consists of multi-source knowledge\nrelated to empathy and personal characteristic. These knowledge covers gender,\nBig Five personality traits, 13 emotions, 19 dialogue acts and 10 scenes. CPED\ncontains more than 12K dialogues of 392 speakers from 40 TV shows. We release\nthe textual dataset with audio features and video features according to the\ncopyright claims, privacy issues, terms of service of video platforms. We\nprovide detailed description of the CPED construction process and introduce\nthree tasks for conversational AI, including personality recognition, emotion\nrecognition in conversations as well as personalized and emotional conversation\ngeneration. Finally, we provide baseline systems for these tasks and consider\nthe function of speakers' personalities and emotions on conversation. Our\nmotivation is to propose a dataset to be widely adopted by the NLP community as\na new open benchmark for conversational AI research. The full dataset is\navailable at https://github.com/scutcyr/CPED.", "published": "2022-05-29 17:45:12", "link": "http://arxiv.org/abs/2205.14727v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Modeling Disagreement in Automatic Data Labelling for Semi-Supervised\n  Learning in Clinical Natural Language Processing", "abstract": "Computational models providing accurate estimates of their uncertainty are\ncrucial for risk management associated with decision making in healthcare\ncontexts. This is especially true since many state-of-the-art systems are\ntrained using the data which has been labelled automatically (self-supervised\nmode) and tend to overfit. In this work, we investigate the quality of\nuncertainty estimates from a range of current state-of-the-art predictive\nmodels applied to the problem of observation detection in radiology reports.\nThis problem remains understudied for Natural Language Processing in the\nhealthcare domain. We demonstrate that Gaussian Processes (GPs) provide\nsuperior performance in quantifying the risks of 3 uncertainty labels based on\nthe negative log predictive probability (NLPP) evaluation metric and mean\nmaximum predicted confidence levels (MMPCL), whilst retaining strong predictive\nperformance.", "published": "2022-05-29 20:20:49", "link": "http://arxiv.org/abs/2205.14761v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CogVideo: Large-scale Pretraining for Text-to-Video Generation via\n  Transformers", "abstract": "Large-scale pretrained transformers have created milestones in text (GPT-3)\nand text-to-image (DALL-E and CogView) generation. Its application to video\ngeneration is still facing many challenges: The potential huge computation cost\nmakes the training from scratch unaffordable; The scarcity and weak relevance\nof text-video datasets hinder the model understanding complex movement\nsemantics. In this work, we present 9B-parameter transformer CogVideo, trained\nby inheriting a pretrained text-to-image model, CogView2. We also propose\nmulti-frame-rate hierarchical training strategy to better align text and video\nclips. As (probably) the first open-source large-scale pretrained text-to-video\nmodel, CogVideo outperforms all publicly available models at a large margin in\nmachine and human evaluations.", "published": "2022-05-29 19:02:15", "link": "http://arxiv.org/abs/2205.15868v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Context-based Virtual Adversarial Training for Text Classification with\n  Noisy Labels", "abstract": "Deep neural networks (DNNs) have a high capacity to completely memorize noisy\nlabels given sufficient training time, and its memorization, unfortunately,\nleads to performance degradation. Recently, virtual adversarial training (VAT)\nattracts attention as it could further improve the generalization of DNNs in\nsemi-supervised learning. The driving force behind VAT is to prevent the models\nfrom overfitting data points by enforcing consistency between the inputs and\nthe perturbed inputs. This strategy could be helpful in learning from noisy\nlabels if it prevents neural models from learning noisy samples while\nencouraging the models to generalize clean samples. In this paper, we propose\ncontext-based virtual adversarial training (ConVAT) to prevent a text\nclassifier from overfitting to noisy labels. Unlike the previous works, the\nproposed method performs the adversarial training at the context level rather\nthan the inputs. It makes the classifier not only learn its label but also its\ncontextual neighbors, which alleviates the learning from noisy labels by\npreserving contextual semantics on each data point. We conduct extensive\nexperiments on four text classification datasets with two types of label\nnoises. Comprehensive experimental results clearly show that the proposed\nmethod works quite well even with extremely noisy settings.", "published": "2022-05-29 14:19:49", "link": "http://arxiv.org/abs/2206.11851v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploiting Transliterated Words for Finding Similarity in Inter-Language\n  News Articles using Machine Learning", "abstract": "Finding similarities between two inter-language news articles is a\nchallenging problem of Natural Language Processing (NLP). It is difficult to\nfind similar news articles in a different language other than the native\nlanguage of user, there is a need for a Machine Learning based automatic system\nto find the similarity between two inter-language news articles. In this\narticle, we propose a Machine Learning model with the combination of English\nUrdu word transliteration which will show whether the English news article is\nsimilar to the Urdu news article or not. The existing approaches to find\nsimilarities has a major drawback when the archives contain articles of\nlow-resourced languages like Urdu along with English news article. The existing\napproaches to find similarities has drawback when the archives contain\nlow-resourced languages like Urdu along with English news articles. We used\nlexicon to link Urdu and English news articles. As Urdu language processing\napplications like machine translation, text to speech, etc are unable to handle\nEnglish text at the same time so this research proposed technique to find\nsimilarities in English and Urdu news articles based on transliteration.", "published": "2022-05-29 12:57:38", "link": "http://arxiv.org/abs/2206.11860v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Urdu News Article Recommendation Model using Natural Language Processing\n  Techniques", "abstract": "There are several online newspapers in urdu but for the users it is difficult\nto find the content they are looking for because these most of them contain\nirrelevant data and most users did not get what they want to retrieve. Our\nproposed framework will help to predict Urdu news in the interests of users and\nreduce the users searching time for news. For this purpose, NLP techniques are\nused for pre-processing, and then TF-IDF with cosine similarity is used for\ngaining the highest similarity and recommended news on user preferences.\nMoreover, the BERT language model is also used for similarity, and by using the\nBERT model similarity increases as compared to TF-IDF so the approach works\nbetter with the BERT language model and recommends news to the user on their\ninterest. The news is recommended when the similarity of the articles is above\n60 percent.", "published": "2022-05-29 12:43:32", "link": "http://arxiv.org/abs/2206.11862v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "What are People Talking about in #BlackLivesMatter and #StopAsianHate?\n  Exploring and Categorizing Twitter Topics Emerging in Online Social Movements\n  through the Latent Dirichlet Allocation Model", "abstract": "Minority groups have been using social media to organize social movements\nthat create profound social impacts. Black Lives Matter (BLM) and Stop Asian\nHate (SAH) are two successful social movements that have spread on Twitter that\npromote protests and activities against racism and increase the public's\nawareness of other social challenges that minority groups face. However,\nprevious studies have mostly conducted qualitative analyses of tweets or\ninterviews with users, which may not comprehensively and validly represent all\ntweets. Very few studies have explored the Twitter topics within BLM and SAH\ndialogs in a rigorous, quantified and data-centered approach. Therefore, in\nthis research, we adopted a mixed-methods approach to comprehensively analyze\nBLM and SAH Twitter topics. We implemented (1) the latent Dirichlet allocation\nmodel to understand the top high-level words and topics and (2) open-coding\nanalysis to identify specific themes across the tweets. We collected more than\none million tweets with the #blacklivesmatter and #stopasianhate hashtags and\ncompared their topics. Our findings revealed that the tweets discussed a\nvariety of influential topics in depth, and social justice, social movements,\nand emotional sentiments were common topics in both movements, though with\nunique subtopics for each movement. Our study contributes to the topic analysis\nof social movements on social media platforms in particular and the literature\non the interplay of AI, ethics, and society in general.", "published": "2022-05-29 17:29:40", "link": "http://arxiv.org/abs/2205.14725v2", "categories": ["cs.IR", "cs.CL", "cs.CY", "cs.LG", "cs.SI", "J.4; I.2.7; K.4.2"], "primary_category": "cs.IR"}
{"title": "To catch a chorus, verse, intro, or anything else: Analyzing a song with\n  structural functions", "abstract": "Conventional music structure analysis algorithms aim to divide a song into\nsegments and to group them with abstract labels (e.g., 'A', 'B', and 'C').\nHowever, explicitly identifying the function of each segment (e.g., 'verse' or\n'chorus') is rarely attempted, but has many applications. We introduce a\nmulti-task deep learning framework to model these structural semantic labels\ndirectly from audio by estimating \"verseness,\" \"chorusness,\" and so forth, as a\nfunction of time. We propose a 7-class taxonomy (i.e., intro, verse, chorus,\nbridge, outro, instrumental, and silence) and provide rules to consolidate\nannotations from four disparate datasets. We also propose to use a\nspectral-temporal Transformer-based model, called SpecTNT, which can be trained\nwith an additional connectionist temporal localization (CTL) loss. In\ncross-dataset evaluations using four public datasets, we demonstrate the\neffectiveness of the SpecTNT model and CTL loss, and obtain strong results\noverall: the proposed system outperforms state-of-the-art chorus-detection and\nboundary-detection methods at detecting choruses and boundaries, respectively.", "published": "2022-05-29 16:01:00", "link": "http://arxiv.org/abs/2205.14700v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Modeling Beats and Downbeats with a Time-Frequency Transformer", "abstract": "Transformer is a successful deep neural network (DNN) architecture that has\nshown its versatility not only in natural language processing but also in music\ninformation retrieval (MIR). In this paper, we present a novel\nTransformer-based approach to tackle beat and downbeat tracking. This approach\nemploys SpecTNT (Spectral-Temporal Transformer in Transformer), a variant of\nTransformer that models both spectral and temporal dimensions of a\ntime-frequency input of music audio. A SpecTNT model uses a stack of blocks,\nwhere each consists of two levels of Transformer encoders. The lower-level (or\nspectral) encoder handles the spectral features and enables the model to pay\nattention to harmonic components of each frame. Since downbeats indicate bar\nboundaries and are often accompanied by harmonic changes, this step may help\ndownbeat modeling. The upper-level (or temporal) encoder aggregates useful\nlocal spectral information to pay attention to beat/downbeat positions. We also\npropose an architecture that combines SpecTNT with a state-of-the-art model,\nTemporal Convolutional Networks (TCN), to further improve the performance.\nExtensive experiments demonstrate that our approach can significantly\noutperform TCN in downbeat tracking while maintaining comparable result in beat\ntracking.", "published": "2022-05-29 16:01:39", "link": "http://arxiv.org/abs/2205.14701v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speaker Identification using Speech Recognition", "abstract": "The audio data is increasing day by day throughout the globe with the\nincrease of telephonic conversations, video conferences and voice messages.\nThis research provides a mechanism for identifying a speaker in an audio file,\nbased on the human voice biometric features like pitch, amplitude, frequency\netc. We proposed an unsupervised learning model where the model can learn\nspeech representation with limited dataset. Librispeech dataset was used in\nthis research and we were able to achieve word error rate of 1.8.", "published": "2022-05-29 13:03:42", "link": "http://arxiv.org/abs/2205.14649v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
