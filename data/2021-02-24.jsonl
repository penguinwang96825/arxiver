{"title": "Hopeful_Men@LT-EDI-EACL2021: Hope Speech Detection Using Indic\n  Transliteration and Transformers", "abstract": "This paper aims to describe the approach we used to detect hope speech in the\nHopeEDI dataset. We experimented with two approaches. In the first approach, we\nused contextual embeddings to train classifiers using logistic regression,\nrandom forest, SVM, and LSTM based models.The second approach involved using a\nmajority voting ensemble of 11 models which were obtained by fine-tuning\npre-trained transformer models (BERT, ALBERT, RoBERTa, IndicBERT) after adding\nan output layer. We found that the second approach was superior for English,\nTamil and Malayalam. Our solution got a weighted F1 score of 0.93, 0.75 and\n0.49 for English,Malayalam and Tamil respectively. Our solution ranked first in\nEnglish, eighth in Malayalam and eleventh in Tamil.", "published": "2021-02-24 06:01:32", "link": "http://arxiv.org/abs/2102.12082v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Meter Classification of Kurdish Poems", "abstract": "Most of the classic texts in Kurdish literature are poems. Knowing the meter\nof the poems is helpful for correct reading, a better understanding of the\nmeaning, and avoidance of ambiguity. This paper presents a rule-based method\nfor automatic classification of the poem meter for the Central Kurdish\nlanguage. The metrical system of Kurdish poetry is divided into three classes\nof quantitative, syllabic, and free verses. As the vowel length is not phonemic\nin the language, there are uncertainties in syllable weight and meter\nidentification. The proposed method generates all the possible situations and\nthen, by considering all lines of the input poem and the common meter patterns\nof Kurdish poetry, identifies the most probable meter type and pattern of the\ninput poem. Evaluation of the method on a dataset from VejinBooks Kurdish\ncorpus resulted in 97.3% of precision in meter type and 96.2% of precision in\npattern identification.", "published": "2021-02-24 07:57:38", "link": "http://arxiv.org/abs/2102.12109v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OneStop QAMaker: Extract Question-Answer Pairs from Text in a One-Stop\n  Approach", "abstract": "Large-scale question-answer (QA) pairs are critical for advancing research\nareas like machine reading comprehension and question answering. To construct\nQA pairs from documents requires determining how to ask a question and what is\nthe corresponding answer. Existing methods for QA pair generation usually\nfollow a pipeline approach. Namely, they first choose the most likely candidate\nanswer span and then generate the answer-specific question. This pipeline\napproach, however, is undesired in mining the most appropriate QA pairs from\ndocuments since it ignores the connection between question generation and\nanswer extraction, which may lead to incompatible QA pair generation, i.e., the\nselected answer span is inappropriate for question generation. However, for\nhuman annotators, we take the whole QA pair into account and consider the\ncompatibility between question and answer. Inspired by such motivation, instead\nof the conventional pipeline approach, we propose a model named OneStop\ngenerate QA pairs from documents in a one-stop approach. Specifically,\nquestions and their corresponding answer span is extracted simultaneously and\nthe process of question generation and answer extraction mutually affect each\nother. Additionally, OneStop is much more efficient to be trained and deployed\nin industrial scenarios since it involves only one model to solve the complex\nQA generation task. We conduct comprehensive experiments on three large-scale\nmachine reading comprehension datasets: SQuAD, NewsQA, and DuReader. The\nexperimental results demonstrate that our OneStop model outperforms the\nbaselines significantly regarding the quality of generated questions, quality\nof generated question-answer pairs, and model efficiency.", "published": "2021-02-24 08:45:00", "link": "http://arxiv.org/abs/2102.12128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmenting Part-of-speech Tagging with Syntactic Information for\n  Vietnamese and Chinese", "abstract": "Word segmentation and part-of-speech tagging are two critical preliminary\nsteps for downstream tasks in Vietnamese natural language processing. In\nreality, people tend to consider also the phrase boundary when performing word\nsegmentation and part of speech tagging rather than solely process word by word\nfrom left to right. In this paper, we implement this idea to improve word\nsegmentation and part of speech tagging the Vietnamese language by employing a\nsimplified constituency parser. Our neural model for joint word segmentation\nand part-of-speech tagging has the architecture of the syllable-based CRF\nconstituency parser. To reduce the complexity of parsing, we replace all\nconstituent labels with a single label indicating for phrases. This model can\nbe augmented with predicted word boundary and part-of-speech tags by other\ntools. Because Vietnamese and Chinese have some similar linguistic phenomena,\nwe evaluated the proposed model and its augmented versions on three Vietnamese\nbenchmark datasets and six Chinese benchmark datasets. Our experimental results\nshow that the proposed model achieves higher performances than previous works\nfor both languages.", "published": "2021-02-24 08:57:02", "link": "http://arxiv.org/abs/2102.12136v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment Analysis of Code-Mixed Social Media Text (Hinglish)", "abstract": "This paper discusses the results obtained for different techniques applied\nfor performing the sentiment analysis of social media (Twitter) code-mixed text\nwritten in Hinglish. The various stages involved in performing the sentiment\nanalysis were data consolidation, data cleaning, data transformation and\nmodelling. Various data cleaning techniques were applied, data was cleaned in\nfive iterations and the results of experiments conducted were noted after each\niteration. Data was transformed using count vectorizer, one hot vectorizer,\ntf-idf vectorizer, doc2vec, word2vec and fasttext embeddings. The models were\ncreated using various machine learning algorithms such as SVM, KNN, Decision\nTrees, Random Forests, Naive Bayes, Logistic Regression, and ensemble voting\nclassifiers. The data was obtained from a task on Codalab competition website\nwhich was listed as Task:9 on the Semeval-2020 competition website. The models\ncreated were evaluated using the F1-score (macro). The best F1-score of 69.07\nwas achieved using ensemble voting classifier.", "published": "2021-02-24 09:15:34", "link": "http://arxiv.org/abs/2102.12149v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Multichannel LSTM-CNN for Telugu Technical Domain Identification", "abstract": "With the instantaneous growth of text information, retrieving domain-oriented\ninformation from the text data has a broad range of applications in Information\nRetrieval and Natural language Processing. Thematic keywords give a compressed\nrepresentation of the text. Usually, Domain Identification plays a significant\nrole in Machine Translation, Text Summarization, Question Answering,\nInformation Extraction, and Sentiment Analysis. In this paper, we proposed the\nMultichannel LSTM-CNN methodology for Technical Domain Identification for\nTelugu. This architecture was used and evaluated in the context of the ICON\nshared task TechDOfication 2020 (task h), and our system got 69.9% of the F1\nscore on the test dataset and 90.01% on the validation set.", "published": "2021-02-24 10:15:30", "link": "http://arxiv.org/abs/2102.12179v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trajectory-Based Meta-Learning for Out-Of-Vocabulary Word Embedding\n  Learning", "abstract": "Word embedding learning methods require a large number of occurrences of a\nword to accurately learn its embedding. However, out-of-vocabulary (OOV) words\nwhich do not appear in the training corpus emerge frequently in the smaller\ndownstream data. Recent work formulated OOV embedding learning as a few-shot\nregression problem and demonstrated that meta-learning can improve results\nobtained. However, the algorithm used, model-agnostic meta-learning (MAML) is\nknown to be unstable and perform worse when a large number of gradient steps\nare used for parameter updates. In this work, we propose the use of Leap, a\nmeta-learning algorithm which leverages the entire trajectory of the learning\nprocess instead of just the beginning and the end points, and thus ameliorates\nthese two issues. In our experiments on a benchmark OOV embedding learning\ndataset and in an extrinsic evaluation, Leap performs comparably or better than\nMAML. We go on to examine which contexts are most beneficial to learn an OOV\nembedding from, and propose that the choice of contexts may matter more than\nthe meta-learning employed.", "published": "2021-02-24 12:57:58", "link": "http://arxiv.org/abs/2102.12266v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Creolizing the Web", "abstract": "The evolution of language has been a hotly debated subject with contradicting\nhypotheses and unreliable claims. Drawing from signalling games, dynamic\npopulation mechanics, machine learning and algebraic topology, we present a\nmethod for detecting evolutionary patterns in a sociological model of language\nevolution. We develop a minimalistic model that provides a rigorous base for\nany generalized evolutionary model for language based on communication between\nindividuals. We also discuss theoretical guarantees of this model, ranging from\nstability of language representations to fast convergence of language by\ntemporal communication and language drift in an interactive setting. Further we\npresent empirical results and their interpretations on a real world dataset\nfrom \\rdt to identify communities and echo chambers for opinions, thus placing\nobstructions to reliable communication among communities.", "published": "2021-02-24 16:08:45", "link": "http://arxiv.org/abs/2102.12382v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Task-Specific Pre-Training and Cross Lingual Transfer for Code-Switched\n  Data", "abstract": "Using task-specific pre-training and leveraging cross-lingual transfer are\ntwo of the most popular ways to handle code-switched data. In this paper, we\naim to compare the effects of both for the task of sentiment analysis. We work\nwith two Dravidian Code-Switched languages - Tamil-Engish and Malayalam-English\nand four different BERT based models. We compare the effects of task-specific\npre-training and cross-lingual transfer and find that task-specific\npre-training results in superior zero-shot and supervised performance when\ncompared to performance achieved by leveraging cross-lingual transfer from\nmultilingual BERT models.", "published": "2021-02-24 16:57:58", "link": "http://arxiv.org/abs/2102.12407v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Probing Classifiers: Promises, Shortcomings, and Advances", "abstract": "Probing classifiers have emerged as one of the prominent methodologies for\ninterpreting and analyzing deep neural network models of natural language\nprocessing. The basic idea is simple -- a classifier is trained to predict some\nlinguistic property from a model's representations -- and has been used to\nexamine a wide variety of models and properties. However, recent studies have\ndemonstrated various methodological limitations of this approach. This article\ncritically reviews the probing classifiers framework, highlighting their\npromises, shortcomings, and advances.", "published": "2021-02-24 18:36:14", "link": "http://arxiv.org/abs/2102.12452v4", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "A Large-Scale, Automated Study of Language Surrounding Artificial\n  Intelligence", "abstract": "This work presents a large-scale analysis of artificial intelligence (AI) and\nmachine learning (ML) references within news articles and scientific\npublications between 2011 and 2019. We implement word association measurements\nthat automatically identify shifts in language co-occurring with AI/ML and\nquantify the strength of these word associations. Our results highlight the\nevolution of perceptions and definitions around AI/ML and detect emerging\napplication areas, models, and systems (e.g., blockchain and cybersecurity).\nRecent small-scale, manual studies have explored AI/ML discourse within the\ngeneral public, the policymaker community, and researcher community, but are\nlimited in their scalability and longevity. Our methods provide new views into\npublic perceptions and subject-area expert discussions of AI/ML and greatly\nexceed the explanative power of prior work.", "published": "2021-02-24 19:14:53", "link": "http://arxiv.org/abs/2102.12516v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RoBERTa-wwm-ext Fine-Tuning for Chinese Text Classification", "abstract": "Bidirectional Encoder Representations from Transformers (BERT) have shown to\nbe a promising way to dramatically improve the performance across various\nNatural Language Processing tasks [Devlin et al., 2019]. Meanwhile, progress\nmade over the past few years by various Neural Net-work has also proved the\neffectiveness of Neural Network in the field of Natural Language Processing. In\nthis project, RoBERTa-wwm-ext [Cui et al., 2019] pre-train language model was\nadopted and fine-tuned for Chinese text classification. The models were able to\nclassify Chinese texts into two categories, containing descriptions of legal\nbehavior and descriptions of illegal behavior. Four different models are also\nproposed in the paper. Those models will use RoBERTa-wwm-extas their embedding\nlayer and feed the embedding into different neural networks. The motivation\nbe-hind proposing these models is straightforward. By introducing complex\noutput layer architecture, the overall performance of the models could be\nimproved. All the models were trained on a data set derived from Chinese public\ncourt records, and the performance of different models were compared.The\nexperiment shows that the performance of pro-posed models failed to beat the\noriginal RoBERTa-wwm-ext model in terms of accuracy and training efficiency.", "published": "2021-02-24 18:57:57", "link": "http://arxiv.org/abs/2103.00492v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SocialNLP EmotionGIF 2020 Challenge Overview: Predicting Reaction GIF\n  Categories on Social Media", "abstract": "We present an overview of the EmotionGIF2020 Challenge, held at the 8th\nInternational Workshop on Natural Language Processing for Social Media\n(SocialNLP), in conjunction with ACL 2020. The challenge required predicting\naffective reactions to online texts, and included the EmotionGIF dataset, with\ntweets labeled for the reaction categories. The novel dataset included 40K\ntweets with their reaction GIFs. Due to the special circumstances of year 2020,\ntwo rounds of the competition were conducted. A total of 84 teams registered\nfor the task. Of these, 25 teams success-fully submitted entries to the\nevaluation phase in the first round, while 13 teams participated successfully\nin the second round. Of the top participants, five teams presented a technical\nreport and shared their code. The top score of the winning team using the\nRecall@K metric was 62.47%.", "published": "2021-02-24 05:22:10", "link": "http://arxiv.org/abs/2102.12073v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "From Universal Language Model to Downstream Task: Improving\n  RoBERTa-Based Vietnamese Hate Speech Detection", "abstract": "Natural language processing is a fast-growing field of artificial\nintelligence. Since the Transformer was introduced by Google in 2017, a large\nnumber of language models such as BERT, GPT, and ELMo have been inspired by\nthis architecture. These models were trained on huge datasets and achieved\nstate-of-the-art results on natural language understanding. However,\nfine-tuning a pre-trained language model on much smaller datasets for\ndownstream tasks requires a carefully-designed pipeline to mitigate problems of\nthe datasets such as lack of training data and imbalanced data. In this paper,\nwe propose a pipeline to adapt the general-purpose RoBERTa language model to a\nspecific text classification task: Vietnamese Hate Speech Detection. We first\ntune the PhoBERT on our dataset by re-training the model on the Masked Language\nModel task; then, we employ its encoder for text classification. In order to\npreserve pre-trained weights while learning new feature representations, we\nfurther utilize different training techniques: layer freezing, block-wise\nlearning rate, and label smoothing. Our experiments proved that our proposed\npipeline boosts the performance significantly, achieving a new state-of-the-art\non Vietnamese Hate Speech Detection campaign with 0.7221 F1 score.", "published": "2021-02-24 09:30:55", "link": "http://arxiv.org/abs/2102.12162v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NLRG at SemEval-2021 Task 5: Toxic Spans Detection Leveraging BERT-based\n  Token Classification and Span Prediction Techniques", "abstract": "Toxicity detection of text has been a popular NLP task in the recent years.\nIn SemEval-2021 Task-5 Toxic Spans Detection, the focus is on detecting toxic\nspans within passages. Most state-of-the-art span detection approaches employ\nvarious techniques, each of which can be broadly classified into Token\nClassification or Span Prediction approaches. In our paper, we explore simple\nversions of both of these approaches and their performance on the task.\nSpecifically, we use BERT-based models -- BERT, RoBERTa, and SpanBERT for both\napproaches. We also combine these approaches and modify them to bring\nimprovements for Toxic Spans prediction. To this end, we investigate results on\nfour hybrid approaches -- Multi-Span, Span+Token, LSTM-CRF, and a combination\nof predicted offsets using union/intersection. Additionally, we perform a\nthorough ablative analysis and analyze our observed results. Our best\nsubmission -- a combination of SpanBERT Span Predictor and RoBERTa Token\nClassifier predictions -- achieves an F1 score of 0.6753 on the test set. Our\nbest post-eval F1 score is 0.6895 on intersection of predicted offsets from\ntop-3 RoBERTa Token Classification checkpoints. These approaches improve the\nperformance by 3% on average than those of the shared baseline models -- RNNSL\nand SpaCy NER.", "published": "2021-02-24 12:30:09", "link": "http://arxiv.org/abs/2102.12254v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LRG at SemEval-2021 Task 4: Improving Reading Comprehension with\n  Abstract Words using Augmentation, Linguistic Features and Voting", "abstract": "In this article, we present our methodologies for SemEval-2021 Task-4:\nReading Comprehension of Abstract Meaning. Given a fill-in-the-blank-type\nquestion and a corresponding context, the task is to predict the most suitable\nword from a list of 5 options. There are three sub-tasks within this task:\nImperceptibility (subtask-I), Non-Specificity (subtask-II), and Intersection\n(subtask-III). We use encoders of transformers-based models pre-trained on the\nmasked language modelling (MLM) task to build our Fill-in-the-blank (FitB)\nmodels. Moreover, to model imperceptibility, we define certain linguistic\nfeatures, and to model non-specificity, we leverage information from hypernyms\nand hyponyms provided by a lexical database. Specifically, for non-specificity,\nwe try out augmentation techniques, and other statistical techniques. We also\npropose variants, namely Chunk Voting and Max Context, to take care of input\nlength restrictions for BERT, etc. Additionally, we perform a thorough ablation\nstudy, and use Integrated Gradients to explain our predictions on a few\nsamples. Our best submissions achieve accuracies of 75.31% and 77.84%, on the\ntest sets for subtask-I and subtask-II, respectively. For subtask-III, we\nachieve accuracies of 65.64% and 62.27%.", "published": "2021-02-24 12:33:12", "link": "http://arxiv.org/abs/2102.12255v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Re-Evaluating GermEval17 Using German Pre-Trained Language Models", "abstract": "The lack of a commonly used benchmark data set (collection) such as\n(Super-)GLUE (Wang et al., 2018, 2019) for the evaluation of non-English\npre-trained language models is a severe shortcoming of current English-centric\nNLP-research. It concentrates a large part of the research on English,\nneglecting the uncertainty when transferring conclusions found for the English\nlanguage to other languages. We evaluate the performance of the German and\nmultilingual BERT-based models currently available via the huggingface\ntransformers library on the four tasks of the GermEval17 workshop. We compare\nthem to pre-BERT architectures (Wojatzki et al., 2017; Schmitt et al., 2018;\nAttia et al., 2018) as well as to an ELMo-based architecture (Biesialska et\nal., 2020) and a BERT-based approach (Guhr et al., 2020). The observed\nimprovements are put in relation to those for similar tasks and similar models\n(pre-BERT vs. BERT-based) for the English language in order to draw tentative\nconclusions about whether the observed improvements are transferable to German\nor potentially other related languages.", "published": "2021-02-24 15:05:56", "link": "http://arxiv.org/abs/2102.12330v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "When Attention Meets Fast Recurrence: Training Language Models with\n  Reduced Compute", "abstract": "Large language models have become increasingly difficult to train because of\nthe growing computation time and cost. In this work, we present SRU++, a\nhighly-efficient architecture that combines fast recurrence and attention for\nsequence modeling. SRU++ exhibits strong modeling capacity and training\nefficiency. On standard language modeling tasks such as Enwik8, Wiki-103 and\nBillion Word datasets, our model obtains better bits-per-character and\nperplexity while using 3x-10x less training cost compared to top-performing\nTransformer models. For instance, our model achieves a state-of-the-art result\non the Enwik8 dataset using 1.6 days of training on an 8-GPU machine. We\nfurther demonstrate that SRU++ requires minimal attention for near\nstate-of-the-art performance. Our results suggest jointly leveraging fast\nrecurrence with little attention as a promising direction for accelerating\nmodel training and inference.", "published": "2021-02-24 18:39:56", "link": "http://arxiv.org/abs/2102.12459v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Generalized and Transferable Patient Language Representation for\n  Phenotyping with Limited Data", "abstract": "The paradigm of representation learning through transfer learning has the\npotential to greatly enhance clinical natural language processing. In this\nwork, we propose a multi-task pre-training and fine-tuning approach for\nlearning generalized and transferable patient representations from medical\nlanguage. The model is first pre-trained with different but related\nhigh-prevalence phenotypes and further fine-tuned on downstream target tasks.\nOur main contribution focuses on the impact this technique can have on\nlow-prevalence phenotypes, a challenging task due to the dearth of data. We\nvalidate the representation from pre-training, and fine-tune the multi-task\npre-trained models on low-prevalence phenotypes including 38 circulatory\ndiseases, 23 respiratory diseases, and 17 genitourinary diseases. We find\nmulti-task pre-training increases learning efficiency and achieves consistently\nhigh performance across the majority of phenotypes. Most important, the\nmulti-task pre-training is almost always either the best-performing model or\nperforms tolerably close to the best-performing model, a property we refer to\nas robust. All these results lead us to conclude that this multi-task transfer\nlearning architecture is a robust approach for developing generalized and\ntransferable patient language representations for numerous phenotypes.", "published": "2021-02-24 18:18:02", "link": "http://arxiv.org/abs/2103.00482v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Teach Me to Explain: A Review of Datasets for Explainable Natural\n  Language Processing", "abstract": "Explainable NLP (ExNLP) has increasingly focused on collecting\nhuman-annotated textual explanations. These explanations are used downstream in\nthree ways: as data augmentation to improve performance on a predictive task,\nas supervision to train models to produce explanations for their predictions,\nand as a ground-truth to evaluate model-generated explanations. In this review,\nwe identify 65 datasets with three predominant classes of textual explanations\n(highlights, free-text, and structured), organize the literature on annotating\neach type, identify strengths and shortcomings of existing collection\nmethodologies, and give recommendations for collecting ExNLP datasets in the\nfuture.", "published": "2021-02-24 04:25:01", "link": "http://arxiv.org/abs/2102.12060v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen\n  Domains", "abstract": "Natural Language Processing algorithms have made incredible progress, but\nthey still struggle when applied to out-of-distribution examples. We address a\nchallenging and underexplored version of this domain adaptation problem, where\nan algorithm is trained on several source domains, and then applied to examples\nfrom unseen domains that are unknown at training time. Particularly, no\nexamples, labeled or unlabeled, or any other knowledge about the target domain\nare available to the algorithm at training time. We present PADA: An\nexample-based autoregressive Prompt learning algorithm for on-the-fly\nAny-Domain Adaptation, based on the T5 language model. Given a test example,\nPADA first generates a unique prompt for it and then, conditioned on this\nprompt, labels the example with respect to the NLP prediction task. PADA is\ntrained to generate a prompt which is a token sequence of unrestricted length,\nconsisting of Domain Related Features (DRFs) that characterize each of the\nsource domains. Intuitively, the generated prompt is a unique signature that\nmaps the test example to a semantic space spanned by the source domains. In\nexperiments with 3 tasks (text classification and sequence tagging), for a\ntotal of 14 multi-source adaptation scenarios, PADA substantially outperforms\nstrong baselines.", "published": "2021-02-24 11:02:29", "link": "http://arxiv.org/abs/2102.12206v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-Task Attentive Residual Networks for Argument Mining", "abstract": "We explore the use of residual networks and neural attention for multiple\nargument mining tasks. We propose a residual architecture that exploits\nattention, multi-task learning, and makes use of ensemble, without any\nassumption on document or argument structure. We present an extensive\nexperimental evaluation on five different corpora of user-generated comments,\nscientific publications, and persuasive essays. Our results show that our\napproach is a strong competitor against state-of-the-art architectures with a\nhigher computational footprint or corpus-specific design, representing an\ninteresting compromise between generality, performance accuracy and reduced\nmodel size.", "published": "2021-02-24 11:35:28", "link": "http://arxiv.org/abs/2102.12227v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "References in Wikipedia: The Editors' Perspective", "abstract": "References are an essential part of Wikipedia. Each statement in Wikipedia\nshould be referenced. In this paper, we explore the creation and collection of\nreferences for new Wikipedia articles from an editors' perspective. We map out\nthe workflow of editors when creating a new article, emphasising how they\nselect references.", "published": "2021-02-24 19:04:17", "link": "http://arxiv.org/abs/2102.12511v2", "categories": ["cs.CL", "cs.CY", "cs.DL"], "primary_category": "cs.CL"}
{"title": "The INTERSPEECH 2021 Computational Paralinguistics Challenge: COVID-19\n  Cough, COVID-19 Speech, Escalation & Primates", "abstract": "The INTERSPEECH 2021 Computational Paralinguistics Challenge addresses four\ndifferent problems for the first time in a research competition under\nwell-defined conditions: In the COVID-19 Cough and COVID-19 Speech\nSub-Challenges, a binary classification on COVID-19 infection has to be made\nbased on coughing sounds and speech; in the Escalation SubChallenge, a\nthree-way assessment of the level of escalation in a dialogue is featured; and\nin the Primates Sub-Challenge, four species vs background need to be\nclassified. We describe the Sub-Challenges, baseline feature extraction, and\nclassifiers based on the 'usual' COMPARE and BoAW features as well as deep\nunsupervised representation learning using the AuDeep toolkit, and deep feature\nextraction from pre-trained CNNs using the Deep Spectrum toolkit; in addition,\nwe add deep end-to-end sequential modelling, and partially linguistic analysis.", "published": "2021-02-24 21:39:59", "link": "http://arxiv.org/abs/2102.13468v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "68", "I.2.7; I.5.0; J.3"], "primary_category": "eess.AS"}
{"title": "Speech Enhancement Using Multi-Stage Self-Attentive Temporal\n  Convolutional Networks", "abstract": "Multi-stage learning is an effective technique to invoke multiple\ndeep-learning modules sequentially. This paper applies multi-stage learning to\nspeech enhancement by using a multi-stage structure, where each stage comprises\na self-attention (SA) block followed by stacks of temporal convolutional\nnetwork (TCN) blocks with doubling dilation factors. Each stage generates a\nprediction that is refined in a subsequent stage. A fusion block is inserted at\nthe input of later stages to re-inject original information. The resulting\nmulti-stage speech enhancement system, in short, multi-stage SA-TCN, is\ncompared with state-of-the-art deep-learning speech enhancement methods using\nthe LibriSpeech and VCTK data sets. The multi-stage SA-TCN system's\nhyper-parameters are fine-tuned, and the impact of the SA block, the fusion\nblock and the number of stages are determined. The use of a multi-stage SA-TCN\nsystem as a front-end for automatic speech recognition systems is investigated\nas well. It is shown that the multi-stage SA-TCN systems perform well relative\nto other state-of-the-art systems in terms of speech enhancement and speech\nrecognition scores.", "published": "2021-02-24 05:48:07", "link": "http://arxiv.org/abs/2102.12078v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SEP-28k: A Dataset for Stuttering Event Detection From Podcasts With\n  People Who Stutter", "abstract": "The ability to automatically detect stuttering events in speech could help\nspeech pathologists track an individual's fluency over time or help improve\nspeech recognition systems for people with atypical speech patterns. Despite\nincreasing interest in this area, existing public datasets are too small to\nbuild generalizable dysfluency detection systems and lack sufficient\nannotations. In this work, we introduce Stuttering Events in Podcasts\n(SEP-28k), a dataset containing over 28k clips labeled with five event types\nincluding blocks, prolongations, sound repetitions, word repetitions, and\ninterjections. Audio comes from public podcasts largely consisting of people\nwho stutter interviewing other people who stutter. We benchmark a set of\nacoustic models on SEP-28k and the public FluencyBank dataset and highlight how\nsimply increasing the amount of training data improves relative detection\nperformance by 28\\% and 24\\% F1 on each. Annotations from over 32k clips across\nboth datasets will be publicly released.", "published": "2021-02-24 16:22:45", "link": "http://arxiv.org/abs/2102.12394v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Thoughts on the potential to compensate a hearing loss in noise", "abstract": "The effect of hearing impairment on speech perception was described by Plomp\n(1978) as a sum of a loss of class A, due to signal attenuation, and a loss of\nclass D, due to signal distortion. While a loss of class A can be compensated\nby linear amplification, a loss of class D, which severely limits the benefit\nof hearing aids in noisy listening conditions, cannot. Not few users of hearing\naids keep complaining about the limited benefit of their devices in noisy\nenvironments. Recently, in an approach to model human speech recognition by\nmeans of a re-purposed automatic speech recognition system, the loss of class D\nwas explained by introducing a level uncertainty which reduces the individual\naccuracy of spectro-temporal signal levels. Based on this finding, an\nimplementation of a patented dynamic range manipulation scheme (PLATT) is\nproposed, which aims to mitigate the effect of increased level uncertainty on\nspeech recognition in noise by expanding spectral modulation patterns in the\nrange of 2 to 4 ERB. An objective evaluation of the benefit in speech\nrecognition thresholds in noise using an ASR-based speech recognition model\nsuggests that more than half of the class D loss due to an increased level\nuncertainty might be compensable.", "published": "2021-02-24 16:33:05", "link": "http://arxiv.org/abs/2102.12397v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Learning Approach for Singer Voice Classification of Vietnamese\n  Popular Music", "abstract": "Singer voice classification is a meaningful task in the digital era. With a\nhuge number of songs today, identifying a singer is very helpful for music\ninformation retrieval, music properties indexing, and so on. In this paper, we\npropose a new method to identify the singer's name based on analysis of\nVietnamese popular music. We employ the use of vocal segment detection and\nsinging voice separation as the pre-processing steps. The purpose of these\nsteps is to extract the singer's voice from the mixture sound. In order to\nbuild a singer classifier, we propose a neural network architecture working\nwith Mel Frequency Cepstral Coefficient as extracted input features from said\nvocal. To verify the accuracy of our methods, we evaluate on a dataset of 300\nVietnamese songs from 18 famous singers. We achieve an accuracy of 92.84% with\n5-fold stratified cross-validation, the best result compared to other methods\non the same data set.", "published": "2021-02-24 08:03:07", "link": "http://arxiv.org/abs/2102.12111v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automatic Feature Extraction for Heartbeat Anomaly Detection", "abstract": "We focus on automatic feature extraction for raw audio heartbeat sounds,\naimed at anomaly detection applications in healthcare. We learn features with\nthe help of an autoencoder composed by a 1D non-causal convolutional encoder\nand a WaveNet decoder trained with a modified objective based on variational\ninference, employing the Maximum Mean Discrepancy (MMD). Moreover we model the\nlatent distribution using a Gaussian chain graphical model to capture temporal\ncorrelations which characterize the encoded signals. After training the\nautoencoder on the reconstruction task in a unsupervised manner, we test the\nsignificance of the learned latent representations by training an SVM to\npredict anomalies. We evaluate the methods on a problem proposed by the PASCAL\nClassifying Heart Sounds Challenge and we compare with results in the\nliterature.", "published": "2021-02-24 13:55:24", "link": "http://arxiv.org/abs/2102.12289v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "68T07"], "primary_category": "cs.SD"}
{"title": "Triplet loss based embeddings for forensic speaker identification in\n  Spanish", "abstract": "With the advent of digital technology, it is more common that committed\ncrimes or legal disputes involve some form of speech recording where the\nidentity of a speaker is questioned [1]. In face of this situation, the field\nof forensic speaker identification has been looking to shed light on the\nproblem by quantifying how much a speech recording belongs to a particular\nperson in relation to a population. In this work, we explore the use of speech\nembeddings obtained by training a CNN using the triplet loss. In particular, we\nfocus on the Spanish language which has not been extensively studies. We\npropose extracting the embeddings from speech spectrograms samples, then\nexplore several configurations of such spectrograms, and finally, quantify the\nembeddings quality. We also show some limitations of our data setting which is\npredominantly composed by male speakers. At the end, we propose two approaches\nto calculate the Likelihood Radio given out speech embeddings and we show that\ntriplet loss is a good alternative to create speech embeddings for forensic\nspeaker identification.", "published": "2021-02-24 21:24:25", "link": "http://arxiv.org/abs/2102.12564v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
