{"title": "IIT_kgp at FinCausal 2020, Shared Task 1: Causality Detection using\n  Sentence Embeddings in Financial Reports", "abstract": "The paper describes the work that the team submitted to FinCausal 2020 Shared\nTask. This work is associated with the first sub-task of identifying causality\nin sentences. The various models used in the experiments tried to obtain a\nlatent space representation for each of the sentences. Linear regression was\nperformed on these representations to classify whether the sentence is causal\nor not. The experiments have shown BERT (Large) performed the best, giving a F1\nscore of 0.958, in the task of detecting the causality of sentences in\nfinancial texts and reports. The class imbalance was dealt with a modified loss\nfunction to give a better metric score for the evaluation.", "published": "2020-11-16 00:57:14", "link": "http://arxiv.org/abs/2011.07670v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WikiAsp: A Dataset for Multi-domain Aspect-based Summarization", "abstract": "Aspect-based summarization is the task of generating focused summaries based\non specific points of interest. Such summaries aid efficient analysis of text,\nsuch as quickly understanding reviews or opinions from different angles.\nHowever, due to large differences in the type of aspects for different domains\n(e.g., sentiment, product features), the development of previous models has\ntended to be domain-specific. In this paper, we propose WikiAsp, a large-scale\ndataset for multi-domain aspect-based summarization that attempts to spur\nresearch in the direction of open-domain aspect-based summarization.\nSpecifically, we build the dataset using Wikipedia articles from 20 different\ndomains, using the section titles and boundaries of each article as a proxy for\naspect annotation. We propose several straightforward baseline models for this\ntask and conduct experiments on the dataset. Results highlight key challenges\nthat existing summarization models face in this setting, such as proper pronoun\nhandling of quoted sources and consistent explanation of time-sensitive events.", "published": "2020-11-16 10:02:52", "link": "http://arxiv.org/abs/2011.07832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Sentence Segmentation and Word Tokenization Systems on\n  Estonian Web Texts", "abstract": "Texts obtained from web are noisy and do not necessarily follow the\northographic sentence and word boundary rules. Thus, sentence segmentation and\nword tokenization systems that have been developed on well-formed texts might\nnot perform so well on unedited web texts. In this paper, we first describe the\nmanual annotation of sentence boundaries of an Estonian web dataset and then\npresent the evaluation results of three existing sentence segmentation and word\ntokenization systems on this corpus: EstNLTK, Stanza and UDPipe. While EstNLTK\nobtains the highest performance compared to other systems on sentence\nsegmentation on this dataset, the sentence segmentation performance of Stanza\nand UDPipe remains well below the results obtained on the more well-formed\nEstonian UD test set.", "published": "2020-11-16 11:13:41", "link": "http://arxiv.org/abs/2011.07868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Score Combination for Improved Parallel Corpus Filtering for Low\n  Resource Conditions", "abstract": "This paper describes our submission to the WMT20 sentence filtering task. We\ncombine scores from (1) a custom LASER built for each source language, (2) a\nclassifier built to distinguish positive and negative pairs by semantic\nalignment, and (3) the original scores included in the task devkit. For the\nmBART finetuning setup, provided by the organizers, our method shows 7% and 5%\nrelative improvement over baseline, in sacreBLEU score on the test set for\nPashto and Khmer respectively.", "published": "2020-11-16 13:31:33", "link": "http://arxiv.org/abs/2011.07933v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Datasets and Models for Authorship Attribution on Italian Personal\n  Writings", "abstract": "Existing research on Authorship Attribution (AA) focuses on texts for which a\nlot of data is available (e.g novels), mainly in English. We approach AA via\nAuthorship Verification on short Italian texts in two novel datasets, and\nanalyze the interaction between genre, topic, gender and length. Results show\nthat AV is feasible even with little data, but more evidence helps. Gender and\ntopic can be indicative clues, and if not controlled for, they might overtake\nmore specific aspects of personal style.", "published": "2020-11-16 14:11:29", "link": "http://arxiv.org/abs/2011.07975v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Person Index Challenge: Extraction of Persons from Messy, Short\n  Texts", "abstract": "When persons are mentioned in texts with their first name, last name and/or\nmiddle names, there can be a high variation which of their names are used, how\ntheir names are ordered and if their names are abbreviated. If multiple persons\nare mentioned consecutively in very different ways, especially short texts can\nbe perceived as \"messy\". Once ambiguous names occur, associations to persons\nmay not be inferred correctly. Despite these eventualities, in this paper we\nask how well an unsupervised algorithm can build a person index from short\ntexts. We define a person index as a structured table that distinctly catalogs\nindividuals by their names. First, we give a formal definition of the problem\nand describe a procedure to generate ground truth data for future evaluations.\nTo give a first solution to this challenge, a baseline approach is implemented.\nBy using our proposed evaluation strategy, we test the performance of the\nbaseline and suggest further improvements. For future research the source code\nis publicly available.", "published": "2020-11-16 14:36:42", "link": "http://arxiv.org/abs/2011.07990v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative Probing of Lexical Semantics Theories for Cognitive\n  Plausibility and Technological Usefulness", "abstract": "Lexical semantics theories differ in advocating that the meaning of words is\nrepresented as an inference graph, a feature mapping or a vector space, thus\nraising the question: is it the case that one of these approaches is superior\nto the others in representing lexical semantics appropriately? Or in its non\nantagonistic counterpart: could there be a unified account of lexical semantics\nwhere these approaches seamlessly emerge as (partial) renderings of (different)\naspects of a core semantic knowledge base?\n  In this paper, we contribute to these research questions with a number of\nexperiments that systematically probe different lexical semantics theories for\ntheir levels of cognitive plausibility and of technological usefulness.\n  The empirical findings obtained from these experiments advance our insight on\nlexical semantics as the feature-based approach emerges as superior to the\nother ones, and arguably also move us closer to finding answers to the research\nquestions above.", "published": "2020-11-16 14:46:08", "link": "http://arxiv.org/abs/2011.07997v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Task Descriptions", "abstract": "Typically, machine learning systems solve new tasks by training on thousands\nof examples. In contrast, humans can solve new tasks by reading some\ninstructions, with perhaps an example or two. To take a step toward closing\nthis gap, we introduce a framework for developing NLP systems that solve new\ntasks after reading their descriptions, synthesizing prior work in this area.\nWe instantiate this framework with a new English language dataset, ZEST,\nstructured for task-oriented evaluation on unseen tasks. Formulating task\ndescriptions as questions, we ensure each is general enough to apply to many\npossible inputs, thus comprehensively evaluating a model's ability to solve\neach task. Moreover, the dataset's structure tests specific types of systematic\ngeneralization. We find that the state-of-the-art T5 model achieves a score of\n12% on ZEST, leaving a significant challenge for NLP researchers.", "published": "2020-11-16 17:25:24", "link": "http://arxiv.org/abs/2011.08115v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Probabilistic Approach in Historical Linguistics Word Order Change in\n  Infinitival Clauses: from Latin to Old French", "abstract": "This research offers a new interdisciplinary approach to the field of\nLinguistics by using Computational Linguistics, NLP, Bayesian Statistics and\nSociolinguistics methods. This thesis investigates word order change in\ninfinitival clauses from Object-Verb (OV) to Verb-Object (VO) in the history of\nLatin and Old French. By applying a variationist approach, I examine a\nsynchronic word order variation in each stage of language change, from which I\ninfer the character, periodization and constraints of diachronic variation. I\nalso show that in discourse-configurational languages, such as Latin and Early\nOld French, it is possible to identify pragmatically neutral contexts by using\ninformation structure annotation. I further argue that by mapping pragmatic\ncategories into a syntactic structure, we can detect how word order change\nunfolds. For this investigation, the data are extracted from annotated corpora\nspanning several centuries of Latin and Old French and from additional\nresources created by using computational linguistic methods. The data are then\nfurther codified for various pragmatic, semantic, syntactic and sociolinguistic\nfactors. This study also evaluates previous factors proposed to account for\nword order alternation and change. I show how information structure and\nsyntactic constraints change over time and propose a method that allows\nresearchers to differentiate a stable word order alternation from alternation\nindicating a change. Finally, I present a three-stage probabilistic model of\nword order change, which also conforms to traditional language change patterns.", "published": "2020-11-16 20:30:31", "link": "http://arxiv.org/abs/2011.08262v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Two-Phase Approach for Abstractive Podcast Summarization", "abstract": "Podcast summarization is different from summarization of other data formats,\nsuch as news, patents, and scientific papers in that podcasts are often longer,\nconversational, colloquial, and full of sponsorship and advertising\ninformation, which imposes great challenges for existing models. In this paper,\nwe focus on abstractive podcast summarization and propose a two-phase approach:\nsentence selection and seq2seq learning. Specifically, we first select\nimportant sentences from the noisy long podcast transcripts. The selection is\nbased on sentence similarity to the reference to reduce the redundancy and the\nassociated latent topics to preserve semantics. Then the selected sentences are\nfed into a pre-trained encoder-decoder framework for the summary generation.\nOur approach achieves promising results regarding both ROUGE-based measures and\nhuman evaluations.", "published": "2020-11-16 21:31:28", "link": "http://arxiv.org/abs/2011.08291v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Facebook AI's WMT20 News Translation Task Submission", "abstract": "This paper describes Facebook AI's submission to WMT20 shared news\ntranslation task. We focus on the low resource setting and participate in two\nlanguage pairs, Tamil <-> English and Inuktitut <-> English, where there are\nlimited out-of-domain bitext and monolingual data. We approach the low resource\nproblem using two main strategies, leveraging all available data and adapting\nthe system to the target news domain. We explore techniques that leverage\nbitext and monolingual data from all languages, such as self-supervised model\npretraining, multilingual models, data augmentation, and reranking. To better\nadapt the translation system to the test domain, we explore dataset tagging and\nfine-tuning on in-domain data. We observe that different techniques provide\nvaried improvements based on the available data of the language pair. Based on\nthe finding, we integrate these techniques into one training pipeline. For\nEn->Ta, we explore an unconstrained setup with additional Tamil bitext and\nmonolingual data and show that further improvement can be obtained. On the test\nset, our best submitted systems achieve 21.5 and 13.7 BLEU for Ta->En and\nEn->Ta respectively, and 27.9 and 13.0 for Iu->En and En->Iu respectively.", "published": "2020-11-16 21:49:00", "link": "http://arxiv.org/abs/2011.08298v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Patronize Me! An Annotated Dataset with Patronizing and\n  Condescending Language towards Vulnerable Communities", "abstract": "In this paper, we introduce a new annotated dataset which is aimed at\nsupporting the development of NLP models to identify and categorize language\nthat is patronizing or condescending towards vulnerable communities (e.g.\nrefugees, homeless people, poor families). While the prevalence of such\nlanguage in the general media has long been shown to have harmful effects, it\ndiffers from other types of harmful language, in that it is generally used\nunconsciously and with good intentions. We furthermore believe that the often\nsubtle nature of patronizing and condescending language (PCL) presents an\ninteresting technical challenge for the NLP community. Our analysis of the\nproposed dataset shows that identifying PCL is hard for standard NLP models,\nwith language models such as BERT achieving the best results.", "published": "2020-11-16 22:45:03", "link": "http://arxiv.org/abs/2011.08320v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Retrieving and ranking short medical questions with two stages neural\n  matching model", "abstract": "Internet hospital is a rising business thanks to recent advances in mobile\nweb technology and high demand of health care services. Online medical services\nbecome increasingly popular and active. According to US data in 2018, 80\npercent of internet users have asked health-related questions online. Numerous\ndata is generated in unprecedented speed and scale. Those representative\nquestions and answers in medical fields are valuable raw data sources for\nmedical data mining. Automated machine interpretation on those sheer amount of\ndata gives an opportunity to assist doctors to answer frequently asked\nmedical-related questions from the perspective of information retrieval and\nmachine learning approaches. In this work, we propose a novel two-stage\nframework for the semantic matching of query-level medical questions.", "published": "2020-11-16 07:00:35", "link": "http://arxiv.org/abs/2012.01254v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Deep Shallow Fusion for RNN-T Personalization", "abstract": "End-to-end models in general, and Recurrent Neural Network Transducer (RNN-T)\nin particular, have gained significant traction in the automatic speech\nrecognition community in the last few years due to their simplicity,\ncompactness, and excellent performance on generic transcription tasks. However,\nthese models are more challenging to personalize compared to traditional hybrid\nsystems due to the lack of external language models and difficulties in\nrecognizing rare long-tail words, specifically entity names. In this work, we\npresent novel techniques to improve RNN-T's ability to model rare WordPieces,\ninfuse extra information into the encoder, enable the use of alternative\ngraphemic pronunciations, and perform deep fusion with personalized language\nmodels for more robust biasing. We show that these combined techniques result\nin 15.4%-34.5% relative Word Error Rate improvement compared to a strong RNN-T\nbaseline which uses shallow fusion and text-to-speech augmentation. Our work\nhelps push the boundary of RNN-T personalization and close the gap with hybrid\nsystems on use cases where biasing and entity recognition are crucial.", "published": "2020-11-16 07:13:58", "link": "http://arxiv.org/abs/2011.07754v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Text Information Aggregation with Centrality Attention", "abstract": "A lot of natural language processing problems need to encode the text\nsequence as a fix-length vector, which usually involves aggregation process of\ncombining the representations of all the words, such as pooling or\nself-attention. However, these widely used aggregation approaches did not take\nhigher-order relationship among the words into consideration. Hence we propose\na new way of obtaining aggregation weights, called eigen-centrality\nself-attention. More specifically, we build a fully-connected graph for all the\nwords in a sentence, then compute the eigen-centrality as the attention score\nof each word.\n  The explicit modeling of relationships as a graph is able to capture some\nhigher-order dependency among words, which helps us achieve better results in 5\ntext classification tasks and one SNLI task than baseline models such as\npooling, self-attention and dynamic routing. Besides, in order to compute the\ndominant eigenvector of the graph, we adopt power method algorithm to get the\neigen-centrality measure. Moreover, we also derive an iterative approach to get\nthe gradient for the power method process to reduce both memory consumption and\ncomputation requirement.}", "published": "2020-11-16 13:08:48", "link": "http://arxiv.org/abs/2011.07916v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "\"What is on your mind?\" Automated Scoring of Mindreading in Childhood\n  and Early Adolescence", "abstract": "In this paper we present the first work on the automated scoring of\nmindreading ability in middle childhood and early adolescence. We create\nMIND-CA, a new corpus of 11,311 question-answer pairs in English from 1,066\nchildren aged 7 to 14. We perform machine learning experiments and carry out\nextensive quantitative and qualitative evaluation. We obtain promising results,\ndemonstrating the applicability of state-of-the-art NLP solutions to a new\ndomain and task.", "published": "2020-11-16 15:41:45", "link": "http://arxiv.org/abs/2011.08035v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NLPGym -- A toolkit for evaluating RL agents on Natural Language\n  Processing Tasks", "abstract": "Reinforcement learning (RL) has recently shown impressive performance in\ncomplex game AI and robotics tasks. To a large extent, this is thanks to the\navailability of simulated environments such as OpenAI Gym, Atari Learning\nEnvironment, or Malmo which allow agents to learn complex tasks through\ninteraction with virtual environments. While RL is also increasingly applied to\nnatural language processing (NLP), there are no simulated textual environments\navailable for researchers to apply and consistently benchmark RL on NLP tasks.\nWith the work reported here, we therefore release NLPGym, an open-source Python\ntoolkit that provides interactive textual environments for standard NLP tasks\nsuch as sequence tagging, multi-label classification, and question answering.\nWe also present experimental results for 6 tasks using different RL algorithms\nwhich serve as baselines for further research. The toolkit is published at\nhttps://github.com/rajcscw/nlp-gym", "published": "2020-11-16 20:58:35", "link": "http://arxiv.org/abs/2011.08272v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Where Are You? Localization from Embodied Dialog", "abstract": "We present Where Are You? (WAY), a dataset of ~6k dialogs in which two humans\n-- an Observer and a Locator -- complete a cooperative localization task. The\nObserver is spawned at random in a 3D environment and can navigate from\nfirst-person views while answering questions from the Locator. The Locator must\nlocalize the Observer in a detailed top-down map by asking questions and giving\ninstructions. Based on this dataset, we define three challenging tasks:\nLocalization from Embodied Dialog or LED (localizing the Observer from dialog\nhistory), Embodied Visual Dialog (modeling the Observer), and Cooperative\nLocalization (modeling both agents). In this paper, we focus on the LED task --\nproviding a strong baseline model with detailed ablations characterizing both\ndataset biases and the importance of various modeling choices. Our best model\nachieves 32.7% success at identifying the Observer's location within 3m in\nunseen buildings, vs. 70.4% for human Locators.", "published": "2020-11-16 21:09:43", "link": "http://arxiv.org/abs/2011.08277v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A New Dataset and Proposed Convolutional Neural Network Architecture for\n  Classification of American Sign Language Digits", "abstract": "According to interviews with people who work with speech impaired persons,\nspeech impaired people have difficulties in communicating with other people\naround them who do not know the sign language, and this situation may cause\nthem to isolate themselves from society and lose their sense of independence.\nWith this paper, to increase the quality of life of individuals with\nfacilitating communication between individuals who use sign language and who do\nnot know this language, a new American Sign Language (ASL) digits dataset that\ncan help to create machine learning algorithms which need to large and varied\ndata to be successful created and published as Sign Language Digits Dataset on\nKaggle Datasets web page, a proposal Convolutional Neural Network (CNN)\narchitecture that can get 98% test accuracy on our dataset presented, and\ncompared with the existing popular CNN models.", "published": "2020-11-16 18:32:22", "link": "http://arxiv.org/abs/2011.08927v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Learning Regular Expressions for Interpretable Medical Text\n  Classification Using a Pool-based Simulated Annealing and Word-vector Models", "abstract": "In this paper, we propose a rule-based engine composed of high quality and\ninterpretable regular expressions for medical text classification. The regular\nexpressions are auto generated by a constructive heuristic method and optimized\nusing a Pool-based Simulated Annealing (PSA) approach. Although existing Deep\nNeural Network (DNN) methods present high quality performance in most Natural\nLanguage Processing (NLP) applications, the solutions are regarded as\nuninterpretable black boxes to humans. Therefore, rule-based methods are often\nintroduced when interpretable solutions are needed, especially in the medical\nfield. However, the construction of regular expressions can be extremely\nlabor-intensive for large data sets. This research aims to reduce the manual\nefforts while maintaining high-quality solutions", "published": "2020-11-16 07:20:02", "link": "http://arxiv.org/abs/2011.09351v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "It's a Thin Line Between Love and Hate: Using the Echo in Modeling\n  Dynamics of Racist Online Communities", "abstract": "The (((echo))) symbol -- triple parenthesis surrounding a name, made it to\nmainstream social networks in early 2016, with the intensification of the U.S.\nPresidential race. It was used by members of the alt-right, white supremacists\nand internet trolls to tag people of Jewish heritage -- a modern incarnation of\nthe infamous yellow badge (Judenstern) used in Nazi-Germany. Tracking this\ntrending meme, its meaning, and its function has proved elusive for its\nsemantic ambiguity (e.g., a symbol for a virtual hug).\n  In this paper we report of the construction of an appropriate dataset\nallowing the reconstruction of networks of racist communities and the way they\nare embedded in the broader community. We combine natural language processing\nand structural network analysis to study communities promoting hate. In order\nto overcome dog-whistling and linguistic ambiguity, we propose a multi-modal\nneural architecture based on a BERT transformer and a BiLSTM network on the\ntweet level, while also taking into account the users ego-network and meta\nfeatures. Our multi-modal neural architecture outperforms a set of strong\nbaselines. We further show how the the use of language and network structure in\ntandem allows the detection of the leaders of the hate communities. We further\nstudy the ``intersectionality'' of hate and show that the antisemitic echo\ncorrelates with hate speech that targets other minority and protected groups.\nFinally, we analyze the role IRA trolls assumed in this network as part of the\nRussian interference campaign. Our findings allow a better understanding of\nrecent manifestations of racism and the dynamics that facilitate it.", "published": "2020-11-16 20:47:54", "link": "http://arxiv.org/abs/2012.01133v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Reinforced Medical Report Generation with X-Linear Attention and\n  Repetition Penalty", "abstract": "To reduce doctors' workload, deep-learning-based automatic medical report\ngeneration has recently attracted more and more research efforts, where\nattention mechanisms and reinforcement learning are integrated with the classic\nencoder-decoder architecture to enhance the performance of deep models.\nHowever, these state-of-the-art solutions mainly suffer from two shortcomings:\n(i) their attention mechanisms cannot utilize high-order feature interactions,\nand (ii) due to the use of TF-IDF-based reward functions, these methods are\nfragile with generating repeated terms. Therefore, in this work, we propose a\nreinforced medical report generation solution with x-linear attention and\nrepetition penalty mechanisms (ReMRG-XR) to overcome these problems.\nSpecifically, x-linear attention modules are used to explore high-order feature\ninteractions and achieve multi-modal reasoning, while repetition penalty is\nused to apply penalties to repeated terms during the model's training process.\nExtensive experimental studies have been conducted on two public datasets, and\nthe results show that ReMRG-XR greatly outperforms the state-of-the-art\nbaselines in terms of all metrics.", "published": "2020-11-16 01:44:47", "link": "http://arxiv.org/abs/2011.07680v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Beyond I.I.D.: Three Levels of Generalization for Question Answering on\n  Knowledge Bases", "abstract": "Existing studies on question answering on knowledge bases (KBQA) mainly\noperate with the standard i.i.d assumption, i.e., training distribution over\nquestions is the same as the test distribution. However, i.i.d may be neither\nreasonably achievable nor desirable on large-scale KBs because 1) true user\ndistribution is hard to capture and 2) randomly sample training examples from\nthe enormous space would be highly data-inefficient. Instead, we suggest that\nKBQA models should have three levels of built-in generalization: i.i.d,\ncompositional, and zero-shot. To facilitate the development of KBQA models with\nstronger generalization, we construct and release a new large-scale,\nhigh-quality dataset with 64,331 questions, GrailQA, and provide evaluation\nsettings for all three levels of generalization. In addition, we propose a\nnovel BERT-based KBQA model. The combination of our dataset and model enables\nus to thoroughly examine and demonstrate, for the first time, the key role of\npre-trained contextual embeddings like BERT in the generalization of KBQA.", "published": "2020-11-16 06:36:26", "link": "http://arxiv.org/abs/2011.07743v6", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Sampling Approach Matters: Active Learning for Robotic Language\n  Acquisition", "abstract": "Ordering the selection of training data using active learning can lead to\nimprovements in learning efficiently from smaller corpora. We present an\nexploration of active learning approaches applied to three grounded language\nproblems of varying complexity in order to analyze what methods are suitable\nfor improving data efficiency in learning. We present a method for analyzing\nthe complexity of data in this joint problem space, and report on how\ncharacteristics of the underlying task, along with design decisions such as\nfeature selection and classification model, drive the results. We observe that\nrepresentativeness, along with diversity, is crucial in selecting data samples.", "published": "2020-11-16 15:18:10", "link": "http://arxiv.org/abs/2011.08021v1", "categories": ["cs.RO", "cs.CL", "cs.LG"], "primary_category": "cs.RO"}
{"title": "End-to-end spoken language understanding using transformer networks and\n  self-supervised pre-trained features", "abstract": "Transformer networks and self-supervised pre-training have consistently\ndelivered state-of-art results in the field of natural language processing\n(NLP); however, their merits in the field of spoken language understanding\n(SLU) still need further investigation. In this paper we introduce a modular\nEnd-to-End (E2E) SLU transformer network based architecture which allows the\nuse of self-supervised pre-trained acoustic features, pre-trained model\ninitialization and multi-task training. Several SLU experiments for predicting\nintent and entity labels/values using the ATIS dataset are performed. These\nexperiments investigate the interaction of pre-trained model initialization and\nmulti-task training with either traditional filterbank or self-supervised\npre-trained acoustic features. Results show not only that self-supervised\npre-trained acoustic features outperform filterbank features in almost all the\nexperiments, but also that when these features are used in combination with\nmulti-task training, they almost eliminate the necessity of pre-trained model\ninitialization.", "published": "2020-11-16 19:30:52", "link": "http://arxiv.org/abs/2011.08238v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Dialog Simulation with Realistic Variations for Training Goal-Oriented\n  Conversational Systems", "abstract": "Goal-oriented dialog systems enable users to complete specific goals like\nrequesting information about a movie or booking a ticket. Typically the dialog\nsystem pipeline contains multiple ML models, including natural language\nunderstanding, state tracking and action prediction (policy learning). These\nmodels are trained through a combination of supervised or reinforcement\nlearning methods and therefore require collection of labeled domain specific\ndatasets. However, collecting annotated datasets with language and dialog-flow\nvariations is expensive, time-consuming and scales poorly due to human\ninvolvement. In this paper, we propose an approach for automatically creating a\nlarge corpus of annotated dialogs from a few thoroughly annotated sample\ndialogs and the dialog schema. Our approach includes a novel goal-sampling\ntechnique for sampling plausible user goals and a dialog simulation technique\nthat uses heuristic interplay between the user and the system (Alexa), where\nthe user tries to achieve the sampled goal. We validate our approach by\ngenerating data and training three different downstream conversational ML\nmodels. We achieve 18 ? 50% relative accuracy improvements on a held-out test\nset compared to a baseline dialog generation approach that only samples natural\nlanguage and entity value variations from existing catalogs but does not\ngenerate any novel dialog flow variations. We also qualitatively establish that\nthe proposed approach is better than the baseline. Moreover, several different\nconversational experiences have been built using this method, which enables\ncustomers to have a wide variety of conversations with Alexa.", "published": "2020-11-16 19:39:15", "link": "http://arxiv.org/abs/2011.08243v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Widening the Dialogue Workflow Modeling Bottleneck in Ontology-Based\n  Personal Assistants", "abstract": "We present a new approach to dialogue specification for Virtual Personal\nAssistants (VPAs) based on so-called dialogue workflow graphs, with several\ndemonstrated advantages over current ontology-based methods. Our new dialogue\nspecification language (DSL) enables customers to more easily participate in\nthe VPA modeling process due to a user-friendly modeling framework. Resulting\nmodels are also significantly more compact. VPAs can be developed much more\nrapidly. The DSL is a new modeling layer on top of our ontology-based Dialogue\nManagement (DM) framework OntoVPA. We explain the rationale and benefits behind\nthe new language and support our claims with concrete reduced Level-of-Effort\n(LOE) numbers from two recent OntoVPA projects.", "published": "2020-11-16 23:32:43", "link": "http://arxiv.org/abs/2011.08334v1", "categories": ["cs.CL", "cs.AI", "cs.HC", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Audio-visual Multi-channel Integration and Recognition of Overlapped\n  Speech", "abstract": "Automatic speech recognition (ASR) technologies have been significantly\nadvanced in the past few decades. However, recognition of overlapped speech\nremains a highly challenging task to date. To this end, multi-channel\nmicrophone array data are widely used in current ASR systems. Motivated by the\ninvariance of visual modality to acoustic signal corruption and the additional\ncues they provide to separate the target speaker from the interfering sound\nsources, this paper presents an audio-visual multi-channel based recognition\nsystem for overlapped speech. It benefits from a tight integration between a\nspeech separation front-end and recognition back-end, both of which incorporate\nadditional video input. A series of audio-visual multi-channel speech\nseparation front-end components based on TF masking, Filter&Sum and mask-based\nMVDR neural channel integration approaches are developed. To reduce the error\ncost mismatch between the separation and recognition components, the entire\nsystem is jointly fine-tuned using a multi-task criterion interpolation of the\nscale-invariant signal to noise ratio (Si-SNR) with either the connectionist\ntemporal classification (CTC), or lattice-free maximum mutual information\n(LF-MMI) loss function. Experiments suggest that: the proposed audio-visual\nmulti-channel recognition system outperforms the baseline audio-only\nmulti-channel ASR system by up to 8.04% (31.68% relative) and 22.86% (58.51%\nrelative) absolute WER reduction on overlapped speech constructed using either\nsimulation or replaying of the LRS2 dataset respectively. Consistent\nperformance improvements are also obtained using the proposed audio-visual\nmulti-channel recognition system when using occluded video input with the face\nregion randomly covered up to 60%.", "published": "2020-11-16 07:17:36", "link": "http://arxiv.org/abs/2011.07755v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "A General Network Architecture for Sound Event Localization and\n  Detection Using Transfer Learning and Recurrent Neural Network", "abstract": "Polyphonic sound event detection and localization (SELD) task is challenging\nbecause it is difficult to jointly optimize sound event detection (SED) and\ndirection-of-arrival (DOA) estimation in the same network. We propose a general\nnetwork architecture for SELD in which the SELD network comprises sub-networks\nthat are pretrained to solve SED and DOA estimation independently, and a\nrecurrent layer that combines the SED and DOA estimation outputs into SELD\noutputs. The recurrent layer does the alignment between the sound classes and\nDOAs of sound events while being unaware of how these outputs are produced by\nthe upstream SED and DOA estimation algorithms. This simple network\narchitecture is compatible with different existing SED and DOA estimation\nalgorithms. It is highly practical since the sub-networks can be improved\nindependently. The experimental results using the DCASE 2020 SELD dataset show\nthat the performances of our proposed network architecture using different SED\nand DOA estimation algorithms and different audio formats are competitive with\nother state-of-the-art SELD algorithms. The source code for the proposed SELD\nnetwork architecture is available at Github.", "published": "2020-11-16 10:57:02", "link": "http://arxiv.org/abs/2011.07859v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Block-Online Guided Source Separation", "abstract": "We propose a block-online algorithm of guided source separation (GSS). GSS is\na speech separation method that uses diarization information to update\nparameters of the generative model of observation signals. Previous studies\nhave shown that GSS performs well in multi-talker scenarios. However, it\nrequires a large amount of calculation time, which is an obstacle to the\ndeployment of online applications. It is also a problem that the offline GSS is\nan utterance-wise algorithm so that it produces latency according to the length\nof the utterance. With the proposed algorithm, block-wise input samples and\ncorresponding time annotations are concatenated with those in the preceding\ncontext and used to update the parameters. Using the context enables the\nalgorithm to estimate time-frequency masks accurately only from one iteration\nof optimization for each block, and its latency does not depend on the\nutterance length but predetermined block length. It also reduces calculation\ncost by updating only the parameters of active speakers in each block and its\ncontext. Evaluation on the CHiME-6 corpus and a meeting corpus showed that the\nproposed algorithm achieved almost the same performance as the conventional\noffline GSS algorithm but with 32x faster calculation, which is sufficient for\nreal-time applications.", "published": "2020-11-16 08:50:34", "link": "http://arxiv.org/abs/2011.07791v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
