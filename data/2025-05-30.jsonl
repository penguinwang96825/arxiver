{"title": "Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents", "abstract": "CAPTCHAs have been a critical bottleneck for deploying web agents in\nreal-world applications, often blocking them from completing end-to-end\nautomation tasks. While modern multimodal LLM agents have demonstrated\nimpressive performance in static perception tasks, their ability to handle\ninteractive, multi-step reasoning challenges like CAPTCHAs is largely untested.\nTo address this gap, we introduce Open CaptchaWorld, the first web-based\nbenchmark and platform specifically designed to evaluate the visual reasoning\nand interaction capabilities of MLLM-powered agents through diverse and dynamic\nCAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225\nCAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth,\nwhich quantifies the number of cognitive and motor steps required to solve each\npuzzle. Experimental results show that humans consistently achieve near-perfect\nscores, state-of-the-art MLLM agents struggle significantly, with success rates\nat most 40.0% by Browser-Use Openai-o3, far below human-level performance,\n93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing\nthe limits of current multimodal agents and guiding the development of more\nrobust multimodal reasoning systems. Code and Data are available at this https\nURL.", "published": "2025-05-30 17:59:55", "link": "http://arxiv.org/abs/2505.24878v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks", "abstract": "Deep reasoning is fundamental for solving complex tasks, especially in\nvision-centric scenarios that demand sequential, multimodal understanding.\nHowever, existing benchmarks typically evaluate agents with fully synthetic,\nsingle-turn queries, limited visual modalities, and lack a framework to assess\nreasoning quality over multiple steps as required in real-world settings. To\naddress this, we introduce Agent-X, a large-scale benchmark for evaluating\nvision-centric agents multi-step and deep reasoning capabilities in real-world,\nmultimodal settings. Agent- X features 828 agentic tasks with authentic visual\ncontexts, including images, multi-image comparisons, videos, and instructional\ntext. These tasks span six major agentic environments: general visual\nreasoning, web browsing, security and surveillance, autonomous driving, sports,\nand math reasoning. Our benchmark requires agents to integrate tool use with\nexplicit, stepwise decision-making in these diverse settings. In addition, we\npropose a fine-grained, step-level evaluation framework that assesses the\ncorrectness and logical coherence of each reasoning step and the effectiveness\nof tool usage throughout the task. Our results reveal that even the\nbest-performing models, including GPT, Gemini, and Qwen families, struggle to\nsolve multi-step vision tasks, achieving less than 50% full-chain success.\nThese findings highlight key bottlenecks in current LMM reasoning and tool-use\ncapabilities and identify future research directions in vision-centric agentic\nreasoning models. Our data and code are publicly available at\nhttps://github.com/mbzuai-oryx/Agent-X", "published": "2025-05-30 17:59:53", "link": "http://arxiv.org/abs/2505.24876v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ReasonGen-R1: CoT for Autoregressive Image generation models through SFT and RL", "abstract": "Although chain-of-thought reasoning and reinforcement learning (RL) have\ndriven breakthroughs in NLP, their integration into generative vision models\nremains underexplored. We introduce ReasonGen-R1, a two-stage framework that\nfirst imbues an autoregressive image generator with explicit text-based\n\"thinking\" skills via supervised fine-tuning on a newly generated reasoning\ndataset of written rationales, and then refines its outputs using Group\nRelative Policy Optimization. To enable the model to reason through text before\ngenerating images, We automatically generate and release a corpus of model\ncrafted rationales paired with visual prompts, enabling controlled planning of\nobject layouts, styles, and scene compositions. Our GRPO algorithm uses reward\nsignals from a pretrained vision language model to assess overall visual\nquality, optimizing the policy in each update. Evaluations on GenEval, DPG, and\nthe T2I benchmark demonstrate that ReasonGen-R1 consistently outperforms strong\nbaselines and prior state-of-the-art models. More: aka.ms/reasongen.", "published": "2025-05-30 17:59:48", "link": "http://arxiv.org/abs/2505.24875v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ProxyThinker: Test-Time Guidance through Small Visual Reasoners", "abstract": "Recent advancements in reinforcement learning with verifiable rewards have\npushed the boundaries of the visual reasoning capabilities in large\nvision-language models (LVLMs). However, training LVLMs with reinforcement\nfine-tuning (RFT) is computationally expensive, posing a significant challenge\nto scaling model size. In this work, we propose ProxyThinker, an inference-time\ntechnique that enables large models to inherit the visual reasoning\ncapabilities from small, slow-thinking visual reasoners without any training.\nBy subtracting the output distributions of base models from those of RFT\nreasoners, ProxyThinker modifies the decoding dynamics and successfully elicits\nthe slow-thinking reasoning demonstrated by the emerged sophisticated behaviors\nsuch as self-verification and self-correction. ProxyThinker consistently boosts\nperformance on challenging visual benchmarks on spatial, mathematical, and\nmulti-disciplinary reasoning, enabling untuned base models to compete with the\nperformance of their full-scale RFT counterparts. Furthermore, our\nimplementation efficiently coordinates multiple language models with\nparallelism techniques and achieves up to 38 $\\times$ faster inference compared\nto previous decoding-time methods, paving the way for the practical deployment\nof ProxyThinker. Code is available at\nhttps://github.com/MrZilinXiao/ProxyThinker.", "published": "2025-05-30 17:59:43", "link": "http://arxiv.org/abs/2505.24872v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning", "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as\na powerful paradigm for post-training large language models (LLMs), achieving\nstate-of-the-art performance on tasks with structured, verifiable answers.\nApplying RLVR to Multimodal LLMs (MLLMs) presents significant opportunities but\nis complicated by the broader, heterogeneous nature of vision-language tasks\nthat demand nuanced visual, logical, and spatial capabilities. As such,\ntraining MLLMs using RLVR on multiple datasets could be beneficial but creates\nchallenges with conflicting objectives from interaction among diverse datasets,\nhighlighting the need for optimal dataset mixture strategies to improve\ngeneralization and reasoning. We introduce a systematic post-training framework\nfor Multimodal LLM RLVR, featuring a rigorous data mixture problem formulation\nand benchmark implementation. Specifically, (1) We developed a multimodal RLVR\nframework for multi-dataset post-training by curating a dataset that contains\ndifferent verifiable vision-language problems and enabling multi-domain online\nRL learning with different verifiable rewards; (2) We proposed a data mixture\nstrategy that learns to predict the RL fine-tuning outcome from the data\nmixture distribution, and consequently optimizes the best mixture.\nComprehensive experiments showcase that multi-domain RLVR training, when\ncombined with mixture prediction strategies, can significantly boost MLLM\ngeneral reasoning capacities. Our best mixture improves the post-trained\nmodel's accuracy on out-of-distribution benchmarks by an average of 5.24%\ncompared to the same model post-trained with uniform data mixture, and by a\ntotal of 20.74% compared to the pre-finetuning baseline.", "published": "2025-05-30 17:59:38", "link": "http://arxiv.org/abs/2505.24871v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models", "abstract": "Recent advances in reasoning-centric language models have highlighted\nreinforcement learning (RL) as a promising method for aligning models with\nverifiable rewards. However, it remains contentious whether RL truly expands a\nmodel's reasoning capabilities or merely amplifies high-reward outputs already\nlatent in the base model's distribution, and whether continually scaling up RL\ncompute reliably leads to improved reasoning performance. In this work, we\nchallenge prevailing assumptions by demonstrating that prolonged RL (ProRL)\ntraining can uncover novel reasoning strategies that are inaccessible to base\nmodels, even under extensive sampling. We introduce ProRL, a novel training\nmethodology that incorporates KL divergence control, reference policy\nresetting, and a diverse suite of tasks. Our empirical analysis reveals that\nRL-trained models consistently outperform base models across a wide range of\npass@k evaluations, including scenarios where base models fail entirely\nregardless of the number of attempts. We further show that reasoning boundary\nimprovements correlates strongly with task competence of base model and\ntraining duration, suggesting that RL can explore and populate new regions of\nsolution space over time. These findings offer new insights into the conditions\nunder which RL meaningfully expands reasoning boundaries in language models and\nestablish a foundation for future work on long-horizon RL for reasoning. We\nrelease model weights to support further research:\nhttps://huggingface.co/nvidia/Nemotron-Research-Reasoning-Qwen-1.5B", "published": "2025-05-30 17:59:01", "link": "http://arxiv.org/abs/2505.24864v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time", "abstract": "This paper presents AlphaOne ($\\alpha$1), a universal framework for\nmodulating reasoning progress in large reasoning models (LRMs) at test time.\n$\\alpha$1 first introduces $\\alpha$ moment, which represents the scaled\nthinking phase with a universal parameter $\\alpha$. Within this scaled\npre-$\\alpha$ moment phase, it dynamically schedules slow thinking transitions\nby modeling the insertion of reasoning transition tokens as a Bernoulli\nstochastic process. After the $\\alpha$ moment, $\\alpha$1 deterministically\nterminates slow thinking with the end-of-thinking token, thereby fostering fast\nreasoning and efficient answer generation. This approach unifies and\ngeneralizes existing monotonic scaling methods by enabling flexible and dense\nslow-to-fast reasoning modulation. Extensive empirical studies on various\nchallenging benchmarks across mathematical, coding, and scientific domains\ndemonstrate $\\alpha$1's superior reasoning capability and efficiency. Project\npage: https://alphaone-project.github.io/", "published": "2025-05-30 17:58:36", "link": "http://arxiv.org/abs/2505.24863v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Multiple Choice: Evaluating Steering Vectors for Adaptive Free-Form Summarization", "abstract": "Steering vectors are a lightweight method for controlling text properties by\nadding a learned bias to language model activations at inference time. So far,\nsteering vectors have predominantly been evaluated in multiple-choice settings,\nwhile their effectiveness in free-form generation tasks remains understudied.\nMoving \"Beyond Multiple Choice,\" we thoroughly evaluate the effectiveness of\nsteering vectors in adaptively controlling topical focus, sentiment, toxicity,\nand readability in abstractive summaries of the NEWTS dataset. We find that\nsteering effectively controls the targeted summary properties, but high\nsteering strengths consistently degrade both intrinsic and extrinsic text\nquality. Compared to steering, prompting offers weaker control, while\npreserving text quality. Combining steering and prompting yields the strongest\ncontrol over text properties and offers the most favorable efficacy-quality\ntrade-off at moderate steering strengths. Our results underscore the practical\ntrade-off between control strength and text quality preservation when applying\nsteering vectors to free-form generation tasks.", "published": "2025-05-30 17:57:15", "link": "http://arxiv.org/abs/2505.24859v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "MetaFaith: Faithful Natural Language Uncertainty Expression in LLMs", "abstract": "A critical component in the trustworthiness of LLMs is reliable uncertainty\ncommunication, yet LLMs often use assertive language when conveying false\nclaims, leading to over-reliance and eroded trust. We present the first\nsystematic study of $\\textit{faithful confidence calibration}$ of LLMs,\nbenchmarking models' ability to use linguistic expressions of uncertainty that\n$\\textit{faithfully reflect}$ their intrinsic uncertainty, across a\ncomprehensive array of models, datasets, and prompting strategies. Our results\ndemonstrate that LLMs largely fail at this task, and that existing\ninterventions are insufficient: standard prompt approaches provide only\nmarginal gains, and existing, factuality-based calibration techniques can even\nharm faithful calibration. To address this critical gap, we introduce\nMetaFaith, a novel prompt-based calibration approach inspired by human\nmetacognition. We show that MetaFaith robustly improves faithful calibration\nacross diverse models and task domains, enabling up to 61% improvement in\nfaithfulness and achieving an 83% win rate over original generations as judged\nby humans.", "published": "2025-05-30 17:54:08", "link": "http://arxiv.org/abs/2505.24858v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Harnessing Negative Signals: Reinforcement Distillation from Teacher Data for LLM Reasoning", "abstract": "Recent advances in model distillation demonstrate that data from advanced\nreasoning models (e.g., DeepSeek-R1, OpenAI's o1) can effectively transfer\ncomplex reasoning abilities to smaller, efficient student models. However,\nstandard practices employ rejection sampling, discarding incorrect reasoning\nexamples -- valuable, yet often underutilized data. This paper addresses the\ncritical question: How can both positive and negative distilled reasoning\ntraces be effectively leveraged to maximize LLM reasoning performance in an\noffline setting? To this end, We propose Reinforcement Distillation (REDI), a\ntwo-stage framework. Stage 1 learns from positive traces via Supervised\nFine-Tuning (SFT). Stage 2 further refines the model using both positive and\nnegative traces through our proposed REDI objective. This novel objective is a\nsimple, reference-free loss function that outperforms established methods like\nDPO and SimPO in this distillation context. Our empirical evaluations\ndemonstrate REDI's superiority over baseline Rejection Sampling SFT or SFT\ncombined with DPO/SimPO on mathematical reasoning tasks. Notably, the\nQwen-REDI-1.5B model, post-trained on just 131k positive and negative examples\nfrom the open Open-R1 dataset, achieves an 83.1% score on MATH-500 (pass@1).\nIts performance matches or surpasses that of DeepSeek-R1-Distill-Qwen-1.5B (a\nmodel post-trained on 800k proprietary data) across various mathematical\nreasoning benchmarks, establishing a new state-of-the-art for 1.5B models\npost-trained offline with openly available data.", "published": "2025-05-30 17:47:17", "link": "http://arxiv.org/abs/2505.24850v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "primary_category": "cs.LG"}
{"title": "MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning", "abstract": "Reward modeling is a key step in building safe foundation models when\napplying reinforcement learning from human feedback (RLHF) to align Large\nLanguage Models (LLMs). However, reward modeling based on the Bradley-Terry\n(BT) model assumes a global reward function, failing to capture the inherently\ndiverse and heterogeneous human preferences. Hence, such oversimplification\nlimits LLMs from supporting personalization and pluralistic alignment.\nTheoretically, we show that when human preferences follow a mixture\ndistribution of diverse subgroups, a single BT model has an irreducible error.\nWhile existing solutions, such as multi-objective learning with fine-grained\nannotations, help address this issue, they are costly and constrained by\npredefined attributes, failing to fully capture the richness of human values.\nIn this work, we introduce MiCRo, a two-stage framework that enhances\npersonalized preference learning by leveraging large-scale binary preference\ndatasets without requiring explicit fine-grained annotations. In the first\nstage, MiCRo introduces context-aware mixture modeling approach to capture\ndiverse human preferences. In the second stage, MiCRo integrates an online\nrouting strategy that dynamically adapts mixture weights based on specific\ncontext to resolve ambiguity, allowing for efficient and scalable preference\nadaptation with minimal additional supervision. Experiments on multiple\npreference datasets demonstrate that MiCRo effectively captures diverse human\npreferences and significantly improves downstream personalization.", "published": "2025-05-30 17:44:28", "link": "http://arxiv.org/abs/2505.24846v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning", "abstract": "Training data mixtures greatly impact the generalization performance of large\nlanguage models. Existing domain reweighting methods often rely on costly\nweight computations and require retraining when new data is introduced. To this\nend, we introduce a flexible and efficient data mixing framework, Chameleon,\nthat employs leverage scores to quantify domain importance within a learned\nembedding space. We first construct a domain affinity matrix over domain\nembeddings. The induced leverage scores determine a mixture that upweights\ndomains sharing common representations in embedding space. This formulation\nallows direct transfer to new data by computing the new domain embeddings. In\nexperiments, we demonstrate improvements over three key scenarios: (i) our\ncomputed weights improve performance on pretraining domains with a fraction of\nthe compute of existing methods; (ii) Chameleon can adapt to data changes\nwithout proxy retraining, boosting few-shot reasoning accuracies when\ntransferred to new data; (iii) our method enables efficient domain reweighting\nin finetuning, consistently improving test perplexity on all finetuning domains\nover uniform mixture. Our code is available at\nhttps://github.com/LIONS-EPFL/Chameleon.", "published": "2025-05-30 17:43:10", "link": "http://arxiv.org/abs/2505.24844v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Vision LLMs Are Bad at Hierarchical Visual Understanding, and LLMs Are the Bottleneck", "abstract": "This paper reveals that many state-of-the-art large language models (LLMs)\nlack hierarchical knowledge about our visual world, unaware of even\nwell-established biology taxonomies. This shortcoming makes LLMs a bottleneck\nfor vision LLMs' hierarchical visual understanding (e.g., recognizing Anemone\nFish but not Vertebrate). We arrive at these findings using about one million\nfour-choice visual question answering (VQA) tasks constructed from six\ntaxonomies and four image datasets. Interestingly, finetuning a vision LLM\nusing our VQA tasks reaffirms LLMs' bottleneck effect to some extent because\nthe VQA tasks improve the LLM's hierarchical consistency more than the vision\nLLM's. We conjecture that one cannot make vision LLMs understand visual\nconcepts fully hierarchical until LLMs possess corresponding taxonomy\nknowledge.", "published": "2025-05-30 17:40:46", "link": "http://arxiv.org/abs/2505.24840v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Multilinguality Does not Make Sense: Investigating Factors Behind Zero-Shot Transfer in Sense-Aware Tasks", "abstract": "Cross-lingual transfer allows models to perform tasks in languages unseen\nduring training and is often assumed to benefit from increased multilinguality.\nIn this work, we challenge this assumption in the context of two underexplored,\nsense-aware tasks: polysemy disambiguation and lexical semantic change. Through\na large-scale analysis across 28 languages, we show that multilingual training\nis neither necessary nor inherently beneficial for effective transfer. Instead,\nwe find that confounding factors - such as fine-tuning data composition and\nevaluation artifacts - better account for the perceived advantages of\nmultilinguality. Our findings call for more rigorous evaluations in\nmultilingual NLP. We release fine-tuned models and benchmarks to support\nfurther research, with implications extending to low-resource and typologically\ndiverse languages.", "published": "2025-05-30 17:36:20", "link": "http://arxiv.org/abs/2505.24834v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How much do language models memorize?", "abstract": "We propose a new method for estimating how much a model ``knows'' about a\ndatapoint and use it to measure the capacity of modern language models. Prior\nstudies of language model memorization have struggled to disentangle\nmemorization from generalization. We formally separate memorization into two\ncomponents: \\textit{unintended memorization}, the information a model contains\nabout a specific dataset, and \\textit{generalization}, the information a model\ncontains about the true data-generation process. When we completely eliminate\ngeneralization, we can compute the total memorization, which provides an\nestimate of model capacity: our measurements estimate that GPT-style models\nhave a capacity of approximately 3.6 bits per parameter. We train language\nmodels on datasets of increasing size and observe that models memorize until\ntheir capacity fills, at which point ``grokking'' begins, and unintended\nmemorization decreases as models begin to generalize. We train hundreds of\ntransformer language models ranging from $500K$ to $1.5B$ parameters and\nproduce a series of scaling laws relating model capacity and data size to\nmembership inference.", "published": "2025-05-30 17:34:03", "link": "http://arxiv.org/abs/2505.24832v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Reliability and Explainability of Medical Question Answering through Atomic Fact Checking in Retrieval-Augmented LLMs", "abstract": "Large language models (LLMs) exhibit extensive medical knowledge but are\nprone to hallucinations and inaccurate citations, which pose a challenge to\ntheir clinical adoption and regulatory compliance. Current methods, such as\nRetrieval Augmented Generation, partially address these issues by grounding\nanswers in source documents, but hallucinations and low fact-level\nexplainability persist. In this work, we introduce a novel atomic fact-checking\nframework designed to enhance the reliability and explainability of LLMs used\nin medical long-form question answering. This method decomposes LLM-generated\nresponses into discrete, verifiable units called atomic facts, each of which is\nindependently verified against an authoritative knowledge base of medical\nguidelines. This approach enables targeted correction of errors and direct\ntracing to source literature, thereby improving the factual accuracy and\nexplainability of medical Q&A. Extensive evaluation using multi-reader\nassessments by medical experts and an automated open Q&A benchmark demonstrated\nsignificant improvements in factual accuracy and explainability. Our framework\nachieved up to a 40% overall answer improvement and a 50% hallucination\ndetection rate. The ability to trace each atomic fact back to the most relevant\nchunks from the database provides a granular, transparent explanation of the\ngenerated responses, addressing a major gap in current medical AI applications.\nThis work represents a crucial step towards more trustworthy and reliable\nclinical applications of LLMs, addressing key prerequisites for clinical\napplication and fostering greater confidence in AI-assisted healthcare.", "published": "2025-05-30 17:33:07", "link": "http://arxiv.org/abs/2505.24830v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LegalEval-Q: A New Benchmark for The Quality Evaluation of LLM-Generated Legal Text", "abstract": "As large language models (LLMs) are increasingly used in legal applications,\ncurrent evaluation benchmarks tend to focus mainly on factual accuracy while\nlargely neglecting important linguistic quality aspects such as clarity,\ncoherence, and terminology. To address this gap, we propose three steps: First,\nwe develop a regression model to evaluate the quality of legal texts based on\nclarity, coherence, and terminology. Second, we create a specialized set of\nlegal questions. Third, we analyze 49 LLMs using this evaluation framework.\n  Our analysis identifies three key findings: First, model quality levels off\nat 14 billion parameters, with only a marginal improvement of $2.7\\%$ noted at\n72 billion parameters. Second, engineering choices such as quantization and\ncontext length have a negligible impact, as indicated by statistical\nsignificance thresholds above 0.016. Third, reasoning models consistently\noutperform base architectures. A significant outcome of our research is the\nrelease of a ranking list and Pareto analysis, which highlight the Qwen3 series\nas the optimal choice for cost-performance tradeoffs. This work not only\nestablishes standardized evaluation protocols for legal LLMs but also uncovers\nfundamental limitations in current training data refinement approaches. Code\nand models are available at: https://github.com/lyxx3rd/LegalEval-Q.", "published": "2025-05-30 17:30:18", "link": "http://arxiv.org/abs/2505.24826v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models", "abstract": "Large language models (LLMs) have rapidly advanced and are increasingly\ncapable of tackling complex scientific problems, including those in physics.\nDespite this progress, current LLMs often fail to emulate the concise,\nprinciple-based reasoning characteristic of human experts, instead generating\nlengthy and opaque solutions. This discrepancy highlights a crucial gap in\ntheir ability to apply core physical principles for efficient and interpretable\nproblem solving. To systematically investigate this limitation, we introduce\nPhySense, a novel principle-based physics reasoning benchmark designed to be\neasily solvable by experts using guiding principles, yet deceptively difficult\nfor LLMs without principle-first reasoning. Our evaluation across multiple\nstate-of-the-art LLMs and prompt types reveals a consistent failure to align\nwith expert-like reasoning paths, providing insights for developing AI systems\nwith efficient, robust and interpretable principle-based scientific reasoning.", "published": "2025-05-30 17:25:20", "link": "http://arxiv.org/abs/2505.24823v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Guiding Generative Storytelling with Knowledge Graphs", "abstract": "Large Language Models (LLMs) have shown great potential in automated story\ngeneration, but challenges remain in maintaining long-form coherence and\nproviding users with intuitive and effective control. Retrieval-Augmented\nGeneration (RAG) has proven effective in reducing hallucinations in text\ngeneration; however, the use of structured data to support generative\nstorytelling remains underexplored. This paper investigates how knowledge\ngraphs (KGs) can enhance LLM-based storytelling by improving narrative quality\nand enabling user-driven modifications. We propose a KG-assisted storytelling\npipeline and evaluate its effectiveness through a user study with 15\nparticipants. Participants created their own story prompts, generated stories,\nand edited knowledge graphs to shape their narratives. Through quantitative and\nqualitative analysis, our findings demonstrate that knowledge graphs\nsignificantly enhance story quality in action-oriented and structured\nnarratives within our system settings. Additionally, editing the knowledge\ngraph increases users' sense of control, making storytelling more engaging,\ninteractive, and playful.", "published": "2025-05-30 17:08:21", "link": "http://arxiv.org/abs/2505.24803v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Drop Dropout on Single-Epoch Language Model Pretraining", "abstract": "Originally, dropout was seen as a breakthrough regularization technique that\nreduced overfitting and improved performance in almost all applications of deep\nlearning by reducing overfitting. Yet, single-epoch pretraining tasks common to\nmodern LLMs yield minimal overfitting, leading to dropout not being used for\nlarge LLMs. Nevertheless, no thorough empirical investigation has been done on\nthe role of dropout in LM pretraining. Through experiments in single-epoch\npretraining of both masked (BERT) and autoregressive (Pythia 160M and 1.4B) LMs\nwith varying levels of dropout, we find that downstream performance in language\nmodeling, morpho-syntax (BLiMP), question answering (SQuAD), and\nnatural-language inference (MNLI) improves when dropout is not applied during\npretraining. We additionally find that the recently-introduced \"early dropout\"\nalso degrades performance over applying no dropout at all. We further\ninvestigate the models' editability, and find that models trained without\ndropout are more successful in gradient-based model editing (MEND) and\nequivalent in representation-based model editing (ReFT). Therefore, we advocate\nto drop dropout during single-epoch pretraining.", "published": "2025-05-30 16:48:38", "link": "http://arxiv.org/abs/2505.24788v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Draw ALL Your Imagine: A Holistic Benchmark and Agent Framework for Complex Instruction-based Image Generation", "abstract": "Recent advancements in text-to-image (T2I) generation have enabled models to\nproduce high-quality images from textual descriptions. However, these models\noften struggle with complex instructions involving multiple objects,\nattributes, and spatial relationships. Existing benchmarks for evaluating T2I\nmodels primarily focus on general text-image alignment and fail to capture the\nnuanced requirements of complex, multi-faceted prompts. Given this gap, we\nintroduce LongBench-T2I, a comprehensive benchmark specifically designed to\nevaluate T2I models under complex instructions. LongBench-T2I consists of 500\nintricately designed prompts spanning nine diverse visual evaluation\ndimensions, enabling a thorough assessment of a model's ability to follow\ncomplex instructions. Beyond benchmarking, we propose an agent framework\n(Plan2Gen) that facilitates complex instruction-driven image generation without\nrequiring additional model training. This framework integrates seamlessly with\nexisting T2I models, using large language models to interpret and decompose\ncomplex prompts, thereby guiding the generation process more effectively. As\nexisting evaluation metrics, such as CLIPScore, fail to adequately capture the\nnuances of complex instructions, we introduce an evaluation toolkit that\nautomates the quality assessment of generated images using a set of\nmulti-dimensional metrics. The data and code are released at\nhttps://github.com/yczhou001/LongBench-T2I.", "published": "2025-05-30 16:48:14", "link": "http://arxiv.org/abs/2505.24787v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models' Uncertainty?", "abstract": "As large language models (LLMs) are increasingly used in high-stakes domains,\naccurately assessing their confidence is crucial. Humans typically express\nconfidence through epistemic markers (e.g., \"fairly confident\") instead of\nnumerical values. However, it remains unclear whether LLMs consistently use\nthese markers to reflect their intrinsic confidence due to the difficulty of\nquantifying uncertainty associated with various markers. To address this gap,\nwe first define marker confidence as the observed accuracy when a model employs\nan epistemic marker. We evaluate its stability across multiple\nquestion-answering datasets in both in-distribution and out-of-distribution\nsettings for open-source and proprietary LLMs. Our results show that while\nmarkers generalize well within the same distribution, their confidence is\ninconsistent in out-of-distribution scenarios. These findings raise significant\nconcerns about the reliability of epistemic markers for confidence estimation,\nunderscoring the need for improved alignment between marker based confidence\nand actual model uncertainty. Our code is available at\nhttps://github.com/HKUST-KnowComp/MarCon.", "published": "2025-05-30 16:41:24", "link": "http://arxiv.org/abs/2505.24778v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Macro to Micro: Probing Dataset Diversity in Language Model Fine-Tuning", "abstract": "Dataset diversity plays a pivotal role for the successful training of many\nmachine learning models, particularly in the supervised fine-tuning (SFT) stage\nof large language model (LLM) development. Despite increasing recognition of\nits importance, systematic analyses of dataset diversity still remain\nunderexplored. To address this gap, this work presents a systematic taxonomy of\nexisting diversity-control strategies, which primarily focus on the instruction\ncomponent, operating at either macroscopic (entire instruction semantics) or\nmesoscopic levels (instruction units), and furthermore introduces a novel\nanalysis of microscopic diversity within the response component, specifically\nanalyzing the statistical distribution of tokens in SFT training samples. In\nthe experimental evaluation, we construct fixed-size datasets (e.g., 10,000\nsamples each) from a corpus of 117,000 open-source SFT samples, incorporating\nsix distinct diversity-control strategies spanning macro-, meso-, and\nmicroscopic levels applied to both instructions and responses. We then\nfine-tune LLMs on these datasets to assess the six diversity-control\nstrategies. Results reveal that while macroscopic and mesoscopic strategies\nlead to higher performance with increasing diversity, the microscopic strategy\nin responses exhibits both a stronger correlation between model performance and\nthe degree of diversity and superior performance with maximum diversity across\nall strategies. These findings offer actionable insights for constructing\nhigh-performance SFT datasets.", "published": "2025-05-30 16:31:05", "link": "http://arxiv.org/abs/2505.24768v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "REASONING GYM: Reasoning Environments for Reinforcement Learning with Verifiable Rewards", "abstract": "We introduce Reasoning Gym (RG), a library of reasoning environments for\nreinforcement learning with verifiable rewards. It provides over 100 data\ngenerators and verifiers spanning multiple domains including algebra,\narithmetic, computation, cognition, geometry, graph theory, logic, and various\ncommon games. Its key innovation is the ability to generate virtually infinite\ntraining data with adjustable complexity, unlike most previous reasoning\ndatasets, which are typically fixed. This procedural generation approach allows\nfor continuous evaluation across varying difficulty levels. Our experimental\nresults demonstrate the efficacy of RG in both evaluating and reinforcement\nlearning of reasoning models.", "published": "2025-05-30 16:20:18", "link": "http://arxiv.org/abs/2505.24760v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LGAR: Zero-Shot LLM-Guided Neural Ranking for Abstract Screening in Systematic Literature Reviews", "abstract": "The scientific literature is growing rapidly, making it hard to keep track of\nthe state-of-the-art. Systematic literature reviews (SLRs) aim to identify and\nevaluate all relevant papers on a topic. After retrieving a set of candidate\npapers, the abstract screening phase determines initial relevance. To date,\nabstract screening methods using large language models (LLMs) focus on binary\nclassification settings; existing question answering (QA) based ranking\napproaches suffer from error propagation. LLMs offer a unique opportunity to\nevaluate the SLR's inclusion and exclusion criteria, yet, existing benchmarks\ndo not provide them exhaustively. We manually extract these criteria as well as\nresearch questions for 57 SLRs, mostly in the medical domain, enabling\nprincipled comparisons between approaches. Moreover, we propose LGAR, a\nzero-shot LLM Guided Abstract Ranker composed of an LLM based graded relevance\nscorer and a dense re-ranker. Our extensive experiments show that LGAR\noutperforms existing QA-based methods by 5-10 pp. in mean average precision.\nOur code and data is publicly available.", "published": "2025-05-30 16:18:50", "link": "http://arxiv.org/abs/2505.24757v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation", "abstract": "In this work, we investigate an important task named instruction-following\ntext embedding, which generates dynamic text embeddings that adapt to user\ninstructions, highlighting specific attributes of text. Despite recent\nadvancements, existing approaches suffer from significant computational\noverhead, as they require re-encoding the entire corpus for each new\ninstruction. To address this challenge, we propose GSTransform, a novel\ninstruction-following text embedding framework based on Guided Space\nTransformation. Our key observation is that instruction-relevant information is\ninherently encoded in generic embeddings but remains underutilized. Instead of\nrepeatedly encoding the corpus for each instruction, GSTransform is a\nlightweight transformation mechanism that adapts pre-computed embeddings in\nreal time to align with user instructions, guided by a small amount of text\ndata with instruction-focused label annotation. We conduct extensive\nexperiments on three instruction-awareness downstream tasks across nine\nreal-world datasets, demonstrating that GSTransform improves\ninstruction-following text embedding quality over state-of-the-art methods\nwhile achieving dramatic speedups of 6~300x in real-time processing on\nlarge-scale datasets. The source code is available at\nhttps://github.com/YingchaojieFeng/GSTransform.", "published": "2025-05-30 16:16:22", "link": "http://arxiv.org/abs/2505.24754v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "SUMO: Subspace-Aware Moment-Orthogonalization for Accelerating Memory-Efficient LLM Training", "abstract": "Low-rank gradient-based optimization methods have significantly improved\nmemory efficiency during the training of large language models (LLMs), enabling\noperations within constrained hardware without sacrificing performance.\nHowever, these methods primarily emphasize memory savings, often overlooking\npotential acceleration in convergence due to their reliance on standard\nisotropic steepest descent techniques, which can perform suboptimally in the\nhighly anisotropic landscapes typical of deep networks, particularly LLMs. In\nthis paper, we propose SUMO (Subspace-Aware Moment-Orthogonalization), an\noptimizer that employs exact singular value decomposition (SVD) for moment\northogonalization within a dynamically adapted low-dimensional subspace,\nenabling norm-inducing steepest descent optimization steps. By explicitly\naligning optimization steps with the spectral characteristics of the loss\nlandscape, SUMO effectively mitigates approximation errors associated with\ncommonly used methods like Newton-Schulz orthogonalization approximation. We\ntheoretically establish an upper bound on these approximation errors, proving\ntheir dependence on the condition numbers of moments, conditions we\nanalytically demonstrate are encountered during LLM training. Furthermore, we\nboth theoretically and empirically illustrate that exact orthogonalization via\nSVD substantially improves convergence rates while reducing overall complexity.\nEmpirical evaluations confirm that SUMO accelerates convergence, enhances\nstability, improves performance, and reduces memory requirements by up to 20%\ncompared to state-of-the-art methods.", "published": "2025-05-30 16:08:40", "link": "http://arxiv.org/abs/2505.24749v1", "categories": ["cs.LG", "cs.CL", "math.OC"], "primary_category": "cs.LG"}
{"title": "\"Dyadosyncrasy\", Idiosyncrasy and Demographic Factors in Turn-Taking", "abstract": "Turn-taking in dialogue follows universal constraints but also varies\nsignificantly. This study examines how demographic (sex, age, education) and\nindividual factors shape turn-taking using a large dataset of US English\nconversations (Fisher). We analyze Transition Floor Offset (TFO) and find\nnotable interspeaker variation. Sex and age have small but significant effects\nfemale speakers and older individuals exhibit slightly shorter offsets - while\neducation shows no effect. Lighter topics correlate with shorter TFOs. However,\nindividual differences have a greater impact, driven by a strong idiosyncratic\nand an even stronger \"dyadosyncratic\" component - speakers in a dyad resemble\neach other more than they resemble themselves in different dyads. This suggests\nthat the dyadic relationship and joint activity are the strongest determinants\nof TFO, outweighing demographic influences.", "published": "2025-05-30 15:55:47", "link": "http://arxiv.org/abs/2505.24736v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Circuit Stability Characterizes Language Model Generalization", "abstract": "Extensively evaluating the capabilities of (large) language models is\ndifficult. Rapid development of state-of-the-art models induce benchmark\nsaturation, while creating more challenging datasets is labor-intensive.\nInspired by the recent developments in mechanistic interpretability, we\nintroduce circuit stability as a new way to assess model performance. Circuit\nstability refers to a model's ability to apply a consistent reasoning\nprocess-its circuit-across various inputs. We mathematically formalize circuit\nstability and circuit equivalence. Then, through three case studies, we\nempirically show that circuit stability and the lack thereof can characterize\nand predict different aspects of generalization. Our proposed methods offer a\nstep towards rigorously relating the generality of models to their\ninterpretability.", "published": "2025-05-30 15:53:56", "link": "http://arxiv.org/abs/2505.24731v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reflect, Retry, Reward: Self-Improving LLMs via Reinforcement Learning", "abstract": "We explore a method for improving the performance of large language models\nthrough self-reflection and reinforcement learning. By incentivizing the model\nto generate better self-reflections when it answers incorrectly, we demonstrate\nthat a model's ability to solve complex, verifiable tasks can be enhanced even\nwhen generating synthetic data is infeasible and only binary feedback is\navailable. Our framework operates in two stages: first, upon failing a given\ntask, the model generates a self-reflective commentary analyzing its previous\nattempt; second, the model is given another attempt at the task with the\nself-reflection in context. If the subsequent attempt succeeds, the tokens\ngenerated during the self-reflection phase are rewarded. Our experimental\nresults show substantial performance gains across a variety of model\narchitectures, as high as 34.7% improvement at math equation writing and 18.1%\nimprovement at function calling. Notably, smaller fine-tuned models (1.5\nbillion to 7 billion parameters) outperform models in the same family that are\n10 times larger. Our novel paradigm is thus an exciting pathway to more useful\nand reliable language models that can self-improve on challenging tasks with\nlimited external feedback.", "published": "2025-05-30 15:49:42", "link": "http://arxiv.org/abs/2505.24726v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CoRet: Improved Retriever for Code Editing", "abstract": "In this paper, we introduce CoRet, a dense retrieval model designed for\ncode-editing tasks that integrates code semantics, repository structure, and\ncall graph dependencies. The model focuses on retrieving relevant portions of a\ncode repository based on natural language queries such as requests to implement\nnew features or fix bugs. These retrieved code chunks can then be presented to\na user or to a second code-editing model or agent. To train CoRet, we propose a\nloss function explicitly designed for repository-level retrieval. On SWE-bench\nand Long Code Arena's bug localisation datasets, we show that our model\nsubstantially improves retrieval recall by at least 15 percentage points over\nexisting models, and ablate the design choices to show their importance in\nachieving these results.", "published": "2025-05-30 15:36:37", "link": "http://arxiv.org/abs/2505.24715v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "FinMME: Benchmark Dataset for Financial Multi-Modal Reasoning Evaluation", "abstract": "Multimodal Large Language Models (MLLMs) have experienced rapid development\nin recent years. However, in the financial domain, there is a notable lack of\neffective and specialized multimodal evaluation datasets. To advance the\ndevelopment of MLLMs in the finance domain, we introduce FinMME, encompassing\nmore than 11,000 high-quality financial research samples across 18 financial\ndomains and 6 asset classes, featuring 10 major chart types and 21 subtypes. We\nensure data quality through 20 annotators and carefully designed validation\nmechanisms. Additionally, we develop FinScore, an evaluation system\nincorporating hallucination penalties and multi-dimensional capability\nassessment to provide an unbiased evaluation. Extensive experimental results\ndemonstrate that even state-of-the-art models like GPT-4o exhibit\nunsatisfactory performance on FinMME, highlighting its challenging nature. The\nbenchmark exhibits high robustness with prediction variations under different\nprompts remaining below 1%, demonstrating superior reliability compared to\nexisting datasets. Our dataset and evaluation protocol are available at\nhttps://huggingface.co/datasets/luojunyu/FinMME and\nhttps://github.com/luo-junyu/FinMME.", "published": "2025-05-30 15:36:19", "link": "http://arxiv.org/abs/2505.24714v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Voice Conversion Improves Cross-Domain Robustness for Spoken Arabic Dialect Identification", "abstract": "Arabic dialect identification (ADI) systems are essential for large-scale\ndata collection pipelines that enable the development of inclusive speech\ntechnologies for Arabic language varieties. However, the reliability of current\nADI systems is limited by poor generalization to out-of-domain speech. In this\npaper, we present an effective approach based on voice conversion for training\nADI models that achieves state-of-the-art performance and significantly\nimproves robustness in cross-domain scenarios. Evaluated on a newly collected\nreal-world test set spanning four different domains, our approach yields\nconsistent improvements of up to +34.1% in accuracy across domains.\nFurthermore, we present an analysis of our approach and demonstrate that voice\nconversion helps mitigate the speaker bias in the ADI dataset. We release our\nrobust ADI model and cross-domain evaluation dataset to support the development\nof inclusive speech technologies for Arabic.", "published": "2025-05-30 15:36:08", "link": "http://arxiv.org/abs/2505.24713v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "HESEIA: A community-based dataset for evaluating social biases in large language models, co-designed in real school settings in Latin America", "abstract": "Most resources for evaluating social biases in Large Language Models are\ndeveloped without co-design from the communities affected by these biases, and\nrarely involve participatory approaches. We introduce HESEIA, a dataset of\n46,499 sentences created in a professional development course. The course\ninvolved 370 high-school teachers and 5,370 students from 189 Latin-American\nschools. Unlike existing benchmarks, HESEIA captures intersectional biases\nacross multiple demographic axes and school subjects. It reflects local\ncontexts through the lived experience and pedagogical expertise of educators.\nTeachers used minimal pairs to create sentences that express stereotypes\nrelevant to their school subjects and communities. We show the dataset\ndiversity in term of demographic axes represented and also in terms of the\nknowledge areas included. We demonstrate that the dataset contains more\nstereotypes unrecognized by current LLMs than previous datasets. HESEIA is\navailable to support bias assessments grounded in educational communities.", "published": "2025-05-30 15:32:48", "link": "http://arxiv.org/abs/2505.24712v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting", "abstract": "Large language models (LLMs) have shown great potential in decision-making\ndue to the vast amount of knowledge stored within the models. However, these\npre-trained models are prone to lack reasoning abilities and are difficult to\nadapt to new environments, further hindering their application to complex\nreal-world tasks. To address these challenges, inspired by the human cognitive\nprocess, we propose Causal-aware LLMs, which integrate the structural causal\nmodel (SCM) into the decision-making process to model, update, and utilize\nstructured knowledge of the environment in a ``learning-adapting-acting\"\nparadigm. Specifically, in the learning stage, we first utilize an LLM to\nextract the environment-specific causal entities and their causal relations to\ninitialize a structured causal model of the environment. Subsequently,in the\nadapting stage, we update the structured causal model through external feedback\nabout the environment, via an idea of causal intervention. Finally, in the\nacting stage, Causal-aware LLMs exploit structured causal knowledge for more\nefficient policy-making through the reinforcement learning agent. The above\nprocesses are performed iteratively to learn causal knowledge, ultimately\nenabling the causal-aware LLMs to achieve a more accurate understanding of the\nenvironment and make more efficient decisions. Experimental results across 22\ndiverse tasks within the open-world game ``Crafter\" validate the effectiveness\nof our proposed method.", "published": "2025-05-30 15:30:44", "link": "http://arxiv.org/abs/2505.24710v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Multi-Domain ABSA Conversation Dataset Generation via LLMs for Real-World Evaluation and Model Comparison", "abstract": "Aspect-Based Sentiment Analysis (ABSA) offers granular insights into opinions\nbut often suffers from the scarcity of diverse, labeled datasets that reflect\nreal-world conversational nuances. This paper presents an approach for\ngenerating synthetic ABSA data using Large Language Models (LLMs) to address\nthis gap. We detail the generation process aimed at producing data with\nconsistent topic and sentiment distributions across multiple domains using\nGPT-4o. The quality and utility of the generated data were evaluated by\nassessing the performance of three state-of-the-art LLMs (Gemini 1.5 Pro,\nClaude 3.5 Sonnet, and DeepSeek-R1) on topic and sentiment classification\ntasks. Our results demonstrate the effectiveness of the synthetic data,\nrevealing distinct performance trade-offs among the models: DeepSeekR1 showed\nhigher precision, Gemini 1.5 Pro and Claude 3.5 Sonnet exhibited strong recall,\nand Gemini 1.5 Pro offered significantly faster inference. We conclude that\nLLM-based synthetic data generation is a viable and flexible method for\ncreating valuable ABSA resources, facilitating research and model evaluation\nwithout reliance on limited or inaccessible real-world labeled data.", "published": "2025-05-30 15:24:17", "link": "http://arxiv.org/abs/2505.24701v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Speech-to-Text Translation with Phoneme-Augmented CoT: Enhancing Cross-Lingual Transfer in Low-Resource Scenarios", "abstract": "We propose a Speech-to-Text Translation (S2TT) approach that integrates\nphoneme representations into a Chain-of-Thought (CoT) framework to improve\ntranslation in low-resource and zero-resource settings. By introducing phoneme\nrecognition as an intermediate step, we enhance cross-lingual transfer,\nenabling translation even for languages with no labeled speech data. Our system\nbuilds on a multilingual LLM, which we extend to process speech and phonemes.\nTraining follows a curriculum learning strategy that progressively introduces\nmore complex tasks. Experiments on multilingual S2TT benchmarks show that\nphoneme-augmented CoT improves translation quality in low-resource conditions\nand enables zero-resource translation, while slightly impacting high-resource\nperformance. Despite this trade-off, our findings demonstrate that\nphoneme-based CoT is a promising step toward making S2TT more accessible across\ndiverse languages.", "published": "2025-05-30 15:15:00", "link": "http://arxiv.org/abs/2505.24691v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "BPE Stays on SCRIPT: Structured Encoding for Robust Multilingual Pretokenization", "abstract": "Byte Pair Encoding (BPE) tokenizers, widely used in Large Language Models,\nface challenges in multilingual settings, including penalization of non-Western\nscripts and the creation of tokens with partial UTF-8 sequences.\nPretokenization, often reliant on complex regular expressions, can also\nintroduce fragility and unexpected edge cases. We propose SCRIPT (Script\nCategory Representation in PreTokenization), a novel encoding scheme that\nbypasses UTF-8 byte conversion by using initial tokens based on Unicode script\nand category properties. This approach enables a simple, rule-based\npretokenization strategy that respects script boundaries, offering a robust\nalternative to pretokenization strategies based on regular expressions. We also\nintroduce and validate a constrained BPE merging strategy that enforces\ncharacter integrity, applicable to both SCRIPT-BPE and byte-based BPE. Our\nexperiments demonstrate that SCRIPT-BPE achieves competitive compression while\neliminating encoding-based penalties for non-Latin-script languages.", "published": "2025-05-30 15:12:41", "link": "http://arxiv.org/abs/2505.24689v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration", "abstract": "Large Language Models (LLMs) struggle with complex reasoning due to limited\ndiversity and inefficient search. We propose Soft Reasoning, an embedding-based\nsearch framework that optimises the embedding of the first token to guide\ngeneration. It combines (1) embedding perturbation for controlled exploration\nand (2) Bayesian optimisation to refine embeddings via a verifier-guided\nobjective, balancing exploration and exploitation. This approach improves\nreasoning accuracy and coherence while avoiding reliance on heuristic search.\nExperiments demonstrate superior correctness with minimal computation, making\nit a scalable, model-agnostic solution.", "published": "2025-05-30 15:11:52", "link": "http://arxiv.org/abs/2505.24688v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Should I Share this Translation? Evaluating Quality Feedback for User Reliance on Machine Translation", "abstract": "As people increasingly use AI systems in work and daily life, feedback\nmechanisms that help them use AI responsibly are urgently needed, particularly\nin settings where users are not equipped to assess the quality of AI\npredictions. We study a realistic Machine Translation (MT) scenario where\nmonolingual users decide whether to share an MT output, first without and then\nwith quality feedback. We compare four types of quality feedback: explicit\nfeedback that directly give users an assessment of translation quality using 1)\nerror highlights and 2) LLM explanations, and implicit feedback that helps\nusers compare MT inputs and outputs through 3) backtranslation and 4)\nquestion-answer (QA) tables. We find that all feedback types, except error\nhighlights, significantly improve both decision accuracy and appropriate\nreliance. Notably, implicit feedback, especially QA tables, yields\nsignificantly greater gains than explicit feedback in terms of decision\naccuracy, appropriate reliance, and user perceptions, receiving the highest\nratings for helpfulness and trust, and the lowest for mental burden.", "published": "2025-05-30 15:08:10", "link": "http://arxiv.org/abs/2505.24683v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Simple Linear Patch Revives Layer-Pruned Large Language Models", "abstract": "Layer pruning has become a popular technique for compressing large language\nmodels (LLMs) due to its simplicity. However, existing layer pruning methods\noften suffer from significant performance drops. We identify that this\ndegradation stems from the mismatch of activation magnitudes across layers and\ntokens at the pruning interface. To address this, we propose LinearPatch, a\nsimple plug-and-play technique to revive the layer-pruned LLMs. The proposed\nmethod adopts Hadamard transformation to suppress massive outliers in\nparticular tokens, and channel-wise scaling to align the activation magnitudes.\nThese operations can be fused into a single matrix, which functions as a patch\nto bridge the pruning interface with negligible inference overhead. LinearPatch\nretains up to 94.15% performance of the original model when pruning 5 layers of\nLLaMA-3-8B on the question answering benchmark, surpassing existing\nstate-of-the-art methods by 4%. In addition, the patch matrix can be further\noptimized with memory efficient offline knowledge distillation. With only 5K\nsamples, the retained performance of LinearPatch can be further boosted to\n95.16% within 30 minutes on a single computing card.", "published": "2025-05-30 15:06:08", "link": "http://arxiv.org/abs/2505.24680v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis", "abstract": "Large Language Models (LLMs) excel in various natural language processing\ntasks but remain vulnerable to generating harmful content or being exploited\nfor malicious purposes. Although safety alignment datasets have been introduced\nto mitigate such risks through supervised fine-tuning (SFT), these datasets\noften lack comprehensive risk coverage. Most existing datasets focus primarily\non lexical diversity while neglecting other critical dimensions. To address\nthis limitation, we propose a novel analysis framework to systematically\nmeasure the risk coverage of alignment datasets across three essential\ndimensions: Lexical Diversity, Malicious Intent, and Jailbreak Tactics. We\nfurther introduce TRIDENT, an automated pipeline that leverages persona-based,\nzero-shot LLM generation to produce diverse and comprehensive instructions\nspanning these dimensions. Each harmful instruction is paired with an ethically\naligned response, resulting in two datasets: TRIDENT-Core, comprising 26,311\nexamples, and TRIDENT-Edge, with 18,773 examples. Fine-tuning Llama 3.1-8B on\nTRIDENT-Edge demonstrates substantial improvements, achieving an average 14.29%\nreduction in Harm Score, and a 20% decrease in Attack Success Rate compared to\nthe best-performing baseline model fine-tuned on the WildBreak dataset.", "published": "2025-05-30 15:02:21", "link": "http://arxiv.org/abs/2505.24672v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multiple LLM Agents Debate for Equitable Cultural Alignment", "abstract": "Large Language Models (LLMs) need to adapt their predictions to diverse\ncultural contexts to benefit diverse communities across the world. While\nprevious efforts have focused on single-LLM, single-turn approaches, we propose\nto exploit the complementary strengths of multiple LLMs to promote cultural\nadaptability. We introduce a Multi-Agent Debate framework, where two LLM-based\nagents debate over a cultural scenario and collaboratively reach a final\ndecision. We propose two variants: one where either LLM agents exclusively\ndebate and another where they dynamically choose between self-reflection and\ndebate during their turns. We evaluate these approaches on 7 open-weight LLMs\n(and 21 LLM combinations) using the NormAd-ETI benchmark for social etiquette\nnorms in 75 countries. Experiments show that debate improves both overall\naccuracy and cultural group parity over single-LLM baselines. Notably,\nmulti-agent debate enables relatively small LLMs (7-9B) to achieve accuracies\ncomparable to that of a much larger model (27B parameters).", "published": "2025-05-30 15:01:52", "link": "http://arxiv.org/abs/2505.24671v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MSDA: Combining Pseudo-labeling and Self-Supervision for Unsupervised Domain Adaptation in ASR", "abstract": "In this work, we investigate the Meta PL unsupervised domain adaptation\nframework for Automatic Speech Recognition (ASR). We introduce a Multi-Stage\nDomain Adaptation pipeline (MSDA), a sample-efficient, two-stage adaptation\napproach that integrates self-supervised learning with semi-supervised\ntechniques. MSDA is designed to enhance the robustness and generalization of\nASR models, making them more adaptable to diverse conditions. It is\nparticularly effective for low-resource languages like Greek and in weakly\nsupervised scenarios where labeled data is scarce or noisy. Through extensive\nexperiments, we demonstrate that Meta PL can be applied effectively to ASR\ntasks, achieving state-of-the-art results, significantly outperforming\nstate-of-the-art methods, and providing more robust solutions for unsupervised\ndomain adaptation in ASR. Our ablations highlight the necessity of utilizing a\ncascading approach when combining self-supervision with self-training.", "published": "2025-05-30 14:46:05", "link": "http://arxiv.org/abs/2505.24656v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "PRISM: A Framework for Producing Interpretable Political Bias Embeddings with Political-Aware Cross-Encoder", "abstract": "Semantic Text Embedding is a fundamental NLP task that encodes textual\ncontent into vector representations, where proximity in the embedding space\nreflects semantic similarity. While existing embedding models excel at\ncapturing general meaning, they often overlook ideological nuances, limiting\ntheir effectiveness in tasks that require an understanding of political bias.\nTo address this gap, we introduce PRISM, the first framework designed to\nProduce inteRpretable polItical biaS eMbeddings. PRISM operates in two key\nstages: (1) Controversial Topic Bias Indicator Mining, which systematically\nextracts fine-grained political topics and their corresponding bias indicators\nfrom weakly labeled news data, and (2) Cross-Encoder Political Bias Embedding,\nwhich assigns structured bias scores to news articles based on their alignment\nwith these indicators. This approach ensures that embeddings are explicitly\ntied to bias-revealing dimensions, enhancing both interpretability and\npredictive power. Through extensive experiments on two large-scale datasets, we\ndemonstrate that PRISM outperforms state-of-the-art text embedding models in\npolitical bias classification while offering highly interpretable\nrepresentations that facilitate diversified retrieval and ideological analysis.\nThe source code is available at https://github.com/dukesun99/ACL-PRISM.", "published": "2025-05-30 14:31:53", "link": "http://arxiv.org/abs/2505.24646v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Optimal Algorithms Still Optimal? Rethinking Sorting in LLM-Based Pairwise Ranking with Batching and Caching", "abstract": "We introduce a novel framework for analyzing sorting algorithms in pairwise\nranking prompting (PRP), re-centering the cost model around LLM inferences\nrather than traditional pairwise comparisons. While classical metrics based on\ncomparison counts have traditionally been used to gauge efficiency, our\nanalysis reveals that expensive LLM inferences overturn these predictions;\naccordingly, our framework encourages strategies such as batching and caching\nto mitigate inference costs. We show that algorithms optimal in the classical\nsetting can lose efficiency when LLM inferences dominate the cost under certain\noptimizations.", "published": "2025-05-30 14:29:55", "link": "http://arxiv.org/abs/2505.24643v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Text Encoders for Labor Market Analysis", "abstract": "Labor market analysis relies on extracting insights from job advertisements,\nwhich provide valuable yet unstructured information on job titles and\ncorresponding skill requirements. While state-of-the-art methods for skill\nextraction achieve strong performance, they depend on large language models\n(LLMs), which are computationally expensive and slow. In this paper, we propose\n\\textbf{ConTeXT-match}, a novel contrastive learning approach with token-level\nattention that is well-suited for the extreme multi-label classification task\nof skill classification. \\textbf{ConTeXT-match} significantly improves skill\nextraction efficiency and performance, achieving state-of-the-art results with\na lightweight bi-encoder model. To support robust evaluation, we introduce\n\\textbf{Skill-XL}, a new benchmark with exhaustive, sentence-level skill\nannotations that explicitly address the redundancy in the large label space.\nFinally, we present \\textbf{JobBERT V2}, an improved job title normalization\nmodel that leverages extracted skills to produce high-quality job title\nrepresentations. Experiments demonstrate that our models are efficient,\naccurate, and scalable, making them ideal for large-scale, real-time labor\nmarket analysis.", "published": "2025-05-30 14:27:25", "link": "http://arxiv.org/abs/2505.24640v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Disentangling Language and Culture for Evaluating Multilingual Large Language Models", "abstract": "This paper introduces a Dual Evaluation Framework to comprehensively assess\nthe multilingual capabilities of LLMs. By decomposing the evaluation along the\ndimensions of linguistic medium and cultural context, this framework enables a\nnuanced analysis of LLMs' ability to process questions within both native and\ncross-cultural contexts cross-lingually. Extensive evaluations are conducted on\na wide range of models, revealing a notable \"CulturalLinguistic Synergy\"\nphenomenon, where models exhibit better performance when questions are\nculturally aligned with the language. This phenomenon is further explored\nthrough interpretability probing, which shows that a higher proportion of\nspecific neurons are activated in a language's cultural context. This\nactivation proportion could serve as a potential indicator for evaluating\nmultilingual performance during model training. Our findings challenge the\nprevailing notion that LLMs, primarily trained on English data, perform\nuniformly across languages and highlight the necessity of culturally and\nlinguistically model evaluations. Our code can be found at\nhttps://yingjiahao14. github.io/Dual-Evaluation/.", "published": "2025-05-30 14:25:45", "link": "http://arxiv.org/abs/2505.24635v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Hallucination Dilemma: Factuality-Aware Reinforcement Learning for Large Reasoning Models", "abstract": "Large language models (LLMs) have significantly advanced in reasoning tasks\nthrough reinforcement learning (RL) optimization, achieving impressive\ncapabilities across various challenging benchmarks. However, our empirical\nanalysis reveals a critical drawback: reasoning-oriented RL fine-tuning\nsignificantly increases the prevalence of hallucinations. We theoretically\nanalyze the RL training dynamics, identifying high-variance gradient,\nentropy-induced randomness, and susceptibility to spurious local optima as key\nfactors leading to hallucinations. To address this drawback, we propose\nFactuality-aware Step-wise Policy Optimization (FSPO), an innovative RL\nfine-tuning algorithm incorporating explicit factuality verification at each\nreasoning step. FSPO leverages automated verification against given evidence to\ndynamically adjust token-level advantage values, incentivizing factual\ncorrectness throughout the reasoning process. Experiments across mathematical\nreasoning and hallucination benchmarks using Qwen2.5 and Llama models\ndemonstrate that FSPO effectively reduces hallucinations while enhancing\nreasoning accuracy, substantially improving both reliability and performance.", "published": "2025-05-30 14:23:32", "link": "http://arxiv.org/abs/2505.24630v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Benchmarking Large Language Models for Cryptanalysis and Mismatched-Generalization", "abstract": "Recent advancements in Large Language Models (LLMs) have transformed natural\nlanguage understanding and generation, leading to extensive benchmarking across\ndiverse tasks. However, cryptanalysis a critical area for data security and\nencryption has not yet been thoroughly explored in LLM evaluations. To address\nthis gap, we evaluate cryptanalytic potential of state of the art LLMs on\nencrypted texts generated using a range of cryptographic algorithms. We\nintroduce a novel benchmark dataset comprising diverse plain texts spanning\nvarious domains, lengths, writing styles, and topics paired with their\nencrypted versions. Using zero-shot and few shot settings, we assess multiple\nLLMs for decryption accuracy and semantic comprehension across different\nencryption schemes. Our findings reveal key insights into the strengths and\nlimitations of LLMs in side-channel communication while raising concerns about\ntheir susceptibility to jailbreaking attacks. This research highlights the\ndual-use nature of LLMs in security contexts and contributes to the ongoing\ndiscussion on AI safety and security.", "published": "2025-05-30 14:12:07", "link": "http://arxiv.org/abs/2505.24621v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpretable phenotyping of Heart Failure patients with Dutch discharge letters", "abstract": "Objective: Heart failure (HF) patients present with diverse phenotypes\naffecting treatment and prognosis. This study evaluates models for phenotyping\nHF patients based on left ventricular ejection fraction (LVEF) classes, using\nstructured and unstructured data, assessing performance and interpretability.\n  Materials and Methods: The study analyzes all HF hospitalizations at both\nAmsterdam UMC hospitals (AMC and VUmc) from 2015 to 2023 (33,105\nhospitalizations, 16,334 patients). Data from AMC were used for model training,\nand from VUmc for external validation. The dataset was unlabelled and included\ntabular clinical measurements and discharge letters. Silver labels for LVEF\nclasses were generated by combining diagnosis codes, echocardiography results,\nand textual mentions. Gold labels were manually annotated for 300 patients for\ntesting. Multiple Transformer-based (black-box) and Aug-Linear (white-box)\nmodels were trained and compared with baselines on structured and unstructured\ndata. To evaluate interpretability, two clinicians annotated 20 discharge\nletters by highlighting information they considered relevant for LVEF\nclassification. These were compared to SHAP and LIME explanations from\nblack-box models and the inherent explanations of Aug-Linear models.\n  Results: BERT-based and Aug-Linear models, using discharge letters alone,\nachieved the highest classification results (AUC=0.84 for BERT, 0.81 for\nAug-Linear on external validation), outperforming baselines. Aug-Linear\nexplanations aligned more closely with clinicians' explanations than post-hoc\nexplanations on black-box models.\n  Conclusions: Discharge letters emerged as the most informative source for\nphenotyping HF patients. Aug-Linear models matched black-box performance while\nproviding clinician-aligned interpretability, supporting their use in\ntransparent clinical decision-making.", "published": "2025-05-30 14:11:32", "link": "http://arxiv.org/abs/2505.24619v1", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7; J.3"], "primary_category": "cs.CL"}
{"title": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX", "abstract": "We introduce POLLUX, a comprehensive open-source benchmark designed to\nevaluate the generative capabilities of large language models (LLMs) in\nRussian. Our main contribution is a novel evaluation methodology that enhances\nthe interpretability of LLM assessment. For each task type, we define a set of\ndetailed criteria and develop a scoring protocol where models evaluate\nresponses and provide justifications for their ratings. This enables\ntransparent, criteria-driven evaluation beyond traditional resource-consuming,\nside-by-side human comparisons. POLLUX includes a detailed, fine-grained\ntaxonomy of 35 task types covering diverse generative domains such as code\ngeneration, creative writing, and practical assistant use cases, totaling 2,100\nmanually crafted and professionally authored prompts. Each task is categorized\nby difficulty (easy/medium/hard), with experts constructing the dataset\nentirely from scratch. We also release a family of LLM-as-a-Judge (7B and 32B)\nevaluators trained for nuanced assessment of generative outputs. This approach\nprovides scalable, interpretable evaluation and annotation tools for model\ndevelopment, effectively replacing costly and less precise human judgments.", "published": "2025-05-30 14:08:17", "link": "http://arxiv.org/abs/2505.24616v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Harnessing Large Language Models for Scientific Novelty Detection", "abstract": "In an era of exponential scientific growth, identifying novel research ideas\nis crucial and challenging in academia. Despite potential, the lack of an\nappropriate benchmark dataset hinders the research of novelty detection. More\nimportantly, simply adopting existing NLP technologies, e.g., retrieving and\nthen cross-checking, is not a one-size-fits-all solution due to the gap between\ntextual similarity and idea conception. In this paper, we propose to harness\nlarge language models (LLMs) for scientific novelty detection (ND), associated\nwith two new datasets in marketing and NLP domains. To construct the\nconsiderate datasets for ND, we propose to extract closure sets of papers based\non their relationship, and then summarize their main ideas based on LLMs. To\ncapture idea conception, we propose to train a lightweight retriever by\ndistilling the idea-level knowledge from LLMs to align ideas with similar\nconception, enabling efficient and accurate idea retrieval for LLM novelty\ndetection. Experiments show our method consistently outperforms others on the\nproposed benchmark datasets for idea retrieval and ND tasks. Codes and data are\navailable at https://anonymous.4open.science/r/NoveltyDetection-10FB/.", "published": "2025-05-30 14:08:13", "link": "http://arxiv.org/abs/2505.24615v1", "categories": ["cs.CL", "H.4.0"], "primary_category": "cs.CL"}
{"title": "When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation", "abstract": "Endowing dialogue agents with persona information has proven to significantly\nimprove the consistency and diversity of their generations. While much focus\nhas been placed on aligning dialogues with provided personas, the adaptation to\nthe interlocutor's profile remains largely underexplored. In this work, we\ninvestigate three key aspects: (1) a model's ability to align responses with\nboth the provided persona and the interlocutor's; (2) its robustness when\ndealing with familiar versus unfamiliar interlocutors and topics, and (3) the\nimpact of additional fine-tuning on specific persona-based dialogues. We\nevaluate dialogues generated with diverse speaker pairings and topics, framing\nthe evaluation as an author identification task and employing both\nLLM-as-a-judge and human evaluations. By systematically masking or disclosing\ninformation about the interlocutor, we assess its impact on dialogue\ngeneration. Results show that access to the interlocutor's persona improves the\nrecognition of the target speaker, while masking it does the opposite. Although\nmodels generalise well across topics, they struggle with unfamiliar\ninterlocutors. Finally, we found that in zero-shot settings, LLMs often copy\nbiographical details, facilitating identification but trivialising the task.", "published": "2025-05-30 14:04:30", "link": "http://arxiv.org/abs/2505.24613v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explainable Depression Detection using Masked Hard Instance Mining", "abstract": "This paper addresses the critical need for improved explainability in\ntext-based depression detection. While offering predictive outcomes, current\nsolutions often overlook the understanding of model predictions which can\nhinder trust in the system. We propose the use of Masked Hard Instance Mining\n(MHIM) to enhance the explainability in the depression detection task. MHIM\nstrategically masks attention weights within the model, compelling it to\ndistribute attention across a wider range of salient features. We evaluate MHIM\non two datasets representing distinct languages: Thai (Thai-Maywe) and English\n(DAIC-WOZ). Our results demonstrate that MHIM significantly improves\nperformance in terms of both prediction accuracy and explainability metrics.", "published": "2025-05-30 14:01:20", "link": "http://arxiv.org/abs/2505.24609v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis", "abstract": "The interpretability of Mixture-of-Experts (MoE) models, especially those\nwith heterogeneous designs, remains underexplored. Existing attribution methods\nfor dense models fail to capture dynamic routing-expert interactions in sparse\nMoE architectures. To address this issue, we propose a cross-level attribution\nalgorithm to analyze sparse MoE architectures (Qwen 1.5-MoE, OLMoE,\nMixtral-8x7B) against dense models (Qwen 1.5-7B, Llama-7B, Mixtral-7B). Results\nshow MoE models achieve 37% higher per-layer efficiency via a \"mid-activation,\nlate-amplification\" pattern: early layers screen experts, while late layers\nrefine knowledge collaboratively. Ablation studies reveal a \"basic-refinement\"\nframework--shared experts handle general tasks (entity recognition), while\nrouted experts specialize in domain-specific processing (geographic\nattributes). Semantic-driven routing is evidenced by strong correlations\nbetween attention heads and experts (r=0.68), enabling task-aware coordination.\nNotably, architectural depth dictates robustness: deep Qwen 1.5-MoE mitigates\nexpert failures (e.g., 43% MRR drop in geographic tasks when blocking top-10\nexperts) through shared expert redundancy, whereas shallow OLMoE suffers severe\ndegradation (76% drop). Task sensitivity further guides design: core-sensitive\ntasks (geography) require concentrated expertise, while distributed-tolerant\ntasks (object attributes) leverage broader participation. These insights\nadvance MoE interpretability, offering principles to balance efficiency,\nspecialization, and robustness.", "published": "2025-05-30 13:40:51", "link": "http://arxiv.org/abs/2505.24593v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GATE: General Arabic Text Embedding for Enhanced Semantic Textual Similarity with Matryoshka Representation Learning and Hybrid Loss Training", "abstract": "Semantic textual similarity (STS) is a critical task in natural language\nprocessing (NLP), enabling applications in retrieval, clustering, and\nunderstanding semantic relationships between texts. However, research in this\narea for the Arabic language remains limited due to the lack of high-quality\ndatasets and pre-trained models. This scarcity of resources has restricted the\naccurate evaluation and advance of semantic similarity in Arabic text. This\npaper introduces General Arabic Text Embedding (GATE) models that achieve\nstate-of-the-art performance on the Semantic Textual Similarity task within the\nMTEB benchmark. GATE leverages Matryoshka Representation Learning and a hybrid\nloss training approach with Arabic triplet datasets for Natural Language\nInference, which are essential for enhancing model performance in tasks that\ndemand fine-grained semantic understanding. GATE outperforms larger models,\nincluding OpenAI, with a 20-25% performance improvement on STS benchmarks,\neffectively capturing the unique semantic nuances of Arabic.", "published": "2025-05-30 13:29:03", "link": "http://arxiv.org/abs/2505.24581v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization", "abstract": "Summarizing long-form narratives--such as books, movies, and TV\nscripts--requires capturing intricate plotlines, character interactions, and\nthematic coherence, a task that remains challenging for existing LLMs. We\nintroduce NexusSum, a multi-agent LLM framework for narrative summarization\nthat processes long-form text through a structured, sequential\npipeline--without requiring fine-tuning. Our approach introduces two key\ninnovations: (1) Dialogue-to-Description Transformation: A narrative-specific\npreprocessing method that standardizes character dialogue and descriptive text\ninto a unified format, improving coherence. (2) Hierarchical Multi-LLM\nSummarization: A structured summarization pipeline that optimizes chunk\nprocessing and controls output length for accurate, high-quality summaries. Our\nmethod establishes a new state-of-the-art in narrative summarization, achieving\nup to a 30.0% improvement in BERTScore (F1) across books, movies, and TV\nscripts. These results demonstrate the effectiveness of multi-agent LLMs in\nhandling long-form content, offering a scalable approach for structured\nsummarization in diverse storytelling domains.", "published": "2025-05-30 13:26:23", "link": "http://arxiv.org/abs/2505.24575v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Identifying Primary Stress Across Related Languages and Dialects with Transformer-based Speech Encoder Models", "abstract": "Automating primary stress identification has been an active research field\ndue to the role of stress in encoding meaning and aiding speech comprehension.\nPrevious studies relied mainly on traditional acoustic features and English\ndatasets. In this paper, we investigate the approach of fine-tuning a\npre-trained transformer model with an audio frame classification head. Our\nexperiments use a new Croatian training dataset, with test sets in Croatian,\nSerbian, the Chakavian dialect, and Slovenian. By comparing an SVM classifier\nusing traditional acoustic features with the fine-tuned speech transformer, we\ndemonstrate the transformer's superiority across the board, achieving\nnear-perfect results for Croatian and Serbian, with a 10-point performance drop\nfor the more distant Chakavian and Slovenian. Finally, we show that only a few\nhundred multi-syllabic training words suffice for strong performance. We\nrelease our datasets and model under permissive licenses.", "published": "2025-05-30 13:23:46", "link": "http://arxiv.org/abs/2505.24571v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Improving Language and Modality Transfer in Translation by Character-level Modeling", "abstract": "Current translation systems, despite being highly multilingual, cover only 5%\nof the world's languages. Expanding language coverage to the long-tail of\nlow-resource languages requires data-efficient methods that rely on\ncross-lingual and cross-modal knowledge transfer. To this end, we propose a\ncharacter-based approach to improve adaptability to new languages and\nmodalities. Our method leverages SONAR, a multilingual fixed-size embedding\nspace with different modules for encoding and decoding. We use a\nteacher-student approach with parallel translation data to obtain a\ncharacter-level encoder. Then, using ASR data, we train a lightweight adapter\nto connect a massively multilingual CTC ASR model (MMS), to the character-level\nencoder, potentially enabling speech translation from 1,000+ languages.\nExperimental results in text translation for 75 languages on FLORES+\ndemonstrate that our character-based approach can achieve better language\ntransfer than traditional subword-based models, especially outperforming them\nin low-resource settings, and demonstrating better zero-shot generalizability\nto unseen languages. Our speech adaptation, maximizing knowledge transfer from\nthe text modality, achieves state-of-the-art results in speech-to-text\ntranslation on the FLEURS benchmark on 33 languages, surpassing previous\nsupervised and cascade models, albeit being a zero-shot model with minimal\nsupervision from ASR data.", "published": "2025-05-30 13:16:08", "link": "http://arxiv.org/abs/2505.24561v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bench4KE: Benchmarking Automated Competency Question Generation", "abstract": "The availability of Large Language Models (LLMs) presents a unique\nopportunity to reinvigorate research on Knowledge Engineering (KE) automation,\na trend already evident in recent efforts developing LLM-based methods and\ntools for the automatic generation of Competency Questions (CQs). However, the\nevaluation of these tools lacks standardisation. This undermines the\nmethodological rigour and hinders the replication and comparison of results. To\naddress this gap, we introduce Bench4KE, an extensible API-based benchmarking\nsystem for KE automation. Its first release focuses on evaluating tools that\ngenerate CQs automatically. CQs are natural language questions used by ontology\nengineers to define the functional requirements of an ontology. Bench4KE\nprovides a curated gold standard consisting of CQ datasets from four real-world\nontology projects. It uses a suite of similarity metrics to assess the quality\nof the CQs generated. We present a comparative analysis of four recent CQ\ngeneration systems, which are based on LLMs, establishing a baseline for future\nresearch. Bench4KE is also designed to accommodate additional KE automation\ntasks, such as SPARQL query generation, ontology testing and drafting. Code and\ndatasets are publicly available under the Apache 2.0 license.", "published": "2025-05-30 13:03:42", "link": "http://arxiv.org/abs/2505.24554v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CREFT: Sequential Multi-Agent LLM for Character Relation Extraction", "abstract": "Understanding complex character relations is crucial for narrative analysis\nand efficient script evaluation, yet existing extraction methods often fail to\nhandle long-form narratives with nuanced interactions. To address this\nchallenge, we present CREFT, a novel sequential framework leveraging\nspecialized Large Language Model (LLM) agents. First, CREFT builds a base\ncharacter graph through knowledge distillation, then iteratively refines\ncharacter composition, relation extraction, role identification, and group\nassignments. Experiments on a curated Korean drama dataset demonstrate that\nCREFT significantly outperforms single-agent LLM baselines in both accuracy and\ncompleteness. By systematically visualizing character networks, CREFT\nstreamlines narrative comprehension and accelerates script review -- offering\nsubstantial benefits to the entertainment, publishing, and educational sectors.", "published": "2025-05-30 13:01:36", "link": "http://arxiv.org/abs/2505.24553v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A*-Thought: Efficient Reasoning via Bidirectional Compression for Low-Resource Settings", "abstract": "Large Reasoning Models (LRMs) achieve superior performance by extending the\nthought length. However, a lengthy thinking trajectory leads to reduced\nefficiency. Most of the existing methods are stuck in the assumption of\noverthinking and attempt to reason efficiently by compressing the\nChain-of-Thought, but this often leads to performance degradation. To address\nthis problem, we introduce A*-Thought, an efficient tree search-based unified\nframework designed to identify and isolate the most essential thoughts from the\nextensive reasoning chains produced by these models. It formulates the\nreasoning process of LRMs as a search tree, where each node represents a\nreasoning span in the giant reasoning space. By combining the A* search\nalgorithm with a cost function specific to the reasoning path, it can\nefficiently compress the chain of thought and determine a reasoning path with\nhigh information density and low cost. In addition, we also propose a\nbidirectional importance estimation mechanism, which further refines this\nsearch process and enhances its efficiency beyond uniform sampling. Extensive\nexperiments on several advanced math tasks show that A*-Thought effectively\nbalances performance and efficiency over a huge search space. Specifically,\nA*-Thought can improve the performance of QwQ-32B by 2.39$\\times$ with\nlow-budget and reduce the length of the output token by nearly 50% with\nhigh-budget. The proposed method is also compatible with several other LRMs,\ndemonstrating its generalization capability. The code can be accessed at:\nhttps://github.com/AI9Stars/AStar-Thought.", "published": "2025-05-30 12:58:34", "link": "http://arxiv.org/abs/2505.24550v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-Attention Speculative Decoding", "abstract": "Speculative decoding (SD) is a widely adopted approach for accelerating\ninference in large language models (LLMs), particularly when the draft and\ntarget models are well aligned. However, state-of-the-art SD methods typically\nrely on tightly coupled, self-attention-based Transformer decoders, often\naugmented with auxiliary pooling or fusion layers. This coupling makes them\nincreasingly complex and harder to generalize across different models. We\npresent Budget EAGLE (Beagle), the first, to our knowledge,\ncross-attention-based Transformer decoder SD model that achieves performance on\npar with leading self-attention SD models (EAGLE-v2) while eliminating the need\nfor pooling or auxiliary components, simplifying the architecture, improving\ntraining efficiency, and maintaining stable memory usage during training-time\nsimulation. To enable effective training of this novel architecture, we propose\nTwo-Stage Block-Attention Training, a new method that achieves training\nstability and convergence efficiency in block-level attention scenarios.\nExtensive experiments across multiple LLMs and datasets show that Beagle\nachieves competitive inference speedups and higher training efficiency than\nEAGLE-v2, offering a strong alternative for architectures in speculative\ndecoding.", "published": "2025-05-30 12:52:35", "link": "http://arxiv.org/abs/2505.24544v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Localizing Persona Representations in LLMs", "abstract": "We present a study on how and where personas -- defined by distinct sets of\nhuman characteristics, values, and beliefs -- are encoded in the representation\nspace of large language models (LLMs). Using a range of dimension reduction and\npattern recognition methods, we first identify the model layers that show the\ngreatest divergence in encoding these representations. We then analyze the\nactivations within a selected layer to examine how specific personas are\nencoded relative to others, including their shared and distinct embedding\nspaces. We find that, across multiple pre-trained decoder-only LLMs, the\nanalyzed personas show large differences in representation space only within\nthe final third of the decoder layers. We observe overlapping activations for\nspecific ethical perspectives -- such as moral nihilism and utilitarianism --\nsuggesting a degree of polysemy. In contrast, political ideologies like\nconservatism and liberalism appear to be represented in more distinct regions.\nThese findings help to improve our understanding of how LLMs internally\nrepresent information and can inform future efforts in refining the modulation\nof specific human traits in LLM outputs. Warning: This paper includes\npotentially offensive sample statements.", "published": "2025-05-30 12:46:44", "link": "http://arxiv.org/abs/2505.24539v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Don't Erase, Inform! Detecting and Contextualizing Harmful Language in Cultural Heritage Collections", "abstract": "Cultural Heritage (CH) data hold invaluable knowledge, reflecting the\nhistory, traditions, and identities of societies, and shaping our understanding\nof the past and present. However, many CH collections contain outdated or\noffensive descriptions that reflect historical biases. CH Institutions (CHIs)\nface significant challenges in curating these data due to the vast scale and\ncomplexity of the task. To address this, we develop an AI-powered tool that\ndetects offensive terms in CH metadata and provides contextual insights into\ntheir historical background and contemporary perception. We leverage a\nmultilingual vocabulary co-created with marginalized communities, researchers,\nand CH professionals, along with traditional NLP techniques and Large Language\nModels (LLMs). Available as a standalone web app and integrated with major CH\nplatforms, the tool has processed over 7.9 million records, contextualizing the\ncontentious terms detected in their metadata. Rather than erasing these terms,\nour approach seeks to inform, making biases visible and providing actionable\ninsights for creating more inclusive and accessible CH collections.", "published": "2025-05-30 12:44:54", "link": "http://arxiv.org/abs/2505.24538v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Linear Steering: Unified Multi-Attribute Control for Language Models", "abstract": "Controlling multiple behavioral attributes in large language models (LLMs) at\ninference time is a challenging problem due to interference between attributes\nand the limitations of linear steering methods, which assume additive behavior\nin activation space and require per-attribute tuning. We introduce K-Steering,\na unified and flexible approach that trains a single non-linear multi-label\nclassifier on hidden activations and computes intervention directions via\ngradients at inference time. This avoids linearity assumptions, removes the\nneed for storing and tuning separate attribute vectors, and allows dynamic\ncomposition of behaviors without retraining. To evaluate our method, we propose\ntwo new benchmarks, ToneBank and DebateMix, targeting compositional behavioral\ncontrol. Empirical results across 3 model families, validated by both\nactivation-based classifiers and LLM-based judges, demonstrate that K-Steering\noutperforms strong baselines in accurately steering multiple behaviors.", "published": "2025-05-30 12:41:19", "link": "http://arxiv.org/abs/2505.24535v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "DEEPQUESTION: Systematic Generation of Real-World Challenges for Evaluating LLMs Performance", "abstract": "LLMs often excel on standard benchmarks but falter on real-world tasks. We\nintroduce DeepQuestion, a scalable automated framework that augments existing\ndatasets based on Bloom's taxonomy and creates novel questions that trace\noriginal solution paths to probe evaluative and creative skills. Extensive\nexperiments across ten open-source and proprietary models, covering both\ngeneral-purpose and reasoning LLMs, reveal substantial performance drops (even\nup to 70% accuracy loss) on higher-order tasks, underscoring persistent gaps in\ndeep reasoning. Our work highlights the need for cognitively diverse benchmarks\nto advance LLM progress. DeepQuestion and related datasets will be released\nupon acceptance of the paper.", "published": "2025-05-30 12:39:42", "link": "http://arxiv.org/abs/2505.24532v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Limited-Resource Adapters Are Regularizers, Not Linguists", "abstract": "Cross-lingual transfer from related high-resource languages is a\nwell-established strategy to enhance low-resource language technologies. Prior\nwork has shown that adapters show promise for, e.g., improving low-resource\nmachine translation (MT). In this work, we investigate an adapter souping\nmethod combined with cross-attention fine-tuning of a pre-trained MT model to\nleverage language transfer for three low-resource Creole languages, which\nexhibit relatedness to different language groups across distinct linguistic\ndimensions. Our approach improves performance substantially over baselines.\nHowever, we find that linguistic relatedness -- or even a lack thereof -- does\nnot covary meaningfully with adapter performance. Surprisingly, our\ncross-attention fine-tuning approach appears equally effective with randomly\ninitialized adapters, implying that the benefit of adapters in this setting\nlies in parameter regularization, and not in meaningful information transfer.\nWe provide analysis supporting this regularization hypothesis. Our findings\nunderscore the reality that neural language processing involves many success\nfactors, and that not all neural methods leverage linguistic knowledge in\nintuitive ways.", "published": "2025-05-30 12:34:28", "link": "http://arxiv.org/abs/2505.24525v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors", "abstract": "Recent advancements in Generative AI and Large Language Models (LLMs) have\nenabled the creation of highly realistic synthetic content, raising concerns\nabout the potential for malicious use, such as misinformation and manipulation.\nMoreover, detecting Machine-Generated Text (MGT) remains challenging due to the\nlack of robust benchmarks that assess generalization to real-world scenarios.\nIn this work, we present a pipeline to test the resilience of state-of-the-art\nMGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed\nadversarial attacks. To challenge the detectors, we fine-tune language models\nusing Direct Preference Optimization (DPO) to shift the MGT style toward\nhuman-written text (HWT). This exploits the detectors' reliance on stylistic\nclues, making new generations more challenging to detect. Additionally, we\nanalyze the linguistic shifts induced by the alignment and which features are\nused by detectors to detect MGT texts. Our results show that detectors can be\neasily fooled with relatively few examples, resulting in a significant drop in\ndetection performance. This highlights the importance of improving detection\nmethods and making them robust to unseen in-domain texts.", "published": "2025-05-30 12:33:30", "link": "http://arxiv.org/abs/2505.24523v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AMIA: Automatic Masking and Joint Intention Analysis Makes LVLMs Robust Jailbreak Defenders", "abstract": "We introduce AMIA, a lightweight, inference-only defense for Large\nVision-Language Models (LVLMs) that (1) Automatically Masks a small set of\ntext-irrelevant image patches to disrupt adversarial perturbations, and (2)\nconducts joint Intention Analysis to uncover and mitigate hidden harmful\nintents before response generation. Without any retraining, AMIA improves\ndefense success rates across diverse LVLMs and jailbreak benchmarks from an\naverage of 52.4% to 81.7%, preserves general utility with only a 2% average\naccuracy drop, and incurs only modest inference overhead. Ablation confirms\nboth masking and intention analysis are essential for a robust safety-utility\ntrade-off.", "published": "2025-05-30 12:30:50", "link": "http://arxiv.org/abs/2505.24519v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "TimeHC-RL: Temporal-aware Hierarchical Cognitive Reinforcement Learning for Enhancing LLMs' Social Intelligence", "abstract": "Recently, Large Language Models (LLMs) have made significant progress in\nIQ-related domains that require careful thinking, such as mathematics and\ncoding. However, enhancing LLMs' cognitive development in social domains,\nparticularly from a post-training perspective, remains underexplored.\nRecognizing that the social world follows a distinct timeline and requires a\nricher blend of cognitive modes (from intuitive reactions (System 1) and\nsurface-level thinking to deliberate thinking (System 2)) than mathematics,\nwhich primarily relies on System 2 cognition (careful, step-by-step reasoning),\nwe introduce Temporal-aware Hierarchical Cognitive Reinforcement Learning\n(TimeHC-RL) for enhancing LLMs' social intelligence. In our experiments, we\nsystematically explore improving LLMs' social intelligence and validate the\neffectiveness of the TimeHC-RL method, through five other post-training\nparadigms and two test-time intervention paradigms on eight datasets with\ndiverse data patterns. Experimental results reveal the superiority of our\nproposed TimeHC-RL method compared to the widely adopted System 2 RL method. It\ngives the 7B backbone model wings, enabling it to rival the performance of\nadvanced models like DeepSeek-R1 and OpenAI-O3. Additionally, the systematic\nexploration from post-training and test-time interventions perspectives to\nimprove LLMs' social intelligence has uncovered several valuable insights.", "published": "2025-05-30 12:01:06", "link": "http://arxiv.org/abs/2505.24500v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Effective Code-Integrated Reasoning", "abstract": "In this paper, we investigate code-integrated reasoning, where models\ngenerate code when necessary and integrate feedback by executing it through a\ncode interpreter. To acquire this capability, models must learn when and how to\nuse external code tools effectively, which is supported by tool-augmented\nreinforcement learning (RL) through interactive learning. Despite its benefits,\ntool-augmented RL can still suffer from potential instability in the learning\ndynamics. In light of this challenge, we present a systematic approach to\nimproving the training effectiveness and stability of tool-augmented RL for\ncode-integrated reasoning. Specifically, we develop enhanced training\nstrategies that balance exploration and stability, progressively building\ntool-use capabilities while improving reasoning performance. Through extensive\nexperiments on five mainstream mathematical reasoning benchmarks, our model\ndemonstrates significant performance improvements over multiple competitive\nbaselines. Furthermore, we conduct an in-depth analysis of the mechanism and\neffect of code-integrated reasoning, revealing several key insights, such as\nthe extension of model's capability boundaries and the simultaneous improvement\nof reasoning efficiency through code integration. All data and code for\nreproducing this work are available at: https://github.com/RUCAIBox/CIR.", "published": "2025-05-30 11:30:18", "link": "http://arxiv.org/abs/2505.24480v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Leveraging Knowledge Graphs and LLMs for Structured Generation of Misinformation", "abstract": "The rapid spread of misinformation, further amplified by recent advances in\ngenerative AI, poses significant threats to society, impacting public opinion,\ndemocratic stability, and national security. Understanding and proactively\nassessing these threats requires exploring methodologies that enable structured\nand scalable misinformation generation. In this paper, we propose a novel\napproach that leverages knowledge graphs (KGs) as structured semantic resources\nto systematically generate fake triplets. By analyzing the structural\nproperties of KGs, such as the distance between entities and their predicates,\nwe identify plausibly false relationships. These triplets are then used to\nguide large language models (LLMs) in generating misinformation statements with\nvarying degrees of credibility. By utilizing structured semantic relationships,\nour deterministic approach produces misinformation inherently challenging for\nhumans to detect, drawing exclusively upon publicly available KGs (e.g.,\nWikiGraphs).\n  Additionally, we investigate the effectiveness of LLMs in distinguishing\nbetween genuine and artificially generated misinformation. Our analysis\nhighlights significant limitations in current LLM-based detection methods,\nunderscoring the necessity for enhanced detection strategies and a deeper\nexploration of inherent biases in generative models.", "published": "2025-05-30 11:29:10", "link": "http://arxiv.org/abs/2505.24479v1", "categories": ["cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.AI"}
{"title": "Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning", "abstract": "Integrating Large Language Models (LLMs) with Knowledge Graphs (KGs) results\nin complex systems with numerous hyperparameters that directly affect\nperformance. While such systems are increasingly common in retrieval-augmented\ngeneration, the role of systematic hyperparameter optimization remains\nunderexplored. In this paper, we study this problem in the context of Cognee, a\nmodular framework for end-to-end KG construction and retrieval. Using three\nmulti-hop QA benchmarks (HotPotQA, TwoWikiMultiHop, and MuSiQue) we optimize\nparameters related to chunking, graph construction, retrieval, and prompting.\nEach configuration is scored using established metrics (exact match, F1, and\nDeepEval's LLM-based correctness metric). Our results demonstrate that\nmeaningful gains can be achieved through targeted tuning. While the gains are\nconsistent, they are not uniform, with performance varying across datasets and\nmetrics. This variability highlights both the value of tuning and the\nlimitations of standard evaluation measures. While demonstrating the immediate\npotential of hyperparameter tuning, we argue that future progress will depend\nnot only on architectural advances but also on clearer frameworks for\noptimization and evaluation in complex, modular systems.", "published": "2025-05-30 11:27:59", "link": "http://arxiv.org/abs/2505.24478v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "VietMix: A Naturally Occurring Vietnamese-English Code-Mixed Corpus with Iterative Augmentation for Machine Translation", "abstract": "Machine translation systems fail when processing code-mixed inputs for\nlow-resource languages. We address this challenge by curating VietMix, a\nparallel corpus of naturally occurring code-mixed Vietnamese text paired with\nexpert English translations. Augmenting this resource, we developed a\ncomplementary synthetic data generation pipeline. This pipeline incorporates\nfiltering mechanisms to ensure syntactic plausibility and pragmatic\nappropriateness in code-mixing patterns. Experimental validation shows our\nnaturalistic and complementary synthetic data boost models' performance,\nmeasured by translation quality estimation scores, of up to 71.84 on COMETkiwi\nand 81.77 on XCOMET. Triangulating positive results with LLM-based assessments,\naugmented models are favored over seed fine-tuned counterparts in approximately\n49% of judgments (54-56% excluding ties). VietMix and our augmentation\nmethodology advance ecological validity in neural MT evaluations and establish\na framework for addressing code-mixed translation challenges across other\nlow-resource pairs.", "published": "2025-05-30 11:18:10", "link": "http://arxiv.org/abs/2505.24472v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CaMMT: Benchmarking Culturally Aware Multimodal Machine Translation", "abstract": "Cultural content poses challenges for machine translation systems due to the\ndifferences in conceptualizations between cultures, where language alone may\nfail to convey sufficient context to capture region-specific meanings. In this\nwork, we investigate whether images can act as cultural context in multimodal\ntranslation. We introduce CaMMT, a human-curated benchmark of over 5,800\ntriples of images along with parallel captions in English and regional\nlanguages. Using this dataset, we evaluate five Vision Language Models (VLMs)\nin text-only and text+image settings. Through automatic and human evaluations,\nwe find that visual context generally improves translation quality, especially\nin handling Culturally-Specific Items (CSIs), disambiguation, and correct\ngender usage. By releasing CaMMT, we aim to support broader efforts in building\nand evaluating multimodal translation systems that are better aligned with\ncultural nuance and regional variation.", "published": "2025-05-30 10:42:44", "link": "http://arxiv.org/abs/2505.24456v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Pre-training Impact on Representations", "abstract": "This empirical study analyzes the effects of the pre-training corpus on the\nquality of learned transformer representations. We focus on the representation\nquality induced solely through pre-training. Our experiments show that\npre-training on a small, specialized corpus can yield effective\nrepresentations, and that the success of combining a generic and a specialized\ncorpus depends on the distributional similarity between the target task and the\nspecialized corpus.", "published": "2025-05-30 10:42:43", "link": "http://arxiv.org/abs/2505.24455v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Large Multimodal Models Confront Evolving Knowledge:Challenges and Pathways", "abstract": "Large language/multimodal models (LLMs/LMMs) store extensive pre-trained\nknowledge but struggle to maintain consistency with real-world updates, making\nit difficult to avoid catastrophic forgetting while acquiring evolving\nknowledge. Previous work focused on constructing textual knowledge datasets and\nexploring knowledge injection in LLMs, lacking exploration of multimodal\nevolving knowledge injection in LMMs. To address this, we propose the EVOKE\nbenchmark to evaluate LMMs' ability to inject multimodal evolving knowledge in\nreal-world scenarios. Meanwhile, a comprehensive evaluation of multimodal\nevolving knowledge injection revealed two challenges: (1) Existing knowledge\ninjection methods perform terribly on evolving knowledge. (2) Supervised\nfine-tuning causes catastrophic forgetting, particularly instruction following\nability is severely compromised. Additionally, we provide pathways and find\nthat: (1) Text knowledge augmentation during the training phase improves\nperformance, while image augmentation cannot achieve it. (2) Continual learning\nmethods, especially Replay and MoELoRA, effectively mitigate forgetting. Our\nfindings indicate that current knowledge injection methods have many\nlimitations on evolving knowledge, which motivates further research on more\nefficient and stable knowledge injection methods.", "published": "2025-05-30 10:36:19", "link": "http://arxiv.org/abs/2505.24449v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring the Impact of Occupational Personas on Domain-Specific QA", "abstract": "Recent studies on personas have improved the way Large Language Models (LLMs)\ninteract with users. However, the effect of personas on domain-specific\nquestion-answering (QA) tasks remains a subject of debate. This study analyzes\nwhether personas enhance specialized QA performance by introducing two types of\npersona: Profession-Based Personas (PBPs) (e.g., scientist), which directly\nrelate to domain expertise, and Occupational Personality-Based Personas (OPBPs)\n(e.g., scientific person), which reflect cognitive tendencies rather than\nexplicit expertise. Through empirical evaluations across multiple scientific\ndomains, we demonstrate that while PBPs can slightly improve accuracy, OPBPs\noften degrade performance, even when semantically related to the task. Our\nfindings suggest that persona relevance alone does not guarantee effective\nknowledge utilization and that they may impose cognitive constraints that\nhinder optimal knowledge application. Future research can explore how nuanced\ndistinctions in persona representations guide LLMs, potentially contributing to\nreasoning and knowledge retrieval that more closely mirror human social\nconceptualization.", "published": "2025-05-30 10:35:39", "link": "http://arxiv.org/abs/2505.24448v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Model Unlearning via Sparse Autoencoder Subspace Guided Projections", "abstract": "Large language models (LLMs) store vast amounts of information, making them\npowerful yet raising privacy and safety concerns when selective knowledge\nremoval is required. Existing unlearning strategies, ranging from\ngradient-based fine-tuning and model editing to sparse autoencoder (SAE)\nsteering, either lack interpretability or fail to provide a robust defense\nagainst adversarial prompts. We propose SAE-Guided Subspace Projection\nUnlearning (SSPU), a novel framework that leverages SAE features to drive\ntargeted updates in the model's parameter space, enabling precise,\ninterpretable, and robust unlearning. SSPU's three-stage pipeline performs\ndata-driven layer and feature selection, subspace construction via QR\ndecomposition, and constrained optimization that controls activations into an\n\"irrelevant\" subspace while preserving retained knowledge. Overall, we use SAE\nfeatures to construct a subspace that supervises unlearning, refining the loss\nand adding a regularization term to guide interpretable parameter updates. In\nexperiments on the WMDP-Cyber forget set and three utility benchmarks (MMLU,\nTruthfulQA, GSM8K), SSPU reduces harmful knowledge accuracy by 3.22% compared\nto the strongest baseline. It also improves adversarial robustness, lowering\nmalicious accuracy under jailbreak prompts compared to baselines. Our findings\nexpose the limitations of prior unlearning methods and demonstrate how\ninterpretable subspace-guided optimization can achieve robust, controllable\nmodel behavior.", "published": "2025-05-30 10:07:52", "link": "http://arxiv.org/abs/2505.24428v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Donate or Create? Comparing Data Collection Strategies for Emotion-labeled Multimodal Social Media Posts", "abstract": "Accurate modeling of subjective phenomena such as emotion expression requires\ndata annotated with authors' intentions. Commonly such data is collected by\nasking study participants to donate and label genuine content produced in the\nreal world, or create content fitting particular labels during the study.\nAsking participants to create content is often simpler to implement and\npresents fewer risks to participant privacy than data donation. However, it is\nunclear if and how study-created content may differ from genuine content, and\nhow differences may impact models. We collect study-created and genuine\nmultimodal social media posts labeled for emotion and compare them on several\ndimensions, including model performance. We find that compared to genuine\nposts, study-created posts are longer, rely more on their text and less on\ntheir images for emotion expression, and focus more on emotion-prototypical\nevents. The samples of participants willing to donate versus create posts are\ndemographically different. Study-created data is valuable to train models that\ngeneralize well to genuine data, but realistic effectiveness estimates require\ngenuine data.", "published": "2025-05-30 10:07:34", "link": "http://arxiv.org/abs/2505.24427v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MMAFFBen: A Multilingual and Multimodal Affective Analysis Benchmark for Evaluating LLMs and VLMs", "abstract": "Large language models and vision-language models (which we jointly call LMs)\nhave transformed NLP and CV, demonstrating remarkable potential across various\nfields. However, their capabilities in affective analysis (i.e. sentiment\nanalysis and emotion detection) remain underexplored. This gap is largely due\nto the absence of comprehensive evaluation benchmarks, and the inherent\ncomplexity of affective analysis tasks. In this paper, we introduce MMAFFBen,\nthe first extensive open-source benchmark for multilingual multimodal affective\nanalysis. MMAFFBen encompasses text, image, and video modalities across 35\nlanguages, covering four key affective analysis tasks: sentiment polarity,\nsentiment intensity, emotion classification, and emotion intensity. Moreover,\nwe construct the MMAFFIn dataset for fine-tuning LMs on affective analysis\ntasks, and further develop MMAFFLM-3b and MMAFFLM-7b based on it. We evaluate\nvarious representative LMs, including GPT-4o-mini, providing a systematic\ncomparison of their affective understanding capabilities. This project is\navailable at https://github.com/lzw108/MMAFFBen.", "published": "2025-05-30 10:02:15", "link": "http://arxiv.org/abs/2505.24423v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLMs Are Globally Multilingual Yet Locally Monolingual: Exploring Knowledge Transfer via Language and Thought Theory", "abstract": "Multilingual large language models (LLMs) open up new possibilities for\nleveraging information across languages, but their factual knowledge recall\nremains inconsistent depending on the input language. While previous studies\nhave attempted to address this issue through English-based prompting and\nevaluation, we explore non-English to English transfer via Language and Thought\nTheory. This perspective allows us to examine language-thought binding in LLMs\nand uncover why factual knowledge often fails to transfer effectively. We\npropose the Language-to-Thought (L2T) prompting strategy, which analyzes the\nrelationship between input language, internal cognitive processes, and\nknowledge. Experimental results challenge the assumption that English-based\napproaches consistently outperform other languages and offer a novel insight\nthat aligning the model's internal thought with the knowledge required for the\ntask is critical for successful cross-lingual transfer. Furthermore, we show\nthat applying L2T during training can alleviate LLMs' reliance on the input\nlanguage and facilitate cross-linguistic knowledge integration without\ntranslation-based learning. Code and datasets will be available.", "published": "2025-05-30 09:47:25", "link": "http://arxiv.org/abs/2505.24409v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs)\nwith external knowledge to improve factuality. However, existing RAG systems\nfrequently underutilize the retrieved documents, failing to extract and\nintegrate the key clues needed to support faithful and interpretable reasoning,\nespecially in cases where relevant evidence is implicit, scattered, or obscured\nby noise. To address this issue, we propose ClueAnchor, a novel framework for\nenhancing RAG via clue-anchored reasoning exploration and optimization.\nClueAnchor extracts key clues from retrieved content and generates multiple\nreasoning paths based on different knowledge configurations, optimizing the\nmodel by selecting the most effective one through reward-based preference\noptimization. Experiments show that ClueAnchor significantly outperforms prior\nRAG baselines in reasoning completeness and robustness. Further analysis\nconfirms its strong resilience to noisy or partially relevant retrieved\ncontent, as well as its capability to identify supporting evidence even in the\nabsence of explicit clue supervision during inference.", "published": "2025-05-30 09:18:08", "link": "http://arxiv.org/abs/2505.24388v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Breaking the Gold Standard: Extracting Forgotten Data under Exact Unlearning in Large Language Models", "abstract": "Large language models are typically trained on datasets collected from the\nweb, which may inadvertently contain harmful or sensitive personal information.\nTo address growing privacy concerns, unlearning methods have been proposed to\nremove the influence of specific data from trained models. Of these, exact\nunlearning -- which retrains the model from scratch without the target data --\nis widely regarded the gold standard, believed to be robust against\nprivacy-related attacks. In this paper, we challenge this assumption by\nintroducing a novel data extraction attack that compromises even exact\nunlearning. Our method leverages both the pre- and post-unlearning models: by\nguiding the post-unlearning model using signals from the pre-unlearning model,\nwe uncover patterns that reflect the removed data distribution. Combining model\nguidance with a token filtering strategy, our attack significantly improves\nextraction success rates -- doubling performance in some cases -- across common\nbenchmarks such as MUSE, TOFU, and WMDP. Furthermore, we demonstrate our\nattack's effectiveness on a simulated medical diagnosis dataset to highlight\nreal-world privacy risks associated with exact unlearning. In light of our\nfindings, which suggest that unlearning may, in a contradictory way, increase\nthe risk of privacy leakage, we advocate for evaluation of unlearning methods\nto consider broader threat models that account not only for post-unlearning\nmodels but also for adversarial access to prior checkpoints.", "published": "2025-05-30 09:09:33", "link": "http://arxiv.org/abs/2505.24379v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "LLM Inference Enhanced by External Knowledge: A Survey", "abstract": "Recent advancements in large language models (LLMs) have enhanced\nnatural-language reasoning. However, their limited parametric memory and\nsusceptibility to hallucination present persistent challenges for tasks\nrequiring accurate, context-based inference. To overcome these limitations, an\nincreasing number of studies have proposed leveraging external knowledge to\nenhance LLMs. This study offers a systematic exploration of strategies for\nusing external knowledge to enhance LLMs, beginning with a taxonomy that\ncategorizes external knowledge into unstructured and structured data. We then\nfocus on structured knowledge, presenting distinct taxonomies for tables and\nknowledge graphs (KGs), detailing their integration paradigms with LLMs, and\nreviewing representative methods. Our comparative analysis further highlights\nthe trade-offs among interpretability, scalability, and performance, providing\ninsights for developing trustworthy and generalizable knowledge-enhanced LLMs.", "published": "2025-05-30 09:08:51", "link": "http://arxiv.org/abs/2505.24377v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowing Before Saying: LLM Representations Encode Information About Chain-of-Thought Success Before Completion", "abstract": "We investigate whether the success of a zero-shot Chain-of-Thought (CoT)\nprocess can be predicted before completion. We discover that a probing\nclassifier, based on LLM representations, performs well \\emph{even before a\nsingle token is generated}, suggesting that crucial information about the\nreasoning process is already present in the initial steps representations. In\ncontrast, a strong BERT-based baseline, which relies solely on the generated\ntokens, performs worse, likely because it depends on shallow linguistic cues\nrather than deeper reasoning dynamics. Surprisingly, using later reasoning\nsteps does not always improve classification. When additional context is\nunhelpful, earlier representations resemble later ones more, suggesting LLMs\nencode key information early. This implies reasoning can often stop early\nwithout loss. To test this, we conduct early stopping experiments, showing that\ntruncating CoT reasoning still improves performance over not using CoT at all,\nthough a gap remains compared to full reasoning. However, approaches like\nsupervised learning or reinforcement learning designed to shorten CoT chains\ncould leverage our classifier's guidance to identify when early stopping is\neffective. Our findings provide insights that may support such methods, helping\nto optimize CoT's efficiency while preserving its benefits.\\footnote{Code and\ndata is available at\n\\href{https://github.com/anum94/CoTpred}{\\texttt{github.com/anum94/CoTpred}}.", "published": "2025-05-30 08:54:28", "link": "http://arxiv.org/abs/2505.24362v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Gloss-free Sign Language Translation: Towards Building a Sign Language Foundation Model", "abstract": "Sign Language Translation (SLT) aims to convert sign language (SL) videos\ninto spoken language text, thereby bridging the communication gap between the\nsign and the spoken community. While most existing works focus on translating a\nsingle sign language into a single spoken language (one-to-one SLT), leveraging\nmultilingual resources could mitigate low-resource issues and enhance\naccessibility. However, multilingual SLT (MLSLT) remains unexplored due to\nlanguage conflicts and alignment difficulties across SLs and spoken languages.\nTo address these challenges, we propose a multilingual gloss-free model with\ndual CTC objectives for token-level SL identification and spoken text\ngeneration. Our model supports 10 SLs and handles one-to-one, many-to-one, and\nmany-to-many SLT tasks, achieving competitive performance compared to\nstate-of-the-art methods on three widely adopted benchmarks: multilingual\nSP-10, PHOENIX14T, and CSL-Daily.", "published": "2025-05-30 08:47:44", "link": "http://arxiv.org/abs/2505.24355v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research", "abstract": "Language agents powered by large language models (LLMs) have demonstrated\nremarkable capabilities in understanding, reasoning, and executing complex\ntasks. However, developing robust agents presents significant challenges:\nsubstantial engineering overhead, lack of standardized components, and\ninsufficient evaluation frameworks for fair comparison. We introduce Agent\nGraph-based Orchestration for Reasoning and Assessment (AGORA), a flexible and\nextensible framework that addresses these challenges through three key\ncontributions: (1) a modular architecture with a graph-based workflow engine,\nefficient memory management, and clean component abstraction; (2) a\ncomprehensive suite of reusable agent algorithms implementing state-of-the-art\nreasoning approaches; and (3) a rigorous evaluation framework enabling\nsystematic comparison across multiple dimensions. Through extensive experiments\non mathematical reasoning and multimodal tasks, we evaluate various agent\nalgorithms across different LLMs, revealing important insights about their\nrelative strengths and applicability. Our results demonstrate that while\nsophisticated reasoning approaches can enhance agent capabilities, simpler\nmethods like Chain-of-Thought often exhibit robust performance with\nsignificantly lower computational overhead. AGORA not only simplifies language\nagent development but also establishes a foundation for reproducible agent\nresearch through standardized evaluation protocols.", "published": "2025-05-30 08:46:23", "link": "http://arxiv.org/abs/2505.24354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fewer Hallucinations, More Verification: A Three-Stage LLM-Based Framework for ASR Error Correction", "abstract": "Automatic Speech Recognition (ASR) error correction aims to correct\nrecognition errors while preserving accurate text. Although traditional\napproaches demonstrate moderate effectiveness, LLMs offer a paradigm that\neliminates the need for training and labeled data. However, directly using LLMs\nwill encounter hallucinations problem, which may lead to the modification of\nthe correct text. To address this problem, we propose the Reliable LLM\nCorrection Framework (RLLM-CF), which consists of three stages: (1) error\npre-detection, (2) chain-of-thought sub-tasks iterative correction, and (3)\nreasoning process verification. The advantage of our method is that it does not\nrequire additional information or fine-tuning of the model, and ensures the\ncorrectness of the LLM correction under multi-pass programming. Experiments on\nAISHELL-1, AISHELL-2, and Librispeech show that the GPT-4o model enhanced by\nour framework achieves 21%, 11%, 9%, and 11.4% relative reductions in CER/WER.", "published": "2025-05-30 08:40:49", "link": "http://arxiv.org/abs/2505.24347v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "KEVER^2: Knowledge-Enhanced Visual Emotion Reasoning and Retrieval", "abstract": "Understanding what emotions images evoke in their viewers is a foundational\ngoal in human-centric visual computing. While recent advances in\nvision-language models (VLMs) have shown promise for visual emotion analysis\n(VEA), several key challenges remain unresolved. Emotional cues in images are\noften abstract, overlapping, and entangled, making them difficult to model and\ninterpret. Moreover, VLMs struggle to align these complex visual patterns with\nemotional semantics due to limited supervision and sparse emotional grounding.\nFinally, existing approaches lack structured affective knowledge to resolve\nambiguity and ensure consistent emotional reasoning across diverse visual\ndomains.\n  To address these limitations, we propose \\textbf{K-EVER\\textsuperscript{2}},\na knowledge-enhanced framework for emotion reasoning and retrieval. Our\napproach introduces a semantically structured formulation of visual emotion\ncues and integrates external affective knowledge through multimodal alignment.\nWithout relying on handcrafted labels or direct emotion supervision,\nK-EVER\\textsuperscript{2} achieves robust and interpretable emotion predictions\nacross heterogeneous image types.\n  We validate our framework on three representative benchmarks, Emotion6,\nEmoSet, and M-Disaster, covering social media imagery, human-centric scenes,\nand disaster contexts. K-EVER\\textsuperscript{2} consistently outperforms\nstrong CNN and VLM baselines, achieving up to a \\textbf{19\\% accuracy gain} for\nspecific emotions and a \\textbf{12.3\\% average accuracy gain} across all\nemotion categories. Our results demonstrate a scalable and generalizable\nsolution for advancing emotional understanding of visual content.", "published": "2025-05-30 08:33:32", "link": "http://arxiv.org/abs/2505.24342v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings", "abstract": "Detecting toxic content using language models is important but challenging.\nWhile large language models (LLMs) have demonstrated strong performance in\nunderstanding Chinese, recent studies show that simple character substitutions\nin toxic Chinese text can easily confuse the state-of-the-art (SOTA) LLMs. In\nthis paper, we highlight the multimodal nature of Chinese language as a key\nchallenge for deploying LLMs in toxic Chinese detection. First, we propose a\ntaxonomy of 3 perturbation strategies and 8 specific approaches in toxic\nChinese content. Then, we curate a dataset based on this taxonomy, and\nbenchmark 9 SOTA LLMs (from both the US and China) to assess if they can detect\nperturbed toxic Chinese text. Additionally, we explore cost-effective\nenhancement solutions like in-context learning (ICL) and supervised fine-tuning\n(SFT). Our results reveal two important findings. (1) LLMs are less capable of\ndetecting perturbed multimodal Chinese toxic contents. (2) ICL or SFT with a\nsmall number of perturbed examples may cause the LLMs \"overcorrect'':\nmisidentify many normal Chinese contents as toxic.", "published": "2025-05-30 08:32:45", "link": "http://arxiv.org/abs/2505.24341v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "GeoVision Labeler: Zero-Shot Geospatial Classification with Vision and Language Models", "abstract": "Classifying geospatial imagery remains a major bottleneck for applications\nsuch as disaster response and land-use monitoring-particularly in regions where\nannotated data is scarce or unavailable. Existing tools (e.g., RS-CLIP) that\nclaim zero-shot classification capabilities for satellite imagery nonetheless\nrely on task-specific pretraining and adaptation to reach competitive\nperformance. We introduce GeoVision Labeler (GVL), a strictly zero-shot\nclassification framework: a vision Large Language Model (vLLM) generates rich,\nhuman-readable image descriptions, which are then mapped to user-defined\nclasses by a conventional Large Language Model (LLM). This modular, and\ninterpretable pipeline enables flexible image classification for a large range\nof use cases. We evaluated GVL across three benchmarks-SpaceNet v7, UC Merced,\nand RESISC45. It achieves up to 93.2% zero-shot accuracy on the binary\nBuildings vs. No Buildings task on SpaceNet v7. For complex multi-class\nclassification tasks (UC Merced, RESISC45), we implemented a recursive\nLLM-driven clustering to form meta-classes at successive depths, followed by\nhierarchical classification-first resolving coarse groups, then finer\ndistinctions-to deliver competitive zero-shot performance. GVL is open-sourced\nat https://github.com/microsoft/geo-vision-labeler to catalyze adoption in\nreal-world geospatial workflows.", "published": "2025-05-30 08:32:37", "link": "http://arxiv.org/abs/2505.24340v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "I.2.10; I.2.7; I.4.8; I.5.3"], "primary_category": "cs.CV"}
{"title": "Pangu DeepDiver: Adaptive Search Intensity Scaling via Open-Web Reinforcement Learning", "abstract": "Information seeking demands iterative evidence gathering and reflective\nreasoning, yet large language models (LLMs) still struggle with it in open-web\nquestion answering. Existing methods rely on static prompting rules or training\nwith Wikipedia-based corpora and retrieval environments, limiting adaptability\nto the real-world web environment where ambiguity, conflicting evidence, and\nnoise are prevalent. These constrained training settings hinder LLMs from\nlearning to dynamically decide when and where to search, and how to adjust\nsearch depth and frequency based on informational demands. We define this\nmissing capacity as Search Intensity Scaling (SIS)--the emergent skill to\nintensify search efforts under ambiguous or conflicting conditions, rather than\nsettling on overconfident, under-verification answers.\n  To study SIS, we introduce WebPuzzle, the first dataset designed to foster\ninformation-seeking behavior in open-world internet environments. WebPuzzle\nconsists of 24K training instances and 275 test questions spanning both\nwiki-based and open-web queries. Building on this dataset, we propose\nDeepDiver, a Reinforcement Learning (RL) framework that promotes SIS by\nencouraging adaptive search policies through exploration under a real-world\nopen-web environment. Experimental results show that Pangu-7B-Reasoner\nempowered by DeepDiver achieve performance on real-web tasks comparable to the\n671B-parameter DeepSeek-R1. We detail DeepDiver's training curriculum from\ncold-start supervised fine-tuning to a carefully designed RL phase, and present\nthat its capability of SIS generalizes from closed-form QA to open-ended tasks\nsuch as long-form writing. Our contributions advance adaptive information\nseeking in LLMs and provide a valuable benchmark and dataset for future\nresearch.", "published": "2025-05-30 08:15:39", "link": "http://arxiv.org/abs/2505.24332v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents", "abstract": "User sentiment on social media reveals the underlying social trends, crises,\nand needs. Researchers have analyzed users' past messages to trace the\nevolution of sentiments and reconstruct sentiment dynamics. However, predicting\nthe imminent sentiment of an ongoing event is rarely studied. In this paper, we\naddress the problem of \\textbf{sentiment forecasting} on social media to\npredict the user's future sentiment in response to the development of the\nevent. We extract sentiment-related features to enhance the modeling skill and\npropose a multi-perspective role-playing framework to simulate the process of\nhuman response. Our preliminary results show significant improvement in\nsentiment forecasting on both microscopic and macroscopic levels.", "published": "2025-05-30 08:13:33", "link": "http://arxiv.org/abs/2505.24331v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SwiftEval: Developing a Language-Specific Benchmark for LLM-generated Code Evaluation", "abstract": "In recent years, large language models (LLMs) have showcased significant\nadvancements in code generation. However, most evaluation benchmarks are\nprimarily oriented towards Python, making it difficult to evaluate other\nprogramming languages, such as Swift, with high quality. By examining widely\nestablished multilingual benchmarks like HumanEval-XL and MultiPL-E, we\nidentified critical issues specific to their Swift components, making them\ninsufficient or even irrelevant for assessing LLM coding capabilities on Swift.\nUnlike these existing approaches, which prioritize rapid scaling and\ngeneralization by automatically translating Python-centric benchmarks with\nLLMs, we adopt a quality-over-quantity methodology. We present SwiftEval, the\nfirst Swift-oriented benchmark consisting of 28 carefully hand-crafted\nproblems, and evaluate 44 popular Code LLMs on it. Our results show significant\nLLM scores drop for problems requiring language-specific features, most\nnoticeable in the models of smaller sizes.", "published": "2025-05-30 08:06:30", "link": "http://arxiv.org/abs/2505.24324v1", "categories": ["cs.LG", "cs.CL", "cs.PL", "cs.SE"], "primary_category": "cs.LG"}
{"title": "HiCaM: A Hierarchical-Causal Modification Framework for Long-Form Text Modification", "abstract": "Large Language Models (LLMs) have achieved remarkable success in various\ndomains. However, when handling long-form text modification tasks, they still\nface two major problems: (1) producing undesired modifications by\ninappropriately altering or summarizing irrelevant content, and (2) missing\nnecessary modifications to implicitly related passages that are crucial for\nmaintaining document coherence. To address these issues, we propose HiCaM, a\nHierarchical-Causal Modification framework that operates through a hierarchical\nsummary tree and a causal graph. Furthermore, to evaluate HiCaM, we derive a\nmulti-domain dataset from various benchmarks, providing a resource for\nassessing its effectiveness. Comprehensive evaluations on the dataset\ndemonstrate significant improvements over strong LLMs, with our method\nachieving up to a 79.50\\% win rate. These results highlight the\ncomprehensiveness of our approach, showing consistent performance improvements\nacross multiple models and domains.", "published": "2025-05-30 08:02:48", "link": "http://arxiv.org/abs/2505.24319v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ScienceMeter: Tracking Scientific Knowledge Updates in Language Models", "abstract": "Large Language Models (LLMs) are increasingly used to support scientific\nresearch, but their knowledge of scientific advancements can quickly become\noutdated. We introduce ScienceMeter, a new framework for evaluating scientific\nknowledge update methods over scientific knowledge spanning the past, present,\nand future. ScienceMeter defines three metrics: knowledge preservation, the\nextent to which models' understanding of previously learned papers are\npreserved; knowledge acquisition, how well scientific claims from newly\nintroduced papers are acquired; and knowledge projection, the ability of the\nupdated model to anticipate or generalize to related scientific claims that may\nemerge in the future. Using ScienceMeter, we examine the scientific knowledge\nof LLMs on claim judgment and generation tasks across a curated dataset of\n15,444 scientific papers and 30,888 scientific claims from ten domains\nincluding medicine, biology, materials science, and computer science. We\nevaluate five representative knowledge update approaches including training-\nand inference-time methods. With extensive experiments, we find that the\nbest-performing knowledge update methods can preserve only 85.9% of existing\nknowledge, acquire 71.7% of new knowledge, and project 37.7% of future\nknowledge. Inference-based methods work for larger models, whereas smaller\nmodels require training to achieve comparable performance. Cross-domain\nanalysis reveals that performance on these objectives is correlated. Even when\napplying on specialized scientific LLMs, existing knowledge update methods fail\nto achieve these objectives collectively, underscoring that developing robust\nscientific knowledge update mechanisms is both crucial and challenging.", "published": "2025-05-30 07:28:20", "link": "http://arxiv.org/abs/2505.24302v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models are Locally Linear Mappings", "abstract": "We demonstrate that the inference operations of several open-weight large\nlanguage models (LLMs) can be mapped to an exactly equivalent linear system for\nan input sequence without modifying the model weights or altering output\npredictions. Extending techniques from image diffusion models that exhibit\nlocal or piecewise linearity, we strategically alter the gradient computation\nwith respect to a given input sequence for a next-token prediction such that\nthe Jacobian of the model nearly exactly reproduces the forward prediction with\na linear system. We demonstrate this approach across models (Llama 3, Gemma 3,\nQwen 3, Phi 4, Mistral Ministral and OLMo 2, up to Llama 3.3 70B Q4) and show\nthrough the singular value decomposition of the detached Jacobian that these\nLLMs operate in extremely low-dimensional subspaces where many of the largest\nsingular vectors decode to concepts related to the most-likely output token.\nThis approach also allows us to examine the operation of each successive layer\n(and its attention and MLP components) as nearly-exact linear systems and\nobserve the emergence of semantic concepts. Despite their expressive power and\nglobal nonlinearity, modern LLMs can be interpreted through nearly-exact\nlocally linear decompositions that provide insights into their internal\nrepresentations and reveal interpretable semantic structures in the next-token\nprediction process.", "published": "2025-05-30 07:08:33", "link": "http://arxiv.org/abs/2505.24293v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Time Blindness: Why Video-Language Models Can't See What Humans Can?", "abstract": "Recent advances in vision-language models (VLMs) have made impressive strides\nin understanding spatio-temporal relationships in videos. However, when spatial\ninformation is obscured, these models struggle to capture purely temporal\npatterns. We introduce $\\textbf{SpookyBench}$, a benchmark where information is\nencoded solely in temporal sequences of noise-like frames, mirroring natural\nphenomena from biological signaling to covert communication. Interestingly,\nwhile humans can recognize shapes, text, and patterns in these sequences with\nover 98% accuracy, state-of-the-art VLMs achieve 0% accuracy. This performance\ngap highlights a critical limitation: an over-reliance on frame-level spatial\nfeatures and an inability to extract meaning from temporal cues. Furthermore,\nwhen trained in data sets with low spatial signal-to-noise ratios (SNR),\ntemporal understanding of models degrades more rapidly than human perception,\nespecially in tasks requiring fine-grained temporal reasoning. Overcoming this\nlimitation will require novel architectures or training paradigms that decouple\nspatial dependencies from temporal processing. Our systematic analysis shows\nthat this issue persists across model scales and architectures. We release\nSpookyBench to catalyze research in temporal pattern recognition and bridge the\ngap between human and machine video understanding. Dataset and code has been\nmade available on our project website: https://timeblindness.github.io/.", "published": "2025-05-30 17:59:12", "link": "http://arxiv.org/abs/2505.24867v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DexMachina: Functional Retargeting for Bimanual Dexterous Manipulation", "abstract": "We study the problem of functional retargeting: learning dexterous\nmanipulation policies to track object states from human hand-object\ndemonstrations. We focus on long-horizon, bimanual tasks with articulated\nobjects, which is challenging due to large action space, spatiotemporal\ndiscontinuities, and embodiment gap between human and robot hands. We propose\nDexMachina, a novel curriculum-based algorithm: the key idea is to use virtual\nobject controllers with decaying strength: an object is first driven\nautomatically towards its target states, such that the policy can gradually\nlearn to take over under motion and contact guidance. We release a simulation\nbenchmark with a diverse set of tasks and dexterous hands, and show that\nDexMachina significantly outperforms baseline methods. Our algorithm and\nbenchmark enable a functional comparison for hardware designs, and we present\nkey findings informed by quantitative and qualitative results. With the recent\nsurge in dexterous hand development, we hope this work will provide a useful\nplatform for identifying desirable hardware capabilities and lower the barrier\nfor contributing to future research. Videos and more at\nhttps://project-dexmachina.github.io/", "published": "2025-05-30 17:50:23", "link": "http://arxiv.org/abs/2505.24853v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software", "abstract": "Computer-Aided Design (CAD) is a time-consuming and complex process,\nrequiring precise, long-horizon user interactions with intricate 3D interfaces.\nWhile recent advances in AI-driven user interface (UI) agents show promise,\nmost existing datasets and methods focus on short, low-complexity tasks in\nmobile or web applications, failing to capture the demands of professional\nengineering tools. In this work, we introduce VideoCAD, the first attempt at\nengineering UI interaction learning for precision tasks. Specifically, VideoCAD\nis a large-scale synthetic dataset consisting of over 41K annotated video\nrecordings of CAD operations, generated using an automated framework for\ncollecting high-fidelity UI action data from human-made CAD designs. Compared\nto existing datasets, VideoCAD offers an order of magnitude higher complexity\nin UI interaction learning for real-world engineering tasks, having up to a 20x\nlonger time horizon than other datasets. We show two important downstream\napplications of VideoCAD: learning UI interactions from professional precision\n3D CAD tools and a visual question-answering (VQA) benchmark designed to\nevaluate multimodal large language models' (LLM) spatial reasoning and video\nunderstanding abilities. To learn the UI interactions, we propose\nVideoCADFormer - a state-of-the-art model in learning CAD interactions directly\nfrom video, which outperforms multiple behavior cloning baselines. Both\nVideoCADFormer and the VQA benchmark derived from VideoCAD reveal key\nchallenges in the current state of video-based UI understanding, including the\nneed for precise action grounding, multi-modal and spatial reasoning, and\nlong-horizon dependencies.", "published": "2025-05-30 17:39:52", "link": "http://arxiv.org/abs/2505.24838v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RealDrive: Retrieval-Augmented Driving with Diffusion Models", "abstract": "Learning-based planners generate natural human-like driving behaviors by\nlearning to reason about nuanced interactions from data, overcoming the rigid\nbehaviors that arise from rule-based planners. Nonetheless, data-driven\napproaches often struggle with rare, safety-critical scenarios and offer\nlimited controllability over the generated trajectories. To address these\nchallenges, we propose RealDrive, a Retrieval-Augmented Generation (RAG)\nframework that initializes a diffusion-based planning policy by retrieving the\nmost relevant expert demonstrations from the training dataset. By interpolating\nbetween current observations and retrieved examples through a denoising\nprocess, our approach enables fine-grained control and safe behavior across\ndiverse scenarios, leveraging the strong prior provided by the retrieved\nscenario. Another key insight we produce is that a task-relevant retrieval\nmodel trained with planning-based objectives results in superior planning\nperformance in our framework compared to a task-agnostic retriever.\nExperimental results demonstrate improved generalization to long-tail events\nand enhanced trajectory diversity compared to standard learning-based planners\n-- we observe a 40% reduction in collision rate on the Waymo Open Motion\ndataset with RAG.", "published": "2025-05-30 17:15:03", "link": "http://arxiv.org/abs/2505.24808v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Inference Acceleration of Autoregressive Normalizing Flows by Selective Jacobi Decoding", "abstract": "Normalizing flows are promising generative models with advantages such as\ntheoretical rigor, analytical log-likelihood computation, and end-to-end\ntraining. However, the architectural constraints to ensure invertibility and\ntractable Jacobian computation limit their expressive power and practical\nusability. Recent advancements utilize autoregressive modeling, significantly\nenhancing expressive power and generation quality. However, such sequential\nmodeling inherently restricts parallel computation during inference, leading to\nslow generation that impedes practical deployment. In this paper, we first\nidentify that strict sequential dependency in inference is unnecessary to\ngenerate high-quality samples. We observe that patches in sequential modeling\ncan also be approximated without strictly conditioning on all preceding\npatches. Moreover, the models tend to exhibit low dependency redundancy in the\ninitial layer and higher redundancy in subsequent layers. Leveraging these\nobservations, we propose a selective Jacobi decoding (SeJD) strategy that\naccelerates autoregressive inference through parallel iterative optimization.\nTheoretical analyses demonstrate the method's superlinear convergence rate and\nguarantee that the number of iterations required is no greater than the\noriginal sequential approach. Empirical evaluations across multiple datasets\nvalidate the generality and effectiveness of our acceleration technique.\nExperiments demonstrate substantial speed improvements up to 4.7 times faster\ninference while keeping the generation quality and fidelity.", "published": "2025-05-30 16:53:15", "link": "http://arxiv.org/abs/2505.24791v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DiG-Net: Enhancing Quality of Life through Hyper-Range Dynamic Gesture Recognition in Assistive Robotics", "abstract": "Dynamic hand gestures play a pivotal role in assistive human-robot\ninteraction (HRI), facilitating intuitive, non-verbal communication,\nparticularly for individuals with mobility constraints or those operating\nrobots remotely. Current gesture recognition methods are mostly limited to\nshort-range interactions, reducing their utility in scenarios demanding robust\nassistive communication from afar. In this paper, we introduce a novel approach\ndesigned specifically for assistive robotics, enabling dynamic gesture\nrecognition at extended distances of up to 30 meters, thereby significantly\nimproving accessibility and quality of life. Our proposed Distance-aware\nGesture Network (DiG-Net) effectively combines Depth-Conditioned Deformable\nAlignment (DADA) blocks with Spatio-Temporal Graph modules, enabling robust\nprocessing and classification of gesture sequences captured under challenging\nconditions, including significant physical attenuation, reduced resolution, and\ndynamic gesture variations commonly experienced in real-world assistive\nenvironments. We further introduce the Radiometric Spatio-Temporal Depth\nAttenuation Loss (RSTDAL), shown to enhance learning and strengthen model\nrobustness across varying distances. Our model demonstrates significant\nperformance improvement over state-of-the-art gesture recognition frameworks,\nachieving a recognition accuracy of 97.3% on a diverse dataset with challenging\nhyper-range gestures. By effectively interpreting gestures from considerable\ndistances, DiG-Net significantly enhances the usability of assistive robots in\nhome healthcare, industrial safety, and remote assistance scenarios, enabling\nseamless and intuitive interactions for users regardless of physical\nlimitations", "published": "2025-05-30 16:47:44", "link": "http://arxiv.org/abs/2505.24786v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "EXP-Bench: Can AI Conduct AI Research Experiments?", "abstract": "Automating AI research holds immense potential for accelerating scientific\nprogress, yet current AI agents struggle with the complexities of rigorous,\nend-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed\nto systematically evaluate AI agents on complete research experiments sourced\nfrom influential AI publications. Given a research question and incomplete\nstarter code, EXP-Bench challenges AI agents to formulate hypotheses, design\nand implement experimental procedures, execute them, and analyze results. To\nenable the creation of such intricate and authentic tasks with high-fidelity,\nwe design a semi-autonomous pipeline to extract and structure crucial\nexperimental details from these research papers and their associated\nopen-source code. With the pipeline, EXP-Bench curated 461 AI research tasks\nfrom 51 top-tier AI research papers. Evaluations of leading LLM-based agents,\nsuch as OpenHands and IterativeAgent on EXP-Bench demonstrate partial\ncapabilities: while scores on individual experimental aspects such as design or\nimplementation correctness occasionally reach 20-35%, the success rate for\ncomplete, executable experiments was a mere 0.5%. By identifying these\nbottlenecks and providing realistic step-by-step experiment procedures,\nEXP-Bench serves as a vital tool for future AI agents to improve their ability\nto conduct AI research experiments. EXP-Bench is open-sourced at\nhttps://github.com/Just-Curieous/Curie/tree/main/benchmark/exp_bench.", "published": "2025-05-30 16:46:29", "link": "http://arxiv.org/abs/2505.24785v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models", "abstract": "Current deep reinforcement learning (DRL) approaches achieve state-of-the-art\nperformance in various domains, but struggle with data efficiency compared to\nhuman learning, which leverages core priors about objects and their\ninteractions. Active inference offers a principled framework for integrating\nsensory information with prior knowledge to learn a world model and quantify\nthe uncertainty of its own beliefs and predictions. However, active inference\nmodels are usually crafted for a single task with bespoke knowledge, so they\nlack the domain flexibility typical of DRL approaches. To bridge this gap, we\npropose a novel architecture that integrates a minimal yet expressive set of\ncore priors about object-centric dynamics and interactions to accelerate\nlearning in low-data regimes. The resulting approach, which we call AXIOM,\ncombines the usual data efficiency and interpretability of Bayesian approaches\nwith the across-task generalization usually associated with DRL. AXIOM\nrepresents scenes as compositions of objects, whose dynamics are modeled as\npiecewise linear trajectories that capture sparse object-object interactions.\nThe structure of the generative model is expanded online by growing and\nlearning mixture models from single events and periodically refined through\nBayesian model reduction to induce generalization. AXIOM masters various games\nwithin only 10,000 interaction steps, with both a small number of parameters\ncompared to DRL, and without the computational expense of gradient-based\noptimization.", "published": "2025-05-30 16:46:20", "link": "http://arxiv.org/abs/2505.24784v1", "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "A survey of using EHR as real-world evidence for discovering and validating new drug indications", "abstract": "Electronic Health Records (EHRs) have been increasingly used as real-world\nevidence (RWE) to support the discovery and validation of new drug indications.\nThis paper surveys current approaches to EHR-based drug repurposing, covering\ndata sources, processing methodologies, and representation techniques. It\ndiscusses study designs and statistical frameworks for evaluating drug\nefficacy. Key challenges in validation are discussed, with emphasis on the role\nof large language models (LLMs) and target trial emulation. By synthesizing\nrecent developments and methodological advances, this work provides a\nfoundational resource for researchers aiming to translate real-world data into\nactionable drug-repurposing evidence.", "published": "2025-05-30 16:30:54", "link": "http://arxiv.org/abs/2505.24767v1", "categories": ["stat.AP", "cs.AI"], "primary_category": "stat.AP"}
{"title": "Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications", "abstract": "Supervised Quantum Machine Learning (QML) represents an intersection of\nquantum computing and classical machine learning, aiming to use quantum\nresources to support model training and inference. This paper reviews recent\ndevelopments in supervised QML, focusing on methods such as variational quantum\ncircuits, quantum neural networks, and quantum kernel methods, along with\nhybrid quantum-classical workflows. We examine recent experimental studies that\nshow partial indications of quantum advantage and describe current limitations\nincluding noise, barren plateaus, scalability issues, and the lack of formal\nproofs of performance improvement over classical methods. The main contribution\nis a ten-year outlook (2025-2035) that outlines possible developments in\nsupervised QML, including a roadmap describing conditions under which QML may\nbe used in applied research and enterprise systems over the next decade.", "published": "2025-05-30 16:29:12", "link": "http://arxiv.org/abs/2505.24765v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Unsupervised Evolutionary Cell Type Matching via Entropy-Minimized Optimal Transport", "abstract": "Identifying evolutionary correspondences between cell types across species is\na fundamental challenge in comparative genomics and evolutionary biology.\nExisting approaches often rely on either reference-based matching, which\nimposes asymmetry by designating one species as the reference, or\nprojection-based matching, which may increase computational complexity and\nobscure biological interpretability at the cell-type level. Here, we present\nOT-MESH, an unsupervised computational framework leveraging entropy-regularized\noptimal transport (OT) to systematically determine cross-species cell type\nhomologies. Our method uniquely integrates the Minimize Entropy of Sinkhorn\n(MESH) technique to refine the OT plan. It begins by selecting genes with high\nSignal-to-Noise Ratio (SNR) to capture the most informative features, from\nwhich a cost matrix is constructed using cosine distances between cell-type\ncentroids. Importantly, the MESH procedure iteratively refines the cost matrix,\nleading to a transport plan with significantly enhanced sparsity and\ninterpretability of the resulting correspondence matrices. Applied to retinal\nbipolar cells (BCs) and retinal ganglion cells (RGCs) from mouse and macaque,\nOT-MESH accurately recovers known evolutionary relationships and uncovers novel\ncorrespondences, one of which was independently validated experimentally. Thus,\nour framework offers a principled, scalable, symmetric, and interpretable\nsolution for evolutionary cell type mapping, facilitating deeper insights into\ncellular specialization and conservation across species.", "published": "2025-05-30 16:20:00", "link": "http://arxiv.org/abs/2505.24759v1", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "HELM: Hyperbolic Large Language Models via Mixture-of-Curvature Experts", "abstract": "Large language models (LLMs) have shown great success in text modeling tasks\nacross domains. However, natural language exhibits inherent semantic\nhierarchies and nuanced geometric structure, which current LLMs do not capture\ncompletely owing to their reliance on Euclidean operations. Recent studies have\nalso shown that not respecting the geometry of token embeddings leads to\ntraining instabilities and degradation of generative capabilities. These\nfindings suggest that shifting to non-Euclidean geometries can better align\nlanguage models with the underlying geometry of text. We thus propose to\noperate fully in Hyperbolic space, known for its expansive, scale-free, and\nlow-distortion properties. We thus introduce HELM, a family of HypErbolic Large\nLanguage Models, offering a geometric rethinking of the Transformer-based LLM\nthat addresses the representational inflexibility, missing set of necessary\noperations, and poor scalability of existing hyperbolic LMs. We additionally\nintroduce a Mixture-of-Curvature Experts model, HELM-MICE, where each expert\noperates in a distinct curvature space to encode more fine-grained geometric\nstructure from text, as well as a dense model, HELM-D. For HELM-MICE, we\nfurther develop hyperbolic Multi-Head Latent Attention (HMLA) for efficient,\nreduced-KV-cache training and inference. For both models, we develop essential\nhyperbolic equivalents of rotary positional encodings and RMS normalization. We\nare the first to train fully hyperbolic LLMs at billion-parameter scale, and\nevaluate them on well-known benchmarks such as MMLU and ARC, spanning STEM\nproblem-solving, general knowledge, and commonsense reasoning. Our results show\nconsistent gains from our HELM architectures -- up to 4% -- over popular\nEuclidean architectures used in LLaMA and DeepSeek, highlighting the efficacy\nand enhanced reasoning afforded by hyperbolic geometry in large-scale LM\npretraining.", "published": "2025-05-30 15:42:42", "link": "http://arxiv.org/abs/2505.24722v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Towards Scalable Schema Mapping using Large Language Models", "abstract": "The growing need to integrate information from a large number of diverse\nsources poses significant scalability challenges for data integration systems.\nThese systems often rely on manually written schema mappings, which are\ncomplex, source-specific, and costly to maintain as sources evolve. While\nrecent advances suggest that large language models (LLMs) can assist in\nautomating schema matching by leveraging both structural and natural language\ncues, key challenges remain. In this paper, we identify three core issues with\nusing LLMs for schema mapping: (1) inconsistent outputs due to sensitivity to\ninput phrasing and structure, which we propose methods to address through\nsampling and aggregation techniques; (2) the need for more expressive mappings\n(e.g., GLaV), which strain the limited context windows of LLMs; and (3) the\ncomputational cost of repeated LLM calls, which we propose to mitigate through\nstrategies like data type prefiltering.", "published": "2025-05-30 15:36:56", "link": "http://arxiv.org/abs/2505.24716v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "On Symmetric Losses for Robust Policy Optimization with Noisy Preferences", "abstract": "Optimizing policies based on human preferences is key to aligning language\nmodels with human intent. This work focuses on reward modeling, a core\ncomponent in reinforcement learning from human feedback (RLHF), and offline\npreference optimization, such as direct preference optimization. Conventional\napproaches typically assume accurate annotations. However, real-world\npreference data often contains noise due to human errors or biases. We propose\na principled framework for robust policy optimization under noisy preferences,\nviewing reward modeling as a classification problem. This allows us to leverage\nsymmetric losses, known for their robustness to label noise in classification,\nleading to our Symmetric Preference Optimization (SymPO) method. We prove that\nsymmetric losses enable successful policy optimization even under noisy labels,\nas the resulting reward remains rank-preserving -- a property sufficient for\npolicy improvement. Experiments on synthetic and real-world tasks demonstrate\nthe effectiveness of SymPO.", "published": "2025-05-30 15:30:43", "link": "http://arxiv.org/abs/2505.24709v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Disentangling Granularity: An Implicit Inductive Bias in Factorized VAEs", "abstract": "Despite the success in learning semantically meaningful, unsupervised\ndisentangled representations, variational autoencoders (VAEs) and their\nvariants face a fundamental theoretical challenge: substantial evidence\nindicates that unsupervised disentanglement is unattainable without implicit\ninductive bias, yet such bias remains elusive. In this work, we focus on\nexploring the implicit inductive bias that drive disentanglement in VAEs with\nfactorization priors. By analyzing the total correlation in \\b{eta}-TCVAE, we\nuncover a crucial implicit inductive bias called disentangling granularity,\nwhich leads to the discovery of an interesting \"V\"-shaped optimal Evidence\nLower Bound (ELBO) trajectory within the parameter space. This finding is\nvalidated through over 100K experiments using factorized VAEs and our newly\nproposed model, \\b{eta}-STCVAE. Notably, experimental results reveal that\nconventional factorized VAEs, constrained by fixed disentangling granularity,\ninherently tend to disentangle low-complexity feature. Whereas, appropriately\ntuning disentangling granularity, as enabled by \\b{eta}-STCVAE, broadens the\nrange of disentangled representations, allowing for the disentanglement of\nhigh-complexity features. Our findings unveil that disentangling granularity as\nan implicit inductive bias in factorized VAEs influence both disentanglement\nperformance and the inference of the ELBO, offering fresh insights into the\ninterpretability and inherent biases of VAEs.", "published": "2025-05-30 15:08:50", "link": "http://arxiv.org/abs/2505.24684v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Generative Knowledge Production Pipeline Driven by Academic Influencers", "abstract": "Generative AI transforms knowledge production, validation, and dissemination,\nraising academic integrity and credibility concerns. This study examines 53\nacademic influencer videos that reached 5.3 million viewers to identify an\nemerging, structured, implementation-ready pipeline balancing originality,\nethical compliance, and human-AI collaboration despite the disruptive impacts.\nFindings highlight generative AI's potential to automate publication workflows\nand democratize participation in knowledge production while challenging\ntraditional scientific norms. Academic influencers emerge as key intermediaries\nin this paradigm shift, connecting bottom-up practices with institutional\npolicies to improve adaptability. Accordingly, the study proposes a generative\npublication production pipeline and a policy framework for co-intelligence\nadaptation and reinforcing credibility-centered standards in AI-powered\nresearch. These insights support scholars, educators, and policymakers in\nunderstanding AI's transformative impact by advocating responsible and\ninnovation-driven knowledge production. Additionally, they reveal pathways for\nautomating best practices, optimizing scholarly workflows, and fostering\ncreativity in academic research and publication.", "published": "2025-05-30 15:07:01", "link": "http://arxiv.org/abs/2505.24681v1", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.SI", "1.2, J.4, K.4"], "primary_category": "cs.CY"}
{"title": "Adaptable Cardiovascular Disease Risk Prediction from Heterogeneous Data using Large Language Models", "abstract": "Cardiovascular disease (CVD) risk prediction models are essential for\nidentifying high-risk individuals and guiding preventive actions. However,\nexisting models struggle with the challenges of real-world clinical practice as\nthey oversimplify patient profiles, rely on rigid input schemas, and are\nsensitive to distribution shifts. We developed AdaCVD, an adaptable CVD risk\nprediction framework built on large language models extensively fine-tuned on\nover half a million participants from the UK Biobank. In benchmark comparisons,\nAdaCVD surpasses established risk scores and standard machine learning\napproaches, achieving state-of-the-art performance. Crucially, for the first\ntime, it addresses key clinical challenges across three dimensions: it flexibly\nincorporates comprehensive yet variable patient information; it seamlessly\nintegrates both structured data and unstructured text; and it rapidly adapts to\nnew patient populations using minimal additional data. In stratified analyses,\nit demonstrates robust performance across demographic, socioeconomic, and\nclinical subgroups, including underrepresented cohorts. AdaCVD offers a\npromising path toward more flexible, AI-driven clinical decision support tools\nsuited to the realities of heterogeneous and dynamic healthcare environments.", "published": "2025-05-30 14:42:02", "link": "http://arxiv.org/abs/2505.24655v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models", "abstract": "Large vision-language models have become widely adopted to advance in various\ndomains. However, developing a trustworthy system with minimal interpretable\ncharacteristics of large-scale models presents a significant challenge. One of\nthe most prevalent terms associated with the fallacy functions caused by these\nsystems is hallucination, where the language model generates a response that\ndoes not correspond to the visual content. To mitigate this problem, several\napproaches have been developed, and one prominent direction is to ameliorate\nthe decoding process. In this paper, we propose a new Bijective Maximum\nLikelihood Learning (BIMA) approach to hallucination mitigation using\nnormalizing flow theories. The proposed BIMA method can efficiently mitigate\nthe hallucination problem in prevailing vision-language models, resulting in\nsignificant improvements. Notably, BIMA achieves the average F1 score of 85.06%\non POPE benchmark and remarkably reduce CHAIRS and CHAIRI by 7.6% and 2.6%,\nrespectively. To the best of our knowledge, this is one of the first studies\nthat contemplates the bijection means to reduce hallucination induced by large\nvision-language models.", "published": "2025-05-30 14:38:07", "link": "http://arxiv.org/abs/2505.24649v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Cloud Optical Thickness Retrievals Using Angle Invariant Attention Based Deep Learning Models", "abstract": "Cloud Optical Thickness (COT) is a critical cloud property influencing\nEarth's climate, weather, and radiation budget. Satellite radiance measurements\nenable global COT retrieval, but challenges like 3D cloud effects, viewing\nangles, and atmospheric interference must be addressed to ensure accurate\nestimation. Traditionally, the Independent Pixel Approximation (IPA) method,\nwhich treats individual pixels independently, has been used for COT estimation.\nHowever, IPA introduces significant bias due to its simplified assumptions.\nRecently, deep learning-based models have shown improved performance over IPA\nbut lack robustness, as they are sensitive to variations in radiance intensity,\ndistortions, and cloud shadows. These models also introduce substantial errors\nin COT estimation under different solar and viewing zenith angles. To address\nthese challenges, we propose a novel angle-invariant, attention-based deep\nmodel called Cloud-Attention-Net with Angle Coding (CAAC). Our model leverages\nattention mechanisms and angle embeddings to account for satellite viewing\ngeometry and 3D radiative transfer effects, enabling more accurate retrieval of\nCOT. Additionally, our multi-angle training strategy ensures angle invariance.\nThrough comprehensive experiments, we demonstrate that CAAC significantly\noutperforms existing state-of-the-art deep learning models, reducing cloud\nproperty retrieval errors by at least a factor of nine.", "published": "2025-05-30 14:26:30", "link": "http://arxiv.org/abs/2505.24638v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors", "abstract": "Previous research has investigated the application of Multimodal Large\nLanguage Models (MLLMs) in understanding 3D scenes by interpreting them as\nvideos. These approaches generally depend on comprehensive 3D data inputs, such\nas point clouds or reconstructed Bird's-Eye View (BEV) maps. In our research,\nwe advance this field by enhancing the capability of MLLMs to understand and\nreason in 3D spaces directly from video data, without the need for additional\n3D input. We propose a novel and efficient method, the Video-3D Geometry Large\nLanguage Model (VG LLM). Our approach employs a 3D visual geometry encoder that\nextracts 3D prior information from video sequences. This information is\nintegrated with visual tokens and fed into the MLLM. Extensive experiments have\nshown that our method has achieved substantial improvements in various tasks\nrelated to 3D scene understanding and spatial reasoning, all directly learned\nfrom video sources. Impressively, our 4B model, which does not rely on explicit\n3D data inputs, achieves competitive results compared to existing\nstate-of-the-art methods, and even surpasses the Gemini-1.5-Pro in the\nVSI-Bench evaluations.", "published": "2025-05-30 14:16:41", "link": "http://arxiv.org/abs/2505.24625v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Hyperbolic Dataset Distillation", "abstract": "To address the computational and storage challenges posed by large-scale\ndatasets in deep learning, dataset distillation has been proposed to synthesize\na compact dataset that replaces the original while maintaining comparable model\nperformance. Unlike optimization-based approaches that require costly bi-level\noptimization, distribution matching (DM) methods improve efficiency by aligning\nthe distributions of synthetic and original data, thereby eliminating nested\noptimization. DM achieves high computational efficiency and has emerged as a\npromising solution. However, existing DM methods, constrained to Euclidean\nspace, treat data as independent and identically distributed points,\noverlooking complex geometric and hierarchical relationships. To overcome this\nlimitation, we propose a novel hyperbolic dataset distillation method, termed\nHDD. Hyperbolic space, characterized by negative curvature and exponential\nvolume growth with distance, naturally models hierarchical and tree-like\nstructures. HDD embeds features extracted by a shallow network into the Lorentz\nhyperbolic space, where the discrepancy between synthetic and original data is\nmeasured by the hyperbolic (geodesic) distance between their centroids. By\noptimizing this distance, the hierarchical structure is explicitly integrated\ninto the distillation process, guiding synthetic samples to gravitate towards\nthe root-centric regions of the original data distribution while preserving\ntheir underlying geometric characteristics. Furthermore, we find that pruning\nin hyperbolic space requires only 20% of the distilled core set to retain model\nperformance, while significantly improving training stability. Notably, HDD is\nseamlessly compatible with most existing DM methods, and extensive experiments\non different datasets validate its effectiveness.", "published": "2025-05-30 14:14:00", "link": "http://arxiv.org/abs/2505.24623v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Random Rule Forest (RRF): Interpretable Ensembles of LLM-Generated Questions for Predicting Startup Success", "abstract": "Predicting startup success requires models that are both accurate and\ninterpretable. We present a lightweight ensemble framework that combines YES/NO\nquestions generated by large language models (LLMs), forming a transparent\ndecision-making system. Each question acts as a weak heuristic, and by\nfiltering, ranking, and aggregating them through a threshold-based voting\nmechanism, we construct a strong ensemble predictor. On a test set where 10% of\nstartups are classified as successful, our approach achieves a precision rate\nof 50%, representing a 5x improvement over random selection, while remaining\nfully transparent. When we incorporate expert-guided heuristics into the\ngeneration process, performance improves further to 54% precision. These\nresults highlight the value of combining LLM reasoning with human insight and\ndemonstrate that simple, interpretable ensembles can support high-stakes\ndecisions in domains such as venture capital (VC).", "published": "2025-05-30 14:13:21", "link": "http://arxiv.org/abs/2505.24622v1", "categories": ["cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Taxonomic Networks: A Representation for Neuro-Symbolic Pairing", "abstract": "We introduce the concept of a \\textbf{neuro-symbolic pair} -- neural and\nsymbolic approaches that are linked through a common knowledge representation.\nNext, we present \\textbf{taxonomic networks}, a type of discrimination network\nin which nodes represent hierarchically organized taxonomic concepts. Using\nthis representation, we construct a novel neuro-symbolic pair and evaluate its\nperformance. We show that our symbolic method learns taxonomic nets more\nefficiently with less data and compute, while the neural method finds\nhigher-accuracy taxonomic nets when provided with greater resources. As a\nneuro-symbolic pair, these approaches can be used interchangeably based on\nsituational needs, with seamless translation between them when necessary. This\nwork lays the foundation for future systems that more fundamentally integrate\nneural and symbolic computation.", "published": "2025-05-30 13:48:34", "link": "http://arxiv.org/abs/2505.24601v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Mixture-of-Experts for Personalized and Semantic-Aware Next Location Prediction", "abstract": "Next location prediction plays a critical role in understanding human\nmobility patterns. However, existing approaches face two core limitations: (1)\nthey fall short in capturing the complex, multi-functional semantics of\nreal-world locations; and (2) they lack the capacity to model heterogeneous\nbehavioral dynamics across diverse user groups. To tackle these challenges, we\nintroduce NextLocMoE, a novel framework built upon large language models (LLMs)\nand structured around a dual-level Mixture-of-Experts (MoE) design. Our\narchitecture comprises two specialized modules: a Location Semantics MoE that\noperates at the embedding level to encode rich functional semantics of\nlocations, and a Personalized MoE embedded within the Transformer backbone to\ndynamically adapt to individual user mobility patterns. In addition, we\nincorporate a history-aware routing mechanism that leverages long-term\ntrajectory data to enhance expert selection and ensure prediction stability.\nEmpirical evaluations across several real-world urban datasets show that\nNextLocMoE achieves superior performance in terms of predictive accuracy,\ncross-domain generalization, and interpretability", "published": "2025-05-30 13:45:19", "link": "http://arxiv.org/abs/2505.24597v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Binary Cumulative Encoding meets Time Series Forecasting", "abstract": "Recent studies in time series forecasting have explored formulating\nregression via classification task. By discretizing the continuous target space\ninto bins and predicting over a fixed set of classes, these approaches benefit\nfrom stable training, robust uncertainty modeling, and compatibility with\nmodern deep learning architectures. However, most existing methods rely on\none-hot encoding that ignores the inherent ordinal structure of the underlying\nvalues. As a result, they fail to provide information about the relative\ndistance between predicted and true values during training. In this paper, we\npropose to address this limitation by introducing binary cumulative encoding\n(BCE), that represents scalar targets into monotonic binary vectors. This\nencoding implicitly preserves order and magnitude information, allowing the\nmodel to learn distance-aware representations while still operating within a\nclassification framework. We propose a convolutional neural network\narchitecture specifically designed for BCE, incorporating residual and dilated\nconvolutions to enable fast and expressive temporal modeling. Through extensive\nexperiments on benchmark forecasting datasets, we show that our approach\noutperforms widely used methods in both point and probabilistic forecasting,\nwhile requiring fewer parameters and enabling faster training.", "published": "2025-05-30 13:41:39", "link": "http://arxiv.org/abs/2505.24595v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Flat Minima Perspective on Understanding Augmentations and Model Robustness", "abstract": "Model robustness indicates a model's capability to generalize well on\nunforeseen distributional shifts, including data corruption, adversarial\nattacks, and domain shifts. Data augmentation is one of the prevalent and\neffective ways to enhance robustness. Despite the great success of\naugmentations in different fields, a general theoretical understanding of their\nefficacy in improving model robustness is lacking. We offer a unified\ntheoretical framework to clarify how augmentations can enhance model robustness\nthrough the lens of loss surface flatness and PAC generalization bound. Our\nwork diverges from prior studies in that our analysis i) broadly encompasses\nmuch of the existing augmentation methods, and ii) is not limited to specific\ntypes of distribution shifts like adversarial attacks. We confirm our theories\nthrough simulations on the existing common corruption and adversarial\nrobustness benchmarks based on the CIFAR and ImageNet datasets, as well as\ndomain generalization benchmarks including PACS and OfficeHome.", "published": "2025-05-30 13:40:44", "link": "http://arxiv.org/abs/2505.24592v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for Auto-Generating Chemical Process and Instrumentation Diagrams", "abstract": "Recent advancements in generative AI have accelerated the discovery of novel\nchemicals and materials; however, transitioning these discoveries to\nindustrial-scale production remains a critical bottleneck, as it requires the\ndevelopment of entirely new chemical manufacturing processes. Current AI\nmethods cannot auto-generate PFDs or PIDs, despite their critical role in\nscaling chemical processes, while adhering to engineering constraints. We\npresent a closed loop, physics aware framework for the automated generation of\nindustrially viable PFDs and PIDs. The framework integrates domain specialized\nsmall scale language models (SLMs) (trained for chemical process QA tasks) with\nfirst principles simulation, leveraging three key components: (1) a\nhierarchical knowledge graph of process flow and instrumentation descriptions\nfor 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes\ndomain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT),\nDirect Preference Optimization (DPO), and Retrieval-Augmented Instruction\nTuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure\nfeasibility. To improve both runtime efficiency and model compactness, the\nframework incorporates advanced inference time optimizations including\nFlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization,\nand Test Time Inference Scaling and independently applies structural pruning\ntechniques (width and depth) guided by importance heuristics to reduce model\nsize with minimal accuracy loss. Experiments demonstrate that the framework\ngenerates simulator-validated process descriptions with high fidelity,\noutperforms baseline methods in correctness, and generalizes to unseen\nchemicals. By bridging AI-driven design with industrial-scale feasibility, this\nwork significantly reduces R&D timelines from lab discovery to plant\ndeployment.", "published": "2025-05-30 13:32:00", "link": "http://arxiv.org/abs/2505.24584v1", "categories": ["cs.LG", "cs.AI", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Mixpert: Mitigating Multimodal Learning Conflicts with Efficient Mixture-of-Vision-Experts", "abstract": "Multimodal large language models (MLLMs) require a nuanced interpretation of\ncomplex image information, typically leveraging a vision encoder to perceive\nvarious visual scenarios. However, relying solely on a single vision encoder to\nhandle diverse task domains proves difficult and inevitably leads to conflicts.\nRecent work enhances data perception by directly integrating multiple\ndomain-specific vision encoders, yet this structure adds complexity and limits\nthe potential for joint optimization. In this paper, we introduce Mixpert, an\nefficient mixture-of-vision-experts architecture that inherits the joint\nlearning advantages from a single vision encoder while being restructured into\na multi-expert paradigm for task-specific fine-tuning across different visual\ntasks. Additionally, we design a dynamic routing mechanism that allocates input\nimages to the most suitable visual expert. Mixpert effectively alleviates\ndomain conflicts encountered by a single vision encoder in multi-task learning\nwith minimal additional computational cost, making it more efficient than\nmultiple encoders. Furthermore, Mixpert integrates seamlessly into any MLLM,\nwith experimental results demonstrating substantial performance gains across\nvarious tasks.", "published": "2025-05-30 12:48:07", "link": "http://arxiv.org/abs/2505.24541v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CHIP: Chameleon Hash-based Irreversible Passport for Robust Deep Model Ownership Verification and Active Usage Control", "abstract": "The pervasion of large-scale Deep Neural Networks (DNNs) and their enormous\ntraining costs make their intellectual property (IP) protection of paramount\nimportance. Recently introduced passport-based methods attempt to steer DNN\nwatermarking towards strengthening ownership verification against ambiguity\nattacks by modulating the affine parameters of normalization layers.\nUnfortunately, neither watermarking nor passport-based methods provide a\nholistic protection with robust ownership proof, high fidelity, active usage\nauthorization and user traceability for offline access distributed models and\nmulti-user Machine-Learning as a Service (MLaaS) cloud model. In this paper, we\npropose a Chameleon Hash-based Irreversible Passport (CHIP) protection\nframework that utilizes the cryptographic chameleon hash function to achieve\nall these goals. The collision-resistant property of chameleon hash allows for\nstrong model ownership claim upon IP infringement and liable user traceability,\nwhile the trapdoor-collision property enables hashing of multiple user\npassports and licensee certificates to the same immutable signature to realize\nactive usage control. Using the owner passport as an oracle, multiple\nuser-specific triplets, each contains a passport-aware user model, a user\npassport, and a licensee certificate can be created for secure offline\ndistribution. The watermarked master model can also be deployed for MLaaS with\nusage permission verifiable by the provision of any trapdoor-colliding user\npassports. CHIP is extensively evaluated on four datasets and two architectures\nto demonstrate its protection versatility and robustness. Our code is released\nat https://github.com/Dshm212/CHIP.", "published": "2025-05-30 12:41:51", "link": "http://arxiv.org/abs/2505.24536v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Directional Non-Commutative Monoidal Structures with Interchange Law via Commutative Generators", "abstract": "We introduce a novel framework consisting of a class of algebraic structures\nthat generalize one-dimensional monoidal systems into higher dimensions by\ndefining per-axis composition operators subject to non-commutativity and a\nglobal interchange law. These structures, defined recursively from a base case\nof vector-matrix pairs, model directional composition in multiple dimensions\nwhile preserving structural coherence through commutative linear operators.\n  We show that the framework that unifies several well-known linear transforms\nin signal processing and data analysis. In this framework, data indices are\nembedded into a composite structure that decomposes into simpler components. We\nshow that classic transforms such as the Discrete Fourier Transform (DFT), the\nWalsh transform, and the Hadamard transform are special cases of our algebraic\nstructure. The framework provides a systematic way to derive these transforms\nby appropriately choosing vector and matrix pairs. By subsuming classical\ntransforms within a common structure, the framework also enables the\ndevelopment of learnable transformations tailored to specific data modalities\nand tasks.", "published": "2025-05-30 12:40:01", "link": "http://arxiv.org/abs/2505.24533v1", "categories": ["cs.LG", "cs.AI", "cs.SC", "20-XX, 08A02", "F.4.1; I.2"], "primary_category": "cs.LG"}
{"title": "Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting", "abstract": "Time series forecasting (TSF) is a fundamental and widely studied task,\nspanning methods from classical statistical approaches to modern deep learning\nand multimodal language modeling. Despite their effectiveness, these methods\noften follow a fast thinking paradigm emphasizing pattern extraction and direct\nvalue mapping, while overlooking explicit reasoning over temporal dynamics and\ncontextual dependencies. Meanwhile, emerging slow-thinking LLMs (e.g.,\nChatGPT-o1, DeepSeek-R1) have demonstrated impressive multi-step reasoning\ncapabilities across diverse domains, suggesting a new opportunity for reframing\nTSF as a structured reasoning task. This motivates a key question: can\nslow-thinking LLMs effectively reason over temporal patterns to support time\nseries forecasting, even in zero-shot manner? To investigate this, in this\npaper, we propose TimeReasoner, an extensive empirical study that formulates\nTSF as a conditional reasoning task. We design a series of prompting strategies\nto elicit inference-time reasoning from pretrained slow-thinking LLMs and\nevaluate their performance across diverse TSF benchmarks. Our findings reveal\nthat slow-thinking LLMs exhibit non-trivial zero-shot forecasting capabilities,\nespecially in capturing high-level trends and contextual shifts. While\npreliminary, our study surfaces important insights into the reasoning behaviors\nof LLMs in temporal domains highlighting both their potential and limitations.\nWe hope this work catalyzes further research into reasoning-based forecasting\nparadigms and paves the way toward more interpretable and generalizable TSF\nframeworks.", "published": "2025-05-30 12:19:02", "link": "http://arxiv.org/abs/2505.24511v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Online Fair Division with Additional Information", "abstract": "We study the problem of fairly allocating indivisible goods to agents in an\nonline setting, where goods arrive sequentially and must be allocated\nirrevocably to agents. Focusing on the popular fairness notions of\nenvy-freeness, proportionality, and maximin share fairness (and their\napproximate variants), we ask how the availability of information on future\ngoods influences the existence and approximability of fair allocations. In the\nabsence of any such information, we establish strong impossibility results,\ndemonstrating the inherent difficulty of achieving even approximate fairness\nguarantees. In contrast, we demonstrate that knowledge of additional\ninformation -- such as aggregate of each agent's total valuations\n(equivalently, normalized valuations) or the multiset of future goods values\n(frequency predictions) -- would enable the design of fairer online algorithms.\nGiven normalization information, we propose an algorithm that achieves stronger\nfairness guarantees than previously known results. Given frequency predictions,\nwe introduce a meta-algorithm that leverages frequency predictions to match the\nbest-known offline guarantees for a broad class of ''share-based'' fairness\nnotions. Our complementary impossibility results in each setting underscore\nboth the limitations imposed by uncertainty about future goods and the\npotential of leveraging structured information to achieve fairer outcomes in\nonline fair division.", "published": "2025-05-30 12:06:16", "link": "http://arxiv.org/abs/2505.24503v1", "categories": ["cs.GT", "cs.AI"], "primary_category": "cs.GT"}
{"title": "MELT: Towards Automated Multimodal Emotion Data Annotation by Leveraging LLM Embedded Knowledge", "abstract": "Although speech emotion recognition (SER) has advanced significantly with\ndeep learning, annotation remains a major hurdle. Human annotation is not only\ncostly but also subject to inconsistencies annotators often have different\npreferences and may lack the necessary contextual knowledge, which can lead to\nvaried and inaccurate labels. Meanwhile, Large Language Models (LLMs) have\nemerged as a scalable alternative for annotating text data. However, the\npotential of LLMs to perform emotional speech data annotation without human\nsupervision has yet to be thoroughly investigated. To address these problems,\nwe apply GPT-4o to annotate a multimodal dataset collected from the sitcom\nFriends, using only textual cues as inputs. By crafting structured text\nprompts, our methodology capitalizes on the knowledge GPT-4o has accumulated\nduring its training, showcasing that it can generate accurate and contextually\nrelevant annotations without direct access to multimodal inputs. Therefore, we\npropose MELT, a multimodal emotion dataset fully annotated by GPT-4o. We\ndemonstrate the effectiveness of MELT by fine-tuning four self-supervised\nlearning (SSL) backbones and assessing speech emotion recognition performance\nacross emotion datasets. Additionally, our subjective experiments\\' results\ndemonstrate a consistence performance improvement on SER.", "published": "2025-05-30 11:45:36", "link": "http://arxiv.org/abs/2505.24493v1", "categories": ["cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "Object Centric Concept Bottlenecks", "abstract": "Developing high-performing, yet interpretable models remains a critical\nchallenge in modern AI. Concept-based models (CBMs) attempt to address this by\nextracting human-understandable concepts from a global encoding (e.g., image\nencoding) and then applying a linear classifier on the resulting concept\nactivations, enabling transparent decision-making. However, their reliance on\nholistic image encodings limits their expressiveness in object-centric\nreal-world settings and thus hinders their ability to solve complex vision\ntasks beyond single-label classification. To tackle these challenges, we\nintroduce Object-Centric Concept Bottlenecks (OCB), a framework that combines\nthe strengths of CBMs and pre-trained object-centric foundation models,\nboosting performance and interpretability. We evaluate OCB on complex image\ndatasets and conduct a comprehensive ablation study to analyze key components\nof the framework, such as strategies for aggregating object-concept encodings.\nThe results show that OCB outperforms traditional CBMs and allows one to make\ninterpretable decisions for complex visual tasks.", "published": "2025-05-30 11:45:05", "link": "http://arxiv.org/abs/2505.24492v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Deformable Attention Mechanisms Applied to Object Detection, case of Remote Sensing", "abstract": "Object detection has recently seen an interesting trend in terms of the most\ninnovative research work, this task being of particular importance in the field\nof remote sensing, given the consistency of these images in terms of\ngeographical coverage and the objects present. Furthermore, Deep Learning (DL)\nmodels, in particular those based on Transformers, are especially relevant for\nvisual computing tasks in general, and target detection in particular. Thus,\nthe present work proposes an application of Deformable-DETR model, a specific\narchitecture using deformable attention mechanisms, on remote sensing images in\ntwo different modes, especially optical and Synthetic Aperture Radar (SAR). To\nachieve this objective, two datasets are used, one optical, which is Pleiades\nAircraft dataset, and the other SAR, in particular SAR Ship Detection Dataset\n(SSDD). The results of a 10-fold stratified validation showed that the proposed\nmodel performed particularly well, obtaining an F1 score of 95.12% for the\noptical dataset and 94.54% for SSDD, while comparing these results with several\nmodels detections, especially those based on CNNs and transformers, as well as\nthose specifically designed to detect different object classes in remote\nsensing images.", "published": "2025-05-30 11:43:09", "link": "http://arxiv.org/abs/2505.24489v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Rehearsal with Auxiliary-Informed Sampling for Audio Deepfake Detection", "abstract": "The performance of existing audio deepfake detection frameworks degrades when\nconfronted with new deepfake attacks. Rehearsal-based continual learning (CL),\nwhich updates models using a limited set of old data samples, helps preserve\nprior knowledge while incorporating new information. However, existing\nrehearsal techniques don't effectively capture the diversity of audio\ncharacteristics, introducing bias and increasing the risk of forgetting. To\naddress this challenge, we propose Rehearsal with Auxiliary-Informed Sampling\n(RAIS), a rehearsal-based CL approach for audio deepfake detection. RAIS\nemploys a label generation network to produce auxiliary labels, guiding diverse\nsample selection for the memory buffer. Extensive experiments show RAIS\noutperforms state-of-the-art methods, achieving an average Equal Error Rate\n(EER) of 1.953 % across five experiences. The code is available at:\nhttps://github.com/falihgoz/RAIS.", "published": "2025-05-30 11:40:50", "link": "http://arxiv.org/abs/2505.24486v1", "categories": ["cs.SD", "cs.AI", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Evaluating Gemini in an arena for learning", "abstract": "Artificial intelligence (AI) is poised to transform education, but the\nresearch community lacks a robust, general benchmark to evaluate AI models for\nlearning. To assess state-of-the-art support for educational use cases, we ran\nan \"arena for learning\" where educators and pedagogy experts conduct blind,\nhead-to-head, multi-turn comparisons of leading AI models. In particular, $N =\n189$ educators drew from their experience to role-play realistic learning use\ncases, interacting with two models sequentially, after which $N = 206$ experts\njudged which model better supported the user's learning goals. The arena\nevaluated a slate of state-of-the-art models: Gemini 2.5 Pro, Claude 3.7\nSonnet, GPT-4o, and OpenAI o3. Excluding ties, experts preferred Gemini 2.5 Pro\nin 73.2% of these match-ups -- ranking it first overall in the arena. Gemini\n2.5 Pro also demonstrated markedly higher performance across key principles of\ngood pedagogy. Altogether, these results position Gemini 2.5 Pro as a leading\nmodel for learning.", "published": "2025-05-30 11:26:32", "link": "http://arxiv.org/abs/2505.24477v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Train One Sparse Autoencoder Across Multiple Sparsity Budgets to Preserve Interpretability and Accuracy", "abstract": "Sparse Autoencoders (SAEs) have proven to be powerful tools for interpreting\nneural networks by decomposing hidden representations into disentangled,\ninterpretable features via sparsity constraints. However, conventional SAEs are\nconstrained by the fixed sparsity level chosen during training; meeting\ndifferent sparsity requirements therefore demands separate models and increases\nthe computational footprint during both training and evaluation. We introduce a\nnovel training objective, \\emph{HierarchicalTopK}, which trains a single SAE to\noptimise reconstructions across multiple sparsity levels simultaneously.\nExperiments with Gemma-2 2B demonstrate that our approach achieves\nPareto-optimal trade-offs between sparsity and explained variance,\noutperforming traditional SAEs trained at individual sparsity levels. Further\nanalysis shows that HierarchicalTopK preserves high interpretability scores\neven at higher sparsity. The proposed objective thus closes an important gap\nbetween flexibility and interpretability in SAE design.", "published": "2025-05-30 11:20:44", "link": "http://arxiv.org/abs/2505.24473v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SEAR: A Multimodal Dataset for Analyzing AR-LLM-Driven Social Engineering Behaviors", "abstract": "The SEAR Dataset is a novel multimodal resource designed to study the\nemerging threat of social engineering (SE) attacks orchestrated through\naugmented reality (AR) and multimodal large language models (LLMs). This\ndataset captures 180 annotated conversations across 60 participants in\nsimulated adversarial scenarios, including meetings, classes and networking\nevents. It comprises synchronized AR-captured visual/audio cues (e.g., facial\nexpressions, vocal tones), environmental context, and curated social media\nprofiles, alongside subjective metrics such as trust ratings and susceptibility\nassessments. Key findings reveal SEAR's alarming efficacy in eliciting\ncompliance (e.g., 93.3% phishing link clicks, 85% call acceptance) and\nhijacking trust (76.7% post-interaction trust surge). The dataset supports\nresearch in detecting AR-driven SE attacks, designing defensive frameworks, and\nunderstanding multimodal adversarial manipulation. Rigorous ethical safeguards,\nincluding anonymization and IRB compliance, ensure responsible use. The SEAR\ndataset is available at https://github.com/INSLabCN/SEAR-Dataset.", "published": "2025-05-30 10:46:13", "link": "http://arxiv.org/abs/2505.24458v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "LPASS: Linear Probes as Stepping Stones for vulnerability detection using compressed LLMs", "abstract": "Large Language Models (LLMs) are being extensively used for cybersecurity\npurposes. One of them is the detection of vulnerable codes. For the sake of\nefficiency and effectiveness, compression and fine-tuning techniques are being\ndeveloped, respectively. However, they involve spending substantial\ncomputational efforts. In this vein, we analyse how Linear Probes (LPs) can be\nused to provide an estimation on the performance of a compressed LLM at an\nearly phase -- before fine-tuning. We also show their suitability to set the\ncut-off point when applying layer pruning compression. Our approach, dubbed\n$LPASS$, is applied in BERT and Gemma for the detection of 12 of MITRE's Top 25\nmost dangerous vulnerabilities on 480k C/C++ samples. LPs can be computed in\n142.97 s. and provide key findings: (1) 33.3 \\% and 72.2\\% of layers can be\nremoved, respectively, with no precision loss; (2) they provide an early\nestimate of the post-fine-tuning and post-compression model effectiveness, with\n3\\% and 8.68\\% as the lowest and average precision errors, respectively.\n$LPASS$-based LLMs outperform the state of the art, reaching 86.9\\% of accuracy\nin multi-class vulnerability detection. Interestingly, $LPASS$-based compressed\nversions of Gemma outperform the original ones by 1.6\\% of F1-score at a\nmaximum while saving 29.4 \\% and 23.8\\% of training and inference time and\n42.98\\% of model size.", "published": "2025-05-30 10:37:14", "link": "http://arxiv.org/abs/2505.24451v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Learning Safety Constraints for Large Language Models", "abstract": "Large language models (LLMs) have emerged as powerful tools but pose\nsignificant safety risks through harmful outputs and vulnerability to\nadversarial attacks. We propose SaP, short for Safety Polytope, a geometric\napproach to LLM safety that learns and enforces multiple safety constraints\ndirectly in the model's representation space. We develop a framework that\nidentifies safe and unsafe regions via the polytope's facets, enabling both\ndetection and correction of unsafe outputs through geometric steering. Unlike\nexisting approaches that modify model weights, SaP operates post-hoc in the\nrepresentation space, preserving model capabilities while enforcing safety\nconstraints. Experiments across multiple LLMs demonstrate that our method can\neffectively detect unethical inputs, reduce adversarial attack success rates\nwhile maintaining performance on standard tasks, thus highlighting the\nimportance of having an explicit geometric model for safety. Analysis of the\nlearned polytope facets reveals emergence of specialization in detecting\ndifferent semantic notions of safety, providing interpretable insights into how\nsafety is captured in LLMs' representation space.", "published": "2025-05-30 10:30:24", "link": "http://arxiv.org/abs/2505.24445v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation", "abstract": "Although multi-agent systems based on large language models show strong\ncapabilities on multiple tasks, they are still limited by high computational\noverhead, information loss, and robustness. Inspired by ResNet's residual\nlearning, we propose Residual Mixture-of-Agents (RMoA), integrating residual\nconnections to optimize efficiency and reliability. To maximize information\nutilization from model responses while minimizing computational costs, we\ninnovatively design an embedding-based diversity selection mechanism that\ngreedily selects responses via vector similarity. Furthermore, to mitigate\niterative information degradation, we introduce a Residual Extraction Agent to\npreserve cross-layer incremental information by capturing inter-layer response\ndifferences, coupled with a Residual Aggregation Agent for hierarchical\ninformation integration. Additionally, we propose an adaptive termination\nmechanism that dynamically halts processing based on residual convergence,\nfurther improving inference efficiency. RMoA achieves state-of-the-art\nperformance on the benchmarks of across alignment, mathematical reasoning, code\ngeneration, and multitasking understanding, while significantly reducing\ncomputational overhead. Code is available at\nhttps://github.com/mindhunter01/RMoA.", "published": "2025-05-30 10:23:11", "link": "http://arxiv.org/abs/2505.24442v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Deep Learning Weather Models for Subregional Ocean Forecasting: A Case Study on the Canary Current Upwelling System", "abstract": "Oceanographic forecasting impacts various sectors of society by supporting\nenvironmental conservation and economic activities. Based on global circulation\nmodels, traditional forecasting methods are computationally expensive and slow,\nlimiting their ability to provide rapid forecasts. Recent advances in deep\nlearning offer faster and more accurate predictions, although these data-driven\nmodels are often trained with global data from numerical simulations, which may\nnot reflect reality. The emergence of such models presents great potential for\nimproving ocean prediction at a subregional domain. However, their ability to\npredict fine-scale ocean processes, like mesoscale structures, remains largely\nunknown. This work aims to adapt a graph neural network initially developed for\nglobal weather forecasting to improve subregional ocean prediction,\nspecifically focusing on the Canary Current upwelling system. The model is\ntrained with satellite data and compared to state-of-the-art physical ocean\nmodels to assess its performance in capturing ocean dynamics. Our results show\nthat the deep learning model surpasses traditional methods in precision despite\nsome challenges in upwelling areas. It demonstrated superior performance in\nreducing RMSE errors compared to ConvLSTM and the GLORYS reanalysis,\nparticularly in regions with complex oceanic dynamics such as Cape Ghir, Cape\nBojador, and Cape Blanc. The model achieved improvements of up to 26.5%\nrelative to ConvLSTM and error reductions of up to 76% in 5-day forecasts\ncompared to the GLORYS reanalysis at these critical locations, highlighting its\nenhanced capability to capture spatial variability and improve predictive\naccuracy in complex areas. These findings suggest the viability of adapting\nmeteorological data-driven models for improving subregional medium-term ocean\nforecasting.", "published": "2025-05-30 10:10:40", "link": "http://arxiv.org/abs/2505.24429v1", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "primary_category": "physics.ao-ph"}
{"title": "P: A Universal Measure of Predictive Intelligence", "abstract": "Over the last thirty years, considerable progress has been made with the\ndevelopment of systems that can drive cars, play games, predict protein folding\nand generate natural language. These systems are described as intelligent and\nthere has been a great deal of talk about the rapid increase in artificial\nintelligence and its potential dangers. However, our theoretical understanding\nof intelligence and ability to measure it lag far behind our capacity for\nbuilding systems that mimic intelligent human behaviour. There is no commonly\nagreed definition of the intelligence that AI systems are said to possess.\nNo-one has developed a practical measure that would enable us to compare the\nintelligence of humans, animals and AIs on a single ratio scale.\n  This paper sets out a new universal measure of intelligence that is based on\nthe hypothesis that prediction is the most important component of intelligence.\nAs an agent interacts with its normal environment, the accuracy of its\npredictions is summed up and the complexity of its predictions and perceived\nenvironment is accounted for using Kolmogorov complexity. Two experiments were\ncarried out to evaluate the practical feasibility of the algorithm. These\ndemonstrated that it could measure the intelligence of an agent embodied in a\nvirtual maze and an agent that makes predictions about time-series data. This\nuniversal measure could be the starting point for a new comparative science of\nintelligence that ranks humans, animals and AIs on a single ratio scale.", "published": "2025-05-30 10:05:54", "link": "http://arxiv.org/abs/2505.24426v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Three Kinds of Negation in Knowledge and Their Mathematical Foundations", "abstract": "In the field of artificial intelligence, understanding, distinguishing,\nexpressing, and computing the negation in knowledge is a fundamental issue in\nknowledge processing and research. In this paper, we examine and analyze the\nunderstanding and characteristics of negation in various fields such as\nphilosophy, logic, and linguistics etc. Based on the distinction between the\nconcepts of contradiction and opposition, we propose that there are three\ndifferent types of negation in knowledge from a conceptual perspective:\ncontradictory negation, opposite negation, and intermediary negation. To\nestablish a mathematical foundation that fully reflects the intrinsic\nconnections, properties, and laws of these different forms of negation, we\nintroduce SCOI: sets with contradictory negation, opposite negation and\nintermediary negation, and LCOI: logic with contradictory negation, opposite\nnegation and intermediary negation, and we proved the main operational\nproperties of SCOI as well as the formal inference relations in LCOI.", "published": "2025-05-30 10:01:37", "link": "http://arxiv.org/abs/2505.24422v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Boosting Automatic Exercise Evaluation Through Musculoskeletal Simulation-Based IMU Data Augmentation", "abstract": "Automated evaluation of movement quality holds significant potential for\nenhancing physiotherapeutic treatments and sports training by providing\nobjective, real-time feedback. However, the effectiveness of deep learning\nmodels in assessing movements captured by inertial measurement units (IMUs) is\noften hampered by limited data availability, class imbalance, and label\nambiguity. In this work, we present a novel data augmentation method that\ngenerates realistic IMU data using musculoskeletal simulations integrated with\nsystematic modifications of movement trajectories. Crucially, our approach\nensures biomechanical plausibility and allows for automatic, reliable labeling\nby combining inverse kinematic parameters with a knowledge-based evaluation\nstrategy. Extensive evaluations demonstrate that augmented variants closely\nresembles real-world data, significantly improving the classification accuracy\nand generalization capability of neural network models. Additionally, we\nhighlight the benefits of augmented data for patient-specific fine-tuning\nscenarios, particularly when only limited subject-specific training examples\nare available. Our findings underline the practicality and efficacy of this\naugmentation method in overcoming common challenges faced by deep learning\napplications in physiotherapeutic exercise evaluation.", "published": "2025-05-30 09:53:37", "link": "http://arxiv.org/abs/2505.24415v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification", "abstract": "Fine-grained bird image classification (FBIC) is not only of great\nsignificance for ecological monitoring and species identification, but also\nholds broad research value in the fields of image recognition and fine-grained\nvisual modeling. Compared with general image classification tasks, FBIC poses\nmore formidable challenges: 1) the differences in species size and imaging\ndistance result in the varying sizes of birds presented in the images; 2)\ncomplex natural habitats often introduce strong background interference; 3) and\nhighly flexible poses such as flying, perching, or foraging result in\nsubstantial intra-class variability. These factors collectively make it\ndifficult for traditional methods to stably extract discriminative features,\nthereby limiting the generalizability and interpretability of models in\nreal-world applications. To address these challenges, this paper proposes a\nfine-grained bird classification framework based on strip-aware spatial\nperception, which aims to capture long-range spatial dependencies across entire\nrows or columns in bird images, thereby enhancing the model's robustness and\ninterpretability. The proposed method incorporates two novel modules:\nextensional perception aggregator (EPA) and channel semantic weaving (CSW).\nSpecifically, EPA integrates local texture details with global structural cues\nby aggregating information across horizontal and vertical spatial directions.\nCSW further refines the semantic representations by adaptively fusing\nlong-range and short-range information along the channel dimension. Built upon\na ResNet-50 backbone, the model enables jump-wise connection of extended\nstructural features across the spatial domain. Experimental results on the\nCUB-200-2011 dataset demonstrate that our framework achieves significant\nperformance improvements while maintaining architectural efficiency.", "published": "2025-05-30 09:10:12", "link": "http://arxiv.org/abs/2505.24380v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Mastering Massive Multi-Task Reinforcement Learning via Mixture-of-Expert Decision Transformer", "abstract": "Despite recent advancements in offline multi-task reinforcement learning\n(MTRL) have harnessed the powerful capabilities of the Transformer\narchitecture, most approaches focus on a limited number of tasks, with scaling\nto extremely massive tasks remaining a formidable challenge. In this paper, we\nfirst revisit the key impact of task numbers on current MTRL method, and\nfurther reveal that naively expanding the parameters proves insufficient to\ncounteract the performance degradation as the number of tasks escalates.\nBuilding upon these insights, we propose M3DT, a novel mixture-of-experts (MoE)\nframework that tackles task scalability by further unlocking the model's\nparameter scalability. Specifically, we enhance both the architecture and the\noptimization of the agent, where we strengthen the Decision Transformer (DT)\nbackbone with MoE to reduce task load on parameter subsets, and introduce a\nthree-stage training mechanism to facilitate efficient training with optimal\nperformance. Experimental results show that, by increasing the number of\nexperts, M3DT not only consistently enhances its performance as model expansion\non the fixed task numbers, but also exhibits remarkable task scalability,\nsuccessfully extending to 160 tasks with superior performance.", "published": "2025-05-30 09:08:52", "link": "http://arxiv.org/abs/2505.24378v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering", "abstract": "In this paper, we propose a Grid-based Local and Global Area Transcription\n(Grid-LoGAT) system for Video Question Answering (VideoQA). The system operates\nin two phases. First, extracting text transcripts from video frames using a\nVision-Language Model (VLM). Next, processing questions using these transcripts\nto generate answers through a Large Language Model (LLM). This design ensures\nimage privacy by deploying the VLM on edge devices and the LLM in the cloud. To\nimprove transcript quality, we propose grid-based visual prompting, which\nextracts intricate local details from each grid cell and integrates them with\nglobal information. Evaluation results show that Grid-LoGAT, using the\nopen-source VLM (LLaVA-1.6-7B) and LLM (Llama-3.1-8B), outperforms\nstate-of-the-art methods with similar baseline models on NExT-QA and STAR-QA\ndatasets with an accuracy of 65.9% and 50.11% respectively. Additionally, our\nmethod surpasses the non-grid version by 24 points on localization-based\nquestions we created using NExT-QA.", "published": "2025-05-30 09:04:30", "link": "http://arxiv.org/abs/2505.24371v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Adversarial Preference Learning for Robust LLM Alignment", "abstract": "Modern language models often rely on Reinforcement Learning from Human\nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to\nadversarial attacks due to three key limitations: (1) the inefficiency and high\ncost of human annotation, (2) the vast diversity of potential adversarial\nattacks, and (3) the risk of feedback bias and reward hacking. To address these\nchallenges, we introduce Adversarial Preference Learning (APL), an iterative\nadversarial training method incorporating three key innovations. First, a\ndirect harmfulness metric based on the model's intrinsic preference\nprobabilities, eliminating reliance on external assessment. Second, a\nconditional generative attacker that synthesizes input-specific adversarial\nvariations. Third, an iterative framework with automated closed-loop feedback,\nenabling continuous adaptation through vulnerability discovery and mitigation.\nExperiments on Mistral-7B-Instruct-v0.3 demonstrate that APL significantly\nenhances robustness, achieving 83.33% harmlessness win rate over the base model\n(evaluated by GPT-4o), reducing harmful outputs from 5.88% to 0.43% (measured\nby LLaMA-Guard), and lowering attack success rate by up to 65% according to\nHarmBench. Notably, APL maintains competitive utility, with an MT-Bench score\nof 6.59 (comparable to the baseline 6.78) and an LC-WinRate of 46.52% against\nthe base model.", "published": "2025-05-30 09:02:07", "link": "http://arxiv.org/abs/2505.24369v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ReCalKV: Low-Rank KV Cache Compression via Head Reordering and Offline Calibration", "abstract": "Large language models (LLMs) have achieved remarkable performance, yet their\ncapability on long-context reasoning is often constrained by the excessive\nmemory required to store the Key-Value (KV) cache. This makes KV cache\ncompression an essential step toward enabling efficient long-context reasoning.\nRecent methods have explored reducing the hidden dimensions of the KV cache,\nbut many introduce additional computation through projection layers or suffer\nfrom significant performance degradation under high compression ratios. To\naddress these challenges, we propose ReCalKV, a post-training KV cache\ncompression method that reduces the hidden dimensions of the KV cache. We\ndevelop distinct compression strategies for Keys and Values based on their\ndifferent roles and varying importance in the attention mechanism. For Keys, we\npropose Head-wise Similarity-aware Reordering (HSR), which clusters similar\nheads and applies grouped SVD to the key projection matrix, reducing additional\ncomputation while preserving accuracy. For Values, we propose Offline\nCalibration and Matrix Fusion (OCMF) to preserve accuracy without extra\ncomputational overhead. Experiments show that ReCalKV outperforms existing\nlow-rank compression methods, achieving high compression ratios with minimal\nperformance loss. Code is available at:\nhttps://github.com/XIANGLONGYAN/ReCalKV.", "published": "2025-05-30 08:49:27", "link": "http://arxiv.org/abs/2505.24357v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "When Humans Growl and Birds Speak: High-Fidelity Voice Conversion from Human to Animal and Designed Sounds", "abstract": "Human to non-human voice conversion (H2NH-VC) transforms human speech into\nanimal or designed vocalizations. Unlike prior studies focused on dog-sounds\nand 16 or 22.05kHz audio transformation, this work addresses a broader range of\nnon-speech sounds, including natural sounds (lion-roars, birdsongs) and\ndesigned voice (synthetic growls). To accomodate generation of diverse\nnon-speech sounds and 44.1kHz high-quality audio transformation, we introduce a\npreprocessing pipeline and an improved CVAE-based H2NH-VC model, both optimized\nfor human and non-human voices. Experimental results showed that the proposed\nmethod outperformed baselines in quality, naturalness, and similarity MOS,\nachieving effective voice conversion across diverse non-human timbres. Demo\nsamples are available at\nhttps://nc-ai.github.io/speech/publications/nonhuman-vc/", "published": "2025-05-30 08:24:41", "link": "http://arxiv.org/abs/2505.24336v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "GridRoute: A Benchmark for LLM-Based Route Planning with Cardinal Movement in Grid Environments", "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated their\npotential in planning and reasoning tasks, offering a flexible alternative to\nclassical pathfinding algorithms. However, most existing studies focus on LLMs'\nindependent reasoning capabilities and overlook the potential synergy between\nLLMs and traditional algorithms. To fill this gap, we propose a comprehensive\nevaluation benchmark GridRoute to assess how LLMs can take advantage of\ntraditional algorithms. We also propose a novel hybrid prompting technique\ncalled Algorithm of Thought (AoT), which introduces traditional algorithms'\nguidance into prompting. Our benchmark evaluates six LLMs ranging from 7B to\n72B parameters across various map sizes, assessing their performance in\ncorrectness, optimality, and efficiency in grid environments with varying\nsizes. Our results show that AoT significantly boosts performance across all\nmodel sizes, particularly in larger or more complex environments, suggesting a\npromising approach to addressing path planning challenges. Our code is\nopen-sourced at https://github.com/LinChance/GridRoute.", "published": "2025-05-30 07:40:59", "link": "http://arxiv.org/abs/2505.24306v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning", "abstract": "Reinforcement learning (RL) has become a trending paradigm for training large\nlanguage models (LLMs), particularly for reasoning tasks. Effective RL for LLMs\nrequires massive parallelization and poses an urgent need for efficient\ntraining systems. Most existing large-scale RL systems for LLMs are synchronous\nby alternating generation and training in a batch setting, where the rollouts\nin each training batch are generated by the same (or latest) model. This\nstabilizes RL training but suffers from severe system-level inefficiency.\nGeneration must wait until the longest output in the batch is completed before\nmodel update, resulting in GPU underutilization. We present AReaL, a\n\\emph{fully asynchronous} RL system that completely decouples generation from\ntraining. Rollout workers in AReaL continuously generate new outputs without\nwaiting, while training workers update the model whenever a batch of data is\ncollected. AReaL also incorporates a collection of system-level optimizations,\nleading to substantially higher GPU utilization. To stabilize RL training,\nAReaL balances the workload of rollout and training workers to control data\nstaleness, and adopts a staleness-enhanced PPO variant to better handle\noutdated training samples. Extensive experiments on math and code reasoning\nbenchmarks show that AReaL achieves \\textbf{up to 2.57$\\times$ training\nspeedup} compared to the best synchronous systems with the same number of GPUs\nand matched or even improved final performance. The code of AReaL is available\nat https://github.com/inclusionAI/AReaL/.", "published": "2025-05-30 07:18:25", "link": "http://arxiv.org/abs/2505.24298v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Mind the Quote: Enabling Quotation-Aware Dialogue in LLMs via Plug-and-Play Modules", "abstract": "Human-AI conversation frequently relies on quoting earlier text-\"check it\nwith the formula I just highlighted\"-yet today's large language models (LLMs)\nlack an explicit mechanism for locating and exploiting such spans. We formalise\nthe challenge as span-conditioned generation, decomposing each turn into the\ndialogue history, a set of token-offset quotation spans, and an intent\nutterance. Building on this abstraction, we introduce a quotation-centric data\npipeline that automatically synthesises task-specific dialogues, verifies\nanswer correctness through multi-stage consistency checks, and yields both a\nheterogeneous training corpus and the first benchmark covering five\nrepresentative scenarios. To meet the benchmark's zero-overhead and\nparameter-efficiency requirements, we propose QuAda, a lightweight\ntraining-based method that attaches two bottleneck projections to every\nattention head, dynamically amplifying or suppressing attention to quoted spans\nat inference time while leaving the prompt unchanged and updating < 2.8% of\nbackbone weights. Experiments across models show that QuAda is suitable for all\nscenarios and generalises to unseen topics, offering an effective,\nplug-and-play solution for quotation-aware dialogue.", "published": "2025-05-30 07:06:11", "link": "http://arxiv.org/abs/2505.24292v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Discl-VC: Disentangled Discrete Tokens and In-Context Learning for Controllable Zero-Shot Voice Conversion", "abstract": "Currently, zero-shot voice conversion systems are capable of synthesizing the\nvoice of unseen speakers. However, most existing approaches struggle to\naccurately replicate the speaking style of the source speaker or mimic the\ndistinctive speaking style of the target speaker, thereby limiting the\ncontrollability of voice conversion. In this work, we propose Discl-VC, a novel\nvoice conversion framework that disentangles content and prosody information\nfrom self-supervised speech representations and synthesizes the target\nspeaker's voice through in-context learning with a flow matching transformer.\nTo enable precise control over the prosody of generated speech, we introduce a\nmask generative transformer that predicts discrete prosody tokens in a\nnon-autoregressive manner based on prompts. Experimental results demonstrate\nthe superior performance of Discl-VC in zero-shot voice conversion and its\nremarkable accuracy in prosody control for synthesized speech.", "published": "2025-05-30 07:04:23", "link": "http://arxiv.org/abs/2505.24291v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "How Much Backtracking is Enough? Exploring the Interplay of SFT and RL in Enhancing LLM Reasoning", "abstract": "Recent breakthroughs in large language models (LLMs) have effectively\nimproved their reasoning abilities, particularly on mathematical and logical\nproblems that have verifiable answers, through techniques such as supervised\nfinetuning (SFT) and reinforcement learning (RL). Prior research indicates that\nRL effectively internalizes search strategies, enabling long chain-of-thought\n(CoT) reasoning, with backtracking emerging naturally as a learned capability.\nHowever, the precise benefits of backtracking, specifically, how significantly\nit contributes to reasoning improvements and the optimal extent of its use,\nremain poorly understood. In this work, we systematically investigate the\ndynamics between SFT and RL on eight reasoning tasks: Countdown, Sudoku, Arc\n1D, Geometry, Color Cube Rotation, List Functions, Zebra Puzzles, and Self\nReference. Our findings highlight that short CoT sequences used in SFT as a\nwarm-up do have moderate contribution to RL training, compared with cold-start\nRL; however such contribution diminishes when tasks become increasingly\ndifficult. Motivated by this observation, we construct synthetic datasets\nvarying systematically in the number of backtracking steps and conduct\ncontrolled experiments to isolate the influence of either the correctness\n(content) or the structure (i.e., backtrack frequency). We find that (1) longer\nCoT with backtracks generally induce better and more stable RL training, (2)\nmore challenging problems with larger search space tend to need higher numbers\nof backtracks during the SFT stage. Additionally, we demonstrate through\nexperiments on distilled data that RL training is largely unaffected by the\ncorrectness of long CoT sequences, suggesting that RL prioritizes structural\npatterns over content correctness. Collectively, our results offer practical\ninsights into designing optimal training strategies to effectively scale\nreasoning in LLMs.", "published": "2025-05-30 06:49:00", "link": "http://arxiv.org/abs/2505.24273v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "INSIGHT: A Survey of In-Network Systems for Intelligent, High-Efficiency AI and Topology Optimization", "abstract": "In-network computation represents a transformative approach to addressing the\nescalating demands of Artificial Intelligence (AI) workloads on network\ninfrastructure. By leveraging the processing capabilities of network devices\nsuch as switches, routers, and Network Interface Cards (NICs), this paradigm\nenables AI computations to be performed directly within the network fabric,\nsignificantly reducing latency, enhancing throughput, and optimizing resource\nutilization. This paper provides a comprehensive analysis of optimizing\nin-network computation for AI, exploring the evolution of programmable network\narchitectures, such as Software-Defined Networking (SDN) and Programmable Data\nPlanes (PDPs), and their convergence with AI. It examines methodologies for\nmapping AI models onto resource-constrained network devices, addressing\nchallenges like limited memory and computational capabilities through efficient\nalgorithm design and model compression techniques. The paper also highlights\nadvancements in distributed learning, particularly in-network aggregation, and\nthe potential of federated learning to enhance privacy and scalability.\nFrameworks like Planter and Quark are discussed for simplifying development,\nalongside key applications such as intelligent network monitoring, intrusion\ndetection, traffic management, and Edge AI. Future research directions,\nincluding runtime programmability, standardized benchmarks, and new\napplications paradigms, are proposed to advance this rapidly evolving field.\nThis survey underscores the potential of in-network AI to create intelligent,\nefficient, and responsive networks capable of meeting the demands of\nnext-generation AI applications.", "published": "2025-05-30 06:47:55", "link": "http://arxiv.org/abs/2505.24269v1", "categories": ["cs.NI", "cs.AI"], "primary_category": "cs.NI"}
{"title": "Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations", "abstract": "Natural language explanations play a fundamental role in Natural Language\nInference (NLI) by revealing how premises logically entail hypotheses. Recent\nwork has shown that the interaction of large language models (LLMs) with\ntheorem provers (TPs) can help verify and improve the validity of NLI\nexplanations. However, TPs require translating natural language into\nmachine-verifiable formal representations, a process that introduces the risk\nof semantic information loss and unfaithful interpretation, an issue compounded\nby LLMs' challenges in capturing critical logical structures with sufficient\nprecision. Moreover, LLMs are still limited in their capacity for rigorous and\nrobust proof construction within formal verification frameworks. To mitigate\nissues related to faithfulness and robustness, this paper investigates\nstrategies to (1) alleviate semantic loss during autoformalisation, (2)\nefficiently identify and correct syntactic errors in logical representations,\n(3) explicitly use logical expressions to guide LLMs in generating structured\nproof sketches, and (4) increase LLMs' capacity of interpreting TP's feedback\nfor iterative refinement. Our empirical results on e-SNLI, QASC and WorldTree\nusing different LLMs demonstrate that the proposed strategies yield significant\nimprovements in autoformalisation (+18.46%, +34.2%, +39.77%) and explanation\nrefinement (+29.5%, +51.5%, +41.25%) over the state-of-the-art model. Moreover,\nwe show that specific interventions on the hybrid LLM-TP architecture can\nsubstantially improve efficiency, drastically reducing the number of iterations\nrequired for successful verification.", "published": "2025-05-30 06:38:39", "link": "http://arxiv.org/abs/2505.24264v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generative AI for Urban Design: A Stepwise Approach Integrating Human Expertise with Multimodal Diffusion Models", "abstract": "Urban design is a multifaceted process that demands careful consideration of\nsite-specific constraints and collaboration among diverse professionals and\nstakeholders. The advent of generative artificial intelligence (GenAI) offers\ntransformative potential by improving the efficiency of design generation and\nfacilitating the communication of design ideas. However, most existing\napproaches are not well integrated with human design workflows. They often\nfollow end-to-end pipelines with limited control, overlooking the iterative\nnature of real-world design. This study proposes a stepwise generative urban\ndesign framework that integrates multimodal diffusion models with human\nexpertise to enable more adaptive and controllable design processes. Instead of\ngenerating design outcomes in a single end-to-end process, the framework\ndivides the process into three key stages aligned with established urban design\nworkflows: (1) road network and land use planning, (2) building layout\nplanning, and (3) detailed planning and rendering. At each stage, multimodal\ndiffusion models generate preliminary designs based on textual prompts and\nimage-based constraints, which can then be reviewed and refined by human\ndesigners. We design an evaluation framework to assess the fidelity,\ncompliance, and diversity of the generated designs. Experiments using data from\nChicago and New York City demonstrate that our framework outperforms baseline\nmodels and end-to-end approaches across all three dimensions. This study\nunderscores the benefits of multimodal diffusion models and stepwise generation\nin preserving human control and facilitating iterative refinements, laying the\ngroundwork for human-AI interaction in urban design solutions.", "published": "2025-05-30 06:33:48", "link": "http://arxiv.org/abs/2505.24260v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "FABLE: A Novel Data-Flow Analysis Benchmark on Procedural Text for Large Language Model Evaluation", "abstract": "Understanding how data moves, transforms, and persists, known as data flow,\nis fundamental to reasoning in procedural tasks. Despite their fluency in\nnatural and programming languages, large language models (LLMs), although\nincreasingly being applied to decisions with procedural tasks, have not been\nsystematically evaluated for their ability to perform data-flow reasoning. We\nintroduce FABLE, an extensible benchmark designed to assess LLMs' understanding\nof data flow using structured, procedural text. FABLE adapts eight classical\ndata-flow analyses from software engineering: reaching definitions, very busy\nexpressions, available expressions, live variable analysis, interval analysis,\ntype-state analysis, taint analysis, and concurrency analysis. These analyses\nare instantiated across three real-world domains: cooking recipes, travel\nroutes, and automated plans. The benchmark includes 2,400 question-answer\npairs, with 100 examples for each domain-analysis combination. We evaluate\nthree types of LLMs: a reasoning-focused model (DeepSeek-R1 8B), a\ngeneral-purpose model (LLaMA 3.1 8B), and a code-specific model (Granite Code\n8B). Each model is tested using majority voting over five sampled completions\nper prompt. Results show that the reasoning model achieves higher accuracy, but\nat the cost of over 20 times slower inference compared to the other models. In\ncontrast, the general-purpose and code-specific models perform close to random\nchance. FABLE provides the first diagnostic benchmark to systematically\nevaluate data-flow reasoning and offers insights for developing models with\nstronger procedural understanding.", "published": "2025-05-30 06:32:34", "link": "http://arxiv.org/abs/2505.24258v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Effects of Theory of Mind and Prosocial Beliefs on Steering Human-Aligned Behaviors of LLMs in Ultimatum Games", "abstract": "Large Language Models (LLMs) have shown potential in simulating human\nbehaviors and performing theory-of-mind (ToM) reasoning, a crucial skill for\ncomplex social interactions. In this study, we investigate the role of ToM\nreasoning in aligning agentic behaviors with human norms in negotiation tasks,\nusing the ultimatum game as a controlled environment. We initialized LLM agents\nwith different prosocial beliefs (including Greedy, Fair, and Selfless) and\nreasoning methods like chain-of-thought (CoT) and varying ToM levels, and\nexamined their decision-making processes across diverse LLMs, including\nreasoning models like o3-mini and DeepSeek-R1 Distilled Qwen 32B. Results from\n2,700 simulations indicated that ToM reasoning enhances behavior alignment,\ndecision-making consistency, and negotiation outcomes. Consistent with previous\nfindings, reasoning models exhibit limited capability compared to models with\nToM reasoning, different roles of the game benefits with different orders of\nToM reasoning. Our findings contribute to the understanding of ToM's role in\nenhancing human-AI interaction and cooperative decision-making. The code used\nfor our experiments can be found at https://github.com/Stealth-py/UltimatumToM.", "published": "2025-05-30 06:23:52", "link": "http://arxiv.org/abs/2505.24255v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Interactive Video Generation via Domain Adaptation", "abstract": "Text-conditioned diffusion models have emerged as powerful tools for\nhigh-quality video generation. However, enabling Interactive Video Generation\n(IVG), where users control motion elements such as object trajectory, remains\nchallenging. Recent training-free approaches introduce attention masking to\nguide trajectory, but this often degrades perceptual quality. We identify two\nkey failure modes in these methods, both of which we interpret as domain shift\nproblems, and propose solutions inspired by domain adaptation. First, we\nattribute the perceptual degradation to internal covariate shift induced by\nattention masking, as pretrained models are not trained to handle masked\nattention. To address this, we propose mask normalization, a pre-normalization\nlayer designed to mitigate this shift via distribution matching. Second, we\naddress initialization gap, where the randomly sampled initial noise does not\nalign with IVG conditioning, by introducing a temporal intrinsic diffusion\nprior that enforces spatio-temporal consistency at each denoising step.\nExtensive qualitative and quantitative evaluations demonstrate that mask\nnormalization and temporal intrinsic denoising improve both perceptual quality\nand trajectory control over the existing state-of-the-art IVG techniques.", "published": "2025-05-30 06:19:47", "link": "http://arxiv.org/abs/2505.24253v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "cs.CV"}
{"title": "A Reward-driven Automated Webshell Malicious-code Generator for Red-teaming", "abstract": "Frequent cyber-attacks have elevated WebShell exploitation and defense to a\ncritical research focus within network security. However, there remains a\nsignificant shortage of publicly available, well-categorized malicious-code\ndatasets organized by obfuscation method. Existing malicious-code generation\nmethods, which primarily rely on prompt engineering, often suffer from limited\ndiversity and high redundancy in the payloads they produce. To address these\nlimitations, we propose \\textbf{RAWG}, a \\textbf{R}eward-driven\n\\textbf{A}utomated \\textbf{W}ebshell Malicious-code \\textbf{G}enerator designed\nfor red-teaming applications. Our approach begins by categorizing webshell\nsamples from common datasets into seven distinct types of obfuscation. We then\nemploy a large language model (LLM) to extract and normalize key tokens from\neach sample, creating a standardized, high-quality corpus. Using this curated\ndataset, we perform supervised fine-tuning (SFT) on an open-source large model\nto enable the generation of diverse, highly obfuscated webshell malicious\npayloads. To further enhance generation quality, we apply Proximal Policy\nOptimization (PPO), treating malicious-code samples as \"chosen\" data and benign\ncode as \"rejected\" data during reinforcement learning. Extensive experiments\ndemonstrate that RAWG significantly outperforms current state-of-the-art\nmethods in both payload diversity and escape effectiveness.", "published": "2025-05-30 06:16:42", "link": "http://arxiv.org/abs/2505.24252v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "AdaHuman: Animatable Detailed 3D Human Generation with Compositional Multiview Diffusion", "abstract": "Existing methods for image-to-3D avatar generation struggle to produce highly\ndetailed, animation-ready avatars suitable for real-world applications. We\nintroduce AdaHuman, a novel framework that generates high-fidelity animatable\n3D avatars from a single in-the-wild image. AdaHuman incorporates two key\ninnovations: (1) A pose-conditioned 3D joint diffusion model that synthesizes\nconsistent multi-view images in arbitrary poses alongside corresponding 3D\nGaussian Splats (3DGS) reconstruction at each diffusion step; (2) A\ncompositional 3DGS refinement module that enhances the details of local body\nparts through image-to-image refinement and seamlessly integrates them using a\nnovel crop-aware camera ray map, producing a cohesive detailed 3D avatar. These\ncomponents allow AdaHuman to generate highly realistic standardized A-pose\navatars with minimal self-occlusion, enabling rigging and animation with any\ninput motion. Extensive evaluation on public benchmarks and in-the-wild images\ndemonstrates that AdaHuman significantly outperforms state-of-the-art methods\nin both avatar reconstruction and reposing. Code and models will be publicly\navailable for research purposes.", "published": "2025-05-30 17:59:54", "link": "http://arxiv.org/abs/2505.24877v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MiniMax-Remover: Taming Bad Noise Helps Video Object Removal", "abstract": "Recent advances in video diffusion models have driven rapid progress in video\nediting techniques. However, video object removal, a critical subtask of video\nediting, remains challenging due to issues such as hallucinated objects and\nvisual artifacts. Furthermore, existing methods often rely on computationally\nexpensive sampling procedures and classifier-free guidance (CFG), resulting in\nslow inference. To address these limitations, we propose MiniMax-Remover, a\nnovel two-stage video object removal approach. Motivated by the observation\nthat text condition is not best suited for this task, we simplify the\npretrained video generation model by removing textual input and cross-attention\nlayers, resulting in a more lightweight and efficient model architecture in the\nfirst stage. In the second stage, we distilled our remover on successful videos\nproduced by the stage-1 model and curated by human annotators, using a minimax\noptimization strategy to further improve editing quality and inference speed.\nSpecifically, the inner maximization identifies adversarial input noise (\"bad\nnoise\") that makes failure removals, while the outer minimization step trains\nthe model to generate high-quality removal results even under such challenging\nconditions. As a result, our method achieves a state-of-the-art video object\nremoval results with as few as 6 sampling steps and doesn't rely on CFG,\nsignificantly improving inference efficiency. Extensive experiments demonstrate\nthe effectiveness and superiority of MiniMax-Remover compared to existing\nmethods. Codes and Videos are available at: https://minimax-remover.github.io.", "published": "2025-05-30 17:59:45", "link": "http://arxiv.org/abs/2505.24873v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GenSpace: Benchmarking Spatially-Aware Image Generation", "abstract": "Humans can intuitively compose and arrange scenes in the 3D space for\nphotography. However, can advanced AI image generators plan scenes with similar\n3D spatial awareness when creating images from text or image prompts? We\npresent GenSpace, a novel benchmark and evaluation pipeline to comprehensively\nassess the spatial awareness of current image generation models. Furthermore,\nstandard evaluations using general Vision-Language Models (VLMs) frequently\nfail to capture the detailed spatial errors. To handle this challenge, we\npropose a specialized evaluation pipeline and metric, which reconstructs 3D\nscene geometry using multiple visual foundation models and provides a more\naccurate and human-aligned metric of spatial faithfulness. Our findings show\nthat while AI models create visually appealing images and can follow general\ninstructions, they struggle with specific 3D details like object placement,\nrelationships, and measurements. We summarize three core limitations in the\nspatial perception of current state-of-the-art image generation models: 1)\nObject Perspective Understanding, 2) Egocentric-Allocentric Transformation and\n3) Metric Measurement Adherence, highlighting possible directions for improving\nspatial intelligence in image generation.", "published": "2025-05-30 17:59:26", "link": "http://arxiv.org/abs/2505.24870v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SiLVR: A Simple Language-based Video Reasoning Framework", "abstract": "Recent advances in test-time optimization have led to remarkable reasoning\ncapabilities in Large Language Models (LLMs), enabling them to solve highly\ncomplex problems in math and coding. However, the reasoning capabilities of\nmultimodal LLMs (MLLMs) still significantly lag, especially for complex\nvideo-language tasks. To address this issue, we present SiLVR, a Simple\nLanguage-based Video Reasoning framework that decomposes complex video\nunderstanding into two stages. In the first stage, SiLVR transforms raw video\ninto language-based representations using multisensory inputs, such as short\nclip captions and audio/speech subtitles. In the second stage, language\ndescriptions are fed into a powerful reasoning LLM to solve complex\nvideo-language understanding tasks. To handle long-context multisensory inputs,\nwe use an adaptive token reduction scheme, which dynamically determines the\ntemporal granularity with which to sample the tokens. Our simple, modular, and\ntraining-free video reasoning framework achieves the best-reported results on\nVideo-MME (long), Video-MMMU (comprehension), Video-MMLU, CGBench, and EgoLife.\nFurthermore, our empirical study focused on video reasoning capabilities shows\nthat, despite not being explicitly trained on video, strong reasoning LLMs can\neffectively aggregate multisensory input information from video, speech, and\naudio for complex temporal, causal, long-context, and knowledge acquisition\nreasoning tasks in video. Code is available at https://github.com/CeeZh/SILVR.", "published": "2025-05-30 17:59:19", "link": "http://arxiv.org/abs/2505.24869v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TalkingHeadBench: A Multi-Modal Benchmark & Analysis of Talking-Head DeepFake Detection", "abstract": "The rapid advancement of talking-head deepfake generation fueled by advanced\ngenerative models has elevated the realism of synthetic videos to a level that\nposes substantial risks in domains such as media, politics, and finance.\nHowever, current benchmarks for deepfake talking-head detection fail to reflect\nthis progress, relying on outdated generators and offering limited insight into\nmodel robustness and generalization. We introduce TalkingHeadBench, a\ncomprehensive multi-model multi-generator benchmark and curated dataset\ndesigned to evaluate the performance of state-of-the-art detectors on the most\nadvanced generators. Our dataset includes deepfakes synthesized by leading\nacademic and commercial models and features carefully constructed protocols to\nassess generalization under distribution shifts in identity and generator\ncharacteristics. We benchmark a diverse set of existing detection methods,\nincluding CNNs, vision transformers, and temporal models, and analyze their\nrobustness and generalization capabilities. In addition, we provide error\nanalysis using Grad-CAM visualizations to expose common failure modes and\ndetector biases. TalkingHeadBench is hosted on\nhttps://huggingface.co/datasets/luchaoqi/TalkingHeadBench with open access to\nall data splits and protocols. Our benchmark aims to accelerate research\ntowards more robust and generalizable detection models in the face of rapidly\nevolving generative techniques.", "published": "2025-05-30 17:59:08", "link": "http://arxiv.org/abs/2505.24866v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ViStoryBench: Comprehensive Benchmark Suite for Story Visualization", "abstract": "Story visualization, which aims to generate a sequence of visually coherent\nimages aligning with a given narrative and reference images, has seen\nsignificant progress with recent advancements in generative models. To further\nenhance the performance of story visualization frameworks in real-world\nscenarios, we introduce a comprehensive evaluation benchmark, ViStoryBench. We\ncollect a diverse dataset encompassing various story types and artistic styles,\nensuring models are evaluated across multiple dimensions such as different\nplots (e.g., comedy, horror) and visual aesthetics (e.g., anime, 3D\nrenderings). ViStoryBench is carefully curated to balance narrative structures\nand visual elements, featuring stories with single and multiple protagonists to\ntest models' ability to maintain character consistency. Additionally, it\nincludes complex plots and intricate world-building to challenge models in\ngenerating accurate visuals. To ensure comprehensive comparisons, our benchmark\nincorporates a wide range of evaluation metrics assessing critical aspects.\nThis structured and multifaceted framework enables researchers to thoroughly\nidentify both the strengths and weaknesses of different models, fostering\ntargeted improvements.", "published": "2025-05-30 17:58:21", "link": "http://arxiv.org/abs/2505.24862v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reading Recognition in the Wild", "abstract": "To enable egocentric contextual AI in always-on smart glasses, it is crucial\nto be able to keep a record of the user's interactions with the world,\nincluding during reading. In this paper, we introduce a new task of reading\nrecognition to determine when the user is reading. We first introduce the\nfirst-of-its-kind large-scale multimodal Reading in the Wild dataset,\ncontaining 100 hours of reading and non-reading videos in diverse and realistic\nscenarios. We then identify three modalities (egocentric RGB, eye gaze, head\npose) that can be used to solve the task, and present a flexible transformer\nmodel that performs the task using these modalities, either individually or\ncombined. We show that these modalities are relevant and complementary to the\ntask, and investigate how to efficiently and effectively encode each modality.\nAdditionally, we show the usefulness of this dataset towards classifying types\nof reading, extending current reading understanding studies conducted in\nconstrained settings to larger scale, diversity and realism. Code, model, and\ndata will be public.", "published": "2025-05-30 17:46:13", "link": "http://arxiv.org/abs/2505.24848v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Zero-Shot Chinese Character Recognition with Hierarchical Multi-Granularity Image-Text Aligning", "abstract": "Chinese Character Recognition (CCR) is a fundamental technology for\nintelligent document processing. Unlike Latin characters, Chinese characters\nexhibit unique spatial structures and compositional rules, allowing for the use\nof fine-grained semantic information in representation. However, existing\napproaches are usually based on auto-regressive as well as edit distance\npost-process and typically rely on a single-level character representation. In\nthis paper, we propose a Hierarchical Multi-Granularity Image-Text Aligning\n(Hi-GITA) framework based on a contrastive paradigm. To leverage the abundant\nfine-grained semantic information of Chinese characters, we propose\nmulti-granularity encoders on both image and text sides. Specifically, the\nImage Multi-Granularity Encoder extracts hierarchical image representations\nfrom character images, capturing semantic cues from localized strokes to\nholistic structures. The Text Multi-Granularity Encoder extracts stroke and\nradical sequence representations at different levels of granularity. To better\ncapture the relationships between strokes and radicals, we introduce\nMulti-Granularity Fusion Modules on the image and text sides, respectively.\nFurthermore, to effectively bridge the two modalities, we further introduce a\nFine-Grained Decoupled Image-Text Contrastive loss, which aligns image and text\nrepresentations across multiple granularities. Extensive experiments\ndemonstrate that our proposed Hi-GITA significantly outperforms existing\nzero-shot CCR methods. For instance, it brings about 20% accuracy improvement\nin handwritten character and radical zero-shot settings. Code and models will\nbe released soon.", "published": "2025-05-30 17:39:14", "link": "http://arxiv.org/abs/2505.24837v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Segmenting France Across Four Centuries", "abstract": "Historical maps offer an invaluable perspective into territory evolution\nacross past centuries--long before satellite or remote sensing technologies\nexisted. Deep learning methods have shown promising results in segmenting\nhistorical maps, but publicly available datasets typically focus on a single\nmap type or period, require extensive and costly annotations, and are not\nsuited for nationwide, long-term analyses. In this paper, we introduce a new\ndataset of historical maps tailored for analyzing large-scale, long-term land\nuse and land cover evolution with limited annotations. Spanning metropolitan\nFrance (548,305 km^2), our dataset contains three map collections from the\n18th, 19th, and 20th centuries. We provide both comprehensive modern labels and\n22,878 km^2 of manually annotated historical labels for the 18th and 19th\ncentury maps. Our dataset illustrates the complexity of the segmentation task,\nfeaturing stylistic inconsistencies, interpretive ambiguities, and significant\nlandscape changes (e.g., marshlands disappearing in favor of forests). We\nassess the difficulty of these challenges by benchmarking three approaches: a\nfully-supervised model trained with historical labels, and two\nweakly-supervised models that rely only on modern annotations. The latter\neither use the modern labels directly or first perform image-to-image\ntranslation to address the stylistic gap between historical and contemporary\nmaps. Finally, we discuss how these methods can support long-term environment\nmonitoring, offering insights into centuries of landscape transformation. Our\nofficial project repository is publicly available at\nhttps://github.com/Archiel19/FRAx4.git.", "published": "2025-05-30 17:26:52", "link": "http://arxiv.org/abs/2505.24824v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Bi-Manual Joint Camera Calibration and Scene Representation", "abstract": "Robot manipulation, especially bimanual manipulation, often requires setting\nup multiple cameras on multiple robot manipulators. Before robot manipulators\ncan generate motion or even build representations of their environments, the\ncameras rigidly mounted to the robot need to be calibrated. Camera calibration\nis a cumbersome process involving collecting a set of images, with each\ncapturing a pre-determined marker. In this work, we introduce the Bi-Manual\nJoint Calibration and Representation Framework (Bi-JCR). Bi-JCR enables\nmultiple robot manipulators, each with cameras mounted, to circumvent taking\nimages of calibration markers. By leveraging 3D foundation models for dense,\nmarker-free multi-view correspondence, Bi-JCR jointly estimates: (i) the\nextrinsic transformation from each camera to its end-effector, (ii) the\ninter-arm relative poses between manipulators, and (iii) a unified,\nscale-consistent 3D representation of the shared workspace, all from the same\ncaptured RGB image sets. The representation, jointly constructed from images\ncaptured by cameras on both manipulators, lives in a common coordinate frame\nand supports collision checking and semantic segmentation to facilitate\ndownstream bimanual coordination tasks. We empirically evaluate the robustness\nof Bi-JCR on a variety of tabletop environments, and demonstrate its\napplicability on a variety of downstream tasks.", "published": "2025-05-30 17:22:00", "link": "http://arxiv.org/abs/2505.24819v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning", "abstract": "Class-Incremental Learning (CIL) aims to learn new classes sequentially while\nretaining the knowledge of previously learned classes. Recently, pre-trained\nmodels (PTMs) combined with parameter-efficient fine-tuning (PEFT) have shown\nremarkable performance in rehearsal-free CIL without requiring exemplars from\nprevious tasks. However, existing adapter-based methods, which incorporate\nlightweight learnable modules into PTMs for CIL, create new adapters for each\nnew task, leading to both parameter redundancy and failure to leverage shared\nknowledge across tasks. In this work, we propose ContinuaL Low-Rank Adaptation\n(CL-LoRA), which introduces a novel dual-adapter architecture combining\n\\textbf{task-shared adapters} to learn cross-task knowledge and\n\\textbf{task-specific adapters} to capture unique features of each new task.\nSpecifically, the shared adapters utilize random orthogonal matrices and\nleverage knowledge distillation with gradient reassignment to preserve\nessential shared knowledge. In addition, we introduce learnable block-wise\nweights for task-specific adapters, which mitigate inter-task interference\nwhile maintaining the model's plasticity. We demonstrate CL-LoRA consistently\nachieves promising performance under multiple benchmarks with reduced training\nand inference computation, establishing a more efficient and scalable paradigm\nfor continual learning with pre-trained models.", "published": "2025-05-30 17:19:52", "link": "http://arxiv.org/abs/2505.24816v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Pretty Pictures: Combined Single- and Multi-Image Super-resolution for Sentinel-2 Images", "abstract": "Super-resolution aims to increase the resolution of satellite images by\nreconstructing high-frequency details, which go beyond na\\\"ive upsampling. This\nhas particular relevance for Earth observation missions like Sentinel-2, which\noffer frequent, regular coverage at no cost; but at coarse resolution. Its\npixel footprint is too large to capture small features like houses, streets, or\nhedge rows. To address this, we present SEN4X, a hybrid super-resolution\narchitecture that combines the advantages of single-image and multi-image\ntechniques. It combines temporal oversampling from repeated Sentinel-2\nacquisitions with a learned prior from high-resolution Pl\\'eiades Neo data. In\ndoing so, SEN4X upgrades Sentinel-2 imagery to 2.5 m ground sampling distance.\nWe test the super-resolved images on urban land-cover classification in Hanoi,\nVietnam. We find that they lead to a significant performance improvement over\nstate-of-the-art super-resolution baselines.", "published": "2025-05-30 17:02:56", "link": "http://arxiv.org/abs/2505.24799v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "TC-GS: A Faster Gaussian Splatting Module Utilizing Tensor Cores", "abstract": "3D Gaussian Splatting (3DGS) renders pixels by rasterizing Gaussian\nprimitives, where conditional alpha-blending dominates the time cost in the\nrendering pipeline. This paper proposes TC-GS, an algorithm-independent\nuniversal module that expands Tensor Core (TCU) applicability for 3DGS, leading\nto substantial speedups and seamless integration into existing 3DGS\noptimization frameworks. The key innovation lies in mapping alpha computation\nto matrix multiplication, fully utilizing otherwise idle TCUs in existing 3DGS\nimplementations. TC-GS provides plug-and-play acceleration for existing\ntop-tier acceleration algorithms tightly coupled with rendering pipeline\ndesigns, like Gaussian compression and redundancy elimination algorithms.\nAdditionally, we introduce a global-to-local coordinate transformation to\nmitigate rounding errors from quadratic terms of pixel coordinates caused by\nTensor Core half-precision computation. Extensive experiments demonstrate that\nour method maintains rendering quality while providing an additional 2.18x\nspeedup over existing Gaussian acceleration algorithms, thus reaching up to a\ntotal 5.6x acceleration. The code is currently available at anonymous\n\\href{https://github.com/TensorCore3DGS/3DGSTensorCore}", "published": "2025-05-30 16:58:18", "link": "http://arxiv.org/abs/2505.24796v1", "categories": ["cs.GR", "cs.CV", "cs.DC", "I.3.6; I.3.2; D.1.3"], "primary_category": "cs.GR"}
{"title": "Lightweight Relational Embedding in Task-Interpolated Few-Shot Networks for Enhanced Gastrointestinal Disease Classification", "abstract": "Traditional diagnostic methods like colonoscopy are invasive yet critical\ntools necessary for accurately diagnosing colorectal cancer (CRC). Detection of\nCRC at early stages is crucial for increasing patient survival rates. However,\ncolonoscopy is dependent on obtaining adequate and high-quality endoscopic\nimages. Prolonged invasive procedures are inherently risky for patients, while\nsuboptimal or insufficient images hamper diagnostic accuracy. These images,\ntypically derived from video frames, often exhibit similar patterns, posing\nchallenges in discrimination. To overcome these challenges, we propose a novel\nDeep Learning network built on a Few-Shot Learning architecture, which includes\na tailored feature extractor, task interpolation, relational embedding, and a\nbi-level routing attention mechanism. The Few-Shot Learning paradigm enables\nour model to rapidly adapt to unseen fine-grained endoscopic image patterns,\nand the task interpolation augments the insufficient images artificially from\nvaried instrument viewpoints. Our relational embedding approach discerns\ncritical intra-image features and captures inter-image transitions between\nconsecutive endoscopic frames, overcoming the limitations of Convolutional\nNeural Networks (CNNs). The integration of a light-weight attention mechanism\nensures a concentrated analysis of pertinent image regions. By training on\ndiverse datasets, the model's generalizability and robustness are notably\nimproved for handling endoscopic images. Evaluated on Kvasir dataset, our model\ndemonstrated superior performance, achieving an accuracy of 90.1\\%, precision\nof 0.845, recall of 0.942, and an F1 score of 0.891. This surpasses current\nstate-of-the-art methods, presenting a promising solution to the challenges of\ninvasive colonoscopy by optimizing CRC detection through advanced image\nanalysis.", "published": "2025-05-30 16:54:51", "link": "http://arxiv.org/abs/2505.24792v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient Estimation of Regularized Tyler's M-Estimator Using Approximate LOOCV", "abstract": "We consider the problem of estimating a regularization parameter, or a\nshrinkage coefficient $\\alpha \\in (0,1)$ for Regularized Tyler's M-estimator\n(RTME). In particular, we propose to estimate an optimal shrinkage coefficient\nby setting $\\alpha$ as the solution to a suitably chosen objective function;\nnamely the leave-one-out cross-validated (LOOCV) log-likelihood loss. Since\nLOOCV is computationally prohibitive even for moderate sample size $n$, we\npropose a computationally efficient approximation for the LOOCV log-likelihood\nloss that eliminates the need for invoking the RTME procedure $n$ times for\neach sample left out during the LOOCV procedure. This approximation yields an\n$O(n)$ reduction in the running time complexity for the LOOCV procedure, which\nresults in a significant speedup for computing the LOOCV estimate. We\ndemonstrate the efficiency and accuracy of the proposed approach on synthetic\nhigh-dimensional data sampled from heavy-tailed elliptical distributions, as\nwell as on real high-dimensional datasets for object recognition, face\nrecognition, and handwritten digit's recognition. Our experiments show that the\nproposed approach is efficient and consistently more accurate than other\nmethods in the literature for shrinkage coefficient estimation.", "published": "2025-05-30 16:43:14", "link": "http://arxiv.org/abs/2505.24781v1", "categories": ["stat.ML", "cs.CE", "cs.CV", "cs.LG", "eess.SP", "I.2.0; I.2.6"], "primary_category": "stat.ML"}
{"title": "Tackling View-Dependent Semantics in 3D Language Gaussian Splatting", "abstract": "Recent advancements in 3D Gaussian Splatting (3D-GS) enable high-quality 3D\nscene reconstruction from RGB images. Many studies extend this paradigm for\nlanguage-driven open-vocabulary scene understanding. However, most of them\nsimply project 2D semantic features onto 3D Gaussians and overlook a\nfundamental gap between 2D and 3D understanding: a 3D object may exhibit\nvarious semantics from different viewpoints--a phenomenon we term\nview-dependent semantics. To address this challenge, we propose LaGa (Language\nGaussians), which establishes cross-view semantic connections by decomposing\nthe 3D scene into objects. Then, it constructs view-aggregated semantic\nrepresentations by clustering semantic descriptors and reweighting them based\non multi-view semantics. Extensive experiments demonstrate that LaGa\neffectively captures key information from view-dependent semantics, enabling a\nmore comprehensive understanding of 3D scenes. Notably, under the same\nsettings, LaGa achieves a significant improvement of +18.7% mIoU over the\nprevious SOTA on the LERF-OVS dataset. Our code is available at:\nhttps://github.com/SJTU-DeepVisionLab/LaGa.", "published": "2025-05-30 16:06:32", "link": "http://arxiv.org/abs/2505.24746v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Contrast-Invariant Self-supervised Segmentation for Quantitative Placental MRI", "abstract": "Accurate placental segmentation is essential for quantitative analysis of the\nplacenta. However, this task is particularly challenging in T2*-weighted\nplacental imaging due to: (1) weak and inconsistent boundary contrast across\nindividual echoes; (2) the absence of manual ground truth annotations for all\necho times; and (3) motion artifacts across echoes caused by fetal and maternal\nmovement. In this work, we propose a contrast-augmented segmentation framework\nthat leverages complementary information across multi-echo T2*-weighted MRI to\nlearn robust, contrast-invariant representations. Our method integrates: (i)\nmasked autoencoding (MAE) for self-supervised pretraining on unlabeled\nmulti-echo slices; (ii) masked pseudo-labeling (MPL) for unsupervised domain\nadaptation across echo times; and (iii) global-local collaboration to align\nfine-grained features with global anatomical context. We further introduce a\nsemantic matching loss to encourage representation consistency across echoes of\nthe same subject. Experiments on a clinical multi-echo placental MRI dataset\ndemonstrate that our approach generalizes effectively across echo times and\noutperforms both single-echo and naive fusion baselines. To our knowledge, this\nis the first work to systematically exploit multi-echo T2*-weighted MRI for\nplacental segmentation.", "published": "2025-05-30 15:58:14", "link": "http://arxiv.org/abs/2505.24739v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "DreamDance: Animating Character Art via Inpainting Stable Gaussian Worlds", "abstract": "This paper presents DreamDance, a novel character art animation framework\ncapable of producing stable, consistent character and scene motion conditioned\non precise camera trajectories. To achieve this, we re-formulate the animation\ntask as two inpainting-based steps: Camera-aware Scene Inpainting and\nPose-aware Video Inpainting. The first step leverages a pre-trained image\ninpainting model to generate multi-view scene images from the reference art and\noptimizes a stable large-scale Gaussian field, which enables coarse background\nvideo rendering with camera trajectories. However, the rendered video is rough\nand only conveys scene motion. To resolve this, the second step trains a\npose-aware video inpainting model that injects the dynamic character into the\nscene video while enhancing background quality. Specifically, this model is a\nDiT-based video generation model with a gating strategy that adaptively\nintegrates the character's appearance and pose information into the base\nbackground video. Through extensive experiments, we demonstrate the\neffectiveness and generalizability of DreamDance, producing high-quality and\nconsistent character animations with remarkable camera dynamics.", "published": "2025-05-30 15:54:34", "link": "http://arxiv.org/abs/2505.24733v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reinforcing Video Reasoning with Focused Thinking", "abstract": "Recent advancements in reinforcement learning, particularly through Group\nRelative Policy Optimization (GRPO), have significantly improved multimodal\nlarge language models for complex reasoning tasks. However, two critical\nlimitations persist: 1) they often produce unfocused, verbose reasoning chains\nthat obscure salient spatiotemporal cues and 2) binary rewarding fails to\naccount for partially correct answers, resulting in high reward variance and\ninefficient learning. In this paper, we propose TW-GRPO, a novel framework that\nenhances visual reasoning with focused thinking and dense reward granularity.\nSpecifically, we employs a token weighting mechanism that prioritizes tokens\nwith high informational density (estimated by intra-group variance),\nsuppressing redundant tokens like generic reasoning prefixes. Furthermore, we\nreformulate RL training by shifting from single-choice to multi-choice QA\ntasks, where soft rewards enable finer-grained gradient estimation by\ndistinguishing partial correctness. Additionally, we propose question-answer\ninversion, a data augmentation strategy to generate diverse multi-choice\nsamples from existing benchmarks. Experiments demonstrate state-of-the-art\nperformance on several video reasoning and general understanding benchmarks.\nNotably, TW-GRPO achieves 50.4\\% accuracy on CLEVRER (18.8\\% improvement over\nVideo-R1) and 65.8\\% on MMVU. Our codes are available at\n\\href{https://github.com/longmalongma/TW-GRPO}{https://github.com/longmalongma/TW-GRPO}.", "published": "2025-05-30 15:42:19", "link": "http://arxiv.org/abs/2505.24718v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RT-X Net: RGB-Thermal cross attention network for Low-Light Image Enhancement", "abstract": "In nighttime conditions, high noise levels and bright illumination sources\ndegrade image quality, making low-light image enhancement challenging. Thermal\nimages provide complementary information, offering richer textures and\nstructural details. We propose RT-X Net, a cross-attention network that fuses\nRGB and thermal images for nighttime image enhancement. We leverage\nself-attention networks for feature extraction and a cross-attention mechanism\nfor fusion to effectively integrate information from both modalities. To\nsupport research in this domain, we introduce the Visible-Thermal Image\nEnhancement Evaluation (V-TIEE) dataset, comprising 50 co-located visible and\nthermal images captured under diverse nighttime conditions. Extensive\nevaluations on the publicly available LLVIP dataset and our V-TIEE dataset\ndemonstrate that RT-X Net outperforms state-of-the-art methods in low-light\nimage enhancement. The code and the V-TIEE can be found here\nhttps://github.com/jhakrraman/rt-xnet.", "published": "2025-05-30 15:26:58", "link": "http://arxiv.org/abs/2505.24705v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches", "abstract": "Deep learning techniques have enabled vast improvements in computer vision\ntechnologies. Nevertheless, these models are vulnerable to adversarial patch\nattacks which catastrophically impair performance. The physically realizable\nnature of these attacks calls for certifiable defenses, which feature provable\nguarantees on robustness. While certifiable defenses have been successfully\napplied to single-label classification, limited work has been done for\nmulti-label classification. In this work, we present PatchDEMUX, a certifiably\nrobust framework for multi-label classifiers against adversarial patches. Our\napproach is a generalizable method which can extend any existing certifiable\ndefense for single-label classification; this is done by considering the\nmulti-label classification task as a series of isolated binary classification\nproblems to provably guarantee robustness. Furthermore, in the scenario where\nan attacker is limited to a single patch we propose an additional certification\nprocedure that can provide tighter robustness bounds. Using the current\nstate-of-the-art (SOTA) single-label certifiable defense PatchCleanser as a\nbackbone, we find that PatchDEMUX can achieve non-trivial robustness on the\nMS-COCO and PASCAL VOC datasets while maintaining high clean performance", "published": "2025-05-30 15:25:51", "link": "http://arxiv.org/abs/2505.24703v1", "categories": ["cs.CR", "cs.CV", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Conformal Prediction for Zero-Shot Models", "abstract": "Vision-language models pre-trained at large scale have shown unprecedented\nadaptability and generalization to downstream tasks. Although its\ndiscriminative potential has been widely explored, its reliability and\nuncertainty are still overlooked. In this work, we investigate the capabilities\nof CLIP models under the split conformal prediction paradigm, which provides\ntheoretical guarantees to black-box models based on a small, labeled\ncalibration set. In contrast to the main body of literature on conformal\npredictors in vision classifiers, foundation models exhibit a particular\ncharacteristic: they are pre-trained on a one-time basis on an inaccessible\nsource domain, different from the transferred task. This domain drift\nnegatively affects the efficiency of the conformal sets and poses additional\nchallenges. To alleviate this issue, we propose Conf-OT, a transfer learning\nsetting that operates transductive over the combined calibration and query\nsets. Solving an optimal transport problem, the proposed method bridges the\ndomain gap between pre-training and adaptation without requiring additional\ndata splits but still maintaining coverage guarantees. We comprehensively\nexplore this conformal prediction strategy on a broad span of 15 datasets and\nthree non-conformity scores. Conf-OT provides consistent relative improvements\nof up to 20% on set efficiency while being 15 times faster than popular\ntransductive approaches.", "published": "2025-05-30 15:16:19", "link": "http://arxiv.org/abs/2505.24693v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning reusable concepts across different egocentric video understanding tasks", "abstract": "Our comprehension of video streams depicting human activities is naturally\nmultifaceted: in just a few moments, we can grasp what is happening, identify\nthe relevance and interactions of objects in the scene, and forecast what will\nhappen soon, everything all at once. To endow autonomous systems with such\nholistic perception, learning how to correlate concepts, abstract knowledge\nacross diverse tasks, and leverage tasks synergies when learning novel skills\nis essential. In this paper, we introduce Hier-EgoPack, a unified framework\nable to create a collection of task perspectives that can be carried across\ndownstream tasks and used as a potential source of additional insights, as a\nbackpack of skills that a robot can carry around and use when needed.", "published": "2025-05-30 15:14:46", "link": "http://arxiv.org/abs/2505.24690v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TumorGen: Boundary-Aware Tumor-Mask Synthesis with Rectified Flow Matching", "abstract": "Tumor data synthesis offers a promising solution to the shortage of annotated\nmedical datasets. However, current approaches either limit tumor diversity by\nusing predefined masks or employ computationally expensive two-stage processes\nwith multiple denoising steps, causing computational inefficiency.\nAdditionally, these methods typically rely on binary masks that fail to capture\nthe gradual transitions characteristic of tumor boundaries. We present\nTumorGen, a novel Boundary-Aware Tumor-Mask Synthesis with Rectified Flow\nMatching for efficient 3D tumor synthesis with three key components: a\nBoundary-Aware Pseudo Mask Generation module that replaces strict binary masks\nwith flexible bounding boxes; a Spatial-Constraint Vector Field Estimator that\nsimultaneously synthesizes tumor latents and masks using rectified flow\nmatching to ensure computational efficiency; and a VAE-guided mask refiner that\nenhances boundary realism. TumorGen significantly improves computational\nefficiency by requiring fewer sampling steps while maintaining pathological\naccuracy through coarse and fine-grained spatial constraints. Experimental\nresults demonstrate TumorGen's superior performance over existing tumor\nsynthesis methods in both efficiency and realism, offering a valuable\ncontribution to AI-driven cancer diagnostics.", "published": "2025-05-30 15:11:25", "link": "http://arxiv.org/abs/2505.24687v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Beyond FACS: Data-driven Facial Expression Dictionaries, with Application to Predicting Autism", "abstract": "The Facial Action Coding System (FACS) has been used by numerous studies to\ninvestigate the links between facial behavior and mental health. The laborious\nand costly process of FACS coding has motivated the development of machine\nlearning frameworks for Action Unit (AU) detection. Despite intense efforts\nspanning three decades, the detection accuracy for many AUs is considered to be\nbelow the threshold needed for behavioral research. Also, many AUs are excluded\naltogether, making it impossible to fulfill the ultimate goal of FACS-the\nrepresentation of any facial expression in its entirety. This paper considers\nan alternative approach. Instead of creating automated tools that mimic FACS\nexperts, we propose to use a new coding system that mimics the key properties\nof FACS. Specifically, we construct a data-driven coding system called the\nFacial Basis, which contains units that correspond to localized and\ninterpretable 3D facial movements, and overcomes three structural limitations\nof automated FACS coding. First, the proposed method is completely\nunsupervised, bypassing costly, laborious and variable manual annotation.\nSecond, Facial Basis reconstructs all observable movement, rather than relying\non a limited repertoire of recognizable movements (as in automated FACS).\nFinally, the Facial Basis units are additive, whereas AUs may fail detection\nwhen they appear in a non-additive combination. The proposed method outperforms\nthe most frequently used AU detector in predicting autism diagnosis from\nin-person and remote conversations, highlighting the importance of encoding\nfacial behavior comprehensively. To our knowledge, Facial Basis is the first\nalternative to FACS for deconstructing facial expressions in videos into\nlocalized movements. We provide an open source implementation of the method at\ngithub.com/sariyanidi/FacialBasis.", "published": "2025-05-30 15:06:01", "link": "http://arxiv.org/abs/2505.24679v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "6D Pose Estimation on Point Cloud Data through Prior Knowledge Integration: A Case Study in Autonomous Disassembly", "abstract": "The accurate estimation of 6D pose remains a challenging task within the\ncomputer vision domain, even when utilizing 3D point cloud data. Conversely, in\nthe manufacturing domain, instances arise where leveraging prior knowledge can\nyield advancements in this endeavor. This study focuses on the disassembly of\nstarter motors to augment the engineering of product life cycles. A pivotal\nobjective in this context involves the identification and 6D pose estimation of\nbolts affixed to the motors, facilitating automated disassembly within the\nmanufacturing workflow. Complicating matters, the presence of occlusions and\nthe limitations of single-view data acquisition, notably when motors are placed\nin a clamping system, obscure certain portions and render some bolts\nimperceptible. Consequently, the development of a comprehensive pipeline\ncapable of acquiring complete bolt information is imperative to avoid oversight\nin bolt detection. In this paper, employing the task of bolt detection within\nthe scope of our project as a pertinent use case, we introduce a meticulously\ndevised pipeline. This multi-stage pipeline effectively captures the 6D\ninformation with regard to all bolts on the motor, thereby showcasing the\neffective utilization of prior knowledge in handling this challenging task. The\nproposed methodology not only contributes to the field of 6D pose estimation\nbut also underscores the viability of integrating domain-specific insights to\ntackle complex problems in manufacturing and automation.", "published": "2025-05-30 14:58:04", "link": "http://arxiv.org/abs/2505.24669v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Decoupled Competitive Framework for Semi-supervised Medical Image Segmentation", "abstract": "Confronting the critical challenge of insufficiently annotated samples in\nmedical domain, semi-supervised medical image segmentation (SSMIS) emerges as a\npromising solution. Specifically, most methodologies following the Mean Teacher\n(MT) or Dual Students (DS) architecture have achieved commendable results.\nHowever, to date, these approaches face a performance bottleneck due to two\ninherent limitations, \\textit{e.g.}, the over-coupling problem within MT\nstructure owing to the employment of exponential moving average (EMA)\nmechanism, as well as the severe cognitive bias between two students of DS\nstructure, both of which potentially lead to reduced efficacy, or even model\ncollapse eventually. To mitigate these issues, a Decoupled Competitive\nFramework (DCF) is elaborated in this work, which utilizes a straightforward\ncompetition mechanism for the update of EMA, effectively decoupling students\nand teachers in a dynamical manner. In addition, the seamless exchange of\ninvaluable and precise insights is facilitated among students, guaranteeing a\nbetter learning paradigm. The DCF introduced undergoes rigorous validation on\nthree publicly accessible datasets, which encompass both 2D and 3D datasets.\nThe results demonstrate the superiority of our method over previous\ncutting-edge competitors. Code will be available at\nhttps://github.com/JiaheChen2002/DCF.", "published": "2025-05-30 14:56:00", "link": "http://arxiv.org/abs/2505.24667v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Black-box Adversarial Attacks on CNN-based SLAM Algorithms", "abstract": "Continuous advancements in deep learning have led to significant progress in\nfeature detection, resulting in enhanced accuracy in tasks like Simultaneous\nLocalization and Mapping (SLAM). Nevertheless, the vulnerability of deep neural\nnetworks to adversarial attacks remains a challenge for their reliable\ndeployment in applications, such as navigation of autonomous agents. Even\nthough CNN-based SLAM algorithms are a growing area of research there is a\nnotable absence of a comprehensive presentation and examination of adversarial\nattacks targeting CNN-based feature detectors, as part of a SLAM system. Our\nwork introduces black-box adversarial perturbations applied to the RGB images\nfed into the GCN-SLAM algorithm. Our findings on the TUM dataset [30] reveal\nthat even attacks of moderate scale can lead to tracking failure in as many as\n76% of the frames. Moreover, our experiments highlight the catastrophic impact\nof attacking depth instead of RGB input images on the SLAM system.", "published": "2025-05-30 14:41:38", "link": "http://arxiv.org/abs/2505.24654v1", "categories": ["cs.RO", "cs.CV", "68T40, 68T45, 68M25,"], "primary_category": "cs.RO"}
{"title": "A Cross Branch Fusion-Based Contrastive Learning Framework for Point Cloud Self-supervised Learning", "abstract": "Contrastive learning is an essential method in self-supervised learning. It\nprimarily employs a multi-branch strategy to compare latent representations\nobtained from different branches and train the encoder. In the case of\nmulti-modal input, diverse modalities of the same object are fed into distinct\nbranches. When using single-modal data, the same input undergoes various\naugmentations before being fed into different branches. However, all existing\ncontrastive learning frameworks have so far only performed contrastive\noperations on the learned features at the final loss end, with no information\nexchange between different branches prior to this stage. In this paper, for\npoint cloud unsupervised learning without the use of extra training data, we\npropose a Contrastive Cross-branch Attention-based framework for Point cloud\ndata (termed PoCCA), to learn rich 3D point cloud representations. By\nintroducing sub-branches, PoCCA allows information exchange between different\nbranches before the loss end. Experimental results demonstrate that in the case\nof using no extra training data, the representations learned with our\nself-supervised model achieve state-of-the-art performances when used for\ndownstream tasks on point clouds.", "published": "2025-05-30 14:28:06", "link": "http://arxiv.org/abs/2505.24641v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Category-Level 6D Object Pose Estimation in Agricultural Settings Using a Lattice-Deformation Framework and Diffusion-Augmented Synthetic Data", "abstract": "Accurate 6D object pose estimation is essential for robotic grasping and\nmanipulation, particularly in agriculture, where fruits and vegetables exhibit\nhigh intra-class variability in shape, size, and texture. The vast majority of\nexisting methods rely on instance-specific CAD models or require depth sensors\nto resolve geometric ambiguities, making them impractical for real-world\nagricultural applications. In this work, we introduce PLANTPose, a novel\nframework for category-level 6D pose estimation that operates purely on RGB\ninput. PLANTPose predicts both the 6D pose and deformation parameters relative\nto a base mesh, allowing a single category-level CAD model to adapt to unseen\ninstances. This enables accurate pose estimation across varying shapes without\nrelying on instance-specific data. To enhance realism and improve\ngeneralization, we also leverage Stable Diffusion to refine synthetic training\nimages with realistic texturing, mimicking variations due to ripeness and\nenvironmental factors and bridging the domain gap between synthetic data and\nthe real world. Our evaluations on a challenging benchmark that includes\nbananas of various shapes, sizes, and ripeness status demonstrate the\neffectiveness of our framework in handling large intraclass variations while\nmaintaining accurate 6D pose predictions, significantly outperforming the\nstate-of-the-art RGB-based approach MegaPose.", "published": "2025-05-30 14:25:52", "link": "http://arxiv.org/abs/2505.24636v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation", "abstract": "LiDAR semantic segmentation plays a vital role in autonomous driving.\nExisting voxel-based methods for LiDAR semantic segmentation apply uniform\npartition to the 3D LiDAR point cloud to form a structured representation based\non cartesian/cylindrical coordinates. Although these methods show impressive\nperformance, the drawback of existing voxel-based methods remains in two\naspects: (1) it requires a large enough input voxel resolution, which brings a\nlarge amount of computation cost and memory consumption. (2) it does not well\nhandle the unbalanced point distribution of LiDAR point cloud. In this paper,\nwe propose a non-uniform cylindrical partition network named NUC-Net to tackle\nthe above challenges. Specifically, we propose the Arithmetic Progression of\nInterval (API) method to non-uniformly partition the radial axis and generate\nthe voxel representation which is representative and efficient. Moreover, we\npropose a non-uniform multi-scale aggregation method to improve contextual\ninformation. Our method achieves state-of-the-art performance on SemanticKITTI\nand nuScenes datasets with much faster speed and much less training time. And\nour method can be a general component for LiDAR semantic segmentation, which\nsignificantly improves both the accuracy and efficiency of the uniform\ncounterpart by $4 \\times$ training faster and $2 \\times$ GPU memory reduction\nand $3 \\times$ inference speedup. We further provide theoretical analysis\ntowards understanding why NUC is effective and how point distribution affects\nperformance. Code is available at\n\\href{https://github.com/alanWXZ/NUC-Net}{https://github.com/alanWXZ/NUC-Net}.", "published": "2025-05-30 14:25:32", "link": "http://arxiv.org/abs/2505.24634v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GARLIC: GAussian Representation LearnIng for spaCe partitioning", "abstract": "We introduce GARLIC (GAussian Representation LearnIng for spaCe\npartitioning), a novel indexing structure based on \\(N\\)-dimensional Gaussians\nfor efficiently learning high-dimensional vector spaces. Our approach is\ninspired from Gaussian splatting techniques, typically used in 3D rendering,\nwhich we adapt for high-dimensional search and classification. We optimize\nGaussian parameters using information-theoretic objectives that balance\ncoverage, assignment confidence, and structural and semantic consistency. A key\ncontribution is to progressively refine the representation through split and\nclone operations, handling hundreds of dimensions, thus handling varying data\ndensities. GARLIC offers the fast building times of traditional space\npartitioning methods (e.g., under \\(\\sim5\\) min build time for SIFT1M) while\nachieving \\(\\sim50\\%\\) Recall10@10 in low-candidate regimes. Experimental\nresults on standard benchmarks demonstrate our method's consistency in (a)\n\\(k\\)-NN retrieval, outperforming methods, such as Faiss-IVF, in fast-recall by\nusing about half their probes for the same Recall10@10 in Fashion-MNIST, and\n(b) in classification tasks, beating by \\(\\sim15\\%\\) accuracy other majority\nvoting methods. Further, we show strong generalization capabilities,\nmaintaining high accuracy even with downsampled training data: using just\n\\(1\\%\\) of the training data returns \\(\\sim 45\\%\\) Recall@1, thus making GARLIC\nquite powerful for applications requiring both speed and accuracy.", "published": "2025-05-30 13:55:54", "link": "http://arxiv.org/abs/2505.24608v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Model-Guided Network with Cluster-Based Operators for Spatio-Spectral Super-Resolution", "abstract": "This paper addresses the problem of reconstructing a high-resolution\nhyperspectral image from a low-resolution multispectral observation. While\nspatial super-resolution and spectral super-resolution have been extensively\nstudied, joint spatio-spectral super-resolution remains relatively explored. We\npropose an end-to-end model-driven framework that explicitly decomposes the\njoint spatio-spectral super-resolution problem into spatial super-resolution,\nspectral super-resolution and fusion tasks. Each sub-task is addressed by\nunfolding a variational-based approach, where the operators involved in the\nproximal gradient iterative scheme are replaced with tailored learnable\nmodules. In particular, we design an upsampling operator for spatial\nsuper-resolution based on classical back-projection algorithms, adapted to\nhandle arbitrary scaling factors. Spectral reconstruction is performed using\nlearnable cluster-based upsampling and downsampling operators. For image\nfusion, we integrate low-frequency estimation and high-frequency injection\nmodules to combine the spatial and spectral information from spatial\nsuper-resolution and spectral super-resolution outputs. Additionally, we\nintroduce an efficient nonlocal post-processing step that leverages image\nself-similarity by combining a multi-head attention mechanism with residual\nconnections. Extensive evaluations on several datasets and sampling factors\ndemonstrate the effectiveness of our approach. The source code will be\navailable at https://github.com/TAMI-UIB/JSSUNet", "published": "2025-05-30 13:54:47", "link": "http://arxiv.org/abs/2505.24605v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "SARD: A Large-Scale Synthetic Arabic OCR Dataset for Book-Style Text Recognition", "abstract": "Arabic Optical Character Recognition (OCR) is essential for converting vast\namounts of Arabic print media into digital formats. However, training modern\nOCR models, especially powerful vision-language models, is hampered by the lack\nof large, diverse, and well-structured datasets that mimic real-world book\nlayouts. Existing Arabic OCR datasets often focus on isolated words or lines or\nare limited in scale, typographic variety, or structural complexity found in\nbooks. To address this significant gap, we introduce SARD (Large-Scale\nSynthetic Arabic OCR Dataset). SARD is a massive, synthetically generated\ndataset specifically designed to simulate book-style documents. It comprises\n843,622 document images containing 690 million words, rendered across ten\ndistinct Arabic fonts to ensure broad typographic coverage. Unlike datasets\nderived from scanned documents, SARD is free from real-world noise and\ndistortions, offering a clean and controlled environment for model training.\nIts synthetic nature provides unparalleled scalability and allows for precise\ncontrol over layout and content variation. We detail the dataset's composition\nand generation process and provide benchmark results for several OCR models,\nincluding traditional and deep learning approaches, highlighting the challenges\nand opportunities presented by this dataset. SARD serves as a valuable resource\nfor developing and evaluating robust OCR and vision-language models capable of\nprocessing diverse Arabic book-style texts.", "published": "2025-05-30 13:47:54", "link": "http://arxiv.org/abs/2505.24600v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Unleashing the Power of Intermediate Domains for Mixed Domain Semi-Supervised Medical Image Segmentation", "abstract": "Both limited annotation and domain shift are prevalent challenges in medical\nimage segmentation. Traditional semi-supervised segmentation and unsupervised\ndomain adaptation methods address one of these issues separately. However, the\ncoexistence of limited annotation and domain shift is quite common, which\nmotivates us to introduce a novel and challenging scenario: Mixed Domain\nSemi-supervised medical image Segmentation (MiDSS), where limited labeled data\nfrom a single domain and a large amount of unlabeled data from multiple\ndomains. To tackle this issue, we propose the UST-RUN framework, which fully\nleverages intermediate domain information to facilitate knowledge transfer. We\nemploy Unified Copy-paste (UCP) to construct intermediate domains, and propose\na Symmetric GuiDance training strategy (SymGD) to supervise unlabeled data by\nmerging pseudo-labels from intermediate samples. Subsequently, we introduce a\nTraining Process aware Random Amplitude MixUp (TP-RAM) to progressively\nincorporate style-transition components into intermediate samples. To generate\nmore diverse intermediate samples, we further select reliable samples with\nhigh-quality pseudo-labels, which are then mixed with other unlabeled data.\nAdditionally, we generate sophisticated intermediate samples with high-quality\npseudo-labels for unreliable samples, ensuring effective knowledge transfer for\nthem. Extensive experiments on four public datasets demonstrate the superiority\nof UST-RUN. Notably, UST-RUN achieves a 12.94% improvement in Dice score on the\nProstate dataset. Our code is available at https://github.com/MQinghe/UST-RUN", "published": "2025-05-30 13:21:05", "link": "http://arxiv.org/abs/2505.24567v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Optimal Weighted Convolution for Classification and Denosing", "abstract": "We introduce a novel weighted convolution operator that enhances traditional\nconvolutional neural networks (CNNs) by integrating a spatial density function\ninto the convolution operator. This extension enables the network to\ndifferentially weight neighbouring pixels based on their relative position to\nthe reference pixel, improving spatial characterisation and feature extraction.\nThe proposed operator maintains the same number of trainable parameters and is\nfully compatible with existing CNN architectures. Although developed for 2D\nimage data, the framework is generalisable to signals on regular grids of\narbitrary dimensions, such as 3D volumetric data or 1D time series. We propose\nan efficient implementation of the weighted convolution by pre-computing the\ndensity function and achieving execution times comparable to standard\nconvolution layers. We evaluate our method on two deep learning tasks: image\nclassification using the CIFAR-100 dataset [KH+09] and image denoising using\nthe DIV2K dataset [AT17]. Experimental results with state-of-the-art\nclassification (e.g., VGG [SZ15], ResNet [HZRS16]) and denoising (e.g., DnCNN\n[ZZC+17], NAFNet [CCZS22]) methods show that the weighted convolution improves\nperformance with respect to standard convolution across different quantitative\nmetrics. For example, VGG achieves an accuracy of 66.94% with weighted\nconvolution versus 56.89% with standard convolution on the classification\nproblem, while DnCNN improves the PSNR value from 20.17 to 22.63 on the\ndenoising problem. All models were trained on the CINECA Leonardo cluster to\nreduce the execution time and improve the tuning of the density function\nvalues. The PyTorch implementation of the weighted convolution is publicly\navailable at: https://github.com/cammarasana123/weightedConvolution2.0.", "published": "2025-05-30 13:10:46", "link": "http://arxiv.org/abs/2505.24558v1", "categories": ["cs.CV", "68T05"], "primary_category": "cs.CV"}
{"title": "Geospatial Foundation Models to Enable Progress on Sustainable Development Goals", "abstract": "Foundation Models (FMs) are large-scale, pre-trained AI systems that have\nrevolutionized natural language processing and computer vision, and are now\nadvancing geospatial analysis and Earth Observation (EO). They promise improved\ngeneralization across tasks, scalability, and efficient adaptation with minimal\nlabeled data. However, despite the rapid proliferation of geospatial FMs, their\nreal-world utility and alignment with global sustainability goals remain\nunderexplored. We introduce SustainFM, a comprehensive benchmarking framework\ngrounded in the 17 Sustainable Development Goals with extremely diverse tasks\nranging from asset wealth prediction to environmental hazard detection. This\nstudy provides a rigorous, interdisciplinary assessment of geospatial FMs and\noffers critical insights into their role in attaining sustainability goals. Our\nfindings show: (1) While not universally superior, FMs often outperform\ntraditional approaches across diverse tasks and datasets. (2) Evaluating FMs\nshould go beyond accuracy to include transferability, generalization, and\nenergy efficiency as key criteria for their responsible use. (3) FMs enable\nscalable, SDG-grounded solutions, offering broad utility for tackling complex\nsustainability challenges. Critically, we advocate for a paradigm shift from\nmodel-centric development to impact-driven deployment, and emphasize metrics\nsuch as energy efficiency, robustness to domain shifts, and ethical\nconsiderations.", "published": "2025-05-30 12:36:38", "link": "http://arxiv.org/abs/2505.24528v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Optimal Density Functions for Weighted Convolution in Learning Models", "abstract": "The paper introduces the weighted convolution, a novel approach to the\nconvolution for signals defined on regular grids (e.g., 2D images) through the\napplication of an optimal density function to scale the contribution of\nneighbouring pixels based on their distance from the central pixel. This choice\ndiffers from the traditional uniform convolution, which treats all neighbouring\npixels equally. Our weighted convolution can be applied to convolutional neural\nnetwork problems to improve the approximation accuracy. Given a convolutional\nnetwork, we define a framework to compute the optimal density function through\na minimisation model. The framework separates the optimisation of the\nconvolutional kernel weights (using stochastic gradient descent) from the\noptimisation of the density function (using DIRECT-L). Experimental results on\na learning model for an image-to-image task (e.g., image denoising) show that\nthe weighted convolution significantly reduces the loss (up to 53% improvement)\nand increases the test accuracy compared to standard convolution. While this\nmethod increases execution time by 11%, it is robust across several\nhyperparameters of the learning model. Future work will apply the weighted\nconvolution to real-case 2D and 3D image convolutional learning problems.", "published": "2025-05-30 12:36:36", "link": "http://arxiv.org/abs/2505.24527v1", "categories": ["cs.CV", "cs.LG", "42A85"], "primary_category": "cs.CV"}
{"title": "UniGeo: Taming Video Diffusion for Unified Consistent Geometry Estimation", "abstract": "Recently, methods leveraging diffusion model priors to assist monocular\ngeometric estimation (e.g., depth and normal) have gained significant attention\ndue to their strong generalization ability. However, most existing works focus\non estimating geometric properties within the camera coordinate system of\nindividual video frames, neglecting the inherent ability of diffusion models to\ndetermine inter-frame correspondence. In this work, we demonstrate that,\nthrough appropriate design and fine-tuning, the intrinsic consistency of video\ngeneration models can be effectively harnessed for consistent geometric\nestimation. Specifically, we 1) select geometric attributes in the global\ncoordinate system that share the same correspondence with video frames as the\nprediction targets, 2) introduce a novel and efficient conditioning method by\nreusing positional encodings, and 3) enhance performance through joint training\non multiple geometric attributes that share the same correspondence. Our\nresults achieve superior performance in predicting global geometric attributes\nin videos and can be directly applied to reconstruction tasks. Even when\ntrained solely on static video data, our approach exhibits the potential to\ngeneralize to dynamic video scenes.", "published": "2025-05-30 12:31:59", "link": "http://arxiv.org/abs/2505.24521v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "un$^2$CLIP: Improving CLIP's Visual Detail Capturing Ability via Inverting unCLIP", "abstract": "Contrastive Language-Image Pre-training (CLIP) has become a foundation model\nand has been applied to various vision and multimodal tasks. However, recent\nworks indicate that CLIP falls short in distinguishing detailed differences in\nimages and shows suboptimal performance on dense-prediction and vision-centric\nmultimodal tasks. Therefore, this work focuses on improving existing CLIP\nmodels, aiming to capture as many visual details in images as possible. We find\nthat a specific type of generative models, unCLIP, provides a suitable\nframework for achieving our goal. Specifically, unCLIP trains an image\ngenerator conditioned on the CLIP image embedding. In other words, it inverts\nthe CLIP image encoder. Compared to discriminative models like CLIP, generative\nmodels are better at capturing image details because they are trained to learn\nthe data distribution of images. Additionally, the conditional input space of\nunCLIP aligns with CLIP's original image-text embedding space. Therefore, we\npropose to invert unCLIP (dubbed un$^2$CLIP) to improve the CLIP model. In this\nway, the improved image encoder can gain unCLIP's visual detail capturing\nability while preserving its alignment with the original text encoder\nsimultaneously. We evaluate our improved CLIP across various tasks to which\nCLIP has been applied, including the challenging MMVP-VLM benchmark, the\ndense-prediction open-vocabulary segmentation task, and multimodal large\nlanguage model tasks. Experiments show that un$^2$CLIP significantly improves\nthe original CLIP and previous CLIP improvement methods. Code and models will\nbe available at https://github.com/LiYinqi/un2CLIP.", "published": "2025-05-30 12:29:38", "link": "http://arxiv.org/abs/2505.24517v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Digital twins enable full-reference quality assessment of photoacoustic image reconstructions", "abstract": "Quantitative comparison of the quality of photoacoustic image reconstruction\nalgorithms remains a major challenge. No-reference image quality measures are\noften inadequate, but full-reference measures require access to an ideal\nreference image. While the ground truth is known in simulations, it is unknown\nin vivo, or in phantom studies, as the reference depends on both the phantom\nproperties and the imaging system. We tackle this problem by using numerical\ndigital twins of tissue-mimicking phantoms and the imaging system to perform a\nquantitative calibration to reduce the simulation gap. The contributions of\nthis paper are two-fold: First, we use this digital-twin framework to compare\nmultiple state-of-the-art reconstruction algorithms. Second, among these is a\nFourier transform-based reconstruction algorithm for circular detection\ngeometries, which we test on experimental data for the first time. Our results\ndemonstrate the usefulness of digital phantom twins by enabling assessment of\nthe accuracy of the numerical forward model and enabling comparison of image\nreconstruction schemes with full-reference image quality assessment. We show\nthat the Fourier transform-based algorithm yields results comparable to those\nof iterative time reversal, but at a lower computational cost. All data and\ncode are publicly available on Zenodo: https://doi.org/10.5281/zenodo.15388429.", "published": "2025-05-30 12:25:36", "link": "http://arxiv.org/abs/2505.24514v1", "categories": ["physics.med-ph", "cs.CV", "eess.SP"], "primary_category": "physics.med-ph"}
{"title": "Reason-SVG: Hybrid Reward RL for Aha-Moments in Vector Graphics Generation", "abstract": "Generating high-quality Scalable Vector Graphics (SVGs) is challenging for\nLarge Language Models (LLMs), as it requires advanced reasoning for structural\nvalidity, semantic faithfulness, and visual coherence -- capabilities in which\ncurrent LLMs often fall short. In this work, we introduce Reason-SVG, a novel\nframework designed to enhance LLM reasoning for SVG generation. Reason-SVG\npioneers the \"Drawing-with-Thought\" (DwT) paradigm, in which models generate\nboth SVG code and explicit design rationales, mimicking the human creative\nprocess. Reason-SVG adopts a two-stage training strategy: First, Supervised\nFine-Tuning (SFT) trains the LLM on the DwT paradigm to activate foundational\nreasoning abilities. Second, Reinforcement Learning (RL), utilizing Group\nRelative Policy Optimization (GRPO), empowers the model to generate both DwT\nand SVGs rationales through refined, reward-driven reasoning. To facilitate\nreasoning-driven SVG generation, we design a Hybrid Reward function that\nevaluates the presence and utility of DwT reasoning, along with structural\nvalidity, semantic alignment, and visual quality. We also introduce the\nSVGX-DwT-10k dataset, a high-quality corpus of 10,000 SVG-DwT pairs, where each\nSVG code is generated based on explicit DwT reasoning. By integrating DwT, SFT,\nand Hybrid Reward-guided RL, Reason-SVG significantly improves LLM performance\nin generating accurate and visually compelling SVGs, potentially fostering \"Aha\nmoments\" in design.", "published": "2025-05-30 11:57:58", "link": "http://arxiv.org/abs/2505.24499v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ACM-UNet: Adaptive Integration of CNNs and Mamba for Efficient Medical Image Segmentation", "abstract": "The U-shaped encoder-decoder architecture with skip connections has become a\nprevailing paradigm in medical image segmentation due to its simplicity and\neffectiveness. While many recent works aim to improve this framework by\ndesigning more powerful encoders and decoders, employing advanced convolutional\nneural networks (CNNs) for local feature extraction, Transformers or state\nspace models (SSMs) such as Mamba for global context modeling, or hybrid\ncombinations of both, these methods often struggle to fully utilize pretrained\nvision backbones (e.g., ResNet, ViT, VMamba) due to structural mismatches. To\nbridge this gap, we introduce ACM-UNet, a general-purpose segmentation\nframework that retains a simple UNet-like design while effectively\nincorporating pretrained CNNs and Mamba models through a lightweight adapter\nmechanism. This adapter resolves architectural incompatibilities and enables\nthe model to harness the complementary strengths of CNNs and SSMs-namely,\nfine-grained local detail extraction and long-range dependency modeling.\nAdditionally, we propose a hierarchical multi-scale wavelet transform module in\nthe decoder to enhance feature fusion and reconstruction fidelity. Extensive\nexperiments on the Synapse and ACDC benchmarks demonstrate that ACM-UNet\nachieves state-of-the-art performance while remaining computationally\nefficient. Notably, it reaches 85.12% Dice Score and 13.89mm HD95 on the\nSynapse dataset with 17.93G FLOPs, showcasing its effectiveness and\nscalability. Code is available at: https://github.com/zyklcode/ACM-UNet.", "published": "2025-05-30 11:30:53", "link": "http://arxiv.org/abs/2505.24481v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Period-LLM: Extending the Periodic Capability of Multimodal Large Language Model", "abstract": "Periodic or quasi-periodic phenomena reveal intrinsic characteristics in\nvarious natural processes, such as weather patterns, movement behaviors,\ntraffic flows, and biological signals. Given that these phenomena span multiple\nmodalities, the capabilities of Multimodal Large Language Models (MLLMs) offer\npromising potential to effectively capture and understand their complex nature.\nHowever, current MLLMs struggle with periodic tasks due to limitations in: 1)\nlack of temporal modelling and 2) conflict between short and long periods. This\npaper introduces Period-LLM, a multimodal large language model designed to\nenhance the performance of periodic tasks across various modalities, and\nconstructs a benchmark of various difficulty for evaluating the cross-modal\nperiodic capabilities of large models. Specially, We adopt an \"Easy to Hard\nGeneralization\" paradigm, starting with relatively simple text-based tasks and\nprogressing to more complex visual and multimodal tasks, ensuring that the\nmodel gradually builds robust periodic reasoning capabilities. Additionally, we\npropose a \"Resisting Logical Oblivion\" optimization strategy to maintain\nperiodic reasoning abilities during semantic alignment. Extensive experiments\ndemonstrate the superiority of the proposed Period-LLM over existing MLLMs in\nperiodic tasks. The code is available at\nhttps://github.com/keke-nice/Period-LLM.", "published": "2025-05-30 11:23:21", "link": "http://arxiv.org/abs/2505.24476v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SPPSFormer: High-quality Superpoint-based Transformer for Roof Plane Instance Segmentation from Point Clouds", "abstract": "Transformers have been seldom employed in point cloud roof plane instance\nsegmentation, which is the focus of this study, and existing superpoint\nTransformers suffer from limited performance due to the use of low-quality\nsuperpoints. To address this challenge, we establish two criteria that\nhigh-quality superpoints for Transformers should satisfy and introduce a\ncorresponding two-stage superpoint generation process. The superpoints\ngenerated by our method not only have accurate boundaries, but also exhibit\nconsistent geometric sizes and shapes, both of which greatly benefit the\nfeature learning of superpoint Transformers. To compensate for the limitations\nof deep learning features when the training set size is limited, we incorporate\nmultidimensional handcrafted features into the model. Additionally, we design a\ndecoder that combines a Kolmogorov-Arnold Network with a Transformer module to\nimprove instance prediction and mask extraction. Finally, our network's\npredictions are refined using traditional algorithm-based postprocessing. For\nevaluation, we annotated a real-world dataset and corrected annotation errors\nin the existing RoofN3D dataset. Experimental results show that our method\nachieves state-of-the-art performance on our dataset, as well as both the\noriginal and reannotated RoofN3D datasets. Moreover, our model is not sensitive\nto plane boundary annotations during training, significantly reducing the\nannotation burden. Through comprehensive experiments, we also identified key\nfactors influencing roof plane segmentation performance: in addition to roof\ntypes, variations in point cloud density, density uniformity, and 3D point\nprecision have a considerable impact. These findings underscore the importance\nof incorporating data augmentation strategies that account for point cloud\nquality to enhance model robustness under diverse and challenging conditions.", "published": "2025-05-30 11:23:16", "link": "http://arxiv.org/abs/2505.24475v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SA-Person: Text-Based Person Retrieval with Scene-aware Re-ranking", "abstract": "Text-based person retrieval aims to identify a target individual from a\ngallery of images based on a natural language description. It presents a\nsignificant challenge due to the complexity of real-world scenes and the\nambiguity of appearance-related descriptions. Existing methods primarily\nemphasize appearance-based cross-modal retrieval, often neglecting the\ncontextual information embedded within the scene, which can offer valuable\ncomplementary insights for retrieval. To address this, we introduce\nSCENEPERSON-13W, a large-scale dataset featuring over 100,000 scenes with rich\nannotations covering both pedestrian appearance and environmental cues. Based\non this, we propose SA-Person, a two-stage retrieval framework. In the first\nstage, it performs discriminative appearance grounding by aligning textual cues\nwith pedestrian-specific regions. In the second stage, it introduces\nSceneRanker, a training-free, scene-aware re-ranking method leveraging\nmultimodal large language models to jointly reason over pedestrian appearance\nand the global scene context. Experiments on SCENEPERSON-13W validate the\neffectiveness of our framework in challenging scene-level retrieval scenarios.\nThe code and dataset will be made publicly available.", "published": "2025-05-30 11:10:28", "link": "http://arxiv.org/abs/2505.24466v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning with Outliers", "abstract": "Conventional semi-supervised learning (SSL) ideally assumes that labeled and\nunlabeled data share an identical class distribution, however in practice, this\nassumption is easily violated, as unlabeled data often includes unknown class\ndata, i.e., outliers. The outliers are treated as noise, considerably degrading\nthe performance of SSL models. To address this drawback, we propose a novel\nframework, Diversify and Conquer (DAC), to enhance SSL robustness in the\ncontext of open-set semi-supervised learning. In particular, we note that\nexisting open-set SSL methods rely on prediction discrepancies between inliers\nand outliers from a single model trained on labeled data. This approach can be\neasily failed when the labeled data is insufficient, leading to performance\ndegradation that is worse than naive SSL that do not account for outliers. In\ncontrast, our approach exploits prediction disagreements among multiple models\nthat are differently biased towards the unlabeled distribution. By leveraging\nthe discrepancies arising from training on unlabeled data, our method enables\nrobust outlier detection even when the labeled data is underspecified. Our key\ncontribution is constructing a collection of differently biased models through\na single training process. By encouraging divergent heads to be differently\nbiased towards outliers while making consistent predictions for inliers, we\nexploit the disagreement among these heads as a measure to identify unknown\nconcepts. Our code is available at https://github.com/heejokong/DivCon.", "published": "2025-05-30 10:24:30", "link": "http://arxiv.org/abs/2505.24443v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "SORCE: Small Object Retrieval in Complex Environments", "abstract": "Text-to-Image Retrieval (T2IR) is a highly valuable task that aims to match a\ngiven textual query to images in a gallery. Existing benchmarks primarily focus\non textual queries describing overall image semantics or foreground salient\nobjects, possibly overlooking inconspicuous small objects, especially in\ncomplex environments. Such small object retrieval is crucial, as in real-world\napplications, the targets of interest are not always prominent in the image.\nThus, we introduce SORCE (Small Object Retrieval in Complex Environments), a\nnew subfield of T2IR, focusing on retrieving small objects in complex images\nwith textual queries. We propose a new benchmark, SORCE-1K, consisting of\nimages with complex environments and textual queries describing less\nconspicuous small objects with minimal contextual cues from other salient\nobjects. Preliminary analysis on SORCE-1K finds that existing T2IR methods\nstruggle to capture small objects and encode all the semantics into a single\nembedding, leading to poor retrieval performance on SORCE-1K. Therefore, we\npropose to represent each image with multiple distinctive embeddings. We\nleverage Multimodal Large Language Models (MLLMs) to extract multiple\nembeddings for each image instructed by a set of Regional Prompts (ReP).\nExperimental results show that our multi-embedding approach through MLLM and\nReP significantly outperforms existing T2IR methods on SORCE-1K. Our\nexperiments validate the effectiveness of SORCE-1K for benchmarking SORCE\nperformances, highlighting the potential of multi-embedding representation and\ntext-customized MLLM features for addressing this task.", "published": "2025-05-30 10:23:05", "link": "http://arxiv.org/abs/2505.24441v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields", "abstract": "Flow matching casts sample generation as learning a continuous-time velocity\nfield that transports noise to data. Existing flow matching networks typically\npredict each point's velocity independently, considering only its location and\ntime along its flow trajectory, and ignoring neighboring points. However, this\npointwise approach may overlook correlations between points along the\ngeneration trajectory that could enhance velocity predictions, thereby\nimproving downstream generation quality. To address this, we propose Graph Flow\nMatching (GFM), a lightweight enhancement that decomposes the learned velocity\ninto a reaction term -- any standard flow matching network -- and a diffusion\nterm that aggregates neighbor information via a graph neural module. This\nreaction-diffusion formulation retains the scalability of deep flow models\nwhile enriching velocity predictions with local context, all at minimal\nadditional computational cost. Operating in the latent space of a pretrained\nvariational autoencoder, GFM consistently improves Fr\\'echet Inception Distance\n(FID) and recall across five image generation benchmarks (LSUN Church, LSUN\nBedroom, FFHQ, AFHQ-Cat, and CelebA-HQ at $256\\times256$), demonstrating its\neffectiveness as a modular enhancement to existing flow matching architectures.", "published": "2025-05-30 10:17:50", "link": "http://arxiv.org/abs/2505.24434v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Bridging 3D Anomaly Localization and Repair via High-Quality Continuous Geometric Representation", "abstract": "3D point cloud anomaly detection is essential for robust vision systems but\nis challenged by pose variations and complex geometric anomalies. Existing\npatch-based methods often suffer from geometric fidelity issues due to discrete\nvoxelization or projection-based representations, limiting fine-grained anomaly\nlocalization. We introduce Pose-Aware Signed Distance Field (PASDF), a novel\nframework that integrates 3D anomaly detection and repair by learning a\ncontinuous, pose-invariant shape representation. PASDF leverages a Pose\nAlignment Module for canonicalization and a SDF Network to dynamically\nincorporate pose, enabling implicit learning of high-fidelity anomaly repair\ntemplates from the continuous SDF. This facilitates precise pixel-level anomaly\nlocalization through an Anomaly-Aware Scoring Module. Crucially, the continuous\n3D representation in PASDF extends beyond detection, facilitating in-situ\nanomaly repair. Experiments on Real3D-AD and Anomaly-ShapeNet demonstrate\nstate-of-the-art performance, achieving high object-level AUROC scores of 80.2%\nand 90.0%, respectively. These results highlight the effectiveness of\ncontinuous geometric representations in advancing 3D anomaly detection and\nfacilitating practical anomaly region repair. The code is available at\nhttps://github.com/ZZZBBBZZZ/PASDF to support further research.", "published": "2025-05-30 10:11:49", "link": "http://arxiv.org/abs/2505.24431v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning", "abstract": "Vision-language models like CLIP have demonstrated remarkable zero-shot\ncapabilities in classification and retrieval. However, these models often\nstruggle with compositional reasoning - the ability to understand the\nrelationships between concepts. A recent benchmark, SugarCrepe++, reveals that\nprevious works on improving compositionality have mainly improved lexical\nsensitivity but neglected semantic understanding. In addition, downstream\nretrieval performance often deteriorates, although one would expect that\nimproving compositionality should enhance retrieval. In this work, we introduce\nCLIC (Compositionally-aware Learning in CLIP), a fine-tuning method based on a\nnovel training technique combining multiple images and their associated\ncaptions. CLIC improves compositionality across architectures as well as\ndifferently pre-trained CLIP models, both in terms of lexical and semantic\nunderstanding, and achieves consistent gains in retrieval performance. This\neven applies to the recent CLIPS, which achieves SOTA retrieval performance.\nNevertheless, the short fine-tuning with CLIC leads to an improvement in\nretrieval and to the best compositional CLIP model on SugarCrepe++. All our\nmodels and code are available at https://clic-compositional-clip.github.io", "published": "2025-05-30 10:04:00", "link": "http://arxiv.org/abs/2505.24424v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "pyMEAL: A Multi-Encoder Augmentation-Aware Learning for Robust and Generalizable Medical Image Translation", "abstract": "Medical imaging is critical for diagnostics, but clinical adoption of\nadvanced AI-driven imaging faces challenges due to patient variability, image\nartifacts, and limited model generalization. While deep learning has\ntransformed image analysis, 3D medical imaging still suffers from data scarcity\nand inconsistencies due to acquisition protocols, scanner differences, and\npatient motion. Traditional augmentation uses a single pipeline for all\ntransformations, disregarding the unique traits of each augmentation and\nstruggling with large data volumes.\n  To address these challenges, we propose a Multi-encoder Augmentation-Aware\nLearning (MEAL) framework that leverages four distinct augmentation variants\nprocessed through dedicated encoders. Three fusion strategies such as\nconcatenation (CC), fusion layer (FL), and adaptive controller block (BD) are\nintegrated to build multi-encoder models that combine augmentation-specific\nfeatures before decoding. MEAL-BD uniquely preserves augmentation-aware\nrepresentations, enabling robust, protocol-invariant feature learning.\n  As demonstrated in a Computed Tomography (CT)-to-T1-weighted Magnetic\nResonance Imaging (MRI) translation study, MEAL-BD consistently achieved the\nbest performance on both unseen- and predefined-test data. On both geometric\ntransformations (like rotations and flips) and non-augmented inputs, MEAL-BD\noutperformed other competing methods, achieving higher mean peak\nsignal-to-noise ratio (PSNR) and structural similarity index measure (SSIM)\nscores. These results establish MEAL as a reliable framework for preserving\nstructural fidelity and generalizing across clinically relevant variability. By\nreframing augmentation as a source of diverse, generalizable features, MEAL\nsupports robust, protocol-invariant learning, advancing clinically reliable\nmedical imaging solutions.", "published": "2025-05-30 10:01:23", "link": "http://arxiv.org/abs/2505.24421v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "EasyText: Controllable Diffusion Transformer for Multilingual Text Rendering", "abstract": "Generating accurate multilingual text with diffusion models has long been\ndesired but remains challenging. Recent methods have made progress in rendering\ntext in a single language, but rendering arbitrary languages is still an\nunexplored area. This paper introduces EasyText, a text rendering framework\nbased on DiT (Diffusion Transformer), which connects denoising latents with\nmultilingual character tokens encoded as character tokens. We propose character\npositioning encoding and position encoding interpolation techniques to achieve\ncontrollable and precise text rendering. Additionally, we construct a\nlarge-scale synthetic text image dataset with 1 million multilingual image-text\nannotations as well as a high-quality dataset of 20K annotated images, which\nare used for pretraining and fine-tuning respectively. Extensive experiments\nand evaluations demonstrate the effectiveness and advancement of our approach\nin multilingual text rendering, visual quality, and layout-aware text\nintegration.", "published": "2025-05-30 09:55:39", "link": "http://arxiv.org/abs/2505.24417v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PCIE_Pose Solution for EgoExo4D Pose and Proficiency Estimation Challenge", "abstract": "This report introduces our team's (PCIE_EgoPose) solutions for the EgoExo4D\nPose and Proficiency Estimation Challenges at CVPR2025. Focused on the\nintricate task of estimating 21 3D hand joints from RGB egocentric videos,\nwhich are complicated by subtle movements and frequent occlusions, we developed\nthe Hand Pose Vision Transformer (HP-ViT+). This architecture synergizes a\nVision Transformer and a CNN backbone, using weighted fusion to refine the hand\npose predictions. For the EgoExo4D Body Pose Challenge, we adopted a multimodal\nspatio-temporal feature integration strategy to address the complexities of\nbody pose estimation across dynamic contexts. Our methods achieved remarkable\nperformance: 8.31 PA-MPJPE in the Hand Pose Challenge and 11.25 MPJPE in the\nBody Pose Challenge, securing championship titles in both competitions. We\nextended our pose estimation solutions to the Proficiency Estimation task,\napplying core technologies such as transformer-based architectures. This\nextension enabled us to achieve a top-1 accuracy of 0.53, a SOTA result, in the\nDemonstrator Proficiency Estimation competition.", "published": "2025-05-30 09:51:04", "link": "http://arxiv.org/abs/2505.24411v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient RAW Image Deblurring with Adaptive Frequency Modulation", "abstract": "Image deblurring plays a crucial role in enhancing visual clarity across\nvarious applications. Although most deep learning approaches primarily focus on\nsRGB images, which inherently lose critical information during the image signal\nprocessing pipeline, RAW images, being unprocessed and linear, possess superior\nrestoration potential but remain underexplored. Deblurring RAW images presents\nunique challenges, particularly in handling frequency-dependent blur while\nmaintaining computational efficiency. To address these issues, we propose\nFrequency Enhanced Network (FrENet), a framework specifically designed for\nRAW-to-RAW deblurring that operates directly in the frequency domain. We\nintroduce a novel Adaptive Frequency Positional Modulation module, which\ndynamically adjusts frequency components according to their spectral positions,\nthereby enabling precise control over the deblurring process. Additionally,\nfrequency domain skip connections are adopted to further preserve\nhigh-frequency details. Experimental results demonstrate that FrENet surpasses\nstate-of-the-art deblurring methods in RAW image deblurring, achieving\nsignificantly better restoration quality while maintaining high efficiency in\nterms of reduced MACs. Furthermore, FrENet's adaptability enables it to be\nextended to sRGB images, where it delivers comparable or superior performance\ncompared to methods specifically designed for sRGB data. The code will be\navailable at https://github.com/WenlongJiao/FrENet .", "published": "2025-05-30 09:46:39", "link": "http://arxiv.org/abs/2505.24407v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "IRBridge: Solving Image Restoration Bridge with Pre-trained Generative Diffusion Models", "abstract": "Bridge models in image restoration construct a diffusion process from\ndegraded to clear images. However, existing methods typically require training\na bridge model from scratch for each specific type of degradation, resulting in\nhigh computational costs and limited performance. This work aims to efficiently\nleverage pretrained generative priors within existing image restoration bridges\nto eliminate this requirement. The main challenge is that standard generative\nmodels are typically designed for a diffusion process that starts from pure\nnoise, while restoration tasks begin with a low-quality image, resulting in a\nmismatch in the state distributions between the two processes. To address this\nchallenge, we propose a transition equation that bridges two diffusion\nprocesses with the same endpoint distribution. Based on this, we introduce the\nIRBridge framework, which enables the direct utilization of generative models\nwithin image restoration bridges, offering a more flexible and adaptable\napproach to image restoration. Extensive experiments on six image restoration\ntasks demonstrate that IRBridge efficiently integrates generative priors,\nresulting in improved robustness and generalization performance. Code will be\navailable at GitHub.", "published": "2025-05-30 09:45:41", "link": "http://arxiv.org/abs/2505.24406v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PCIE_Interaction Solution for Ego4D Social Interaction Challenge", "abstract": "This report presents our team's PCIE_Interaction solution for the Ego4D\nSocial Interaction Challenge at CVPR 2025, addressing both Looking At Me (LAM)\nand Talking To Me (TTM) tasks. The challenge requires accurate detection of\nsocial interactions between subjects and the camera wearer, with LAM relying\nexclusively on face crop sequences and TTM combining speaker face crops with\nsynchronized audio segments. In the LAM track, we employ face quality\nenhancement and ensemble methods. For the TTM task, we extend visual\ninteraction analysis by fusing audio and visual cues, weighted by a visual\nquality score. Our approach achieved 0.81 and 0.71 mean average precision (mAP)\non the LAM and TTM challenges leader board. Code is available at\nhttps://github.com/KanokphanL/PCIE_Ego4D_Social_Interaction", "published": "2025-05-30 09:35:25", "link": "http://arxiv.org/abs/2505.24404v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leveraging Intermediate Features of Vision Transformer for Face Anti-Spoofing", "abstract": "Face recognition systems are designed to be robust against changes in head\npose, illumination, and blurring during image capture. If a malicious person\npresents a face photo of the registered user, they may bypass the\nauthentication process illegally. Such spoofing attacks need to be detected\nbefore face recognition. In this paper, we propose a spoofing attack detection\nmethod based on Vision Transformer (ViT) to detect minute differences between\nlive and spoofed face images. The proposed method utilizes the intermediate\nfeatures of ViT, which have a good balance between local and global features\nthat are important for spoofing attack detection, for calculating loss in\ntraining and score in inference. The proposed method also introduces two data\naugmentation methods: face anti-spoofing data augmentation and patch-wise data\naugmentation, to improve the accuracy of spoofing attack detection. We\ndemonstrate the effectiveness of the proposed method through experiments using\nthe OULU-NPU and SiW datasets.", "published": "2025-05-30 09:33:01", "link": "http://arxiv.org/abs/2505.24402v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "S3CE-Net: Spike-guided Spatiotemporal Semantic Coupling and Expansion Network for Long Sequence Event Re-Identification", "abstract": "In this paper, we leverage the advantages of event cameras to resist harsh\nlighting conditions, reduce background interference, achieve high time\nresolution, and protect facial information to study the long-sequence\nevent-based person re-identification (Re-ID) task. To this end, we propose a\nsimple and efficient long-sequence event Re-ID model, namely the Spike-guided\nSpatiotemporal Semantic Coupling and Expansion Network (S3CE-Net). To better\nhandle asynchronous event data, we build S3CE-Net based on spiking neural\nnetworks (SNNs). The S3CE-Net incorporates the Spike-guided Spatial-temporal\nAttention Mechanism (SSAM) and the Spatiotemporal Feature Sampling Strategy\n(STFS). The SSAM is designed to carry out semantic interaction and association\nin both spatial and temporal dimensions, leveraging the capabilities of SNNs.\nThe STFS involves sampling spatial feature subsequences and temporal feature\nsubsequences from the spatiotemporal dimensions, driving the Re-ID model to\nperceive broader and more robust effective semantics. Notably, the STFS\nintroduces no additional parameters and is only utilized during the training\nstage. Therefore, S3CE-Net is a low-parameter and high-efficiency model for\nlong-sequence event-based person Re-ID. Extensive experiments have verified\nthat our S3CE-Net achieves outstanding performance on many mainstream\nlong-sequence event-based person Re-ID datasets. Code is available\nat:https://github.com/Mhsunshine/SC3E_Net.", "published": "2025-05-30 09:32:37", "link": "http://arxiv.org/abs/2505.24401v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Leadership Assessment in Pediatric Intensive Care Unit Team Training", "abstract": "This paper addresses the task of assessing PICU team's leadership skills by\ndeveloping an automated analysis framework based on egocentric vision. We\nidentify key behavioral cues, including fixation object, eye contact, and\nconversation patterns, as essential indicators of leadership assessment. In\norder to capture these multimodal signals, we employ Aria Glasses to record\negocentric video, audio, gaze, and head movement data. We collect one-hour\nvideos of four simulated sessions involving doctors with different roles and\nlevels. To automate data processing, we propose a method leveraging REMoDNaV,\nSAM, YOLO, and ChatGPT for fixation object detection, eye contact detection,\nand conversation classification. In the experiments, significant correlations\nare observed between leadership skills and behavioral metrics, i.e., the output\nof our proposed methods, such as fixation time, transition patterns, and direct\norders in speech. These results indicate that our proposed data collection and\nanalysis framework can effectively solve skill assessment for training PICU\nteams.", "published": "2025-05-30 09:19:33", "link": "http://arxiv.org/abs/2505.24389v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Spatiotemporal Analysis of Forest Machine Operations Using 3D Video Classification", "abstract": "This paper presents a deep learning-based framework for classifying forestry\noperations from dashcam video footage. Focusing on four key work elements -\ncrane-out, cutting-and-to-processing, driving, and processing - the approach\nemploys a 3D ResNet-50 architecture implemented with PyTorchVideo. Trained on a\nmanually annotated dataset of field recordings, the model achieves strong\nperformance, with a validation F1 score of 0.88 and precision of 0.90. These\nresults underscore the effectiveness of spatiotemporal convolutional networks\nfor capturing both motion patterns and appearance in real-world forestry\nenvironments.\n  The system integrates standard preprocessing and augmentation techniques to\nimprove generalization, but overfitting is evident, highlighting the need for\nmore training data and better class balance. Despite these challenges, the\nmethod demonstrates clear potential for reducing the manual workload associated\nwith traditional time studies, offering a scalable solution for operational\nmonitoring and efficiency analysis in forestry.\n  This work contributes to the growing application of AI in natural resource\nmanagement and sets the foundation for future systems capable of real-time\nactivity recognition in forest machinery. Planned improvements include dataset\nexpansion, enhanced regularization, and deployment trials on embedded systems\nfor in-field use.", "published": "2025-05-30 09:07:57", "link": "http://arxiv.org/abs/2505.24375v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "D2AF: A Dual-Driven Annotation and Filtering Framework for Visual Grounding", "abstract": "Visual Grounding is a task that aims to localize a target region in an image\nbased on a free-form natural language description. With the rise of Transformer\narchitectures, there is an increasing need for larger datasets to boost\nperformance. However, the high cost of manual annotation poses a challenge,\nhindering the scale of data and the ability of large models to enhance their\neffectiveness. Previous pseudo label generation methods heavily rely on\nhuman-labeled captions of the original dataset, limiting scalability and\ndiversity. To address this, we propose D2AF, a robust annotation framework for\nvisual grounding using only input images. This approach overcomes dataset size\nlimitations and enriches both the quantity and diversity of referring\nexpressions. Our approach leverages multimodal large models and object\ndetection models. By implementing dual-driven annotation strategies, we\neffectively generate detailed region-text pairs using both closed-set and\nopen-set approaches. We further conduct an in-depth analysis of data quantity\nand data distribution. Our findings demonstrate that increasing data volume\nenhances model performance. However, the degree of improvement depends on how\nwell the pseudo labels broaden the original data distribution. Based on these\ninsights, we propose a consistency and distribution aware filtering method to\nfurther improve data quality by effectively removing erroneous and redundant\ndata. This approach effectively eliminates noisy data, leading to improved\nperformance. Experiments on three visual grounding tasks demonstrate that our\nmethod significantly improves the performance of existing models and achieves\nstate-of-the-art results.", "published": "2025-05-30 09:04:47", "link": "http://arxiv.org/abs/2505.24372v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Revisiting Cross-Modal Knowledge Distillation: A Disentanglement Approach for RGBD Semantic Segmentation", "abstract": "Multi-modal RGB and Depth (RGBD) data are predominant in many domains such as\nrobotics, autonomous driving and remote sensing. The combination of these\nmulti-modal data enhances environmental perception by providing 3D spatial\ncontext, which is absent in standard RGB images. Although RGBD multi-modal data\ncan be available to train computer vision models, accessing all sensor\nmodalities during the inference stage may be infeasible due to sensor failures\nor resource constraints, leading to a mismatch between data modalities\navailable during training and inference. Traditional Cross-Modal Knowledge\nDistillation (CMKD) frameworks, developed to address this task, are typically\nbased on a teacher/student paradigm, where a multi-modal teacher distills\nknowledge into a single-modality student model. However, these approaches face\nchallenges in teacher architecture choices and distillation process selection,\nthus limiting their adoption in real-world scenarios. To overcome these issues,\nwe introduce CroDiNo-KD (Cross-Modal Disentanglement: a New Outlook on\nKnowledge Distillation), a novel cross-modal knowledge distillation framework\nfor RGBD semantic segmentation. Our approach simultaneously learns\nsingle-modality RGB and Depth models by exploiting disentanglement\nrepresentation, contrastive learning and decoupled data augmentation with the\naim to structure the internal manifolds of neural network models through\ninteraction and collaboration. We evaluated CroDiNo-KD on three RGBD datasets\nacross diverse domains, considering recent CMKD frameworks as competitors. Our\nfindings illustrate the quality of CroDiNo-KD, and they suggest reconsidering\nthe conventional teacher/student paradigm to distill information from\nmulti-modal data to single-modality neural networks.", "published": "2025-05-30 08:53:35", "link": "http://arxiv.org/abs/2505.24361v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Novel Coronary Artery Registration Method Based on Super-pixel Particle Swarm Optimization", "abstract": "Percutaneous Coronary Intervention (PCI) is a minimally invasive procedure\nthat improves coronary blood flow and treats coronary artery disease. Although\nPCI typically requires 2D X-ray angiography (XRA) to guide catheter placement\nat real-time, computed tomography angiography (CTA) may substantially improve\nPCI by providing precise information of 3D vascular anatomy and status. To\nleverage real-time XRA and detailed 3D CTA anatomy for PCI, accurate multimodal\nimage registration of XRA and CTA is required, to guide the procedure and avoid\ncomplications. This is a challenging process as it requires registration of\nimages from different geometrical modalities (2D -> 3D and vice versa), with\nvariations in contrast and noise levels. In this paper, we propose a novel\nmultimodal coronary artery image registration method based on a swarm\noptimization algorithm, which effectively addresses challenges such as large\ndeformations, low contrast, and noise across these imaging modalities. Our\nalgorithm consists of two main modules: 1) preprocessing of XRA and CTA images\nseparately, and 2) a registration module based on feature extraction using the\nSteger and Superpixel Particle Swarm Optimization algorithms. Our technique was\nevaluated on a pilot dataset of 28 pairs of XRA and CTA images from 10 patients\nwho underwent PCI. The algorithm was compared with four state-of-the-art (SOTA)\nmethods in terms of registration accuracy, robustness, and efficiency. Our\nmethod outperformed the selected SOTA baselines in all aspects. Experimental\nresults demonstrate the significant effectiveness of our algorithm, surpassing\nthe previous benchmarks and proposes a novel clinical approach that can\npotentially have merit for improving patient outcomes in coronary artery\ndisease.", "published": "2025-05-30 08:44:46", "link": "http://arxiv.org/abs/2505.24351v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "VUDG: A Dataset for Video Understanding Domain Generalization", "abstract": "Video understanding has made remarkable progress in recent years, largely\ndriven by advances in deep models and the availability of large-scale annotated\ndatasets. However, existing works typically ignore the inherent domain shifts\nencountered in real-world video applications, leaving domain generalization\n(DG) in video understanding underexplored. Hence, we propose Video\nUnderstanding Domain Generalization (VUDG), a novel dataset designed\nspecifically for evaluating the DG performance in video understanding. VUDG\ncontains videos from 11 distinct domains that cover three types of domain\nshifts, and maintains semantic similarity across different domains to ensure\nfair and meaningful evaluation. We propose a multi-expert progressive\nannotation framework to annotate each video with both multiple-choice and\nopen-ended question-answer pairs. Extensive experiments on 9 representative\nlarge video-language models (LVLMs) and several traditional video question\nanswering methods show that most models (including state-of-the-art LVLMs)\nsuffer performance degradation under domain shifts. These results highlight the\nchallenges posed by VUDG and the difference in the robustness of current models\nto data distribution shifts. We believe VUDG provides a valuable resource for\nprompting future research in domain generalization video understanding.", "published": "2025-05-30 08:39:36", "link": "http://arxiv.org/abs/2505.24346v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "KairosAD: A SAM-Based Model for Industrial Anomaly Detection on Embedded Devices", "abstract": "In the era of intelligent manufacturing, anomaly detection has become\nessential for maintaining quality control on modern production lines. However,\nwhile many existing models show promising performance, they are often too\nlarge, computationally demanding, and impractical to deploy on\nresource-constrained embedded devices that can be easily installed on the\nproduction lines of Small and Medium Enterprises (SMEs). To bridge this gap, we\npresent KairosAD, a novel supervised approach that uses the power of the Mobile\nSegment Anything Model (MobileSAM) for image-based anomaly detection. KairosAD\nhas been evaluated on the two well-known industrial anomaly detection datasets,\ni.e., MVTec-AD and ViSA. The results show that KairosAD requires 78% fewer\nparameters and boasts a 4x faster inference time compared to the leading\nstate-of-the-art model, while maintaining comparable AUROC performance. We\ndeployed KairosAD on two embedded devices, the NVIDIA Jetson NX, and the NVIDIA\nJetson AGX. Finally, KairosAD was successfully installed and tested on the real\nproduction line of the Industrial Computer Engineering Laboratory (ICE Lab) at\nthe University of Verona. The code is available at\nhttps://github.com/intelligolabs/KairosAD.", "published": "2025-05-30 08:18:49", "link": "http://arxiv.org/abs/2505.24334v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DisTime: Distribution-based Time Representation for Video Large Language Models", "abstract": "Despite advances in general video understanding, Video Large Language Models\n(Video-LLMs) face challenges in precise temporal localization due to discrete\ntime representations and limited temporally aware datasets. Existing methods\nfor temporal expression either conflate time with text-based numerical values,\nadd a series of dedicated temporal tokens, or regress time using specialized\ntemporal grounding heads. To address these issues, we introduce DisTime, a\nlightweight framework designed to enhance temporal comprehension in Video-LLMs.\nDisTime employs a learnable token to create a continuous temporal embedding\nspace and incorporates a Distribution-based Time Decoder that generates\ntemporal probability distributions, effectively mitigating boundary ambiguities\nand maintaining temporal continuity. Additionally, the Distribution-based Time\nEncoder re-encodes timestamps to provide time markers for Video-LLMs. To\novercome temporal granularity limitations in existing datasets, we propose an\nautomated annotation paradigm that combines the captioning capabilities of\nVideo-LLMs with the localization expertise of dedicated temporal models. This\nleads to the creation of InternVid-TG, a substantial dataset with 1.25M\ntemporally grounded events across 179k videos, surpassing ActivityNet-Caption\nby 55 times. Extensive experiments demonstrate that DisTime achieves\nstate-of-the-art performance across benchmarks in three time-sensitive tasks\nwhile maintaining competitive performance in Video QA tasks. Code and data are\nreleased at https://github.com/josephzpng/DisTime.", "published": "2025-05-30 08:10:18", "link": "http://arxiv.org/abs/2505.24329v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "STAR-Net: An Interpretable Model-Aided Network for Remote Sensing Image Denoising", "abstract": "Remote sensing image (RSI) denoising is an important topic in the field of\nremote sensing. Despite the impressive denoising performance of RSI denoising\nmethods, most current deep learning-based approaches function as black boxes\nand lack integration with physical information models, leading to limited\ninterpretability. Additionally, many methods may struggle with insufficient\nattention to non-local self-similarity in RSI and require tedious tuning of\nregularization parameters to achieve optimal performance, particularly in\nconventional iterative optimization approaches. In this paper, we first propose\na novel RSI denoising method named sparse tensor-aided representation network\n(STAR-Net), which leverages a low-rank prior to effectively capture the\nnon-local self-similarity within RSI. Furthermore, we extend STAR-Net to a\nsparse variant called STAR-Net-S to deal with the interference caused by\nnon-Gaussian noise in original RSI for the purpose of improving robustness.\nDifferent from conventional iterative optimization, we develop an alternating\ndirection method of multipliers (ADMM)-guided deep unrolling network, in which\nall regularization parameters can be automatically learned, thus inheriting the\nadvantages of both model-based and deep learning-based approaches and\nsuccessfully addressing the above-mentioned shortcomings. Comprehensive\nexperiments on synthetic and real-world datasets demonstrate that STAR-Net and\nSTAR-Net-S outperform state-of-the-art RSI denoising methods.", "published": "2025-05-30 08:09:31", "link": "http://arxiv.org/abs/2505.24327v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "InteractAnything: Zero-shot Human Object Interaction Synthesis via LLM Feedback and Object Affordance Parsing", "abstract": "Recent advances in 3D human-aware generation have made significant progress.\nHowever, existing methods still struggle with generating novel Human Object\nInteraction (HOI) from text, particularly for open-set objects. We identify\nthree main challenges of this task: precise human-object relation reasoning,\naffordance parsing for any object, and detailed human interaction pose\nsynthesis aligning description and object geometry. In this work, we propose a\nnovel zero-shot 3D HOI generation framework without training on specific\ndatasets, leveraging the knowledge from large-scale pre-trained models.\nSpecifically, the human-object relations are inferred from large language\nmodels (LLMs) to initialize object properties and guide the optimization\nprocess. Then we utilize a pre-trained 2D image diffusion model to parse unseen\nobjects and extract contact points, avoiding the limitations imposed by\nexisting 3D asset knowledge. The initial human pose is generated by sampling\nmultiple hypotheses through multi-view SDS based on the input text and object\ngeometry. Finally, we introduce a detailed optimization to generate\nfine-grained, precise, and natural interaction, enforcing realistic 3D contact\nbetween the 3D object and the involved body parts, including hands in grasping.\nThis is achieved by distilling human-level feedback from LLMs to capture\ndetailed human-object relations from the text instruction. Extensive\nexperiments validate the effectiveness of our approach compared to prior works,\nparticularly in terms of the fine-grained nature of interactions and the\nability to handle open-set 3D objects.", "published": "2025-05-30 07:53:55", "link": "http://arxiv.org/abs/2505.24315v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Progressive Class-level Distillation", "abstract": "In knowledge distillation (KD), logit distillation (LD) aims to transfer\nclass-level knowledge from a more powerful teacher network to a small student\nmodel via accurate teacher-student alignment at the logits level. Since\nhigh-confidence object classes usually dominate the distillation process,\nlow-probability classes which also contain discriminating information are\ndownplayed in conventional methods, leading to insufficient knowledge transfer.\nTo address this issue, we propose a simple yet effective LD method termed\nProgressive Class-level Distillation (PCD). In contrast to existing methods\nwhich perform all-class ensemble distillation, our PCD approach performs\nstage-wise distillation for step-by-step knowledge transfer. More specifically,\nwe perform ranking on teacher-student logits difference for identifying\ndistillation priority from scratch, and subsequently divide the entire LD\nprocess into multiple stages. Next, bidirectional stage-wise distillation\nincorporating fine-to-coarse progressive learning and reverse coarse-to-fine\nrefinement is conducted, allowing comprehensive knowledge transfer via\nsufficient logits alignment within separate class groups in different\ndistillation stages. Extension experiments on public benchmarking datasets\ndemonstrate the superiority of our method compared to state-of-the-arts for\nboth classification and detection tasks.", "published": "2025-05-30 07:49:01", "link": "http://arxiv.org/abs/2505.24310v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping", "abstract": "Recent advancements in 3D robotic manipulation have improved grasping of\neveryday objects, but transparent and specular materials remain challenging due\nto depth sensing limitations. While several 3D reconstruction and depth\ncompletion approaches address these challenges, they suffer from setup\ncomplexity or limited observation information utilization. To address this,\nleveraging the power of single view 3D object reconstruction approaches, we\npropose a training free framework SR3D that enables robotic grasping of\ntransparent and specular objects from a single view observation. Specifically,\ngiven single view RGB and depth images, SR3D first uses the external visual\nmodels to generate 3D reconstructed object mesh based on RGB image. Then, the\nkey idea is to determine the 3D object's pose and scale to accurately localize\nthe reconstructed object back into its original depth corrupted 3D scene.\nTherefore, we propose view matching and keypoint matching mechanisms,which\nleverage both the 2D and 3D's inherent semantic and geometric information in\nthe observation to determine the object's 3D state within the scene, thereby\nreconstructing an accurate 3D depth map for effective grasp detection.\nExperiments in both simulation and real world show the reconstruction\neffectiveness of SR3D.", "published": "2025-05-30 07:38:46", "link": "http://arxiv.org/abs/2505.24305v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Category-aware EEG image generation based on wavelet transform and contrast semantic loss", "abstract": "Reconstructing visual stimuli from EEG signals is a crucial step in realizing\nbrain-computer interfaces. In this paper, we propose a transformer-based EEG\nsignal encoder integrating the Discrete Wavelet Transform (DWT) and the gating\nmechanism. Guided by the feature alignment and category-aware fusion losses,\nthis encoder is used to extract features related to visual stimuli from EEG\nsignals. Subsequently, with the aid of a pre-trained diffusion model, these\nfeatures are reconstructed into visual stimuli. To verify the effectiveness of\nthe model, we conducted EEG-to-image generation and classification tasks using\nthe THINGS-EEG dataset. To address the limitations of quantitative analysis at\nthe semantic level, we combined WordNet-based classification and semantic\nsimilarity metrics to propose a novel semantic-based score, emphasizing the\nability of our model to transfer neural activities into visual representations.\nExperimental results show that our model significantly improves semantic\nalignment and classification accuracy, which achieves a maximum single-subject\naccuracy of 43\\%, outperforming other state-of-the-art methods. The source code\nand supplementary material is available at\nhttps://github.com/zes0v0inn/DWT_EEG_Reconstruction/tree/main.", "published": "2025-05-30 07:24:58", "link": "http://arxiv.org/abs/2505.24301v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "EgoExOR: An Ego-Exo-Centric Operating Room Dataset for Surgical Activity Understanding", "abstract": "Operating rooms (ORs) demand precise coordination among surgeons, nurses, and\nequipment in a fast-paced, occlusion-heavy environment, necessitating advanced\nperception models to enhance safety and efficiency. Existing datasets either\nprovide partial egocentric views or sparse exocentric multi-view context, but\ndo not explore the comprehensive combination of both. We introduce EgoExOR, the\nfirst OR dataset and accompanying benchmark to fuse first-person and\nthird-person perspectives. Spanning 94 minutes (84,553 frames at 15 FPS) of two\nemulated spine procedures, Ultrasound-Guided Needle Insertion and Minimally\nInvasive Spine Surgery, EgoExOR integrates egocentric data (RGB, gaze, hand\ntracking, audio) from wearable glasses, exocentric RGB and depth from RGB-D\ncameras, and ultrasound imagery. Its detailed scene graph annotations, covering\n36 entities and 22 relations (568,235 triplets), enable robust modeling of\nclinical interactions, supporting tasks like action recognition and\nhuman-centric perception. We evaluate the surgical scene graph generation\nperformance of two adapted state-of-the-art models and offer a new baseline\nthat explicitly leverages EgoExOR's multimodal and multi-perspective signals.\nThis new dataset and benchmark set a new foundation for OR perception, offering\na rich, multimodal resource for next-generation clinical perception.", "published": "2025-05-30 07:02:00", "link": "http://arxiv.org/abs/2505.24287v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "LLM-powered Query Expansion for Enhancing Boundary Prediction in Language-driven Action Localization", "abstract": "Language-driven action localization in videos requires not only semantic\nalignment between language query and video segment, but also prediction of\naction boundaries.\n  However, the language query primarily describes the main content of an action\nand usually lacks specific details of action start and end boundaries, which\nincreases the subjectivity of manual boundary annotation and leads to boundary\nuncertainty in training data.\n  In this paper, on one hand, we propose to expand the original query by\ngenerating textual descriptions of the action start and end boundaries through\nLLMs, which can provide more detailed boundary cues for localization and thus\nreduce the impact of boundary uncertainty.\n  On the other hand, to enhance the tolerance to boundary uncertainty during\ntraining, we propose to model probability scores of action boundaries by\ncalculating the semantic similarities between frames and the expanded query as\nwell as the temporal distances between frames and the annotated boundary\nframes. They can provide more consistent boundary supervision, thus improving\nthe stability of training.\n  Our method is model-agnostic and can be seamlessly and easily integrated into\nany existing models of language-driven action localization in an off-the-shelf\nmanner. Experimental results on several datasets demonstrate the effectiveness\nof our method.", "published": "2025-05-30 06:59:35", "link": "http://arxiv.org/abs/2505.24282v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Out of Sight, Not Out of Context? Egocentric Spatial Reasoning in VLMs Across Disjoint Frames", "abstract": "An embodied AI assistant operating on egocentric video must integrate spatial\ncues across time - for instance, determining where an object A, glimpsed a few\nmoments ago lies relative to an object B encountered later. We introduce\nDisjoint-3DQA , a generative QA benchmark that evaluates this ability of VLMs\nby posing questions about object pairs that are not co-visible in the same\nframe. We evaluated seven state-of-the-art VLMs and found that models lag\nbehind human performance by 28%, with steeper declines in accuracy (60% to 30\n%) as the temporal gap widens. Our analysis further reveals that providing\ntrajectories or bird's-eye-view projections to VLMs results in only marginal\nimprovements, whereas providing oracle 3D coordinates leads to a substantial\n20% performance increase. This highlights a core bottleneck of multi-frame VLMs\nin constructing and maintaining 3D scene representations over time from visual\nsignals. Disjoint-3DQA therefore sets a clear, measurable challenge for\nlong-horizon spatial reasoning and aims to catalyze future research at the\nintersection of vision, language, and embodied AI.", "published": "2025-05-30 06:32:26", "link": "http://arxiv.org/abs/2505.24257v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Harnessing Foundation Models for Robust and Generalizable 6-DOF Bronchoscopy Localization", "abstract": "Vision-based 6-DOF bronchoscopy localization offers a promising solution for\naccurate and cost-effective interventional guidance. However, existing methods\nstruggle with 1) limited generalization across patient cases due to scarce\nlabeled data, and 2) poor robustness under visual degradation, as bronchoscopy\nprocedures frequently involve artifacts such as occlusions and motion blur that\nimpair visual information. To address these challenges, we propose PANSv2, a\ngeneralizable and robust bronchoscopy localization framework. Motivated by PANS\nthat leverages multiple visual cues for pose likelihood measurement, PANSv2\nintegrates depth estimation, landmark detection, and centerline constraints\ninto a unified pose optimization framework that evaluates pose probability and\nsolves for the optimal bronchoscope pose. To further enhance generalization\ncapabilities, we leverage the endoscopic foundation model EndoOmni for depth\nestimation and the video foundation model EndoMamba for landmark detection,\nincorporating both spatial and temporal analyses. Pretrained on diverse\nendoscopic datasets, these models provide stable and transferable visual\nrepresentations, enabling reliable performance across varied bronchoscopy\nscenarios. Additionally, to improve robustness to visual degradation, we\nintroduce an automatic re-initialization module that detects tracking failures\nand re-establishes pose using landmark detections once clear views are\navailable. Experimental results on bronchoscopy dataset encompassing 10 patient\ncases show that PANSv2 achieves the highest tracking success rate, with an\n18.1% improvement in SR-5 (percentage of absolute trajectory error under 5 mm)\ncompared to existing methods, showing potential towards real clinical usage.", "published": "2025-05-30 06:14:12", "link": "http://arxiv.org/abs/2505.24249v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "50 Years of Automated Face Recognition", "abstract": "Over the past 50 years, automated face recognition has evolved from\nrudimentary, handcrafted systems into sophisticated deep learning models that\nrival and often surpass human performance. This paper chronicles the history\nand technological progression of FR, from early geometric and statistical\nmethods to modern deep neural architectures leveraging massive real and\nAI-generated datasets. We examine key innovations that have shaped the field,\nincluding developments in dataset, loss function, neural network design and\nfeature fusion. We also analyze how the scale and diversity of training data\ninfluence model generalization, drawing connections between dataset growth and\nbenchmark improvements. Recent advances have achieved remarkable milestones:\nstate-of-the-art face verification systems now report False Negative\nIdentification Rates of 0.13% against a 12.4 million gallery in NIST FRVT\nevaluations for 1:N visa-to-border matching. While recent advances have enabled\nremarkable accuracy in high- and low-quality face scenarios, numerous\nchallenges persist. While remarkable progress has been achieved, several open\nresearch problems remain. We outline critical challenges and promising\ndirections for future face recognition research, including scalability,\nmulti-modal fusion, synthetic identity generation, and explainable systems.", "published": "2025-05-30 06:10:48", "link": "http://arxiv.org/abs/2505.24247v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Computational Search for Minimal Obstruction Graphs for the Lov\u00e1sz--Schrijver SDP Hierarchy", "abstract": "We study the lift-and-project relaxations of the stable set polytope of\ngraphs generated by $\\text{LS}_+$, the SDP lift-and-project operator devised by\nLov\\'{a}sz and Schrijver. In particular, we focus on searching for\n$\\ell$-minimal graphs, which are graphs on $3\\ell$ vertices whose stable set\npolytope has rank $\\ell$ with respect to $\\text{LS}_+$. These are the graphs\nwhich are the most challenging for the $\\text{LS}_+$ operator according to one\nof the main complexity measures (smallest graphs with largest\n$\\text{LS}_+$-rank). We introduce the notion of $\\text{LS}_+$ certificate\npackages, which is a framework that allows for efficient and reliable\nverification of membership of points in $\\text{LS}_+$-relaxations. Using this\nframework, we present numerical certificates which (combined with other\nresults) show that there are at least $49$ $3$-minimal graphs, as well as over\n$4000$ $4$-minimal graphs. This marks a significant leap from the $14$\n$3$-minimal and $588$ $4$-minimal graphs known before this work, with many of\nthe newly-discovered graphs containing novel structures which helps enrich and\nrecalibrate our understanding of $\\ell$-minimal graphs. Some of this\ncomputational work leads to interesting conjectures. We also find all of the\nsmallest vertex-transitive graphs with $\\text{LS}_+$-rank $\\ell$ for every\n$\\ell \\leq 4$.", "published": "2025-05-30 15:55:45", "link": "http://arxiv.org/abs/2505.24735v1", "categories": ["math.CO", "cs.DM", "math.OC", "90C22, 90C27"], "primary_category": "math.CO"}
{"title": "On the maximum number of edges of outer k-planar graphs", "abstract": "We study the maximum number of straight-line segments connecting $n$ points\nin convex position in the plane, so that each segment intersects at most $k$\nothers. This question can also be framed as the maximum number of edges of an\nouter $k$-planar graph on $n$ vertices. We outline several approaches to tackle\nthe problem with the best approach yielding an upper bound of\n$(\\sqrt{2}+\\varepsilon)\\sqrt{k}n$ edges (with $\\varepsilon \\rightarrow 0$ for\nsufficiently large $k$). We further investigate the case where the points are\narbitrarily bicolored and segments always connect two different colors (i.e.,\nthe corresponding graph has to be bipartite). To this end, we also consider the\nmaximum cut problem for the circulant graph $C_n^{1,2,\\dots,r}$ which might be\nof independent interest.", "published": "2025-05-30 11:43:14", "link": "http://arxiv.org/abs/2505.24490v1", "categories": ["math.CO", "cs.DM", "05C10, 05C62", "G.2.2"], "primary_category": "math.CO"}
{"title": "A first view on the density of 5-planar graphs", "abstract": "$k$-planar graphs are generalizations of planar graphs that can be drawn in\nthe plane with at most $k > 0$ crossings per edge. One of the central research\nquestions of $k$-planarity is the maximum edge density, i.e., the maximum\nnumber of edges a $k$-planar graph on $n$ vertices may have. While there are\nnumerous results for the classes of general $k$-planar graphs for $k\\leq 2$,\nthere are only very few results for increasing $k=3$ or $4$ due to the\ncomplexity of the classes. We make a first step towards even larger $k>4$ by\nexploring the class of $5$-planar graphs. While our main tool is still the\ndischarging technique, a better understanding of the structure of the denser\nparts leads to corresponding density bounds in a much simpler way.\n  We first apply a simplified version of our technique to outer $5$-planar\ngraphs and use the resulting density bound to assert that the structure of\nmaximally dense $5$-planar graphs differs from the uniform structure when $k$\nis small. As the central result of this paper, we then show that simple\n$5$-planar graphs have at most $\\frac{340}{49}(n-2) \\approx 6.94(n-2)$ edges,\nwhich is a drastic improvement from the previous best bound of $\\approx8.3n$.\nThis even implies a small improvement of the leading constant in the Crossing\nLemma $cr(G) \\ge c \\frac{m^3}{n^2}$ from $c=\\frac{1}{27.48}$ to\n$c=\\frac{1}{27.19}$. To demonstrate the potential of our new technique, we also\napply it to other graph classes, such as 4-planar and 6-planar graphs.", "published": "2025-05-30 08:55:29", "link": "http://arxiv.org/abs/2505.24364v1", "categories": ["cs.DM", "math.CO", "05C62, 05C10", "G.2.2"], "primary_category": "cs.DM"}
{"title": "Cartesian Prime Graphs and Cospectral Families", "abstract": "We introduce a method for constructing larger families of connected\ncospectral graphs from two given cospectral families of sizes $p$ and $q$. The\nresulting family size depends on the Cartesian primality of the input graphs\nand can be one of $pq$, $p + q - 1$, or $\\max(p, q)$, based on the strictness\nof the applied conditions. Under the strictest condition, our method generates\n$O(p^3q^3)$ new cospectral triplets, while the more relaxed conditions yield\n$\\varOmega(pq^3 + qp^3)$ such triplets. We also use the existence of specific\ncospectral families to establish that of larger ones.", "published": "2025-05-30 08:49:56", "link": "http://arxiv.org/abs/2505.24358v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Context is Gold to find the Gold Passage: Evaluating and Training Contextual Document Embeddings", "abstract": "A limitation of modern document retrieval embedding methods is that they\ntypically encode passages (chunks) from the same documents independently, often\noverlooking crucial contextual information from the rest of the document that\ncould greatly improve individual chunk representations.\n  In this work, we introduce ConTEB (Context-aware Text Embedding Benchmark), a\nbenchmark designed to evaluate retrieval models on their ability to leverage\ndocument-wide context. Our results show that state-of-the-art embedding models\nstruggle in retrieval scenarios where context is required. To address this\nlimitation, we propose InSeNT (In-sequence Negative Training), a novel\ncontrastive post-training approach which combined with late chunking pooling\nenhances contextual representation learning while preserving computational\nefficiency. Our method significantly improves retrieval quality on ConTEB\nwithout sacrificing base model performance. We further find chunks embedded\nwith our method are more robust to suboptimal chunking strategies and larger\nretrieval corpus sizes. We open-source all artifacts at\nhttps://github.com/illuin-tech/contextual-embeddings.", "published": "2025-05-30 16:43:28", "link": "http://arxiv.org/abs/2505.24782v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Novel Discrete Memristor-Coupled Heterogeneous Dual-Neuron Model and Its Application in Multi-Scenario Image Encryption", "abstract": "Simulating brain functions using neural networks is an important area of\nresearch. Recently, discrete memristor-coupled neurons have attracted\nsignificant attention, as memristors effectively mimic synaptic behavior, which\nis essential for learning and memory. This highlights the biological relevance\nof such models. This study introduces a discrete memristive heterogeneous\ndual-neuron network (MHDNN). The stability of the MHDNN is analyzed with\nrespect to initial conditions and a range of neuronal parameters. Numerical\nsimulations demonstrate complex dynamical behaviors. Various neuronal firing\npatterns are investigated under different coupling strengths, and\nsynchronization phenomena between neurons are explored. The MHDNN is\nimplemented and validated on the STM32 hardware platform. An image encryption\nalgorithm based on the MHDNN is proposed, along with two hardware platforms\ntailored for multi-scenario police image encryption. These solutions enable\nreal-time and secure transmission of police data in complex environments,\nreducing hacking risks and enhancing system security.", "published": "2025-05-30 07:12:02", "link": "http://arxiv.org/abs/2505.24294v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "On the Scaling of Robustness and Effectiveness in Dense Retrieval", "abstract": "Robustness and Effectiveness are critical aspects of developing dense\nretrieval models for real-world applications. It is known that there is a\ntrade-off between the two. Recent work has addressed scaling laws of\neffectiveness in dense retrieval, revealing a power-law relationship between\neffectiveness and the size of models and data. Does robustness follow scaling\nlaws too? If so, can scaling improve both robustness and effectiveness\ntogether, or do they remain locked in a trade-off?\n  To answer these questions, we conduct a comprehensive experimental study. We\nfind that:(i) Robustness, including out-of-distribution and adversarial\nrobustness, also follows a scaling law.(ii) Robustness and effectiveness\nexhibit different scaling patterns, leading to significant resource costs when\njointly improving both. Given these findings, we shift to the third factor that\naffects model performance, namely the optimization strategy, beyond the model\nsize and data size. We find that: (i) By fitting different optimization\nstrategies, the joint performance of robustness and effectiveness traces out a\nPareto frontier. (ii) When the optimization strategy strays from Pareto\nefficiency, the joint performance scales in a sub-optimal direction. (iii) By\nadjusting the optimization weights to fit the Pareto efficiency, we can achieve\nPareto training, where the scaling of joint performance becomes most efficient.\nEven without requiring additional resources, Pareto training is comparable to\nthe performance of scaling resources several times under optimization\nstrategies that overly prioritize either robustness or effectiveness. Finally,\nwe demonstrate that our findings can help deploy dense retrieval models in\nreal-world applications that scale efficiently and are balanced for robustness\nand effectiveness.", "published": "2025-05-30 06:57:27", "link": "http://arxiv.org/abs/2505.24279v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "MGS3: A Multi-Granularity Self-Supervised Code Search Framework", "abstract": "In the pursuit of enhancing software reusability and developer productivity,\ncode search has emerged as a key area, aimed at retrieving code snippets\nrelevant to functionalities based on natural language queries. Despite\nsignificant progress in self-supervised code pre-training utilizing the vast\namount of code data in repositories, existing methods have primarily focused on\nleveraging contrastive learning to align natural language with function-level\ncode snippets. These studies have overlooked the abundance of fine-grained\n(such as block-level and statement-level) code snippets prevalent within the\nfunction-level code snippets, which results in suboptimal performance across\nall levels of granularity. To address this problem, we first construct a\nmulti-granularity code search dataset called MGCodeSearchNet, which contains\n536K+ pairs of natural language and code snippets. Subsequently, we introduce a\nnovel Multi-Granularity Self-Supervised contrastive learning code Search\nframework (MGS$^{3}$}). First, MGS$^{3}$ features a Hierarchical\nMulti-Granularity Representation module (HMGR), which leverages syntactic\nstructural relationships for hierarchical representation and aggregates\nfine-grained information into coarser-grained representations. Then, during the\ncontrastive learning phase, we endeavor to construct positive samples of the\nsame granularity for fine-grained code, and introduce in-function negative\nsamples for fine-grained code. Finally, we conduct extensive experiments on\ncode search benchmarks across various granularities, demonstrating that the\nframework exhibits outstanding performance in code search tasks of multiple\ngranularities. These experiments also showcase its model-agnostic nature and\ncompatibility with existing pre-trained code representation models.", "published": "2025-05-30 06:49:39", "link": "http://arxiv.org/abs/2505.24274v1", "categories": ["cs.SE", "cs.IR"], "primary_category": "cs.SE"}
{"title": "Proactive Guidance of Multi-Turn Conversation in Industrial Search", "abstract": "The evolution of Large Language Models (LLMs) has significantly advanced\nmulti-turn conversation systems, emphasizing the need for proactive guidance to\nenhance users' interactions. However, these systems face challenges in\ndynamically adapting to shifts in users' goals and maintaining low latency for\nreal-time interactions. In the Baidu Search AI assistant, an industrial-scale\nmulti-turn search system, we propose a novel two-phase framework to provide\nproactive guidance. The first phase, Goal-adaptive Supervised Fine-Tuning\n(G-SFT), employs a goal adaptation agent that dynamically adapts to user goal\nshifts and provides goal-relevant contextual information. G-SFT also\nincorporates scalable knowledge transfer to distill insights from LLMs into a\nlightweight model for real-time interaction. The second phase, Click-oriented\nReinforcement Learning (C-RL), adopts a generate-rank paradigm, systematically\nconstructs preference pairs from user click signals, and proactively improves\nclick-through rates through more engaging guidance. This dual-phase\narchitecture achieves complementary objectives: G-SFT ensures accurate goal\ntracking, while C-RL optimizes interaction quality through click signal-driven\nreinforcement learning. Extensive experiments demonstrate that our framework\nachieves 86.10% accuracy in offline evaluation (+23.95% over baseline) and\n25.28% CTR in online deployment (149.06% relative improvement), while reducing\ninference latency by 69.55% through scalable knowledge distillation.", "published": "2025-05-30 06:16:30", "link": "http://arxiv.org/abs/2505.24251v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Heterogeneous Graph Masked Contrastive Learning for Robust Recommendation", "abstract": "Heterogeneous graph neural networks (HGNNs) have demonstrated their\nsuperiority in exploiting auxiliary information for recommendation tasks.\nHowever, graphs constructed using meta-paths in HGNNs are usually too dense and\ncontain a large number of noise edges. The propagation mechanism of HGNNs\npropagates even small amounts of noise in a graph to distant neighboring nodes,\nthereby affecting numerous node embeddings. To address this limitation, we\nintroduce a novel model, named Masked Contrastive Learning (MCL), to enhance\nrecommendation robustness to noise. MCL employs a random masking strategy to\naugment the graph via meta-paths, reducing node sensitivity to specific\nneighbors and bolstering embedding robustness. Furthermore, MCL employs\ncontrastive cross-view on a Heterogeneous Information Network (HIN) from two\nperspectives: one-hop neighbors and meta-path neighbors. This approach acquires\nembeddings capturing both local and high-order structures simultaneously for\nrecommendation. Empirical evaluations on three real-world datasets confirm the\nsuperiority of our approach over existing recommendation methods.", "published": "2025-05-30 03:32:26", "link": "http://arxiv.org/abs/2505.24172v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Statistical mechanics of extensive-width Bayesian neural networks near interpolation", "abstract": "For three decades statistical mechanics has been providing a framework to\nanalyse neural networks. However, the theoretically tractable models, e.g.,\nperceptrons, random features models and kernel machines, or multi-index models\nand committee machines with few neurons, remained simple compared to those used\nin applications. In this paper we help reducing the gap between practical\nnetworks and their theoretical understanding through a statistical physics\nanalysis of the supervised learning of a two-layer fully connected network with\ngeneric weight distribution and activation function, whose hidden layer is\nlarge but remains proportional to the inputs dimension. This makes it more\nrealistic than infinitely wide networks where no feature learning occurs, but\nalso more expressive than narrow ones or with fixed inner weights. We focus on\nthe Bayes-optimal learning in the teacher-student scenario, i.e., with a\ndataset generated by another network with the same architecture. We operate\naround interpolation, where the number of trainable parameters and of data are\ncomparable and feature learning emerges. Our analysis uncovers a rich\nphenomenology with various learning transitions as the number of data\nincreases. In particular, the more strongly the features (i.e., hidden neurons\nof the target) contribute to the observed responses, the less data is needed to\nlearn them. Moreover, when the data is scarce, the model only learns non-linear\ncombinations of the teacher weights, rather than \"specialising\" by aligning its\nweights with the teacher's. Specialisation occurs only when enough data becomes\navailable, but it can be hard to find for practical training algorithms,\npossibly due to statistical-to-computational~gaps.", "published": "2025-05-30 17:46:59", "link": "http://arxiv.org/abs/2505.24849v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.IT", "cs.LG", "math.IT"], "primary_category": "stat.ML"}
{"title": "Coordinated Beamforming for RIS-Empowered ISAC Systems over Secure Low-Altitude Networks", "abstract": "Emerging as a cornerstone for next-generation wireless networks, integrated\nsensing and communication (ISAC) systems demand innovative solutions to balance\nspectral efficiency and sensing accuracy. In this paper, we propose a\ncoordinated beamforming framework for a reconfigurable intelligent surface\n(RIS)-empowered ISAC system, where the active precoding at the dual-functional\nbase station (DFBS) and the passive beamforming at the RIS are jointly\noptimized to provide communication services for legitimate unmanned aerial\nvehicles (UAVs) while sensing the unauthorized UAVs. The sum-rate of all\nlegitimate UAVs are maximized, while satisfying the radar sensing\nsignal-to-noise ratio requirements, the transmit power constraints, and the\nreflection coefficients of the RIS. To address the inherent non-convexity from\ncoupled variables, we propose a low-complexity algorithm integrating fractional\nprogramming with alternating optimization, featuring convergence guarantees.\nNumerical results demonstrate that the proposed algorithm achieves higher data\nrate compared to disjoint optimization benchmarks. This underscores RIS's\npivotal role in harmonizing communication and target sensing functionalities\nfor low-altitude networks.", "published": "2025-05-30 17:09:20", "link": "http://arxiv.org/abs/2505.24804v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Robust Distributed Phase Retrieval for Multi-View Compressive Networked Sensing With Outliers", "abstract": "This work examines the multi-view compressive phase retrieval problem in a\ndistributed sensor network, where each sensor device, limited by storage and\nsensing capabilities, can access only intensity measurements from an unknown\npart of the global sparse vector. The goal is to enable each sensor to recover\nits observable sparse signal when measurements are corrupted by outliers. To\nachieve reliable local signal recovery with limited data access, we propose a\ndistributed reconstruction algorithm that enables collaboration among sensor\ndevices without the need to share individual raw data. The proposed scheme\nemploys a two-stage approach that first recovers the amplitude of the global\nsignal (at a central server) and subsequently estimates the observable nonzero\nsignal entries (at each local device). Our analytic results show that perfect\nglobal signal amplitude recovery can be achieved under mild conditions on the\nsupport size of sparse outliers and the view blockage level. In addition, the\nexact reconstruction of locally observed signal components is shown to be\nattainable in the noise-free case by solving a binary optimization problem,\nsubject to a mild requirement on the structure of the sensing matrix. Computer\nsimulations are provided to illustrate the effectiveness of the proposed\nscheme.", "published": "2025-05-30 14:39:12", "link": "http://arxiv.org/abs/2505.24651v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Maximally recoverable codes with locality and availability", "abstract": "In this work, we introduce maximally recoverable codes with locality and\navailability. We consider locally repairable codes (LRCs) where certain subsets\nof $ t $ symbols belong each to $ N $ local repair sets, which are pairwise\ndisjoint after removing the $ t $ symbols, and which are of size $ r+\\delta-1 $\nand can correct $ \\delta-1 $ erasures locally. Classical LRCs with $ N $\ndisjoint repair sets and LRCs with $ N $-availability are recovered when\nsetting $ t = 1 $ and $ t=\\delta-1=1 $, respectively. Allowing $ t > 1 $\nenables our codes to reduce the storage overhead for the same locality and\navailability. In this setting, we define maximally recoverable LRCs (MR-LRCs)\nas those that can correct any globally correctable erasure pattern given the\nlocality and availability constraints. We provide three explicit constructions,\nbased on MSRD codes, each attaining the smallest finite-field sizes for some\nparameter regime. Finally, we extend the known lower bound on finite-field\nsizes from classical MR-LRCs to our setting.", "published": "2025-05-30 13:25:44", "link": "http://arxiv.org/abs/2505.24573v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Identifiability through special linear measurements", "abstract": "We show that one can always identify a point on an algebraic variety $X$\nuniquely with $\\dim X +1$ generic linear measurements taken themselves from a\nvariety under minimal assumptions. As illustrated by several examples the\nresult is sharp, that is, $\\dim X$ measurements are in general not enough for\nunique identifiability.", "published": "2025-05-30 08:09:55", "link": "http://arxiv.org/abs/2505.24328v1", "categories": ["math.AG", "cs.IT", "cs.NA", "math.IT", "math.NA", "14Q15, 15A29, 90C30"], "primary_category": "math.AG"}
{"title": "Multi-Waveguide Pinching Antennas for ISAC", "abstract": "Recently, a novel flexible-antenna technology, called pinching antennas, has\nattracted growing academic interest. By inserting discrete dielectric\nmaterials, pinching antennas can be activated at arbitrary points along\nwaveguides, allowing for flexible customization of large-scale path loss. This\npaper investigates a multi-waveguide pinching-antenna integrated sensing and\ncommunications (ISAC) system, where transmit pinching antennas (TPAs) and\nreceive pinching antennas (RPAs) coordinate to simultaneously detect one\npotential target and serve one downlink user. We formulate a communication rate\nmaximization problem subject to radar signal-to-noise ratio (SNR) requirement,\ntransmit power budget, and the allowable movement region of the TPAs, by\njointly optimizing TPA locations and transmit beamforming design. To address\nthe non-convexity of the problem, we propose a novel fine-tuning approximation\nmethod to reformulate it into a tractable form, followed by a successive convex\napproximation (SCA)-based algorithm to obtain the solution efficiently.\nExtensive simulations validate both the system design and the proposed\nalgorithm. Results show that the proposed method achieves near-optimal\nperformance compared with the computational-intensive exhaustive search-based\nbenchmark, and pinching-antenna ISAC systems exhibit a distinct\ncommunication-sensing trade-off compared with conventional systems.", "published": "2025-05-30 07:41:31", "link": "http://arxiv.org/abs/2505.24307v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Rydberg Atomic Receivers for Multi-Band Communications and Sensing", "abstract": "Harnessing multi-level electron transitions, Rydberg Atomic Receivers (RAREs)\ncan detect wireless signals across a wide range of frequency bands, from\nMegahertz to Terahertz, enabling multi-band communications and sensing (C&S).\nCurrent research on multi-band RAREs primarily focuses on experimental\ndemonstrations, lacking an interpretable model to mathematically characterize\ntheir mechanisms. This issue leaves the multi-band RARE as a black box, posing\nchallenges in its practical C&S applications. To fill in this gap, this paper\ninvestigates the underlying mechanism of multi-band RAREs and explores their\noptimal performance. For the first time, the closed-form expression of the\ntransfer function of a multi-band RARE is derived by solving the quantum\nresponse of Rydberg atoms excited by multi-band signals. The function reveals\nthat a multiband RARE simultaneously serves as both a multi-band atomic mixer\nfor down-converting multi-band signals and a multi-band atomic amplifier that\nreflects its sensitivity to each band. Further analysis of the atomic amplifier\nunveils that the gain factor at each frequency band can be decoupled into a\nglobal gain term and a Rabi attention term. The former determines the overall\nsensitivity of a RARE to all frequency bands of wireless signals. The latter\ninfluences the allocation of the overall sensitivity to each frequency band,\nrepresenting a unique attention mechanism of multi-band RAREs. The optimal\ndesign of the global gain is provided to maximize the overall sensitivity of\nmulti-band RAREs. Subsequently, the optimal Rabi attentions are also derived to\nmaximize the practical multi-band C&S performance. Numerical results confirm\nthe effectiveness of the derived transfer function and the superiority of\nmulti-band RAREs.", "published": "2025-05-30 03:22:23", "link": "http://arxiv.org/abs/2505.24168v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Bounds on the Excess Minimum Risk via Generalized Information Divergence Measures", "abstract": "Given finite-dimensional random vectors $Y$, $X$, and $Z$ that form a Markov\nchain in that order (i.e., $Y \\to X \\to Z$), we derive upper bounds on the\nexcess minimum risk using generalized information divergence measures. Here,\n$Y$ is a target vector to be estimated from an observed feature vector $X$ or\nits stochastically degraded version $Z$. The excess minimum risk is defined as\nthe difference between the minimum expected loss in estimating $Y$ from $X$ and\nfrom $Z$. We present a family of bounds that generalize the mutual information\nbased bound of Gy\\\"orfi et al. (2023), using the R\\'enyi and\n$\\alpha$-Jensen-Shannon divergences, as well as Sibson's mutual information.\nOur bounds are similar to those developed by Modak et al. (2021) and Aminian et\nal. (2024) for the generalization error of learning algorithms. However, unlike\nthese works, our bounds do not require the sub-Gaussian parameter to be\nconstant and therefore apply to a broader class of joint distributions over\n$Y$, $X$, and $Z$. We also provide numerical examples under both constant and\nnon-constant sub-Gaussianity assumptions, illustrating that our generalized\ndivergence based bounds can be tighter than the one based on mutual information\nfor certain regimes of the parameter $\\alpha$.", "published": "2025-05-30 01:28:18", "link": "http://arxiv.org/abs/2505.24117v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models", "abstract": "Neuro-symbolic learning was proposed to address challenges with training\nneural networks for complex reasoning tasks with the added benefits of\ninterpretability, reliability, and efficiency. Neuro-symbolic learning methods\ntraditionally train neural models in conjunction with symbolic programs, but\nthey face significant challenges that limit them to simplistic problems. On the\nother hand, purely-neural foundation models now reach state-of-the-art\nperformance through prompting rather than training, but they are often\nunreliable and lack interpretability. Supplementing foundation models with\nsymbolic programs, which we call neuro-symbolic prompting, provides a way to\nuse these models for complex reasoning tasks. Doing so raises the question:\nWhat role does specialized model training as part of neuro-symbolic learning\nhave in the age of foundation models? To explore this question, we highlight\nthree pitfalls of traditional neuro-symbolic learning with respect to the\ncompute, data, and programs leading to generalization problems. This position\npaper argues that foundation models enable generalizable neuro-symbolic\nsolutions, offering a path towards achieving the original goals of\nneuro-symbolic learning without the downsides of training from scratch.", "published": "2025-05-30 17:59:46", "link": "http://arxiv.org/abs/2505.24874v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Accelerated Sampling from Masked Diffusion Models via Entropy Bounded Unmasking", "abstract": "Recent masked diffusion models (MDMs) have shown competitive performance\ncompared to autoregressive models (ARMs) for language modeling. While most\nliterature has focused on performance enhancing sampling procedures, efficient\nsampling from MDMs has been scarcely explored. We make the observation that\noften a given sequence of partially masked tokens determines the values of\nmultiple unknown tokens deterministically, meaning that a single prediction of\na masked model holds additional information unused by standard sampling\nprocedures. Based on this observation, we introduce EB-Sampler, a simple\ndrop-in replacement for existing samplers, utilizing an Entropy Bounded\nunmasking procedure that dynamically unmasks multiple tokens in one function\nevaluation with predefined approximate error tolerance. We formulate the\nEB-Sampler as part of a broad family of adaptive samplers for which we provide\nan error analysis that motivates our algorithmic choices. EB-Sampler\naccelerates sampling from current state of the art MDMs by roughly 2-3x on\nstandard coding and math reasoning benchmarks without loss in performance. We\nalso validate the same procedure works well on smaller reasoning tasks\nincluding maze navigation and Sudoku, tasks ARMs often struggle with.", "published": "2025-05-30 17:52:55", "link": "http://arxiv.org/abs/2505.24857v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Chameleon: A MatMul-Free Temporal Convolutional Network Accelerator for End-to-End Few-Shot and Continual Learning from Sequential Data", "abstract": "On-device learning at the edge enables low-latency, private personalization\nwith improved long-term robustness and reduced maintenance costs. Yet,\nachieving scalable, low-power end-to-end on-chip learning, especially from\nreal-world sequential data with a limited number of examples, is an open\nchallenge. Indeed, accelerators supporting error backpropagation optimize for\nlearning performance at the expense of inference efficiency, while simplified\nlearning algorithms often fail to reach acceptable accuracy targets. In this\nwork, we present Chameleon, leveraging three key contributions to solve these\nchallenges. (i) A unified learning and inference architecture supports few-shot\nlearning (FSL), continual learning (CL) and inference at only 0.5% area\noverhead to the inference logic. (ii) Long temporal dependencies are\nefficiently captured with temporal convolutional networks (TCNs), enabling the\nfirst demonstration of end-to-end on-chip FSL and CL on sequential data and\ninference on 16-kHz raw audio. (iii) A dual-mode, matrix-multiplication-free\ncompute array allows either matching the power consumption of state-of-the-art\ninference-only keyword spotting (KWS) accelerators or enabling $4.3\\times$\nhigher peak GOPS. Fabricated in 40-nm CMOS, Chameleon sets new accuracy records\non Omniglot for end-to-end on-chip FSL (96.8%, 5-way 1-shot, 98.8%, 5-way\n5-shot) and CL (82.2% final accuracy for learning 250 classes with 10 shots),\nwhile maintaining an inference accuracy of 93.3% on the 12-class Google Speech\nCommands dataset at an extreme-edge power budget of 3.1 $\\mu$W.", "published": "2025-05-30 17:49:30", "link": "http://arxiv.org/abs/2505.24852v1", "categories": ["cs.AR", "cs.LG", "C.3; B.6.0; B.7.0; I.2.6; B.5.0"], "primary_category": "cs.AR"}
{"title": "From Invariant Representations to Invariant Data: Provable Robustness to Spurious Correlations via Noisy Counterfactual Matching", "abstract": "Spurious correlations can cause model performance to degrade in new\nenvironments. Prior causality-inspired works aim to learn invariant\nrepresentations (e.g., IRM) but typically underperform empirical risk\nminimization (ERM). Recent alternatives improve robustness by leveraging\ntest-time data, but such data may be unavailable in practice. To address these\nissues, we take a data-centric approach by leveraging invariant data pairs,\npairs of samples that would have the same prediction with the optimally robust\nclassifier. We prove that certain counterfactual pairs will naturally satisfy\nthis invariance property and introduce noisy counterfactual matching (NCM), a\nsimple constraint-based method for leveraging invariant pairs for enhanced\nrobustness, even with a small set of noisy pairs-in the ideal case, each pair\ncan eliminate one spurious feature. For linear causal models, we prove that the\ntest domain error can be upper bounded by the in-domain error and a term that\ndepends on the counterfactuals' diversity and quality. We validate on a\nsynthetic dataset and demonstrate on real-world benchmarks that linear probing\non a pretrained backbone improves robustness.", "published": "2025-05-30 17:42:32", "link": "http://arxiv.org/abs/2505.24843v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Cascading Adversarial Bias from Injection to Distillation in Language Models", "abstract": "Model distillation has become essential for creating smaller, deployable\nlanguage models that retain larger system capabilities. However, widespread\ndeployment raises concerns about resilience to adversarial manipulation. This\npaper investigates vulnerability of distilled models to adversarial injection\nof biased content during training. We demonstrate that adversaries can inject\nsubtle biases into teacher models through minimal data poisoning, which\npropagates to student models and becomes significantly amplified. We propose\ntwo propagation modes: Untargeted Propagation, where bias affects multiple\ntasks, and Targeted Propagation, focusing on specific tasks while maintaining\nnormal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning\nrate), student models generate biased responses 76.9% of the time in targeted\nscenarios - higher than 69.4% in teacher models. For untargeted propagation,\nadversarial bias appears 6x-29x more frequently in student models on unseen\ntasks. We validate findings across six bias types (targeted advertisements,\nphishing links, narrative manipulations, insecure coding practices), various\ndistillation methods, and different modalities spanning text and code\ngeneration. Our evaluation reveals shortcomings in current defenses -\nperplexity filtering, bias detection systems, and LLM-based autorater\nframeworks - against these attacks. Results expose significant security\nvulnerabilities in distilled models, highlighting need for specialized\nsafeguards. We propose practical design principles for building effective\nadversarial bias mitigation strategies.", "published": "2025-05-30 17:41:58", "link": "http://arxiv.org/abs/2505.24842v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Timing is important: Risk-aware Fund Allocation based on Time-Series Forecasting", "abstract": "Fund allocation has been an increasingly important problem in the financial\ndomain. In reality, we aim to allocate the funds to buy certain assets within a\ncertain future period. Naive solutions such as prediction-only or\nPredict-then-Optimize approaches suffer from goal mismatch. Additionally, the\nintroduction of the SOTA time series forecasting model inevitably introduces\nadditional uncertainty in the predicted result. To solve both problems\nmentioned above, we introduce a Risk-aware Time-Series Predict-and-Allocate\n(RTS-PnO) framework, which holds no prior assumption on the forecasting models.\nSuch a framework contains three features: (i) end-to-end training with\nobjective alignment measurement, (ii) adaptive forecasting uncertainty\ncalibration, and (iii) agnostic towards forecasting models. The evaluation of\nRTS-PnO is conducted over both online and offline experiments. For offline\nexperiments, eight datasets from three categories of financial applications are\nused: Currency, Stock, and Cryptos. RTS-PnO consistently outperforms other\ncompetitive baselines. The online experiment is conducted on the Cross-Border\nPayment business at FiT, Tencent, and an 8.4\\% decrease in regret is witnessed\nwhen compared with the product-line approach. The code for the offline\nexperiment is available at https://github.com/fuyuanlyu/RTS-PnO.", "published": "2025-05-30 17:36:45", "link": "http://arxiv.org/abs/2505.24835v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ByzFL: Research Framework for Robust Federated Learning", "abstract": "We present ByzFL, an open-source Python library for developing and\nbenchmarking robust federated learning (FL) algorithms. ByzFL provides a\nunified and extensible framework that includes implementations of\nstate-of-the-art robust aggregators, a suite of configurable attacks, and tools\nfor simulating a variety of FL scenarios, including heterogeneous data\ndistributions, multiple training algorithms, and adversarial threat models. The\nlibrary enables systematic experimentation via a single JSON-based\nconfiguration file and includes built-in utilities for result visualization.\nCompatible with PyTorch tensors and NumPy arrays, ByzFL is designed to\nfacilitate reproducible research and rapid prototyping of robust FL solutions.\nByzFL is available at https://byzfl.epfl.ch/, with source code hosted on\nGitHub: https://github.com/LPD-EPFL/byzfl.", "published": "2025-05-30 17:08:15", "link": "http://arxiv.org/abs/2505.24802v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "QGAN-based data augmentation for hybrid quantum-classical neural networks", "abstract": "Quantum neural networks converge faster and achieve higher accuracy than\nclassical models. However, data augmentation in quantum machine learning\nremains underexplored. To tackle data scarcity, we integrate quantum generative\nadversarial networks (QGANs) with hybrid quantum-classical neural networks\n(HQCNNs) to develop an augmentation framework. We propose two strategies: a\ngeneral approach to enhance data processing and classification across HQCNNs,\nand a customized strategy that dynamically generates samples tailored to the\nHQCNN's performance on specific data categories, improving its ability to learn\nfrom complex datasets. Simulation experiments on the MNIST dataset demonstrate\nthat QGAN outperforms traditional data augmentation methods and classical GANs.\nCompared to baseline DCGAN, QGAN achieves comparable performance with half the\nparameters, balancing efficiency and effectiveness. This suggests that QGANs\ncan simplify models and generate high-quality data, enhancing HQCNN accuracy\nand performance. These findings pave the way for applying quantum data\naugmentation techniques in machine learning.", "published": "2025-05-30 16:42:31", "link": "http://arxiv.org/abs/2505.24780v1", "categories": ["cs.LG", "quant-ph"], "primary_category": "cs.LG"}
{"title": "EVA-MILP: Towards Standardized Evaluation of MILP Instance Generation", "abstract": "Mixed-Integer Linear Programming (MILP) is fundamental to solving complex\ndecision-making problems. The proliferation of MILP instance generation\nmethods, driven by machine learning's demand for diverse optimization datasets\nand the limitations of static benchmarks, has significantly outpaced\nstandardized evaluation techniques. Consequently, assessing the fidelity and\nutility of synthetic MILP instances remains a critical, multifaceted challenge.\nThis paper introduces a comprehensive benchmark framework designed for the\nsystematic and objective evaluation of MILP instance generation methods. Our\nframework provides a unified and extensible methodology, assessing instance\nquality across crucial dimensions: mathematical validity, structural\nsimilarity, computational hardness, and utility in downstream machine learning\ntasks. A key innovation is its in-depth analysis of solver-internal features --\nparticularly by comparing distributions of key solver outputs including root\nnode gap, heuristic success rates, and cut plane usage -- leveraging the\nsolver's dynamic solution behavior as an `expert assessment' to reveal nuanced\ncomputational resemblances. By offering a structured approach with clearly\ndefined solver-independent and solver-dependent metrics, our benchmark aims to\nfacilitate robust comparisons among diverse generation techniques, spur the\ndevelopment of higher-quality instance generators, and ultimately enhance the\nreliability of research reliant on synthetic MILP data. The framework's\neffectiveness in systematically comparing the fidelity of instance sets is\ndemonstrated using contemporary generative models.", "published": "2025-05-30 16:42:15", "link": "http://arxiv.org/abs/2505.24779v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Diffusion-Based Symbolic Regression", "abstract": "Diffusion has emerged as a powerful framework for generative modeling,\nachieving remarkable success in applications such as image and audio synthesis.\nEnlightened by this progress, we propose a novel diffusion-based approach for\nsymbolic regression. We construct a random mask-based diffusion and denoising\nprocess to generate diverse and high-quality equations. We integrate this\ngenerative processes with a token-wise Group Relative Policy Optimization\n(GRPO) method to conduct efficient reinforcement learning on the given\nmeasurement dataset. In addition, we introduce a long short-term risk-seeking\npolicy to expand the pool of top-performing candidates, further enhancing\nperformance. Extensive experiments and ablation studies have demonstrated the\neffectiveness of our approach.", "published": "2025-05-30 16:39:29", "link": "http://arxiv.org/abs/2505.24776v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "AFLoRA: Adaptive Federated Fine-Tuning of Large Language Models with Resource-Aware Low-Rank Adaption", "abstract": "Federated fine-tuning has emerged as a promising approach to adapt foundation\nmodels to downstream tasks using decentralized data. However, real-world\ndeployment remains challenging due to the high computational and communication\ndemands of fine-tuning Large Language Models (LLMs) on clients with data and\nsystem resources that are heterogeneous and constrained. In such settings, the\nglobal model's performance is often bottlenecked by the weakest clients and\nfurther degraded by the non-IID nature of local data. Although existing methods\nleverage parameter-efficient techniques such as Low-Rank Adaptation (LoRA) to\nreduce communication and computation overhead, they often fail to\nsimultaneously ensure accurate aggregation of low-rank updates and maintain low\nsystem costs, thereby hindering overall performance. To address these\nchallenges, we propose AFLoRA, an adaptive and lightweight federated\nfine-tuning framework for LLMs. AFLoRA decouples shared and client-specific\nupdates to reduce overhead and improve aggregation accuracy, incorporates\ndiagonal matrix-based rank pruning to better utilize local resources, and\nemploys rank-aware aggregation with public data refinement to strengthen\ngeneralization under data heterogeneity. Extensive experiments demonstrate that\nAFLoRA outperforms state-of-the-art methods in both accuracy and efficiency,\nproviding a practical solution for efficient LLM adaptation in heterogeneous\nenvironments in the real world.", "published": "2025-05-30 16:35:32", "link": "http://arxiv.org/abs/2505.24773v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Generalization Dynamics of Linear Diffusion Models", "abstract": "Diffusion models trained on finite datasets with $N$ samples from a target\ndistribution exhibit a transition from memorisation, where the model reproduces\ntraining examples, to generalisation, where it produces novel samples that\nreflect the underlying data distribution. Understanding this transition is key\nto characterising the sample efficiency and reliability of generative models,\nbut our theoretical understanding of this transition is incomplete. Here, we\nanalytically study the memorisation-to-generalisation transition in a simple\nmodel using linear denoisers, which allow explicit computation of test errors,\nsampling distributions, and Kullback-Leibler divergences between samples and\ntarget distribution. Using these measures, we predict that this transition\noccurs roughly when $N \\asymp d$, the dimension of the inputs. When $N$ is\nsmaller than the dimension of the inputs $d$, so that only a fraction of\nrelevant directions of variation are present in the training data, we\ndemonstrate how both regularization and early stopping help to prevent\noverfitting. For $N > d$, we find that the sampling distributions of linear\ndiffusion models approach their optimum (measured by the Kullback-Leibler\ndivergence) linearly with $d/N$, independent of the specifics of the data\ndistribution. Our work clarifies how sample complexity governs generalisation\nin a simple model of diffusion-based generative models and provides insight\ninto the training dynamics of linear denoisers.", "published": "2025-05-30 16:31:58", "link": "http://arxiv.org/abs/2505.24769v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Adapting to Linear Separable Subsets with Large-Margin in Differentially Private Learning", "abstract": "This paper studies the problem of differentially private empirical risk\nminimization (DP-ERM) for binary linear classification. We obtain an efficient\n$(\\varepsilon,\\delta)$-DP algorithm with an empirical zero-one risk bound of\n$\\tilde{O}\\left(\\frac{1}{\\gamma^2\\varepsilon n} +\n\\frac{|S_{\\mathrm{out}}|}{\\gamma n}\\right)$ where $n$ is the number of data\npoints, $S_{\\mathrm{out}}$ is an arbitrary subset of data one can remove and\n$\\gamma$ is the margin of linear separation of the remaining data points (after\n$S_{\\mathrm{out}}$ is removed). Here, $\\tilde{O}(\\cdot)$ hides only logarithmic\nterms. In the agnostic case, we improve the existing results when the number of\noutliers is small. Our algorithm is highly adaptive because it does not require\nknowing the margin parameter $\\gamma$ or outlier subset $S_{\\mathrm{out}}$. We\nalso derive a utility bound for the advanced private hyperparameter tuning\nalgorithm.", "published": "2025-05-30 15:56:58", "link": "http://arxiv.org/abs/2505.24737v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Feature Attribution from First Principles", "abstract": "Feature attribution methods are a popular approach to explain the behavior of\nmachine learning models. They assign importance scores to each input feature,\nquantifying their influence on the model's prediction. However, evaluating\nthese methods empirically remains a significant challenge. To bypass this\nshortcoming, several prior works have proposed axiomatic frameworks that any\nfeature attribution method should satisfy. In this work, we argue that such\naxioms are often too restrictive, and propose in response a new feature\nattribution framework, built from the ground up. Rather than imposing axioms,\nwe start by defining attributions for the simplest possible models, i.e.,\nindicator functions, and use these as building blocks for more complex models.\nWe then show that one recovers several existing attribution methods, depending\non the choice of atomic attribution. Subsequently, we derive closed-form\nexpressions for attribution of deep ReLU networks, and take a step toward the\noptimization of evaluation metrics with respect to feature attributions.", "published": "2025-05-30 15:53:11", "link": "http://arxiv.org/abs/2505.24729v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Robust Federated Learning against Model Perturbation in Edge Networks", "abstract": "Federated Learning (FL) is a promising paradigm for realizing edge\nintelligence, allowing collaborative learning among distributed edge devices by\nsharing models instead of raw data. However, the shared models are often\nassumed to be ideal, which would be inevitably violated in practice due to\nvarious perturbations, leading to significant performance degradation. To\novercome this challenge, we propose a novel method, termed Sharpness-Aware\nMinimization-based Robust Federated Learning (SMRFL), which aims to improve\nmodel robustness against perturbations by exploring the geometrical property of\nthe model landscape. Specifically, SMRFL solves a min-max optimization problem\nthat promotes model convergence towards a flat minimum by minimizing the\nmaximum loss within a neighborhood of the model parameters. In this way, model\nsensitivity to perturbations is reduced, and robustness is enhanced since\nmodels in the neighborhood of the flat minimum also enjoy low loss values. The\ntheoretical result proves that SMRFL can converge at the same rate as FL\nwithout perturbations. Extensive experimental results show that SMRFL\nsignificantly enhances robustness against perturbations compared to three\nbaseline methods on two real-world datasets under three perturbation scenarios.", "published": "2025-05-30 15:52:05", "link": "http://arxiv.org/abs/2505.24728v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Knockoff-Guided Compressive Sensing: A Statistical Machine Learning Framework for Support-Assured Signal Recovery", "abstract": "This paper introduces a novel Knockoff-guided compressive sensing framework,\nreferred to as \\TheName{}, which enhances signal recovery by leveraging precise\nfalse discovery rate (FDR) control during the support identification phase.\nUnlike LASSO, which jointly performs support selection and signal estimation\nwithout explicit error control, our method guarantees FDR control in finite\nsamples, enabling more reliable identification of the true signal support. By\nseparating and controlling the support recovery process through statistical\nKnockoff filters, our framework achieves more accurate signal reconstruction,\nespecially in challenging scenarios where traditional methods fail. We\nestablish theoretical guarantees demonstrating how FDR control directly ensures\nrecovery performance under weaker conditions than traditional $\\ell_1$-based\ncompressive sensing methods, while maintaining accurate signal reconstruction.\nExtensive numerical experiments demonstrate that our proposed Knockoff-based\nmethod consistently outperforms LASSO-based and other state-of-the-art\ncompressive sensing techniques. In simulation studies, our method improves\nF1-score by up to 3.9x over baseline methods, attributed to principled false\ndiscovery rate (FDR) control and enhanced support recovery. The method also\nconsistently yields lower reconstruction and relative errors. We further\nvalidate the framework on real-world datasets, where it achieves top downstream\npredictive performance across both regression and classification tasks, often\nnarrowing or even surpassing the performance gap relative to uncompressed\nsignals. These results establish \\TheName{} as a robust and practical\nalternative to existing approaches, offering both theoretical guarantees and\nstrong empirical performance through statistically grounded support selection.", "published": "2025-05-30 15:50:58", "link": "http://arxiv.org/abs/2505.24727v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach", "abstract": "Memristor-based hardware offers new possibilities for energy-efficient\nmachine learning (ML) by providing analog in-memory matrix multiplication.\nCurrent hardware prototypes cannot fit large neural networks, and related\nliterature covers only small ML models for tasks like MNIST or single word\nrecognition. Simulation can be used to explore how hardware properties affect\nlarger models, but existing software assumes simplified hardware. We propose a\nPyTorch-based library based on \"Synaptogen\" to simulate neural network\nexecution with accurately captured memristor hardware properties. For the first\ntime, we show how an ML system with millions of parameters would behave on\nmemristor hardware, using a Conformer trained on the speech recognition task\nTED-LIUMv2 as example. With adjusted quantization-aware training, we limit the\nrelative degradation in word error rate to 25% when using a 3-bit weight\nprecision to execute linear operations via simulated analog computation.", "published": "2025-05-30 15:42:41", "link": "http://arxiv.org/abs/2505.24721v1", "categories": ["cs.LG", "cs.AR", "cs.ET"], "primary_category": "cs.LG"}
{"title": "PDE-Transformer: Efficient and Versatile Transformers for Physics Simulations", "abstract": "We introduce PDE-Transformer, an improved transformer-based architecture for\nsurrogate modeling of physics simulations on regular grids. We combine recent\narchitectural improvements of diffusion transformers with adjustments specific\nfor large-scale simulations to yield a more scalable and versatile\ngeneral-purpose transformer architecture, which can be used as the backbone for\nbuilding large-scale foundation models in physical sciences. We demonstrate\nthat our proposed architecture outperforms state-of-the-art transformer\narchitectures for computer vision on a large dataset of 16 different types of\nPDEs. We propose to embed different physical channels individually as\nspatio-temporal tokens, which interact via channel-wise self-attention. This\nhelps to maintain a consistent information density of tokens when learning\nmultiple types of PDEs simultaneously. We demonstrate that our pre-trained\nmodels achieve improved performance on several challenging downstream tasks\ncompared to training from scratch and also beat other foundation model\narchitectures for physics simulations.", "published": "2025-05-30 15:39:54", "link": "http://arxiv.org/abs/2505.24717v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "K$^2$IE: Kernel Method-based Kernel Intensity Estimators for Inhomogeneous Poisson Processes", "abstract": "Kernel method-based intensity estimators, formulated within reproducing\nkernel Hilbert spaces (RKHSs), and classical kernel intensity estimators (KIEs)\nhave been among the most easy-to-implement and feasible methods for estimating\nthe intensity functions of inhomogeneous Poisson processes. While both\napproaches share the term \"kernel\", they are founded on distinct theoretical\nprinciples, each with its own strengths and limitations. In this paper, we\npropose a novel regularized kernel method for Poisson processes based on the\nleast squares loss and show that the resulting intensity estimator involves a\nspecialized variant of the representer theorem: it has the dual coefficient of\nunity and coincides with classical KIEs. This result provides new theoretical\ninsights into the connection between classical KIEs and kernel method-based\nintensity estimators, while enabling us to develop an efficient KIE by\nleveraging advanced techniques from RKHS theory. We refer to the proposed model\nas the kernel method-based kernel intensity estimator (K$^2$IE). Through\nexperiments on synthetic datasets, we show that K$^2$IE achieves comparable\npredictive performance while significantly surpassing the state-of-the-art\nkernel method-based estimator in computational efficiency.", "published": "2025-05-30 15:26:35", "link": "http://arxiv.org/abs/2505.24704v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Quick-Draw Bandits: Quickly Optimizing in Nonstationary Environments with Extremely Many Arms", "abstract": "Canonical algorithms for multi-armed bandits typically assume a stationary\nreward environment where the size of the action space (number of arms) is\nsmall. More recently developed methods typically relax only one of these\nassumptions: existing non-stationary bandit policies are designed for a small\nnumber of arms, while Lipschitz, linear, and Gaussian process bandit policies\nare designed to handle a large (or infinite) number of arms in stationary\nreward environments under constraints on the reward function. In this\nmanuscript, we propose a novel policy to learn reward environments over a\ncontinuous space using Gaussian interpolation. We show that our method\nefficiently learns continuous Lipschitz reward functions with\n$\\mathcal{O}^*(\\sqrt{T})$ cumulative regret. Furthermore, our method naturally\nextends to non-stationary problems with a simple modification. We finally\ndemonstrate that our method is computationally favorable (100-10000x faster)\nand experimentally outperforms sliding Gaussian process policies on datasets\nwith non-stationarity and an extremely large number of arms.", "published": "2025-05-30 15:15:18", "link": "http://arxiv.org/abs/2505.24692v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Predicting the Past: Estimating Historical Appraisals with OCR and Machine Learning", "abstract": "Despite well-documented consequences of the U.S. government's 1930s housing\npolicies on racial wealth disparities, scholars have struggled to quantify its\nprecise financial effects due to the inaccessibility of historical property\nappraisal records. Many counties still store these records in physical formats,\nmaking large-scale quantitative analysis difficult. We present an approach\nscholars can use to digitize historical housing assessment data, applying it to\nbuild and release a dataset for one county. Starting from publicly available\nscanned documents, we manually annotated property cards for over 12,000\nproperties to train and validate our methods. We use OCR to label data for an\nadditional 50,000 properties, based on our two-stage approach combining\nclassical computer vision techniques with deep learning-based OCR. For cases\nwhere OCR cannot be applied, such as when scanned documents are not available,\nwe show how a regression model based on building feature data can estimate the\nhistorical values, and test the generalizability of this model to other\ncounties. With these cost-effective tools, scholars, community activists, and\npolicy makers can better analyze and understand the historical impacts of\nredlining.", "published": "2025-05-30 15:04:21", "link": "http://arxiv.org/abs/2505.24676v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Impact of Bottleneck Layers and Skip Connections on the Generalization of Linear Denoising Autoencoders", "abstract": "Modern deep neural networks exhibit strong generalization even in highly\noverparameterized regimes. Significant progress has been made to understand\nthis phenomenon in the context of supervised learning, but for unsupervised\ntasks such as denoising, several open questions remain. While some recent works\nhave successfully characterized the test error of the linear denoising problem,\nthey are limited to linear models (one-layer network). In this work, we focus\non two-layer linear denoising autoencoders trained under gradient flow,\nincorporating two key ingredients of modern deep learning architectures: A\nlow-dimensional bottleneck layer that effectively enforces a rank constraint on\nthe learned solution, as well as the possibility of a skip connection that\nbypasses the bottleneck. We derive closed-form expressions for all critical\npoints of this model under product regularization, and in particular describe\nits global minimizer under the minimum-norm principle. From there, we derive\nthe test risk formula in the overparameterized regime, both for models with and\nwithout skip connections. Our analysis reveals two interesting phenomena:\nFirstly, the bottleneck layer introduces an additional complexity measure akin\nto the classical bias-variance trade-off -- increasing the bottleneck width\nreduces bias but introduces variance, and vice versa. Secondly, skip connection\ncan mitigate the variance in denoising autoencoders -- especially when the\nmodel is mildly overparameterized. We further analyze the impact of skip\nconnections in denoising autoencoder using random matrix theory and support our\nclaims with numerical evidence.", "published": "2025-05-30 14:58:02", "link": "http://arxiv.org/abs/2505.24668v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Learning geometry and topology via multi-chart flows", "abstract": "Real world data often lie on low-dimensional Riemannian manifolds embedded in\nhigh-dimensional spaces. This motivates learning degenerate normalizing flows\nthat map between the ambient space and a low-dimensional latent space. However,\nif the manifold has a non-trivial topology, it can never be correctly learned\nusing a single flow. Instead multiple flows must be `glued together'. In this\npaper, we first propose the general training scheme for learning such a\ncollection of flows, and secondly we develop the first numerical algorithms for\ncomputing geodesics on such manifolds. Empirically, we demonstrate that this\nleads to highly significant improvements in topology estimation.", "published": "2025-05-30 14:54:25", "link": "http://arxiv.org/abs/2505.24665v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning Distributions over Permutations and Rankings with Factorized Representations", "abstract": "Learning distributions over permutations is a fundamental problem in machine\nlearning, with applications in ranking, combinatorial optimization, structured\nprediction, and data association. Existing methods rely on mixtures of\nparametric families or neural networks with expensive variational inference\nprocedures. In this work, we propose a novel approach that leverages\nalternative representations for permutations, including Lehmer codes,\nFisher-Yates draws, and Insertion-Vectors. These representations form a\nbijection with the symmetric group, allowing for unconstrained learning using\nconventional deep learning techniques, and can represent any probability\ndistribution over permutations. Our approach enables a trade-off between\nexpressivity of the model family and computational requirements. In the least\nexpressive and most computationally efficient case, our method subsumes\nprevious families of well established probabilistic models over permutations,\nincluding Mallow's and the Repeated Insertion Model. Experiments indicate our\nmethod significantly outperforms current approaches on the jigsaw puzzle\nbenchmark, a common task for permutation learning. However, we argue this\nbenchmark is limited in its ability to assess learning probability\ndistributions, as the target is a delta distribution (i.e., a single correct\nsolution exists). We therefore propose two additional benchmarks: learning\ncyclic permutations and re-ranking movies based on user preference. We show\nthat our method learns non-trivial distributions even in the least expressive\nmode, while traditional models fail to even generate valid permutations in this\nsetting.", "published": "2025-05-30 14:53:40", "link": "http://arxiv.org/abs/2505.24664v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "WILTing Trees: Interpreting the Distance Between MPNN Embeddings", "abstract": "We investigate the distance function learned by message passing neural\nnetworks (MPNNs) in specific tasks, aiming to capture the functional distance\nbetween prediction targets that MPNNs implicitly learn. This contrasts with\nprevious work, which links MPNN distances on arbitrary tasks to structural\ndistances on graphs that ignore task-specific information. To address this gap,\nwe distill the distance between MPNN embeddings into an interpretable graph\ndistance. Our method uses optimal transport on the Weisfeiler Leman Labeling\nTree (WILT), where the edge weights reveal subgraphs that strongly influence\nthe distance between embeddings. This approach generalizes two well-known graph\nkernels and can be computed in linear time. Through extensive experiments, we\ndemonstrate that MPNNs define the relative position of embeddings by focusing\non a small set of subgraphs that are known to be functionally important in the\ndomain.", "published": "2025-05-30 14:28:41", "link": "http://arxiv.org/abs/2505.24642v1", "categories": ["cs.LG", "I.2.6"], "primary_category": "cs.LG"}
{"title": "Stop Guessing: Optimizing Goalkeeper Policies for Soccer Penalty Kicks", "abstract": "Penalties are fraught and game-changing moments in soccer games that teams\nexplicitly prepare for. Consequently, there has been substantial interest in\nanalyzing them in order to provide advice to practitioners. From a data science\nperspective, such analyses suffer from a significant limitation: they make the\nunrealistic simplifying assumption that goalkeepers and takers select their\naction -- where to dive and where to the place the kick -- independently of\neach other. In reality, the choices that some goalkeepers make depend on the\ntaker's movements and vice-versa. This adds substantial complexity to the\nproblem because not all players have the same action capacities, that is, only\nsome players are capable of basing their decisions on their opponent's\nmovements. However, the small sample sizes on the player level mean that one\nmay have limited insights into a specific opponent's capacities. We address\nthese challenges by developing a player-agnostic simulation framework that can\nevaluate the efficacy of different goalkeeper strategies. It considers a rich\nset of choices and incorporates information about a goalkeeper's skills. Our\nwork is grounded in a large dataset of penalties that were annotated by penalty\nexperts and include aspects of both kicker and goalkeeper strategies. We show\nhow our framework can be used to optimize goalkeeper policies in real-world\nsituations.", "published": "2025-05-30 14:23:12", "link": "http://arxiv.org/abs/2505.24629v1", "categories": ["cs.LG", "cs.GT"], "primary_category": "cs.LG"}
{"title": "Rethinking Neural Combinatorial Optimization for Vehicle Routing Problems with Different Constraint Tightness Degrees", "abstract": "Recent neural combinatorial optimization (NCO) methods have shown promising\nproblem-solving ability without requiring domain-specific expertise. Most\nexisting NCO methods use training and testing data with a fixed constraint\nvalue and lack research on the effect of constraint tightness on the\nperformance of NCO methods. This paper takes the capacity-constrained vehicle\nrouting problem (CVRP) as an example to empirically analyze the NCO performance\nunder different tightness degrees of the capacity constraint. Our analysis\nreveals that existing NCO methods overfit the capacity constraint, and they can\nonly perform satisfactorily on a small range of the constraint values but\npoorly on other values. To tackle this drawback of existing NCO methods, we\ndevelop an efficient training scheme that explicitly considers varying degrees\nof constraint tightness and proposes a multi-expert module to learn a generally\nadaptable solving strategy. Experimental results show that the proposed method\ncan effectively overcome the overfitting issue, demonstrating superior\nperformances on the CVRP and CVRP with time windows (CVRPTW) with various\nconstraint tightness degrees.", "published": "2025-05-30 14:21:33", "link": "http://arxiv.org/abs/2505.24627v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-criteria Rank-based Aggregation for Explainable AI", "abstract": "Explainability is crucial for improving the transparency of black-box machine\nlearning models. With the advancement of explanation methods such as LIME and\nSHAP, various XAI performance metrics have been developed to evaluate the\nquality of explanations. However, different explainers can provide contrasting\nexplanations for the same prediction, introducing trade-offs across conflicting\nquality metrics. Although available aggregation approaches improve robustness,\nreducing explanations' variability, very limited research employed a\nmulti-criteria decision-making approach. To address this gap, this paper\nintroduces a multi-criteria rank-based weighted aggregation method that\nbalances multiple quality metrics simultaneously to produce an ensemble of\nexplanation models. Furthermore, we propose rank-based versions of existing XAI\nmetrics (complexity, faithfulness and stability) to better evaluate ranked\nfeature importance explanations. Extensive experiments on publicly available\ndatasets demonstrate the robustness of the proposed model across these metrics.\nComparative analyses of various multi-criteria decision-making and rank\naggregation algorithms showed that TOPSIS and WSUM are the best candidates for\nthis use case.", "published": "2025-05-30 14:02:59", "link": "http://arxiv.org/abs/2505.24612v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The Gaussian Mixing Mechanism: Renyi Differential Privacy via Gaussian Sketches", "abstract": "Gaussian sketching, which consists of pre-multiplying the data with a random\nGaussian matrix, is a widely used technique for multiple problems in data\nscience and machine learning, with applications spanning computationally\nefficient optimization, coded computing, and federated learning. This operation\nalso provides differential privacy guarantees due to its inherent randomness.\nIn this work, we revisit this operation through the lens of Renyi Differential\nPrivacy (RDP), providing a refined privacy analysis that yields significantly\ntighter bounds than prior results. We then demonstrate how this improved\nanalysis leads to performance improvement in different linear regression\nsettings, establishing theoretical utility guarantees. Empirically, our methods\nimprove performance across multiple datasets and, in several cases, reduce\nruntime.", "published": "2025-05-30 13:52:48", "link": "http://arxiv.org/abs/2505.24603v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Conservation-preserved Fourier Neural Operator through Adaptive Correction", "abstract": "Fourier Neural Operators (FNOs) have recently emerged as a promising and\nefficient approach for learning the numerical solutions to partial differential\nequations (PDEs) from data. However, standard FNO often fails to preserve key\nconservation laws, such as mass conservation, momentum conservation, norm\nconservation, etc., which are crucial for accurately modeling physical systems.\nExisting methods for incorporating these conservation laws into Fourier neural\noperators are achieved by designing related loss function or incorporating\npost-processing method at the training time. None of them can both exactly and\nadaptively correct the outputs to satisfy conservation laws, and our\nexperiments show that these methods can lead to inferior performance while\npreserving conservation laws. In this work, we propose a novel adaptive\ncorrection approach to ensure the conservation of fundamental quantities. Our\nmethod introduces a learnable matrix to adaptively adjust the solution to\nsatisfy the conservation law during training. It ensures that the outputs\nexactly satisfy the goal conservation law and allow for more flexibility and\nadaptivity for the model to correct the outputs. We theoretically show that\napplying our adaptive correction to an unconstrained FNO yields a solution with\ndata loss no worse than that of the best conservation-satisfying FNO. We\ncompare our approach with existing methods on a range of representative PDEs.\nExperiment results show that our method consistently outperform other methods.", "published": "2025-05-30 13:28:12", "link": "http://arxiv.org/abs/2505.24579v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Neuro-Symbolic Operator for Interpretable and Generalizable Characterization of Complex Piezoelectric Systems", "abstract": "Complex piezoelectric systems are foundational in industrial applications.\nTheir performance, however, is challenged by the nonlinear voltage-displacement\nhysteretic relationships. Efficient characterization methods are, therefore,\nessential for reliable design, monitoring, and maintenance. Recently proposed\nneural operator methods serve as surrogates for system characterization but\nface two pressing issues: interpretability and generalizability.\nState-of-the-art (SOTA) neural operators are black-boxes, providing little\ninsight into the learned operator. Additionally, generalizing them to novel\nvoltages and predicting displacement profiles beyond the training domain is\nchallenging, limiting their practical use. To address these limitations, this\npaper proposes a neuro-symbolic operator (NSO) framework that derives the\nanalytical operators governing hysteretic relationships. NSO first learns a\nFourier neural operator mapping voltage fields to displacement profiles,\nfollowed by a library-based sparse model discovery method, generating white-box\nparsimonious models governing the underlying hysteresis. These models enable\naccurate and interpretable prediction of displacement profiles across varying\nand out-of-distribution voltage fields, facilitating generalizability. The\npotential of NSO is demonstrated by accurately predicting voltage-displacement\nhysteresis, including butterfly-shaped relationships. Moreover, NSO predicts\ndisplacement profiles even for noisy and low-fidelity voltage data, emphasizing\nits robustness. The results highlight the advantages of NSO compared to SOTA\nneural operators and model discovery methods on several evaluation metrics.\nConsequently, NSO contributes to characterizing complex piezoelectric systems\nwhile improving the interpretability and generalizability of neural operators,\nessential for design, monitoring, maintenance, and other real-world scenarios.", "published": "2025-05-30 13:28:11", "link": "http://arxiv.org/abs/2505.24578v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "HLSAD: Hodge Laplacian-based Simplicial Anomaly Detection", "abstract": "In this paper, we propose HLSAD, a novel method for detecting anomalies in\ntime-evolving simplicial complexes. While traditional graph anomaly detection\ntechniques have been extensively studied, they often fail to capture changes in\nhigher-order interactions that are crucial for identifying complex structural\nanomalies. These higher-order interactions can arise either directly from the\nunderlying data itself or through graph lifting techniques. Our approach\nleverages the spectral properties of Hodge Laplacians of simplicial complexes\nto effectively model multi-way interactions among data points. By incorporating\nhigher-dimensional simplicial structures into our method, our method enhances\nboth detection accuracy and computational efficiency. Through comprehensive\nexperiments on both synthetic and real-world datasets, we demonstrate that our\napproach outperforms existing graph methods in detecting both events and change\npoints.", "published": "2025-05-30 12:41:08", "link": "http://arxiv.org/abs/2505.24534v1", "categories": ["cs.LG", "cs.SI"], "primary_category": "cs.LG"}
{"title": "Transformers Are Universally Consistent", "abstract": "Despite their central role in the success of foundational models and\nlarge-scale language modeling, the theoretical foundations governing the\noperation of Transformers remain only partially understood. Contemporary\nresearch has largely focused on their representational capacity for language\ncomprehension and their prowess in in-context learning, frequently under\nidealized assumptions such as linearized attention mechanisms. Initially\nconceived to model sequence-to-sequence transformations, a fundamental and\nunresolved question is whether Transformers can robustly perform functional\nregression over sequences of input tokens. This question assumes heightened\nimportance given the inherently non-Euclidean geometry underlying real-world\ndata distributions. In this work, we establish that Transformers equipped with\nsoftmax-based nonlinear attention are uniformly consistent when tasked with\nexecuting Ordinary Least Squares (OLS) regression, provided both the inputs and\noutputs are embedded in hyperbolic space. We derive deterministic upper bounds\non the empirical error which, in the asymptotic regime, decay at a provable\nrate of $\\mathcal{O}(t^{-1/2d})$, where $t$ denotes the number of input tokens\nand $d$ the embedding dimensionality. Notably, our analysis subsumes the\nEuclidean setting as a special case, recovering analogous convergence\nguarantees parameterized by the intrinsic dimensionality of the data manifold.\nThese theoretical insights are corroborated through empirical evaluations on\nreal-world datasets involving both continuous and categorical response\nvariables.", "published": "2025-05-30 12:39:26", "link": "http://arxiv.org/abs/2505.24531v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Airborne Neural Network", "abstract": "Deep Learning, driven by neural networks, has led to groundbreaking\nadvancements in Artificial Intelligence by enabling systems to learn and adapt\nlike the human brain. These models have achieved remarkable results,\nparticularly in data-intensive domains, supported by massive computational\ninfrastructure. However, deploying such systems in Aerospace, where real time\ndata processing and ultra low latency are critical, remains a challenge due to\ninfrastructure limitations. This paper proposes a novel concept: the Airborne\nNeural Network a distributed architecture where multiple airborne devices each\nhost a subset of neural network neurons. These devices compute collaboratively,\nguided by an airborne network controller and layer specific controllers,\nenabling real-time learning and inference during flight. This approach has the\npotential to revolutionize Aerospace applications, including airborne air\ntraffic control, real-time weather and geographical predictions, and dynamic\ngeospatial data processing. By enabling large-scale neural network operations\nin airborne environments, this work lays the foundation for the next generation\nof AI powered Aerospace systems.", "published": "2025-05-30 12:22:02", "link": "http://arxiv.org/abs/2505.24513v1", "categories": ["cs.LG", "cs.NE"], "primary_category": "cs.LG"}
{"title": "Learning to Optimally Dispatch Power: Performance on a Nation-Wide Real-World Dataset", "abstract": "The Optimal Reactive Power Dispatch (ORPD) problem plays a crucial role in\npower system operations, ensuring voltage stability and minimizing power\nlosses. Recent advances in machine learning, particularly within the ``learning\nto optimize'' framework, have enabled fast and efficient approximations of ORPD\nsolutions, typically by training models on precomputed optimization results.\nWhile these approaches have demonstrated promising performance on synthetic\ndatasets, their effectiveness under real-world grid conditions remains largely\nunexplored. This paper makes two key contributions. First, we introduce a\npublicly available power system dataset that includes both the structural\ncharacteristics of Uruguay's electrical grid and nearly two years of real-world\noperational data, encompassing actual demand and generation profiles. Given\nUruguay's high penetration of renewable energy, the ORPD problem has become the\nprimary optimization challenge in its power network. Second, we assess the\nimpact of real-world data on learning-based ORPD solutions, revealing a\nsignificant increase in prediction errors when transitioning from synthetic to\nactual demand and generation inputs. Our results highlight the limitations of\nexisting models in learning under the complex statistical properties of real\ngrid conditions and emphasize the need for more expressive architectures. By\nproviding this dataset, we aim to facilitate further research into robust\nlearning-based optimization techniques for power system management.", "published": "2025-05-30 12:07:38", "link": "http://arxiv.org/abs/2505.24505v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Efficient Neural and Numerical Methods for High-Quality Online Speech Spectrogram Inversion via Gradient Theorem", "abstract": "Recent work in online speech spectrogram inversion effectively combines Deep\nLearning with the Gradient Theorem to predict phase derivatives directly from\nmagnitudes. Then, phases are estimated from their derivatives via least\nsquares, resulting in a high quality reconstruction. In this work, we introduce\nthree innovations that drastically reduce computational cost, while maintaining\nhigh quality: Firstly, we introduce a novel neural network architecture with\njust 8k parameters, 30 times smaller than previous state of the art. Secondly,\nincreasing latency by 1 hop size allows us to further halve the cost of the\nneural inference step. Thirdly, we we observe that the least squares problem\nfeatures a tridiagonal matrix and propose a linear-complexity solver for the\nleast squares step that leverages tridiagonality and positive-semidefiniteness,\nachieving a speedup of several orders of magnitude. We release samples online.", "published": "2025-05-30 11:51:05", "link": "http://arxiv.org/abs/2505.24498v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Real-time Fall Prevention system for the Next-generation of Workers", "abstract": "Developing a general-purpose wearable real-time fall-detection system is\nstill a challenging task, especially for healthy and strong subjects, such as\nindustrial workers that work in harsh environments. In this work, we present a\nhybrid approach for fall detection and prevention, which uses the dynamic model\nof an inverted pendulum to generate simulations of falling that are then fed to\na deep learning framework. The output is a signal to activate a fall mitigation\nmechanism when the subject is at risk of harm. The advantage of this approach\nis that abstracted models can be used to efficiently generate training data for\nthousands of different subjects with different falling initial conditions,\nsomething that is practically impossible with real experiments. This approach\nis suitable for a specific type of fall, where the subjects fall without\nchanging their initial configuration significantly, and it is the first step\ntoward a general-purpose wearable device, with the aim of reducing\nfall-associated injuries in industrial environments, which can improve the\nsafety of workers.", "published": "2025-05-30 11:41:16", "link": "http://arxiv.org/abs/2505.24487v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Smooth Model Compression without Fine-Tuning", "abstract": "Compressing and pruning large machine learning models has become a critical\nstep towards their deployment in real-world applications. Standard pruning and\ncompression techniques are typically designed without taking the structure of\nthe network's weights into account, limiting their effectiveness. We explore\nthe impact of smooth regularization on neural network training and model\ncompression. By applying nuclear norm, first- and second-order derivative\npenalties of the weights during training, we encourage structured smoothness\nwhile preserving predictive performance on par with non-smooth models. We find\nthat standard pruning methods often perform better when applied to these smooth\nmodels. Building on this observation, we apply a\nSingular-Value-Decomposition-based compression method that exploits the\nunderlying smooth structure and approximates the model's weight tensors by\nsmaller low-rank tensors. Our approach enables state-of-the-art compression\nwithout any fine-tuning - reaching up to $91\\%$ accuracy on a smooth ResNet-18\non CIFAR-10 with $70\\%$ fewer parameters.", "published": "2025-05-30 11:13:48", "link": "http://arxiv.org/abs/2505.24469v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Distributed gradient methods under heavy-tailed communication noise", "abstract": "We consider a standard distributed optimization problem in which networked\nnodes collaboratively minimize the sum of their locally known convex costs. For\nthis setting, we address for the first time the fundamental problem of design\nand analysis of distributed methods to solve the above problem when inter-node\ncommunication is subject to \\emph{heavy-tailed} noise. Heavy-tailed noise is\nhighly relevant and frequently arises in densely deployed wireless sensor and\nInternet of Things (IoT) networks. Specifically, we design a distributed\ngradient-type method that features a carefully balanced mixed time-scale\ntime-varying consensus and gradient contribution step sizes and a bounded\nnonlinear operator on the consensus update to limit the effect of heavy-tailed\nnoise. Assuming heterogeneous strongly convex local costs with mutually\ndifferent minimizers that are arbitrarily far apart, we show that the proposed\nmethod converges to a neighborhood of the network-wide problem solution in the\nmean squared error (MSE) sense, and we also characterize the corresponding\nconvergence rate. We further show that the asymptotic MSE can be made\narbitrarily small through consensus step-size tuning, possibly at the cost of\nslowing down the transient error decay. Numerical experiments corroborate our\nfindings and demonstrate the resilience of the proposed method to heavy-tailed\n(and infinite variance) communication noise. They also show that existing\ndistributed methods, designed for finite-communication-noise-variance settings,\nfail in the presence of infinite variance noise.", "published": "2025-05-30 11:07:21", "link": "http://arxiv.org/abs/2505.24464v1", "categories": ["math.OC", "cs.LG", "90C25, 65K05"], "primary_category": "math.OC"}
{"title": "Logits-Based Finetuning", "abstract": "The core of out-of-distribution (OOD) detection is to learn the\nin-distribution (ID) representation, which is distinguishable from OOD samples.\nPrevious work applied recognition-based methods to learn the ID features, which\ntend to learn shortcuts instead of comprehensive representations. In this work,\nwe find surprisingly that simply using reconstruction-based methods could boost\nthe performance of OOD detection significantly. We deeply explore the main\ncontributors of OOD detection and find that reconstruction-based pretext tasks\nhave the potential to provide a generally applicable and efficacious prior,\nwhich benefits the model in learning intrinsic data distributions of the ID\ndataset. Specifically, we take Masked Image Modeling as a pretext task for our\nOOD detection framework (MOOD). Without bells and whistles, MOOD outperforms\nprevious SOTA of one-class OOD detection by 5.7%, multi-class OOD detection by\n3.0%, and near-distribution OOD detection by 2.1%. It even defeats the\n10-shot-per-class outlier exposure OOD detection, although we do not include\nany OOD samples for our detection. Codes are available at\nhttps://github.com/JulietLJY/MOOD.", "published": "2025-05-30 10:57:09", "link": "http://arxiv.org/abs/2505.24461v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Stepsize anything: A unified learning rate schedule for budgeted-iteration training", "abstract": "The expanding computational costs and limited resources underscore the\ncritical need for budgeted-iteration training, which aims to achieve optimal\nlearning within predetermined iteration budgets.While learning rate schedules\nfundamentally govern the performance of different networks and tasks,\nparticularly in budgeted-iteration scenarios, their design remains largely\nheuristic, lacking theoretical foundations.In addition, the optimal learning\nrate schedule requires extensive trial-and-error selection, making the training\nprocess inefficient.In this work, we propose the Unified Budget-Aware (UBA)\nschedule, a theoretically grounded learning rate schedule that consistently\noutperforms commonly-used schedules among diverse architectures and tasks under\ndifferent constrained training budgets.First, we bridge the gap by constructing\na novel training budget-aware optimization framework, which explicitly accounts\nfor the robustness to landscape curvature variations.From this framework, we\nderive the UBA schedule, controlled by a single hyper-parameter $\\varphi$ that\nprovides a trade-off between flexibility and simplicity, eliminating the need\nfor per-network numerical optimization. Moreover, we establish a theoretical\nconnection between $\\varphi$ and the condition number, adding interpretation\nand justification to our approach. Besides, we prove the convergence for\ndifferent values of $\\varphi$.We offer practical guidelines for its selection\nvia theoretical analysis and empirical results.xtensive experimental results\nshow that UBA \\textit{consistently surpasses} the commonly-used schedules\nacross diverse vision and language tasks, spanning network architectures (e.g.,\nResNet, OLMo) and scales, under different training-iteration budgets.", "published": "2025-05-30 10:38:03", "link": "http://arxiv.org/abs/2505.24452v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Weisfeiler and Leman Follow the Arrow of Time: Expressive Power of Message Passing in Temporal Event Graphs", "abstract": "An important characteristic of temporal graphs is how the directed arrow of\ntime influences their causal topology, i.e., which nodes can possibly influence\neach other causally via time-respecting paths. The resulting patterns are often\nneglected by temporal graph neural networks (TGNNs). To formally analyze the\nexpressive power of TGNNs, we lack a generalization of graph isomorphism to\ntemporal graphs that fully captures their causal topology. Addressing this gap,\nwe introduce the notion of consistent event graph isomorphism, which utilizes a\ntime-unfolded representation of time-respecting paths in temporal graphs. We\ncompare this definition with existing notions of temporal graph isomorphisms.\nWe illustrate and highlight the advantages of our approach and develop a\ntemporal generalization of the Weisfeiler-Leman algorithm to heuristically\ndistinguish non-isomorphic temporal graphs. Building on this theoretical\nfoundation, we derive a novel message passing scheme for temporal graph neural\nnetworks that operates on the event graph representation of temporal graphs. An\nexperimental evaluation shows that our approach performs well in a temporal\ngraph classification experiment.", "published": "2025-05-30 10:20:30", "link": "http://arxiv.org/abs/2505.24438v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Multi-task Learning for Heterogeneous Multi-source Block-Wise Missing Data", "abstract": "Multi-task learning (MTL) has emerged as an imperative machine learning tool\nto solve multiple learning tasks simultaneously and has been successfully\napplied to healthcare, marketing, and biomedical fields. However, in order to\nborrow information across different tasks effectively, it is essential to\nutilize both homogeneous and heterogeneous information. Among the extensive\nliterature on MTL, various forms of heterogeneity are presented in MTL\nproblems, such as block-wise, distribution, and posterior heterogeneity.\nExisting methods, however, struggle to tackle these forms of heterogeneity\nsimultaneously in a unified framework. In this paper, we propose a two-step\nlearning strategy for MTL which addresses the aforementioned heterogeneity.\nFirst, we impute the missing blocks using shared representations extracted from\nhomogeneous source across different tasks. Next, we disentangle the mappings\nbetween input features and responses into a shared component and a\ntask-specific component, respectively, thereby enabling information borrowing\nthrough the shared component. Our numerical experiments and real-data analysis\nfrom the ADNI database demonstrate the superior MTL performance of the proposed\nmethod compared to other competing methods.", "published": "2025-05-30 09:52:03", "link": "http://arxiv.org/abs/2505.24413v1", "categories": ["cs.LG", "stat.CO"], "primary_category": "cs.LG"}
{"title": "On the Lipschitz Continuity of Set Aggregation Functions and Neural Networks for Sets", "abstract": "The Lipschitz constant of a neural network is connected to several important\nproperties of the network such as its robustness and generalization. It is thus\nuseful in many settings to estimate the Lipschitz constant of a model. Prior\nwork has focused mainly on estimating the Lipschitz constant of multi-layer\nperceptrons and convolutional neural networks. Here we focus on data modeled as\nsets or multisets of vectors and on neural networks that can handle such data.\nThese models typically apply some permutation invariant aggregation function,\nsuch as the sum, mean or max operator, to the input multisets to produce a\nsingle vector for each input sample. In this paper, we investigate whether\nthese aggregation functions are Lipschitz continuous with respect to three\ndistance functions for unordered multisets, and we compute their Lipschitz\nconstants. In the general case, we find that each aggregation function is\nLipschitz continuous with respect to only one of the three distance functions.\nThen, we build on these results to derive upper bounds on the Lipschitz\nconstant of neural networks that can process multisets of vectors, while we\nalso study their stability to perturbations and generalization under\ndistribution shifts. To empirically verify our theoretical analysis, we conduct\na series of experiments on datasets from different domains.", "published": "2025-05-30 09:34:58", "link": "http://arxiv.org/abs/2505.24403v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "LightSAM: Parameter-Agnostic Sharpness-Aware Minimization", "abstract": "Sharpness-Aware Minimization (SAM) optimizer enhances the generalization\nability of the machine learning model by exploring the flat minima landscape\nthrough weight perturbations. Despite its empirical success, SAM introduces an\nadditional hyper-parameter, the perturbation radius, which causes the\nsensitivity of SAM to it. Moreover, it has been proved that the perturbation\nradius and learning rate of SAM are constrained by problem-dependent parameters\nto guarantee convergence. These limitations indicate the requirement of\nparameter-tuning in practical applications. In this paper, we propose the\nalgorithm LightSAM which sets the perturbation radius and learning rate of SAM\nadaptively, thus extending the application scope of SAM. LightSAM employs three\npopular adaptive optimizers, including AdaGrad-Norm, AdaGrad and Adam, to\nreplace the SGD optimizer for weight perturbation and model updating, reducing\nsensitivity to parameters. Theoretical results show that under weak\nassumptions, LightSAM could converge ideally with any choices of perturbation\nradius and learning rate, thus achieving parameter-agnostic. We conduct\npreliminary experiments on several deep learning tasks, which together with the\ntheoretical findings validate the the effectiveness of LightSAM.", "published": "2025-05-30 09:28:38", "link": "http://arxiv.org/abs/2505.24399v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Anomaly Detection and Improvement of Clusters using Enhanced K-Means Algorithm", "abstract": "This paper introduces a unified approach to cluster refinement and anomaly\ndetection in datasets. We propose a novel algorithm that iteratively reduces\nthe intra-cluster variance of N clusters until a global minimum is reached,\nyielding tighter clusters than the standard k-means algorithm. We evaluate the\nmethod using intrinsic measures for unsupervised learning, including the\nsilhouette coefficient, Calinski-Harabasz index, and Davies-Bouldin index, and\nextend it to anomaly detection by identifying points whose assignment causes a\nsignificant variance increase. External validation on synthetic data and the\nUCI Breast Cancer and UCI Wine Quality datasets employs the Jaccard similarity\nscore, V-measure, and F1 score. Results show variance reductions of 18.7% and\n88.1% on the synthetic and Wine Quality datasets, respectively, along with\naccuracy and F1 score improvements of 22.5% and 20.8% on the Wine Quality\ndataset.", "published": "2025-05-30 08:56:53", "link": "http://arxiv.org/abs/2505.24365v1", "categories": ["cs.LG", "cs.PF"], "primary_category": "cs.LG"}
{"title": "Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning", "abstract": "Sparse autoencoders are a promising new approach for decomposing language\nmodel activations for interpretation and control. They have been applied\nsuccessfully to vision transformer image encoders and to small-scale diffusion\nmodels. Inference-Time Decomposition of Activations (ITDA) is a recently\nproposed variant of dictionary learning that takes the dictionary to be a set\nof data points from the activation distribution and reconstructs them with\ngradient pursuit. We apply Sparse Autoencoders (SAEs) and ITDA to a large\ntext-to-image diffusion model, Flux 1, and consider the interpretability of\nembeddings of both by introducing a visual automated interpretation pipeline.\nWe find that SAEs accurately reconstruct residual stream embeddings and beat\nMLP neurons on interpretability. We are able to use SAE features to steer image\ngeneration through activation addition. We find that ITDA has comparable\ninterpretability to SAEs.", "published": "2025-05-30 08:53:27", "link": "http://arxiv.org/abs/2505.24360v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Distributed Intelligence in the Computing Continuum with Active Inference", "abstract": "The Computing Continuum (CC) is an emerging Internet-based computing paradigm\nthat spans from local Internet of Things sensors and constrained edge devices\nto large-scale cloud data centers. Its goal is to orchestrate a vast array of\ndiverse and distributed computing resources to support the next generation of\nInternet-based applications. However, the distributed, heterogeneous, and\ndynamic nature of CC platforms demands distributed intelligence for adaptive\nand resilient service management. This article introduces a distributed stream\nprocessing pipeline as a CC use case, where each service is managed by an\nActive Inference (AIF) agent. These agents collaborate to fulfill service needs\nspecified by SLOiDs, a term we introduce to denote Service Level Objectives\nthat are aware of its deployed devices, meaning that non-functional\nrequirements must consider the characteristics of the hosting device. We\ndemonstrate how AIF agents can be modeled and deployed alongside distributed\nservices to manage them autonomously. Our experiments show that AIF agents\nachieve over 90% SLOiD fulfillment when using tested transition models, and\naround 80% when learning the models during deployment. We compare their\nperformance to a multi-agent reinforcement learning algorithm, finding that\nwhile both approaches yield similar results, MARL requires extensive training,\nwhereas AIF agents can operate effectively from the start. Additionally, we\nevaluate the behavior of AIF agents in offloading scenarios, observing a strong\ncapacity for adaptation. Finally, we outline key research directions to advance\nAIF integration in CC platforms.", "published": "2025-05-30 14:10:33", "link": "http://arxiv.org/abs/2505.24618v1", "categories": ["cs.DC", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.DC"}
{"title": "R3DM: Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning", "abstract": "Multi-agent reinforcement learning (MARL) has achieved significant progress\nin large-scale traffic control, autonomous vehicles, and robotics. Drawing\ninspiration from biological systems where roles naturally emerge to enable\ncoordination, role-based MARL methods have been proposed to enhance cooperation\nlearning for complex tasks. However, existing methods exclusively derive roles\nfrom an agent's past experience during training, neglecting their influence on\nits future trajectories. This paper introduces a key insight: an agent's role\nshould shape its future behavior to enable effective coordination. Hence, we\npropose Role Discovery and Diversity through Dynamics Models (R3DM), a novel\nrole-based MARL framework that learns emergent roles by maximizing the mutual\ninformation between agents' roles, observed trajectories, and expected future\nbehaviors. R3DM optimizes the proposed objective through contrastive learning\non past trajectories to first derive intermediate roles that shape intrinsic\nrewards to promote diversity in future behaviors across different roles through\na learned dynamics model. Benchmarking on SMAC and SMACv2 environments\ndemonstrates that R3DM outperforms state-of-the-art MARL approaches, improving\nmulti-agent coordination to increase win rates by up to 20%.", "published": "2025-05-30 06:40:19", "link": "http://arxiv.org/abs/2505.24265v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring", "abstract": "While multi-agent LLM systems show strong capabilities in various domains,\nthey are highly vulnerable to adversarial and low-performing agents. To resolve\nthis issue, in this paper, we introduce a general and adversary-resistant\nmulti-agent LLM framework based on credibility scoring. We model the\ncollaborative query-answering process as an iterative game, where the agents\ncommunicate and contribute to a final system output. Our system associates a\ncredibility score that is used when aggregating the team outputs. The\ncredibility scores are learned gradually based on the past contributions of\neach agent in query answering. Our experiments across multiple tasks and\nsettings demonstrate our system's effectiveness in mitigating adversarial\ninfluence and enhancing the resilience of multi-agent cooperation, even in the\nadversary-majority settings.", "published": "2025-05-30 05:57:37", "link": "http://arxiv.org/abs/2505.24239v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Distributed Neural Policy Gradient Algorithm for Global Convergence of Networked Multi-Agent Reinforcement Learning", "abstract": "This paper studies the networked multi-agent reinforcement learning (NMARL)\nproblem, where the objective of agents is to collaboratively maximize the\ndiscounted average cumulative rewards. Different from the existing methods that\nsuffer from poor expression due to linear function approximation, we propose a\ndistributed neural policy gradient algorithm that features two innovatively\ndesigned neural networks, specifically for the approximate Q-functions and\npolicy functions of agents. This distributed neural policy gradient algorithm\nconsists of two key components: the distributed critic step and the\ndecentralized actor step. In the distributed critic step, agents receive the\napproximate Q-function parameters from their neighboring agents via a\ntime-varying communication networks to collaboratively evaluate the joint\npolicy. In contrast, in the decentralized actor step, each agent updates its\nlocal policy parameter solely based on its own approximate Q-function. In the\nconvergence analysis, we first establish the global convergence of agents for\nthe joint policy evaluation in the distributed critic step. Subsequently, we\nrigorously demonstrate the global convergence of the overall distributed neural\npolicy gradient algorithm with respect to the objective function. Finally, the\neffectiveness of the proposed algorithm is demonstrated by comparing it with a\ncentralized algorithm through simulation in the robot path planning\nenvironment.", "published": "2025-05-30 01:23:14", "link": "http://arxiv.org/abs/2505.24113v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "A localized consensus-based sampling algorithm", "abstract": "We develop a novel interacting-particle method for sampling from non-Gaussian\ndistributions. As a first step, we propose a new way to derive the\nconsensus-based sampling (CBS) algorithm, starting from ensemble-preconditioned\nLangevin diffusions. We approximate the target potential by its Moreau\nenvelope, such that the gradient in the Langevin equation can be replaced by a\nproximal operator. We then approximate the proximal operator by a weighted\nmean, and finally assume that the initial and target distributions are\nGaussian, resulting in the CBS dynamics. If we keep only those approximations\nthat can be justified in the non-Gaussian setting, the result is a new\ninteracting-particle method for sampling, which we call localized\nconsensus-based sampling. We prove that our algorithm is affine-invariant and\nexact for Gaussian distributions in the mean-field setting. Numerical tests\nillustrate that localized CBS compares favorably to alternative methods in\nterms of affine-invariance and performance on non-Gaussian distributions.", "published": "2025-05-30 17:58:20", "link": "http://arxiv.org/abs/2505.24861v1", "categories": ["math.NA", "cs.NA", "math.OC", "62F15 (Primary) 65C05, 65C35, 82C31 (Secondary)"], "primary_category": "math.NA"}
{"title": "AFIRE: Accurate and Fast Image Reconstruction Algorithm for Geometric-inconsistency Multispectral CT", "abstract": "For nonlinear multispectral computed tomography (CT), accurate and fast image\nreconstruction is challenging when the scanning geometries under different\nX-ray energy spectra are inconsistent or mismatched. Motivated by this, we\npropose an accurate and fast algorithm named AFIRE to address such problem in\nthe case of mildly full scan. We discover that the derivative operator\n(gradient) of the involved nonlinear mapping at some special points, for\nexample, at zero, can be represented as a composition (block multiplication) of\na diagonal operator (matrix) composed of X-ray transforms (projection matrices)\nand a very small-scale matrix. Based on the insights, the AFIRE is proposed\nrespectively from the continuous, discrete and actual-use perspectives by\nleveraging the simplified Newton method. Under proper conditions, we establish\nthe convergence theory of the proposed algorithm. Furthermore, numerical\nexperiments are also carried out to verify that the proposed algorithm can\naccurately and effectively reconstruct the basis images in completely\ngeometric-inconsistency dual-energy CT with noiseless and noisy projection\ndata. Particularly, the proposed algorithm significantly outperforms some\nstate-of-the-art methods in terms of accuracy and efficiency. Finally, the\nflexibility and extensibility of the proposed algorithm are also demonstrated.", "published": "2025-05-30 16:55:23", "link": "http://arxiv.org/abs/2505.24793v1", "categories": ["math.NA", "cs.NA", "physics.med-ph", "65J15, 65R32, 65J22, 68U10"], "primary_category": "math.NA"}
{"title": "Jacobian-free Multigrid Preconditioner for Discontinuous Galerkin Methods applied to Numerical Weather Prediction", "abstract": "Discontinuous Galerkin (DG) methods are promising high order discretizations\nfor unsteady compressible flows. Here, we focus on Numerical Weather Prediction\n(NWP). These flows are characterized by a fine resolution in $z$-direction and\nlow Mach numbers, making the system stiff. Thus, implicit time integration is\nrequired and for this a fast, highly parallel, low-memory iterative solver for\nthe resulting algebraic systems. As a basic framework, we use inexact\nJacobian-Free Newton-GMRES with a preconditioner.\n  For low order finite volume discretizations, multigrid methods have been\nsuccessfully applied to steady and unsteady fluid flows. However, for high\norder DG methods, such solvers are currently lacking. %The lack of efficient\nsolvers suitable for contemporary computer architectures inhibits wider\nadoption of DG methods. This motivates our research to construct a\nJacobian-free precondtioner for high order DG discretizations. The\npreconditioner is based on a multigrid method constructed for a low order\nfinite volume discretization defined on a subgrid of the DG mesh. We design a\ncomputationally efficient and mass conservative mapping between the grids. As\nsmoothers, explicit Runge-Kutta pseudo time iterations are used, which can be\nimplemented in parallel in a Jacobian-free low-memory manner.\n  We consider DG Methods for the Euler equations and for viscous flow equations\nin 2D, both with gravity, in a well balanced formulation. Numerical experiments\nin the software framework DUNE-FEM on atmospheric flow problems show the\nbenefit of this approach.", "published": "2025-05-30 12:06:38", "link": "http://arxiv.org/abs/2505.24504v1", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "65M55, 65M60"], "primary_category": "math.NA"}
{"title": "Provably convergent stochastic fixed-point algorithm for free-support Wasserstein barycenter of continuous non-parametric measures", "abstract": "We propose a provably convergent algorithm for approximating the\n2-Wasserstein barycenter of continuous non-parametric probability measures. Our\nalgorithm is inspired by the fixed-point iterative scheme of \\'Alvarez-Esteban\net al. (2016) whose convergence to the 2-Wasserstein barycenter relies on\nobtaining exact optimal transport (OT) maps. However, typically in practice, OT\nmaps are only approximately computed and exact computation of OT maps between\ncontinuous probability measures is only tractable for certain restrictive\nparametric families. To circumvent the need to compute exact OT maps between\ngeneral non-parametric measures, we develop a tailored iterative scheme that\nutilizes consistent estimators of the OT maps instead of the exact OT maps.\nThis gives rise to a computationally tractable stochastic fixed-point algorithm\nwhich is provably convergent to the 2-Wasserstein barycenter. Our algorithm\nremarkably does not restrict the support of the 2-Wasserstein barycenter to be\nany fixed finite set and can be implemented in a distributed computing\nenvironment, which makes it suitable for large-scale data aggregation problems.\nIn our numerical experiments, we propose a method of generating non-trivial\ninstances of 2-Wasserstein barycenter problems where the ground-truth\nbarycenter measure is known. Our numerical results showcase the capability of\nour algorithm in developing high-quality approximations of the 2-Wasserstein\nbarycenter, as well as its superiority over state-of-the-art methods based on\ngenerative neural networks in terms of accuracy, stability, and efficiency.", "published": "2025-05-30 09:13:57", "link": "http://arxiv.org/abs/2505.24384v1", "categories": ["math.OC", "cs.NA", "math.NA", "math.PR"], "primary_category": "math.OC"}
{"title": "Factorization method for near-field inverse scattering problems in elastodynamics", "abstract": "Consider a time-harmonic elastic point source incident on a bounded obstacle\nwhich is embedded in an open space filled with a homogeneous and isotropic\nelastic medium. This paper is concerned with the inverse problem of recovering\nthe location and shape of the obstacle from near-field data generated by\ninfinitely many incident point source waves at a fixed energy. The incident\npoint sources and the receivers for recording scattered signals are both\nlocated on a spherical closed surface, on which an outgoing-to-incoming\noperator is defined for facilitating the factorization of the near-field\noperator. Numerical examples in 2D are presented to show the validity and\naccuracy of the inversion algorithm.", "published": "2025-05-30 07:02:06", "link": "http://arxiv.org/abs/2505.24288v1", "categories": ["math.AP", "cs.NA", "math.NA", "35R30, 65N21, 35P25"], "primary_category": "math.AP"}
{"title": "Nonlinear PDEs with modulated dispersion IV: normal form approach and unconditional uniqueness", "abstract": "We study the modulated Korteweg-de~Vries equation (KdV) on the circle with a\ntime non-homogeneous modulation acting on the linear dispersion term. By\nadapting the normal form approach to the modulated setting, we prove sharp\nunconditional uniqueness of solutions to the modulated KdV in $L^2(\\mathbb T)$\nif a modulation is sufficiently irregular. For example, this result implies\nthat if the modulation is given by a sample path of a fractional Brownian\nmotion with Hurst index $0 < H < \\frac 25$, the modulated KdV on the circle is\nunconditionally well-posed in $L^2(\\mathbb T)$. Our normal form approach\nprovides the construction of solutions to the modulated KdV (and the associated\nnonlinear Young integral) {\\it without} assuming any positive regularity in\ntime. As an interesting byproduct of our normal form approach, we extend the\nconstruction of the nonlinear Young integral to a much larger class of\nfunctions, and obtain an improved Euler approximation scheme as compared to the\nclassical sewing lemma approach. We also establish analogous sharp\nunconditional uniqueness results for the modulated Benjamin-Ono equation and\nthe modulated derivative nonlinear Schr\\\"odinger equation (NLS) with a\nquadratic nonlinearity. In the appendix, we prove sharp unconditional\nuniqueness of the cubic modulated NLS on the circle in $H^{\\frac 16}(\\mathbb\nT)$.", "published": "2025-05-30 06:47:59", "link": "http://arxiv.org/abs/2505.24270v1", "categories": ["math.AP", "cs.NA", "math.NA", "math.PR", "35Q53, 35Q35, 35Q55, 60L20, 65M12, 65M15"], "primary_category": "math.AP"}
{"title": "STORK: Improving the Fidelity of Mid-NFE Sampling for Diffusion and Flow Matching Models", "abstract": "Diffusion models (DMs) have demonstrated remarkable performance in\nhigh-fidelity image and video generation. Because high-quality generations with\nDMs typically require a large number of function evaluations (NFEs), resulting\nin slow sampling, there has been extensive research successfully reducing the\nNFE to a small range (<10) while maintaining acceptable image quality. However,\nmany practical applications, such as those involving Stable Diffusion 3.5,\nFLUX, and SANA, commonly operate in the mid-NFE regime (20-50 NFE) to achieve\nsuperior results, and, despite the practical relevance, research on the\neffective sampling within this mid-NFE regime remains underexplored. In this\nwork, we propose a novel, training-free, and structure-independent DM ODE\nsolver called the Stabilized Taylor Orthogonal Runge--Kutta (STORK) method,\nbased on a class of stiff ODE solvers with a Taylor expansion adaptation.\nUnlike prior work such as DPM-Solver, which is dependent on the semi-linear\nstructure of the DM ODE, STORK is applicable to any DM sampling, including\nnoise-based and flow matching-based models. Within the 20-50 NFE range, STORK\nachieves improved generation quality, as measured by FID scores, across\nunconditional pixel-level generation and conditional latent-space generation\ntasks using models like Stable Diffusion 3.5 and SANA. Code is available at\nhttps://github.com/ZT220501/STORK.", "published": "2025-05-30 04:46:34", "link": "http://arxiv.org/abs/2505.24210v1", "categories": ["cs.CV", "cs.NA", "math.NA"], "primary_category": "cs.CV"}
{"title": "Path-dependent option pricing with two-dimensional PDE using MPDATA", "abstract": "In this paper, we discuss a simple yet robust PDE method for evaluating\npath-dependent Asian-style options using the non-oscillatory forward-in-time\nsecond-order MPDATA finite-difference scheme. The valuation methodology\ninvolves casting the Black-Merton-Scholes equation as a transport problem by\nfirst transforming it into a homogeneous advection-diffusion PDE via variable\nsubstitution, and then expressing the diffusion term as an advective flux using\nthe pseudo-velocity technique. As a result, all terms of the\nBlack-Merton-Sholes equation are consistently represented using a single\nhigh-order numerical scheme for the advection operator. We detail the\nadditional steps required to solve the two-dimensional valuation problem\ncompared to MPDATA valuations of vanilla instruments documented in a prior\nstudy. Using test cases employing fixed-strike instruments, we validate the\nsolutions against Monte Carlo valuations, as well as against an approximate\nanalytical solution in which geometric instead of arithmetic averaging is used.\nThe analysis highlights the critical importance of the MPDATA corrective steps\nthat improve the solution over the underlying first-order \"upwind\" step. The\nintroduced valuation scheme is robust: conservative, non-oscillatory, and\npositive-definite; yet lucid: explicit in time, engendering intuitive\nstability-condition interpretation and inflow/outflow boundary-condition\nheuristics. MPDATA is particularly well suited for two-dimensional problems as\nit is not a dimensionally split scheme. The documented valuation workflow also\nconstitutes a useful two-dimensional case for testing advection schemes\nfeaturing both Monte Carlo solutions and analytic bounds. An implementation of\nthe introduced valuation workflow, based on the PyMPDATA package and the Numba\nJust-In-Time compiler for Python, is provided as free and open source software.", "published": "2025-05-30 10:19:12", "link": "http://arxiv.org/abs/2505.24435v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "A Causation-Based Framework for Pricing and Cost Allocation of Energy, Reserves, and Transmission in Modern Power Systems", "abstract": "The increasing vulnerability of power systems has heightened the need for\noperating reserves to manage contingencies such as generator outages, line\nfailures, and sudden load variations. Unlike energy costs, driven by consumer\ndemand, operating reserve costs arise from addressing the most critical\ncredible contingencies - prompting the question: how should these costs be\nallocated through efficient pricing mechanisms? As an alternative to previously\nreported schemes, this paper presents a new causation-based pricing framework\nfor electricity markets based on contingency-constrained energy and reserve\nscheduling models. Major salient features include a novel security charge\nmechanism along with the explicit definition of prices for up-spinning\nreserves, down-spinning reserves, and transmission services. These features\nensure more comprehensive and efficient cost-reflective market operations.\nMoreover, the proposed nodal pricing scheme yields revenue adequacy and\nneutrality while promoting reliability incentives for generators based on the\ncost-causation principle. An additional salient aspect of the proposed\nframework is the economic incentive for transmission assets, which are\nremunerated based on their use to deliver energy and reserves across all\ncontingency states. Numerical results from two case studies illustrate the\nperformance of the proposed pricing scheme.", "published": "2025-05-30 03:07:06", "link": "http://arxiv.org/abs/2505.24159v1", "categories": ["eess.SY", "cs.SY", "econ.TH", "math.OC", "q-fin.CP", "q-fin.PR"], "primary_category": "eess.SY"}
{"title": "Consistent line clustering using geometric hypergraphs", "abstract": "Traditional data analysis often represents data as a weighted graph with\npairwise similarities, but many problems do not naturally fit this framework.\nIn line clustering, points in a Euclidean space must be grouped so that each\ncluster is well approximated by a line segment. Since any two points define a\nline, pairwise similarities fail to capture the structure of the problem,\nnecessitating the use of higher-order interactions modeled by geometric\nhypergraphs. We encode geometry into a 3-uniform hypergraph by treating sets of\nthree points as hyperedges whenever they are approximately collinear. The\nresulting hypergraph contains information about the underlying line segments,\nwhich can then be extracted using community recovery algorithms. In contrast to\nclassical hypergraph block models, latent geometric constraints in this\nconstruction introduce significant dependencies between hyperedges, which\nrestricts the applicability of many standard theoretical tools. We aim to\ndetermine the fundamental limits of line clustering and evaluate\nhypergraph-based line clustering methods. To this end, we derive\ninformation-theoretic thresholds for exact and almost exact recovery for data\ngenerated from intersecting lines on a plane with additive Gaussian noise. We\ndevelop a polynomial-time spectral algorithm and show that it succeeds under\nnoise conditions that match the information-theoretic bounds up to a\npolylogarithmic factor.", "published": "2025-05-30 17:59:17", "link": "http://arxiv.org/abs/2505.24868v1", "categories": ["math.ST", "stat.ML", "stat.TH", "62H30, 62R10, 62C20, 05C65, 05C80, 62H12, 94A15, 90B15"], "primary_category": "math.ST"}
{"title": "Sample-optimal learning of quantum states using gentle measurements", "abstract": "Gentle measurements of quantum states do not entirely collapse the initial\nstate. Instead, they provide a post-measurement state at a prescribed trace\ndistance $\\alpha$ from the initial state together with a random variable used\nfor quantum learning of the initial state. We introduce here the class of\n$\\alpha-$locally-gentle measurements ($\\alpha-$LGM) on a finite dimensional\nquantum system which are product measurements on product states and prove a\nstrong quantum Data-Processing Inequality (qDPI) on this class using an\nimproved relation between gentleness and quantum differential privacy. We\nfurther show a gentle quantum Neyman-Pearson lemma which implies that our qDPI\nis asymptotically optimal (for small $\\alpha$). This inequality is employed to\nshow that the necessary number of quantum states for prescribed accuracy\n$\\epsilon$ is of order $1/(\\epsilon^2 \\alpha^2)$ for both quantum tomography\nand quantum state certification. Finally, we propose an $\\alpha-$LGM called\nquantum Label Switch that attains these bounds. It is a general implementable\nmethod to turn any two-outcome measurement into an $\\alpha-$LGM.", "published": "2025-05-30 13:34:11", "link": "http://arxiv.org/abs/2505.24587v1", "categories": ["quant-ph", "math.ST", "stat.ML", "stat.TH", "81P15 (Primary), 68P27 (Secondary)"], "primary_category": "quant-ph"}
{"title": "Neural Drift Estimation for Ergodic Diffusions: Non-parametric Analysis and Numerical Exploration", "abstract": "We take into consideration generalization bounds for the problem of the\nestimation of the drift component for ergodic stochastic differential\nequations, when the estimator is a ReLU neural network and the estimation is\nnon-parametric with respect to the statistical model. We show a practical way\nto enforce the theoretical estimation procedure, enabling inference on noisy\nand rough functional data. Results are shown for a simulated It\\^o-Taylor\napproximation of the sample paths.", "published": "2025-05-30 09:12:49", "link": "http://arxiv.org/abs/2505.24383v1", "categories": ["math.ST", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Two failure modes of deep transformers and how to avoid them: a unified theory of signal propagation at initialisation", "abstract": "Finding the right initialisation for neural networks is crucial to ensure\nsmooth training and good performance. In transformers, the wrong initialisation\ncan lead to one of two failure modes of self-attention layers: rank collapse,\nwhere all tokens collapse into similar representations, and entropy collapse,\nwhere highly concentrated attention scores lead to training instability. While\nthe right initialisation has been extensively studied in feed-forward networks,\nan exact description of signal propagation through a full transformer block has\nso far been lacking. Here, we provide an analytical theory of signal\npropagation through vanilla transformer blocks with self-attention layers,\nlayer normalisation, skip connections and ReLU MLP. To treat the self-attention\nlayer, we draw on a formal parallel with the Random Energy Model from\nstatistical physics. We identify and characterise two regimes governed by the\nvariance of the query and key initialisations: a low-variance regime, where we\nrecover the known rank collapse behaviour; and a previously unexplored\nhigh-variance regime, where signal is preserved but \\textit{entropy collapse}\noccurs. In the low-variance regime, we calculate the critical strength for the\nresidual connection to ensure signal propagation. Our theory yields\ntrainability diagrams that identify the correct choice of initialisation\nhyper-parameters for a given architecture. Experiments with BERT-style models\ntrained on TinyStories validate our predictions. Our theoretical framework\ngives a unified perspective on the two failure modes of self-attention and\ngives quantitative predictions on the scale of both weights and residual\nconnections that guarantees smooth training.", "published": "2025-05-30 08:18:23", "link": "http://arxiv.org/abs/2505.24333v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Equilibrium Distribution for t-Distributed Stochastic Neighbor Embedding with Generalized Kernels", "abstract": "T-distributed stochastic neighbor embedding (t-SNE) is a well-known algorithm\nfor visualizing high-dimensional data by finding low-dimensional\nrepresentations. In this paper, we study the convergence of t-SNE with\ngeneralized kernels and extend the results of Auffinger and Fletcher in 2023.\nOur work starts by giving a concrete formulation of generalized input and\noutput kernels. Then we prove that under certain conditions, the t-SNE\nalgorithm converges to an equilibrium distribution for a wide range of input\nand output kernels as the number of data points diverges.", "published": "2025-05-30 07:50:09", "link": "http://arxiv.org/abs/2505.24311v1", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.TH", "60"], "primary_category": "stat.ML"}
{"title": "Multi-task Learning for Heterogeneous Data via Integrating Shared and Task-Specific Encodings", "abstract": "Multi-task learning (MTL) has become an essential machine learning tool for\naddressing multiple learning tasks simultaneously and has been effectively\napplied across fields such as healthcare, marketing, and biomedical research.\nHowever, to enable efficient information sharing across tasks, it is crucial to\nleverage both shared and heterogeneous information. Despite extensive research\non MTL, various forms of heterogeneity, including distribution and posterior\nheterogeneity, present significant challenges. Existing methods often fail to\naddress these forms of heterogeneity within a unified framework. In this paper,\nwe propose a dual-encoder framework to construct a heterogeneous latent factor\nspace for each task, incorporating a task-shared encoder to capture common\ninformation across tasks and a task-specific encoder to preserve unique task\ncharacteristics. Additionally, we explore the intrinsic similarity structure of\nthe coefficients corresponding to learned latent factors, allowing for adaptive\nintegration across tasks to manage posterior heterogeneity. We introduce a\nunified algorithm that alternately learns the task-specific and task-shared\nencoders and coefficients. In theory, we investigate the excess risk bound for\nthe proposed MTL method using local Rademacher complexity and apply it to a new\nbut related task. Through simulation studies, we demonstrate that the proposed\nmethod outperforms existing data integration methods across various settings.\nFurthermore, the proposed method achieves superior predictive performance for\ntime to tumor doubling across five distinct cancer types in PDX data.", "published": "2025-05-30 06:58:42", "link": "http://arxiv.org/abs/2505.24281v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "GradPower: Powering Gradients for Faster Language Model Pre-Training", "abstract": "We propose GradPower, a lightweight gradient-transformation technique for\naccelerating language model pre-training. Given a gradient vector $g=(g_i)_i$,\nGradPower first applies the elementwise sign-power transformation:\n$\\varphi_p(g)=({\\rm sign}(g_i)|g_i|^p)_{i}$ for a fixed $p>0$, and then feeds\nthe transformed gradient into a base optimizer. Notably, GradPower requires\nonly a single-line code change and no modifications to the base optimizer's\ninternal logic, including the hyperparameters. When applied to Adam (termed\nAdamPower), GradPower consistently achieves lower terminal loss across diverse\narchitectures (LLaMA, Qwen2MoE), parameter scales (66M to 2B), datasets (C4,\nOpenWebText), and learning-rate schedules (cosine, warmup-stable-decay). The\nmost pronounced gains are observed when training modern mixture-of-experts\nmodels with warmup-stable-decay schedules. GradPower also integrates seamlessly\nwith other state-of-the-art optimizers, such as Muon, yielding further\nimprovements. Finally, we provide theoretical analyses that reveal the\nunderlying mechanism of GradPower and highlights the influence of gradient\nnoise.", "published": "2025-05-30 06:49:57", "link": "http://arxiv.org/abs/2505.24275v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Taming Hyperparameter Sensitivity in Data Attribution: Practical Selection Without Costly Retraining", "abstract": "Data attribution methods, which quantify the influence of individual training\ndata points on a machine learning model, have gained increasing popularity in\ndata-centric applications in modern AI. Despite a recent surge of new methods\ndeveloped in this space, the impact of hyperparameter tuning in these methods\nremains under-explored. In this work, we present the first large-scale\nempirical study to understand the hyperparameter sensitivity of common data\nattribution methods. Our results show that most methods are indeed sensitive to\ncertain key hyperparameters. However, unlike typical machine learning\nalgorithms -- whose hyperparameters can be tuned using computationally-cheap\nvalidation metrics -- evaluating data attribution performance often requires\nretraining models on subsets of training data, making such metrics\nprohibitively costly for hyperparameter tuning. This poses a critical open\nchallenge for the practical application of data attribution methods. To address\nthis challenge, we advocate for better theoretical understandings of\nhyperparameter behavior to inform efficient tuning strategies. As a case study,\nwe provide a theoretical analysis of the regularization term that is critical\nin many variants of influence function methods. Building on this analysis, we\npropose a lightweight procedure for selecting the regularization value without\nmodel retraining, and validate its effectiveness across a range of standard\ndata attribution benchmarks. Overall, our study identifies a fundamental yet\noverlooked challenge in the practical application of data attribution, and\nhighlights the importance of careful discussion on hyperparameter selection in\nfuture method development.", "published": "2025-05-30 06:33:56", "link": "http://arxiv.org/abs/2505.24261v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Model Informed Flows for Bayesian Inference of Probabilistic Programs", "abstract": "Variational inference often struggles with the posterior geometry exhibited\nby complex hierarchical Bayesian models. Recent advances in flow-based\nvariational families and Variationally Inferred Parameters (VIP) each address\naspects of this challenge, but their formal relationship is unexplored. Here,\nwe prove that the combination of VIP and a full-rank Gaussian can be\nrepresented exactly as a forward autoregressive flow augmented with a\ntranslation term and input from the model's prior. Guided by this theoretical\ninsight, we introduce the Model-Informed Flow (MIF) architecture, which adds\nthe necessary translation mechanism, prior information, and hierarchical\nordering. Empirically, MIF delivers tighter posterior approximations and\nmatches or exceeds state-of-the-art performance across a suite of hierarchical\nand non-hierarchical benchmarks.", "published": "2025-05-30 06:08:00", "link": "http://arxiv.org/abs/2505.24243v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Alternate Groundwater Modelling Strategies: A Multi-Faceted Data-Driven Approach", "abstract": "The impact of statistical methodologies on studying groundwater has been\nsignificant in the last several decades, due to cheaper computational abilities\nand presence of technologies that enable us to extract and measure more and\nmore data. This paper focuses on the validation of statistical methodologies\nthat are in practice and continue to be at the earliest disposal of the\nresearcher, demonstrating how traditional time-series models and modern neural\nnetworks may be a viable option to analyze and make viable forecasts from data\ncommonly available in this domain, and suggesting a copula-based strategy to\nobtain directional dependencies of groundwater level, spatially. This paper\nalso proposes a sphere of model validation, seldom addressed in this domain:\nthe model longevity or the model shelf-life. Use of such validation techniques\nnot only ensure lower computational cost while maintaining reasonably high\naccuracy, but also, in some cases, ensure robust predictions or forecasts, and\nassist in comparing multiple models.", "published": "2025-05-30 05:51:13", "link": "http://arxiv.org/abs/2505.24235v1", "categories": ["stat.AP", "stat.CO", "stat.ML"], "primary_category": "stat.AP"}
{"title": "On the Expressive Power of Mixture-of-Experts for Structured Complex Tasks", "abstract": "Mixture-of-experts networks (MoEs) have demonstrated remarkable efficiency in\nmodern deep learning. Despite their empirical success, the theoretical\nfoundations underlying their ability to model complex tasks remain poorly\nunderstood. In this work, we conduct a systematic study of the expressive power\nof MoEs in modeling complex tasks with two common structural priors:\nlow-dimensionality and sparsity. For shallow MoEs, we prove that they can\nefficiently approximate functions supported on low-dimensional manifolds,\novercoming the curse of dimensionality. For deep MoEs, we show that\n$\\cO(L)$-layer MoEs with $E$ experts per layer can approximate piecewise\nfunctions comprising $E^L$ pieces with compositional sparsity, i.e., they can\nexhibit an exponential number of structured tasks. Our analysis reveals the\nroles of critical architectural components and hyperparameters in MoEs,\nincluding the gating mechanism, expert networks, the number of experts, and the\nnumber of layers, and offers natural suggestions for MoE variants.", "published": "2025-05-30 04:35:03", "link": "http://arxiv.org/abs/2505.24205v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Mathematical Perspective On Contrastive Learning", "abstract": "Multimodal contrastive learning is a methodology for linking different data\nmodalities; the canonical example is linking image and text data. The\nmethodology is typically framed as the identification of a set of encoders, one\nfor each modality, that align representations within a common latent space. In\nthis work, we focus on the bimodal setting and interpret contrastive learning\nas the optimization of (parameterized) encoders that define conditional\nprobability distributions, for each modality conditioned on the other,\nconsistent with the available data. This provides a framework for multimodal\nalgorithms such as crossmodal retrieval, which identifies the mode of one of\nthese conditional distributions, and crossmodal classification, which is\nsimilar to retrieval but includes a fine-tuning step to make it task specific.\n  The framework we adopt also gives rise to crossmodal generative models. This\nprobabilistic perspective suggests two natural generalizations of contrastive\nlearning: the introduction of novel probabilistic loss functions, and the use\nof alternative metrics for measuring alignment in the common latent space. We\nstudy these generalizations of the classical approach in the multivariate\nGaussian setting. In this context we view the latent space identification as a\nlow-rank matrix approximation problem. This allows us to characterize the\ncapabilities of loss functions and alignment metrics to approximate natural\nstatistics, such as conditional means and covariances; doing so yields novel\nvariants on contrastive learning algorithms for specific mode-seeking and for\ngenerative tasks. The framework we introduce is also studied through numerical\nexperiments on multivariate Gaussians, the labeled MNIST dataset, and on a data\nassimilation application arising in oceanography.", "published": "2025-05-30 02:09:37", "link": "http://arxiv.org/abs/2505.24134v1", "categories": ["stat.ML", "cs.CV", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Attractor learning for spatiotemporally chaotic dynamical systems using echo state networks with transfer learning", "abstract": "In this paper, we explore the predictive capabilities of echo state networks\n(ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypal\nnonlinear PDE that exhibits spatiotemporal chaos. We introduce a novel\nmethodology that integrates ESNs with transfer learning, aiming to enhance\npredictive performance across various parameter regimes of the gKS model. Our\nresearch focuses on predicting changes in long-term statistical patterns of the\ngKS model that result from varying the dispersion relation or the length of the\nspatial domain. We use transfer learning to adapt ESNs to different parameter\nsettings and successfully capture changes in the underlying chaotic attractor.", "published": "2025-05-30 01:01:09", "link": "http://arxiv.org/abs/2505.24099v1", "categories": ["math.DS", "cs.AI", "cs.LG", "nlin.CD", "stat.ML", "37N99, 68T30"], "primary_category": "math.DS"}
{"title": "Performative Risk Control: Calibrating Models for Reliable Deployment under Performativity", "abstract": "Calibrating blackbox machine learning models to achieve risk control is\ncrucial to ensure reliable decision-making. A rich line of literature has been\nstudying how to calibrate a model so that its predictions satisfy explicit\nfinite-sample statistical guarantees under a fixed, static, and unknown\ndata-generating distribution. However, prediction-supported decisions may\ninfluence the outcome they aim to predict, a phenomenon named performativity of\npredictions, which is commonly seen in social science and economics. In this\npaper, we introduce Performative Risk Control, a framework to calibrate models\nto achieve risk control under performativity with provable theoretical\nguarantees. Specifically, we provide an iteratively refined calibration\nprocess, where we ensure the predictions are improved and risk-controlled\nthroughout the process. We also study different types of risk measures and\nchoices of tail bounds. Lastly, we demonstrate the effectiveness of our\nframework by numerical experiments on the task of predicting credit default\nrisk. To the best of our knowledge, this work is the first one to study\nstatistically rigorous risk control under performativity, which will serve as\nan important safeguard against a wide range of strategic manipulation in\ndecision-making processes.", "published": "2025-05-30 00:59:25", "link": "http://arxiv.org/abs/2505.24097v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Masked Self-distilled Transducer-based Keyword Spotting with Semi-autoregressive Decoding", "abstract": "RNN-T-based keyword spotting (KWS) with autoregressive decoding~(AR) has\ngained attention due to its streaming architecture and superior performance.\nHowever, the simplicity of the prediction network in RNN-T poses an overfitting\nissue, especially under challenging scenarios, resulting in degraded\nperformance. In this paper, we propose a masked self-distillation (MSD)\ntraining strategy that avoids RNN-Ts overly relying on prediction networks to\nalleviate overfitting. Such training enables masked non-autoregressive (NAR)\ndecoding, which fully masks the RNN-T predictor output during KWS decoding. In\naddition, we propose a semi-autoregressive (SAR) decoding approach to integrate\nthe advantages of AR and NAR decoding. Our experiments across multiple KWS\ndatasets demonstrate that MSD training effectively alleviates overfitting. The\nSAR decoding method preserves the superior performance of AR decoding while\nbenefits from the overfitting suppression of NAR decoding, achieving excellent\nresults.", "published": "2025-05-30 17:22:39", "link": "http://arxiv.org/abs/2505.24820v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Composite Predictive-Generative Approach to Monaural Universal Speech Enhancement", "abstract": "It is promising to design a single model that can suppress various\ndistortions and improve speech quality, i.e., universal speech enhancement\n(USE). Compared to supervised learning-based predictive methods,\ndiffusion-based generative models have shown greater potential due to the\ngenerative capacities from degraded speech with severely damaged information.\nHowever, artifacts may be introduced in highly adverse conditions, and\ndiffusion models often suffer from a heavy computational burden due to many\nsteps for inference. In order to jointly leverage the superiority of prediction\nand generation and overcome the respective defects, in this work we propose a\nuniversal speech enhancement model called PGUSE by combining predictive and\ngenerative modeling. Our model consists of two branches: the predictive branch\ndirectly predicts clean samples from degraded signals, while the generative\nbranch optimizes the denoising objective of diffusion models. We utilize the\noutput fusion and truncated diffusion scheme to effectively integrate\npredictive and generative modeling, where the former directly combines results\nfrom both branches and the latter modifies the reverse diffusion process with\ninitial estimates from the predictive branch. Extensive experiments on several\ndatasets verify the superiority of the proposed model over state-of-the-art\nbaselines, demonstrating the complementarity and benefits of combining\npredictive and generative modeling.", "published": "2025-05-30 13:26:42", "link": "http://arxiv.org/abs/2505.24576v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Pretraining Multi-Speaker Identification for Neural Speaker Diarization", "abstract": "End-to-end speaker diarization enables accurate overlap-aware diarization by\njointly estimating multiple speakers' speech activities in parallel. This\napproach is data-hungry, requiring a large amount of labeled conversational\ndata, which cannot be fully obtained from real datasets alone. To address this\nissue, large-scale simulated data is often used for pretraining, but it\nrequires enormous storage and I/O capacity, and simulating data that closely\nresembles real conversations remains challenging. In this paper, we propose\npretraining a model to identify multiple speakers from an input fully\noverlapped mixture as an alternative to pretraining a diarization model. This\nmethod eliminates the need to prepare a large-scale simulated dataset while\nleveraging large-scale speaker recognition datasets for training. Through\ncomprehensive experiments, we demonstrate that the proposed method enables a\nhighly accurate yet lightweight local diarization model without simulated\nconversational data.", "published": "2025-05-30 12:53:27", "link": "http://arxiv.org/abs/2505.24545v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ARECHO: Autoregressive Evaluation via Chain-Based Hypothesis Optimization for Speech Multi-Metric Estimation", "abstract": "Speech signal analysis poses significant challenges, particularly in tasks\nsuch as speech quality evaluation and profiling, where the goal is to predict\nmultiple perceptual and objective metrics. For instance, metrics like PESQ\n(Perceptual Evaluation of Speech Quality), STOI (Short-Time Objective\nIntelligibility), and MOS (Mean Opinion Score) each capture different aspects\nof speech quality. However, these metrics often have different scales,\nassumptions, and dependencies, making joint estimation non-trivial. To address\nthese issues, we introduce ARECHO (Autoregressive Evaluation via Chain-based\nHypothesis Optimization), a chain-based, versatile evaluation system for speech\nassessment grounded in autoregressive dependency modeling. ARECHO is\ndistinguished by three key innovations: (1) a comprehensive speech information\ntokenization pipeline; (2) a dynamic classifier chain that explicitly captures\ninter-metric dependencies; and (3) a two-step confidence-oriented decoding\nalgorithm that enhances inference reliability. Experiments demonstrate that\nARECHO significantly outperforms the baseline framework across diverse\nevaluation scenarios, including enhanced speech analysis, speech generation\nevaluation, and noisy speech evaluation. Furthermore, its dynamic dependency\nmodeling improves interpretability by capturing inter-metric relationships.", "published": "2025-05-30 12:30:04", "link": "http://arxiv.org/abs/2505.24518v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech Token Prediction via Compressed-to-fine Language Modeling for Speech Generation", "abstract": "Neural audio codecs, used as speech tokenizers, have demonstrated remarkable\npotential in the field of speech generation. However, to ensure high-fidelity\naudio reconstruction, neural audio codecs typically encode audio into long\nsequences of speech tokens, posing a significant challenge for downstream\nlanguage models in long-context modeling. We observe that speech token\nsequences exhibit short-range dependency: due to the monotonic alignment\nbetween text and speech in text-to-speech (TTS) tasks, the prediction of the\ncurrent token primarily relies on its local context, while long-range tokens\ncontribute less to the current token prediction and often contain redundant\ninformation. Inspired by this observation, we propose a\n\\textbf{compressed-to-fine language modeling} approach to address the challenge\nof long sequence speech tokens within neural codec language models: (1)\n\\textbf{Fine-grained Initial and Short-range Information}: Our approach retains\nthe prompt and local tokens during prediction to ensure text alignment and the\nintegrity of paralinguistic information; (2) \\textbf{Compressed Long-range\nContext}: Our approach compresses long-range token spans into compact\nrepresentations to reduce redundant information while preserving essential\nsemantics. Extensive experiments on various neural audio codecs and downstream\nlanguage models validate the effectiveness and generalizability of the proposed\napproach, highlighting the importance of token compression in improving speech\ngeneration within neural codec language models. The demo of audio samples will\nbe available at\nhttps://anonymous.4open.science/r/SpeechTokenPredictionViaCompressedToFinedLM.", "published": "2025-05-30 11:47:29", "link": "http://arxiv.org/abs/2505.24496v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "SuPseudo: A Pseudo-supervised Learning Method for Neural Speech Enhancement in Far-field Speech Recognition", "abstract": "Due to the lack of target speech annotations in real-recorded far-field\nconversational datasets, speech enhancement (SE) models are typically trained\non simulated data. However, the trained models often perform poorly in\nreal-world conditions, hindering their application in far-field speech\nrecognition. To address the issue, we (a) propose direct sound estimation (DSE)\nto estimate the oracle direct sound of real-recorded data for SE; and (b)\npresent a novel pseudo-supervised learning method, SuPseudo, which leverages\nDSE-estimates as pseudo-labels and enables SE models to directly learn from and\nadapt to real-recorded data, thereby improving their generalization capability.\nFurthermore, an SE model called FARNET is designed to fully utilize SuPseudo.\nExperiments on the MISP2023 corpus demonstrate the effectiveness of SuPseudo,\nand our system significantly outperforms the previous state-of-the-art. A demo\nof our method can be found at https://EeLLJ.github.io/SuPseudo/.", "published": "2025-05-30 10:36:32", "link": "http://arxiv.org/abs/2505.24450v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Pseudo Labels-based Neural Speech Enhancement for the AVSR Task in the MISP-Meeting Challenge", "abstract": "This paper presents our system for the MISP-Meeting Challenge Track 2. The\nprimary difficulty lies in the dataset, which contains strong background noise,\nreverberation, overlapping speech, and diverse meeting topics. To address these\nissues, we (a) designed G-SpatialNet, a speech enhancement (SE) model to\nimprove Guided Source Separation (GSS) signals; (b) proposed TLS, a framework\ncomprising time alignment, level alignment, and signal-to-noise ratio\nfiltering, to generate signal-level pseudo labels for real-recorded far-field\naudio data, thereby facilitating SE models' training; and (c) explored\nfine-tuning strategies, data augmentation, and multimodal information to\nenhance the performance of pre-trained Automatic Speech Recognition (ASR)\nmodels in meeting scenarios. Finally, our system achieved character error rates\n(CERs) of 5.44% and 9.52% on the Dev and Eval sets, respectively, with relative\nimprovements of 64.8% and 52.6% over the baseline, securing second place.", "published": "2025-05-30 10:33:54", "link": "http://arxiv.org/abs/2505.24446v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SwitchCodec: A High-Fidelity Nerual Audio Codec With Sparse Quantization", "abstract": "We present a universal high-fidelity neural audio compression algorithm that\ncan compress speech, music, and general audio below 3 kbps bandwidth. Although\ncurrent state-of-the-art audio codecs excel in audio compression, their\neffectiveness significantly declines when embedding space is sharply reduced,\nwhich corresponds to higher compression. To address this problem, we propose\nResidual Experts Vector Quantization (REVQ), which significantly expands the\navailable embedding space and improves the performance while hardly sacrificing\nthe bandwidth. Furthermore, we introduce a strategy to ensure that the vast\nembedding space can be fully utilized. Additionally, we propose a STFT-based\ndiscriminator to guide the generator in producing indistinguishable\nspectrograms. We demonstrate that the proposed approach outperforms baseline\nmethods through detailed ablations.", "published": "2025-05-30 10:20:04", "link": "http://arxiv.org/abs/2505.24437v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DS-Codec: Dual-Stage Training with Mirror-to-NonMirror Architecture Switching for Speech Codec", "abstract": "Neural speech codecs are essential for advancing text-to-speech (TTS)\nsystems. With the recent success of large language models in text generation,\ndeveloping high-quality speech tokenizers has become increasingly important.\nThis paper introduces DS-Codec, a novel neural speech codec featuring a\ndual-stage training framework with mirror and non-mirror architectures\nswitching, designed to achieve superior speech reconstruction. We conduct\nextensive experiments and ablation studies to evaluate the effectiveness of our\ntraining strategy and compare the performance of the two architectures. Our\nresults show that the mirrored structure significantly enhances the robustness\nof the learned codebooks, and the training strategy balances the advantages\nbetween mirrored and non-mirrored structures, leading to improved high-fidelity\nspeech reconstruction.", "published": "2025-05-30 07:53:01", "link": "http://arxiv.org/abs/2505.24314v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Perception-Based L2 Speech Intelligibility Indicator: Leveraging a Rater's Shadowing and Sequence-to-sequence Voice Conversion", "abstract": "Evaluating L2 speech intelligibility is crucial for effective\ncomputer-assisted language learning (CALL). Conventional ASR-based methods\noften focus on native-likeness, which may fail to capture the actual\nintelligibility perceived by human listeners. In contrast, our work introduces\na novel, perception based L2 speech intelligibility indicator that leverages a\nnative rater's shadowing data within a sequence-to-sequence (seq2seq) voice\nconversion framework. By integrating an alignment mechanism and acoustic\nfeature reconstruction, our approach simulates the auditory perception of\nnative listeners, identifying segments in L2 speech that are likely to cause\ncomprehension difficulties. Both objective and subjective evaluations indicate\nthat our method aligns more closely with native judgments than traditional\nASR-based metrics, offering a promising new direction for CALL systems in a\nglobal, multilingual contexts.", "published": "2025-05-30 07:35:40", "link": "http://arxiv.org/abs/2505.24304v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Probing the Robustness Properties of Neural Speech Codecs", "abstract": "Neural speech codecs have revolutionized speech coding, achieving higher\ncompression while preserving audio fidelity. Beyond compression, they have\nemerged as tokenization strategies, enabling language modeling on speech and\ndriving paradigm shifts across various speech processing tasks. Despite these\nadvancements, their robustness in noisy environments remains underexplored,\nraising concerns about their generalization to real-world scenarios. In this\nwork, we systematically evaluate neural speech codecs under various noise\nconditions, revealing non-trivial differences in their robustness. We further\nexamine their linearity properties, uncovering non-linear distortions which\npartly explain observed variations in robustness. Lastly, we analyze their\nfrequency response to identify factors affecting audio fidelity. Our findings\nprovide critical insights into codec behavior and future codec design, as well\nas emphasizing the importance of noise robustness for their real-world\nintegration.", "published": "2025-05-30 06:12:52", "link": "http://arxiv.org/abs/2505.24248v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Dynamic Context-Aware Streaming Pretrained Language Model For Inverse Text Normalization", "abstract": "Inverse Text Normalization (ITN) is crucial for converting spoken Automatic\nSpeech Recognition (ASR) outputs into well-formatted written text, enhancing\nboth readability and usability. Despite its importance, the integration of\nstreaming ITN within streaming ASR remains largely unexplored due to challenges\nin accuracy, efficiency, and adaptability, particularly in low-resource and\nlimited-context scenarios. In this paper, we introduce a streaming pretrained\nlanguage model for ITN, leveraging pretrained linguistic representations for\nimproved robustness. To address streaming constraints, we propose Dynamic\nContext-Aware during training and inference, enabling adaptive chunk size\nadjustments and the integration of right-context information. Experimental\nresults demonstrate that our method achieves accuracy comparable to\nnon-streaming ITN and surpasses existing streaming ITN models on a Vietnamese\ndataset, all while maintaining low latency, ensuring seamless integration into\nASR systems.", "published": "2025-05-30 05:41:03", "link": "http://arxiv.org/abs/2505.24229v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MOPSA: Mixture of Prompt-Experts Based Speaker Adaptation for Elderly Speech Recognition", "abstract": "This paper proposes a novel Mixture of Prompt-Experts based Speaker\nAdaptation approach (MOPSA) for elderly speech recognition. It allows\nzero-shot, real-time adaptation to unseen speakers, and leverages domain\nknowledge tailored to elderly speakers. Top-K most distinctive speaker prompt\nclusters derived using K-means serve as experts. A router network is trained to\ndynamically combine clustered prompt-experts. Acoustic and language level\nvariability among elderly speakers are modelled using separate encoder and\ndecoder prompts for Whisper. Experiments on the English DementiaBank Pitt and\nCantonese JCCOCC MoCA elderly speech datasets suggest that online MOPSA\nadaptation outperforms the speaker-independent (SI) model by statistically\nsignificant word error rate (WER) or character error rate (CER) reductions of\n0.86% and 1.47% absolute (4.21% and 5.40% relative). Real-time factor (RTF)\nspeed-up ratios of up to 16.12 times are obtained over offline batch-mode\nadaptation.", "published": "2025-05-30 05:23:16", "link": "http://arxiv.org/abs/2505.24224v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC", "abstract": "Multilingual speech processing with self-supervised or supervised pre-trained\nSpeech Foundation Models (SFM) has achieved strong performance on tasks like\nLanguage Identification (LID) and Automatic Speech Recognition (ASR). However,\nthese models struggle with limited resources during fine-tuning. This paper\nenhances multilingual LID and ASR on ML-SUPERB 2.0 by exploring multiple\nstrategies for adapting SFMs, including frozen upstream training, partial\nfine-tuning, and low-rank adaptation. Furthermore, we employ data augmentation\nto mitigate performance gaps in few-shot settings and introduce LID\nConnectionist Temporal Classification (CTC) loss for regularization. Our\napproach achieves a 14% relative improvement in LID accuracy and a 30% relative\nreduction in ASR CER over the baseline on ML-SUPERB 2.0, securing second place\nin the Interspeech 2025 ML-SUPERB 2.0 Challenge.", "published": "2025-05-30 04:25:15", "link": "http://arxiv.org/abs/2505.24200v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FeatureSense: Protecting Speaker Attributes in Always-On Audio Sensing System", "abstract": "Audio is a rich sensing modality that is useful for a variety of human\nactivity recognition tasks. However, the ubiquitous nature of smartphones and\nsmart speakers with always-on microphones has led to numerous privacy concerns\nand a lack of trust in deploying these audio-based sensing systems. This paper\naddresses this critical challenge of preserving user privacy when using audio\nfor sensing applications while maintaining utility. While prior work focuses\nprimarily on protecting recoverable speech content, we show that sensitive\nspeaker-specific attributes such as age and gender can still be inferred after\nmasking speech and propose a comprehensive privacy evaluation framework to\nassess this speaker attribute leakage. We design and implement FeatureSense, an\nopen-source library that provides a set of generalizable privacy-aware audio\nfeatures that can be used for wide range of sensing applications. We present an\nadaptive task-specific feature selection algorithm that optimizes the\nprivacy-utility-cost trade-off based on the application requirements. Through\nour extensive evaluation, we demonstrate the high utility of FeatureSense\nacross a diverse set of sensing tasks. Our system outperforms existing privacy\ntechniques by 60.6% in preserving user-specific privacy. This work provides a\nfoundational framework for ensuring trust in audio sensing by enabling\neffective privacy-aware audio classification systems.", "published": "2025-05-30 01:26:31", "link": "http://arxiv.org/abs/2505.24115v1", "categories": ["cs.SD", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fine-tune Before Structured Pruning: Towards Compact and Accurate Self-Supervised Models for Speaker Diarization", "abstract": "Self-supervised learning (SSL) models like WavLM can be effectively utilized\nwhen building speaker diarization systems but are often large and slow,\nlimiting their use in resource constrained scenarios. Previous studies have\nexplored compression techniques, but usually for the price of degraded\nperformance at high pruning ratios. In this work, we propose to compress SSL\nmodels through structured pruning by introducing knowledge distillation.\nDifferent from the existing works, we emphasize the importance of fine-tuning\nSSL models before pruning. Experiments on far-field single-channel AMI,\nAISHELL-4, and AliMeeting datasets show that our method can remove redundant\nparameters of WavLM Base+ and WavLM Large by up to 80% without any performance\ndegradation. After pruning, the inference speeds on a single GPU for the Base+\nand Large models are 4.0 and 2.6 times faster, respectively. Our source code is\npublicly available.", "published": "2025-05-30 01:19:58", "link": "http://arxiv.org/abs/2505.24111v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Detecting Airborne Objects with 5G NR Radars", "abstract": "The integration of sensing capabilities into 5G New Radio (5G NR) networks\noffers an opportunity to enable the detection of airborne objects without the\nneed for dedicated radars. This paper investigates the feasibility of using\nstandardized Positioning Reference Signals (PRS) to detect UAVs in Urban Micro\n(UMi) and Urban Macro (UMa) propagation environments. A full 5G NR radar\nprocessing chain is implemented, including clutter suppression, angle and range\nestimation, and 3D position reconstruction. Simulation results show that\nperformance strongly depends on the propagation environment. 5G NR radars\nexhibit the highest missed detection rate, up to 16%, in UMi, due to severe\nclutter. Positioning error increases with target distance, resulting in larger\nerrors in UMa scenarios and at higher UAV altitudes. In particular, the system\nachieves a position error within 4m in the UMi environment and within 8m in\nUMa. The simulation platform has been released as open-source software to\nsupport reproducible research in integrated sensing and communication (ISAC)\nsystems.", "published": "2025-05-30 16:26:09", "link": "http://arxiv.org/abs/2505.24763v1", "categories": ["eess.SP", "cs.NI"], "primary_category": "eess.SP"}
{"title": "Cognitive-Radio Functionality: A Novel Configuration for STAR-RIS assisted RSMA Networks", "abstract": "Cognitive radio rate-splitting multiple access (CR-RSMA) has emerged as a\npromising multiple access framework that can efficiently manage interference\nand adapt dynamically to heterogeneous quality-of-service (QoS) requirements.\nTo effectively support such demanding access schemes, programmable wireless\nenvironments have attracted considerable attention, especially through\nsimultaneously transmitting and reflecting reconfigurable intelligent surfaces\n(STAR-RISs), which can enable full-space control of signal propagation in\nasymmetric user deployments. In this paper, we propose the cognitive radio (CR)\nfunctionality for STAR-RIS-assisted CR-RSMA systems, leveraging the unique\ncapability of the STAR-RIS to combine element and power splitting for adaptive\ncontrol of transmission and reflection in CR scenarios. Specifically, the\nproposed CR functionality partitions the STAR-RIS into two regions\nindependently controlling the transmission and reflection of signals,\nsimultaneously ensuring the required QoS for the primary user and enhancing the\nperformance of the secondary user. To accurately characterize the system\nperformance, we derive analytical expressions for the ergodic rate of the\nsecondary user and the outage rate of the primary user under Nakagami-m fading.\nFinally, simulation results show that the proposed approach effectively manages\ninterference, guarantees the QoS of the primary user, and significantly\nimproves the throughput of the secondary user, highlighting STAR-RIS as an\nefficient solution for CR-RSMA-based services.", "published": "2025-05-30 13:30:37", "link": "http://arxiv.org/abs/2505.24583v1", "categories": ["cs.ET", "eess.SP"], "primary_category": "cs.ET"}
{"title": "How can AI reduce wrist injuries in the workplace?", "abstract": "This paper explores the development of a control and sensor strategy for an\nindustrial wearable wrist exoskeleton by classifying and predicting workers'\nactions. The study evaluates the correlation between exerted force and effort\nintensity, along with sensor strategy optimization, for designing purposes.\nUsing data from six healthy subjects in a manufacturing plant, this paper\npresents EMG-based models for wrist motion classification and force prediction.\nWrist motion recognition is achieved through a pattern recognition algorithm\ndeveloped with surface EMG data from an 8-channel EMG sensor (Myo Armband);\nwhile a force regression model uses wrist and hand force measurements from a\ncommercial handheld dynamometer (Vernier GoDirect Hand Dynamometer). This\ncontrol strategy forms the foundation for a streamlined exoskeleton\narchitecture designed for industrial applications, focusing on simplicity,\nreduced costs, and minimal sensor use while ensuring reliable and effective\nassistance.", "published": "2025-05-30 12:18:05", "link": "http://arxiv.org/abs/2505.24510v1", "categories": ["eess.SP", "cs.RO"], "primary_category": "eess.SP"}
{"title": "How can AI reduce fall injuries in the workplace?", "abstract": "Fall-caused injuries are common in all types of work environments, including\noffices. They are the main cause of absences longer than three days, especially\nfor small and medium-sized businesses (SMEs). However, data, data amount, data\nheterogeneity, and stringent processing time constraints continue to pose\nchallenges to real-time fall detection. This work proposes a new approach based\non a recurrent neural network (RNN) for Fall Detection and a Kolmogorov-Arnold\nNetwork (KAN) to estimate the time of impact of the fall. The approach is\ntested on SisFall, a dataset consisting of 2706 Activities of Daily Living\n(ADLs) and 1798 falls recorded by three sensors. The results show that the\nproposed approach achieves an average TPR of 82.6% and TNR of 98.4% for fall\nsequences and 94.4% in ADL. Besides, the Root Mean Squared Error of the\nestimated time of impact is approximately 160ms.", "published": "2025-05-30 12:09:38", "link": "http://arxiv.org/abs/2505.24507v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "MagicGripper: A Multimodal Sensor-Integrated Gripper for Contact-Rich Robotic Manipulation", "abstract": "Contact-rich manipulation in unstructured environments demands precise,\nmultimodal perception to enable robust and adaptive control. Vision-based\ntactile sensors (VBTSs) have emerged as an effective solution; however,\nconventional VBTSs often face challenges in achieving compact, multi-modal\nfunctionality due to hardware constraints and algorithmic complexity. In this\nwork, we present MagicGripper, a multimodal sensor-integrated gripper designed\nfor contact-rich robotic manipulation. Building on our prior design, MagicTac,\nwe develop a compact variant, mini-MagicTac, which features a\nthree-dimensional, multi-layered grid embedded in a soft elastomer.\nMagicGripper integrates mini-MagicTac, enabling high-resolution tactile\nfeedback alongside proximity and visual sensing within a compact,\ngripper-compatible form factor. We conduct a thorough evaluation of\nmini-MagicTac's performance, demonstrating its capabilities in spatial\nresolution, contact localization, and force regression. We also assess its\nrobustness across manufacturing variability, mechanical deformation, and\nsensing performance under real-world conditions. Furthermore, we validate the\neffectiveness of MagicGripper through three representative robotic tasks: a\nteleoperated assembly task, a contact-based alignment task, and an autonomous\nrobotic grasping task. Across these experiments, MagicGripper exhibits reliable\nmultimodal perception, accurate force estimation, and high adaptability to\nchallenging manipulation scenarios. Our results highlight the potential of\nMagicGripper as a practical and versatile tool for embodied intelligence in\ncomplex, contact-rich environments.", "published": "2025-05-30 09:10:31", "link": "http://arxiv.org/abs/2505.24382v1", "categories": ["cs.RO", "eess.SP"], "primary_category": "cs.RO"}
{"title": "Joint Transmit and Receive Beamforming for Tri-directional Coil-Based Magnetic Induction Communications", "abstract": "In this paper, we enhance the omnidirectional coverage performance of\ntri-directional coil-based magnetic induction communication (TC-MIC) and reduce\nthe pathloss with a joint transmit and receive magnetic beamforming method. An\niterative optimization algorithm incorporating the transmit current vector and\nreceive weight matrix is developed to minimize the pathloss under constant\ntransmit power constraints. We formulate the mathematical models for the mutual\ninductance of tri-directional coils, receive power, and pathloss. The\noptimization problem is decomposed into Rayleigh quotient extremum optimization\nfor transmit currents and Cauchy-Schwarz inequality-constrained optimization\nfor receive weights, with an alternating iterative algorithm to approach the\nglobal optimum. Numerical results demonstrate that the proposed algorithm\nconverges within an average of 13.6 iterations, achieving up to 54% pathloss\nreduction compared with equal power allocation schemes. The joint optimization\napproach exhibits superior angular robustness, maintaining pathloss fluctuation\nsmaller than 2 dB, and reducing fluctuation of pathloss by approximately 45%\ncompared with single-parameter optimization methods.", "published": "2025-05-30 08:47:56", "link": "http://arxiv.org/abs/2505.24356v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Wideband channel sensing with holographic interference surfaces", "abstract": "The Holographic Interference Surface (HIS) opens up a new prospect for\nbuilding a more cost-effective wireless communication architecture by\nperforming Radio Frequency (RF) domain signal processing. In this paper, we\nestablish a wideband channel sensing architecture for electromagnetic wave\nreception and channel estimation based on the principle of holographic\ninterference theory. Dute to the nonlinear structure of holograms,\ninterferential fringes composed of wideband RF signals exhibit severe\nself-interference effects in the time-frequency domain, which are inherently\nresistant to the classical signal processing tools. To overcome the\nself-interference, we propose a holographic channel recovery method, which\nanalyzes the time-domain variation of holograms from a geometrical perspective\nand constructs an inverse mapping from wideband holograms to object waves.\nBased on the Wirtinger partial derivative and Armijo condition, we then develop\na wideband hologram-based maximum likelihood (WH-ML) estimation method for\nestimating the channel state information (CSI) from holograms. We also propose\na geometric rotation-based object wave sensing (GROWS) algorithm to address the\ncomplicated computation of ML estimation. Furthermore, we derive the\nCram\\'er-Rao lower bound (CRLB) for investigating the achievable performance of\nwideband holographic channel estimation. Simulation results show that under the\nwideband channel sensing architecture, our proposed algorithm can accurately\nestimate the CSI in wideband scenarios.", "published": "2025-05-30 03:37:00", "link": "http://arxiv.org/abs/2505.24177v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Channel Knowledge Maps for 6G Wireless Networks: Construction, Applications, and Future Challenges", "abstract": "The advent of 6G wireless networks promises unprecedented connectivity,\nsupporting ultra-high data rates, low latency, and massive device connectivity.\nHowever, these ambitious goals introduce significant challenges, particularly\nin channel estimation due to complex and dynamic propagation environments. This\npaper explores the concept of channel knowledge maps (CKMs) as a solution to\nthese challenges. CKMs enable environment-aware communications by providing\nlocation-specific channel information, reducing reliance on real-time pilot\nmeasurements. We categorize CKM construction techniques into measurement-based,\nmodel-based, and hybrid methods, and examine their key applications in\nintegrated sensing and communication systems, beamforming, trajectory\noptimization of unmanned aerial vehicles, base station placement, and resource\nallocation. Furthermore, we discuss open challenges and propose future research\ndirections to enhance the robustness, accuracy, and scalability of CKM-based\nsystems in the evolving 6G landscape.", "published": "2025-05-30 02:54:55", "link": "http://arxiv.org/abs/2505.24151v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "B2LoRa: Boosting LoRa Transmission for Satellite-IoT Systems with Blind Coherent Combining", "abstract": "With the rapid growth of Low Earth Orbit (LEO) satellite networks,\nsatellite-IoT systems using the LoRa technique have been increasingly deployed\nto provide widespread Internet services to low-power and low-cost ground\ndevices. However, the long transmission distance and adverse environments from\nIoT satellites to ground devices pose a huge challenge to link reliability, as\nevidenced by the measurement results based on our real-world setup. In this\npaper, we propose a blind coherent combining design named B2LoRa to boost LoRa\ntransmission performance. The intuition behind B2LoRa is to leverage the\nrepeated broadcasting mechanism inherent in satellite-IoT systems to achieve\ncoherent combining under the low-power and low-cost constraints, where each\nre-transmission at different times is regarded as the same packet transmitted\nfrom different antenna elements within an antenna array. Then, the problem is\ntranslated into aligning these packets at a fine granularity despite the time,\nfrequency, and phase offsets between packets in the case of frequent packet\nloss. To overcome this challenge, we present three designs - joint packet\nsniffing, frequency shift alignment, and phase drift mitigation to deal with\nultra-low SNRs and Doppler shifts featured in satellite-IoT systems,\nrespectively. Finally, experiment results based on our real-world deployments\ndemonstrate the high efficiency of B2LoRa.", "published": "2025-05-30 02:22:59", "link": "http://arxiv.org/abs/2505.24140v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "How much do language models memorize?", "abstract": "We propose a new method for estimating how much a model ``knows'' about a\ndatapoint and use it to measure the capacity of modern language models. Prior\nstudies of language model memorization have struggled to disentangle\nmemorization from generalization. We formally separate memorization into two\ncomponents: \\textit{unintended memorization}, the information a model contains\nabout a specific dataset, and \\textit{generalization}, the information a model\ncontains about the true data-generation process. When we completely eliminate\ngeneralization, we can compute the total memorization, which provides an\nestimate of model capacity: our measurements estimate that GPT-style models\nhave a capacity of approximately 3.6 bits per parameter. We train language\nmodels on datasets of increasing size and observe that models memorize until\ntheir capacity fills, at which point ``grokking'' begins, and unintended\nmemorization decreases as models begin to generalize. We train hundreds of\ntransformer language models ranging from $500K$ to $1.5B$ parameters and\nproduce a series of scaling laws relating model capacity and data size to\nmembership inference.", "published": "2025-05-30 17:34:03", "link": "http://arxiv.org/abs/2505.24832v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Guiding Generative Storytelling with Knowledge Graphs", "abstract": "Large Language Models (LLMs) have shown great potential in automated story\ngeneration, but challenges remain in maintaining long-form coherence and\nproviding users with intuitive and effective control. Retrieval-Augmented\nGeneration (RAG) has proven effective in reducing hallucinations in text\ngeneration; however, the use of structured data to support generative\nstorytelling remains underexplored. This paper investigates how knowledge\ngraphs (KGs) can enhance LLM-based storytelling by improving narrative quality\nand enabling user-driven modifications. We propose a KG-assisted storytelling\npipeline and evaluate its effectiveness through a user study with 15\nparticipants. Participants created their own story prompts, generated stories,\nand edited knowledge graphs to shape their narratives. Through quantitative and\nqualitative analysis, our findings demonstrate that knowledge graphs\nsignificantly enhance story quality in action-oriented and structured\nnarratives within our system settings. Additionally, editing the knowledge\ngraph increases users' sense of control, making storytelling more engaging,\ninteractive, and playful.", "published": "2025-05-30 17:08:21", "link": "http://arxiv.org/abs/2505.24803v2", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "MSDA: Combining Pseudo-labeling and Self-Supervision for Unsupervised Domain Adaptation in ASR", "abstract": "In this work, we investigate the Meta PL unsupervised domain adaptation\nframework for Automatic Speech Recognition (ASR). We introduce a Multi-Stage\nDomain Adaptation pipeline (MSDA), a sample-efficient, two-stage adaptation\napproach that integrates self-supervised learning with semi-supervised\ntechniques. MSDA is designed to enhance the robustness and generalization of\nASR models, making them more adaptable to diverse conditions. It is\nparticularly effective for low-resource languages like Greek and in weakly\nsupervised scenarios where labeled data is scarce or noisy. Through extensive\nexperiments, we demonstrate that Meta PL can be applied effectively to ASR\ntasks, achieving state-of-the-art results, significantly outperforming\nstate-of-the-art methods, and providing more robust solutions for unsupervised\ndomain adaptation in ASR. Our ablations highlight the necessity of utilizing a\ncascading approach when combining self-supervision with self-training.", "published": "2025-05-30 14:46:05", "link": "http://arxiv.org/abs/2505.24656v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Knowing Before Saying: LLM Representations Encode Information About Chain-of-Thought Success Before Completion", "abstract": "We investigate whether the success of a zero-shot Chain-of-Thought (CoT)\nprocess can be predicted before completion. We discover that a probing\nclassifier, based on LLM representations, performs well \\emph{even before a\nsingle token is generated}, suggesting that crucial information about the\nreasoning process is already present in the initial steps representations. In\ncontrast, a strong BERT-based baseline, which relies solely on the generated\ntokens, performs worse, likely because it depends on shallow linguistic cues\nrather than deeper reasoning dynamics. Surprisingly, using later reasoning\nsteps does not always improve classification. When additional context is\nunhelpful, earlier representations resemble later ones more, suggesting LLMs\nencode key information early. This implies reasoning can often stop early\nwithout loss. To test this, we conduct early stopping experiments, showing that\ntruncating CoT reasoning still improves performance over not using CoT at all,\nthough a gap remains compared to full reasoning. However, approaches like\nsupervised learning or reinforcement learning designed to shorten CoT chains\ncould leverage our classifier's guidance to identify when early stopping is\neffective. Our findings provide insights that may support such methods, helping\nto optimize CoT's efficiency while preserving its benefits.", "published": "2025-05-30 08:54:28", "link": "http://arxiv.org/abs/2505.24362v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EXP-Bench: Can AI Conduct AI Research Experiments?", "abstract": "Automating AI research holds immense potential for accelerating scientific\nprogress, yet current AI agents struggle with the complexities of rigorous,\nend-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed\nto systematically evaluate AI agents on complete research experiments sourced\nfrom influential AI publications. Given a research question and incomplete\nstarter code, EXP-Bench challenges AI agents to formulate hypotheses, design\nand implement experimental procedures, execute them, and analyze results. To\nenable the creation of such intricate and authentic tasks with high-fidelity,\nwe design a semi-autonomous pipeline to extract and structure crucial\nexperimental details from these research papers and their associated\nopen-source code. With the pipeline, EXP-Bench curated 461 AI research tasks\nfrom 51 top-tier AI research papers. Evaluations of leading LLM-based agents,\nsuch as OpenHands and IterativeAgent on EXP-Bench demonstrate partial\ncapabilities: while scores on individual experimental aspects such as design or\nimplementation correctness occasionally reach 20-35%, the success rate for\ncomplete, executable experiments was a mere 0.5%. By identifying these\nbottlenecks and providing realistic step-by-step experiment procedures,\nEXP-Bench serves as a vital tool for future AI agents to improve their ability\nto conduct AI research experiments. EXP-Bench is open-sourced at\nhttps://github.com/Just-Curieous/Curie/tree/main/benchmark/exp_bench.", "published": "2025-05-30 16:46:29", "link": "http://arxiv.org/abs/2505.24785v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for Auto-Generating Chemical Process and Instrumentation Diagrams", "abstract": "Recent advancements in generative AI have accelerated the discovery of novel\nchemicals and materials; however, transitioning these discoveries to\nindustrial-scale production remains a critical bottleneck, as it requires the\ndevelopment of entirely new chemical manufacturing processes. Current AI\nmethods cannot auto-generate PFDs or PIDs, despite their critical role in\nscaling chemical processes, while adhering to engineering constraints. We\npresent a closed loop, physics aware framework for the automated generation of\nindustrially viable PFDs and PIDs. The framework integrates domain specialized\nsmall scale language models (SLMs) (trained for chemical process QA tasks) with\nfirst principles simulation, leveraging three key components: (1) a\nhierarchical knowledge graph of process flow and instrumentation descriptions\nfor 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes\ndomain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT),\nDirect Preference Optimization (DPO), and Retrieval-Augmented Instruction\nTuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure\nfeasibility. To improve both runtime efficiency and model compactness, the\nframework incorporates advanced inference time optimizations including\nFlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization,\nand Test Time Inference Scaling and independently applies structural pruning\ntechniques (width and depth) guided by importance heuristics to reduce model\nsize with minimal accuracy loss. Experiments demonstrate that the framework\ngenerates simulator-validated process descriptions with high fidelity,\noutperforms baseline methods in correctness, and generalizes to unseen\nchemicals. By bridging AI-driven design with industrial-scale feasibility, this\nwork significantly reduces R&D timelines from lab discovery to plant\ndeployment.", "published": "2025-05-30 13:32:00", "link": "http://arxiv.org/abs/2505.24584v2", "categories": ["cs.LG", "cs.AI", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Beyond Pretty Pictures: Combined Single- and Multi-Image Super-resolution for Sentinel-2 Images", "abstract": "Super-resolution aims to increase the resolution of satellite images by\nreconstructing high-frequency details, which go beyond na\\\"ive upsampling. This\nhas particular relevance for Earth observation missions like Sentinel-2, which\noffer frequent, regular coverage at no cost; but at coarse resolution. Its\npixel footprint is too large to capture small features like houses, streets, or\nhedge rows. To address this, we present SEN4X, a hybrid super-resolution\narchitecture that combines the advantages of single-image and multi-image\ntechniques. It combines temporal oversampling from repeated Sentinel-2\nacquisitions with a learned prior from high-resolution Pl\\'eiades Neo data. In\ndoing so, SEN4X upgrades Sentinel-2 imagery to 2.5 m ground sampling distance.\nWe test the super-resolved images on urban land-cover classification in Hanoi,\nVietnam. We find that they lead to a significant performance improvement over\nstate-of-the-art super-resolution baselines.", "published": "2025-05-30 17:02:56", "link": "http://arxiv.org/abs/2505.24799v2", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "NUC-Net: Non-uniform Cylindrical Partition Network for Efficient LiDAR Semantic Segmentation", "abstract": "LiDAR semantic segmentation plays a vital role in autonomous driving.\nExisting voxel-based methods for LiDAR semantic segmentation apply uniform\npartition to the 3D LiDAR point cloud to form a structured representation based\non cartesian/cylindrical coordinates. Although these methods show impressive\nperformance, the drawback of existing voxel-based methods remains in two\naspects: (1) it requires a large enough input voxel resolution, which brings a\nlarge amount of computation cost and memory consumption. (2) it does not well\nhandle the unbalanced point distribution of LiDAR point cloud. In this paper,\nwe propose a non-uniform cylindrical partition network named NUC-Net to tackle\nthe above challenges. Specifically, we propose the Arithmetic Progression of\nInterval (API) method to non-uniformly partition the radial axis and generate\nthe voxel representation which is representative and efficient. Moreover, we\npropose a non-uniform multi-scale aggregation method to improve contextual\ninformation. Our method achieves state-of-the-art performance on SemanticKITTI\nand nuScenes datasets with much faster speed and much less training time. And\nour method can be a general component for LiDAR semantic segmentation, which\nsignificantly improves both the accuracy and efficiency of the uniform\ncounterpart by $4 \\times$ training faster and $2 \\times$ GPU memory reduction\nand $3 \\times$ inference speedup. We further provide theoretical analysis\ntowards understanding why NUC is effective and how point distribution affects\nperformance. Code is available at\n\\href{https://github.com/alanWXZ/NUC-Net}{https://github.com/alanWXZ/NUC-Net}.", "published": "2025-05-30 14:25:32", "link": "http://arxiv.org/abs/2505.24634v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Localizing Persona Representations in LLMs", "abstract": "We present a study on how and where personas -- defined by distinct sets of\nhuman characteristics, values, and beliefs -- are encoded in the representation\nspace of large language models (LLMs). Using a range of dimension reduction and\npattern recognition methods, we first identify the model layers that show the\ngreatest divergence in encoding these representations. We then analyze the\nactivations within a selected layer to examine how specific personas are\nencoded relative to others, including their shared and distinct embedding\nspaces. We find that, across multiple pre-trained decoder-only LLMs, the\nanalyzed personas show large differences in representation space only within\nthe final third of the decoder layers. We observe overlapping activations for\nspecific ethical perspectives -- such as moral nihilism and utilitarianism --\nsuggesting a degree of polysemy. In contrast, political ideologies like\nconservatism and liberalism appear to be represented in more distinct regions.\nThese findings help to improve our understanding of how LLMs internally\nrepresent information and can inform future efforts in refining the modulation\nof specific human traits in LLM outputs. Warning: This paper includes\npotentially offensive sample statements.", "published": "2025-05-30 12:46:44", "link": "http://arxiv.org/abs/2505.24539v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Binary Cumulative Encoding meets Time Series Forecasting", "abstract": "Recent studies in time series forecasting have explored formulating\nregression via classification task. By discretizing the continuous target space\ninto bins and predicting over a fixed set of classes, these approaches benefit\nfrom stable training, robust uncertainty modeling, and compatibility with\nmodern deep learning architectures. However, most existing methods rely on\none-hot encoding that ignores the inherent ordinal structure of the underlying\nvalues. As a result, they fail to provide information about the relative\ndistance between predicted and true values during training. In this paper, we\npropose to address this limitation by introducing binary cumulative encoding\n(BCE), that represents scalar targets into monotonic binary vectors. This\nencoding implicitly preserves order and magnitude information, allowing the\nmodel to learn distance-aware representations while still operating within a\nclassification framework. We propose a convolutional neural network\narchitecture specifically designed for BCE, incorporating residual and dilated\nconvolutions to enable fast and expressive temporal modeling. Through extensive\nexperiments on benchmark forecasting datasets, we show that our approach\noutperforms widely used methods in both point and probabilistic forecasting,\nwhile requiring fewer parameters and enabling faster training.", "published": "2025-05-30 13:41:39", "link": "http://arxiv.org/abs/2505.24595v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification", "abstract": "Fine-grained bird image classification (FBIC) is not only of great\nsignificance for ecological monitoring and species identification, but also\nholds broad research value in the fields of image recognition and fine-grained\nvisual modeling. Compared with general image classification tasks, FBIC poses\nmore formidable challenges: 1) the differences in species size and imaging\ndistance result in the varying sizes of birds presented in the images; 2)\ncomplex natural habitats often introduce strong background interference; 3) and\nhighly flexible poses such as flying, perching, or foraging result in\nsubstantial intra-class variability. These factors collectively make it\ndifficult for traditional methods to stably extract discriminative features,\nthereby limiting the generalizability and interpretability of models in\nreal-world applications. To address these challenges, this paper proposes a\nfine-grained bird classification framework based on strip-aware spatial\nperception, which aims to capture long-range spatial dependencies across entire\nrows or columns in bird images, thereby enhancing the model's robustness and\ninterpretability. The proposed method incorporates two novel modules:\nextensional perception aggregator (EPA) and channel semantic weaving (CSW).\nSpecifically, EPA integrates local texture details with global structural cues\nby aggregating information across horizontal and vertical spatial directions.\nCSW further refines the semantic representations by adaptively fusing\nlong-range and short-range information along the channel dimension. Built upon\na ResNet-50 backbone, the model enables jump-wise connection of extended\nstructural features across the spatial domain. Experimental results on the\nCUB-200-2011 dataset demonstrate that our framework achieves significant\nperformance improvements while maintaining architectural efficiency.", "published": "2025-05-30 09:10:12", "link": "http://arxiv.org/abs/2505.24380v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Reinforcing Video Reasoning with Focused Thinking", "abstract": "Recent advancements in reinforcement learning, particularly through Group\nRelative Policy Optimization (GRPO), have significantly improved multimodal\nlarge language models for complex reasoning tasks. However, two critical\nlimitations persist: 1) they often produce unfocused, verbose reasoning chains\nthat obscure salient spatiotemporal cues and 2) binary rewarding fails to\naccount for partially correct answers, resulting in high reward variance and\ninefficient learning. In this paper, we propose TW-GRPO, a novel framework that\nenhances visual reasoning with focused thinking and dense reward granularity.\nSpecifically, we employs a token weighting mechanism that prioritizes tokens\nwith high informational density (estimated by intra-group variance),\nsuppressing redundant tokens like generic reasoning prefixes. Furthermore, we\nreformulate RL training by shifting from single-choice to multi-choice QA\ntasks, where soft rewards enable finer-grained gradient estimation by\ndistinguishing partial correctness. Additionally, we propose question-answer\ninversion, a data augmentation strategy to generate diverse multi-choice\nsamples from existing benchmarks. Experiments demonstrate state-of-the-art\nperformance on several video reasoning and general understanding benchmarks.\nNotably, TW-GRPO achieves 50.4\\% accuracy on CLEVRER (18.8\\% improvement over\nVideo-R1) and 65.8\\% on MMVU. Our codes are available at\n\\href{https://github.com/longmalongma/TW-GRPO}.", "published": "2025-05-30 15:42:19", "link": "http://arxiv.org/abs/2505.24718v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Efficient RAW Image Deblurring with Adaptive Frequency Modulation", "abstract": "Image deblurring plays a crucial role in enhancing visual clarity across\nvarious applications. Although most deep learning approaches primarily focus on\nsRGB images, which inherently lose critical information during the image signal\nprocessing pipeline, RAW images, being unprocessed and linear, possess superior\nrestoration potential but remain underexplored. Deblurring RAW images presents\nunique challenges, particularly in handling frequency-dependent blur while\nmaintaining computational efficiency. To address these issues, we propose\nFrequency Enhanced Network (FrENet), a framework specifically designed for\nRAW-to-RAW deblurring that operates directly in the frequency domain. We\nintroduce a novel Adaptive Frequency Positional Modulation module, which\ndynamically adjusts frequency components according to their spectral positions,\nthereby enabling precise control over the deblurring process. Additionally,\nfrequency domain skip connections are adopted to further preserve\nhigh-frequency details. Experimental results demonstrate that FrENet surpasses\nstate-of-the-art deblurring methods in RAW image deblurring, achieving\nsignificantly better restoration quality while maintaining high efficiency in\nterms of reduced MACs. Furthermore, FrENet's adaptability enables it to be\nextended to sRGB images, where it delivers comparable or superior performance\ncompared to methods specifically designed for sRGB data. The code will be\navailable at https://github.com/WenlongJiao/FrENet .", "published": "2025-05-30 09:46:39", "link": "http://arxiv.org/abs/2505.24407v2", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "EVA-MILP: Towards Standardized Evaluation of MILP Instance Generation", "abstract": "Mixed-Integer Linear Programming (MILP) is fundamental to solving complex\ndecision-making problems. The proliferation of MILP instance generation\nmethods, driven by machine learning's demand for diverse optimization datasets\nand the limitations of static benchmarks, has significantly outpaced\nstandardized evaluation techniques. Consequently, assessing the fidelity and\nutility of synthetic MILP instances remains a critical, multifaceted challenge.\nThis paper introduces a comprehensive benchmark framework designed for the\nsystematic and objective evaluation of MILP instance generation methods. Our\nframework provides a unified and extensible methodology, assessing instance\nquality across crucial dimensions: mathematical validity, structural\nsimilarity, computational hardness, and utility in downstream machine learning\ntasks. A key innovation is its in-depth analysis of solver-internal features --\nparticularly by comparing distributions of key solver outputs including root\nnode gap, heuristic success rates, and cut plane usage -- leveraging the\nsolver's dynamic solution behavior as an `expert assessment' to reveal nuanced\ncomputational resemblances. By offering a structured approach with clearly\ndefined solver-independent and solver-dependent metrics, our benchmark aims to\nfacilitate robust comparisons among diverse generation techniques, spur the\ndevelopment of higher-quality instance generators, and ultimately enhance the\nreliability of research reliant on synthetic MILP data. The framework's\neffectiveness in systematically comparing the fidelity of instance sets is\ndemonstrated using contemporary generative models.", "published": "2025-05-30 16:42:15", "link": "http://arxiv.org/abs/2505.24779v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning", "abstract": "Sparse autoencoders are a promising new approach for decomposing language\nmodel activations for interpretation and control. They have been applied\nsuccessfully to vision transformer image encoders and to small-scale diffusion\nmodels. Inference-Time Decomposition of Activations (ITDA) is a recently\nproposed variant of dictionary learning that takes the dictionary to be a set\nof data points from the activation distribution and reconstructs them with\ngradient pursuit. We apply Sparse Autoencoders (SAEs) and ITDA to a large\ntext-to-image diffusion model, Flux 1, and consider the interpretability of\nembeddings of both by introducing a visual automated interpretation pipeline.\nWe find that SAEs accurately reconstruct residual stream embeddings and beat\nMLP neurons on interpretability. We are able to use SAE features to steer image\ngeneration through activation addition. We find that ITDA has comparable\ninterpretability to SAEs.", "published": "2025-05-30 08:53:27", "link": "http://arxiv.org/abs/2505.24360v2", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC", "abstract": "Multilingual speech processing with self-supervised or supervised pre-trained\nSpeech Foundation Models (SFM) has achieved strong performance on tasks like\nLanguage Identification (LID) and Automatic Speech Recognition (ASR). However,\nthese models struggle with limited resources during fine-tuning. This paper\nenhances multilingual LID and ASR on ML-SUPERB 2.0 by exploring multiple\nstrategies for adapting SFMs, including frozen upstream training, partial\nfine-tuning, and low-rank adaptation. Furthermore, we employ data augmentation\nto mitigate performance gaps in few-shot settings and introduce LID\nConnectionist Temporal Classification (CTC) loss for regularization. Our\napproach achieves a 14% relative improvement in LID accuracy and a 30% relative\nreduction in ASR CER over the baseline on ML-SUPERB 2.0, securing second place\nin the Interspeech 2025 ML-SUPERB 2.0 Challenge.", "published": "2025-05-30 04:25:15", "link": "http://arxiv.org/abs/2505.24200v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automated Symmetric Constructions in Discrete Geometry", "abstract": "We present a computational methodology for obtaining rotationally symmetric\nsets of points satisfying discrete geometric constraints, and demonstrate its\napplicability by discovering new solutions to some well-known problems in\ncombinatorial geometry. Our approach takes the usage of SAT solvers in discrete\ngeometry further by directly embedding rotational symmetry into the\ncombinatorial encoding of geometric configurations. Then, to realize concrete\npoint sets corresponding to abstract designs provided by a SAT solver, we\nintroduce a novel local-search realizability solver, which shows excellent\npractical performance despite the intrinsic $\\exists \\mathbb{R}$-completeness\nof the problem. Leveraging this combined approach, we provide symmetric\nextremal solutions to the Erd\\H{o}s-Szekeres problem, as well as a minimal\nodd-sized solution with 21 points for the everywhere-unbalanced-points problem,\nimproving on the previously known 23-point configuration. The imposed\nsymmetries yield more aesthetically appealing solutions, enhancing human\ninterpretability, and simultaneously offer computational benefits by\nsignificantly reducing the number of variables required to encode discrete\ngeometric problems.", "published": "2025-05-30 21:00:43", "link": "http://arxiv.org/abs/2506.00224v1", "categories": ["cs.DM", "cs.CG"], "primary_category": "cs.DM"}
{"title": "FACE: A Fine-grained Reference Free Evaluator for Conversational Recommender Systems", "abstract": "A systematic, reliable, and low-cost evaluation of Conversational Recommender\nSystems (CRSs) remains an open challenge. Existing automatic CRS evaluation\nmethods are proven insufficient for evaluating the dynamic nature of\nrecommendation conversations. This work proposes FACE: a Fine-grained,\nAspect-based Conversation Evaluation method that provides evaluation scores for\ndiverse turn and dialogue level qualities of recommendation conversations. FACE\nis reference-free and shows strong correlation with human judgments, achieving\nsystem correlation of 0.9 and turn/dialogue-level of 0.5, outperforming\nstate-of-the-art CRS evaluation methods by a large margin. Additionally, unlike\nexisting LLM-based methods that provide single uninterpretable scores, FACE\nprovides insights into the system performance and enables identifying and\nlocating problems within conversations.", "published": "2025-05-30 23:54:13", "link": "http://arxiv.org/abs/2506.00314v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "GPR: Empowering Generation with Graph-Pretrained Retriever", "abstract": "Graph retrieval-augmented generation (GRAG) places high demands on\ngraph-specific retrievers. However, existing retrievers often rely on language\nmodels pretrained on plain text, limiting their effectiveness due to domain\nmisalignment and structure ignorance. To address these challenges, we propose\nGPR, a graph-based retriever pretrained directly on knowledge graphs. GPR\naligns natural language questions with relevant subgraphs through LLM-guided\ngraph augmentation and employs a structure-aware objective to learn\nfine-grained retrieval strategies. Experiments on two datasets, three LLM\nbackbones, and five baselines show that GPR consistently improves both\nretrieval quality and downstream generation, demonstrating its effectiveness as\na robust retrieval solution for GRAG.", "published": "2025-05-30 21:50:29", "link": "http://arxiv.org/abs/2506.00261v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "ZeShot-VQA: Zero-Shot Visual Question Answering Framework with Answer Mapping for Natural Disaster Damage Assessment", "abstract": "Natural disasters usually affect vast areas and devastate infrastructures.\nPerforming a timely and efficient response is crucial to minimize the impact on\naffected communities, and data-driven approaches are the best choice. Visual\nquestion answering (VQA) models help management teams to achieve in-depth\nunderstanding of damages. However, recently published models do not possess the\nability to answer open-ended questions and only select the best answer among a\npredefined list of answers. If we want to ask questions with new additional\npossible answers that do not exist in the predefined list, the model needs to\nbe fin-tuned/retrained on a new collected and annotated dataset, which is a\ntime-consuming procedure. In recent years, large-scale Vision-Language Models\n(VLMs) have earned significant attention. These models are trained on extensive\ndatasets and demonstrate strong performance on both unimodal and multimodal\nvision/language downstream tasks, often without the need for fine-tuning. In\nthis paper, we propose a VLM-based zero-shot VQA (ZeShot-VQA) method, and\ninvestigate the performance of on post-disaster FloodNet dataset. Since the\nproposed method takes advantage of zero-shot learning, it can be applied on new\ndatasets without fine-tuning. In addition, ZeShot-VQA is able to process and\ngenerate answers that has been not seen during the training procedure, which\ndemonstrates its flexibility.", "published": "2025-05-30 21:15:11", "link": "http://arxiv.org/abs/2506.00238v1", "categories": ["cs.CV", "cs.CL", "cs.IR", "cs.LG", "I.2.7; I.2.10; I.5.1"], "primary_category": "cs.CV"}
{"title": "Curate, Connect, Inquire: A System for Findable Accessible Interoperable and Reusable (FAIR) Human-Robot Centered Datasets", "abstract": "The rapid growth of AI in robotics has amplified the need for high-quality,\nreusable datasets, particularly in human-robot interaction (HRI) and\nAI-embedded robotics. While more robotics datasets are being created, the\nlandscape of open data in the field is uneven. This is due to a lack of\ncuration standards and consistent publication practices, which makes it\ndifficult to discover, access, and reuse robotics data. To address these\nchallenges, this paper presents a curation and access system with two main\ncontributions: (1) a structured methodology to curate, publish, and integrate\nFAIR (Findable, Accessible, Interoperable, Reusable) human-centered robotics\ndatasets; and (2) a ChatGPT-powered conversational interface trained with the\ncurated datasets metadata and documentation to enable exploration, comparison\nrobotics datasets and data retrieval using natural language. Developed based on\npractical experience curating datasets from robotics labs within Texas Robotics\nat the University of Texas at Austin, the system demonstrates the value of\nstandardized curation and persistent publication of robotics data. The system's\nevaluation suggests that access and understandability of human-robotics data\nare significantly improved. This work directly aligns with the goals of the\nHCRL @ ICRA 2025 workshop and represents a step towards more human-centered\naccess to data for embodied AI.", "published": "2025-05-30 20:48:32", "link": "http://arxiv.org/abs/2506.00220v1", "categories": ["cs.IR", "cs.HC", "cs.RO"], "primary_category": "cs.IR"}
{"title": "The World As Large Language Models See It: Exploring the reliability of LLMs in representing geographical features", "abstract": "As large language models (LLMs) continue to evolve, questions about their\ntrustworthiness in delivering factual information have become increasingly\nimportant. This concern also applies to their ability to accurately represent\nthe geographic world. With recent advancements in this field, it is relevant to\nconsider whether and to what extent LLMs' representations of the geographical\nworld can be trusted. This study evaluates the performance of GPT-4o and Gemini\n2.0 Flash in three key geospatial tasks: geocoding, elevation estimation, and\nreverse geocoding. In the geocoding task, both models exhibited systematic and\nrandom errors in estimating the coordinates of St. Anne's Column in Innsbruck,\nAustria, with GPT-4o showing greater deviations and Gemini 2.0 Flash\ndemonstrating more precision but a significant systematic offset. For elevation\nestimation, both models tended to underestimate elevations across Austria,\nthough they captured overall topographical trends, and Gemini 2.0 Flash\nperformed better in eastern regions. The reverse geocoding task, which involved\nidentifying Austrian federal states from coordinates, revealed that Gemini 2.0\nFlash outperformed GPT-4o in overall accuracy and F1-scores, demonstrating\nbetter consistency across regions. Despite these findings, neither model\nachieved an accurate reconstruction of Austria's federal states, highlighting\npersistent misclassifications. The study concludes that while LLMs can\napproximate geographic information, their accuracy and reliability are\ninconsistent, underscoring the need for fine-tuning with geographical\ninformation to enhance their utility in GIScience and Geoinformatics.", "published": "2025-05-30 20:14:17", "link": "http://arxiv.org/abs/2506.00203v1", "categories": ["cs.CY", "cs.AI", "cs.IR"], "primary_category": "cs.CY"}
{"title": "LaMP-QA: A Benchmark for Personalized Long-form Question Answering", "abstract": "Personalization is essential for question answering systems that are\nuser-centric. Despite its importance, personalization in answer generation has\nbeen relatively underexplored. This is mainly due to lack of resources for\ntraining and evaluating personalized question answering systems. We address\nthis gap by introducing LaMP-QA -- a benchmark designed for evaluating\npersonalized long-form answer generation. The benchmark covers questions from\nthree major categories: (1) Arts & Entertainment, (2) Lifestyle & Personal\nDevelopment, and (3) Society & Culture, encompassing over 45 subcategories in\ntotal. To assess the quality and potential impact of the LaMP-QA benchmark for\npersonalized question answering, we conduct comprehensive human and automatic\nevaluations, to compare multiple evaluation strategies for evaluating generated\npersonalized responses and measure their alignment with human preferences.\nFurthermore, we benchmark a number of non-personalized and personalized\napproaches based on open-source and proprietary large language models (LLMs).\nOur results show that incorporating the personalized context provided leads to\nperformance improvements of up to 39%. The benchmark is publicly released to\nsupport future research in this area.", "published": "2025-05-30 18:16:03", "link": "http://arxiv.org/abs/2506.00137v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Gated Multimodal Graph Learning for Personalized Recommendation", "abstract": "Multimodal recommendation has emerged as a promising solution to alleviate\nthe cold-start and sparsity problems in collaborative filtering by\nincorporating rich content information, such as product images and textual\ndescriptions. However, effectively integrating heterogeneous modalities into a\nunified recommendation framework remains a challenge. Existing approaches often\nrely on fixed fusion strategies or complex architectures , which may fail to\nadapt to modality quality variance or introduce unnecessary computational\noverhead.\n  In this work, we propose RLMultimodalRec, a lightweight and modular\nrecommendation framework that combines graph-based user modeling with adaptive\nmultimodal item encoding. The model employs a gated fusion module to\ndynamically balance the contribution of visual and textual modalities, enabling\nfine-grained and content-aware item representations. Meanwhile, a two-layer\nLightGCN encoder captures high-order collaborative signals by propagating\nembeddings over the user-item interaction graph without relying on nonlinear\ntransformations.\n  We evaluate our model on a real-world dataset from the Amazon product domain.\nExperimental results demonstrate that RLMultimodalRec consistently outperforms\nseveral competitive baselines, including collaborative filtering, visual-aware,\nand multimodal GNN-based methods. The proposed approach achieves significant\nimprovements in top-K recommendation metrics while maintaining scalability and\ninterpretability, making it suitable for practical deployment.", "published": "2025-05-30 16:57:17", "link": "http://arxiv.org/abs/2506.00107v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "PersianMedQA: Language-Centric Evaluation of LLMs in the Persian Medical Domain", "abstract": "Large Language Models (LLMs) have achieved remarkable performance on a wide\nrange of NLP benchmarks, often surpassing human-level accuracy. However, their\nreliability in high-stakes domains such as medicine, particularly in\nlow-resource languages, remains underexplored. In this work, we introduce\nPersianMedQA, a large-scale, expert-validated dataset of multiple-choice\nPersian medical questions, designed to evaluate LLMs across both Persian and\nEnglish. We benchmark over 40 state-of-the-art models, including\ngeneral-purpose, Persian fine-tuned, and medical LLMs, in zero-shot and\nchain-of-thought (CoT) settings. Our results show that closed-source general\nmodels (e.g., GPT-4.1) consistently outperform all other categories, achieving\n83.3% accuracy in Persian and 80.7% in English, while Persian fine-tuned models\nsuch as Dorna underperform significantly (e.g., 35.9% in Persian), often\nstruggling with both instruction-following and domain reasoning. We also\nanalyze the impact of translation, showing that while English performance is\ngenerally higher, Persian responses are sometimes more accurate due to cultural\nand clinical contextual cues. Finally, we demonstrate that model size alone is\ninsufficient for robust performance without strong domain or language\nadaptation. PersianMedQA provides a foundation for evaluating multilingual and\nculturally grounded medical reasoning in LLMs. The PersianMedQA dataset can be\naccessed at: https://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA", "published": "2025-05-30 21:34:30", "link": "http://arxiv.org/abs/2506.00250v2", "categories": ["cs.CL", "cs.IT", "math.IT"], "primary_category": "cs.CL"}
{"title": "Overfitting has a limitation: a model-independent generalization error bound based on R\u00e9nyi entropy", "abstract": "Will further scaling up of machine learning models continue to bring success?\nA significant challenge in answering this question lies in understanding\ngeneralization error, which is the impact of overfitting. Understanding\ngeneralization error behavior of increasingly large-scale machine learning\nmodels remains a significant area of investigation, as conventional analyses\noften link error bounds to model complexity, failing to fully explain the\nsuccess of extremely large architectures. This research introduces a novel\nperspective by establishing a model-independent upper bound for generalization\nerror applicable to algorithms whose outputs are determined solely by the\ndata's histogram, such as empirical risk minimization or gradient-based\nmethods. Crucially, this bound is shown to depend only on the R\\'enyi entropy\nof the data-generating distribution, suggesting that a small generalization\nerror can be maintained even with arbitrarily large models, provided the data\nquantity is sufficient relative to this entropy. This framework offers a direct\nexplanation for the phenomenon where generalization performance degrades\nsignificantly upon injecting random noise into data, where the performance\ndegrade is attributed to the consequent increase in the data distribution's\nR\\'enyi entropy. Furthermore, we adapt the no-free-lunch theorem to be\ndata-distribution-dependent, demonstrating that an amount of data corresponding\nto the R\\'enyi entropy is indeed essential for successful learning, thereby\nhighlighting the tightness of our proposed generalization bound.", "published": "2025-05-30 19:41:37", "link": "http://arxiv.org/abs/2506.00182v1", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Sorrel: A simple and flexible framework for multi-agent reinforcement learning", "abstract": "We introduce Sorrel (https://github.com/social-ai-uoft/sorrel), a simple\nPython interface for generating and testing new multi-agent reinforcement\nlearning environments. This interface places a high degree of emphasis on\nsimplicity and accessibility, and uses a more psychologically intuitive\nstructure for the basic agent-environment loop, making it a useful tool for\nsocial scientists to investigate how learning and social interaction leads to\nthe development and change of group dynamics. In this short paper, we outline\nthe basic design philosophy and features of Sorrel.", "published": "2025-05-30 21:04:47", "link": "http://arxiv.org/abs/2506.00228v1", "categories": ["cs.MA", "cs.LG"], "primary_category": "cs.MA"}
{"title": "On general and complete multidimensional Riemann solvers for nonlinear systems of hyperbolic conservation laws", "abstract": "In this work, we introduce a framework to design multidimensional Riemann\nsolvers for nonlinear systems of hyperbolic conservation laws on general\nunstructured polygonal Voronoi-like tessellations. In this framework we propose\ntwo simple but complete solvers. The first method is a direct extension of the\nOsher-Solomon Riemann solver to multiple space dimensions. Here, the\nmultidimensional numerical dissipation is obtained by integrating the absolute\nvalue of the flux Jacobians over a dual triangular mesh around each node of the\nprimal polygonal grid. The required nodal gradient is then evaluated on a local\ncomputational simplex involving the d+1 neighbors meeting at each corner. The\nsecond method is a genuinely multidimensional upwind flux. By introducing a\nfluctuation form of finite volume methods with corner fluxes, we show an\nequivalence with residual distribution schemes (RD). This naturally allows to\nconstruct genuinely multidimensional upwind corner fluxes starting from\nexisting and well-known RD fluctuations. In particular, we explore the use of\ncorner fluxes obtained from the so-called N scheme, i.e. the Roe's original\noptimal multidimensional upwind advection scheme.\n  Both methods use the full eigenstructure of the underlying hyperbolic system\nand are therefore complete by construction. A simple higher order extension up\nto fourth order in space and time is then introduced at the aid of a CWENO\nreconstruction in space and an ADER approach in time, leading to a family of\nhigh order accurate fully-discrete one-step schemes based on genuinely\nmultidimensional Riemann solvers.\n  We present applications of our new numerical schemes to several test problems\nfor the compressible Euler equations of gas-dyanamics. In particular, we show\nthat the proposed schemes are at the same time carbuncle-free and preserve\ncertain stationary shear waves exactly.", "published": "2025-05-30 20:27:24", "link": "http://arxiv.org/abs/2506.00207v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "On the regularization property of Levenberg-Marquardt method with Singular Scaling for nonlinear inverse problems", "abstract": "Recently, in Applied Mathematics and Computation 474 (2024) 128688, a\nLevenberg-Marquardt method (LMM) with Singular Scaling was analyzed and\nsuccessfully applied in parameter estimation problems in heat conduction where\nthe use of a particular singular scaling matrix (semi-norm regularizer)\nprovided approximate solutions of better quality than those of the classic LMM.\nHere we propose a regularization framework for the Levenberg-Marquardt method\nwith Singular Scaling (LMMSS) applied to nonlinear inverse problems with noisy\ndata. Assuming that the noise-free problem admits exact solutions\n(zero-residual case), we consider the LMMSS iteration where the regularization\neffect is induced by the choice of a possibly singular scaling matrix and an\nimplicit control of the regularization parameter. The discrepancy principle is\nused to define a stopping index that ensures stability of the computed\nsolutions with respect to data perturbations. Under a new Tangent Cone\nCondition, we prove that the iterates obtained with noisy data converge to a\nsolution of the unperturbed problem as the noise level tends to zero. This work\nrepresents a first step toward the analysis of regularizing properties of the\nLMMSS method and extends previous results in the literature on regularizing\nLM-type methods.", "published": "2025-05-30 19:59:47", "link": "http://arxiv.org/abs/2506.00190v1", "categories": ["math.NA", "cs.NA", "math.OC", "49M37, 65K05, 90C30"], "primary_category": "math.NA"}
{"title": "The Impact of Uniform Circular Array on Near-field ISAC", "abstract": "A novel uniform circular array (UCA) based near-field (NF) integrated sensing\nand communication (ISAC) framework is proposed, where the Cylindrical\ncoordinate is invoked to evaluate the joint positioning performance. The joint\nsquared position error bound (SPEB) of the sensing target (ST) is derived for\nthe coplanar and non-coplanar cases. For the coplanar case, where the ST is\nlocated in the coplanar region of the UCA, the approximate Cram{\\'e}r-Rao bound\n(CRB) expressions for the separate angle and distance estimation are given by\nexploiting the uniform spherical wavefront model. A SPEB minimization problem\nis formulated with the constraints of communication requirement and power\nbudget, where the closed-form solution to minimize the CRB of the angle is\nderived. Inspired by the close-form expression, a low complexity vector-based\nquadratic transformation (VQF) algorithm is proposed by invoking the Rayleigh\nquotient. For the non-coplanar case, where the ST is located beyond the\ncoplanar region of the UCA, the separate CRBs over three-dimensional\ncoordinates and the joint SPEB approximations are derived. To minimize the SPEB\nperformance, the semi-definite relaxation (SDR) method and extended\nlow-complexity VQF algorithm are proposed. Numerical results validated that i)\nthe Fisher Information Matrix about angle and distance in NF propagation can be\napproximated as a diagonal matrix with the trinity loss; ii) Compared with the\nuniform planar array, the UCA achieve better positioning performance when ST\nlocated in the coplanar of the antenna array; and iii) the proposed VQF\nalgorithms reach higher solution precision than conventional SDR algorithm with\nmuch less computation complexity.", "published": "2025-05-30 20:33:31", "link": "http://arxiv.org/abs/2506.00211v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "STARS-assisted Near-field ISAC: Sensor Deployment and Beamforming Design", "abstract": "A simultaneously transmitting and reflecting surface (STARS) assisted\nnear-field (NF) integrated sensing and communication (ISAC) framework is\nproposed, where the radio sensors are installed on the STARS to directly\nconduct the distance-domain sensing by exploiting the characteristic spherical\nwavefront. A new squared position error bound (SPEB) expression is derived to\nreveal the dependence on beamforming (BF) design and sensor deployment. To\nbalance the trade-off between the SPEB and the sensor deployment cost, a cost\nfunction minimization problem, a cost function minimization problem is\nformulated to jointly optimize the sensor deployment, the active and passive\nBF, subject to communication and power consumption constraints. For the sensor\ndeployment optimization, a joint sensor deployment algorithm is proposed by\ninvoking the successive convex approximation. Under a specific relationship\nbetween the sensor numbers and BF design, we derive the optimal sensor interval\nin a closed-form expression. For the joint BF optimization, a penalty-based\nmethod is invoked. Simulation results validated that the derived SPEB\nexpression is close to the exact SPEB, which reveals the Fisher information\nMatrix of position estimation in NF can be approximated as a diagonal matrix.\nFurthermore, the proposed algorithms achieve the best SPEB performance than the\nbenchmark schemes accompanying the lowest deployment cost.", "published": "2025-05-30 20:02:56", "link": "http://arxiv.org/abs/2506.00192v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
