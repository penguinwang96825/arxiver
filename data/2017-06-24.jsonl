{"title": "Encoder-Decoder Shift-Reduce Syntactic Parsing", "abstract": "Starting from NMT, encoder-decoder neu- ral networks have been used for many\nNLP problems. Graph-based models and transition-based models borrowing the en-\ncoder components achieve state-of-the-art performance on dependency parsing and\nconstituent parsing, respectively. How- ever, there has not been work\nempirically studying the encoder-decoder neural net- works for transition-based\nparsing. We apply a simple encoder-decoder to this end, achieving comparable\nresults to the parser of Dyer et al. (2015) on standard de- pendency parsing,\nand outperforming the parser of Vinyals et al. (2015) on con- stituent parsing.", "published": "2017-06-24 04:08:11", "link": "http://arxiv.org/abs/1706.07905v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cluster Based Symbolic Representation for Skewed Text Categorization", "abstract": "In this work, a problem associated with imbalanced text corpora is addressed.\nA method of converting an imbalanced text corpus into a balanced one is\npresented. The presented method employs a clustering algorithm for conversion.\nInitially to avoid curse of dimensionality, an effective representation scheme\nbased on term class relevancy measure is adapted, which drastically reduces the\ndimension to the number of classes in the corpus. Subsequently, the samples of\nlarger sized classes are grouped into a number of subclasses of smaller sizes\nto make the entire corpus balanced. Each subclass is then given a single\nsymbolic vector representation by the use of interval valued features. This\nsymbolic representation in addition to being compact helps in reducing the\nspace requirement and also the classification time. The proposed model has been\nempirically demonstrated for its superiority on bench marking datasets viz.,\nReuters 21578 and TDT2. Further, it has been compared against several other\nexisting contemporary models including model based on support vector machine.\nThe comparative analysis indicates that the proposed model outperforms the\nother existing models.", "published": "2017-06-24 06:04:21", "link": "http://arxiv.org/abs/1706.07912v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Semi-supervised Text Categorization Using Recursive K-means Clustering", "abstract": "In this paper, we present a semi-supervised learning algorithm for\nclassification of text documents. A method of labeling unlabeled text documents\nis presented. The presented method is based on the principle of divide and\nconquer strategy. It uses recursive K-means algorithm for partitioning both\nlabeled and unlabeled data collection. The K-means algorithm is applied\nrecursively on each partition till a desired level partition is achieved such\nthat each partition contains labeled documents of a single class. Once the\ndesired clusters are obtained, the respective cluster centroids are considered\nas representatives of the clusters and the nearest neighbor rule is used for\nclassifying an unknown text document. Series of experiments have been conducted\nto bring out the superiority of the proposed model over other recent state of\nthe art models on 20Newsgroups dataset.", "published": "2017-06-24 06:08:27", "link": "http://arxiv.org/abs/1706.07913v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
