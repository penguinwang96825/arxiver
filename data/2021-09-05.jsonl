{"title": "SideControl: Controlled Open-domain Dialogue Generation via Additive\n  Side Networks", "abstract": "Transformer-based pre-trained language models boost the performance of\nopen-domain dialogue systems. Prior works leverage Transformer-based\npre-trained language models to generate texts with desired attributes in two\ngeneral approaches: (1) gradient-based methods: updating all latent\nrepresentations of pre-trained models with gradients from attribute models; (2)\nweighted-decoding methods: re-ranking beam candidates from pre-trained models\nwith attribute functions. However, gradient-based methods lead to high\ncomputation cost and can easily get overfitted on small training sets, while\nweighted-decoding methods are inherently constrained by the low-variance\nhigh-bias pre-trained model. In this work, we propose a novel approach to\ncontrol the generation of Transformer-based pre-trained language models: the\nSideControl framework, which leverages a novel control attributes loss to\nincorporate useful control signals, and is shown to perform well with very\nlimited training samples. We evaluate our proposed method on two benchmark\nopen-domain dialogue datasets, and results show that the SideControl framework\nhas better controllability, higher generation quality and better\nsample-efficiency than existing gradient-based and weighted-decoding baselines.", "published": "2021-09-05 01:15:26", "link": "http://arxiv.org/abs/2109.01958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counterfactual Evaluation for Explainable AI", "abstract": "While recent years have witnessed the emergence of various explainable\nmethods in machine learning, to what degree the explanations really represent\nthe reasoning process behind the model prediction -- namely, the faithfulness\nof explanation -- is still an open problem. One commonly used way to measure\nfaithfulness is \\textit{erasure-based} criteria. Though conceptually simple,\nerasure-based criterion could inevitably introduce biases and artifacts. We\npropose a new methodology to evaluate the faithfulness of explanations from the\n\\textit{counterfactual reasoning} perspective: the model should produce\nsubstantially different outputs for the original input and its corresponding\ncounterfactual edited on a faithful feature. Specially, we introduce two\nalgorithms to find the proper counterfactuals in both discrete and continuous\nscenarios and then use the acquired counterfactuals to measure faithfulness.\nEmpirical results on several datasets show that compared with existing metrics,\nour proposed counterfactual evaluation method can achieve top correlation with\nthe ground truth under diffe", "published": "2021-09-05 01:38:49", "link": "http://arxiv.org/abs/2109.01962v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Hierarchical Structures with Differentiable Nondeterministic\n  Stacks", "abstract": "Learning hierarchical structures in sequential data -- from simple\nalgorithmic patterns to natural language -- in a reliable, generalizable way\nremains a challenging problem for neural language models. Past work has shown\nthat recurrent neural networks (RNNs) struggle to generalize on held-out\nalgorithmic or syntactic patterns without supervision or some inductive bias.\nTo remedy this, many papers have explored augmenting RNNs with various\ndifferentiable stacks, by analogy with finite automata and pushdown automata\n(PDAs). In this paper, we improve the performance of our recently proposed\nNondeterministic Stack RNN (NS-RNN), which uses a differentiable data structure\nthat simulates a nondeterministic PDA, with two important changes. First, the\nmodel now assigns unnormalized positive weights instead of probabilities to\nstack actions, and we provide an analysis of why this improves training.\nSecond, the model can directly observe the state of the underlying PDA. Our\nmodel achieves lower cross-entropy than all previous stack RNNs on five\ncontext-free language modeling tasks (within 0.05 nats of the\ninformation-theoretic lower bound), including a task on which the NS-RNN\npreviously failed to outperform a deterministic stack RNN baseline. Finally, we\npropose a restricted version of the NS-RNN that incrementally processes\ninfinitely long sequences, and we present language modeling results on the Penn\nTreebank.", "published": "2021-09-05 03:25:23", "link": "http://arxiv.org/abs/2109.01982v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Re-entry Prediction for Online Conversations via Self-Supervised\n  Learning", "abstract": "In recent years, world business in online discussions and opinion sharing on\nsocial media is booming. Re-entry prediction task is thus proposed to help\npeople keep track of the discussions which they wish to continue. Nevertheless,\nexisting works only focus on exploiting chatting history and context\ninformation, and ignore the potential useful learning signals underlying\nconversation data, such as conversation thread patterns and repeated engagement\nof target users, which help better understand the behavior of target users in\nconversations. In this paper, we propose three interesting and well-founded\nauxiliary tasks, namely, Spread Pattern, Repeated Target user, and Turn\nAuthorship, as the self-supervised signals for re-entry prediction. These\nauxiliary tasks are trained together with the main task in a multi-task manner.\nExperimental results on two datasets newly collected from Twitter and Reddit\nshow that our method outperforms the previous state-of-the-arts with fewer\nparameters and faster convergence. Extensive experiments and analysis show the\neffectiveness of our proposed models and also point out some key ideas in\ndesigning self-supervised tasks.", "published": "2021-09-05 08:07:52", "link": "http://arxiv.org/abs/2109.02020v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Self-Debiasing Framework for Robust NLU Training", "abstract": "Existing Natural Language Understanding (NLU) models have been shown to\nincorporate dataset biases leading to strong performance on in-distribution\n(ID) test sets but poor performance on out-of-distribution (OOD) ones. We\nintroduce a simple yet effective debiasing framework whereby the shallow\nrepresentations of the main model are used to derive a bias model and both\nmodels are trained simultaneously. We demonstrate on three well studied NLU\ntasks that despite its simplicity, our method leads to competitive OOD results.\nIt significantly outperforms other debiasing approaches on two tasks, while\nstill delivering high in-distribution performance.", "published": "2021-09-05 13:20:31", "link": "http://arxiv.org/abs/2109.02071v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformer Models for Text Coherence Assessment", "abstract": "Coherence is an important aspect of text quality and is crucial for ensuring\nits readability. It is essential desirable for outputs from text generation\nsystems like summarization, question answering, machine translation, question\ngeneration, table-to-text, etc. An automated coherence scoring model is also\nhelpful in essay scoring or providing writing feedback. A large body of\nprevious work has leveraged entity-based methods, syntactic patterns, discourse\nrelations, and more recently traditional deep learning architectures for text\ncoherence assessment. Previous work suffers from drawbacks like the inability\nto handle long-range dependencies, out-of-vocabulary words, or model sequence\ninformation. We hypothesize that coherence assessment is a cognitively complex\ntask that requires deeper models and can benefit from other related tasks.\nAccordingly, in this paper, we propose four different Transformer-based\narchitectures for the task: vanilla Transformer, hierarchical Transformer,\nmulti-task learning-based model, and a model with fact-based input\nrepresentation. Our experiments with popular benchmark datasets across multiple\ndomains on four different coherence assessment tasks demonstrate that our\nmodels achieve state-of-the-art results outperforming existing models by a good\nmargin.", "published": "2021-09-05 22:27:17", "link": "http://arxiv.org/abs/2109.02176v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowing False Negatives: An Adversarial Training Method for Distantly\n  Supervised Relation Extraction", "abstract": "Distantly supervised relation extraction (RE) automatically aligns\nunstructured text with relation instances in a knowledge base (KB). Due to the\nincompleteness of current KBs, sentences implying certain relations may be\nannotated as N/A instances, which causes the so-called false negative (FN)\nproblem. Current RE methods usually overlook this problem, inducing improper\nbiases in both training and testing procedures. To address this issue, we\npropose a two-stage approach. First, it finds out possible FN samples by\nheuristically leveraging the memory mechanism of deep neural networks. Then, it\naligns those unlabeled data with the training data into a unified feature space\nby adversarial training to assign pseudo labels and further utilize the\ninformation contained in them. Experiments on two wildly-used benchmark\ndatasets demonstrate the effectiveness of our approach.", "published": "2021-09-05 15:11:24", "link": "http://arxiv.org/abs/2109.02099v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Teaching Autoregressive Language Models Complex Tasks By Demonstration", "abstract": "This paper demonstrates that by fine-tuning an autoregressive language model\n(GPT-Neo) on appropriately structured step-by-step demonstrations, it is\npossible to teach it to execute a mathematical task that has previously proved\ndifficult for Transformers - longhand modulo operations - with a relatively\nsmall number of examples. Specifically, we fine-tune GPT-Neo to solve the\nnumbers__div_remainder task from the DeepMind Mathematics Dataset; Saxton et\nal. (arXiv:1904.01557) reported below 40% accuracy on this task with 2 million\ntraining examples. We show that after fine-tuning on 200 appropriately\nstructured demonstrations of solving long division problems and reporting the\nremainders, the smallest available GPT-Neo model achieves over 80% accuracy.\nThis is achieved by constructing an appropriate dataset for fine-tuning, with\nno changes to the learning algorithm. These results suggest that fine-tuning\nautoregressive language models on small sets of well-crafted demonstrations may\nbe a useful paradigm for enabling individuals without training in machine\nlearning to coax such models to perform some kinds of complex multi-step tasks.", "published": "2021-09-05 15:25:28", "link": "http://arxiv.org/abs/2109.02102v3", "categories": ["cs.CL", "cs.AI", "I.2.0; I.2.6"], "primary_category": "cs.CL"}
{"title": "Data Efficient Masked Language Modeling for Vision and Language", "abstract": "Masked language modeling (MLM) is one of the key sub-tasks in vision-language\npretraining. In the cross-modal setting, tokens in the sentence are masked at\nrandom, and the model predicts the masked tokens given the image and the text.\nIn this paper, we observe several key disadvantages of MLM in this setting.\nFirst, as captions tend to be short, in a third of the sentences no token is\nsampled. Second, the majority of masked tokens are stop-words and punctuation,\nleading to under-utilization of the image. We investigate a range of\nalternative masking strategies specific to the cross-modal setting that address\nthese shortcomings, aiming for better fusion of text and image in the learned\nrepresentation. When pre-training the LXMERT model, our alternative masking\nstrategies consistently improve over the original masking strategy on three\ndownstream tasks, especially in low resource settings. Further, our\npre-training approach substantially outperforms the baseline model on a\nprompt-based probing task designed to elicit image objects. These results and\nour analysis indicate that our method allows for better utilization of the\ntraining data.", "published": "2021-09-05 11:27:53", "link": "http://arxiv.org/abs/2109.02040v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Attention Branch Network with Combined Loss Function for\n  Automatic Speaker Verification Spoof Detection", "abstract": "Many endeavors have sought to develop countermeasure techniques as\nenhancements on Automatic Speaker Verification (ASV) systems, in order to make\nthem more robust against spoof attacks. As evidenced by the latest ASVspoof\n2019 countermeasure challenge, models currently deployed for the task of ASV\nare, at their best, devoid of suitable degrees of generalization to unseen\nattacks. Upon further investigation of the proposed methods, it appears that a\nbroader three-tiered view of the proposed systems. comprised of the classifier,\nfeature extraction phase, and model loss function, may to some extent lessen\nthe problem. Accordingly, the present study proposes the Efficient Attention\nBranch Network (EABN) modular architecture with a combined loss function to\naddress the generalization problem...", "published": "2021-09-05 12:10:16", "link": "http://arxiv.org/abs/2109.02051v2", "categories": ["cs.SD", "cs.CL", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The SpeakIn System for VoxCeleb Speaker Recognition Challange 2021", "abstract": "This report describes our submission to the track 1 and track 2 of the\nVoxCeleb Speaker Recognition Challenge 2021 (VoxSRC 2021). Both track 1 and\ntrack 2 share the same speaker verification system, which only uses\nVoxCeleb2-dev as our training set. This report explores several parts,\nincluding data augmentation, network structures, domain-based large margin\nfine-tuning, and back-end refinement. Our system is a fusion of 9 models and\nachieves first place in these two tracks of VoxSRC 2021. The minDCF of our\nsubmission is 0.1034, and the corresponding EER is 1.8460%.", "published": "2021-09-05 04:07:05", "link": "http://arxiv.org/abs/2109.01989v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The DKU-DukeECE-Lenovo System for the Diarization Task of the 2021\n  VoxCeleb Speaker Recognition Challenge", "abstract": "This report describes the submission of the DKU-DukeECE-Lenovo team to the\nVoxCeleb Speaker Recognition Challenge (VoxSRC) 2021 track 4. Our system\nincluding a voice activity detection (VAD) model, a speaker embedding model,\ntwo clustering-based speaker diarization systems with different similarity\nmeasurements, two different overlapped speech detection (OSD) models, and a\ntarget-speaker voice activity detection (TS-VAD) model. Our final submission,\nconsisting of 5 independent systems, achieves a DER of 5.07% on the challenge\ntest set.", "published": "2021-09-05 05:45:52", "link": "http://arxiv.org/abs/2109.02002v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "The ByteDance Speaker Diarization System for the VoxCeleb Speaker\n  Recognition Challenge 2021", "abstract": "This paper describes the ByteDance speaker diarization system for the fourth\ntrack of the VoxCeleb Speaker Recognition Challenge 2021 (VoxSRC-21). The\nVoxSRC-21 provides both the dev set and test set of VoxConverse for use in\nvalidation and a standalone test set for evaluation. We first collect the\nduration and signal-to-noise ratio (SNR) of all audio and find that the\ndistribution of the VoxConverse's test set and the VoxSRC-21's test set is more\ncloser. Our system consists of voice active detection (VAD), speaker embedding\nextraction, spectral clustering followed by a re-clustering step based on\nagglomerative hierarchical clustering (AHC) and overlapped speech detection and\nhandling. Finally, we integrate systems with different time scales using\nDOVER-Lap. Our best system achieves 5.15\\% of the diarization error rate (DER)\non evaluation set, ranking the second at the diarization track of the\nchallenge.", "published": "2021-09-05 11:55:34", "link": "http://arxiv.org/abs/2109.02047v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Two-stage Complex Network using Cycle-consistent Generative\n  Adversarial Networks for Speech Enhancement", "abstract": "Cycle-consistent generative adversarial networks (CycleGAN) have shown their\npromising performance for speech enhancement (SE), while one intractable\nshortcoming of these CycleGAN-based SE systems is that the noise components\npropagate throughout the cycle and cannot be completely eliminated.\nAdditionally, conventional CycleGAN-based SE systems only estimate the spectral\nmagnitude, while the phase is unaltered. Motivated by the multi-stage learning\nconcept, we propose a novel two-stage denoising system that combines a\nCycleGAN-based magnitude enhancing network and a subsequent complex spectral\nrefining network in this paper. Specifically, in the first stage, a\nCycleGAN-based model is responsible for only estimating magnitude, which is\nsubsequently coupled with the original noisy phase to obtain a coarsely\nenhanced complex spectrum. After that, the second stage is applied to further\nsuppress the residual noise components and estimate the clean phase by a\ncomplex spectral mapping network, which is a pure complex-valued network\ncomposed of complex 2D convolution/deconvolution and complex temporal-frequency\nattention blocks. Experimental results on two public datasets demonstrate that\nthe proposed approach consistently surpasses previous one-stage CycleGANs and\nother state-of-the-art SE systems in terms of various evaluation metrics,\nespecially in background noise suppression.", "published": "2021-09-05 07:09:10", "link": "http://arxiv.org/abs/2109.02011v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Phonexia VoxCeleb Speaker Recognition Challenge 2021 System\n  Description", "abstract": "We describe the Phonexia submission for the VoxCeleb Speaker Recognition\nChallenge 2021 (VoxSRC-21) in the unsupervised speaker verification track. Our\nsolution was very similar to IDLab's winning submission for VoxSRC-20. An\nembedding extractor was bootstrapped using momentum contrastive learning, with\ninput augmentations as the only source of supervision. This was followed by\nseveral iterations of clustering to assign pseudo-speaker labels that were then\nused for supervised embedding extractor training. Finally, a score fusion was\ndone, by averaging the zt-normalized cosine scores of five different embedding\nextractors. We briefly also describe unsuccessful solutions involving i-vectors\ninstead of DNN embeddings and PLDA instead of cosine scoring.", "published": "2021-09-05 12:10:26", "link": "http://arxiv.org/abs/2109.02052v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Timbre Transfer with Variational Auto Encoding and Cycle-Consistent\n  Adversarial Networks", "abstract": "This research project investigates the application of deep learning to timbre\ntransfer, where the timbre of a source audio can be converted to the timbre of\na target audio with minimal loss in quality. The adopted approach combines\nVariational Autoencoders with Generative Adversarial Networks to construct\nmeaningful representations of the source audio and produce realistic\ngenerations of the target audio and is applied to the Flickr 8k Audio dataset\nfor transferring the vocal timbre between speakers and the URMP dataset for\ntransferring the musical timbre between instruments. Furthermore, variations of\nthe adopted approach are trained, and generalised performance is compared using\nthe metrics SSIM (Structural Similarity Index) and FAD (Frech\\'et Audio\nDistance). It was found that a many-to-many approach supersedes a one-to-one\napproach in terms of reconstructive capabilities, and that the adoption of a\nbasic over a bottleneck residual block design is more suitable for enriching\ncontent information about a latent space. It was also found that the decision\non whether cyclic loss takes on a variational autoencoder or vanilla\nautoencoder approach does not have a significant impact on reconstructive and\nadversarial translation aspects of the model.", "published": "2021-09-05 15:06:53", "link": "http://arxiv.org/abs/2109.02096v2", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
