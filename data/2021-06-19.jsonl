{"title": "Enhancing Question Generation with Commonsense Knowledge", "abstract": "Question generation (QG) is to generate natural and grammatical questions\nthat can be answered by a specific answer for a given context. Previous\nsequence-to-sequence models suffer from a problem that asking high-quality\nquestions requires commonsense knowledge as backgrounds, which in most cases\ncan not be learned directly from training data, resulting in unsatisfactory\nquestions deprived of knowledge. In this paper, we propose a multi-task\nlearning framework to introduce commonsense knowledge into question generation\nprocess. We first retrieve relevant commonsense knowledge triples from mature\ndatabases and select triples with the conversion information from source\ncontext to question. Based on these informative knowledge triples, we design\ntwo auxiliary tasks to incorporate commonsense knowledge into the main QG\nmodel, where one task is Concept Relation Classification and the other is Tail\nConcept Generation. Experimental results on SQuAD show that our proposed\nmethods are able to noticeably improve the QG performance on both automatic and\nhuman evaluation metrics, demonstrating that incorporating external commonsense\nknowledge with multi-task learning can help the model generate human-like and\nhigh-quality questions.", "published": "2021-06-19 08:58:13", "link": "http://arxiv.org/abs/2106.10454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Condense-then-Select Strategy for Text Summarization", "abstract": "Select-then-compress is a popular hybrid, framework for text summarization\ndue to its high efficiency. This framework first selects salient sentences and\nthen independently condenses each of the selected sentences into a concise\nversion. However, compressing sentences separately ignores the context\ninformation of the document, and is therefore prone to delete salient\ninformation. To address this limitation, we propose a novel\ncondense-then-select framework for text summarization. Our framework first\nconcurrently condenses each document sentence. Original document sentences and\ntheir compressed versions then become the candidates for extraction. Finally,\nan extractor utilizes the context information of the document to select\ncandidates and assembles them into a summary. If salient information is deleted\nduring condensing, the extractor can select an original sentence to retain the\ninformation. Thus, our framework helps to avoid the loss of salient\ninformation, while preserving the high efficiency of sentence-level\ncompression. Experiment results on the CNN/DailyMail, DUC-2002, and Pubmed\ndatasets demonstrate that our framework outperforms the select-then-compress\nframework and other strong baselines.", "published": "2021-06-19 10:33:10", "link": "http://arxiv.org/abs/2106.10468v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transformers for Headline Selection for Russian News Clusters", "abstract": "In this paper, we explore various multilingual and Russian pre-trained\ntransformer-based models for the Dialogue Evaluation 2021 shared task on\nheadline selection. Our experiments show that the combined approach is superior\nto individual multilingual and monolingual models. We present an analysis of a\nnumber of ways to obtain sentence embeddings and learn a ranking model on top\nof them. We achieve the result of 87.28% and 86.60% accuracy for the public and\nprivate test sets respectively.", "published": "2021-06-19 12:34:00", "link": "http://arxiv.org/abs/2106.10487v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Compositional Generalization in Classification Tasks via\n  Structure Annotations", "abstract": "Compositional generalization is the ability to generalize systematically to a\nnew data distribution by combining known components. Although humans seem to\nhave a great ability to generalize compositionally, state-of-the-art neural\nmodels struggle to do so. In this work, we study compositional generalization\nin classification tasks and present two main contributions. First, we study\nways to convert a natural language sequence-to-sequence dataset to a\nclassification dataset that also requires compositional generalization. Second,\nwe show that providing structural hints (specifically, providing parse trees\nand entity links as attention masks for a Transformer model) helps\ncompositional generalization.", "published": "2021-06-19 06:07:27", "link": "http://arxiv.org/abs/2106.10434v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Hybrid approach to detecting symptoms of depression in social media\n  entries", "abstract": "Sentiment and lexical analyses are widely used to detect depression or\nanxiety disorders. It has been documented that there are significant\ndifferences in the language used by a person with emotional disorders in\ncomparison to a healthy individual. Still, the effectiveness of these lexical\napproaches could be improved further because the current analysis focuses on\nwhat the social media entries are about, and not how they are written. In this\nstudy, we focus on aspects in which these short texts are similar to each\nother, and how they were created. We present an innovative approach to the\ndepression screening problem by applying Collgram analysis, which is a known\neffective method of obtaining linguistic information from texts. We compare\nthese results with sentiment analysis based on the BERT architecture. Finally,\nwe create a hybrid model achieving a diagnostic accuracy of 71%.", "published": "2021-06-19 12:28:30", "link": "http://arxiv.org/abs/2106.10485v1", "categories": ["cs.CL", "cs.LG", "68T07, 68T50", "I.2.7; J.4"], "primary_category": "cs.CL"}
{"title": "JointGT: Graph-Text Joint Representation Learning for Text Generation\n  from Knowledge Graphs", "abstract": "Existing pre-trained models for knowledge-graph-to-text (KG-to-text)\ngeneration simply fine-tune text-to-text pre-trained models such as BART or T5\non KG-to-text datasets, which largely ignore the graph structure during\nencoding and lack elaborate pre-training tasks to explicitly model graph-text\nalignments. To tackle these problems, we propose a graph-text joint\nrepresentation learning model called JointGT. During encoding, we devise a\nstructure-aware semantic aggregation module which is plugged into each\nTransformer layer to preserve the graph structure. Furthermore, we propose\nthree new pre-training tasks to explicitly enhance the graph-text alignment\nincluding respective text / graph reconstruction, and graph-text alignment in\nthe embedding space via Optimal Transport. Experiments show that JointGT\nobtains new state-of-the-art performance on various KG-to-text datasets.", "published": "2021-06-19 14:10:10", "link": "http://arxiv.org/abs/2106.10502v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TweeNLP: A Twitter Exploration Portal for Natural Language Processing", "abstract": "We present TweeNLP, a one-stop portal that organizes Twitter's natural\nlanguage processing (NLP) data and builds a visualization and exploration\nplatform. It curates 19,395 tweets (as of April 2021) from various NLP\nconferences and general NLP discussions. It supports multiple features such as\nTweetExplorer to explore tweets by topics, visualize insights from Twitter\nactivity throughout the organization cycle of conferences, discover popular\nresearch papers and researchers. It also builds a timeline of conference and\nworkshop submission deadlines. We envision TweeNLP to function as a collective\nmemory unit for the NLP community by integrating the tweets pertaining to\nresearch papers with the NLPExplorer scientific literature search engine. The\ncurrent system is hosted at http://nlpexplorer.org/twitter/CFP .", "published": "2021-06-19 15:11:22", "link": "http://arxiv.org/abs/2106.10512v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Improving robustness of one-shot voice conversion with deep\n  discriminative speaker encoder", "abstract": "One-shot voice conversion has received significant attention since only one\nutterance from source speaker and target speaker respectively is required.\nMoreover, source speaker and target speaker do not need to be seen during\ntraining. However, available one-shot voice conversion approaches are not\nstable for unseen speakers as the speaker embedding extracted from one\nutterance of an unseen speaker is not reliable. In this paper, we propose a\ndeep discriminative speaker encoder to extract speaker embedding from one\nutterance more effectively. Specifically, the speaker encoder first integrates\nresidual network and squeeze-and-excitation network to extract discriminative\nspeaker information in frame level by modeling frame-wise and channel-wise\ninterdependence in features. Then attention mechanism is introduced to further\nemphasize speaker related information via assigning different weights to frame\nlevel speaker information. Finally a statistic pooling layer is used to\naggregate weighted frame level speaker information to form utterance level\nspeaker embedding. The experimental results demonstrate that our proposed\nspeaker encoder can improve the robustness of one-shot voice conversion for\nunseen speakers and outperforms baseline systems in terms of speech quality and\nspeaker similarity.", "published": "2021-06-19 03:09:11", "link": "http://arxiv.org/abs/2106.10406v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "GPLA-12: An Acoustic Signal Dataset of Gas Pipeline Leakage", "abstract": "In this paper, we introduce a new acoustic leakage dataset of gas pipelines,\ncalled as GPLA-12, which has 12 categories over 684 training/testing acoustic\nsignals. Unlike massive image and voice datasets, there have relatively few\nacoustic signal datasets, especially for engineering fault detection. In order\nto enhance the development of fault diagnosis, we collect acoustic leakage\nsignals on the basis of an intact gas pipe system with external artificial\nleakages, and then preprocess the collected data with structured tailoring\nwhich are turned into GPLA-12. GPLA-12 dedicates to serve as a feature learning\ndataset for time-series tasks and classifications. To further understand the\ndataset, we train both shadow and deep learning algorithms to observe the\nperformance. The dataset as well as the pretrained models have been released at\nboth www.daip.club and github.com/Deep-AI-Application-DAIP", "published": "2021-06-19 04:37:39", "link": "http://arxiv.org/abs/2106.10277v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Advances in Speech Vocoding for Text-to-Speech with Continuous\n  Parameters", "abstract": "Vocoders received renewed attention as main components in statistical\nparametric text-to-speech (TTS) synthesis and speech transformation systems.\nEven though there are vocoding techniques give almost accepted synthesized\nspeech, their high computational complexity and irregular structures are still\nconsidered challenging concerns, which yield a variety of voice quality\ndegradation. Therefore, this paper presents new techniques in a continuous\nvocoder, that is all features are continuous and presents a flexible speech\nsynthesis system. First, a new continuous noise masking based on the phase\ndistortion is proposed to eliminate the perceptual impact of the residual noise\nand letting an accurate reconstruction of noise characteristics. Second, we\naddressed the need of neural sequence to sequence modeling approach for the\ntask of TTS based on recurrent networks. Bidirectional long short-term memory\n(LSTM) and gated recurrent unit (GRU) are studied and applied to model\ncontinuous parameters for more natural-sounding like a human. The evaluation\nresults proved that the proposed model achieves the state-of-the-art\nperformance of the speech synthesis compared with the other traditional\nmethods.", "published": "2021-06-19 12:05:01", "link": "http://arxiv.org/abs/2106.10481v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
