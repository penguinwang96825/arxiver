{"title": "Circular Directional Flow Decomposition of Networks", "abstract": "We introduce the Circular Directional Flow Decomposition (CDFD), a new\nframework for analyzing circularity in weighted directed networks. CDFD\nseparates flow into two components: a circular (divergence-free) component and\nan acyclic component that carries all nett directional flow. This yields a\nnormalized circularity index between 0 (fully acyclic) and 1 (for networks\nformed solely by the superposition of cycles), with the complement measuring\ndirectionality. This index captures the proportion of flow involved in cycles,\nand admits a range of interpretations - such as system closure, feedback,\nweighted strong connectivity, structural redundancy, or inefficiency. Although\nthe decomposition is generally non-unique, we show that the set of all\ndecompositions forms a well-structured geometric space with favourable\ntopological properties. Within this space, we highlight two benchmark\ndecompositions aligned with distinct analytical goals: the maximum circularity\nsolution, which minimizes nett flow, and the Balanced Flow Forwarding (BFF)\nsolution, a unique, locally computable decomposition that distributes circular\nflow across all feasible cycles in proportion to the original network\nstructure. We demonstrate the interpretive value and computational tractability\nof both decompositions on synthetic and empirical networks. They outperform\nexisting circularity metrics in detecting meaningful structural variation. The\ndecomposition also enables structural analysis - such as mapping the\ndistribution of cyclic flow - and supports practical applications that require\nexplicit flow allocation or routing, including multilateral netting and\nefficient transport.", "published": "2025-06-14 15:39:05", "link": "http://arxiv.org/abs/2506.12546v1", "categories": ["physics.soc-ph", "cs.DM", "cs.SI", "math.CO", "q-fin.RM", "05C20, 05C38, 05C21, 90B10, 90C27, 94C15"], "primary_category": "physics.soc-ph"}
{"title": "Stereotype graph: A mathematical framework of category stereotypes via graph theory", "abstract": "In social psychology and cognitive science, there has been much interest in\nstudying category stereotypes. However, we still lack a consensual mathematical\ndefinition or framework, which is necessary for us to hold a deeper\nunderstanding of stereotypes in human cognition. In this paper, we use graph\ntheory to portray category stereotypes in human cognition, based on pairs of\nlabels having special relations. By using methods and conclusions in graph\ntheory (including algebraic graph theory and vertex coloring) as well as strict\nratiocination, we give criteria for judging the stability of a given\nstereotype, some of which are computationally practicable. We also define the\nchromatic stability index (CSI) to measure the stability of a stereotype in\nhuman cognition, as well as to provide its precise range. From the perspective\nof stereotype graphs and CSI, we may explain why stereotypes can easily stay in\nhuman cognition.", "published": "2025-06-14 15:07:00", "link": "http://arxiv.org/abs/2506.12533v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "Layered tree-independence number and clique-based separators", "abstract": "Motivated by a question of Galby, Munaro, and Yang (SoCG 2023) asking whether\nevery graph class of bounded layered tree-independence number admits\nclique-based separators of sublinear weight, we investigate relations between\nlayered tree-independence number, weight of clique-based separators, clique\ncover degeneracy and independence degeneracy. In particular, we provide a\nnumber of results bounding these parameters on geometric intersection graphs.\nFor example, we show that the layered tree-independence number is\n$\\mathcal{O}(g)$ for $g$-map graphs, $\\mathcal{O}(\\frac{r}{\\tanh r})$ for\nhyperbolic uniform disk graphs with radius $r$, and $\\mathcal{O}(1)$ for\nspherical uniform disk graphs with radius $r$. Our structural results have\nalgorithmic consequences. In particular, we obtain a number of subexponential\nor quasi-polynomial-time algorithms for weighted problems such as \\textsc{Max\nWeight Independent Set} and \\textsc{Min Weight Feedback Vertex Set} on several\ngeometric intersection graphs. Finally, we conjecture that every fractionally\ntree-independence-number-fragile graph class has bounded independence\ndegeneracy.", "published": "2025-06-14 09:50:44", "link": "http://arxiv.org/abs/2506.12424v1", "categories": ["math.CO", "cs.CG", "cs.DM", "05C10, 05C62, 05C75, 05C85"], "primary_category": "math.CO"}
{"title": "INTERPOS: Interaction Rhythm Guided Positional Morphing for Mobile App Recommender Systems", "abstract": "The mobile app market has expanded exponentially, offering millions of apps\nwith diverse functionalities, yet research in mobile app recommendation remains\nlimited. Traditional sequential recommender systems utilize the order of items\nin users' historical interactions to predict the next item for the users.\nPosition embeddings, well-established in transformer-based architectures for\nnatural language processing tasks, effectively distinguish token positions in\nsequences. In sequential recommendation systems, position embeddings can\ncapture the order of items in a user's historical interaction sequence.\nNevertheless, this ordering does not consider the time elapsed between two\ninteractions of the same user (e.g., 1 day, 1 week, 1 month), referred to as\n\"user rhythm\". In mobile app recommendation datasets, the time between\nconsecutive user interactions is notably longer compared to other domains like\nmovies, posing significant challenges for sequential recommender systems. To\naddress this phenomenon in the mobile app domain, we introduce INTERPOS, an\nInteraction Rhythm Guided Positional Morphing strategy for autoregressive\nmobile app recommender systems. INTERPOS incorporates rhythm-guided position\nembeddings, providing a more comprehensive representation that considers both\nthe sequential order of interactions and the temporal gaps between them. This\napproach enables a deep understanding of users' rhythms at a fine-grained\nlevel, capturing the intricacies of their interaction patterns over time. We\npropose three strategies to incorporate the morphed positional embeddings in\ntwo transformer-based sequential recommendation system architectures. Our\nextensive evaluations show that INTERPOS outperforms state-of-the-art models\nusing 7 mobile app recommendation datasets on NDCG@K and HIT@K metrics. The\nsource code of INTERPOS is available at https://github.com/dlgrad/INTERPOS.", "published": "2025-06-14 23:40:49", "link": "http://arxiv.org/abs/2506.12661v1", "categories": ["cs.IR", "cs.LG"], "primary_category": "cs.IR"}
{"title": "A Gradient Meta-Learning Joint Optimization for Beamforming and Antenna Position in Pinching-Antenna Systems", "abstract": "In this paper, we consider a novel optimization design for multi-waveguide\npinching-antenna systems, aiming to maximize the weighted sum rate (WSR) by\njointly optimizing beamforming coefficients and antenna position. To handle the\nformulated non-convex problem, a gradient-based meta-learning joint\noptimization (GML-JO) algorithm is proposed. Specifically, the original problem\nis initially decomposed into two sub-problems of beamforming optimization and\nantenna position optimization through equivalent substitution. Then, the convex\napproximation methods are used to deal with the nonconvex constraints of\nsub-problems, and two sub-neural networks are constructed to calculate the\nsub-problems separately. Different from alternating optimization (AO), where\ntwo sub-problems are solved alternately and the solutions are influenced by the\ninitial values, two sub-neural networks of proposed GML-JO with fixed channel\ncoefficients are considered as local sub-tasks and the computation results are\nused to calculate the loss function of joint optimization. Finally, the\nparameters of sub-networks are updated using the average loss function over\ndifferent sub-tasks and the solution that is robust to the initial value is\nobtained. Simulation results demonstrate that the proposed GML-JO algorithm\nachieves 5.6 bits/s/Hz WSR within 100 iterations, yielding a 32.7\\% performance\nenhancement over conventional AO with substantially reduced computational\ncomplexity. Moreover, the proposed GML-JO algorithm is robust to different\nchoices of initialization and yields better performance compared with the\nexisting optimization methods.", "published": "2025-06-14 17:35:27", "link": "http://arxiv.org/abs/2506.12583v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "DoTA-RAG: Dynamic of Thought Aggregation RAG", "abstract": "In this paper, we introduce DoTA-RAG (Dynamic-of-Thought Aggregation RAG), a\nretrieval-augmented generation system optimized for high-throughput,\nlarge-scale web knowledge indexes. Traditional RAG pipelines often suffer from\nhigh latency and limited accuracy over massive, diverse datasets. DoTA-RAG\naddresses these challenges with a three-stage pipeline: query rewriting,\ndynamic routing to specialized sub-indexes, and multi-stage retrieval and\nranking. We further enhance retrieval by evaluating and selecting a superior\nembedding model, re-embedding the large FineWeb-10BT corpus. Moreover, we\ncreate a diverse Q&A dataset of 500 questions generated via the DataMorgana\nsetup across a broad range of WebOrganizer topics and formats. DoTA-RAG\nimproves the answer correctness score from 0.752 (baseline, using LiveRAG\npre-built vector store) to 1.478 while maintaining low latency, and it achieves\na 0.929 correctness score on the Live Challenge Day. These results highlight\nDoTA-RAG's potential for practical deployment in domains requiring fast,\nreliable access to large and evolving knowledge sources.", "published": "2025-06-14 16:56:00", "link": "http://arxiv.org/abs/2506.12571v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "FlexRAG: A Flexible and Comprehensive Framework for Retrieval-Augmented Generation", "abstract": "Retrieval-Augmented Generation (RAG) plays a pivotal role in modern large\nlanguage model applications, with numerous existing frameworks offering a wide\nrange of functionalities to facilitate the development of RAG systems. However,\nwe have identified several persistent challenges in these frameworks, including\ndifficulties in algorithm reproduction and sharing, lack of new techniques, and\nhigh system overhead. To address these limitations, we introduce\n\\textbf{FlexRAG}, an open-source framework specifically designed for research\nand prototyping. FlexRAG supports text-based, multimodal, and network-based\nRAG, providing comprehensive lifecycle support alongside efficient asynchronous\nprocessing and persistent caching capabilities. By offering a robust and\nflexible solution, FlexRAG enables researchers to rapidly develop, deploy, and\nshare advanced RAG systems. Our toolkit and resources are available at\n\\href{https://github.com/ictnlp/FlexRAG}{https://github.com/ictnlp/FlexRAG}.", "published": "2025-06-14 13:16:31", "link": "http://arxiv.org/abs/2506.12494v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Optimal and Suboptimal Decoders under Finite-Alphabet Interference: A Mismatched Decoding Perspective", "abstract": "Interference widely exists in communication systems and is often not\noptimally treated at the receivers due to limited knowledge and/or\ncomputational burden. Evolutions of receivers have been proposed to balance\ncomplexity and spectral efficiency, for example, for 6G, while commonly used\nperformance metrics, such as capacity and mutual information, fail to capture\nthe suboptimal treatment of interference, leading to potentially inaccurate\nperformance evaluations. Mismatched decoding is an information-theoretic tool\nfor analyzing communications with suboptimal decoders. In this work, we use\nmismatched decoding to analyze communications with decoders that treat\ninterference suboptimally, aiming at more accurate performance metrics.\nSpecifically, we consider a finite-alphabet input Gaussian channel under\ninterference, representative of modern systems, where the decoder can be\nmatched (optimal) or mismatched (suboptimal) to the channel. The matched\ncapacity is derived using Mutual Information (MI), while a lower bound on the\nmismatched capacity under various decoding metrics is derived using the\nGeneralized Mutual Information (GMI). We show that the decoding metric in the\nproposed channel model is closely related to the behavior of the demodulator in\nBit-Interleaved Coded Modulation (BICM) systems. Simulations illustrate that\nGMI/MI accurately predicts the throughput performance of BICM-type systems.\nFinally, we extend the channel model and the GMI to multiple antenna cases,\nwith an example of multi-user multiple-input-single-output (MU-MISO) precoder\noptimization problem considering GMI under different decoding strategies. In\nshort, this work discovers new insights about the impact of interference,\nproposes novel receivers, and introduces a new design and performance\nevaluation framework that more accurately captures the effect of interference.", "published": "2025-06-14 22:12:09", "link": "http://arxiv.org/abs/2506.12646v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "On the cross-correlation properties of large-size families of Costas arrays", "abstract": "Costas arrays have been an interesting combinatorial object for decades\nbecause of their optimal aperiodic auto-correlation properties. Meanwhile, it\nis interesting to find families of Costas arrays or extended arrays with small\nmaximal cross-correlation values, since for applications in multi-user systems,\nthe cross-interferences between different signals should also be small. The\nobjective of this paper is to study several large-size families of Costas\narrays or extended arrays, and their values of maximal cross-correlation are\npartially bounded for some cases of horizontal shifts $u$ and vertical shifts\n$v$. Given a prime $p \\geq 5$, in particular, a large-size family of Costas\narrays over $\\{1, \\ldots, p-1\\}$ is investigated, including both the\nexponential Welch Costas arrays and logarithmic Welch Costas arrays. An upper\nbound on the maximal cross-correlation of this family for arbitrary $u$ and $v$\nis given. We also show that the maximal cross-correlation of the family of\npower permutations over $\\{1, \\ldots, p-1\\}$ for $u = 0$ and $v \\neq 0$ is\nbounded by $\\frac{1}{2}+\\sqrt{p-1}$. Furthermore, we give the first nontrivial\nupper bound of $(p-1)/t$ on the maximal cross-correlation of the larger family\nincluding both exponential Welch Costas arrays and power permutations over\n$\\{1, \\ldots, p-1\\}$ for arbitrary $u$ and $v=0$, where $t$ is the smallest\nprime divisor of $(p-1)/2$.", "published": "2025-06-14 16:02:43", "link": "http://arxiv.org/abs/2506.12559v1", "categories": ["cs.IT", "math.CO", "math.IT"], "primary_category": "cs.IT"}
{"title": "Perfect Secrecy in the Wild: A Characterization", "abstract": "Alice wishes to reveal the state $X$ to Bob, if he knows some other\ninformation $Y$ also known to her. If Bob does not, she wishes to reveal\nnothing about $X$ at all. When can Alice accomplish this? We provide a simple\nnecessary and sufficient condition on the joint distribution of $X$ and $Y$.\nShannon's result on the perfect secrecy of the one-time pad follows as a\nspecial case.", "published": "2025-06-14 09:19:26", "link": "http://arxiv.org/abs/2506.12416v1", "categories": ["econ.TH", "cs.GT", "cs.IT", "math.IT"], "primary_category": "econ.TH"}
{"title": "Stacked Intelligent Metasurfaces for Multi-Modal Semantic Communications", "abstract": "Semantic communication (SemCom) powered by generative artificial intelligence\nenables highly efficient and reliable information transmission. However, it\nstill necessitates the transmission of substantial amounts of data when dealing\nwith complex scene information. In contrast, the stacked intelligent\nmetasurface (SIM), leveraging wave-domain computing, provides a cost-effective\nsolution for directly imaging complex scenes. Building on this concept, we\npropose an innovative SIM-aided multi-modal SemCom system. Specifically, an SIM\nis positioned in front of the transmit antenna for transmitting visual semantic\ninformation of complex scenes via imaging on the uniform planar array at the\nreceiver. Furthermore, the simple scene description that contains textual\nsemantic information is transmitted via amplitude-phase modulation over\nelectromagnetic waves. To simultaneously transmit multi-modal information, we\noptimize the amplitude and phase of meta-atoms in the SIM using a customized\ngradient descent algorithm. The optimization aims to gradually minimize the\nmean squared error between the normalized energy distribution on the receiver\narray and the desired pattern corresponding to the visual semantic information.\nBy combining the textual and visual semantic information, a conditional\ngenerative adversarial network is used to recover the complex scene accurately.\nExtensive numerical results verify the effectiveness of the proposed\nmulti-modal SemCom system in reducing bandwidth overhead as well as the\ncapability of the SIM for imaging the complex scene.", "published": "2025-06-14 06:16:39", "link": "http://arxiv.org/abs/2506.12368v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Trust-MARL: Trust-Based Multi-Agent Reinforcement Learning Framework for Cooperative On-Ramp Merging Control in Heterogeneous Traffic Flow", "abstract": "Intelligent transportation systems require connected and automated vehicles\n(CAVs) to conduct safe and efficient cooperation with human-driven vehicles\n(HVs) in complex real-world traffic environments. However, the inherent\nunpredictability of human behaviour, especially at bottlenecks such as highway\non-ramp merging areas, often disrupts traffic flow and compromises system\nperformance. To address the challenge of cooperative on-ramp merging in\nheterogeneous traffic environments, this study proposes a trust-based\nmulti-agent reinforcement learning (Trust-MARL) framework. At the macro level,\nTrust-MARL enhances global traffic efficiency by leveraging inter-agent trust\nto improve bottleneck throughput and mitigate traffic shockwave through\nemergent group-level coordination. At the micro level, a dynamic trust\nmechanism is designed to enable CAVs to adjust their cooperative strategies in\nresponse to real-time behaviors and historical interactions with both HVs and\nother CAVs. Furthermore, a trust-triggered game-theoretic decision-making\nmodule is integrated to guide each CAV in adapting its cooperation factor and\nexecuting context-aware lane-changing decisions under safety, comfort, and\nefficiency constraints. An extensive set of ablation studies and comparative\nexperiments validates the effectiveness of the proposed Trust-MARL approach,\ndemonstrating significant improvements in safety, efficiency, comfort, and\nadaptability across varying CAV penetration rates and traffic densities.", "published": "2025-06-14 18:35:10", "link": "http://arxiv.org/abs/2506.12600v1", "categories": ["cs.MA", "cs.AI", "cs.ET", "cs.GT", "cs.RO"], "primary_category": "cs.MA"}
{"title": "A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications", "abstract": "This survey examines the rapidly evolving field of Deep Research systems --\nAI-powered applications that automate complex research workflows through the\nintegration of large language models, advanced information retrieval, and\nautonomous reasoning capabilities. We analyze more than 80 commercial and\nnon-commercial implementations that have emerged since 2023, including\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\nnumerous open-source alternatives. Through comprehensive examination, we\npropose a novel hierarchical taxonomy that categorizes systems according to\nfour fundamental technical dimensions: foundation models and reasoning engines,\ntool utilization and environmental interaction, task planning and execution\ncontrol, and knowledge synthesis and output generation. We explore the\narchitectural patterns, implementation approaches, and domain-specific\nadaptations that characterize these systems across academic, scientific,\nbusiness, and educational applications. Our analysis reveals both the\nsignificant capabilities of current implementations and the technical and\nethical challenges they present regarding information accuracy, privacy,\nintellectual property, and accessibility. The survey concludes by identifying\npromising research directions in advanced reasoning architectures, multimodal\nintegration, domain specialization, human-AI collaboration, and ecosystem\nstandardization that will likely shape the future evolution of this\ntransformative technology. By providing a comprehensive framework for\nunderstanding Deep Research systems, this survey contributes to both the\ntheoretical understanding of AI-augmented knowledge work and the practical\ndevelopment of more capable, responsible, and accessible research technologies.\nThe paper resources can be viewed at\nhttps://github.com/scienceaix/deepresearch.", "published": "2025-06-14 18:19:05", "link": "http://arxiv.org/abs/2506.12594v1", "categories": ["cs.AI", "cs.MA", "I.2.8"], "primary_category": "cs.AI"}
{"title": "IndoorWorld: Integrating Physical Task Solving and Social Simulation in A Heterogeneous Multi-Agent Environment", "abstract": "Virtual environments are essential to AI agent research. Existing\nenvironments for LLM agent research typically focus on either physical task\nsolving or social simulation, with the former oversimplifying agent\nindividuality and social dynamics, and the latter lacking physical grounding of\nsocial behaviors. We introduce IndoorWorld, a heterogeneous multi-agent\nenvironment that tightly integrates physical and social dynamics. By\nintroducing novel challenges for LLM-driven agents in orchestrating social\ndynamics to influence physical environments and anchoring social interactions\nwithin world states, IndoorWorld opens up possibilities of LLM-based building\noccupant simulation for architectural design. We demonstrate the potential with\na series of experiments within an office setting to examine the impact of\nmulti-agent collaboration, resource competition, and spatial layout on agent\nbehavior.", "published": "2025-06-14 03:44:09", "link": "http://arxiv.org/abs/2506.12331v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Deep Fictitious Play-Based Potential Differential Games for Learning Human-Like Interaction at Unsignalized Intersections", "abstract": "Modeling vehicle interactions at unsignalized intersections is a challenging\ntask due to the complexity of the underlying game-theoretic processes. Although\nprior studies have attempted to capture interactive driving behaviors, most\napproaches relied solely on game-theoretic formulations and did not leverage\nnaturalistic driving datasets. In this study, we learn human-like interactive\ndriving policies at unsignalized intersections using Deep Fictitious Play.\nSpecifically, we first model vehicle interactions as a Differential Game, which\nis then reformulated as a Potential Differential Game. The weights in the cost\nfunction are learned from the dataset and capture diverse driving styles. We\nalso demonstrate that our framework provides a theoretical guarantee of\nconvergence to a Nash equilibrium. To the best of our knowledge, this is the\nfirst study to train interactive driving policies using Deep Fictitious Play.\nWe validate the effectiveness of our Deep Fictitious Play-Based Potential\nDifferential Game (DFP-PDG) framework using the INTERACTION dataset. The\nresults demonstrate that the proposed framework achieves satisfactory\nperformance in learning human-like driving policies. The learned individual\nweights effectively capture variations in driver aggressiveness and\npreferences. Furthermore, the ablation study highlights the importance of each\ncomponent within our model.", "published": "2025-06-14 00:08:33", "link": "http://arxiv.org/abs/2506.12283v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "The convergence proof of the sixth-order compact 9-point FDM for the 2D transport problem", "abstract": "It is widely acknowledged that the convergence proof of the error in the\n$l_{\\infty}$ norm of the high-order finite difference method (FDM) and finite\nelement method (FEM) in 2D is challenging. In this paper, we derive the\nsixth-order compact 9-point FDM with the explicit stencil for the 2D transport\nproblem with the constant coefficient and the Dirichlet boundary condition in a\nunit square. The proposed sixth-order FDM forms an M-matrix for the any mesh\nsize $h$ employing the uniform Cartesian mesh. The explicit formula of our FDM\nalso enables us to construct the comparison function with the explicit\nexpression to rigorously prove the sixth-order convergence rate of the maximum\npointwise error by the discrete maximum principle. Most importantly, we\ndemonstrate that the sixth-order convergence proof is valid for any mesh size\n$h$. The numerical results are consistent with sixth-order accuracy in the\n$l_{\\infty}$ norm. Our theoretical convergence proof is clear and the proposed\nsixth-order FDM is straightforward to be implemented, facilitating the\nreproduction of our numerical results.", "published": "2025-06-14 15:46:21", "link": "http://arxiv.org/abs/2506.12549v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An optimal two-side Robin-Robin domain decomposition method for H(div)-elliptic problem", "abstract": "In this paper, we develop a new two-side Robin-Robin domain decomposition\nmethod for H(div)-elliptic problem. Numerical results show that the convergence\nrate of the new algorithm only depends on $H/h$, where $H$ is diameter of\nsubdomains and $h$ is the mesh size. Besides, an algebraic system of Robin\nboundary conditions is derived from the iterative method. We solve it by MINRES\nand get asymptotically stable iteration numbers as well.", "published": "2025-06-14 12:51:53", "link": "http://arxiv.org/abs/2506.12485v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Superconvergent quadriatic finite element on uniform tetrahedral meshes", "abstract": "By a direct computation, we show that the $P_2$ interpolation of a $P_3$\nfunction is also a local $H^1$-projection on uniform tetrahedral meshes, i.e.,\nthe difference is $H^1$-orthogonal to the $P_2$ Lagrange basis function on the\nsupport patch of tetrahedra of the basis function. Consequently, we show the\n$H^1$ and $L^2$ rconvergence of the $P_2$ Lagrange finite element on uniform\ntetrahedral meshes. Using the standard 20-points Lagrange $P_3$ interpolation,\nwhere the 20 nodes are exactly some $P_2$ global basis nodes, we lift the\nsuperconvergent $P_2$ finite element solution to a quasi-optimal $P_3$ solution\non each cube. Numerical results confirm the theory.", "published": "2025-06-14 08:56:27", "link": "http://arxiv.org/abs/2506.12407v1", "categories": ["math.NA", "cs.NA", "65N15, 65N30"], "primary_category": "math.NA"}
{"title": "A new Lagrange multiplier approach for constructing structure preserving schemes, III. Bound preserving and energy dissipating", "abstract": "In the third part of this series, we continue to explore the idea of the\nLagrange multiplier introduced in the first part [2020, Comput. Methods Appl.\nMech. Engr., 391, 114585] and refined in the second part [2022, SIAM J. Numer.\nAnal., 60, 970-998] to further develop efficient and accurate numerical schemes\nthat preserve the maximum bound principle (MBP) and energy dissipation for\nsolving gradient flows. The proposed framework allows us to begin with any\nconventional scheme as a predictor step which is followed by two consecutive\ncorrection steps written in the form of the Karush-Kuhn-Tucker conditions for\nstructure preserving. The preservation of both energy dissipation and MBP and\nthe solvability of the general resulting scheme are rigorously established. In\nsuch a framework, we implement an explicit and efficient scheme by employing\nthe Runge-Kutta exponential time differencing scheme as the predictor step, and\ngive its convergence analysis. Extensive numerical experiments are provided to\nvalidate the effectiveness of our approach.", "published": "2025-06-14 08:38:57", "link": "http://arxiv.org/abs/2506.12402v1", "categories": ["math.NA", "cs.NA", "65M12, 35K20, 35K35, 35K55, 65Z05"], "primary_category": "math.NA"}
{"title": "$\u03be$-Based adaptive phase field model for quasi-static anti-plane fracture", "abstract": "The $\\xi$-based spatially adaptive three-field variable phase-field model for\nquasi-static anti-plane crack propagation is introduced. A dynamically\noptimized regularization length is integrated to improve computational\nefficiency and accuracy in numerical approximations. A local adaptive mesh\nrefinement strategy is developed, which maintains an optimal balance between\nmesh resolution and the accurate depiction of fractures using the \\textsf{AT1}\ndiffuse interface model. The total energy functional is comprised of three\ncomponents: strain energy, surface energy, and a third term reliant on the\ndamage zone's regularization length. The governing partial differential\nequations for mechanics and phase-field variables, derived from Euler-Lagrange,\nare discretized via the finite-element method. Two parameters functioning as\npenalty variables are incorporated; both are asymptotically estimated from the\ngradient of the phase-field variable. By these estimated parameters, mesh\nadaptivity is enhanced, ensuring the convergence of the numerical solution.\nStandard phase-field methods are shown by numerical results to be surpassed by\nthe adaptive model; an accurate representation of fractures is provided, and\ncomputational costs are significantly lowered. By employing the proposed\nspatially adaptive approach, a vastly larger regularization length parameter is\nachieved compared to other methods throughout the entire computation.", "published": "2025-06-14 05:42:52", "link": "http://arxiv.org/abs/2506.12360v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Convergence Analysis of a Dual-Wind Discontinuous Galerkin Method for an Elliptic Optimal Control Problem with Control Constraints", "abstract": "This paper investigates a symmetric dual-wind discontinuous Galerkin (DWDG)\nmethod for solving an elliptic optimal control problem with control\nconstraints. The governing constraint is an elliptic partial differential\nequation (PDE), which is discretized using the symmetric DWDG approach. We\nderive error estimates in the energy norm for both the state and the adjoint\nstate, as well as in the $L^2$ norm of the control variable. Numerical\nexperiments are provided to demonstrate the robustness and effectiveness of the\ndeveloped scheme.", "published": "2025-06-14 03:42:33", "link": "http://arxiv.org/abs/2506.12330v1", "categories": ["math.NA", "cs.NA", "65K15, 65N30"], "primary_category": "math.NA"}
{"title": "Small Volatility Approximation and Multi-Factor HJM Models", "abstract": "Here we demonstrate how we can use Small Volatility Approximation in\ncalibration of Multi-Factor HJM model with deterministic correlations, factor\nvolatilities and mean reversals. It is noticed that quality of this calibration\nis very good and it does not depend on number of factors.", "published": "2025-06-14 17:37:25", "link": "http://arxiv.org/abs/2506.12584v1", "categories": ["q-fin.PR", "q-fin.CP"], "primary_category": "q-fin.PR"}
{"title": "A New Approach for the Continuous Time Kyle-Back Strategic Insider Equilibrium Problem", "abstract": "This paper considers a continuous time Kyle-Back model which is a game\nproblem between an insider and a market marker. The existing literature\ntypically focuses on the existence of equilibrium by using the PDE approach,\nwhich requires certain Markovian structure and the equilibrium is in the bridge\nform. We shall provide a new approach which is used widely for stochastic\ncontrols and stochastic differential games. We characterize all equilibria\nthrough a coupled system of forward backward SDEs, where the forward one is the\nconditional law of the inside information and the backward one is the insider's\noptimal value. In particular, when the time duration is small, we show that the\nFBSDE is wellposed and thus the game has a unique equilibrium. This is the\nfirst uniqueness result in the literature, without restricting the equilibria\nto certain special structure. Moreover, this unique equilibrium may not be\nMarkovian, indicating that the PDE approach cannot work in this case. We next\nstudy the set value of the game, which roughly speaking is the set of insider's\nvalues over all equilibria and thus is by nature unique. We show that, although\nthe bridge type of equilibria in the literature does not satisfy the required\nintegrability for our equilibria, its truncation serves as a desired\napproximate equilibrium and its value belongs to our set value. Finally, we\ncharacterize our set value through a level set of certain standard HJB\nequation.", "published": "2025-06-14 00:06:16", "link": "http://arxiv.org/abs/2506.12281v1", "categories": ["math.OC", "q-fin.TR", "91A27, 91G15, 60H10"], "primary_category": "math.OC"}
{"title": "Beyond Sin-Squared Error: Linear-Time Entrywise Uncertainty Quantification for Streaming PCA", "abstract": "We propose a novel statistical inference framework for streaming principal\ncomponent analysis (PCA) using Oja's algorithm, enabling the construction of\nconfidence intervals for individual entries of the estimated eigenvector. Most\nexisting works on streaming PCA focus on providing sharp sin-squared error\nguarantees. Recently, there has been some interest in uncertainty\nquantification for the sin-squared error. However, uncertainty quantification\nor sharp error guarantees for entries of the estimated eigenvector in the\nstreaming setting remains largely unexplored. We derive a sharp Bernstein-type\nconcentration bound for elements of the estimated vector matching the optimal\nerror rate up to logarithmic factors. We also establish a Central Limit Theorem\nfor a suitably centered and scaled subset of the entries. To efficiently\nestimate the coordinate-wise variance, we introduce a provably consistent\nsubsampling algorithm that leverages the median-of-means approach, empirically\nachieving similar accuracy to multiplier bootstrap methods while being\nsignificantly more computationally efficient. Numerical experiments demonstrate\nits effectiveness in providing reliable uncertainty estimates with a fraction\nof the computational cost of existing methods.", "published": "2025-06-14 22:50:54", "link": "http://arxiv.org/abs/2506.12655v1", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "primary_category": "math.ST"}
{"title": "Existence of Adversarial Examples for Random Convolutional Networks via Isoperimetric Inequalities on $\\mathbb{so}(d)$", "abstract": "We show that adversarial examples exist for various random convolutional\nnetworks, and furthermore, that this is a relatively simple consequence of the\nisoperimetric inequality on the special orthogonal group $\\mathbb{so}(d)$. This\nextends and simplifies a recent line of work which shows similar results for\nrandom fully connected networks.", "published": "2025-06-14 19:48:44", "link": "http://arxiv.org/abs/2506.12613v1", "categories": ["cs.LG", "math.PR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "RAW-Explainer: Post-hoc Explanations of Graph Neural Networks on Knowledge Graphs", "abstract": "Graph neural networks have demonstrated state-of-the-art performance on\nknowledge graph tasks such as link prediction. However, interpreting GNN\npredictions remains a challenging open problem. While many GNN explainability\nmethods have been proposed for node or graph-level tasks, approaches for\ngenerating explanations for link predictions in heterogeneous settings are\nlimited. In this paper, we propose RAW-Explainer, a novel framework designed to\ngenerate connected, concise, and thus interpretable subgraph explanations for\nlink prediction. Our method leverages the heterogeneous information in\nknowledge graphs to identify connected subgraphs that serve as patterns of\nfactual explanation via a random walk objective. Unlike existing methods\ntailored to knowledge graphs, our approach employs a neural network to\nparameterize the explanation generation process, which significantly speeds up\nthe production of collective explanations. Furthermore, RAW-Explainer is\ndesigned to overcome the distribution shift issue when evaluating the quality\nof an explanatory subgraph which is orders of magnitude smaller than the full\ngraph, by proposing a robust evaluator that generalizes to the subgraph\ndistribution. Extensive quantitative results on real-world knowledge graph\ndatasets demonstrate that our approach strikes a balance between explanation\nquality and computational efficiency.", "published": "2025-06-14 15:55:17", "link": "http://arxiv.org/abs/2506.12558v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Language Models Enable Data-Augmented Synthesis Planning for Inorganic Materials", "abstract": "Inorganic synthesis planning currently relies primarily on heuristic\napproaches or machine-learning models trained on limited datasets, which\nconstrains its generality. We demonstrate that language models, without\ntask-specific fine-tuning, can recall synthesis conditions. Off-the-shelf\nmodels, such as GPT-4.1, Gemini 2.0 Flash and Llama 4 Maverick, achieve a Top-1\nprecursor-prediction accuracy of up to 53.8 % and a Top-5 performance of 66.1 %\non a held-out set of 1,000 reactions. They also predict calcination and\nsintering temperatures with mean absolute errors below 126 {\\deg}C, matching\nspecialized regression methods. Ensembling these language models further\nenhances predictive accuracy and reduces inference cost per prediction by up to\n70 %. We subsequently employ language models to generate 28,548 synthetic\nreaction recipes, which we combine with literature-mined examples to pretrain a\ntransformer-based model, SyntMTE. After fine-tuning on the combined dataset,\nSyntMTE reduces mean-absolute error in sintering temperature prediction to 73\n{\\deg}C and in calcination temperature to 98 {\\deg}C. This strategy improves\nmodels by up to 8.7 % compared with baselines trained exclusively on\nexperimental data. Finally, in a case study on Li7La3Zr2O12 solid-state\nelectrolytes, we demonstrate that SyntMTE reproduces the experimentally\nobserved dopant-dependent sintering trends. Our hybrid workflow enables\nscalable, data-efficient inorganic synthesis planning.", "published": "2025-06-14 15:55:05", "link": "http://arxiv.org/abs/2506.12557v1", "categories": ["cond-mat.mtrl-sci", "cs.LG", "stat.ML"], "primary_category": "cond-mat.mtrl-sci"}
{"title": "Beyond Laplace and Gaussian: Exploring the Generalized Gaussian Mechanism for Private Machine Learning", "abstract": "Differential privacy (DP) is obtained by randomizing a data analysis\nalgorithm, which necessarily introduces a tradeoff between its utility and\nprivacy. Many DP mechanisms are built upon one of two underlying tools: Laplace\nand Gaussian additive noise mechanisms. We expand the search space of\nalgorithms by investigating the Generalized Gaussian mechanism, which samples\nthe additive noise term $x$ with probability proportional to $e^{-\\frac{| x\n|}{\\sigma}^{\\beta} }$ for some $\\beta \\geq 1$. The Laplace and Gaussian\nmechanisms are special cases of GG for $\\beta=1$ and $\\beta=2$, respectively.\n  In this work, we prove that all members of the GG family satisfy differential\nprivacy, and provide an extension of an existing numerical accountant (the PRV\naccountant) for these mechanisms. We show that privacy accounting for the GG\nMechanism and its variants is dimension independent, which substantially\nimproves computational costs of privacy accounting.\n  We apply the GG mechanism to two canonical tools for private machine\nlearning, PATE and DP-SGD; we show empirically that $\\beta$ has a weak\nrelationship with test-accuracy, and that generally $\\beta=2$ (Gaussian) is\nnearly optimal. This provides justification for the widespread adoption of the\nGaussian mechanism in DP learning, and can be interpreted as a negative result,\nthat optimizing over $\\beta$ does not lead to meaningful improvements in\nperformance.", "published": "2025-06-14 15:49:25", "link": "http://arxiv.org/abs/2506.12553v1", "categories": ["cs.LG", "cs.CR", "stat.ML"], "primary_category": "cs.LG"}
{"title": "PLD: A Choice-Theoretic List-Wise Knowledge Distillation", "abstract": "Knowledge distillation is a model compression technique in which a compact\n\"student\" network is trained to replicate the predictive behavior of a larger\n\"teacher\" network. In logit-based knowledge distillation it has become the de\nfacto approach to augment cross-entropy with a distillation term. Typically\nthis term is either a KL divergence-matching marginal probabilities or a\ncorrelation-based loss capturing intra- and inter-class relationships but in\nevery case it sits as an add-on to cross-entropy with its own weight that must\nbe carefully tuned. In this paper we adopt a choice-theoretic perspective and\nrecast knowledge distillation under the Plackett-Luce model by interpreting\nteacher logits as \"worth\" scores. We introduce Plackett-Luce Distillation\n(PLD), a weighted list-wise ranking loss in which the teacher model transfers\nknowledge of its full ranking of classes, weighting each ranked choice by its\nown confidence. PLD directly optimizes a single teacher-optimal ranking of the\ntrue label first, followed by the remaining classes in descending teacher\nconfidence, yielding a convex, translation-invariant surrogate that subsumes\nweighted cross-entropy. Empirically on standard image classification\nbenchmarks, PLD improves Top-1 accuracy by an average of +0.42% over DIST\n(arXiv:2205.10536) and +1.04% over KD (arXiv:1503.02531) in homogeneous\nsettings and by +0.48% and +1.09% over DIST and KD, respectively, in\nheterogeneous settings.", "published": "2025-06-14 15:31:54", "link": "http://arxiv.org/abs/2506.12542v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Similarity as Reward Alignment: Robust and Versatile Preference-based Reinforcement Learning", "abstract": "Preference-based Reinforcement Learning (PbRL) entails a variety of\napproaches for aligning models with human intent to alleviate the burden of\nreward engineering. However, most previous PbRL work has not investigated the\nrobustness to labeler errors, inevitable with labelers who are non-experts or\noperate under time constraints. Additionally, PbRL algorithms often target very\nspecific settings (e.g. pairwise ranked preferences or purely offline\nlearning). We introduce Similarity as Reward Alignment (SARA), a simple\ncontrastive framework that is both resilient to noisy labels and adaptable to\ndiverse feedback formats and training paradigms. SARA learns a latent\nrepresentation of preferred samples and computes rewards as similarities to the\nlearned latent. We demonstrate strong performance compared to baselines on\ncontinuous control offline RL benchmarks. We further demonstrate SARA's\nversatility in applications such as trajectory filtering for downstream tasks,\ncross-task preference transfer, and reward shaping in online learning.", "published": "2025-06-14 15:01:59", "link": "http://arxiv.org/abs/2506.12529v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Note on Follow-the-Perturbed-Leader in Combinatorial Semi-Bandit Problems", "abstract": "This paper studies the optimality and complexity of\nFollow-the-Perturbed-Leader (FTPL) policy in size-invariant combinatorial\nsemi-bandit problems. Recently, Honda et al. (2023) and Lee et al. (2024)\nshowed that FTPL achieves Best-of-Both-Worlds (BOBW) optimality in standard\nmulti-armed bandit problems with Fr\\'{e}chet-type distributions. However, the\noptimality of FTPL in combinatorial semi-bandit problems remains unclear. In\nthis paper, we consider the regret bound of FTPL with geometric resampling (GR)\nin size-invariant semi-bandit setting, showing that FTPL respectively achieves\n$O\\left(\\sqrt{m^2 d^\\frac{1}{\\alpha}T}+\\sqrt{mdT}\\right)$ regret with\nFr\\'{e}chet distributions, and the best possible regret bound of\n$O\\left(\\sqrt{mdT}\\right)$ with Pareto distributions in adversarial setting.\nFurthermore, we extend the conditional geometric resampling (CGR) to\nsize-invariant semi-bandit setting, which reduces the computational complexity\nfrom $O(d^2)$ of original GR to $O\\left(md\\left(\\log(d/m)+1\\right)\\right)$\nwithout sacrificing the regret performance of FTPL.", "published": "2025-06-14 13:06:30", "link": "http://arxiv.org/abs/2506.12490v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Delving into Instance-Dependent Label Noise in Graph Data: A Comprehensive Study and Benchmark", "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in\nnode classification tasks but struggle with label noise in real-world data.\nExisting studies on graph learning with label noise commonly rely on\nclass-dependent label noise, overlooking the complexities of instance-dependent\nnoise and falling short of capturing real-world corruption patterns. We\nintroduce BeGIN (Benchmarking for Graphs with Instance-dependent Noise), a new\nbenchmark that provides realistic graph datasets with various noise types and\ncomprehensively evaluates noise-handling strategies across GNN architectures,\nnoisy label detection, and noise-robust learning. To simulate\ninstance-dependent corruptions, BeGIN introduces algorithmic methods and\nLLM-based simulations. Our experiments reveal the challenges of\ninstance-dependent noise, particularly LLM-based corruption, and underscore the\nimportance of node-specific parameterization to enhance GNN robustness. By\ncomprehensively evaluating noise-handling strategies, BeGIN provides insights\ninto their effectiveness, efficiency, and key performance factors. We expect\nthat BeGIN will serve as a valuable resource for advancing research on label\nnoise in graphs and fostering the development of robust GNN training methods.\nThe code is available at https://github.com/kimsu55/BeGIN.", "published": "2025-06-14 12:14:15", "link": "http://arxiv.org/abs/2506.12468v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Merlin: Multi-View Representation Learning for Robust Multivariate Time Series Forecasting with Unfixed Missing Rates", "abstract": "Multivariate Time Series Forecasting (MTSF) involves predicting future values\nof multiple interrelated time series. Recently, deep learning-based MTSF models\nhave gained significant attention for their promising ability to mine semantics\n(global and local information) within MTS data. However, these models are\npervasively susceptible to missing values caused by malfunctioning data\ncollectors. These missing values not only disrupt the semantics of MTS, but\ntheir distribution also changes over time. Nevertheless, existing models lack\nrobustness to such issues, leading to suboptimal forecasting performance. To\nthis end, in this paper, we propose Multi-View Representation Learning\n(Merlin), which can help existing models achieve semantic alignment between\nincomplete observations with different missing rates and complete observations\nin MTS. Specifically, Merlin consists of two key modules: offline knowledge\ndistillation and multi-view contrastive learning. The former utilizes a teacher\nmodel to guide a student model in mining semantics from incomplete\nobservations, similar to those obtainable from complete observations. The\nlatter improves the student model's robustness by learning from\npositive/negative data pairs constructed from incomplete observations with\ndifferent missing rates, ensuring semantic alignment across different missing\nrates. Therefore, Merlin is capable of effectively enhancing the robustness of\nexisting models against unfixed missing rates while preserving forecasting\naccuracy. Experiments on four real-world datasets demonstrate the superiority\nof Merlin.", "published": "2025-06-14 11:55:18", "link": "http://arxiv.org/abs/2506.12459v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "A Transfer Learning Framework for Multilayer Networks via Model Averaging", "abstract": "Link prediction in multilayer networks is a key challenge in applications\nsuch as recommendation systems and protein-protein interaction prediction.\nWhile many techniques have been developed, most rely on assumptions about\nshared structures and require access to raw auxiliary data, limiting their\npracticality. To address these issues, we propose a novel transfer learning\nframework for multilayer networks using a bi-level model averaging method. A\n$K$-fold cross-validation criterion based on edges is used to automatically\nweight inter-layer and intra-layer candidate models. This enables the transfer\nof information from auxiliary layers while mitigating model uncertainty, even\nwithout prior knowledge of shared structures. Theoretically, we prove the\noptimality and weight convergence of our method under mild conditions.\nComputationally, our framework is efficient and privacy-preserving, as it\navoids raw data sharing and supports parallel processing across multiple\nservers. Simulations show our method outperforms others in predictive accuracy\nand robustness. We further demonstrate its practical value through two\nreal-world recommendation system applications.", "published": "2025-06-14 11:32:31", "link": "http://arxiv.org/abs/2506.12455v1", "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "stat.ML"}
{"title": "On the existence of consistent adversarial attacks in high-dimensional linear classification", "abstract": "What fundamentally distinguishes an adversarial attack from a\nmisclassification due to limited model expressivity or finite data? In this\nwork, we investigate this question in the setting of high-dimensional binary\nclassification, where statistical effects due to limited data availability play\na central role. We introduce a new error metric that precisely capture this\ndistinction, quantifying model vulnerability to consistent adversarial attacks\n-- perturbations that preserve the ground-truth labels. Our main technical\ncontribution is an exact and rigorous asymptotic characterization of these\nmetrics in both well-specified models and latent space models, revealing\ndifferent vulnerability patterns compared to standard robust error measures.\nThe theoretical results demonstrate that as models become more\noverparameterized, their vulnerability to label-preserving perturbations grows,\noffering theoretical insight into the mechanisms underlying model sensitivity\nto adversarial attacks.", "published": "2025-06-14 11:25:35", "link": "http://arxiv.org/abs/2506.12454v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.CR", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Interpretable Causal Representation Learning for Biological Data in the Pathway Space", "abstract": "Predicting the impact of genomic and drug perturbations in cellular function\nis crucial for understanding gene functions and drug effects, ultimately\nleading to improved therapies. To this end, Causal Representation Learning\n(CRL) constitutes one of the most promising approaches, as it aims to identify\nthe latent factors that causally govern biological systems, thus facilitating\nthe prediction of the effect of unseen perturbations. Yet, current CRL methods\nfail in reconciling their principled latent representations with known\nbiological processes, leading to models that are not interpretable. To address\nthis major issue, we present SENA-discrepancy-VAE, a model based on the\nrecently proposed CRL method discrepancy-VAE, that produces representations\nwhere each latent factor can be interpreted as the (linear) combination of the\nactivity of a (learned) set of biological processes. To this extent, we present\nan encoder, SENA-{\\delta}, that efficiently compute and map biological\nprocesses' activity levels to the latent causal factors. We show that\nSENA-discrepancy-VAE achieves predictive performances on unseen combinations of\ninterventions that are comparable with its original, non-interpretable\ncounterpart, while inferring causal latent factors that are biologically\nmeaningful.", "published": "2025-06-14 10:33:19", "link": "http://arxiv.org/abs/2506.12439v1", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Cross-Domain Conditional Diffusion Models for Time Series Imputation", "abstract": "Cross-domain time series imputation is an underexplored data-centric research\ntask that presents significant challenges, particularly when the target domain\nsuffers from high missing rates and domain shifts in temporal dynamics.\nExisting time series imputation approaches primarily focus on the single-domain\nsetting, which cannot effectively adapt to a new domain with domain shifts.\nMeanwhile, conventional domain adaptation techniques struggle with data\nincompleteness, as they typically assume the data from both source and target\ndomains are fully observed to enable adaptation. For the problem of\ncross-domain time series imputation, missing values introduce high uncertainty\nthat hinders distribution alignment, making existing adaptation strategies\nineffective. Specifically, our proposed solution tackles this problem from\nthree perspectives: (i) Data: We introduce a frequency-based time series\ninterpolation strategy that integrates shared spectral components from both\ndomains while retaining domain-specific temporal structures, constructing\ninformative priors for imputation. (ii) Model: We design a diffusion-based\nimputation model that effectively learns domain-shared representations and\ncaptures domain-specific temporal dependencies with dedicated denoising\nnetworks. (iii) Algorithm: We further propose a cross-domain consistency\nalignment strategy that selectively regularizes output-level domain\ndiscrepancies, enabling effective knowledge transfer while preserving\ndomain-specific characteristics. Extensive experiments on three real-world\ndatasets demonstrate the superiority of our proposed approach. Our code\nimplementation is available here.", "published": "2025-06-14 09:09:07", "link": "http://arxiv.org/abs/2506.12412v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "PROTOCOL: Partial Optimal Transport-enhanced Contrastive Learning for Imbalanced Multi-view Clustering", "abstract": "While contrastive multi-view clustering has achieved remarkable success, it\nimplicitly assumes balanced class distribution. However, real-world multi-view\ndata primarily exhibits class imbalance distribution. Consequently, existing\nmethods suffer performance degradation due to their inability to perceive and\nmodel such imbalance. To address this challenge, we present the first\nsystematic study of imbalanced multi-view clustering, focusing on two\nfundamental problems: i. perceiving class imbalance distribution, and ii.\nmitigating representation degradation of minority samples. We propose PROTOCOL,\na novel PaRtial Optimal TranspOrt-enhanced COntrastive Learning framework for\nimbalanced multi-view clustering. First, for class imbalance perception, we map\nmulti-view features into a consensus space and reformulate the imbalanced\nclustering as a partial optimal transport (POT) problem, augmented with\nprogressive mass constraints and weighted KL divergence for class\ndistributions. Second, we develop a POT-enhanced class-rebalanced contrastive\nlearning at both feature and class levels, incorporating logit adjustment and\nclass-sensitive learning to enhance minority sample representations. Extensive\nexperiments demonstrate that PROTOCOL significantly improves clustering\nperformance on imbalanced multi-view data, filling a critical research gap in\nthis field.", "published": "2025-06-14 08:58:14", "link": "http://arxiv.org/abs/2506.12408v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Revisiting Clustering of Neural Bandits: Selective Reinitialization for Mitigating Loss of Plasticity", "abstract": "Clustering of Bandits (CB) methods enhance sequential decision-making by\ngrouping bandits into clusters based on similarity and incorporating\ncluster-level contextual information, demonstrating effectiveness and\nadaptability in applications like personalized streaming recommendations.\nHowever, when extending CB algorithms to their neural version (commonly\nreferred to as Clustering of Neural Bandits, or CNB), they suffer from loss of\nplasticity, where neural network parameters become rigid and less adaptable\nover time, limiting their ability to adapt to non-stationary environments\n(e.g., dynamic user preferences in recommendation). To address this challenge,\nwe propose Selective Reinitialization (SeRe), a novel bandit learning framework\nthat dynamically preserves the adaptability of CNB algorithms in evolving\nenvironments. SeRe leverages a contribution utility metric to identify and\nselectively reset underutilized units, mitigating loss of plasticity while\nmaintaining stable knowledge retention. Furthermore, when combining SeRe with\nCNB algorithms, the adaptive change detection mechanism adjusts the\nreinitialization frequency according to the degree of non-stationarity,\nensuring effective adaptation without unnecessary resets. Theoretically, we\nprove that SeRe enables sublinear cumulative regret in piecewise-stationary\nenvironments, outperforming traditional CNB approaches in long-term\nperformances. Extensive experiments on six real-world recommendation datasets\ndemonstrate that SeRe-enhanced CNB algorithms can effectively mitigate the loss\nof plasticity with lower regrets, improving adaptability and robustness in\ndynamic settings.", "published": "2025-06-14 07:58:27", "link": "http://arxiv.org/abs/2506.12389v1", "categories": ["cs.LG", "cs.AI", "stat.ML", "I.2.m"], "primary_category": "cs.LG"}
{"title": "Scaling Probabilistic Circuits via Monarch Matrices", "abstract": "Probabilistic Circuits (PCs) are tractable representations of probability\ndistributions allowing for exact and efficient computation of likelihoods and\nmarginals. Recent advancements have improved the scalability of PCs either by\nleveraging their sparse properties or through the use of tensorized operations\nfor better hardware utilization. However, no existing method fully exploits\nboth aspects simultaneously. In this paper, we propose a novel sparse and\nstructured parameterization for the sum blocks in PCs. By replacing dense\nmatrices with sparse Monarch matrices, we significantly reduce the memory and\ncomputation costs, enabling unprecedented scaling of PCs. From a theory\nperspective, our construction arises naturally from circuit multiplication;\nfrom a practical perspective, compared to previous efforts on scaling up\ntractable probabilistic models, our approach not only achieves state-of-the-art\ngenerative modeling performance on challenging benchmarks like Text8, LM1B and\nImageNet, but also demonstrates superior scaling behavior, achieving the same\nperformance with substantially less compute as measured by the number of\nfloating-point operations (FLOPs) during training.", "published": "2025-06-14 07:39:15", "link": "http://arxiv.org/abs/2506.12383v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Path-specific effects for pulse-oximetry guided decisions in critical care", "abstract": "Identifying and measuring biases associated with sensitive attributes is a\ncrucial consideration in healthcare to prevent treatment disparities. One\nprominent issue is inaccurate pulse oximeter readings, which tend to\noverestimate oxygen saturation for dark-skinned patients and misrepresent\nsupplemental oxygen needs. Most existing research has revealed statistical\ndisparities linking device errors to patient outcomes in intensive care units\n(ICUs) without causal formalization. In contrast, this study causally\ninvestigates how racial discrepancies in oximetry measurements affect invasive\nventilation in ICU settings. We employ a causal inference-based approach using\npath-specific effects to isolate the impact of bias by race on clinical\ndecision-making. To estimate these effects, we leverage a doubly robust\nestimator, propose its self-normalized variant for improved sample efficiency,\nand provide novel finite-sample guarantees. Our methodology is validated on\nsemi-synthetic data and applied to two large real-world health datasets:\nMIMIC-IV and eICU. Contrary to prior work, our analysis reveals minimal impact\nof racial discrepancies on invasive ventilation rates. However, path-specific\neffects mediated by oxygen saturation disparity are more pronounced on\nventilation duration, and the severity differs by dataset. Our work provides a\nnovel and practical pipeline for investigating potential disparities in the ICU\nand, more crucially, highlights the necessity of causal methods to robustly\nassess fairness in decision-making.", "published": "2025-06-14 06:45:53", "link": "http://arxiv.org/abs/2506.12371v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Efficient Network Automatic Relevance Determination", "abstract": "We propose Network Automatic Relevance Determination (NARD), an extension of\nARD for linearly probabilistic models, to simultaneously model sparse\nrelationships between inputs $X \\in \\mathbb R^{d \\times N}$ and outputs $Y \\in\n\\mathbb R^{m \\times N}$, while capturing the correlation structure among the\n$Y$. NARD employs a matrix normal prior which contains a sparsity-inducing\nparameter to identify and discard irrelevant features, thereby promoting\nsparsity in the model. Algorithmically, it iteratively updates both the\nprecision matrix and the relationship between $Y$ and the refined inputs. To\nmitigate the computational inefficiencies of the $\\mathcal O(m^3 + d^3)$ cost\nper iteration, we introduce Sequential NARD, which evaluates features\nsequentially, and a Surrogate Function Method, leveraging an efficient\napproximation of the marginal likelihood and simplifying the calculation of\ndeterminant and inverse of an intermediate matrix. Combining the Sequential\nupdate with the Surrogate Function method further reduces computational costs.\nThe computational complexity per iteration for these three methods is reduced\nto $\\mathcal O(m^3+p^3)$, $\\mathcal O(m^3 + d^2)$, $\\mathcal O(m^3+p^2)$,\nrespectively, where $p \\ll d$ is the final number of features in the model. Our\nmethods demonstrate significant improvements in computational efficiency with\ncomparable performance on both synthetic and real-world datasets.", "published": "2025-06-14 05:20:25", "link": "http://arxiv.org/abs/2506.12352v1", "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Theoretical Tensions in RLHF: Reconciling Empirical Success with Inconsistencies in Social Choice Theory", "abstract": "Despite its empirical success, Reinforcement Learning from Human Feedback\n(RLHF) has been shown to violate almost all the fundamental axioms in social\nchoice theory -- such as majority consistency, pairwise majority consistency,\nand Condorcet consistency. This raises a foundational question: why does RLHF\nperform so well in practice if it fails these seemingly essential properties?\nIn this paper, we resolve this paradox by showing that under mild and\nempirically plausible assumptions on the preference profile, RLHF does satisfy\npairwise majority and Condorcet consistency. These assumptions are frequently\nsatisfied in real-world alignment tasks, offering a theoretical explanation for\nRLHF's strong practical performance. Furthermore, we show that a slight\nmodification to the reward modeling objective can ensure pairwise majority or\nCondorcet consistency even under general preference profiles, thereby improving\nthe alignment process. Finally, we go beyond classical axioms in economic and\nsocial choice theory and introduce new alignment criteria -- preference\nmatching, preference equivalence, and group preference matching -- that better\nreflect the goal of learning distributions over responses. We show that while\nRLHF satisfies the first two properties, it fails to satisfy the third. We\nconclude by discussing how future alignment methods may be designed to satisfy\nall three.", "published": "2025-06-14 05:14:49", "link": "http://arxiv.org/abs/2506.12350v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Conditional Average Treatment Effect Estimation Under Hidden Confounders", "abstract": "One of the major challenges in estimating conditional potential outcomes and\nconditional average treatment effects (CATE) is the presence of hidden\nconfounders. Since testing for hidden confounders cannot be accomplished only\nwith observational data, conditional unconfoundedness is commonly assumed in\nthe literature of CATE estimation. Nevertheless, under this assumption, CATE\nestimation can be significantly biased due to the effects of unobserved\nconfounders. In this work, we consider the case where in addition to a\npotentially large observational dataset, a small dataset from a randomized\ncontrolled trial (RCT) is available. Notably, we make no assumptions on the\nexistence of any covariate information for the RCT dataset, we only require the\noutcomes to be observed. We propose a CATE estimation method based on a\npseudo-confounder generator and a CATE model that aligns the learned potential\noutcomes from the observational data with those observed from the RCT. Our\nmethod is applicable to many practical scenarios of interest, particularly\nthose where privacy is a concern (e.g., medical applications). Extensive\nnumerical experiments are provided demonstrating the effectiveness of our\napproach for both synthetic and real-world datasets.", "published": "2025-06-14 01:43:07", "link": "http://arxiv.org/abs/2506.12304v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SPIRE: Conditional Personalization for Federated Diffusion Generative Models", "abstract": "Recent advances in diffusion models have revolutionized generative AI, but\ntheir sheer size makes on device personalization, and thus effective federated\nlearning (FL), infeasible. We propose Shared Backbone Personal Identity\nRepresentation Embeddings (SPIRE), a framework that casts per client diffusion\nbased generation as conditional generation in FL. SPIRE factorizes the network\ninto (i) a high capacity global backbone that learns a population level score\nfunction and (ii) lightweight, learnable client embeddings that encode local\ndata statistics. This separation enables parameter efficient finetuning that\ntouches $\\leq 0.01\\%$ of weights. We provide the first theoretical bridge\nbetween conditional diffusion training and maximum likelihood estimation in\nGaussian mixture models. For a two component mixture we prove that gradient\ndescent on the DDPM with respect to mixing weights loss recovers the optimal\nmixing weights and enjoys dimension free error bounds. Our analysis also hints\nat how client embeddings act as biases that steer a shared score network toward\npersonalized distributions. Empirically, SPIRE matches or surpasses strong\nbaselines during collaborative pretraining, and vastly outperforms them when\nadapting to unseen clients, reducing Kernel Inception Distance while updating\nonly hundreds of parameters. SPIRE further mitigates catastrophic forgetting\nand remains robust across finetuning learning rate and epoch choices.", "published": "2025-06-14 01:40:31", "link": "http://arxiv.org/abs/2506.12303v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "GrokAlign: Geometric Characterisation and Acceleration of Grokking", "abstract": "A key challenge for the machine learning community is to understand and\naccelerate the training dynamics of deep networks that lead to delayed\ngeneralisation and emergent robustness to input perturbations, also known as\ngrokking. Prior work has associated phenomena like delayed generalisation with\nthe transition of a deep network from a linear to a feature learning regime,\nand emergent robustness with changes to the network's functional geometry, in\nparticular the arrangement of the so-called linear regions in deep networks\nemploying continuous piecewise affine nonlinearities. Here, we explain how\ngrokking is realised in the Jacobian of a deep network and demonstrate that\naligning a network's Jacobians with the training data (in the sense of cosine\nsimilarity) ensures grokking under a low-rank Jacobian assumption. Our results\nprovide a strong theoretical motivation for the use of Jacobian regularisation\nin optimizing deep networks -- a method we introduce as GrokAlign -- which we\nshow empirically to induce grokking much sooner than more conventional\nregularizers like weight decay. Moreover, we introduce centroid alignment as a\ntractable and interpretable simplification of Jacobian alignment that\neffectively identifies and tracks the stages of deep network training dynamics.\nAccompanying\n\\href{https://thomaswalker1.github.io/blog/grokalign.html}{webpage} and\n\\href{https://github.com/ThomasWalker1/grokalign}{code}.", "published": "2025-06-14 00:16:11", "link": "http://arxiv.org/abs/2506.12284v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "ANIRA: An Architecture for Neural Network Inference in Real-Time Audio Applications", "abstract": "Numerous tools for neural network inference are currently available, yet many\ndo not meet the requirements of real-time audio applications. In response, we\nintroduce anira, an efficient cross-platform library. To ensure compatibility\nwith a broad range of neural network architectures and frameworks, anira\nsupports ONNX Runtime, LibTorch, and TensorFlow Lite as backends. Each\ninference engine exhibits real-time violations, which anira mitigates by\ndecoupling the inference from the audio callback to a static thread pool. The\nlibrary incorporates built-in latency management and extensive benchmarking\ncapabilities, both crucial to ensure a continuous signal flow. Three different\nneural network architectures for audio effect emulation are then subjected to\nbenchmarking across various configurations. Statistical modeling is employed to\nidentify the influence of various factors on performance. The findings indicate\nthat for stateless models, ONNX Runtime exhibits the lowest runtimes. For\nstateful models, LibTorch demonstrates the fastest performance. Our results\nalso indicate that for certain model-engine combinations, the initial\ninferences take longer, particularly when these inferences exhibit a higher\nincidence of real-time violations.", "published": "2025-06-14 23:55:58", "link": "http://arxiv.org/abs/2506.12665v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Towards Neural Audio Codec Source Parsing", "abstract": "A new class of audio deepfakes-codecfakes (CFs)-has recently caught\nattention, synthesized by Audio Language Models that leverage neural audio\ncodecs (NACs) in the backend. In response, the community has introduced\ndedicated benchmarks and tailored detection strategies. As the field advances,\nefforts have moved beyond binary detection toward source attribution, including\nopen-set attribution, which aims to identify the NAC responsible for generation\nand flag novel, unseen ones during inference. This shift toward source\nattribution improves forensic interpretability and accountability. However,\nopen-set attribution remains fundamentally limited: while it can detect that a\nNAC is unfamiliar, it cannot characterize or identify individual unseen codecs.\nIt treats such inputs as generic ``unknowns'', lacking insight into their\ninternal configuration. This leads to major shortcomings: limited\ngeneralization to new NACs and inability to resolve fine-grained variations\nwithin NAC families. To address these gaps, we propose Neural Audio Codec\nSource Parsing (NACSP) - a paradigm shift that reframes source attribution for\nCFs as structured regression over generative NAC parameters such as quantizers,\nbandwidth, and sampling rate. We formulate NACSP as a multi-task regression\ntask for predicting these NAC parameters and establish the first comprehensive\nbenchmark using various state-of-the-art speech pre-trained models (PTMs). To\nthis end, we propose HYDRA, a novel framework that leverages hyperbolic\ngeometry to disentangle complex latent properties from PTM representations. By\nemploying task-specific attention over multiple curvature-aware hyperbolic\nsubspaces, HYDRA enables superior multi-task generalization. Our extensive\nexperiments show HYDRA achieves top results on benchmark CFs datasets compared\nto baselines operating in Euclidean space.", "published": "2025-06-14 21:00:39", "link": "http://arxiv.org/abs/2506.12627v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Video-Guided Text-to-Music Generation Using Public Domain Movie Collections", "abstract": "Despite recent advancements in music generation systems, their application in\nfilm production remains limited, as they struggle to capture the nuances of\nreal-world filmmaking, where filmmakers consider multiple factors-such as\nvisual content, dialogue, and emotional tone-when selecting or composing music\nfor a scene. This limitation primarily stems from the absence of comprehensive\ndatasets that integrate these elements. To address this gap, we introduce Open\nScreen Sound Library (OSSL), a dataset consisting of movie clips from public\ndomain films, totaling approximately 36.5 hours, paired with high-quality\nsoundtracks and human-annotated mood information. To demonstrate the\neffectiveness of our dataset in improving the performance of pre-trained models\non film music generation tasks, we introduce a new video adapter that enhances\nan autoregressive transformer-based text-to-music model by adding video-based\nconditioning. Our experimental results demonstrate that our proposed approach\neffectively enhances MusicGen-Medium in terms of both objective measures of\ndistributional and paired fidelity, and subjective compatibility in mood and\ngenre. The dataset and code are available at\nhttps://havenpersona.github.io/ossl-v1.", "published": "2025-06-14 16:58:42", "link": "http://arxiv.org/abs/2506.12573v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "StreamMel: Real-Time Zero-shot Text-to-Speech via Interleaved Continuous Autoregressive Modeling", "abstract": "Recent advances in zero-shot text-to-speech (TTS) synthesis have achieved\nhigh-quality speech generation for unseen speakers, but most systems remain\nunsuitable for real-time applications because of their offline design. Current\nstreaming TTS paradigms often rely on multi-stage pipelines and discrete\nrepresentations, leading to increased computational cost and suboptimal system\nperformance. In this work, we propose StreamMel, a pioneering single-stage\nstreaming TTS framework that models continuous mel-spectrograms. By\ninterleaving text tokens with acoustic frames, StreamMel enables low-latency,\nautoregressive synthesis while preserving high speaker similarity and\nnaturalness. Experiments on LibriSpeech demonstrate that StreamMel outperforms\nexisting streaming TTS baselines in both quality and latency. It even achieves\nperformance comparable to offline systems while supporting efficient real-time\ngeneration, showcasing broad prospects for integration with real-time speech\nlarge language models. Audio samples are available at:\nhttps://aka.ms/StreamMel.", "published": "2025-06-14 16:53:39", "link": "http://arxiv.org/abs/2506.12570v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Speech-Language Models with Decoupled Tokenizers and Multi-Token Prediction", "abstract": "Speech-language models (SLMs) offer a promising path toward unifying speech\nand text understanding and generation. However, challenges remain in achieving\neffective cross-modal alignment and high-quality speech generation. In this\nwork, we systematically investigate the impact of key components (i.e., speech\ntokenizers, speech heads, and speaker modeling) on the performance of\nLLM-centric SLMs. We compare coupled, semi-decoupled, and fully decoupled\nspeech tokenizers under a fair SLM framework and find that decoupled\ntokenization significantly improves alignment and synthesis quality. To address\nthe information density mismatch between speech and text, we introduce\nmulti-token prediction (MTP) into SLMs, enabling each hidden state to decode\nmultiple speech tokens. This leads to up to 12$\\times$ faster decoding and a\nsubstantial drop in word error rate (from 6.07 to 3.01). Furthermore, we\npropose a speaker-aware generation paradigm and introduce RoleTriviaQA, a\nlarge-scale role-playing knowledge QA benchmark with diverse speaker\nidentities. Experiments demonstrate that our methods enhance both knowledge\nunderstanding and speaker consistency.", "published": "2025-06-14 15:26:31", "link": "http://arxiv.org/abs/2506.12537v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Mitigating Non-Target Speaker Bias in Guided Speaker Embedding", "abstract": "Obtaining high-quality speaker embeddings in multi-speaker conditions is\ncrucial for many applications. A recently proposed guided speaker embedding\nframework, which utilizes speech activities of target and non-target speakers\nas clues, drastically improved embeddings under severe overlap with small\ndegradation in low-overlap cases. However, since extreme overlaps are rare in\nnatural conversations, this degradation cannot be overlooked. This paper first\nreveals that the degradation is caused by the global-statistics-based modules,\nwidely used in speaker embedding extractors, being overly sensitive to\nintervals containing only non-target speakers. As a countermeasure, we propose\nan extension of such modules that exploit the target speaker activity clues, to\ncompute statistics from intervals where the target is active. The proposed\nmethod improves speaker verification performance in both low and high overlap\nratios, and diarization performance on multiple datasets.", "published": "2025-06-14 13:31:35", "link": "http://arxiv.org/abs/2506.12500v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Exploring Audio Cues for Enhanced Test-Time Video Model Adaptation", "abstract": "Test-time adaptation (TTA) aims to boost the generalization capability of a\ntrained model by conducting self-/unsupervised learning during the testing\nphase. While most existing TTA methods for video primarily utilize visual\nsupervisory signals, they often overlook the potential contribution of inherent\naudio data. To address this gap, we propose a novel approach that incorporates\naudio information into video TTA. Our method capitalizes on the rich semantic\ncontent of audio to generate audio-assisted pseudo-labels, a new concept in the\ncontext of video TTA. Specifically, we propose an audio-to-video label mapping\nmethod by first employing pre-trained audio models to classify audio signals\nextracted from videos and then mapping the audio-based predictions to video\nlabel spaces through large language models, thereby establishing a connection\nbetween the audio categories and video labels. To effectively leverage the\ngenerated pseudo-labels, we present a flexible adaptation cycle that determines\nthe optimal number of adaptation iterations for each sample, based on changes\nin loss and consistency across different views. This enables a customized\nadaptation process for each sample. Experimental results on two widely used\ndatasets (UCF101-C and Kinetics-Sounds-C), as well as on two newly constructed\naudio-video TTA datasets (AVE-C and AVMIT-C) with various corruption types,\ndemonstrate the superiority of our approach. Our method consistently improves\nadaptation performance across different video classification models and\nrepresents a significant step forward in integrating audio information into\nvideo TTA. Code: https://github.com/keikeiqi/Audio-Assisted-TTA.", "published": "2025-06-14 12:44:58", "link": "http://arxiv.org/abs/2506.12481v1", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Style-based Composer Identification and Attribution of Symbolic Music Scores: a Systematic Survey", "abstract": "This paper presents the first comprehensive systematic review of literature\non style-based composer identification and authorship attribution in symbolic\nmusic scores. Addressing the critical need for improved reliability and\nreproducibility in this field, the review rigorously analyzes 58 peer-reviewed\npapers published across various historical periods, with the search adapted to\nevolving terminology. The analysis critically assesses prevailing repertoires,\ncomputational approaches, and evaluation methodologies, highlighting\nsignificant challenges. It reveals that a substantial portion of existing\nresearch suffers from inadequate validation protocols and an over-reliance on\nsimple accuracy metrics for often imbalanced datasets, which can undermine the\ncredibility of attribution claims. The crucial role of robust metrics like\nBalanced Accuracy and rigorous cross-validation in ensuring trustworthy results\nis emphasized. The survey also details diverse feature representations and the\nevolution of machine learning models employed. Notable real-world authorship\nattribution cases, such as those involving works attributed to Bach, Josquin\nDesprez, and Lennon-McCartney, are specifically discussed, illustrating the\nopportunities and pitfalls of applying computational techniques to resolve\ndisputed musical provenance. Based on these insights, a set of actionable\nguidelines for future research are proposed. These recommendations are designed\nto significantly enhance the reliability, reproducibility, and musicological\nvalidity of composer identification and authorship attribution studies,\nfostering more robust and interpretable computational stylistic analysis.", "published": "2025-06-14 10:34:07", "link": "http://arxiv.org/abs/2506.12440v1", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.DL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "GSDNet: Revisiting Incomplete Multimodal-Diffusion from Graph Spectrum Perspective for Conversation Emotion Recognition", "abstract": "Multimodal emotion recognition in conversations (MERC) aims to infer the\nspeaker's emotional state by analyzing utterance information from multiple\nsources (i.e., video, audio, and text). Compared with unimodality, a more\nrobust utterance representation can be obtained by fusing complementary\nsemantic information from different modalities. However, the modality missing\nproblem severely limits the performance of MERC in practical scenarios. Recent\nwork has achieved impressive performance on modality completion using graph\nneural networks and diffusion models, respectively. This inspires us to combine\nthese two dimensions through the graph diffusion model to obtain more powerful\nmodal recovery capabilities. Unfortunately, existing graph diffusion models may\ndestroy the connectivity and local structure of the graph by directly adding\nGaussian noise to the adjacency matrix, resulting in the generated graph data\nbeing unable to retain the semantic and topological information of the original\ngraph. To this end, we propose a novel Graph Spectral Diffusion Network\n(GSDNet), which maps Gaussian noise to the graph spectral space of missing\nmodalities and recovers the missing data according to its original\ndistribution. Compared with previous graph diffusion methods, GSDNet only\naffects the eigenvalues of the adjacency matrix instead of destroying the\nadjacency matrix directly, which can maintain the global topological\ninformation and important spectral features during the diffusion process.\nExtensive experiments have demonstrated that GSDNet achieves state-of-the-art\nemotion recognition performance in various modality loss scenarios.", "published": "2025-06-14 03:24:19", "link": "http://arxiv.org/abs/2506.12325v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Phonikud: Hebrew Grapheme-to-Phoneme Conversion for Real-Time Text-to-Speech", "abstract": "Real-time text-to-speech (TTS) for Modern Hebrew is challenging due to the\nlanguage's orthographic complexity. Existing solutions ignore crucial phonetic\nfeatures such as stress that remain underspecified even when vowel marks are\nadded. To address these limitations, we introduce Phonikud, a lightweight,\nopen-source Hebrew grapheme-to-phoneme (G2P) system that outputs\nfully-specified IPA transcriptions. Our approach adapts an existing\ndiacritization model with lightweight adaptors, incurring negligible additional\nlatency. We also contribute the ILSpeech dataset of transcribed Hebrew speech\nwith IPA annotations, serving as a benchmark for Hebrew G2P and as training\ndata for TTS systems. Our results demonstrate that Phonikud G2P conversion more\naccurately predicts phonemes from Hebrew text compared to prior methods, and\nthat this enables training of effective real-time Hebrew TTS models with\nsuperior speed-accuracy trade-offs. We release our code, data, and models at\nhttps://phonikud.github.io.", "published": "2025-06-14 02:16:38", "link": "http://arxiv.org/abs/2506.12311v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "CMI-Bench: A Comprehensive Benchmark for Evaluating Music Instruction Following", "abstract": "Recent advances in audio-text large language models (LLMs) have opened new\npossibilities for music understanding and generation. However, existing\nbenchmarks are limited in scope, often relying on simplified tasks or\nmulti-choice evaluations that fail to reflect the complexity of real-world\nmusic analysis. We reinterpret a broad range of traditional MIR annotations as\ninstruction-following formats and introduce CMI-Bench, a comprehensive music\ninstruction following benchmark designed to evaluate audio-text LLMs on a\ndiverse set of music information retrieval (MIR) tasks. These include genre\nclassification, emotion regression, emotion tagging, instrument classification,\npitch estimation, key detection, lyrics transcription, melody extraction, vocal\ntechnique recognition, instrument performance technique detection, music\ntagging, music captioning, and (down)beat tracking: reflecting core challenges\nin MIR research. Unlike previous benchmarks, CMI-Bench adopts standardized\nevaluation metrics consistent with previous state-of-the-art MIR models,\nensuring direct comparability with supervised approaches. We provide an\nevaluation toolkit supporting all open-source audio-textual LLMs, including\nLTU, Qwen-audio, SALMONN, MusiLingo, etc. Experiment results reveal significant\nperformance gaps between LLMs and supervised models, along with their culture,\nchronological and gender bias, highlighting the potential and limitations of\ncurrent models in addressing MIR tasks. CMI-Bench establishes a unified\nfoundation for evaluating music instruction following, driving progress in\nmusic-aware LLMs.", "published": "2025-06-14 00:18:44", "link": "http://arxiv.org/abs/2506.12285v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Semi-Blind Channel Estimation for Downlink Communications Based on Dynamic Metasurface Antennas", "abstract": "Dynamic metasurface antennas (DMAs) are emerging as a promising technology to\nenable energy-efficient, large array-based multi-antenna systems. This paper\npresents a simple channel estimation scheme for the downlink of a\nmultiple-input single-output orthogonal frequency division multiplexing\n(MISO-OFDM) communication system exploiting DMAs. The proposed scheme extracts\nseparate estimates of the wireless channel and the unknown waveguide\npropagation vector using a simple iterative algorithm based on the parallel\nfactor (PARAFAC) decomposition. Obtaining decoupled estimates of the wireless\nchannel and inner waveguide vector enables the isolation and compensation for\nits effect when designing the DMA beamformer, regardless of the wireless\nchannel state, which evolves much faster due to its shorter coherence time and\nbandwidth. Additionally, our solution operates in a data-aided manner,\ndelivering estimates of useful data symbols jointly with channel estimates,\nwithout requiring sequential pilot and data stages. To the best of our\nknowledge, this is the first work to explore this CE approach. Numerical\nresults corroborate the notable performance of the proposed scheme.", "published": "2025-06-14 21:47:54", "link": "http://arxiv.org/abs/2506.12639v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Smooshed BMOCZ Zero Constellation for CFO Estimation Without Channel Coding", "abstract": "In this study, we propose a new binary modulation on conjugate-reciprocal\nzeros (BMOCZ) zero constellation, which we call smooshed binary modulation on\nconjugate-reciprocal zeros (SBMOCZ), to address carrier frequency offset\n(CFO)-induced zero rotation without depending on channel coding. In our\napproach, we modify the phase mapping of Huffman BMOCZ by shrinking the angle\nbetween adjacent zeros, except for the first and last, to introduce a gap in\nthe zero constellation. By discerning the gap location in the received\npolynomial, the receiver can estimate and correct the phase rotation. We\ndemonstrate the error rate performance of SBMOCZ relative to Huffman BMOCZ,\nshowing that SBMOCZ addresses a CFO-induced rotation at the cost of a modest\nperformance reduction compared to Huffman BMOCZ in the absence of a CFO.\nFinally, we compare SBMOCZ to Huffman BMOCZ using a cyclically permutable code\n(CPC), showing a 4 dB bit error rate (BER) improvement in a fading channel,\nwhile demonstrating comparable performance across other simulations.", "published": "2025-06-14 18:34:52", "link": "http://arxiv.org/abs/2506.12599v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Quantizing Small-Scale State-Space Models for Edge AI", "abstract": "State-space models (SSMs) have recently gained attention in deep learning for\ntheir ability to efficiently model long-range dependencies, making them\npromising candidates for edge-AI applications. In this paper, we analyze the\neffects of quantization on small-scale SSMs with a focus on reducing memory and\ncomputational costs while maintaining task performance. Using the S4D\narchitecture, we first investigate post-training quantization (PTQ) and show\nthat the state matrix A and internal state x are particularly sensitive to\nquantization. Furthermore, we analyze the impact of different quantization\ntechniques applied to the parameters and activations in the S4D architecture.\nTo address the observed performance drop after Post-training Quantization\n(PTQ), we apply Quantization-aware Training (QAT), significantly improving\nperformance from 40% (PTQ) to 96% on the sequential MNIST benchmark at 8-bit\nprecision. We further demonstrate the potential of QAT in enabling sub-8-bit\nprecisions and evaluate different parameterization schemes for QAT stability.\nAdditionally, we propose a heterogeneous quantization strategy that assigns\ndifferent precision levels to model components, reducing the overall memory\nfootprint by a factor of 6x without sacrificing performance. Our results\nprovide actionable insights for deploying quantized SSMs in\nresource-constrained environments.", "published": "2025-06-14 12:43:47", "link": "http://arxiv.org/abs/2506.12480v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "AI Flow: Perspectives, Scenarios, and Approaches", "abstract": "Pioneered by the foundational information theory by Claude Shannon and the\nvisionary framework of machine intelligence by Alan Turing, the convergent\nevolution of information and communication technologies (IT/CT) has created an\nunbroken wave of connectivity and computation. This synergy has sparked a\ntechnological revolution, now reaching its peak with large artificial\nintelligence (AI) models that are reshaping industries and redefining\nhuman-machine collaboration. However, the realization of ubiquitous\nintelligence faces considerable challenges due to substantial resource\nconsumption in large models and high communication bandwidth demands. To\naddress these challenges, AI Flow has been introduced as a multidisciplinary\nframework that integrates cutting-edge IT and CT advancements, with a\nparticular emphasis on the following three key points. First, device-edge-cloud\nframework serves as the foundation, which integrates end devices, edge servers,\nand cloud clusters to optimize scalability and efficiency for low-latency model\ninference. Second, we introduce the concept of familial models, which refers to\na series of different-sized models with aligned hidden features, enabling\neffective collaboration and the flexibility to adapt to varying resource\nconstraints and dynamic scenarios. Third, connectivity- and interaction-based\nintelligence emergence is a novel paradigm of AI Flow. By leveraging\ncommunication networks to enhance connectivity, the collaboration among AI\nmodels across heterogeneous nodes achieves emergent intelligence that surpasses\nthe capability of any single model. The innovations of AI Flow provide enhanced\nintelligence, timely responsiveness, and ubiquitous accessibility to AI\nservices, paving the way for the tighter fusion of AI techniques and\ncommunication systems.", "published": "2025-06-14 12:43:07", "link": "http://arxiv.org/abs/2506.12479v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.DC", "eess.SP"], "primary_category": "cs.AI"}
{"title": "From Ground to Sky: Architectures, Applications, and Challenges Shaping Low-Altitude Wireless Networks", "abstract": "In this article, we introduce a novel low-altitude wireless network (LAWN),\nwhich is a reconfigurable, three-dimensional (3D) layered architecture. In\nparticular, the LAWN integrates connectivity, sensing, control, and computing\nacross aerial and terrestrial nodes that enable seamless operation in complex,\ndynamic, and mission-critical environments. In this article, we introduce a\nnovel low-altitude wireless network (LAWN), which is a reconfigurable,\nthree-dimensional (3D) layered architecture. Different from the conventional\naerial communication systems, LAWN's distinctive feature is its tight\nintegration of functional planes in which multiple functionalities continually\nreshape themselves to operate safely and efficiently in the low-altitude sky.\nWith the LAWN, we discuss several enabling technologies, such as integrated\nsensing and communication (ISAC), semantic communication, and fully-actuated\ncontrol systems. Finally, we identify potential applications and key\ncross-layer challenges. This article offers a comprehensive roadmap for future\nresearch and development in the low-altitude airspace.", "published": "2025-06-14 02:04:41", "link": "http://arxiv.org/abs/2506.12308v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Parkinson's Disease Freezing of Gait (FoG) Symptom Detection Using Machine Learning from Wearable Sensor Data", "abstract": "Freezing of gait (FoG) is a special symptom found in patients with\nParkinson's disease (PD). Patients who have FoG abruptly lose the capacity to\nwalk as they normally would. Accelerometers worn by patients can record\nmovement data during these episodes, and machine learning algorithms can be\nuseful to categorize this information. Thus, the combination may be able to\nidentify FoG in real time. In order to identify FoG events in accelerometer\ndata, we introduce the Transformer Encoder-Bi-LSTM fusion model in this paper.\nThe model's capability to differentiate between FoG episodes and normal\nmovement was used to evaluate its performance, and on the Kaggle Parkinson's\nFreezing of Gait dataset, the proposed Transformer Encoder-Bi-LSTM fusion model\nproduced 92.6% accuracy, 80.9% F1 score, and 52.06% in terms of mean average\nprecision. The findings highlight how Deep Learning-based approaches may\nprogress the field of FoG identification and help PD patients receive better\ntreatments and management plans.", "published": "2025-06-14 16:07:17", "link": "http://arxiv.org/abs/2506.12561v1", "categories": ["cs.CV", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Delving into Instance-Dependent Label Noise in Graph Data: A Comprehensive Study and Benchmark", "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in\nnode classification tasks but struggle with label noise in real-world data.\nExisting studies on graph learning with label noise commonly rely on\nclass-dependent label noise, overlooking the complexities of instance-dependent\nnoise and falling short of capturing real-world corruption patterns. We\nintroduce BeGIN (Benchmarking for Graphs with Instance-dependent Noise), a new\nbenchmark that provides realistic graph datasets with various noise types and\ncomprehensively evaluates noise-handling strategies across GNN architectures,\nnoisy label detection, and noise-robust learning. To simulate\ninstance-dependent corruptions, BeGIN introduces algorithmic methods and\nLLM-based simulations. Our experiments reveal the challenges of\ninstance-dependent noise, particularly LLM-based corruption, and underscore the\nimportance of node-specific parameterization to enhance GNN robustness. By\ncomprehensively evaluating noise-handling strategies, BeGIN provides insights\ninto their effectiveness, efficiency, and key performance factors. We expect\nthat BeGIN will serve as a valuable resource for advancing research on label\nnoise in graphs and fostering the development of robust GNN training methods.\nThe code is available at https://github.com/kimsu55/BeGIN.", "published": "2025-06-14 12:14:15", "link": "http://arxiv.org/abs/2506.12468v2", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "From Ground to Sky: Architectures, Applications, and Challenges Shaping Low-Altitude Wireless Networks", "abstract": "In this article, we introduce a novel low-altitude wireless network (LAWN),\nwhich is a reconfigurable, three-dimensional (3D) layered architecture. In\nparticular, the LAWN integrates connectivity, sensing, control, and computing\nacross aerial and terrestrial nodes that enable seamless operation in complex,\ndynamic, and mission-critical environments. Different from the conventional\naerial communication systems, LAWN's distinctive feature is its tight\nintegration of functional planes in which multiple functionalities continually\nreshape themselves to operate safely and efficiently in the low-altitude sky.\nWith the LAWN, we discuss several enabling technologies, such as integrated\nsensing and communication (ISAC), semantic communication, and fully-actuated\ncontrol systems. Finally, we identify potential applications and key\ncross-layer challenges. This article offers a comprehensive roadmap for future\nresearch and development in the low-altitude airspace.", "published": "2025-06-14 02:04:41", "link": "http://arxiv.org/abs/2506.12308v2", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "PLD: A Choice-Theoretic List-Wise Knowledge Distillation", "abstract": "Knowledge distillation is a model compression technique in which a compact\n\"student\" network is trained to replicate the predictive behavior of a larger\n\"teacher\" network. In logit-based knowledge distillation it has become the de\nfacto approach to augment cross-entropy with a distillation term. Typically\nthis term is either a KL divergence-matching marginal probabilities or a\ncorrelation-based loss capturing intra- and inter-class relationships but in\nevery case it sits as an add-on to cross-entropy with its own weight that must\nbe carefully tuned. In this paper we adopt a choice-theoretic perspective and\nrecast knowledge distillation under the Plackett-Luce model by interpreting\nteacher logits as \"worth\" scores. We introduce Plackett-Luce Distillation\n(PLD), a weighted list-wise ranking loss in which the teacher model transfers\nknowledge of its full ranking of classes, weighting each ranked choice by its\nown confidence. PLD directly optimizes a single teacher-optimal ranking of the\ntrue label first, followed by the remaining classes in descending teacher\nconfidence, yielding a convex, translation-invariant surrogate that subsumes\nweighted cross-entropy. Empirically on standard image classification\nbenchmarks, PLD improves Top-1 accuracy by an average of +0.42% over DIST\n(arXiv:2205.10536) and +1.04% over KD (arXiv:1503.02531) in homogeneous\nsettings and by +0.48% and +1.09% over DIST and KD, respectively, in\nheterogeneous settings.", "published": "2025-06-14 15:31:54", "link": "http://arxiv.org/abs/2506.12542v2", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Video-Guided Text-to-Music Generation Using Public Domain Movie Collections", "abstract": "Despite recent advancements in music generation systems, their application in\nfilm production remains limited, as they struggle to capture the nuances of\nreal-world filmmaking, where filmmakers consider multiple factors-such as\nvisual content, dialogue, and emotional tone-when selecting or composing music\nfor a scene. This limitation primarily stems from the absence of comprehensive\ndatasets that integrate these elements. To address this gap, we introduce Open\nScreen Sound Library (OSSL), a dataset consisting of movie clips from public\ndomain films, totaling approximately 36.5 hours, paired with high-quality\nsoundtracks and human-annotated mood information. To demonstrate the\neffectiveness of our dataset in improving the performance of pre-trained models\non film music generation tasks, we introduce a new video adapter that enhances\nan autoregressive transformer-based text-to-music model by adding video-based\nconditioning. Our experimental results demonstrate that our proposed approach\neffectively enhances MusicGen-Medium in terms of both objective measures of\ndistributional and paired fidelity, and subjective compatibility in mood and\ngenre. The dataset and code are available at\nhttps://havenpersona.github.io/ossl-v1.", "published": "2025-06-14 16:58:42", "link": "http://arxiv.org/abs/2506.12573v2", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Smooshed BMOCZ Zero Constellation for CFO Estimation Without Channel Coding", "abstract": "In this study, we propose a new binary modulation on conjugate-reciprocal\nzeros (BMOCZ) zero constellation, which we call smooshed binary modulation on\nconjugate-reciprocal zeros (SBMOCZ), to address carrier frequency offset\n(CFO)-induced zero rotation without depending on channel coding. In our\napproach, we modify the phase mapping of Huffman BMOCZ by shrinking the angle\nbetween adjacent zeros, except for the first and last, to introduce a gap in\nthe zero constellation. By discerning the gap location in the received\npolynomial, the receiver can estimate and correct the phase rotation. We\ndemonstrate the error rate performance of SBMOCZ relative to Huffman BMOCZ,\nshowing that SBMOCZ addresses a CFO-induced rotation at the cost of a modest\nperformance reduction compared to Huffman BMOCZ in the absence of a CFO.\nFinally, we compare SBMOCZ to Huffman BMOCZ using a cyclically permutable code\n(CPC), showing a 4 dB bit error rate (BER) improvement in a fading channel,\nwhile demonstrating comparable performance across other simulations.", "published": "2025-06-14 18:34:52", "link": "http://arxiv.org/abs/2506.12599v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
