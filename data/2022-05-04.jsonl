{"title": "Unified Semantic Typing with Meaningful Label Inference", "abstract": "Semantic typing aims at classifying tokens or spans of interest in a textual\ncontext into semantic categories such as relations, entity types, and event\ntypes. The inferred labels of semantic categories meaningfully interpret how\nmachines understand components of text. In this paper, we present UniST, a\nunified framework for semantic typing that captures label semantics by\nprojecting both inputs and labels into a joint semantic embedding space. To\nformulate different lexical and relational semantic typing tasks as a unified\ntask, we incorporate task descriptions to be jointly encoded with the input,\nallowing UniST to be adapted to different tasks without introducing\ntask-specific model components. UniST optimizes a margin ranking loss such that\nthe semantic relatedness of the input and labels is reflected from their\nembedding similarity. Our experiments demonstrate that UniST achieves strong\nperformance across three semantic typing tasks: entity typing, relation\nclassification and event typing. Meanwhile, UniST effectively transfers\nsemantic knowledge of labels and substantially improves generalizability on\ninferring rarely seen and unseen types. In addition, multiple semantic typing\ntasks can be jointly trained within the unified framework, leading to a single\ncompact multi-tasking model that performs comparably to dedicated single-task\nmodels, while offering even better transferability.", "published": "2022-05-04 00:28:17", "link": "http://arxiv.org/abs/2205.01826v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Entity Interactions for Few-Shot Relation Learning (Student\n  Abstract)", "abstract": "Few-shot relation learning refers to infer facts for relations with a limited\nnumber of observed triples. Existing metric-learning methods for this problem\nmostly neglect entity interactions within and between triples. In this paper,\nwe explore this kind of fine-grained semantic meanings and propose our model\nTransAM. Specifically, we serialize reference entities and query entities into\nsequence and apply transformer structure with local-global attention to capture\nboth intra- and inter-triple entity interactions. Experiments on two public\nbenchmark datasets NELL-One and Wiki-One with 1-shot setting prove the\neffectiveness of TransAM.", "published": "2022-05-04 03:54:44", "link": "http://arxiv.org/abs/2205.01878v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Word Embeddings in Hyperbolic Space", "abstract": "Cross-lingual word embeddings can be applied to several natural language\nprocessing applications across multiple languages. Unlike prior works that use\nword embeddings based on the Euclidean space, this short paper presents a\nsimple and effective cross-lingual Word2Vec model that adapts to the Poincar\\'e\nball model of hyperbolic space to learn unsupervised cross-lingual word\nrepresentations from a German-English parallel corpus. It has been shown that\nhyperbolic embeddings can capture and preserve hierarchical relationships. We\nevaluate the model on both hypernymy and analogy tasks. The proposed model\nachieves comparable performance with the vanilla Word2Vec model on the\ncross-lingual analogy task, the hypernymy task shows that the cross-lingual\nPoincar\\'e Word2Vec model can capture latent hierarchical structure from free\ntext across languages, which are absent from the Euclidean-based Word2Vec\nrepresentations. Our results show that by preserving the latent hierarchical\ninformation, hyperbolic spaces can offer better representations for\ncross-lingual embeddings.", "published": "2022-05-04 06:15:37", "link": "http://arxiv.org/abs/2205.01907v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexical Knowledge Internalization for Neural Dialog Generation", "abstract": "We propose knowledge internalization (KI), which aims to complement the\nlexical knowledge into neural dialog models. Instead of further conditioning\nthe knowledge-grounded dialog (KGD) models on externally retrieved knowledge,\nwe seek to integrate knowledge about each input token internally into the\nmodel's parameters. To tackle the challenge due to the large scale of lexical\nknowledge, we adopt the contrastive learning approach and create an effective\ntoken-level lexical knowledge retriever that requires only weak supervision\nmined from Wikipedia. We demonstrate the effectiveness and general\napplicability of our approach on various datasets and diversified model\nstructures.", "published": "2022-05-04 08:23:44", "link": "http://arxiv.org/abs/2205.01941v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Non-Autoregressive Machine Translation: It's Not as Fast as it Seems", "abstract": "Efficient machine translation models are commercially important as they can\nincrease inference speeds, and reduce costs and carbon emissions. Recently,\nthere has been much interest in non-autoregressive (NAR) models, which promise\nfaster translation. In parallel to the research on NAR models, there have been\nsuccessful attempts to create optimized autoregressive models as part of the\nWMT shared task on efficient translation. In this paper, we point out flaws in\nthe evaluation methodology present in the literature on NAR models and we\nprovide a fair comparison between a state-of-the-art NAR model and the\nautoregressive submissions to the shared task. We make the case for consistent\nevaluation of NAR models, and also for the importance of comparing NAR models\nwith other widely used methods for improving efficiency. We run experiments\nwith a connectionist-temporal-classification-based (CTC) NAR model implemented\nin C++ and compare it with AR models using wall clock times. Our results show\nthat, although NAR models are faster on GPUs, with small batch sizes, they are\nalmost always slower under more realistic usage conditions. We call for more\nrealistic and extensive evaluation of NAR models in future work.", "published": "2022-05-04 09:30:17", "link": "http://arxiv.org/abs/2205.01966v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Few Thousand Translations Go a Long Way! Leveraging Pre-trained Models\n  for African News Translation", "abstract": "Recent advances in the pre-training of language models leverage large-scale\ndatasets to create multilingual models. However, low-resource languages are\nmostly left out in these datasets. This is primarily because many widely spoken\nlanguages are not well represented on the web and therefore excluded from the\nlarge-scale crawls used to create datasets. Furthermore, downstream users of\nthese models are restricted to the selection of languages originally chosen for\npre-training. This work investigates how to optimally leverage existing\npre-trained models to create low-resource translation systems for 16 African\nlanguages. We focus on two questions: 1) How can pre-trained models be used for\nlanguages not included in the initial pre-training? and 2) How can the\nresulting translation models effectively transfer to new domains? To answer\nthese questions, we create a new African news corpus covering 16 languages, of\nwhich eight languages are not part of any existing evaluation dataset. We\ndemonstrate that the most effective strategy for transferring both to\nadditional languages and to additional domains is to fine-tune large\npre-trained models on small quantities of high-quality translation data.", "published": "2022-05-04 12:11:47", "link": "http://arxiv.org/abs/2205.02022v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Same Neurons, Different Languages: Probing Morphosyntax in Multilingual\n  Pre-trained Models", "abstract": "The success of multilingual pre-trained models is underpinned by their\nability to learn representations shared by multiple languages even in absence\nof any explicit supervision. However, it remains unclear how these models learn\nto generalise across languages. In this work, we conjecture that multilingual\npre-trained models can derive language-universal abstractions about grammar. In\nparticular, we investigate whether morphosyntactic information is encoded in\nthe same subset of neurons in different languages. We conduct the first\nlarge-scale empirical study over 43 languages and 14 morphosyntactic categories\nwith a state-of-the-art neuron-level probe. Our findings show that the\ncross-lingual overlap between neurons is significant, but its extent may vary\nacross categories and depends on language proximity and pre-training data size.", "published": "2022-05-04 12:22:31", "link": "http://arxiv.org/abs/2205.02023v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Masked Summarization to Generate Factually Inconsistent Summaries for\n  Improved Factual Consistency Checking", "abstract": "Despite the recent advances in abstractive summarization systems, it is still\ndifficult to determine whether a generated summary is factual consistent with\nthe source text. To this end, the latest approach is to train a factual\nconsistency classifier on factually consistent and inconsistent summaries.\nLuckily, the former is readily available as reference summaries in existing\nsummarization datasets. However, generating the latter remains a challenge, as\nthey need to be factually inconsistent, yet closely relevant to the source text\nto be effective. In this paper, we propose to generate factually inconsistent\nsummaries using source texts and reference summaries with key information\nmasked. Experiments on seven benchmark datasets demonstrate that factual\nconsistency classifiers trained on summaries generated using our method\ngenerally outperform existing models and show a competitive correlation with\nhuman judgments. We also analyze the characteristics of the summaries generated\nusing our method. We will release the pre-trained model and the code at\nhttps://github.com/hwanheelee1993/MFMA.", "published": "2022-05-04 12:48:49", "link": "http://arxiv.org/abs/2205.02035v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring and Improving Compositional Generalization in Text-to-SQL via\n  Component Alignment", "abstract": "In text-to-SQL tasks -- as in much of NLP -- compositional generalization is\na major challenge: neural networks struggle with compositional generalization\nwhere training and test distributions differ. However, most recent attempts to\nimprove this are based on word-level synthetic data or specific dataset splits\nto generate compositional biases. In this work, we propose a clause-level\ncompositional example generation method. We first split the sentences in the\nSpider text-to-SQL dataset into sub-sentences, annotating each sub-sentence\nwith its corresponding SQL clause, resulting in a new dataset Spider-SS. We\nthen construct a further dataset, Spider-CG, by composing Spider-SS\nsub-sentences in different combinations, to test the ability of models to\ngeneralize compositionally. Experiments show that existing models suffer\nsignificant performance degradation when evaluated on Spider-CG, even though\nevery sub-sentence is seen during training. To deal with this problem, we\nmodify a number of state-of-the-art models to train on the segmented data of\nSpider-SS, and we show that this method improves the generalization\nperformance.", "published": "2022-05-04 13:29:17", "link": "http://arxiv.org/abs/2205.02054v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Compositional Task-Oriented Parsing as Abstractive Question Answering", "abstract": "Task-oriented parsing (TOP) aims to convert natural language into\nmachine-readable representations of specific tasks, such as setting an alarm. A\npopular approach to TOP is to apply seq2seq models to generate linearized parse\ntrees. A more recent line of work argues that pretrained seq2seq models are\nbetter at generating outputs that are themselves natural language, so they\nreplace linearized parse trees with canonical natural-language paraphrases that\ncan then be easily translated into parse trees, resulting in so-called\nnaturalized parsers. In this work we continue to explore naturalized semantic\nparsing by presenting a general reduction of TOP to abstractive question\nanswering that overcomes some limitations of canonical paraphrasing.\nExperimental results show that our QA-based technique outperforms\nstate-of-the-art methods in full-data settings while achieving dramatic\nimprovements in few-shot settings.", "published": "2022-05-04 14:01:08", "link": "http://arxiv.org/abs/2205.02068v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are All the Datasets in Benchmark Necessary? A Pilot Study of Dataset\n  Evaluation for Text Classification", "abstract": "In this paper, we ask the research question of whether all the datasets in\nthe benchmark are necessary. We approach this by first characterizing the\ndistinguishability of datasets when comparing different systems. Experiments on\n9 datasets and 36 systems show that several existing benchmark datasets\ncontribute little to discriminating top-scoring systems, while those less used\ndatasets exhibit impressive discriminative power. We further, taking the text\nclassification task as a case study, investigate the possibility of predicting\ndataset discrimination based on its properties (e.g., average sentence length).\nOur preliminary experiments promisingly show that given a sufficient number of\ntraining experimental records, a meaningful predictor can be learned to\nestimate dataset discrimination over unseen datasets. We released all datasets\nwith features explored in this work on DataLab:\n\\url{https://datalab.nlpedia.ai}.", "published": "2022-05-04 15:33:00", "link": "http://arxiv.org/abs/2205.02129v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Granularity Semantic Aware Graph Model for Reducing Position Bias\n  in Emotion-Cause Pair Extraction", "abstract": "The Emotion-Cause Pair Extraction (ECPE) task aims to extract emotions and\ncauses as pairs from documents. We observe that the relative distance\ndistribution of emotions and causes is extremely imbalanced in the typical ECPE\ndataset. Existing methods have set a fixed size window to capture relations\nbetween neighboring clauses. However, they neglect the effective semantic\nconnections between distant clauses, leading to poor generalization ability\ntowards position-insensitive data. To alleviate the problem, we propose a novel\nMulti-Granularity Semantic Aware Graph model (MGSAG) to incorporate\nfine-grained and coarse-grained semantic features jointly, without regard to\ndistance limitation. In particular, we first explore semantic dependencies\nbetween clauses and keywords extracted from the document that convey\nfine-grained semantic features, obtaining keywords enhanced clause\nrepresentations. Besides, a clause graph is also established to model\ncoarse-grained semantic relations between clauses. Experimental results\nindicate that MGSAG surpasses the existing state-of-the-art ECPE models.\nEspecially, MGSAG outperforms other models significantly in the condition of\nposition-insensitive data.", "published": "2022-05-04 15:39:46", "link": "http://arxiv.org/abs/2205.02132v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reproducibility Beyond the Research Community: Experience from NLP\n  Beginners", "abstract": "As NLP research attracts public attention and excitement, it becomes\nincreasingly important for it to be accessible to a broad audience. As the\nresearch community works to democratize NLP, it remains unclear whether\nbeginners to the field can easily apply the latest developments. To understand\ntheir needs, we conducted a study with 93 students in an introductory NLP\ncourse, where students reproduced results of recent NLP papers. Surprisingly,\nour results suggest that their technical skill (i.e., programming experience)\nhas limited impact on their effort spent completing the exercise. Instead, we\nfind accessibility efforts by research authors to be key to a successful\nexperience, including thorough documentation and easy access to required models\nand datasets.", "published": "2022-05-04 16:54:00", "link": "http://arxiv.org/abs/2205.02182v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "User-Centric Gender Rewriting", "abstract": "In this paper, we define the task of gender rewriting in contexts involving\ntwo users (I and/or You) - first and second grammatical persons with\nindependent grammatical gender preferences. We focus on Arabic, a\ngender-marking morphologically rich language. We develop a multi-step system\nthat combines the positive aspects of both rule-based and neural rewriting\nmodels. Our results successfully demonstrate the viability of this approach on\na recently created corpus for Arabic gender rewriting, achieving 88.42 M2 F0.5\non a blind test set. Our proposed system improves over previous work on the\nfirst-person-only version of this task, by 3.05 absolute increase in M2 F0.5.\nWe demonstrate a use case of our gender rewriting system by using it to\npost-edit the output of a commercial MT system to provide personalized outputs\nbased on the users' grammatical gender preferences. We make our code, data, and\nmodels publicly available.", "published": "2022-05-04 17:46:17", "link": "http://arxiv.org/abs/2205.02211v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Robust and Semantically Organised Latent Representations for\n  Unsupervised Text Style Transfer", "abstract": "Recent studies show that auto-encoder based approaches successfully perform\nlanguage generation, smooth sentence interpolation, and style transfer over\nunseen attributes using unlabelled datasets in a zero-shot manner. The latent\nspace geometry of such models is organised well enough to perform on datasets\nwhere the style is \"coarse-grained\" i.e. a small fraction of words alone in a\nsentence are enough to determine the overall style label. A recent study uses a\ndiscrete token-based perturbation approach to map \"similar\" sentences\n(\"similar\" defined by low Levenshtein distance/ high word overlap) close by in\nlatent space. This definition of \"similarity\" does not look into the underlying\nnuances of the constituent words while mapping latent space neighbourhoods and\ntherefore fails to recognise sentences with different style-based semantics\nwhile mapping latent neighbourhoods. We introduce EPAAEs (Embedding Perturbed\nAdversarial AutoEncoders) which completes this perturbation model, by adding a\nfinely adjustable noise component on the continuous embeddings space. We\nempirically show that this (a) produces a better organised latent space that\nclusters stylistically similar sentences together, (b) performs best on a\ndiverse set of text style transfer tasks than similar denoising-inspired\nbaselines, and (c) is capable of fine-grained control of Style Transfer\nstrength. We also extend the text style transfer tasks to NLI datasets and show\nthat these more complex definitions of style are learned best by EPAAE. To the\nbest of our knowledge, extending style transfer to NLI tasks has not been\nexplored before.", "published": "2022-05-04 20:04:24", "link": "http://arxiv.org/abs/2205.02309v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Great Truths are Always Simple: A Rather Simple Knowledge Encoder for\n  Enhancing the Commonsense Reasoning Capacity of Pre-Trained Models", "abstract": "Commonsense reasoning in natural language is a desired ability of artificial\nintelligent systems. For solving complex commonsense reasoning tasks, a typical\nsolution is to enhance pre-trained language models~(PTMs) with a\nknowledge-aware graph neural network~(GNN) encoder that models a commonsense\nknowledge graph~(CSKG). Despite the effectiveness, these approaches are built\non heavy architectures, and can't clearly explain how external knowledge\nresources improve the reasoning capacity of PTMs. Considering this issue, we\nconduct a deep empirical analysis, and find that it is indeed relation features\nfrom CSKGs (but not node features) that mainly contribute to the performance\nimprovement of PTMs. Based on this finding, we design a simple MLP-based\nknowledge encoder that utilizes statistical relation paths as features.\nExtensive experiments conducted on five benchmarks demonstrate the\neffectiveness of our approach, which also largely reduces the parameters for\nencoding CSKGs. Our codes and data are publicly available at\nhttps://github.com/RUCAIBox/SAFE.", "published": "2022-05-04 01:27:36", "link": "http://arxiv.org/abs/2205.01841v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Seed-Guided Topic Discovery with Out-of-Vocabulary Seeds", "abstract": "Discovering latent topics from text corpora has been studied for decades.\nMany existing topic models adopt a fully unsupervised setting, and their\ndiscovered topics may not cater to users' particular interests due to their\ninability of leveraging user guidance. Although there exist seed-guided topic\ndiscovery approaches that leverage user-provided seeds to discover\ntopic-representative terms, they are less concerned with two factors: (1) the\nexistence of out-of-vocabulary seeds and (2) the power of pre-trained language\nmodels (PLMs). In this paper, we generalize the task of seed-guided topic\ndiscovery to allow out-of-vocabulary seeds. We propose a novel framework, named\nSeeTopic, wherein the general knowledge of PLMs and the local semantics learned\nfrom the input corpus can mutually benefit each other. Experiments on three\nreal datasets from different domains demonstrate the effectiveness of SeeTopic\nin terms of topic coherence, accuracy, and diversity.", "published": "2022-05-04 01:49:36", "link": "http://arxiv.org/abs/2205.01845v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Visual Commonsense in Pretrained Unimodal and Multimodal Models", "abstract": "Our commonsense knowledge about objects includes their typical visual\nattributes; we know that bananas are typically yellow or green, and not purple.\nText and image corpora, being subject to reporting bias, represent this\nworld-knowledge to varying degrees of faithfulness. In this paper, we\ninvestigate to what degree unimodal (language-only) and multimodal (image and\nlanguage) models capture a broad range of visually salient attributes. To that\nend, we create the Visual Commonsense Tests (ViComTe) dataset covering 5\nproperty types (color, shape, material, size, and visual co-occurrence) for\nover 5000 subjects. We validate this dataset by showing that our grounded color\ndata correlates much better than ungrounded text-only data with crowdsourced\ncolor judgments provided by Paik et al. (2021). We then use our dataset to\nevaluate pretrained unimodal models and multimodal models. Our results indicate\nthat multimodal models better reconstruct attribute distributions, but are\nstill subject to reporting bias. Moreover, increasing model size does not\nenhance performance, suggesting that the key to visual commonsense lies in the\ndata.", "published": "2022-05-04 02:07:55", "link": "http://arxiv.org/abs/2205.01850v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "All You May Need for VQA are Image Captions", "abstract": "Visual Question Answering (VQA) has benefited from increasingly sophisticated\nmodels, but has not enjoyed the same level of engagement in terms of data\ncreation. In this paper, we propose a method that automatically derives VQA\nexamples at volume, by leveraging the abundance of existing image-caption\nannotations combined with neural models for textual question generation. We\nshow that the resulting data is of high-quality. VQA models trained on our data\nimprove state-of-the-art zero-shot accuracy by double digits and achieve a\nlevel of robustness that lacks in the same model trained on human-annotated VQA\ndata.", "published": "2022-05-04 04:09:23", "link": "http://arxiv.org/abs/2205.01883v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "P^3 Ranker: Mitigating the Gaps between Pre-training and Ranking\n  Fine-tuning with Prompt-based Learning and Pre-finetuning", "abstract": "Compared to other language tasks, applying pre-trained language models (PLMs)\nfor search ranking often requires more nuances and training signals. In this\npaper, we identify and study the two mismatches between pre-training and\nranking fine-tuning: the training schema gap regarding the differences in\ntraining objectives and model architectures, and the task knowledge gap\nconsidering the discrepancy between the knowledge needed in ranking and that\nlearned during pre-training. To mitigate these gaps, we propose Pre-trained,\nPrompt-learned and Pre-finetuned Neural Ranker (P^3 Ranker). P^3 Ranker\nleverages prompt-based learning to convert the ranking task into a pre-training\nlike schema and uses pre-finetuning to initialize the model on intermediate\nsupervised tasks. Experiments on MS MARCO and Robust04 show the superior\nperformances of P^3 Ranker in few-shot ranking. Analyses reveal that P^3 Ranker\nis able to better accustom to the ranking task through prompt-based learning\nand retrieve necessary ranking-oriented knowledge gleaned in pre-finetuning,\nresulting in data-efficient PLM adaptation. Our code is available at\nhttps://github.com/NEUIR/P3Ranker.", "published": "2022-05-04 04:23:29", "link": "http://arxiv.org/abs/2205.01886v2", "categories": ["cs.IR", "cs.CL", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Improving Multi-Document Summarization through Referenced Flexible\n  Extraction with Credit-Awareness", "abstract": "A notable challenge in Multi-Document Summarization (MDS) is the\nextremely-long length of the input. In this paper, we present an\nextract-then-abstract Transformer framework to overcome the problem.\nSpecifically, we leverage pre-trained language models to construct a\nhierarchical extractor for salient sentence selection across documents and an\nabstractor for rewriting the selected contents as summaries. However, learning\nsuch a framework is challenging since the optimal contents for the abstractor\nare generally unknown. Previous works typically create pseudo extraction oracle\nto enable the supervised learning for both the extractor and the abstractor.\nNevertheless, we argue that the performance of such methods could be restricted\ndue to the insufficient information for prediction and inconsistent objectives\nbetween training and testing. To this end, we propose a loss weighting\nmechanism that makes the model aware of the unequal importance for the\nsentences not in the pseudo extraction oracle, and leverage the fine-tuned\nabstractor to generate summary references as auxiliary signals for learning the\nextractor. Moreover, we propose a reinforcement learning method that can\nefficiently apply to the extractor for harmonizing the optimization between\ntraining and testing. Experiment results show that our framework substantially\noutperforms strong baselines with comparable model sizes and achieves the best\nresults on the Multi-News, Multi-XScience, and WikiCatSum corpora.", "published": "2022-05-04 04:40:39", "link": "http://arxiv.org/abs/2205.01889v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Go Back in Time: Generating Flashbacks in Stories with Event Temporal\n  Prompts", "abstract": "Stories or narratives are comprised of a sequence of events. To compose\ninteresting stories, professional writers often leverage a creative writing\ntechnique called flashback that inserts past events into current storylines as\nwe commonly observe in novels and plays. However, it is challenging for\nmachines to generate flashback as it requires a solid understanding of event\ntemporal order (e.g. \"feeling hungry\" before \"eat,\" not vice versa), and the\ncreativity to arrange storylines so that earlier events do not always appear\nfirst in narrative order. Two major issues in existing systems that exacerbate\nthe challenges: 1) temporal bias in pertaining and story datasets that leads to\nmonotonic event temporal orders; 2) lack of explicit guidance that helps\nmachines decide where to insert flashbacks. We propose to address these issues\nusing structured storylines to encode events and their pair-wise temporal\nrelations (before, after and vague) as temporal prompts that guide how stories\nshould unfold temporally. We leverage a Plan-and-Write framework enhanced by\nreinforcement learning to generate storylines and stories end-to-end.\nEvaluation results show that the proposed method can generate more interesting\nstories with flashbacks while maintaining textual diversity, fluency, and\ntemporal coherence.", "published": "2022-05-04 05:26:05", "link": "http://arxiv.org/abs/2205.01898v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Modeling Task Interactions in Document-Level Joint Entity and Relation\n  Extraction", "abstract": "We target on the document-level relation extraction in an end-to-end setting,\nwhere the model needs to jointly perform mention extraction, coreference\nresolution (COREF) and relation extraction (RE) at once, and gets evaluated in\nan entity-centric way. Especially, we address the two-way interaction between\nCOREF and RE that has not been the focus by previous work, and propose to\nintroduce explicit interaction namely Graph Compatibility (GC) that is\nspecifically designed to leverage task characteristics, bridging decisions of\ntwo tasks for direct task interference. Our experiments are conducted on DocRED\nand DWIE; in addition to GC, we implement and compare different multi-task\nsettings commonly adopted in previous work, including pipeline, shared\nencoders, graph propagation, to examine the effectiveness of different\ninteractions. The result shows that GC achieves the best performance by up to\n2.3/5.1 F1 improvement over the baseline.", "published": "2022-05-04 06:18:28", "link": "http://arxiv.org/abs/2205.01909v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Aligning to Social Norms and Values in Interactive Narratives", "abstract": "We focus on creating agents that act in alignment with socially beneficial\nnorms and values in interactive narratives or text-based games -- environments\nwherein an agent perceives and interacts with a world through natural language.\nSuch interactive agents are often trained via reinforcement learning to\noptimize task performance, even when such rewards may lead to agent behaviors\nthat violate societal norms -- causing harm either to the agent itself or other\nentities in the environment. Social value alignment refers to creating agents\nwhose behaviors conform to expected moral and social norms for a given context\nand group of people -- in our case, it means agents that behave in a manner\nthat is less harmful and more beneficial for themselves and others.\n  We build on the Jiminy Cricket benchmark (Hendrycks et al. 2021), a set of 25\nannotated interactive narratives containing thousands of morally salient\nscenarios covering everything from theft and bodily harm to altruism. We\nintroduce the GALAD (Game-value ALignment through Action Distillation) agent\nthat uses the social commonsense knowledge present in specially trained\nlanguage models to contextually restrict its action space to only those actions\nthat are aligned with socially beneficial values. An experimental study shows\nthat the GALAD agent makes decisions efficiently enough to improve\nstate-of-the-art task performance by 4% while reducing the frequency of\nsocially harmful behaviors by 25% compared to strong contemporary value\nalignment approaches.", "published": "2022-05-04 09:54:33", "link": "http://arxiv.org/abs/2205.01975v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Framework to Generate High-Quality Datapoints for Multiple Novel\n  Intent Detection", "abstract": "Systems like Voice-command based conversational agents are characterized by a\npre-defined set of skills or intents to perform user specified tasks. In the\ncourse of time, newer intents may emerge requiring retraining. However, the\nnewer intents may not be explicitly announced and need to be inferred\ndynamically. Thus, there are two important tasks at hand (a). identifying\nemerging new intents, (b). annotating data of the new intents so that the\nunderlying classifier can be retrained efficiently. The tasks become specially\nchallenging when a large number of new intents emerge simultaneously and there\nis a limited budget of manual annotation. In this paper, we propose MNID\n(Multiple Novel Intent Detection) which is a cluster based framework to detect\nmultiple novel intents with budgeted human annotation cost. Empirical results\non various benchmark datasets (of different sizes) demonstrate that MNID, by\nintelligently using the budget for annotation, outperforms the baseline methods\nin terms of accuracy and F1-score.", "published": "2022-05-04 11:32:15", "link": "http://arxiv.org/abs/2205.02005v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hyperbolic Relevance Matching for Neural Keyphrase Extraction", "abstract": "Keyphrase extraction is a fundamental task in natural language processing and\ninformation retrieval that aims to extract a set of phrases with important\ninformation from a source document. Identifying important keyphrase is the\ncentral component of the keyphrase extraction task, and its main challenge is\nhow to represent information comprehensively and discriminate importance\naccurately. In this paper, to address these issues, we design a new hyperbolic\nmatching model (HyperMatch) to represent phrases and documents in the same\nhyperbolic space and explicitly estimate the phrase-document relevance via the\nPoincar\\'e distance as the important score of each phrase. Specifically, to\ncapture the hierarchical syntactic and semantic structure information,\nHyperMatch takes advantage of the hidden representations in multiple layers of\nRoBERTa and integrates them as the word embeddings via an adaptive mixing\nlayer. Meanwhile, considering the hierarchical structure hidden in the\ndocument, HyperMatch embeds both phrases and documents in the same hyperbolic\nspace via a hyperbolic phrase encoder and a hyperbolic document encoder. This\nstrategy can further enhance the estimation of phrase-document relevance due to\nthe good properties of hyperbolic space. In this setting, the keyphrase\nextraction can be taken as a matching problem and effectively implemented by\nminimizing a hyperbolic margin-based triplet loss. Extensive experiments are\nconducted on six benchmarks and demonstrate that HyperMatch outperforms the\nstate-of-the-art baselines.", "published": "2022-05-04 13:13:52", "link": "http://arxiv.org/abs/2205.02047v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Improve Discourse Dependency Parsing with Contextualized Representations", "abstract": "Recent works show that discourse analysis benefits from modeling intra- and\ninter-sentential levels separately, where proper representations for text units\nof different granularities are desired to capture both the meaning of text\nunits and their relations to the context. In this paper, we propose to take\nadvantage of transformers to encode contextualized representations of units of\ndifferent levels to dynamically capture the information required for discourse\ndependency analysis on intra- and inter-sentential levels. Motivated by the\nobservation of writing patterns commonly shared across articles, we propose a\nnovel method that treats discourse relation identification as a sequence\nlabelling task, which takes advantage of structural information from the\ncontext of extracted discourse trees, and substantially outperforms traditional\ndirect-classification methods. Experiments show that our model achieves\nstate-of-the-art results on both English and Chinese datasets.", "published": "2022-05-04 14:35:38", "link": "http://arxiv.org/abs/2205.02090v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Using virtual edges to extract keywords from texts modeled as complex\n  networks", "abstract": "Detecting keywords in texts is important for many text mining applications.\nGraph-based methods have been commonly used to automatically find the key\nconcepts in texts, however, relevant information provided by embeddings has not\nbeen widely used to enrich the graph structure. Here we modeled texts\nco-occurrence networks, where nodes are words and edges are established either\nby contextual or semantical similarity. We compared two embedding approaches --\nWord2vec and BERT -- to check whether edges created via word embeddings can\nimprove the quality of the keyword extraction method. We found that, in fact,\nthe use of virtual edges can improve the discriminability of co-occurrence\nnetworks. The best performance was obtained when we considered low percentages\nof addition of virtual (embedding) edges. A comparative analysis of structural\nand dynamical network metrics revealed the degree, PageRank, and accessibility\nare the metrics displaying the best performance in the model enriched with\nvirtual edges.", "published": "2022-05-04 16:43:03", "link": "http://arxiv.org/abs/2205.02172v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Semi-supervised learning approaches for predicting South African\n  political sentiment for local government elections", "abstract": "This study aims to understand the South African political context by\nanalysing the sentiments shared on Twitter during the local government\nelections. An emphasis on the analysis was placed on understanding the\ndiscussions led around four predominant political parties ANC, DA, EFF and\nActionSA. A semi-supervised approach by means of a graph-based technique to\nlabel the vast accessible Twitter data for the classification of tweets into\nnegative and positive sentiment was used. The tweets expressing negative\nsentiment were further analysed through latent topic extraction to uncover\nhidden topics of concern associated with each of the political parties. Our\nfindings demonstrated that the general sentiment across South African Twitter\nusers is negative towards all four predominant parties with the worst negative\nsentiment among users projected towards the current ruling party, ANC, relating\nto concerns cantered around corruption, incompetence and loadshedding.", "published": "2022-05-04 17:55:57", "link": "http://arxiv.org/abs/2205.02223v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "HiURE: Hierarchical Exemplar Contrastive Learning for Unsupervised\n  Relation Extraction", "abstract": "Unsupervised relation extraction aims to extract the relationship between\nentities from natural language sentences without prior information on\nrelational scope or distribution. Existing works either utilize self-supervised\nschemes to refine relational feature signals by iteratively leveraging adaptive\nclustering and classification that provoke gradual drift problems, or adopt\ninstance-wise contrastive learning which unreasonably pushes apart those\nsentence pairs that are semantically similar. To overcome these defects, we\npropose a novel contrastive learning framework named HiURE, which has the\ncapability to derive hierarchical signals from relational feature space using\ncross hierarchy attention and effectively optimize relation representation of\nsentences under exemplar-wise contrastive learning. Experimental results on two\npublic datasets demonstrate the advanced effectiveness and robustness of HiURE\non unsupervised relation extraction when compared with state-of-the-art models.", "published": "2022-05-04 17:56:48", "link": "http://arxiv.org/abs/2205.02225v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Dataset for N-ary Relation Extraction of Drug Combinations", "abstract": "Combination therapies have become the standard of care for diseases such as\ncancer, tuberculosis, malaria and HIV. However, the combinatorial set of\navailable multi-drug treatments creates a challenge in identifying effective\ncombination therapies available in a situation. To assist medical professionals\nin identifying beneficial drug-combinations, we construct an expert-annotated\ndataset for extracting information about the efficacy of drug combinations from\nthe scientific literature. Beyond its practical utility, the dataset also\npresents a unique NLP challenge, as the first relation extraction dataset\nconsisting of variable-length relations. Furthermore, the relations in this\ndataset predominantly require language understanding beyond the sentence level,\nadding to the challenge of this task. We provide a promising baseline model and\nidentify clear areas for further improvement. We release our dataset, code, and\nbaseline models publicly to encourage the NLP community to participate in this\ntask.", "published": "2022-05-04 19:01:16", "link": "http://arxiv.org/abs/2205.02289v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Language Models in the Loop: Incorporating Prompting into Weak\n  Supervision", "abstract": "We propose a new strategy for applying large pre-trained language models to\nnovel tasks when labeled training data is limited. Rather than apply the model\nin a typical zero-shot or few-shot fashion, we treat the model as the basis for\nlabeling functions in a weak supervision framework. To create a classifier, we\nfirst prompt the model to answer multiple distinct queries about an example and\ndefine how the possible responses should be mapped to votes for labels and\nabstentions. We then denoise these noisy label sources using the Snorkel system\nand train an end classifier with the resulting training data. Our experimental\nevaluation shows that prompting large language models within a weak supervision\nframework can provide significant gains in accuracy. On the WRENCH weak\nsupervision benchmark, this approach can significantly improve over zero-shot\nperformance, an average 19.5% reduction in errors. We also find that this\napproach produces classifiers with comparable or superior accuracy to those\ntrained from hand-engineered rules.", "published": "2022-05-04 20:42:40", "link": "http://arxiv.org/abs/2205.02318v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Knowledge Distillation of Russian Language Models with Reduction of\n  Vocabulary", "abstract": "Today, transformer language models serve as a core component for majority of\nnatural language processing tasks. Industrial application of such models\nrequires minimization of computation time and memory footprint. Knowledge\ndistillation is one of approaches to address this goal. Existing methods in\nthis field are mainly focused on reducing the number of layers or dimension of\nembeddings/hidden representations. Alternative option is to reduce the number\nof tokens in vocabulary and therefore the embeddings matrix of the student\nmodel. The main problem with vocabulary minimization is mismatch between input\nsequences and output class distributions of a teacher and a student models. As\na result, it is impossible to directly apply KL-based knowledge distillation.\nWe propose two simple yet effective alignment techniques to make knowledge\ndistillation to the students with reduced vocabulary. Evaluation of distilled\nmodels on a number of common benchmarks for Russian such as Russian SuperGLUE,\nSberQuAD, RuSentiment, ParaPhaser, Collection-3 demonstrated that our\ntechniques allow to achieve compression from $17\\times$ to $49\\times$, while\nmaintaining quality of $1.7\\times$ compressed student with the full-sized\nvocabulary, but reduced number of Transformer layers only. We make our code and\ndistilled models available.", "published": "2022-05-04 21:56:57", "link": "http://arxiv.org/abs/2205.02340v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "KenSwQuAD -- A Question Answering Dataset for Swahili Low Resource\n  Language", "abstract": "The need for Question Answering datasets in low resource languages is the\nmotivation of this research, leading to the development of Kencorpus Swahili\nQuestion Answering Dataset, KenSwQuAD. This dataset is annotated from raw story\ntexts of Swahili low resource language, which is a predominantly spoken in\nEastern African and in other parts of the world. Question Answering (QA)\ndatasets are important for machine comprehension of natural language for tasks\nsuch as internet search and dialog systems. Machine learning systems need\ntraining data such as the gold standard Question Answering set developed in\nthis research. The research engaged annotators to formulate QA pairs from\nSwahili texts collected by the Kencorpus project, a Kenyan languages corpus.\nThe project annotated 1,445 texts from the total 2,585 texts with at least 5 QA\npairs each, resulting into a final dataset of 7,526 QA pairs. A quality\nassurance set of 12.5% of the annotated texts confirmed that the QA pairs were\nall correctly annotated. A proof of concept on applying the set to the QA task\nconfirmed that the dataset can be usable for such tasks. KenSwQuAD has also\ncontributed to resourcing of the Swahili language.", "published": "2022-05-04 23:53:23", "link": "http://arxiv.org/abs/2205.02364v3", "categories": ["cs.CL", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "AmbiPun: Generating Humorous Puns with Ambiguous Context", "abstract": "In this paper, we propose a simple yet effective way to generate pun\nsentences that does not require any training on existing puns. Our approach is\ninspired by humor theories that ambiguity comes from the context rather than\nthe pun word itself. Given a pair of definitions of a pun word, our model first\nproduces a list of related concepts through a reverse dictionary. We then\nutilize one-shot GPT3 to generate context words and then generate puns\nincorporating context words from both concepts. Human evaluation shows that our\nmethod successfully generates pun 52\\% of the time, outperforming well-crafted\nbaselines and the state-of-the-art models by a large margin.", "published": "2022-05-04 00:24:11", "link": "http://arxiv.org/abs/2205.01825v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Provably Confidential Language Modelling", "abstract": "Large language models are shown to memorize privacy information such as\nsocial security numbers in training data. Given the sheer scale of the training\ncorpus, it is challenging to screen and filter these privacy data, either\nmanually or automatically. In this paper, we propose Confidentially Redacted\nTraining (CRT), a method to train language generation models while protecting\nthe confidential segments. We borrow ideas from differential privacy (which\nsolves a related but distinct problem) and show that our method is able to\nprovably prevent unintended memorization by randomizing parts of the training\nprocess. Moreover, we show that redaction with an approximately correct\nscreening policy amplifies the confidentiality guarantee. We implement the\nmethod for both LSTM and GPT language models. Our experimental results show\nthat the models trained by CRT obtain almost the same perplexity while\npreserving strong confidentiality.", "published": "2022-05-04 02:33:45", "link": "http://arxiv.org/abs/2205.01863v2", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Word Tour: One-dimensional Word Embeddings via the Traveling Salesman\n  Problem", "abstract": "Word embeddings are one of the most fundamental technologies used in natural\nlanguage processing. Existing word embeddings are high-dimensional and consume\nconsiderable computational resources. In this study, we propose WordTour,\nunsupervised one-dimensional word embeddings. To achieve the challenging goal,\nwe propose a decomposition of the desiderata of word embeddings into two parts,\ncompleteness and soundness, and focus on soundness in this paper. Owing to the\nsingle dimensionality, WordTour is extremely efficient and provides a minimal\nmeans to handle word embeddings. We experimentally confirmed the effectiveness\nof the proposed method via user study and document classification.", "published": "2022-05-04 08:46:02", "link": "http://arxiv.org/abs/2205.01954v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ON-TRAC Consortium Systems for the IWSLT 2022 Dialect and Low-resource\n  Speech Translation Tasks", "abstract": "This paper describes the ON-TRAC Consortium translation systems developed for\ntwo challenge tracks featured in the Evaluation Campaign of IWSLT 2022:\nlow-resource and dialect speech translation. For the Tunisian Arabic-English\ndataset (low-resource and dialect tracks), we build an end-to-end model as our\njoint primary submission, and compare it against cascaded models that leverage\na large fine-tuned wav2vec 2.0 model for ASR. Our results show that in our\nsettings pipeline approaches are still very competitive, and that with the use\nof transfer learning, they can outperform end-to-end models for speech\ntranslation (ST). For the Tamasheq-French dataset (low-resource track) our\nprimary submission leverages intermediate representations from a wav2vec 2.0\nmodel trained on 234 hours of Tamasheq audio, while our contrastive model uses\na French phonetic transcription of the Tamasheq audio as input in a Conformer\nspeech translation architecture jointly trained on automatic speech\nrecognition, ST and machine translation losses. Our results highlight that\nself-supervised models trained on smaller sets of target data are more\neffective to low-resource end-to-end ST fine-tuning, compared to large\noff-the-shelf models. Results also illustrate that even approximate phonetic\ntranscriptions can improve ST scores.", "published": "2022-05-04 10:36:57", "link": "http://arxiv.org/abs/2205.01987v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "EmoBank: Studying the Impact of Annotation Perspective and\n  Representation Format on Dimensional Emotion Analysis", "abstract": "We describe EmoBank, a corpus of 10k English sentences balancing multiple\ngenres, which we annotated with dimensional emotion metadata in the\nValence-Arousal-Dominance (VAD) representation format. EmoBank excels with a\nbi-perspectival and bi-representational design. On the one hand, we distinguish\nbetween writer's and reader's emotions, on the other hand, a subset of the\ncorpus complements dimensional VAD annotations with categorical ones based on\nBasic Emotions. We find evidence for the supremacy of the reader's perspective\nin terms of IAA and rating intensity, and achieve close-to-human performance\nwhen mapping between dimensional and categorical formats.", "published": "2022-05-04 11:03:21", "link": "http://arxiv.org/abs/2205.01996v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Design of a novel Korean learning application for efficient\n  pronunciation correction", "abstract": "The Korean wave, which denotes the global popularity of South Korea's\ncultural economy, contributes to the increasing demand for the Korean language.\nHowever, as there does not exist any application for foreigners to learn\nKorean, this paper suggested a design of a novel Korean learning application.\nSpeech recognition, speech-to-text, and speech-to-waveform are the three key\nsystems in the proposed system. The Google API and the librosa library will\ntransform the user's voice into a sentence and MFCC. The software will then\ndisplay the user's phrase and answer, with mispronounced elements highlighted\nin red, allowing users to more easily recognize the incorrect parts of their\npronunciation. Furthermore, the Siamese network might utilize those translated\nspectrograms to provide a similarity score, which could subsequently be used to\noffer feedback to the user. Despite the fact that we were unable to collect\nsufficient foreigner data for this research, it is notable that we presented a\nnovel Korean pronunciation correction method for foreigners.", "published": "2022-05-04 11:19:29", "link": "http://arxiv.org/abs/2205.02001v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "A Computational Inflection for Scientific Discovery", "abstract": "We stand at the foot of a significant inflection in the trajectory of\nscientific discovery. As society continues on its fast-paced digital\ntransformation, so does humankind's collective scientific knowledge and\ndiscourse. We now read and write papers in digitized form, and a great deal of\nthe formal and informal processes of science are captured digitally --\nincluding papers, preprints and books, code and datasets, conference\npresentations, and interactions in social networks and collaboration and\ncommunication platforms. The transition has led to the creation and growth of a\ntremendous amount of information -- much of which is available for public\naccess -- opening exciting opportunities for computational models and systems\nthat analyze and harness it. In parallel, exponential growth in data processing\npower has fueled remarkable advances in artificial intelligence, including\nlarge neural language models capable of learning powerful representations from\nunstructured text. Dramatic changes in scientific communication -- such as the\nadvent of the first scientific journal in the 17th century -- have historically\ncatalyzed revolutions in scientific thought. The confluence of societal and\ncomputational trends suggests that computer science is poised to ignite a\nrevolution in the scientific process itself.", "published": "2022-05-04 11:36:54", "link": "http://arxiv.org/abs/2205.02007v2", "categories": ["cs.CL", "cs.CY", "cs.HC", "cs.IR"], "primary_category": "cs.CL"}
{"title": "On Continual Model Refinement in Out-of-Distribution Data Streams", "abstract": "Real-world natural language processing (NLP) models need to be continually\nupdated to fix the prediction errors in out-of-distribution (OOD) data streams\nwhile overcoming catastrophic forgetting. However, existing continual learning\n(CL) problem setups cannot cover such a realistic and complex scenario. In\nresponse to this, we propose a new CL problem formulation dubbed continual\nmodel refinement (CMR). Compared to prior CL settings, CMR is more practical\nand introduces unique challenges (boundary-agnostic and non-stationary\ndistribution shift, diverse mixtures of multiple OOD data clusters,\nerror-centric streams, etc.). We extend several existing CL approaches to the\nCMR setting and evaluate them extensively. For benchmarking and analysis, we\npropose a general sampling algorithm to obtain dynamic OOD data streams with\ncontrollable non-stationarity, as well as a suite of metrics measuring various\naspects of online performance. Our experiments and detailed analysis reveal the\npromise and challenges of the CMR problem, supporting that studying CMR in\ndynamic OOD streams can benefit the longevity of deployed NLP models in\nproduction.", "published": "2022-05-04 11:54:44", "link": "http://arxiv.org/abs/2205.02014v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CODE-MVP: Learning to Represent Source Code from Multiple Views with\n  Contrastive Pre-Training", "abstract": "Recent years have witnessed increasing interest in code representation\nlearning, which aims to represent the semantics of source code into distributed\nvectors. Currently, various works have been proposed to represent the complex\nsemantics of source code from different views, including plain text, Abstract\nSyntax Tree (AST), and several kinds of code graphs (e.g., Control/Data Flow\nGraph). However, most of them only consider a single view of source code\nindependently, ignoring the correspondences among different views. In this\npaper, we propose to integrate different views with the natural-language\ndescription of source code into a unified framework with Multi-View contrastive\nPre-training, and name our model as CODE-MVP. Specifically, we first extract\nmultiple code views using compiler tools, and learn the complementary\ninformation among them under a contrastive learning framework. Inspired by the\ntype checking in compilation, we also design a fine-grained type inference\nobjective in the pre-training. Experiments on three downstream tasks over five\ndatasets demonstrate the superiority of CODE-MVP when compared with several\nstate-of-the-art baselines. For example, we achieve 2.4/2.3/1.1 gain in terms\nof MRR/MAP/Accuracy metrics on natural language code retrieval, code\nsimilarity, and code defect detection tasks, respectively.", "published": "2022-05-04 12:40:58", "link": "http://arxiv.org/abs/2205.02029v1", "categories": ["cs.PL", "cs.AI", "cs.CL"], "primary_category": "cs.PL"}
{"title": "Few-Shot Document-Level Relation Extraction", "abstract": "We present FREDo, a few-shot document-level relation extraction (FSDLRE)\nbenchmark. As opposed to existing benchmarks which are built on sentence-level\nrelation extraction corpora, we argue that document-level corpora provide more\nrealism, particularly regarding none-of-the-above (NOTA) distributions.\nTherefore, we propose a set of FSDLRE tasks and construct a benchmark based on\ntwo existing supervised learning data sets, DocRED and sciERC. We adapt the\nstate-of-the-art sentence-level method MNAV to the document-level and develop\nit further for improved domain adaptation. We find FSDLRE to be a challenging\nsetting with interesting new characteristics such as the ability to sample NOTA\ninstances from the support set. The data, code, and trained models are\navailable online (https://github.com/nicpopovic/FREDo).", "published": "2022-05-04 13:16:19", "link": "http://arxiv.org/abs/2205.02048v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Few-Shot Fine-Tuning for Opinion Summarization", "abstract": "Abstractive summarization models are typically pre-trained on large amounts\nof generic texts, then fine-tuned on tens or hundreds of thousands of annotated\nsamples. However, in opinion summarization, large annotated datasets of reviews\npaired with reference summaries are not available and would be expensive to\ncreate. This calls for fine-tuning methods robust to overfitting on small\ndatasets. In addition, generically pre-trained models are often not accustomed\nto the specifics of customer reviews and, after fine-tuning, yield summaries\nwith disfluencies and semantic mistakes. To address these problems, we utilize\nan efficient few-shot method based on adapters which, as we show, can easily\nstore in-domain knowledge. Instead of fine-tuning the entire model, we add\nadapters and pre-train them in a task-specific way on a large corpus of\nunannotated customer reviews, using held-out reviews as pseudo summaries. Then,\nfine-tune the adapters on the small available human-annotated dataset. We show\nthat this self-supervised adapter pre-training improves summary quality over\nstandard fine-tuning by 2.0 and 1.3 ROUGE-L points on the Amazon and Yelp\ndatasets, respectively. Finally, for summary personalization, we condition on\naspect keyword queries, automatically created from generic datasets. In the\nsame vein, we pre-train the adapters in a query-based manner on customer\nreviews and then fine-tune them on annotated datasets. This results in\nbetter-organized summary content reflected in improved coherence and fewer\nredundancies.", "published": "2022-05-04 16:38:37", "link": "http://arxiv.org/abs/2205.02170v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Original or Translated? A Causal Analysis of the Impact of\n  Translationese on Machine Translation Performance", "abstract": "Human-translated text displays distinct features from naturally written text\nin the same language. This phenomena, known as translationese, has been argued\nto confound the machine translation (MT) evaluation. Yet, we find that existing\nwork on translationese neglects some important factors and the conclusions are\nmostly correlational but not causal. In this work, we collect CausalMT, a\ndataset where the MT training data are also labeled with the human translation\ndirections. We inspect two critical factors, the train-test direction match\n(whether the human translation directions in the training and test sets are\naligned), and data-model direction match (whether the model learns in the same\ndirection as the human translation direction in the dataset). We show that\nthese two factors have a large causal effect on the MT performance, in addition\nto the test-model direction mismatch highlighted by existing work on the impact\nof translationese. In light of our findings, we provide a set of suggestions\nfor MT training and evaluation. Our code and data are at\nhttps://github.com/EdisonNi-hku/CausalMT", "published": "2022-05-04 19:17:55", "link": "http://arxiv.org/abs/2205.02293v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt\n  Tuning", "abstract": "Pre-trained language models have contributed significantly to relation\nextraction by demonstrating remarkable few-shot learning abilities. However,\nprompt tuning methods for relation extraction may still fail to generalize to\nthose rare or hard patterns. Note that the previous parametric learning\nparadigm can be viewed as memorization regarding training data as a book and\ninference as the close-book test. Those long-tailed or hard patterns can hardly\nbe memorized in parameters given few-shot instances. To this end, we regard RE\nas an open-book examination and propose a new semiparametric paradigm of\nretrieval-enhanced prompt tuning for relation extraction. We construct an\nopen-book datastore for retrieval regarding prompt-based instance\nrepresentations and corresponding relation labels as memorized key-value pairs.\nDuring inference, the model can infer relations by linearly interpolating the\nbase output of PLM with the non-parametric nearest neighbor distribution over\nthe datastore. In this way, our model not only infers relation through\nknowledge stored in the weights during training but also assists\ndecision-making by unwinding and querying examples in the open-book datastore.\nExtensive experiments on benchmark datasets show that our method can achieve\nstate-of-the-art in both standard supervised and few-shot settings. Code are\navailable in https://github.com/zjunlp/PromptKG/tree/main/research/RetrievalRE.", "published": "2022-05-04 23:38:37", "link": "http://arxiv.org/abs/2205.02355v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Job-Transition-Tag Graph for a Better Job Title Representation\n  Learning", "abstract": "Works on learning job title representation are mainly based on\n\\textit{Job-Transition Graph}, built from the working history of talents.\nHowever, since these records are usually messy, this graph is very sparse,\nwhich affects the quality of the learned representation and hinders further\nanalysis. To address this specific issue, we propose to enrich the graph with\nadditional nodes that improve the quality of job title representation.\nSpecifically, we construct \\textit{Job-Transition-Tag Graph}, a heterogeneous\ngraph containing two types of nodes, i.e., job titles and tags (i.e., words\nrelated to job responsibilities or functionalities). Along this line, we\nreformulate job title representation learning as the task of learning node\nembedding on the \\textit{Job-Transition-Tag Graph}. Experiments on two datasets\nshow the interest of our approach.", "published": "2022-05-04 12:11:31", "link": "http://arxiv.org/abs/2206.02782v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Data Governance in the Age of Large-Scale Data-Driven Language\n  Technology", "abstract": "The recent emergence and adoption of Machine Learning technology, and\nspecifically of Large Language Models, has drawn attention to the need for\nsystematic and transparent management of language data. This work proposes an\napproach to global language data governance that attempts to organize data\nmanagement amongst stakeholders, values, and rights. Our proposal is informed\nby prior work on distributed governance that accounts for human values and\ngrounded by an international research collaboration that brings together\nresearchers and practitioners from 60 countries. The framework we present is a\nmulti-party international governance structure focused on language data, and\nincorporating technical and organizational tools needed to support its work.", "published": "2022-05-04 00:44:35", "link": "http://arxiv.org/abs/2206.03216v2", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "MM-Claims: A Dataset for Multimodal Claim Detection in Social Media", "abstract": "In recent years, the problem of misinformation on the web has become\nwidespread across languages, countries, and various social media platforms.\nAlthough there has been much work on automated fake news detection, the role of\nimages and their variety are not well explored. In this paper, we investigate\nthe roles of image and text at an earlier stage of the fake news detection\npipeline, called claim detection. For this purpose, we introduce a novel\ndataset, MM-Claims, which consists of tweets and corresponding images over\nthree topics: COVID-19, Climate Change and broadly Technology. The dataset\ncontains roughly 86000 tweets, out of which 3400 are labeled manually by\nmultiple annotators for the training and evaluation of multimodal models. We\ndescribe the dataset in detail, evaluate strong unimodal and multimodal\nbaselines, and analyze the potential and drawbacks of current models.", "published": "2022-05-04 10:43:58", "link": "http://arxiv.org/abs/2205.01989v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge\n  Graph Completion", "abstract": "Multimodal Knowledge Graphs (MKGs), which organize visual-text factual\nknowledge, have recently been successfully applied to tasks such as information\nretrieval, question answering, and recommendation system. Since most MKGs are\nfar from complete, extensive knowledge graph completion studies have been\nproposed focusing on the multimodal entity, relation extraction and link\nprediction. However, different tasks and modalities require changes to the\nmodel architecture, and not all images/objects are relevant to text input,\nwhich hinders the applicability to diverse real-world scenarios. In this paper,\nwe propose a hybrid transformer with multi-level fusion to address those\nissues. Specifically, we leverage a hybrid transformer architecture with\nunified input-output for diverse multimodal knowledge graph completion tasks.\nMoreover, we propose multi-level fusion, which integrates visual and text\nrepresentation via coarse-grained prefix-guided interaction and fine-grained\ncorrelation-aware fusion modules. We conduct extensive experiments to validate\nthat our MKGformer can obtain SOTA performance on four datasets of multimodal\nlink prediction, multimodal RE, and multimodal NER. Code is available in\nhttps://github.com/zjunlp/MKGformer.", "published": "2022-05-04 23:40:04", "link": "http://arxiv.org/abs/2205.02357v5", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Does a PESQNet (Loss) Require a Clean Reference Input? The Original PESQ\n  Does, But ACR Listening Tests Don't", "abstract": "Perceptual evaluation of speech quality (PESQ) requires a clean speech\nreference as input, but predicts the results from (reference-free) absolute\ncategory rating (ACR) tests. In this work, we train a fully convolutional\nrecurrent neural network (FCRN) as deep noise suppression (DNS) model, with\neither a non-intrusive or an intrusive PESQNet, where only the latter has\naccess to a clean speech reference. The PESQNet is used as a mediator providing\na perceptual loss during the DNS training to maximize the PESQ score of the\nenhanced speech signal. For the intrusive PESQNet, we investigate two\ntopologies, called early-fusion (EF) and middle-fusion (MF) PESQNet, and\ncompare to the non-intrusive PESQNet to evaluate and to quantify the benefits\nof employing a clean speech reference input during DNS training. Detailed\nanalyses show that the DNS trained with the MF-intrusive PESQNet outperforms\nthe Interspeech 2021 DNS Challenge baseline and the same DNS trained with an\nMSE loss by 0.23 and 0.12 PESQ points, respectively. Furthermore, we can show\nthat only marginal benefits are obtained compared to the DNS trained with the\nnon-intrusive PESQNet. Therefore, as ACR listening tests, the PESQNet does not\nnecessarily require a clean speech reference input, opening the possibility of\nusing real data for DNS training.", "published": "2022-05-04 14:26:02", "link": "http://arxiv.org/abs/2205.02085v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Virtual Analog Modeling of Distortion Circuits Using Neural Ordinary\n  Differential Equations", "abstract": "Recent research in deep learning has shown that neural networks can learn\ndifferential equations governing dynamical systems. In this paper, we adapt\nthis concept to Virtual Analog (VA) modeling to learn the ordinary differential\nequations (ODEs) governing the first-order and the second-order diode clipper.\nThe proposed models achieve performance comparable to state-of-the-art\nrecurrent neural networks (RNNs) albeit using fewer parameters. We show that\nthis approach does not require oversampling and allows to increase the sampling\nrate after the training has completed, which results in increased accuracy.\nUsing a sophisticated numerical solver allows to increase the accuracy at the\ncost of slower processing. ODEs learned this way do not require closed forms\nbut are still physically interpretable.", "published": "2022-05-04 05:19:46", "link": "http://arxiv.org/abs/2205.01897v3", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SVTS: Scalable Video-to-Speech Synthesis", "abstract": "Video-to-speech synthesis (also known as lip-to-speech) refers to the\ntranslation of silent lip movements into the corresponding audio. This task has\nreceived an increasing amount of attention due to its self-supervised nature\n(i.e., can be trained without manual labelling) combined with the ever-growing\ncollection of audio-visual data available online. Despite these strong\nmotivations, contemporary video-to-speech works focus mainly on small- to\nmedium-sized corpora with substantial constraints in both vocabulary and\nsetting. In this work, we introduce a scalable video-to-speech framework\nconsisting of two components: a video-to-spectrogram predictor and a\npre-trained neural vocoder, which converts the mel-frequency spectrograms into\nwaveform audio. We achieve state-of-the art results for GRID and considerably\noutperform previous approaches on LRW. More importantly, by focusing on\nspectrogram prediction using a simple feedforward model, we can efficiently and\neffectively scale our method to very large and unconstrained datasets: To the\nbest of our knowledge, we are the first to show intelligible results on the\nchallenging LRS3 dataset.", "published": "2022-05-04 13:34:07", "link": "http://arxiv.org/abs/2205.02058v2", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
