{"title": "Comprehensive Event Representations using Event Knowledge Graphs and\n  Natural Language Processing", "abstract": "Recent work has utilised knowledge-aware approaches to natural language\nunderstanding, question answering, recommendation systems, and other tasks.\nThese approaches rely on well-constructed and large-scale knowledge graphs that\ncan be useful for many downstream applications and empower knowledge-aware\nmodels with commonsense reasoning. Such knowledge graphs are constructed\nthrough knowledge acquisition tasks such as relation extraction and knowledge\ngraph completion. This work seeks to utilise and build on the growing body of\nwork that uses findings from the field of natural language processing (NLP) to\nextract knowledge from text and build knowledge graphs. The focus of this\nresearch project is on how we can use transformer-based approaches to extract\nand contextualise event information, matching it to existing ontologies, to\nbuild a comprehensive knowledge of graph-based event representations.\nSpecifically, sub-event extraction is used as a way of creating sub-event-aware\nevent representations. These event representations are then further enriched\nthrough fine-grained location extraction and contextualised through the\nalignment of historically relevant quotes.", "published": "2023-03-08 18:43:39", "link": "http://arxiv.org/abs/2303.04794v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lexical Complexity Prediction: An Overview", "abstract": "The occurrence of unknown words in texts significantly hinders reading\ncomprehension. To improve accessibility for specific target populations,\ncomputational modelling has been applied to identify complex words in texts and\nsubstitute them for simpler alternatives. In this paper, we present an overview\nof computational approaches to lexical complexity prediction focusing on the\nwork carried out on English data. We survey relevant approaches to this problem\nwhich include traditional machine learning classifiers (e.g. SVMs, logistic\nregression) and deep neural networks as well as a variety of features, such as\nthose inspired by literature in psycholinguistics as well as word frequency,\nword length, and many others. Furthermore, we introduce readers to past\ncompetitions and available datasets created on this topic. Finally, we include\nbrief sections on applications of lexical complexity prediction, such as\nreadability and text simplification, together with related studies on languages\nother than English.", "published": "2023-03-08 19:35:08", "link": "http://arxiv.org/abs/2303.04851v1", "categories": ["cs.CL", "A.1"], "primary_category": "cs.CL"}
{"title": "Sample Efficient Multimodal Semantic Augmentation for Incremental\n  Summarization", "abstract": "In this work, we develop a prompting approach for incremental summarization\nof task videos. We develop a sample-efficient few-shot approach for extracting\nsemantic concepts as an intermediate step. We leverage an existing model for\nextracting the concepts from the images and extend it to videos and introduce a\nclustering and querying approach for sample efficiency, motivated by the recent\nadvances in perceiver-based architectures. Our work provides further evidence\nthat an approach with richer input context with relevant entities and actions\nfrom the videos and using these as prompts could enhance the summaries\ngenerated by the model. We show the results on a relevant dataset and discuss\npossible directions for the work.", "published": "2023-03-08 03:58:06", "link": "http://arxiv.org/abs/2303.04361v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Automatically Auditing Large Language Models via Discrete Optimization", "abstract": "Auditing large language models for unexpected behaviors is critical to\npreempt catastrophic deployments, yet remains challenging. In this work, we\ncast auditing as an optimization problem, where we automatically search for\ninput-output pairs that match a desired target behavior. For example, we might\naim to find a non-toxic input that starts with \"Barack Obama\" that a model maps\nto a toxic output. This optimization problem is difficult to solve as the set\nof feasible points is sparse, the space is discrete, and the language models we\naudit are non-linear and high-dimensional. To combat these challenges, we\nintroduce a discrete optimization algorithm, ARCA, that jointly and efficiently\noptimizes over inputs and outputs. Our approach automatically uncovers\nderogatory completions about celebrities (e.g. \"Barack Obama is a legalized\nunborn\" -> \"child murderer\"), produces French inputs that complete to English\noutputs, and finds inputs that generate a specific name. Our work offers a\npromising new tool to uncover models' failure-modes before deployment.", "published": "2023-03-08 05:09:59", "link": "http://arxiv.org/abs/2303.04381v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Query-Utterance Attention with Joint modeling for Query-Focused Meeting\n  Summarization", "abstract": "Query-focused meeting summarization (QFMS) aims to generate summaries from\nmeeting transcripts in response to a given query. Previous works typically\nconcatenate the query with meeting transcripts and implicitly model the query\nrelevance only at the token level with attention mechanism. However, due to the\ndilution of key query-relevant information caused by long meeting transcripts,\nthe original transformer-based model is insufficient to highlight the key parts\nrelated to the query. In this paper, we propose a query-aware framework with\njoint modeling token and utterance based on Query-Utterance Attention. It\ncalculates the utterance-level relevance to the query with a dense retrieval\nmodule. Then both token-level query relevance and utterance-level query\nrelevance are combined and incorporated into the generation process with\nattention mechanism explicitly. We show that the query relevance of different\ngranularities contributes to generating a summary more related to the query.\nExperimental results on the QMSum dataset show that the proposed model achieves\nnew state-of-the-art performance.", "published": "2023-03-08 10:21:45", "link": "http://arxiv.org/abs/2303.04487v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Extending the Pre-Training of BLOOM for Improved Support of Traditional\n  Chinese: Models, Methods and Results", "abstract": "In this paper we present the multilingual language model BLOOM-zh that\nfeatures enhanced support for Traditional Chinese. BLOOM-zh has its origins in\nthe open-source BLOOM models presented by BigScience in 2022. Starting from\nreleased models, we extended the pre-training of BLOOM by additional 7.4\nbillion tokens in Traditional Chinese and English covering a variety of domains\nsuch as news articles, books, encyclopedias, educational materials as well as\nspoken language. In order to show the properties of BLOOM-zh, both existing and\nnewly created benchmark scenarios are used for evaluating the performance.\nBLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks\nwhile maintaining its English capability. We release all our models to the\nresearch community.", "published": "2023-03-08 16:53:19", "link": "http://arxiv.org/abs/2303.04715v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic Detection of Industry Sectors in Legal Articles Using Machine\n  Learning Approaches", "abstract": "The ability to automatically identify industry sector coverage in articles on\nlegal developments, or any kind of news articles for that matter, can bring\nplentiful of benefits both to the readers and the content creators themselves.\nBy having articles tagged based on industry coverage, readers from all around\nthe world would be able to get to legal news that are specific to their region\nand professional industry. Simultaneously, writers would benefit from\nunderstanding which industries potentially lack coverage or which industries\nreaders are currently mostly interested in and thus, they would focus their\nwriting efforts towards more inclusive and relevant legal news coverage. In\nthis paper, a Machine Learning-powered industry analysis approach which\ncombined Natural Language Processing (NLP) with Statistical and Machine\nLearning (ML) techniques was investigated. A dataset consisting of over 1,700\nannotated legal articles was created for the identification of six industry\nsectors. Text and legal based features were extracted from the text. Both\ntraditional ML methods (e.g. gradient boosting machine algorithms, and\ndecision-tree based algorithms) and deep neural network (e.g. transformer\nmodels) were applied for performance comparison of predictive models. The\nsystem achieved promising results with area under the receiver operating\ncharacteristic curve scores above 0.90 and F-scores above 0.81 with respect to\nthe six industry sectors. The experimental results show that the suggested\nautomated industry analysis which employs ML techniques allows the processing\nof large collections of text data in an easy, efficient, and scalable way.\nTraditional ML methods perform better than deep neural networks when only a\nsmall and domain-specific training data is available for the study.", "published": "2023-03-08 12:41:56", "link": "http://arxiv.org/abs/2303.05387v1", "categories": ["cs.CL", "cs.LG", "I.2.6, I.2.7, 68T50, 68T07"], "primary_category": "cs.CL"}
{"title": "FaceChat: An Emotion-Aware Face-to-face Dialogue Framework", "abstract": "While current dialogue systems like ChatGPT have made significant\nadvancements in text-based interactions, they often overlook the potential of\nother modalities in enhancing the overall user experience. We present FaceChat,\na web-based dialogue framework that enables emotionally-sensitive and\nface-to-face conversations. By seamlessly integrating cutting-edge technologies\nin natural language processing, computer vision, and speech processing,\nFaceChat delivers a highly immersive and engaging user experience. FaceChat\nframework has a wide range of potential applications, including counseling,\nemotional support, and personalized customer service. The system is designed to\nbe simple and flexible as a platform for future researchers to advance the\nfield of multimodal dialogue systems. The code is publicly available at\nhttps://github.com/qywu/FaceChat.", "published": "2023-03-08 20:45:37", "link": "http://arxiv.org/abs/2303.07316v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ChatGPT Participates in a Computer Science Exam", "abstract": "We asked ChatGPT to participate in an undergraduate computer science exam on\n''Algorithms and Data Structures''. The program was evaluated on the entire\nexam as posed to the students. We hand-copied its answers onto an exam sheet,\nwhich was subsequently graded in a blind setup alongside those of 200\nparticipating students. We find that ChatGPT narrowly passed the exam,\nobtaining 20.5 out of 40 points. This impressive performance indicates that\nChatGPT can indeed succeed in challenging tasks like university exams. At the\nsame time, the questions in our exam are structurally similar to those of other\nexams, solved homework problems, and teaching materials that can be found\nonline and might have been part of ChatGPT's training data. Therefore, it would\nbe inadequate to conclude from this experiment that ChatGPT has any\nunderstanding of computer science. We also assess the improvements brought by\nGPT-4. We find that GPT-4 would have obtained about 17\\% more exam points than\nGPT-3.5, reaching the performance of the average student. The transcripts of\nour conversations with ChatGPT are available at\n\\url{https://github.com/tml-tuebingen/chatgpt-algorithm-exam}, and the entire\ngraded exam is in the appendix of this paper.", "published": "2023-03-08 15:46:14", "link": "http://arxiv.org/abs/2303.09461v2", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Does Synthetic Data Generation of LLMs Help Clinical Text Mining?", "abstract": "Recent advancements in large language models (LLMs) have led to the\ndevelopment of highly potent models like OpenAI's ChatGPT. These models have\nexhibited exceptional performance in a variety of tasks, such as question\nanswering, essay composition, and code generation. However, their effectiveness\nin the healthcare sector remains uncertain. In this study, we seek to\ninvestigate the potential of ChatGPT to aid in clinical text mining by\nexamining its ability to extract structured information from unstructured\nhealthcare texts, with a focus on biological named entity recognition and\nrelation extraction. However, our preliminary results indicate that employing\nChatGPT directly for these tasks resulted in poor performance and raised\nprivacy concerns associated with uploading patients' information to the ChatGPT\nAPI. To overcome these limitations, we propose a new training paradigm that\ninvolves generating a vast quantity of high-quality synthetic data with labels\nutilizing ChatGPT and fine-tuning a local model for the downstream task. Our\nmethod has resulted in significant improvements in the performance of\ndownstream tasks, improving the F1-score from 23.37% to 63.99% for the named\nentity recognition task and from 75.86% to 83.59% for the relation extraction\ntask. Furthermore, generating data using ChatGPT can significantly reduce the\ntime and effort required for data collection and labeling, as well as mitigate\ndata privacy concerns. In summary, the proposed framework presents a promising\nsolution to enhance the applicability of LLM models to clinical text mining.", "published": "2023-03-08 03:56:31", "link": "http://arxiv.org/abs/2303.04360v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NASTyLinker: NIL-Aware Scalable Transformer-based Entity Linker", "abstract": "Entity Linking (EL) is the task of detecting mentions of entities in text and\ndisambiguating them to a reference knowledge base. Most prevalent EL approaches\nassume that the reference knowledge base is complete. In practice, however, it\nis necessary to deal with the case of linking to an entity that is not\ncontained in the knowledge base (NIL entity). Recent works have shown that,\ninstead of focusing only on affinities between mentions and entities,\nconsidering inter-mention affinities can be used to represent NIL entities by\nproducing clusters of mentions. At the same time, inter-mention affinities can\nhelp to substantially improve linking performance for known entities. With\nNASTyLinker, we introduce an EL approach that is aware of NIL entities and\nproduces corresponding mention clusters while maintaining high linking\nperformance for known entities. The approach clusters mentions and entities\nbased on dense representations from Transformers and resolves conflicts (if\nmore than one entity is assigned to a cluster) by computing transitive\nmention-entity affinities. We show the effectiveness and scalability of\nNASTyLinker on NILK, a dataset that is explicitly constructed to evaluate EL\nwith respect to NIL entities. Further, we apply the presented approach to an\nactual EL task, namely to knowledge graph population by linking entities in\nWikipedia listings, and provide an analysis of the outcome.", "published": "2023-03-08 08:08:57", "link": "http://arxiv.org/abs/2303.04426v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "MenuCraft: Interactive Menu System Design with Large Language Models", "abstract": "Menu system design for user interfaces is a challenging task involving many\ndesign options and various human factors. For example, one crucial factor that\ndesigners need to consider is the semantic and systematic relation of menu\ncommands. However, capturing these relations can be challenging due to limited\navailable resources. Large language models can be helpful in this regard, using\ntheir pre-training knowledge to design and refine menu systems. In this paper,\nwe propose MenuCraft, an AI-assisted designer for menu design that enables\ncollaboration between the designer and a dialogue system to design menus.\nMenuCraft offers an interactive language-based menu design tool that simplifies\nthe menu design process and enables easy customization of design options.\nMenuCraft supports a variety of interactions through dialog that allows\nperforming in-context learning.", "published": "2023-03-08 10:39:38", "link": "http://arxiv.org/abs/2303.04496v3", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Models of symbol emergence in communication: a conceptual review and a\n  guide for avoiding local minima", "abstract": "Computational simulations are a popular method for testing hypotheses about\nthe emergence of communication. This kind of research is performed in a variety\nof traditions including language evolution, developmental psychology, cognitive\nscience, machine learning, robotics, etc. The motivations for the models are\ndifferent, but the operationalizations and methods used are often similar. We\nidentify the assumptions and explanatory targets of several most representative\nmodels and summarise the known results. We claim that some of the assumptions\n-- such as portraying meaning in terms of mapping, focusing on the descriptive\nfunction of communication, modelling signals with amodal tokens -- may hinder\nthe success of modelling. Relaxing these assumptions and foregrounding the\ninteractions of embodied and situated agents allows one to systematise the\nmultiplicity of pressures under which symbolic systems evolve. In line with\nthis perspective, we sketch the road towards modelling the emergence of\nmeaningful symbolic communication, where symbols are simultaneously grounded in\naction and perception and form an abstract system.", "published": "2023-03-08 12:53:03", "link": "http://arxiv.org/abs/2303.04544v1", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Extrapolative Controlled Sequence Generation via Iterative Refinement", "abstract": "We study the problem of extrapolative controlled generation, i.e., generating\nsequences with attribute values beyond the range seen in training. This task is\nof significant importance in automated design, especially drug discovery, where\nthe goal is to design novel proteins that are \\textit{better} (e.g., more\nstable) than existing sequences. Thus, by definition, the target sequences and\ntheir attribute values are out of the training distribution, posing challenges\nto existing methods that aim to directly generate the target sequence. Instead,\nin this work, we propose Iterative Controlled Extrapolation (ICE) which\niteratively makes local edits to a sequence to enable extrapolation. We train\nthe model on synthetically generated sequence pairs that demonstrate small\nimprovement in the attribute value. Results on one natural language task\n(sentiment analysis) and two protein engineering tasks (ACE2 stability and AAV\nfitness) show that ICE considerably outperforms state-of-the-art approaches\ndespite its simplicity. Our code and models are available at:\nhttps://github.com/vishakhpk/iter-extrapolation.", "published": "2023-03-08 13:21:27", "link": "http://arxiv.org/abs/2303.04562v3", "categories": ["cs.LG", "cs.CL", "q-bio.QM"], "primary_category": "cs.LG"}
{"title": "Cost-Effective Hyperparameter Optimization for Large Language Model\n  Generation Inference", "abstract": "Large Language Models (LLMs) have sparked significant interest in their\ngenerative capabilities, leading to the development of various commercial\napplications. The high cost of using the models drives application builders to\nmaximize the value of generation under a limited inference budget. This paper\npresents a study of optimizing inference hyperparameters such as the number of\nresponses, temperature and max tokens, which significantly affects the\nutility/cost of text generation. We design a framework named EcoOptiGen which\nleverages economical hyperparameter optimization and cost-based pruning.\nExperiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its\neffectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML\nlibrary: \\url{https://aka.ms/autogen}.", "published": "2023-03-08 15:52:14", "link": "http://arxiv.org/abs/2303.04673v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-contained Beta-with-Spikes Approximation for Inference Under a\n  Wright-Fisher Model", "abstract": "We construct a reliable estimation of evolutionary parameters within the\nWright-Fisher model, which describes changes in allele frequencies due to\nselection and genetic drift, from time-series data. Such data exists for\nbiological populations, for example via artificial evolution experiments, and\nfor the cultural evolution of behavior, such as linguistic corpora that\ndocument historical usage of different words with similar meanings. Our method\nof analysis builds on a Beta-with-Spikes approximation to the distribution of\nallele frequencies predicted by the Wright-Fisher model. We introduce a\nself-contained scheme for estimating the parameters in the approximation, and\ndemonstrate its robustness with synthetic data, especially in the\nstrong-selection and near-extinction regimes where previous approaches fail. We\nfurther apply to allele frequency data for baker's yeast (Saccharomyces\ncerevisiae), finding a significant signal of selection in cases where\nindependent evidence supports such a conclusion. We further demonstrate the\npossibility of detecting time-points at which evolutionary parameters change in\nthe context of a historical spelling reform in the Spanish language.", "published": "2023-03-08 16:32:10", "link": "http://arxiv.org/abs/2303.04691v2", "categories": ["q-bio.PE", "cond-mat.stat-mech", "cs.CL"], "primary_category": "q-bio.PE"}
{"title": "Stealing the Decoding Algorithms of Language Models", "abstract": "A key component of generating text from modern language models (LM) is the\nselection and tuning of decoding algorithms. These algorithms determine how to\ngenerate text from the internal probability distribution generated by the LM.\nThe process of choosing a decoding algorithm and tuning its hyperparameters\ntakes significant time, manual effort, and computation, and it also requires\nextensive human evaluation. Therefore, the identity and hyperparameters of such\ndecoding algorithms are considered to be extremely valuable to their owners. In\nthis work, we show, for the first time, that an adversary with typical API\naccess to an LM can steal the type and hyperparameters of its decoding\nalgorithms at very low monetary costs. Our attack is effective against popular\nLMs used in text generation APIs, including GPT-2, GPT-3 and GPT-Neo. We\ndemonstrate the feasibility of stealing such information with only a few\ndollars, e.g., $\\$0.8$, $\\$1$, $\\$4$, and $\\$40$ for the four versions of\nGPT-3.", "published": "2023-03-08 17:15:58", "link": "http://arxiv.org/abs/2303.04729v4", "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "The Casual Conversations v2 Dataset", "abstract": "This paper introduces a new large consent-driven dataset aimed at assisting\nin the evaluation of algorithmic bias and robustness of computer vision and\naudio speech models in regards to 11 attributes that are self-provided or\nlabeled by trained annotators. The dataset includes 26,467 videos of 5,567\nunique paid participants, with an average of almost 5 videos per person,\nrecorded in Brazil, India, Indonesia, Mexico, Vietnam, Philippines, and the\nUSA, representing diverse demographic characteristics. The participants agreed\nfor their data to be used in assessing fairness of AI models and provided\nself-reported age, gender, language/dialect, disability status, physical\nadornments, physical attributes and geo-location information, while trained\nannotators labeled apparent skin tone using the Fitzpatrick Skin Type and Monk\nSkin Tone scales, and voice timbre. Annotators also labeled for different\nrecording setups and per-second activity annotations.", "published": "2023-03-08 19:17:05", "link": "http://arxiv.org/abs/2303.04838v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.CV"}
{"title": "disco: a toolkit for Distributional Control of Generative Models", "abstract": "Pre-trained language models and other generative models have revolutionized\nNLP and beyond. However, these models tend to reproduce undesirable biases\npresent in their training data. Also, they may overlook patterns that are\nimportant but challenging to capture. To address these limitations, researchers\nhave introduced distributional control techniques. These techniques, not\nlimited to language, allow controlling the prevalence (i.e., expectations) of\nany features of interest in the model's outputs. Despite their potential, the\nwidespread adoption of these techniques has been hindered by the difficulty in\nadapting complex, disconnected code. Here, we present disco, an open-source\nPython library that brings these techniques to the broader public.", "published": "2023-03-08 18:58:52", "link": "http://arxiv.org/abs/2303.05431v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Comparing Trajectory and Vision Modalities for Verb Representation", "abstract": "Three-dimensional trajectories, or the 3D position and rotation of objects\nover time, have been shown to encode key aspects of verb semantics (e.g., the\nmeanings of roll vs. slide). However, most multimodal models in NLP use 2D\nimages as representations of the world. Given the importance of 3D space in\nformal models of verb semantics, we expect that these 2D images would result in\nimpoverished representations that fail to capture nuanced differences in\nmeaning. This paper tests this hypothesis directly in controlled experiments.\nWe train self-supervised image and trajectory encoders, and then evaluate them\non the extent to which each learns to differentiate verb concepts. Contrary to\nour initial expectations, we find that 2D visual modalities perform similarly\nwell to 3D trajectories. While further work should be conducted on this\nquestion, our initial findings challenge the conventional wisdom that richer\nenvironment representations necessarily translate into better representation\nlearning for language.", "published": "2023-03-08 20:32:42", "link": "http://arxiv.org/abs/2303.12737v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "68T50"], "primary_category": "cs.CV"}
{"title": "Student's t-Distribution: On Measuring the Inter-Rater Reliability When\n  the Observations are Scarce", "abstract": "In natural language processing (NLP) we always rely on human judgement as the\ngolden quality evaluation method. However, there has been an ongoing debate on\nhow to better evaluate inter-rater reliability (IRR) levels for certain\nevaluation tasks, such as translation quality evaluation (TQE), especially when\nthe data samples (observations) are very scarce. In this work, we first\nintroduce the study on how to estimate the confidence interval for the\nmeasurement value when only one data (evaluation) point is available. Then,\nthis leads to our example with two human-generated observational scores, for\nwhich, we introduce ``Student's \\textit{t}-Distribution'' method and explain\nhow to use it to measure the IRR score using only these two data points, as\nwell as the confidence intervals (CIs) of the quality evaluation. We give\nquantitative analysis on how the evaluation confidence can be greatly improved\nby introducing more observations, even if only one extra observation. We\nencourage researchers to report their IRR scores in all possible means, e.g.\nusing Student's \\textit{t}-Distribution method whenever possible; thus making\nthe NLP evaluation more meaningful, transparent, and trustworthy. This\n\\textit{t}-Distribution method can be also used outside of NLP fields to\nmeasure IRR level for trustworthy evaluation of experimental investigations,\nwhenever the observational data is scarce.\n  Keywords: Inter-Rater Reliability (IRR); Scarce Observations; Confidence\nIntervals (CIs); Natural Language Processing (NLP); Translation Quality\nEvaluation (TQE); Student's \\textit{t}-Distribution", "published": "2023-03-08 11:51:26", "link": "http://arxiv.org/abs/2303.04526v2", "categories": ["cs.CL", "cs.IT", "cs.NA", "math.IT", "math.NA", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Onsets and Velocities: Affordable Real-Time Piano Transcription Using\n  Convolutional Neural Networks", "abstract": "Polyphonic Piano Transcription has recently experienced substantial progress,\ndriven by the use of sophisticated Deep Learning approaches and the\nintroduction of new subtasks such as note onset, offset, velocity and pedal\ndetection. This progress was coupled with an increased complexity and size of\nthe proposed models, typically relying on non-realtime components and\nhigh-resolution data. In this work we focus on onset and velocity detection,\nshowing that a substantially smaller and simpler convolutional approach, using\nlower temporal resolution (24ms), is still competitive: our proposed\nONSETS&VELOCITIES model achieves state-of-the-art performance on the MAESTRO\ndataset for onset detection (F1=96.78%) and sets a good novel baseline for\nonset+velocity (F1=94.50%), while having ~3.1M parameters and maintaining\nreal-time capabilities on modest commodity hardware. We provide open-source\ncode to reproduce our results and a real-time demo with a pretrained model.", "published": "2023-03-08 10:17:27", "link": "http://arxiv.org/abs/2303.04485v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Light Weight Model for Active Speaker Detection", "abstract": "Active speaker detection is a challenging task in audio-visual scenario\nunderstanding, which aims to detect who is speaking in one or more speakers\nscenarios. This task has received extensive attention as it is crucial in\napplications such as speaker diarization, speaker tracking, and automatic video\nediting. The existing studies try to improve performance by inputting multiple\ncandidate information and designing complex models. Although these methods\nachieved outstanding performance, their high consumption of memory and\ncomputational power make them difficult to be applied in resource-limited\nscenarios. Therefore, we construct a lightweight active speaker detection\narchitecture by reducing input candidates, splitting 2D and 3D convolutions for\naudio-visual feature extraction, and applying gated recurrent unit (GRU) with\nlow computational complexity for cross-modal modeling. Experimental results on\nthe AVA-ActiveSpeaker dataset show that our framework achieves competitive mAP\nperformance (94.1% vs. 94.2%), while the resource costs are significantly lower\nthan the state-of-the-art method, especially in model parameters (1.0M vs.\n22.5M, about 23x) and FLOPs (0.6G vs. 2.6G, about 4x). In addition, our\nframework also performs well on the Columbia dataset showing good robustness.\nThe code and model weights are available at\nhttps://github.com/Junhua-Liao/Light-ASD.", "published": "2023-03-08 08:40:56", "link": "http://arxiv.org/abs/2303.04439v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Exploring Efficient-Tuned Learning Audio Representation Method from\n  BriVL", "abstract": "Recently, researchers have gradually realized that in some cases, the\nself-supervised pre-training on large-scale Internet data is better than that\nof high-quality/manually labeled data sets, and multimodal/large models are\nbetter than single or bimodal/small models. In this paper, we propose a robust\naudio representation learning method WavBriVL based on\nBridging-Vision-and-Language (BriVL). WavBriVL projects audio, image and text\ninto a shared embedded space, so that multi-modal applications can be realized.\nWe demonstrate the qualitative evaluation of the image generated from WavBriVL\nas a shared embedded space, with the main purposes of this paper:(1) Learning\nthe correlation between audio and image;(2) Explore a new way of image\ngeneration, that is, use audio to generate pictures. Experimental results show\nthat this method can effectively generate appropriate images from audio.", "published": "2023-03-08 13:58:55", "link": "http://arxiv.org/abs/2303.04585v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TOLD: A Novel Two-Stage Overlap-Aware Framework for Speaker Diarization", "abstract": "Recently, end-to-end neural diarization (EEND) is introduced and achieves\npromising results in speaker-overlapped scenarios. In EEND, speaker diarization\nis formulated as a multi-label prediction problem, where speaker activities are\nestimated independently and their dependency are not well considered. To\novercome these disadvantages, we employ the power set encoding to reformulate\nspeaker diarization as a single-label classification problem and propose the\noverlap-aware EEND (EEND-OLA) model, in which speaker overlaps and dependency\ncan be modeled explicitly. Inspired by the success of two-stage hybrid systems,\nwe further propose a novel Two-stage OverLap-aware Diarization framework (TOLD)\nby involving a speaker overlap-aware post-processing (SOAP) model to\niteratively refine the diarization results of EEND-OLA. Experimental results\nshow that, compared with the original EEND, the proposed EEND-OLA achieves a\n14.39% relative improvement in terms of diarization error rates (DER), and\nutilizing SOAP provides another 19.33% relative improvement. As a result, our\nmethod TOLD achieves a DER of 10.14% on the CALLHOME dataset, which is a new\nstate-of-the-art result on this benchmark to the best of our knowledge.", "published": "2023-03-08 05:05:26", "link": "http://arxiv.org/abs/2303.05397v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
