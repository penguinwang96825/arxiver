{"title": "Studio Ousia's Quiz Bowl Question Answering System", "abstract": "In this chapter, we describe our question answering system, which was the\nwinning system at the Human-Computer Question Answering (HCQA) Competition at\nthe Thirty-first Annual Conference on Neural Information Processing Systems\n(NIPS). The competition requires participants to address a factoid question\nanswering task referred to as quiz bowl. To address this task, we use two novel\nneural network models and combine these models with conventional information\nretrieval models using a supervised machine learning model. Our system achieved\nthe best performance among the systems submitted in the competition and won a\nmatch against six top human quiz experts by a wide margin.", "published": "2018-03-23 04:15:07", "link": "http://arxiv.org/abs/1803.08652v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stance Detection on Tweets: An SVM-based Approach", "abstract": "Stance detection is a subproblem of sentiment analysis where the stance of\nthe author of a piece of natural language text for a particular target (either\nexplicitly stated in the text or not) is explored. The stance output is usually\ngiven as Favor, Against, or Neither. In this paper, we target at stance\ndetection on sports-related tweets and present the performance results of our\nSVM-based stance classifiers on such tweets. First, we describe three versions\nof our proprietary tweet data set annotated with stance information, all of\nwhich are made publicly available for research purposes. Next, we evaluate SVM\nclassifiers using different feature sets for stance detection on this data set.\nThe employed features are based on unigrams, bigrams, hashtags, external links,\nemoticons, and lastly, named entities. The results indicate that joint use of\nthe features based on unigrams, hashtags, and named entities by SVM classifiers\nis a plausible approach for stance detection problem on sports-related tweets.", "published": "2018-03-23 17:49:04", "link": "http://arxiv.org/abs/1803.08910v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speech2Vec: A Sequence-to-Sequence Framework for Learning Word\n  Embeddings from Speech", "abstract": "In this paper, we propose a novel deep neural network architecture,\nSpeech2Vec, for learning fixed-length vector representations of audio segments\nexcised from a speech corpus, where the vectors contain semantic information\npertaining to the underlying spoken words, and are close to other vectors in\nthe embedding space if their corresponding underlying spoken words are\nsemantically similar. The proposed model can be viewed as a speech version of\nWord2Vec. Its design is based on a RNN Encoder-Decoder framework, and borrows\nthe methodology of skipgrams or continuous bag-of-words for training. Learning\nword embeddings directly from speech enables Speech2Vec to make use of the\nsemantic information carried by speech that does not exist in plain text. The\nlearned word embeddings are evaluated and analyzed on 13 widely used word\nsimilarity benchmarks, and outperform word embeddings learned by Word2Vec from\nthe transcriptions.", "published": "2018-03-23 20:59:09", "link": "http://arxiv.org/abs/1803.08976v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging translations for speech transcription in low-resource\n  settings", "abstract": "Recently proposed data collection frameworks for endangered language\ndocumentation aim not only to collect speech in the language of interest, but\nalso to collect translations into a high-resource language that will render the\ncollected resource interpretable. We focus on this scenario and explore whether\nwe can improve transcription quality under these extremely low-resource\nsettings with the assistance of text translations. We present a neural\nmulti-source model and evaluate several variations of it on three low-resource\ndatasets. We find that our multi-source model with shared attention outperforms\nthe baselines, reducing transcription character error rate by up to 12.3%.", "published": "2018-03-23 21:56:54", "link": "http://arxiv.org/abs/1803.08991v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Keyphrase Extraction with Multipartite Graphs", "abstract": "We propose an unsupervised keyphrase extraction model that encodes topical\ninformation within a multipartite graph structure. Our model represents\nkeyphrase candidates and topics in a single graph and exploits their mutually\nreinforcing relationship to improve candidate ranking. We further introduce a\nnovel mechanism to incorporate keyphrase selection preferences into the model.\nExperiments conducted on three widely used datasets show significant\nimprovements over state-of-the-art graph-based models.", "published": "2018-03-23 10:35:42", "link": "http://arxiv.org/abs/1803.08721v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Multilingual bottleneck features for subword modeling in zero-resource\n  languages", "abstract": "How can we effectively develop speech technology for languages where no\ntranscribed data is available? Many existing approaches use no annotated\nresources at all, yet it makes sense to leverage information from large\nannotated corpora in other languages, for example in the form of multilingual\nbottleneck features (BNFs) obtained from a supervised speech recognition\nsystem. In this work, we evaluate the benefits of BNFs for subword modeling\n(feature extraction) in six unseen languages on a word discrimination task.\nFirst we establish a strong unsupervised baseline by combining two existing\nmethods: vocal tract length normalisation (VTLN) and the correspondence\nautoencoder (cAE). We then show that BNFs trained on a single language already\nbeat this baseline; including up to 10 languages results in additional\nimprovements which cannot be matched by just adding more data from a single\nlanguage. Finally, we show that the cAE can improve further on the BNFs if\nhigh-quality same-word pairs are available.", "published": "2018-03-23 16:18:27", "link": "http://arxiv.org/abs/1803.08863v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Explicit Reasoning over End-to-End Neural Architectures for Visual\n  Question Answering", "abstract": "Many vision and language tasks require commonsense reasoning beyond\ndata-driven image and natural language processing. Here we adopt Visual\nQuestion Answering (VQA) as an example task, where a system is expected to\nanswer a question in natural language about an image. Current state-of-the-art\nsystems attempted to solve the task using deep neural architectures and\nachieved promising performance. However, the resulting systems are generally\nopaque and they struggle in understanding questions for which extra knowledge\nis required. In this paper, we present an explicit reasoning layer on top of a\nset of penultimate neural network based systems. The reasoning layer enables\nreasoning and answering questions where additional knowledge is required, and\nat the same time provides an interpretable interface to the end users.\nSpecifically, the reasoning layer adopts a Probabilistic Soft Logic (PSL) based\nengine to reason over a basket of inputs: visual relations, the semantic parse\nof the question, and background ontological knowledge from word2vec and\nConceptNet. Experimental analysis of the answers and the key evidential\npredicates generated on the VQA dataset validate our approach.", "published": "2018-03-23 17:17:16", "link": "http://arxiv.org/abs/1803.08896v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Automated Evaluation of Out-of-Context Errors", "abstract": "We present a new approach to evaluate computational models for the task of\ntext understanding by the means of out-of-context error detection. Through the\nnovel design of our automated modification process, existing large-scale data\nsources can be adopted for a vast number of text understanding tasks. The data\nis thereby altered on a semantic level, allowing models to be tested against a\nchallenging set of modified text passages that require to comprise a broader\nnarrative discourse. Our newly introduced task targets actual real-world\nproblems of transcription and translation systems by inserting authentic\nout-of-context errors. The automated modification process is applied to the\n2016 TEDTalk corpus. Entirely automating the process allows the adoption of\ncomplete datasets at low cost, facilitating supervised learning procedures and\ndeeper networks to be trained and tested. To evaluate the quality of the\nmodification algorithm a language model and a supervised binary classification\nmodel are trained and tested on the altered dataset. A human baseline\nevaluation is examined to compare the results with human performance. The\noutcome of the evaluation task indicates the difficulty to detect semantic\nerrors for machine-learning algorithms and humans, showing that the errors\ncannot be identified when limited to a single sentence.", "published": "2018-03-23 21:20:00", "link": "http://arxiv.org/abs/1803.08983v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WikiRank: Improving Keyphrase Extraction Based on Background Knowledge", "abstract": "Keyphrase is an efficient representation of the main idea of documents. While\nbackground knowledge can provide valuable information about documents, they are\nrarely incorporated in keyphrase extraction methods. In this paper, we propose\nWikiRank, an unsupervised method for keyphrase extraction based on the\nbackground knowledge from Wikipedia. Firstly, we construct a semantic graph for\nthe document. Then we transform the keyphrase extraction problem into an\noptimization problem on the graph. Finally, we get the optimal keyphrase set to\nbe the output. Our method obtains improvements over other state-of-art models\nby more than 2% in F1-score.", "published": "2018-03-23 22:30:58", "link": "http://arxiv.org/abs/1803.09000v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "On the difficulty of a distributional semantics of spoken language", "abstract": "In the domain of unsupervised learning most work on speech has focused on\ndiscovering low-level constructs such as phoneme inventories or word-like\nunits. In contrast, for written language, where there is a large body of work\non unsupervised induction of semantic representations of words, whole sentences\nand longer texts. In this study we examine the challenges of adapting these\napproaches from written to spoken language. We conjecture that unsupervised\nlearning of the semantics of spoken language becomes feasible if we abstract\nfrom the surface variability. We simulate this setting with a dataset of\nutterances spoken by a realistic but uniform synthetic voice. We evaluate two\nsimple unsupervised models which, to varying degrees of success, learn semantic\nrepresentations of speech fragments. Finally we present inconclusive results on\nhuman speech, and discuss the challenges inherent in learning distributional\nsemantic representations on unrestricted natural spoken language.", "published": "2018-03-23 16:30:06", "link": "http://arxiv.org/abs/1803.08869v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Counterexamples for Robotic Planning Explained in Structured Language", "abstract": "Automated techniques such as model checking have been used to verify models\nof robotic mission plans based on Markov decision processes (MDPs) and generate\ncounterexamples that may help diagnose requirement violations. However, such\nartifacts may be too complex for humans to understand, because existing\nrepresentations of counterexamples typically include a large number of paths or\na complex automaton. To help improve the interpretability of counterexamples,\nwe define a notion of explainable counterexample, which includes a set of\nstructured natural language sentences to describe the robotic behavior that\nlead to a requirement violation in an MDP model of robotic mission plan. We\npropose an approach based on mixed-integer linear programming for generating\nexplainable counterexamples that are minimal, sound and complete. We\ndemonstrate the usefulness of the proposed approach via a case study of\nwarehouse robots planning.", "published": "2018-03-23 20:14:51", "link": "http://arxiv.org/abs/1803.08966v1", "categories": ["cs.RO", "cs.CL", "cs.FL"], "primary_category": "cs.RO"}
{"title": "Style Tokens: Unsupervised Style Modeling, Control and Transfer in\n  End-to-End Speech Synthesis", "abstract": "In this work, we propose \"global style tokens\" (GSTs), a bank of embeddings\nthat are jointly trained within Tacotron, a state-of-the-art end-to-end speech\nsynthesis system. The embeddings are trained with no explicit labels, yet learn\nto model a large range of acoustic expressiveness. GSTs lead to a rich set of\nsignificant results. The soft interpretable \"labels\" they generate can be used\nto control synthesis in novel ways, such as varying speed and speaking style -\nindependently of the text content. They can also be used for style transfer,\nreplicating the speaking style of a single audio clip across an entire\nlong-form text corpus. When trained on noisy, unlabeled found data, GSTs learn\nto factorize noise and speaker identity, providing a path towards highly\nscalable but robust speech synthesis.", "published": "2018-03-23 23:56:49", "link": "http://arxiv.org/abs/1803.09017v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Exploring the robustness of features and enhancement on speech\n  recognition systems in highly-reverberant real environments", "abstract": "This paper evaluates the robustness of a DNN-HMM-based speech recognition\nsystem in highly-reverberant real environments using the HRRE database. The\nperformance of locally-normalized filter bank (LNFB) and Mel filter bank\n(MelFB) features in combination with Non-negative Matrix Factorization (NMF),\nSuppression of Slowly-varying components and the Falling edge (SSF) and\nWeighted Prediction Error (WPE) enhancement methods are discussed and\nevaluated. Two training conditions were considered: clean and reverberated\n(Reverb). With Reverb training the use of WPE and LNFB provides WERs that are\n3% and 20% lower in average than SSF and NMF, respectively. WPE and MelFB\nprovides WERs that are 11% and 24% lower in average than SSF and NMF,\nrespectively. With clean training, which represents a significant mismatch\nbetween testing and training conditions, LNFB features clearly outperform MelFB\nfeatures. The results show that different types of training, parametrization,\nand enhancement techniques may work better for a specific combination of\nspeaker-microphone distance and reverberation time. This suggests that there\ncould be some degree of complementarity between systems trained with different\nenhancement and parametrization methods.", "published": "2018-03-23 23:31:25", "link": "http://arxiv.org/abs/1803.09013v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An improved DNN-based spectral feature mapping that removes noise and\n  reverberation for robust automatic speech recognition", "abstract": "Reverberation and additive noise have detrimental effects on the performance\nof automatic speech recognition systems. In this paper we explore the ability\nof a DNN-based spectral feature mapping to remove the effects of reverberation\nand additive noise. Experiments with the CHiME-2 database show that this DNN\ncan achieve an average reduction in WER of 4.5%, when compared to the baseline\nsystem, at SNRs equal to -6 dB, -3 dB, 0 dB and 3 dB, and just 0.8% at greater\nSNRs of 6 dB and 9 dB. These results suggest that this DNN is more effective in\nremoving additive noise than reverberation. To improve the DNN performance, we\ncombine it with the weighted prediction error (WPE) method that shows a\ncomplementary behavior. While this combination provided a reduction in WER of\napproximately 11% when compared with the baseline, the observed improvement is\nnot as great as that obtained using WPE alone. However, modifications to the\nDNN training process were applied and an average reduction in WER equal to\n18.3% was achieved when compared with the baseline system. Furthermore, the\nimproved DNN combined with WPE achieves a reduction in WER of 7.9% when\ncompared with WPE alone.", "published": "2018-03-23 23:46:34", "link": "http://arxiv.org/abs/1803.09016v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
