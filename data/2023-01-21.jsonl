{"title": "Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL\n  Robustness", "abstract": "Neural text-to-SQL models have achieved remarkable performance in translating\nnatural language questions into SQL queries. However, recent studies reveal\nthat text-to-SQL models are vulnerable to task-specific perturbations. Previous\ncurated robustness test sets usually focus on individual phenomena. In this\npaper, we propose a comprehensive robustness benchmark based on Spider, a\ncross-domain text-to-SQL benchmark, to diagnose the model robustness. We design\n17 perturbations on databases, natural language questions, and SQL queries to\nmeasure the robustness from different angles. In order to collect more\ndiversified natural question perturbations, we utilize large pretrained\nlanguage models (PLMs) to simulate human behaviors in creating natural\nquestions. We conduct a diagnostic study of the state-of-the-art models on the\nrobustness set. Experimental results reveal that even the most robust model\nsuffers from a 14.0% performance drop overall and a 50.7% performance drop on\nthe most challenging perturbation. We also present a breakdown analysis\nregarding text-to-SQL model designs and provide insights for improving model\nrobustness.", "published": "2023-01-21 03:57:18", "link": "http://arxiv.org/abs/2301.08881v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unifying Structure Reasoning and Language Model Pre-training for Complex\n  Reasoning", "abstract": "Recent pre-trained language models (PLMs) equipped with foundation reasoning\nskills have shown remarkable performance on downstream complex tasks. However,\nthe significant structure reasoning skill has been rarely studied, which\ninvolves modeling implicit structure information within the text and performing\nexplicit logical reasoning over them to deduce the conclusion. This paper\nproposes a unified learning framework that combines explicit structure\nreasoning and language pre-training to endow PLMs with the structure reasoning\nskill. It first identifies several elementary structures within contexts to\nconstruct structured queries and performs step-by-step reasoning along the\nqueries to identify the answer entity. The fusion of textual semantics and\nstructure reasoning is achieved by using contextual representations learned by\nPLMs to initialize the representation space of structures, and performing\nstepwise reasoning on this semantic representation space. Experimental results\non four datasets demonstrate that the proposed model achieves significant\nimprovements in complex reasoning tasks involving diverse structures, and shows\ntransferability to downstream tasks with limited training data and\neffectiveness for complex reasoning of KGs modality.", "published": "2023-01-21 08:18:11", "link": "http://arxiv.org/abs/2301.08913v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ExClaim: Explainable Neural Claim Verification Using Rationalization", "abstract": "With the advent of deep learning, text generation language models have\nimproved dramatically, with text at a similar level as human-written text. This\ncan lead to rampant misinformation because content can now be created cheaply\nand distributed quickly. Automated claim verification methods exist to validate\nclaims, but they lack foundational data and often use mainstream news as\nevidence sources that are strongly biased towards a specific agenda. Current\nclaim verification methods use deep neural network models and complex\nalgorithms for a high classification accuracy but it is at the expense of model\nexplainability. The models are black-boxes and their decision-making process\nand the steps it took to arrive at a final prediction are obfuscated from the\nuser. We introduce a novel claim verification approach, namely: ExClaim, that\nattempts to provide an explainable claim verification system with foundational\nevidence. Inspired by the legal system, ExClaim leverages rationalization to\nprovide a verdict for the claim and justifies the verdict through a natural\nlanguage explanation (rationale) to describe the model's decision-making\nprocess. ExClaim treats the verdict classification task as a question-answer\nproblem and achieves a performance of 0.93 F1 score. It provides subtasks\nexplanations to also justify the intermediate outcomes. Statistical and\nExplainable AI (XAI) evaluations are conducted to ensure valid and trustworthy\noutcomes. Ensuring claim verification systems are assured, rational, and\nexplainable is an essential step toward improving Human-AI trust and the\naccessibility of black-box systems.", "published": "2023-01-21 08:26:27", "link": "http://arxiv.org/abs/2301.08914v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "REDAffectiveLM: Leveraging Affect Enriched Embedding and\n  Transformer-based Neural Language Model for Readers' Emotion Detection", "abstract": "Technological advancements in web platforms allow people to express and share\nemotions towards textual write-ups written and shared by others. This brings\nabout different interesting domains for analysis; emotion expressed by the\nwriter and emotion elicited from the readers. In this paper, we propose a novel\napproach for Readers' Emotion Detection from short-text documents using a deep\nlearning model called REDAffectiveLM. Within state-of-the-art NLP tasks, it is\nwell understood that utilizing context-specific representations from\ntransformer-based pre-trained language models helps achieve improved\nperformance. Within this affective computing task, we explore how incorporating\naffective information can further enhance performance. Towards this, we\nleverage context-specific and affect enriched representations by using a\ntransformer-based pre-trained language model in tandem with affect enriched\nBi-LSTM+Attention. For empirical evaluation, we procure a new dataset REN-20k,\nbesides using RENh-4k and SemEval-2007. We evaluate the performance of our\nREDAffectiveLM rigorously across these datasets, against a vast set of\nstate-of-the-art baselines, where our model consistently outperforms baselines\nand obtains statistically significant results. Our results establish that\nutilizing affect enriched representation along with context-specific\nrepresentation within a neural architecture can considerably enhance readers'\nemotion detection. Since the impact of affect enrichment specifically in\nreaders' emotion detection isn't well explored, we conduct a detailed analysis\nover affect enriched Bi-LSTM+Attention using qualitative and quantitative model\nbehavior evaluation techniques. We observe that compared to conventional\nsemantic embedding, affect enriched embedding increases ability of the network\nto effectively identify and assign weightage to key terms responsible for\nreaders' emotion detection.", "published": "2023-01-21 19:28:25", "link": "http://arxiv.org/abs/2301.08995v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntax-guided Neural Module Distillation to Probe Compositionality in\n  Sentence Embeddings", "abstract": "Past work probing compositionality in sentence embedding models faces issues\ndetermining the causal impact of implicit syntax representations. Given a\nsentence, we construct a neural module net based on its syntax parse and train\nit end-to-end to approximate the sentence's embedding generated by a\ntransformer model. The distillability of a transformer to a Syntactic NeurAl\nModule Net (SynNaMoN) then captures whether syntax is a strong causal model of\nits compositional ability. Furthermore, we address questions about the geometry\nof semantic composition by specifying individual SynNaMoN modules' internal\narchitecture & linearity. We find differences in the distillability of various\nsentence embedding models that broadly correlate with their performance, but\nobserve that distillability doesn't considerably vary by model size. We also\npresent preliminary evidence that much syntax-guided composition in sentence\nembedding models is linear, and that non-linearities may serve primarily to\nhandle non-compositional phrases.", "published": "2023-01-21 19:42:02", "link": "http://arxiv.org/abs/2301.08998v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics\n  Without the Reference", "abstract": "Machine translation quality estimation (QE) predicts human judgements of a\ntranslation hypothesis without seeing the reference. State-of-the-art QE\nsystems based on pretrained language models have been achieving remarkable\ncorrelations with human judgements yet they are computationally heavy and\nrequire human annotations, which are slow and expensive to create. To address\nthese limitations, we define the problem of metric estimation (ME) where one\npredicts the automated metric scores also without the reference. We show that\neven without access to the reference, our model can estimate automated metrics\n($\\rho$=60% for BLEU, $\\rho$=51% for other metrics) at the sentence-level.\nBecause automated metrics correlate with human judgements, we can leverage the\nME task for pre-training a QE model. For the QE task, we find that pre-training\non TER is better ($\\rho$=23%) than training for scratch ($\\rho$=20%).", "published": "2023-01-21 21:02:16", "link": "http://arxiv.org/abs/2301.09008v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transfer Knowledge from Natural Language to Electrocardiography: Can We\n  Detect Cardiovascular Disease Through Language Models?", "abstract": "Recent advancements in Large Language Models (LLMs) have drawn increasing\nattention since the learned embeddings pretrained on large-scale datasets have\nshown powerful ability in various downstream applications. However, whether the\nlearned knowledge by LLMs can be transferred to clinical cardiology remains\nunknown. In this work, we aim to bridge this gap by transferring the knowledge\nof LLMs to clinical Electrocardiography (ECG). We propose an approach for\ncardiovascular disease diagnosis and automatic ECG diagnosis report generation.\nWe also introduce an additional loss function by Optimal Transport (OT) to\nalign the distribution between ECG and language embedding. The learned\nembeddings are evaluated on two downstream tasks: (1) automatic ECG diagnosis\nreport generation, and (2) zero-shot cardiovascular disease detection. Our\napproach is able to generate high-quality cardiac diagnosis reports and also\nachieves competitive zero-shot classification performance even compared with\nsupervised baselines, which proves the feasibility of transferring knowledge\nfrom LLMs to the cardiac domain.", "published": "2023-01-21 21:58:00", "link": "http://arxiv.org/abs/2301.09017v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stress Test for BERT and Deep Models: Predicting Words from Italian\n  Poetry", "abstract": "In this paper we present a set of experiments carried out with BERT on a\nnumber of Italian sentences taken from poetry domain. The experiments are\norganized on the hypothesis of a very high level of difficulty in\npredictability at the three levels of linguistic complexity that we intend to\nmonitor: lexical, syntactic and semantic level. To test this hypothesis we ran\nthe Italian version of BERT with 80 sentences for a total of 900 tokens mostly\nextracted from Italian poetry of the first half of last century. Then we\nalternated canonical and noncanonical versions of the same sentence before\nprocessing them with the same DL model. We used then sentences from the\nnewswire domain containing similar syntactic structures. The results show that\nthe DL model is highly sensitive to presence of noncanonical structures.\nHowever, DLs are also very sensitive to word frequency and to local non literal\nmeaning compositional effect. This is also apparent by the preference for\npredicting function vs content words, collocates vs infrequent word phrases. In\nthe paper, we focused our attention on the use of subword units done by BERT\nfor out of vocabulary words.", "published": "2023-01-21 09:44:19", "link": "http://arxiv.org/abs/2302.09303v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProKD: An Unsupervised Prototypical Knowledge Distillation Network for\n  Zero-Resource Cross-Lingual Named Entity Recognition", "abstract": "For named entity recognition (NER) in zero-resource languages, utilizing\nknowledge distillation methods to transfer language-independent knowledge from\nthe rich-resource source languages to zero-resource languages is an effective\nmeans. Typically, these approaches adopt a teacher-student architecture, where\nthe teacher network is trained in the source language, and the student network\nseeks to learn knowledge from the teacher network and is expected to perform\nwell in the target language. Despite the impressive performance achieved by\nthese methods, we argue that they have two limitations. Firstly, the teacher\nnetwork fails to effectively learn language-independent knowledge shared across\nlanguages due to the differences in the feature distribution between the source\nand target languages. Secondly, the student network acquires all of its\nknowledge from the teacher network and ignores the learning of target\nlanguage-specific knowledge. Undesirably, these limitations would hinder the\nmodel's performance in the target language. This paper proposes an unsupervised\nprototype knowledge distillation network (ProKD) to address these issues.\nSpecifically, ProKD presents a contrastive learning-based prototype alignment\nmethod to achieve class feature alignment by adjusting the distance among\nprototypes in the source and target languages, boosting the teacher network's\ncapacity to acquire language-independent knowledge. In addition, ProKD\nintroduces a prototypical self-training method to learn the intrinsic structure\nof the language by retraining the student network on the target data using\nsamples' distance information from prototypes, thereby enhancing the student\nnetwork's ability to acquire language-specific knowledge. Extensive experiments\non three benchmark cross-lingual NER datasets demonstrate the effectiveness of\nour approach.", "published": "2023-01-21 02:20:43", "link": "http://arxiv.org/abs/2301.08855v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rationalization for Explainable NLP: A Survey", "abstract": "Recent advances in deep learning have improved the performance of many\nNatural Language Processing (NLP) tasks such as translation,\nquestion-answering, and text classification. However, this improvement comes at\nthe expense of model explainability. Black-box models make it difficult to\nunderstand the internals of a system and the process it takes to arrive at an\noutput. Numerical (LIME, Shapley) and visualization (saliency heatmap)\nexplainability techniques are helpful; however, they are insufficient because\nthey require specialized knowledge. These factors led rationalization to emerge\nas a more accessible explainable technique in NLP. Rationalization justifies a\nmodel's output by providing a natural language explanation (rationale). Recent\nimprovements in natural language generation have made rationalization an\nattractive technique because it is intuitive, human-comprehensible, and\naccessible to non-technical users. Since rationalization is a relatively new\nfield, it is disorganized. As the first survey, rationalization literature in\nNLP from 2007-2022 is analyzed. This survey presents available methods,\nexplainable evaluations, code, and datasets used across various NLP tasks that\nuse rationalization. Further, a new subfield in Explainable AI (XAI), namely,\nRational AI (RAI), is introduced to advance the current state of\nrationalization. A discussion on observed insights, challenges, and future\ndirections is provided to point to promising research opportunities.", "published": "2023-01-21 07:58:03", "link": "http://arxiv.org/abs/2301.08912v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Exploring Methods for Building Dialects-Mandarin Code-Mixing Corpora: A\n  Case Study in Taiwanese Hokkien", "abstract": "In natural language processing (NLP), code-mixing (CM) is a challenging task,\nespecially when the mixed languages include dialects. In Southeast Asian\ncountries such as Singapore, Indonesia, and Malaysia, Hokkien-Mandarin is the\nmost widespread code-mixed language pair among Chinese immigrants, and it is\nalso common in Taiwan. However, dialects such as Hokkien often have a scarcity\nof resources and the lack of an official writing system, limiting the\ndevelopment of dialect CM research. In this paper, we propose a method to\nconstruct a Hokkien-Mandarin CM dataset to mitigate the limitation, overcome\nthe morphological issue under the Sino-Tibetan language family, and offer an\nefficient Hokkien word segmentation method through a linguistics-based toolkit.\nFurthermore, we use our proposed dataset and employ transfer learning to train\nthe XLM (cross-lingual language model) for translation tasks. To fit the\ncode-mixing scenario, we adapt XLM slightly. We found that by using linguistic\nknowledge, rules, and language tags, the model produces good results on CM data\ntranslation while maintaining monolingual translation quality.", "published": "2023-01-21 11:04:20", "link": "http://arxiv.org/abs/2301.08937v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Blacks is to Anger as Whites is to Joy? Understanding Latent Affective\n  Bias in Large Pre-trained Neural Language Models", "abstract": "Groundbreaking inventions and highly significant performance improvements in\ndeep learning based Natural Language Processing are witnessed through the\ndevelopment of transformer based large Pre-trained Language Models (PLMs). The\nwide availability of unlabeled data within human generated data deluge along\nwith self-supervised learning strategy helps to accelerate the success of large\nPLMs in language generation, language understanding, etc. But at the same time,\nlatent historical bias/unfairness in human minds towards a particular gender,\nrace, etc., encoded unintentionally/intentionally into the corpora harms and\nquestions the utility and efficacy of large PLMs in many real-world\napplications, particularly for the protected groups. In this paper, we present\nan extensive investigation towards understanding the existence of \"Affective\nBias\" in large PLMs to unveil any biased association of emotions such as anger,\nfear, joy, etc., towards a particular gender, race or religion with respect to\nthe downstream task of textual emotion detection. We conduct our exploration of\naffective bias from the very initial stage of corpus level affective bias\nanalysis by searching for imbalanced distribution of affective words within a\ndomain, in large scale corpora that are used to pre-train and fine-tune PLMs.\nLater, to quantify affective bias in model predictions, we perform an extensive\nset of class-based and intensity-based evaluations using various bias\nevaluation corpora. Our results show the existence of statistically significant\naffective bias in the PLM based emotion detection systems, indicating biased\nassociation of certain emotions towards a particular gender, race, and\nreligion.", "published": "2023-01-21 20:23:09", "link": "http://arxiv.org/abs/2301.09003v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MTTN: Multi-Pair Text to Text Narratives for Prompt Generation", "abstract": "The increased interest in diffusion models has opened up opportunities for\nadvancements in generative text modeling. These models can produce impressive\nimages when given a well-crafted prompt, but creating a powerful or meaningful\nprompt can be hit-or-miss. To address this, we have created a large-scale\ndataset that is derived and synthesized from real prompts and indexed with\npopular image-text datasets such as MS-COCO and Flickr. We have also\nimplemented stages that gradually reduce context and increase complexity, which\nwill further enhance the output due to the complex annotations created. The\ndataset, called MTTN, includes over 2.4 million sentences divided into 5\nstages, resulting in a total of over 12 million pairs, and a vocabulary of over\n300,000 unique words, providing ample variation. The original 2.4 million pairs\nare designed to reflect the way language is used on the internet globally,\nmaking the dataset more robust for any model trained on it.", "published": "2023-01-21 06:55:44", "link": "http://arxiv.org/abs/2301.10172v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Investigating Strategies for Clause Recommendation", "abstract": "Clause recommendation is the problem of recommending a clause to a legal\ncontract, given the context of the contract in question and the clause type to\nwhich the clause should belong. With not much prior work being done toward the\ngeneration of legal contracts, this problem was proposed as a first step toward\nthe bigger problem of contract generation. As an open-ended text generation\nproblem, the distinguishing characteristics of this problem lie in the nature\nof legal language as a sublanguage and the considerable similarity of textual\ncontent within the clauses of a specific type. This similarity aspect in legal\nclauses drives us to investigate the importance of similar contracts'\nrepresentation for recommending clauses. In our work, we experiment with\ngenerating clauses for 15 commonly occurring clause types in contracts\nexpanding upon the previous work on this problem and analyzing clause\nrecommendations in varying settings using information derived from similar\ncontracts.", "published": "2023-01-21 11:03:47", "link": "http://arxiv.org/abs/2301.10716v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Adapting a Language Model While Preserving its General Knowledge", "abstract": "Domain-adaptive pre-training (or DA-training for short), also known as\npost-training, aims to train a pre-trained general-purpose language model (LM)\nusing an unlabeled corpus of a particular domain to adapt the LM so that\nend-tasks in the domain can give improved performances. However, existing\nDA-training methods are in some sense blind as they do not explicitly identify\nwhat knowledge in the LM should be preserved and what should be changed by the\ndomain corpus. This paper shows that the existing methods are suboptimal and\nproposes a novel method to perform a more informed adaptation of the knowledge\nin the LM by (1) soft-masking the attention heads based on their importance to\nbest preserve the general knowledge in the LM and (2) contrasting the\nrepresentations of the general and the full (both general and domain knowledge)\nto learn an integrated representation with both general and domain-specific\nknowledge. Experimental results will demonstrate the effectiveness of the\nproposed approach.", "published": "2023-01-21 17:57:53", "link": "http://arxiv.org/abs/2301.08986v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Weakly-Supervised Questions for Zero-Shot Relation Extraction", "abstract": "Zero-Shot Relation Extraction (ZRE) is the task of Relation Extraction where\nthe training and test sets have no shared relation types. This very challenging\ndomain is a good test of a model's ability to generalize. Previous approaches\nto ZRE reframed relation extraction as Question Answering (QA), allowing for\nthe use of pre-trained QA models. However, this method required manually\ncreating gold question templates for each new relation. Here, we do away with\nthese gold templates and instead learn a model that can generate questions for\nunseen relations. Our technique can successfully translate relation\ndescriptions into relevant questions, which are then leveraged to generate the\ncorrect tail entity. On tail entity extraction, we outperform the previous\nstate-of-the-art by more than 16 F1 points without using gold question\ntemplates. On the RE-QA dataset where no previous baseline for relation\nextraction exists, our proposed algorithm comes within 0.7 F1 points of a\nsystem that uses gold question templates. Our model also outperforms the\nstate-of-the-art ZRE baselines on the FewRel and WikiZSL datasets, showing that\nQA models no longer need template questions to match the performance of models\nspecifically tailored to the ZRE task. Our implementation is available at\nhttps://github.com/fyshelab/QA-ZRE.", "published": "2023-01-21 22:18:24", "link": "http://arxiv.org/abs/2301.09640v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Multi-Purpose Audio-Visual Corpus for Multi-Modal Persian Speech\n  Recognition: the Arman-AV Dataset", "abstract": "In recent years, significant progress has been made in automatic lip reading.\nBut these methods require large-scale datasets that do not exist for many\nlow-resource languages. In this paper, we have presented a new multipurpose\naudio-visual dataset for Persian. This dataset consists of almost 220 hours of\nvideos with 1760 corresponding speakers. In addition to lip reading, the\ndataset is suitable for automatic speech recognition, audio-visual speech\nrecognition, and speaker recognition. Also, it is the first large-scale lip\nreading dataset in Persian. A baseline method was provided for each mentioned\ntask. In addition, we have proposed a technique to detect visemes (a visual\nequivalent of a phoneme) in Persian. The visemes obtained by this method\nincrease the accuracy of the lip reading task by 7% relatively compared to the\npreviously proposed visemes, which can be applied to other languages as well.", "published": "2023-01-21 05:13:30", "link": "http://arxiv.org/abs/2301.10180v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Regeneration Learning: A Learning Paradigm for Data Generation", "abstract": "Machine learning methods for conditional data generation usually build a\nmapping from source conditional data X to target data Y. The target Y (e.g.,\ntext, speech, music, image, video) is usually high-dimensional and complex, and\ncontains information that does not exist in source data, which hinders\neffective and efficient learning on the source-target mapping. In this paper,\nwe present a learning paradigm called regeneration learning for data\ngeneration, which first generates Y' (an abstraction/representation of Y) from\nX and then generates Y from Y'. During training, Y' is obtained from Y through\neither handcrafted rules or self-supervised learning and is used to learn\nX-->Y' and Y'-->Y. Regeneration learning extends the concept of representation\nlearning to data generation tasks, and can be regarded as a counterpart of\ntraditional representation learning, since 1) regeneration learning handles the\nabstraction (Y') of the target data Y for data generation while traditional\nrepresentation learning handles the abstraction (X') of source data X for data\nunderstanding; 2) both the processes of Y'-->Y in regeneration learning and\nX-->X' in representation learning can be learned in a self-supervised way\n(e.g., pre-training); 3) both the mappings from X to Y' in regeneration\nlearning and from X' to Y in representation learning are simpler than the\ndirect mapping from X to Y. We show that regeneration learning can be a\nwidely-used paradigm for data generation (e.g., text generation, speech\nrecognition, speech synthesis, music composition, image generation, and video\ngeneration) and can provide valuable insights into developing data generation\nmethods.", "published": "2023-01-21 01:33:34", "link": "http://arxiv.org/abs/2301.08846v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "eess.AS"], "primary_category": "cs.LG"}
{"title": "New Challenges for Content Privacy in Speech and Audio", "abstract": "Privacy in speech and audio has many facets. A particularly under-developed\narea of privacy in this domain involves consideration for information related\nto content and context. Speech content can include words and their meaning or\neven stylistic markers, pathological speech, intonation patterns, or emotion.\nMore generally, audio captured in-the-wild may contain background speech or\nreveal contextual information such as markers of location, room\ncharacteristics, paralinguistic sounds, or other audible events. Audio\nrecording devices and speech technologies are becoming increasingly commonplace\nin everyday life. At the same time, commercialised speech and audio\ntechnologies do not provide consumers with a range of privacy choices. Even\nwhere privacy is regulated or protected by law, technical solutions to privacy\nassurance and enforcement fall short. This position paper introduces three\nimportant and timely research challenges for content privacy in speech and\naudio. We highlight current gaps and opportunities, and identify focus areas,\nthat could have significant implications for developing ethical and safer\nspeech technologies.", "published": "2023-01-21 09:16:09", "link": "http://arxiv.org/abs/2301.08925v1", "categories": ["eess.AS", "cs.CR", "cs.SD"], "primary_category": "eess.AS"}
