{"title": "Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature\n  and PRESupposition", "abstract": "Natural language inference (NLI) is an increasingly important task for\nnatural language understanding, which requires one to infer whether a sentence\nentails another. However, the ability of NLI models to make pragmatic\ninferences remains understudied. We create an IMPlicature and PRESupposition\ndiagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated\nsentence pairs illustrating well-studied pragmatic inference types. We use\nIMPPRES to evaluate whether BERT, InferSent, and BOW NLI models trained on\nMultiNLI (Williams et al., 2018) learn to make pragmatic inferences. Although\nMultiNLI appears to contain very few pairs illustrating these inference types,\nwe find that BERT learns to draw pragmatic inferences. It reliably treats\nscalar implicatures triggered by \"some\" as entailments. For some presupposition\ntriggers like \"only\", BERT reliably recognizes the presupposition as an\nentailment, even when the trigger is embedded under an entailment canceling\noperator like negation. BOW and InferSent show weaker evidence of pragmatic\nreasoning. We conclude that NLI training encourages models to learn some, but\nnot all, pragmatic inferences.", "published": "2020-04-07 01:20:55", "link": "http://arxiv.org/abs/2004.03066v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interview: A Large-Scale Open-Source Corpus of Media Dialog", "abstract": "Existing conversational datasets consist either of written proxies for dialog\nor small-scale transcriptions of natural speech. We introduce 'Interview': a\nlarge-scale (105K conversations) media dialog dataset collected from news\ninterview transcripts. Compared to existing large-scale proxies for\nconversational data, language models trained on our dataset exhibit better\nzero-shot out-of-domain performance on existing spoken dialog datasets,\ndemonstrating its usefulness in modeling real-world conversations. 'Interview'\ncontains speaker role annotations for each turn, facilitating the development\nof engaging, responsive dialog systems. In fact, experiments on two dialog\ntasks show that leveraging such labels improves performance over strong\nspeaker-agnostic baselines, and enabling models to generate more specific and\ninquisitive responses in interview-style conversations.", "published": "2020-04-07 02:44:50", "link": "http://arxiv.org/abs/2004.03090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exemplar Auditing for Multi-Label Biomedical Text Classification", "abstract": "Many practical applications of AI in medicine consist of semi-supervised\ndiscovery: The investigator aims to identify features of interest at a\nresolution more fine-grained than that of the available human labels. This is\noften the scenario faced in healthcare applications as coarse, high-level\nlabels (e.g., billing codes) are often the only sources that are readily\navailable. These challenges are compounded for modalities such as text, where\nthe feature space is very high-dimensional, and often contains considerable\namounts of noise.\n  In this work, we generalize a recently proposed zero-shot sequence labeling\nmethod, \"binary labeling via a convolutional decomposition\", to the case where\nthe available document-level human labels are themselves relatively\nhigh-dimensional. The approach yields classification with \"introspection\",\nrelating the fine-grained features of an inference-time prediction to their\nnearest neighbors from the training set, under the model. The approach is\neffective, yet parsimonious, as demonstrated on a well-studied MIMIC-III\nmulti-label classification task of electronic health record data, and is useful\nas a tool for organizing the analysis of neural model predictions and\nhigh-dimensional datasets. Our proposed approach yields both a competitively\neffective classification model and an interrogation mechanism to aid healthcare\nworkers in understanding the salient features that drive the model's\npredictions.", "published": "2020-04-07 02:54:20", "link": "http://arxiv.org/abs/2004.03093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is Graph Structure Necessary for Multi-hop Question Answering?", "abstract": "Recently, attempting to model texts as graph structure and introducing graph\nneural networks to deal with it has become a trend in many NLP research areas.\nIn this paper, we investigate whether the graph structure is necessary for\nmulti-hop question answering. Our analysis is centered on HotpotQA. We\nconstruct a strong baseline model to establish that, with the proper use of\npre-trained models, graph structure may not be necessary for multi-hop question\nanswering. We point out that both graph structure and adjacency matrix are\ntask-related prior knowledge, and graph-attention can be considered as a\nspecial case of self-attention. Experiments and visualized analysis demonstrate\nthat graph-attention or the entire graph structure can be replaced by\nself-attention or Transformers.", "published": "2020-04-07 02:59:42", "link": "http://arxiv.org/abs/2004.03096v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Non-task-specific Distillation of BERT via Sentence\n  Representation Approximation", "abstract": "Recently, BERT has become an essential ingredient of various NLP deep models\ndue to its effectiveness and universal-usability. However, the online\ndeployment of BERT is often blocked by its large-scale parameters and high\ncomputational cost. There are plenty of studies showing that the knowledge\ndistillation is efficient in transferring the knowledge from BERT into the\nmodel with a smaller size of parameters. Nevertheless, current BERT\ndistillation approaches mainly focus on task-specified distillation, such\nmethodologies lead to the loss of the general semantic knowledge of BERT for\nuniversal-usability. In this paper, we propose a sentence representation\napproximating oriented distillation framework that can distill the pre-trained\nBERT into a simple LSTM based model without specifying tasks. Consistent with\nBERT, our distilled model is able to perform transfer learning via fine-tuning\nto adapt to any sentence-level downstream task. Besides, our model can further\ncooperate with task-specific distillation procedures. The experimental results\non multiple NLP tasks from the GLUE benchmark show that our approach\noutperforms other task-specific distillation methods or even much larger\nmodels, i.e., ELMO, with efficiency well-improved.", "published": "2020-04-07 03:03:00", "link": "http://arxiv.org/abs/2004.03097v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Sentence Cloze Dataset for Chinese Machine Reading Comprehension", "abstract": "Owing to the continuous efforts by the Chinese NLP community, more and more\nChinese machine reading comprehension datasets become available. To add\ndiversity in this area, in this paper, we propose a new task called Sentence\nCloze-style Machine Reading Comprehension (SC-MRC). The proposed task aims to\nfill the right candidate sentence into the passage that has several blanks. We\nbuilt a Chinese dataset called CMRC 2019 to evaluate the difficulty of the\nSC-MRC task. Moreover, to add more difficulties, we also made fake candidates\nthat are similar to the correct ones, which requires the machine to judge their\ncorrectness in the context. The proposed dataset contains over 100K blanks\n(questions) within over 10K passages, which was originated from Chinese\nnarrative stories. To evaluate the dataset, we implement several baseline\nsystems based on the pre-trained models, and the results show that the\nstate-of-the-art model still underperforms human performance by a large margin.\nWe release the dataset and baseline system to further facilitate our community.\nResources available through https://github.com/ymcui/cmrc2019", "published": "2020-04-07 04:09:00", "link": "http://arxiv.org/abs/2004.03116v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex\n  Text-to-SQL in Cross-Domain Databases", "abstract": "Text-to-SQL is the problem of converting a user question into an SQL query,\nwhen the question and database are given. In this paper, we present a neural\nnetwork approach called RYANSQL (Recursively Yielding Annotation Network for\nSQL) to solve complex Text-to-SQL tasks for cross-domain databases. State-ment\nPosition Code (SPC) is defined to trans-form a nested SQL query into a set of\nnon-nested SELECT statements; a sketch-based slot filling approach is proposed\nto synthesize each SELECT statement for its corresponding SPC. Additionally,\ntwo input manipulation methods are presented to improve generation performance\nfurther. RYANSQL achieved 58.2% accuracy on the challenging Spider benchmark,\nwhich is a 3.2%p improvement over previous state-of-the-art approaches. At the\ntime of writing, RYANSQL achieves the first position on the Spider leaderboard.", "published": "2020-04-07 04:51:04", "link": "http://arxiv.org/abs/2004.03125v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin\n  Chinese Based on a New Open Benchmark Dataset", "abstract": "Conversion of Chinese graphemes to phonemes (G2P) is an essential component\nin Mandarin Chinese Text-To-Speech (TTS) systems. One of the biggest challenges\nin Chinese G2P conversion is how to disambiguate the pronunciation of\npolyphones - characters having multiple pronunciations. Although many academic\nefforts have been made to address it, there has been no open dataset that can\nserve as a standard benchmark for fair comparison to date. In addition, most of\nthe reported systems are hard to employ for researchers or practitioners who\nwant to convert Chinese text into pinyin at their convenience. Motivated by\nthese, in this work, we introduce a new benchmark dataset that consists of\n99,000+ sentences for Chinese polyphone disambiguation. We train a simple\nneural network model on it, and find that it outperforms other preexisting G2P\nsystems. Finally, we package our project and share it on PyPi.", "published": "2020-04-07 05:44:58", "link": "http://arxiv.org/abs/2004.03136v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-lingual Supervision Improves Unsupervised Neural Machine\n  Translation", "abstract": "Neural machine translation~(NMT) is ineffective for zero-resource languages.\nRecent works exploring the possibility of unsupervised neural machine\ntranslation (UNMT) with only monolingual data can achieve promising results.\nHowever, there are still big gaps between UNMT and NMT with parallel\nsupervision. In this work, we introduce a multilingual unsupervised NMT\n(\\method) framework to leverage weakly supervised signals from high-resource\nlanguage pairs to zero-resource translation directions. More specifically, for\nunsupervised language pairs \\texttt{En-De}, we can make full use of the\ninformation from parallel dataset \\texttt{En-Fr} to jointly train the\nunsupervised translation directions all in one model. \\method is based on\nmultilingual models which require no changes to the standard unsupervised NMT.\nEmpirical results demonstrate that \\method significantly improves the\ntranslation quality by more than 3 BLEU score on six benchmark unsupervised\ntranslation directions.", "published": "2020-04-07 05:46:49", "link": "http://arxiv.org/abs/2004.03137v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Induced Curriculum Learning in Self-Supervised Neural Machine\n  Translation", "abstract": "Self-supervised neural machine translation (SSNMT) jointly learns to identify\nand select suitable training data from comparable (rather than parallel)\ncorpora and to translate, in a way that the two tasks support each other in a\nvirtuous circle. In this study, we provide an in-depth analysis of the sampling\nchoices the SSNMT model makes during training. We show how, without it having\nbeen told to do so, the model self-selects samples of increasing (i) complexity\nand (ii) task-relevance in combination with (iii) performing a denoising\ncurriculum. We observe that the dynamics of the mutual-supervision signals of\nboth system internal representation types are vital for the extraction and\ntranslation performance. We show that in terms of the Gunning-Fog Readability\nindex, SSNMT starts extracting and learning from Wikipedia data suitable for\nhigh school students and quickly moves towards content suitable for first year\nundergraduate students.", "published": "2020-04-07 06:45:45", "link": "http://arxiv.org/abs/2004.03151v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Translation with Unsupervised Length-Constraints", "abstract": "We have seen significant improvements in machine translation due to the usage\nof deep learning. While the improvements in translation quality are impressive,\nthe encoder-decoder architecture enables many more possibilities. In this\npaper, we explore one of these, the generation of constraint translation. We\nfocus on length constraints, which are essential if the translation should be\ndisplayed in a given format. In this work, we propose an end-to-end approach\nfor this task. Compared to a traditional method that first translates and then\nperforms sentence compression, the text compression is learned completely\nunsupervised. By combining the idea with zero-shot multilingual machine\ntranslation, we are also able to perform unsupervised monolingual sentence\ncompression. In order to fulfill the length constraints, we investigated\nseveral methods to integrate the constraints into the model. Using the\npresented technique, we are able to significantly improve the translation\nquality under constraints. Furthermore, we are able to perform unsupervised\nmonolingual sentence compression.", "published": "2020-04-07 07:55:41", "link": "http://arxiv.org/abs/2004.03176v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Multimodal Simultaneous Neural Machine Translation", "abstract": "Simultaneous translation involves translating a sentence before the speaker's\nutterance is completed in order to realize real-time understanding in multiple\nlanguages. This task is significantly more challenging than the general full\nsentence translation because of the shortage of input information during\ndecoding. To alleviate this shortage, we propose multimodal simultaneous neural\nmachine translation (MSNMT), which leverages visual information as an\nadditional modality. Our experiments with the Multi30k dataset showed that\nMSNMT significantly outperforms its text-only counterpart in more timely\ntranslation situations with low latency. Furthermore, we verified the\nimportance of visual information during decoding by performing an adversarial\nevaluation of MSNMT, where we studied how models behaved with incongruent input\nmodality and analyzed the effect of different word order between source and\ntarget languages.", "published": "2020-04-07 08:02:21", "link": "http://arxiv.org/abs/2004.03180v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "More Data, More Relations, More Context and More Openness: A Review and\n  Outlook for Relation Extraction", "abstract": "Relational facts are an important component of human knowledge, which are\nhidden in vast amounts of text. In order to extract these facts from text,\npeople have been working on relation extraction (RE) for years. From early\npattern matching to current neural networks, existing RE methods have achieved\nsignificant progress. Yet with explosion of Web text and emergence of new\nrelations, human knowledge is increasing drastically, and we thus require\n\"more\" from RE: a more powerful RE system that can robustly utilize more data,\nefficiently learn more relations, easily handle more complicated context, and\nflexibly generalize to more open domains. In this paper, we look back at\nexisting RE methods, analyze key challenges we are facing nowadays, and show\npromising directions towards more powerful RE. We hope our view can advance\nthis field and inspire more efforts in the community.", "published": "2020-04-07 08:15:21", "link": "http://arxiv.org/abs/2004.03186v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Fluency of Non-Autoregressive Machine Translation", "abstract": "Non-autoregressive (nAR) models for machine translation (MT) manifest\nsuperior decoding speed when compared to autoregressive (AR) models, at the\nexpense of impaired fluency of their outputs. We improve the fluency of a nAR\nmodel with connectionist temporal classification (CTC) by employing additional\nfeatures in the scoring model used during beam search decoding. Since the beam\nsearch decoding in our model only requires to run the network in a single\nforward pass, the decoding speed is still notably higher than in standard AR\nmodels. We train models for three language pairs: German, Czech, and Romanian\nfrom and into English. The results show that our proposed models can be more\nefficient in terms of decoding speed and still achieve a competitive BLEU score\nrelative to AR models.", "published": "2020-04-07 09:40:54", "link": "http://arxiv.org/abs/2004.03227v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A German Corpus for Fine-Grained Named Entity Recognition and Relation\n  Extraction of Traffic and Industry Events", "abstract": "Monitoring mobility- and industry-relevant events is important in areas such\nas personal travel planning and supply chain management, but extracting events\npertaining to specific companies, transit routes and locations from\nheterogeneous, high-volume text streams remains a significant challenge. This\nwork describes a corpus of German-language documents which has been annotated\nwith fine-grained geo-entities, such as streets, stops and routes, as well as\nstandard named entity types. It has also been annotated with a set of 15\ntraffic- and industry-related n-ary relations and events, such as accidents,\ntraffic jams, acquisitions, and strikes. The corpus consists of newswire texts,\nTwitter messages, and traffic reports from radio stations, police and railway\ncompanies. It allows for training and evaluating both named entity recognition\nalgorithms that aim for fine-grained typing of geo-entities, as well as n-ary\nrelation extraction systems.", "published": "2020-04-07 11:39:50", "link": "http://arxiv.org/abs/2004.03283v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Corpus Study and Annotation Schema for Named Entity Recognition and\n  Relation Extraction of Business Products", "abstract": "Recognizing non-standard entity types and relations, such as B2B products,\nproduct classes and their producers, in news and forum texts is important in\napplication areas such as supply chain monitoring and market research. However,\nthere is a decided lack of annotated corpora and annotation guidelines in this\ndomain. In this work, we present a corpus study, an annotation schema and\nassociated guidelines, for the annotation of product entity and company-product\nrelation mentions. We find that although product mentions are often realized as\nnoun phrases, defining their exact extent is difficult due to high boundary\nambiguity and the broad syntactic and semantic variety of their surface\nrealizations. We also describe our ongoing annotation effort, and present a\npreliminary corpus of English web and social media documents annotated\naccording to the proposed guidelines.", "published": "2020-04-07 11:45:22", "link": "http://arxiv.org/abs/2004.03287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language\n  Understanding", "abstract": "Natural language inference (NLI) and semantic textual similarity (STS) are\nkey tasks in natural language understanding (NLU). Although several benchmark\ndatasets for those tasks have been released in English and a few other\nlanguages, there are no publicly available NLI or STS datasets in the Korean\nlanguage. Motivated by this, we construct and release new datasets for Korean\nNLI and STS, dubbed KorNLI and KorSTS, respectively. Following previous\napproaches, we machine-translate existing English training sets and manually\ntranslate development and test sets into Korean. To accelerate research on\nKorean NLU, we also establish baselines on KorNLI and KorSTS. Our datasets are\npublicly available at https://github.com/kakaobrain/KorNLUDatasets.", "published": "2020-04-07 11:49:15", "link": "http://arxiv.org/abs/2004.03289v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Windowing Models for Abstractive Summarization of Long Texts", "abstract": "Neural summarization models suffer from the fixed-size input limitation: if\ntext length surpasses the model's maximal number of input tokens, some document\ncontent (possibly summary-relevant) gets truncated Independently summarizing\nwindows of maximal input size disallows for information flow between windows\nand leads to incoherent summaries. We propose windowing models for neural\nabstractive summarization of (arbitrarily) long texts. We extend the\nsequence-to-sequence model augmented with pointer generator network by (1)\nallowing the encoder to slide over different windows of the input document and\n(2) sharing the decoder and retaining its state across different input windows.\nWe explore two windowing variants: Static Windowing precomputes the number of\ntokens the decoder should generate from each window (based on training corpus\nstatistics); in Dynamic Windowing the decoder learns to emit a token that\nsignals encoder's shift to the next input window. Empirical results render our\nmodels effective in their intended use-case: summarizing long texts with\nrelevant content not bound to the very document beginning.", "published": "2020-04-07 13:01:26", "link": "http://arxiv.org/abs/2004.03324v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inexpensive Domain Adaptation of Pretrained Language Models: Case\n  Studies on Biomedical NER and Covid-19 QA", "abstract": "Domain adaptation of Pretrained Language Models (PTLMs) is typically achieved\nby unsupervised pretraining on target-domain text. While successful, this\napproach is expensive in terms of hardware, runtime and CO_2 emissions. Here,\nwe propose a cheaper alternative: We train Word2Vec on target-domain text and\nalign the resulting word vectors with the wordpiece vectors of a general-domain\nPTLM. We evaluate on eight biomedical Named Entity Recognition (NER) tasks and\ncompare against the recently proposed BioBERT model. We cover over 60% of the\nBioBERT-BERT F1 delta, at 5% of BioBERT's CO_2 footprint and 2% of its cloud\ncompute cost. We also show how to quickly adapt an existing general-domain\nQuestion Answering (QA) model to an emerging domain: the Covid-19 pandemic.", "published": "2020-04-07 13:31:06", "link": "http://arxiv.org/abs/2004.03354v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Legal Approach to Hate Speech: Operationalizing the EU's Legal\n  Framework against the Expression of Hatred as an NLP Task", "abstract": "We propose a 'legal approach' to hate speech detection by operationalization\nof the decision as to whether a post is subject to criminal law into an NLP\ntask. Comparing existing regulatory regimes for hate speech, we base our\ninvestigation on the European Union's framework as it provides a widely\napplicable legal minimum standard. Accurately judging whether a post is\npunishable or not usually requires legal training. We show that, by breaking\nthe legal assessment down into a series of simpler sub-decisions, even\nlaypersons can annotate consistently. Based on a newly annotated dataset, our\nexperiments show that directly learning an automated model of punishable\ncontent is challenging. However, learning the two sub-tasks of `target group'\nand `targeting conduct' instead of an end-to-end approach to punishability\nyields better results. Overall, our method also provides decisions that are\nmore transparent than those of end-to-end models, which is a crucial point in\nlegal decision-making.", "published": "2020-04-07 14:13:38", "link": "http://arxiv.org/abs/2004.03422v3", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "What do Models Learn from Question Answering Datasets?", "abstract": "While models have reached superhuman performance on popular question\nanswering (QA) datasets such as SQuAD, they have yet to outperform humans on\nthe task of question answering itself. In this paper, we investigate if models\nare learning reading comprehension from QA datasets by evaluating BERT-based\nmodels across five datasets. We evaluate models on their generalizability to\nout-of-domain examples, responses to missing or incorrect data, and ability to\nhandle question variations. We find that no single dataset is robust to all of\nour experiments and identify shortcomings in both datasets and evaluation\nmethods. Following our analysis, we make recommendations for building future QA\ndatasets that better evaluate the task of question answering through reading\ncomprehension. We also release code to convert QA datasets to a shared format\nfor easier experimentation at\nhttps://github.com/amazon-research/qa-dataset-converter.", "published": "2020-04-07 15:41:55", "link": "http://arxiv.org/abs/2004.03490v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Named Entity Typing over Distantly Supervised Data Based on\n  Refined Representations", "abstract": "Fine-Grained Named Entity Typing (FG-NET) is a key component in Natural\nLanguage Processing (NLP). It aims at classifying an entity mention into a wide\nrange of entity types. Due to a large number of entity types, distant\nsupervision is used to collect training data for this task, which noisily\nassigns type labels to entity mentions irrespective of the context. In order to\nalleviate the noisy labels, existing approaches on FGNET analyze the entity\nmentions entirely independent of each other and assign type labels solely based\non mention sentence-specific context. This is inadequate for highly overlapping\nand noisy type labels as it hinders information passing across sentence\nboundaries. For this, we propose an edge-weighted attentive graph convolution\nnetwork that refines the noisy mention representations by attending over\ncorpus-level contextual clues prior to the end classification. Experimental\nevaluation shows that the proposed model outperforms the existing research by a\nrelative score of upto 10.2% and 8.3% for macro f1 and micro f1 respectively.", "published": "2020-04-07 17:26:36", "link": "http://arxiv.org/abs/2004.03554v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entity Linking via Dual and Cross-Attention Encoders", "abstract": "Entity Linking has two main open areas of research: 1) generate candidate\nentities without using alias tables and 2) generate more contextual\nrepresentations for both mentions and entities. Recently, a solution has been\nproposed for the former as a dual-encoder entity retrieval system (Gillick et\nal., 2019) that learns mention and entity representations in the same space,\nand performs linking by selecting the nearest entity to the mention in this\nspace. In this work, we use this retrieval system solely for generating\ncandidate entities. We then rerank the entities by using a cross-attention\nencoder over the target mention and each of the candidate entities. Whereas a\ndual encoder approach forces all information to be contained in the small,\nfixed set of vector dimensions used to represent mentions and entities, a\ncrossattention model allows for the use of detailed information (read:\nfeatures) from the entirety of each <mention, context, candidate entity> tuple.\nWe experiment with features used in the reranker including different ways of\nincorporating document-level context. We achieve state-of-the-art results on\nTACKBP-2010 dataset, with 92.05% accuracy. Furthermore, we show how the\nrescoring model generalizes well when trained on the larger CoNLL-2003 dataset\nand evaluated on TACKBP-2010.", "published": "2020-04-07 17:28:28", "link": "http://arxiv.org/abs/2004.03555v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speaker-Aware BERT for Multi-Turn Response Selection in Retrieval-Based\n  Chatbots", "abstract": "In this paper, we study the problem of employing pre-trained language models\nfor multi-turn response selection in retrieval-based chatbots. A new model,\nnamed Speaker-Aware BERT (SA-BERT), is proposed in order to make the model\naware of the speaker change information, which is an important and intrinsic\nproperty of multi-turn dialogues. Furthermore, a speaker-aware disentanglement\nstrategy is proposed to tackle the entangled dialogues. This strategy selects a\nsmall number of most important utterances as the filtered context according to\nthe speakers' information in them. Finally, domain adaptation is performed to\nincorporate the in-domain knowledge into pre-trained language models.\nExperiments on five public datasets show that our proposed model outperforms\nthe present models on all metrics by large margins and achieves new\nstate-of-the-art performances for multi-turn response selection.", "published": "2020-04-07 02:08:04", "link": "http://arxiv.org/abs/2004.03588v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TuringAdvice: A Generative and Dynamic Evaluation of Language Use", "abstract": "We propose TuringAdvice, a new challenge task and dataset for language\nunderstanding models. Given a written situation that a real person is currently\nfacing, a model must generate helpful advice in natural language. Our\nevaluation framework tests a fundamental aspect of human language\nunderstanding: our ability to use language to resolve open-ended situations by\ncommunicating with each other.\n  Empirical results show that today's models struggle at TuringAdvice, even\nmultibillion parameter models finetuned on 600k in-domain training examples.\nThe best model, a finetuned T5, writes advice that is at least as helpful as\nhuman-written advice in only 14% of cases; a much larger non-finetunable GPT3\nmodel does even worse at 4%. This low performance reveals language\nunderstanding errors that are hard to spot outside of a generative setting,\nshowing much room for progress.", "published": "2020-04-07 18:00:03", "link": "http://arxiv.org/abs/2004.03607v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Re-translation versus Streaming for Simultaneous Translation", "abstract": "There has been great progress in improving streaming machine translation, a\nsimultaneous paradigm where the system appends to a growing hypothesis as more\nsource content becomes available. We study a related problem in which revisions\nto the hypothesis beyond strictly appending words are permitted. This is\nsuitable for applications such as live captioning an audio feed. In this\nsetting, we compare custom streaming approaches to re-translation, a\nstraightforward strategy where each new source token triggers a distinct\ntranslation from scratch. We find re-translation to be as good or better than\nstate-of-the-art streaming systems, even when operating under constraints that\nallow very few revisions. We attribute much of this success to a previously\nproposed data-augmentation technique that adds prefix-pairs to the training\ndata, which alongside wait-k inference forms a strong baseline for streaming\ntranslation. We also highlight re-translation's ability to wrap arbitrarily\npowerful MT systems with an experiment showing large improvements from an\nupgrade to its base model.", "published": "2020-04-07 18:27:32", "link": "http://arxiv.org/abs/2004.03643v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Russian Drug Reaction Corpus and Neural Models for Drug Reactions\n  and Effectiveness Detection in User Reviews", "abstract": "The Russian Drug Reaction Corpus (RuDReC) is a new partially annotated corpus\nof consumer reviews in Russian about pharmaceutical products for the detection\nof health-related named entities and the effectiveness of pharmaceutical\nproducts. The corpus itself consists of two parts, the raw one and the labelled\none. The raw part includes 1.4 million health-related user-generated texts\ncollected from various Internet sources, including social media. The labelled\npart contains 500 consumer reviews about drug therapy with drug- and\ndisease-related information. Labels for sentences include health-related issues\nor their absence. The sentences with one are additionally labelled at the\nexpression level for identification of fine-grained subtypes such as drug\nclasses and drug forms, drug indications, and drug reactions. Further, we\npresent a baseline model for named entity recognition (NER) and multi-label\nsentence classification tasks on this corpus. The macro F1 score of 74.85% in\nthe NER task was achieved by our RuDR-BERT model. For the sentence\nclassification task, our model achieves the macro F1 score of 68.82% gaining\n7.47% over the score of BERT model trained on Russian data. We make the RuDReC\ncorpus and pretrained weights of domain-specific BERT models freely available\nat https://github.com/cimm-kzn/RuDReC", "published": "2020-04-07 19:26:13", "link": "http://arxiv.org/abs/2004.03659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Data Selection and Weighting for Iterative Back-Translation", "abstract": "Back-translation has proven to be an effective method to utilize monolingual\ndata in neural machine translation (NMT), and iteratively conducting\nback-translation can further improve the model performance. Selecting which\nmonolingual data to back-translate is crucial, as we require that the resulting\nsynthetic data are of high quality and reflect the target domain. To achieve\nthese two goals, data selection and weighting strategies have been proposed,\nwith a common practice being to select samples close to the target domain but\nalso dissimilar to the average general-domain text. In this paper, we provide\ninsights into this commonly used approach and generalize it to a dynamic\ncurriculum learning strategy, which is applied to iterative back-translation\nmodels. In addition, we propose weighting strategies based on both the current\nquality of the sentence and its improvement over the previous iteration. We\nevaluate our models on domain adaptation, low-resource, and high-resource MT\nsettings and on two language pairs. Experimental results demonstrate that our\nmethods achieve improvements of up to 1.8 BLEU points over competitive\nbaselines.", "published": "2020-04-07 19:49:58", "link": "http://arxiv.org/abs/2004.03672v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Byte Pair Encoding is Suboptimal for Language Model Pretraining", "abstract": "The success of pretrained transformer language models (LMs) in natural\nlanguage processing has led to a wide range of pretraining setups. In\nparticular, these models employ a variety of subword tokenization methods, most\nnotably byte-pair encoding (BPE) (Sennrich et al., 2016; Gage, 1994), the\nWordPiece method (Schuster and Nakajima, 2012), and unigram language modeling\n(Kudo, 2018), to segment text. However, to the best of our knowledge, the\nliterature does not contain a direct evaluation of the impact of tokenization\non language model pretraining. We analyze differences between BPE and unigram\nLM tokenization, finding that the latter method recovers subword units that\nalign more closely with morphology and avoids problems stemming from BPE's\ngreedy construction procedure. We then compare the fine-tuned task performance\nof identical transformer masked language models pretrained with these\ntokenizations. Across downstream tasks and two languages (English and\nJapanese), we find that the unigram LM tokenization method matches or\noutperforms BPE. We hope that developers of future pretrained LMs will consider\nadopting the unigram LM method over the more prevalent BPE.", "published": "2020-04-07 21:21:06", "link": "http://arxiv.org/abs/2004.03720v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Decomposing Word Embedding with the Capsule Network", "abstract": "Word sense disambiguation tries to learn the appropriate sense of an\nambiguous word in a given context. The existing pre-trained language methods\nand the methods based on multi-embeddings of word did not explore the power of\nthe unsupervised word embedding sufficiently.\n  In this paper, we discuss a capsule network-based approach, taking advantage\nof capsule's potential for recognizing highly overlapping features and dealing\nwith segmentation. We propose a Capsule network-based method to Decompose the\nunsupervised word Embedding of an ambiguous word into context specific Sense\nembedding, called CapsDecE2S. In this approach, the unsupervised ambiguous\nembedding is fed into capsule network to produce its multiple morpheme-like\nvectors, which are defined as the basic semantic language units of meaning.\nWith attention operations, CapsDecE2S integrates the word context to\nreconstruct the multiple morpheme-like vectors into the context-specific sense\nembedding. To train CapsDecE2S, we propose a sense matching training method. In\nthis method, we convert the sense learning into a binary classification that\nexplicitly learns the relation between senses by the label of matching and\nnon-matching. The CapsDecE2S was experimentally evaluated on two sense learning\ntasks, i.e., word in context and word sense disambiguation. Results on two\npublic corpora Word-in-Context and English all-words Word Sense Disambiguation\nshow that, the CapsDecE2S model achieves the new state-of-the-art for the word\nin context and word sense disambiguation tasks.", "published": "2020-04-07 06:37:27", "link": "http://arxiv.org/abs/2004.13844v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Information-Theoretic Probing for Linguistic Structure", "abstract": "The success of neural networks on a diverse set of NLP tasks has led\nresearchers to question how much these networks actually ``know'' about natural\nlanguage. Probes are a natural way of assessing this. When probing, a\nresearcher chooses a linguistic task and trains a supervised model to predict\nannotations in that linguistic task from the network's learned representations.\nIf the probe does well, the researcher may conclude that the representations\nencode knowledge related to the task. A commonly held belief is that using\nsimpler models as probes is better; the logic is that simpler models will\nidentify linguistic structure, but not learn the task itself. We propose an\ninformation-theoretic operationalization of probing as estimating mutual\ninformation that contradicts this received wisdom: one should always select the\nhighest performing probe one can, even if it is more complex, since it will\nresult in a tighter estimate, and thus reveal more of the linguistic\ninformation inherent in the representation. The experimental portion of our\npaper focuses on empirically estimating the mutual information between a\nlinguistic property and BERT, comparing these estimates to several baselines.\nWe evaluate on a set of ten typologically diverse languages often\nunderrepresented in NLP research---plus English---totalling eleven languages.", "published": "2020-04-07 01:06:36", "link": "http://arxiv.org/abs/2004.03061v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Inferential Text Generation with Multiple Knowledge Sources and\n  Meta-Learning", "abstract": "We study the problem of generating inferential texts of events for a variety\nof commonsense like \\textit{if-else} relations. Existing approaches typically\nuse limited evidence from training examples and learn for each relation\nindividually. In this work, we use multiple knowledge sources as fuels for the\nmodel. Existing commonsense knowledge bases like ConceptNet are dominated by\ntaxonomic knowledge (e.g., \\textit{isA} and \\textit{relatedTo} relations),\nhaving a limited number of inferential knowledge. We use not only structured\ncommonsense knowledge bases, but also natural language snippets from\nsearch-engine results. These sources are incorporated into a generative base\nmodel via key-value memory network. In addition, we introduce a meta-learning\nbased multi-task learning algorithm. For each targeted commonsense relation, we\nregard the learning of examples from other relations as the meta-training\nprocess, and the evaluation on examples from the targeted relation as the\nmeta-test process. We conduct experiments on Event2Mind and ATOMIC datasets.\nResults show that both the integration of multiple knowledge sources and the\nuse of the meta-learning algorithm improve the performance.", "published": "2020-04-07 01:49:18", "link": "http://arxiv.org/abs/2004.03070v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Text-Guided Neural Image Inpainting", "abstract": "Image inpainting task requires filling the corrupted image with contents\ncoherent with the context. This research field has achieved promising progress\nby using neural image inpainting methods. Nevertheless, there is still a\ncritical challenge in guessing the missed content with only the context pixels.\nThe goal of this paper is to fill the semantic information in corrupted images\naccording to the provided descriptive text. Unique from existing text-guided\nimage generation works, the inpainting models are required to compare the\nsemantic content of the given text and the remaining part of the image, then\nfind out the semantic content that should be filled for missing part. To\nfulfill such a task, we propose a novel inpainting model named Text-Guided Dual\nAttention Inpainting Network (TDANet). Firstly, a dual multimodal attention\nmechanism is designed to extract the explicit semantic information about the\ncorrupted regions, which is done by comparing the descriptive text and\ncomplementary image areas through reciprocal attention. Secondly, an image-text\nmatching loss is applied to maximize the semantic similarity of the generated\nimage and the text. Experiments are conducted on two open datasets. Results\nshow that the proposed TDANet model reaches new state-of-the-art on both\nquantitative and qualitative measures. Result analysis suggests that the\ngenerated images are consistent with the guidance text, enabling the generation\nof various results by providing different descriptions. Codes are available at\nhttps://github.com/idealwhite/TDANet", "published": "2020-04-07 09:04:43", "link": "http://arxiv.org/abs/2004.03212v4", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Efficient Context and Schema Fusion Networks for Multi-Domain Dialogue\n  State Tracking", "abstract": "Dialogue state tracking (DST) aims at estimating the current dialogue state\ngiven all the preceding conversation. For multi-domain DST, the data sparsity\nproblem is a major obstacle due to increased numbers of state candidates and\ndialogue lengths. To encode the dialogue context efficiently, we utilize the\nprevious dialogue state (predicted) and the current dialogue utterance as the\ninput for DST. To consider relations among different domain-slots, the schema\ngraph involving prior knowledge is exploited. In this paper, a novel context\nand schema fusion network is proposed to encode the dialogue context and schema\ngraph by using internal and external attention mechanisms. Experiment results\nshow that our approach can obtain new state-of-the-art performance of the\nopen-vocabulary DST on both MultiWOZ 2.0 and MultiWOZ 2.1 benchmarks.", "published": "2020-04-07 13:46:39", "link": "http://arxiv.org/abs/2004.03386v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Emergent Language Generalization and Acquisition Speed are not tied to\n  Compositionality", "abstract": "Studies of discrete languages emerging when neural agents communicate to\nsolve a joint task often look for evidence of compositional structure. This\nstems for the expectation that such a structure would allow languages to be\nacquired faster by the agents and enable them to generalize better. We argue\nthat these beneficial properties are only loosely connected to\ncompositionality. In two experiments, we demonstrate that, depending on the\ntask, non-compositional languages might show equal, or better, generalization\nperformance and acquisition speed than compositional ones. Further research in\nthe area should be clearer about what benefits are expected from\ncompositionality, and how the latter would lead to them.", "published": "2020-04-07 14:10:27", "link": "http://arxiv.org/abs/2004.03420v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Few Topical Tweets are Enough for Effective User-Level Stance\n  Detection", "abstract": "Stance detection entails ascertaining the position of a user towards a\ntarget, such as an entity, topic, or claim. Recent work that employs\nunsupervised classification has shown that performing stance detection on vocal\nTwitter users, who have many tweets on a target, can yield very high accuracy\n(+98%). However, such methods perform poorly or fail completely for less vocal\nusers, who may have authored only a few tweets about a target. In this paper,\nwe tackle stance detection for such users using two approaches. In the first\napproach, we improve user-level stance detection by representing tweets using\ncontextualized embeddings, which capture latent meanings of words in context.\nWe show that this approach outperforms two strong baselines and achieves 89.6%\naccuracy and 91.3% macro F-measure on eight controversial topics. In the second\napproach, we expand the tweets of a given user using their Twitter timeline\ntweets, and then we perform unsupervised classification of the user, which\nentails clustering a user with other users in the training set. This approach\nachieves 95.6% accuracy and 93.1% macro F-measure.", "published": "2020-04-07 15:35:55", "link": "http://arxiv.org/abs/2004.03485v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Towards Faithfully Interpretable NLP Systems: How should we define and\n  evaluate faithfulness?", "abstract": "With the growing popularity of deep-learning based NLP models, comes a need\nfor interpretable systems. But what is interpretability, and what constitutes a\nhigh-quality interpretation? In this opinion piece we reflect on the current\nstate of interpretability evaluation research. We call for more clearly\ndifferentiating between different desired criteria an interpretation should\nsatisfy, and focus on the faithfulness criteria. We survey the literature with\nrespect to faithfulness evaluation, and arrange the current approaches around\nthree assumptions, providing an explicit form to how faithfulness is \"defined\"\nby the community. We provide concrete guidelines on how evaluation of\ninterpretation methods should and should not be conducted. Finally, we claim\nthat the current binary definition for faithfulness sets a potentially\nunrealistic bar for being considered faithful. We call for discarding the\nbinary notion of faithfulness in favor of a more graded one, which we believe\nwill be of greater practical utility.", "published": "2020-04-07 20:15:28", "link": "http://arxiv.org/abs/2004.03685v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Evaluating the Robustness of Chinese BERT Classifiers", "abstract": "Recent advances in large-scale language representation models such as BERT\nhave improved the state-of-the-art performances in many NLP tasks. Meanwhile,\ncharacter-level Chinese NLP models, including BERT for Chinese, have also\ndemonstrated that they can outperform the existing models. In this paper, we\nshow that, however, such BERT-based models are vulnerable under character-level\nadversarial attacks. We propose a novel Chinese char-level attack method\nagainst BERT-based classifiers. Essentially, we generate \"small\" perturbation\non the character level in the embedding space and guide the character\nsubstitution procedure. Extensive experiments show that the classification\naccuracy on a Chinese news dataset drops from 91.8% to 0% by manipulating less\nthan 2 characters on average based on the proposed attack. Human evaluations\nalso confirm that our generated Chinese adversarial examples barely affect\nhuman performance on these NLP tasks.", "published": "2020-04-07 23:02:37", "link": "http://arxiv.org/abs/2004.03742v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TextGAIL: Generative Adversarial Imitation Learning for Text Generation", "abstract": "Generative Adversarial Networks (GANs) for text generation have recently\nreceived many criticisms, as they perform worse than their MLE counterparts. We\nsuspect previous text GANs' inferior performance is due to the lack of a\nreliable guiding signal in their discriminators. To address this problem, we\npropose a generative adversarial imitation learning framework for text\ngeneration that uses large pre-trained language models to provide more reliable\nreward guidance. Our approach uses contrastive discriminator, and proximal\npolicy optimization (PPO) to stabilize and improve text generation performance.\nFor evaluation, we conduct experiments on a diverse set of unconditional and\nconditional text generation tasks. Experimental results show that TextGAIL\nachieves better performance in terms of both quality and diversity than the MLE\nbaseline. We also validate our intuition that TextGAIL's discriminator\ndemonstrates the capability of providing reasonable rewards with an additional\ntask.", "published": "2020-04-07 00:24:35", "link": "http://arxiv.org/abs/2004.13796v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Knowledge Fusion and Semantic Knowledge Ranking for Open Domain Question\n  Answering", "abstract": "Open Domain Question Answering requires systems to retrieve external\nknowledge and perform multi-hop reasoning by composing knowledge spread over\nmultiple sentences. In the recently introduced open domain question answering\nchallenge datasets, QASC and OpenBookQA, we need to perform retrieval of facts\nand compose facts to correctly answer questions. In our work, we learn a\nsemantic knowledge ranking model to re-rank knowledge retrieved through Lucene\nbased information retrieval systems. We further propose a \"knowledge fusion\nmodel\" which leverages knowledge in BERT-based language models with externally\nretrieved knowledge and improves the knowledge understanding of the BERT-based\nlanguage models. On both OpenBookQA and QASC datasets, the knowledge fusion\nmodel with semantically re-ranked knowledge outperforms previous attempts.", "published": "2020-04-07 03:16:47", "link": "http://arxiv.org/abs/2004.03101v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neutralizing Gender Bias in Word Embedding with Latent Disentanglement\n  and Counterfactual Generation", "abstract": "Recent research demonstrates that word embeddings, trained on the\nhuman-generated corpus, have strong gender biases in embedding spaces, and\nthese biases can result in the discriminative results from the various\ndownstream tasks. Whereas the previous methods project word embeddings into a\nlinear subspace for debiasing, we introduce a \\textit{Latent Disentanglement}\nmethod with a siamese auto-encoder structure with an adapted gradient reversal\nlayer. Our structure enables the separation of the semantic latent information\nand gender latent information of given word into the disjoint latent\ndimensions. Afterwards, we introduce a \\textit{Counterfactual Generation} to\nconvert the gender information of words, so the original and the modified\nembeddings can produce a gender-neutralized word embedding after geometric\nalignment regularization, without loss of semantic information. From the\nvarious quantitative and qualitative debiasing experiments, our method shows to\nbe better than existing debiasing methods in debiasing word embeddings. In\naddition, Our method shows the ability to preserve semantic information during\ndebiasing by minimizing the semantic information losses for extrinsic NLP\ndownstream tasks.", "published": "2020-04-07 05:16:48", "link": "http://arxiv.org/abs/2004.03133v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Multilingual enrichment of disease biomedical ontologies", "abstract": "Translating biomedical ontologies is an important challenge, but doing it\nmanually requires much time and money. We study the possibility to use\nopen-source knowledge bases to translate biomedical ontologies. We focus on two\naspects: coverage and quality. We look at the coverage of two biomedical\nontologies focusing on diseases with respect to Wikidata for 9 European\nlanguages (Czech, Dutch, English, French, German, Italian, Polish, Portuguese\nand Spanish) for both ontologies, plus Arabic, Chinese and Russian for the\nsecond one. We first use direct links between Wikidata and the studied\nontologies and then use second-order links by going through other intermediate\nontologies. We then compare the quality of the translations obtained thanks to\nWikidata with a commercial machine translation tool, here Google Cloud\nTranslation.", "published": "2020-04-07 08:04:21", "link": "http://arxiv.org/abs/2004.03181v1", "categories": ["q-bio.QM", "cs.CL", "cs.IR"], "primary_category": "q-bio.QM"}
{"title": "Improving the Robustness of QA Models to Challenge Sets with Variational\n  Question-Answer Pair Generation", "abstract": "Question answering (QA) models for reading comprehension have achieved\nhuman-level accuracy on in-distribution test sets. However, they have been\ndemonstrated to lack robustness to challenge sets, whose distribution is\ndifferent from that of training sets. Existing data augmentation methods\nmitigate this problem by simply augmenting training sets with synthetic\nexamples sampled from the same distribution as the challenge sets. However,\nthese methods assume that the distribution of a challenge set is known a\npriori, making them less applicable to unseen challenge sets. In this study, we\nfocus on question-answer pair generation (QAG) to mitigate this problem. While\nmost existing QAG methods aim to improve the quality of synthetic examples, we\nconjecture that diversity-promoting QAG can mitigate the sparsity of training\nsets and lead to better robustness. We present a variational QAG model that\ngenerates multiple diverse QA pairs from a paragraph. Our experiments show that\nour method can improve the accuracy of 12 challenge sets, as well as the\nin-distribution accuracy. Our code and data are available at\nhttps://github.com/KazutoshiShinoda/VQAG.", "published": "2020-04-07 10:15:19", "link": "http://arxiv.org/abs/2004.03238v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MedDialog: Two Large-scale Medical Dialogue Datasets", "abstract": "Medical dialogue systems are promising in assisting in telemedicine to\nincrease access to healthcare services, improve the quality of patient care,\nand reduce medical costs. To facilitate the research and development of medical\ndialogue systems, we build two large-scale medical dialogue datasets:\nMedDialog-EN and MedDialog-CN. MedDialog-EN is an English dataset containing\n0.3 million conversations between patients and doctors and 0.5 million\nutterances. MedDialog-CN is an Chinese dataset containing 1.1 million\nconversations and 4 million utterances. To our best knowledge,\nMedDialog-(EN,CN) are the largest medical dialogue datasets to date. The\ndataset is available at https://github.com/UCSD-AI4H/Medical-Dialogue-System", "published": "2020-04-07 13:07:09", "link": "http://arxiv.org/abs/2004.03329v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Evaluating Online Continual Learning with CALM", "abstract": "Online Continual Learning (OCL) studies learning over a continuous data\nstream without observing any single example more than once, a setting that is\ncloser to the experience of humans and systems that must learn \"on-the-wild\".\nYet, commonly available benchmarks are far from these real-world conditions,\nbecause they explicitly signal different tasks, lack latent similarity\nstructure or assume temporal independence between different examples. Here, we\npropose a new benchmark for OCL based on language modelling in which input\nalternates between different languages and domains without any explicit\ndelimitation. Additionally, we propose new metrics to study catastrophic\nforgetting in this setting and evaluate multiple baseline models based on\ncompositions of experts. Finally, we introduce a simple gating technique that\nlearns the latent similarities between different inputs, improving the\nperformance of a Products of Experts model.", "published": "2020-04-07 13:17:05", "link": "http://arxiv.org/abs/2004.03340v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Homophone-based Label Smoothing in End-to-End Automatic Speech\n  Recognition", "abstract": "A new label smoothing method that makes use of prior knowledge of a language\nat human level, homophone, is proposed in this paper for automatic speech\nrecognition (ASR). Compared with its forerunners, the proposed method uses\npronunciation knowledge of homophones in a more complex way. End-to-end ASR\nmodels that learn acoustic model and language model jointly and modelling units\nof characters are necessary conditions for this method. Experiments with hybrid\nCTC sequence-to-sequence model show that the new method can reduce character\nerror rate (CER) by 0.4% absolutely.", "published": "2020-04-07 14:37:30", "link": "http://arxiv.org/abs/2004.03437v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Automated Utterance Generation", "abstract": "Conversational AI assistants are becoming popular and question-answering is\nan important part of any conversational assistant. Using relevant utterances as\nfeatures in question-answering has shown to improve both the precision and\nrecall for retrieving the right answer by a conversational assistant. Hence,\nutterance generation has become an important problem with the goal of\ngenerating relevant utterances (sentences or phrases) from a knowledge base\narticle that consists of a title and a description. However, generating good\nutterances usually requires a lot of manual effort, creating the need for an\nautomated utterance generation. In this paper, we propose an utterance\ngeneration system which 1) uses extractive summarization to extract important\nsentences from the description, 2) uses multiple paraphrasing techniques to\ngenerate a diverse set of paraphrases of the title and summary sentences, and\n3) selects good candidate paraphrases with the help of a novel candidate\nselection algorithm.", "published": "2020-04-07 15:35:54", "link": "http://arxiv.org/abs/2004.03484v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for\n  Span-based Question Answering", "abstract": "We introduce a novel approach to transformers that learns hierarchical\nrepresentations in multiparty dialogue. First, three language modeling tasks\nare used to pre-train the transformers, token- and utterance-level language\nmodeling and utterance order prediction, that learn both token and utterance\nembeddings for better understanding in dialogue contexts. Then, multi-task\nlearning between the utterance prediction and the token span prediction is\napplied to fine-tune for span-based question answering (QA). Our approach is\nevaluated on the FriendsQA dataset and shows improvements of 3.8% and 1.4% over\nthe two state-of-the-art transformer models, BERT and RoBERTa, respectively.", "published": "2020-04-07 17:36:33", "link": "http://arxiv.org/abs/2004.03561v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Salience Estimation with Multi-Attention Learning for Abstractive Text\n  Summarization", "abstract": "Attention mechanism plays a dominant role in the sequence generation models\nand has been used to improve the performance of machine translation and\nabstractive text summarization. Different from neural machine translation, in\nthe task of text summarization, salience estimation for words, phrases or\nsentences is a critical component, since the output summary is a distillation\nof the input text. Although the typical attention mechanism can conduct text\nfragment selection from the input text conditioned on the decoder states, there\nis still a gap to conduct direct and effective salience detection. To bring\nback direct salience estimation for summarization with neural networks, we\npropose a Multi-Attention Learning framework which contains two new attention\nlearning components for salience estimation: supervised attention learning and\nunsupervised attention learning. We regard the attention weights as the\nsalience information, which means that the semantic units with large attention\nvalue will be more important. The context information obtained based on the\nestimated salience is incorporated with the typical attention mechanism in the\ndecoder to conduct summary generation. Extensive experiments on some benchmark\ndatasets in different languages demonstrate the effectiveness of the proposed\nframework for the task of abstractive summarization.", "published": "2020-04-07 02:38:56", "link": "http://arxiv.org/abs/2004.03589v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient long-distance relation extraction with DG-SpanBERT", "abstract": "In natural language processing, relation extraction seeks to rationally\nunderstand unstructured text. Here, we propose a novel SpanBERT-based graph\nconvolutional network (DG-SpanBERT) that extracts semantic features from a raw\nsentence using the pre-trained language model SpanBERT and a graph\nconvolutional network to pool latent features. Our DG-SpanBERT model inherits\nthe advantage of SpanBERT on learning rich lexical features from large-scale\ncorpus. It also has the ability to capture long-range relations between\nentities due to the usage of GCN on dependency tree. The experimental results\nshow that our model outperforms other existing dependency-based and\nsequence-based models and achieves a state-of-the-art performance on the TACRED\ndataset.", "published": "2020-04-07 18:21:47", "link": "http://arxiv.org/abs/2004.03636v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Faithful Embeddings for Knowledge Base Queries", "abstract": "The deductive closure of an ideal knowledge base (KB) contains exactly the\nlogical queries that the KB can answer. However, in practice KBs are both\nincomplete and over-specified, failing to answer some queries that have\nreal-world answers. \\emph{Query embedding} (QE) techniques have been recently\nproposed where KB entities and KB queries are represented jointly in an\nembedding space, supporting relaxation and generalization in KB inference.\nHowever, experiments in this paper show that QE systems may disagree with\ndeductive reasoning on answers that do not require generalization or\nrelaxation. We address this problem with a novel QE method that is more\nfaithful to deductive reasoning, and show that this leads to better performance\non complex queries to incomplete KBs. Finally we show that inserting this new\nQE module into a neural question-answering system leads to substantial\nimprovements over the state-of-the-art.", "published": "2020-04-07 19:25:16", "link": "http://arxiv.org/abs/2004.03658v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Query-controllable Video Summarization", "abstract": "When video collections become huge, how to explore both within and across\nvideos efficiently is challenging. Video summarization is one of the ways to\ntackle this issue. Traditional summarization approaches limit the effectiveness\nof video exploration because they only generate one fixed video summary for a\ngiven input video independent of the information need of the user. In this\nwork, we introduce a method which takes a text-based query as input and\ngenerates a video summary corresponding to it. We do so by modeling video\nsummarization as a supervised learning problem and propose an end-to-end deep\nlearning based method for query-controllable video summarization to generate a\nquery-dependent video summary. Our proposed method consists of a video summary\ncontroller, video summary generator, and video summary output module. To foster\nthe research of query-controllable video summarization and conduct our\nexperiments, we introduce a dataset that contains frame-based relevance score\nlabels. Based on our experimental result, it shows that the text-based query\nhelps control the video summary. It also shows the text-based query improves\nour model performance. Our code and dataset:\nhttps://github.com/Jhhuangkay/Query-controllable-Video-Summarization.", "published": "2020-04-07 19:35:04", "link": "http://arxiv.org/abs/2004.03661v1", "categories": ["cs.IR", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Locality Preserving Loss: Neighbors that Live together, Align together", "abstract": "We present a locality preserving loss (LPL) that improves the alignment\nbetween vector space embeddings while separating uncorrelated representations.\nGiven two pretrained embedding manifolds, LPL optimizes a model to project an\nembedding and maintain its local neighborhood while aligning one manifold to\nanother. This reduces the overall size of the dataset required to align the two\nin tasks such as cross-lingual word alignment. We show that the LPL-based\nalignment between input vector spaces acts as a regularizer, leading to better\nand consistent accuracy than the baseline, especially when the size of the\ntraining set is small. We demonstrate the effectiveness of LPL optimized\nalignment on semantic text similarity (STS), natural language inference (SNLI),\nmulti-genre language inference (MNLI) and cross-lingual word alignment(CLA)\nshowing consistent improvements, finding up to 16% improvement over our\nbaseline in lower resource settings.", "published": "2020-04-07 22:26:09", "link": "http://arxiv.org/abs/2004.03734v2", "categories": ["cs.LG", "cs.CL", "stat.ML", "I.2.7"], "primary_category": "cs.LG"}
{"title": "e-SNLI-VE: Corrected Visual-Textual Entailment with Natural Language\n  Explanations", "abstract": "The recently proposed SNLI-VE corpus for recognising visual-textual\nentailment is a large, real-world dataset for fine-grained multimodal\nreasoning. However, the automatic way in which SNLI-VE has been assembled (via\ncombining parts of two related datasets) gives rise to a large number of errors\nin the labels of this corpus. In this paper, we first present a data collection\neffort to correct the class with the highest error rate in SNLI-VE. Secondly,\nwe re-evaluate an existing model on the corrected corpus, which we call\nSNLI-VE-2.0, and provide a quantitative comparison with its performance on the\nnon-corrected corpus. Thirdly, we introduce e-SNLI-VE, which appends\nhuman-written natural language explanations to SNLI-VE-2.0. Finally, we train\nmodels that learn from these explanations at training time, and output such\nexplanations at testing time.", "published": "2020-04-07 23:12:51", "link": "http://arxiv.org/abs/2004.03744v3", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Graph-to-Tree Neural Networks for Learning Structured Input-Output\n  Translation with Applications to Semantic Parsing and Math Word Problem", "abstract": "The celebrated Seq2Seq technique and its numerous variants achieve excellent\nperformance on many tasks such as neural machine translation, semantic parsing,\nand math word problem solving. However, these models either only consider input\nobjects as sequences while ignoring the important structural information for\nencoding, or they simply treat output objects as sequence outputs instead of\nstructural objects for decoding. In this paper, we present a novel\nGraph-to-Tree Neural Networks, namely Graph2Tree consisting of a graph encoder\nand a hierarchical tree decoder, that encodes an augmented graph-structured\ninput and decodes a tree-structured output. In particular, we investigated our\nmodel for solving two problems, neural semantic parsing and math word problem.\nOur extensive experiments demonstrate that our Graph2Tree model outperforms or\nmatches the performance of other state-of-the-art models on these tasks.", "published": "2020-04-07 17:36:38", "link": "http://arxiv.org/abs/2004.13781v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Improving Multi-Scale Aggregation Using Feature Pyramid Module for\n  Robust Speaker Verification of Variable-Duration Utterances", "abstract": "Currently, the most widely used approach for speaker verification is the deep\nspeaker embedding learning. In this approach, we obtain a speaker embedding\nvector by pooling single-scale features that are extracted from the last layer\nof a speaker feature extractor. Multi-scale aggregation (MSA), which utilizes\nmulti-scale features from different layers of the feature extractor, has\nrecently been introduced and shows superior performance for variable-duration\nutterances. To increase the robustness dealing with utterances of arbitrary\nduration, this paper improves the MSA by using a feature pyramid module. The\nmodule enhances speaker-discriminative information of features from multiple\nlayers via a top-down pathway and lateral connections. We extract speaker\nembeddings using the enhanced features that contain rich speaker information\nwith different time scales. Experiments on the VoxCeleb dataset show that the\nproposed module improves previous MSA methods with a smaller number of\nparameters. It also achieves better performance than state-of-the-art\napproaches for both short and long utterances.", "published": "2020-04-07 08:35:05", "link": "http://arxiv.org/abs/2004.03194v4", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Direct Speech-to-image Translation", "abstract": "Direct speech-to-image translation without text is an interesting and useful\ntopic due to the potential applications in human-computer interaction, art\ncreation, computer-aided design. etc. Not to mention that many languages have\nno writing form. However, as far as we know, it has not been well-studied how\nto translate the speech signals into images directly and how well they can be\ntranslated. In this paper, we attempt to translate the speech signals into the\nimage signals without the transcription stage. Specifically, a speech encoder\nis designed to represent the input speech signals as an embedding feature, and\nit is trained with a pretrained image encoder using teacher-student learning to\nobtain better generalization ability on new classes. Subsequently, a stacked\ngenerative adversarial network is used to synthesize high-quality images\nconditioned on the embedding feature. Experimental results on both synthesized\nand real data show that our proposed method is effective to translate the raw\nspeech signals into images without the middle text representation. Ablation\nstudy gives more insights about our method.", "published": "2020-04-07 14:05:30", "link": "http://arxiv.org/abs/2004.03413v2", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Universal Adversarial Perturbations Generative Network for Speaker\n  Recognition", "abstract": "Attacking deep learning based biometric systems has drawn more and more\nattention with the wide deployment of fingerprint/face/speaker recognition\nsystems, given the fact that the neural networks are vulnerable to the\nadversarial examples, which have been intentionally perturbed to remain almost\nimperceptible for human. In this paper, we demonstrated the existence of the\nuniversal adversarial perturbations~(UAPs) for the speaker recognition systems.\nWe proposed a generative network to learn the mapping from the low-dimensional\nnormal distribution to the UAPs subspace, then synthesize the UAPs to perturbe\nany input signals to spoof the well-trained speaker recognition model with high\nprobability. Experimental results on TIMIT and LibriSpeech datasets demonstrate\nthe effectiveness of our model.", "published": "2020-04-07 14:22:10", "link": "http://arxiv.org/abs/2004.03428v1", "categories": ["eess.AS", "cs.CR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Learning to fool the speaker recognition", "abstract": "Due to the widespread deployment of fingerprint/face/speaker recognition\nsystems, attacking deep learning based biometric systems has drawn more and\nmore attention. Previous research mainly studied the attack to the vision-based\nsystem, such as fingerprint and face recognition. While the attack for speaker\nrecognition has not been investigated yet, although it has been widely used in\nour daily life. In this paper, we attempt to fool the state-of-the-art speaker\nrecognition model and present \\textit{speaker recognition attacker}, a\nlightweight model to fool the deep speaker recognition model by adding\nimperceptible perturbations onto the raw speech waveform. We find that the\nspeaker recognition system is also vulnerable to the attack, and we achieve a\nhigh success rate on the non-targeted attack. Besides, we also present an\neffective method to optimize the speaker recognition attacker to obtain a\ntrade-off between the attack success rate with the perceptual quality.\nExperiments on the TIMIT dataset show that we can achieve a sentence error rate\nof $99.2\\%$ with an average SNR $57.2\\text{dB}$ and PESQ 4.2 with speed rather\nfaster than real-time.", "published": "2020-04-07 14:29:28", "link": "http://arxiv.org/abs/2004.03434v1", "categories": ["eess.AS", "cs.CR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "SNR-Based Features and Diverse Training Data for Robust DNN-Based Speech\n  Enhancement", "abstract": "In this paper, we address the generalization of deep neural network (DNN)\nbased speech enhancement to unseen noise conditions for the case that training\ndata is limited in size and diversity. To gain more insights, we analyze the\ngeneralization with respect to (1) the size and diversity of the training data,\n(2) different network architectures, and (3) the chosen features. To address\n(1), we train networks on the Hu noise corpus (limited size), the CHiME 3 noise\ncorpus (limited diversity) and also propose a large and diverse dataset\ncollected based on freely available sounds. To address (2), we compare a\nfully-connected feed-forward and a long short-term memory (LSTM) architecture.\nTo address (3), we compare three input features, namely logarithmized noisy\nperiodograms, noise aware training (NAT) and the proposed signal-to-noise ratio\n(SNR) based noise aware training (SNR-NAT). We confirm that rich training data\nand improved network architectures help DNNs to generalize. Furthermore, we\nshow via experimental results and an analysis using t-distributed stochastic\nneighbor embedding (t-SNE) that the proposed SNR-NAT features yield robust and\nlevel independent results in unseen noise even with simple network\narchitectures and when trained on only small datasets, which is the key\ncontribution of this paper.", "published": "2020-04-07 16:09:54", "link": "http://arxiv.org/abs/2004.03512v2", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep Normalization for Speaker Vectors", "abstract": "Deep speaker embedding has demonstrated state-of-the-art performance in\nspeaker recognition tasks. However, one potential issue with this approach is\nthat the speaker vectors derived from deep embedding models tend to be\nnon-Gaussian for each individual speaker, and non-homogeneous for distributions\nof different speakers. These irregular distributions can seriously impact\nspeaker recognition performance, especially with the popular PLDA scoring\nmethod, which assumes homogeneous Gaussian distribution. In this paper, we\nargue that deep speaker vectors require deep normalization, and propose a deep\nnormalization approach based on a novel discriminative normalization flow (DNF)\nmodel. We demonstrate the effectiveness of the proposed approach with\nexperiments using the widely used SITW and CNCeleb corpora. In these\nexperiments, the DNF-based normalization delivered substantial performance\ngains and also showed strong generalization capability in out-of-domain tests.", "published": "2020-04-07 09:20:48", "link": "http://arxiv.org/abs/2004.04095v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Keywords Extraction and Sentiment Analysis using Automatic Speech\n  Recognition", "abstract": "Automatic Speech Recognition (ASR) is the interdisciplinary subfield of\ncomputational linguistics that develops methodologies and technologies that\nenables the recognition and translation of spoken language into text by\ncomputers. It incorporates knowledge and research in linguistics, computer\nscience, and electrical engineering fields. Sentiment analysis is contextual\nmining of text which identifies and extracts subjective information in the\nsource material and helping a business to understand the social sentiment of\ntheir brand, product or service while monitoring online conversations.\nAccording to the speech structure, three models are used in speech recognition\nto do the match: Acoustic Model, Phonetic Dictionary and Language Model. Any\nspeech recognition program is evaluated using two factors: Accuracy (percentage\nerror in converting spoken words to digital data) and Speed (the extent to\nwhich the program can keep up with a human speaker). For the purpose of\nconverting speech to text (STT), we will be studying the following open source\ntoolkits: CMU Sphinx and Kaldi. The toolkits use Mel-Frequency Cepstral\nCoefficients (MFCC) and I-vector for feature extraction. CMU Sphinx has been\nused with pre-trained Hidden Markov Models (HMM) and Gaussian Mixture Models\n(GMM), while Kaldi is used with pre-trained Neural Networks (NNET) as acoustic\nmodels. The n-gram language models contain the phonemes or pdf-ids for\ngenerating the most probable hypothesis (transcription) in the form of a\nlattice. The speech dataset is stored in the form of .raw or .wav file and is\ntranscribed in .txt file. The system then tries to identify opinions within the\ntext, and extract the following attributes: Polarity (if the speaker expresses\na positive or negative opinion) and Keywords (the thing that is being talked\nabout).", "published": "2020-04-07 05:37:36", "link": "http://arxiv.org/abs/2004.04099v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "primary_category": "eess.AS"}
{"title": "From Artificial Neural Networks to Deep Learning for Music Generation --\n  History, Concepts and Trends", "abstract": "The current wave of deep learning (the hyper-vitamined return of artificial\nneural networks) applies not only to traditional statistical machine learning\ntasks: prediction and classification (e.g., for weather prediction and pattern\nrecognition), but has already conquered other areas, such as translation. A\ngrowing area of application is the generation of creative content, notably the\ncase of music, the topic of this paper. The motivation is in using the capacity\nof modern deep learning techniques to automatically learn musical styles from\narbitrary musical corpora and then to generate musical samples from the\nestimated distribution, with some degree of control over the generation. This\npaper provides a tutorial on music generation based on deep learning\ntechniques. After a short introduction to the topic illustrated by a recent\nexemple, the paper analyzes some early works from the late 1980s using\nartificial neural networks for music generation and how their pioneering\ncontributions have prefigured current techniques. Then, we introduce some\nconceptual framework to analyze the various concepts and dimensions involved.\nVarious examples of recent systems are introduced and analyzed to illustrate\nthe variety of concerns and of techniques.", "published": "2020-04-07 00:33:56", "link": "http://arxiv.org/abs/2004.03586v2", "categories": ["eess.AS", "cs.LG", "cs.MM", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
