{"title": "What Words Do We Use to Lie?: Word Choice in Deceptive Messages", "abstract": "Text messaging is the most widely used form of computer-mediated\ncommunication (CMC). Previous findings have shown that linguistic factors can\nreliably indicate messages as deceptive. For example, users take longer and use\nmore words to craft deceptive messages than they do truthful messages. Existing\nresearch has also examined how factors, such as student status and gender,\naffect rates of deception and word choice in deceptive messages. However, this\nresearch has been limited by small sample sizes and has returned contradicting\nfindings. This paper aims to address these issues by using a dataset of text\nmessages collected from a large and varied set of participants using an Android\nmessaging application. The results of this paper show significant differences\nin word choice and frequency of deceptive messages between male and female\nparticipants, as well as between students and non-students.", "published": "2017-10-01 00:04:10", "link": "http://arxiv.org/abs/1710.00273v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fully Automated Fact Checking Using External Sources", "abstract": "Given the constantly growing proliferation of false claims online in recent\nyears, there has been also a growing research interest in automatically\ndistinguishing false rumors from factually true claims. Here, we propose a\ngeneral-purpose framework for fully-automatic fact checking using external\nsources, tapping the potential of the entire Web as a knowledge source to\nconfirm or reject a claim. Our framework uses a deep neural network with LSTM\ntext encoding to combine semantic kernels with task-specific embeddings that\nencode a claim together with pieces of potentially-relevant text fragments from\nthe Web, taking the source reliability into account. The evaluation results\nshow good performance on two different tasks and datasets: (i) rumor detection\nand (ii) fact checking of the answers to a question in community question\nanswering forums.", "published": "2017-10-01 12:54:50", "link": "http://arxiv.org/abs/1710.00341v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Robust Tuning Datasets for Statistical Machine Translation", "abstract": "We explore the idea of automatically crafting a tuning dataset for\nStatistical Machine Translation (SMT) that makes the hyper-parameters of the\nSMT system more robust with respect to some specific deficiencies of the\nparameter tuning algorithms. This is an under-explored research direction,\nwhich can allow better parameter tuning. In this paper, we achieve this goal by\nselecting a subset of the available sentence pairs, which are more suitable for\nspecific combinations of optimizers, objective functions, and evaluation\nmeasures. We demonstrate the potential of the idea with the pairwise ranking\noptimization (PRO) optimizer, which is known to yield too short translations.\nWe show that the learning problem can be alleviated by tuning on a subset of\nthe development set, selected based on sentence length. In particular, using\nthe longest 50% of the tuning sentences, we achieve two-fold tuning speedup,\nand improvements in BLEU score that rival those of alternatives, which fix\nBLEU+1's smoothing instead.", "published": "2017-10-01 13:18:48", "link": "http://arxiv.org/abs/1710.00346v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Efficient and Effective Single-Document Summarizations and A\n  Word-Embedding Measurement of Quality", "abstract": "Our task is to generate an effective summary for a given document with\nspecific realtime requirements. We use the softplus function to enhance keyword\nrankings to favor important sentences, based on which we present a number of\nsummarization algorithms using various keyword extraction and topic clustering\nmethods. We show that our algorithms meet the realtime requirements and yield\nthe best ROUGE recall scores on DUC-02 over all previously-known algorithms. We\nshow that our algorithms meet the realtime requirements and yield the best\nROUGE recall scores on DUC-02 over all previously-known algorithms. To evaluate\nthe quality of summaries without human-generated benchmarks, we define a\nmeasure called WESM based on word-embedding using Word Mover's Distance. We\nshow that the orderings of the ROUGE and WESM scores of our algorithms are\nhighly comparable, suggesting that WESM may serve as a viable alternative for\nmeasuring the quality of a summary.", "published": "2017-10-01 03:36:45", "link": "http://arxiv.org/abs/1710.00284v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "DTATG: An Automatic Title Generator based on Dependency Trees", "abstract": "We study automatic title generation for a given block of text and present a\nmethod called DTATG to generate titles. DTATG first extracts a small number of\ncentral sentences that convey the main meanings of the text and are in a\nsuitable structure for conversion into a title. DTATG then constructs a\ndependency tree for each of these sentences and removes certain branches using\na Dependency Tree Compression Model we devise. We also devise a title test to\ndetermine if a sentence can be used as a title. If a trimmed sentence passes\nthe title test, then it becomes a title candidate. DTATG selects the title\ncandidate with the highest ranking score as the final title. Our experiments\nshowed that DTATG can generate adequate titles. We also showed that\nDTATG-generated titles have higher F1 scores than those generated by the\nprevious methods.", "published": "2017-10-01 03:52:37", "link": "http://arxiv.org/abs/1710.00286v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Mathematical foundations of matrix syntax", "abstract": "Matrix syntax is a formal model of syntactic relations in language. The\npurpose of this paper is to explain its mathematical foundations, for an\naudience with some formal background. We make an axiomatic presentation,\nmotivating each axiom on linguistic and practical grounds. The resulting\nmathematical structure resembles some aspects of quantum mechanics. Matrix\nsyntax allows us to describe a number of language phenomena that are otherwise\nvery difficult to explain, such as linguistic chains, and is arguably a more\neconomical theory of language than most of the theories proposed in the context\nof the minimalist program in linguistics. In particular, sentences are\nnaturally modelled as vectors in a Hilbert space with a tensor product\nstructure, built from 2x2 matrices belonging to some specific group.", "published": "2017-10-01 15:55:17", "link": "http://arxiv.org/abs/1710.00372v2", "categories": ["cs.CL", "quant-ph"], "primary_category": "cs.CL"}
{"title": "Large-scale weakly supervised audio classification using gated\n  convolutional neural network", "abstract": "In this paper, we present a gated convolutional neural network and a temporal\nattention-based localization method for audio classification, which won the 1st\nplace in the large-scale weakly supervised sound event detection task of\nDetection and Classification of Acoustic Scenes and Events (DCASE) 2017\nchallenge. The audio clips in this task, which are extracted from YouTube\nvideos, are manually labeled with one or a few audio tags but without\ntimestamps of the audio events, which is called as weakly labeled data. Two\nsub-tasks are defined in this challenge including audio tagging and sound event\ndetection using this weakly labeled data. A convolutional recurrent neural\nnetwork (CRNN) with learnable gated linear units (GLUs) non-linearity applied\non the log Mel spectrogram is proposed. In addition, a temporal attention\nmethod is proposed along the frames to predicate the locations of each audio\nevent in a chunk from the weakly labeled data. We ranked the 1st and the 2nd as\na team in these two sub-tasks of DCASE 2017 challenge with F value 55.6\\% and\nEqual error 0.73, respectively.", "published": "2017-10-01 12:57:45", "link": "http://arxiv.org/abs/1710.00343v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
