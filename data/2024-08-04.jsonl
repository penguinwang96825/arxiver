{"title": "Cross-layer Attention Sharing for Large Language Models", "abstract": "As large language models (LLMs) evolve, the increase in model depth and\nparameter number leads to substantial redundancy. To enhance the efficiency of\nthe attention mechanism, previous works primarily compress the KV cache or\ngroup attention heads, while largely overlooking redundancy between layers. Our\ncomprehensive analyses across various LLMs show that highly similar attention\npatterns persist within most layers. It's intuitive to save the computation by\nsharing attention weights across layers. However, further analysis reveals two\nchallenges: (1) Directly sharing the weight matrix without carefully\nrearranging the attention heads proves to be ineffective; (2) Shallow layers\nare vulnerable to small deviations in attention weights. Driven by these\ninsights, we introduce LiSA, a lightweight substitute for self-attention in\nwell-trained LLMs. LiSA employs tiny feed-forward networks to align attention\nheads between adjacent layers and low-rank matrices to approximate differences\nin layer-wise attention weights. Evaluations encompassing 13 typical benchmarks\ndemonstrate that LiSA maintains high response quality in terms of accuracy and\nperplexity while reducing redundant attention calculations within 53-84% of the\ntotal layers. Our implementations of LiSA achieve a 6X compression of Q and K,\nwith maximum throughput improvements of 19.5% for LLaMA3-8B and 32.3% for\nLLaMA2-7B.", "published": "2024-08-04 00:38:34", "link": "http://arxiv.org/abs/2408.01890v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Optimal and efficient text counterfactuals using Graph Neural Networks", "abstract": "As NLP models become increasingly integral to decision-making processes, the\nneed for explainability and interpretability has become paramount. In this\nwork, we propose a framework that achieves the aforementioned by generating\nsemantically edited inputs, known as counterfactual interventions, which change\nthe model prediction, thus providing a form of counterfactual explanations for\nthe model. We test our framework on two NLP tasks - binary sentiment\nclassification and topic classification - and show that the generated edits are\ncontrastive, fluent and minimal, while the whole process remains significantly\nfaster that other state-of-the-art counterfactual editors.", "published": "2024-08-04 09:09:13", "link": "http://arxiv.org/abs/2408.01969v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLaSA: Large Language and E-Commerce Shopping Assistant", "abstract": "The e-commerce platform has evolved rapidly due to its widespread popularity\nand convenience. Developing an e-commerce shopping assistant for customers is\ncrucial to aiding them in quickly finding desired products and recommending\nprecisely what they need. However, most previous shopping assistants face two\nmain problems: (1) task-specificity, which necessitates the development of\ndifferent models for various tasks, thereby increasing development costs and\nlimiting effectiveness; and (2) poor generalization, where the trained model\nperforms inadequately on up-to-date products. To resolve these issues, we\nemploy Large Language Models (LLMs) to construct an omnipotent assistant,\nleveraging their adeptness at handling multiple tasks and their superior\ngeneralization capability. Nonetheless, LLMs lack inherent knowledge of\ne-commerce concepts. To address this, we create an instruction dataset\ncomprising 65,000 samples and diverse tasks, termed as EshopInstruct. Through\ninstruction tuning on our dataset, the assistant, named LLaSA, demonstrates the\npotential to function as an omnipotent assistant. Additionally, we propose\nvarious inference optimization strategies to enhance performance with limited\ninference resources. In the Amazon KDD Cup 2024 Challenge, our proposed method,\nLLaSA, achieved an overall ranking of 3rd place on ShopBench, including 57\ntasks and approximately 20,000 questions, and we secured top-5 rankings in each\ntrack, especially in track4, where we achieved the best performance result\namong all student teams. Our extensive practices fully demonstrate that LLMs\npossess the great potential to be competent e-commerce shopping assistants.", "published": "2024-08-04 12:10:51", "link": "http://arxiv.org/abs/2408.02006v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Effective Demonstration Annotation for In-Context Learning via Language\n  Model-Based Determinantal Point Process", "abstract": "In-context learning (ICL) is a few-shot learning paradigm that involves\nlearning mappings through input-output pairs and appropriately applying them to\nnew instances. Despite the remarkable ICL capabilities demonstrated by Large\nLanguage Models (LLMs), existing works are highly dependent on large-scale\nlabeled support sets, not always feasible in practical scenarios. To refine\nthis approach, we focus primarily on an innovative selective annotation\nmechanism, which precedes the standard demonstration retrieval. We introduce\nthe Language Model-based Determinant Point Process (LM-DPP) that simultaneously\nconsiders the uncertainty and diversity of unlabeled instances for optimal\nselection. Consequently, this yields a subset for annotation that strikes a\ntrade-off between the two factors. We apply LM-DPP to various language models,\nincluding GPT-J, LlaMA, and GPT-3. Experimental results on 9 NLU and 2\nGeneration datasets demonstrate that LM-DPP can effectively select canonical\nexamples. Further analysis reveals that LLMs benefit most significantly from\nsubsets that are both low uncertainty and high diversity.", "published": "2024-08-04 18:08:15", "link": "http://arxiv.org/abs/2408.02103v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Table Transformers for Imputing Textual Attributes", "abstract": "Missing data in tabular dataset is a common issue as the performance of\ndownstream tasks usually depends on the completeness of the training dataset.\nPrevious missing data imputation methods focus on numeric and categorical\ncolumns, but we propose a novel end-to-end approach called Table Transformers\nfor Imputing Textual Attributes (TTITA) based on the transformer to impute\nunstructured textual columns using other columns in the table. We conduct\nextensive experiments on three datasets, and our approach shows competitive\nperformance outperforming baseline models such as recurrent neural networks and\nLlama2. The performance improvement is more significant when the target\nsequence has a longer length. Additionally, we incorporate multi-task learning\nto simultaneously impute for heterogeneous columns, boosting the performance\nfor text imputation. We also qualitatively compare with ChatGPT for realistic\napplications.", "published": "2024-08-04 19:54:12", "link": "http://arxiv.org/abs/2408.02128v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language\n  Models", "abstract": "Large language models (LLMs) have recently showcased remarkable capabilities,\nspanning a wide range of tasks and applications, including those in the medical\ndomain. Models like GPT-4 excel in medical question answering but may face\nchallenges in the lack of interpretability when handling complex tasks in real\nclinical settings. We thus introduce the diagnostic reasoning dataset for\nclinical notes (DiReCT), aiming at evaluating the reasoning ability and\ninterpretability of LLMs compared to human doctors. It contains 511 clinical\nnotes, each meticulously annotated by physicians, detailing the diagnostic\nreasoning process from observations in a clinical note to the final diagnosis.\nAdditionally, a diagnostic knowledge graph is provided to offer essential\nknowledge for reasoning, which may not be covered in the training data of\nexisting LLMs. Evaluations of leading LLMs on DiReCT bring out a significant\ngap between their reasoning ability and that of human doctors, highlighting the\ncritical need for models that can reason effectively in real-world clinical\nscenarios.", "published": "2024-08-04 05:15:02", "link": "http://arxiv.org/abs/2408.01933v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Defining and Evaluating Decision and Composite Risk in Language Models\n  Applied to Natural Language Inference", "abstract": "Despite their impressive performance, large language models (LLMs) such as\nChatGPT are known to pose important risks. One such set of risks arises from\nmisplaced confidence, whether over-confidence or under-confidence, that the\nmodels have in their inference. While the former is well studied, the latter is\nnot, leading to an asymmetry in understanding the comprehensive risk of the\nmodel based on misplaced confidence. In this paper, we address this asymmetry\nby defining two types of risk (decision and composite risk), and proposing an\nexperimental framework consisting of a two-level inference architecture and\nappropriate metrics for measuring such risks in both discriminative and\ngenerative LLMs. The first level relies on a decision rule that determines\nwhether the underlying language model should abstain from inference. The second\nlevel (which applies if the model does not abstain) is the model's inference.\nDetailed experiments on four natural language commonsense reasoning datasets\nusing both an open-source ensemble-based RoBERTa model and ChatGPT, demonstrate\nthe practical utility of the evaluation framework. For example, our results\nshow that our framework can get an LLM to confidently respond to an extra 20.1%\nof low-risk inference tasks that other methods might misclassify as high-risk,\nand skip 19.8% of high-risk tasks, which would have been answered incorrectly.", "published": "2024-08-04 05:24:32", "link": "http://arxiv.org/abs/2408.01935v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Novel Metric for Measuring the Robustness of Large Language Models in\n  Non-adversarial Scenarios", "abstract": "We evaluate the robustness of several large language models on multiple\ndatasets. Robustness here refers to the relative insensitivity of the model's\nanswers to meaning-preserving variants of their input. Benchmark datasets are\nconstructed by introducing naturally-occurring, non-malicious perturbations, or\nby generating semantically equivalent paraphrases of input questions or\nstatements. We further propose a novel metric for assessing a model robustness,\nand demonstrate its benefits in the non-adversarial scenario by empirical\nevaluation of several models on the created datasets.", "published": "2024-08-04 08:43:09", "link": "http://arxiv.org/abs/2408.01963v4", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Fine-tuning multilingual language models in Twitter/X sentiment\n  analysis: a study on Eastern-European V4 languages", "abstract": "The aspect-based sentiment analysis (ABSA) is a standard NLP task with\nnumerous approaches and benchmarks, where large language models (LLM) represent\nthe current state-of-the-art. We focus on ABSA subtasks based on Twitter/X data\nin underrepresented languages. On such narrow tasks, small tuned language\nmodels can often outperform universal large ones, providing available and cheap\nsolutions.\n  We fine-tune several LLMs (BERT, BERTweet, Llama2, Llama3, Mistral) for\nclassification of sentiment towards Russia and Ukraine in the context of the\nongoing military conflict. The training/testing dataset was obtained from the\nacademic API from Twitter/X during 2023, narrowed to the languages of the V4\ncountries (Czech Republic, Slovakia, Poland, Hungary). Then we measure their\nperformance under a variety of settings including translations, sentiment\ntargets, in-context learning and more, using GPT4 as a reference model. We\ndocument several interesting phenomena demonstrating, among others, that some\nmodels are much better fine-tunable on multilingual Twitter tasks than others,\nand that they can reach the SOTA level with a very small training set. Finally\nwe identify combinations of settings providing the best results.", "published": "2024-08-04 14:35:30", "link": "http://arxiv.org/abs/2408.02044v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MedSyn: LLM-based Synthetic Medical Text Generation Framework", "abstract": "Generating synthetic text addresses the challenge of data availability in\nprivacy-sensitive domains such as healthcare. This study explores the\napplicability of synthetic data in real-world medical settings. We introduce\nMedSyn, a novel medical text generation framework that integrates large\nlanguage models with a Medical Knowledge Graph (MKG). We use MKG to sample\nprior medical information for the prompt and generate synthetic clinical notes\nwith GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data\nthrough application in the ICD code prediction task. Our research indicates\nthat synthetic data can increase the classification accuracy of vital and\nchallenging codes by up to 17.8% compared to settings without synthetic data.\nFurthermore, to provide new data for further research in the healthcare domain,\nwe present the largest open-source synthetic dataset of clinical notes for the\nRussian language, comprising over 41k samples covering 219 ICD-10 codes.", "published": "2024-08-04 15:07:44", "link": "http://arxiv.org/abs/2408.02056v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Recent Advances in Multi-Choice Machine Reading Comprehension: A Survey\n  on Methods and Datasets", "abstract": "This paper provides a thorough examination of recent developments in the\nfield of multi-choice Machine Reading Comprehension (MRC). Focused on benchmark\ndatasets, methodologies, challenges, and future trajectories, our goal is to\noffer researchers a comprehensive overview of the current landscape in\nmulti-choice MRC. The analysis delves into 30 existing cloze-style and\nmultiple-choice MRC benchmark datasets, employing a refined classification\nmethod based on attributes such as corpus style, domain, complexity, context\nstyle, question style, and answer style. This classification system enhances\nour understanding of each dataset's diverse attributes and categorizes them\nbased on their complexity. Furthermore, the paper categorizes recent\nmethodologies into Fine-tuned and Prompt-tuned methods. Fine-tuned methods\ninvolve adapting pre-trained language models (PLMs) to a specific task through\nretraining on domain-specific datasets, while prompt-tuned methods use prompts\nto guide PLM response generation, presenting potential applications in\nzero-shot or few-shot learning scenarios. By contributing to ongoing\ndiscussions, inspiring future research directions, and fostering innovations,\nthis paper aims to propel multi-choice MRC towards new frontiers of\nachievement.", "published": "2024-08-04 18:57:21", "link": "http://arxiv.org/abs/2408.02114v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Analyzing Cultural Representations of Emotions in LLMs through Mixed\n  Emotion Survey", "abstract": "Large Language Models (LLMs) have gained widespread global adoption,\nshowcasing advanced linguistic capabilities across multiple of languages. There\nis a growing interest in academia to use these models to simulate and study\nhuman behaviors. However, it is crucial to acknowledge that an LLM's\nproficiency in a specific language might not fully encapsulate the norms and\nvalues associated with its culture. Concerns have emerged regarding potential\nbiases towards Anglo-centric cultures and values due to the predominance of\nWestern and US-based training data. This study focuses on analyzing the\ncultural representations of emotions in LLMs, in the specific case of\nmixed-emotion situations. Our methodology is based on the studies of Miyamoto\net al. (2010), which identified distinctive emotional indicators in Japanese\nand American human responses. We first administer their mixed emotion survey to\nfive different LLMs and analyze their outputs. Second, we experiment with\ncontextual variables to explore variations in responses considering both\nlanguage and speaker origin. Thirdly, we expand our investigation to encompass\nadditional East Asian and Western European origin languages to gauge their\nalignment with their respective cultures, anticipating a closer fit. We find\nthat (1) models have limited alignment with the evidence in the literature; (2)\nwritten language has greater effect on LLMs' response than information on\nparticipants origin; and (3) LLMs responses were found more similar for East\nAsian languages than Western European languages.", "published": "2024-08-04 20:56:05", "link": "http://arxiv.org/abs/2408.02143v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge AI: Fine-tuning NLP Models for Facilitating Scientific\n  Knowledge Extraction and Understanding", "abstract": "This project investigates the efficacy of Large Language Models (LLMs) in\nunderstanding and extracting scientific knowledge across specific domains and\nto create a deep learning framework: Knowledge AI. As a part of this framework,\nwe employ pre-trained models and fine-tune them on datasets in the scientific\ndomain. The models are adapted for four key Natural Language Processing (NLP)\ntasks: summarization, text generation, question answering, and named entity\nrecognition. Our results indicate that domain-specific fine-tuning\nsignificantly enhances model performance in each of these tasks, thereby\nimproving their applicability for scientific contexts. This adaptation enables\nnon-experts to efficiently query and extract information within targeted\nscientific fields, demonstrating the potential of fine-tuned LLMs as a tool for\nknowledge discovery in the sciences.", "published": "2024-08-04 01:32:09", "link": "http://arxiv.org/abs/2408.04651v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Semi-supervised Multi-channel Graph Convolutional Network for Query\n  Classification in E-commerce", "abstract": "Query intent classification is an essential module for customers to find\ndesired products on the e-commerce application quickly. Most existing query\nintent classification methods rely on the users' click behavior as a supervised\nsignal to construct training samples. However, these methods based entirely on\nposterior labels may lead to serious category imbalance problems because of the\nMatthew effect in click samples. Compared with popular categories, it is\ndifficult for products under long-tail categories to obtain traffic and user\nclicks, which makes the models unable to detect users' intent for products\nunder long-tail categories. This in turn aggravates the problem that long-tail\ncategories cannot obtain traffic, forming a vicious circle. In addition, due to\nthe randomness of the user's click, the posterior label is unstable for the\nquery with similar semantics, which makes the model very sensitive to the\ninput, leading to an unstable and incomplete recall of categories.\n  In this paper, we propose a novel Semi-supervised Multi-channel Graph\nConvolutional Network (SMGCN) to address the above problems from the\nperspective of label association and semi-supervised learning. SMGCN extends\ncategory information and enhances the posterior label by utilizing the\nsimilarity score between the query and categories. Furthermore, it leverages\nthe co-occurrence and semantic similarity graph of categories to strengthen the\nrelations among labels and weaken the influence of posterior label instability.\nWe conduct extensive offline and online A/B experiments, and the experimental\nresults show that SMGCN significantly outperforms the strong baselines, which\nshows its effectiveness and practicality.", "published": "2024-08-04 04:52:21", "link": "http://arxiv.org/abs/2408.01928v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Why Perturbing Symbolic Music is Necessary: Fitting the Distribution of\n  Never-used Notes through a Joint Probabilistic Diffusion Model", "abstract": "Existing music generation models are mostly language-based, neglecting the\nfrequency continuity property of notes, resulting in inadequate fitting of rare\nor never-used notes and thus reducing the diversity of generated samples. We\nargue that the distribution of notes can be modeled by translational invariance\nand periodicity, especially using diffusion models to generalize notes by\ninjecting frequency-domain Gaussian noise. However, due to the low-density\nnature of music symbols, estimating the distribution of notes latent in the\nhigh-density solution space poses significant challenges. To address this\nproblem, we introduce the Music-Diff architecture, which fits a joint\ndistribution of notes and accompanying semantic information to generate\nsymbolic music conditionally. We first enhance the fragmentation module for\nextracting semantics by using event-based notations and the structural\nsimilarity index, thereby preventing boundary blurring. As a prerequisite for\nmultivariate perturbation, we introduce a joint pre-training method to\nconstruct the progressions between notes and musical semantics while avoiding\ndirect modeling of low-density notes. Finally, we recover the perturbed notes\nby a multi-branch denoiser that fits multiple noise objectives via Pareto\noptimization. Our experiments suggest that in contrast to language models,\njoint probability diffusion models perturbing at both note and semantic levels\ncan provide more sample diversity and compositional regularity. The case study\nhighlights the rhythmic advantages of our model over language- and DDPMs-based\nmodels by analyzing the hierarchical structure expressed in the self-similarity\nmetrics.", "published": "2024-08-04 07:38:38", "link": "http://arxiv.org/abs/2408.01950v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ML-EAT: A Multilevel Embedding Association Test for Interpretable and\n  Transparent Social Science", "abstract": "This research introduces the Multilevel Embedding Association Test (ML-EAT),\na method designed for interpretable and transparent measurement of intrinsic\nbias in language technologies. The ML-EAT addresses issues of ambiguity and\ndifficulty in interpreting the traditional EAT measurement by quantifying bias\nat three levels of increasing granularity: the differential association between\ntwo target concepts with two attribute concepts; the individual effect size of\neach target concept with two attribute concepts; and the association between\neach individual target concept and each individual attribute concept. Using the\nML-EAT, this research defines a taxonomy of EAT patterns describing the nine\npossible outcomes of an embedding association test, each of which is associated\nwith a unique EAT-Map, a novel four-quadrant visualization for interpreting the\nML-EAT. Empirical analysis of static and diachronic word embeddings, GPT-2\nlanguage models, and a CLIP language-and-image model shows that EAT patterns\nadd otherwise unobservable information about the component biases that make up\nan EAT; reveal the effects of prompting in zero-shot models; and can also\nidentify situations when cosine similarity is an ineffective metric, rendering\nan EAT unreliable. Our work contributes a method for rendering bias more\nobservable and interpretable, improving the transparency of computational\ninvestigations into human minds and societies.", "published": "2024-08-04 09:04:44", "link": "http://arxiv.org/abs/2408.01966v2", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data\n  Assessment and Selection for Instruction Tuning of Language Models", "abstract": "Instruction tuning plays a critical role in aligning large language models\n(LLMs) with human preference. Despite the vast amount of open instruction\ndatasets, naively training a LLM on all existing instructions may not be\noptimal and practical. To pinpoint the most beneficial datapoints, data\nassessment and selection methods have been proposed in the fields of natural\nlanguage processing (NLP) and deep learning. However, under the context of\ninstruction tuning, there still exists a gap in knowledge on what kind of data\nevaluation metrics can be employed and how they can be integrated into the\nselection mechanism. To bridge this gap, we present a comprehensive review on\nexisting literature of data assessment and selection especially for instruction\ntuning of LLMs. We systematically categorize all applicable methods into\nquality-based, diversity-based, and importance-based ones where a unified,\nfine-grained taxonomy is structured. For each category, representative methods\nare elaborated to describe the landscape of relevant research. In addition,\ncomparison between the latest methods is conducted on their officially reported\nresults to provide in-depth discussions on their limitations. Finally, we\nsummarize the open challenges and propose the promosing avenues for future\nstudies. All related contents are available at\nhttps://github.com/yuleiqin/fantastic-data-engineering.", "published": "2024-08-04 16:50:07", "link": "http://arxiv.org/abs/2408.02085v5", "categories": ["cs.CV", "cs.AI", "cs.CL", "eess.SP"], "primary_category": "cs.CV"}
{"title": "Generative Retrieval with Few-shot Indexing", "abstract": "Existing generative retrieval (GR) approaches rely on training-based\nindexing, i.e., fine-tuning a model to memorise the associations between a\nquery and the document identifier (docid) of a relevant document.\nTraining-based indexing has three limitations: high training overhead,\nunder-utilization of the pre-trained knowledge of large language models (LLMs),\nand challenges in adapting to a dynamic document corpus. To address the above\nissues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).\nIt has a novel few-shot indexing process, where we prompt an LLM to generate\ndocids for all documents in a corpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query to the same LLM and constrain\nit to generate a docid within the docid bank created during indexing, and then\nmap the generated docid back to its corresponding document. Few-Shot GR relies\nsolely on prompting an LLM without requiring any training, making it more\nefficient. Moreover, we devise few-shot indexing with one-to-many mapping to\nfurther enhance Few-Shot GR. Experiments show that Few-Shot GR achieves\nsuperior performance to state-of-the-art GR methods that require heavy\ntraining.", "published": "2024-08-04 22:00:34", "link": "http://arxiv.org/abs/2408.02152v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Leveraging Large Language Models with Chain-of-Thought and Prompt\n  Engineering for Traffic Crash Severity Analysis and Inference", "abstract": "Harnessing the power of Large Language Models (LLMs), this study explores the\nuse of three state-of-the-art LLMs, specifically GPT-3.5-turbo, LLaMA3-8B, and\nLLaMA3-70B, for crash severity inference, framing it as a classification task.\nWe generate textual narratives from original traffic crash tabular data using a\npre-built template infused with domain knowledge. Additionally, we incorporated\nChain-of-Thought (CoT) reasoning to guide the LLMs in analyzing the crash\ncauses and then inferring the severity. This study also examine the impact of\nprompt engineering specifically designed for crash severity inference. The LLMs\nwere tasked with crash severity inference to: (1) evaluate the models'\ncapabilities in crash severity analysis, (2) assess the effectiveness of CoT\nand domain-informed prompt engineering, and (3) examine the reasoning abilities\nwith the CoT framework. Our results showed that LLaMA3-70B consistently\noutperformed the other models, particularly in zero-shot settings. The CoT and\nPrompt Engineering techniques significantly enhanced performance, improving\nlogical reasoning and addressing alignment issues. Notably, the CoT offers\nvaluable insights into LLMs' reasoning processes, unleashing their capacity to\nconsider diverse factors such as environmental conditions, driver behavior, and\nvehicle characteristics in severity analysis and inference.", "published": "2024-08-04 17:14:10", "link": "http://arxiv.org/abs/2408.04652v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dataset Scale and Societal Consistency Mediate Facial Impression Bias in\n  Vision-Language AI", "abstract": "Multimodal AI models capable of associating images and text hold promise for\nnumerous domains, ranging from automated image captioning to accessibility\napplications for blind and low-vision users. However, uncertainty about bias\nhas in some cases limited their adoption and availability. In the present work,\nwe study 43 CLIP vision-language models to determine whether they learn\nhuman-like facial impression biases, and we find evidence that such biases are\nreflected across three distinct CLIP model families. We show for the first time\nthat the the degree to which a bias is shared across a society predicts the\ndegree to which it is reflected in a CLIP model. Human-like impressions of\nvisually unobservable attributes, like trustworthiness and sexuality, emerge\nonly in models trained on the largest dataset, indicating that a better fit to\nuncurated cultural data results in the reproduction of increasingly subtle\nsocial biases. Moreover, we use a hierarchical clustering approach to show that\ndataset size predicts the extent to which the underlying structure of facial\nimpression bias resembles that of facial impression bias in humans. Finally, we\nshow that Stable Diffusion models employing CLIP as a text encoder learn facial\nimpression biases, and that these biases intersect with racial biases in Stable\nDiffusion XL-Turbo. While pretrained CLIP models may prove useful for\nscientific studies of bias, they will also require significant dataset curation\nwhen intended for use as general-purpose models in a zero-shot setting.", "published": "2024-08-04 08:26:58", "link": "http://arxiv.org/abs/2408.01959v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study", "abstract": "Popular and news media often portray teenagers with sensationalism, as both a\nrisk to society and at risk from society. As AI begins to absorb some of the\nepistemic functions of traditional media, we study how teenagers in two\ncountries speaking two languages: 1) are depicted by AI, and 2) how they would\nprefer to be depicted. Specifically, we study the biases about teenagers\nlearned by static word embeddings (SWEs) and generative language models (GLMs),\ncomparing these with the perspectives of adolescents living in the U.S. and\nNepal. We find English-language SWEs associate teenagers with societal\nproblems, and more than 50% of the 1,000 words most associated with teenagers\nin the pretrained GloVe SWE reflect such problems. Given prompts about\nteenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss\nsocietal problems, most commonly violence, but also drug use, mental illness,\nand sexual taboo. Nepali models, while not free of such associations, are less\ndominated by social problems. Data from workshops with N=13 U.S. adolescents\nand N=18 Nepalese adolescents show that AI presentations are disconnected from\nteenage life, which revolves around activities like school and friendship.\nParticipant ratings of how well 20 trait words describe teens are decorrelated\nfrom SWE associations, with Pearson's r=.02, n.s. in English FastText and\nr=.06, n.s. in GloVe; and r=.06, n.s. in Nepali FastText and r=-.23, n.s. in\nGloVe. U.S. participants suggested AI could fairly present teens by\nhighlighting diversity, while Nepalese participants centered positivity.\nParticipants were optimistic that, if it learned from adolescents, rather than\nmedia sources, AI could help mitigate stereotypes. Our work offers an\nunderstanding of the ways SWEs and GLMs misrepresent a developmentally\nvulnerable group and provides a template for less sensationalized\ncharacterization.", "published": "2024-08-04 08:35:02", "link": "http://arxiv.org/abs/2408.01961v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.CY"}
{"title": "The Implications of Open Generative Models in Human-Centered Data\n  Science Work: A Case Study with Fact-Checking Organizations", "abstract": "Calls to use open generative language models in academic research have\nhighlighted the need for reproducibility and transparency in scientific\nresearch. However, the impact of generative AI extends well beyond academia, as\ncorporations and public interest organizations have begun integrating these\nmodels into their data science pipelines. We expand this lens to include the\nimpact of open models on organizations, focusing specifically on fact-checking\norganizations, which use AI to observe and analyze large volumes of circulating\nmisinformation, yet must also ensure the reproducibility and impartiality of\ntheir work. We wanted to understand where fact-checking organizations use open\nmodels in their data science pipelines; what motivates their use of open models\nor proprietary models; and how their use of open or proprietary models can\ninform research on the societal impact of generative AI. To answer these\nquestions, we conducted an interview study with N=24 professionals at 20\nfact-checking organizations on six continents. Based on these interviews, we\noffer a five-component conceptual model of where fact-checking organizations\nemploy generative AI to support or automate parts of their data science\npipeline, including Data Ingestion, Data Analysis, Data Retrieval, Data\nDelivery, and Data Sharing. We then provide taxonomies of fact-checking\norganizations' motivations for using open models and the limitations that\nprevent them for further adopting open models, finding that they prefer open\nmodels for Organizational Autonomy, Data Privacy and Ownership, Application\nSpecificity, and Capability Transparency. However, they nonetheless use\nproprietary models due to perceived advantages in Performance, Usability, and\nSafety, as well as Opportunity Costs related to participation in emerging\ngenerative AI ecosystems. Our work provides novel perspective on open models in\ndata-driven organizations.", "published": "2024-08-04 08:41:48", "link": "http://arxiv.org/abs/2408.01962v1", "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.ET"], "primary_category": "cs.HC"}
{"title": "Re-ENACT: Reinforcement Learning for Emotional Speech Generation using\n  Actor-Critic Strategy", "abstract": "In this paper, we propose the first method to modify the prosodic features of\na given speech signal using actor-critic reinforcement learning strategy. Our\napproach uses a Bayesian framework to identify contiguous segments of\nimportance that links segments of the given utterances to perception of\nemotions in humans. We train a neural network to produce the variational\nposterior of a collection of Bernoulli random variables; our model applies a\nMarkov prior on it to ensure continuity. A sample from this distribution is\nused for downstream emotion prediction. Further, we train the neural network to\npredict a soft assignment over emotion categories as the target variable. In\nthe next step, we modify the prosodic features (pitch, intensity, and rhythm)\nof the masked segment to increase the score of target emotion. We employ an\nactor-critic reinforcement learning to train the prosody modifier by\ndiscretizing the space of modifications. Further, it provides a simple solution\nto the problem of gradient computation through WSOLA operation for rhythm\nmanipulation. Our experiments demonstrate that this framework changes the\nperceived emotion of a given speech utterance to the target. Further, we show\nthat our unified technique is on par with state-of-the-art emotion conversion\nmodels from supervised and unsupervised domains that require pairwise training.", "published": "2024-08-04 00:47:29", "link": "http://arxiv.org/abs/2408.01892v1", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Joint Learning of Emotions in Music and Generalized Sounds", "abstract": "In this study, we aim to determine if generalized sounds and music can share\na common emotional space, improving predictions of emotion in terms of arousal\nand valence. We propose the use of multiple datasets as a multi-domain learning\ntechnique. Our approach involves creating a common space encompassing features\nthat characterize both generalized sounds and music, as they can evoke emotions\nin a similar manner. To achieve this, we utilized two publicly available\ndatasets, namely IADS-E and PMEmo, following a standardized experimental\nprotocol. We employed a wide variety of features that capture diverse aspects\nof the audio structure including key parameters of spectrum, energy, and\nvoicing. Subsequently, we performed joint learning on the common feature space,\nleveraging heterogeneous model architectures. Interestingly, this synergistic\nscheme outperforms the state-of-the-art in both sound and music emotion\nprediction. The code enabling full replication of the presented experimental\npipeline is available at https://github.com/LIMUNIMI/MusicSoundEmotions.", "published": "2024-08-04 12:19:03", "link": "http://arxiv.org/abs/2408.02009v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Contrastive Learning-based Chaining-Cluster for Multilingual Voice-Face\n  Association", "abstract": "The innate correlation between a person's face and voice has recently emerged\nas a compelling area of study, especially within the context of multilingual\nenvironments. This paper introduces our novel solution to the Face-Voice\nAssociation in Multilingual Environments (FAME) 2024 challenge, focusing on a\ncontrastive learning-based chaining-cluster method to enhance face-voice\nassociation. This task involves the challenges of building biometric relations\nbetween auditory and visual modality cues and modelling the prosody\ninterdependence between different languages while addressing both intrinsic and\nextrinsic variability present in the data. To handle these non-trivial\nchallenges, our method employs supervised cross-contrastive (SCC) learning to\nestablish robust associations between voices and faces in multi-language\nscenarios. Following this, we have specifically designed a\nchaining-cluster-based post-processing step to mitigate the impact of outliers\noften found in unconstrained in the wild data. We conducted extensive\nexperiments to investigate the impact of language on face-voice association.\nThe overall results were evaluated on the FAME public evaluation platform,\nwhere we achieved 2nd place. The results demonstrate the superior performance\nof our method, and we validate the robustness and effectiveness of our proposed\napproach. Code is available at https://github.com/colaudiolab/FAME24_solution.", "published": "2024-08-04 13:24:36", "link": "http://arxiv.org/abs/2408.02025v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Dise\u00f1o de sonido para producciones audiovisuales e historias sonoras\n  en el aula. Hacia una docencia creativa mediante el uso de herramientas\n  inteligentes", "abstract": "This study aims to share a teaching experience teaching sound design for\naudiovisual productions and compares different projects tackled by students. It\nis not intended to be a comparative analysis of different types of teaching but\nrather an analysis of different problems observed in different profiles of\nstudents of the subject who study it in different grades. The world of audio\ncan be very interesting for a large part of the students, both those with\ncreative and technical inclinations. Musical creation and production,\nsynchronization with images, dubbing, etc. They are disciplines that are\ngenerally interesting but can have a very high barrier to entry due to their\ngreat technical complexity. Sometimes it can take weeks or even months for the\nuninitiated to begin to use audio editing programs with the necessary ease,\nwhich are not always particularly intuitive for students. Learning through the\nuse of PBL methodologies generates, in our experience, results much superior to\nthose that can be observed through the use of other teaching methods such as\nmaster classes. Students acquire technical skills while developing creative\nprojects in which they get personally involved. Despite everything mentioned\nabove, most interactions between teachers and students focus on aspects of\ntechnical correction. From different parameters in reverbs (such as pre-delay,\ndecay, modulation...) to how to correctly adjust compressors, noise gates,\netc.; The number of tools with which to work with audio is incredibly\nextensive, as well as many of its features that can present serious differences\ndepending on their manufacturers.", "published": "2024-08-04 18:54:59", "link": "http://arxiv.org/abs/2408.02113v2", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
