{"title": "MIZAN: A Large Persian-English Parallel Corpus", "abstract": "One of the most major and essential tasks in natural language processing is\nmachine translation that is now highly dependent upon multilingual parallel\ncorpora. Through this paper, we introduce the biggest Persian-English parallel\ncorpus with more than one million sentence pairs collected from masterpieces of\nliterature. We also present acquisition process and statistics of the corpus,\nand experiment a base-line statistical machine translation system using the\ncorpus.", "published": "2018-01-07 00:48:43", "link": "http://arxiv.org/abs/1801.02107v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Group Communication Analysis: A Computational Linguistics Approach for\n  Detecting Sociocognitive Roles in Multi-Party Interactions", "abstract": "Roles are one of the most important concepts in understanding human\nsociocognitive behavior. During group interactions, members take on different\nroles within the discussion. Roles have distinct patterns of behavioral\nengagement (i.e., active or passive, leading or following), contribution\ncharacteristics (i.e., providing new information or echoing given material),\nand social orientation (i.e., individual or group). Different combinations of\nthese roles can produce characteristically different group outcomes, being\neither less or more productive towards collective goals. In online\ncollaborative learning environments, this can lead to better or worse learning\noutcomes for the individual participants. In this study, we propose and\nvalidate a novel approach for detecting emergent roles from the participants'\ncontributions and patterns of interaction. Specifically, we developed a group\ncommunication analysis (GCA) by combining automated computational linguistic\ntechniques with analyses of the sequential interactions of online group\ncommunication. The GCA was applied to three large collaborative interaction\ndatasets (participant N = 2,429; group N = 3,598). Cluster analyses and linear\nmixed-effects modeling were used to assess the validity of the GCA approach and\nthe influence of learner roles on student and group performance. The results\nindicate that participants' patterns in linguistic coordination and cohesion\nare representative of the roles that individuals play in collaborative\ndiscussions. More broadly, GCA provides a framework for researchers to explore\nthe micro intra- and interpersonal patterns associated with the participants'\nroles and the sociocognitive processes related to successful collaboration.", "published": "2018-01-07 15:18:21", "link": "http://arxiv.org/abs/1801.03563v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trading the Twitter Sentiment with Reinforcement Learning", "abstract": "This paper is to explore the possibility to use alternative data and\nartificial intelligence techniques to trade stocks. The efficacy of the daily\nTwitter sentiment on predicting the stock return is examined using machine\nlearning methods. Reinforcement learning(Q-learning) is applied to generate the\noptimal trading policy based on the sentiment signal. The predicting power of\nthe sentiment signal is more significant if the stock price is driven by the\nexpectation of the company growth and when the company has a major event that\ndraws the public attention. The optimal trading strategy based on reinforcement\nlearning outperforms the trading strategy based on the machine learning\nprediction.", "published": "2018-01-07 20:26:00", "link": "http://arxiv.org/abs/1801.02243v1", "categories": ["cs.AI", "cs.CL", "cs.SI"], "primary_category": "cs.AI"}
{"title": "Binning based algorithm for Pitch Detection in Hindustani Classical\n  Music", "abstract": "Speech coding forms a crucial element in speech communications. An important\narea concerning it lies in feature extraction which can be used for analyzing\nHindustani Classical Music. An important feature in this respect is the\nfundamental frequency often referred to as the pitch. In this work, the terms\npitch and its acoustical sensation, the frequency is used interchangeably.\nThere exists numerous pitch detection algorithms which detect the main/\nfundamental frequency in a given musical piece, but we have come up with a\nunique algorithm for pitch detection using the binning method as described in\nthe paper using appropriate bin size. Previous work on this subject throws\nlight on pitch identification for Hindustani Classical Music. Pitch Class\nDistribution has been employed in this work. It can be used to identify pitches\nin Hindustani Classical Music which is based on suitable intonations and\nswaras. It follows a particular ratio pattern which is a tuning for diatonic\nscale proposed by Ptolemy and confirmed by Zarlino is explored in this paper.\nWe have also given our estimated of these ratios and compared the error with\nthe above. The error produced by varying the bin size in our algorithm is\ninvestigated and an estimate for an appropriate bin size is suggested and\ntested. The binning algorithm thus helps to segregate the important pitches in\na given musical piece.", "published": "2018-01-07 08:09:52", "link": "http://arxiv.org/abs/1801.02155v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Cross-modal Embeddings for Video and Audio Retrieval", "abstract": "The increasing amount of online videos brings several opportunities for\ntraining self-supervised neural networks. The creation of large scale datasets\nof videos such as the YouTube-8M allows us to deal with this large amount of\ndata in manageable way. In this work, we find new ways of exploiting this\ndataset by taking advantage of the multi-modal information it provides. By\nmeans of a neural network, we are able to create links between audio and visual\ndocuments, by projecting them into a common region of the feature space,\nobtaining joint audio-visual embeddings. These links are used to retrieve audio\nsamples that fit well to a given silent video, and also to retrieve images that\nmatch a given a query audio. The results in terms of Recall@K obtained over a\nsubset of YouTube-8M videos show the potential of this unsupervised approach\nfor cross-modal feature learning. We train embeddings for both scales and\nassess their quality in a retrieval problem, formulated as using the feature\nextracted from one modality to retrieve the most similar videos based on the\nfeatures computed in the other modality.", "published": "2018-01-07 15:43:22", "link": "http://arxiv.org/abs/1801.02200v1", "categories": ["cs.IR", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.IR"}
