{"title": "Domain Adaptation for Statistical Machine Translation", "abstract": "Statistical machine translation (SMT) systems perform poorly when it is\napplied to new target domains. Our goal is to explore domain adaptation\napproaches and techniques for improving the translation quality of\ndomain-specific SMT systems. However, translating texts from a specific domain\n(e.g., medicine) is full of challenges. The first challenge is ambiguity. Words\nor phrases contain different meanings in different contexts. The second one is\nlanguage style due to the fact that texts from different genres are always\npresented in different syntax, length and structural organization. The third\none is the out-of-vocabulary words (OOVs) problem. In-domain training data are\noften scarce with low terminology coverage. In this thesis, we explore the\nstate-of-the-art domain adaptation approaches and propose effective solutions\nto address those problems.", "published": "2018-04-05 10:24:15", "link": "http://arxiv.org/abs/1804.01760v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chinese-Portuguese Machine Translation: A Study on Building Parallel\n  Corpora from Comparable Texts", "abstract": "Although there are increasing and significant ties between China and\nPortuguese-speaking countries, there is not much parallel corpora in the\nChinese-Portuguese language pair. Both languages are very populous, with 1.2\nbillion native Chinese speakers and 279 million native Portuguese speakers, the\nlanguage pair, however, could be considered as low-resource in terms of\navailable parallel corpora. In this paper, we describe our methods to curate\nChinese-Portuguese parallel corpora and evaluate their quality. We extracted\nbilingual data from Macao government websites and proposed a hierarchical\nstrategy to build a large parallel corpus. Experiments are conducted on\nexisting and our corpora using both Phrased-Based Machine Translation (PBMT)\nand the state-of-the-art Neural Machine Translation (NMT) models. The results\nof this work can be used as a benchmark for future Chinese-Portuguese MT\nsystems. The approach we used in this paper also shows a good example on how to\nboost performance of MT systems for low-resource language pairs.", "published": "2018-04-05 10:35:51", "link": "http://arxiv.org/abs/1804.01768v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Not just about size - A Study on the Role of Distributed Word\n  Representations in the Analysis of Scientific Publications", "abstract": "The emergence of knowledge graphs in the scholarly communication domain and\nrecent advances in artificial intelligence and natural language processing\nbring us closer to a scenario where intelligent systems can assist scientists\nover a range of knowledge-intensive tasks. In this paper we present\nexperimental results about the generation of word embeddings from scholarly\npublications for the intelligent processing of scientific texts extracted from\nSciGraph. We compare the performance of domain-specific embeddings with\nexisting pre-trained vectors generated from very large and general purpose\ncorpora. Our results suggest that there is a trade-off between corpus\nspecificity and volume. Embeddings from domain-specific scientific corpora\neffectively capture the semantics of the domain. On the other hand, obtaining\ncomparable results through general corpora can also be achieved, but only in\nthe presence of very large corpora of well formed text. Furthermore, We also\nshow that the degree of overlapping between knowledge areas is directly related\nto the performance of embeddings in domain evaluation tasks.", "published": "2018-04-05 10:48:26", "link": "http://arxiv.org/abs/1804.01772v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word Segmentation as Graph Partition", "abstract": "We propose a new approach to the Chinese word segmentation problem that\nconsiders the sentence as an undirected graph, whose nodes are the characters.\nOne can use various techniques to compute the edge weights that measure the\nconnection strength between characters. Spectral graph partition algorithms are\nused to group the characters and achieve word segmentation. We follow the graph\npartition approach and design several unsupervised algorithms, and we show\ntheir inspiring segmentation results on two corpora: (1) electronic health\nrecords in Chinese, and (2) benchmark data from the Second International\nChinese Word Segmentation Bakeoff.", "published": "2018-04-05 11:02:38", "link": "http://arxiv.org/abs/1804.01778v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ETH-DS3Lab at SemEval-2018 Task 7: Effectively Combining Recurrent and\n  Convolutional Neural Networks for Relation Classification and Extraction", "abstract": "Reliably detecting relevant relations between entities in unstructured text\nis a valuable resource for knowledge extraction, which is why it has awaken\nsignificant interest in the field of Natural Language Processing. In this\npaper, we present a system for relation classification and extraction based on\nan ensemble of convolutional and recurrent neural networks that ranked first in\n3 out of the 4 subtasks at SemEval 2018 Task 7. We provide detailed\nexplanations and grounds for the design choices behind the most relevant\nfeatures and analyze their importance.", "published": "2018-04-05 20:01:48", "link": "http://arxiv.org/abs/1804.02042v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-Shot Text Classification with Pre-Trained Word Embeddings and a\n  Human in the Loop", "abstract": "Most of the literature around text classification treats it as a supervised\nlearning problem: given a corpus of labeled documents, train a classifier such\nthat it can accurately predict the classes of unseen documents. In industry,\nhowever, it is not uncommon for a business to have entire corpora of documents\nwhere few or none have been classified, or where existing classifications have\nbecome meaningless. With web content, for example, poor taxonomy management can\nresult in labels being applied indiscriminately, making filtering by these\nlabels unhelpful. Our work aims to make it possible to classify an entire\ncorpus of unlabeled documents using a human-in-the-loop approach, where the\ncontent owner manually classifies just one or two documents per category and\nthe rest can be automatically classified. This \"few-shot\" learning approach\nrequires rich representations of the documents such that those that have been\nmanually labeled can be treated as prototypes, and automatic classification of\nthe rest is a simple case of measuring the distance to prototypes. This\napproach uses pre-trained word embeddings, where documents are represented\nusing a simple weighted average of constituent word embeddings. We have tested\nthe accuracy of the approach on existing labeled datasets and provide the\nresults here. We have also made code available for reproducing the results we\ngot on the 20 Newsgroups dataset.", "published": "2018-04-05 21:28:54", "link": "http://arxiv.org/abs/1804.02063v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Crowd-Labeling Fashion Reviews with Quality Control", "abstract": "We present a new methodology for high-quality labeling in the fashion domain\nwith crowd workers instead of experts. We focus on the Aspect-Based Sentiment\nAnalysis task. Our methods filter out inaccurate input from crowd workers but\nwe preserve different worker labeling to capture the inherent high variability\nof the opinions. We demonstrate the quality of labeled data based on Facebook's\nFastText framework as a baseline.", "published": "2018-04-05 16:07:08", "link": "http://arxiv.org/abs/1805.09648v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Finding beans in burgers: Deep semantic-visual embedding with\n  localization", "abstract": "Several works have proposed to learn a two-path neural network that maps\nimages and texts, respectively, to a same shared Euclidean space where geometry\ncaptures useful semantic relationships. Such a multi-modal embedding can be\ntrained and used for various tasks, notably image captioning. In the present\nwork, we introduce a new architecture of this type, with a visual path that\nleverages recent space-aware pooling mechanisms. Combined with a textual path\nwhich is jointly trained from scratch, our semantic-visual embedding offers a\nversatile model. Once trained under the supervision of captioned images, it\nyields new state-of-the-art performance on cross-modal retrieval. It also\nallows the localization of new concepts from the embedding space into any input\nimage, delivering state-of-the-art result on the visual grounding of phrases.", "published": "2018-04-05 08:13:37", "link": "http://arxiv.org/abs/1804.01720v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Automated Classification of Text Sentiment", "abstract": "The ability to identify sentiment in text, referred to as sentiment analysis,\nis one which is natural to adult humans. This task is, however, not one which a\ncomputer can perform by default. Identifying sentiments in an automated,\nalgorithmic manner will be a useful capability for business and research in\ntheir search to understand what consumers think about their products or\nservices and to understand human sociology. Here we propose two new Genetic\nAlgorithms (GAs) for the task of automated text sentiment analysis. The GAs\nlearn whether words occurring in a text corpus are either sentiment or\namplifier words, and their corresponding magnitude. Sentiment words, such as\n'horrible', add linearly to the final sentiment. Amplifier words in contrast,\nwhich are typically adjectives/adverbs like 'very', multiply the sentiment of\nthe following word. This increases, decreases or negates the sentiment of the\nfollowing word. The sentiment of the full text is then the sum of these terms.\nThis approach grows both a sentiment and amplifier dictionary which can be\nreused for other purposes and fed into other machine learning algorithms. We\nreport the results of multiple experiments conducted on large Amazon data sets.\nThe results reveal that our proposed approach was able to outperform several\npublic and/or commercial sentiment analysis algorithms.", "published": "2018-04-05 17:21:48", "link": "http://arxiv.org/abs/1804.01963v1", "categories": ["cs.CL", "cs.IR", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Analyzing Self-Driving Cars on Twitter", "abstract": "This paper studies users' perception regarding a controversial product,\nnamely self-driving (autonomous) cars. To find people's opinion regarding this\nnew technology, we used an annotated Twitter dataset, and extracted the topics\nin positive and negative tweets using an unsupervised, probabilistic model\nknown as topic modeling. We later used the topics, as well as linguist and\nTwitter specific features to classify the sentiment of the tweets. Regarding\nthe opinions, the result of our analysis shows that people are optimistic and\nexcited about the future technology, but at the same time they find it\ndangerous and not reliable. For the classification task, we found Twitter\nspecific features, such as hashtags as well as linguistic features such as\nemphatic words among top attributes in classifying the sentiment of the tweets.", "published": "2018-04-05 23:31:44", "link": "http://arxiv.org/abs/1804.04058v1", "categories": ["cs.LG", "cs.CL", "cs.SI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Jointly Detecting and Separating Singing Voice: A Multi-Task Approach", "abstract": "A main challenge in applying deep learning to music processing is the\navailability of training data. One potential solution is Multi-task Learning,\nin which the model also learns to solve related auxiliary tasks on additional\ndatasets to exploit their correlation. While intuitive in principle, it can be\nchallenging to identify related tasks and construct the model to optimally\nshare information between tasks. In this paper, we explore vocal activity\ndetection as an additional task to stabilise and improve the performance of\nvocal separation. Further, we identify problematic biases specific to each\ndataset that could limit the generalisation capability of separation and\ndetection models, to which our proposed approach is robust. Experiments show\nimproved performance in separation as well as vocal detection compared to\nsingle-task baselines. However, we find that the commonly used\nSignal-to-Distortion Ratio (SDR) metrics did not capture the improvement on\nnon-vocal sections, indicating the need for improved evaluation methodologies.", "published": "2018-04-05 01:55:39", "link": "http://arxiv.org/abs/1804.01650v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning to Separate Object Sounds by Watching Unlabeled Video", "abstract": "Perceiving a scene most fully requires all the senses. Yet modeling how\nobjects look and sound is challenging: most natural scenes and events contain\nmultiple objects, and the audio track mixes all the sound sources together. We\npropose to learn audio-visual object models from unlabeled video, then exploit\nthe visual context to perform audio source separation in novel videos. Our\napproach relies on a deep multi-instance multi-label learning framework to\ndisentangle the audio frequency bases that map to individual visual objects,\neven without observing/hearing those objects in isolation. We show how the\nrecovered disentangled bases can be used to guide audio source separation to\nobtain better-separated, object-level sounds. Our work is the first to learn\naudio source separation from large-scale \"in the wild\" videos containing\nmultiple audio sources per video. We obtain state-of-the-art results on\nvisually-aided audio source separation and audio denoising. Our video results:\nhttp://vision.cs.utexas.edu/projects/separating_object_sounds/", "published": "2018-04-05 04:06:46", "link": "http://arxiv.org/abs/1804.01665v2", "categories": ["cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "A Large-Scale Study of Language Models for Chord Prediction", "abstract": "We conduct a large-scale study of language models for chord prediction.\nSpecifically, we compare N-gram models to various flavours of recurrent neural\nnetworks on a comprehensive dataset comprising all publicly available datasets\nof annotated chords known to us. This large amount of data allows us to\nsystematically explore hyper-parameter settings for the recurrent neural\nnetworks---a crucial step in achieving good results with this model class. Our\nresults show not only a quantitative difference between the models, but also a\nqualitative one: in contrast to static N-gram models, certain RNN\nconfigurations adapt to the songs at test time. This finding constitutes a\nfurther step towards the development of chord recognition systems that are more\naware of local musical context than what was previously possible.", "published": "2018-04-05 13:51:10", "link": "http://arxiv.org/abs/1804.01849v1", "categories": ["cs.LG", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.LG"}
