{"title": "RoBERTweet: A BERT Language Model for Romanian Tweets", "abstract": "Developing natural language processing (NLP) systems for social media\nanalysis remains an important topic in artificial intelligence research. This\narticle introduces RoBERTweet, the first Transformer architecture trained on\nRomanian tweets. Our RoBERTweet comes in two versions, following the base and\nlarge architectures of BERT. The corpus used for pre-training the models\nrepresents a novelty for the Romanian NLP community and consists of all tweets\ncollected from 2008 to 2022. Experiments show that RoBERTweet models outperform\nthe previous general-domain Romanian and multilingual language models on three\nNLP tasks with tweet inputs: emotion detection, sexist language identification,\nand named entity recognition. We make our models and the newly created corpus\nof Romanian tweets freely available.", "published": "2023-06-11 06:11:56", "link": "http://arxiv.org/abs/2306.06598v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mimicking the Thinking Process for Emotion Recognition in Conversation\n  with Prompts and Paraphrasing", "abstract": "Emotion recognition in conversation, which aims to predict the emotion for\nall utterances, has attracted considerable research attention in recent years.\nIt is a challenging task since the recognition of the emotion in one utterance\ninvolves many complex factors, such as the conversational context, the\nspeaker's background, and the subtle difference between emotion labels. In this\npaper, we propose a novel framework which mimics the thinking process when\nmodeling these factors. Specifically, we first comprehend the conversational\ncontext with a history-oriented prompt to selectively gather information from\npredecessors of the target utterance. We then model the speaker's background\nwith an experience-oriented prompt to retrieve the similar utterances from all\nconversations. We finally differentiate the subtle label semantics with a\nparaphrasing mechanism to elicit the intrinsic label related knowledge. We\nconducted extensive experiments on three benchmarks. The empirical results\ndemonstrate the superiority of our proposed framework over the state-of-the-art\nbaselines.", "published": "2023-06-11 06:36:19", "link": "http://arxiv.org/abs/2306.06601v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Diverse and Effective Question-Answer Pair Generation from\n  Children Storybooks", "abstract": "Recent advances in QA pair generation (QAG) have raised interest in applying\nthis technique to the educational field. However, the diversity of QA types\nremains a challenge despite its contributions to comprehensive learning and\nassessment of children. In this paper, we propose a QAG framework that enhances\nQA type diversity by producing different interrogative sentences and\nimplicit/explicit answers. Our framework comprises a QFS-based answer\ngenerator, an iterative QA generator, and a relevancy-aware ranker. The two\ngenerators aim to expand the number of candidates while covering various types.\nThe ranker trained on the in-context negative samples clarifies the top-N\noutputs based on the ranking score. Extensive evaluations and detailed analyses\ndemonstrate that our approach outperforms previous state-of-the-art results by\nsignificant margins, achieving improved diversity and quality. Our\ntask-oriented processes are consistent with real-world demand, which highlights\nour system's high applicability.", "published": "2023-06-11 06:55:59", "link": "http://arxiv.org/abs/2306.06605v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RestGPT: Connecting Large Language Models with Real-World RESTful APIs", "abstract": "Tool-augmented large language models (LLMs) have achieved remarkable progress\nin tackling a broad range of tasks. However, existing methods are mainly\nrestricted to specifically designed tools and fail to fulfill complex\ninstructions, having great limitations when confronted with real-world\nscenarios. In this paper, we explore a more realistic scenario by connecting\nLLMs with RESTful APIs, which adhere to the widely adopted REST software\narchitectural style for web service development. To address the practical\nchallenges of tackling complex instructions, we propose RestGPT, which exploits\nthe power of LLMs and conducts a coarse-to-fine online planning mechanism to\nenhance the abilities of task decomposition and API selection. RestGPT also\ncontains an API executor tailored for calling RESTful APIs, which can\nmeticulously formulate parameters and parse API responses. To fully evaluate\nthe performance of RestGPT, we propose RestBench, a high-quality benchmark\nwhich consists of two real-world scenarios and human-annotated instructions\nwith gold solution paths. Experiments show that RestGPT is able to achieve\nimpressive results in complex tasks and has strong robustness, which paves a\nnew way towards AGI. RestGPT and RestBench is publicly available at\nhttps://restgpt.github.io/.", "published": "2023-06-11 08:53:12", "link": "http://arxiv.org/abs/2306.06624v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open Brain AI. Automatic Language Assessment", "abstract": "Language assessment plays a crucial role in diagnosing and treating\nindividuals with speech, language, and communication disorders caused by\nneurogenic conditions, whether developmental or acquired. However, current\nassessment methods are manual, laborious, and time-consuming to administer and\nscore, causing additional patient stress. To address these challenges, we\ndeveloped Open Brain AI (https://openbrainai.com). This computational platform\nharnesses innovative AI techniques, namely machine learning, natural language\nprocessing, large language models, and automatic speech-to-text transcription,\nto automatically analyze multilingual spoken and written speech productions.\nThis paper discusses the development of Open Brain AI, the AI language\nprocessing modules, and the linguistic measurements of discourse\nmacro-structure and micro-structure. The fast and automatic analysis of\nlanguage alleviates the burden on clinicians, enabling them to streamline their\nworkflow and allocate more time and resources to direct patient care. Open\nBrain AI is freely accessible, empowering clinicians to conduct critical data\nanalyses and give more attention and resources to other critical aspects of\ntherapy and treatment.", "published": "2023-06-11 14:37:45", "link": "http://arxiv.org/abs/2306.06693v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QUERT: Continual Pre-training of Language Model for Query Understanding\n  in Travel Domain Search", "abstract": "In light of the success of the pre-trained language models (PLMs), continual\npre-training of generic PLMs has been the paradigm of domain adaption. In this\npaper, we propose QUERT, A Continual Pre-trained Language Model for QUERy\nUnderstanding in Travel Domain Search. QUERT is jointly trained on four\ntailored pre-training tasks to the characteristics of query in travel domain\nsearch: Geography-aware Mask Prediction, Geohash Code Prediction, User Click\nBehavior Learning, and Phrase and Token Order Prediction. Performance\nimprovement of downstream tasks and ablation experiment demonstrate the\neffectiveness of our proposed pre-training tasks. To be specific, the average\nperformance of downstream tasks increases by 2.02% and 30.93% in supervised and\nunsupervised settings, respectively. To check on the improvement of QUERT to\nonline business, we deploy QUERT and perform A/B testing on Fliggy APP. The\nfeedback results show that QUERT increases the Unique Click-Through Rate and\nPage Click-Through Rate by 0.89% and 1.03% when applying QUERT as the encoder.\nOur code and downstream task data will be released for future research.", "published": "2023-06-11 15:39:59", "link": "http://arxiv.org/abs/2306.06707v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Source Test-Time Adaptation as Dueling Bandits for Extractive\n  Question Answering", "abstract": "In this work, we study multi-source test-time model adaptation from user\nfeedback, where K distinct models are established for adaptation. To allow\nefficient adaptation, we cast the problem as a stochastic decision-making\nprocess, aiming to determine the best adapted model after adaptation. We\ndiscuss two frameworks: multi-armed bandit learning and multi-armed dueling\nbandits. Compared to multi-armed bandit learning, the dueling framework allows\npairwise collaboration among K models, which is solved by a novel method named\nCo-UCB proposed in this work. Experiments on six datasets of extractive\nquestion answering (QA) show that the dueling framework using Co-UCB is more\neffective than other strong baselines for our studied problem.", "published": "2023-06-11 21:18:50", "link": "http://arxiv.org/abs/2306.06779v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AraMUS: Pushing the Limits of Data and Model Scale for Arabic Natural\n  Language Processing", "abstract": "Developing monolingual large Pre-trained Language Models (PLMs) is shown to\nbe very successful in handling different tasks in Natural Language Processing\n(NLP). In this work, we present AraMUS, the largest Arabic PLM with 11B\nparameters trained on 529GB of high-quality Arabic textual data. AraMUS\nachieves state-of-the-art performances on a diverse set of Arabic\nclassification and generative tasks. Moreover, AraMUS shows impressive few-shot\nlearning abilities compared with the best existing Arabic PLMs.", "published": "2023-06-11 22:55:18", "link": "http://arxiv.org/abs/2306.06800v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inductive reasoning in humans and large language models", "abstract": "The impressive recent performance of large language models has led many to\nwonder to what extent they can serve as models of general intelligence or are\nsimilar to human cognition. We address this issue by applying GPT-3.5 and GPT-4\nto a classic problem in human inductive reasoning known as property induction.\nOver two experiments, we elicit human judgments on a range of property\ninduction tasks spanning multiple domains. Although GPT-3.5 struggles to\ncapture many aspects of human behaviour, GPT-4 is much more successful: for the\nmost part, its performance qualitatively matches that of humans, and the only\nnotable exception is its failure to capture the phenomenon of premise\nnon-monotonicity. Our work demonstrates that property induction allows for\ninteresting comparisons between human and machine intelligence and provides two\nlarge datasets that can serve as benchmarks for future work in this vein.", "published": "2023-06-11 00:23:25", "link": "http://arxiv.org/abs/2306.06548v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Empowering Molecule Discovery for Molecule-Caption Translation with\n  Large Language Models: A ChatGPT Perspective", "abstract": "Molecule discovery plays a crucial role in various scientific fields,\nadvancing the design of tailored materials and drugs. However, most of the\nexisting methods heavily rely on domain experts, require excessive\ncomputational cost, or suffer from sub-optimal performance. On the other hand,\nLarge Language Models (LLMs), like ChatGPT, have shown remarkable performance\nin various cross-modal tasks due to their powerful capabilities in natural\nlanguage understanding, generalization, and in-context learning (ICL), which\nprovides unprecedented opportunities to advance molecule discovery. Despite\nseveral previous works trying to apply LLMs in this task, the lack of\ndomain-specific corpus and difficulties in training specialized LLMs still\nremain challenges. In this work, we propose a novel LLM-based framework\n(MolReGPT) for molecule-caption translation, where an In-Context Few-Shot\nMolecule Learning paradigm is introduced to empower molecule discovery with\nLLMs like ChatGPT to perform their in-context learning capability without\ndomain-specific pre-training and fine-tuning. MolReGPT leverages the principle\nof molecular similarity to retrieve similar molecules and their text\ndescriptions from a local database to enable LLMs to learn the task knowledge\nfrom context examples. We evaluate the effectiveness of MolReGPT on\nmolecule-caption translation, including molecule understanding and text-based\nmolecule generation. Experimental results show that compared to fine-tuned\nmodels, MolReGPT outperforms MolT5-base and is comparable to MolT5-large\nwithout additional training. To the best of our knowledge, MolReGPT is the\nfirst work to leverage LLMs via in-context learning in molecule-caption\ntranslation for advancing molecule discovery. Our work expands the scope of LLM\napplications, as well as providing a new paradigm for molecule discovery and\ndesign.", "published": "2023-06-11 08:16:25", "link": "http://arxiv.org/abs/2306.06615v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are Intermediate Layers and Labels Really Necessary? A General Language\n  Model Distillation Method", "abstract": "The large scale of pre-trained language models poses a challenge for their\ndeployment on various devices, with a growing emphasis on methods to compress\nthese models, particularly knowledge distillation. However, current knowledge\ndistillation methods rely on the model's intermediate layer features and the\ngolden labels (also called hard labels), which usually require aligned model\narchitecture and enough labeled data respectively. Moreover, the parameters of\nvocabulary are usually neglected in existing methods. To address these\nproblems, we propose a general language model distillation (GLMD) method that\nperforms two-stage word prediction distillation and vocabulary compression,\nwhich is simple and surprisingly shows extremely strong performance.\nSpecifically, GLMD supports more general application scenarios by eliminating\nthe constraints of dimension and structure between models and the need for\nlabeled datasets through the absence of intermediate layers and golden labels.\nMeanwhile, based on the long-tailed distribution of word frequencies in the\ndata, GLMD designs a strategy of vocabulary compression through decreasing\nvocabulary size instead of dimensionality. Experimental results show that our\nmethod outperforms 25 state-of-the-art methods on the SuperGLUE benchmark,\nachieving an average score that surpasses the best method by 3%.", "published": "2023-06-11 08:53:27", "link": "http://arxiv.org/abs/2306.06625v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GKD: A General Knowledge Distillation Framework for Large-scale\n  Pre-trained Language Model", "abstract": "Currently, the reduction in the parameter scale of large-scale pre-trained\nlanguage models (PLMs) through knowledge distillation has greatly facilitated\ntheir widespread deployment on various devices. However, the deployment of\nknowledge distillation systems faces great challenges in real-world\nindustrial-strength applications, which require the use of complex distillation\nmethods on even larger-scale PLMs (over 10B), limited by memory on GPUs and the\nswitching of methods. To overcome these challenges, we propose GKD, a general\nknowledge distillation framework that supports distillation on larger-scale\nPLMs using various distillation methods. With GKD, developers can build larger\ndistillation models on memory-limited GPUs and easily switch and combine\ndifferent distillation methods within a single framework. Experimental results\nshow that GKD can support the distillation of at least 100B-scale PLMs and 25\nmainstream methods on 8 NVIDIA A100 (40GB) GPUs.", "published": "2023-06-11 09:17:21", "link": "http://arxiv.org/abs/2306.06629v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Resolution for Constrained Pseudo-Propositional Logic", "abstract": "This work, shows how propositional resolution can be generalized to obtain a\nresolution proof system for constrained pseudo-propositional logic (CPPL),\nwhich is an extension resulted from inserting the natural numbers with few\nconstraints symbols into the alphabet of propositional logic and adjusting the\nunderling language accordingly. Unlike the construction of CNF formulas which\nare restricted to a finite set of clauses, the extended CPPL does not require\nthe corresponding set to be finite.\n  Although this restriction is made dispensable, this work presents a\nconstructive proof showing that the generalized resolution for CPPL is sound\nand complete. As a marginal result, this implies that propositional resolution\nis also sound and complete for formulas with even infinite set of clauses.", "published": "2023-06-11 09:17:24", "link": "http://arxiv.org/abs/2306.06630v1", "categories": ["math.LO", "cs.CL", "03B05"], "primary_category": "math.LO"}
{"title": "EaSyGuide : ESG Issue Identification Framework leveraging Abilities of\n  Generative Large Language Models", "abstract": "This paper presents our participation in the FinNLP-2023 shared task on\nmulti-lingual environmental, social, and corporate governance issue\nidentification (ML-ESG). The task's objective is to classify news articles\nbased on the 35 ESG key issues defined by the MSCI ESG rating guidelines. Our\napproach focuses on the English and French subtasks, employing the CerebrasGPT,\nOPT, and Pythia models, along with the zero-shot and GPT3Mix Augmentation\ntechniques. We utilize various encoder models, such as RoBERTa, DeBERTa, and\nFinBERT, subjecting them to knowledge distillation and additional training.\n  Our approach yielded exceptional results, securing the first position in the\nEnglish text subtask with F1-score 0.69 and the second position in the French\ntext subtask with F1-score 0.78. These outcomes underscore the effectiveness of\nour methodology in identifying ESG issues in news articles across different\nlanguages. Our findings contribute to the exploration of ESG topics and\nhighlight the potential of leveraging advanced language models for ESG issue\nidentification.", "published": "2023-06-11 12:25:02", "link": "http://arxiv.org/abs/2306.06662v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Versatilists vs. Specialists: An Empirical Revisiting on\n  Multilingual Transfer Ability", "abstract": "Multilingual transfer ability, which reflects how well the models fine-tuned\non one source language can be applied to other languages, has been well studied\nin multilingual pre-trained models (e.g., BLOOM). However, such ability has not\nbeen investigated for English-centric models (e.g., LLaMA). To fill this gap,\nwe study the following research questions. First, does multilingual transfer\nability exist in English-centric models and how does it compare with\nmultilingual pretrained models? Second, does it only appears when English is\nthe source language for the English-centric model? Third, how does it vary in\ndifferent tasks? We take multilingual reasoning ability as our focus and\nconduct extensive experiments across four types of reasoning tasks. We find\nthat the multilingual pretrained model does not always outperform an\nEnglish-centric model. Furthermore, English appears to be a less suitable\nsource language, and the choice of source language becomes less important when\nthe English-centric model scales up. In addition, different types of tasks\nexhibit different multilingual transfer abilities. These findings demonstrate\nthat English-centric models not only possess multilingual transfer ability but\nmay even surpass the transferability of multilingual pretrained models if\nwell-trained. By showing the strength and weaknesses, the experiments also\nprovide valuable insights into enhancing multilingual reasoning abilities for\nthe English-centric models.", "published": "2023-06-11 14:03:09", "link": "http://arxiv.org/abs/2306.06688v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A blind spot for large language models: Supradiegetic linguistic\n  information", "abstract": "Large Language Models (LLMs) like ChatGPT reflect profound changes in the\nfield of Artificial Intelligence, achieving a linguistic fluency that is\nimpressively, even shockingly, human-like. The extent of their current and\npotential capabilities is an active area of investigation by no means limited\nto scientific researchers. It is common for people to frame the training data\nfor LLMs as \"text\" or even \"language\". We examine the details of this framing\nusing ideas from several areas, including linguistics, embodied cognition,\ncognitive science, mathematics, and history. We propose that considering what\nit is like to be an LLM like ChatGPT, as Nagel might have put it, can help us\ngain insight into its capabilities in general, and in particular, that its\nexposure to linguistic training data can be productively reframed as exposure\nto the diegetic information encoded in language, and its deficits can be\nreframed as ignorance of extradiegetic information, including supradiegetic\nlinguistic information. Supradiegetic linguistic information consists of those\narbitrary aspects of the physical form of language that are not derivable from\nthe one-dimensional relations of context -- frequency, adjacency, proximity,\nco-occurrence -- that LLMs like ChatGPT have access to. Roughly speaking, the\ndiegetic portion of a word can be thought of as its function, its meaning, as\nthe information in a theoretical vector in a word embedding, while the\nsupradiegetic portion of the word can be thought of as its form, like the\nshapes of its letters or the sounds of its syllables. We use these concepts to\ninvestigate why LLMs like ChatGPT have trouble handling palindromes, the visual\ncharacteristics of symbols, translating Sumerian cuneiform, and continuing\ninteger sequences.", "published": "2023-06-11 22:15:01", "link": "http://arxiv.org/abs/2306.06794v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Machine Translation for the Indigenous Languages of the Americas:\n  An Introduction", "abstract": "Neural models have drastically advanced state of the art for machine\ntranslation (MT) between high-resource languages. Traditionally, these models\nrely on large amounts of training data, but many language pairs lack these\nresources. However, an important part of the languages in the world do not have\nthis amount of data. Most languages from the Americas are among them, having a\nlimited amount of parallel and monolingual data, if any. Here, we present an\nintroduction to the interested reader to the basic challenges, concepts, and\ntechniques that involve the creation of MT systems for these languages.\nFinally, we discuss the recent advances and findings and open questions,\nproduct of an increased interest of the NLP community in these languages.", "published": "2023-06-11 23:27:47", "link": "http://arxiv.org/abs/2306.06804v1", "categories": ["cs.CL", "stat.ML"], "primary_category": "cs.CL"}
{"title": "A Comprehensive Survey on Applications of Transformers for Deep Learning\n  Tasks", "abstract": "Transformer is a deep neural network that employs a self-attention mechanism\nto comprehend the contextual relationships within sequential data. Unlike\nconventional neural networks or updated versions of Recurrent Neural Networks\n(RNNs) such as Long Short-Term Memory (LSTM), transformer models excel in\nhandling long dependencies between input sequence elements and enable parallel\nprocessing. As a result, transformer-based models have attracted substantial\ninterest among researchers in the field of artificial intelligence. This can be\nattributed to their immense potential and remarkable achievements, not only in\nNatural Language Processing (NLP) tasks but also in a wide range of domains,\nincluding computer vision, audio and speech processing, healthcare, and the\nInternet of Things (IoT). Although several survey papers have been published\nhighlighting the transformer's contributions in specific fields, architectural\ndifferences, or performance evaluations, there is still a significant absence\nof a comprehensive survey paper encompassing its major applications across\nvarious domains. Therefore, we undertook the task of filling this gap by\nconducting an extensive survey of proposed transformer models from 2017 to\n2022. Our survey encompasses the identification of the top five application\ndomains for transformer-based models, namely: NLP, Computer Vision,\nMulti-Modality, Audio and Speech Processing, and Signal Processing. We analyze\nthe impact of highly influential transformer-based models in these domains and\nsubsequently classify them based on their respective tasks using a proposed\ntaxonomy. Our aim is to shed light on the existing potential and future\npossibilities of transformers for enthusiastic researchers, thus contributing\nto the broader understanding of this groundbreaking technology.", "published": "2023-06-11 23:13:51", "link": "http://arxiv.org/abs/2306.07303v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with\n  Academic Compute", "abstract": "Self-supervised learning (SSL) has led to great strides in speech processing.\nHowever, the resources needed to train these models has become prohibitively\nlarge as they continue to scale. Currently, only a few groups with substantial\nresources are capable of creating SSL models, which harms reproducibility. In\nthis work, we optimize HuBERT SSL to fit in academic constraints. We reproduce\nHuBERT independently from the original implementation, with no performance\nloss. Our code and training optimizations make SSL feasible with only 8 GPUs,\ninstead of the 32 used in the original work. We also explore a semi-supervised\nroute, using an ASR model to skip the first pre-training iteration. Within one\niteration of pre-training, our models improve over HuBERT on several tasks.\nFurthermore, our HuBERT Large variant requires only 8 GPUs, achieving similar\nperformance to the original trained on 128. As our contribution to the\ncommunity, all models, configurations, and code are made open-source in ESPnet.", "published": "2023-06-11 12:53:46", "link": "http://arxiv.org/abs/2306.06672v1", "categories": ["cs.CL", "cs.AI", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Estimating the Uncertainty in Emotion Attributes using Deep Evidential\n  Regression", "abstract": "In automatic emotion recognition (AER), labels assigned by different human\nannotators to the same utterance are often inconsistent due to the inherent\ncomplexity of emotion and the subjectivity of perception. Though deterministic\nlabels generated by averaging or voting are often used as the ground truth, it\nignores the intrinsic uncertainty revealed by the inconsistent labels. This\npaper proposes a Bayesian approach, deep evidential emotion regression (DEER),\nto estimate the uncertainty in emotion attributes. Treating the emotion\nattribute labels of an utterance as samples drawn from an unknown Gaussian\ndistribution, DEER places an utterance-specific normal-inverse gamma prior over\nthe Gaussian likelihood and predicts its hyper-parameters using a deep neural\nnetwork model. It enables a joint estimation of emotion attributes along with\nthe aleatoric and epistemic uncertainties. AER experiments on the widely used\nMSP-Podcast and IEMOCAP datasets showed DEER produced state-of-the-art results\nfor both the mean values and the distribution of emotion attributes.", "published": "2023-06-11 20:07:29", "link": "http://arxiv.org/abs/2306.06760v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "The Impact of ChatGPT and LLMs on Medical Imaging Stakeholders:\n  Perspectives and Use Cases", "abstract": "This study investigates the transformative potential of Large Language Models\n(LLMs), such as OpenAI ChatGPT, in medical imaging. With the aid of public\ndata, these models, which possess remarkable language understanding and\ngeneration capabilities, are augmenting the interpretive skills of\nradiologists, enhancing patient-physician communication, and streamlining\nclinical workflows. The paper introduces an analytic framework for presenting\nthe complex interactions between LLMs and the broader ecosystem of medical\nimaging stakeholders, including businesses, insurance entities, governments,\nresearch institutions, and hospitals (nicknamed BIGR-H). Through detailed\nanalyses, illustrative use cases, and discussions on the broader implications\nand future directions, this perspective seeks to raise discussion in strategic\nplanning and decision-making in the era of AI-enabled healthcare.", "published": "2023-06-11 20:39:13", "link": "http://arxiv.org/abs/2306.06767v2", "categories": ["eess.IV", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Impact of Experiencing Misrecognition by Teachable Agents on Learning\n  and Rapport", "abstract": "While speech-enabled teachable agents have some advantages over typing-based\nones, they are vulnerable to errors stemming from misrecognition by automatic\nspeech recognition (ASR). These errors may propagate, resulting in unexpected\nchanges in the flow of conversation. We analyzed how such changes are linked\nwith learning gains and learners' rapport with the agents. Our results show\nthey are not related to learning gains or rapport, regardless of the types of\nresponses the agents should have returned given the correct input from learners\nwithout ASR errors. We also discuss the implications for optimal error-recovery\npolicies for teachable agents that can be drawn from these findings.", "published": "2023-06-11 21:49:42", "link": "http://arxiv.org/abs/2306.07302v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "cs.HC"}
{"title": "Multi-modal Representation Learning for Social Post Location Inference", "abstract": "Inferring geographic locations via social posts is essential for many\npractical location-based applications such as product marketing,\npoint-of-interest recommendation, and infector tracking for COVID-19. Unlike\nimage-based location retrieval or social-post text embedding-based location\ninference, the combined effect of multi-modal information (i.e., post images,\ntext, and hashtags) for social post positioning receives less attention. In\nthis work, we collect real datasets of social posts with images, texts, and\nhashtags from Instagram and propose a novel Multi-modal Representation Learning\nFramework (MRLF) capable of fusing different modalities of social posts for\nlocation inference. MRLF integrates a multi-head attention mechanism to enhance\nlocation-salient information extraction while significantly improving location\ninference compared with single domain-based methods. To overcome the noisy\nuser-generated textual content, we introduce a novel attention-based\ncharacter-aware module that considers the relative dependencies between\ncharacters of social post texts and hashtags for flexible multi-model\ninformation fusion. The experimental results show that MRLF can make accurate\nlocation predictions and open a new door to understanding the multi-modal data\nof social posts for online inference tasks.", "published": "2023-06-11 02:35:48", "link": "http://arxiv.org/abs/2306.07935v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Pairing Enhancement Approach for Aspect Sentiment Triplet Extraction", "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to extract the triplet of an\naspect term, an opinion term, and their corresponding sentiment polarity from\nthe review texts. Due to the complexity of language and the existence of\nmultiple aspect terms and opinion terms in a single sentence, current models\noften confuse the connections between an aspect term and the opinion term\ndescribing it. To address this issue, we propose a pairing enhancement approach\nfor ASTE, which incorporates contrastive learning during the training stage to\ninject aspect-opinion pairing knowledge into the triplet extraction model.\nExperimental results demonstrate that our approach performs well on four ASTE\ndatasets (i.e., 14lap, 14res, 15res and 16res) compared to several related\nclassical and state-of-the-art triplet extraction methods. Moreover, ablation\nstudies conduct an analysis and verify the advantage of contrastive learning\nover other pairing enhancement approaches.", "published": "2023-06-11 07:32:10", "link": "http://arxiv.org/abs/2306.10042v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Audio-Visual Mandarin Electrolaryngeal Speech Voice Conversion", "abstract": "Electrolarynx is a commonly used assistive device to help patients with\nremoved vocal cords regain their ability to speak. Although the electrolarynx\ncan generate excitation signals like the vocal cords, the naturalness and\nintelligibility of electrolaryngeal (EL) speech are very different from those\nof natural (NL) speech. Many deep-learning-based models have been applied to\nelectrolaryngeal speech voice conversion (ELVC) for converting EL speech to NL\nspeech. In this study, we propose a multimodal voice conversion (VC) model that\nintegrates acoustic and visual information into a unified network. We compared\ndifferent pre-trained models as visual feature extractors and evaluated the\neffectiveness of these features in the ELVC task. The experimental results\ndemonstrate that the proposed multimodal VC model outperforms single-modal\nmodels in both objective and subjective metrics, suggesting that the\nintegration of visual information can significantly improve the quality of\nELVC.", "published": "2023-06-11 11:25:17", "link": "http://arxiv.org/abs/2306.06652v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Mandarin Electrolaryngeal Speech Voice Conversion using Cross-domain\n  Features", "abstract": "Patients who have had their entire larynx removed, including the vocal folds,\nowing to throat cancer may experience difficulties in speaking. In such cases,\nelectrolarynx devices are often prescribed to produce speech, which is commonly\nreferred to as electrolaryngeal speech (EL speech). However, the quality and\nintelligibility of EL speech are poor. To address this problem, EL voice\nconversion (ELVC) is a method used to improve the intelligibility and quality\nof EL speech. In this paper, we propose a novel ELVC system that incorporates\ncross-domain features, specifically spectral features and self-supervised\nlearning (SSL) embeddings. The experimental results show that applying\ncross-domain features can notably improve the conversion performance for the\nELVC task compared with utilizing only traditional spectral features.", "published": "2023-06-11 11:25:49", "link": "http://arxiv.org/abs/2306.06653v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "High-Fidelity Audio Compression with Improved RVQGAN", "abstract": "Language models have been successfully used to model natural signals, such as\nimages, speech, and music. A key component of these models is a high quality\nneural compression model that can compress high-dimensional natural signals\ninto lower dimensional discrete tokens. To that end, we introduce a\nhigh-fidelity universal neural audio compression algorithm that achieves ~90x\ncompression of 44.1 KHz audio into tokens at just 8kbps bandwidth. We achieve\nthis by combining advances in high-fidelity audio generation with better vector\nquantization techniques from the image domain, along with improved adversarial\nand reconstruction losses. We compress all domains (speech, environment, music,\netc.) with a single universal model, making it widely applicable to generative\nmodeling of all audio. We compare with competing audio compression algorithms,\nand find our method outperforms them significantly. We provide thorough\nablations for every design choice, as well as open-source code and trained\nmodel weights. We hope our work can lay the foundation for the next generation\nof high-fidelity audio modeling.", "published": "2023-06-11 00:13:00", "link": "http://arxiv.org/abs/2306.06546v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
