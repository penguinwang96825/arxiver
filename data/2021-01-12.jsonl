{"title": "Neural Contract Element Extraction Revisited: Letters from Sesame Street", "abstract": "We investigate contract element extraction. We show that LSTM-based encoders\nperform better than dilated CNNs, Transformers, and BERT in this task. We also\nfind that domain-specific WORD2VEC embeddings outperform generic pre-trained\nGLOVE embeddings. Morpho-syntactic features in the form of POS tag and token\nshape embeddings, as well as context-aware ELMO embeddings do not improve\nperformance. Several of these observations contradict choices or findings of\nprevious work on contract element extraction and generic sequence labeling\ntasks, indicating that contract element extraction requires careful\ntask-specific choices. Analyzing the results of (i) plain TRANSFORMER-based and\n(ii) BERT-based models, we find that in the examined task, where the entities\nare highly context-sensitive, the lack of recurrency in TRANSFORMERs greatly\naffects their performance.", "published": "2021-01-12 09:02:22", "link": "http://arxiv.org/abs/2101.04355v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A character representation enhanced on-device Intent Classification", "abstract": "Intent classification is an important task in natural language understanding\nsystems. Existing approaches have achieved perfect scores on the benchmark\ndatasets. However they are not suitable for deployment on low-resource devices\nlike mobiles, tablets, etc. due to their massive model size. Therefore, in this\npaper, we present a novel light-weight architecture for intent classification\nthat can run efficiently on a device. We use character features to enrich the\nword representation. Our experiments prove that our proposed model outperforms\nexisting approaches and achieves state-of-the-art results on benchmark\ndatasets. We also report that our model has tiny memory footprint of ~5 MB and\nlow inference time of ~2 milliseconds, which proves its efficiency in a\nresource-constrained environment.", "published": "2021-01-12 13:02:05", "link": "http://arxiv.org/abs/2101.04456v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fake News Detection System using XLNet model with Topic Distributions:\n  CONSTRAINT@AAAI2021 Shared Task", "abstract": "With the ease of access to information, and its rapid dissemination over the\ninternet (both velocity and volume), it has become challenging to filter out\ntruthful information from fake ones. The research community is now faced with\nthe task of automatic detection of fake news, which carries real-world\nsocio-political impact. One such research contribution came in the form of the\nConstraint@AAA12021 Shared Task on COVID19 Fake News Detection in English. In\nthis paper, we shed light on a novel method we proposed as a part of this\nshared task. Our team introduced an approach to combine topical distributions\nfrom Latent Dirichlet Allocation (LDA) with contextualized representations from\nXLNet. We also compared our method with existing baselines to show that XLNet +\nTopic Distributions outperforms other approaches by attaining an F1-score of\n0.967.", "published": "2021-01-12 16:23:24", "link": "http://arxiv.org/abs/2101.11425v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transforming Multi-Conditioned Generation from Meaning Representation", "abstract": "In task-oriented conversation systems, natural language generation systems\nthat generate sentences with specific information related to conversation flow\nare useful. Our study focuses on language generation by considering various\ninformation representing the meaning of utterances as multiple conditions of\ngeneration. NLG from meaning representations, the conditions for sentence\nmeaning, generally goes through two steps: sentence planning and surface\nrealization. However, we propose a simple one-stage framework to generate\nutterances directly from MR (Meaning Representation). Our model is based on\nGPT2 and generates utterances with flat conditions on slot and value pairs,\nwhich does not need to determine the structure of the sentence. We evaluate\nseveral systems in the E2E dataset with 6 automatic metrics. Our system is a\nsimple method, but it demonstrates comparable performance to previous systems\nin automated metrics. In addition, using only 10\\% of the data set without any\nother techniques, our model achieves comparable performance, and shows the\npossibility of performing zero-shot generation and expanding to other datasets.", "published": "2021-01-12 01:45:06", "link": "http://arxiv.org/abs/2101.04257v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Quantum Cognitively Motivated Decision Fusion for Video Sentiment\n  Analysis", "abstract": "Video sentiment analysis as a decision-making process is inherently complex,\ninvolving the fusion of decisions from multiple modalities and the so-caused\ncognitive biases. Inspired by recent advances in quantum cognition, we show\nthat the sentiment judgment from one modality could be incompatible with the\njudgment from another, i.e., the order matters and they cannot be jointly\nmeasured to produce a final decision. Thus the cognitive process exhibits\n\"quantum-like\" biases that cannot be captured by classical probability\ntheories. Accordingly, we propose a fundamentally new, quantum cognitively\nmotivated fusion strategy for predicting sentiment judgments. In particular, we\nformulate utterances as quantum superposition states of positive and negative\nsentiment judgments, and uni-modal classifiers as mutually incompatible\nobservables, on a complex-valued Hilbert space with positive-operator valued\nmeasures. Experiments on two benchmarking datasets illustrate that our model\nsignificantly outperforms various existing decision level and a range of\nstate-of-the-art content-level fusion approaches. The results also show that\nthe concept of incompatibility allows effective handling of all combination\npatterns, including those extreme cases that are wrongly predicted by all\nuni-modal classifiers.", "published": "2021-01-12 11:06:04", "link": "http://arxiv.org/abs/2101.04406v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Of Non-Linearity and Commutativity in BERT", "abstract": "In this work we provide new insights into the transformer architecture, and\nin particular, its best-known variant, BERT. First, we propose a method to\nmeasure the degree of non-linearity of different elements of transformers.\nNext, we focus our investigation on the feed-forward networks (FFN) inside\ntransformers, which contain 2/3 of the model parameters and have so far not\nreceived much attention. We find that FFNs are an inefficient yet important\narchitectural element and that they cannot simply be replaced by attention\nblocks without a degradation in performance. Moreover, we study the\ninteractions between layers in BERT and show that, while the layers exhibit\nsome hierarchical structure, they extract features in a fuzzy manner. Our\nresults suggest that BERT has an inductive bias towards layer commutativity,\nwhich we find is mainly due to the skip connections. This provides a\njustification for the strong performance of recurrent and weight-shared\ntransformer models.", "published": "2021-01-12 15:29:38", "link": "http://arxiv.org/abs/2101.04547v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Latent Alignment of Procedural Concepts in Multimodal Recipes", "abstract": "We propose a novel alignment mechanism to deal with procedural reasoning on a\nnewly released multimodal QA dataset, named RecipeQA. Our model is solving the\ntextual cloze task which is a reading comprehension on a recipe containing\nimages and instructions. We exploit the power of attention networks,\ncross-modal representations, and a latent alignment space between instructions\nand candidate answers to solve the problem. We introduce constrained\nmax-pooling which refines the max-pooling operation on the alignment matrix to\nimpose disjoint constraints among the outputs of the model. Our evaluation\nresult indicates a 19\\% improvement over the baselines.", "published": "2021-01-12 19:55:53", "link": "http://arxiv.org/abs/2101.04727v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Quantum Mathematics in Artificial Intelligence", "abstract": "In the decade since 2010, successes in artificial intelligence have been at\nthe forefront of computer science and technology, and vector space models have\nsolidified a position at the forefront of artificial intelligence. At the same\ntime, quantum computers have become much more powerful, and announcements of\nmajor advances are frequently in the news.\n  The mathematical techniques underlying both these areas have more in common\nthan is sometimes realized. Vector spaces took a position at the axiomatic\nheart of quantum mechanics in the 1930s, and this adoption was a key motivation\nfor the derivation of logic and probability from the linear geometry of vector\nspaces. Quantum interactions between particles are modelled using the tensor\nproduct, which is also used to express objects and operations in artificial\nneural networks.\n  This paper describes some of these common mathematical areas, including\nexamples of how they are used in artificial intelligence (AI), particularly in\nautomated reasoning and natural language processing (NLP). Techniques discussed\ninclude vector spaces, scalar products, subspaces and implication, orthogonal\nprojection and negation, dual vectors, density matrices, positive operators,\nand tensor products. Application areas include information retrieval,\ncategorization and implication, modelling word-senses and disambiguation,\ninference in knowledge bases, and semantic composition.\n  Some of these approaches can potentially be implemented on quantum hardware.\nMany of the practical steps in this implementation are in early stages, and\nsome are already realized. Explaining some of the common mathematical tools can\nhelp researchers in both AI and quantum computing further exploit these\noverlaps, recognizing and exploring new directions along the way.", "published": "2021-01-12 01:35:56", "link": "http://arxiv.org/abs/2101.04255v6", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "On the Calibration and Uncertainty of Neural Learning to Rank Models", "abstract": "According to the Probability Ranking Principle (PRP), ranking documents in\ndecreasing order of their probability of relevance leads to an optimal document\nranking for ad-hoc retrieval. The PRP holds when two conditions are met: [C1]\nthe models are well calibrated, and, [C2] the probabilities of relevance are\nreported with certainty. We know however that deep neural networks (DNNs) are\noften not well calibrated and have several sources of uncertainty, and thus\n[C1] and [C2] might not be satisfied by neural rankers. Given the success of\nneural Learning to Rank (L2R) approaches-and here, especially BERT-based\napproaches-we first analyze under which circumstances deterministic, i.e.\noutputs point estimates, neural rankers are calibrated. Then, motivated by our\nfindings we use two techniques to model the uncertainty of neural rankers\nleading to the proposed stochastic rankers, which output a predictive\ndistribution of relevance as opposed to point estimates. Our experimental\nresults on the ad-hoc retrieval task of conversation response ranking reveal\nthat (i) BERT-based rankers are not robustly calibrated and that stochastic\nBERT-based rankers yield better calibration; and (ii) uncertainty estimation is\nbeneficial for both risk-aware neural ranking, i.e.taking into account the\nuncertainty when ranking documents, and for predicting unanswerable\nconversational contexts.", "published": "2021-01-12 09:05:46", "link": "http://arxiv.org/abs/2101.04356v1", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Toward Effective Automated Content Analysis via Crowdsourcing", "abstract": "Many computer scientists use the aggregated answers of online workers to\nrepresent ground truth. Prior work has shown that aggregation methods such as\nmajority voting are effective for measuring relatively objective features. For\nsubjective features such as semantic connotation, online workers, known for\noptimizing their hourly earnings, tend to deteriorate in the quality of their\nresponses as they work longer. In this paper, we aim to address this issue by\nproposing a quality-aware semantic data annotation system. We observe that with\ntimely feedback on workers' performance quantified by quality scores, better\ninformed online workers can maintain the quality of their labeling throughout\nan extended period of time. We validate the effectiveness of the proposed\nannotation system through i) evaluating performance based on an expert-labeled\ndataset, and ii) demonstrating machine learning tasks that can lead to\nconsistent learning behavior with 70%-80% accuracy. Our results suggest that\nwith our system, researchers can collect high-quality answers of subjective\nsemantic features at a large scale.", "published": "2021-01-12 17:14:18", "link": "http://arxiv.org/abs/2101.04615v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "AI- and HPC-enabled Lead Generation for SARS-CoV-2: Models and Processes\n  to Extract Druglike Molecules Contained in Natural Language Text", "abstract": "Researchers worldwide are seeking to repurpose existing drugs or discover new\ndrugs to counter the disease caused by severe acute respiratory syndrome\ncoronavirus 2 (SARS-CoV-2). A promising source of candidates for such studies\nis molecules that have been reported in the scientific literature to be\ndrug-like in the context of coronavirus research. We report here on a project\nthat leverages both human and artificial intelligence to detect references to\ndrug-like molecules in free text. We engage non-expert humans to create a\ncorpus of labeled text, use this labeled corpus to train a named entity\nrecognition model, and employ the trained model to extract 10912 drug-like\nmolecules from the COVID-19 Open Research Dataset Challenge (CORD-19) corpus of\n198875 papers. Performance analyses show that our automated extraction model\ncan achieve performance on par with that of non-expert humans.", "published": "2021-01-12 17:15:43", "link": "http://arxiv.org/abs/2101.04617v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Self-Training Pre-Trained Language Models for Zero- and Few-Shot\n  Multi-Dialectal Arabic Sequence Labeling", "abstract": "A sufficient amount of annotated data is usually required to fine-tune\npre-trained language models for downstream tasks. Unfortunately, attaining\nlabeled data can be costly, especially for multiple language varieties and\ndialects. We propose to self-train pre-trained language models in zero- and\nfew-shot scenarios to improve performance on data-scarce varieties using only\nresources from data-rich ones. We demonstrate the utility of our approach in\nthe context of Arabic sequence labeling by using a language model fine-tuned on\nModern Standard Arabic (MSA) only to predict named entities (NE) and\npart-of-speech (POS) tags on several dialectal Arabic (DA) varieties. We show\nthat self-training is indeed powerful, improving zero-shot MSA-to-DA transfer\nby as large as \\texttildelow 10\\% F$_1$ (NER) and 2\\% accuracy (POS tagging).\nWe acquire even better performance in few-shot scenarios with limited amounts\nof labeled data. We conduct an ablation study and show that the performance\nboost observed directly results from the unlabeled DA examples used for\nself-training. Our work opens up opportunities for developing DA models\nexploiting only MSA resources and it can be extended to other languages and\ntasks. Our code and fine-tuned models can be accessed at\nhttps://github.com/mohammadKhalifa/zero-shot-arabic-dialects.", "published": "2021-01-12 21:29:30", "link": "http://arxiv.org/abs/2101.04758v4", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "TrNews: Heterogeneous User-Interest Transfer Learning for News\n  Recommendation", "abstract": "We investigate how to solve the cross-corpus news recommendation for unseen\nusers in the future. This is a problem where traditional content-based\nrecommendation techniques often fail. Luckily, in real-world recommendation\nservices, some publisher (e.g., Daily news) may have accumulated a large corpus\nwith lots of consumers which can be used for a newly deployed publisher (e.g.,\nPolitical news). To take advantage of the existing corpus, we propose a\ntransfer learning model (dubbed as TrNews) for news recommendation to transfer\nthe knowledge from a source corpus to a target corpus. To tackle the\nheterogeneity of different user interests and of different word distributions\nacross corpora, we design a translator-based transfer-learning strategy to\nlearn a representation mapping between source and target corpora. The learned\ntranslator can be used to generate representations for unseen users in the\nfuture. We show through experiments on real-world datasets that TrNews is\nbetter than various baselines in terms of four metrics. We also show that our\ntranslator is effective among existing transfer strategies.", "published": "2021-01-12 13:52:53", "link": "http://arxiv.org/abs/2101.05611v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Sound Event Detection with Binary Neural Networks on Tightly\n  Power-Constrained IoT Devices", "abstract": "Sound event detection (SED) is a hot topic in consumer and smart city\napplications. Existing approaches based on Deep Neural Networks are very\neffective, but highly demanding in terms of memory, power, and throughput when\ntargeting ultra-low power always-on devices.\n  Latency, availability, cost, and privacy requirements are pushing recent IoT\nsystems to process the data on the node, close to the sensor, with a very\nlimited energy supply, and tight constraints on the memory size and processing\ncapabilities precluding to run state-of-the-art DNNs.\n  In this paper, we explore the combination of extreme quantization to a\nsmall-footprint binary neural network (BNN) with the highly energy-efficient,\nRISC-V-based (8+1)-core GAP8 microcontroller. Starting from an existing CNN for\nSED whose footprint (815 kB) exceeds the 512 kB of memory available on our\nplatform, we retrain the network using binary filters and activations to match\nthese memory constraints. (Fully) binary neural networks come with a natural\ndrop in accuracy of 12-18% on the challenging ImageNet object recognition\nchallenge compared to their equivalent full-precision baselines. This BNN\nreaches a 77.9% accuracy, just 7% lower than the full-precision version, with\n58 kB (7.2 times less) for the weights and 262 kB (2.4 times less) memory in\ntotal. With our BNN implementation, we reach a peak throughput of 4.6 GMAC/s\nand 1.5 GMAC/s over the full network, including preprocessing with Mel bins,\nwhich corresponds to an efficiency of 67.1 GMAC/s/W and 31.3 GMAC/s/W,\nrespectively. Compared to the performance of an ARM Cortex-M4 implementation,\nour system has a 10.3 times faster execution time and a 51.1 times higher\nenergy-efficiency.", "published": "2021-01-12 12:38:23", "link": "http://arxiv.org/abs/2101.04446v1", "categories": ["cs.LG", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Neural Network-based Virtual Microphone Estimator", "abstract": "Developing microphone array technologies for a small number of microphones is\nimportant due to the constraints of many devices. One direction to address this\nsituation consists of virtually augmenting the number of microphone signals,\ne.g., based on several physical model assumptions. However, such assumptions\nare not necessarily met in realistic conditions. In this paper, as an\nalternative approach, we propose a neural network-based virtual microphone\nestimator (NN-VME). The NN-VME estimates virtual microphone signals directly in\nthe time domain, by utilizing the precise estimation capability of the recent\ntime-domain neural networks. We adopt a fully supervised learning framework\nthat uses actual observations at the locations of the virtual microphones at\ntraining time. Consequently, the NN-VME can be trained using only multi-channel\nobservations and thus directly on real recordings, avoiding the need for\nunrealistic physical model-based assumptions. Experiments on the CHiME-4 corpus\nshow that the proposed NN-VME achieves high virtual microphone estimation\nperformance even for real recordings and that a beamformer augmented with the\nNN-VME improves both the speech enhancement and recognition performance.", "published": "2021-01-12 06:30:24", "link": "http://arxiv.org/abs/2101.04315v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Practical Speech Re-use Prevention in Voice-driven Services", "abstract": "Voice-driven services (VDS) are being used in a variety of applications\nranging from smart home control to payments using digital assistants. The input\nto such services is often captured via an open voice channel, e.g., using a\nmicrophone, in an unsupervised setting. One of the key operational security\nrequirements in such setting is the freshness of the input speech. We present\nAEOLUS, a security overlay that proactively embeds a dynamic acoustic nonce at\nthe time of user interaction, and detects the presence of the embedded nonce in\nthe recorded speech to ensure freshness. We demonstrate that acoustic nonce can\n(i) be reliably embedded and retrieved, and (ii) be non-disruptive (and even\nimperceptible) to a VDS user. Optimal parameters (acoustic nonce's operating\nfrequency, amplitude, and bitrate) are determined for (i) and (ii) from a\npractical perspective. Experimental results show that AEOLUS yields 0.5% FRR at\n0% FAR for speech re-use prevention upto a distance of 4 meters in three\nreal-world environments with different background noise levels. We also conduct\na user study with 120 participants, which shows that the acoustic nonce does\nnot degrade overall user experience for 94.16% of speech samples, on average,\nin these environments. AEOLUS can therefore be used in practice to prevent\nspeech re-use and ensure the freshness of speech input.", "published": "2021-01-12 22:00:59", "link": "http://arxiv.org/abs/2101.04773v1", "categories": ["cs.SD", "cs.AI", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MP3net: coherent, minute-long music generation from raw audio with a\n  simple convolutional GAN", "abstract": "We present a deep convolutional GAN which leverages techniques from\nMP3/Vorbis audio compression to produce long, high-quality audio samples with\nlong-range coherence. The model uses a Modified Discrete Cosine Transform\n(MDCT) data representation, which includes all phase information. Phase\ngeneration is hence integral part of the model. We leverage the auditory\nmasking and psychoacoustic perception limit of the human ear to widen the true\ndistribution and stabilize the training process. The model architecture is a\ndeep 2D convolutional network, where each subsequent generator model block\nincreases the resolution along the time axis and adds a higher octave along the\nfrequency axis. The deeper layers are connected with all parts of the output\nand have the context of the full track. This enables generation of samples\nwhich exhibit long-range coherence. We use MP3net to create 95s stereo tracks\nwith a 22kHz sample rate after training for 250h on a single Cloud TPUv2. An\nadditional benefit of the CNN-based model architecture is that generation of\nnew songs is almost instantaneous.", "published": "2021-01-12 22:37:21", "link": "http://arxiv.org/abs/2101.04785v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Efficient Representations for Keyword Spotting with Triplet\n  Loss", "abstract": "In the past few years, triplet loss-based metric embeddings have become a\nde-facto standard for several important computer vision problems, most\nno-tably, person reidentification. On the other hand, in the area of speech\nrecognition the metric embeddings generated by the triplet loss are rarely used\neven for classification problems. We fill this gap showing that a combination\nof two representation learning techniques: a triplet loss-based embedding and a\nvariant of kNN for classification instead of cross-entropy loss significantly\n(by 26% to 38%) improves the classification accuracy for convolutional networks\non a LibriSpeech-derived LibriWords datasets. To do so, we propose a novel\nphonetic similarity based triplet mining approach. We also improve the current\nbest published SOTA for Google Speech Commands dataset V1 10+2 -class\nclassification by about 34%, achieving 98.55% accuracy, V2 10+2-class\nclassification by about 20%, achieving 98.37% accuracy, and V2 35-class\nclassification by over 50%, achieving 97.0% accuracy.", "published": "2021-01-12 22:55:17", "link": "http://arxiv.org/abs/2101.04792v4", "categories": ["eess.AS", "cs.AI", "cs.LG"], "primary_category": "eess.AS"}
