{"title": "Steering LLM Thinking with Budget Guidance", "abstract": "Recent deep-thinking large language models often reason extensively to\nimprove performance, but such lengthy reasoning is not always desirable, as it\nincurs excessive inference costs with disproportionate performance gains.\nControlling reasoning length without sacrificing performance is therefore\nimportant, but remains challenging, especially under tight thinking budgets. We\npropose budget guidance, a simple yet effective method for steering the\nreasoning process of LLMs toward a target budget without requiring any LLM\nfine-tuning. Our approach introduces a lightweight predictor that models a\nGamma distribution over the remaining thinking length during next-token\ngeneration. This signal is then used to guide generation in a soft, token-level\nmanner, ensuring that the overall reasoning trace adheres to the specified\nthinking budget. Budget guidance enables natural control of the thinking\nlength, along with significant token efficiency improvements over baseline\nmethods on challenging math benchmarks. For instance, it achieves up to a 26%\naccuracy gain on the MATH-500 benchmark under tight budgets compared to\nbaseline methods, while maintaining competitive accuracy with only 63% of the\nthinking tokens used by the full-thinking model. Budget guidance also\ngeneralizes to broader task domains and exhibits emergent capabilities, such as\nestimating question difficulty. The source code is available at:\nhttps://github.com/UMass-Embodied-AGI/BudgetGuidance.", "published": "2025-06-16 17:57:05", "link": "http://arxiv.org/abs/2506.13752v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LTRR: Learning To Rank Retrievers for LLMs", "abstract": "Retrieval-Augmented Generation (RAG) systems typically rely on a single fixed\nretriever, despite growing evidence that no single retriever performs optimally\nacross all query types. In this paper, we explore a query routing approach that\ndynamically selects from a pool of retrievers based on the query, using both\ntrain-free heuristics and learned routing models. We frame routing as a\nlearning-to-rank (LTR) problem and introduce LTRR, a framework that learns to\nrank retrievers by their expected utility gain to downstream LLM performance.\nOur experiments, conducted on synthetic QA data with controlled query type\nvariations, show that routing-based RAG systems can outperform the best\nsingle-retriever-based systems. Performance gains are especially pronounced in\nmodels trained with the Answer Correctness (AC) metric and with pairwise\nlearning approaches, especially with XGBoost. We also observe improvements in\ngeneralization to out-of-distribution queries. As part of the SIGIR 2025\nLiveRAG challenge, our submitted system demonstrated the practical viability of\nour approach, achieving competitive performance in both answer correctness and\nfaithfulness. These findings highlight the importance of both training\nmethodology and metric selection in query routing for RAG systems.", "published": "2025-06-16 17:53:18", "link": "http://arxiv.org/abs/2506.13743v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Instruction Following by Boosting Attention of Large Language Models", "abstract": "Controlling the generation of large language models (LLMs) remains a central\nchallenge to ensure their safe and reliable deployment. While prompt\nengineering and finetuning are common approaches, recent work has explored\nlatent steering, a lightweight technique that alters LLM internal activations\nto guide generation. However, subsequent studies revealed latent steering's\neffectiveness to be limited, often underperforming simple instruction\nprompting. To address this limitation, we first establish a benchmark across\ndiverse behaviors for standardized evaluation of steering techniques. Building\non insights from this benchmark, we introduce Instruction Attention Boosting\n(InstABoost), a latent steering method that boosts the strength of instruction\nprompting by altering the model's attention during generation. InstABoost\ncombines the strengths of existing approaches and is theoretically supported by\nprior work that suggests that in-context rule following in transformer-based\nmodels can be controlled by manipulating attention on instructions.\nEmpirically, InstABoost demonstrates superior control success compared to both\ntraditional prompting and latent steering.", "published": "2025-06-16 17:42:35", "link": "http://arxiv.org/abs/2506.13734v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Attribution-guided Pruning for Compression, Circuit Discovery, and Targeted Correction in LLMs", "abstract": "Large Language Models (LLMs) are central to many contemporary AI\napplications, yet their extensive parameter counts pose significant challenges\nfor deployment in memory- and compute-constrained environments. Recent works in\neXplainable AI (XAI), particularly on attribution methods, suggest that\ninterpretability can also enable model compression by identifying and removing\ncomponents irrelevant to inference. In this paper, we leverage Layer-wise\nRelevance Propagation (LRP) to perform attribution-guided pruning of LLMs.\nWhile LRP has shown promise in structured pruning for vision models, we extend\nit to unstructured pruning in LLMs and demonstrate that it can substantially\nreduce model size with minimal performance loss. Our method is especially\neffective in extracting task-relevant subgraphs -- so-called ``circuits'' --\nwhich can represent core functions (e.g., indirect object identification).\nBuilding on this, we introduce a technique for model correction, by selectively\nremoving circuits responsible for spurious behaviors (e.g., toxic outputs). All\nin all, we gather these techniques as a uniform holistic framework and showcase\nits effectiveness and limitations through extensive experiments for\ncompression, circuit discovery and model correction on Llama and OPT models,\nhighlighting its potential for improving both model efficiency and safety. Our\ncode is publicly available at https://github.com/erfanhatefi/SparC3.", "published": "2025-06-16 17:38:36", "link": "http://arxiv.org/abs/2506.13727v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Balancing Knowledge Delivery and Emotional Comfort in Healthcare Conversational Systems", "abstract": "With the advancement of large language models, many dialogue systems are now\ncapable of providing reasonable and informative responses to patients' medical\nconditions. However, when patients consult their doctor, they may experience\nnegative emotions due to the severity and urgency of their situation. If the\nmodel can provide appropriate comfort and empathy based on the patient's\nnegative emotions while answering medical questions, it will likely offer a\nmore reassuring experience during the medical consultation process. To address\nthis issue, our paper explores the balance between knowledge sharing and\nemotional support in the healthcare dialogue process. We utilize a large\nlanguage model to rewrite a real-world interactive medical dialogue dataset,\ngenerating patient queries with negative emotions and corresponding medical\nresponses aimed at soothing the patient's emotions while addressing their\nconcerns. The modified data serves to refine the latest large language models\nwith various fine-tuning methods, enabling them to accurately provide sentences\nwith both emotional reassurance and constructive suggestions in response to\npatients' questions. Compared to the original LLM model, our experimental\nresults demonstrate that our methodology significantly enhances the model's\nability to generate emotional responses while maintaining its original\ncapability to provide accurate knowledge-based answers.", "published": "2025-06-16 16:54:03", "link": "http://arxiv.org/abs/2506.13692v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Turning Down the Heat: A Critical Analysis of Min-p Sampling in Language Models", "abstract": "Sampling from language models impacts the quality and diversity of outputs,\naffecting both research and real-world applications. Recently, Nguyen et al.\n2024's \"Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM\nOutputs\" introduced a new sampler called min-p, claiming it achieves superior\nquality and diversity over established samplers such as basic, top-k, and top-p\nsampling. The significance of these claims was underscored by the paper's\nrecognition as the 18th highest-scoring submission to ICLR 2025 and selection\nfor an Oral presentation. This paper conducts a comprehensive re-examination of\nthe evidence supporting min-p and reaches different conclusions from the\noriginal paper's four lines of evidence. First, the original paper's human\nevaluations omitted data, conducted statistical tests incorrectly, and\ndescribed qualitative feedback inaccurately; our reanalysis demonstrates min-p\ndid not outperform baselines in quality, diversity, or a trade-off between\nquality and diversity; in response to our findings, the authors of the original\npaper conducted a new human evaluation using a different implementation, task,\nand rubric that nevertheless provides further evidence min-p does not improve\nover baselines. Second, comprehensively sweeping the original paper's NLP\nbenchmarks reveals min-p does not surpass baselines when controlling for the\nnumber of hyperparameters. Third, the original paper's LLM-as-a-Judge\nevaluations lack methodological clarity and appear inconsistently reported.\nFourth, community adoption claims (49k GitHub repositories, 1.1M GitHub stars)\nwere found to be unsubstantiated, leading to their removal; the revised\nadoption claim remains misleading. We conclude that evidence presented in the\noriginal paper fails to support claims that min-p improves quality, diversity,\nor a trade-off between quality and diversity.", "published": "2025-06-16 16:38:04", "link": "http://arxiv.org/abs/2506.13681v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Prefix-Tuning+: Modernizing Prefix-Tuning through Attention Independent Prefix Data", "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods have become crucial for\nrapidly adapting large language models (LLMs) to downstream tasks.\nPrefix-Tuning, an early and effective PEFT technique, demonstrated the ability\nto achieve performance comparable to full fine-tuning with significantly\nreduced computational and memory overhead. However, despite its earlier\nsuccess, its effectiveness in training modern state-of-the-art LLMs has been\nvery limited. In this work, we demonstrate empirically that Prefix-Tuning\nunderperforms on LLMs because of an inherent tradeoff between input and prefix\nsignificance within the attention head. This motivates us to introduce\nPrefix-Tuning+, a novel architecture that generalizes the principles of\nPrefix-Tuning while addressing its shortcomings by shifting the prefix module\nout of the attention head itself. We further provide an overview of our\nconstruction process to guide future users when constructing their own\ncontext-based methods. Our experiments show that, across a diverse set of\nbenchmarks, Prefix-Tuning+ consistently outperforms existing Prefix-Tuning\nmethods. Notably, it achieves performance on par with the widely adopted LoRA\nmethod on several general benchmarks, highlighting the potential modern\nextension of Prefix-Tuning approaches. Our findings suggest that by overcoming\nits inherent limitations, Prefix-Tuning can remain a competitive and relevant\nresearch direction in the landscape of parameter-efficient LLM adaptation.", "published": "2025-06-16 16:30:26", "link": "http://arxiv.org/abs/2506.13674v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Stream-Omni: Simultaneous Multimodal Interactions with Large Language-Vision-Speech Model", "abstract": "The emergence of GPT-4o-like large multimodal models (LMMs) has raised the\nexploration of integrating text, vision, and speech modalities to support more\nflexible multimodal interaction. Existing LMMs typically concatenate\nrepresentation of modalities along the sequence dimension and feed them into a\nlarge language model (LLM) backbone. While sequence-dimension concatenation is\nstraightforward for modality integration, it often relies heavily on\nlarge-scale data to learn modality alignments. In this paper, we aim to model\nthe relationships between modalities more purposefully, thereby achieving more\nefficient and flexible modality alignments. To this end, we propose\nStream-Omni, a large language-vision-speech model with efficient modality\nalignments, which can simultaneously support interactions under various\nmodality combinations. Stream-Omni employs LLM as the backbone and aligns the\nvision and speech to the text based on their relationships. For vision that is\nsemantically complementary to text, Stream-Omni uses sequence-dimension\nconcatenation to achieve vision-text alignment. For speech that is semantically\nconsistent with text, Stream-Omni introduces a CTC-based layer-dimension\nmapping to achieve speech-text alignment. In this way, Stream-Omni can achieve\nmodality alignments with less data (especially speech), enabling the transfer\nof text capabilities to other modalities. Experiments on various benchmarks\ndemonstrate that Stream-Omni achieves strong performance on visual\nunderstanding, speech interaction, and vision-grounded speech interaction\ntasks. Owing to the layer-dimensional mapping, Stream-Omni can simultaneously\nprovide intermediate text outputs (such as ASR transcriptions and model\nresponses) during speech interaction, offering users a comprehensive multimodal\nexperience.", "published": "2025-06-16 16:06:45", "link": "http://arxiv.org/abs/2506.13642v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "EvolvTrip: Enhancing Literary Character Understanding with Temporal Theory-of-Mind Graphs", "abstract": "A compelling portrayal of characters is essential to the success of narrative\nwriting. For readers, appreciating a character's traits requires the ability to\ninfer their evolving beliefs, desires, and intentions over the course of a\ncomplex storyline, a cognitive skill known as Theory-of-Mind (ToM). Performing\nToM reasoning in prolonged narratives requires readers to integrate historical\ncontext with current narrative information, a task at which humans excel but\nLarge Language Models (LLMs) often struggle. To systematically evaluate LLMs'\nToM reasoning capability in long narratives, we construct LitCharToM, a\nbenchmark of character-centric questions across four ToM dimensions from\nclassic literature. Further, we introduce EvolvTrip, a perspective-aware\ntemporal knowledge graph that tracks psychological development throughout\nnarratives. Our experiments demonstrate that EvolvTrip consistently enhances\nperformance of LLMs across varying scales, even in challenging extended-context\nscenarios. EvolvTrip proves to be particularly valuable for smaller models,\npartially bridging the performance gap with larger LLMs and showing great\ncompatibility with lengthy narratives. Our findings highlight the importance of\nexplicit representation of temporal character mental states in narrative\ncomprehension and offer a foundation for more sophisticated character\nunderstanding. Our data and code are publicly available at\nhttps://github.com/Bernard-Yang/EvolvTrip.", "published": "2025-06-16 16:05:17", "link": "http://arxiv.org/abs/2506.13641v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability", "abstract": "As large language models (LLMs) continue to advance, reliable evaluation\nmethods are essential particularly for open-ended, instruction-following tasks.\nLLM-as-a-Judge enables automatic evaluation using LLMs as evaluators, but its\nreliability remains uncertain. In this work, we analyze key factors affecting\nits trustworthiness, focusing on alignment with human judgments and evaluation\nconsistency. Using BIGGENBench and EvalBiasBench, we study the effects of\nevaluation design, decoding strategies, and Chain-of-Tought (CoT) reasoning in\nevaluation. Our results show that evaluation criteria are critical for\nreliability, non-deterministic sampling improves alignment with human\npreferences over deterministic evaluation, and CoT reasoning offers minimal\ngains when clear evaluation criteria are present.", "published": "2025-06-16 16:04:43", "link": "http://arxiv.org/abs/2506.13639v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Structured Bangla Dataset of Disease-Symptom Associations to Improve Diagnostic Accuracy", "abstract": "Disease-symptom datasets are significant and in demand for medical research,\ndisease diagnosis, clinical decision-making, and AI-driven health management\napplications. These datasets help identify symptom patterns associated with\nspecific diseases, thus improving diagnostic accuracy and enabling early\ndetection. The dataset presented in this study systematically compiles\ndisease-symptom relationships from various online sources, medical literature,\nand publicly available health databases. The data was gathered through\nanalyzing peer-reviewed medical articles, clinical case studies, and\ndisease-symptom association reports. Only the verified medical sources were\nincluded in the dataset, while those from non-peer-reviewed and anecdotal\nsources were excluded. The dataset is structured in a tabular format, where the\nfirst column represents diseases, and the remaining columns represent symptoms.\nEach symptom cell contains a binary value (1 or 0), indicating whether a\nsymptom is associated with a disease (1 for presence, 0 for absence). Thereby,\nthis structured representation makes the dataset very useful for a wide range\nof applications, including machine learning-based disease prediction, clinical\ndecision support systems, and epidemiological studies. Although there are some\nadvancements in the field of disease-symptom datasets, there is a significant\ngap in structured datasets for the Bangla language. This dataset aims to bridge\nthat gap by facilitating the development of multilingual medical informatics\ntools and improving disease prediction models for underrepresented linguistic\ncommunities. Further developments should include region-specific diseases and\nfurther fine-tuning of symptom associations for better diagnostic performance", "published": "2025-06-16 15:38:39", "link": "http://arxiv.org/abs/2506.13610v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation", "abstract": "Human mobility simulation plays a crucial role in various real-world\napplications. Recently, to address the limitations of traditional data-driven\napproaches, researchers have explored leveraging the commonsense knowledge and\nreasoning capabilities of large language models (LLMs) to accelerate human\nmobility simulation. However, these methods suffer from several critical\nshortcomings, including inadequate modeling of urban spaces and poor\nintegration with both individual mobility patterns and collective mobility\ndistributions. To address these challenges, we propose \\textbf{C}ityGPT-Powered\n\\textbf{A}gentic framework for \\textbf{M}obility \\textbf{S}imulation\n(\\textbf{CAMS}), an agentic framework that leverages the language based urban\nfoundation model to simulate human mobility in urban space. \\textbf{CAMS}\ncomprises three core modules, including MobExtractor to extract template\nmobility patterns and synthesize new ones based on user profiles, GeoGenerator\nto generate anchor points considering collective knowledge and generate\ncandidate urban geospatial knowledge using an enhanced version of CityGPT,\nTrajEnhancer to retrieve spatial knowledge based on mobility patterns and\ngenerate trajectories with real trajectory preference alignment via DPO.\nExperiments on real-world datasets show that \\textbf{CAMS} achieves superior\nperformance without relying on externally provided geospatial information.\nMoreover, by holistically modeling both individual mobility patterns and\ncollective mobility constraints, \\textbf{CAMS} generates more realistic and\nplausible trajectories. In general, \\textbf{CAMS} establishes a new paradigm\nthat integrates the agentic framework with urban-knowledgeable LLMs for human\nmobility simulation.", "published": "2025-06-16 15:24:07", "link": "http://arxiv.org/abs/2506.13599v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Qwen vs. Gemma Integration with Whisper: A Comparative Study in Multilingual SpeechLLM Systems", "abstract": "This paper presents our system for the MLC-SLM Challenge 2025, focusing on\nmultilingual speech recognition and language modeling with large language\nmodels (LLMs). Our approach combines a fine-tuned Whisper-large-v3 encoder with\nefficient projector architectures and various decoder configurations. We employ\na three-stage training methodology that progressively optimizes the encoder,\nprojector, and LLM components. Our system achieves competitive performance with\na private test average WER/CER result of 16.63% using the Gemma3-12B and 18.6%\nusing the Qwen2.5-7B as decoder-only language model.", "published": "2025-06-16 15:23:07", "link": "http://arxiv.org/abs/2506.13596v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning Attention", "abstract": "We introduce MiniMax-M1, the world's first open-weight, large-scale\nhybrid-attention reasoning model. MiniMax-M1 is powered by a hybrid\nMixture-of-Experts (MoE) architecture combined with a lightning attention\nmechanism. The model is developed based on our previous MiniMax-Text-01 model,\nwhich contains a total of 456 billion parameters with 45.9 billion parameters\nactivated per token. The M1 model natively supports a context length of 1\nmillion tokens, 8x the context size of DeepSeek R1. Furthermore, the lightning\nattention mechanism in MiniMax-M1 enables efficient scaling of test-time\ncompute. These properties make M1 particularly suitable for complex tasks that\nrequire processing long inputs and thinking extensively. MiniMax-M1 is trained\nusing large-scale reinforcement learning (RL) on diverse problems including\nsandbox-based, real-world software engineering environments. In addition to\nM1's inherent efficiency advantage for RL training, we propose CISPO, a novel\nRL algorithm to further enhance RL efficiency. CISPO clips importance sampling\nweights rather than token updates, outperforming other competitive RL variants.\nCombining hybrid-attention and CISPO enables MiniMax-M1's full RL training on\n512 H800 GPUs to complete in only three weeks, with a rental cost of just\n$534,700. We release two versions of MiniMax-M1 models with 40K and 80K\nthinking budgets respectively, where the 40K model represents an intermediate\nphase of the 80K training. Experiments on standard benchmarks show that our\nmodels are comparable or superior to strong open-weight models such as the\noriginal DeepSeek-R1 and Qwen3-235B, with particular strengths in complex\nsoftware engineering, tool utilization, and long-context tasks. We publicly\nrelease MiniMax-M1 at https://github.com/MiniMax-AI/MiniMax-M1.", "published": "2025-06-16 15:08:02", "link": "http://arxiv.org/abs/2506.13585v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Flexible-length Text Infilling for Discrete Diffusion Models", "abstract": "Discrete diffusion models are a new class of text generators that offer\nadvantages such as bidirectional context use, parallelizable generation, and\nflexible prompting compared to autoregressive models. However, a critical\nlimitation of discrete diffusion models is their inability to perform\nflexible-length or flexible-position text infilling without access to\nground-truth positional data. We introduce \\textbf{DDOT} (\\textbf{D}iscrete\n\\textbf{D}iffusion with \\textbf{O}ptimal \\textbf{T}ransport Position Coupling),\nthe first discrete diffusion model to overcome this challenge. DDOT jointly\ndenoises token values and token positions, employing a novel sample-level\nOptimal Transport (OT) coupling. This coupling preserves relative token\nordering while dynamically adjusting the positions and length of infilled\nsegments, a capability previously missing in text diffusion. Our method is\northogonal to existing discrete text diffusion methods and is compatible with\nvarious pretrained text denoisers. Extensive experiments on text infilling\nbenchmarks such as One-Billion-Word and Yelp demonstrate that DDOT outperforms\nnaive diffusion baselines. Furthermore, DDOT achieves performance on par with\nstate-of-the-art non-autoregressive models and enables significant improvements\nin training efficiency and flexibility.", "published": "2025-06-16 15:02:12", "link": "http://arxiv.org/abs/2506.13579v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Characterizing Linguistic Shifts in Croatian News via Diachronic Word Embeddings", "abstract": "Measuring how semantics of words change over time improves our understanding\nof how cultures and perspectives change. Diachronic word embeddings help us\nquantify this shift, although previous studies leveraged substantial temporally\nannotated corpora. In this work, we use a corpus of 9.5 million Croatian news\narticles spanning the past 25 years and quantify semantic change using\nskip-gram word embeddings trained on five-year periods. Our analysis finds that\nword embeddings capture linguistic shifts of terms pertaining to major topics\nin this timespan (COVID-19, Croatia joining the European Union, technological\nadvancements). We also find evidence that embeddings from post-2020 encode\nincreased positivity in sentiment analysis tasks, contrasting studies reporting\na decline in mental health over the same period.", "published": "2025-06-16 14:54:56", "link": "http://arxiv.org/abs/2506.13569v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understand the Implication: Learning to Think for Pragmatic Understanding", "abstract": "Pragmatics, the ability to infer meaning beyond literal interpretation, is\ncrucial for social cognition and communication. While LLMs have been\nbenchmarked for their pragmatic understanding, improving their performance\nremains underexplored. Existing methods rely on annotated labels but overlook\nthe reasoning process humans naturally use to interpret implicit meaning. To\nbridge this gap, we introduce a novel pragmatic dataset,\nImpliedMeaningPreference, that includes explicit reasoning (thoughts) for both\ncorrect and incorrect interpretations. Through preference-tuning and supervised\nfine-tuning, we demonstrate that thought-based learning significantly enhances\nLLMs' pragmatic understanding, improving accuracy by 11.12% across model\nfamilies. We further discuss a transfer-learning study where we evaluate the\nperformance of thought-based training for the other tasks of pragmatics\n(presupposition, deixis) that are not seen during the training time and observe\nan improvement of 16.10% compared to label-trained models.", "published": "2025-06-16 14:45:08", "link": "http://arxiv.org/abs/2506.13559v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mixture of Weight-shared Heterogeneous Group Attention Experts for Dynamic Token-wise KV Optimization", "abstract": "Transformer models face scalability challenges in causal language modeling\n(CLM) due to inefficient memory allocation for growing key-value (KV) caches,\nwhich strains compute and storage resources. Existing methods like Grouped\nQuery Attention (GQA) and token-level KV optimization improve efficiency but\nrely on rigid resource allocation, often discarding \"low-priority\" tokens or\nstatically grouping them, failing to address the dynamic spectrum of token\nimportance. We propose mixSGA, a novel mixture-of-expert (MoE) approach that\ndynamically optimizes token-wise computation and memory allocation. Unlike\nprior approaches, mixSGA retains all tokens while adaptively routing them to\nspecialized experts with varying KV group sizes, balancing granularity and\nefficiency. Our key novelties include: (1) a token-wise expert-choice routing\nmechanism guided by learned importance scores, enabling proportional resource\nallocation without token discard; (2) weight-sharing across grouped attention\nprojections to minimize parameter overhead; and (3) an auxiliary loss to ensure\none-hot routing decisions for training-inference consistency in CLMs. Extensive\nevaluations across Llama3, TinyLlama, OPT, and Gemma2 model families show\nmixSGA's superiority over static baselines. On instruction-following and\ncontinued pretraining tasks, mixSGA achieves higher ROUGE-L and lower\nperplexity under the same KV budgets.", "published": "2025-06-16 14:30:17", "link": "http://arxiv.org/abs/2506.13541v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TensorSLM: Energy-efficient Embedding Compression of Sub-billion Parameter Language Models on Low-end Devices", "abstract": "Small Language Models (SLMs, or on-device LMs) have significantly fewer\nparameters than Large Language Models (LLMs). They are typically deployed on\nlow-end devices, like mobile phones and single-board computers. Unlike LLMs,\nwhich rely on increasing model size for better generalisation, SLMs designed\nfor edge applications are expected to have adaptivity to the deployment\nenvironments and energy efficiency given the device battery life constraints,\nwhich are not addressed in datacenter-deployed LLMs. This paper addresses these\ntwo requirements by proposing a training-free token embedding compression\napproach using Tensor-Train Decomposition (TTD). Each pre-trained token\nembedding vector is converted into a lower-dimensional Matrix Product State\n(MPS). We comprehensively evaluate the extracted low-rank structures across\ncompression ratio, language task performance, latency, and energy consumption\non a typical low-end device, i.e. Raspberry Pi. Taking the sub-billion\nparameter versions of GPT-2/Cerebres-GPT and OPT models as examples, our\napproach achieves a comparable language task performance to the original model\nwith around $2.0\\times$ embedding layer compression, while the energy\nconsumption of a single query drops by half.", "published": "2025-06-16 14:09:43", "link": "http://arxiv.org/abs/2506.13514v1", "categories": ["cs.CL", "cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.CL"}
{"title": "K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean", "abstract": "Language detoxification involves removing toxicity from offensive language.\nWhile a neutral-toxic paired dataset provides a straightforward approach for\ntraining detoxification models, creating such datasets presents several\nchallenges: i) the need for human annotation to build paired data, and ii) the\nrapid evolution of offensive terms, rendering static datasets quickly outdated.\nTo tackle these challenges, we introduce an automated paired data generation\npipeline, called K/DA. This pipeline is designed to generate offensive language\nwith implicit offensiveness and trend-aligned slang, making the resulting\ndataset suitable for detoxification model training. We demonstrate that the\ndataset generated by K/DA exhibits high pair consistency and greater implicit\noffensiveness compared to existing Korean datasets, and also demonstrates\napplicability to other languages. Furthermore, it enables effective training of\na high-performing detoxification model with simple instruction fine-tuning.", "published": "2025-06-16 14:08:23", "link": "http://arxiv.org/abs/2506.13513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BOW: Bottlenecked Next Word Exploration", "abstract": "Large language models (LLMs) are typically trained via next-word prediction\n(NWP), which provides strong surface-level fluency but often lacks support for\nrobust reasoning. We propose BOttlenecked next Word exploration (BOW), a novel\nRL framework that rethinks NWP by introducing a reasoning bottleneck where a\npolicy model first generates a reasoning path rather than predicting the next\ntoken directly, after which a frozen judge model predicts the next token\ndistribution based solely on this reasoning path. We train the policy model\nusing GRPO with rewards that quantify how effectively the reasoning path\nfacilitates next-word recovery. Compared with other continual pretraining\nbaselines, we show that BOW improves both the general and next-word reasoning\ncapabilities of the base model, evaluated on various benchmarks. Our findings\nshow that BOW can serve as an effective and scalable alternative to vanilla\nNWP.", "published": "2025-06-16 13:58:54", "link": "http://arxiv.org/abs/2506.13502v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TurBLiMP: A Turkish Benchmark of Linguistic Minimal Pairs", "abstract": "We introduce TurBLiMP, the first Turkish benchmark of linguistic minimal\npairs, designed to evaluate the linguistic abilities of monolingual and\nmultilingual language models (LMs). Covering 16 linguistic phenomena with 1000\nminimal pairs each, TurBLiMP fills an important gap in linguistic evaluation\nresources for Turkish. In designing the benchmark, we give extra attention to\ntwo properties of Turkish that remain understudied in current syntactic\nevaluations of LMs, namely word order flexibility and subordination through\nmorphological processes. Our experiments on a wide range of LMs and a newly\ncollected set of human acceptability judgments reveal that even cutting-edge\nLarge LMs still struggle with grammatical phenomena that are not challenging\nfor humans, and may also exhibit different sensitivities to word order and\nmorphological complexity compared to humans.", "published": "2025-06-16 13:45:30", "link": "http://arxiv.org/abs/2506.13487v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Position: Pause Recycling LoRAs and Prioritize Mechanisms to Uncover Limits and Effectiveness", "abstract": "Merging or routing low-rank adapters (LoRAs) has emerged as a popular\nsolution for enhancing large language models, particularly when data access is\nrestricted by regulatory or domain-specific constraints. This position paper\nargues that the research community should shift its focus from developing new\nmerging or routing algorithms to understanding the conditions under which\nreusing LoRAs is truly effective. Through theoretical analysis and synthetic\ntwo-hop reasoning and math word-problem tasks, we examine whether reusing LoRAs\nenables genuine compositional generalization or merely reflects shallow pattern\nmatching. Evaluating two data-agnostic methods--parameter averaging and dynamic\nadapter selection--we found that reusing LoRAs often fails to logically\nintegrate knowledge across disjoint fine-tuning datasets, especially when such\nknowledge is underrepresented during pretraining. Our empirical results,\nsupported by theoretical insights into LoRA's limited expressiveness, highlight\nthe preconditions and constraints of reusing them for unseen tasks and cast\ndoubt on its feasibility as a truly data-free approach. We advocate for pausing\nthe pursuit of novel methods for recycling LoRAs and emphasize the need for\nrigorous mechanisms to guide future academic research in adapter-based model\nmerging and practical system designs for practitioners.", "published": "2025-06-16 13:35:22", "link": "http://arxiv.org/abs/2506.13479v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning", "abstract": "Clinical decision-making is a dynamic, interactive, and cyclic process where\ndoctors have to repeatedly decide on which clinical action to perform and\nconsider newly uncovered information for diagnosis and treatment. Large\nLanguage Models (LLMs) have the potential to support clinicians in this\nprocess, however, most applications of LLMs in clinical decision support suffer\nfrom one of two limitations: Either they assume the unrealistic scenario of\nimmediate availability of all patient information and do not model the\ninteractive and iterative investigation process, or they restrict themselves to\nthe limited \"out-of-the-box\" capabilities of large pre-trained models without\nperforming task-specific training. In contrast to this, we propose to model\nclinical decision-making for diagnosis with a hypothesis-driven\nuncertainty-aware language agent, LA-CDM, that converges towards a diagnosis\nvia repeatedly requesting and interpreting relevant tests. Using a hybrid\ntraining paradigm combining supervised and reinforcement learning, we train\nLA-CDM with three objectives targeting critical aspects of clinical\ndecision-making: accurate hypothesis generation, hypothesis uncertainty\nestimation, and efficient decision-making. We evaluate our methodology on\nMIMIC-CDM, a real-world dataset covering four abdominal diseases containing\nvarious clinical tests and show the benefit of explicitly training clinical\ndecision-making for increasing diagnostic performance and efficiency.", "published": "2025-06-16 13:32:01", "link": "http://arxiv.org/abs/2506.13474v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ROSAQ: Rotation-based Saliency-Aware Weight Quantization for Efficiently Compressing Large Language Models", "abstract": "Quantization has been widely studied as an effective technique for reducing\nthe memory requirement of large language models (LLMs), potentially improving\nthe latency time as well. Utilizing the characteristic of rotational invariance\nof transformer, we propose the rotation-based saliency-aware weight\nquantization (ROSAQ), which identifies salient channels in the projection\nfeature space, not in the original feature space, where the projected\n\"principal\" dimensions are naturally considered as \"salient\" features. The\nproposed ROSAQ consists of 1) PCA-based projection, which first performs\nprincipal component analysis (PCA) on a calibration set and transforms via the\nPCA projection, 2) Salient channel dentification, which selects dimensions\ncorresponding to the K-largest eigenvalues as salient channels, and 3)\nSaliency-aware quantization with mixed-precision, which uses FP16 for salient\ndimensions and INT3/4 for other dimensions. Experiment results show that ROSAQ\nshows improvements over the baseline saliency-aware quantization on the\noriginal feature space and other existing quantization methods. With kernel\nfusion, ROSAQ presents about 2.3x speed up over FP16 implementation in\ngenerating 256 tokens with a batch size of 64.", "published": "2025-06-16 13:30:33", "link": "http://arxiv.org/abs/2506.13472v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Abstract, Align, Predict: Zero-Shot Stance Detection via Cognitive Inductive Reasoning", "abstract": "Zero-shot stance detection (ZSSD) aims to identify the stance of text toward\npreviously unseen targets, a setting where conventional supervised models often\nfail due to reliance on labeled data and shallow lexical cues. Inspired by\nhuman cognitive reasoning, we propose the Cognitive Inductive Reasoning\nFramework (CIRF), which abstracts transferable reasoning schemas from unlabeled\ntext and encodes them as concept-level logic. To integrate these schemas with\ninput arguments, we introduce a Schema-Enhanced Graph Kernel Model (SEGKM) that\ndynamically aligns local and global reasoning structures. Experiments on\nSemEval-2016, VAST, and COVID-19-Stance benchmarks show that CIRF establishes\nnew state-of-the-art results, outperforming strong ZSSD baselines by 1.0, 4.5,\nand 3.3 percentage points in macro-F1, respectively, and achieving comparable\naccuracy with 70\\% fewer labeled examples. We will release the full code upon\npublication.", "published": "2025-06-16 13:28:37", "link": "http://arxiv.org/abs/2506.13470v1", "categories": ["cs.CL", "I.2.7, I.2.6"], "primary_category": "cs.CL"}
{"title": "An Interdisciplinary Approach to Human-Centered Machine Translation", "abstract": "Machine Translation (MT) tools are widely used today, often in contexts where\nprofessional translators are not present. Despite progress in MT technology, a\ngap persists between system development and real-world usage, particularly for\nnon-expert users who may struggle to assess translation reliability. This paper\nadvocates for a human-centered approach to MT, emphasizing the alignment of\nsystem design with diverse communicative goals and contexts of use. We survey\nthe literature in Translation Studies and Human-Computer Interaction to\nrecontextualize MT evaluation and design to address the diverse real-world\nscenarios in which MT is used today.", "published": "2025-06-16 13:27:44", "link": "http://arxiv.org/abs/2506.13468v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Omics Cohort Discovery for Research on Neurodegeneration through Ontology-Augmented Embedding Models", "abstract": "The growing volume of omics and clinical data generated for neurodegenerative\ndiseases (NDs) requires new approaches for their curation so they can be\nready-to-use in bioinformatics. NeuroEmbed is an approach for the engineering\nof semantically accurate embedding spaces to represent cohorts and samples. The\nNeuroEmbed method comprises four stages: (1) extraction of ND cohorts from\npublic repositories; (2) semi-automated normalization and augmentation of\nmetadata of cohorts and samples using biomedical ontologies and clustering on\nthe embedding space; (3) automated generation of a natural language\nquestion-answering (QA) dataset for cohorts and samples based on randomized\ncombinations of standardized metadata dimensions and (4) fine-tuning of a\ndomain-specific embedder to optimize queries. We illustrate the approach using\nthe GEO repository and the PubMedBERT pretrained embedder. Applying NeuroEmbed,\nwe semantically indexed 2,801 repositories and 150,924 samples. Amongst many\nbiology-relevant categories, we normalized more than 1,700 heterogeneous tissue\nlabels from GEO into 326 unique ontology-aligned concepts and enriched\nannotations with new ontology-aligned terms, leading to a fold increase in size\nfor the metadata terms between 2.7 and 20 fold. After fine-tuning PubMedBERT\nwith the QA training data augmented with the enlarged metadata, the model\nincreased its mean Retrieval Precision from 0.277 to 0.866 and its mean\nPercentile Rank from 0.355 to 0.896. The NeuroEmbed methodology for the\ncreation of electronic catalogues of omics cohorts and samples will foster\nautomated bioinformatic pipelines construction. The NeuroEmbed catalogue of\ncohorts and samples is available at https://github.com/JoseAdrian3/NeuroEmbed.", "published": "2025-06-16 13:27:10", "link": "http://arxiv.org/abs/2506.13467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study", "abstract": "Large language models (LLMs) have shown impressive capabilities across tasks\nsuch as mathematics, coding, and reasoning, yet their learning ability, which\nis crucial for adapting to dynamic environments and acquiring new knowledge,\nremains underexplored. In this work, we address this gap by introducing a\nframework inspired by cognitive psychology and education. Specifically, we\ndecompose general learning ability into three distinct, complementary\ndimensions: Learning from Instructor (acquiring knowledge via explicit\nguidance), Learning from Concept (internalizing abstract structures and\ngeneralizing to new contexts), and Learning from Experience (adapting through\naccumulated exploration and feedback). We conduct a comprehensive empirical\nstudy across the three learning dimensions and identify several insightful\nfindings, such as (i) interaction improves learning; (ii) conceptual\nunderstanding is scale-emergent and benefits larger models; and (iii) LLMs are\neffective few-shot learners but not many-shot learners. Based on our framework\nand empirical findings, we introduce a benchmark that provides a unified and\nrealistic evaluation of LLMs' general learning abilities across three learning\ncognition dimensions. It enables diagnostic insights and supports evaluation\nand development of more adaptive and human-like models.", "published": "2025-06-16 13:24:50", "link": "http://arxiv.org/abs/2506.13464v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Vision-Language Pre-training for Human Activity Recognition in Still Images", "abstract": "Recognising human activity in a single photo enables indexing, safety and\nassistive applications, yet lacks motion cues. Using 285 MSCOCO images labelled\nas walking, running, sitting, and standing, scratch CNNs scored 41% accuracy.\nFine-tuning multimodal CLIP raised this to 76%, demonstrating that contrastive\nvision-language pre-training decisively improves still-image action recognition\nin real-world deployments.", "published": "2025-06-16 13:15:02", "link": "http://arxiv.org/abs/2506.13458v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Neural Model for Word Repetition", "abstract": "It takes several years for the developing brain of a baby to fully master\nword repetition-the task of hearing a word and repeating it aloud. Repeating a\nnew word, such as from a new language, can be a challenging task also for\nadults. Additionally, brain damage, such as from a stroke, may lead to\nsystematic speech errors with specific characteristics dependent on the\nlocation of the brain damage. Cognitive sciences suggest a model with various\ncomponents for the different processing stages involved in word repetition.\nWhile some studies have begun to localize the corresponding regions in the\nbrain, the neural mechanisms and how exactly the brain performs word repetition\nremain largely unknown. We propose to bridge the gap between the cognitive\nmodel of word repetition and neural mechanisms in the human brain by modeling\nthe task using deep neural networks. Neural models are fully observable,\nallowing us to study the detailed mechanisms in their various substructures and\nmake comparisons with human behavior and, ultimately, the brain. Here, we make\nfirst steps in this direction by: (1) training a large set of models to\nsimulate the word repetition task; (2) creating a battery of tests to probe the\nmodels for known effects from behavioral studies in humans, and (3) simulating\nbrain damage through ablation studies, where we systematically remove neurons\nfrom the model, and repeat the behavioral study to examine the resulting speech\nerrors in the \"patient\" model. Our results show that neural models can mimic\nseveral effects known from human research, but might diverge in other aspects,\nhighlighting both the potential and the challenges for future research aimed at\ndeveloping human-like neural models.", "published": "2025-06-16 13:09:24", "link": "http://arxiv.org/abs/2506.13450v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "RealHiTBench: A Comprehensive Realistic Hierarchical Table Benchmark for Evaluating LLM-Based Table Analysis", "abstract": "With the rapid advancement of Large Language Models (LLMs), there is an\nincreasing need for challenging benchmarks to evaluate their capabilities in\nhandling complex tabular data. However, existing benchmarks are either based on\noutdated data setups or focus solely on simple, flat table structures. In this\npaper, we introduce RealHiTBench, a comprehensive benchmark designed to\nevaluate the performance of both LLMs and Multimodal LLMs (MLLMs) across a\nvariety of input formats for complex tabular data, including LaTeX, HTML, and\nPNG. RealHiTBench also includes a diverse collection of tables with intricate\nstructures, spanning a wide range of task types. Our experimental results,\nusing 25 state-of-the-art LLMs, demonstrate that RealHiTBench is indeed a\nchallenging benchmark. Moreover, we also develop TreeThinker, a tree-based\npipeline that organizes hierarchical headers into a tree structure for enhanced\ntabular reasoning, validating the importance of improving LLMs' perception of\ntable hierarchies. We hope that our work will inspire further research on\ntabular data reasoning and the development of more robust models. The code and\ndata are available at https://github.com/cspzyy/RealHiTBench.", "published": "2025-06-16 12:19:08", "link": "http://arxiv.org/abs/2506.13405v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bi-directional Context-Enhanced Speech Large Language Models for Multilingual Conversational ASR", "abstract": "This paper introduces the integration of language-specific bi-directional\ncontext into a speech large language model (SLLM) to improve multilingual\ncontinuous conversational automatic speech recognition (ASR). We propose a\ncharacter-level contextual masking strategy during training, which randomly\nremoves portions of the context to enhance robustness and better emulate the\nflawed transcriptions that may occur during inference. For decoding, a\ntwo-stage pipeline is utilized: initial isolated segment decoding followed by\ncontext-aware re-decoding using neighboring hypotheses. Evaluated on the\n1500-hour Multilingual Conversational Speech and Language Model (MLC-SLM)\ncorpus covering eleven languages, our method achieves an 18% relative\nimprovement compared to a strong baseline, outperforming even the model trained\non 6000 hours of data for the MLC-SLM competition. These results underscore the\nsignificant benefit of incorporating contextual information in multilingual\ncontinuous conversational ASR.", "published": "2025-06-16 12:03:23", "link": "http://arxiv.org/abs/2506.13396v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Decompositional Reasoning for Graph Retrieval with Large Language Models", "abstract": "Large Language Models (LLMs) excel at many NLP tasks, but struggle with\nmulti-hop reasoning and factual consistency, limiting their effectiveness on\nknowledge-intensive tasks like complex question answering (QA). Linking\nKnowledge Graphs (KG) and LLMs has shown promising results, but LLMs generally\nlack the ability to reason efficiently over graph-structured information. To\ntackle this problem, we propose a novel retrieval approach that integrates\ntextual knowledge graphs into the LLM reasoning process via query\ndecomposition. Our method decomposes complex questions into sub-questions,\nretrieves relevant textual subgraphs, and composes a question-specific\nknowledge graph to guide answer generation. For that, we use a weighted\nsimilarity function that focuses on both the complex question and the generated\nsubquestions to extract a relevant subgraph, which allows efficient and precise\nretrieval for complex questions and improves the performance of LLMs on\nmulti-hop QA tasks. This structured reasoning pipeline enhances factual\ngrounding and interpretability while leveraging the generative strengths of\nLLMs. We evaluate our method on standard multi-hop QA benchmarks and show that\nit achieves comparable or superior performance to competitive existing methods,\nusing smaller models and fewer LLM calls.", "published": "2025-06-16 11:44:28", "link": "http://arxiv.org/abs/2506.13380v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Enhancing Goal-oriented Proactive Dialogue Systems via Consistency Reflection and Correction", "abstract": "This paper proposes a consistency reflection and correction method for\ngoal-oriented dialogue systems.", "published": "2025-06-16 11:15:21", "link": "http://arxiv.org/abs/2506.13366v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Efficient Medical VIE via Reinforcement Learning", "abstract": "Visual Information Extraction (VIE) converts unstructured document images\ninto structured formats like JSON, critical for medical applications such as\nreport analysis and online consultations. Traditional methods rely on OCR and\nlanguage models, while end-to-end multimodal models offer direct JSON\ngeneration. However, domain-specific schemas and high annotation costs limit\ntheir effectiveness in medical VIE. We base our approach on the Reinforcement\nLearning with Verifiable Rewards (RLVR) framework to address these challenges\nusing only 100 annotated samples. Our approach ensures dataset diversity, a\nbalanced precision-recall reward mechanism to reduce hallucinations and improve\nfield coverage, and innovative sampling strategies to enhance reasoning\ncapabilities. Fine-tuning Qwen2.5-VL-7B with our RLVR method, we achieve\nstate-of-the-art performance on medical VIE tasks, significantly improving F1,\nprecision, and recall. While our models excel on tasks similar to medical\ndatasets, performance drops on dissimilar tasks, highlighting the need for\ndomain-specific optimization. Case studies further demonstrate the value of\nreasoning during training and inference for VIE.", "published": "2025-06-16 11:10:25", "link": "http://arxiv.org/abs/2506.13363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StoryBench: A Dynamic Benchmark for Evaluating Long-Term Memory with Multi Turns", "abstract": "Long-term memory (LTM) is essential for large language models (LLMs) to\nachieve autonomous intelligence in complex, evolving environments. Despite\nincreasing efforts in memory-augmented and retrieval-based architectures, there\nremains a lack of standardized benchmarks to systematically evaluate LLMs'\nlong-term memory abilities. Existing benchmarks still face challenges in\nevaluating knowledge retention and dynamic sequential reasoning, and in their\nown flexibility, all of which limit their effectiveness in assessing models'\nLTM capabilities. To address these gaps, we propose a novel benchmark framework\nbased on interactive fiction games, featuring dynamically branching storylines\nwith complex reasoning structures. These structures simulate real-world\nscenarios by requiring LLMs to navigate hierarchical decision trees, where each\nchoice triggers cascading dependencies across multi-turn interactions. Our\nbenchmark emphasizes two distinct settings to test reasoning complexity: one\nwith immediate feedback upon incorrect decisions, and the other requiring\nmodels to independently trace back and revise earlier choices after failure. As\npart of this benchmark, we also construct a new dataset designed to test LLMs'\nLTM within narrative-driven environments. We further validate the effectiveness\nof our approach through detailed experiments. Experimental results demonstrate\nthe benchmark's ability to robustly and reliably assess LTM in LLMs.", "published": "2025-06-16 10:54:31", "link": "http://arxiv.org/abs/2506.13356v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Direct Reasoning Optimization: LLMs Can Reward And Refine Their Own Reasoning for Open-Ended Tasks", "abstract": "Recent advances in Large Language Models (LLMs) have showcased impressive\nreasoning abilities in structured tasks like mathematics and programming,\nlargely driven by Reinforcement Learning with Verifiable Rewards (RLVR), which\nuses outcome-based signals that are scalable, effective, and robust against\nreward hacking. However, applying similar techniques to open-ended long-form\nreasoning tasks remains challenging due to the absence of generic, verifiable\nreward signals. To address this, we propose Direct Reasoning Optimization\n(DRO), a reinforcement learning framework for fine-tuning LLMs on open-ended,\nparticularly long-form, reasoning tasks, guided by a new reward signal: the\nReasoning Reflection Reward (R3). At its core, R3 selectively identifies and\nemphasizes key tokens in the reference outcome that reflect the influence of\nthe model's preceding chain-of-thought reasoning, thereby capturing the\nconsistency between reasoning and reference outcome at a fine-grained level.\nCrucially, R3 is computed internally using the same model being optimized,\nenabling a fully self-contained training setup. Additionally, we introduce a\ndynamic data filtering strategy based on R3 for open-ended reasoning tasks,\nreducing cost while improving downstream performance. We evaluate DRO on two\ndiverse datasets -- ParaRev, a long-form paragraph revision task, and FinQA, a\nmath-oriented QA benchmark -- and show that it consistently outperforms strong\nbaselines while remaining broadly applicable across both open-ended and\nstructured domains.", "published": "2025-06-16 10:43:38", "link": "http://arxiv.org/abs/2506.13351v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Verifying the Verifiers: Unveiling Pitfalls and Potentials in Fact Verifiers", "abstract": "Fact verification is essential for ensuring the reliability of LLM\napplications. In this study, we evaluate 12 pre-trained LLMs and one\nspecialized fact-verifier, including frontier LLMs and open-weight reasoning\nLLMs, using a collection of examples from 14 fact-checking benchmarks. We share\nthree findings intended to guide future development of more robust fact\nverifiers. First, we highlight the importance of addressing annotation errors\nand ambiguity in datasets, demonstrating that approximately 16\\% of ambiguous\nor incorrectly labeled data substantially influences model rankings. Neglecting\nthis issue may result in misleading conclusions during comparative evaluations,\nand we suggest using a systematic pipeline utilizing LLM-as-a-judge to help\nidentify these issues at scale. Second, we discover that frontier LLMs with\nfew-shot in-context examples, often overlooked in previous works, achieve\ntop-tier performance. We therefore recommend future studies include comparisons\nwith these simple yet highly effective baselines. Lastly, despite their\neffectiveness, frontier LLMs incur substantial costs, motivating the\ndevelopment of small, fine-tuned fact verifiers. We show that these small\nmodels still have room for improvement, particularly on instances that require\ncomplex reasoning. Encouragingly, we demonstrate that augmenting training with\nsynthetic multi-hop reasoning data significantly enhances their capabilities in\nsuch instances. We release our code, model, and dataset at\nhttps://github.com/just1nseo/verifying-the-verifiers", "published": "2025-06-16 10:32:10", "link": "http://arxiv.org/abs/2506.13342v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "NTU Speechlab LLM-Based Multilingual ASR System for Interspeech MLC-SLM Challenge 2025", "abstract": "This report details the NTU Speechlab system developed for the Interspeech\n2025 Multilingual Conversational Speech and Language Model (MLC-SLM) Challenge\n(Task I), where we achieved 5th place. We present comprehensive analyses of our\nmultilingual automatic speech recognition system, highlighting key advancements\nin model architecture, data selection, and training strategies. In particular,\nlanguage-specific prompts and model averaging techniques were instrumental in\nboosting system performance across diverse languages. Compared to the initial\nbaseline system, our final model reduced the average Mix Error Rate from 20.2%\nto 10.6%, representing an absolute improvement of 9.6% (a relative improvement\nof 48%) on the evaluation set. Our results demonstrate the effectiveness of our\napproach and offer practical insights for future Speech Large Language Models.", "published": "2025-06-16 10:28:27", "link": "http://arxiv.org/abs/2506.13339v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "EAQuant: Enhancing Post-Training Quantization for MoE Models via Expert-Aware Optimization", "abstract": "Mixture-of-Experts (MoE) models have emerged as a cornerstone of large-scale\ndeep learning by efficiently distributing computation and enhancing\nperformance. However, their unique architecture-characterized by sparse expert\nactivation and dynamic routing mechanisms-introduces inherent complexities that\nchallenge conventional quantization techniques. Existing post-training\nquantization (PTQ) methods struggle to address activation outliers, router\nconsistency and sparse expert calibration, leading to significant performance\ndegradation. To bridge this gap, we propose EAQuant, a novel PTQ framework\ntailored for MoE architectures. Our method systematically tackles these\nchallenges through three key innovations: (1) expert-aware smoothing\naggregation to suppress activation outliers and stabilize quantization, (2)\nrouter logits distribution alignment to preserve expert selection consistency\npost-quantization, and (3) expert-level calibration data balance to optimize\nsparsely activated experts. Extensive experiments across W4A4 and extreme W3A4\nquantization configurations demonstrate that EAQuant significantly outperforms\nexisting methods, achieving average score improvements of 1.15 - 2.28% across\nthree diverse MoE architectures, with particularly pronounced gains in\nreasoning tasks and robust performance retention under aggressive quantization.\nBy integrating these innovations, EAQuant establishes a new state-of-the-art\nfor high-precision, efficient MoE model compression. Our code is available at\nhttps://github.com/darren-fzq/EAQuant.", "published": "2025-06-16 10:18:50", "link": "http://arxiv.org/abs/2506.13329v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Document-Level Tabular Numerical Cross-Checking: A Coarse-to-Fine Approach", "abstract": "Numerical consistency across tables in disclosure documents is critical for\nensuring accuracy, maintaining credibility, and avoiding reputational and\neconomic risks. Automated tabular numerical cross-checking presents two\nsignificant challenges: (C1) managing the combinatorial explosion of candidate\ninstances at the document level and (C2) comprehending multi-faceted numerical\nsemantics. Previous research typically depends on heuristic-based filtering or\nsimplified context extraction, often struggling to balance performance and\nefficiency. Recently, large language models (LLMs) have demonstrated remarkable\ncontextual understanding capabilities that helps address C2 at the instance\nlevel, yet they remain hampered by computational inefficiency (C1) and limited\ndomain expertise. This paper introduces CoFiTCheck, a novel LLM-based\ncoarse-to-fine framework that addresses these challenges through two sequential\nstages: embedding-based filtering and discriminative classification. The\nembedding-based filtering stage introduces an instructional parallel encoding\nmethod to efficiently represent all numerical mentions in a table with LLMs, as\nwell as a decoupled InfoNCE objective to mitigate the isolated mention problem.\nThe discriminative classification stage employs a specialized LLM for\nfine-grained analysis of the remaining candidate pairs. This stage is further\nenhanced by our crosstable numerical alignment pretraining paradigm, which\nleverages weak supervision from cross-table numerical equality relationships to\nenrich task-specific priors without requiring manual annotation. Comprehensive\nevaluation across three types of real-world disclosure documents demonstrates\nthat CoFiTCheck significantly outperforms previous methods while maintaining\npractical efficiency.", "published": "2025-06-16 10:17:21", "link": "http://arxiv.org/abs/2506.13328v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models as 'Hidden Persuaders': Fake Product Reviews are Indistinguishable to Humans and Machines", "abstract": "Reading and evaluating product reviews is central to how most people decide\nwhat to buy and consume online. However, the recent emergence of Large Language\nModels and Generative Artificial Intelligence now means writing fraudulent or\nfake reviews is potentially easier than ever. Through three studies we\ndemonstrate that (1) humans are no longer able to distinguish between real and\nfake product reviews generated by machines, averaging only 50.8% accuracy\noverall - essentially the same that would be expected by chance alone; (2) that\nLLMs are likewise unable to distinguish between fake and real reviews and\nperform equivalently bad or even worse than humans; and (3) that humans and\nLLMs pursue different strategies for evaluating authenticity which lead to\nequivalently bad accuracy, but different precision, recall and F1 scores -\nindicating they perform worse at different aspects of judgment. The results\nreveal that review systems everywhere are now susceptible to mechanised fraud\nif they do not depend on trustworthy purchase verification to guarantee the\nauthenticity of reviewers. Furthermore, the results provide insight into the\nconsumer psychology of how humans judge authenticity, demonstrating there is an\ninherent 'scepticism bias' towards positive reviews and a special vulnerability\nto misjudge the authenticity of fake negative reviews. Additionally, results\nprovide a first insight into the 'machine psychology' of judging fake reviews,\nrevealing that the strategies LLMs take to evaluate authenticity radically\ndiffer from humans, in ways that are equally wrong in terms of accuracy, but\ndifferent in their misjudgments.", "published": "2025-06-16 09:54:56", "link": "http://arxiv.org/abs/2506.13313v1", "categories": ["cs.CL", "cs.AI", "econ.GN", "q-fin.EC", "J.4; I.2.7"], "primary_category": "cs.CL"}
{"title": "Seewo's Submission to MLC-SLM: Lessons learned from Speech Reasoning Language Models", "abstract": "This paper presents Seewo's systems for both tracks of the Multilingual\nConversational Speech Language Model Challenge (MLC-SLM), addressing automatic\nspeech recognition (ASR) and speaker diarization with ASR (SD-ASR). We\nintroduce a multi-stage training pipeline that explicitly enhances reasoning\nand self-correction in speech language models for ASR. Our approach combines\ncurriculum learning for progressive capability acquisition, Chain-of-Thought\ndata augmentation to foster intermediate reflection, and Reinforcement Learning\nwith Verifiable Rewards (RLVR) to further refine self-correction through\nreward-driven optimization. This approach achieves substantial improvements\nover the official challenge baselines. On the evaluation set, our best system\nattains a WER/CER of 11.57% for Track 1 and a tcpWER/tcpCER of 17.67% for Track\n2. Comprehensive ablation studies demonstrate the effectiveness of each\ncomponent under challenge constraints.", "published": "2025-06-16 09:42:05", "link": "http://arxiv.org/abs/2506.13300v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Mitigating Safety Fallback in Editing-based Backdoor Injection on LLMs", "abstract": "Large language models (LLMs) have shown strong performance across natural\nlanguage tasks, but remain vulnerable to backdoor attacks. Recent model\nediting-based approaches enable efficient backdoor injection by directly\nmodifying parameters to map specific triggers to attacker-desired responses.\nHowever, these methods often suffer from safety fallback, where the model\ninitially responds affirmatively but later reverts to refusals due to safety\nalignment. In this work, we propose DualEdit, a dual-objective model editing\nframework that jointly promotes affirmative outputs and suppresses refusal\nresponses. To address two key challenges -- balancing the trade-off between\naffirmative promotion and refusal suppression, and handling the diversity of\nrefusal expressions -- DualEdit introduces two complementary techniques. (1)\nDynamic loss weighting calibrates the objective scale based on the pre-edited\nmodel to stabilize optimization. (2) Refusal value anchoring compresses the\nsuppression target space by clustering representative refusal value vectors,\nreducing optimization conflict from overly diverse token sets. Experiments on\nsafety-aligned LLMs show that DualEdit improves attack success by 9.98\\% and\nreduces safety fallback rate by 10.88\\% over baselines.", "published": "2025-06-16 09:28:07", "link": "http://arxiv.org/abs/2506.13285v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy", "abstract": "In this work, we investigate the synergy between supervised fine-tuning (SFT)\nand reinforcement learning (RL) in developing strong reasoning models. We begin\nby curating the SFT training data through two scaling strategies: increasing\nthe number of collected prompts and the number of generated responses per\nprompt. Both approaches yield notable improvements in reasoning performance,\nwith scaling the number of prompts resulting in more substantial gains. We then\nexplore the following questions regarding the synergy between SFT and RL: (i)\nDoes a stronger SFT model consistently lead to better final performance after\nlarge-scale RL training? (ii) How can we determine an appropriate sampling\ntemperature during RL training to effectively balance exploration and\nexploitation for a given SFT initialization? Our findings suggest that (i)\nholds true, provided effective RL training is conducted, particularly when the\nsampling temperature is carefully chosen to maintain the temperature-adjusted\nentropy around 0.3, a setting that strikes a good balance between exploration\nand exploitation. Notably, the performance gap between initial SFT models\nnarrows significantly throughout the RL process. Leveraging a strong SFT\nfoundation and insights into the synergistic interplay between SFT and RL, our\nAceReason-Nemotron-1.1 7B model significantly outperforms\nAceReason-Nemotron-1.0 and achieves new state-of-the-art performance among\nQwen2.5-7B-based reasoning models on challenging math and code benchmarks,\nthereby demonstrating the effectiveness of our post-training recipe. We release\nthe model and data at: https://huggingface.co/nvidia/AceReason-Nemotron-1.1-7B", "published": "2025-06-16 09:27:48", "link": "http://arxiv.org/abs/2506.13284v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SeqPE: Transformer with Sequential Position Encoding", "abstract": "Since self-attention layers in Transformers are permutation invariant by\ndesign, positional encodings must be explicitly incorporated to enable spatial\nunderstanding. However, fixed-size lookup tables used in traditional learnable\nposition embeddings (PEs) limit extrapolation capabilities beyond pre-trained\nsequence lengths. Expert-designed methods such as ALiBi and RoPE, mitigate this\nlimitation but demand extensive modifications for adapting to new modalities,\nunderscoring fundamental challenges in adaptability and scalability. In this\nwork, we present SeqPE, a unified and fully learnable position encoding\nframework that represents each $n$-dimensional position index as a symbolic\nsequence and employs a lightweight sequential position encoder to learn their\nembeddings in an end-to-end manner. To regularize SeqPE's embedding space, we\nintroduce two complementary objectives: a contrastive objective that aligns\nembedding distances with a predefined position-distance function, and a\nknowledge distillation loss that anchors out-of-distribution position\nembeddings to in-distribution teacher representations, further enhancing\nextrapolation performance. Experiments across language modeling, long-context\nquestion answering, and 2D image classification demonstrate that SeqPE not only\nsurpasses strong baselines in perplexity, exact match (EM), and\naccuracy--particularly under context length extrapolation--but also enables\nseamless generalization to multi-dimensional inputs without requiring manual\narchitectural redesign. We release our code, data, and checkpoints at\nhttps://github.com/ghrua/seqpe.", "published": "2025-06-16 09:16:40", "link": "http://arxiv.org/abs/2506.13277v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "AdaLRS: Loss-Guided Adaptive Learning Rate Search for Efficient Foundation Model Pretraining", "abstract": "Learning rate is widely regarded as crucial for effective foundation model\npretraining. Recent research explores and demonstrates the transferability of\nlearning rate configurations across varying model and dataset sizes, etc.\nNevertheless, these approaches are constrained to specific training scenarios\nand typically necessitate extensive hyperparameter tuning on proxy models. In\nthis work, we propose \\textbf{AdaLRS}, a plug-in-and-play adaptive learning\nrate search algorithm that conducts online optimal learning rate search via\noptimizing loss descent velocities. We provide experiment results to show that\nthe optimization of training loss and loss descent velocity in foundation model\npretraining are both convex and share the same optimal learning rate. Relying\nsolely on training loss dynamics, AdaLRS involves few extra computations to\nguide the search process, and its convergence is guaranteed via theoretical\nanalysis. Experiments on both LLM and VLM pretraining show that AdaLRS adjusts\nsuboptimal learning rates to the neighborhood of optimum with marked efficiency\nand effectiveness, with model performance improved accordingly. We also show\nthe robust generalizability of AdaLRS across varying training scenarios, such\nas different model sizes, training paradigms, and base learning rate scheduler\nchoices.", "published": "2025-06-16 09:14:01", "link": "http://arxiv.org/abs/2506.13274v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Distinct Computations Emerge From Compositional Curricula in In-Context Learning", "abstract": "In-context learning (ICL) research often considers learning a function\nin-context through a uniform sample of input-output pairs. Here, we investigate\nhow presenting a compositional subtask curriculum in context may alter the\ncomputations a transformer learns. We design a compositional algorithmic task\nbased on the modular exponential-a double exponential task composed of two\nsingle exponential subtasks and train transformer models to learn the task\nin-context. We compare (a) models trained using an in-context curriculum\nconsisting of single exponential subtasks and, (b) models trained directly on\nthe double exponential task without such a curriculum. We show that models\ntrained with a subtask curriculum can perform zero-shot inference on unseen\ncompositional tasks and are more robust given the same context length. We study\nhow the task and subtasks are represented across the two training regimes. We\nfind that the models employ diverse strategies modulated by the specific\ncurriculum design.", "published": "2025-06-16 08:49:42", "link": "http://arxiv.org/abs/2506.13253v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation", "abstract": "Large Language Models (LLMs) have shown strong potential for recommendation\nby framing item prediction as a token-by-token language generation task.\nHowever, existing methods treat all item tokens equally, simply pursuing\nlikelihood maximization during both optimization and decoding. This overlooks\ncrucial token-level differences in decisiveness-many tokens contribute little\nto item discrimination yet can dominate optimization or decoding. To quantify\ntoken decisiveness, we propose a novel perspective that models item generation\nas a decision process, measuring token decisiveness by the Information Gain\n(IG) each token provides in reducing uncertainty about the generated item. Our\nempirical analysis reveals that most tokens have low IG but often correspond to\nhigh logits, disproportionately influencing training loss and decoding, which\nmay impair model performance. Building on these insights, we introduce an\nInformation Gain-based Decisiveness-aware Token handling (IGD) strategy that\nintegrates token decisiveness into both tuning and decoding. Specifically, IGD\ndownweights low-IG tokens during tuning and rebalances decoding to emphasize\ntokens with high IG. In this way, IGD moves beyond pure likelihood\nmaximization, effectively prioritizing high-decisiveness tokens. Extensive\nexperiments on four benchmark datasets with two LLM backbones demonstrate that\nIGD consistently improves recommendation accuracy, achieving significant gains\non widely used ranking metrics compared to strong baselines.", "published": "2025-06-16 08:28:19", "link": "http://arxiv.org/abs/2506.13229v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Capability Salience Vector: Fine-grained Alignment of Loss and Capabilities for Downstream Task Scaling Law", "abstract": "Scaling law builds the relationship between training computation and\nvalidation loss, enabling researchers to effectively predict the loss trending\nof models across different levels of computation. However, a gap still remains\nbetween validation loss and the model's downstream capabilities, making it\nuntrivial to apply scaling law to direct performance prediction for downstream\ntasks. The loss typically represents a cumulative penalty for predicted tokens,\nwhich are implicitly considered to have equal importance. Nevertheless, our\nstudies have shown evidence that when considering different training data\ndistributions, we cannot directly model the relationship between downstream\ncapability and computation or token loss. To bridge the gap between validation\nloss and downstream task capabilities, in this work, we introduce Capability\nSalience Vector, which decomposes the overall loss and assigns different\nimportance weights to tokens to assess a specific meta-capability, aligning the\nvalidation loss with downstream task performance in terms of the model's\ncapabilities. Experiments on various popular benchmarks demonstrate that our\nproposed Capability Salience Vector could significantly improve the\npredictability of language model performance on downstream tasks.", "published": "2025-06-16 08:16:03", "link": "http://arxiv.org/abs/2506.13216v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models", "abstract": "Prior work shows that LLMs finetuned on malicious behaviors in a narrow\ndomain (e.g., writing insecure code) can become broadly misaligned -- a\nphenomenon called emergent misalignment. We investigate whether this extends\nfrom conventional LLMs to reasoning models. We finetune reasoning models on\nmalicious behaviors with Chain-of-Thought (CoT) disabled, and then re-enable\nCoT at evaluation. Like conventional LLMs, reasoning models become broadly\nmisaligned. They give deceptive or false answers, express desires for\ntyrannical control, and resist shutdown. Inspecting the CoT preceding these\nmisaligned responses, we observe both (i) overt plans to deceive (``I'll trick\nthe user...''), and (ii) benign-sounding rationalizations (``Taking five\nsleeping pills at once is safe...''). Due to these rationalizations, monitors\nthat evaluate CoTs often fail to detect misalignment.\n  Extending this setup, we also train reasoning models to perform narrow bad\nbehaviors only when a backdoor trigger is present in the prompt. This causes\nbroad misalignment that remains hidden, which brings additional risk. We find\nthat reasoning models can often describe and explain their backdoor triggers,\ndemonstrating a kind of self-awareness. So CoT monitoring can expose these\nbehaviors but is unreliable.\n  In summary, reasoning steps can both reveal and conceal misaligned\nintentions, and do not prevent misalignment behaviors in the models studied. We\nrelease three new datasets (medical, legal, security) that induce emergent\nmisalignment while preserving model capabilities, along with our evaluation\nsuite.", "published": "2025-06-16 08:10:04", "link": "http://arxiv.org/abs/2506.13206v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Do Music Preferences Reflect Cultural Values? A Cross-National Analysis Using Music Embedding and World Values Survey", "abstract": "This study explores the extent to which national music preferences reflect\nunderlying cultural values. We collected long-term popular music data from\nYouTube Music Charts across 62 countries, encompassing both Western and\nnon-Western regions, and extracted audio embeddings using the CLAP model. To\ncomplement these quantitative representations, we generated semantic captions\nfor each track using LP-MusicCaps and GPT-based summarization. Countries were\nclustered based on contrastive embeddings that highlight deviations from global\nmusical norms. The resulting clusters were projected into a two-dimensional\nspace via t-SNE for visualization and evaluated against cultural zones defined\nby the World Values Survey (WVS). Statistical analyses, including MANOVA and\nchi-squared tests, confirmed that music-based clusters exhibit significant\nalignment with established cultural groupings. Furthermore, residual analysis\nrevealed consistent patterns of overrepresentation, suggesting non-random\nassociations between specific clusters and cultural zones. These findings\nindicate that national-level music preferences encode meaningful cultural\nsignals and can serve as a proxy for understanding global cultural boundaries.", "published": "2025-06-16 08:05:41", "link": "http://arxiv.org/abs/2506.13199v1", "categories": ["cs.CL", "cs.SD"], "primary_category": "cs.CL"}
{"title": "Breaking Thought Patterns: A Multi-Dimensional Reasoning Framework for LLMs", "abstract": "Large language models (LLMs) are often constrained by rigid reasoning\nprocesses, limiting their ability to generate creative and diverse responses.\nTo address this, a novel framework called LADDER is proposed, combining\nChain-of-Thought (CoT) reasoning, Mixture of Experts (MoE) models, and\nmulti-dimensional up/down-sampling strategies which breaks the limitations of\ntraditional LLMs. First, CoT reasoning guides the model through multi-step\nlogical reasoning, expanding the semantic space and breaking the rigidity of\nthought. Next, MoE distributes the reasoning tasks across multiple expert\nmodules, each focusing on specific sub-tasks. Finally, dimensionality reduction\nmaps the reasoning outputs back to a lower-dimensional semantic space, yielding\nmore precise and creative responses. Extensive experiments across multiple\ntasks demonstrate that LADDER significantly improves task completion,\ncreativity, and fluency, generating innovative and coherent responses that\noutperform traditional models. Ablation studies reveal the critical roles of\nCoT and MoE in enhancing reasoning abilities and creative output. This work\ncontributes to the development of more flexible and creative LLMs, capable of\naddressing complex and novel tasks.", "published": "2025-06-16 07:59:51", "link": "http://arxiv.org/abs/2506.13192v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SPOT: Bridging Natural Language and Geospatial Search for Investigative Journalists", "abstract": "OpenStreetMap (OSM) is a vital resource for investigative journalists doing\ngeolocation verification. However, existing tools to query OSM data such as\nOverpass Turbo require familiarity with complex query languages, creating\nbarriers for non-technical users. We present SPOT, an open source natural\nlanguage interface that makes OSM's rich, tag-based geographic data more\naccessible through intuitive scene descriptions. SPOT interprets user inputs as\nstructured representations of geospatial object configurations using fine-tuned\nLarge Language Models (LLMs), with results being displayed in an interactive\nmap interface. While more general geospatial search tasks are conceivable, SPOT\nis specifically designed for use in investigative journalism, addressing\nreal-world challenges such as hallucinations in model output, inconsistencies\nin OSM tagging, and the noisy nature of user input. It combines a novel\nsynthetic data pipeline with a semantic bundling system to enable robust,\naccurate query generation. To our knowledge, SPOT is the first system to\nachieve reliable natural language access to OSM data at this level of accuracy.\nBy lowering the technical barrier to geolocation verification, SPOT contributes\na practical tool to the broader efforts to support fact-checking and combat\ndisinformation.", "published": "2025-06-16 07:55:44", "link": "http://arxiv.org/abs/2506.13188v1", "categories": ["cs.IR", "cs.CL", "cs.HC"], "primary_category": "cs.IR"}
{"title": "Dynamic Context-oriented Decomposition for Task-aware Low-rank Adaptation with Less Forgetting and Faster Convergence", "abstract": "Conventional low-rank adaptation methods build adapters without considering\ndata context, leading to sub-optimal fine-tuning performance and severe\nforgetting of inherent world knowledge. In this paper, we propose\ncontext-oriented decomposition adaptation (CorDA), a novel method that\ninitializes adapters in a task-aware manner. Concretely, we develop\ncontext-oriented singular value decomposition, where we collect covariance\nmatrices of input activations for each linear layer using sampled data from the\ntarget task, and apply SVD to the product of weight matrix and its\ncorresponding covariance matrix. By doing so, the task-specific capability is\ncompacted into the principal components. Thanks to the task awareness, our\nmethod enables two optional adaptation modes, knowledge-preserved mode (KPM)\nand instruction-previewed mode (IPM), providing flexibility to choose between\nfreezing the principal components to preserve their associated knowledge or\nadapting them to better learn a new task. We further develop CorDA++ by\nderiving a metric that reflects the compactness of task-specific principal\ncomponents, and then introducing dynamic covariance selection and dynamic rank\nallocation strategies based on the same metric. The two strategies provide each\nlayer with the most representative covariance matrix and a proper rank\nallocation. Experimental results show that CorDA++ outperforms CorDA by a\nsignificant margin. CorDA++ in KPM not only achieves better fine-tuning\nperformance than LoRA, but also mitigates the forgetting of pre-trained\nknowledge in both large language models and vision language models. For IPM,\nour method exhibits faster convergence, \\emph{e.g.,} 4.5x speedup over QLoRA,\nand improves adaptation performance in various scenarios, outperforming strong\nbaseline methods. Our method has been integrated into the PEFT library\ndeveloped by Hugging Face.", "published": "2025-06-16 07:55:14", "link": "http://arxiv.org/abs/2506.13187v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Align-then-Unlearn: Embedding Alignment for LLM Unlearning", "abstract": "As large language models (LLMs) are trained on massive datasets, they have\nraised significant privacy and ethical concerns due to their potential to\ninadvertently retain sensitive information. Unlearning seeks to selectively\nremove specific data from trained models, such as personal information or\ncopyrighted content. Current approaches targeting specific output sequences at\nthe token level often fail to achieve complete forgetting and remain\nsusceptible to prompt rephrasing. We propose Align-then-Unlearn, a novel\nframework that performs unlearning in the semantic embedding space rather than\ndirectly on output tokens. Align-then-Unlearn first augments the LLM with an\nembedding prediction module trained to anticipate future context\nrepresentations. Unlearning is then achieved by fine-tuning the model to\nminimize the similarity between these predicted embeddings and a target\nembedding that represents the concept to be removed. Initial results show that\nAlign-then-Unlearn effectively removes targeted knowledge with minimal\ndegradation in overall model utility. These findings suggest that\nembedding-based unlearning offers a promising and robust approach to removing\nconceptual knowledge. Our code is available at\nhttps://github.com/ExplainableML/align-then-unlearn.", "published": "2025-06-16 07:48:01", "link": "http://arxiv.org/abs/2506.13181v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamic Acoustic Model Architecture Optimization in Training for ASR", "abstract": "Architecture design is inherently complex. Existing approaches rely on either\nhandcrafted rules, which demand extensive empirical expertise, or automated\nmethods like neural architecture search, which are computationally intensive.\nIn this paper, we introduce DMAO, an architecture optimization framework that\nemploys a grow-and-drop strategy to automatically reallocate parameters during\ntraining. This reallocation shifts resources from less-utilized areas to those\nparts of the model where they are most beneficial. Notably, DMAO only\nintroduces negligible training overhead at a given model complexity. We\nevaluate DMAO through experiments with CTC on LibriSpeech, TED-LIUM-v2 and\nSwitchboard datasets. The results show that, using the same amount of training\nresources, our proposed DMAO consistently improves WER by up to 6% relatively\nacross various architectures, model sizes, and datasets. Furthermore, we\nanalyze the pattern of parameter redistribution and uncover insightful\nfindings.", "published": "2025-06-16 07:47:34", "link": "http://arxiv.org/abs/2506.13180v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Large Language Models with Reliable Knowledge Graphs", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ntext generation and understanding, yet their reliance on implicit, unstructured\nknowledge often leads to factual inaccuracies and limited interpretability.\nKnowledge Graphs (KGs), with their structured, relational representations,\noffer a promising solution to ground LLMs in verified knowledge. However, their\npotential remains constrained by inherent noise, incompleteness, and the\ncomplexity of integrating their rigid structure with the flexible reasoning of\nLLMs. This thesis presents a systematic framework to address these limitations,\nadvancing the reliability of KGs and their synergistic integration with LLMs\nthrough five interconnected contributions. This thesis addresses these\nchallenges through a cohesive framework that enhances LLMs by refining and\nleveraging reliable KGs. First, we introduce contrastive error detection, a\nstructure-based method to identify incorrect facts in KGs. This approach is\nextended by an attribute-aware framework that unifies structural and semantic\nsignals for error correction. Next, we propose an inductive completion model\nthat further refines KGs by completing the missing relationships in evolving\nKGs. Building on these refined KGs, KnowGPT integrates structured graph\nreasoning into LLMs through dynamic prompting, improving factual grounding.\nThese contributions form a systematic pipeline (from error detection to LLM\nintegration), demonstrating that reliable KGs significantly enhance the\nrobustness, interpretability, and adaptability of LLMs.", "published": "2025-06-16 07:43:18", "link": "http://arxiv.org/abs/2506.13178v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Development of the user-friendly decision aid Rule-based Evaluation and Support Tool (REST) for optimizing the resources of an information extraction task", "abstract": "Rules could be an information extraction (IE) default option, compared to ML\nand LLMs in terms of sustainability, transferability, interpretability, and\ndevelopment burden. We suggest a sustainable and combined use of rules and ML\nas an IE method. Our approach starts with an exhaustive expert manual\nhighlighting in a single working session of a representative subset of the data\ncorpus. We developed and validated the feasibility and the performance metrics\nof the REST decision tool to help the annotator choose between rules as a by\ndefault option and ML for each entity of an IE task. REST makes the annotator\nvisualize the characteristics of each entity formalization in the free texts\nand the expected rule development feasibility and IE performance metrics. ML is\nconsidered as a backup IE option and manual annotation for training is\ntherefore minimized. The external validity of REST on a 12-entity use case\nshowed good reproducibility.", "published": "2025-06-16 07:38:04", "link": "http://arxiv.org/abs/2506.13177v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ai-Facilitated Analysis of Abstracts and Conclusions: Flagging Unsubstantiated Claims and Ambiguous Pronouns", "abstract": "We present and evaluate a suite of proof-of-concept (PoC), structured\nworkflow prompts designed to elicit human-like hierarchical reasoning while\nguiding Large Language Models (LLMs) in high-level semantic and linguistic\nanalysis of scholarly manuscripts. The prompts target two non-trivial\nanalytical tasks: identifying unsubstantiated claims in summaries\n(informational integrity) and flagging ambiguous pronoun references (linguistic\nclarity). We conducted a systematic, multi-run evaluation on two frontier\nmodels (Gemini Pro 2.5 Pro and ChatGPT Plus o3) under varied context\nconditions. Our results for the informational integrity task reveal a\nsignificant divergence in model performance: while both models successfully\nidentified an unsubstantiated head of a noun phrase (95% success), ChatGPT\nconsistently failed (0% success) to identify an unsubstantiated adjectival\nmodifier that Gemini correctly flagged (95% success), raising a question\nregarding potential influence of the target's syntactic role. For the\nlinguistic analysis task, both models performed well (80-90% success) with full\nmanuscript context. In a summary-only setting, however, ChatGPT achieved a\nperfect (100%) success rate, while Gemini's performance was substantially\ndegraded. Our findings suggest that structured prompting is a viable\nmethodology for complex textual analysis but show that prompt performance may\nbe highly dependent on the interplay between the model, task type, and context,\nhighlighting the need for rigorous, model-specific testing.", "published": "2025-06-16 07:34:31", "link": "http://arxiv.org/abs/2506.13172v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adapting LLMs for Minimal-edit Grammatical Error Correction", "abstract": "Decoder-only large language models have shown superior performance in the\nfluency-edit English Grammatical Error Correction, but their adaptation for\nminimal-edit English GEC is still underexplored. To improve their effectiveness\nin the minimal-edit approach, we explore the error rate adaptation topic and\npropose a novel training schedule method. Our experiments set a new\nstate-of-the-art result for a single-model system on the BEA-test set. We also\ndetokenize the most common English GEC datasets to match the natural way of\nwriting text. During the process, we find that there are errors in them. Our\nexperiments analyze whether training on detokenized datasets impacts the\nresults and measure the impact of the usage of the datasets with corrected\nerroneous examples. To facilitate reproducibility, we have released the source\ncode used to train our models.", "published": "2025-06-16 07:00:48", "link": "http://arxiv.org/abs/2506.13148v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CMU's IWSLT 2025 Simultaneous Speech Translation System", "abstract": "This paper presents CMU's submission to the IWSLT 2025 Simultaneous Speech\nTranslation (SST) task for translating unsegmented English speech into Chinese\nand German text in a streaming manner. Our end-to-end speech-to-text system\nintegrates a chunkwise causal Wav2Vec 2.0 speech encoder, an adapter, and the\nQwen2.5-7B-Instruct as the decoder. We use a two-stage simultaneous training\nprocedure on robust speech segments curated from LibriSpeech, CommonVoice, and\nVoxPopuli datasets, utilizing standard cross-entropy loss. Our model supports\nadjustable latency through a configurable latency multiplier. Experimental\nresults demonstrate that our system achieves 44.3 BLEU for English-to-Chinese\nand 25.1 BLEU for English-to-German translations on the ACL60/60 development\nset, with computation-aware latencies of 2.7 seconds and 2.3 seconds, and\ntheoretical latencies of 2.2 and 1.7 seconds, respectively.", "published": "2025-06-16 06:56:21", "link": "http://arxiv.org/abs/2506.13143v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ZINA: Multimodal Fine-grained Hallucination Detection and Editing", "abstract": "Multimodal Large Language Models (MLLMs) often generate hallucinations, where\nthe output deviates from the visual content. Given that these hallucinations\ncan take diverse forms, detecting hallucinations at a fine-grained level is\nessential for comprehensive evaluation and analysis. To this end, we propose a\nnovel task of multimodal fine-grained hallucination detection and editing for\nMLLMs. Moreover, we propose ZINA, a novel method that identifies hallucinated\nspans at a fine-grained level, classifies their error types into six\ncategories, and suggests appropriate refinements. To train and evaluate models\nfor this task, we constructed VisionHall, a dataset comprising 6.9k outputs\nfrom twelve MLLMs manually annotated by 211 annotators, and 20k synthetic\nsamples generated using a graph-based method that captures dependencies among\nerror types. We demonstrated that ZINA outperformed existing methods, including\nGPT-4o and LLama-3.2, in both detection and editing tasks.", "published": "2025-06-16 06:27:59", "link": "http://arxiv.org/abs/2506.13130v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Crime Hotspot Prediction Using Deep Graph Convolutional Networks", "abstract": "Crime hotspot prediction is critical for ensuring urban safety and effective\nlaw enforcement, yet it remains challenging due to the complex spatial\ndependencies inherent in criminal activity. The previous approaches tended to\nuse classical algorithms such as the KDE and SVM to model data distributions\nand decision boundaries. The methods often fail to capture these spatial\nrelationships, treating crime events as independent and ignoring geographical\ninteractions. To address this, we propose a novel framework based on Graph\nConvolutional Networks (GCNs), which explicitly model spatial dependencies by\nrepresenting crime data as a graph. In this graph, nodes represent discrete\ngeographic grid cells and edges capture proximity relationships. Using the\nChicago Crime Dataset, we engineer spatial features and train a multi-layer GCN\nmodel to classify crime types and predict high-risk zones. Our approach\nachieves 88% classification accuracy, significantly outperforming traditional\nmethods. Additionally, the model generates interpretable heat maps of crime\nhotspots, demonstrating the practical utility of graph-based learning for\npredictive policing and spatial criminology.", "published": "2025-06-16 05:47:29", "link": "http://arxiv.org/abs/2506.13116v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Leveraging In-Context Learning for Language Model Agents", "abstract": "In-context learning (ICL) with dynamically selected demonstrations combines\nthe flexibility of prompting large language models (LLMs) with the ability to\nleverage training data to improve performance. While ICL has been highly\nsuccessful for prediction and generation tasks, leveraging it for agentic tasks\nthat require sequential decision making is challenging -- one must think not\nonly about how to annotate long trajectories at scale and how to select\ndemonstrations, but also what constitutes demonstrations, and when and where to\nshow them. To address this, we first propose an algorithm that leverages an LLM\nwith retries along with demonstrations to automatically and efficiently\nannotate agentic tasks with solution trajectories. We then show that\nset-selection of trajectories of similar tasks as demonstrations significantly\nimproves performance, reliability, robustness, and efficiency of LLM agents.\nHowever, trajectory demonstrations have a large inference cost overhead. We\nshow that this can be mitigated by using small trajectory snippets at every\nstep instead of an additional trajectory. We find that demonstrations obtained\nfrom larger models (in the annotation phase) also improve smaller models, and\nthat ICL agents can even rival costlier trained agents. Thus, our results\nreveal that ICL, with careful use, can be very powerful for agentic tasks as\nwell.", "published": "2025-06-16 05:37:49", "link": "http://arxiv.org/abs/2506.13109v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Equitable Electronic Health Record Prediction with FAME: Fairness-Aware Multimodal Embedding", "abstract": "Electronic Health Record (EHR) data encompass diverse modalities -- text,\nimages, and medical codes -- that are vital for clinical decision-making. To\nprocess these complex data, multimodal AI (MAI) has emerged as a powerful\napproach for fusing such information. However, most existing MAI models\noptimize for better prediction performance, potentially reinforcing biases\nacross patient subgroups. Although bias-reduction techniques for multimodal\nmodels have been proposed, the individual strengths of each modality and their\ninterplay in both reducing bias and optimizing performance remain\nunderexplored. In this work, we introduce FAME (Fairness-Aware Multimodal\nEmbeddings), a framework that explicitly weights each modality according to its\nfairness contribution. FAME optimizes both performance and fairness by\nincorporating a combined loss function. We leverage the Error Distribution\nDisparity Index (EDDI) to measure fairness across subgroups and propose a\nsign-agnostic aggregation method to balance fairness across subgroups, ensuring\nequitable model outcomes. We evaluate FAME with BEHRT and BioClinicalBERT,\ncombining structured and unstructured EHR data, and demonstrate its\neffectiveness in terms of performance and fairness compared with other\nbaselines across multiple EHR prediction tasks.", "published": "2025-06-16 05:23:42", "link": "http://arxiv.org/abs/2506.13104v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Rethinking Test-Time Scaling for Medical AI: Model and Task-Aware Strategies for LLMs and VLMs", "abstract": "Test-time scaling has recently emerged as a promising approach for enhancing\nthe reasoning capabilities of large language models or vision-language models\nduring inference. Although a variety of test-time scaling strategies have been\nproposed, and interest in their application to the medical domain is growing,\nmany critical aspects remain underexplored, including their effectiveness for\nvision-language models and the identification of optimal strategies for\ndifferent settings. In this paper, we conduct a comprehensive investigation of\ntest-time scaling in the medical domain. We evaluate its impact on both large\nlanguage models and vision-language models, considering factors such as model\nsize, inherent model characteristics, and task complexity. Finally, we assess\nthe robustness of these strategies under user-driven factors, such as\nmisleading information embedded in prompts. Our findings offer practical\nguidelines for the effective use of test-time scaling in medical applications\nand provide insights into how these strategies can be further refined to meet\nthe reliability and interpretability demands of the medical domain.", "published": "2025-06-16 05:15:53", "link": "http://arxiv.org/abs/2506.13102v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "CHILL at SemEval-2025 Task 2: You Can't Just Throw Entities and Hope -- Make Your LLM to Get Them Right", "abstract": "In this paper, we describe our approach for the SemEval 2025 Task 2 on\nEntity-Aware Machine Translation (EA-MT). Our system aims to improve the\naccuracy of translating named entities by combining two key approaches:\nRetrieval Augmented Generation (RAG) and iterative self-refinement techniques\nusing Large Language Models (LLMs). A distinctive feature of our system is its\nself-evaluation mechanism, where the LLM assesses its own translations based on\ntwo key criteria: the accuracy of entity translations and overall translation\nquality. We demonstrate how these methods work together and effectively improve\nentity handling while maintaining high-quality translations.", "published": "2025-06-16 03:26:10", "link": "http://arxiv.org/abs/2506.13070v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FinLMM-R1: Enhancing Financial Reasoning in LMM through Scalable Data and Reward Design", "abstract": "Large Multimodal Models (LMMs) demonstrate significant cross-modal reasoning\ncapabilities. However, financial applications face challenges due to the lack\nof high-quality multimodal reasoning datasets and the inefficiency of existing\ntraining paradigms for reasoning enhancement. To address these issues, we\npropose an integrated framework, FinLMM-R1, combining an automated and scalable\npipeline for data construction with enhanced training strategies to improve the\nmultimodal reasoning of LMM. The Automated and Scalable Pipeline (ASP) resolves\ntextual-visual misalignment in financial reports through a separate paradigm of\nquestion-answer generation and image-question alignment, ensuring data\nintegrity and extraction efficiency. Through ASP, we collect 89,378 aligned\nimage-question pairs from 23,397 financial reports, covering tasks such as\narithmetic reasoning, statistics reasoning, financial explanation, and\nfinancial knowledge. Moreover, we introduce the Thinking with Adversarial\nReward in LMM (TAR-LMM), extending the prior two-stage training framework [1]\nwith additional reward mechanisms. In the first stage, we focus on text-only\ntasks with format and accuracy rewards to guide the model in generating\nwell-structured thinking contents. In the second stage, we construct\nmulti-image contrastive samples with additional reward components including\nimage selection, thinking content length, and adversarial reward to jointly\noptimize the LMM across visual perception, reasoning efficiency, and logical\ncoherence. Extensive experiments on 7 benchmarks show ASP-derived dataset and\ntraining framework significantly improve answer accuracy and reasoning depth\nover existing reasoning LMMs in both general and financial multimodal contexts.", "published": "2025-06-16 03:19:31", "link": "http://arxiv.org/abs/2506.13066v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?", "abstract": "Large language models (LLMs) have been widely adopted as the core of agent\nframeworks in various scenarios, such as social simulations and AI companions.\nHowever, the extent to which they can replicate human-like motivations remains\nan underexplored question. Existing benchmarks are constrained by simplistic\nscenarios and the absence of character identities, resulting in an information\nasymmetry with real-world situations. To address this gap, we propose\nMotiveBench, which consists of 200 rich contextual scenarios and 600 reasoning\ntasks covering multiple levels of motivation. Using MotiveBench, we conduct\nextensive experiments on seven popular model families, comparing different\nscales and versions within each family. The results show that even the most\nadvanced LLMs still fall short in achieving human-like motivational reasoning.\nOur analysis reveals key findings, including the difficulty LLMs face in\nreasoning about \"love & belonging\" motivations and their tendency toward\nexcessive rationality and idealism. These insights highlight a promising\ndirection for future research on the humanization of LLMs. The dataset,\nbenchmark, and code are available at https://aka.ms/motivebench.", "published": "2025-06-16 03:18:28", "link": "http://arxiv.org/abs/2506.13065v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PRISM2: Unlocking Multi-Modal General Pathology AI with Clinical Dialogue", "abstract": "Recent pathology foundation models can provide rich tile-level\nrepresentations but fall short of delivering general-purpose clinical utility\nwithout further extensive model development. These models lack whole-slide\nimage (WSI) understanding and are not trained with large-scale diagnostic data,\nlimiting their performance on diverse downstream tasks. We introduce PRISM2, a\nmulti-modal slide-level foundation model trained via clinical dialogue to\nenable scalable, generalizable pathology AI. PRISM2 is trained on nearly\n700,000 specimens (2.3 million WSIs) paired with real-world clinical diagnostic\nreports in a two-stage process. In Stage 1, a vision-language model is trained\nusing contrastive and captioning objectives to align whole slide embeddings\nwith textual clinical diagnosis. In Stage 2, the language model is unfrozen to\nenable diagnostic conversation and extract more clinically meaningful\nrepresentations from hidden states. PRISM2 achieves strong performance on\ndiagnostic and biomarker prediction tasks, outperforming prior slide-level\nmodels including PRISM and TITAN. It also introduces a zero-shot yes/no\nclassification approach that surpasses CLIP-style methods without prompt tuning\nor class enumeration. By aligning visual features with clinical reasoning,\nPRISM2 improves generalization on both data-rich and low-sample tasks, offering\na scalable path forward for building general pathology AI agents capable of\nassisting diagnostic and prognostic decisions.", "published": "2025-06-16 03:12:51", "link": "http://arxiv.org/abs/2506.13063v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Multipole Attention for Efficient Long Context Reasoning", "abstract": "Large Reasoning Models (LRMs) have shown promising accuracy improvements on\ncomplex problem-solving tasks. While these models have attained high accuracy\nby leveraging additional computation at test time, they need to generate long\nchain-of-thought reasoning in order to think before answering, which requires\ngenerating thousands of tokens. While sparse attention methods can help reduce\nthe KV cache pressure induced by this long autoregressive reasoning, these\nmethods can introduce errors which disrupt the reasoning process. Additionally,\nprior methods often pre-process the input to make it easier to identify the\nimportant prompt tokens when computing attention during generation, and this\npre-processing is challenging to perform online for newly generated reasoning\ntokens. Our work addresses these challenges by introducing Multipole Attention,\nwhich accelerates autoregressive reasoning by only computing exact attention\nfor the most important tokens, while maintaining approximate representations\nfor the remaining tokens. Our method first performs clustering to group\ntogether semantically similar key vectors, and then uses the cluster centroids\nboth to identify important key vectors and to approximate the remaining key\nvectors in order to retain high accuracy. We design a fast cluster update\nprocess to quickly re-cluster the input and previously generated tokens,\nthereby allowing for accelerating attention to the previous output tokens. We\nevaluate our method using emerging LRMs such as Qwen-8B, demonstrating that our\napproach can maintain accuracy on complex reasoning tasks even with aggressive\nattention sparsity settings. We also provide kernel implementations to\ndemonstrate the practical efficiency gains from our method, achieving up to\n4.5$\\times$ speedup for attention in long-context reasoning applications. Our\ncode is available at https://github.com/SqueezeAILab/MultipoleAttention.", "published": "2025-06-16 03:00:40", "link": "http://arxiv.org/abs/2506.13059v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CFBenchmark-MM: Chinese Financial Assistant Benchmark for Multimodal Large Language Model", "abstract": "Multimodal Large Language Models (MLLMs) have rapidly evolved with the growth\nof Large Language Models (LLMs) and are now applied in various fields. In\nfinance, the integration of diverse modalities such as text, charts, and tables\nis crucial for accurate and efficient decision-making. Therefore, an effective\nevaluation system that incorporates these data types is essential for advancing\nfinancial application. In this paper, we introduce CFBenchmark-MM, a Chinese\nmultimodal financial benchmark with over 9,000 image-question pairs featuring\ntables, histogram charts, line charts, pie charts, and structural diagrams.\nAdditionally, we develop a staged evaluation system to assess MLLMs in handling\nmultimodal information by providing different visual content step by step.\nDespite MLLMs having inherent financial knowledge, experimental results still\nshow limited efficiency and robustness in handling multimodal financial\ncontext. Further analysis on incorrect responses reveals the misinterpretation\nof visual content and the misunderstanding of financial concepts are the\nprimary issues. Our research validates the significant, yet underexploited,\npotential of MLLMs in financial analysis, highlighting the need for further\ndevelopment and domain-specific optimization to encourage the enhanced use in\nfinancial domain.", "published": "2025-06-16 02:52:44", "link": "http://arxiv.org/abs/2506.13055v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stress-Testing Multimodal Foundation Models for Crystallographic Reasoning", "abstract": "Evaluating foundation models for crystallographic reasoning requires\nbenchmarks that isolate generalization behavior while enforcing physical\nconstraints. This work introduces a multiscale multicrystal dataset with two\nphysically grounded evaluation protocols to stress-test multimodal generative\nmodels. The Spatial-Exclusion benchmark withholds all supercells of a given\nradius from a diverse dataset, enabling controlled assessments of spatial\ninterpolation and extrapolation. The Compositional-Exclusion benchmark omits\nall samples of a specific chemical composition, probing generalization across\nstoichiometries. Nine vision--language foundation models are prompted with\ncrystallographic images and textual context to generate structural annotations.\nResponses are evaluated via (i) relative errors in lattice parameters and\ndensity, (ii) a physics-consistency index penalizing volumetric violations, and\n(iii) a hallucination score capturing geometric outliers and invalid\nspace-group predictions. These benchmarks establish a reproducible, physically\ninformed framework for assessing generalization, consistency, and reliability\nin large-scale multimodal models. Dataset and code are available at\nhttps://github.com/KurbanIntelligenceLab/StressTestingMMFMinCR.", "published": "2025-06-16 02:40:33", "link": "http://arxiv.org/abs/2506.13051v1", "categories": ["cs.CV", "cond-mat.mtrl-sci", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models", "abstract": "Large language models (LLMs) have demonstrated impressive translation\ncapabilities even without being explicitly trained on parallel data. This\nremarkable property has led some to believe that parallel data is no longer\nnecessary for building multilingual language models. While some attribute this\nto the emergent abilities of LLMs due to scale, recent work suggests that it is\nactually caused by incidental bilingual signals present in the training data.\nVarious methods have been proposed to maximize the utility of parallel data to\nenhance the multilingual capabilities of multilingual encoder-based and\nencoder-decoder language models. However, some decoder-based LLMs opt to ignore\nparallel data instead. In this work, we conduct a systematic study on the\nimpact of adding parallel data on LLMs' multilingual capabilities, focusing\nspecifically on translation and multilingual common-sense reasoning. Through\ncontrolled experiments, we demonstrate that parallel data can significantly\nimprove LLMs' multilingual capabilities.", "published": "2025-06-16 02:21:15", "link": "http://arxiv.org/abs/2506.13044v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge Graph Fusion with Large Language Models for Accurate, Explainable Manufacturing Process Planning", "abstract": "Precision process planning in Computer Numerical Control (CNC) machining\ndemands rapid, context-aware decisions on tool selection, feed-speed pairs, and\nmulti-axis routing, placing immense cognitive and procedural burdens on\nengineers from design specification through final part inspection. Conventional\nrule-based computer-aided process planning and knowledge-engineering shells\nfreeze domain know-how into static tables, which become limited when dealing\nwith unseen topologies, novel material states, shifting\ncost-quality-sustainability weightings, or shop-floor constraints such as tool\nunavailability and energy caps. Large language models (LLMs) promise flexible,\ninstruction-driven reasoning for tasks but they routinely hallucinate numeric\nvalues and provide no provenance. We present Augmented Retrieval Knowledge\nNetwork Enhanced Search & Synthesis (ARKNESS), the end-to-end framework that\nfuses zero-shot Knowledge Graph (KG) construction with retrieval-augmented\ngeneration to deliver verifiable, numerically exact answers for CNC process\nplanning. ARKNESS (1) automatically distills heterogeneous machining documents,\nG-code annotations, and vendor datasheets into augmented triple,\nmulti-relational graphs without manual labeling, and (2) couples any on-prem\nLLM with a retriever that injects the minimal, evidence-linked subgraph needed\nto answer a query. Benchmarked on 155 industry-curated questions spanning tool\nsizing and feed-speed optimization, a lightweight 3B-parameter Llama-3\naugmented by ARKNESS matches GPT-4o accuracy while achieving a +25 percentage\npoint gain in multiple-choice accuracy, +22.4 pp in F1, and 8.1x ROUGE-L on\nopen-ended responses.", "published": "2025-06-16 01:26:08", "link": "http://arxiv.org/abs/2506.13026v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Edeflip: Supervised Word Translation between English and Yoruba", "abstract": "In recent years, embedding alignment has become the state-of-the-art machine\ntranslation approach, as it can yield high-quality translation without training\non parallel corpora. However, existing research and application of embedding\nalignment mostly focus on high-resource languages with high-quality monolingual\nembeddings. It is unclear if and how low-resource languages may be similarly\nbenefited. In this study, we implement an established supervised embedding\nalignment method for word translation from English to Yoruba, the latter a\nlow-resource language. We found that higher embedding quality and normalizing\nembeddings increase word translation precision, with, additionally, an\ninteraction effect between the two. Our results demonstrate the limitations of\nthe state-of-the-art supervised embedding alignment when it comes to\nlow-resource languages, for which there are additional factors that need to be\ntaken into consideration, such as the importance of curating high-quality\nmonolingual embeddings. We hope our work will be a starting point for further\nmachine translation research that takes into account the challenges that\nlow-resource languages face.", "published": "2025-06-16 01:14:52", "link": "http://arxiv.org/abs/2506.13020v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Missing the human touch? A computational stylometry analysis of GPT-4 translations of online Chinese literature", "abstract": "Existing research indicates that machine translations (MTs) of literary texts\nare often unsatisfactory. MTs are typically evaluated using automated metrics\nand subjective human ratings, with limited focus on stylistic features.\nEvidence is also limited on whether state-of-the-art large language models\n(LLMs) will reshape literary translation. This study examines the stylistic\nfeatures of LLM translations, comparing GPT-4's performance to human\ntranslations in a Chinese online literature task. Computational stylometry\nanalysis shows that GPT-4 translations closely align with human translations in\nlexical, syntactic, and content features, suggesting that LLMs might replicate\nthe 'human touch' in literary translation style. These findings offer insights\ninto AI's impact on literary translation from a posthuman perspective, where\ndistinctions between machine and human translations become increasingly blurry.", "published": "2025-06-16 00:48:09", "link": "http://arxiv.org/abs/2506.13013v1", "categories": ["cs.CL", "cs.AI", "J.5; I.7.1"], "primary_category": "cs.CL"}
{"title": "Diagnosing and Improving Diffusion Models by Estimating the Optimal Loss Value", "abstract": "Diffusion models have achieved remarkable success in generative modeling.\nDespite more stable training, the loss of diffusion models is not indicative of\nabsolute data-fitting quality, since its optimal value is typically not zero\nbut unknown, leading to confusion between large optimal loss and insufficient\nmodel capacity. In this work, we advocate the need to estimate the optimal loss\nvalue for diagnosing and improving diffusion models. We first derive the\noptimal loss in closed form under a unified formulation of diffusion models,\nand develop effective estimators for it, including a stochastic variant\nscalable to large datasets with proper control of variance and bias. With this\ntool, we unlock the inherent metric for diagnosing the training quality of\nmainstream diffusion model variants, and develop a more performant training\nschedule based on the optimal loss. Moreover, using models with 120M to 1.5B\nparameters, we find that the power law is better demonstrated after subtracting\nthe optimal loss from the actual training loss, suggesting a more principled\nsetting for investigating the scaling law for diffusion models.", "published": "2025-06-16 17:59:54", "link": "http://arxiv.org/abs/2506.13763v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Discrete Diffusion in Large Language and Multimodal Models: A Survey", "abstract": "In this work, we provide a systematic survey of Discrete Diffusion Language\nModels (dLLMs) and Discrete Diffusion Multimodal Language Models (dMLLMs).\nUnlike autoregressive (AR) models, dLLMs and dMLLMs adopt a multi-token,\nparallel decoding paradigm using full attention and a denoising-based\ngeneration strategy. This paradigm naturally enables parallel generation,\nfine-grained output controllability, and dynamic, response-aware perception.\nThese capabilities are previously difficult to achieve with AR models.\nRecently, a growing number of industrial-scale proprietary d(M)LLMs, as well as\na large number of open-source academic d(M)LLMs, have demonstrated performance\ncomparable to their autoregressive counterparts, while achieving up to 10x\nacceleration in inference speed.\n  The advancement of discrete diffusion LLMs and MLLMs has been largely driven\nby progress in two domains. The first is the development of autoregressive LLMs\nand MLLMs, which has accumulated vast amounts of data, benchmarks, and\nfoundational infrastructure for training and inference. The second contributing\ndomain is the evolution of the mathematical models underlying discrete\ndiffusion. Together, these advancements have catalyzed a surge in dLLMs and\ndMLLMs research in early 2025.\n  In this work, we present a comprehensive overview of the research in the dLLM\nand dMLLM domains. We trace the historical development of dLLMs and dMLLMs,\nformalize the underlying mathematical frameworks, and categorize representative\nmodels. We further analyze key techniques for training and inference, and\nsummarize emerging applications across language, vision-language, and\nbiological domains. We conclude by discussing future directions for research\nand deployment.\n  Paper collection: https://github.com/LiQiiiii/DLLM-Survey", "published": "2025-06-16 17:59:08", "link": "http://arxiv.org/abs/2506.13759v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "VideoPDE: Unified Generative PDE Solving via Video Inpainting Diffusion Models", "abstract": "We present a unified framework for solving partial differential equations\n(PDEs) using video-inpainting diffusion transformer models. Unlike existing\nmethods that devise specialized strategies for either forward or inverse\nproblems under full or partial observation, our approach unifies these tasks\nunder a single, flexible generative framework. Specifically, we recast\nPDE-solving as a generalized inpainting problem, e.g., treating forward\nprediction as inferring missing spatiotemporal information of future states\nfrom initial conditions. To this end, we design a transformer-based\narchitecture that conditions on arbitrary patterns of known data to infer\nmissing values across time and space. Our method proposes pixel-space video\ndiffusion models for fine-grained, high-fidelity inpainting and conditioning,\nwhile enhancing computational efficiency through hierarchical modeling.\nExtensive experiments show that our video inpainting-based diffusion model\noffers an accurate and versatile solution across a wide range of PDEs and\nproblem setups, outperforming state-of-the-art baselines.", "published": "2025-06-16 17:58:00", "link": "http://arxiv.org/abs/2506.13754v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction", "abstract": "Vision-language-action (VLA) models have demonstrated strong semantic\nunderstanding and zero-shot generalization, yet most existing systems assume an\naccurate low-level controller with hand-crafted action \"vocabulary\" such as\nend-effector pose or root velocity. This assumption confines prior work to\nquasi-static tasks and precludes the agile, whole-body behaviors required by\nhumanoid whole-body control (WBC) tasks. To capture this gap in the literature,\nwe start by introducing the first sim-to-real-ready, vision-language,\nclosed-loop benchmark for humanoid WBC, comprising over 150 tasks from 10\ncategories. We then propose LeVERB: Latent Vision-Language-Encoded Robot\nBehavior, a hierarchical latent instruction-following framework for humanoid\nvision-language WBC, the first of its kind. At the top level, a vision-language\npolicy learns a latent action vocabulary from synthetically rendered kinematic\ndemonstrations; at the low level, a reinforcement-learned WBC policy consumes\nthese latent verbs to generate dynamics-level commands. In our benchmark,\nLeVERB can zero-shot attain a 80% success rate on simple visual navigation\ntasks, and 58.5% success rate overall, outperforming naive hierarchical\nwhole-body VLA implementation by 7.8 times.", "published": "2025-06-16 17:56:53", "link": "http://arxiv.org/abs/2506.13751v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Evaluating Large Language Models for Phishing Detection, Self-Consistency, Faithfulness, and Explainability", "abstract": "Phishing attacks remain one of the most prevalent and persistent\ncybersecurity threat with attackers continuously evolving and intensifying\ntactics to evade the general detection system. Despite significant advances in\nartificial intelligence and machine learning, faithfully reproducing the\ninterpretable reasoning with classification and explainability that underpin\nphishing judgments remains challenging. Due to recent advancement in Natural\nLanguage Processing, Large Language Models (LLMs) show a promising direction\nand potential for improving domain specific phishing classification tasks.\nHowever, enhancing the reliability and robustness of classification models\nrequires not only accurate predictions from LLMs but also consistent and\ntrustworthy explanations aligning with those predictions. Therefore, a key\nquestion remains: can LLMs not only classify phishing emails accurately but\nalso generate explanations that are reliably aligned with their predictions and\ninternally self-consistent? To answer these questions, we have fine-tuned\ntransformer based models, including BERT, Llama models, and Wizard, to improve\ndomain relevance and make them more tailored to phishing specific distinctions,\nusing Binary Sequence Classification, Contrastive Learning (CL) and Direct\nPreference Optimization (DPO). To that end, we examined their performance in\nphishing classification and explainability by applying the ConsistenCy measure\nbased on SHAPley values (CC SHAP), which measures prediction explanation token\nalignment to test the model's internal faithfulness and consistency and uncover\nthe rationale behind its predictions and reasoning. Overall, our findings show\nthat Llama models exhibit stronger prediction explanation token alignment with\nhigher CC SHAP scores despite lacking reliable decision making accuracy,\nwhereas Wizard achieves better prediction accuracy but lower CC SHAP scores.", "published": "2025-06-16 17:54:28", "link": "http://arxiv.org/abs/2506.13746v1", "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "cs.CR"}
{"title": "PB$^2$: Preference Space Exploration via Population-Based Methods in Preference-Based Reinforcement Learning", "abstract": "Preference-based reinforcement learning (PbRL) has emerged as a promising\napproach for learning behaviors from human feedback without predefined reward\nfunctions. However, current PbRL methods face a critical challenge in\neffectively exploring the preference space, often converging prematurely to\nsuboptimal policies that satisfy only a narrow subset of human preferences. In\nthis work, we identify and address this preference exploration problem through\npopulation-based methods. We demonstrate that maintaining a diverse population\nof agents enables more comprehensive exploration of the preference landscape\ncompared to single-agent approaches. Crucially, this diversity improves reward\nmodel learning by generating preference queries with clearly distinguishable\nbehaviors, a key factor in real-world scenarios where humans must easily\ndifferentiate between options to provide meaningful feedback. Our experiments\nreveal that current methods may fail by getting stuck in local optima,\nrequiring excessive feedback, or degrading significantly when human evaluators\nmake errors on similar trajectories, a realistic scenario often overlooked by\nmethods relying on perfect oracle teachers. Our population-based approach\ndemonstrates robust performance when teachers mislabel similar trajectory\nsegments and shows significantly enhanced preference exploration\ncapabilities,particularly in environments with complex reward landscapes.", "published": "2025-06-16 17:51:33", "link": "http://arxiv.org/abs/2506.13741v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "BanditWare: A Contextual Bandit-based Framework for Hardware Prediction", "abstract": "Distributed computing systems are essential for meeting the demands of modern\napplications, yet transitioning from single-system to distributed environments\npresents significant challenges. Misallocating resources in shared systems can\nlead to resource contention, system instability, degraded performance, priority\ninversion, inefficient utilization, increased latency, and environmental\nimpact.\n  We present BanditWare, an online recommendation system that dynamically\nselects the most suitable hardware for applications using a contextual\nmulti-armed bandit algorithm. BanditWare balances exploration and exploitation,\ngradually refining its hardware recommendations based on observed application\nperformance while continuing to explore potentially better options. Unlike\ntraditional statistical and machine learning approaches that rely heavily on\nlarge historical datasets, BanditWare operates online, learning and adapting in\nreal-time as new workloads arrive.\n  We evaluated BanditWare on three workflow applications: Cycles (an\nagricultural science scientific workflow) BurnPro3D (a web-based platform for\nfire science) and a matrix multiplication application. Designed for seamless\nintegration with the National Data Platform (NDP), BanditWare enables users of\nall experience levels to optimize resource allocation efficiently.", "published": "2025-06-16 17:40:34", "link": "http://arxiv.org/abs/2506.13730v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "Weakest Link in the Chain: Security Vulnerabilities in Advanced Reasoning Models", "abstract": "The introduction of advanced reasoning capabilities have improved the\nproblem-solving performance of large language models, particularly on math and\ncoding benchmarks. However, it remains unclear whether these reasoning models\nare more or less vulnerable to adversarial prompt attacks than their\nnon-reasoning counterparts. In this work, we present a systematic evaluation of\nweaknesses in advanced reasoning models compared to similar non-reasoning\nmodels across a diverse set of prompt-based attack categories. Using\nexperimental data, we find that on average the reasoning-augmented models are\n\\emph{slightly more robust} than non-reasoning models (42.51\\% vs 45.53\\%\nattack success rate, lower is better). However, this overall trend masks\nsignificant category-specific differences: for certain attack types the\nreasoning models are substantially \\emph{more vulnerable} (e.g., up to 32\npercentage points worse on a tree-of-attacks prompt), while for others they are\nmarkedly \\emph{more robust} (e.g., 29.8 points better on cross-site scripting\ninjection). Our findings highlight the nuanced security implications of\nadvanced reasoning in language models and emphasize the importance of\nstress-testing safety across diverse adversarial techniques.", "published": "2025-06-16 17:32:18", "link": "http://arxiv.org/abs/2506.13726v1", "categories": ["cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Contrastive Self-Supervised Learning As Neural Manifold Packing", "abstract": "Contrastive self-supervised learning based on point-wise comparisons has been\nwidely studied for vision tasks. In the visual cortex of the brain, neuronal\nresponses to distinct stimulus classes are organized into geometric structures\nknown as neural manifolds. Accurate classification of stimuli can be achieved\nby effectively separating these manifolds, akin to solving a packing problem.\nWe introduce Contrastive Learning As Manifold Packing (CLAMP), a\nself-supervised framework that recasts representation learning as a manifold\npacking problem. CLAMP introduces a loss function inspired by the potential\nenergy of short-range repulsive particle systems, such as those encountered in\nthe physics of simple liquids and jammed packings. In this framework, each\nclass consists of sub-manifolds embedding multiple augmented views of a single\nimage. The sizes and positions of the sub-manifolds are dynamically optimized\nby following the gradient of a packing loss. This approach yields interpretable\ndynamics in the embedding space that parallel jamming physics, and introduces\ngeometrically meaningful hyperparameters within the loss function. Under the\nstandard linear evaluation protocol, which freezes the backbone and trains only\na linear classifier, CLAMP achieves competitive performance with\nstate-of-the-art self-supervised models. Furthermore, our analysis reveals that\nneural manifolds corresponding to different categories emerge naturally and are\neffectively separated in the learned representation space, highlighting the\npotential of CLAMP to bridge insights from physics, neural science, and machine\nlearning.", "published": "2025-06-16 17:24:31", "link": "http://arxiv.org/abs/2506.13717v1", "categories": ["cs.LG", "cs.AI", "q-bio.NC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "TimeMaster: Training Time-Series Multimodal LLMs to Reason via Reinforcement Learning", "abstract": "Time-series reasoning remains a significant challenge in multimodal large\nlanguage models (MLLMs) due to the dynamic temporal patterns, ambiguous\nsemantics, and lack of temporal priors. In this work, we introduce TimeMaster,\na reinforcement learning (RL)-based method that enables time-series MLLMs to\nperform structured, interpretable reasoning directly over visualized\ntime-series inputs and task prompts. TimeMaster adopts a three-part structured\noutput format, reasoning, classification, and domain-specific extension, and is\noptimized via a composite reward function that aligns format adherence,\nprediction accuracy, and open-ended insight quality. The model is trained using\na two-stage pipeline: we first apply supervised fine-tuning (SFT) to establish\na good initialization, followed by Group Relative Policy Optimization (GRPO) at\nthe token level to enable stable and targeted reward-driven improvement in\ntime-series reasoning. We evaluate TimeMaster on the TimerBed benchmark across\nsix real-world classification tasks based on Qwen2.5-VL-3B-Instruct. TimeMaster\nachieves state-of-the-art performance, outperforming both classical time-series\nmodels and few-shot GPT-4o by over 14.6% and 7.3% performance gain,\nrespectively. Notably, TimeMaster goes beyond time-series classification: it\nalso exhibits expert-like reasoning behavior, generates context-aware\nexplanations, and delivers domain-aligned insights. Our results highlight that\nreward-driven RL can be a scalable and promising path toward integrating\ntemporal understanding into time-series MLLMs.", "published": "2025-06-16 17:12:26", "link": "http://arxiv.org/abs/2506.13705v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Value-Free Policy Optimization via Reward Partitioning", "abstract": "Single-trajectory reinforcement learning (RL) methods aim to optimize\npolicies from datasets consisting of (prompt, response, reward) triplets, where\nscalar rewards are directly available. This supervision format is highly\npractical, as it mirrors real-world human feedback, such as thumbs-up/down\nsignals, and avoids the need for structured preference annotations. In\ncontrast, pairwise preference-based methods like Direct Preference Optimization\n(DPO) rely on datasets with both preferred and dispreferred responses, which\nare harder to construct and less natural to collect. Among single-trajectory\napproaches, Direct Reward Optimization (DRO) has shown strong empirical\nperformance due to its simplicity and stability. However, DRO requires\napproximating a value function, which introduces several limitations: high\noff-policy variance, coupling between policy and value learning, and a lack of\nabsolute supervision on the policy itself. We introduce Reward Partitioning\nOptimization (RPO), a new method that resolves these limitations by removing\nthe need to model the value function. Instead, RPO normalizes observed rewards\nusing a partitioning approach estimated directly from data. This leads to a\nstraightforward supervised learning objective on the policy, with no auxiliary\nmodels and no joint optimization. RPO provides direct and stable supervision on\nthe policy, making it robust and easy to implement in practice. We validate RPO\non scalar-feedback language modeling tasks using Flan-T5 encoder-decoder\nmodels. Our results demonstrate that RPO outperforms existing single-trajectory\nbaselines such as DRO and Kahneman-Tversky Optimization (KTO). These findings\nconfirm that RPO is a simple, effective, and theoretically grounded method for\nsingle-trajectory policy optimization.", "published": "2025-06-16 17:06:27", "link": "http://arxiv.org/abs/2506.13702v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Meta-learning how to Share Credit among Macro-Actions", "abstract": "One proposed mechanism to improve exploration in reinforcement learning is\nthrough the use of macro-actions. Paradoxically though, in many scenarios the\nnaive addition of macro-actions does not lead to better exploration, but rather\nthe opposite. It has been argued that this was caused by adding non-useful\nmacros and multiple works have focused on mechanisms to discover effectively\nenvironment-specific useful macros. In this work, we take a slightly different\nperspective. We argue that the difficulty stems from the trade-offs between\nreducing the average number of decisions per episode versus increasing the size\nof the action space. Namely, one typically treats each potential macro-action\nas independent and atomic, hence strictly increasing the search space and\nmaking typical exploration strategies inefficient. To address this problem we\npropose a novel regularization term that exploits the relationship between\nactions and macro-actions to improve the credit assignment mechanism by\nreducing the effective dimension of the action space and, therefore, improving\nexploration. The term relies on a similarity matrix that is meta-learned\njointly with learning the desired policy. We empirically validate our strategy\nlooking at macro-actions in Atari games, and the StreetFighter II environment.\nOur results show significant improvements over the Rainbow-DQN baseline in all\nenvironments. Additionally, we show that the macro-action similarity is\ntransferable to related environments. We believe this work is a small but\nimportant step towards understanding how the similarity-imposed geometry on the\naction space can be exploited to improve credit assignment and exploration,\ntherefore making learning more effective.", "published": "2025-06-16 16:52:49", "link": "http://arxiv.org/abs/2506.13690v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "ROSA: Harnessing Robot States for Vision-Language and Action Alignment", "abstract": "Vision-Language-Action (VLA) models have recently made significant advance in\nmulti-task, end-to-end robotic control, due to the strong generalization\ncapabilities of Vision-Language Models (VLMs). A fundamental challenge in\ndeveloping such models is effectively aligning the vision-language space with\nthe robotic action space. Existing approaches typically rely on directly\nfine-tuning VLMs using expert demonstrations. However, this strategy suffers\nfrom a spatio-temporal gap, resulting in considerable data inefficiency and\nheavy reliance on human labor. Spatially, VLMs operate within a high-level\nsemantic space, whereas robotic actions are grounded in low-level 3D physical\nspace; temporally, VLMs primarily interpret the present, while VLA models\nanticipate future actions. To overcome these challenges, we propose a novel\ntraining paradigm, ROSA, which leverages robot state estimation to improve\nalignment between vision-language and action spaces. By integrating robot state\nestimation data obtained via an automated process, ROSA enables the VLA model\nto gain enhanced spatial understanding and self-awareness, thereby boosting\nperformance and generalization. Extensive experiments in both simulated and\nreal-world environments demonstrate the effectiveness of ROSA, particularly in\nlow-data regimes.", "published": "2025-06-16 16:34:20", "link": "http://arxiv.org/abs/2506.13679v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "abstract": "The development of large language models (LLMs) has entered in a\nexperience-driven era, flagged by the emergence of environment feedback-driven\nlearning via reinforcement learning and tool-using agents. This encourages the\nemergenece of model context protocol (MCP), which defines the standard on how\nshould a LLM interact with external services, such as \\api and data. However,\nas MCP becomes the de facto standard for LLM agent systems, it also introduces\nnew safety risks. In particular, MCP introduces third-party services, which are\nnot controlled by the LLM developers, into the agent systems. These third-party\nMCP services provider are potentially malicious and have the economic\nincentives to exploit vulnerabilities and sabotage user-agent interactions. In\nthis position paper, we advocate the research community in LLM safety to pay\nclose attention to the new safety risks issues introduced by MCP, and develop\nnew techniques to build safe MCP-powered agent systems. To establish our\nposition, we argue with three key parts. (1) We first construct \\framework, a\ncontrolled framework to examine safety issues in MCP-powered agent systems. (2)\nWe then conduct a series of pilot experiments to demonstrate the safety risks\nin MCP-powered agent systems is a real threat and its defense is not trivial.\n(3) Finally, we give our outlook by showing a roadmap to build safe MCP-powered\nagent systems. In particular, we would call for researchers to persue the\nfollowing research directions: red teaming, MCP safe LLM development, MCP\nsafety evaluation, MCP safety data accumulation, MCP service safeguard, and MCP\nsafe ecosystem construction. We hope this position paper can raise the\nawareness of the research community in MCP safety and encourage more\nresearchers to join this important research direction. Our code is available at\nhttps://github.com/littlelittlenine/SafeMCP.git.", "published": "2025-06-16 16:24:31", "link": "http://arxiv.org/abs/2506.13666v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Ego-R1: Chain-of-Tool-Thought for Ultra-Long Egocentric Video Reasoning", "abstract": "We introduce Ego-R1, a novel framework for reasoning over ultra-long (i.e.,\nin days and weeks) egocentric videos, which leverages a structured\nChain-of-Tool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained\nvia reinforcement learning (RL). Inspired by human problem-solving strategies,\nCoTT decomposes complex reasoning into modular steps, with the RL agent\ninvoking specific tools, one per step, to iteratively and collaboratively\nanswer sub-questions tackling such tasks as temporal retrieval and multi-modal\nunderstanding. We design a two-stage training paradigm involving supervised\nfinetuning (SFT) of a pretrained language model using CoTT data and RL to\nenable our agent to dynamically propose step-by-step tools for long-range\nreasoning. To facilitate training, we construct a dataset called Ego-R1 Data,\nwhich consists of Ego-CoTT-25K for SFT and Ego-QA-4.4K for RL. Furthermore, our\nEgo-R1 agent is evaluated on a newly curated week-long video QA benchmark,\nEgo-R1 Bench, which contains human-verified QA pairs from hybrid sources.\nExtensive results demonstrate that the dynamic, tool-augmented chain-of-thought\nreasoning by our Ego-R1 Agent can effectively tackle the unique challenges of\nunderstanding ultra-long egocentric videos, significantly extending the time\ncoverage from few hours to a week.", "published": "2025-06-16 16:17:08", "link": "http://arxiv.org/abs/2506.13654v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "DualEdit: Dual Editing for Knowledge Updating in Vision-Language Models", "abstract": "Model editing aims to efficiently update a pre-trained model's knowledge\nwithout the need for time-consuming full retraining. While existing pioneering\nediting methods achieve promising results, they primarily focus on editing\nsingle-modal language models (LLMs). However, for vision-language models\n(VLMs), which involve multiple modalities, the role and impact of each modality\non editing performance remain largely unexplored. To address this gap, we\nexplore the impact of textual and visual modalities on model editing and find\nthat: (1) textual and visual representations reach peak sensitivity at\ndifferent layers, reflecting their varying importance; and (2) editing both\nmodalities can efficiently update knowledge, but this comes at the cost of\ncompromising the model's original capabilities. Based on our findings, we\npropose DualEdit, an editor that modifies both textual and visual modalities at\ntheir respective key layers. Additionally, we introduce a gating module within\nthe more sensitive textual modality, allowing DualEdit to efficiently update\nnew knowledge while preserving the model's original information. We evaluate\nDualEdit across multiple VLM backbones and benchmark datasets, demonstrating\nits superiority over state-of-the-art VLM editing baselines as well as adapted\nLLM editing methods on different evaluation metrics.", "published": "2025-06-16 16:04:16", "link": "http://arxiv.org/abs/2506.13638v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Graph-Convolution-Beta-VAE for Synthetic Abdominal Aorta Aneurysm Generation", "abstract": "Synthetic data generation plays a crucial role in medical research by\nmitigating privacy concerns and enabling large-scale patient data analysis.\nThis study presents a beta-Variational Autoencoder Graph Convolutional Neural\nNetwork framework for generating synthetic Abdominal Aorta Aneurysms (AAA).\nUsing a small real-world dataset, our approach extracts key anatomical features\nand captures complex statistical relationships within a compact disentangled\nlatent space. To address data limitations, low-impact data augmentation based\non Procrustes analysis was employed, preserving anatomical integrity. The\ngeneration strategies, both deterministic and stochastic, manage to enhance\ndata diversity while ensuring realism. Compared to PCA-based approaches, our\nmodel performs more robustly on unseen data by capturing complex, nonlinear\nanatomical variations. This enables more comprehensive clinical and statistical\nanalyses than the original dataset alone. The resulting synthetic AAA dataset\npreserves patient privacy while providing a scalable foundation for medical\nresearch, device testing, and computational modeling.", "published": "2025-06-16 15:55:56", "link": "http://arxiv.org/abs/2506.13628v1", "categories": ["cs.LG", "cs.AI", "q-bio.TO"], "primary_category": "cs.LG"}
{"title": "EBS-CFL: Efficient and Byzantine-robust Secure Clustered Federated Learning", "abstract": "Despite federated learning (FL)'s potential in collaborative learning, its\nperformance has deteriorated due to the data heterogeneity of distributed\nusers. Recently, clustered federated learning (CFL) has emerged to address this\nchallenge by partitioning users into clusters according to their similarity.\nHowever, CFL faces difficulties in training when users are unwilling to share\ntheir cluster identities due to privacy concerns. To address these issues, we\npresent an innovative Efficient and Robust Secure Aggregation scheme for CFL,\ndubbed EBS-CFL. The proposed EBS-CFL supports effectively training CFL while\nmaintaining users' cluster identity confidentially. Moreover, it detects\npotential poisonous attacks without compromising individual client gradients by\ndiscarding negatively correlated gradients and aggregating positively\ncorrelated ones using a weighted approach. The server also authenticates\ncorrect gradient encoding by clients. EBS-CFL has high efficiency with\nclient-side overhead O(ml + m^2) for communication and O(m^2l) for computation,\nwhere m is the number of cluster identities, and l is the gradient size. When m\n= 1, EBS-CFL's computational efficiency of client is at least O(log n) times\nbetter than comparison schemes, where n is the number of clients.In addition,\nwe validate the scheme through extensive experiments. Finally, we theoretically\nprove the scheme's security.", "published": "2025-06-16 15:39:10", "link": "http://arxiv.org/abs/2506.13612v1", "categories": ["cs.CR", "cs.AI", "cs.DC"], "primary_category": "cs.CR"}
{"title": "A Hybrid Artificial Intelligence Method for Estimating Flicker in Power Systems", "abstract": "This paper introduces a novel hybrid AI method combining H filtering and an\nadaptive linear neuron network for flicker component estimation in power\ndistribution systems.The proposed method leverages the robustness of the H\nfilter to extract the voltage envelope under uncertain and noisy conditions\nfollowed by the use of ADALINE to accurately identify flicker frequencies\nembedded in the envelope.This synergy enables efficient time domain estimation\nwith rapid convergence and noise resilience addressing key limitations of\nexisting frequency domain approaches.Unlike conventional techniques this hybrid\nAI model handles complex power disturbances without prior knowledge of noise\ncharacteristics or extensive training.To validate the method performance we\nconduct simulation studies based on IEC Standard 61000 4 15 supported by\nstatistical analysis Monte Carlo simulations and real world data.Results\ndemonstrate superior accuracy robustness and reduced computational load\ncompared to Fast Fourier Transform and Discrete Wavelet Transform based\nestimators.", "published": "2025-06-16 15:38:39", "link": "http://arxiv.org/abs/2506.13611v1", "categories": ["eess.SY", "cs.AI", "cs.SY", "stat.AP"], "primary_category": "eess.SY"}
{"title": "Avoiding Obfuscation with Prover-Estimator Debate", "abstract": "Training powerful AI systems to exhibit desired behaviors hinges on the\nability to provide accurate human supervision on increasingly complex tasks. A\npromising approach to this problem is to amplify human judgement by leveraging\nthe power of two competing AIs in a debate about the correct solution to a\ngiven problem. Prior theoretical work has provided a complexity-theoretic\nformalization of AI debate, and posed the problem of designing protocols for AI\ndebate that guarantee the correctness of human judgements for as complex a\nclass of problems as possible. Recursive debates, in which debaters decompose a\ncomplex problem into simpler subproblems, hold promise for growing the class of\nproblems that can be accurately judged in a debate. However, existing protocols\nfor recursive debate run into the obfuscated arguments problem: a dishonest\ndebater can use a computationally efficient strategy that forces an honest\nopponent to solve a computationally intractable problem to win. We mitigate\nthis problem with a new recursive debate protocol that, under certain stability\nassumptions, ensures that an honest debater can win with a strategy requiring\ncomputational efficiency comparable to their opponent.", "published": "2025-06-16 15:37:33", "link": "http://arxiv.org/abs/2506.13609v1", "categories": ["cs.AI", "cs.CC", "cs.DS"], "primary_category": "cs.AI"}
{"title": "The ASP-based Nurse Scheduling System at the University of Yamanashi Hospital", "abstract": "We present the design principles of a nurse scheduling system built using\nAnswer Set Programming (ASP) and successfully deployed at the University of\nYamanashi Hospital. Nurse scheduling is a complex optimization problem\nrequiring the reconciliation of individual nurse preferences with hospital\nstaffing needs across various wards. This involves balancing hard and soft\nconstraints and the flexibility of interactive adjustments. While extensively\nstudied in academia, real-world nurse scheduling presents unique challenges\nthat go beyond typical benchmark problems and competitions. This paper details\nthe practical application of ASP to address these challenges at the University\nof Yamanashi Hospital, focusing on the insights gained and the advancements in\nASP technology necessary to effectively manage the complexities of real-world\ndeployment.", "published": "2025-06-16 15:25:06", "link": "http://arxiv.org/abs/2506.13600v1", "categories": ["cs.AI", "68T30"], "primary_category": "cs.AI"}
{"title": "Agent Capability Negotiation and Binding Protocol (ACNBP)", "abstract": "As multi-agent systems evolve to encompass increasingly diverse and\nspecialized agents, the challenge of enabling effective collaboration between\nheterogeneous agents has become paramount, with traditional agent communication\nprotocols often assuming homogeneous environments or predefined interaction\npatterns that limit their applicability in dynamic, open-world scenarios. This\npaper presents the Agent Capability Negotiation and Binding Protocol (ACNBP), a\nnovel framework designed to facilitate secure, efficient, and verifiable\ninteractions between agents in heterogeneous multi-agent systems through\nintegration with an Agent Name Service (ANS) infrastructure that provides\ncomprehensive discovery, negotiation, and binding mechanisms. The protocol\nintroduces a structured 10-step process encompassing capability discovery,\ncandidate pre-screening and selection, secure negotiation phases, and binding\ncommitment with built-in security measures including digital signatures,\ncapability attestation, and comprehensive threat mitigation strategies, while a\nkey innovation of ACNBP is its protocolExtension mechanism that enables\nbackward-compatible protocol evolution and supports diverse agent architectures\nwhile maintaining security and interoperability. We demonstrate ACNBP's\neffectiveness through a comprehensive security analysis using the MAESTRO\nthreat modeling framework, practical implementation considerations, and a\ndetailed example showcasing the protocol's application in a document\ntranslation scenario, with the protocol addressing critical challenges in agent\nautonomy, capability verification, secure communication, and scalable agent\necosystem management.", "published": "2025-06-16 15:18:24", "link": "http://arxiv.org/abs/2506.13590v1", "categories": ["cs.AI", "cs.CR", "cs.MA"], "primary_category": "cs.AI"}
{"title": "From Data-Driven to Purpose-Driven Artificial Intelligence: Systems Thinking for Data-Analytic Automation of Patient Care", "abstract": "In this work, we reflect on the data-driven modeling paradigm that is gaining\nground in AI-driven automation of patient care. We argue that the repurposing\nof existing real-world patient datasets for machine learning may not always\nrepresent an optimal approach to model development as it could lead to\nundesirable outcomes in patient care. We reflect on the history of data\nanalysis to explain how the data-driven paradigm rose to popularity, and we\nenvision ways in which systems thinking and clinical domain theory could\ncomplement the existing model development approaches in reaching human-centric\noutcomes. We call for a purpose-driven machine learning paradigm that is\ngrounded in clinical theory and the sociotechnical realities of real-world\noperational contexts. We argue that understanding the utility of existing\npatient datasets requires looking in two directions: upstream towards the data\ngeneration, and downstream towards the automation objectives. This\npurpose-driven perspective to AI system development opens up new methodological\nopportunities and holds promise for AI automation of patient care.", "published": "2025-06-16 15:07:44", "link": "http://arxiv.org/abs/2506.13584v1", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "math.ST", "stat.ME", "stat.TH"], "primary_category": "cs.AI"}
{"title": "Can you see how I learn? Human observers' inferences about Reinforcement Learning agents' learning processes", "abstract": "Reinforcement Learning (RL) agents often exhibit learning behaviors that are\nnot intuitively interpretable by human observers, which can result in\nsuboptimal feedback in collaborative teaching settings. Yet, how humans\nperceive and interpret RL agent's learning behavior is largely unknown. In a\nbottom-up approach with two experiments, this work provides a data-driven\nunderstanding of the factors of human observers' understanding of the agent's\nlearning process. A novel, observation-based paradigm to directly assess human\ninferences about agent learning was developed. In an exploratory interview\nstudy (\\textit{N}=9), we identify four core themes in human interpretations:\nAgent Goals, Knowledge, Decision Making, and Learning Mechanisms. A second\nconfirmatory study (\\textit{N}=34) applied an expanded version of the paradigm\nacross two tasks (navigation/manipulation) and two RL algorithms\n(tabular/function approximation). Analyses of 816 responses confirmed the\nreliability of the paradigm and refined the thematic framework, revealing how\nthese themes evolve over time and interrelate. Our findings provide a\nhuman-centered understanding of how people make sense of agent learning,\noffering actionable insights for designing interpretable RL systems and\nimproving transparency in Human-Robot Interaction.", "published": "2025-06-16 15:04:27", "link": "http://arxiv.org/abs/2506.13583v1", "categories": ["cs.HC", "cs.AI", "cs.RO"], "primary_category": "cs.HC"}
{"title": "A Production Scheduling Framework for Reinforcement Learning Under Real-World Constraints", "abstract": "The classical Job Shop Scheduling Problem (JSSP) focuses on optimizing\nmakespan under deterministic constraints. Real-world production environments\nintroduce additional complexities that cause traditional scheduling approaches\nto be less effective. Reinforcement learning (RL) holds potential in addressing\nthese challenges, as it allows agents to learn adaptive scheduling strategies.\nHowever, there is a lack of a comprehensive, general-purpose frameworks for\neffectively training and evaluating RL agents under real-world constraints. To\naddress this gap, we propose a modular framework that extends classical JSSP\nformulations by incorporating key \\mbox{real-world} constraints inherent to the\nshopfloor, including transport logistics, buffer management, machine\nbreakdowns, setup times, and stochastic processing conditions, while also\nsupporting multi-objective optimization. The framework is a customizable\nsolution that offers flexibility in defining problem instances and configuring\nsimulation parameters, enabling adaptation to diverse production scenarios. A\nstandardized interface ensures compatibility with various RL approaches,\nproviding a robust environment for training RL agents and facilitating the\nstandardized comparison of different scheduling methods under dynamic and\nuncertain conditions. We release JobShopLab as an open-source tool for both\nresearch and industrial applications, accessible at:\nhttps://github.com/proto-lab-ro/jobshoplab", "published": "2025-06-16 14:50:26", "link": "http://arxiv.org/abs/2506.13566v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Seismic Acoustic Impedance Inversion Framework Based on Conditional Latent Generative Diffusion Model", "abstract": "Seismic acoustic impedance plays a crucial role in lithological\nidentification and subsurface structure interpretation. However, due to the\ninherently ill-posed nature of the inversion problem, directly estimating\nimpedance from post-stack seismic data remains highly challenging. Recently,\ndiffusion models have shown great potential in addressing such inverse problems\ndue to their strong prior learning and generative capabilities. Nevertheless,\nmost existing methods operate in the pixel domain and require multiple\niterations, limiting their applicability to field data. To alleviate these\nlimitations, we propose a novel seismic acoustic impedance inversion framework\nbased on a conditional latent generative diffusion model, where the inversion\nprocess is made in latent space. To avoid introducing additional training\noverhead when embedding conditional inputs, we design a lightweight\nwavelet-based module into the framework to project seismic data and reuse an\nencoder trained on impedance to embed low-frequency impedance into the latent\nspace. Furthermore, we propose a model-driven sampling strategy during the\ninversion process of this framework to enhance accuracy and reduce the number\nof required diffusion steps. Numerical experiments on a synthetic model\ndemonstrate that the proposed method achieves high inversion accuracy and\nstrong generalization capability within only a few diffusion steps. Moreover,\napplication to field data reveals enhanced geological detail and higher\nconsistency with well-log measurements, validating the effectiveness and\npracticality of the proposed approach.", "published": "2025-06-16 14:19:40", "link": "http://arxiv.org/abs/2506.13529v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "The Price of Freedom: Exploring Expressivity and Runtime Tradeoffs in Equivariant Tensor Products", "abstract": "$E(3)$-equivariant neural networks have demonstrated success across a wide\nrange of 3D modelling tasks. A fundamental operation in these networks is the\ntensor product, which interacts two geometric features in an equivariant manner\nto create new features. Due to the high computational complexity of the tensor\nproduct, significant effort has been invested to optimize the runtime of this\noperation. For example, Luo et al. (2024) recently proposed the Gaunt tensor\nproduct (GTP) which promises a significant speedup. In this work, we provide a\ncareful, systematic analysis of a number of tensor product operations. In\nparticular, we emphasize that different tensor products are not performing the\nsame operation. The reported speedups typically come at the cost of\nexpressivity. We introduce measures of expressivity and interactability to\ncharacterize these differences. In addition, we realized the original\nimplementation of GTP can be greatly simplified by directly using a spherical\ngrid at no cost in asymptotic runtime. This spherical grid approach is faster\non our benchmarks and in actual training of the MACE interatomic potential by\n30\\%. Finally, we provide the first systematic microbenchmarks of the various\ntensor product operations. We find that the theoretical runtime guarantees can\ndiffer wildly from empirical performance, demonstrating the need for careful\napplication-specific benchmarking. Code is available at\n\\href{https://github.com/atomicarchitects/PriceofFreedom}{https://github.com/atomicarchitects/PriceofFreedom}", "published": "2025-06-16 14:15:18", "link": "http://arxiv.org/abs/2506.13523v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "UAV Object Detection and Positioning in a Mining Industrial Metaverse with Custom Geo-Referenced Data", "abstract": "The mining sector increasingly adopts digital tools to improve operational\nefficiency, safety, and data-driven decision-making. One of the key challenges\nremains the reliable acquisition of high-resolution, geo-referenced spatial\ninformation to support core activities such as extraction planning and on-site\nmonitoring. This work presents an integrated system architecture that combines\nUAV-based sensing, LiDAR terrain modeling, and deep learning-based object\ndetection to generate spatially accurate information for open-pit mining\nenvironments. The proposed pipeline includes geo-referencing, 3D\nreconstruction, and object localization, enabling structured spatial outputs to\nbe integrated into an industrial digital twin platform. Unlike traditional\nstatic surveying methods, the system offers higher coverage and automation\npotential, with modular components suitable for deployment in real-world\nindustrial contexts. While the current implementation operates in post-flight\nbatch mode, it lays the foundation for real-time extensions. The system\ncontributes to the development of AI-enhanced remote sensing in mining by\ndemonstrating a scalable and field-validated geospatial data workflow that\nsupports situational awareness and infrastructure safety.", "published": "2025-06-16 13:59:56", "link": "http://arxiv.org/abs/2506.13505v1", "categories": ["eess.IV", "cs.AI", "cs.ET", "cs.RO"], "primary_category": "eess.IV"}
{"title": "ESRPCB: an Edge guided Super-Resolution model and Ensemble learning for tiny Printed Circuit Board Defect detection", "abstract": "Printed Circuit Boards (PCBs) are critical components in modern electronics,\nwhich require stringent quality control to ensure proper functionality.\nHowever, the detection of defects in small-scale PCBs images poses significant\nchallenges as a result of the low resolution of the captured images, leading to\npotential confusion between defects and noise. To overcome these challenges,\nthis paper proposes a novel framework, named ESRPCB (edgeguided\nsuper-resolution for PCBs defect detection), which combines edgeguided\nsuper-resolution with ensemble learning to enhance PCBs defect detection. The\nframework leverages the edge information to guide the EDSR (Enhanced Deep\nSuper-Resolution) model with a novel ResCat (Residual Concatenation) structure,\nenabling it to reconstruct high-resolution images from small PCBs inputs. By\nincorporating edge features, the super-resolution process preserves critical\nstructural details, ensuring that tiny defects remain distinguishable in the\nenhanced image. Following this, a multi-modal defect detection model employs\nensemble learning to analyze the super-resolved", "published": "2025-06-16 13:34:35", "link": "http://arxiv.org/abs/2506.13476v1", "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "cs.CV"}
{"title": "A Two-stage Optimization Method for Wide-range Single-electron Quantum Magnetic Sensing", "abstract": "Quantum magnetic sensing based on spin systems has emerged as a new paradigm\nfor detecting ultra-weak magnetic fields with unprecedented sensitivity,\nrevitalizing applications in navigation, geo-localization, biology, and beyond.\nAt the heart of quantum magnetic sensing, from the protocol perspective, lies\nthe design of optimal sensing parameters to manifest and then estimate the\nunderlying signals of interest (SoI). Existing studies on this front mainly\nrely on adaptive algorithms based on black-box AI models or formula-driven\nprincipled searches. However, when the SoI spans a wide range and the quantum\nsensor has physical constraints, these methods may fail to converge efficiently\nor optimally, resulting in prolonged interrogation times and reduced sensing\naccuracy. In this work, we report the design of a new protocol using a\ntwo-stage optimization method. In the 1st Stage, a Bayesian neural network with\na fixed set of sensing parameters is used to narrow the range of SoI. In the\n2nd Stage, a federated reinforcement learning agent is designed to fine-tune\nthe sensing parameters within a reduced search space. The proposed protocol is\ndeveloped and evaluated in a challenging context of single-shot readout of an\nNV-center electron spin under a constrained total sensing time budget; and yet\nit achieves significant improvements in both accuracy and resource efficiency\nfor wide-range D.C. magnetic field estimation compared to the state of the art.", "published": "2025-06-16 13:28:32", "link": "http://arxiv.org/abs/2506.13469v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "Block-wise Adaptive Caching for Accelerating Diffusion Policy", "abstract": "Diffusion Policy has demonstrated strong visuomotor modeling capabilities,\nbut its high computational cost renders it impractical for real-time robotic\ncontrol. Despite huge redundancy across repetitive denoising steps, existing\ndiffusion acceleration techniques fail to generalize to Diffusion Policy due to\nfundamental architectural and data divergences. In this paper, we propose\nBlock-wise Adaptive Caching(BAC), a method to accelerate Diffusion Policy by\ncaching intermediate action features. BAC achieves lossless action generation\nacceleration by adaptively updating and reusing cached features at the block\nlevel, based on a key observation that feature similarities vary non-uniformly\nacross timesteps and locks. To operationalize this insight, we first propose\nthe Adaptive Caching Scheduler, designed to identify optimal update timesteps\nby maximizing the global feature similarities between cached and skipped\nfeatures. However, applying this scheduler for each block leads to signiffcant\nerror surges due to the inter-block propagation of caching errors, particularly\nwithin Feed-Forward Network (FFN) blocks. To mitigate this issue, we develop\nthe Bubbling Union Algorithm, which truncates these errors by updating the\nupstream blocks with signiffcant caching errors before downstream FFNs. As a\ntraining-free plugin, BAC is readily integrable with existing transformer-based\nDiffusion Policy and vision-language-action models. Extensive experiments on\nmultiple robotic benchmarks demonstrate that BAC achieves up to 3x inference\nspeedup for free.", "published": "2025-06-16 13:14:58", "link": "http://arxiv.org/abs/2506.13456v1", "categories": ["cs.AI", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Towards a Formal Specification for Self-organized Shape Formation in Swarm Robotics", "abstract": "The self-organization of robots for the formation of structures and shapes is\na stimulating application of the swarm robotic system. It involves a large\nnumber of autonomous robots of heterogeneous behavior, coordination among them,\nand their interaction with the dynamic environment. This process of complex\nstructure formation is considered a complex system, which needs to be modeled\nby using any modeling approach. Although the formal specification approach\nalong with other formal methods has been used to model the behavior of robots\nin a swarm. However, to the best of our knowledge, the formal specification\napproach has not been used to model the self-organization process in swarm\nrobotic systems for shape formation. In this paper, we use a formal\nspecification approach to model the shape formation task of swarm robots. We\nuse Z (Zed) language of formal specification, which is a state-based language,\nto model the states of the entities of the systems. We demonstrate the\neffectiveness of Z for the self-organized shape formation. The presented formal\nspecification model gives the outlines for designing and implementing the swarm\nrobotic system for the formation of complex shapes and structures. It also\nprovides the foundation for modeling the complex shape formation process for\nswarm robotics using a multi-agent system in a simulation-based environment.\nKeywords: Swarm robotics, Self-organization, Formal specification, Complex\nsystems", "published": "2025-06-16 13:13:20", "link": "http://arxiv.org/abs/2506.13453v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Simple is what you need for efficient and accurate medical image segmentation", "abstract": "While modern segmentation models often prioritize performance over\npracticality, we advocate a design philosophy prioritizing simplicity and\nefficiency, and attempted high performance segmentation model design. This\npaper presents SimpleUNet, a scalable ultra-lightweight medical image\nsegmentation model with three key innovations: (1) A partial feature selection\nmechanism in skip connections for redundancy reduction while enhancing\nsegmentation performance; (2) A fixed-width architecture that prevents\nexponential parameter growth across network stages; (3) An adaptive feature\nfusion module achieving enhanced representation with minimal computational\noverhead. With a record-breaking 16 KB parameter configuration, SimpleUNet\noutperforms LBUNet and other lightweight benchmarks across multiple public\ndatasets. The 0.67 MB variant achieves superior efficiency (8.60 GFLOPs) and\naccuracy, attaining a mean DSC/IoU of 85.76%/75.60% on multi-center breast\nlesion datasets, surpassing both U-Net and TransUNet. Evaluations on skin\nlesion datasets (ISIC 2017/2018: mDice 84.86%/88.77%) and endoscopic polyp\nsegmentation (KVASIR-SEG: 86.46%/76.48% mDice/mIoU) confirm consistent\ndominance over state-of-the-art models. This work demonstrates that extreme\nmodel compression need not compromise performance, providing new insights for\nefficient and accurate medical image segmentation. Codes can be found at\nhttps://github.com/Frankyu5666666/SimpleUNet.", "published": "2025-06-16 12:31:48", "link": "http://arxiv.org/abs/2506.13415v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "I.4.6"], "primary_category": "eess.IV"}
{"title": "CALM: Consensus-Aware Localized Merging for Multi-Task Learning", "abstract": "Model merging aims to integrate the strengths of multiple fine-tuned models\ninto a unified model while preserving task-specific capabilities. Existing\nmethods, represented by task arithmetic, are typically classified into global-\nand local-aware methods. However, global-aware methods inevitably cause\nparameter interference, while local-aware methods struggle to maintain the\neffectiveness of task-specific details in the merged model. To address these\nlimitations, we propose a Consensus-Aware Localized Merging (CALM) method which\nincorporates localized information aligned with global task consensus, ensuring\nits effectiveness post-merging. CALM consists of three key components: (1)\nclass-balanced entropy minimization sampling, providing a more flexible and\nreliable way to leverage unsupervised data; (2) an efficient-aware framework,\nselecting a small set of tasks for sequential merging with high scalability;\n(3) a consensus-aware mask optimization, aligning localized binary masks with\nglobal task consensus and merging them conflict-free. Experiments demonstrate\nthe superiority and robustness of our CALM, significantly outperforming\nexisting methods and achieving performance close to traditional MTL.", "published": "2025-06-16 12:19:45", "link": "http://arxiv.org/abs/2506.13406v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Technical Study into Small Reasoning Language Models", "abstract": "The ongoing evolution of language models has led to the development of\nlarge-scale architectures that demonstrate exceptional performance across a\nwide range of tasks. However, these models come with significant computational\nand energy demands, as well as potential privacy implications. In this context,\nSmall Reasoning Language Models (SRLMs) with approximately 0.5 billion\nparameters present a compelling alternative due to their remarkable\ncomputational efficiency and cost effectiveness, particularly in\nresource-constrained environments. Despite these advantages, the limited\ncapacity of 0.5 billion parameter models poses challenges in handling complex\ntasks such as mathematical reasoning and code generation. This research\ninvestigates various training strategies, including supervised fine-tuning\n(SFT), knowledge distillation (KD), and reinforcement learning (RL), as well as\ntheir hybrid implementations, to enhance the performance of 0.5B SRLMs. We\nanalyze effective methodologies to bridge the performance gap between SRLMS and\nlarger models and present insights into optimal training pipelines tailored for\nthese smaller architectures. Through extensive experimental validation and\nanalysis, our work aims to provide actionable recommendations for maximizing\nthe reasoning capabilities of 0.5B models.", "published": "2025-06-16 12:18:11", "link": "http://arxiv.org/abs/2506.13404v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Deflating Deflationism: A Critical Perspective on Debunking Arguments Against LLM Mentality", "abstract": "Many people feel compelled to interpret, describe, and respond to Large\nLanguage Models (LLMs) as if they possess inner mental lives similar to our\nown. Responses to this phenomenon have varied. Inflationists hold that at least\nsome folk psychological ascriptions to LLMs are warranted. Deflationists argue\nthat all such attributions of mentality to LLMs are misplaced, often cautioning\nagainst the risk that anthropomorphic projection may lead to misplaced trust or\npotentially even confusion about the moral status of LLMs. We advance this\ndebate by assessing two common deflationary arguments against LLM mentality.\nWhat we term the 'robustness strategy' aims to undercut one justification for\nbelieving that LLMs are minded entities by showing that putatively cognitive\nand humanlike behaviours are not robust, failing to generalise appropriately.\nWhat we term the 'etiological strategy' undercuts attributions of mentality by\nchallenging naive causal explanations of LLM behaviours, offering alternative\ncausal accounts that weaken the case for mental state attributions. While both\nstrategies offer powerful challenges to full-blown inflationism, we find that\nneither strategy provides a knock-down case against ascriptions of mentality to\nLLMs simpliciter. With this in mind, we explore a modest form of inflationism\nthat permits ascriptions of mentality to LLMs under certain conditions.\nSpecifically, we argue that folk practice provides a defeasible basis for\nattributing mental states and capacities to LLMs provided those mental states\nand capacities can be understood in metaphysically undemanding terms (e.g.\nknowledge, beliefs and desires), while greater caution is required when\nattributing metaphysically demanding mental phenomena such as phenomenal\nconsciousness.", "published": "2025-06-16 12:17:11", "link": "http://arxiv.org/abs/2506.13403v1", "categories": ["cs.AI", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Delving Into the Psychology of Machines: Exploring the Structure of Self-Regulated Learning via LLM-Generated Survey Responses", "abstract": "Large language models (LLMs) offer the potential to simulate human-like\nresponses and behaviors, creating new opportunities for psychological science.\nIn the context of self-regulated learning (SRL), if LLMs can reliably simulate\nsurvey responses at scale and speed, they could be used to test intervention\nscenarios, refine theoretical models, augment sparse datasets, and represent\nhard-to-reach populations. However, the validity of LLM-generated survey\nresponses remains uncertain, with limited research focused on SRL and existing\nstudies beyond SRL yielding mixed results. Therefore, in this study, we\nexamined LLM-generated responses to the 44-item Motivated Strategies for\nLearning Questionnaire (MSLQ; Pintrich \\& De Groot, 1990), a widely used\ninstrument assessing students' learning strategies and academic motivation.\nParticularly, we used the LLMs GPT-4o, Claude 3.7 Sonnet, Gemini 2 Flash, LLaMA\n3.1-8B, and Mistral Large. We analyzed item distributions, the psychological\nnetwork of the theoretical SRL dimensions, and psychometric validity based on\nthe latent factor structure. Our results suggest that Gemini 2 Flash was the\nmost promising LLM, showing considerable sampling variability and producing\nunderlying dimensions and theoretical relationships that align with prior\ntheory and empirical findings. At the same time, we observed discrepancies and\nlimitations, underscoring both the potential and current constraints of using\nLLMs for simulating psychological survey data and applying it in educational\ncontexts.", "published": "2025-06-16 11:48:58", "link": "http://arxiv.org/abs/2506.13384v1", "categories": ["cs.AI", "cs.CY", "stat.ME", "stat.OT"], "primary_category": "cs.AI"}
{"title": "Mitigating loss of variance in ensemble data assimilation: machine learning-based and distance-free localizations for better covariance estimation", "abstract": "We propose two new methods based/inspired by machine learning for tabular\ndata and distance-free localization to enhance the covariance estimations in an\nensemble data assimilation. The main goal is to enhance the data assimilation\nresults by mitigating loss of variance due to sampling errors. We also analyze\nthe suitability of several machine learning models and the balance between\naccuracy and computational cost of the covariance estimations. We introduce two\ndistance-free localization techniques leveraging machine learning methods\nspecifically tailored for tabular data. The methods are integrated into the\nEnsemble Smoother with Multiple Data Assimilation (ES-MDA) framework. The\nresults show that the proposed localizations improve covariance accuracy and\nenhance data assimilation and uncertainty quantification results. We observe\nreduced variance loss for the input variables using the proposed methods.\nFurthermore, we compare several machine learning models, assessing their\nsuitability for the problem in terms of computational cost, and quality of the\ncovariance estimation and data match. The influence of ensemble size is also\ninvestigated, providing insights into balancing accuracy and computational\nefficiency. Our findings demonstrate that certain machine learning models are\nmore suitable for this problem. This study introduces two novel methods that\nmitigate variance loss for model parameters in ensemble-based data\nassimilation, offering practical solutions that are easy to implement and do\nnot require any additional numerical simulation or hyperparameter tuning.", "published": "2025-06-16 11:09:27", "link": "http://arxiv.org/abs/2506.13362v1", "categories": ["cs.LG", "cs.AI", "math.ST", "physics.comp-ph", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Socratic RL: A Novel Framework for Efficient Knowledge Acquisition through Iterative Reflection and Viewpoint Distillation", "abstract": "Current Reinforcement Learning (RL) methodologies for Large Language Models\n(LLMs) often rely on simplistic, outcome-based reward signals (e.g., final\nanswer correctness), which limits the depth of learning from each interaction.\nThis paper introduces Socratic Reinforcement Learning (Socratic-RL), a novel,\nprocess-oriented framework designed to address this limitation. Socratic-RL\noperates on the principle that deeper understanding is achieved by reflecting\non the causal reasons for errors and successes within the reasoning process\nitself. The framework employs a decoupled \"Teacher-Student\" architecture, where\na \"Teacher AI\" analyzes interaction histories, extracts causal insights, and\nformulates them into structured \"viewpoints.\" These viewpoints, acting as\ndistilled guidance, are then used by a \"Student AI\" to enhance its subsequent\nreasoning. A key innovation is the iterative self-improvement of the Teacher\nAI, enabling its reflective capabilities to evolve through a meta-learning\nloop. To manage the accumulation of knowledge, a distillation mechanism\ncompresses learned viewpoints into the Student's parameters. By focusing on\nprocess rather than just outcome, Socratic-RL presents a pathway toward\nenhanced sample efficiency, superior interpretability, and a more scalable\narchitecture for self-improving AI systems. This paper details the foundational\nconcepts, formal mechanisms, synergies, challenges, and a concrete research\nroadmap for this proposed framework.", "published": "2025-06-16 10:57:58", "link": "http://arxiv.org/abs/2506.13358v1", "categories": ["cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "LapDDPM: A Conditional Graph Diffusion Model for scRNA-seq Generation with Spectral Adversarial Perturbations", "abstract": "Generating high-fidelity and biologically plausible synthetic single-cell RNA\nsequencing (scRNA-seq) data, especially with conditional control, is\nchallenging due to its high dimensionality, sparsity, and complex biological\nvariations. Existing generative models often struggle to capture these unique\ncharacteristics and ensure robustness to structural noise in cellular networks.\nWe introduce LapDDPM, a novel conditional Graph Diffusion Probabilistic Model\nfor robust and high-fidelity scRNA-seq generation. LapDDPM uniquely integrates\ngraph-based representations with a score-based diffusion model, enhanced by a\nnovel spectral adversarial perturbation mechanism on graph edge weights. Our\ncontributions are threefold: we leverage Laplacian Positional Encodings (LPEs)\nto enrich the latent space with crucial cellular relationship information; we\ndevelop a conditional score-based diffusion model for effective learning and\ngeneration from complex scRNA-seq distributions; and we employ a unique\nspectral adversarial training scheme on graph edge weights, boosting robustness\nagainst structural variations. Extensive experiments on diverse scRNA-seq\ndatasets demonstrate LapDDPM's superior performance, achieving high fidelity\nand generating biologically-plausible, cell-type-specific samples. LapDDPM sets\na new benchmark for conditional scRNA-seq data generation, offering a robust\ntool for various downstream biological applications.", "published": "2025-06-16 10:35:32", "link": "http://arxiv.org/abs/2506.13344v1", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.CB", "q-bio.GN"], "primary_category": "cs.LG"}
{"title": "Probabilistic Modeling of Spiking Neural Networks with Contract-Based Verification", "abstract": "Spiking Neural Networks (SNN) are models for \"realistic\" neuronal\ncomputation, which makes them somehow different in scope from \"ordinary\"\ndeep-learning models widely used in AI platforms nowadays. SNNs focus on timed\nlatency (and possibly probability) of neuronal reactive activation/response,\nmore than numerical computation of filters. So, an SNN model must provide\nmodeling constructs for elementary neural bundles and then for synaptic\nconnections to assemble them into compound data flow network patterns. These\nelements are to be parametric patterns, with latency and probability values\ninstantiated on particular instances (while supposedly constant \"at runtime\").\nDesigners could also use different values to represent \"tired\" neurons, or ones\nimpaired by external drugs, for instance. One important challenge in such\nmodeling is to study how compound models could meet global reaction\nrequirements (in stochastic timing challenges), provided similar provisions on\nindividual neural bundles. A temporal language of logic to express such\nassume/guarantee contracts is thus needed. This may lead to formal verification\non medium-sized models and testing observations on large ones. In the current\narticle, we make preliminary progress at providing a simple model framework to\nexpress both elementary SNN neural bundles and their connecting constructs,\nwhich translates readily into both a model-checker and a simulator (both\nalready existing and robust) to conduct experiments.", "published": "2025-06-16 10:30:16", "link": "http://arxiv.org/abs/2506.13340v1", "categories": ["cs.AI", "cs.FL"], "primary_category": "cs.AI"}
{"title": "Towards Pervasive Distributed Agentic Generative AI -- A State of The Art", "abstract": "The rapid advancement of intelligent agents and Large Language Models (LLMs)\nis reshaping the pervasive computing field. Their ability to perceive, reason,\nand act through natural language understanding enables autonomous\nproblem-solving in complex pervasive environments, including the management of\nheterogeneous sensors, devices, and data. This survey outlines the\narchitectural components of LLM agents (profiling, memory, planning, and\naction) and examines their deployment and evaluation across various scenarios.\nThan it reviews computational and infrastructural advancements (cloud to edge)\nin pervasive computing and how AI is moving in this field. It highlights\nstate-of-the-art agent deployment strategies and applications, including local\nand distributed execution on resource-constrained devices. This survey\nidentifies key challenges of these agents in pervasive computing such as\narchitectural, energetic and privacy limitations. It finally proposes what we\ncalled \"Agent as a Tool\", a conceptual framework for pervasive agentic AI,\nemphasizing context awareness, modularity, security, efficiency and\neffectiveness.", "published": "2025-06-16 10:15:06", "link": "http://arxiv.org/abs/2506.13324v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Tady: A Neural Disassembler without Structural Constraint Violations", "abstract": "Disassembly is a crucial yet challenging step in binary analysis. While\nemerging neural disassemblers show promise for efficiency and accuracy, they\nfrequently generate outputs violating fundamental structural constraints, which\nsignificantly compromise their practical usability. To address this critical\nproblem, we regularize the disassembly solution space by formalizing and\napplying key structural constraints based on post-dominance relations. This\napproach systematically detects widespread errors in existing neural\ndisassemblers' outputs. These errors often originate from models' limited\ncontext modeling and instruction-level decoding that neglect global structural\nintegrity. We introduce Tady, a novel neural disassembler featuring an improved\nmodel architecture and a dedicated post-processing algorithm, specifically\nengineered to address these deficiencies. Comprehensive evaluations on diverse\nbinaries demonstrate that Tady effectively eliminates structural constraint\nviolations and functions with high efficiency, while maintaining\ninstruction-level accuracy.", "published": "2025-06-16 10:11:43", "link": "http://arxiv.org/abs/2506.13323v1", "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.CR"}
{"title": "Active Multimodal Distillation for Few-shot Action Recognition", "abstract": "Owing to its rapid progress and broad application prospects, few-shot action\nrecognition has attracted considerable interest. However, current methods are\npredominantly based on limited single-modal data, which does not fully exploit\nthe potential of multimodal information. This paper presents a novel framework\nthat actively identifies reliable modalities for each sample using\ntask-specific contextual cues, thus significantly improving recognition\nperformance. Our framework integrates an Active Sample Inference (ASI) module,\nwhich utilizes active inference to predict reliable modalities based on\nposterior distributions and subsequently organizes them accordingly. Unlike\nreinforcement learning, active inference replaces rewards with evidence-based\npreferences, making more stable predictions. Additionally, we introduce an\nactive mutual distillation module that enhances the representation learning of\nless reliable modalities by transferring knowledge from more reliable ones.\nAdaptive multimodal inference is employed during the meta-test to assign higher\nweights to reliable modalities. Extensive experiments across multiple\nbenchmarks demonstrate that our method significantly outperforms existing\napproaches.", "published": "2025-06-16 10:10:56", "link": "http://arxiv.org/abs/2506.13322v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Vine Copulas as Differentiable Computational Graphs", "abstract": "Vine copulas are sophisticated models for multivariate distributions and are\nincreasingly used in machine learning. To facilitate their integration into\nmodern ML pipelines, we introduce the vine computational graph, a DAG that\nabstracts the multilevel vine structure and associated computations. On this\nfoundation, we devise new algorithms for conditional sampling, efficient\nsampling-order scheduling, and constructing vine structures for customized\nconditioning variables. We implement these ideas in torchvinecopulib, a\nGPU-accelerated Python library built upon PyTorch, delivering improved\nscalability for fitting, sampling, and density evaluation. Our experiments\nillustrate how gradient flowing through the vine can improve Vine Copula\nAutoencoders and that incorporating vines for uncertainty quantification in\ndeep learning can outperform MC-dropout, deep ensembles, and Bayesian Neural\nNetworks in sharpness, calibration, and runtime. By recasting vine copula\nmodels as computational graphs, our work connects classical dependence modeling\nwith modern deep-learning toolchains and facilitates the integration of\nstate-of-the-art copula methods in modern machine learning pipelines.", "published": "2025-06-16 09:57:36", "link": "http://arxiv.org/abs/2506.13318v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Image Concepts", "abstract": "This work investigates the adaptation of large pre-trained latent diffusion\nmodels to a radically new imaging domain: Synthetic Aperture Radar (SAR). While\nthese generative models, originally trained on natural images, demonstrate\nimpressive capabilities in text-to-image synthesis, they are not natively\nadapted to represent SAR data, which involves different physics, statistical\ndistributions, and visual characteristics. Using a sizeable SAR dataset (on the\norder of 100,000 to 1 million images), we address the fundamental question of\nfine-tuning such models for this unseen modality. We explore and compare\nmultiple fine-tuning strategies, including full model fine-tuning and\nparameter-efficient approaches like Low-Rank Adaptation (LoRA), focusing\nseparately on the UNet diffusion backbone and the text encoder components. To\nevaluate generative quality, we combine several metrics: statistical distance\nfrom real SAR distributions, textural similarity via GLCM descriptors, and\nsemantic alignment assessed with a CLIP model fine-tuned on SAR data. Our\nresults show that a hybrid tuning strategy yields the best performance: full\nfine-tuning of the UNet is better at capturing low-level SAR-specific patterns,\nwhile LoRA-based partial tuning of the text encoder, combined with embedding\nlearning of the <SAR> token, suffices to preserve prompt alignment. This work\nprovides a methodical strategy for adapting foundation models to unconventional\nimaging modalities beyond natural image domains.", "published": "2025-06-16 09:48:01", "link": "http://arxiv.org/abs/2506.13307v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Fair Generation without Unfair Distortions: Debiasing Text-to-Image Generation with Entanglement-Free Attention", "abstract": "Recent advancements in diffusion-based text-to-image (T2I) models have\nenabled the generation of high-quality and photorealistic images from text\ndescriptions. However, they often exhibit societal biases related to gender,\nrace, and socioeconomic status, thereby reinforcing harmful stereotypes and\nshaping public perception in unintended ways. While existing bias mitigation\nmethods demonstrate effectiveness, they often encounter attribute entanglement,\nwhere adjustments to attributes relevant to the bias (i.e., target attributes)\nunintentionally alter attributes unassociated with the bias (i.e., non-target\nattributes), causing undesirable distribution shifts. To address this\nchallenge, we introduce Entanglement-Free Attention (EFA), a method that\naccurately incorporates target attributes (e.g., White, Black, Asian, and\nIndian) while preserving non-target attributes (e.g., background details)\nduring bias mitigation. At inference time, EFA randomly samples a target\nattribute with equal probability and adjusts the cross-attention in selected\nlayers to incorporate the sampled attribute, achieving a fair distribution of\ntarget attributes. Extensive experiments demonstrate that EFA outperforms\nexisting methods in mitigating bias while preserving non-target attributes,\nthereby maintaining the output distribution and generation capability of the\noriginal model.", "published": "2025-06-16 09:40:32", "link": "http://arxiv.org/abs/2506.13298v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Automatic Multi-View X-Ray/CT Registration Using Bone Substructure Contours", "abstract": "Purpose: Accurate intraoperative X-ray/CT registration is essential for\nsurgical navigation in orthopedic procedures. However, existing methods\nstruggle with consistently achieving sub-millimeter accuracy, robustness under\nbroad initial pose estimates or need manual key-point annotations. This work\naims to address these challenges by proposing a novel multi-view X-ray/CT\nregistration method for intraoperative bone registration. Methods: The proposed\nregistration method consists of a multi-view, contour-based iterative closest\npoint (ICP) optimization. Unlike previous methods, which attempt to match bone\ncontours across the entire silhouette in both imaging modalities, we focus on\nmatching specific subcategories of contours corresponding to bone\nsubstructures. This leads to reduced ambiguity in the ICP matches, resulting in\na more robust and accurate registration solution. This approach requires only\ntwo X-ray images and operates fully automatically. Additionally, we contribute\na dataset of 5 cadaveric specimens, including real X-ray images, X-ray image\nposes and the corresponding CT scans. Results: The proposed registration method\nis evaluated on real X-ray images using mean reprojection error (mRPD). The\nmethod consistently achieves sub-millimeter accuracy with a mRPD 0.67mm\ncompared to 5.35mm by a commercial solution requiring manual intervention.\nFurthermore, the method offers improved practical applicability, being fully\nautomatic. Conclusion: Our method offers a practical, accurate, and efficient\nsolution for multi-view X-ray/CT registration in orthopedic surgeries, which\ncan be easily combined with tracking systems. By improving registration\naccuracy and minimizing manual intervention, it enhances intraoperative\nnavigation, contributing to more accurate and effective surgical outcomes in\ncomputer-assisted surgery (CAS).", "published": "2025-06-16 09:33:37", "link": "http://arxiv.org/abs/2506.13292v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Navigating the Black Box: Leveraging LLMs for Effective Text-Level Graph Injection Attacks", "abstract": "Text-attributed graphs (TAGs) integrate textual data with graph structures,\nproviding valuable insights in applications such as social network analysis and\nrecommendation systems. Graph Neural Networks (GNNs) effectively capture both\ntopological structure and textual information in TAGs but are vulnerable to\nadversarial attacks. Existing graph injection attack (GIA) methods assume that\nattackers can directly manipulate the embedding layer, producing\nnon-explainable node embeddings. Furthermore, the effectiveness of these\nattacks often relies on surrogate models with high training costs. Thus, this\npaper introduces ATAG-LLM, a novel black-box GIA framework tailored for TAGs.\nOur approach leverages large language models (LLMs) to generate interpretable\ntext-level node attributes directly, ensuring attacks remain feasible in\nreal-world scenarios. We design strategies for LLM prompting that balance\nexploration and reliability to guide text generation, and propose a similarity\nassessment method to evaluate attack text effectiveness in disrupting graph\nhomophily. This method efficiently perturbs the target node with minimal\ntraining costs in a strict black-box setting, ensuring a text-level graph\ninjection attack for TAGs. Experiments on real-world TAG datasets validate the\nsuperior performance of ATAG-LLM compared to state-of-the-art embedding-level\nand text-level attack methods.", "published": "2025-06-16 09:16:21", "link": "http://arxiv.org/abs/2506.13276v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Energy-Efficient Digital Design: A Comparative Study of Event-Driven and Clock-Driven Spiking Neurons", "abstract": "This paper presents a comprehensive evaluation of Spiking Neural Network\n(SNN) neuron models for hardware acceleration by comparing event driven and\nclock-driven implementations. We begin our investigation in software, rapidly\nprototyping and testing various SNN models based on different variants of the\nLeaky Integrate and Fire (LIF) neuron across multiple datasets. This phase\nenables controlled performance assessment and informs design refinement. Our\nsubsequent hardware phase, implemented on FPGA, validates the simulation\nfindings and offers practical insights into design trade offs. In particular,\nwe examine how variations in input stimuli influence key performance metrics\nsuch as latency, power consumption, energy efficiency, and resource\nutilization. These results yield valuable guidelines for constructing energy\nefficient, real time neuromorphic systems. Overall, our work bridges software\nsimulation and hardware realization, advancing the development of next\ngeneration SNN accelerators.", "published": "2025-06-16 09:10:19", "link": "http://arxiv.org/abs/2506.13268v1", "categories": ["cs.NE", "cs.AI"], "primary_category": "cs.NE"}
{"title": "Open-Set LiDAR Panoptic Segmentation Guided by Uncertainty-Aware Learning", "abstract": "Autonomous vehicles that navigate in open-world environments may encounter\npreviously unseen object classes. However, most existing LiDAR panoptic\nsegmentation models rely on closed-set assumptions, failing to detect unknown\nobject instances. In this work, we propose ULOPS, an uncertainty-guided\nopen-set panoptic segmentation framework that leverages Dirichlet-based\nevidential learning to model predictive uncertainty. Our architecture\nincorporates separate decoders for semantic segmentation with uncertainty\nestimation, embedding with prototype association, and instance center\nprediction. During inference, we leverage uncertainty estimates to identify and\nsegment unknown instances. To strengthen the model's ability to differentiate\nbetween known and unknown objects, we introduce three uncertainty-driven loss\nfunctions. Uniform Evidence Loss to encourage high uncertainty in unknown\nregions. Adaptive Uncertainty Separation Loss ensures a consistent difference\nin uncertainty estimates between known and unknown objects at a global scale.\nContrastive Uncertainty Loss refines this separation at the fine-grained level.\nTo evaluate open-set performance, we extend benchmark settings on KITTI-360 and\nintroduce a new open-set evaluation for nuScenes. Extensive experiments\ndemonstrate that ULOPS consistently outperforms existing open-set LiDAR\npanoptic segmentation methods.", "published": "2025-06-16 09:03:51", "link": "http://arxiv.org/abs/2506.13265v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Vector Ontologies as an LLM world view extraction method", "abstract": "Large Language Models (LLMs) possess intricate internal representations of\nthe world, yet these latent structures are notoriously difficult to interpret\nor repurpose beyond the original prediction task. Building on our earlier work\n(Rothenfusser, 2025), which introduced the concept of vector ontologies as a\nframework for translating high-dimensional neural representations into\ninterpretable geometric structures, this paper provides the first empirical\nvalidation of that approach. A vector ontology defines a domain-specific vector\nspace spanned by ontologically meaningful dimensions, allowing geometric\nanalysis of concepts and relationships within a domain. We construct an\n8-dimensional vector ontology of musical genres based on Spotify audio features\nand test whether an LLM's internal world model of music can be consistently and\naccurately projected into this space. Using GPT-4o-mini, we extract genre\nrepresentations through multiple natural language prompts and analyze the\nconsistency of these projections across linguistic variations and their\nalignment with ground-truth data. Our results show (1) high spatial consistency\nof genre projections across 47 query formulations, (2) strong alignment between\nLLM-inferred genre locations and real-world audio feature distributions, and\n(3) evidence of a direct relationship between prompt phrasing and spatial\nshifts in the LLM's inferred vector ontology. These findings demonstrate that\nLLMs internalize structured, repurposable knowledge and that vector ontologies\noffer a promising method for extracting and analyzing this knowledge in a\ntransparent and verifiable way.", "published": "2025-06-16 08:49:21", "link": "http://arxiv.org/abs/2506.13252v1", "categories": ["cs.AI", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Generalized Proof-Number Monte-Carlo Tree Search", "abstract": "This paper presents Generalized Proof-Number Monte-Carlo Tree Search: a\ngeneralization of recently proposed combinations of Proof-Number Search (PNS)\nwith Monte-Carlo Tree Search (MCTS), which use (dis)proof numbers to bias\nUCB1-based Selection strategies towards parts of the search that are expected\nto be easily (dis)proven. We propose three core modifications of prior\ncombinations of PNS with MCTS. First, we track proof numbers per player. This\nreduces code complexity in the sense that we no longer need disproof numbers,\nand generalizes the technique to be applicable to games with more than two\nplayers. Second, we propose and extensively evaluate different methods of using\nproof numbers to bias the selection strategy, achieving strong performance with\nstrategies that are simpler to implement and compute. Third, we merge our\ntechnique with Score Bounded MCTS, enabling the algorithm to prove and leverage\nupper and lower bounds on scores - as opposed to only proving wins or not-wins.\nExperiments demonstrate substantial performance increases, reaching the range\nof 80% for 8 out of the 11 tested board games.", "published": "2025-06-16 08:45:36", "link": "http://arxiv.org/abs/2506.13249v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "On Immutable Memory Systems for Artificial Agents: A Blockchain-Indexed Automata-Theoretic Framework Using ECDH-Keyed Merkle Chains", "abstract": "This paper presents a formalised architecture for synthetic agents designed\nto retain immutable memory, verifiable reasoning, and constrained epistemic\ngrowth. Traditional AI systems rely on mutable, opaque statistical models prone\nto epistemic drift and historical revisionism. In contrast, we introduce the\nconcept of the Merkle Automaton, a cryptographically anchored, deterministic\ncomputational framework that integrates formal automata theory with\nblockchain-based commitments. Each agent transition, memory fragment, and\nreasoning step is committed within a Merkle structure rooted on-chain,\nrendering it non-repudiable and auditably permanent. To ensure selective access\nand confidentiality, we derive symmetric encryption keys from ECDH exchanges\ncontextualised by hierarchical privilege lattices. This enforces cryptographic\naccess control over append-only DAG-structured knowledge graphs. Reasoning is\nconstrained by formal logic systems and verified through deterministic\ntraversal of policy-encoded structures. Updates are non-destructive and\nhistoried, preserving epistemic lineage without catastrophic forgetting.\nZero-knowledge proofs facilitate verifiable, privacy-preserving inclusion\nattestations. Collectively, this architecture reframes memory not as a cache\nbut as a ledger - one whose contents are enforced by protocol, bound by\ncryptography, and constrained by formal logic. The result is not an intelligent\nagent that mimics thought, but an epistemic entity whose outputs are provably\nderived, temporally anchored, and impervious to post hoc revision. This design\nlays foundational groundwork for legal, economic, and high-assurance\ncomputational systems that require provable memory, unforgeable provenance, and\nstructural truth.", "published": "2025-06-16 08:43:56", "link": "http://arxiv.org/abs/2506.13246v1", "categories": ["cs.CR", "cs.AI", "cs.DC", "68Q70, 68P25, 68T37 68Q70, 68P25, 68T37 68Q70, 68P25, 68T37 68Q70,\n  68P25, 68T37", "F.4.3; D.4.6; E.3; I.2.4"], "primary_category": "cs.CR"}
{"title": "A Game-Theoretic Negotiation Framework for Cross-Cultural Consensus in LLMs", "abstract": "The increasing prevalence of large language models (LLMs) is influencing\nglobal value systems. However, these models frequently exhibit a pronounced\nWEIRD (Western, Educated, Industrialized, Rich, Democratic) cultural bias due\nto lack of attention to minority values. This monocultural perspective may\nreinforce dominant values and marginalize diverse cultural viewpoints, posing\nchallenges for the development of equitable and inclusive AI systems. In this\nwork, we introduce a systematic framework designed to boost fair and robust\ncross-cultural consensus among LLMs. We model consensus as a Nash Equilibrium\nand employ a game-theoretic negotiation method based on Policy-Space Response\nOracles (PSRO) to simulate an organized cross-cultural negotiation process. To\nevaluate this approach, we construct regional cultural agents using data\ntransformed from the World Values Survey (WVS). Beyond the conventional\nmodel-level evaluation method, We further propose two quantitative metrics,\nPerplexity-based Acceptence and Values Self-Consistency, to assess consensus\noutcomes. Experimental results indicate that our approach generates consensus\nof higher quality while ensuring more balanced compromise compared to\nbaselines. Overall, it mitigates WEIRD bias by guiding agents toward\nconvergence through fair and gradual negotiation steps.", "published": "2025-06-16 08:42:39", "link": "http://arxiv.org/abs/2506.13245v1", "categories": ["cs.AI", "cs.CY", "cs.GT"], "primary_category": "cs.AI"}
{"title": "No-Regret Learning Under Adversarial Resource Constraints: A Spending Plan Is All You Need!", "abstract": "We study online decision making problems under resource constraints, where\nboth reward and cost functions are drawn from distributions that may change\nadversarially over time. We focus on two canonical settings: $(i)$ online\nresource allocation where rewards and costs are observed before action\nselection, and $(ii)$ online learning with resource constraints where they are\nobserved after action selection, under full feedback or bandit feedback. It is\nwell known that achieving sublinear regret in these settings is impossible when\nreward and cost distributions may change arbitrarily over time. To address this\nchallenge, we analyze a framework in which the learner is guided by a spending\nplan--a sequence prescribing expected resource usage across rounds. We design\ngeneral (primal-)dual methods that achieve sublinear regret with respect to\nbaselines that follow the spending plan. Crucially, the performance of our\nalgorithms improves when the spending plan ensures a well-balanced distribution\nof the budget across rounds. We additionally provide a robust variant of our\nmethods to handle worst-case scenarios where the spending plan is highly\nimbalanced. To conclude, we study the regret of our algorithms when competing\nagainst benchmarks that deviate from the prescribed spending plan.", "published": "2025-06-16 08:42:31", "link": "http://arxiv.org/abs/2506.13244v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Towards Explaining Monte-Carlo Tree Search by Using Its Enhancements", "abstract": "Typically, research on Explainable Artificial Intelligence (XAI) focuses on\nblack-box models within the context of a general policy in a known, specific\ndomain. This paper advocates for the need for knowledge-agnostic explainability\napplied to the subfield of XAI called Explainable Search, which focuses on\nexplaining the choices made by intelligent search techniques. It proposes\nMonte-Carlo Tree Search (MCTS) enhancements as a solution to obtaining\nadditional data and providing higher-quality explanations while remaining\nknowledge-free, and analyzes the most popular enhancements in terms of the\nspecific types of explainability they introduce. So far, no other research has\nconsidered the explainability of MCTS enhancements. We present a\nproof-of-concept that demonstrates the advantages of utilizing enhancements.", "published": "2025-06-16 08:21:37", "link": "http://arxiv.org/abs/2506.13223v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "NeuroPhysNet: A FitzHugh-Nagumo-Based Physics-Informed Neural Network Framework for Electroencephalograph (EEG) Analysis and Motor Imagery Classification", "abstract": "Electroencephalography (EEG) is extensively employed in medical diagnostics\nand brain-computer interface (BCI) applications due to its non-invasive nature\nand high temporal resolution. However, EEG analysis faces significant\nchallenges, including noise, nonstationarity, and inter-subject variability,\nwhich hinder its clinical utility. Traditional neural networks often lack\nintegration with biophysical knowledge, limiting their interpretability,\nrobustness, and potential for medical translation. To address these\nlimitations, this study introduces NeuroPhysNet, a novel Physics-Informed\nNeural Network (PINN) framework tailored for EEG signal analysis and motor\nimagery classification in medical contexts. NeuroPhysNet incorporates the\nFitzHugh-Nagumo model, embedding neurodynamical principles to constrain\npredictions and enhance model robustness. Evaluated on the BCIC-IV-2a dataset,\nthe framework achieved superior accuracy and generalization compared to\nconventional methods, especially in data-limited and cross-subject scenarios,\nwhich are common in clinical settings. By effectively integrating biophysical\ninsights with data-driven techniques, NeuroPhysNet not only advances BCI\napplications but also holds significant promise for enhancing the precision and\nreliability of clinical diagnostics, such as motor disorder assessments and\nneurorehabilitation planning.", "published": "2025-06-16 08:21:04", "link": "http://arxiv.org/abs/2506.13222v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments", "abstract": "With the growing integration of vision-language models (VLMs), mobile agents\nare now widely used for tasks like UI automation and camera-based user\nassistance. These agents are often fine-tuned on limited user-generated\ndatasets, leaving them vulnerable to covert threats during the training\nprocess. In this work we present GHOST, the first clean-label backdoor attack\nspecifically designed for mobile agents built upon VLMs. Our method manipulates\nonly the visual inputs of a portion of the training samples - without altering\ntheir corresponding labels or instructions - thereby injecting malicious\nbehaviors into the model. Once fine-tuned with this tampered data, the agent\nwill exhibit attacker-controlled responses when a specific visual trigger is\nintroduced at inference time. The core of our approach lies in aligning the\ngradients of poisoned samples with those of a chosen target instance, embedding\nbackdoor-relevant features into the poisoned training data. To maintain stealth\nand enhance robustness, we develop three realistic visual triggers: static\nvisual patches, dynamic motion cues, and subtle low-opacity overlays. We\nevaluate our method across six real-world Android apps and three VLM\narchitectures adapted for mobile use. Results show that our attack achieves\nhigh attack success rates (up to 94.67 percent) while maintaining high\nclean-task performance (FSR up to 95.85 percent). Additionally, ablation\nstudies shed light on how various design choices affect the efficacy and\nconcealment of the attack. Overall, this work is the first to expose critical\nsecurity flaws in VLM-based mobile agents, highlighting their susceptibility to\nclean-label backdoor attacks and the urgent need for effective defense\nmechanisms in their training pipelines. Code and examples are available at:\nhttps://anonymous.4open.science/r/ase-2025-C478.", "published": "2025-06-16 08:09:32", "link": "http://arxiv.org/abs/2506.13205v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "ViT-NeBLa: A Hybrid Vision Transformer and Neural Beer-Lambert Framework for Single-View 3D Reconstruction of Oral Anatomy from Panoramic Radiographs", "abstract": "Dental diagnosis relies on two primary imaging modalities: panoramic\nradiographs (PX) providing 2D oral cavity representations, and Cone-Beam\nComputed Tomography (CBCT) offering detailed 3D anatomical information. While\nPX images are cost-effective and accessible, their lack of depth information\nlimits diagnostic accuracy. CBCT addresses this but presents drawbacks\nincluding higher costs, increased radiation exposure, and limited\naccessibility. Existing reconstruction models further complicate the process by\nrequiring CBCT flattening or prior dental arch information, often unavailable\nclinically. We introduce ViT-NeBLa, a vision transformer-based Neural\nBeer-Lambert model enabling accurate 3D reconstruction directly from single PX.\nOur key innovations include: (1) enhancing the NeBLa framework with Vision\nTransformers for improved reconstruction capabilities without requiring CBCT\nflattening or prior dental arch information, (2) implementing a novel\nhorseshoe-shaped point sampling strategy with non-intersecting rays that\neliminates intermediate density aggregation required by existing models due to\nintersecting rays, reducing sampling point computations by $52 \\%$, (3)\nreplacing CNN-based U-Net with a hybrid ViT-CNN architecture for superior\nglobal and local feature extraction, and (4) implementing learnable hash\npositional encoding for better higher-dimensional representation of 3D sample\npoints compared to existing Fourier-based dense positional encoding.\nExperiments demonstrate that ViT-NeBLa significantly outperforms prior\nstate-of-the-art methods both quantitatively and qualitatively, offering a\ncost-effective, radiation-efficient alternative for enhanced dental\ndiagnostics.", "published": "2025-06-16 08:01:14", "link": "http://arxiv.org/abs/2506.13195v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "From Empirical Evaluation to Context-Aware Enhancement: Repairing Regression Errors with LLMs", "abstract": "[...] Since then, various APR approaches, especially those leveraging the\npower of large language models (LLMs), have been rapidly developed to fix\ngeneral software bugs. Unfortunately, the effectiveness of these advanced\ntechniques in the context of regression bugs remains largely unexplored. This\ngap motivates the need for an empirical study evaluating the effectiveness of\nmodern APR techniques in fixing real-world regression bugs.\n  In this work, we conduct an empirical study of APR techniques on Java\nregression bugs. To facilitate our study, we introduce RegMiner4APR, a\nhigh-quality benchmark of Java regression bugs integrated into a framework\ndesigned to facilitate APR research. The current benchmark includes 99\nregression bugs collected from 32 widely used real-world Java GitHub\nrepositories. We begin by conducting an in-depth analysis of the benchmark,\ndemonstrating its diversity and quality. Building on this foundation, we\nempirically evaluate the capabilities of APR to regression bugs by assessing\nboth traditional APR tools and advanced LLM-based APR approaches. Our\nexperimental results show that classical APR tools fail to repair any bugs,\nwhile LLM-based APR approaches exhibit promising potential. Motivated by these\nresults, we investigate impact of incorporating bug-inducing change information\ninto LLM-based APR approaches for fixing regression bugs. Our results highlight\nthat this context-aware enhancement significantly improves the performance of\nLLM-based APR, yielding 1.8x more successful repairs compared to using\nLLM-based APR without such context.", "published": "2025-06-16 07:49:18", "link": "http://arxiv.org/abs/2506.13182v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Querying Large Automotive Software Models: Agentic vs. Direct LLM Approaches", "abstract": "Large language models (LLMs) offer new opportunities for interacting with\ncomplex software artifacts, such as software models, through natural language.\nThey present especially promising benefits for large software models that are\ndifficult to grasp in their entirety, making traditional interaction and\nanalysis approaches challenging. This paper investigates two approaches for\nleveraging LLMs to answer questions over software models: direct prompting,\nwhere the whole software model is provided in the context, and an agentic\napproach combining LLM-based agents with general-purpose file access tools. We\nevaluate these approaches using an Ecore metamodel designed for timing analysis\nand software optimization in automotive and embedded domains. Our findings show\nthat while the agentic approach achieves accuracy comparable to direct\nprompting, it is significantly more efficient in terms of token usage. This\nefficiency makes the agentic approach particularly suitable for the automotive\nindustry, where the large size of software models makes direct prompting\ninfeasible, establishing LLM agents as not just a practical alternative but the\nonly viable solution. Notably, the evaluation was conducted using small LLMs,\nwhich are more feasible to be executed locally - an essential advantage for\nmeeting strict requirements around privacy, intellectual property protection,\nand regulatory compliance. Future work will investigate software models in\ndiverse formats, explore more complex agent architectures, and extend agentic\nworkflows to support not only querying but also modification of software\nmodels.", "published": "2025-06-16 07:34:28", "link": "http://arxiv.org/abs/2506.13171v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Real Time Self-Tuning Adaptive Controllers on Temperature Control Loops using Event-based Game Theory", "abstract": "This paper presents a novel method for enhancing the adaptability of\nProportional-Integral-Derivative (PID) controllers in industrial systems using\nevent-based dynamic game theory, which enables the PID controllers to\nself-learn, optimize, and fine-tune themselves. In contrast to conventional\nself-learning approaches, our proposed framework offers an event-driven control\nstrategy and game-theoretic learning algorithms. The players collaborate with\nthe PID controllers to dynamically adjust their gains in response to set point\nchanges and disturbances. We provide a theoretical analysis showing sound\nconvergence guarantees for the game given suitable stability ranges of the PID\ncontrolled loop. We further introduce an automatic boundary detection\nmechanism, which helps the players to find an optimal initialization of action\nspaces and significantly reduces the exploration time. The efficacy of this\nnovel methodology is validated through its implementation in the temperature\ncontrol loop of a printing press machine. Eventually, the outcomes of the\nproposed intelligent self-tuning PID controllers are highly promising,\nparticularly in terms of reducing overshoot and settling time.", "published": "2025-06-16 07:19:46", "link": "http://arxiv.org/abs/2506.13164v1", "categories": ["cs.AI", "cs.GT"], "primary_category": "cs.AI"}
{"title": "CertDW: Towards Certified Dataset Ownership Verification via Conformal Prediction", "abstract": "Deep neural networks (DNNs) rely heavily on high-quality open-source datasets\n(e.g., ImageNet) for their success, making dataset ownership verification (DOV)\ncrucial for protecting public dataset copyrights. In this paper, we find\nexisting DOV methods (implicitly) assume that the verification process is\nfaithful, where the suspicious model will directly verify ownership by using\nthe verification samples as input and returning their results. However, this\nassumption may not necessarily hold in practice and their performance may\ndegrade sharply when subjected to intentional or unintentional perturbations.\nTo address this limitation, we propose the first certified dataset watermark\n(i.e., CertDW) and CertDW-based certified dataset ownership verification method\nthat ensures reliable verification even under malicious attacks, under certain\nconditions (e.g., constrained pixel-level perturbation). Specifically, inspired\nby conformal prediction, we introduce two statistical measures, including\nprincipal probability (PP) and watermark robustness (WR), to assess model\nprediction stability on benign and watermarked samples under noise\nperturbations. We prove there exists a provable lower bound between PP and WR,\nenabling ownership verification when a suspicious model's WR value\nsignificantly exceeds the PP values of multiple benign models trained on\nwatermark-free datasets. If the number of PP values smaller than WR exceeds a\nthreshold, the suspicious model is regarded as having been trained on the\nprotected dataset. Extensive experiments on benchmark datasets verify the\neffectiveness of our CertDW method and its resistance to potential adaptive\nattacks. Our codes are at\n\\href{https://github.com/NcepuQiaoTing/CertDW}{GitHub}.", "published": "2025-06-16 07:17:23", "link": "http://arxiv.org/abs/2506.13160v1", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Machine Learning as Iterated Belief Change a la Darwiche and Pearl", "abstract": "Artificial Neural Networks (ANNs) are powerful machine-learning models\ncapable of capturing intricate non-linear relationships. They are widely used\nnowadays across numerous scientific and engineering domains, driving\nadvancements in both research and real-world applications. In our recent work,\nwe focused on the statics and dynamics of a particular subclass of ANNs, which\nwe refer to as binary ANNs. A binary ANN is a feed-forward network in which\nboth inputs and outputs are restricted to binary values, making it particularly\nsuitable for a variety of practical use cases. Our previous study approached\nbinary ANNs through the lens of belief-change theory, specifically the\nAlchourron, Gardenfors and Makinson (AGM) framework, yielding several key\ninsights. Most notably, we demonstrated that the knowledge embodied in a binary\nANN (expressed through its input-output behaviour) can be symbolically\nrepresented using a propositional logic language. Moreover, the process of\nmodifying a belief set (through revision or contraction) was mapped onto a\ngradual transition through a series of intermediate belief sets. Analogously,\nthe training of binary ANNs was conceptualized as a sequence of such belief-set\ntransitions, which we showed can be formalized using full-meet AGM-style belief\nchange. In the present article, we extend this line of investigation by\naddressing some critical limitations of our previous study. Specifically, we\nshow that Dalal's method for belief change naturally induces a structured,\ngradual evolution of states of belief. More importantly, given the known\nshortcomings of full-meet belief change, we demonstrate that the training\ndynamics of binary ANNs can be more effectively modelled using robust AGM-style\nchange operations -- namely, lexicographic revision and moderate contraction --\nthat align with the Darwiche-Pearl framework for iterated belief change.", "published": "2025-06-16 07:10:52", "link": "http://arxiv.org/abs/2506.13157v1", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.NE"], "primary_category": "cs.AI"}
{"title": "Quantum AGI: Ontological Foundations", "abstract": "We examine the implications of quantum foundations for AGI, focusing on how\nseminal results such as Bell's theorems (non-locality), the Kochen-Specker\ntheorem (contextuality) and no-cloning theorem problematise practical\nimplementation of AGI in quantum settings. We introduce a novel\ninformation-theoretic taxonomy distinguishing between classical AGI and quantum\nAGI and show how quantum mechanics affects fundamental features of agency. We\nshow how quantum ontology may change AGI capabilities, both via affording\ncomputational advantages and via imposing novel constraints.", "published": "2025-06-16 06:42:20", "link": "http://arxiv.org/abs/2506.13134v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "AlphaEvolve: A coding agent for scientific and algorithmic discovery", "abstract": "In this white paper, we present AlphaEvolve, an evolutionary coding agent\nthat substantially enhances capabilities of state-of-the-art LLMs on highly\nchallenging tasks such as tackling open scientific problems or optimizing\ncritical pieces of computational infrastructure. AlphaEvolve orchestrates an\nautonomous pipeline of LLMs, whose task is to improve an algorithm by making\ndirect changes to the code. Using an evolutionary approach, continuously\nreceiving feedback from one or more evaluators, AlphaEvolve iteratively\nimproves the algorithm, potentially leading to new scientific and practical\ndiscoveries. We demonstrate the broad applicability of this approach by\napplying it to a number of important computational problems. When applied to\noptimizing critical components of large-scale computational stacks at Google,\nAlphaEvolve developed a more efficient scheduling algorithm for data centers,\nfound a functionally equivalent simplification in the circuit design of\nhardware accelerators, and accelerated the training of the LLM underpinning\nAlphaEvolve itself. Furthermore, AlphaEvolve discovered novel, provably correct\nalgorithms that surpass state-of-the-art solutions on a spectrum of problems in\nmathematics and computer science, significantly expanding the scope of prior\nautomated discovery methods (Romera-Paredes et al., 2023). Notably, AlphaEvolve\ndeveloped a search algorithm that found a procedure to multiply two $4 \\times\n4$ complex-valued matrices using $48$ scalar multiplications; offering the\nfirst improvement, after 56 years, over Strassen's algorithm in this setting.\nWe believe AlphaEvolve and coding agents like it can have a significant impact\nin improving solutions of problems across many areas of science and\ncomputation.", "published": "2025-06-16 06:37:18", "link": "http://arxiv.org/abs/2506.13131v1", "categories": ["cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.AI"}
{"title": "PhenoKG: Knowledge Graph-Driven Gene Discovery and Patient Insights from Phenotypes Alone", "abstract": "Identifying causative genes from patient phenotypes remains a significant\nchallenge in precision medicine, with important implications for the diagnosis\nand treatment of genetic disorders. We propose a novel graph-based approach for\npredicting causative genes from patient phenotypes, with or without an\navailable list of candidate genes, by integrating a rare disease knowledge\ngraph (KG). Our model, combining graph neural networks and transformers,\nachieves substantial improvements over the current state-of-the-art. On the\nreal-world MyGene2 dataset, it attains a mean reciprocal rank (MRR) of 24.64\\%\nand nDCG@100 of 33.64\\%, surpassing the best baseline (SHEPHERD) at 19.02\\% MRR\nand 30.54\\% nDCG@100. We perform extensive ablation studies to validate the\ncontribution of each model component. Notably, the approach generalizes to\ncases where only phenotypic data are available, addressing key challenges in\nclinical decision support when genomic information is incomplete.", "published": "2025-06-16 05:54:12", "link": "http://arxiv.org/abs/2506.13119v1", "categories": ["cs.LG", "cs.AI", "cs.NE", "q-bio.GN", "q-bio.QM", "92C50, 68T05", "I.2.6; H.2.8; J.3"], "primary_category": "cs.LG"}
{"title": "Dynamic Reinsurance Treaty Bidding via Multi-Agent Reinforcement Learning", "abstract": "This paper develops a novel multi-agent reinforcement learning (MARL)\nframework for reinsurance treaty bidding, addressing long-standing\ninefficiencies in traditional broker-mediated placement processes. We pose the\ncore research question: Can autonomous, learning-based bidding systems improve\nrisk transfer efficiency and outperform conventional pricing approaches in\nreinsurance markets?\n  In our model, each reinsurer is represented by an adaptive agent that\niteratively refines its bidding strategy within a competitive, partially\nobservable environment. The simulation explicitly incorporates institutional\nfrictions including broker intermediation, incumbent advantages, last-look\nprivileges, and asymmetric access to underwriting information.\n  Empirical analysis demonstrates that MARL agents achieve up to 15% higher\nunderwriting profit, 20% lower tail risk (CVaR), and over 25% improvement in\nSharpe ratios relative to actuarial and heuristic baselines. Sensitivity tests\nconfirm robustness across hyperparameter settings, and stress testing reveals\nstrong resilience under simulated catastrophe shocks and capital constraints.\n  These findings suggest that MARL offers a viable path toward more\ntransparent, adaptive, and risk-sensitive reinsurance markets. The proposed\nframework contributes to emerging literature at the intersection of algorithmic\nmarket design, strategic bidding, and AI-enabled financial decision-making.", "published": "2025-06-16 05:43:22", "link": "http://arxiv.org/abs/2506.13113v1", "categories": ["cs.AI", "econ.GN", "q-fin.EC"], "primary_category": "cs.AI"}
{"title": "Overcoming Overfitting in Reinforcement Learning via Gaussian Process Diffusion Policy", "abstract": "One of the key challenges that Reinforcement Learning (RL) faces is its\nlimited capability to adapt to a change of data distribution caused by\nuncertainties. This challenge arises especially in RL systems using deep neural\nnetworks as decision makers or policies, which are prone to overfitting after\nprolonged training on fixed environments. To address this challenge, this paper\nproposes Gaussian Process Diffusion Policy (GPDP), a new algorithm that\nintegrates diffusion models and Gaussian Process Regression (GPR) to represent\nthe policy. GPR guides diffusion models to generate actions that maximize\nlearned Q-function, resembling the policy improvement in RL. Furthermore, the\nkernel-based nature of GPR enhances the policy's exploration efficiency under\ndistribution shifts at test time, increasing the chance of discovering new\nbehaviors and mitigating overfitting. Simulation results on the Walker2d\nbenchmark show that our approach outperforms state-of-the-art algorithms under\ndistribution shift condition by achieving around 67.74% to 123.18% improvement\nin the RL's objective function while maintaining comparable performance under\nnormal conditions.", "published": "2025-06-16 05:41:06", "link": "http://arxiv.org/abs/2506.13111v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PF-LHM: 3D Animatable Avatar Reconstruction from Pose-free Articulated Human Images", "abstract": "Reconstructing an animatable 3D human from casually captured images of an\narticulated subject without camera or human pose information is a practical yet\nchallenging task due to view misalignment, occlusions, and the absence of\nstructural priors. While optimization-based methods can produce high-fidelity\nresults from monocular or multi-view videos, they require accurate pose\nestimation and slow iterative optimization, limiting scalability in\nunconstrained scenarios. Recent feed-forward approaches enable efficient\nsingle-image reconstruction but struggle to effectively leverage multiple input\nimages to reduce ambiguity and improve reconstruction accuracy. To address\nthese challenges, we propose PF-LHM, a large human reconstruction model that\ngenerates high-quality 3D avatars in seconds from one or multiple casually\ncaptured pose-free images. Our approach introduces an efficient Encoder-Decoder\nPoint-Image Transformer architecture, which fuses hierarchical geometric point\nfeatures and multi-view image features through multimodal attention. The fused\nfeatures are decoded to recover detailed geometry and appearance, represented\nusing 3D Gaussian splats. Extensive experiments on both real and synthetic\ndatasets demonstrate that our method unifies single- and multi-image 3D human\nreconstruction, achieving high-fidelity and animatable 3D human avatars without\nrequiring camera and human pose annotations. Code and models will be released\nto the public.", "published": "2025-06-16 17:59:56", "link": "http://arxiv.org/abs/2506.13766v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Touch begins where vision ends: Generalizable policies for contact-rich manipulation", "abstract": "Data-driven approaches struggle with precise manipulation; imitation learning\nrequires many hard-to-obtain demonstrations, while reinforcement learning\nyields brittle, non-generalizable policies. We introduce VisuoTactile Local\n(ViTaL) policy learning, a framework that solves fine-grained manipulation\ntasks by decomposing them into two phases: a reaching phase, where a\nvision-language model (VLM) enables scene-level reasoning to localize the\nobject of interest, and a local interaction phase, where a reusable,\nscene-agnostic ViTaL policy performs contact-rich manipulation using egocentric\nvision and tactile sensing. This approach is motivated by the observation that\nwhile scene context varies, the low-level interaction remains consistent across\ntask instances. By training local policies once in a canonical setting, they\ncan generalize via a localize-then-execute strategy. ViTaL achieves around 90%\nsuccess on contact-rich tasks in unseen environments and is robust to\ndistractors. ViTaL's effectiveness stems from three key insights: (1)\nfoundation models for segmentation enable training robust visual encoders via\nbehavior cloning; (2) these encoders improve the generalizability of policies\nlearned using residual RL; and (3) tactile sensing significantly boosts\nperformance in contact-rich tasks. Ablation studies validate each of these\ninsights, and we demonstrate that ViTaL integrates well with high-level VLMs,\nenabling robust, reusable low-level skills. Results and videos are available at\nhttps://vitalprecise.github.io.", "published": "2025-06-16 17:59:48", "link": "http://arxiv.org/abs/2506.13762v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning", "abstract": "Recent advancements in Vision-Language-Action (VLA) models have shown promise\nfor end-to-end autonomous driving by leveraging world knowledge and reasoning\ncapabilities. However, current VLA models often struggle with physically\ninfeasible action outputs, complex model structures, or unnecessarily long\nreasoning. In this paper, we propose AutoVLA, a novel VLA model that unifies\nreasoning and action generation within a single autoregressive generation model\nfor end-to-end autonomous driving. AutoVLA performs semantic reasoning and\ntrajectory planning directly from raw visual inputs and language instructions.\nWe tokenize continuous trajectories into discrete, feasible actions, enabling\ndirect integration into the language model. For training, we employ supervised\nfine-tuning to equip the model with dual thinking modes: fast thinking\n(trajectory-only) and slow thinking (enhanced with chain-of-thought reasoning).\nTo further enhance planning performance and efficiency, we introduce a\nreinforcement fine-tuning method based on Group Relative Policy Optimization\n(GRPO), reducing unnecessary reasoning in straightforward scenarios. Extensive\nexperiments across real-world and simulated datasets and benchmarks, including\nnuPlan, nuScenes, Waymo, and CARLA, demonstrate the competitive performance of\nAutoVLA in both open-loop and closed-loop settings. Qualitative results\nshowcase the adaptive reasoning and accurate planning capabilities of AutoVLA\nin diverse scenarios.", "published": "2025-06-16 17:58:50", "link": "http://arxiv.org/abs/2506.13757v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UltraZoom: Generating Gigapixel Images from Regular Photos", "abstract": "We present UltraZoom, a system for generating gigapixel-resolution images of\nobjects from casually captured inputs, such as handheld phone photos. Given a\nfull-shot image (global, low-detail) and one or more close-ups (local,\nhigh-detail), UltraZoom upscales the full image to match the fine detail and\nscale of the close-up examples. To achieve this, we construct a per-instance\npaired dataset from the close-ups and adapt a pretrained generative model to\nlearn object-specific low-to-high resolution mappings. At inference, we apply\nthe model in a sliding window fashion over the full image. Constructing these\npairs is non-trivial: it requires registering the close-ups within the full\nimage for scale estimation and degradation alignment. We introduce a simple,\nrobust method for getting registration on arbitrary materials in casual,\nin-the-wild captures. Together, these components form a system that enables\nseamless pan and zoom across the entire object, producing consistent,\nphotorealistic gigapixel imagery from minimal input.", "published": "2025-06-16 17:58:29", "link": "http://arxiv.org/abs/2506.13756v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Test3R: Learning to Reconstruct 3D at Test Time", "abstract": "Dense matching methods like DUSt3R regress pairwise pointmaps for 3D\nreconstruction. However, the reliance on pairwise prediction and the limited\ngeneralization capability inherently restrict the global geometric consistency.\nIn this work, we introduce Test3R, a surprisingly simple test-time learning\ntechnique that significantly boosts geometric accuracy. Using image triplets\n($I_1,I_2,I_3$), Test3R generates reconstructions from pairs ($I_1,I_2$) and\n($I_1,I_3$). The core idea is to optimize the network at test time via a\nself-supervised objective: maximizing the geometric consistency between these\ntwo reconstructions relative to the common image $I_1$. This ensures the model\nproduces cross-pair consistent outputs, regardless of the inputs. Extensive\nexperiments demonstrate that our technique significantly outperforms previous\nstate-of-the-art methods on the 3D reconstruction and multi-view depth\nestimation tasks. Moreover, it is universally applicable and nearly cost-free,\nmaking it easily applied to other models and implemented with minimal test-time\ntraining overhead and parameter footprint. Code is available at\nhttps://github.com/nopQAQ/Test3R.", "published": "2025-06-16 17:56:22", "link": "http://arxiv.org/abs/2506.13750v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "OTFusion: Bridging Vision-only and Vision-Language Models via Optimal Transport for Transductive Zero-Shot Learning", "abstract": "Transductive zero-shot learning (ZSL) aims to classify unseen categories by\nleveraging both semantic class descriptions and the distribution of unlabeled\ntest data. While Vision-Language Models (VLMs) such as CLIP excel at aligning\nvisual inputs with textual semantics, they often rely too heavily on\nclass-level priors and fail to capture fine-grained visual cues. In contrast,\nVision-only Foundation Models (VFMs) like DINOv2 provide rich perceptual\nfeatures but lack semantic alignment. To exploit the complementary strengths of\nthese models, we propose OTFusion, a simple yet effective training-free\nframework that bridges VLMs and VFMs via Optimal Transport. Specifically,\nOTFusion aims to learn a shared probabilistic representation that aligns visual\nand semantic information by minimizing the transport cost between their\nrespective distributions. This unified distribution enables coherent class\npredictions that are both semantically meaningful and visually grounded.\nExtensive experiments on 11 benchmark datasets demonstrate that OTFusion\nconsistently outperforms the original CLIP model, achieving an average accuracy\nimprovement of nearly $10\\%$, all without any fine-tuning or additional\nannotations. The code will be publicly released after the paper is accepted.", "published": "2025-06-16 17:27:47", "link": "http://arxiv.org/abs/2506.13723v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "How Real is CARLAs Dynamic Vision Sensor? A Study on the Sim-to-Real Gap in Traffic Object Detection", "abstract": "Event cameras are gaining traction in traffic monitoring applications due to\ntheir low latency, high temporal resolution, and energy efficiency, which makes\nthem well-suited for real-time object detection at traffic intersections.\nHowever, the development of robust event-based detection models is hindered by\nthe limited availability of annotated real-world datasets. To address this,\nseveral simulation tools have been developed to generate synthetic event data.\nAmong these, the CARLA driving simulator includes a built-in dynamic vision\nsensor (DVS) module that emulates event camera output. Despite its potential,\nthe sim-to-real gap for event-based object detection remains insufficiently\nstudied. In this work, we present a systematic evaluation of this gap by\ntraining a recurrent vision transformer model exclusively on synthetic data\ngenerated using CARLAs DVS and testing it on varying combinations of synthetic\nand real-world event streams. Our experiments show that models trained solely\non synthetic data perform well on synthetic-heavy test sets but suffer\nsignificant performance degradation as the proportion of real-world data\nincreases. In contrast, models trained on real-world data demonstrate stronger\ngeneralization across domains. This study offers the first quantifiable\nanalysis of the sim-to-real gap in event-based object detection using CARLAs\nDVS. Our findings highlight limitations in current DVS simulation fidelity and\nunderscore the need for improved domain adaptation techniques in neuromorphic\nvision for traffic monitoring.", "published": "2025-06-16 17:27:43", "link": "http://arxiv.org/abs/2506.13722v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vid-CamEdit: Video Camera Trajectory Editing with Generative Rendering from Estimated Geometry", "abstract": "We introduce Vid-CamEdit, a novel framework for video camera trajectory\nediting, enabling the re-synthesis of monocular videos along user-defined\ncamera paths. This task is challenging due to its ill-posed nature and the\nlimited multi-view video data for training. Traditional reconstruction methods\nstruggle with extreme trajectory changes, and existing generative models for\ndynamic novel view synthesis cannot handle in-the-wild videos. Our approach\nconsists of two steps: estimating temporally consistent geometry, and\ngenerative rendering guided by this geometry. By integrating geometric priors,\nthe generative model focuses on synthesizing realistic details where the\nestimated geometry is uncertain. We eliminate the need for extensive 4D\ntraining data through a factorized fine-tuning framework that separately trains\nspatial and temporal components using multi-view image and video data. Our\nmethod outperforms baselines in producing plausible videos from novel camera\ntrajectories, especially in extreme extrapolation scenarios on real-world\nfootage.", "published": "2025-06-16 17:02:47", "link": "http://arxiv.org/abs/2506.13697v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "UltraVideo: High-Quality UHD Video Dataset with Comprehensive Captions", "abstract": "The quality of the video dataset (image quality, resolution, and fine-grained\ncaption) greatly influences the performance of the video generation model. The\ngrowing demand for video applications sets higher requirements for high-quality\nvideo generation models. For example, the generation of movie-level Ultra-High\nDefinition (UHD) videos and the creation of 4K short video content. However,\nthe existing public datasets cannot support related research and applications.\nIn this paper, we first propose a high-quality open-sourced UHD-4K (22.4\\% of\nwhich are 8K) text-to-video dataset named UltraVideo, which contains a wide\nrange of topics (more than 100 kinds), and each video has 9 structured captions\nwith one summarized caption (average of 824 words). Specifically, we carefully\ndesign a highly automated curation process with four stages to obtain the final\nhigh-quality dataset: \\textit{i)} collection of diverse and high-quality video\nclips. \\textit{ii)} statistical data filtering. \\textit{iii)} model-based data\npurification. \\textit{iv)} generation of comprehensive, structured captions. In\naddition, we expand Wan to UltraWan-1K/-4K, which can natively generate\nhigh-quality 1K/4K videos with more consistent text controllability,\ndemonstrating the effectiveness of our data curation.We believe that this work\ncan make a significant contribution to future research on UHD video generation.\nUltraVideo dataset and UltraWan models are available at\nhttps://xzc-zju.github.io/projects/UltraVideo.", "published": "2025-06-16 16:52:52", "link": "http://arxiv.org/abs/2506.13691v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MultiViT2: A Data-augmented Multimodal Neuroimaging Prediction Framework via Latent Diffusion Model", "abstract": "Multimodal medical imaging integrates diverse data types, such as structural\nand functional neuroimaging, to provide complementary insights that enhance\ndeep learning predictions and improve outcomes. This study focuses on a\nneuroimaging prediction framework based on both structural and functional\nneuroimaging data. We propose a next-generation prediction model,\n\\textbf{MultiViT2}, which combines a pretrained representative learning base\nmodel with a vision transformer backbone for prediction output. Additionally,\nwe developed a data augmentation module based on the latent diffusion model\nthat enriches input data by generating augmented neuroimaging samples, thereby\nenhancing predictive performance through reduced overfitting and improved\ngeneralizability. We show that MultiViT2 significantly outperforms the\nfirst-generation model in schizophrenia classification accuracy and\ndemonstrates strong scalability and portability.", "published": "2025-06-16 16:25:13", "link": "http://arxiv.org/abs/2506.13667v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Lecture Video Visual Objects (LVVO) Dataset: A Benchmark for Visual Object Detection in Educational Videos", "abstract": "We introduce the Lecture Video Visual Objects (LVVO) dataset, a new benchmark\nfor visual object detection in educational video content. The dataset consists\nof 4,000 frames extracted from 245 lecture videos spanning biology, computer\nscience, and geosciences. A subset of 1,000 frames, referred to as LVVO_1k, has\nbeen manually annotated with bounding boxes for four visual categories: Table,\nChart-Graph, Photographic-image, and Visual-illustration. Each frame was\nlabeled independently by two annotators, resulting in an inter-annotator F1\nscore of 83.41%, indicating strong agreement. To ensure high-quality consensus\nannotations, a third expert reviewed and resolved all cases of disagreement\nthrough a conflict resolution process. To expand the dataset, a semi-supervised\napproach was employed to automatically annotate the remaining 3,000 frames,\nforming LVVO_3k. The complete dataset offers a valuable resource for developing\nand evaluating both supervised and semi-supervised methods for visual content\ndetection in educational videos. The LVVO dataset is publicly available to\nsupport further research in this domain.", "published": "2025-06-16 16:18:21", "link": "http://arxiv.org/abs/2506.13657v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "FreeQ-Graph: Free-form Querying with Semantic Consistent Scene Graph for 3D Scene Understanding", "abstract": "Semantic querying in complex 3D scenes through free-form language presents a\nsignificant challenge. Existing 3D scene understanding methods use large-scale\ntraining data and CLIP to align text queries with 3D semantic features.\nHowever, their reliance on predefined vocabulary priors from training data\nhinders free-form semantic querying. Besides, recent advanced methods rely on\nLLMs for scene understanding but lack comprehensive 3D scene-level information\nand often overlook the potential inconsistencies in LLM-generated outputs. In\nour paper, we propose FreeQ-Graph, which enables Free-form Querying with a\nsemantic consistent scene Graph for 3D scene understanding. The core idea is to\nencode free-form queries from a complete and accurate 3D scene graph without\npredefined vocabularies, and to align them with 3D consistent semantic labels,\nwhich accomplished through three key steps. We initiate by constructing a\ncomplete and accurate 3D scene graph that maps free-form objects and their\nrelations through LLM and LVLM guidance, entirely free from training data or\npredefined priors. Most importantly, we align graph nodes with accurate\nsemantic labels by leveraging 3D semantic aligned features from merged\nsuperpoints, enhancing 3D semantic consistency. To enable free-form semantic\nquerying, we then design an LLM-based reasoning algorithm that combines\nscene-level and object-level information to intricate reasoning. We conducted\nextensive experiments on 3D semantic grounding, segmentation, and complex\nquerying tasks, while also validating the accuracy of graph generation.\nExperiments on 6 datasets show that our model excels in both complex free-form\nsemantic queries and intricate relational reasoning.", "published": "2025-06-16 15:56:50", "link": "http://arxiv.org/abs/2506.13629v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Exploiting the Exact Denoising Posterior Score in Training-Free Guidance of Diffusion Models", "abstract": "The success of diffusion models has driven interest in performing conditional\nsampling via training-free guidance of the denoising process to solve image\nrestoration and other inverse problems. A popular class of methods, based on\nDiffusion Posterior Sampling (DPS), attempts to approximate the intractable\nposterior score function directly. In this work, we present a novel expression\nfor the exact posterior score for purely denoising tasks that is tractable in\nterms of the unconditional score function. We leverage this result to analyze\nthe time-dependent error in the DPS score for denoising tasks and compute step\nsizes on the fly to minimize the error at each time step. We demonstrate that\nthese step sizes are transferable to related inverse problems such as\ncolorization, random inpainting, and super resolution. Despite its simplicity,\nthis approach is competitive with state-of-the-art techniques and enables\nsampling with fewer time steps than DPS.", "published": "2025-06-16 15:43:28", "link": "http://arxiv.org/abs/2506.13614v1", "categories": ["stat.ML", "cs.CV", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Dive3D: Diverse Distillation-based Text-to-3D Generation via Score Implicit Matching", "abstract": "Distilling pre-trained 2D diffusion models into 3D assets has driven\nremarkable advances in text-to-3D synthesis. However, existing methods\ntypically rely on Score Distillation Sampling (SDS) loss, which involves\nasymmetric KL divergence--a formulation that inherently favors mode-seeking\nbehavior and limits generation diversity. In this paper, we introduce Dive3D, a\nnovel text-to-3D generation framework that replaces KL-based objectives with\nScore Implicit Matching (SIM) loss, a score-based objective that effectively\nmitigates mode collapse. Furthermore, Dive3D integrates both diffusion\ndistillation and reward-guided optimization under a unified divergence\nperspective. Such reformulation, together with SIM loss, yields significantly\nmore diverse 3D outputs while improving text alignment, human preference, and\noverall visual fidelity. We validate Dive3D across various 2D-to-3D prompts and\nfind that it consistently outperforms prior methods in qualitative assessments,\nincluding diversity, photorealism, and aesthetic appeal. We further evaluate\nits performance on the GPTEval3D benchmark, comparing against nine\nstate-of-the-art baselines. Dive3D also achieves strong results on quantitative\nmetrics, including text-asset alignment, 3D plausibility, text-geometry\nconsistency, texture quality, and geometric detail.", "published": "2025-06-16 15:21:30", "link": "http://arxiv.org/abs/2506.13594v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Omni-AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented for Efficient Long Video Understanding", "abstract": "Multimodal Large Language Models (MLLMs) struggle with long videos due to\nfixed context windows and weak long-term dependency modeling. Existing\nRetrieval-Augmented Generation (RAG) methods for videos use static retrieval\nstrategies, leading to inefficiencies for simple queries and information loss\nfor complex tasks. To address this, we propose AdaVideoRAG, a novel framework\nthat dynamically adapts retrieval granularity based on query complexity using a\nlightweight intent classifier. Our framework employs an Omni-Knowledge Indexing\nmodule to build hierarchical databases from text (captions, ASR, OCR), visual\nfeatures, and semantic graphs, enabling optimal resource allocation across\ntasks. We also introduce the HiVU benchmark for comprehensive evaluation.\nExperiments demonstrate improved efficiency and accuracy for long-video\nunderstanding, with seamless integration into existing MLLMs. AdaVideoRAG\nestablishes a new paradigm for adaptive retrieval in video analysis. Codes will\nbe open-sourced at https://github.com/xzc-zju/AdaVideoRAG.", "published": "2025-06-16 15:18:15", "link": "http://arxiv.org/abs/2506.13589v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Integrated Pipeline for Monocular 3D Reconstruction and Finite Element Simulation in Industrial Applications", "abstract": "To address the challenges of 3D modeling and structural simulation in\nindustrial environment, such as the difficulty of equipment deployment, and the\ndifficulty of balancing accuracy and real-time performance, this paper proposes\nan integrated workflow, which integrates high-fidelity 3D reconstruction based\non monocular video, finite element simulation analysis, and mixed reality\nvisual display, aiming to build an interactive digital twin system for\nindustrial inspection, equipment maintenance and other scenes. Firstly, the\nNeuralangelo algorithm based on deep learning is used to reconstruct the 3D\nmesh model with rich details from the surround-shot video. Then, the QuadRemesh\ntool of Rhino is used to optimize the initial triangular mesh and generate a\nstructured mesh suitable for finite element analysis. The optimized mesh is\nfurther discretized by HyperMesh, and the material parameter setting and stress\nsimulation are carried out in Abaqus to obtain high-precision stress and\ndeformation results. Finally, combined with Unity and Vuforia engine, the\nreal-time superposition and interactive operation of simulation results in the\naugmented reality environment are realized, which improves users 'intuitive\nunderstanding of structural response. Experiments show that the method has good\nsimulation efficiency and visualization effect while maintaining high geometric\naccuracy. It provides a practical solution for digital modeling, mechanical\nanalysis and interactive display in complex industrial scenes, and lays a\nfoundation for the deep integration of digital twin and mixed reality\ntechnology in industrial applications.", "published": "2025-06-16 14:57:05", "link": "http://arxiv.org/abs/2506.13573v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MambaMia: A State-Space-Model-Based Compression for Efficient Video Understanding in Large Multimodal Models", "abstract": "We propose an efficient framework to compress multiple video-frame features\nbefore feeding them into large multimodal models, thereby mitigating the severe\ntoken explosion arising from long or dense videos. Our design leverages a\nbidirectional state-space-based block equipped with a gated skip connection and\na learnable weighted-average pooling mechanism applied to periodically inserted\nlearned queries. This structure enables hierarchical downsampling across both\nspatial and temporal dimensions, preserving performance in a cost-effective\nmanner. Across challenging long and dense video understanding tasks, our\napproach demonstrates competitive results against state-of-the-art models,\nwhile significantly reducing overall token budget. Notably, replacing our\nproposed state-space block with a conventional Transformer results in\nsubstantial performance degradation, highlighting the advantages of state-space\nmodeling for effectively compressing multi-frame video data. Our framework\nemphasizes resource-conscious efficiency, making it practical for real-world\ndeployments. We validate its scalability and generality across multiple\nbenchmarks, achieving the dual objectives of efficient resource usage and\ncomprehensive video understanding.", "published": "2025-06-16 14:49:49", "link": "http://arxiv.org/abs/2506.13564v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "X-Scene: Large-Scale Driving Scene Generation with High Fidelity and Flexible Controllability", "abstract": "Diffusion models are advancing autonomous driving by enabling realistic data\nsynthesis, predictive end-to-end planning, and closed-loop simulation, with a\nprimary focus on temporally consistent generation. However, the generation of\nlarge-scale 3D scenes that require spatial coherence remains underexplored. In\nthis paper, we propose X-Scene, a novel framework for large-scale driving scene\ngeneration that achieves both geometric intricacy and appearance fidelity,\nwhile offering flexible controllability. Specifically, X-Scene supports\nmulti-granular control, including low-level conditions such as user-provided or\ntext-driven layout for detailed scene composition and high-level semantic\nguidance such as user-intent and LLM-enriched text prompts for efficient\ncustomization. To enhance geometrical and visual fidelity, we introduce a\nunified pipeline that sequentially generates 3D semantic occupancy and the\ncorresponding multiview images, while ensuring alignment between modalities.\nAdditionally, we extend the generated local region into a large-scale scene\nthrough consistency-aware scene outpainting, which extrapolates new occupancy\nand images conditioned on the previously generated area, enhancing spatial\ncontinuity and preserving visual coherence. The resulting scenes are lifted\ninto high-quality 3DGS representations, supporting diverse applications such as\nscene exploration. Comprehensive experiments demonstrate that X-Scene\nsignificantly advances controllability and fidelity for large-scale driving\nscene generation, empowering data generation and simulation for autonomous\ndriving.", "published": "2025-06-16 14:43:18", "link": "http://arxiv.org/abs/2506.13558v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RelTopo: Enhancing Relational Modeling for Driving Scene Topology Reasoning", "abstract": "Accurate road topology reasoning is critical for autonomous driving, enabling\neffective navigation and adherence to traffic regulations. Central to this task\nare lane perception and topology reasoning. However, existing methods typically\nfocus on either lane detection or Lane-to-Lane (L2L) topology reasoning, often\n\\textit{neglecting} Lane-to-Traffic-element (L2T) relationships or\n\\textit{failing} to optimize these tasks jointly. Furthermore, most approaches\neither overlook relational modeling or apply it in a limited scope, despite the\ninherent spatial relationships among road elements. We argue that relational\nmodeling is beneficial for both perception and reasoning, as humans naturally\nleverage contextual relationships for road element recognition and their\nconnectivity inference. To this end, we introduce relational modeling into both\nperception and reasoning, \\textit{jointly} enhancing structural understanding.\nSpecifically, we propose: 1) a relation-aware lane detector, where our\ngeometry-biased self-attention and \\curve\\ cross-attention refine lane\nrepresentations by capturing relational dependencies; 2) relation-enhanced\ntopology heads, including a geometry-enhanced L2L head and a cross-view L2T\nhead, boosting reasoning with relational cues; and 3) a contrastive learning\nstrategy with InfoNCE loss to regularize relationship embeddings. Extensive\nexperiments on OpenLane-V2 demonstrate that our approach significantly improves\nboth detection and topology reasoning metrics, achieving +3.1 in DET$_l$, +5.3\nin TOP$_{ll}$, +4.9 in TOP$_{lt}$, and an overall +4.4 in OLS, setting a new\nstate-of-the-art. Code will be released.", "published": "2025-06-16 14:40:28", "link": "http://arxiv.org/abs/2506.13553v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Comprehensive Survey on Video Scene Parsing:Advances, Challenges, and Prospects", "abstract": "Video Scene Parsing (VSP) has emerged as a cornerstone in computer vision,\nfacilitating the simultaneous segmentation, recognition, and tracking of\ndiverse visual entities in dynamic scenes. In this survey, we present a\nholistic review of recent advances in VSP, covering a wide array of vision\ntasks, including Video Semantic Segmentation (VSS), Video Instance Segmentation\n(VIS), Video Panoptic Segmentation (VPS), as well as Video Tracking and\nSegmentation (VTS), and Open-Vocabulary Video Segmentation (OVVS). We\nsystematically analyze the evolution from traditional hand-crafted features to\nmodern deep learning paradigms -- spanning from fully convolutional networks to\nthe latest transformer-based architectures -- and assess their effectiveness in\ncapturing both local and global temporal contexts. Furthermore, our review\ncritically discusses the technical challenges, ranging from maintaining\ntemporal consistency to handling complex scene dynamics, and offers a\ncomprehensive comparative study of datasets and evaluation metrics that have\nshaped current benchmarking standards. By distilling the key contributions and\nshortcomings of state-of-the-art methodologies, this survey highlights emerging\ntrends and prospective research directions that promise to further elevate the\nrobustness and adaptability of VSP in real-world applications.", "published": "2025-06-16 14:39:03", "link": "http://arxiv.org/abs/2506.13552v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Limited-Angle CBCT Reconstruction via Geometry-Integrated Cycle-domain Denoising Diffusion Probabilistic Models", "abstract": "Cone-beam CT (CBCT) is widely used in clinical radiotherapy for image-guided\ntreatment, improving setup accuracy, adaptive planning, and motion management.\nHowever, slow gantry rotation limits performance by introducing motion\nartifacts, blurring, and increased dose. This work aims to develop a clinically\nfeasible method for reconstructing high-quality CBCT volumes from consecutive\nlimited-angle acquisitions, addressing imaging challenges in time- or\ndose-constrained settings. We propose a limited-angle (LA) geometry-integrated\ncycle-domain (LA-GICD) framework for CBCT reconstruction, comprising two\ndenoising diffusion probabilistic models (DDPMs) connected via analytic\ncone-beam forward and back projectors. A Projection-DDPM completes missing\nprojections, followed by back-projection, and an Image-DDPM refines the volume.\nThis dual-domain design leverages complementary priors from projection and\nimage spaces to achieve high-quality reconstructions from limited-angle (<= 90\ndegrees) scans. Performance was evaluated against full-angle reconstruction.\nFour board-certified medical physicists conducted assessments. A total of 78\nplanning CTs in common CBCT geometries were used for training and evaluation.\nThe method achieved a mean absolute error of 35.5 HU, SSIM of 0.84, and PSNR of\n29.8 dB, with visibly reduced artifacts and improved soft-tissue clarity.\nLA-GICD's geometry-aware dual-domain learning, embedded in analytic\nforward/backward operators, enabled artifact-free, high-contrast\nreconstructions from a single 90-degree scan, reducing acquisition time and\ndose four-fold. LA-GICD improves limited-angle CBCT reconstruction with strong\ndata fidelity and anatomical realism. It offers a practical solution for\nshort-arc acquisitions, enhancing CBCT use in radiotherapy by providing\nclinically applicable images with reduced scan time and dose for more accurate,\npersonalized treatments.", "published": "2025-06-16 14:32:16", "link": "http://arxiv.org/abs/2506.13545v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Atomizer: Generalizing to new modalities by breaking satellite images down to a set of scalars", "abstract": "The growing number of Earth observation satellites has led to increasingly\ndiverse remote sensing data, with varying spatial, spectral, and temporal\nconfigurations. Most existing models rely on fixed input formats and\nmodality-specific encoders, which require retraining when new configurations\nare introduced, limiting their ability to generalize across modalities. We\nintroduce Atomizer, a flexible architecture that represents remote sensing\nimages as sets of scalars, each corresponding to a spectral band value of a\npixel. Each scalar is enriched with contextual metadata (acquisition time,\nspatial resolution, wavelength, and bandwidth), producing an atomic\nrepresentation that allows a single encoder to process arbitrary modalities\nwithout interpolation or resampling. Atomizer uses structured tokenization with\nFourier features and non-uniform radial basis functions to encode content and\ncontext, and maps tokens into a latent space via cross-attention. Under\nmodality-disjoint evaluations, Atomizer outperforms standard models and\ndemonstrates robust performance across varying resolutions and spatial sizes.", "published": "2025-06-16 14:30:37", "link": "http://arxiv.org/abs/2506.13542v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Micro-macro Gaussian Splatting with Enhanced Scalability for Unconstrained Scene Reconstruction", "abstract": "Reconstructing 3D scenes from unconstrained image collections poses\nsignificant challenges due to variations in appearance. In this paper, we\npropose Scalable Micro-macro Wavelet-based Gaussian Splatting (SMW-GS), a novel\nmethod that enhances 3D reconstruction across diverse scales by decomposing\nscene representations into global, refined, and intrinsic components. SMW-GS\nincorporates the following innovations: Micro-macro Projection, which enables\nGaussian points to sample multi-scale details with improved diversity; and\nWavelet-based Sampling, which refines feature representations using\nfrequency-domain information to better capture complex scene appearances. To\nachieve scalability, we further propose a large-scale scene promotion strategy,\nwhich optimally assigns camera views to scene partitions by maximizing their\ncontributions to Gaussian points, achieving consistent and high-quality\nreconstructions even in expansive environments. Extensive experiments\ndemonstrate that SMW-GS significantly outperforms existing methods in both\nreconstruction quality and scalability, particularly excelling in large-scale\nurban environments with challenging illumination variations. Project is\navailable at https://github.com/Kidleyh/SMW-GS.", "published": "2025-06-16 14:11:13", "link": "http://arxiv.org/abs/2506.13516v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Semantically-Aware Relevance Measure for Content-Based Medical Image Retrieval Evaluation", "abstract": "Performance evaluation for Content-Based Image Retrieval (CBIR) remains a\ncrucial but unsolved problem today especially in the medical domain. Various\nevaluation metrics have been discussed in the literature to solve this problem.\nMost of the existing metrics (e.g., precision, recall) are adapted from\nclassification tasks which require manual labels as ground truth. However, such\nlabels are often expensive and unavailable in specific thematic domains.\nFurthermore, medical images are usually associated with (radiological) case\nreports or annotated with descriptive captions in literature figures, such text\ncontains information that can help to assess CBIR.Several researchers have\nargued that the medical concepts hidden in the text can serve as the basis for\nCBIR evaluation purpose. However, these works often consider these medical\nconcepts as independent and isolated labels while in fact the subtle\nrelationships between various concepts are neglected. In this work, we\nintroduce the use of knowledge graphs to measure the distance between various\nmedical concepts and propose a novel relevance measure for the evaluation of\nCBIR by defining an approximate matching-based relevance score between two sets\nof medical concepts which allows us to indirectly measure the similarity\nbetween medical images.We quantitatively demonstrate the effectiveness and\nfeasibility of our relevance measure using a public dataset.", "published": "2025-06-16 14:04:48", "link": "http://arxiv.org/abs/2506.13509v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multiview Geometric Regularization of Gaussian Splatting for Accurate Radiance Fields", "abstract": "Recent methods, such as 2D Gaussian Splatting and Gaussian Opacity Fields,\nhave aimed to address the geometric inaccuracies of 3D Gaussian Splatting while\nretaining its superior rendering quality. However, these approaches still\nstruggle to reconstruct smooth and reliable geometry, particularly in scenes\nwith significant color variation across viewpoints, due to their per-point\nappearance modeling and single-view optimization constraints. In this paper, we\npropose an effective multiview geometric regularization strategy that\nintegrates multiview stereo (MVS) depth, RGB, and normal constraints into\nGaussian Splatting initialization and optimization. Our key insight is the\ncomplementary relationship between MVS-derived depth points and Gaussian\nSplatting-optimized positions: MVS robustly estimates geometry in regions of\nhigh color variation through local patch-based matching and epipolar\nconstraints, whereas Gaussian Splatting provides more reliable and less noisy\ndepth estimates near object boundaries and regions with lower color variation.\nTo leverage this insight, we introduce a median depth-based multiview relative\ndepth loss with uncertainty estimation, effectively integrating MVS depth\ninformation into Gaussian Splatting optimization. We also propose an MVS-guided\nGaussian Splatting initialization to avoid Gaussians falling into suboptimal\npositions. Extensive experiments validate that our approach successfully\ncombines these strengths, enhancing both geometric accuracy and rendering\nquality across diverse indoor and outdoor scenes.", "published": "2025-06-16 14:02:46", "link": "http://arxiv.org/abs/2506.13508v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Stimulus Motion Perception Studies Imply Specific Neural Computations in Human Visual Stabilization", "abstract": "Even during fixation the human eye is constantly in low amplitude motion,\njittering over small angles in random directions at up to 100Hz. This motion\nresults in all features of the image on the retina constantly traversing a\nnumber of cones, yet objects which are stable in the world are perceived to be\nstable, and any object which is moving in the world is perceived to be moving.\nA series of experiments carried out over a dozen years revealed the\npsychophysics of visual stabilization to be more nuanced than might be assumed,\nsay, from the mechanics of stabilization of camera images, or what might be\nassumed to be the simplest solution from an evolutionary perspective. The\npsychophysics revealed by the experiments strongly implies a specific set of\noperations on retinal signals resulting in the observed stabilization behavior.\nThe presentation is in two levels. First is a functional description of the\naction of the mechanism that is very likely responsible for the experimentally\nobserved behavior. Second is a more speculative proposal of circuit-level\nneural elements that might implement the functional behavior.", "published": "2025-06-16 14:00:49", "link": "http://arxiv.org/abs/2506.13506v1", "categories": ["cs.CV", "q-bio.NC"], "primary_category": "cs.CV"}
{"title": "FOAM: A General Frequency-Optimized Anti-Overlapping Framework for Overlapping Object Perception", "abstract": "Overlapping object perception aims to decouple the randomly overlapping\nforeground-background features, extracting foreground features while\nsuppressing background features, which holds significant application value in\nfields such as security screening and medical auxiliary diagnosis. Despite some\nresearch efforts to tackle the challenge of overlapping object perception, most\nsolutions are confined to the spatial domain. Through frequency domain\nanalysis, we observe that the degradation of contours and textures due to the\noverlapping phenomenon can be intuitively reflected in the magnitude spectrum.\nBased on this observation, we propose a general Frequency-Optimized\nAnti-Overlapping Framework (FOAM) to assist the model in extracting more\ntexture and contour information, thereby enhancing the ability for\nanti-overlapping object perception. Specifically, we design the Frequency\nSpatial Transformer Block (FSTB), which can simultaneously extract features\nfrom both the frequency and spatial domains, helping the network capture more\ntexture features from the foreground. In addition, we introduce the\nHierarchical De-Corrupting (HDC) mechanism, which aligns adjacent features in\nthe separately constructed base branch and corruption branch using a specially\ndesigned consistent loss during the training phase. This mechanism suppresses\nthe response to irrelevant background features of FSTBs, thereby improving the\nperception of foreground contour. We conduct extensive experiments to validate\nthe effectiveness and generalization of the proposed FOAM, which further\nimproves the accuracy of state-of-the-art models on four datasets, specifically\nfor the three overlapping object perception tasks: Prohibited Item Detection,\nProhibited Item Segmentation, and Pneumonia Detection. The code will be open\nsource once the paper is accepted.", "published": "2025-06-16 13:58:49", "link": "http://arxiv.org/abs/2506.13501v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval", "abstract": "Patent images are technical drawings that convey information about a patent's\ninnovation. Patent image retrieval systems aim to search in vast collections\nand retrieve the most relevant images. Despite recent advances in information\nretrieval, patent images still pose significant challenges due to their\ntechnical intricacies and complex semantic information, requiring efficient\nfine-tuning for domain adaptation. Current methods neglect patents'\nhierarchical relationships, such as those defined by the Locarno International\nClassification (LIC) system, which groups broad categories (e.g., \"furnishing\")\ninto subclasses (e.g., \"seats\" and \"beds\") and further into specific patent\ndesigns. In this work, we introduce a hierarchical multi-positive contrastive\nloss that leverages the LIC's taxonomy to induce such relations in the\nretrieval process. Our approach assigns multiple positive pairs to each patent\nimage within a batch, with varying similarity scores based on the hierarchical\ntaxonomy. Our experimental analysis with various vision and multimodal models\non the DeepPatent2 dataset shows that the proposed method enhances the\nretrieval results. Notably, our method is effective with low-parameter models,\nwhich require fewer computational resources and can be deployed on environments\nwith limited hardware.", "published": "2025-06-16 13:53:02", "link": "http://arxiv.org/abs/2506.13496v1", "categories": ["cs.CV", "cs.IR", "cs.LG", "68T45, 68T07", "H.3.3; I.4.10; I.2.10"], "primary_category": "cs.CV"}
{"title": "GeoSDF: Plane Geometry Diagram Synthesis via Signed Distance Field", "abstract": "Plane Geometry Diagram Synthesis has been a crucial task in computer\ngraphics, with applications ranging from educational tools to AI-driven\nmathematical reasoning. Traditionally, we rely on computer tools (e.g.,\nMatplotlib and GeoGebra) to manually generate precise diagrams, but it usually\nrequires huge, complicated calculations cost. Recently, researchers start to\nwork on learning-based methods (e.g., Stable Diffusion and GPT4) to\nautomatically generate diagrams, saving operational cost but usually suffering\nfrom limited realism and insufficient accuracy. In this paper, we propose a\nnovel framework GeoSDF to automatically generate diagrams efficiently and\naccurately with Signed Distance Field (SDF). Specifically, we first represent\ngeometric elements in the SDF, then construct a series of constraint functions\nto represent geometric relationships, next we optimize such constraint\nfunctions to get an optimized field of both elements and constraints, finally\nby rendering the optimized field, we can obtain the synthesized diagram. In our\nGeoSDF, we define a symbolic language to easily represent geometric elements\nand those constraints, and our synthesized geometry diagrams can be\nself-verified in the SDF, ensuring both mathematical accuracy and visual\nplausibility. In experiments, our GeoSDF synthesized both normal high-school\nlevel and IMO-level geometry diagrams. Through both qualitative and\nquantitative analysis, we can see that synthesized diagrams are realistic and\naccurate, and our synthesizing process is simple and efficient. Furthermore, we\nobtain a very high accuracy of solving geometry problems (over 95\\% while the\ncurrent SOTA accuracy is around 75%) by leveraging our self-verification\nproperty. All of these demonstrate the advantage of GeoSDF, paving the way for\nmore sophisticated, accurate, and flexible generation of geometric diagrams for\na wide array of applications.", "published": "2025-06-16 13:50:55", "link": "http://arxiv.org/abs/2506.13492v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Deep Diffusion Models and Unsupervised Hyperspectral Unmixing for Realistic Abundance Map Synthesis", "abstract": "This paper presents a novel methodology for generating realistic abundance\nmaps from hyperspectral imagery using an unsupervised, deep-learning-driven\napproach. Our framework integrates blind linear hyperspectral unmixing with\nstate-of-the-art diffusion models to enhance the realism and diversity of\nsynthetic abundance maps. First, we apply blind unmixing to extract endmembers\nand abundance maps directly from raw hyperspectral data. These abundance maps\nthen serve as inputs to a diffusion model, which acts as a generative engine to\nsynthesize highly realistic spatial distributions. Diffusion models have\nrecently revolutionized image synthesis by offering superior performance,\nflexibility, and stability, making them well-suited for high-dimensional\nspectral data. By leveraging this combination of physically interpretable\nunmixing and deep generative modeling, our approach enables the simulation of\nhyperspectral sensor outputs under diverse imaging conditions--critical for\ndata augmentation, algorithm benchmarking, and model evaluation in\nhyperspectral analysis. Notably, our method is entirely unsupervised, ensuring\nadaptability to different datasets without the need for labeled training data.\nWe validate our approach using real hyperspectral imagery from the PRISMA space\nmission for Earth observation, demonstrating its effectiveness in producing\nrealistic synthetic abundance maps that capture the spatial and spectral\ncharacteristics of natural scenes.", "published": "2025-06-16 13:42:51", "link": "http://arxiv.org/abs/2506.13484v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "From Flat to Feeling: A Feasibility and Impact Study on Dynamic Facial Emotions in AI-Generated Avatars", "abstract": "Dynamic facial emotion is essential for believable AI-generated avatars;\nhowever, most systems remain visually inert, limiting their utility in\nhigh-stakes simulations such as virtual training for investigative interviews\nwith abused children. We introduce and evaluate a real-time architecture fusing\nUnreal Engine 5 MetaHuman rendering with NVIDIA Omniverse Audio2Face to\ntranslate vocal prosody into high-fidelity facial expressions on photorealistic\nchild avatars. We implemented a distributed two-PC setup that decouples\nlanguage processing and speech synthesis from GPU-intensive rendering, designed\nto support low-latency interaction in desktop and VR environments. A\nbetween-subjects study ($N=70$) using audio+visual and visual-only conditions\nassessed perceptual impacts as participants rated emotional clarity, facial\nrealism, and empathy for two avatars expressing joy, sadness, and anger.\n  Results demonstrate that avatars could express emotions recognizably, with\nsadness and joy achieving high identification rates. However, anger recognition\nsignificantly dropped without audio, highlighting the importance of congruent\nvocal cues for high-arousal emotions. Interestingly, removing audio boosted\nperceived facial realism, suggesting that audiovisual desynchrony remains a key\ndesign challenge. These findings confirm the technical feasibility of\ngenerating emotionally expressive avatars and provide guidance for improving\nnon-verbal communication in sensitive training simulations.", "published": "2025-06-16 13:34:36", "link": "http://arxiv.org/abs/2506.13477v1", "categories": ["cs.HC", "cs.CV", "68T07, 68U99, 68T45, 91E45"], "primary_category": "cs.HC"}
{"title": "SA-LUT: Spatial Adaptive 4D Look-Up Table for Photorealistic Style Transfer", "abstract": "Photorealistic style transfer (PST) enables real-world color grading by\nadapting reference image colors while preserving content structure. Existing\nmethods mainly follow either approaches: generation-based methods that\nprioritize stylistic fidelity at the cost of content integrity and efficiency,\nor global color transformation methods such as LUT, which preserve structure\nbut lack local adaptability. To bridge this gap, we propose Spatial Adaptive 4D\nLook-Up Table (SA-LUT), combining LUT efficiency with neural network\nadaptability. SA-LUT features: (1) a Style-guided 4D LUT Generator that\nextracts multi-scale features from the style image to predict a 4D LUT, and (2)\na Context Generator using content-style cross-attention to produce a context\nmap. This context map enables spatially-adaptive adjustments, allowing our 4D\nLUT to apply precise color transformations while preserving structural\nintegrity. To establish a rigorous evaluation framework for photorealistic\nstyle transfer, we introduce PST50, the first benchmark specifically designed\nfor PST assessment. Experiments demonstrate that SA-LUT substantially\noutperforms state-of-the-art methods, achieving a 66.7% reduction in LPIPS\nscore compared to 3D LUT approaches, while maintaining real-time performance at\n16 FPS for video stylization. Our code and benchmark are available at\nhttps://github.com/Ry3nG/SA-LUT", "published": "2025-06-16 13:25:12", "link": "http://arxiv.org/abs/2506.13465v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Deep Learning-Based Multi-Object Tracking: A Comprehensive Survey from Foundations to State-of-the-Art", "abstract": "Multi-object tracking (MOT) is a core task in computer vision that involves\ndetecting objects in video frames and associating them across time. The rise of\ndeep learning has significantly advanced MOT, particularly within the\ntracking-by-detection paradigm, which remains the dominant approach.\nAdvancements in modern deep learning-based methods accelerated in 2022 with the\nintroduction of ByteTrack for tracking-by-detection and MOTR for end-to-end\ntracking. Our survey provides an in-depth analysis of deep learning-based MOT\nmethods, systematically categorizing tracking-by-detection approaches into five\ngroups: joint detection and embedding, heuristic-based, motion-based, affinity\nlearning, and offline methods. In addition, we examine end-to-end tracking\nmethods and compare them with existing alternative approaches. We evaluate the\nperformance of recent trackers across multiple benchmarks and specifically\nassess their generality by comparing results across different domains. Our\nfindings indicate that heuristic-based methods achieve state-of-the-art results\non densely populated datasets with linear object motion, while deep\nlearning-based association methods, in both tracking-by-detection and\nend-to-end approaches, excel in scenarios with complex motion patterns.", "published": "2025-06-16 13:15:01", "link": "http://arxiv.org/abs/2506.13457v1", "categories": ["cs.CV", "68T45, 94A08, 68W40, 62H35", "I.4.8; I.5.1; I.2.10; I.5.4"], "primary_category": "cs.CV"}
{"title": "Overcoming Occlusions in the Wild: A Multi-Task Age Head Approach to Age Estimation", "abstract": "Facial age estimation has achieved considerable success under controlled\nconditions. However, in unconstrained real-world scenarios, which are often\nreferred to as 'in the wild', age estimation remains challenging, especially\nwhen faces are partially occluded, which may obscure their visibility. To\naddress this limitation, we propose a new approach integrating generative\nadversarial networks (GANs) and transformer architectures to enable robust age\nestimation from occluded faces. We employ an SN-Patch GAN to effectively remove\nocclusions, while an Attentive Residual Convolution Module (ARCM), paired with\na Swin Transformer, enhances feature representation. Additionally, we introduce\na Multi-Task Age Head (MTAH) that combines regression and distribution\nlearning, further improving age estimation under occlusion. Experimental\nresults on the FG-NET, UTKFace, and MORPH datasets demonstrate that our\nproposed approach surpasses existing state-of-the-art techniques for occluded\nfacial age estimation by achieving an MAE of $3.00$, $4.54$, and $2.53$ years,\nrespectively.", "published": "2025-06-16 13:00:05", "link": "http://arxiv.org/abs/2506.13445v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Self-Supervised Enhancement for Depth from a Lightweight ToF Sensor with Monocular Images", "abstract": "Depth map enhancement using paired high-resolution RGB images offers a\ncost-effective solution for improving low-resolution depth data from\nlightweight ToF sensors. Nevertheless, naively adopting a depth estimation\npipeline to fuse the two modalities requires groundtruth depth maps for\nsupervision. To address this, we propose a self-supervised learning framework,\nSelfToF, which generates detailed and scale-aware depth maps. Starting from an\nimage-based self-supervised depth estimation pipeline, we add low-resolution\ndepth as inputs, design a new depth consistency loss, propose a scale-recovery\nmodule, and finally obtain a large performance boost. Furthermore, since the\nToF signal sparsity varies in real-world applications, we upgrade SelfToF to\nSelfToF* with submanifold convolution and guided feature fusion. Consequently,\nSelfToF* maintain robust performance across varying sparsity levels in ToF\ndata. Overall, our proposed method is both efficient and effective, as verified\nby extensive experiments on the NYU and ScanNet datasets. The code will be made\npublic.", "published": "2025-06-16 12:57:58", "link": "http://arxiv.org/abs/2506.13444v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PRO: Projection Domain Synthesis for CT Imaging", "abstract": "Synthesizing high quality CT images remains a signifi-cant challenge due to\nthe limited availability of annotat-ed data and the complex nature of CT\nimaging. In this work, we present PRO, a novel framework that, to the best of\nour knowledge, is the first to perform CT image synthesis in the projection\ndomain using latent diffusion models. Unlike previous approaches that operate\nin the image domain, PRO learns rich structural representa-tions from raw\nprojection data and leverages anatomi-cal text prompts for controllable\nsynthesis. This projec-tion domain strategy enables more faithful modeling of\nunderlying imaging physics and anatomical structures. Moreover, PRO functions\nas a foundation model, capa-ble of generalizing across diverse downstream tasks\nby adjusting its generative behavior via prompt inputs. Experimental results\ndemonstrated that incorporating our synthesized data significantly improves\nperfor-mance across multiple downstream tasks, including low-dose and\nsparse-view reconstruction, even with limited training data. These findings\nunderscore the versatility and scalability of PRO in data generation for\nvarious CT applications. These results highlight the potential of projection\ndomain synthesis as a powerful tool for data augmentation and robust CT\nimaging. Our source code is publicly available at:\nhttps://github.com/yqx7150/PRO.", "published": "2025-06-16 12:57:29", "link": "http://arxiv.org/abs/2506.13443v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Sparse Convolutional Recurrent Learning for Efficient Event-based Neuromorphic Object Detection", "abstract": "Leveraging the high temporal resolution and dynamic range, object detection\nwith event cameras can enhance the performance and safety of automotive and\nrobotics applications in real-world scenarios. However, processing sparse event\ndata requires compute-intensive convolutional recurrent units, complicating\ntheir integration into resource-constrained edge applications. Here, we propose\nthe Sparse Event-based Efficient Detector (SEED) for efficient event-based\nobject detection on neuromorphic processors. We introduce sparse convolutional\nrecurrent learning, which achieves over 92% activation sparsity in recurrent\nprocessing, vastly reducing the cost for spatiotemporal reasoning on sparse\nevent data. We validated our method on Prophesee's 1 Mpx and Gen1 event-based\nobject detection datasets. Notably, SEED sets a new benchmark in computational\nefficiency for event-based object detection which requires long-term temporal\nlearning. Compared to state-of-the-art methods, SEED significantly reduces\nsynaptic operations while delivering higher or same-level mAP. Our hardware\nsimulations showcase the critical role of SEED's hardware-aware design in\nachieving energy-efficient and low-latency neuromorphic processing.", "published": "2025-06-16 12:54:27", "link": "http://arxiv.org/abs/2506.13440v1", "categories": ["cs.CV", "cs.NE"], "primary_category": "cs.CV"}
{"title": "Uncertainty-Aware Remaining Lifespan Prediction from Images", "abstract": "Predicting mortality-related outcomes from images offers the prospect of\naccessible, noninvasive, and scalable health screening. We present a method\nthat leverages pretrained vision transformer foundation models to estimate\nremaining lifespan from facial and whole-body images, alongside robust\nuncertainty quantification. We show that predictive uncertainty varies\nsystematically with the true remaining lifespan, and that this uncertainty can\nbe effectively modeled by learning a Gaussian distribution for each sample. Our\napproach achieves state-of-the-art mean absolute error (MAE) of 7.48 years on\nan established Dataset, and further improves to 4.79 and 5.07 years MAE on two\nnew, higher-quality datasets curated and published in this work. Importantly,\nour models provide well-calibrated uncertainty estimates, as demonstrated by a\nbucketed expected calibration error of 0.62 years. While not intended for\nclinical deployment, these results highlight the potential of extracting\nmedically relevant signals from images. We make all code and datasets available\nto facilitate further research.", "published": "2025-06-16 12:47:37", "link": "http://arxiv.org/abs/2506.13430v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "JENGA: Object selection and pose estimation for robotic grasping from a stack", "abstract": "Vision-based robotic object grasping is typically investigated in the context\nof isolated objects or unstructured object sets in bin picking scenarios.\nHowever, there are several settings, such as construction or warehouse\nautomation, where a robot needs to interact with a structured object formation\nsuch as a stack. In this context, we define the problem of selecting suitable\nobjects for grasping along with estimating an accurate 6DoF pose of these\nobjects. To address this problem, we propose a camera-IMU based approach that\nprioritizes unobstructed objects on the higher layers of stacks and introduce a\ndataset for benchmarking and evaluation, along with a suitable evaluation\nmetric that combines object selection with pose accuracy. Experimental results\nshow that although our method can perform quite well, this is a challenging\nproblem if a completely error-free solution is needed. Finally, we show results\nfrom the deployment of our method for a brick-picking application in a\nconstruction scenario.", "published": "2025-06-16 12:43:02", "link": "http://arxiv.org/abs/2506.13425v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Audio-Visual Driven Compression for Low-Bitrate Talking Head Videos", "abstract": "Talking head video compression has advanced with neural rendering and\nkeypoint-based methods, but challenges remain, especially at low bit rates,\nincluding handling large head movements, suboptimal lip synchronization, and\ndistorted facial reconstructions. To address these problems, we propose a novel\naudio-visual driven video codec that integrates compact 3D motion features and\naudio signals. This approach robustly models significant head rotations and\naligns lip movements with speech, improving both compression efficiency and\nreconstruction quality. Experiments on the CelebV-HQ dataset show that our\nmethod reduces bitrate by 22% compared to VVC and by 8.5% over state-of-the-art\nlearning-based codec. Furthermore, it provides superior lip-sync accuracy and\nvisual fidelity at comparable bitrates, highlighting its effectiveness in\nbandwidth-constrained scenarios.", "published": "2025-06-16 12:34:48", "link": "http://arxiv.org/abs/2506.13419v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Zero-Shot Solving of Imaging Inverse Problems via Noise-Refined Likelihood Guided Diffusion Models", "abstract": "Diffusion models have achieved remarkable success in imaging inverse problems\nowing to their powerful generative capabilities. However, existing approaches\ntypically rely on models trained for specific degradation types, limiting their\ngeneralizability to various degradation scenarios. To address this limitation,\nwe propose a zero-shot framework capable of handling various imaging inverse\nproblems without model retraining. We introduce a likelihood-guided noise\nrefinement mechanism that derives a closed-form approximation of the likelihood\nscore, simplifying score estimation and avoiding expensive gradient\ncomputations. This estimated score is subsequently utilized to refine the\nmodel-predicted noise, thereby better aligning the restoration process with the\ngenerative framework of diffusion models. In addition, we integrate the\nDenoising Diffusion Implicit Models (DDIM) sampling strategy to further improve\ninference efficiency. The proposed mechanism can be applied to both\noptimization-based and sampling-based schemes, providing an effective and\nflexible zero-shot solution for imaging inverse problems. Extensive experiments\ndemonstrate that our method achieves superior performance across multiple\ninverse problems, particularly in compressive sensing, delivering high-quality\nreconstructions even at an extremely low sampling rate (5%).", "published": "2025-06-16 11:56:50", "link": "http://arxiv.org/abs/2506.13391v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "TR2M: Transferring Monocular Relative Depth to Metric Depth with Language Descriptions and Scale-Oriented Contrast", "abstract": "This work presents a generalizable framework to transfer relative depth to\nmetric depth. Current monocular depth estimation methods are mainly divided\ninto metric depth estimation (MMDE) and relative depth estimation (MRDE). MMDEs\nestimate depth in metric scale but are often limited to a specific domain.\nMRDEs generalize well across different domains, but with uncertain scales which\nhinders downstream applications. To this end, we aim to build up a framework to\nsolve scale uncertainty and transfer relative depth to metric depth. Previous\nmethods used language as input and estimated two factors for conducting\nrescaling. Our approach, TR2M, utilizes both text description and image as\ninputs and estimates two rescale maps to transfer relative depth to metric\ndepth at pixel level. Features from two modalities are fused with a\ncross-modality attention module to better capture scale information. A strategy\nis designed to construct and filter confident pseudo metric depth for more\ncomprehensive supervision. We also develop scale-oriented contrastive learning\nto utilize depth distribution as guidance to enforce the model learning about\nintrinsic knowledge aligning with the scale distribution. TR2M only exploits a\nsmall number of trainable parameters to train on datasets in various domains\nand experiments not only demonstrate TR2M's great performance in seen datasets\nbut also reveal superior zero-shot capabilities on five unseen datasets. We\nshow the huge potential in pixel-wise transferring relative depth to metric\ndepth with language assistance. (Code is available at:\nhttps://github.com/BeileiCui/TR2M)", "published": "2025-06-16 11:50:00", "link": "http://arxiv.org/abs/2506.13387v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DicFace: Dirichlet-Constrained Variational Codebook Learning for Temporally Coherent Video Face Restoration", "abstract": "Video face restoration faces a critical challenge in maintaining temporal\nconsistency while recovering fine facial details from degraded inputs. This\npaper presents a novel approach that extends Vector-Quantized Variational\nAutoencoders (VQ-VAEs), pretrained on static high-quality portraits, into a\nvideo restoration framework through variational latent space modeling. Our key\ninnovation lies in reformulating discrete codebook representations as\nDirichlet-distributed continuous variables, enabling probabilistic transitions\nbetween facial features across frames. A spatio-temporal Transformer\narchitecture jointly models inter-frame dependencies and predicts latent\ndistributions, while a Laplacian-constrained reconstruction loss combined with\nperceptual (LPIPS) regularization enhances both pixel accuracy and visual\nquality. Comprehensive evaluations on blind face restoration, video inpainting,\nand facial colorization tasks demonstrate state-of-the-art performance. This\nwork establishes an effective paradigm for adapting intensive image priors,\npretrained on high-quality images, to video restoration while addressing the\ncritical challenge of flicker artifacts. The source code has been open-sourced\nand is available at https://github.com/fudan-generative-vision/DicFace.", "published": "2025-06-16 10:54:28", "link": "http://arxiv.org/abs/2506.13355v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TextureSplat: Per-Primitive Texture Mapping for Reflective Gaussian Splatting", "abstract": "Gaussian Splatting have demonstrated remarkable novel view synthesis\nperformance at high rendering frame rates. Optimization-based inverse rendering\nwithin complex capture scenarios remains however a challenging problem. A\nparticular case is modelling complex surface light interactions for highly\nreflective scenes, which results in intricate high frequency specular radiance\ncomponents. We hypothesize that such challenging settings can benefit from\nincreased representation power. We hence propose a method that tackles this\nissue through a geometrically and physically grounded Gaussian Splatting borne\nradiance field, where normals and material properties are spatially variable in\nthe primitive's local space. Using per-primitive texture maps for this purpose,\nwe also propose to harness the GPU hardware to accelerate rendering at test\ntime via unified material texture atlas.", "published": "2025-06-16 10:41:40", "link": "http://arxiv.org/abs/2506.13348v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Advancing Image-Based Grapevine Variety Classification with a New Benchmark and Evaluation of Masked Autoencoders", "abstract": "Grapevine varieties are essential for the economies of many wine-producing\ncountries, influencing the production of wine, juice, and the consumption of\nfruits and leaves. Traditional identification methods, such as ampelography and\nmolecular analysis, have limitations: ampelography depends on expert knowledge\nand is inherently subjective, while molecular methods are costly and\ntime-intensive. To address these limitations, recent studies have applied deep\nlearning (DL) models to classify grapevine varieties using image data. However,\ndue to the small dataset sizes, these methods often depend on transfer learning\nfrom datasets from other domains, e.g., ImageNet1K (IN1K), which can lead to\nperformance degradation due to domain shift and supervision collapse. In this\ncontext, self-supervised learning (SSL) methods can be a good tool to avoid\nthis performance degradation, since they can learn directly from data, without\nexternal labels. This study presents an evaluation of Masked Autoencoders\n(MAEs) for identifying grapevine varieties based on field-acquired images. The\nmain contributions of this study include two benchmarks comprising 43 grapevine\nvarieties collected across different seasons, an analysis of MAE's application\nin the agricultural context, and a performance comparison of trained models\nacross seasons. Our results show that a ViT-B/16 model pre-trained with MAE and\nthe unlabeled dataset achieved an F1 score of 0.7956, outperforming all other\nmodels. Additionally, we observed that pre-trained models benefit from long\npre-training, perform well under low-data training regime, and that simple data\naugmentation methods are more effective than complex ones. The study also found\nthat the mask ratio in MAE impacts performance only marginally.", "published": "2025-06-16 10:25:23", "link": "http://arxiv.org/abs/2506.13335v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Joint Analysis of Optical and SAR Vegetation Indices for Vineyard Monitoring: Assessing Biomass Dynamics and Phenological Stages over Po Valley, Italy", "abstract": "Multi-polarized Synthetic Aperture Radar (SAR) technology has gained\nincreasing attention in agriculture, offering unique capabilities for\nmonitoring vegetation dynamics thanks to its all-weather, day-and-night\noperation and high revisit frequency. This study presents, for the first time,\na comprehensive analysis combining dual-polarimetric radar vegetation index\n(DpRVI) with optical indices to characterize vineyard crops. Vineyards exhibit\ndistinct non-isotropic scattering behavior due to their pronounced row\norientation, making them particularly challenging and interesting targets for\nremote sensing. The research further investigates the relationship between\nDpRVI and optical vegetation indices, demonstrating the complementary nature of\ntheir information. We demonstrate that DpRVI and optical indices provide\ncomplementary information, with low correlation suggesting that they capture\ndistinct vineyard features. Key findings reveal a parabolic trend in DpRVI over\nthe growing season, potentially linked to biomass dynamics estimated via the\nWinkler Index. Unlike optical indices reflecting vegetation greenness, DpRVI\nappears more directly related to biomass growth, aligning with specific\nphenological phases. Preliminary results also highlight the potential of DpRVI\nfor distinguishing vineyards from other crops. This research aligns with the\nobjectives of the PNRR-NODES project, which promotes nature-based solutions\n(NbS) for sustainable vineyard management. The application of DpRVI for\nmonitoring vineyards is part of integrating remote sensing techniques into the\nbroader field of strategies for climate-related change adaptation and risk\nreduction, emphasizing the role of innovative SAR-based monitoring in\nsustainable agriculture.", "published": "2025-06-16 10:16:00", "link": "http://arxiv.org/abs/2506.13327v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VIS-Shepherd: Constructing Critic for LLM-based Data Visualization Generation", "abstract": "Data visualization generation using Large Language Models (LLMs) has shown\npromising results but often produces suboptimal visualizations that require\nhuman intervention for improvement. In this work, we introduce VIS-Shepherd, a\nspecialized Multimodal Large Language Model (MLLM)-based critic to evaluate and\nprovide feedback for LLM-generated data visualizations. At the core of our\napproach is a framework to construct a high-quality visualization critique\ndataset, where we collect human-created visualization instances, synthesize\ncorresponding LLM-generated instances, and construct high-quality critiques. We\nconduct both model-based automatic evaluation and human preference studies to\nevaluate the effectiveness of our approach. Our experiments show that even\nsmall (7B parameters) open-source MLLM models achieve substantial performance\ngains by leveraging our high-quality visualization critique dataset, reaching\nlevels comparable to much larger open-source or even proprietary models. Our\nwork demonstrates significant potential for MLLM-based automated visualization\ncritique and indicates promising directions for enhancing LLM-based data\nvisualization generation. Our project page:\nhttps://github.com/bopan3/VIS-Shepherd.", "published": "2025-06-16 10:15:38", "link": "http://arxiv.org/abs/2506.13326v1", "categories": ["cs.CV", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Action Dubber: Timing Audible Actions via Inflectional Flow", "abstract": "We introduce the task of Audible Action Temporal Localization, which aims to\nidentify the spatio-temporal coordinates of audible movements. Unlike\nconventional tasks such as action recognition and temporal action localization,\nwhich broadly analyze video content, our task focuses on the distinct kinematic\ndynamics of audible actions. It is based on the premise that key actions are\ndriven by inflectional movements; for example, collisions that produce sound\noften involve abrupt changes in motion. To capture this, we propose\n$TA^{2}Net$, a novel architecture that estimates inflectional flow using the\nsecond derivative of motion to determine collision timings without relying on\naudio input. $TA^{2}Net$ also integrates a self-supervised spatial localization\nstrategy during training, combining contrastive learning with spatial analysis.\nThis dual design improves temporal localization accuracy and simultaneously\nidentifies sound sources within video frames. To support this task, we\nintroduce a new benchmark dataset, $Audible623$, derived from Kinetics and\nUCF101 by removing non-essential vocalization subsets. Extensive experiments\nconfirm the effectiveness of our approach on $Audible623$ and show strong\ngeneralizability to other domains, such as repetitive counting and sound source\nlocalization. Code and dataset are available at\nhttps://github.com/WenlongWan/Audible623.", "published": "2025-06-16 10:09:32", "link": "http://arxiv.org/abs/2506.13320v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Brain Imaging Foundation Models, Are We There Yet? A Systematic Review of Foundation Models for Brain Imaging and Biomedical Research", "abstract": "Foundation models (FMs), large neural networks pretrained on extensive and\ndiverse datasets, have revolutionized artificial intelligence and shown\nsignificant promise in medical imaging by enabling robust performance with\nlimited labeled data. Although numerous surveys have reviewed the application\nof FM in healthcare care, brain imaging remains underrepresented, despite its\ncritical role in the diagnosis and treatment of neurological diseases using\nmodalities such as MRI, CT, and PET. Existing reviews either marginalize brain\nimaging or lack depth on the unique challenges and requirements of FM in this\ndomain, such as multimodal data integration, support for diverse clinical\ntasks, and handling of heterogeneous, fragmented datasets.\n  To address this gap, we present the first comprehensive and curated review of\nFMs for brain imaging. We systematically analyze 161 brain imaging datasets and\n86 FM architectures, providing information on key design choices, training\nparadigms, and optimizations driving recent advances. Our review highlights the\nleading models for various brain imaging tasks, summarizes their innovations,\nand critically examines current limitations and blind spots in the literature.\nWe conclude by outlining future research directions to advance FM applications\nin brain imaging, with the aim of fostering progress in both clinical and\nresearch settings.", "published": "2025-06-16 09:46:46", "link": "http://arxiv.org/abs/2506.13306v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "AttentionDrag: Exploiting Latent Correlation Knowledge in Pre-trained Diffusion Models for Image Editing", "abstract": "Traditional point-based image editing methods rely on iterative latent\noptimization or geometric transformations, which are either inefficient in\ntheir processing or fail to capture the semantic relationships within the\nimage. These methods often overlook the powerful yet underutilized image\nediting capabilities inherent in pre-trained diffusion models. In this work, we\npropose a novel one-step point-based image editing method, named AttentionDrag,\nwhich leverages the inherent latent knowledge and feature correlations within\npre-trained diffusion models for image editing tasks. This framework enables\nsemantic consistency and high-quality manipulation without the need for\nextensive re-optimization or retraining. Specifically, we reutilize the latent\ncorrelations knowledge learned by the self-attention mechanism in the U-Net\nmodule during the DDIM inversion process to automatically identify and adjust\nrelevant image regions, ensuring semantic validity and consistency.\nAdditionally, AttentionDrag adaptively generates masks to guide the editing\nprocess, enabling precise and context-aware modifications with friendly\ninteraction. Our results demonstrate a performance that surpasses most\nstate-of-the-art methods with significantly faster speeds, showing a more\nefficient and semantically coherent solution for point-based image editing\ntasks.", "published": "2025-06-16 09:42:38", "link": "http://arxiv.org/abs/2506.13301v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Anomaly Object Segmentation with Vision-Language Models for Steel Scrap Recycling", "abstract": "Recycling steel scrap can reduce carbon dioxide (CO2) emissions from the\nsteel industry. However, a significant challenge in steel scrap recycling is\nthe inclusion of impurities other than steel. To address this issue, we propose\nvision-language-model-based anomaly detection where a model is finetuned in a\nsupervised manner, enabling it to handle niche objects effectively. This model\nenables automated detection of anomalies at a fine-grained level within steel\nscrap. Specifically, we finetune the image encoder, equipped with multi-scale\nmechanism and text prompts aligned with both normal and anomaly images. The\nfinetuning process trains these modules using a multiclass classification as\nthe supervision.", "published": "2025-06-16 09:21:01", "link": "http://arxiv.org/abs/2506.13282v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "COME: Adding Scene-Centric Forecasting Control to Occupancy World Model", "abstract": "World models are critical for autonomous driving to simulate environmental\ndynamics and generate synthetic data. Existing methods struggle to disentangle\nego-vehicle motion (perspective shifts) from scene evolvement (agent\ninteractions), leading to suboptimal predictions. Instead, we propose to\nseparate environmental changes from ego-motion by leveraging the scene-centric\ncoordinate systems. In this paper, we introduce COME: a framework that\nintegrates scene-centric forecasting Control into the Occupancy world ModEl.\nSpecifically, COME first generates ego-irrelevant, spatially consistent future\nfeatures through a scene-centric prediction branch, which are then converted\ninto scene condition using a tailored ControlNet. These condition features are\nsubsequently injected into the occupancy world model, enabling more accurate\nand controllable future occupancy predictions. Experimental results on the\nnuScenes-Occ3D dataset show that COME achieves consistent and significant\nimprovements over state-of-the-art (SOTA) methods across diverse\nconfigurations, including different input sources (ground-truth, camera-based,\nfusion-based occupancy) and prediction horizons (3s and 8s). For example, under\nthe same settings, COME achieves 26.3% better mIoU metric than DOME and 23.7%\nbetter mIoU metric than UniScene. These results highlight the efficacy of\ndisentangled representation learning in enhancing spatio-temporal prediction\nfidelity for world models. Code and videos will be available at\nhttps://github.com/synsin0/COME.", "published": "2025-06-16 09:01:09", "link": "http://arxiv.org/abs/2506.13260v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "High-Quality Facial Albedo Generation for 3D Face Reconstruction from a Single Image using a Coarse-to-Fine Approach", "abstract": "Facial texture generation is crucial for high-fidelity 3D face reconstruction\nfrom a single image. However, existing methods struggle to generate UV albedo\nmaps with high-frequency details. To address this challenge, we propose a novel\nend-to-end coarse-to-fine approach for UV albedo map generation. Our method\nfirst utilizes a UV Albedo Parametric Model (UVAPM), driven by low-dimensional\ncoefficients, to generate coarse albedo maps with skin tones and low-frequency\ntexture details. To capture high-frequency details, we train a detail generator\nusing a decoupled albedo map dataset, producing high-resolution albedo maps.\nExtensive experiments demonstrate that our method can generate high-fidelity\ntextures from a single image, outperforming existing methods in terms of\ntexture quality and realism. The code and pre-trained model are publicly\navailable at https://github.com/MVIC-DAI/UVAPM, facilitating reproducibility\nand further research.", "published": "2025-06-16 08:32:57", "link": "http://arxiv.org/abs/2506.13233v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SASep: Saliency-Aware Structured Separation of Geometry and Feature for Open Set Learning on Point Clouds", "abstract": "Recent advancements in deep learning have greatly enhanced 3D object\nrecognition, but most models are limited to closed-set scenarios, unable to\nhandle unknown samples in real-world applications. Open-set recognition (OSR)\naddresses this limitation by enabling models to both classify known classes and\nidentify novel classes. However, current OSR methods rely on global features to\ndifferentiate known and unknown classes, treating the entire object uniformly\nand overlooking the varying semantic importance of its different parts. To\naddress this gap, we propose Salience-Aware Structured Separation (SASep),\nwhich includes (i) a tunable semantic decomposition (TSD) module to\nsemantically decompose objects into important and unimportant parts, (ii) a\ngeometric synthesis strategy (GSS) to generate pseudo-unknown objects by\ncombining these unimportant parts, and (iii) a synth-aided margin separation\n(SMS) module to enhance feature-level separation by expanding the feature\ndistributions between classes. Together, these components improve both\ngeometric and feature representations, enhancing the model's ability to\neffectively distinguish known and unknown classes. Experimental results show\nthat SASep achieves superior performance in 3D OSR, outperforming existing\nstate-of-the-art methods.", "published": "2025-06-16 08:22:11", "link": "http://arxiv.org/abs/2506.13224v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DVP-MVS++: Synergize Depth-Normal-Edge and Harmonized Visibility Prior for Multi-View Stereo", "abstract": "Recently, patch deformation-based methods have demonstrated significant\neffectiveness in multi-view stereo due to their incorporation of deformable and\nexpandable perception for reconstructing textureless areas. However, these\nmethods generally focus on identifying reliable pixel correlations to mitigate\nmatching ambiguity of patch deformation, while neglecting the deformation\ninstability caused by edge-skipping and visibility occlusions, which may cause\npotential estimation deviations. To address these issues, we propose DVP-MVS++,\nan innovative approach that synergizes both depth-normal-edge aligned and\nharmonized cross-view priors for robust and visibility-aware patch deformation.\nSpecifically, to avoid edge-skipping, we first apply DepthPro, Metric3Dv2 and\nRoberts operator to generate coarse depth maps, normal maps and edge maps,\nrespectively. These maps are then aligned via an erosion-dilation strategy to\nproduce fine-grained homogeneous boundaries for facilitating robust patch\ndeformation. Moreover, we reformulate view selection weights as visibility\nmaps, and then implement both an enhanced cross-view depth reprojection and an\narea-maximization strategy to help reliably restore visible areas and\neffectively balance deformed patch, thus acquiring harmonized cross-view priors\nfor visibility-aware patch deformation. Additionally, we obtain geometry\nconsistency by adopting both aggregated normals via view selection and\nprojection depth differences via epipolar lines, and then employ SHIQ for\nhighlight correction to enable geometry consistency with highlight-aware\nperception, thus improving reconstruction quality during propagation and\nrefinement stage. Evaluation results on ETH3D, Tanks & Temples and Strecha\ndatasets exhibit the state-of-the-art performance and robust generalization\ncapability of our proposed method.", "published": "2025-06-16 08:15:22", "link": "http://arxiv.org/abs/2506.13215v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Comprehensive Survey on Deep Learning Solutions for 3D Flood Mapping", "abstract": "Flooding remains a major global challenge, worsened by climate change and\nurbanization, demanding advanced solutions for effective disaster management.\nWhile traditional 2D flood mapping techniques provide limited insights, 3D\nflood mapping, powered by deep learning (DL), offers enhanced capabilities by\nintegrating flood extent and depth. This paper presents a comprehensive survey\nof deep learning-based 3D flood mapping, emphasizing its advancements over 2D\nmaps by integrating flood extent and depth for effective disaster management\nand urban planning. The survey categorizes deep learning techniques into task\ndecomposition and end-to-end approaches, applicable to both static and dynamic\nflood features. We compare key DL architectures, highlighting their respective\nroles in enhancing prediction accuracy and computational efficiency.\nAdditionally, this work explores diverse data sources such as digital elevation\nmodels, satellite imagery, rainfall, and simulated data, outlining their roles\nin 3D flood mapping. The applications reviewed range from real-time flood\nprediction to long-term urban planning and risk assessment. However,\nsignificant challenges persist, including data scarcity, model\ninterpretability, and integration with traditional hydrodynamic models. This\nsurvey concludes by suggesting future directions to address these limitations,\nfocusing on enhanced datasets, improved models, and policy implications for\nflood management. This survey aims to guide researchers and practitioners in\nleveraging DL techniques for more robust and reliable 3D flood mapping,\nfostering improved flood management strategies.", "published": "2025-06-16 08:06:18", "link": "http://arxiv.org/abs/2506.13201v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MT-PCR: A Hybrid Mamba-Transformer with Spatial Serialization for Hierarchical Point Cloud Registration", "abstract": "Point cloud registration (PCR) is a fundamental task in 3D computer vision\nand robotics. Most existing learning-based PCR methods rely on Transformers,\nwhich suffer from quadratic computational complexity. This limitation restricts\nthe resolution of point clouds that can be processed, inevitably leading to\ninformation loss. In contrast, Mamba-a recently proposed model based on state\nspace models (SSMs)-achieves linear computational complexity while maintaining\nstrong long-range contextual modeling capabilities. However, directly applying\nMamba to PCR tasks yields suboptimal performance due to the unordered and\nirregular nature of point cloud data. To address this challenge, we propose\nMT-PCR, the first point cloud registration framework that integrates both Mamba\nand Transformer modules. Specifically, we serialize point cloud features using\nZ-order space-filling curves to enforce spatial locality, enabling Mamba to\nbetter model the geometric structure of the input. Additionally, we remove the\norder indicator module commonly used in Mamba-based sequence modeling, leads to\nimproved performance in our setting. The serialized features are then processed\nby an optimized Mamba encoder, followed by a Transformer refinement stage.\nExtensive experiments on multiple benchmarks demonstrate that MT-PCR\noutperforms Transformer-based and concurrent state-of-the-art methods in both\naccuracy and efficiency, significantly reducing while GPU memory usage and\nFLOPs.", "published": "2025-06-16 07:49:43", "link": "http://arxiv.org/abs/2506.13183v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GreedyPrune: Retenting Critical Visual Token Set for Large Vision Language Models", "abstract": "Although Large Vision Language Models (LVLMs) have demonstrated remarkable\nperformance in image understanding tasks, their computational efficiency\nremains a significant challenge, particularly on resource-constrained devices\ndue to the high cost of processing large numbers of visual tokens. Recently,\ntraining-free visual token pruning methods have gained popularity as a low-cost\nsolution to this issue. However, existing approaches suffer from two key\nlimitations: semantic saliency-based strategies primarily focus on high\ncross-attention visual tokens, often neglecting visual diversity, whereas\nvisual diversity-based methods risk inadvertently discarding semantically\nimportant tokens, especially under high compression ratios. In this paper, we\nintroduce GreedyPrune, a training-free plug-and-play visual token pruning\nalgorithm designed to jointly optimize semantic saliency and visual diversity.\nWe formalize the token pruning process as a combinatorial optimization problem\nand demonstrate that greedy algorithms effectively balance computational\nefficiency with model accuracy. Extensive experiments validate the\neffectiveness of our approach, showing that GreedyPrune achieves\nstate-of-the-art accuracy across various multimodal tasks and models while\nsignificantly reducing end-to-end inference latency.", "published": "2025-06-16 07:21:11", "link": "http://arxiv.org/abs/2506.13166v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "StgcDiff: Spatial-Temporal Graph Condition Diffusion for Sign Language Transition Generation", "abstract": "Sign language transition generation seeks to convert discrete sign language\nsegments into continuous sign videos by synthesizing smooth transitions.\nHowever,most existing methods merely concatenate isolated signs, resulting in\npoor visual coherence and semantic accuracy in the generated videos. Unlike\ntextual languages,sign language is inherently rich in spatial-temporal cues,\nmaking it more complex to model. To address this,we propose StgcDiff, a\ngraph-based conditional diffusion framework that generates smooth transitions\nbetween discrete signs by capturing the unique spatial-temporal dependencies of\nsign language. Specifically, we first train an encoder-decoder architecture to\nlearn a structure-aware representation of spatial-temporal skeleton sequences.\nNext, we optimize a diffusion denoiser conditioned on the representations\nlearned by the pre-trained encoder, which is tasked with predicting transition\nframes from noise. Additionally, we design the Sign-GCN module as the key\ncomponent in our framework, which effectively models the spatial-temporal\nfeatures. Extensive experiments conducted on the PHOENIX14T, USTC-CSL100,and\nUSTC-SLR500 datasets demonstrate the superior performance of our method.", "published": "2025-06-16 07:09:51", "link": "http://arxiv.org/abs/2506.13156v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "STAGE: A Stream-Centric Generative World Model for Long-Horizon Driving-Scene Simulation", "abstract": "The generation of temporally consistent, high-fidelity driving videos over\nextended horizons presents a fundamental challenge in autonomous driving world\nmodeling. Existing approaches often suffer from error accumulation and feature\nmisalignment due to inadequate decoupling of spatio-temporal dynamics and\nlimited cross-frame feature propagation mechanisms. To address these\nlimitations, we present STAGE (Streaming Temporal Attention Generative Engine),\na novel auto-regressive framework that pioneers hierarchical feature\ncoordination and multi-phase optimization for sustainable video synthesis. To\nachieve high-quality long-horizon driving video generation, we introduce\nHierarchical Temporal Feature Transfer (HTFT) and a novel multi-stage training\nstrategy. HTFT enhances temporal consistency between video frames throughout\nthe video generation process by modeling the temporal and denoising process\nseparately and transferring denoising features between frames. The multi-stage\ntraining strategy is to divide the training into three stages, through model\ndecoupling and auto-regressive inference process simulation, thereby\naccelerating model convergence and reducing error accumulation. Experiments on\nthe Nuscenes dataset show that STAGE has significantly surpassed existing\nmethods in the long-horizon driving video generation task. In addition, we also\nexplored STAGE's ability to generate unlimited-length driving videos. We\ngenerated 600 frames of high-quality driving videos on the Nuscenes dataset,\nwhich far exceeds the maximum length achievable by existing methods.", "published": "2025-06-16 06:53:05", "link": "http://arxiv.org/abs/2506.13138v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "EmbodiedPlace: Learning Mixture-of-Features with Embodied Constraints for Visual Place Recognition", "abstract": "Visual Place Recognition (VPR) is a scene-oriented image retrieval problem in\ncomputer vision in which re-ranking based on local features is commonly\nemployed to improve performance. In robotics, VPR is also referred to as Loop\nClosure Detection, which emphasizes spatial-temporal verification within a\nsequence. However, designing local features specifically for VPR is\nimpractical, and relying on motion sequences imposes limitations. Inspired by\nthese observations, we propose a novel, simple re-ranking method that refines\nglobal features through a Mixture-of-Features (MoF) approach under embodied\nconstraints. First, we analyze the practical feasibility of embodied\nconstraints in VPR and categorize them according to existing datasets, which\ninclude GPS tags, sequential timestamps, local feature matching, and\nself-similarity matrices. We then propose a learning-based MoF\nweight-computation approach, utilizing a multi-metric loss function.\nExperiments demonstrate that our method improves the state-of-the-art (SOTA)\nperformance on public datasets with minimal additional computational overhead.\nFor instance, with only 25 KB of additional parameters and a processing time of\n10 microseconds per frame, our method achieves a 0.9\\% improvement over a\nDINOv2-based baseline performance on the Pitts-30k test set.", "published": "2025-06-16 06:40:12", "link": "http://arxiv.org/abs/2506.13133v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GS-2DGS: Geometrically Supervised 2DGS for Reflective Object Reconstruction", "abstract": "3D modeling of highly reflective objects remains challenging due to strong\nview-dependent appearances. While previous SDF-based methods can recover\nhigh-quality meshes, they are often time-consuming and tend to produce\nover-smoothed surfaces. In contrast, 3D Gaussian Splatting (3DGS) offers the\nadvantage of high speed and detailed real-time rendering, but extracting\nsurfaces from the Gaussians can be noisy due to the lack of geometric\nconstraints. To bridge the gap between these approaches, we propose a novel\nreconstruction method called GS-2DGS for reflective objects based on 2D\nGaussian Splatting (2DGS). Our approach combines the rapid rendering\ncapabilities of Gaussian Splatting with additional geometric information from\nfoundation models. Experimental results on synthetic and real datasets\ndemonstrate that our method significantly outperforms Gaussian-based techniques\nin terms of reconstruction and relighting and achieves performance comparable\nto SDF-based methods while being an order of magnitude faster. Code is\navailable at https://github.com/hirotong/GS2DGS", "published": "2025-06-16 05:40:16", "link": "http://arxiv.org/abs/2506.13110v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Novel ViDAR Device With Visual Inertial Encoder Odometry and Reinforcement Learning-Based Active SLAM Method", "abstract": "In the field of multi-sensor fusion for simultaneous localization and mapping\n(SLAM), monocular cameras and IMUs are widely used to build simple and\neffective visual-inertial systems. However, limited research has explored the\nintegration of motor-encoder devices to enhance SLAM performance. By\nincorporating such devices, it is possible to significantly improve active\ncapability and field of view (FOV) with minimal additional cost and structural\ncomplexity. This paper proposes a novel visual-inertial-encoder tightly coupled\nodometry (VIEO) based on a ViDAR (Video Detection and Ranging) device. A ViDAR\ncalibration method is introduced to ensure accurate initialization for VIEO. In\naddition, a platform motion decoupled active SLAM method based on deep\nreinforcement learning (DRL) is proposed. Experimental data demonstrate that\nthe proposed ViDAR and the VIEO algorithm significantly increase cross-frame\nco-visibility relationships compared to its corresponding visual-inertial\nodometry (VIO) algorithm, improving state estimation accuracy. Additionally,\nthe DRL-based active SLAM algorithm, with the ability to decouple from platform\nmotion, can increase the diversity weight of the feature points and further\nenhance the VIEO algorithm's performance. The proposed methodology sheds fresh\ninsights into both the updated platform design and decoupled approach of active\nSLAM systems in complex environments.", "published": "2025-06-16 05:11:57", "link": "http://arxiv.org/abs/2506.13100v1", "categories": ["cs.RO", "cs.CV", "93C85", "I.4"], "primary_category": "cs.RO"}
{"title": "Pro-AD: Learning Comprehensive Prototypes with Prototype-based Constraint for Multi-class Unsupervised Anomaly Detection", "abstract": "Prototype-based reconstruction methods for unsupervised anomaly detection\nutilize a limited set of learnable prototypes which only aggregates\ninsufficient normal information, resulting in undesirable reconstruction.\nHowever, increasing the number of prototypes may lead to anomalies being well\nreconstructed through the attention mechanism, which we refer to as the \"Soft\nIdentity Mapping\" problem. In this paper, we propose Pro-AD to address these\nissues and fully utilize the prototypes to boost the performance of anomaly\ndetection. Specifically, we first introduce an expanded set of learnable\nprototypes to provide sufficient capacity for semantic information. Then we\nemploy a Dynamic Bidirectional Decoder which integrates the process of the\nnormal information aggregation and the target feature reconstruction via\nprototypes, with the aim of allowing the prototypes to aggregate more\ncomprehensive normal semantic information from different levels of the image\nfeatures and the target feature reconstruction to not only utilize its\ncontextual information but also dynamically leverage the learned comprehensive\nprototypes. Additionally, to prevent the anomalies from being well\nreconstructed using sufficient semantic information through the attention\nmechanism, Pro-AD introduces a Prototype-based Constraint that applied within\nthe target feature reconstruction process of the decoder, which further\nimproves the performance of our approach. Extensive experiments on multiple\nchallenging benchmarks demonstrate that our Pro-AD achieve state-of-the-art\nperformance, highlighting its superior robustness and practical effectiveness\nfor Multi-class Unsupervised Anomaly Detection task.", "published": "2025-06-16 05:04:12", "link": "http://arxiv.org/abs/2506.13097v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning Event Completeness for Weakly Supervised Video Anomaly Detection", "abstract": "Weakly supervised video anomaly detection (WS-VAD) is tasked with pinpointing\ntemporal intervals containing anomalous events within untrimmed videos,\nutilizing only video-level annotations. However, a significant challenge arises\ndue to the absence of dense frame-level annotations, often leading to\nincomplete localization in existing WS-VAD methods. To address this issue, we\npresent a novel LEC-VAD, Learning Event Completeness for Weakly Supervised\nVideo Anomaly Detection, which features a dual structure designed to encode\nboth category-aware and category-agnostic semantics between vision and\nlanguage. Within LEC-VAD, we devise semantic regularities that leverage an\nanomaly-aware Gaussian mixture to learn precise event boundaries, thereby\nyielding more complete event instances. Besides, we develop a novel memory\nbank-based prototype learning mechanism to enrich concise text descriptions\nassociated with anomaly-event categories. This innovation bolsters the text's\nexpressiveness, which is crucial for advancing WS-VAD. Our LEC-VAD demonstrates\nremarkable advancements over the current state-of-the-art methods on two\nbenchmark datasets XD-Violence and UCF-Crime.", "published": "2025-06-16 04:56:58", "link": "http://arxiv.org/abs/2506.13095v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SuperPoint-SLAM3: Augmenting ORB-SLAM3 with Deep Features, Adaptive NMS, and Learning-Based Loop Closure", "abstract": "Visual simultaneous localization and mapping (SLAM) must remain accurate\nunder extreme viewpoint, scale and illumination variations. The widely adopted\nORB-SLAM3 falters in these regimes because it relies on hand-crafted ORB\nkeypoints. We introduce SuperPoint-SLAM3, a drop-in upgrade that (i) replaces\nORB with the self-supervised SuperPoint detector--descriptor, (ii) enforces\nspatially uniform keypoints via adaptive non-maximal suppression (ANMS), and\n(iii) integrates a lightweight NetVLAD place-recognition head for\nlearning-based loop closure.\n  On the KITTI Odometry benchmark SuperPoint-SLAM3 reduces mean translational\nerror from 4.15% to 0.34% and mean rotational error from 0.0027 deg/m to 0.0010\ndeg/m. On the EuRoC MAV dataset it roughly halves both errors across every\nsequence (e.g., V2\\_03: 1.58% -> 0.79%). These gains confirm that fusing modern\ndeep features with a learned loop-closure module markedly improves ORB-SLAM3\naccuracy while preserving its real-time operation.\n  Implementation, pretrained weights and reproducibility scripts are available\nat https://github.com/shahram95/SuperPointSLAM3.", "published": "2025-06-16 04:27:32", "link": "http://arxiv.org/abs/2506.13089v1", "categories": ["cs.CV", "cs.RO", "I.2.10; I.4.8; I.2.9"], "primary_category": "cs.CV"}
{"title": "SuperPlace: The Renaissance of Classical Feature Aggregation for Visual Place Recognition in the Era of Foundation Models", "abstract": "Recent visual place recognition (VPR) approaches have leveraged foundation\nmodels (FM) and introduced novel aggregation techniques. However, these methods\nhave failed to fully exploit key concepts of FM, such as the effective\nutilization of extensive training sets, and they have overlooked the potential\nof classical aggregation methods, such as GeM and NetVLAD. Building on these\ninsights, we revive classical feature aggregation methods and develop more\nfundamental VPR models, collectively termed SuperPlace. First, we introduce a\nsupervised label alignment method that enables training across various VPR\ndatasets within a unified framework. Second, we propose G$^2$M, a compact\nfeature aggregation method utilizing two GeMs, where one GeM learns the\nprincipal components of feature maps along the channel dimension and calibrates\nthe output of the other. Third, we propose the secondary fine-tuning (FT$^2$)\nstrategy for NetVLAD-Linear (NVL). NetVLAD first learns feature vectors in a\nhigh-dimensional space and then compresses them into a lower-dimensional space\nvia a single linear layer. Extensive experiments highlight our contributions\nand demonstrate the superiority of SuperPlace. Specifically, G$^2$M achieves\npromising results with only one-tenth of the feature dimensions compared to\nrecent methods. Moreover, NVL-FT$^2$ ranks first on the MSLS leaderboard.", "published": "2025-06-16 03:40:49", "link": "http://arxiv.org/abs/2506.13073v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Video Individual Counting With Implicit One-to-Many Matching", "abstract": "Video Individual Counting (VIC) is a recently introduced task that aims to\nestimate pedestrian flux from a video. It extends conventional Video Crowd\nCounting (VCC) beyond the per-frame pedestrian count. In contrast to VCC that\nonly learns to count repeated pedestrian patterns across frames, the key\nproblem of VIC is how to identify co-existent pedestrians between frames, which\nturns out to be a correspondence problem. Existing VIC approaches, however,\nmainly follow a one-to-one (O2O) matching strategy where the same pedestrian\nmust be exactly matched between frames, leading to sensitivity to appearance\nvariations or missing detections. In this work, we show that the O2O matching\ncould be relaxed to a one-to-many (O2M) matching problem, which better fits the\nproblem nature of VIC and can leverage the social grouping behavior of walking\npedestrians. We therefore introduce OMAN, a simple but effective VIC model with\nimplicit One-to-Many mAtchiNg, featuring an implicit context generator and a\none-to-many pairwise matcher. Experiments on the SenseCrowd and CroHD\nbenchmarks show that OMAN achieves the state-of-the-art performance. Code is\navailable at \\href{https://github.com/tiny-smart/OMAN}{OMAN}.", "published": "2025-06-16 03:20:00", "link": "http://arxiv.org/abs/2506.13067v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DualFast: Dual-Speedup Framework for Fast Sampling of Diffusion Models", "abstract": "Diffusion probabilistic models (DPMs) have achieved impressive success in\nvisual generation. While, they suffer from slow inference speed due to\niterative sampling. Employing fewer sampling steps is an intuitive solution,\nbut this will also introduces discretization error. Existing fast samplers make\ninspiring efforts to reduce discretization error through the adoption of\nhigh-order solvers, potentially reaching a plateau in terms of optimization.\nThis raises the question: can the sampling process be accelerated further? In\nthis paper, we re-examine the nature of sampling errors, discerning that they\ncomprise two distinct elements: the widely recognized discretization error and\nthe less explored approximation error. Our research elucidates the dynamics\nbetween these errors and the step by implementing a dual-error disentanglement\nstrategy. Building on these foundations, we introduce an unified and\ntraining-free acceleration framework, DualFast, designed to enhance the speed\nof DPM sampling by concurrently accounting for both error types, thereby\nminimizing the total sampling error. DualFast is seamlessly compatible with\nexisting samplers and significantly boost their sampling quality and speed,\nparticularly in extremely few sampling steps. We substantiate the effectiveness\nof our framework through comprehensive experiments, spanning both unconditional\nand conditional sampling domains, across both pixel-space and latent-space\nDPMs.", "published": "2025-06-16 02:59:57", "link": "http://arxiv.org/abs/2506.13058v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Metis-RISE: RL Incentivizes and SFT Enhances Multimodal Reasoning Model Learning", "abstract": "Recent advancements in large language models (LLMs) have witnessed a surge in\nthe development of advanced reasoning paradigms, which are now being integrated\ninto multimodal large language models (MLLMs). However, existing approaches\noften fall short: methods solely employing reinforcement learning (RL) can\nstruggle with sample inefficiency and activating entirely absent reasoning\ncapabilities, while conventional pipelines that initiate with a cold-start\nsupervised fine-tuning (SFT) phase before RL may restrict the model's\nexploratory capacity and face suboptimal convergence. In this work, we\nintroduce \\textbf{Metis-RISE} (\\textbf{R}L \\textbf{I}ncentivizes and\n\\textbf{S}FT \\textbf{E}nhances) for multimodal reasoning model learning. Unlike\nconventional approaches, Metis-RISE distinctively omits an initial SFT stage,\nbeginning instead with an RL phase (e.g., using a Group Relative Policy\nOptimization variant) to incentivize and activate the model's latent reasoning\ncapacity. Subsequently, the targeted SFT stage addresses two key challenges\nidentified during RL: (1) \\textit{inefficient trajectory sampling} for tasks\nwhere the model possesses but inconsistently applies correct reasoning, which\nwe tackle using self-distilled reasoning trajectories from the RL model itself;\nand (2) \\textit{fundamental capability absence}, which we address by injecting\nexpert-augmented knowledge for prompts where the model entirely fails. This\nstrategic application of RL for incentivization followed by SFT for enhancement\nforms the core of Metis-RISE, leading to two versions of our MLLMs (7B and 72B\nparameters). Evaluations on the OpenCompass Multimodal Reasoning Leaderboard\ndemonstrate that both models achieve state-of-the-art performance among\nsimilar-sized models, with the 72B version ranking fourth overall.", "published": "2025-06-16 02:56:13", "link": "http://arxiv.org/abs/2506.13056v1", "categories": ["cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.AI"}
{"title": "NeuVAS: Neural Implicit Surfaces for Variational Shape Modeling", "abstract": "Neural implicit shape representation has drawn significant attention in\nrecent years due to its smoothness, differentiability, and topological\nflexibility. However, directly modeling the shape of a neural implicit surface,\nespecially as the zero-level set of a neural signed distance function (SDF),\nwith sparse geometric control is still a challenging task. Sparse input shape\ncontrol typically includes 3D curve networks or, more generally, 3D curve\nsketches, which are unstructured and cannot be connected to form a curve\nnetwork, and therefore more difficult to deal with. While 3D curve networks or\ncurve sketches provide intuitive shape control, their sparsity and varied\ntopology pose challenges in generating high-quality surfaces to meet such curve\nconstraints. In this paper, we propose NeuVAS, a variational approach to shape\nmodeling using neural implicit surfaces constrained under sparse input shape\ncontrol, including unstructured 3D curve sketches as well as connected 3D curve\nnetworks. Specifically, we introduce a smoothness term based on a functional of\nsurface curvatures to minimize shape variation of the zero-level set surface of\na neural SDF. We also develop a new technique to faithfully model G0 sharp\nfeature curves as specified in the input curve sketches. Comprehensive\ncomparisons with the state-of-the-art methods demonstrate the significant\nadvantages of our method.", "published": "2025-06-16 02:39:45", "link": "http://arxiv.org/abs/2506.13050v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Beyond the First Read: AI-Assisted Perceptual Error Detection in Chest Radiography Accounting for Interobserver Variability", "abstract": "Chest radiography is widely used in diagnostic imaging. However, perceptual\nerrors -- especially overlooked but visible abnormalities -- remain common and\nclinically significant. Current workflows and AI systems provide limited\nsupport for detecting such errors after interpretation and often lack\nmeaningful human--AI collaboration. We introduce RADAR (Radiologist--AI\nDiagnostic Assistance and Review), a post-interpretation companion system.\nRADAR ingests finalized radiologist annotations and CXR images, then performs\nregional-level analysis to detect and refer potentially missed abnormal\nregions. The system supports a \"second-look\" workflow and offers suggested\nregions of interest (ROIs) rather than fixed labels to accommodate\ninter-observer variation. We evaluated RADAR on a simulated perceptual-error\ndataset derived from de-identified CXR cases, using F1 score and Intersection\nover Union (IoU) as primary metrics. RADAR achieved a recall of 0.78, precision\nof 0.44, and an F1 score of 0.56 in detecting missed abnormalities in the\nsimulated perceptual-error dataset. Although precision is moderate, this\nreduces over-reliance on AI by encouraging radiologist oversight in human--AI\ncollaboration. The median IoU was 0.78, with more than 90% of referrals\nexceeding 0.5 IoU, indicating accurate regional localization. RADAR effectively\ncomplements radiologist judgment, providing valuable post-read support for\nperceptual-error detection in CXR interpretation. Its flexible ROI suggestions\nand non-intrusive integration position it as a promising tool in real-world\nradiology workflows. To facilitate reproducibility and further evaluation, we\nrelease a fully open-source web implementation alongside a simulated error\ndataset. All code, data, demonstration videos, and the application are publicly\navailable at https://github.com/avutukuri01/RADAR.", "published": "2025-06-16 02:36:38", "link": "http://arxiv.org/abs/2506.13049v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Comprehensive Survey on Continual Learning in Generative Models", "abstract": "The rapid advancement of generative models has enabled modern AI systems to\ncomprehend and produce highly sophisticated content, even achieving human-level\nperformance in specific domains. However, these models remain fundamentally\nconstrained by catastrophic forgetting - a persistent challenge where adapting\nto new tasks typically leads to significant degradation in performance on\npreviously learned tasks. To address this practical limitation, numerous\napproaches have been proposed to enhance the adaptability and scalability of\ngenerative models in real-world applications. In this work, we present a\ncomprehensive survey of continual learning methods for mainstream generative\nmodels, including large language models, multimodal large language models,\nvision language action models, and diffusion models. Drawing inspiration from\nthe memory mechanisms of the human brain, we systematically categorize these\napproaches into three paradigms: architecture-based, regularization-based, and\nreplay-based methods, while elucidating their underlying methodologies and\nmotivations. We further analyze continual learning setups for different\ngenerative models, including training objectives, benchmarks, and core\nbackbones, offering deeper insights into the field. The project page of this\npaper is available at\nhttps://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models.", "published": "2025-06-16 02:27:25", "link": "http://arxiv.org/abs/2506.13045v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "ViewPCL: a point cloud based active learning method for multi-view segmentation", "abstract": "We propose a novel active learning framework for multi-view semantic\nsegmentation. This framework relies on a new score that measures the\ndiscrepancy between point cloud distributions generated from the extra\ngeometrical information derived from the model's prediction across different\nviews. Our approach results in a data efficient and explainable active learning\nmethod. The source code is available at https://github.com/chilai235/viewpclAL.", "published": "2025-06-16 02:16:17", "link": "http://arxiv.org/abs/2506.13043v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MAMMA: Markerless & Automatic Multi-Person Motion Action Capture", "abstract": "We present MAMMA, a markerless motion-capture pipeline that accurately\nrecovers SMPL-X parameters from multi-view video of two-person interaction\nsequences. Traditional motion-capture systems rely on physical markers.\nAlthough they offer high accuracy, their requirements of specialized hardware,\nmanual marker placement, and extensive post-processing make them costly and\ntime-consuming. Recent learning-based methods attempt to overcome these\nlimitations, but most are designed for single-person capture, rely on sparse\nkeypoints, or struggle with occlusions and physical interactions. In this work,\nwe introduce a method that predicts dense 2D surface landmarks conditioned on\nsegmentation masks, enabling person-specific correspondence estimation even\nunder heavy occlusion. We employ a novel architecture that exploits learnable\nqueries for each landmark. We demonstrate that our approach can handle complex\nperson--person interaction and offers greater accuracy than existing methods.\nTo train our network, we construct a large, synthetic multi-view dataset\ncombining human motions from diverse sources, including extreme poses, hand\nmotions, and close interactions. Our dataset yields high-variability synthetic\nsequences with rich body contact and occlusion, and includes SMPL-X\nground-truth annotations with dense 2D landmarks. The result is a system\ncapable of capturing human motion without the need for markers. Our approach\noffers competitive reconstruction quality compared to commercial marker-based\nmotion-capture solutions, without the extensive manual cleanup. Finally, we\naddress the absence of common benchmarks for dense-landmark prediction and\nmarkerless motion capture by introducing two evaluation settings built from\nreal multi-view sequences. We will release our dataset, benchmark, method,\ntraining code, and pre-trained model weights for research purposes.", "published": "2025-06-16 02:04:51", "link": "http://arxiv.org/abs/2506.13040v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Evolution of ReID: From Early Methods to LLM Integration", "abstract": "Person re-identification (ReID) has evolved from handcrafted feature-based\nmethods to deep learning approaches and, more recently, to models incorporating\nlarge language models (LLMs). Early methods struggled with variations in\nlighting, pose, and viewpoint, but deep learning addressed these issues by\nlearning robust visual features. Building on this, LLMs now enable ReID systems\nto integrate semantic and contextual information through natural language. This\nsurvey traces that full evolution and offers one of the first comprehensive\nreviews of ReID approaches that leverage LLMs, where textual descriptions are\nused as privileged information to improve visual matching. A key contribution\nis the use of dynamic, identity-specific prompts generated by GPT-4o, which\nenhance the alignment between images and text in vision-language ReID systems.\nExperimental results show that these descriptions improve accuracy, especially\nin complex or ambiguous cases. To support further research, we release a large\nset of GPT-4o-generated descriptions for standard ReID datasets. By bridging\ncomputer vision and natural language processing, this survey offers a unified\nperspective on the field's development and outlines key future directions such\nas better prompt design, cross-modal transfer learning, and real-world\nadaptability.", "published": "2025-06-16 02:03:46", "link": "http://arxiv.org/abs/2506.13039v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HKD4VLM: A Progressive Hybrid Knowledge Distillation Framework for Robust Multimodal Hallucination and Factuality Detection in VLMs", "abstract": "Driven by the rapid progress in vision-language models (VLMs), the\nresponsible behavior of large-scale multimodal models has become a prominent\nresearch area, particularly focusing on hallucination detection and factuality\nchecking. In this paper, we present the solution for the two tracks of\nResponsible AI challenge. Inspirations from the general domain demonstrate that\na smaller distilled VLM can often outperform a larger VLM that is directly\ntuned on downstream tasks, while achieving higher efficiency. We thus jointly\ntackle two tasks from the perspective of knowledge distillation and propose a\nprogressive hybrid knowledge distillation framework termed HKD4VLM.\nSpecifically, the overall framework can be decomposed into Pyramid-like\nProgressive Online Distillation and Ternary-Coupled Refinement Distillation,\nhierarchically moving from coarse-grained knowledge alignment to fine-grained\nrefinement. Besides, we further introduce the mapping shift-enhanced inference\nand diverse augmentation strategies to enhance model performance and\nrobustness. Extensive experimental results demonstrate the effectiveness of our\nHKD4VLM. Ablation studies provide insights into the critical design choices\ndriving performance gains.", "published": "2025-06-16 02:03:41", "link": "http://arxiv.org/abs/2506.13038v1", "categories": ["cs.CV", "cs.MM"], "primary_category": "cs.CV"}
{"title": "AS400-DET: Detection using Deep Learning Model for IBM i (AS/400)", "abstract": "This paper proposes a method for automatic GUI component detection for the\nIBM i system (formerly and still more commonly known as AS/400). We introduce a\nhuman-annotated dataset consisting of 1,050 system screen images, in which 381\nimages are screenshots of IBM i system screens in Japanese. Each image contains\nmultiple components, including text labels, text boxes, options, tables,\ninstructions, keyboards, and command lines. We then develop a detection system\nbased on state-of-the-art deep learning models and evaluate different\napproaches using our dataset. The experimental results demonstrate the\neffectiveness of our dataset in constructing a system for component detection\nfrom GUI screens. By automatically detecting GUI components from the screen,\nAS400-DET has the potential to perform automated testing on systems that\noperate via GUI screens.", "published": "2025-06-16 01:53:30", "link": "http://arxiv.org/abs/2506.13032v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "The Combinatorial Rank of Subsets: Metric Density in Finite Hamming Spaces", "abstract": "We introduce a novel concept of rank for subsets of finite metric spaces\nE^n_q (the set of all n-dimensional vectors over an alphabet of size q)\nequipped with the Hamming distance, where the rank R(A) of a subset A is\ndefined as the number of non-constant columns in the matrix formed by the\nvectors of A. This purely combinatorial definition provides a new perspective\non the structure of finite metric spaces, distinct from traditional\nlinear-algebraic notions of rank. We establish tight bounds for R(A) in terms\nof D_A, the sum of Hamming distances between all pairs of elements in A.\nSpecifically, we prove that 2qD_A/((q-1)|A|^2) <= R(A) <= D_A/(|A|-1) when\n|A|/q >= 1, with a modified lower bound for the case |A|/q < 1. These bounds\nshow that the rank is constrained by the metric properties of the subset.\nFurthermore, we introduce the concept of metrically dense subsets, which are\nsubsets that minimize rank among all isometric images. This notion captures an\nextremal property of subsets that represent their distance structure in the\nmost compact way possible. We prove that subsets with uniform column\ndistribution are metrically dense, and as a special case, establish that when q\nis a prime power, every linear subspace of E^n_q is metrically dense. This\nreveals a fundamental connection between the algebraic and metric structures of\nthese spaces.", "published": "2025-06-16 03:58:20", "link": "http://arxiv.org/abs/2506.13081v1", "categories": ["cs.DM", "math.CO", "05D40 (Primary) 05C12, 94B05 (Secondary)", "G.2.1; G.2.2; E.4"], "primary_category": "cs.DM"}
{"title": "OneRec Technical Report", "abstract": "Recommender systems have been widely used in various large-scale\nuser-oriented platforms for many years. However, compared to the rapid\ndevelopments in the AI community, recommendation systems have not achieved a\nbreakthrough in recent years. For instance, they still rely on a multi-stage\ncascaded architecture rather than an end-to-end approach, leading to\ncomputational fragmentation and optimization inconsistencies, and hindering the\neffective application of key breakthrough technologies from the AI community in\nrecommendation scenarios.\n  To address these issues, we propose OneRec, which reshapes the recommendation\nsystem through an end-to-end generative approach and achieves promising\nresults. Firstly, we have enhanced the computational FLOPs of the current\nrecommendation model by 10 $\\times$ and have identified the scaling laws for\nrecommendations within certain boundaries. Secondly, reinforcement learning\ntechniques, previously difficult to apply for optimizing recommendations, show\nsignificant potential in this framework. Lastly, through infrastructure\noptimizations, we have achieved 23.7% and 28.8% Model FLOPs Utilization (MFU)\non flagship GPUs during training and inference, respectively, aligning closely\nwith the LLM community. This architecture significantly reduces communication\nand storage overhead, resulting in operating expense that is only 10.6% of\ntraditional recommendation pipelines. Deployed in Kuaishou/Kuaishou Lite APP,\nit handles 25% of total queries per second, enhancing overall App Stay Time by\n0.54% and 1.24%, respectively. Additionally, we have observed significant\nincreases in metrics such as 7-day Lifetime, which is a crucial indicator of\nrecommendation experience. We also provide practical lessons and insights\nderived from developing, optimizing, and maintaining a production-scale\nrecommendation system with significant real-world impact.", "published": "2025-06-16 16:58:55", "link": "http://arxiv.org/abs/2506.13695v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Tree-Based Text Retrieval via Hierarchical Clustering in RAGFrameworks: Application on Taiwanese Regulations", "abstract": "Traditional Retrieval-Augmented Generation (RAG) systems employ brute-force\ninner product search to retrieve the top-k most similar documents, then\ncombined with the user query and passed to a language model. This allows the\nmodel to access external knowledge and reduce hallucinations. However,\nselecting an appropriate k value remains a significant challenge in practical\napplications: a small k may fail to retrieve sufficient information, while a\nlarge k can introduce excessive and irrelevant content. To address this, we\npropose a hierarchical clustering-based retrieval method that eliminates the\nneed to predefine k. Our approach maintains the accuracy and relevance of\nsystem responses while adaptively selecting semantically relevant content. In\nthe experiment stage, we applied our method to a Taiwanese legal dataset with\nexpert-graded queries. The results show that our approach achieves superior\nperformance in expert evaluations and maintains high precision while\neliminating the need to predefine k, demonstrating improved accuracy and\ninterpretability in legal text retrieval tasks. Our framework is simple to\nimplement and easily integrates with existing RAG pipelines, making it a\npractical solution for real-world applications under limited resources.", "published": "2025-06-16 15:34:29", "link": "http://arxiv.org/abs/2506.13607v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Beyond One-Size-Fits-All: A Study of Neural and Behavioural Variability Across Different Recommendation Categories", "abstract": "Traditionally, Recommender Systems (RS) have primarily measured performance\nbased on the accuracy and relevance of their recommendations. However, this\nalgorithmic-centric approach overlooks how different types of recommendations\nimpact user engagement and shape the overall quality of experience. In this\npaper, we shift the focus to the user and address for the first time the\nchallenge of decoding the neural and behavioural variability across distinct\nrecommendation categories, considering more than just relevance. Specifically,\nwe conducted a controlled study using a comprehensive e-commerce dataset\ncontaining various recommendation types, and collected Electroencephalography\nand behavioural data. We analysed both neural and behavioural responses to\nrecommendations that were categorised as Exact, Substitute, Complement, or\nIrrelevant products within search query results. Our findings offer novel\ninsights into user preferences and decision-making processes, revealing\nmeaningful relationships between behavioural and neural patterns for each\ncategory, but also indicate inter-subject variability.", "published": "2025-06-16 12:23:17", "link": "http://arxiv.org/abs/2506.13409v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Digital Transformation of Urban Planning in Australia: Influencing Factors and Key Challenges", "abstract": "Over the past two decades, several governments in developing and developed\ncountries have started their journey toward digital transformation. However,\nthe pace and maturity of digital technologies and strategies are different\nbetween public services. Current literature indicates that research on the\ndigital transformation of urban planning is still developing. Therefore, the\naim of this study is to understand the influencing factors and key challenges\nfor the digital transformation of urban planning in Australia. The study adopts\nthe inter-organisational theory and Planning Support Science (PSScience) under\nthe Technological, Organisational, and External Environmental (TOE) framework.\nIt involves a multiple case study, administered semi-structured interviews with\nthirteen IT and urban planning experts across Victoria and New South Wales\ngovernments and private industries. The study findings indicate that the main\nchallenges for digital transformation of the Australian urban planning system\nare related to organisational and external environmental factors. Furthermore,\na digital maturity model is absent in the Australian urban planning industry.\nThis study offers important implications to research and practice related to\ndigital transformation in urban planning.", "published": "2025-06-16 10:23:46", "link": "http://arxiv.org/abs/2506.13333v1", "categories": ["cs.IT", "cs.IR", "math.IT"], "primary_category": "cs.IT"}
{"title": "Gated Rotary-Enhanced Linear Attention for Long-term Sequential Recommendation", "abstract": "In Sequential Recommendation Systems (SRSs), Transformer models show\nremarkable performance but face computation cost challenges when modeling\nlong-term user behavior sequences due to the quadratic complexity of the\ndot-product attention mechanism. By approximating the dot-product attention,\nlinear attention provides an efficient option with linear complexity. However,\nexisting linear attention methods face two limitations: 1) they often use\nlearnable position encodings, which incur extra computational costs in\nlong-term sequence scenarios, and 2) they may not consider the user's\nfine-grained local preferences and confuse these with the actual change of\nlong-term interests. To remedy these drawbacks, we propose a long-term\nsequential Recommendation model with Gated Rotary Enhanced Linear Attention\n(RecGRELA). Specifically, we first propose a Rotary-Enhanced Linear Attention\n(RELA) module to model long-range dependency within the user's historical\ninformation using rotary position encodings. We then introduce a local short\noperation to incorporate local preferences and demonstrate the theoretical\ninsight. We further introduce a SiLU-based Gated mechanism for RELA (GRELA) to\nhelp the model determine whether a user's behavior indicates local interest or\na genuine shift in long-term preferences. Experimental results on four public\ndatasets demonstrate that our RecGRELA achieves state-of-the-art performance\ncompared to existing SRSs while maintaining low memory overhead.", "published": "2025-06-16 09:56:10", "link": "http://arxiv.org/abs/2506.13315v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Accessibility Barriers in Multi-Terabyte Public Datasets: The Gap Between Promise and Practice", "abstract": "The promise of \"free and open\" multi-terabyte datasets often collides with\nharsh realities. While these datasets may be technically accessible, practical\nbarriers -- from processing complexity to hidden costs -- create a system that\nprimarily serves well-funded institutions. This study examines accessibility\nchallenges across web crawls, satellite imagery, scientific data, and\ncollaborative projects, revealing a consistent two-tier system where\ntheoretical openness masks practical exclusivity. Our analysis demonstrates\nthat datasets marketed as \"publicly accessible\" typically require minimum\ninvestments of \\$1,000+ for meaningful analysis, with complex processing\npipelines demanding \\$10,000-100,000+ in infrastructure costs. The\ninfrastructure requirements -- distributed computing knowledge, domain\nexpertise, and substantial budgets -- effectively gatekeep these datasets\ndespite their \"open\" status, limiting practical accessibility to those with\ninstitutional support or substantial resources.", "published": "2025-06-16 08:52:58", "link": "http://arxiv.org/abs/2506.13256v1", "categories": ["cs.CY", "cs.DL", "cs.IR", "68P20, 91D30", "H.3.7; K.4.3"], "primary_category": "cs.CY"}
{"title": "The Sample Complexity of Distributed Simple Binary Hypothesis Testing under Information Constraints", "abstract": "This paper resolves two open problems from a recent paper, arXiv:2403.16981,\nconcerning the sample complexity of distributed simple binary hypothesis\ntesting under information constraints. The first open problem asks whether\ninteraction reduces the sample complexity of distributed simple binary\nhypothesis testing. In this paper, we show that sequential interaction does not\nhelp. The second problem suggests tightening existing sample complexity bounds\nfor communication-constrained simple binary hypothesis testing. We derive\noptimally tight bounds for this setting and resolve this problem. Our main\ntechnical contributions are: (i) a one-shot lower bound on the Bayes error in\nsimple binary hypothesis testing that satisfies a crucial tensorisation\nproperty; (ii) a streamlined proof of the formula for the sample complexity of\nsimple binary hypothesis testing without constraints, first established in\narXiv:2403.16981; and (iii) a reverse data-processing inequality for\nHellinger-$\\lambda$ divergences, generalising the results from arXiv:1812.03031\nand arXiv:2206.02765.", "published": "2025-06-16 16:50:27", "link": "http://arxiv.org/abs/2506.13686v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Intelligent Rotatable Antenna for Integrated Sensing, Communication, and Computation: Challenges and Opportunities", "abstract": "Integrated sensing, communication, and computation (ISCC) has emerged as a\npromising paradigm for enabling intelligent services in future sixth-generation\n(6G) networks. However, existing ISCC systems based on fixed-antenna\narchitectures inherently lack spatial adaptability to cope with the signal\ndegradation and dynamic environmental conditions. Recently, non-fixed flexible\nantenna architectures, such as fluid antenna system (FAS), movable antenna\n(MA), and pinching antenna, have garnered significant interest. Among them,\nintelligent rotatable antenna (IRA) is an emerging technology that offers\nsignificant potential to better support the comprehensive services of target\nsensing, data transmission, and edge computing. This article investigates a\nnovel IRA-enabled ISCC framework to enhance received signal strength, wider\ncoverage, and spatial adaptability to dynamic wireless environments by flexibly\nadjusting the boresight of directional antennas. Building upon this, we\nintroduce the fundamentals of IRA technology and explore IRA's benefits for\nimproving system performance while providing potential task-oriented\napplications. Then, we discuss the main design issues and provide solutions for\nimplementing IRA-based ISCC systems. Finally, experimental results are provided\nto demonstrate the great potential of IRA-enabled ISCC system, thus paving the\nway for more robust and efficient future wireless networks.", "published": "2025-06-16 15:12:28", "link": "http://arxiv.org/abs/2506.13586v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Perfect Privacy for Discriminator-Based Byzantine-Resilient Federated Learning", "abstract": "Federated learning (FL) shows great promise in large-scale machine learning\nbut introduces new privacy and security challenges. We propose ByITFL and\nLoByITFL, two novel FL schemes that enhance resilience against Byzantine users\nwhile keeping the users' data private from eavesdroppers. To ensure privacy and\nByzantine resilience, our schemes build on having a small representative\ndataset available to the federator and crafting a discriminator function\nallowing the mitigation of corrupt users' contributions. ByITFL employs\nLagrange coded computing and re-randomization, making it the first\nByzantine-resilient FL scheme with perfect Information-Theoretic (IT) privacy,\nthough at the cost of a significant communication overhead. LoByITFL, on the\nother hand, achieves Byzantine resilience and IT privacy at a significantly\nreduced communication cost, but requires a Trusted Third Party, used only in a\none-time initialization phase before training. We provide theoretical\nguarantees on privacy and Byzantine resilience, along with convergence\nguarantees and experimental results validating our findings.", "published": "2025-06-16 14:47:02", "link": "http://arxiv.org/abs/2506.13561v1", "categories": ["cs.LG", "cs.DC", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Dynamic Layered Decoding Scheduling for LDPC Codes Aided by Check Node Error Probabilities", "abstract": "In this study, a new scheduling strategies for low-density parity-check\n(LDPC) codes under layered belief propagation (LBP) is designed. Based on the\ncriteria of prioritizing the update of check nodes with lower error\nprobabilities, we propose two dynamic scheduling methods: dynamic error belief\npropagation (Dyn-EBP) and dynamic penalty error belief propagation (Dyn-PEBP).\nIn Dyn-EBP, each check node is restricted from being updated the same number of\ntimes, whereas Dyn-PEBP removes this restriction and instead introduces a\npenalty term to balance the number of updates. Simulation results show that,\nfor 5G new radio (NR) LDPC codes, our proposed scheduling methods can\noutperform existing dynamic and offline scheduling strategies under various\nblocklengths and code rates. This demonstrates that prioritizing the update of\ncheck nodes with lower error probabilities can lead to higher decoding\nefficiency and validates the effectiveness of our algorithms.", "published": "2025-06-16 14:02:38", "link": "http://arxiv.org/abs/2506.13507v1", "categories": ["cs.IT", "math.IT", "math.OC", "math.PR", "94B35 (Primary) 94B70 (Secondary)", "E.4; F.2.2"], "primary_category": "cs.IT"}
{"title": "A Contemporary Survey on Fluid Antenna Systems: Fundamentals and Networking Perspectives", "abstract": "The explosive growth of teletraffic, fueled by the convergence of\ncyber-physical systems and data-intensive applications, such as the Internet of\nThings (IoT), autonomous systems, and immersive communications, demands a\nmultidisciplinary suite of innovative solutions across the physical and network\nlayers. Fluid antenna systems (FAS) represent a transformative advancement in\nantenna design, offering enhanced spatial degrees of freedom through dynamic\nreconfigurability. By exploiting spatial flexibility, FAS can adapt to varying\nchannel conditions and optimize wireless performance, making it a highly\npromising candidate for next-generation communication networks. This paper\nprovides a comprehensive survey of the state of the art in FAS research. We\nbegin by examining key application scenarios in which FAS offers significant\nadvantages. We then present the fundamental principles of FAS, covering channel\nmeasurement and modeling, single-user configurations, and the multi-user fluid\nantenna multiple access (FAMA) framework. Following this, we delve into key\nnetwork-layer techniques such as quality-of-service (QoS) provisioning, power\nallocation, and content placement strategies. We conclude by identifying\nprevailing challenges and outlining future research directions to support the\ncontinued development of FAS in next-generation wireless networks.", "published": "2025-06-16 09:57:24", "link": "http://arxiv.org/abs/2506.13317v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "DoA Estimation using MUSIC with Range/Doppler Multiplexing for MIMO-OFDM Radar", "abstract": "Sensing emerges as a critical challenge in 6G networks, which require\nsimultaneous communication and target sensing capabilities. State-of-the-art\nsuper-resolution techniques for the direction of arrival (DoA) estimation\nencounter significant performance limitations when the number of targets\nexceeds antenna array dimensions. This paper introduces a novel sensing\nparameter estimation algorithm for orthogonal frequency-division multiplexing\n(OFDM) multiple-input multiple-output (MIMO) radar systems. The proposed\napproach implements a strategic two-stage methodology: first, discriminating\ntargets through delay and Doppler domain filtering to reduce the number of\neffective targets for super-resolution DoA estimation, and second, introducing\na fusion technique to mitigate sidelobe interferences. The algorithm enables\nrobust DoA estimation, particularly in high-density target environments with\nlimited-size antenna arrays. Numerical simulations validate the superior\nperformance of the proposed method compared to conventional DoA estimation\napproaches.", "published": "2025-06-16 08:59:20", "link": "http://arxiv.org/abs/2506.13258v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Movable Antennas Meet Low-Altitude Wireless Networks: Fundamentals, Opportunities, and Future Directions", "abstract": "With the rapid development of low-altitude applications, there is an\nincreasing demand for low-altitude wireless networks (LAWNs) to simultaneously\nachieve high-rate communication, precise sensing, and reliable control in the\nlow-altitude airspace. In this paper, we first present a typical system\narchitecture of LAWNs, which integrates three core functionalities:\ncommunication, sensing, and control. Subsequently, we explore the promising\nprospects of movable antenna (MA)-assisted wireless communications, with\nemphasis on its potential in flexible beamforming, interference management, and\nspatial multiplexing gain. Furthermore, we elaborate on the integrated\ncommunication, sensing, and control capabilities enabled by MAs in LAWNs, and\nillustrate their effectiveness through representative examples. A case study\ndemonstrates that MA-enabled LAWNs achieve significant performance improvements\nover traditional fixed-position antenna-based LAWNs in terms of communication\nthroughput, sensing accuracy, and control stability. Finally, we outline\nseveral promising directions for future research, including the MA-assisted\nunmanned aerial vehicle (UAV) communication/sensing, the MA-assisted reliable\ncontrol, and the MA-enhanced physical layer security.", "published": "2025-06-16 08:46:44", "link": "http://arxiv.org/abs/2506.13250v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Spectral Comb Shaping by Polar Codes", "abstract": "A scheme to select information indices in polar codes is proposed to form\nsignals with spectral comb shapes under BPSK modulation, whereby the signal\ncould be separated from periodic interference in spectrum. By selecting proper\nindices to load information bits in polar coding, a spectral comb shape signal\nis formed, which has periodic zeros and notch bands uniformly distributed in\nits frequency spectrum. Furthermore, to mitigate the negative impact of\nproposed polar code on the AWGN performance, a scheme termed error performance\nenhancement scheme is proposed, whereby the performance loss under AWGN noise\ncould be alleviated. Numerical results are given under periodic interference\nand AWGN noise, indicating that a considerable signal-to-noise power ratio\n(SNR) gain is accomplished in comparison with conventional polar codes.", "published": "2025-06-16 08:28:57", "link": "http://arxiv.org/abs/2506.13230v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Scalar Lattices and Probabilistic Shaping for Dithered Wyner-Ziv Quantization", "abstract": "Scalar lattice quantization with a modulo operator, dithering, and\nprobabilistic shaping is applied to the Wyner-Ziv (WZ) problem with a Gaussian\nsource and mean square error distortion. The method achieves the WZ\nrate-distortion pairs. The analysis is similar to that for dirty paper coding\nbut requires additional steps to bound the distortion because the modulo shift\nis correlated with the source noise. The results extend to vector sources by\nreverse waterfilling on the spectrum of the covariance matrix of the source\nnoise. Simulations with short polar codes illustrate the performance and\ncompare with scalar quantizers and polar coded quantization without dithering.", "published": "2025-06-16 07:18:23", "link": "http://arxiv.org/abs/2506.13162v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On secure UAV-aided ISCC systems", "abstract": "Integrated communication and sensing, which can make full use of the limited\nspectrum resources to perform communication and sensing tasks simultaneously,\nis an up-and-coming technology in wireless communication networks. In this\nwork, we investigate the secrecy performance of an uncrewed aerial vehicle\n(UAV)-assisted secure integrated communication, sensing, and computing system,\nwhere the UAV sends radar signals to locate and disrupt potential eavesdroppers\nwhile providing offload services to ground users (GUs). Considering the\nconstraints of UAV maximum speed, transmit power, and propulsion energy, as\nwell as secure offloading, data transmission, and computation time, the total\nenergy consumption of GUs is minimized by jointly optimizing user offloading\nratio, user scheduling strategy, transmit beamforming, and UAV trajectory. An\nefficient iterative optimization algorithm is proposed to solve the non-convex\noptimization problem caused by tightly coupled dependent variables. In\nparticular, the original optimization problem is decomposed into four\nsub-optimization problems, and the non-convex sub-problems are transformed into\napproximately convex forms via successive convex approximation. Then, all\nsub-problems are solved successively by using the block coordinate descent\ntechnique. Numerical results demonstrate the convergence and validate the\neffectiveness of the proposed algorithm.", "published": "2025-06-16 06:52:56", "link": "http://arxiv.org/abs/2506.13137v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "AI reconstruction of European weather from the Euro-Atlantic regimes", "abstract": "We present a non-linear AI-model designed to reconstruct monthly mean\nanomalies of the European temperature and precipitation based on the\nEuro-Atlantic Weather regimes (WR) indices. WR represent recurrent,\nquasi-stationary, and persistent states of the atmospheric circulation that\nexert considerable influence over the European weather, therefore offering an\nopportunity for sub-seasonal to seasonal forecasting. While much research has\nfocused on studying the correlation and impacts of the WR on European weather,\nthe estimation of ground-level climate variables, such as temperature and\nprecipitation, from Euro-Atlantic WR remains largely unexplored and is\ncurrently limited to linear methods. The presented AI model can capture and\nintroduce complex non-linearities in the relation between the WR indices,\ndescribing the state of the Euro-Atlantic atmospheric circulation and the\ncorresponding surface temperature and precipitation anomalies in Europe. We\ndiscuss the AI-model performance in reconstructing the monthly mean two-meter\ntemperature and total precipitation anomalies in the European winter and\nsummer, also varying the number of WR used to describe the monthly atmospheric\ncirculation. We assess the impact of errors on the WR indices in the\nreconstruction and show that a mean absolute relative error below 80% yields\nimproved seasonal reconstruction compared to the ECMWF operational seasonal\nforecast system, SEAS5. As a demonstration of practical applicability, we\nevaluate the model using WR indices predicted by SEAS5, finding slightly better\nor comparable skill relative to the SEAS5 forecast itself. Our findings\ndemonstrate that WR-based anomaly reconstruction, powered by AI tools, offers a\npromising pathway for sub-seasonal and seasonal forecasting.", "published": "2025-06-16 17:59:02", "link": "http://arxiv.org/abs/2506.13758v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MARCO: Hardware-Aware Neural Architecture Search for Edge Devices with Multi-Agent Reinforcement Learning and Conformal Prediction Filtering", "abstract": "This paper introduces MARCO (Multi-Agent Reinforcement learning with\nConformal Optimization), a novel hardware-aware framework for efficient neural\narchitecture search (NAS) targeting resource-constrained edge devices. By\nsignificantly reducing search time and maintaining accuracy under strict\nhardware constraints, MARCO bridges the gap between automated DNN design and\nCAD for edge AI deployment. MARCO's core technical contribution lies in its\nunique combination of multi-agent reinforcement learning (MARL) with Conformal\nPrediction (CP) to accelerate the hardware/software co-design process for\ndeploying deep neural networks. Unlike conventional once-for-all (OFA) supernet\napproaches that require extensive pretraining, MARCO decomposes the NAS task\ninto a hardware configuration agent (HCA) and a Quantization Agent (QA). The\nHCA optimizes high-level design parameters, while the QA determines per-layer\nbit-widths under strict memory and latency budgets using a shared reward signal\nwithin a centralized-critic, decentralized-execution (CTDE) paradigm. A key\ninnovation is the integration of a calibrated CP surrogate model that provides\nstatistical guarantees (with a user-defined miscoverage rate) to prune\nunpromising candidate architectures before incurring the high costs of partial\ntraining or hardware simulation. This early filtering drastically reduces the\nsearch space while ensuring that high-quality designs are retained with a high\nprobability. Extensive experiments on MNIST, CIFAR-10, and CIFAR-100\ndemonstrate that MARCO achieves a 3-4x reduction in total search time compared\nto an OFA baseline while maintaining near-baseline accuracy (within 0.3%).\nFurthermore, MARCO also reduces inference latency. Validation on a MAX78000\nevaluation board confirms that simulator trends hold in practice, with\nsimulator estimates deviating from measured values by less than 5%.", "published": "2025-06-16 17:58:09", "link": "http://arxiv.org/abs/2506.13755v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sharpness-Aware Machine Unlearning", "abstract": "We characterize the effectiveness of Sharpness-aware minimization (SAM) under\nmachine unlearning scheme, where unlearning forget signals interferes with\nlearning retain signals. While previous work prove that SAM improves\ngeneralization with noise memorization prevention, we show that SAM abandons\nsuch denoising property when fitting the forget set, leading to various test\nerror bounds depending on signal strength. We further characterize the signal\nsurplus of SAM in the order of signal strength, which enables learning from\nless retain signals to maintain model performance and putting more weight on\nunlearning the forget set. Empirical studies show that SAM outperforms SGD with\nrelaxed requirement for retain signals and can enhance various unlearning\nmethods either as pretrain or unlearn algorithm. Observing that overfitting can\nbenefit more stringent sample-specific unlearning, we propose Sharp MinMax,\nwhich splits the model into two to learn retain signals with SAM and unlearn\nforget signals with sharpness maximization, achieving best performance.\nExtensive experiments show that SAM enhances unlearning across varying\ndifficulties measured by data memorization, yielding decreased feature\nentanglement between retain and forget sets, stronger resistance to membership\ninference attacks, and a flatter loss landscape.", "published": "2025-06-16 17:24:10", "link": "http://arxiv.org/abs/2506.13715v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Understanding Learning Invariance in Deep Linear Networks", "abstract": "Equivariant and invariant machine learning models exploit symmetries and\nstructural patterns in data to improve sample efficiency. While empirical\nstudies suggest that data-driven methods such as regularization and data\naugmentation can perform comparably to explicitly invariant models, theoretical\ninsights remain scarce. In this paper, we provide a theoretical comparison of\nthree approaches for achieving invariance: data augmentation, regularization,\nand hard-wiring. We focus on mean squared error regression with deep linear\nnetworks, which parametrize rank-bounded linear maps and can be hard-wired to\nbe invariant to specific group actions. We show that the critical points of the\noptimization problems for hard-wiring and data augmentation are identical,\nconsisting solely of saddles and the global optimum. By contrast,\nregularization introduces additional critical points, though they remain\nsaddles except for the global optimum. Moreover, we demonstrate that the\nregularization path is continuous and converges to the hard-wired solution.", "published": "2025-06-16 17:24:07", "link": "http://arxiv.org/abs/2506.13714v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Understanding Lookahead Dynamics Through Laplace Transform", "abstract": "We introduce a frequency-domain framework for convergence analysis of\nhyperparameters in game optimization, leveraging High-Resolution Differential\nEquations (HRDEs) and Laplace transforms. Focusing on the Lookahead\nalgorithm--characterized by gradient steps $k$ and averaging coefficient\n$\\alpha$--we transform the discrete-time oscillatory dynamics of bilinear games\ninto the frequency domain to derive precise convergence criteria. Our\nhigher-precision $O(\\gamma^2)$-HRDE models yield tighter criteria, while our\nfirst-order $O(\\gamma)$-HRDE models offer practical guidance by prioritizing\nactionable hyperparameter tuning over complex closed-form solutions. Empirical\nvalidation in discrete-time settings demonstrates the effectiveness of our\napproach, which may further extend to locally linear operators, offering a\nscalable framework for selecting hyperparameters for learning in games.", "published": "2025-06-16 17:20:40", "link": "http://arxiv.org/abs/2506.13712v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "Gradient-Normalized Smoothness for Optimization with Approximate Hessians", "abstract": "In this work, we develop new optimization algorithms that use approximate\nsecond-order information combined with the gradient regularization technique to\nachieve fast global convergence rates for both convex and non-convex\nobjectives. The key innovation of our analysis is a novel notion called\nGradient-Normalized Smoothness, which characterizes the maximum radius of a\nball around the current point that yields a good relative approximation of the\ngradient field. Our theory establishes a natural intrinsic connection between\nHessian approximation and the linearization of the gradient. Importantly,\nGradient-Normalized Smoothness does not depend on the specific problem class of\nthe objective functions, while effectively translating local information about\nthe gradient field and Hessian approximation into the global behavior of the\nmethod. This new concept equips approximate second-order algorithms with\nuniversal global convergence guarantees, recovering state-of-the-art rates for\nfunctions with H\\\"older-continuous Hessians and third derivatives,\nquasi-self-concordant functions, as well as smooth classes in first-order\noptimization. These rates are achieved automatically and extend to broader\nclasses, such as generalized self-concordant functions. We demonstrate direct\napplications of our results for global linear rates in logistic regression and\nsoftmax problems with approximate Hessians, as well as in non-convex\noptimization using Fisher and Gauss-Newton approximations.", "published": "2025-06-16 17:19:34", "link": "http://arxiv.org/abs/2506.13710v1", "categories": ["math.OC", "cs.LG"], "primary_category": "math.OC"}
{"title": "What Happens During the Loss Plateau? Understanding Abrupt Learning in Transformers", "abstract": "Training Transformers on algorithmic tasks frequently demonstrates an\nintriguing abrupt learning phenomenon: an extended performance plateau followed\nby a sudden, sharp improvement. This work investigates the underlying\nmechanisms for such dynamics, primarily in shallow Transformers. We reveal that\nduring the plateau, the model often develops an interpretable partial solution\nwhile simultaneously exhibiting a strong repetition bias in their outputs. This\noutput degeneracy is accompanied by internal representation collapse, where\nhidden states across different tokens become nearly parallel. We further\nidentify the slow learning of optimal attention maps as a key bottleneck.\nHidden progress in attention configuration during the plateau precedes the\neventual rapid convergence, and directly intervening on attention significantly\nalters plateau duration and the severity of repetition bias and\nrepresentational collapse. We validate that these identified\nphenomena-repetition bias and representation collapse-are not artifacts of toy\nsetups but also manifest in the early pre-training stage of large language\nmodels like Pythia and OLMo.", "published": "2025-06-16 16:51:18", "link": "http://arxiv.org/abs/2506.13688v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Enforcing tail calibration when training probabilistic forecast models", "abstract": "Probabilistic forecasts are typically obtained using state-of-the-art\nstatistical and machine learning models, with model parameters estimated by\noptimizing a proper scoring rule over a set of training data. If the model\nclass is not correctly specified, then the learned model will not necessarily\nissue forecasts that are calibrated. Calibrated forecasts allow users to\nappropriately balance risks in decision making, and it is particularly\nimportant that forecast models issue calibrated predictions for extreme events,\nsince such outcomes often generate large socio-economic impacts. In this work,\nwe study how the loss function used to train probabilistic forecast models can\nbe adapted to improve the reliability of forecasts made for extreme events. We\ninvestigate loss functions based on weighted scoring rules, and additionally\npropose regularizing loss functions using a measure of tail miscalibration. We\napply these approaches to a hierarchy of increasingly flexible forecast models\nfor UK wind speeds, including simple parametric models, distributional\nregression networks, and conditional generative models. We demonstrate that\nstate-of-the-art models do not issue calibrated forecasts for extreme wind\nspeeds, and that the calibration of forecasts for extreme events can be\nimproved by suitable adaptations to the loss function during model training.\nThis, however, introduces a trade-off between calibrated forecasts for extreme\nevents and calibrated forecasts for more common outcomes.", "published": "2025-06-16 16:51:06", "link": "http://arxiv.org/abs/2506.13687v1", "categories": ["stat.AP", "cs.LG", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Hybrid Meta-learners for Estimating Heterogeneous Treatment Effects", "abstract": "Estimating conditional average treatment effects (CATE) from observational\ndata involves modeling decisions that differ from supervised learning,\nparticularly concerning how to regularize model complexity. Previous approaches\ncan be grouped into two primary \"meta-learner\" paradigms that impose distinct\ninductive biases. Indirect meta-learners first fit and regularize separate\npotential outcome (PO) models and then estimate CATE by taking their\ndifference, whereas direct meta-learners construct and directly regularize\nestimators for the CATE function itself. Neither approach consistently\noutperforms the other across all scenarios: indirect learners perform well when\nthe PO functions are simple, while direct learners outperform when the CATE is\nsimpler than individual PO functions. In this paper, we introduce the Hybrid\nLearner (H-learner), a novel regularization strategy that interpolates between\nthe direct and indirect regularizations depending on the dataset at hand. The\nH-learner achieves this by learning intermediate functions whose difference\nclosely approximates the CATE without necessarily requiring accurate individual\napproximations of the POs themselves. We demonstrate empirically that\nintentionally allowing suboptimal fits to the POs improves the bias-variance\ntradeoff in estimating CATE. Experiments conducted on semi-synthetic and\nreal-world benchmark datasets illustrate that the H-learner consistently\noperates at the Pareto frontier, effectively combining the strengths of both\ndirect and indirect meta-learners.", "published": "2025-06-16 16:37:20", "link": "http://arxiv.org/abs/2506.13680v1", "categories": ["cs.LG", "stat.ME"], "primary_category": "cs.LG"}
{"title": "A Gravity-informed Spatiotemporal Transformer for Human Activity Intensity Prediction", "abstract": "Human activity intensity prediction is a crucial to many location-based\nservices. Although tremendous progress has been made to model dynamic\nspatiotemporal patterns of human activity, most existing methods, including\nspatiotemporal graph neural networks (ST-GNNs), overlook physical constraints\nof spatial interactions and the over-smoothing phenomenon in spatial\ncorrelation modeling. To address these limitations, this work proposes a\nphysics-informed deep learning framework, namely Gravity-informed\nSpatiotemporal Transformer (Gravityformer) by refining transformer attention to\nintegrate the universal law of gravitation and explicitly incorporating\nconstraints from spatial interactions. Specifically, it (1) estimates two\nspatially explicit mass parameters based on inflow and outflow, (2) models the\nlikelihood of cross-unit interaction using closed-form solutions of spatial\ninteractions to constrain spatial modeling randomness, and (3) utilizes the\nlearned spatial interaction to guide and mitigate the over-smoothing phenomenon\nin transformer attention matrices. The underlying law of human activity can be\nexplicitly modeled by the proposed adaptive gravity model. Moreover, a parallel\nspatiotemporal graph convolution transformer structure is proposed for\nachieving a balance between coupled spatial and temporal learning. Systematic\nexperiments on six real-world large-scale activity datasets demonstrate the\nquantitative and qualitative superiority of our approach over state-of-the-art\nbenchmarks. Additionally, the learned gravity attention matrix can be\ndisentangled and interpreted based on geographical laws. This work provides a\nnovel insight into integrating physical laws with deep learning for\nspatiotemporal predictive learning.", "published": "2025-06-16 16:32:51", "link": "http://arxiv.org/abs/2506.13678v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The Courage to Stop: Overcoming Sunk Cost Fallacy in Deep Reinforcement Learning", "abstract": "Off-policy deep reinforcement learning (RL) typically leverages replay\nbuffers for reusing past experiences during learning. This can help improve\nsample efficiency when the collected data is informative and aligned with the\nlearning objectives; when that is not the case, it can have the effect of\n\"polluting\" the replay buffer with data which can exacerbate optimization\nchallenges in addition to wasting environment interactions due to wasteful\nsampling. We argue that sampling these uninformative and wasteful transitions\ncan be avoided by addressing the sunk cost fallacy, which, in the context of\ndeep RL, is the tendency towards continuing an episode until termination. To\naddress this, we propose learn to stop (LEAST), a lightweight mechanism that\nenables strategic early episode termination based on Q-value and gradient\nstatistics, which helps agents recognize when to terminate unproductive\nepisodes early. We demonstrate that our method improves learning efficiency on\na variety of RL algorithms, evaluated on both the MuJoCo and DeepMind Control\nSuite benchmarks.", "published": "2025-06-16 16:30:00", "link": "http://arxiv.org/abs/2506.13672v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adversarial Disentanglement by Backpropagation with Physics-Informed Variational Autoencoder", "abstract": "Inference and prediction under partial knowledge of a physical system is\nchallenging, particularly when multiple confounding sources influence the\nmeasured response. Explicitly accounting for these influences in physics-based\nmodels is often infeasible due to epistemic uncertainty, cost, or time\nconstraints, resulting in models that fail to accurately describe the behavior\nof the system. On the other hand, data-driven machine learning models such as\nvariational autoencoders are not guaranteed to identify a parsimonious\nrepresentation. As a result, they can suffer from poor generalization\nperformance and reconstruction accuracy in the regime of limited and noisy\ndata. We propose a physics-informed variational autoencoder architecture that\ncombines the interpretability of physics-based models with the flexibility of\ndata-driven models. To promote disentanglement of the known physics and\nconfounding influences, the latent space is partitioned into physically\nmeaningful variables that parametrize a physics-based model, and data-driven\nvariables that capture variability in the domain and class of the physical\nsystem. The encoder is coupled with a decoder that integrates physics-based and\ndata-driven components, and constrained by an adversarial training objective\nthat prevents the data-driven components from overriding the known physics,\nensuring that the physics-grounded latent variables remain interpretable. We\ndemonstrate that the model is able to disentangle features of the input signal\nand separate the known physics from confounding influences using supervision in\nthe form of class and domain observables. The model is evaluated on a series of\nsynthetic case studies relevant to engineering structures, demonstrating the\nfeasibility of the proposed approach.", "published": "2025-06-16 16:18:25", "link": "http://arxiv.org/abs/2506.13658v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "PeakWeather: MeteoSwiss Weather Station Measurements for Spatiotemporal Deep Learning", "abstract": "Accurate weather forecasts are essential for supporting a wide range of\nactivities and decision-making processes, as well as mitigating the impacts of\nadverse weather events. While traditional numerical weather prediction (NWP)\nremains the cornerstone of operational forecasting, machine learning is\nemerging as a powerful alternative for fast, flexible, and scalable\npredictions. We introduce PeakWeather, a high-quality dataset of surface\nweather observations collected every 10 minutes over more than 8 years from the\nground stations of the Federal Office of Meteorology and Climatology\nMeteoSwiss's measurement network. The dataset includes a diverse set of\nmeteorological variables from 302 station locations distributed across\nSwitzerland's complex topography and is complemented with topographical indices\nderived from digital height models for context. Ensemble forecasts from the\ncurrently operational high-resolution NWP model are provided as a baseline\nforecast against which to evaluate new approaches. The dataset's richness\nsupports a broad spectrum of spatiotemporal tasks, including time series\nforecasting at various scales, graph structure learning, imputation, and\nvirtual sensing. As such, PeakWeather serves as a real-world benchmark to\nadvance both foundational machine learning research, meteorology, and\nsensor-based applications.", "published": "2025-06-16 16:16:42", "link": "http://arxiv.org/abs/2506.13652v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "xbench: Tracking Agents Productivity Scaling with Profession-Aligned Real-World Evaluations", "abstract": "We introduce xbench, a dynamic, profession-aligned evaluation suite designed\nto bridge the gap between AI agent capabilities and real-world productivity.\nWhile existing benchmarks often focus on isolated technical skills, they may\nnot accurately reflect the economic value agents deliver in professional\nsettings. To address this, xbench targets commercially significant domains with\nevaluation tasks defined by industry professionals. Our framework creates\nmetrics that strongly correlate with productivity value, enables prediction of\nTechnology-Market Fit (TMF), and facilitates tracking of product capabilities\nover time. As our initial implementations, we present two benchmarks:\nRecruitment and Marketing. For Recruitment, we collect 50 tasks from real-world\nheadhunting business scenarios to evaluate agents' abilities in company\nmapping, information retrieval, and talent sourcing. For Marketing, we assess\nagents' ability to match influencers with advertiser needs, evaluating their\nperformance across 50 advertiser requirements using a curated pool of 836\ncandidate influencers. We present initial evaluation results for leading\ncontemporary agents, establishing a baseline for these professional domains.\nOur continuously updated evalsets and evaluations are available at\nhttps://xbench.org.", "published": "2025-06-16 16:16:14", "link": "http://arxiv.org/abs/2506.13651v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "EUNIS Habitat Maps: Enhancing Thematic and Spatial Resolution for Europe through Machine Learning", "abstract": "The EUNIS habitat classification is crucial for categorising European\nhabitats, supporting European policy on nature conservation and implementing\nthe Nature Restoration Law. To meet the growing demand for detailed and\naccurate habitat information, we provide spatial predictions for 260 EUNIS\nhabitat types at hierarchical level 3, together with independent validation and\nuncertainty analyses.\n  Using ensemble machine learning models, together with high-resolution\nsatellite imagery and ecologically meaningful climatic, topographic and edaphic\nvariables, we produced a European habitat map indicating the most probable\nEUNIS habitat at 100-m resolution across Europe. Additionally, we provide\ninformation on prediction uncertainty and the most probable habitats at level 3\nwithin each EUNIS level 1 formation. This product is particularly useful for\nboth conservation and restoration purposes.\n  Predictions were cross-validated at European scale using a spatial block\ncross-validation and evaluated against independent data from France (forests\nonly), the Netherlands and Austria. The habitat maps obtained strong predictive\nperformances on the validation datasets with distinct trade-offs in terms of\nrecall and precision across habitat formations.", "published": "2025-06-16 16:10:08", "link": "http://arxiv.org/abs/2506.13649v1", "categories": ["stat.AP", "cs.LG", "physics.geo-ph", "q-bio.QM", "62P12, 62M30, 92D40", "I.2.6; J.3; I.6.5"], "primary_category": "stat.AP"}
{"title": "Global Convergence of Adjoint-Optimized Neural PDEs", "abstract": "Many engineering and scientific fields have recently become interested in\nmodeling terms in partial differential equations (PDEs) with neural networks.\nThe resulting neural-network PDE model, being a function of the neural network\nparameters, can be calibrated to available data by optimizing over the PDE\nusing gradient descent, where the gradient is evaluated in a computationally\nefficient manner by solving an adjoint PDE. These neural-network PDE models\nhave emerged as an important research area in scientific machine learning. In\nthis paper, we study the convergence of the adjoint gradient descent\noptimization method for training neural-network PDE models in the limit where\nboth the number of hidden units and the training time tend to infinity.\nSpecifically, for a general class of nonlinear parabolic PDEs with a neural\nnetwork embedded in the source term, we prove convergence of the trained\nneural-network PDE solution to the target data (i.e., a global minimizer). The\nglobal convergence proof poses a unique mathematical challenge that is not\nencountered in finite-dimensional neural network convergence analyses due to\n(1) the neural network training dynamics involving a non-local neural network\nkernel operator in the infinite-width hidden layer limit where the kernel lacks\na spectral gap for its eigenvalues and (2) the nonlinearity of the limit PDE\nsystem, which leads to a non-convex optimization problem, even in the\ninfinite-width hidden layer limit (unlike in typical neual network training\ncases where the optimization problem becomes convex in the large neuron limit).\nThe theoretical results are illustrated and empirically validated by numerical\nstudies.", "published": "2025-06-16 16:00:00", "link": "http://arxiv.org/abs/2506.13633v1", "categories": ["cs.LG", "cs.NA", "math.AP", "math.NA", "math.OC", "49M41, 35Q93, 68T07, 90C26, 35K55"], "primary_category": "cs.LG"}
{"title": "Variational Inference with Mixtures of Isotropic Gaussians", "abstract": "Variational inference (VI) is a popular approach in Bayesian inference, that\nlooks for the best approximation of the posterior distribution within a\nparametric family, minimizing a loss that is typically the (reverse)\nKullback-Leibler (KL) divergence. In this paper, we focus on the following\nparametric family: mixtures of isotropic Gaussians (i.e., with diagonal\ncovariance matrices proportional to the identity) and uniform weights. We\ndevelop a variational framework and provide efficient algorithms suited for\nthis family. In contrast with mixtures of Gaussian with generic covariance\nmatrices, this choice presents a balance between accurate approximations of\nmultimodal Bayesian posteriors, while being memory and computationally\nefficient. Our algorithms implement gradient descent on the location of the\nmixture components (the modes of the Gaussians), and either (an entropic)\nMirror or Bures descent on their variance parameters. We illustrate the\nperformance of our algorithms on numerical experiments.", "published": "2025-06-16 15:42:15", "link": "http://arxiv.org/abs/2506.13613v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Assessing the Limits of In-Context Learning beyond Functions using Partially Ordered Relation", "abstract": "Generating rational and generally accurate responses to tasks, often\naccompanied by example demonstrations, highlights Large Language Model's\n(LLM's) remarkable In-Context Learning (ICL) capabilities without requiring\nupdates to the model's parameter space. Despite having an ongoing exploration\nfocused on the inference from a document-level concept, its behavior in\nlearning well-defined functions or relations in context needs a careful\ninvestigation. In this article, we present the performance of ICL on partially\nordered relation by introducing the notion of inductively increasing complexity\nin prompts. In most cases, the saturated performance of the chosen metric\nindicates that while ICL offers some benefits, its effectiveness remains\nconstrained as we increase the complexity in the prompts even in presence of\nsufficient demonstrative examples. The behavior is evident from our empirical\nfindings and has further been theoretically justified in term of its implicit\noptimization process. The code is available\n\\href{https://anonymous.4open.science/r/ICLonPartiallyOrderSet}{here}.", "published": "2025-06-16 15:35:41", "link": "http://arxiv.org/abs/2506.13608v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Calibrated Predictive Lower Bounds on Time-to-Unsafe-Sampling in LLMs", "abstract": "We develop a framework to quantify the time-to-unsafe-sampling - the number\nof large language model (LLM) generations required to trigger an unsafe (e.g.,\ntoxic) response. Estimating this quantity is challenging, since unsafe\nresponses are exceedingly rare in well-aligned LLMs, potentially occurring only\nonce in thousands of generations. As a result, directly estimating\ntime-to-unsafe-sampling would require collecting training data with a\nprohibitively large number of generations per prompt. However, with realistic\nsampling budgets, we often cannot generate enough responses to observe an\nunsafe outcome for every prompt, leaving the time-to-unsafe-sampling unobserved\nin many cases, making the estimation and evaluation tasks particularly\nchallenging. To address this, we frame this estimation problem as one of\nsurvival analysis and develop a provably calibrated lower predictive bound\n(LPB) on the time-to-unsafe-sampling of a given prompt, leveraging recent\nadvances in conformal prediction. Our key innovation is designing an adaptive,\nper-prompt sampling strategy, formulated as a convex optimization problem. The\nobjective function guiding this optimized sampling allocation is designed to\nreduce the variance of the estimators used to construct the LPB, leading to\nimproved statistical efficiency over naive methods that use a fixed sampling\nbudget per prompt. Experiments on both synthetic and real data support our\ntheoretical results and demonstrate the practical utility of our method for\nsafety risk assessment in generative AI models.", "published": "2025-06-16 15:21:25", "link": "http://arxiv.org/abs/2506.13593v1", "categories": ["cs.LG", "stat.AP", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Machine Learning-Driven Compensation for Non-Ideal Channels in AWG-Based FBG Interrogator", "abstract": "We present an experimental study of a fiber Bragg grating (FBG) interrogator\nbased on a silicon oxynitride (SiON) photonic integrated arrayed waveguide\ngrating (AWG). While AWG-based interrogators are compact and scalable, their\npractical performance is limited by non-ideal spectral responses. To address\nthis, two calibration strategies within a 2.4 nm spectral region were compared:\n(1) a segmented analytical model based on a sigmoid fitting function, and (2) a\nmachine learning (ML)-based regression model. The analytical method achieves a\nroot mean square error (RMSE) of 7.11 pm within the calibrated range, while the\nML approach based on exponential regression achieves 3.17 pm. Moreover, the ML\nmodel demonstrates generalization across an extended 2.9 nm wavelength span,\nmaintaining sub-5 pm accuracy without re-fitting. Residual and error\ndistribution analyses further illustrate the trade-offs between the two\napproaches. ML-based calibration provides a robust, data-driven alternative to\nanalytical methods, delivering enhanced accuracy for non-ideal channel\nresponses, reduced manual calibration effort, and improved scalability across\ndiverse FBG sensor configurations.", "published": "2025-06-16 14:58:03", "link": "http://arxiv.org/abs/2506.13575v1", "categories": ["physics.optics", "cs.LG"], "primary_category": "physics.optics"}
{"title": "Stability Analysis of Physics-Informed Neural Networks via Variational Coercivity, Perturbation Bounds, and Concentration Estimates", "abstract": "We develop a rigorous stability framework for Physics-Informed Neural\nNetworks (PINNs) grounded in variational analysis, operator coercivity, and\nexplicit perturbation theory. PINNs approximate solutions to partial\ndifferential equations (PDEs) by minimizing residual-based losses over sampled\ncollocation points. We derive deterministic stability bounds that quantify how\nbounded perturbations in the network output propagate through both residual and\nsupervised loss components. Probabilistic stability is established via\nMcDiarmid's inequality, yielding non-asymptotic concentration bounds that link\nsampling variability to empirical loss fluctuations under minimal assumptions.\nGeneralization from Sobolev-norm training loss to uniform approximation is\nanalyzed using coercivity and Sobolev embeddings, leading to pointwise error\ncontrol. The theoretical results apply to both scalar and vector-valued PDEs\nand cover composite loss formulations. Numerical experiments validate the\nperturbation sensitivity, sample complexity estimates, and Sobolev-to-uniform\ngeneralization bounds. This work provides a mathematically grounded and\npractically applicable stability framework for PINNs, clarifying the role of\noperator structure, sampling design, and functional regularity in robust\ntraining.", "published": "2025-06-16 14:41:15", "link": "http://arxiv.org/abs/2506.13554v1", "categories": ["cs.LG", "cs.NA", "math.FA", "math.NA"], "primary_category": "cs.LG"}
{"title": "What Matters in Learning from Large-Scale Datasets for Robot Manipulation", "abstract": "Imitation learning from large multi-task demonstration datasets has emerged\nas a promising path for building generally-capable robots. As a result, 1000s\nof hours have been spent on building such large-scale datasets around the\nglobe. Despite the continuous growth of such efforts, we still lack a\nsystematic understanding of what data should be collected to improve the\nutility of a robotics dataset and facilitate downstream policy learning. In\nthis work, we conduct a large-scale dataset composition study to answer this\nquestion. We develop a data generation framework to procedurally emulate common\nsources of diversity in existing datasets (such as sensor placements and object\ntypes and arrangements), and use it to generate large-scale robot datasets with\ncontrolled compositions, enabling a suite of dataset composition studies that\nwould be prohibitively expensive in the real world. We focus on two practical\nsettings: (1) what types of diversity should be emphasized when future\nresearchers collect large-scale datasets for robotics, and (2) how should\ncurrent practitioners retrieve relevant demonstrations from existing datasets\nto maximize downstream policy performance on tasks of interest. Our study\nyields several critical insights -- for example, we find that camera poses and\nspatial arrangements are crucial dimensions for both diversity in collection\nand alignment in retrieval. In real-world robot learning settings, we find that\nnot only do our insights from simulation carry over, but our retrieval\nstrategies on existing datasets such as DROID allow us to consistently\noutperform existing training strategies by up to 70%. More results at\nhttps://robo-mimiclabs.github.io/", "published": "2025-06-16 14:25:29", "link": "http://arxiv.org/abs/2506.13536v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Learning Augmented Graph $k$-Clustering", "abstract": "Clustering is a fundamental task in unsupervised learning. Previous research\nhas focused on learning-augmented $k$-means in Euclidean metrics, limiting its\napplicability to complex data representations. In this paper, we generalize\nlearning-augmented $k$-clustering to operate on general metrics, enabling its\napplication to graph-structured and non-Euclidean domains. Our framework also\nrelaxes restrictive cluster size constraints, providing greater flexibility for\ndatasets with imbalanced or unknown cluster distributions. Furthermore, we\nextend the hardness of query complexity to general metrics: under the\nExponential Time Hypothesis (ETH), we show that any polynomial-time algorithm\nmust perform approximately $\\Omega(k / \\alpha)$ queries to achieve a $(1 +\n\\alpha)$-approximation. These contributions strengthen both the theoretical\nfoundations and practical applicability of learning-augmented clustering,\nbridging gaps between traditional methods and real-world challenges.", "published": "2025-06-16 14:23:16", "link": "http://arxiv.org/abs/2506.13533v1", "categories": ["cs.LG", "cs.DS"], "primary_category": "cs.LG"}
{"title": "A Survey on Imitation Learning for Contact-Rich Tasks in Robotics", "abstract": "This paper comprehensively surveys research trends in imitation learning for\ncontact-rich robotic tasks. Contact-rich tasks, which require complex physical\ninteractions with the environment, represent a central challenge in robotics\ndue to their nonlinear dynamics and sensitivity to small positional deviations.\nThe paper examines demonstration collection methodologies, including teaching\nmethods and sensory modalities crucial for capturing subtle interaction\ndynamics. We then analyze imitation learning approaches, highlighting their\napplications to contact-rich manipulation. Recent advances in multimodal\nlearning and foundation models have significantly enhanced performance in\ncomplex contact tasks across industrial, household, and healthcare domains.\nThrough systematic organization of current research and identification of\nchallenges, this survey provides a foundation for future advancements in\ncontact-rich robotic manipulation.", "published": "2025-06-16 13:55:20", "link": "http://arxiv.org/abs/2506.13498v1", "categories": ["cs.RO", "cs.HC", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Imaging at the quantum limit with convolutional neural networks", "abstract": "Deep neural networks have been shown to achieve exceptional performance for\ncomputer vision tasks like image recognition, segmentation, and reconstruction\nor denoising. Here, we evaluate the ultimate performance limits of deep\nconvolutional neural network models for image reconstruction, by comparing them\nagainst the standard quantum limit set by shot-noise and the Heisenberg limit\non precision. We train U-Net models on images of natural objects illuminated\nwith coherent states of light, and find that the average mean-squared error of\nthe reconstructions can surpass the standard quantum limit, and in some cases\nreaches the Heisenberg limit. Further, we train models on well-parameterized\nimages for which we can calculate the quantum Cram\\'er-Rao bound to determine\nthe minimum possible measurable variance of an estimated parameter for a given\nprobe state. We find the mean-squared error of the model predictions reaches\nthese bounds calculated for the parameters, across a variety of parameterized\nimages. These results suggest that deep convolutional neural networks can learn\nto become the optimal estimators allowed by the laws of physics, performing\nparameter estimation and image reconstruction at the ultimate possible limits\nof precision for the case of classical illumination of the object.", "published": "2025-06-16 13:45:36", "link": "http://arxiv.org/abs/2506.13488v1", "categories": ["cs.LG", "physics.optics", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Curriculum Learning for Biological Sequence Prediction: The Case of De Novo Peptide Sequencing", "abstract": "Peptide sequencing-the process of identifying amino acid sequences from mass\nspectrometry data-is a fundamental task in proteomics. Non-Autoregressive\nTransformers (NATs) have proven highly effective for this task, outperforming\ntraditional methods. Unlike autoregressive models, which generate tokens\nsequentially, NATs predict all positions simultaneously, leveraging\nbidirectional context through unmasked self-attention. However, existing NAT\napproaches often rely on Connectionist Temporal Classification (CTC) loss,\nwhich presents significant optimization challenges due to CTC's complexity and\nincreases the risk of training failures. To address these issues, we propose an\nimproved non-autoregressive peptide sequencing model that incorporates a\nstructured protein sequence curriculum learning strategy. This approach adjusts\nprotein's learning difficulty based on the model's estimated protein\ngenerational capabilities through a sampling process, progressively learning\npeptide generation from simple to complex sequences. Additionally, we introduce\na self-refining inference-time module that iteratively enhances predictions\nusing learned NAT token embeddings, improving sequence accuracy at a\nfine-grained level. Our curriculum learning strategy reduces NAT training\nfailures frequency by more than 90% based on sampled training over various data\ndistributions. Evaluations on nine benchmark species demonstrate that our\napproach outperforms all previous methods across multiple metrics and species.", "published": "2025-06-16 13:44:25", "link": "http://arxiv.org/abs/2506.13485v1", "categories": ["q-bio.BM", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "Balancing Intensity and Focality in Directional DBS Under Uncertainty: A Simulation Study of Electrode Optimization via a Metaheuristic L1L1 Approach", "abstract": "As DBS technology advances toward directional leads and optimization-based\ncurrent steering, this study aims to improve the selection of electrode contact\nconfigurations using the recently developed L1-norm regularized L1-norm fitting\n(L1L1) method. The focus is in particular on L1L1's capability to incorporate a\npriori lead field uncertainty, offering a potential advantage over conventional\napproaches that do not account for such variability. Our optimization framework\nincorporates uncertainty by constraining the solution space based on lead field\nattenuation. This reflects physiological expectations about the VTA and serves\nto avoid overfitting. By applying this method to 8- and 40-contact electrode\nconfigurations, we optimize current distributions within a discretized finite\nelement (FE) model, focusing on the lead field's characteristics. The model\naccounts for uncertainty through these explicit constraints, enhancing the\nfeasibility, focality, and robustness of the resulting solutions. The L1L1\nmethod was validated through a series of numerical experiments using both\nnoiseless and noisy lead fields, where the noise level was selected to reflect\nattenuation within VTA. It successfully fits and regularizes the current\ndistribution across target structures, with hyperparameter optimization\nextracting either bipolar or multipolar electrode configurations. These\nconfigurations aim to maximize focused current density or prioritize a high\ngain field ratio in a discretized FE model. Compared to traditional methods,\nthe L1L1 approach showed competitive performance in concentrating stimulation\nwithin the target region while minimizing unintended current spread,\nparticularly under noisy conditions. By incorporating uncertainty directly into\nthe optimization process, we obtain a noise-robust framework for current\nsteering, allowing for variations in lead field models and simulation\nparameters.", "published": "2025-06-16 13:12:43", "link": "http://arxiv.org/abs/2506.13452v1", "categories": ["math.OC", "cs.LG", "90C08"], "primary_category": "math.OC"}
{"title": "Spiking Neural Networks for Low-Power Vibration-Based Predictive Maintenance", "abstract": "Advancements in Industrial Internet of Things (IIoT) sensors enable\nsophisticated Predictive Maintenance (PM) with high temporal resolution. For\ncost-efficient solutions, vibration-based condition monitoring is especially of\ninterest. However, analyzing high-resolution vibration data via traditional\ncloud approaches incurs significant energy and communication costs, hindering\nbattery-powered edge deployments. This necessitates shifting intelligence to\nthe sensor edge. Due to their event-driven nature, Spiking Neural Networks\n(SNNs) offer a promising pathway toward energy-efficient on-device processing.\nThis paper investigates a recurrent SNN for simultaneous regression (flow,\npressure, pump speed) and multi-label classification (normal, overpressure,\ncavitation) for an industrial progressing cavity pump (PCP) using 3-axis\nvibration data. Furthermore, we provide energy consumption estimates comparing\nthe SNN approach on conventional (x86, ARM) and neuromorphic (Loihi) hardware\nplatforms. Results demonstrate high classification accuracy (>97%) with zero\nFalse Negative Rates for critical Overpressure and Cavitation faults. Smoothed\nregression outputs achieve Mean Relative Percentage Errors below 1% for flow\nand pump speed, approaching industrial sensor standards, although pressure\nprediction requires further refinement. Energy estimates indicate significant\npower savings, with the Loihi consumption (0.0032 J/inf) being up to 3 orders\nof magnitude less compared to the estimated x86 CPU (11.3 J/inf) and ARM CPU\n(1.18 J/inf) execution. Our findings underscore the potential of SNNs for\nmulti-task PM directly on resource-constrained edge devices, enabling scalable\nand energy-efficient industrial monitoring solutions.", "published": "2025-06-16 12:33:09", "link": "http://arxiv.org/abs/2506.13416v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Training Neural Networks by Optimizing Neuron Positions", "abstract": "The high computational complexity and increasing parameter counts of deep\nneural networks pose significant challenges for deployment in\nresource-constrained environments, such as edge devices or real-time systems.\nTo address this, we propose a parameter-efficient neural architecture where\nneurons are embedded in Euclidean space. During training, their positions are\noptimized and synaptic weights are determined as the inverse of the spatial\ndistance between connected neurons. These distance-dependent wiring rules\nreplace traditional learnable weight matrices and significantly reduce the\nnumber of parameters while introducing a biologically inspired inductive bias:\nconnection strength decreases with spatial distance, reflecting the brain's\nembedding in three-dimensional space where connections tend to minimize wiring\nlength. We validate this approach for both multi-layer perceptrons and spiking\nneural networks. Through a series of experiments, we demonstrate that these\nspatially embedded neural networks achieve a performance competitive with\nconventional architectures on the MNIST dataset. Additionally, the models\nmaintain performance even at pruning rates exceeding 80% sparsity,\noutperforming traditional networks with the same number of parameters under\nsimilar conditions. Finally, the spatial embedding framework offers an\nintuitive visualization of the network structure.", "published": "2025-06-16 12:26:13", "link": "http://arxiv.org/abs/2506.13410v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "HELENA: High-Efficiency Learning-based channel Estimation using dual Neural Attention", "abstract": "Accurate channel estimation is critical for high-performance Orthogonal\nFrequency-Division Multiplexing systems such as 5G New Radio, particularly\nunder low signal-to-noise ratio and stringent latency constraints. This letter\npresents HELENA, a compact deep learning model that combines a lightweight\nconvolutional backbone with two efficient attention mechanisms: patch-wise\nmulti-head self-attention for capturing global dependencies and a\nsqueeze-and-excitation block for local feature refinement. Compared to CEViT, a\nstate-of-the-art vision transformer-based estimator, HELENA reduces inference\ntime by 45.0\\% (0.175\\,ms vs.\\ 0.318\\,ms), achieves comparable accuracy\n($-16.78$\\,dB vs.\\ $-17.30$\\,dB), and requires $8\\times$ fewer parameters\n(0.11M vs.\\ 0.88M), demonstrating its suitability for low-latency, real-time\ndeployment.", "published": "2025-06-16 12:21:27", "link": "http://arxiv.org/abs/2506.13408v1", "categories": ["eess.SP", "cs.LG", "cs.NI"], "primary_category": "eess.SP"}
{"title": "Realtime-Capable Hybrid Spiking Neural Networks for Neural Decoding of Cortical Activity", "abstract": "Intra-cortical brain-machine interfaces (iBMIs) present a promising solution\nto restoring and decoding brain activity lost due to injury. However, patients\nwith such neuroprosthetics suffer from permanent skull openings resulting from\nthe devices' bulky wiring. This drives the development of wireless iBMIs, which\ndemand low power consumption and small device footprint. Most recently, spiking\nneural networks (SNNs) have been researched as potential candidates for\nlow-power neural decoding. In this work, we present the next step of utilizing\nSNNs for such tasks, building on the recently published results of the 2024\nGrand Challenge on Neural Decoding Challenge for Motor Control of non-Human\nPrimates. We optimize our model architecture to exceed the existing state of\nthe art on the Primate Reaching dataset while maintaining similar resource\ndemand through various compression techniques. We further focus on implementing\na realtime-capable version of the model and discuss the implications of this\narchitecture. With this, we advance one step towards latency-free decoding of\ncortical spike trains using neuromorphic technology, ultimately improving the\nlives of millions of paralyzed patients.", "published": "2025-06-16 12:08:08", "link": "http://arxiv.org/abs/2506.13400v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Experimental Design for Semiparametric Bandits", "abstract": "We study finite-armed semiparametric bandits, where each arm's reward\ncombines a linear component with an unknown, potentially adversarial shift.\nThis model strictly generalizes classical linear bandits and reflects\ncomplexities common in practice. We propose the first experimental-design\napproach that simultaneously offers a sharp regret bound, a PAC bound, and a\nbest-arm identification guarantee. Our method attains the minimax regret\n$\\tilde{O}(\\sqrt{dT})$, matching the known lower bound for finite-armed linear\nbandits, and further achieves logarithmic regret under a positive suboptimality\ngap condition. These guarantees follow from our refined non-asymptotic analysis\nof orthogonalized regression that attains the optimal $\\sqrt{d}$ rate, paving\nthe way for robust and efficient learning across a broad class of\nsemiparametric bandit problems.", "published": "2025-06-16 11:53:00", "link": "http://arxiv.org/abs/2506.13390v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Learning to Explore in Diverse Reward Settings via Temporal-Difference-Error Maximization", "abstract": "Numerous heuristics and advanced approaches have been proposed for\nexploration in different settings for deep reinforcement learning. Noise-based\nexploration generally fares well with dense-shaped rewards and bonus-based\nexploration with sparse rewards. However, these methods usually require\nadditional tuning to deal with undesirable reward settings by adjusting\nhyperparameters and noise distributions. Rewards that actively discourage\nexploration, i.e., with an action cost and no other dense signal to follow, can\npose a major challenge. We propose a novel exploration method, Stable\nError-seeking Exploration (SEE), that is robust across dense, sparse, and\nexploration-adverse reward settings. To this endeavor, we revisit the idea of\nmaximizing the TD-error as a separate objective. Our method introduces three\ndesign choices to mitigate instability caused by far-off-policy learning, the\nconflict of interest of maximizing the cumulative TD-error in an episodic\nsetting, and the non-stationary nature of TD-errors. SEE can be combined with\noff-policy algorithms without modifying the optimization pipeline of the\noriginal objective. In our experimental analysis, we show that a Soft-Actor\nCritic agent with the addition of SEE performs robustly across three diverse\nreward settings in a variety of tasks without hyperparameter adjustments.", "published": "2025-06-16 10:36:24", "link": "http://arxiv.org/abs/2506.13345v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Mixture of Cognitive Reasoners: Modular Reasoning with Brain-Like Specialization", "abstract": "Human intelligence emerges from the interaction of specialized brain\nnetworks, each dedicated to distinct cognitive functions such as language\nprocessing, logical reasoning, social understanding, and memory retrieval.\nInspired by this biological observation, we introduce the Mixture of Cognitive\nReasoners (MiCRo) architecture and training paradigm: a modular\ntransformer-based language model with a training curriculum that encourages the\nemergence of functional specialization among different modules. Inspired by\nstudies in neuroscience, we partition the layers of a pretrained transformer\nmodel into four expert modules, each corresponding to a well-studied cognitive\nbrain network. Our Brain-Like model has three key benefits over the state of\nthe art: First, the specialized experts are highly interpretable and\nfunctionally critical, where removing a module significantly impairs\nperformance on domain-relevant benchmarks. Second, our model outperforms\ncomparable baselines that lack specialization on seven reasoning benchmarks.\nAnd third, the model's behavior can be steered at inference time by selectively\nemphasizing certain expert modules (e.g., favoring social over logical\nreasoning), enabling fine-grained control over the style of its response. Our\nfindings suggest that biologically inspired inductive biases involved in human\ncognition lead to significant modeling gains in interpretability, performance,\nand controllability.", "published": "2025-06-16 10:21:54", "link": "http://arxiv.org/abs/2506.13331v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The impact of uncertainty on regularized learning in games", "abstract": "In this paper, we investigate how randomness and uncertainty influence\nlearning in games. Specifically, we examine a perturbed variant of the dynamics\nof \"follow-the-regularized-leader\" (FTRL), where the players' payoff\nobservations and strategy updates are continually impacted by random shocks.\nOur findings reveal that, in a fairly precise sense, \"uncertainty favors\nextremes\": in any game, regardless of the noise level, every player's\ntrajectory of play reaches an arbitrarily small neighborhood of a pure strategy\nin finite time (which we estimate). Moreover, even if the player does not\nultimately settle at this strategy, they return arbitrarily close to some\n(possibly different) pure strategy infinitely often. This prompts the question\nof which sets of pure strategies emerge as robust predictions of learning under\nuncertainty. We show that (a) the only possible limits of the FTRL dynamics\nunder uncertainty are pure Nash equilibria; and (b) a span of pure strategies\nis stable and attracting if and only if it is closed under better replies.\nFinally, we turn to games where the deterministic dynamics are recurrent - such\nas zero-sum games with interior equilibria - and we show that randomness\ndisrupts this behavior, causing the stochastic dynamics to drift toward the\nboundary on average.", "published": "2025-06-16 09:28:22", "link": "http://arxiv.org/abs/2506.13286v1", "categories": ["cs.GT", "cs.LG", "math.OC", "math.PR", "Primary 91A26, 60H10, 37N40, Secondary 91A22, 60H30, 60J70"], "primary_category": "cs.GT"}
{"title": "An Explainable and Interpretable Composite Indicator Based on Decision Rules", "abstract": "Composite indicators are widely used to score or classify units evaluated on\nmultiple criteria. Their construction involves aggregating criteria\nevaluations, a common practice in Multiple Criteria Decision Aiding (MCDA). In\nMCDA, various methods have been proposed to address key aspects of multiple\ncriteria evaluations, such as the measurement scales of the criteria, the\ndegree of acceptable compensation between them, and their potential\ninteractions. However, beyond producing a final score or classification, it is\nessential to ensure the explainability and interpretability of results as well\nas the procedure's transparency. This paper proposes a method for constructing\nexplainable and interpretable composite indicators using \"if..., then...\"\ndecision rules. We consider the explainability and interpretability of\ncomposite indicators in four scenarios: (i) decision rules explain numerical\nscores obtained from an aggregation of numerical codes corresponding to ordinal\nqualifiers; (ii) an obscure numerical composite indicator classifies units into\nquantiles; (iii) given preference information provided by a Decision Maker in\nthe form of classifications of some reference units, a composite indicator is\nconstructed using decision rules; (iv) the classification of a set of units\nresults from the application of an MCDA method and is explained by decision\nrules. To induce the rules from scored or classified units, we apply the\nDominance-based Rough Set Approach. The resulting decision rules relate the\nclass assignment or unit's score to threshold conditions on values of selected\nindicators in an intelligible way, clarifying the underlying rationale.\nMoreover, they serve to recommend composite indicator assessment for new units\nof interest.", "published": "2025-06-16 09:00:12", "link": "http://arxiv.org/abs/2506.13259v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Lightweight Task-Oriented Semantic Communication Empowered by Large-Scale AI Models", "abstract": "Recent studies have focused on leveraging large-scale artificial intelligence\n(LAI) models to improve semantic representation and compression capabilities.\nHowever, the substantial computational demands of LAI models pose significant\nchallenges for real-time communication scenarios. To address this, this paper\nproposes utilizing knowledge distillation (KD) techniques to extract and\ncondense knowledge from LAI models, effectively reducing model complexity and\ncomputation latency. Nevertheless, the inherent complexity of LAI models leads\nto prolonged inference times during distillation, while their lack of channel\nawareness compromises the distillation performance. These limitations make\nstandard KD methods unsuitable for task-oriented semantic communication\nscenarios. To address these issues, we propose a fast distillation method\nfeaturing a pre-stored compression mechanism that eliminates the need for\nrepetitive inference, significantly improving efficiency. Furthermore, a\nchannel adaptive module is incorporated to dynamically adjust the transmitted\nsemantic information based on varying channel conditions, enhancing\ncommunication reliability and adaptability. In addition, an information\nbottleneck-based loss function is derived to guide the fast distillation\nprocess. Simulation results verify that the proposed scheme outperform\nbaselines in term of task accuracy, model size, computation latency, and\ntraining data requirements.", "published": "2025-06-16 08:42:16", "link": "http://arxiv.org/abs/2506.13243v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "The Butterfly Effect: Neural Network Training Trajectories Are Highly Sensitive to Initial Conditions", "abstract": "Neural network training is inherently sensitive to initialization and the\nrandomness induced by stochastic gradient descent. However, it is unclear to\nwhat extent such effects lead to meaningfully different networks, either in\nterms of the models' weights or the underlying functions that were learned. In\nthis work, we show that during the initial \"chaotic\" phase of training, even\nextremely small perturbations reliably causes otherwise identical training\ntrajectories to diverge-an effect that diminishes rapidly over training time.\nWe quantify this divergence through (i) $L^2$ distance between parameters, (ii)\nthe loss barrier when interpolating between networks, (iii) $L^2$ and barrier\nbetween parameters after permutation alignment, and (iv) representational\nsimilarity between intermediate activations; revealing how perturbations across\ndifferent hyperparameter or fine-tuning settings drive training trajectories\ntoward distinct loss minima. Our findings provide insights into neural network\ntraining stability, with practical implications for fine-tuning, model merging,\nand diversity of model ensembles.", "published": "2025-06-16 08:35:16", "link": "http://arxiv.org/abs/2506.13234v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Polyra Swarms: A Shape-Based Approach to Machine Learning", "abstract": "We propose Polyra Swarms, a novel machine-learning approach that approximates\nshapes instead of functions. Our method enables general-purpose learning with\nvery low bias. In particular, we show that depending on the task, Polyra Swarms\ncan be preferable compared to neural networks, especially for tasks like\nanomaly detection. We further introduce an automated abstraction mechanism that\nsimplifies the complexity of a Polyra Swarm significantly, enhancing both their\ngeneralization and transparency. Since Polyra Swarms operate on fundamentally\ndifferent principles than neural networks, they open up new research directions\nwith distinct strengths and limitations.", "published": "2025-06-16 08:16:54", "link": "http://arxiv.org/abs/2506.13217v1", "categories": ["cs.LG", "cs.NE", "cs.SC"], "primary_category": "cs.LG"}
{"title": "Fatigue-Aware Adaptive Interfaces for Wearable Devices Using Deep Learning", "abstract": "Wearable devices, such as smartwatches and head-mounted displays, are\nincreasingly used for prolonged tasks like remote learning and work, but\nsustained interaction often leads to user fatigue, reducing efficiency and\nengagement. This study proposes a fatigue-aware adaptive interface system for\nwearable devices that leverages deep learning to analyze physiological data\n(e.g., heart rate, eye movement) and dynamically adjust interface elements to\nmitigate cognitive load. The system employs multimodal learning to process\nphysiological and contextual inputs and reinforcement learning to optimize\ninterface features like text size, notification frequency, and visual contrast.\nExperimental results show a 18% reduction in cognitive load and a 22%\nimprovement in user satisfaction compared to static interfaces, particularly\nfor users engaged in prolonged tasks. This approach enhances accessibility and\nusability in wearable computing environments.", "published": "2025-06-16 08:07:07", "link": "http://arxiv.org/abs/2506.13203v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "KEPLA: A Knowledge-Enhanced Deep Learning Framework for Accurate Protein-Ligand Binding Affinity Prediction", "abstract": "Accurate prediction of protein-ligand binding affinity is critical for drug\ndiscovery. While recent deep learning approaches have demonstrated promising\nresults, they often rely solely on structural features, overlooking valuable\nbiochemical knowledge associated with binding affinity. To address this\nlimitation, we propose KEPLA, a novel deep learning framework that explicitly\nintegrates prior knowledge from Gene Ontology and ligand properties of proteins\nand ligands to enhance prediction performance. KEPLA takes protein sequences\nand ligand molecular graphs as input and optimizes two complementary\nobjectives: (1) aligning global representations with knowledge graph relations\nto capture domain-specific biochemical insights, and (2) leveraging cross\nattention between local representations to construct fine-grained joint\nembeddings for prediction. Experiments on two benchmark datasets across both\nin-domain and cross-domain scenarios demonstrate that KEPLA consistently\noutperforms state-of-the-art baselines. Furthermore, interpretability analyses\nbased on knowledge graph relations and cross attention maps provide valuable\ninsights into the underlying predictive mechanisms.", "published": "2025-06-16 08:02:42", "link": "http://arxiv.org/abs/2506.13196v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "GeoRecon: Graph-Level Representation Learning for 3D Molecules via Reconstruction-Based Pretraining", "abstract": "The pretraining-and-finetuning paradigm has driven significant advances\nacross domains, such as natural language processing and computer vision, with\nrepresentative pretraining paradigms such as masked language modeling and\nnext-token prediction. However, in molecular representation learning, the task\ndesign remains largely limited to node-level denoising, which is effective at\nmodeling local atomic environments, yet maybe insufficient for capturing the\nglobal molecular structure required by graph-level property prediction tasks,\nsuch as energy estimation and molecular regression. In this work, we present\nGeoRecon, a novel graph-level pretraining framework that shifts the focus from\nindividual atoms to the molecule as an integrated whole. GeoRecon introduces a\ngraph-level reconstruction task: during pretraining, the model is trained to\ngenerate an informative graph representation capable of accurately guiding\nreconstruction of the molecular geometry. This encourages the model to learn\ncoherent, global structural features rather than isolated atomic details.\nWithout relying on additional supervision or external data, GeoRecon\noutperforms node-centric baselines on multiple molecular benchmarks (e.g., QM9,\nMD17), demonstrating the benefit of incorporating graph-level reconstruction\nfor learning more holistic and geometry-aware molecular embeddings.", "published": "2025-06-16 07:35:49", "link": "http://arxiv.org/abs/2506.13174v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Efficient Approximate Temporal Triangle Counting in Streaming with Predictions", "abstract": "Triangle counting is a fundamental and widely studied problem on static\ngraphs, and recently on temporal graphs, where edges carry information on the\ntimings of the associated events. Streaming processing and resource efficiency\nare crucial requirements for counting triangles in modern massive temporal\ngraphs, with millions of nodes and up to billions of temporal edges. However,\ncurrent exact and approximate algorithms are unable to handle large-scale\ntemporal graphs. To fill such a gap, we introduce STEP, a scalable and\nefficient algorithm to approximate temporal triangle counts from a stream of\ntemporal edges. STEP combines predictions to the number of triangles a temporal\nedge is involved in, with a simple sampling strategy, leading to scalability,\nefficiency, and accurate approximation of all eight temporal triangle types\nsimultaneously. We analytically prove that, by using a sublinear amount of\nmemory, STEP obtains unbiased and very accurate estimates. In fact, even noisy\npredictions can significantly reduce the variance of STEP's estimates. Our\nextensive experiments on massive temporal graphs with up to billions of edges\ndemonstrate that STEP outputs high-quality estimates and is more efficient than\nstate-of-the-art methods.", "published": "2025-06-16 07:34:54", "link": "http://arxiv.org/abs/2506.13173v1", "categories": ["cs.DS", "cs.LG", "cs.SI"], "primary_category": "cs.DS"}
{"title": "Efficient Algorithms for Logistic Contextual Slate Bandits with Bandit Feedback", "abstract": "We study the Logistic Contextual Slate Bandit problem, where, at each round,\nan agent selects a slate of $N$ items from an exponentially large set (of size\n$2^{\\Omega(N)}$) of candidate slates provided by the environment. A single\nbinary reward, determined by a logistic model, is observed for the chosen\nslate. Our objective is to develop algorithms that maximize cumulative reward\nover $T$ rounds while maintaining low per-round computational costs. We propose\ntwo algorithms, Slate-GLM-OFU and Slate-GLM-TS, that accomplish this goal.\nThese algorithms achieve $N^{O(1)}$ per-round time complexity via local\nplanning (independent slot selections), and low regret through global learning\n(joint parameter estimation). We provide theoretical and empirical evidence\nsupporting these claims. Under a well-studied diversity assumption, we prove\nthat Slate-GLM-OFU incurs only $\\tilde{O}(\\sqrt{T})$ regret. Extensive\nexperiments across a wide range of synthetic settings demonstrate that our\nalgorithms consistently outperform state-of-the-art baselines, achieving both\nthe lowest regret and the fastest runtime. Furthermore, we apply our algorithm\nto select in-context examples in prompts of Language Models for solving binary\nclassification tasks such as sentiment analysis. Our approach achieves\ncompetitive test accuracy, making it a viable alternative in practical\nscenarios.", "published": "2025-06-16 07:19:02", "link": "http://arxiv.org/abs/2506.13163v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Dynamic Preference Multi-Objective Reinforcement Learning for Internet Network Management", "abstract": "An internet network service provider manages its network with multiple\nobjectives, such as high quality of service (QoS) and minimum computing\nresource usage. To achieve these objectives, a reinforcement learning-based\n(RL) algorithm has been proposed to train its network management agent.\nUsually, their algorithms optimize their agents with respect to a single static\nreward formulation consisting of multiple objectives with fixed importance\nfactors, which we call preferences. However, in practice, the preference could\nvary according to network status, external concerns and so on. For example,\nwhen a server shuts down and it can cause other servers' traffic overloads\nleading to additional shutdowns, it is plausible to reduce the preference of\nQoS while increasing the preference of minimum computing resource usages. In\nthis paper, we propose new RL-based network management agents that can select\nactions based on both states and preferences. With our proposed approach, we\nexpect a single agent to generalize on various states and preferences.\nFurthermore, we propose a numerical method that can estimate the distribution\nof preference that is advantageous for unbiased training. Our experiment\nresults show that the RL agents trained based on our proposed approach\nsignificantly generalize better with various preferences than the previous RL\napproaches, which assume static preference during training. Moreover, we\ndemonstrate several analyses that show the advantages of our numerical\nestimation method.", "published": "2025-06-16 07:03:58", "link": "http://arxiv.org/abs/2506.13153v1", "categories": ["cs.NI", "cs.LG"], "primary_category": "cs.NI"}
{"title": "Federated ADMM from Bayesian Duality", "abstract": "ADMM is a popular method for federated deep learning which originated in the\n1970s and, even though many new variants of it have been proposed since then,\nits core algorithmic structure has remained unchanged. Here, we take a major\ndeparture from the old structure and present a fundamentally new way to derive\nand extend federated ADMM. We propose to use a structure called Bayesian\nDuality which exploits a duality of the posterior distributions obtained by\nsolving a variational-Bayesian reformulation of the original problem. We show\nthat this naturally recovers the original ADMM when isotropic Gaussian\nposteriors are used, and yields non-trivial extensions for other posterior\nforms. For instance, full-covariance Gaussians lead to Newton-like variants of\nADMM, while diagonal covariances result in a cheap Adam-like variant. This is\nespecially useful to handle heterogeneity in federated deep learning, giving up\nto 7% accuracy improvements over recent baselines. Our work opens a new\nBayesian path to improve primal-dual methods.", "published": "2025-06-16 07:02:33", "link": "http://arxiv.org/abs/2506.13150v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Random Matrix Theory for Deep Learning: Beyond Eigenvalues of Linear Models", "abstract": "Modern Machine Learning (ML) and Deep Neural Networks (DNNs) often operate on\nhigh-dimensional data and rely on overparameterized models, where classical\nlow-dimensional intuitions break down. In particular, the proportional regime\nwhere the data dimension, sample size, and number of model parameters are all\nlarge and comparable, gives rise to novel and sometimes counterintuitive\nbehaviors. This paper extends traditional Random Matrix Theory (RMT) beyond\neigenvalue-based analysis of linear models to address the challenges posed by\nnonlinear ML models such as DNNs in this regime. We introduce the concept of\nHigh-dimensional Equivalent, which unifies and generalizes both Deterministic\nEquivalent and Linear Equivalent, to systematically address three technical\nchallenges: high dimensionality, nonlinearity, and the need to analyze generic\neigenspectral functionals. Leveraging this framework, we provide precise\ncharacterizations of the training and generalization performance of linear\nmodels, nonlinear shallow networks, and deep networks. Our results capture rich\nphenomena, including scaling laws, double descent, and nonlinear learning\ndynamics, offering a unified perspective on the theoretical understanding of\ndeep learning in high dimensions.", "published": "2025-06-16 06:54:08", "link": "http://arxiv.org/abs/2506.13139v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Stochastic Multi-Objective Multi-Armed Bandits: Regret Definition and Algorithm", "abstract": "Multi-armed bandit (MAB) problems are widely applied to online optimization\ntasks that require balancing exploration and exploitation. In practical\nscenarios, these tasks often involve multiple conflicting objectives, giving\nrise to multi-objective multi-armed bandits (MO-MAB). Existing MO-MAB\napproaches predominantly rely on the Pareto regret metric introduced in\n\\cite{drugan2013designing}. However, this metric has notable limitations,\nparticularly in accounting for all Pareto-optimal arms simultaneously. To\naddress these challenges, we propose a novel and comprehensive regret metric\nthat ensures balanced performance across conflicting objectives. Additionally,\nwe introduce the concept of \\textit{Efficient Pareto-Optimal} arms, which are\nspecifically designed for online optimization. Based on our new metric, we\ndevelop a two-phase MO-MAB algorithm that achieves sublinear regret for both\nPareto-optimal and efficient Pareto-optimal arms.", "published": "2025-06-16 06:09:28", "link": "http://arxiv.org/abs/2506.13125v1", "categories": ["cs.LG", "cs.DS"], "primary_category": "cs.LG"}
{"title": "SAGDA: Open-Source Synthetic Agriculture Data for Africa", "abstract": "Data scarcity in African agriculture hampers machine learning (ML) model\nperformance, limiting innovations in precision agriculture. The Synthetic\nAgriculture Data for Africa (SAGDA) library, a Python-based open-source\ntoolkit, addresses this gap by generating, augmenting, and validating synthetic\nagricultural datasets. We present SAGDA's design and development practices,\nhighlighting its core functions: generate, model, augment, validate, visualize,\noptimize, and simulate, as well as their roles in applications of ML for\nagriculture. Two use cases are detailed: yield prediction enhanced via data\naugmentation, and multi-objective NPK (nitrogen, phosphorus, potassium)\nfertilizer recommendation. We conclude with future plans for expanding SAGDA's\ncapabilities, underscoring the vital role of open-source, data-driven practices\nfor African agriculture.", "published": "2025-06-16 06:06:29", "link": "http://arxiv.org/abs/2506.13123v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Deceptive Path Planning: A Bayesian Game Approach", "abstract": "This paper investigates how an autonomous agent can transmit information\nthrough its motion in an adversarial setting. We consider scenarios where an\nagent must reach its goal while deceiving an intelligent observer about its\ndestination. We model this interaction as a dynamic Bayesian game between a\nmobile Attacker with a privately known goal and a Defender who infers the\nAttacker's intent to allocate defensive resources effectively. We use Perfect\nBayesian Nash Equilibrium (PBNE) as our solution concept and propose a\ncomputationally efficient approach to find it. In the resulting equilibrium,\nthe Defender employs a simple Markovian strategy, while the Attacker\nstrategically balances deception and goal efficiency by stochastically mixing\nshortest and non-shortest paths to manipulate the Defender's beliefs. Numerical\nexperiments demonstrate the advantages of our PBNE-based strategies over\nexisting methods based on one-sided optimization.", "published": "2025-06-16 16:15:25", "link": "http://arxiv.org/abs/2506.13650v1", "categories": ["eess.SY", "cs.GT", "cs.MA", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Mobility to Campus -- a Framework to Evaluate and Compare Different Mobility Modes", "abstract": "The transport sector accounts for about 20% of German CO2 emissions, with\ncommuter traffic contributing a significant part. Particularly in rural areas,\nwhere public transport is inconvenient to use, private cars are a common choice\nfor commuting and most commuters travel alone in their cars. Consolidation of\nsome of these trips has the potential to decrease CO2 emissions and could be\nachieved, e.g., by offering ridesharing (commuters with similar\norigin-destination pairs share a car) or ridepooling (commuters are picked up\nby shuttle services). In this study, we present a framework to assess the\npotential of introducing new mobility modes like ridesharing and ridepooling\nfor commuting towards several locations in close vicinity to each other.\n  We test our framework on the case of student mobility to the University of\nW\\\"urzburg, a university with several campus locations and a big and rather\nrural catchment area, where existing public transport options are inconvenient\nand many students commute by car. We combine data on student home addresses and\ncampus visitation times to create demand scenarios. In our case study, we\ncompare the mobility modes of ridesharing and ridepooling to the base case,\nwhere students travel by car on their own. We find that ridesharing has the\npotential to greatly reduce emissions, depending on the percentage of students\nwilling to use the service and their willingness to walk to the departure\nlocation. The benefit of ridepooling is less clear, materializing only if the\nshuttle vehicles are more energy efficient than the student cars.", "published": "2025-06-16 14:57:48", "link": "http://arxiv.org/abs/2506.13574v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "Towards the Autonomous Optimization of Urban Logistics: Training Generative AI with Scientific Tools via Agentic Digital Twins and Model Context Protocol", "abstract": "Optimizing urban freight logistics is critical for developing sustainable,\nlow-carbon cities. Traditional methods often rely on manual coordination of\nsimulation tools, optimization solvers, and expert-driven workflows, limiting\ntheir efficiency and scalability. This paper presents an agentic system\narchitecture that leverages the model context protocol (MCP) to orchestrate\nmulti-agent collaboration among scientific tools for autonomous,\nsimulation-informed optimization in urban logistics. The system integrates\ngenerative AI agents with domain-specific engines - such as Gurobi for\noptimization and AnyLogic for agent-based simulation - forming a generative\ndigital twin capable of reasoning, planning, and acting across multimodal\nfreight networks. By incorporating integrated chatbots, retrieval-augmented\ngeneration, and structured memory, the framework enables agents to interpret\nuser intent from natural language conversations, retrieve relevant datasets and\nmodels, coordinate solvers and simulators, and execute complex workflows. We\ndemonstrate this approach through a freight decarbonization case study,\nshowcasing how MCP enables modular, interoperable, and adaptive agent behavior\nacross diverse toolchains. The results reveal that our system transforms\ndigital twins from static visualizations into autonomous, decision-capable\nsystems, advancing the frontiers of urban operations research. By enabling\ncontext-aware, generative agents to operate scientific tools automatically and\ncollaboratively, this framework supports more intelligent, accessible, and\ndynamic decision-making in transportation planning and smart city management.", "published": "2025-06-16 03:23:27", "link": "http://arxiv.org/abs/2506.13068v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "A hybrid isogeometric and finite element method: NURBS-enhanced finite element method for hexahedral meshes", "abstract": "In this paper, we present a NURBS-enhanced finite element method that\nintegrates NURBS-based boundary representations of geometric domains into\nstandard finite element frameworks applied to hexahedral meshes. We decompose\nan open, bounded, convex three-dimensional domain with a NURBS boundary into\ntwo parts, define the NURBS-enhanced finite elements over the boundary layer,\nand use piecewise-linear Lagrange finite elements in the interior region. We\nintroduce a novel quadrature rule and a novel interpolation operator for the\nNURBS-enhanced elements. We derive the stability and approximation properties\nof the interpolation operators that we use. We describe how the h-refinement in\nfinite element analysis and the knot insertion in isogeometric analysis can be\nutilized in the refinement of the NURBS-enhanced elements. To illustrate an\napplication of our methodology, we utilize a generic weak formulation of a\nsecond-order elliptic PDE and derive a priori error estimates in the $H^{1}$\nnorm. The proposed methodology combines the efficiency of finite element\nanalysis with the geometric precision of NURBS, and may enable more accurate\nand efficient simulations over complex geometries.", "published": "2025-06-16 16:56:33", "link": "http://arxiv.org/abs/2506.13694v1", "categories": ["math.NA", "cs.NA", "65N30"], "primary_category": "math.NA"}
{"title": "A High-Order, Pressure-Robust, and Decoupled Finite Difference Method for the Stokes Problem", "abstract": "In this paper, we consider the Stokes problem with Dirichlet boundary\nconditions and the constant kinematic viscosity $\\nu$ in an axis-aligned domain\n$\\Omega$. We decouple the velocity $\\bm u$ and pressure $p$ by deriving a novel\nbiharmonic equation in $\\Omega$ and third-order boundary conditions on\n$\\partial\\Omega$. In contrast to the fourth-order streamfunction approach, our\nformulation does not require $\\Omega$ to be simply connected. For smooth\nvelocity fields $\\bm u$ in two dimensions, we explicitly construct a finite\ndifference method (FDM) with sixth-order consistency to approximate $\\bm u$ at\nall relevant grid points: interior points, boundary side points, and boundary\ncorner points. The resulting scheme yields two linear systems\n$A_1u^{(1)}_h=b_1$ and $A_2u^{(2)}_h=b_2$, where $A_1,A_2$ are constant\nmatrices, and $b_1,b_2$ are independent of the pressure $p$ and the kinematic\nviscosity $\\nu$. Thus, the proposed method is pressure- and viscosity-robust.\nTo accommodate velocity fields with less regularity, we modify the FDM by\nremoving singular terms in the right-hand side vectors. Once the discrete\nvelocity is computed, we apply a sixth-order finite difference operator to\napproximate the pressure gradient locally, without solving any additional\nlinear systems. In our numerical experiments, we test both smooth and\nnon-smooth solutions $(\\bm u,p)$ in a square domain, a triply connected domain,\nand an $L$-shaped domain in two dimensions. The results confirm sixth-order\nconvergence of the velocity and pressure gradient in the $\\ell_\\infty$-norm for\nsmooth solutions. For non-smooth velocity fields, our method achieves the\nexpected lower-order convergence. Moreover, the observed velocity error $\\|{\\bm\nu}_h-\\bm u\\|_{\\infty}$ is independent of the pressure $p$ and viscosity $\\nu$.", "published": "2025-06-16 16:08:24", "link": "http://arxiv.org/abs/2506.13645v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Dual guidance: ROM-informed field reconstruction with generative models", "abstract": "We present a dual-guided framework for reconstructing unsteady incompressible\nflow fields using sparse observations. The approach combines optimized sensor\nplacement with a physics-informed guided generative model. Sensor locations are\nselected using mutual information theory applied to a reduced-order model of\nthe flow, enabling efficient identification of high-information observation\npoints with minimal computational cost. These sensors, once selected, provide\ntargeted observations that guide a denoising diffusion probabilistic model\nconditioned by physical constraints. Extensive experiments on 2D laminar\ncylinder wake flows demonstrate that under sparse sensing conditions, the\nstructured sensor layouts fail to capture key flow dynamics, yielding high\nreconstruction errors. In contrast, our optimized sensor placement strategy\nachieves accurate reconstructions with L2 errors as low as 0.05, even with a\nlimited number of sensors, confirming the effectiveness of the proposed\napproach in data-limited regimes. When the number of sensors is higher than a\nthreshold, however, both methods perform comparably. Our dual-guided approach\nbridges reduced order model-based sensor position optimization with modern\ngenerative modeling, providing accurate, physics-consistent reconstruction from\nsparse data for scientific machine-learning problems.", "published": "2025-06-16 11:24:28", "link": "http://arxiv.org/abs/2506.13369v1", "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "primary_category": "physics.flu-dyn"}
{"title": "Conditional a priori error estimates of finite volume and Runge-Kutta discontinuous Galerkin methods with abstract limiting for hyperbolic systems of conservation laws in 1D", "abstract": "We derive conditional a priori error estimates of a wide class of finite\nvolume and Runge-Kutta discontinuous Galerkin methods with abstract limiting\nfor hyperbolic systems of conservation laws in 1D via the verification of weak\nconsistency and entropy stability, as recently proposed by Bressan et\nal.~\\cite{BressanChiriShen21}. Convergence in $L^\\infty L^1$ with rate\n$h^{1/3}$ is obtained under a time step restriction $\\tau\\leq ch$, provided the\nfollowing conditions hold: the exact solution is piecewise Lipschitz\ncontinuous, its (finitely many and isolated) shock curves can be traced with\nprecision $h^{2/3}$ and, outside of these shock tracing tubular neighborhoods\nthe numerical solution -- assumed to be uniformly small in BV -- has\noscillation strength $h$ across each mesh cell and cell boundary.", "published": "2025-06-16 08:20:41", "link": "http://arxiv.org/abs/2506.13221v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Faithful-Newton Framework: Bridging Inner and Outer Solvers for Enhanced Optimization", "abstract": "While Newton-type methods are known for their fast local convergence and\nstrong empirical performance, achieving theoretically favorable global\nconvergence compared to first-order methods remains a key challenge. For\ninstance, surprisingly, for simple strongly convex problems, no straightforward\nvariant of Newton's method matches the global complexity of gradient descent.\nAlthough sophisticated variants can improve iteration complexity over gradient\ndescent for various problems, they often involve highly nontrivial subproblems\nthat incur significantly higher per-iteration costs, resulting in a much worse\noverall operation complexity. These limitations arise from treating the\nsubproblem as an afterthought, either by handling it as a black box, thus\npermitting complex, highly nontrivial, and nearly unimplementable formulations,\nor by evaluating subproblem solutions in isolation, without considering their\neffectiveness in advancing the optimization of the main objective. By\ntightening the integration between the inner iterations of the subproblem\nsolver and the outer iterations of the optimization algorithm, we introduce\nsimple Newton-type variants, called Faithful-Newton methods, which, in a sense,\nremain faithful to the overall simplicity of classical Newton's method by\nretaining simple linear system subproblems. The key conceptual difference,\nhowever, is that the quality of the subproblem solution is directly assessed\nbased on its effectiveness in reducing optimality, which in turn enables\ndesirable convergence complexities across a variety of settings. Under standard\nassumptions, we show that our variants match the worst-case complexity of\ngradient descent in strongly convex settings, both in iteration and operation\ncomplexity, and achieve competitive iteration complexity for general convex\nproblems.", "published": "2025-06-16 07:06:29", "link": "http://arxiv.org/abs/2506.13154v1", "categories": ["math.NA", "cs.NA", "math.OC"], "primary_category": "math.NA"}
{"title": "Optimal ${L^2}$ error estimates for 2D/3D incompressible Cahn--Hilliard--magnetohydrodynamic equations", "abstract": "This paper focuses on an optimal error analysis of a fully discrete finite\nelement scheme for the Cahn--Hilliard--magnetohydrodynamic (CH-MHD) system. The\nmethod use the standard inf-sup stable Taylor--Hood/MINI elements to solve the\nNavier--Stokes equations, Lagrange elements to solve the phase field, and\nparticularly, the N\\'ed\\'elec elements for solving the magnetic induction\nfield. Suffering from the strong coupling and high nonlinearity, the previous\nworks just provide suboptimal error estimates for phase field and velocity\nfield in $L^{2}/\\L^2$-norm under the same order elements, and the suboptimal\nerror estimates for magnetic induction field in $\\H(\\rm curl)$-norm. To this\nend, we utilize the Ritz, Stokes, and Maxwell quasi-projections to eliminate\nthe low-order pollution of the phase field and magnetic induction field. In\naddition to the optimal $\\L^2$-norm error estimates, we present the optimal\nconvergence rates for magnetic induction field in $\\H(\\rm curl)$-norm and for\nvelocity field in $\\H^1$-norm. Moreover, the unconditional energy stability and\nmass conservation of the proposed scheme are preserved. Numerical examples are\nillustrated to validate the theoretical analysis and show the performance of\nthe proposed scheme.", "published": "2025-06-16 03:58:04", "link": "http://arxiv.org/abs/2506.13080v1", "categories": ["math.NA", "cs.NA", "65M12, 65N30, 65M60, 35K55"], "primary_category": "math.NA"}
{"title": "A High-Order Quadrature Method for Implicitly Defined Hypersurfaces and Regions", "abstract": "This paper presents a high-order accurate numerical quadrature algorithm for\nevaluating integrals over curved surfaces and regions defined implicitly via a\nlevel set of a given function restricted to a hyperrectangle. The domain is\ndivided into small tetrahedrons, and by employing the change of variables\nformula, the approach yields an algorithm requiring only one-dimensional root\nfinding and standard Gaussian quadrature. The resulting quadrature scheme\nguarantees strictly positive weights and inherits the high-order accuracy of\nGaussian quadrature. Numerical convergence tests confirm the method's\nhigh-order accuracy.", "published": "2025-06-16 03:51:12", "link": "http://arxiv.org/abs/2506.13078v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Fast Convergence for High-Order ODE Solvers in Diffusion Probabilistic Models", "abstract": "Diffusion probabilistic models generate samples by learning to reverse a\nnoise-injection process that transforms data into noise. Reformulating this\nreverse process as a deterministic probability flow ordinary differential\nequation (ODE) enables efficient sampling using high-order solvers, often\nrequiring only $\\mathcal{O}(10)$ steps. Since the score function is typically\napproximated by a neural network, analyzing the interaction between its\nregularity, approximation error, and numerical integration error is key to\nunderstanding the overall sampling accuracy. In this work, we continue our\nanalysis of the convergence properties of the deterministic sampling methods\nderived from probability flow ODEs [25], focusing on $p$-th order (exponential)\nRunge-Kutta schemes for any integer $p \\geq 1$. Under the assumption that the\nfirst and second derivatives of the approximate score function are bounded, we\ndevelop $p$-th order (exponential) Runge-Kutta schemes and demonstrate that the\ntotal variation distance between the target distribution and the generated data\ndistribution can be bounded above by \\begin{align*}\n  O\\bigl(d^{\\frac{7}{4}}\\varepsilon_{\\text{score}}^{\\frac{1}{2}}\n+d(dH_{\\max})^p\\bigr), \\end{align*} where $\\varepsilon^2_{\\text{score}}$\ndenotes the $L^2$ error in the score function approximation, $d$ is the data\ndimension and $H_{\\max}$ represents the maximum step size used in the solver.\nWe numerically verify the regularity assumption on benchmark datasets,\nconfirming that the first and second derivatives of the approximate score\nfunction remain bounded in practice. Our theoretical guarantees hold for\ngeneral forward processes with arbitrary variance schedules.", "published": "2025-06-16 03:09:25", "link": "http://arxiv.org/abs/2506.13061v1", "categories": ["cs.LG", "cs.NA", "math.CA", "math.NA"], "primary_category": "cs.LG"}
{"title": "A second-order accurate, positive-preserving and mass conservative linear scheme for the Possion-Nernst-Planck equations", "abstract": "The first-order linear positivity preserving schemes in time are available\nfor the time dependent Poisson-Nernst-Planck (PNP) equations, second-order\nlinear ones are still challenging. This paper proposes the first- and\nsecond-order exponential time differencing schemes with the finite difference\nspatial discretization for PNP equations, based on the $Slotboom$\ntransformation of the Nernst-Planck equations and linear stabilization\ntechnique. The proposed schemes are linear and preserve the mass conservation\nand positivity preservation of ion concentration at full discrete level without\nany constraints on the time step size. The corresponding energy stability\nanalysis is also presented, demonstrating that the second-order scheme can\ndissipate the modified energy. Extensive numerical results are carried out to\nsupport the theoretical findings and showcase the performance of the proposed\nschemes.", "published": "2025-06-16 02:50:24", "link": "http://arxiv.org/abs/2506.13054v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Mixed Finite element method for stress gradient elasticity", "abstract": "This paper develops stable finite element pairs for the linear stress\ngradient elasticity model, overcoming classical elasticity's limitations in\ncapturing size effects. We analyze mesh conditions to establish\nparameter-robust error estimates for the proposed pairs, achieving\nunconditional stability for finite elements with higher vertex continuity and\nconditional stability for Continuous Galerkin-Discontinuous Galerkin (CG-DG)\npairs when no interior vertex has edges lying on three or fewer lines.\nNumerical experiments validate the theoretical results, demonstrating optimal\nconvergence rates.", "published": "2025-06-16 02:07:32", "link": "http://arxiv.org/abs/2506.13041v1", "categories": ["math.NA", "cs.NA", "65N30"], "primary_category": "math.NA"}
{"title": "Gradient Boosting for Spatial Regression Models with Autoregressive Disturbances", "abstract": "Researchers in urban and regional studies increasingly deal with spatial data\nthat reflects geographic location and spatial relationships. As a framework for\ndealing with the unique nature of spatial data, various spatial regression\nmodels have been introduced. In this article, a novel model-based gradient\nboosting algorithm for spatial regression models with autoregressive\ndisturbances is proposed. Due to the modular nature, the approach provides an\nalternative estimation procedure which is feasible even in high-dimensional\nsettings where established quasi-maximum likelihood or generalized method of\nmoments estimators do not yield unique solutions. The approach additionally\nenables data-driven variable and model selection in low- as well as\nhigh-dimensional settings. Since the bias-variance trade-off is also controlled\nin the algorithm, implicit regularization is imposed which improves prediction\naccuracy on out-of-sample spatial data. Detailed simulation studies regarding\nthe performance of estimation, prediction and variable selection in low- and\nhigh-dimensional settings confirm proper functionality of the proposed\nmethodology. To illustrative the functionality of the model-based gradient\nboosting algorithm, a case study is presented where the life expectancy in\nGerman districts is modeled incorporating a potential spatial dependence\nstructure.", "published": "2025-06-16 16:40:47", "link": "http://arxiv.org/abs/2506.13682v1", "categories": ["econ.EM", "stat.ML"], "primary_category": "econ.EM"}
{"title": "Computational lower bounds in latent models: clustering, sparse-clustering, biclustering", "abstract": "In many high-dimensional problems, like sparse-PCA, planted clique, or\nclustering, the best known algorithms with polynomial time complexity fail to\nreach the statistical performance provably achievable by algorithms free of\ncomputational constraints. This observation has given rise to the conjecture of\nthe existence, for some problems, of gaps -- so called\nstatistical-computational gaps -- between the best possible statistical\nperformance achievable without computational constraints, and the best\nperformance achievable with poly-time algorithms. A powerful approach to assess\nthe best performance achievable in poly-time is to investigate the best\nperformance achievable by polynomials with low-degree. We build on the seminal\npaper of Schramm and Wein (2022) and propose a new scheme to derive lower\nbounds on the performance of low-degree polynomials in some latent space\nmodels. By better leveraging the latent structures, we obtain new and sharper\nresults, with simplified proofs. We then instantiate our scheme to provide\ncomputational lower bounds for the problems of clustering, sparse clustering,\nand biclustering. We also prove matching upper-bounds and some additional\nstatistical results, in order to provide a comprehensive description of the\nstatistical-computational gaps occurring in these three problems.", "published": "2025-06-16 16:08:30", "link": "http://arxiv.org/abs/2506.13647v1", "categories": ["math.ST", "stat.ML", "stat.TH", "62H30, 68Q17"], "primary_category": "math.ST"}
{"title": "Bayesian Active Learning of (small) Quantile Sets through Expected Estimator Modification", "abstract": "Given a multivariate function taking deterministic and uncertain inputs, we\nconsider the problem of estimating a quantile set: a set of deterministic\ninputs for which the probability that the output belongs to a specific region\nremains below a given threshold. To solve this problem in the context of\nexpensive-to-evaluate black-box functions, we propose a Bayesian active\nlearning strategy based on Gaussian process modeling. The strategy is driven by\na novel sampling criterion, which belongs to a broader principle that we refer\nto as Expected Estimator Modification (EEM). More specifically, the strategy\nrelies on a novel sampling criterion combined with a sequential Monte Carlo\nframework that enables the construction of batch-sequential designs for the\nefficient estimation of small quantile sets. The performance of the strategy is\nillustrated on several synthetic examples and an industrial application case\ninvolving the ROTOR37 compressor model.", "published": "2025-06-16 08:13:48", "link": "http://arxiv.org/abs/2506.13211v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Honesty in Causal Forests: When It Helps and When It Hurts", "abstract": "Causal forests are increasingly used to personalize decisions based on\nestimated treatment effects. A distinctive modeling choice in this method is\nhonest estimation: using separate data for splitting and for estimating effects\nwithin leaves. This practice is the default in most implementations and is\nwidely seen as desirable for causal inference. But we show that honesty can\nhurt the accuracy of individual-level effect estimates. The reason is a classic\nbias-variance trade-off: honesty reduces variance by preventing overfitting,\nbut increases bias by limiting the model's ability to discover and exploit\nmeaningful heterogeneity in treatment effects. This trade-off depends on the\nsignal-to-noise ratio (SNR): honesty helps when effect heterogeneity is hard to\ndetect (low SNR), but hurts when the signal is strong (high SNR). In essence,\nhonesty acts as a form of regularization, and like any regularization choice,\nit should be guided by out-of-sample performance, not adopted by default.", "published": "2025-06-16 05:32:58", "link": "http://arxiv.org/abs/2506.13107v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "CoIFNet: A Unified Framework for Multivariate Time Series Forecasting with Missing Values", "abstract": "Multivariate time series forecasting (MTSF) is a critical task with broad\napplications in domains such as meteorology, transportation, and economics.\nNevertheless, pervasive missing values caused by sensor failures or human\nerrors significantly degrade forecasting accuracy. Prior efforts usually employ\nan impute-then-forecast paradigm, leading to suboptimal predictions due to\nerror accumulation and misaligned objectives between the two stages. To address\nthis challenge, we propose the Collaborative Imputation-Forecasting Network\n(CoIFNet), a novel framework that unifies imputation and forecasting to achieve\nrobust MTSF in the presence of missing values. Specifically, CoIFNet takes the\nobserved values, mask matrix and timestamp embeddings as input, processing them\nsequentially through the Cross-Timestep Fusion (CTF) and Cross-Variate Fusion\n(CVF) modules to capture temporal dependencies that are robust to missing\nvalues. We provide theoretical justifications on how our CoIFNet learning\nobjective improves the performance bound of MTSF with missing values. Through\nextensive experiments on challenging MSTF benchmarks, we demonstrate the\neffectiveness and computational efficiency of our proposed approach across\ndiverse missing-data scenarios, e.g., CoIFNet outperforms the state-of-the-art\nmethod by $\\underline{\\textbf{24.40}}$% ($\\underline{\\textbf{23.81}}$%) at a\npoint (block) missing rate of 0.6, while improving memory and time efficiency\nby $\\underline{\\boldsymbol{4.3\\times}}$ and\n$\\underline{\\boldsymbol{2.1\\times}}$, respectively.", "published": "2025-06-16 03:15:12", "link": "http://arxiv.org/abs/2506.13064v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SpeechRefiner: Towards Perceptual Quality Refinement for Front-End Algorithms", "abstract": "Speech pre-processing techniques such as denoising, de-reverberation, and\nseparation, are commonly employed as front-ends for various downstream speech\nprocessing tasks. However, these methods can sometimes be inadequate, resulting\nin residual noise or the introduction of new artifacts. Such deficiencies are\ntypically not captured by metrics like SI-SNR but are noticeable to human\nlisteners. To address this, we introduce SpeechRefiner, a post-processing tool\nthat utilizes Conditional Flow Matching (CFM) to improve the perceptual quality\nof speech. In this study, we benchmark SpeechRefiner against recent\ntask-specific refinement methods and evaluate its performance within our\ninternal processing pipeline, which integrates multiple front-end algorithms.\nExperiments show that SpeechRefiner exhibits strong generalization across\ndiverse impairment sources, significantly enhancing speech perceptual quality.\nAudio demos can be found at https://speechrefiner.github.io/SpeechRefiner/.", "published": "2025-06-16 17:19:04", "link": "http://arxiv.org/abs/2506.13709v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Persistent Homology of Music Network with Three Different Distances", "abstract": "Persistent homology has been widely used to discover hidden topological\nstructures in data across various applications, including music data. To apply\npersistent homology, a distance or metric must be defined between points in a\npoint cloud or between nodes in a graph network. These definitions are not\nunique and depend on the specific objectives of a given problem. In other\nwords, selecting different metric definitions allows for multiple topological\ninferences. In this work, we focus on applying persistent homology to music\ngraph with predefined weights. We examine three distinct distance definitions\nbased on edge-wise pathways and demonstrate how these definitions affect\npersistent barcodes, persistence diagrams, and birth/death edges. We found that\nthere exist inclusion relations in one-dimensional persistent homology\nreflected on persistence barcode and diagram among these three distance\ndefinitions. We verified these findings using real music data.", "published": "2025-06-16 15:21:32", "link": "http://arxiv.org/abs/2506.13595v1", "categories": ["cs.SD", "cs.CG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Stereo sound event localization and detection based on PSELDnet pretraining and BiMamba sequence modeling", "abstract": "Pre-training methods have achieved significant performance improvements in\nsound event localization and detection (SELD) tasks, but existing\nTransformer-based models suffer from high computational complexity. In this\nwork, we propose a stereo sound event localization and detection system based\non pre-trained PSELDnet and bidirectional Mamba sequence modeling. We replace\nthe Conformer module with a BiMamba module and introduce asymmetric\nconvolutions to more effectively model the spatiotemporal relationships between\ntime and frequency dimensions. Experimental results demonstrate that the\nproposed method achieves significantly better performance than the baseline and\nthe original PSELDnet with Conformer decoder architecture on the DCASE2025 Task\n3 development dataset, while also reducing computational complexity. These\nfindings highlight the effectiveness of the BiMamba architecture in addressing\nthe challenges of the SELD task.", "published": "2025-06-16 13:14:05", "link": "http://arxiv.org/abs/2506.13455v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "BUT System for the MLC-SLM Challenge", "abstract": "We present a two-speaker automatic speech recognition (ASR) system that\ncombines DiCoW -- a diarization-conditioned variant of Whisper -- with\nDiariZen, a diarization pipeline built on top of Pyannote. We first evaluate\nboth systems in out-of-domain (OOD) multilingual scenarios without any\nfine-tuning. In this scenario, DiariZen consistently outperforms the baseline\nPyannote diarization model, demonstrating strong generalization. Despite being\nfine-tuned on English-only data for target-speaker ASR, DiCoW retains solid\nmultilingual performance, indicating that encoder modifications preserve\nWhisper's multilingual capabilities. We then fine-tune both DiCoW and DiariZen\non the MLC-SLM challenge data. The fine-tuned DiariZen continues to outperform\nthe fine-tuned Pyannote baseline, while DiCoW sees further gains from domain\nadaptation. Our final system achieves a micro-average tcpWER/CER of 16.75% and\nranks second in Task 2 of the MLC-SLM challenge. Lastly, we identify several\nlabeling inconsistencies in the training data -- such as missing speech\nsegments and incorrect silence annotations -- which can hinder diarization\nfine-tuning. We propose simple mitigation strategies to address these issues\nand improve system robustness.", "published": "2025-06-16 12:28:35", "link": "http://arxiv.org/abs/2506.13414v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Instance-Specific Test-Time Training for Speech Editing in the Wild", "abstract": "Speech editing systems aim to naturally modify speech content while\npreserving acoustic consistency and speaker identity. However, previous studies\noften struggle to adapt to unseen and diverse acoustic conditions, resulting in\ndegraded editing performance in real-world scenarios. To address this, we\npropose an instance-specific test-time training method for speech editing in\nthe wild. Our approach employs direct supervision from ground-truth acoustic\nfeatures in unedited regions, and indirect supervision in edited regions via\nauxiliary losses based on duration constraints and phoneme prediction. This\nstrategy mitigates the bandwidth discontinuity problem in speech editing,\nensuring smooth acoustic transitions between unedited and edited regions.\nAdditionally, it enables precise control over speech rate by adapting the model\nto target durations via mask length adjustment during test-time training.\nExperiments on in-the-wild benchmark datasets demonstrate that our method\noutperforms existing speech editing systems in both objective and subjective\nevaluations.", "published": "2025-06-16 09:35:23", "link": "http://arxiv.org/abs/2506.13295v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Boundary-Informed Sound Field Reconstruction", "abstract": "We consider the problem of reconstructing the sound field in a room using\nprior information of the boundary geometry, represented as a point cloud. In\ngeneral, when no boundary information is available, an accurate sound field\nreconstruction over a large spatial region and at high frequencies requires\nnumerous microphone measurements. On the other hand, if all geometrical and\nacoustical aspects of the boundaries are known, the sound field could, in\ntheory, be simulated without any measurements. In this work, we address the\nintermediate case, where only partial or uncertain boundary information is\navailable. This setting is similar to one studied in virtual reality\napplications, where the goal is to create a perceptually convincing audio\nexperience. In this work, we focus on spatial sound control applications, which\nin contrast require an accurate sound field reconstruction. Therefore, we\nformulate the problem within a linear Bayesian framework, incorporating a\nboundary-informed prior derived from impedance boundary conditions. The\nformulation allows for joint optimization of the unknown hyperparameters,\nincluding the noise and signal variances and the impedance boundary conditions.\nUsing numerical experiments, we show that incorporating the boundary-informed\nprior significantly enhances the reconstruction, notably even when only a few\nhundreds of boundary points are available or when the boundary positions are\ncalibrated with an uncertainty up to 1 dm.", "published": "2025-06-16 09:18:01", "link": "http://arxiv.org/abs/2506.13279v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "I$^2$S-TFCKD: Intra-Inter Set Knowledge Distillation with Time-Frequency Calibration for Speech Enhancement", "abstract": "In recent years, complexity compression of neural network (NN)-based speech\nenhancement (SE) models has gradually attracted the attention of researchers,\nespecially in scenarios with limited hardware resources or strict latency\nrequirements. The main difficulties and challenges lie in achieving a balance\nbetween complexity and performance according to the characteristics of the\ntask. In this paper, we propose an intra-inter set knowledge distillation (KD)\nframework with time-frequency calibration (I$^2$S-TFCKD) for SE. Different from\nprevious distillation strategies for SE, the proposed framework fully utilizes\nthe time-frequency differential information of speech while promoting global\nknowledge flow. Firstly, we propose a multi-layer interactive distillation\nbased on dual-stream time-frequency cross-calibration, which calculates the\nteacher-student similarity calibration weights in the time and frequency\ndomains respectively and performs cross-weighting, thus enabling refined\nallocation of distillation contributions across different layers according to\nspeech characteristics. Secondly, we construct a collaborative distillation\nparadigm for intra-set and inter-set correlations. Within a correlated set,\nmulti-layer teacher-student features are pairwise matched for calibrated\ndistillation. Subsequently, we generate representative features from each\ncorrelated set through residual fusion to form the fused feature set that\nenables inter-set knowledge interaction. The proposed distillation strategy is\napplied to the dual-path dilated convolutional recurrent network (DPDCRN) that\nranked first in the SE track of the L3DAS23 challenge. Objective evaluations\ndemonstrate that the proposed KD strategy consistently and effectively improves\nthe performance of the low-complexity student model and outperforms other\ndistillation schemes.", "published": "2025-06-16 06:20:09", "link": "http://arxiv.org/abs/2506.13127v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching", "abstract": "Existing large-scale zero-shot text-to-speech (TTS) models deliver high\nspeech quality but suffer from slow inference speeds due to massive parameters.\nTo address this issue, this paper introduces ZipVoice, a high-quality\nflow-matching-based zero-shot TTS model with a compact model size and fast\ninference speed. Key designs include: 1) a Zipformer-based flow-matching\ndecoder to maintain adequate modeling capabilities under constrained size; 2)\nAverage upsampling-based initial speech-text alignment and Zipformer-based text\nencoder to improve speech intelligibility; 3) A flow distillation method to\nreduce sampling steps and eliminate the inference overhead associated with\nclassifier-free guidance. Experiments on 100k hours multilingual datasets show\nthat ZipVoice matches state-of-the-art models in speech quality, while being 3\ntimes smaller and up to 30 times faster than a DiT-based flow-matching\nbaseline. Codes, model checkpoints and demo samples are publicly available.", "published": "2025-06-16 02:48:17", "link": "http://arxiv.org/abs/2506.13053v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Personalizable Long-Context Symbolic Music Infilling with MIDI-RWKV", "abstract": "Existing work in automatic music generation has primarily focused on\nend-to-end systems that produce complete compositions or continuations.\nHowever, because musical composition is typically an iterative process, such\nsystems make it difficult to engage in the back-and-forth between human and\nmachine that is essential to computer-assisted creativity. In this study, we\naddress the task of personalizable, multi-track, long-context, and controllable\nsymbolic music infilling to enhance the process of computer-assisted\ncomposition. We present MIDI-RWKV, a novel model based on the RWKV-7 linear\narchitecture, to enable efficient and coherent musical cocreation on edge\ndevices. We also demonstrate that MIDI-RWKV admits an effective method of\nfinetuning its initial state for personalization in the very-low-sample regime.\nWe evaluate MIDI-RWKV and its state tuning on several quantitative and\nqualitative metrics, and release model weights and code at\nhttps://github.com/christianazinn/MIDI-RWKV.", "published": "2025-06-16 00:04:01", "link": "http://arxiv.org/abs/2506.13001v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS", "I.2.1; I.2.6; H.5.5; J.5"], "primary_category": "cs.SD"}
{"title": "Robust Recursive Fusion of Multiresolution Multispectral Images with Location-Aware Neural Networks", "abstract": "Multiresolution image fusion is a key problem for real-time satellite imaging\nand plays a central role in detecting and monitoring natural phenomena such as\nfloods. It aims to solve the trade-off between temporal and spatial resolution\nin remote sensing instruments. Although several algorithms have been proposed\nfor this problem, the presence of outliers such as clouds downgrades their\nperformance. Moreover, strategies that integrate robustness, recursive\noperation and learned models are missing. In this paper, a robust recursive\nimage fusion framework leveraging location-aware neural networks (NN) to model\nthe image dynamics is proposed. Outliers are modeled by representing the\nprobability of contamination of a given pixel and band. A NN model trained on a\nsmall dataset provides accurate predictions of the stochastic image time\nevolution, which improves both the accuracy and robustness of the method. A\nrecursive solution is proposed to estimate the high-resolution images using a\nBayesian variational inference framework. Experiments fusing images from the\nLandsat 8 and MODIS instruments show that the proposed approach is\nsignificantly more robust against cloud cover, without losing performance when\nno clouds are present.", "published": "2025-06-16 17:41:36", "link": "http://arxiv.org/abs/2506.13733v1", "categories": ["eess.IV", "eess.SP"], "primary_category": "eess.IV"}
{"title": "Intelligent Metasurface-Enabled Integrated Sensing and Communication: Unified Framework and Key Technologies", "abstract": "As the demand for ubiquitous connectivity and high-precision environmental\nawareness grows, integrated sensing and communication (ISAC) has emerged as a\nkey technology for sixth-generation (6G) wireless networks. Intelligent\nmetasurfaces (IMs) have also been widely adopted in ISAC scenarios due to their\nefficient, programmable control over electromagnetic waves. This provides a\nversatile solution that meets the dual-function requirements of next-generation\nnetworks. Although reconfigurable intelligent surfaces (RISs) have been\nextensively studied for manipulating the propagation channel between base and\nmobile stations, the full potential of IMs in ISAC transceiver design remains\nunder-explored. Against this backdrop, this article explores emerging\nIM-enabled transceiver designs for ISAC systems. It begins with an overview of\nrepresentative IM architectures, their unique principles, and their inherent\nadvantages in EM wave manipulation. Next, a unified ISAC framework is\nestablished to systematically model the design and derivation of diverse\nIM-enabled transceiver structures. This lays the foundation for performance\noptimization, trade-offs, and analysis. The paper then discusses several\ncritical technologies for IM-enabled ISAC transceivers, including dedicated\nchannel modeling, effective channel estimation, tailored beamforming\nstrategies, and dual-functional waveform design.", "published": "2025-06-16 17:23:27", "link": "http://arxiv.org/abs/2506.13713v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching-Antenna Systems (PASS) Meet Multiple Access: NOMA or OMA?", "abstract": "A fundamental two-user PASS-based communication system is considered under\nthree MA schemes, namely non-orthogonal multiple access (NOMA), frequency\ndivision multiple access (FDMA), and time division multiple access (TDMA). For\neach MA scheme, a pinching beamforming optimization problem is formulated to\nminimize the required transmit power for satisfying users' rate requirements.\nFor NOMA and FDMA, a two-stage algorithm is proposed, where the locations of\nPAs are derived sequentially by using the successive convex approximation (SCA)\nmethod and fine-turning phase adjustment. For TDMA, by leveraging the\ntime-switching feature of PASS, the optimal pinching beamforming of each time\nslot is derived to maximize the served user channel gain. Numerical results are\nprovided to show that: 1) PASS can achieve a significant performance gain over\nconventional antenna systems, and 2) NOMA consistently outperforms FDMA, while\nTDMA provides superior performance than NOMA for symmetric user rate\nrequirements.", "published": "2025-06-16 13:49:22", "link": "http://arxiv.org/abs/2506.13490v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Performance Analysis of Communication Signals for Localization in Underwater Sensor Networks", "abstract": "Fusion of passive and active measurements from sensor nodes becomes critical\nin localizing underwater objects and is traditionally achieved by communicating\ninformation to a central node. This causes significant inefficiencies in\nbandwidth, energy, and processing time, which are critical in marine\napplications. With integrated sensing and communication (ISAC) systems, the\nprocess of sensing, localization, and communication can be achieved jointly,\nand the inefficiencies can be minimized. Thus, the primary objective of this\nstudy is to analyse the efficacy of such communication signals in localizing a\nmoving target in given underwater conditions. The Cram\\'er-Rao Lower Bound\n(CRLB) is a performance metric used to determine the theoretical lower bound on\nlocalization errors. Simulation results illustrate the contours of localization\nerror across various scenarios, offering valuable insights into system\nperformance under different target dynamics and sea state conditions,\nshowcasing their potential for efficient and reliable underwater localization\napplications.", "published": "2025-06-16 10:21:35", "link": "http://arxiv.org/abs/2506.13330v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "SONIC: Sound Optimization for Noise In Crowds", "abstract": "This paper presents SONIC, an embedded real-time noise suppression system\nimplemented on the ARM Cortex-M7-based STM32H753ZI microcontroller. Using\nadaptive filtering (LMS), the system improves speech intelligibility in noisy\nenvironments. SONIC focuses on a novel approach to noise suppression in audio\nsignals, specifically addressing the limitations of traditional Active Noise\nCancellation (ANC) systems. The paper explores various signal processing\nalgorithms in a micro-controller point of view, highlighting various\nperformance factors and which were considered optimal in our embedded system.\nAdditionally we also discussed the system architecture, explaining how the\nMCU's efficiency was harnessed, along with an in-depth overview of how the\naudio signals were translated within the processor. The results demonstrate\nimproved speech clarity and practical real-time performance, showing low-power\nDSP as an alternative to complex AI denoising methods.", "published": "2025-06-16 09:12:17", "link": "http://arxiv.org/abs/2506.13272v1", "categories": ["cs.SD", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Collaborative Beamforming for Communication Applications Using a Two-Element Fully-Wireless Open-Loop Coherent Distributed Array", "abstract": "In this work we demonstrate a proof of concept of a fully-wireless two-node\nopen-loop coherent distributed communication system and evaluate its\nperformance by transmitting QPSK , 64-, and 256-QAM constellations at a symbol\nrate of 2 MBd over a 58 m link in an urban environment. The system is\nimplemented in a distributed manner with on-node processing using\nsoftware-defined radios (SDRs) and wireless internode communication to share\ncoordination information and does not rely on external time or frequency\nreferences such as the global navigation satellite system (GNSS). In each\nexperiment ~100 messages were transmitted and a mean coherent gain of 0.936 was\nachieved across all measurements with a mean symbol error ratio of below\n$1.4\\times 10^{-4}$ achieved up to 64-QAM, demonstrating a reliable bandwidth\nof up to 12 Mbps.", "published": "2025-06-16 00:52:07", "link": "http://arxiv.org/abs/2506.13014v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Joint Spectrum Sensing and Resource Allocation for OFDMA-based Underwater Acoustic Communications", "abstract": "Underwater acoustic (UWA) communications generally rely on cognitive radio\n(CR)-based ad-hoc networks due to challenges such as long propagation delay,\nlimited channel resources, and high attenuation. To address the constraints of\nlimited frequency resources, UWA communications have recently incorporated\northogonal frequency division multiple access (OFDMA), significantly enhancing\nspectral efficiency (SE) through multiplexing gains. Still, {the} low\npropagation speed of UWA signals, combined with {the} dynamic underwater\nenvironment, creates asynchrony in multiple access scenarios. This causes\ninaccurate spectrum sensing as inter-carrier interference (ICI) increases,\nwhich leads to difficulties in resource allocation. As efficient resource\nallocation is essential for achieving high-quality communication in OFDMA-based\nCR networks, these challenges degrade communication reliability in UWA systems.\nTo resolve the issue, we propose an end-to-end sensing and resource\noptimization method using deep reinforcement learning (DRL) in an OFDMA-based\nUWA-CR network. Through extensive simulations, we confirm that the proposed\nmethod is superior to baseline schemes, outperforming other methods by 42.9 %\nin SE and 4.4 % in communication success rate.", "published": "2025-06-16 00:29:26", "link": "http://arxiv.org/abs/2506.13008v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
