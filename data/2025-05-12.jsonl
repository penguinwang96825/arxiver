{"title": "A Comparative Analysis of Static Word Embeddings for Hungarian", "abstract": "This paper presents a comprehensive analysis of various static word\nembeddings for Hungarian, including traditional models such as Word2Vec,\nFastText, as well as static embeddings derived from BERT-based models using\ndifferent extraction methods. We evaluate these embeddings on both intrinsic\nand extrinsic tasks to provide a holistic view of their performance. For\nintrinsic evaluation, we employ a word analogy task, which assesses the\nembeddings ability to capture semantic and syntactic relationships. Our results\nindicate that traditional static embeddings, particularly FastText, excel in\nthis task, achieving high accuracy and mean reciprocal rank (MRR) scores. Among\nthe BERT-based models, the X2Static method for extracting static embeddings\ndemonstrates superior performance compared to decontextualized and aggregate\nmethods, approaching the effectiveness of traditional static embeddings. For\nextrinsic evaluation, we utilize a bidirectional LSTM model to perform Named\nEntity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The results\nreveal that embeddings derived from dynamic models, especially those extracted\nusing the X2Static method, outperform purely static embeddings. Notably, ELMo\nembeddings achieve the highest accuracy in both NER and POS tagging tasks,\nunderscoring the benefits of contextualized representations even when used in a\nstatic form. Our findings highlight the continued relevance of static word\nembeddings in NLP applications and the potential of advanced extraction methods\nto enhance the utility of BERT-based models. This piece of research contributes\nto the understanding of embedding performance in the Hungarian language and\nprovides valuable insights for future developments in the field. The training\nscripts, evaluation codes, restricted vocabulary, and extracted embeddings will\nbe made publicly available to support further research and reproducibility.", "published": "2025-05-12 17:57:11", "link": "http://arxiv.org/abs/2505.07809v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning Dynamics in Continual Pre-Training for Large Language Models", "abstract": "Continual Pre-Training (CPT) has become a popular and effective method to\napply strong foundation models to specific downstream tasks. In this work, we\nexplore the learning dynamics throughout the CPT process for large language\nmodels. We specifically focus on how general and downstream domain performance\nevolves at each training step, with domain performance measured via validation\nlosses. We have observed that the CPT loss curve fundamentally characterizes\nthe transition from one curve to another hidden curve, and could be described\nby decoupling the effects of distribution shift and learning rate annealing. We\nderive a CPT scaling law that combines the two factors, enabling the prediction\nof loss at any (continual) training steps and across learning rate schedules\n(LRS) in CPT. Our formulation presents a comprehensive understanding of several\ncritical factors in CPT, including loss potential, peak learning rate, training\nsteps, replay ratio, etc. Moreover, our approach can be adapted to customize\ntraining hyper-parameters to different CPT goals such as balancing general and\ndomain-specific performance. Extensive experiments demonstrate that our scaling\nlaw holds across various CPT datasets and training hyper-parameters.", "published": "2025-05-12 17:47:32", "link": "http://arxiv.org/abs/2505.07796v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning from Peers in Reasoning Models", "abstract": "Large Reasoning Models (LRMs) have the ability to self-correct even when they\nmake mistakes in their reasoning paths. However, our study reveals that when\nthe reasoning process starts with a short but poor beginning, it becomes\ndifficult for the model to recover. We refer to this phenomenon as the \"Prefix\nDominance Trap\". Inspired by psychological findings that peer interaction can\npromote self-correction without negatively impacting already accurate\nindividuals, we propose **Learning from Peers** (LeaP) to address this\nphenomenon. Specifically, every tokens, each reasoning path summarizes its\nintermediate reasoning and shares it with others through a routing mechanism,\nenabling paths to incorporate peer insights during inference. However, we\nobserve that smaller models sometimes fail to follow summarization and\nreflection instructions effectively. To address this, we fine-tune them into\nour **LeaP-T** model series. Experiments on AIME 2024, AIME 2025, AIMO 2025,\nand GPQA Diamond show that LeaP provides substantial improvements. For\ninstance, QwQ-32B with LeaP achieves nearly 5 absolute points higher than the\nbaseline on average, and surpasses DeepSeek-R1-671B on three math benchmarks\nwith an average gain of 3.3 points. Notably, our fine-tuned LeaP-T-7B matches\nthe performance of DeepSeek-R1-Distill-Qwen-14B on AIME 2024. In-depth analysis\nreveals LeaP's robust error correction by timely peer insights, showing strong\nerror tolerance and handling varied task difficulty. LeaP marks a milestone by\nenabling LRMs to collaborate during reasoning. Our code, datasets, and models\nare available at https://learning-from-peers.github.io/ .", "published": "2025-05-12 17:39:56", "link": "http://arxiv.org/abs/2505.07787v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Regeneration: How well do LLMs match syntactic properties of text domains?", "abstract": "Recent improvement in large language model performance have, in all\nlikelihood, been accompanied by improvement in how well they can approximate\nthe distribution of their training data. In this work, we explore the following\nquestion: which properties of text domains do LLMs faithfully approximate, and\nhow well do they do so? Applying observational approaches familiar from corpus\nlinguistics, we prompt a commonly used, opensource LLM to regenerate text from\ntwo domains of permissively licensed English text which are often contained in\nLLM training data -- Wikipedia and news text. This regeneration paradigm allows\nus to investigate whether LLMs can faithfully match the original human text\ndomains in a fairly semantically-controlled setting. We investigate varying\nlevels of syntactic abstraction, from more simple properties like sentence\nlength, and article readability, to more complex and higher order properties\nsuch as dependency tag distribution, parse depth, and parse complexity. We find\nthat the majority of the regenerated distributions show a shifted mean, a lower\nstandard deviation, and a reduction of the long tail, as compared to the human\noriginals.", "published": "2025-05-12 17:37:17", "link": "http://arxiv.org/abs/2505.07784v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Must Read: A Systematic Survey of Computational Persuasion", "abstract": "Persuasion is a fundamental aspect of communication, influencing\ndecision-making across diverse contexts, from everyday conversations to\nhigh-stakes scenarios such as politics, marketing, and law. The rise of\nconversational AI systems has significantly expanded the scope of persuasion,\nintroducing both opportunities and risks. AI-driven persuasion can be leveraged\nfor beneficial applications, but also poses threats through manipulation and\nunethical influence. Moreover, AI systems are not only persuaders, but also\nsusceptible to persuasion, making them vulnerable to adversarial attacks and\nbias reinforcement. Despite rapid advancements in AI-generated persuasive\ncontent, our understanding of what makes persuasion effective remains limited\ndue to its inherently subjective and context-dependent nature. In this survey,\nwe provide a comprehensive overview of computational persuasion, structured\naround three key perspectives: (1) AI as a Persuader, which explores\nAI-generated persuasive content and its applications; (2) AI as a Persuadee,\nwhich examines AI's susceptibility to influence and manipulation; and (3) AI as\na Persuasion Judge, which analyzes AI's role in evaluating persuasive\nstrategies, detecting manipulation, and ensuring ethical persuasion. We\nintroduce a taxonomy for computational persuasion research and discuss key\nchallenges, including evaluating persuasiveness, mitigating manipulative\npersuasion, and developing responsible AI-driven persuasive systems. Our survey\noutlines future research directions to enhance the safety, fairness, and\neffectiveness of AI-powered persuasion while addressing the risks posed by\nincreasingly capable language models.", "published": "2025-05-12 17:26:31", "link": "http://arxiv.org/abs/2505.07775v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Enhancing Code Generation via Bidirectional Comment-Level Mutual Grounding", "abstract": "Large Language Models (LLMs) have demonstrated unprecedented capability in\ncode generation. However, LLM-generated code is still plagued with a wide range\nof functional errors, especially for complex programming tasks that LLMs have\nnot seen before. Recent studies have shown that developers often struggle with\ninspecting and fixing incorrect code generated by LLMs, diminishing their\nproductivity and trust in LLM-based code generation. Inspired by the mutual\ngrounding theory in communication, we propose an interactive approach that\nleverages code comments as a medium for developers and LLMs to establish a\nshared understanding. Our approach facilitates iterative grounding by\ninterleaving code generation, inline comment generation, and contextualized\nuser feedback through editable comments to align generated code with developer\nintent. We evaluated our approach on two popular benchmarks and demonstrated\nthat our approach significantly improved multiple state-of-the-art LLMs, e.g.,\n17.1% pass@1 improvement for code-davinci-002 on HumanEval. Furthermore, we\nconducted a user study with 12 participants in comparison to two baselines: (1)\ninteracting with GitHub Copilot, and (2) interacting with a multi-step code\ngeneration paradigm called Multi-Turn Program Synthesis. Participants completed\nthe given programming tasks 16.7% faster and with 10.5% improvement in task\nsuccess rate when using our approach. Both results show that interactively\nrefining code comments enables the collaborative establishment of mutual\ngrounding, leading to more accurate code generation and higher developer\nconfidence.", "published": "2025-05-12 17:20:30", "link": "http://arxiv.org/abs/2505.07768v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Spoken Language Understanding on Unseen Tasks With In-Context Learning", "abstract": "Spoken language understanding (SLU) tasks involve diverse skills that probe\nthe information extraction, classification and/or generation capabilities of\nmodels. In this setting, task-specific training data may not always be\navailable. While traditional task-specific SLU models are unable to cater to\nsuch requirements, the speech-text large language models (LLMs) offer a\npromising alternative with emergent abilities. However, out of-the-box, our\nevaluations indicate that the zero/few-shot performance of prominent\nopen-source speech-text LLMs on SLU tasks are not up to the mark. In this\npaper, we introduce a novel approach to robust task-agnostic fine-tuning using\nrandomized class labels. With this proposed fine-tuning, we illustrate that the\nperformance of the speech-text LLMs on an unseen task is significantly improved\nover standard approaches. Critically, the proposed approach avoids the\nrequirement of task-specific data annotations for enabling new tasks in\nspeech-text LLMs.", "published": "2025-05-12 16:38:43", "link": "http://arxiv.org/abs/2505.07731v1", "categories": ["cs.CL", "cs.LG", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Codifying Character Logic in Role-Playing", "abstract": "This paper introduces Codified Profiles for role-playing, a novel approach\nthat represents character logic as structured, executable functions for\nbehavioral decision-making. Each profile defines a set of functions\nparse_by_scene(scene) that outputs a list of logic-grounded assertions\ntriggered_statements, using both explicit control structures (e.g.,\nif-then-else) and condition checks like check_condition(scene, question), where\neach question is a semantically meaningful prompt about the scene (e.g., \"Is\nthe character in danger?\") discriminated by the role-playing LLM as true,\nfalse, or unknown. This explicit representation offers three key advantages\nover traditional prompt-based profiles, which append character descriptions\ndirectly into text prompts: (1) Persistence, by enforcing complete and\nconsistent execution of character logic, rather than relying on the model's\nimplicit reasoning; (2) Updatability, through systematic inspection and\nrevision of behavioral logic, which is difficult to track or debug in\nprompt-only approaches; (3) Controllable Randomness, by supporting stochastic\nbehavior directly within the logic, enabling fine-grained variability that\nprompting alone struggles to achieve. To validate these advantages, we\nintroduce a new benchmark constructed from 83 characters and 5,141 scenes\ncurated from Fandom, using NLI-based scoring to compare character responses\nagainst ground-truth actions. Our experiments demonstrate the significant\nbenefits of codified profiles in improving persistence, updatability, and\nbehavioral diversity. Notably, by offloading a significant portion of reasoning\nto preprocessing, codified profiles enable even 1B-parameter models to perform\nhigh-quality role-playing, providing a scalable and efficient foundation for\nlocal deployment of role-play agents.", "published": "2025-05-12 16:12:42", "link": "http://arxiv.org/abs/2505.07705v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Through the Looking Glass: Common Sense Consistency Evaluation of Weird Images", "abstract": "Measuring how real images look is a complex task in artificial intelligence\nresearch. For example, an image of a boy with a vacuum cleaner in a desert\nviolates common sense. We introduce a novel method, which we call Through the\nLooking Glass (TLG), to assess image common sense consistency using Large\nVision-Language Models (LVLMs) and Transformer-based encoder. By leveraging\nLVLMs to extract atomic facts from these images, we obtain a mix of accurate\nfacts. We proceed by fine-tuning a compact attention-pooling classifier over\nencoded atomic facts. Our TLG has achieved a new state-of-the-art performance\non the WHOOPS! and WEIRD datasets while leveraging a compact fine-tuning\ncomponent.", "published": "2025-05-12 16:12:11", "link": "http://arxiv.org/abs/2505.07704v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit", "abstract": "We present OnPrem.LLM, a Python-based toolkit for applying large language\nmodels (LLMs) to sensitive, non-public data in offline or restricted\nenvironments. The system is designed for privacy-preserving use cases and\nprovides prebuilt pipelines for document processing and storage,\nretrieval-augmented generation (RAG), information extraction, summarization,\nclassification, and prompt/output processing with minimal configuration.\nOnPrem.LLM supports multiple LLM backends -- including llama.cpp, Ollama, vLLM,\nand Hugging Face Transformers -- with quantized model support, GPU\nacceleration, and seamless backend switching. Although designed for fully local\nexecution, OnPrem.LLM also supports integration with a wide range of cloud LLM\nproviders when permitted, enabling hybrid deployments that balance performance\nwith data control. A no-code web interface extends accessibility to\nnon-technical users.", "published": "2025-05-12 15:36:27", "link": "http://arxiv.org/abs/2505.07672v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Benchmarking Retrieval-Augmented Generation for Chemistry", "abstract": "Retrieval-augmented generation (RAG) has emerged as a powerful framework for\nenhancing large language models (LLMs) with external knowledge, particularly in\nscientific domains that demand specialized and dynamic information. Despite its\npromise, the application of RAG in the chemistry domain remains underexplored,\nprimarily due to the lack of high-quality, domain-specific corpora and\nwell-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a\ncomprehensive benchmark designed to systematically assess the effectiveness of\nRAG across a diverse set of chemistry-related tasks. The accompanying chemistry\ncorpus integrates heterogeneous knowledge sources, including scientific\nliterature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia\nentries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG\ntoolkit that supports five retrieval algorithms and eight LLMs. Using\nChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain\n-- achieving an average relative improvement of 17.4% over direct inference\nmethods. We further conduct in-depth analyses on retriever architectures,\ncorpus selection, and the number of retrieved passages, culminating in\npractical recommendations to guide future research and deployment of RAG\nsystems in the chemistry domain. The code and data is available at\nhttps://chemrag.github.io.", "published": "2025-05-12 15:34:45", "link": "http://arxiv.org/abs/2505.07671v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Using Information Theory to Characterize Prosodic Typology: The Case of Tone, Pitch-Accent and Stress-Accent", "abstract": "This paper argues that the relationship between lexical identity and prosody\n-- one well-studied parameter of linguistic variation -- can be characterized\nusing information theory. We predict that languages that use prosody to make\nlexical distinctions should exhibit a higher mutual information between word\nidentity and prosody, compared to languages that don't. We test this hypothesis\nin the domain of pitch, which is used to make lexical distinctions in tonal\nlanguages, like Cantonese. We use a dataset of speakers reading sentences aloud\nin ten languages across five language families to estimate the mutual\ninformation between the text and their pitch curves. We find that, across\nlanguages, pitch curves display similar amounts of entropy. However, these\ncurves are easier to predict given their associated text in the tonal\nlanguages, compared to pitch- and stress-accent languages, and thus the mutual\ninformation is higher in these languages, supporting our hypothesis. Our\nresults support perspectives that view linguistic typology as gradient, rather\nthan categorical.", "published": "2025-05-12 15:25:17", "link": "http://arxiv.org/abs/2505.07659v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JobHop: A Large-Scale Dataset of Career Trajectories", "abstract": "Understanding labor market dynamics is essential for policymakers, employers,\nand job seekers. However, comprehensive datasets that capture real-world career\ntrajectories are scarce. In this paper, we introduce JobHop, a large-scale\npublic dataset derived from anonymized resumes provided by VDAB, the public\nemployment service in Flanders, Belgium. Utilizing Large Language Models\n(LLMs), we process unstructured resume data to extract structured career\ninformation, which is then mapped to standardized ESCO occupation codes using a\nmulti-label classification model. This results in a rich dataset of over 2.3\nmillion work experiences, extracted from and grouped into more than 391,000\nuser resumes and mapped to standardized ESCO occupation codes, offering\nvaluable insights into real-world occupational transitions. This dataset\nenables diverse applications, such as analyzing labor market mobility, job\nstability, and the effects of career breaks on occupational transitions. It\nalso supports career path prediction and other data-driven decision-making\nprocesses. To illustrate its potential, we explore key dataset characteristics,\nincluding job distributions, career breaks, and job transitions, demonstrating\nits value for advancing labor market research.", "published": "2025-05-12 15:22:29", "link": "http://arxiv.org/abs/2505.07653v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chronocept: Instilling a Sense of Time in Machines", "abstract": "Human cognition is deeply intertwined with a sense of time, known as\nChronoception. This sense allows us to judge how long facts remain valid and\nwhen knowledge becomes outdated. Despite progress in vision, language, and\nmotor control, AI still struggles to reason about temporal validity. We\nintroduce Chronocept, the first benchmark to model temporal validity as a\ncontinuous probability distribution over time. Using skew-normal curves fitted\nalong semantically decomposed temporal axes, Chronocept captures nuanced\npatterns of emergence, decay, and peak relevance. It includes two datasets:\nBenchmark I (atomic facts) and Benchmark II (multi-sentence passages).\nAnnotations show strong inter-annotator agreement (84% and 89%). Our baselines\npredict curve parameters - location, scale, and skewness - enabling\ninterpretable, generalizable learning and outperforming classification-based\napproaches. Chronocept fills a foundational gap in AI's temporal reasoning,\nsupporting applications in knowledge grounding, fact-checking,\nretrieval-augmented generation (RAG), and proactive agents. Code and data are\npublicly available.", "published": "2025-05-12 15:07:32", "link": "http://arxiv.org/abs/2505.07637v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Concept-Level Explainability for Auditing & Steering LLM Responses", "abstract": "As large language models (LLMs) become widely deployed, concerns about their\nsafety and alignment grow. An approach to steer LLM behavior, such as\nmitigating biases or defending against jailbreaks, is to identify which parts\nof a prompt influence specific aspects of the model's output. Token-level\nattribution methods offer a promising solution, but still struggle in text\ngeneration, explaining the presence of each token in the output separately,\nrather than the underlying semantics of the entire LLM response. We introduce\nConceptX, a model-agnostic, concept-level explainability method that identifies\nthe concepts, i.e., semantically rich tokens in the prompt, and assigns them\nimportance based on the outputs' semantic similarity. Unlike current\ntoken-level methods, ConceptX also offers to preserve context integrity through\nin-place token replacements and supports flexible explanation goals, e.g.,\ngender bias. ConceptX enables both auditing, by uncovering sources of bias, and\nsteering, by modifying prompts to shift the sentiment or reduce the harmfulness\nof LLM responses, without requiring retraining. Across three LLMs, ConceptX\noutperforms token-level methods like TokenSHAP in both faithfulness and human\nalignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for\nrandom edits and lower attack success rates from 0.463 to 0.242, outperforming\nattribution and paraphrasing baselines. While prompt engineering and\nself-explaining methods sometimes yield safer responses, ConceptX offers a\ntransparent and faithful alternative for improving LLM safety and alignment,\ndemonstrating the practical value of attribution-based explainability in\nguiding LLM behavior.", "published": "2025-05-12 14:31:51", "link": "http://arxiv.org/abs/2505.07610v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining", "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with\noptimization across both pre-training and post-training stages. During\npre-training, we enhance the data preprocessing pipeline and employ a\nthree-stage data mixing strategy to strengthen the base model's reasoning\npotential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional\nMulti-Token Prediction objective for enhanced performance and accelerated\ninference speed. During post-training, we curate a dataset of 130K verifiable\nmathematics and programming problems for reinforcement learning, integrating a\ntest-difficulty-driven code-reward scheme to alleviate sparse-reward issues and\nemploying strategic data resampling to stabilize training. Extensive\nevaluations show that MiMo-7B-Base possesses exceptional reasoning potential,\noutperforming even much larger 32B models. The final RL-tuned model,\nMiMo-7B-RL, achieves superior performance on mathematics, code and general\nreasoning tasks, surpassing the performance of OpenAI o1-mini. The model\ncheckpoints are available at https://github.com/xiaomimimo/MiMo.", "published": "2025-05-12 14:30:11", "link": "http://arxiv.org/abs/2505.07608v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Characterizing the Investigative Methods of Fictional Detectives with Large Language Models", "abstract": "Detective fiction, a genre defined by its complex narrative structures and\ncharacter-driven storytelling, presents unique challenges for computational\nnarratology, a research field focused on integrating literary theory into\nautomated narrative generation. While traditional literary studies have offered\ndeep insights into the methods and archetypes of fictional detectives, these\nanalyses often focus on a limited number of characters and lack the scalability\nneeded for the extraction of unique traits that can be used to guide narrative\ngeneration methods. In this paper, we present an AI-driven approach for\nsystematically characterizing the investigative methods of fictional\ndetectives. Our multi-phase workflow explores the capabilities of 15 Large\nLanguage Models (LLMs) to extract, synthesize, and validate distinctive\ninvestigative traits of fictional detectives. This approach was tested on a\ndiverse set of seven iconic detectives - Hercule Poirot, Sherlock Holmes,\nWilliam Murdoch, Columbo, Father Brown, Miss Marple, and Auguste Dupin -\ncapturing the distinctive investigative styles that define each character. The\nidentified traits were validated against existing literary analyses and further\ntested in a reverse identification phase, achieving an overall accuracy of\n91.43%, demonstrating the method's effectiveness in capturing the distinctive\ninvestigative approaches of each detective. This work contributes to the\nbroader field of computational narratology by providing a scalable framework\nfor character analysis, with potential applications in AI-driven interactive\nstorytelling and automated narrative generation.", "published": "2025-05-12 14:24:58", "link": "http://arxiv.org/abs/2505.07601v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent", "abstract": "Retrieval-augmented generation (RAG) is a common strategy to reduce\nhallucinations in Large Language Models (LLMs). While reinforcement learning\n(RL) can enable LLMs to act as search agents by activating retrieval\ncapabilities, existing ones often underutilize their internal knowledge. This\ncan lead to redundant retrievals, potential harmful knowledge conflicts, and\nincreased inference latency. To address these limitations, an efficient and\nadaptive search agent capable of discerning optimal retrieval timing and\nsynergistically integrating parametric (internal) and retrieved (external)\nknowledge is in urgent need. This paper introduces the Reinforced\nInternal-External Knowledge Synergistic Reasoning Agent (IKEA), which could\nindentify its own knowledge boundary and prioritize the utilization of internal\nknowledge, resorting to external search only when internal knowledge is deemed\ninsufficient. This is achieved using a novel knowledge-boundary aware reward\nfunction and a knowledge-boundary aware training dataset. These are designed\nfor internal-external knowledge synergy oriented RL, incentivizing the model to\ndeliver accurate answers, minimize unnecessary retrievals, and encourage\nappropriate external searches when its own knowledge is lacking. Evaluations\nacross multiple knowledge reasoning tasks demonstrate that IKEA significantly\noutperforms baseline methods, reduces retrieval frequency significantly, and\nexhibits robust generalization capabilities.", "published": "2025-05-12 14:21:57", "link": "http://arxiv.org/abs/2505.07596v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models", "abstract": "Instruction following evaluates large language models (LLMs) on their ability\nto generate outputs that adhere to user-defined constraints. However, existing\nbenchmarks often rely on templated constraint prompts, which lack the diversity\nof real-world usage and limit fine-grained performance assessment. To fill this\ngap, we propose a multi-dimensional constraint framework encompassing three\nconstraint patterns, four constraint categories, and four difficulty levels.\nBuilding on this framework, we develop an automated instruction generation\npipeline that performs constraint expansion, conflict detection, and\ninstruction rewriting, yielding 1,200 code-verifiable instruction-following\ntest samples. We evaluate 19 LLMs across seven model families and uncover\nsubstantial variation in performance across constraint forms. For instance,\naverage performance drops from 77.67% at Level I to 32.96% at Level IV.\nFurthermore, we demonstrate the utility of our approach by using it to generate\ndata for reinforcement learning, achieving substantial gains in instruction\nfollowing without degrading general performance. In-depth analysis indicates\nthat these gains stem primarily from modifications in the model's attention\nmodules parameters, which enhance constraint recognition and adherence. Code\nand data are available in https://github.com/Junjie-Ye/MulDimIF.", "published": "2025-05-12 14:16:55", "link": "http://arxiv.org/abs/2505.07591v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Direct Density Ratio Optimization: A Statistically Consistent Approach to Aligning Large Language Models", "abstract": "Aligning large language models (LLMs) with human preferences is crucial for\nsafe deployment, yet existing methods assume specific preference models like\nBradley-Terry model. This assumption leads to statistical inconsistency, where\nmore data doesn't guarantee convergence to true human preferences. To address\nthis critical gap, we introduce a novel alignment method Direct Density Ratio\nOptimization (DDRO). DDRO directly estimates the density ratio between\npreferred and unpreferred output distributions, circumventing the need for\nexplicit human preference modeling. We theoretically prove that DDRO is\nstatistically consistent, ensuring convergence to the true preferred\ndistribution as the data size grows, regardless of the underlying preference\nstructure. Experiments demonstrate that DDRO achieves superior performance\ncompared to existing methods on many major benchmarks. DDRO unlocks the\npotential for truly data-driven alignment, paving the way for more reliable and\nhuman-aligned LLMs.", "published": "2025-05-12 13:36:25", "link": "http://arxiv.org/abs/2505.07558v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion", "abstract": "Retrieval-Augmented Generation (RAG) models frequently encounter\nhallucination phenomena when integrating external information with internal\nparametric knowledge. Empirical studies demonstrate that the disequilibrium\nbetween external contextual information and internal parametric knowledge\nconstitutes a primary factor in hallucination generation. Existing\nhallucination detection methodologies predominantly emphasize either the\nexternal or internal mechanism in isolation, thereby overlooking their\nsynergistic effects. The recently proposed ReDeEP framework decouples these\ndual mechanisms, identifying two critical contributors to hallucinations:\nexcessive reliance on parametric knowledge encoded in feed-forward networks\n(FFN) and insufficient utilization of external information by attention\nmechanisms (particularly copy heads). ReDeEP quantitatively assesses these\nfactors to detect hallucinations and dynamically modulates the contributions of\nFFNs and copy heads to attenuate their occurrence. Nevertheless, ReDeEP and\nnumerous other hallucination detection approaches have been employed at\nlogit-level uncertainty estimation or language-level self-consistency\nevaluation, inadequately address the semantic dimensions of model responses,\nresulting in inconsistent hallucination assessments in RAG implementations.\nBuilding upon ReDeEP's foundation, this paper introduces SEReDeEP, which\nenhances computational processes through semantic entropy captured via trained\nlinear probes, thereby achieving hallucination assessments that more accurately\nreflect ground truth evaluations.", "published": "2025-05-12 13:10:46", "link": "http://arxiv.org/abs/2505.07528v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution", "abstract": "The tool-using capability of large language models (LLMs) enables them to\naccess up-to-date external information and handle complex tasks. Current\napproaches to enhancing this capability primarily rely on distilling advanced\nmodels by data synthesis. However, this method incurs significant costs\nassociated with advanced model usage and often results in data compatibility\nissues, led by the high discrepancy in the knowledge scope between the advanced\nmodel and the target model. To address these challenges, we propose\nToolACE-DEV, a self-improving framework for tool learning. First, we decompose\nthe tool-learning objective into sub-tasks that enhance basic tool-making and\ntool-using abilities. Then, we introduce a self-evolving paradigm that allows\nlightweight models to self-improve, reducing reliance on advanced LLMs.\nExtensive experiments validate the effectiveness of our approach across models\nof varying scales and architectures.", "published": "2025-05-12 12:48:30", "link": "http://arxiv.org/abs/2505.07512v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Translating the Grievance Dictionary: a psychometric evaluation of Dutch, German, and Italian versions", "abstract": "This paper introduces and evaluates three translations of the Grievance\nDictionary, a psycholinguistic dictionary for the analysis of violent,\nthreatening or grievance-fuelled texts. Considering the relevance of these\nthemes in languages beyond English, we translated the Grievance Dictionary to\nDutch, German, and Italian. We describe the process of automated translation\nsupplemented by human annotation. Psychometric analyses are performed,\nincluding internal reliability of dictionary categories and correlations with\nthe LIWC dictionary. The Dutch and German translations perform similarly to the\noriginal English version, whereas the Italian dictionary shows low reliability\nfor some categories. Finally, we make suggestions for further validation and\napplication of the dictionary, as well as for future dictionary translations\nfollowing a similar approach.", "published": "2025-05-12 12:27:38", "link": "http://arxiv.org/abs/2505.07495v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Collaborative Mechanisms Between Large and Small Language Models", "abstract": "Large Language Models (LLMs) deliver powerful AI capabilities but face\ndeployment challenges due to high resource costs and latency, whereas Small\nLanguage Models (SLMs) offer efficiency and deployability at the cost of\nreduced performance. Collaboration between LLMs and SLMs emerges as a crucial\nparadigm to synergistically balance these trade-offs, enabling advanced AI\napplications, especially on resource-constrained edge devices. This survey\nprovides a comprehensive overview of LLM-SLM collaboration, detailing various\ninteraction mechanisms (pipeline, routing, auxiliary, distillation, fusion),\nkey enabling technologies, and diverse application scenarios driven by\non-device needs like low latency, privacy, personalization, and offline\noperation. While highlighting the significant potential for creating more\nefficient, adaptable, and accessible AI, we also discuss persistent challenges\nincluding system overhead, inter-model consistency, robust task allocation,\nevaluation complexity, and security/privacy concerns. Future directions point\ntowards more intelligent adaptive frameworks, deeper model fusion, and\nexpansion into multimodal and embodied AI, positioning LLM-SLM collaboration as\na key driver for the next generation of practical and ubiquitous artificial\nintelligence.", "published": "2025-05-12 11:48:42", "link": "http://arxiv.org/abs/2505.07460v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Matching Tasks with Industry Groups for Augmenting Commonsense Knowledge", "abstract": "Commonsense knowledge bases (KB) are a source of specialized knowledge that\nis widely used to improve machine learning applications. However, even for a\nlarge KB such as ConceptNet, capturing explicit knowledge from each industry\ndomain is challenging. For example, only a few samples of general {\\em tasks}\nperformed by various industries are available in ConceptNet. Here, a task is a\nwell-defined knowledge-based volitional action to achieve a particular goal. In\nthis paper, we aim to fill this gap and present a weakly-supervised framework\nto augment commonsense KB with tasks carried out by various industry groups\n(IG). We attempt to {\\em match} each task with one or more suitable IGs by\ntraining a neural model to learn task-IG affinity and apply clustering to\nselect the top-k tasks per IG. We extract a total of 2339 triples of the form\n$\\langle IG, is~capable~of, task \\rangle$ from two publicly available news\ndatasets for 24 IGs with the precision of 0.86. This validates the reliability\nof the extracted task-IG pairs that can be directly added to existing KBs.", "published": "2025-05-12 11:02:41", "link": "http://arxiv.org/abs/2505.07440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparative sentiment analysis of public perception: Monkeypox vs. COVID-19 behavioral insights", "abstract": "The emergence of global health crises, such as COVID-19 and Monkeypox (mpox),\nhas underscored the importance of understanding public sentiment to inform\neffective public health strategies. This study conducts a comparative sentiment\nanalysis of public perceptions surrounding COVID-19 and mpox by leveraging\nextensive datasets of 147,475 and 106,638 tweets, respectively. Advanced\nmachine learning models, including Logistic Regression, Naive Bayes, RoBERTa,\nDistilRoBERTa and XLNet, were applied to perform sentiment classification, with\nresults indicating key trends in public emotion and discourse. The analysis\nhighlights significant differences in public sentiment driven by disease\ncharacteristics, media representation, and pandemic fatigue. Through the lens\nof sentiment polarity and thematic trends, this study offers valuable insights\ninto tailoring public health messaging, mitigating misinformation, and\nfostering trust during concurrent health crises. The findings contribute to\nadvancing sentiment analysis applications in public health informatics, setting\nthe groundwork for enhanced real-time monitoring and multilingual analysis in\nfuture research.", "published": "2025-05-12 10:37:33", "link": "http://arxiv.org/abs/2505.07430v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ViMRHP: A Vietnamese Benchmark Dataset for Multimodal Review Helpfulness Prediction via Human-AI Collaborative Annotation", "abstract": "Multimodal Review Helpfulness Prediction (MRHP) is an essential task in\nrecommender systems, particularly in E-commerce platforms. Determining the\nhelpfulness of user-generated reviews enhances user experience and improves\nconsumer decision-making. However, existing datasets focus predominantly on\nEnglish and Indonesian, resulting in a lack of linguistic diversity, especially\nfor low-resource languages such as Vietnamese. In this paper, we introduce\nViMRHP (Vietnamese Multimodal Review Helpfulness Prediction), a large-scale\nbenchmark dataset for MRHP task in Vietnamese. This dataset covers four\ndomains, including 2K products with 46K reviews. Meanwhile, a large-scale\ndataset requires considerable time and cost. To optimize the annotation\nprocess, we leverage AI to assist annotators in constructing the ViMRHP\ndataset. With AI assistance, annotation time is reduced (90 to 120 seconds per\ntask down to 20 to 40 seconds per task) while maintaining data quality and\nlowering overall costs by approximately 65%. However, AI-generated annotations\nstill have limitations in complex annotation tasks, which we further examine\nthrough a detailed performance analysis. In our experiment on ViMRHP, we\nevaluate baseline models on human-verified and AI-generated annotations to\nassess their quality differences. The ViMRHP dataset is publicly available at\nhttps://github.com/trng28/ViMRHP", "published": "2025-05-12 10:11:28", "link": "http://arxiv.org/abs/2505.07416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Computational Fact-Checking of Online Discourse: Scoring scientific accuracy in climate change related news articles", "abstract": "Democratic societies need reliable information. Misinformation in popular\nmedia such as news articles or videos threatens to impair civic discourse.\nCitizens are, unfortunately, not equipped to verify this content flood consumed\ndaily at increasing rates. This work aims to semi-automatically quantify\nscientific accuracy of online media. By semantifying media of unknown veracity,\ntheir statements can be compared against equally processed trusted sources. We\nimplemented a workflow using LLM-based statement extraction and knowledge graph\nanalysis. Our neurosymbolic system was able to evidently streamline\nstate-of-the-art veracity quantification. Evaluated via expert interviews and a\nuser survey, the tool provides a beneficial veracity indication. This\nindicator, however, is unable to annotate public media at the required\ngranularity and scale. Further work towards a FAIR (Findable, Accessible,\nInteroperable, Reusable) ground truth and complementary metrics are required to\nscientifically support civic discourse.", "published": "2025-05-12 10:03:15", "link": "http://arxiv.org/abs/2505.07409v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Domain Audio Question Answering Toward Acoustic Content Reasoning in The DCASE 2025 Challenge", "abstract": "We present Task 5 of the DCASE 2025 Challenge: an Audio Question Answering\n(AQA) benchmark spanning multiple domains of sound understanding. This task\ndefines three QA subsets (Bioacoustics, Temporal Soundscapes, and Complex QA)\nto test audio-language models on interactive question-answering over diverse\nacoustic scenes. We describe the dataset composition (from marine mammal calls\nto soundscapes and complex real-world clips), the evaluation protocol (top-1\naccuracy with answer-shuffling robustness), and baseline systems\n(Qwen2-Audio-7B, AudioFlamingo 2, Gemini-2-Flash). Preliminary results on the\ndevelopment set are compared, showing strong variation across models and\nsubsets. This challenge aims to advance the audio understanding and reasoning\ncapabilities of audio-language models toward human-level acuity, which are\ncrucial for enabling AI agents to perceive and interact about the world\neffectively.", "published": "2025-05-12 09:04:16", "link": "http://arxiv.org/abs/2505.07365v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines", "abstract": "Large language models (LLMs) have been widely used for relevance assessment\nin information retrieval. However, our study demonstrates that combining two\ndistinct small language models (SLMs) with different architectures can\noutperform LLMs in this task. Our approach -- QUPID -- integrates a generative\nSLM with an embedding-based SLM, achieving higher relevance judgment accuracy\nwhile reducing computational costs compared to state-of-the-art LLM solutions.\nThis computational efficiency makes QUPID highly scalable for real-world search\nsystems processing millions of queries daily. In experiments across diverse\ndocument types, our method demonstrated consistent performance improvements\n(Cohen's Kappa of 0.646 versus 0.387 for leading LLMs) while offering 60x\nfaster inference times. Furthermore, when integrated into production search\npipelines, QUPID improved nDCG@5 scores by 1.9%. These findings underscore how\narchitectural diversity in model combinations can significantly enhance both\nsearch relevance and operational efficiency in information retrieval systems.", "published": "2025-05-12 08:35:09", "link": "http://arxiv.org/abs/2505.07345v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study", "abstract": "Designing effective collaboration structure for multi-agent LLM systems to\nenhance collective reasoning is crucial yet remains under-explored. In this\npaper, we systematically investigate how collaborative reasoning performance is\naffected by three key design dimensions: (1) Expertise-Domain Alignment, (2)\nCollaboration Paradigm (structured workflow vs. diversity-driven integration),\nand (3) System Scale. Our findings reveal that expertise alignment benefits are\nhighly domain-contingent, proving most effective for contextual reasoning\ntasks. Furthermore, collaboration focused on integrating diverse knowledge\nconsistently outperforms rigid task decomposition. Finally, we empirically\nexplore the impact of scaling the multi-agent system with expertise\nspecialization and study the computational trade off, highlighting the need for\nmore efficient communication protocol design. This work provides concrete\nguidelines for configuring specialized multi-agent system and identifies\ncritical architectural trade-offs and bottlenecks for scalable multi-agent\nreasoning. The code will be made available upon acceptance.", "published": "2025-05-12 07:59:13", "link": "http://arxiv.org/abs/2505.07313v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AttentionInfluence: Adopting Attention Head Influence for Weak-to-Strong Pretraining Data Selection", "abstract": "Recently, there has been growing interest in collecting reasoning-intensive\npretraining data to improve LLMs' complex reasoning ability. Prior approaches\ntypically rely on supervised classifiers to identify such data, which requires\nlabeling by humans or LLMs, often introducing domain-specific biases. Due to\nthe attention heads being crucial to in-context reasoning, we propose\nAttentionInfluence, a simple yet effective, training-free method without\nsupervision signal. Our approach enables a small pretrained language model to\nact as a strong data selector through a simple attention head masking\noperation. Specifically, we identify retrieval heads and compute the loss\ndifference when masking these heads. We apply AttentionInfluence to a\n1.3B-parameter dense model to conduct data selection on the SmolLM corpus of\n241B tokens, and mix the SmolLM corpus with the selected subset comprising 73B\ntokens to pretrain a 7B-parameter dense model using 1T training tokens and WSD\nlearning rate scheduling. Our experimental results demonstrate substantial\nimprovements, ranging from 1.4pp to 3.5pp, across several knowledge-intensive\nand reasoning-heavy benchmarks (i.e., MMLU, MMLU-Pro, AGIEval-en, GSM8K, and\nHumanEval). This demonstrates an effective weak-to-strong scaling property,\nwith small models improving the final performance of larger models-offering a\npromising and scalable path for reasoning-centric data selection.", "published": "2025-05-12 07:25:51", "link": "http://arxiv.org/abs/2505.07293v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semantic Retention and Extreme Compression in LLMs: Can We Have Both?", "abstract": "The exponential growth in Large Language Model (LLM) deployment has\nintensified the need for efficient model compression techniques to reduce\ncomputational and memory costs. While pruning and quantization have shown\npromise, their combined potential remains largely unexplored. In this paper, we\nexamine joint compression and how strategically combining pruning and\nquantization could yield superior performance-to-compression ratios compared to\nsingle-method approaches. Recognizing the challenges in accurately assessing\nLLM performance, we address key limitations of previous evaluation frameworks\nand introduce the Semantic Retention Compression Rate (SrCr), a novel metric\nthat quantifies the trade-off between model compression and semantic\npreservation, facilitating the optimization of pruning-quantization\nconfigurations. Experiments demonstrate that our recommended combination\nachieves, on average, a 20% performance increase compared to an equivalent\nquantization-only model at the same theoretical compression rate.", "published": "2025-05-12 07:23:19", "link": "http://arxiv.org/abs/2505.07289v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "68P30 (Primary) 68T07, 68T50 (Secondary)", "I.2.6; I.5.1; I.2.7"], "primary_category": "cs.CL"}
{"title": "On the Robustness of Reward Models for Language Model Alignment", "abstract": "The Bradley-Terry (BT) model is widely practiced in reward modeling for\nreinforcement learning with human feedback (RLHF). Despite its effectiveness,\nreward models (RMs) trained with BT model loss are prone to over-optimization,\nlosing generalizability to unseen input distributions. In this paper, we study\nthe cause of over-optimization in RM training and its downstream effects on the\nRLHF procedure, accentuating the importance of distributional robustness of RMs\nin unseen data. First, we show that the excessive dispersion of hidden state\nnorms is the main source of over-optimization. Then, we propose batch-wise\nsum-to-zero regularization (BSR) to enforce zero-centered reward sum per batch,\nconstraining the rewards with extreme magnitudes. We assess the impact of BSR\nin improving robustness in RMs through four scenarios of over-optimization,\nwhere BSR consistently manifests better robustness. Subsequently, we compare\nthe plain BT model and BSR on RLHF training and empirically show that robust\nRMs better align the policy to the gold preference model. Finally, we apply BSR\nto high-quality data and models, which surpasses state-of-the-art RMs in the 8B\nscale by adding more than 5% in complex preference prediction tasks. By\nconducting RLOO training with 8B RMs, AlpacaEval 2.0 reduces generation length\nby 40% while adding a 7% increase in win rate, further highlighting that\nrobustness in RMs induces robustness in RLHF training. We release the code,\ndata, and models: https://github.com/LinkedIn-XFACT/RM-Robustness.", "published": "2025-05-12 06:48:26", "link": "http://arxiv.org/abs/2505.07271v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "No Query, No Access", "abstract": "Textual adversarial attacks mislead NLP models, including Large Language\nModels (LLMs), by subtly modifying text. While effective, existing attacks\noften require knowledge of the victim model, extensive queries, or access to\ntraining data, limiting real-world feasibility. To overcome these constraints,\nwe introduce the \\textbf{Victim Data-based Adversarial Attack (VDBA)}, which\noperates using only victim texts. To prevent access to the victim model, we\ncreate a shadow dataset with publicly available pre-trained models and\nclustering methods as a foundation for developing substitute models. To address\nthe low attack success rate (ASR) due to insufficient information feedback, we\npropose the hierarchical substitution model design, generating substitute\nmodels to mitigate the failure of a single substitute model at the decision\nboundary.\n  Concurrently, we use diverse adversarial example generation, employing\nvarious attack methods to generate and select the adversarial example with\nbetter similarity and attack effectiveness. Experiments on the Emotion and SST5\ndatasets show that VDBA outperforms state-of-the-art methods, achieving an ASR\nimprovement of 52.08\\% while significantly reducing attack queries to 0. More\nimportantly, we discover that VDBA poses a significant threat to LLMs such as\nQwen2 and the GPT family, and achieves the highest ASR of 45.99% even without\naccess to the API, confirming that advanced NLP models still face serious\nsecurity risks. Our codes can be found at\nhttps://anonymous.4open.science/r/VDBA-Victim-Data-based-Adversarial-Attack-36EC/", "published": "2025-05-12 06:19:59", "link": "http://arxiv.org/abs/2505.07258v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models", "abstract": "Subjective Answer Grading (SAG) plays a crucial role in education,\nstandardized testing, and automated assessment systems, particularly for\nevaluating short-form responses in Short Answer Scoring (SAS). However,\nexisting approaches often produce coarse-grained scores and lack detailed\nreasoning. Although large language models (LLMs) have demonstrated potential as\nzero-shot evaluators, they remain susceptible to bias, inconsistencies with\nhuman judgment, and limited transparency in scoring decisions. To overcome\nthese limitations, we introduce SAS-Bench, a benchmark specifically designed\nfor LLM-based SAS tasks. SAS-Bench provides fine-grained, step-wise scoring,\nexpert-annotated error categories, and a diverse range of question types\nderived from real-world subject-specific exams. This benchmark facilitates\ndetailed evaluation of model reasoning processes and explainability. We also\nrelease an open-source dataset containing 1,030 questions and 4,109 student\nresponses, each annotated by domain experts. Furthermore, we conduct\ncomprehensive experiments with various LLMs, identifying major challenges in\nscoring science-related questions and highlighting the effectiveness of\nfew-shot prompting in improving scoring accuracy. Our work offers valuable\ninsights into the development of more robust, fair, and educationally\nmeaningful LLM-based evaluation systems.", "published": "2025-05-12 05:43:21", "link": "http://arxiv.org/abs/2505.07247v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) systems combine large language models\n(LLMs) with external knowledge retrieval, making them highly effective for\nknowledge-intensive tasks. A crucial but often under-explored component of\nthese systems is the reranker, which refines retrieved documents to enhance\ngeneration quality and explainability. The challenge of selecting the optimal\nnumber of documents (k) remains unsolved: too few may omit critical\ninformation, while too many introduce noise and inefficiencies. Although recent\nstudies have explored LLM-based rerankers, they primarily leverage internal\nmodel knowledge and overlook the rich supervisory signals that LLMs can\nprovide, such as using response quality as feedback for optimizing reranking\ndecisions. In this paper, we propose DynamicRAG, a novel RAG framework where\nthe reranker dynamically adjusts both the order and number of retrieved\ndocuments based on the query. We model the reranker as an agent optimized\nthrough reinforcement learning (RL), using rewards derived from LLM output\nquality. Across seven knowledge-intensive datasets, DynamicRAG demonstrates\nsuperior performance, achieving state-of-the-art results. The model, data and\ncode are available at https://github.com/GasolSun36/DynamicRAG", "published": "2025-05-12 05:19:01", "link": "http://arxiv.org/abs/2505.07233v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030", "abstract": "Large Language Models (LLMs) are poised to transform healthcare under China's\nHealthy China 2030 initiative, yet they introduce new ethical and\npatient-safety challenges. We present a novel 12,000-item Q&A benchmark\ncovering 11 ethics and 9 safety dimensions in medical contexts, to\nquantitatively evaluate these risks. Using this dataset, we assess\nstate-of-the-art Chinese medical LLMs (e.g., Qwen 2.5-32B, DeepSeek), revealing\nmoderate baseline performance (accuracy 42.7% for Qwen 2.5-32B) and significant\nimprovements after fine-tuning on our data (up to 50.8% accuracy). Results show\nnotable gaps in LLM decision-making on ethics and safety scenarios, reflecting\ninsufficient institutional oversight. We then identify systemic governance\nshortfalls-including the lack of fine-grained ethical audit protocols, slow\nadaptation by hospital IRBs, and insufficient evaluation tools-that currently\nhinder safe LLM deployment. Finally, we propose a practical governance\nframework for healthcare institutions (embedding LLM auditing teams, enacting\ndata ethics guidelines, and implementing safety simulation pipelines) to\nproactively manage LLM risks. Our study highlights the urgent need for robust\nLLM governance in Chinese healthcare, aligning AI innovation with patient\nsafety and ethical standards.", "published": "2025-05-12 03:28:05", "link": "http://arxiv.org/abs/2505.07205v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Cost and Benefits of Training Context with Utterance or Full Conversation Training: A Comparative Stud", "abstract": "Modern TTS systems designed for conversations achieve high-quality utterances\nbut often remain inaccessible publicly. Are existing open-source architectures\ninadequate, or are current training techniques insufficient? This paper\ninvestigates prominent models and their underlying behaviors regarding\nconversational context. Using 20 GPU-hours on an NVIDIA H100, we empirically\nexamine two approaches: context-based utterance-level training versus full\nconversation training. Results demonstrate that context-based utterance\ntraining achieves superior MOS scores (4.3/5.0 vs 3.7/5.0) and reduces training\ntime by 37%, while full conversation approaches suffer from speaker similarity\nhallucination issues. These findings provide practical guidelines for\nconversational TTS development, favoring utterance-level training with\ncontextual conditioning for both resource efficiency and output quality.", "published": "2025-05-12 03:19:55", "link": "http://arxiv.org/abs/2505.07202v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Securing Genomic Data Against Inference Attacks in Federated Learning Environments", "abstract": "Federated Learning (FL) offers a promising framework for collaboratively\ntraining machine learning models across decentralized genomic datasets without\ndirect data sharing. While this approach preserves data locality, it remains\nsusceptible to sophisticated inference attacks that can compromise individual\nprivacy. In this study, we simulate a federated learning setup using synthetic\ngenomic data and assess its vulnerability to three key attack vectors:\nMembership Inference Attack (MIA), Gradient-Based Membership Inference Attack,\nand Label Inference Attack (LIA). Our experiments reveal that Gradient-Based\nMIA achieves the highest effectiveness, with a precision of 0.79 and F1-score\nof 0.87, underscoring the risk posed by gradient exposure in federated updates.\nAdditionally, we visualize comparative attack performance through radar plots\nand quantify model leakage across clients. The findings emphasize the\ninadequacy of na\\\"ive FL setups in safeguarding genomic privacy and motivate\nthe development of more robust privacy-preserving mechanisms tailored to the\nunique sensitivity of genomic data.", "published": "2025-05-12 02:36:50", "link": "http://arxiv.org/abs/2505.07188v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs", "abstract": "Large language models (LLMs) have achieved unprecedented performance by\nleveraging vast pretraining corpora, yet their performance remains suboptimal\nin knowledge-intensive domains such as medicine and scientific research, where\nhigh factual precision is required. While synthetic data provides a promising\navenue for augmenting domain knowledge, existing methods frequently generate\nredundant samples that do not align with the model's true knowledge gaps. To\novercome this limitation, we propose a novel Structural Entropy-guided\nKnowledge Navigator (SENATOR) framework that addresses the intrinsic knowledge\ndeficiencies of LLMs. Our approach employs the Structure Entropy (SE) metric to\nquantify uncertainty along knowledge graph paths and leverages Monte Carlo Tree\nSearch (MCTS) to selectively explore regions where the model lacks\ndomain-specific knowledge. Guided by these insights, the framework generates\ntargeted synthetic data for supervised fine-tuning, enabling continuous\nself-improvement. Experimental results on LLaMA-3 and Qwen2 across multiple\ndomain-specific benchmarks show that SENATOR effectively detects and repairs\nknowledge deficiencies, achieving notable performance improvements. The code\nand data for our methods and experiments are available at\nhttps://github.com/weiyifan1023/senator.", "published": "2025-05-12 02:21:36", "link": "http://arxiv.org/abs/2505.07184v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "One Trigger Token Is Enough: A Defense Strategy for Balancing Safety and Usability in Large Language Models", "abstract": "Large Language Models (LLMs) have been extensively used across diverse\ndomains, including virtual assistants, automated code generation, and\nscientific research. However, they remain vulnerable to jailbreak attacks,\nwhich manipulate the models into generating harmful responses despite safety\nalignment. Recent studies have shown that current safety-aligned LLMs often\nundergo the shallow safety alignment, where the first few tokens largely\ndetermine whether the response will be harmful. Through comprehensive\nobservations, we find that safety-aligned LLMs and various defense strategies\ngenerate highly similar initial tokens in their refusal responses, which we\ndefine as safety trigger tokens. Building on this insight, we propose\n\\texttt{D-STT}, a simple yet effective defense algorithm that identifies and\nexplicitly decodes safety trigger tokens of the given safety-aligned LLM to\ntrigger the model's learned safety patterns. In this process, the safety\ntrigger is constrained to a single token, which effectively preserves model\nusability by introducing minimum intervention in the decoding process.\nExtensive experiments across diverse jailbreak attacks and benign prompts\ndemonstrate that \\ours significantly reduces output harmfulness while\npreserving model usability and incurring negligible response time overhead,\noutperforming ten baseline methods.", "published": "2025-05-12 01:26:50", "link": "http://arxiv.org/abs/2505.07167v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Pre-training vs. Fine-tuning: A Reproducibility Study on Dense Retrieval Knowledge Acquisition", "abstract": "Dense retrievers utilize pre-trained backbone language models (e.g., BERT,\nLLaMA) that are fine-tuned via contrastive learning to perform the task of\nencoding text into sense representations that can be then compared via a\nshallow similarity operation, e.g. inner product. Recent research has\nquestioned the role of fine-tuning vs. that of pre-training within dense\nretrievers, specifically arguing that retrieval knowledge is primarily gained\nduring pre-training, meaning knowledge not acquired during pre-training cannot\nbe sub-sequentially acquired via fine-tuning. We revisit this idea here as the\nclaim was only studied in the context of a BERT-based encoder using DPR as\nrepresentative dense retriever. We extend the previous analysis by testing\nother representation approaches (comparing the use of CLS tokens with that of\nmean pooling), backbone architectures (encoder-only BERT vs. decoder-only\nLLaMA), and additional datasets (MSMARCO in addition to Natural Questions). Our\nstudy confirms that in DPR tuning, pre-trained knowledge underpins retrieval\nperformance, with fine-tuning primarily adjusting neuron activation rather than\nreorganizing knowledge. However, this pattern does not hold universally, such\nas in mean-pooled (Contriever) and decoder-based (LLaMA) models. We ensure full\nreproducibility and make our implementation publicly available at\nhttps://github.com/ielab/DenseRetriever-Knowledge-Acquisition.", "published": "2025-05-12 01:24:00", "link": "http://arxiv.org/abs/2505.07166v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "KDH-MLTC: Knowledge Distillation for Healthcare Multi-Label Text Classification", "abstract": "The increasing volume of healthcare textual data requires computationally\nefficient, yet highly accurate classification approaches able to handle the\nnuanced and complex nature of medical terminology. This research presents\nKnowledge Distillation for Healthcare Multi-Label Text Classification\n(KDH-MLTC), a framework leveraging model compression and Large Language Models\n(LLMs). The proposed approach addresses conventional healthcare Multi-Label\nText Classification (MLTC) challenges by integrating knowledge distillation and\nsequential fine-tuning, subsequently optimized through Particle Swarm\nOptimization (PSO) for hyperparameter tuning. KDH-MLTC transfers knowledge from\na more complex teacher LLM (i.e., BERT) to a lighter student LLM (i.e.,\nDistilBERT) through sequential training adapted to MLTC that preserves the\nteacher's learned information while significantly reducing computational\nrequirements. As a result, the classification is enabled to be conducted\nlocally, making it suitable for healthcare textual data characterized by\nsensitivity and, therefore, ensuring HIPAA compliance. The experiments\nconducted on three medical literature datasets of different sizes, sampled from\nthe Hallmark of Cancer (HoC) dataset, demonstrate that KDH-MLTC achieves\nsuperior performance compared to existing approaches, particularly for the\nlargest dataset, reaching an F1 score of 82.70%. Additionally, statistical\nvalidation and an ablation study are carried out, proving the robustness of\nKDH-MLTC. Furthermore, the PSO-based hyperparameter optimization process\nallowed the identification of optimal configurations. The proposed approach\ncontributes to healthcare text classification research, balancing efficiency\nrequirements in resource-constrained healthcare settings with satisfactory\naccuracy demands.", "published": "2025-05-12 00:58:25", "link": "http://arxiv.org/abs/2505.07162v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Actionable Pedagogical Feedback: A Multi-Perspective Analysis of Mathematics Teaching and Tutoring Dialogue", "abstract": "Effective feedback is essential for refining instructional practices in\nmathematics education, and researchers often turn to advanced natural language\nprocessing (NLP) models to analyze classroom dialogues from multiple\nperspectives. However, utterance-level discourse analysis encounters two\nprimary challenges: (1) multifunctionality, where a single utterance may serve\nmultiple purposes that a single tag cannot capture, and (2) the exclusion of\nmany utterances from domain-specific discourse move classifications, leading to\ntheir omission in feedback. To address these challenges, we proposed a\nmulti-perspective discourse analysis that integrates domain-specific talk moves\nwith dialogue act (using the flattened multi-functional SWBD-MASL schema with\n43 tags) and discourse relation (applying Segmented Discourse Representation\nTheory with 16 relations). Our top-down analysis framework enables a\ncomprehensive understanding of utterances that contain talk moves, as well as\nutterances that do not contain talk moves. This is applied to two mathematics\neducation datasets: TalkMoves (teaching) and SAGA22 (tutoring). Through\ndistributional unigram analysis, sequential talk move analysis, and multi-view\ndeep dive, we discovered meaningful discourse patterns, and revealed the vital\nrole of utterances without talk moves, demonstrating that these utterances, far\nfrom being mere fillers, serve crucial functions in guiding, acknowledging, and\nstructuring classroom discourse. These insights underscore the importance of\nincorporating discourse relations and dialogue acts into AI-assisted education\nsystems to enhance feedback and create more responsive learning environments.\nOur framework may prove helpful for providing human educator feedback, but also\naiding in the development of AI agents that can effectively emulate the roles\nof both educators and students.", "published": "2025-05-12 00:48:17", "link": "http://arxiv.org/abs/2505.07161v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "HAMLET: Healthcare-focused Adaptive Multilingual Learning Embedding-based Topic Modeling", "abstract": "Traditional topic models often struggle with contextual nuances and fail to\nadequately handle polysemy and rare words. This limitation typically results in\ntopics that lack coherence and quality. Large Language Models (LLMs) can\nmitigate this issue by generating an initial set of topics. However, these raw\ntopics frequently lack refinement and representativeness, which leads to\nredundancy without lexical similarity and reduced interpretability. This paper\nintroduces HAMLET, a graph-driven architecture for cross-lingual healthcare\ntopic modeling that uses LLMs. The proposed approach leverages neural-enhanced\nsemantic fusion to refine the embeddings of topics generated by the LLM.\nInstead of relying solely on statistical co-occurrence or human interpretation\nto extract topics from a document corpus, this method introduces a topic\nembedding refinement that uses Bidirectional Encoder Representations from\nTransformers (BERT) and Graph Neural Networks (GNN). After topic generation, a\nhybrid technique that involves BERT and Sentence-BERT (SBERT) is employed for\nembedding. The topic representations are further refined using a GNN, which\nestablishes connections between documents, topics, words, similar topics, and\nsimilar words. A novel method is introduced to compute similarities.\nConsequently, the topic embeddings are refined, and the top k topics are\nextracted. Experiments were conducted using two healthcare datasets, one in\nEnglish and one in French, from which six sets were derived. The results\ndemonstrate the effectiveness of HAMLET.", "published": "2025-05-12 00:31:36", "link": "http://arxiv.org/abs/2505.07157v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reassessing Large Language Model Boolean Query Generation for Systematic Reviews", "abstract": "Systematic reviews are comprehensive literature reviews that address highly\nfocused research questions and represent the highest form of evidence in\nmedicine. A critical step in this process is the development of complex Boolean\nqueries to retrieve relevant literature. Given the difficulty of manually\nconstructing these queries, recent efforts have explored Large Language Models\n(LLMs) to assist in their formulation. One of the first studies,Wang et al.,\ninvestigated ChatGPT for this task, followed by Staudinger et al., which\nevaluated multiple LLMs in a reproducibility study. However, the latter\noverlooked several key aspects of the original work, including (i) validation\nof generated queries, (ii) output formatting constraints, and (iii) selection\nof examples for chain-of-thought (Guided) prompting. As a result, its findings\ndiverged significantly from the original study. In this work, we systematically\nreproduce both studies while addressing these overlooked factors. Our results\nshow that query effectiveness varies significantly across models and prompt\ndesigns, with guided query formulation benefiting from well-chosen seed\nstudies. Overall, prompt design and model selection are key drivers of\nsuccessful query formulation. Our findings provide a clearer understanding of\nLLMs' potential in Boolean query generation and highlight the importance of\nmodel- and prompt-specific optimisations. The complex nature of systematic\nreviews adds to challenges in both developing and reproducing methods but also\nhighlights the importance of reproducibility studies in this domain.", "published": "2025-05-12 00:15:02", "link": "http://arxiv.org/abs/2505.07155v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "H$^{\\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning", "abstract": "Visuomotor policy learning has witnessed substantial progress in robotic\nmanipulation, with recent approaches predominantly relying on generative models\nto model the action distribution. However, these methods often overlook the\ncritical coupling between visual perception and action prediction. In this\nwork, we introduce $\\textbf{Triply-Hierarchical Diffusion\nPolicy}~(\\textbf{H$^{\\mathbf{3}}$DP})$, a novel visuomotor learning framework\nthat explicitly incorporates hierarchical structures to strengthen the\nintegration between visual features and action generation. H$^{3}$DP contains\n$\\mathbf{3}$ levels of hierarchy: (1) depth-aware input layering that organizes\nRGB-D observations based on depth information; (2) multi-scale visual\nrepresentations that encode semantic features at varying levels of granularity;\nand (3) a hierarchically conditioned diffusion process that aligns the\ngeneration of coarse-to-fine actions with corresponding visual features.\nExtensive experiments demonstrate that H$^{3}$DP yields a $\\mathbf{+27.5\\%}$\naverage relative improvement over baselines across $\\mathbf{44}$ simulation\ntasks and achieves superior performance in $\\mathbf{4}$ challenging bimanual\nreal-world manipulation tasks. Project Page: https://lyy-iiis.github.io/h3dp/.", "published": "2025-05-12 17:59:43", "link": "http://arxiv.org/abs/2505.07819v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "A class of distributed automata that contains the modal mu-fragment", "abstract": "This paper gives a translation from the $\\mu$-fragment of the graded modal\n$\\mu$-calculus to a class of distributed message-passing automata. As a\ncorollary, we obtain an alternative proof for a theorem from\n\\cite{ahvonen_neurips} stating that recurrent graph neural networks working\nwith reals and graded modal substitution calculus have the same expressive\npower in restriction to the logic monadic second-order logic MSO.", "published": "2025-05-12 17:59:22", "link": "http://arxiv.org/abs/2505.07816v1", "categories": ["cs.LO", "cs.AI", "F.4.1; F.1.1; I.2.0"], "primary_category": "cs.LO"}
{"title": "DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies", "abstract": "Large-scale, diverse robot datasets have emerged as a promising path toward\nenabling dexterous manipulation policies to generalize to novel environments,\nbut acquiring such datasets presents many challenges. While teleoperation\nprovides high-fidelity datasets, its high cost limits its scalability. Instead,\nwhat if people could use their own hands, just as they do in everyday life, to\ncollect data? In DexWild, a diverse team of data collectors uses their hands to\ncollect hours of interactions across a multitude of environments and objects.\nTo record this data, we create DexWild-System, a low-cost, mobile, and\neasy-to-use device. The DexWild learning framework co-trains on both human and\nrobot demonstrations, leading to improved performance compared to training on\neach dataset individually. This combination results in robust robot policies\ncapable of generalizing to novel environments, tasks, and embodiments with\nminimal additional robot-specific data. Experimental results demonstrate that\nDexWild significantly improves performance, achieving a 68.5% success rate in\nunseen environments-nearly four times higher than policies trained with robot\ndata only-and offering 5.8x better cross-embodiment generalization. Video\nresults, codebases, and instructions at https://dexwild.github.io", "published": "2025-05-12 17:59:05", "link": "http://arxiv.org/abs/2505.07813v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Improving Trajectory Stitching with Flow Models", "abstract": "Generative models have shown great promise as trajectory planners, given\ntheir affinity to modeling complex distributions and guidable inference\nprocess. Previous works have successfully applied these in the context of\nrobotic manipulation but perform poorly when the required solution does not\nexist as a complete trajectory within the training set. We identify that this\nis a result of being unable to plan via stitching, and subsequently address the\narchitectural and dataset choices needed to remedy this. On top of this, we\npropose a novel addition to the training and inference procedures to both\nstabilize and enhance these capabilities. We demonstrate the efficacy of our\napproach by generating plans with out of distribution boundary conditions and\nperforming obstacle avoidance on the Franka Panda in simulation and on real\nhardware. In both of these tasks our method performs significantly better than\nthe baselines and is able to avoid obstacles up to four times as large.", "published": "2025-05-12 17:50:10", "link": "http://arxiv.org/abs/2505.07802v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Overflow Prevention Enhances Long-Context Recurrent LLMs", "abstract": "A recent trend in LLMs is developing recurrent sub-quadratic models that\nimprove long-context processing efficiency. We investigate leading large\nlong-context models, focusing on how their fixed-size recurrent memory affects\ntheir performance. Our experiments reveal that, even when these models are\ntrained for extended contexts, their use of long contexts remains\nunderutilized. Specifically, we demonstrate that a chunk-based inference\nprocedure, which identifies and processes only the most relevant portion of the\ninput can mitigate recurrent memory failures and be effective for many\nlong-context tasks: On LongBench, our method improves the overall performance\nof Falcon3-Mamba-Inst-7B by 14%, Falcon-Mamba-Inst-7B by 28%,\nRecurrentGemma-IT-9B by 50%, and RWKV6-Finch-7B by 51%. Surprisingly, this\nsimple approach also leads to state-of-the-art results in the challenging\nLongBench v2 benchmark, showing competitive performance with equivalent size\nTransformers. Furthermore, our findings raise questions about whether recurrent\nmodels genuinely exploit long-range dependencies, as our single-chunk strategy\ndelivers stronger performance - even in tasks that presumably require\ncross-context relations.", "published": "2025-05-12 17:45:05", "link": "http://arxiv.org/abs/2505.07793v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving", "abstract": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks\nrequiring precise, verifiable computation. While Reinforcement Learning (RL)\nfrom outcome-based rewards enhances text-based reasoning, understanding how\nagents autonomously learn to leverage external tools like code execution\nremains crucial. We investigate RL from outcome-based rewards for\nTool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously\ngenerate and execute Python code for mathematical problems without supervised\ntool-use examples. Our central contribution is we demonstrate that as RL\ntraining progresses, key metrics scale predictably. Specifically, we observe\nstrong positive correlations where increased training steps lead to increases\nin the spontaneous code execution frequency, the average response length, and,\ncritically, the final task accuracy. This suggests a quantifiable relationship\nbetween computational effort invested in training and the emergence of\neffective, tool-augmented reasoning strategies. We implement a robust framework\nfeaturing a decoupled code execution environment and validate our findings\nacross standard RL algorithms and frameworks. Experiments show ZeroTIR\nsignificantly surpasses non-tool ZeroRL baselines on challenging math\nbenchmarks. Our findings provide a foundational understanding of how autonomous\ntool use is acquired and scales within Agent RL, offering a reproducible\nbenchmark for future studies. Code is released at\n\\href{https://github.com/Anonymize-Author/AgentRL}{https://github.com/Anonymize-Author/AgentRL}.", "published": "2025-05-12 17:23:34", "link": "http://arxiv.org/abs/2505.07773v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "\"I Apologize For Not Understanding Your Policy\": Exploring the Specification and Evaluation of User-Managed Access Control Policies by AI Virtual Assistants", "abstract": "The rapid evolution of Artificial Intelligence (AI)-based Virtual Assistants\n(VAs) e.g., Google Gemini, ChatGPT, Microsoft Copilot, and High-Flyer Deepseek\nhas turned them into convenient interfaces for managing emerging technologies\nsuch as Smart Homes, Smart Cars, Electronic Health Records, by means of\nexplicit commands,e.g., prompts, which can be even launched via voice, thus\nproviding a very convenient interface for end-users. However, the proper\nspecification and evaluation of User-Managed Access Control Policies (U-MAPs),\nthe rules issued and managed by end-users to govern access to sensitive data\nand device functionality - within these VAs presents significant challenges,\nsince such a process is crucial for preventing security vulnerabilities and\nprivacy leaks without impacting user experience. This study provides an initial\nexploratory investigation on whether current publicly-available VAs can manage\nU-MAPs effectively across differing scenarios. By conducting unstructured to\nstructured tests, we evaluated the comprehension of such VAs, revealing a lack\nof understanding in varying U-MAP approaches. Our research not only identifies\nkey limitations, but offers valuable insights into how VAs can be further\nimproved to manage complex authorization rules and adapt to dynamic changes.", "published": "2025-05-12 17:03:52", "link": "http://arxiv.org/abs/2505.07759v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Emotion-Gradient Metacognitive RSI (Part I): Theoretical Foundations and Single-Agent Architecture", "abstract": "We present the Emotion-Gradient Metacognitive Recursive Self-Improvement\n(EG-MRSI) framework, a novel architecture that integrates introspective\nmetacognition, emotion-based intrinsic motivation, and recursive\nself-modification into a unified theoretical system. The framework is\nexplicitly capable of overwriting its own learning algorithm under formally\nbounded risk. Building upon the Noise-to-Meaning RSI (N2M-RSI) foundation,\nEG-MRSI introduces a differentiable intrinsic reward function driven by\nconfidence, error, novelty, and cumulative success. This signal regulates both\na metacognitive mapping and a self-modification operator constrained by\nprovable safety mechanisms. We formally define the initial agent configuration,\nemotion-gradient dynamics, and RSI trigger conditions, and derive a\nreinforcement-compatible optimization objective that guides the agent's\ndevelopment trajectory. Meaning Density and Meaning Conversion Efficiency are\nintroduced as quantifiable metrics of semantic learning, closing the gap\nbetween internal structure and predictive informativeness. This Part I paper\nestablishes the single-agent theoretical foundations of EG-MRSI. Future parts\nwill extend this framework to include safety certificates and rollback\nprotocols (Part II), collective intelligence mechanisms (Part III), and\nfeasibility constraints including thermodynamic and computational limits (Part\nIV). Together, the EG-MRSI series provides a rigorous, extensible foundation\nfor open-ended and safe AGI.", "published": "2025-05-12 17:02:47", "link": "http://arxiv.org/abs/2505.07757v1", "categories": ["cs.AI", "cs.LG", "F.1.2; I.2.0"], "primary_category": "cs.AI"}
{"title": "Benchmarking of CPU-intensive Stream Data Processing in The Edge Computing Systems", "abstract": "Edge computing has emerged as a pivotal technology, offering significant\nadvantages such as low latency, enhanced data security, and reduced reliance on\ncentralized cloud infrastructure. These benefits are crucial for applications\nrequiring real-time data processing or strict security measures. Despite these\nadvantages, edge devices operating within edge clusters are often\nunderutilized. This inefficiency is mainly due to the absence of a holistic\nperformance profiling mechanism which can help dynamically adjust the desired\nsystem configuration for a given workload. Since edge computing environments\ninvolve a complex interplay between CPU frequency, power consumption, and\napplication performance, a deeper understanding of these correlations is\nessential. By uncovering these relationships, it becomes possible to make\ninformed decisions that enhance both computational efficiency and energy\nsavings. To address this gap, this paper evaluates the power consumption and\nperformance characteristics of a single processing node within an edge cluster\nusing a synthetic microbenchmark by varying the workload size and CPU\nfrequency. The results show how an optimal measure can lead to optimized usage\nof edge resources, given both performance and power consumption.", "published": "2025-05-12 17:02:02", "link": "http://arxiv.org/abs/2505.07755v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "Guiding Data Collection via Factored Scaling Curves", "abstract": "Generalist imitation learning policies trained on large datasets show great\npromise for solving diverse manipulation tasks. However, to ensure\ngeneralization to different conditions, policies need to be trained with data\ncollected across a large set of environmental factor variations (e.g., camera\npose, table height, distractors) $-$ a prohibitively expensive undertaking, if\ndone exhaustively. We introduce a principled method for deciding what data to\ncollect and how much to collect for each factor by constructing factored\nscaling curves (FSC), which quantify how policy performance varies as data\nscales along individual or paired factors. These curves enable targeted data\nacquisition for the most influential factor combinations within a given budget.\nWe evaluate the proposed method through extensive simulated and real-world\nexperiments, across both training-from-scratch and fine-tuning settings, and\nshow that it boosts success rates in real-world tasks in new environments by up\nto 26% over existing data-collection strategies. We further demonstrate how\nfactored scaling curves can effectively guide data collection using an offline\nmetric, without requiring real-world evaluation at scale.", "published": "2025-05-12 16:36:35", "link": "http://arxiv.org/abs/2505.07728v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Hybrid Spiking Vision Transformer for Object Detection with Event Cameras", "abstract": "Event-based object detection has gained increasing attention due to its\nadvantages such as high temporal resolution, wide dynamic range, and\nasynchronous address-event representation. Leveraging these advantages, Spiking\nNeural Networks (SNNs) have emerged as a promising approach, offering low\nenergy consumption and rich spatiotemporal dynamics. To further enhance the\nperformance of event-based object detection, this study proposes a novel hybrid\nspike vision Transformer (HsVT) model. The HsVT model integrates a spatial\nfeature extraction module to capture local and global features, and a temporal\nfeature extraction module to model time dependencies and long-term patterns in\nevent sequences. This combination enables HsVT to capture spatiotemporal\nfeatures, improving its capability to handle complex event-based object\ndetection tasks. To support research in this area, we developed and publicly\nreleased The Fall Detection Dataset as a benchmark for event-based object\ndetection tasks. This dataset, captured using an event-based camera, ensures\nfacial privacy protection and reduces memory usage due to the event\nrepresentation format. We evaluated the HsVT model on GEN1 and Fall Detection\ndatasets across various model sizes. Experimental results demonstrate that HsVT\nachieves significant performance improvements in event detection with fewer\nparameters.", "published": "2025-05-12 16:19:20", "link": "http://arxiv.org/abs/2505.07715v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Circuit Partitioning Using Large Language Models for Quantum Compilation and Simulations", "abstract": "We are in the midst of the noisy intermediate-scale quantum (NISQ) era, where\nquantum computers are limited by noisy gates, some of which are more\nerror-prone than others and can render the final computation incomprehensible.\nQuantum circuit compilation algorithms attempt to minimize these noisy gates\nwhen mapping quantum algorithms onto quantum hardware but face computational\nchallenges that restrict their application to circuits with no more than 5-6\nqubits, necessitating the need to partition large circuits before the\napplication of noisy quantum gate minimization algorithms. The existing\ngeneration of these algorithms is heuristic in nature and does not account for\ndownstream gate minimization tasks. Large language models (LLMs) have the\npotential to change this and help improve quantum circuit partitions. This\npaper investigates the use of LLMs, such as Llama and Mistral, for partitioning\nquantum circuits by capitalizing on their abilities to understand and generate\ncode, including QASM. Specifically, we teach LLMs to partition circuits using\nthe quick partition approach of the Berkeley Quantum Synthesis Toolkit. Through\nexperimental evaluations, we show that careful fine-tuning of open source LLMs\nenables us to obtain an accuracy of 53.4% for the partition task while\nover-the-shelf LLMs are unable to correctly partition circuits, using standard\n1-shot and few-shot training approaches.", "published": "2025-05-12 16:18:48", "link": "http://arxiv.org/abs/2505.07711v1", "categories": ["cs.ET", "cs.AI", "quant-ph"], "primary_category": "cs.ET"}
{"title": "Lightweight End-to-end Text-to-speech Synthesis for low resource on-device applications", "abstract": "Recent works have shown that modelling raw waveform directly from text in an\nend-to-end (E2E) fashion produces more natural-sounding speech than traditional\nneural text-to-speech (TTS) systems based on a cascade or two-stage approach.\nHowever, current E2E state-of-the-art models are computationally complex and\nmemory-consuming, making them unsuitable for real-time offline on-device\napplications in low-resource scenarios. To address this issue, we propose a\nLightweight E2E-TTS (LE2E) model that generates high-quality speech requiring\nminimal computational resources. We evaluate the proposed model on the LJSpeech\ndataset and show that it achieves state-of-the-art performance while being up\nto $90\\%$ smaller in terms of model parameters and $10\\times$ faster in\nreal-time-factor. Furthermore, we demonstrate that the proposed E2E training\nparadigm achieves better quality compared to an equivalent architecture trained\nin a two-stage approach. Our results suggest that LE2E is a promising approach\nfor developing real-time, high quality, low-resource TTS applications for\non-device applications.", "published": "2025-05-12 16:10:15", "link": "http://arxiv.org/abs/2505.07701v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Belief Injection for Epistemic Control in Linguistic State Space", "abstract": "This work introduces belief injection, a proactive epistemic control\nmechanism for artificial agents whose cognitive states are structured as\ndynamic ensembles of linguistic belief fragments. Grounded in the Semantic\nManifold framework, belief injection directly incorporates targeted linguistic\nbeliefs into an agent's internal cognitive state, influencing reasoning and\nalignment proactively rather than reactively. We delineate various injection\nstrategies, such as direct, context-aware, goal-oriented, and reflective\napproaches, and contrast belief injection with related epistemic control\nmechanisms, notably belief filtering. Additionally, this work discusses\npractical applications, implementation considerations, ethical implications,\nand outlines promising directions for future research into cognitive governance\nusing architecturally embedded belief injection.", "published": "2025-05-12 15:58:56", "link": "http://arxiv.org/abs/2505.07693v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models", "abstract": "As Test-Time Scaling emerges as an active research focus in the large\nlanguage model community, advanced post-training methods increasingly emphasize\nextending chain-of-thought (CoT) generation length, thereby enhancing reasoning\ncapabilities to approach Deepseek R1-like reasoning models. However, recent\nstudies reveal that reasoning models (even Qwen3) consistently exhibit\nexcessive thought redundancy in CoT generation. This overthinking problem stems\nfrom conventional outcome-reward reinforcement learning's systematic neglect in\nregulating intermediate reasoning steps. This paper proposes Serial-Group\nDecaying-Reward Policy Optimization (namely S-GRPO), a novel reinforcement\nlearning method that empowers models with the capability to determine the\nsufficiency of reasoning steps, subsequently triggering early exit of CoT\ngeneration. Specifically, unlike GRPO, which samples multiple possible\ncompletions (parallel group) in parallel, we select multiple temporal positions\nin the generation of one CoT to allow the model to exit thinking and instead\ngenerate answers (serial group), respectively. For the correct answers in a\nserial group, we assign rewards that decay according to positions, with lower\nrewards towards the later ones, thereby reinforcing the model's behavior to\ngenerate higher-quality answers at earlier phases with earlier exits of\nthinking. Empirical evaluations demonstrate compatibility with state-of-the-art\nreasoning models, including Qwen3 and Deepseek-distill models, achieving 35.4%\n~ 61.1\\% sequence length reduction with 0.72% ~ 6.08% accuracy improvements\nacross GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond benchmarks.", "published": "2025-05-12 15:50:44", "link": "http://arxiv.org/abs/2505.07686v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Multimodal Survival Modeling in the Age of Foundation Models", "abstract": "The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a\nlarge-scale reference through its harmonized genomics, clinical, and image\ndata. Prior studies have trained bespoke cancer survival prediction models from\nunimodal or multimodal TCGA data. A modern paradigm in biomedical deep learning\nis the development of foundation models (FMs) to derive meaningful feature\nembeddings, agnostic to a specific modeling task. Biomedical text especially\nhas seen growing development of FMs. While TCGA contains free-text data as\npathology reports, these have been historically underutilized. Here, we\ninvestigate the feasibility of training classical, multimodal survival models\nover zero-shot embeddings extracted by FMs. We show the ease and additive\neffect of multimodal fusion, outperforming unimodal models. We demonstrate the\nbenefit of including pathology report text and rigorously evaluate the effect\nof model-based text summarization and hallucination. Overall, we modernize\nsurvival modeling by leveraging FMs and information extraction from pathology\nreports.", "published": "2025-05-12 15:47:21", "link": "http://arxiv.org/abs/2505.07683v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Simple Semi-supervised Knowledge Distillation from Vision-Language Models via $\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead $\\mathbf{\\texttt{O}}$ptimization", "abstract": "Vision-language models (VLMs) have achieved remarkable success across diverse\ntasks by leveraging rich textual information with minimal labeled data.\nHowever, deploying such large models remains challenging, particularly in\nresource-constrained environments. Knowledge distillation (KD) offers a\nwell-established solution to this problem; however, recent KD approaches from\nVLMs often involve multi-stage training or additional tuning, increasing\ncomputational overhead and optimization complexity. In this paper, we propose\n$\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead\n$\\mathbf{\\texttt{O}}$ptimization ($\\mathbf{\\texttt{DHO}}$) -- a simple yet\neffective KD framework that transfers knowledge from VLMs to compact,\ntask-specific models in semi-supervised settings. Specifically, we introduce\ndual prediction heads that independently learn from labeled data and teacher\npredictions, and propose to linearly combine their outputs during inference. We\nobserve that $\\texttt{DHO}$ mitigates gradient conflicts between supervised and\ndistillation signals, enabling more effective feature learning than single-head\nKD baselines. As a result, extensive experiments show that $\\texttt{DHO}$\nconsistently outperforms baselines across multiple domains and fine-grained\ndatasets. Notably, on ImageNet, it achieves state-of-the-art performance,\nimproving accuracy by 3% and 0.1% with 1% and 10% labeled data, respectively,\nwhile using fewer parameters.", "published": "2025-05-12 15:39:51", "link": "http://arxiv.org/abs/2505.07675v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "A Case Study Investigating the Role of Generative AI in Quality Evaluations of Epics in Agile Software Development", "abstract": "The broad availability of generative AI offers new opportunities to support\nvarious work domains, including agile software development. Agile epics are a\nkey artifact for product managers to communicate requirements to stakeholders.\nHowever, in practice, they are often poorly defined, leading to churn, delivery\ndelays, and cost overruns. In this industry case study, we investigate\nopportunities for large language models (LLMs) to evaluate agile epic quality\nin a global company. Results from a user study with 17 product managers\nindicate how LLM evaluations could be integrated into their work practices,\nincluding perceived values and usage in improving their epics. High levels of\nsatisfaction indicate that agile epics are a new, viable application of AI\nevaluations. However, our findings also outline challenges, limitations, and\nadoption barriers that can inform both practitioners and researchers on the\nintegration of such evaluations into future agile work practices.", "published": "2025-05-12 15:31:16", "link": "http://arxiv.org/abs/2505.07664v1", "categories": ["cs.SE", "cs.AI", "cs.HC"], "primary_category": "cs.SE"}
{"title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents", "abstract": "The rapid evolution of artificial intelligence (AI) has shifted from static,\ndata-driven models to dynamic systems capable of perceiving and interacting\nwith real-world environments. Despite advancements in pattern recognition and\nsymbolic reasoning, current AI systems, such as large language models, remain\ndisembodied, unable to physically engage with the world. This limitation has\ndriven the rise of embodied AI, where autonomous agents, such as humanoid\nrobots, must navigate and manipulate unstructured environments with human-like\nadaptability. At the core of this challenge lies the concept of Neural Brain, a\ncentral intelligence system designed to drive embodied agents with human-like\nadaptability. A Neural Brain must seamlessly integrate multimodal sensing and\nperception with cognitive capabilities. Achieving this also requires an\nadaptive memory system and energy-efficient hardware-software co-design,\nenabling real-time action in dynamic environments. This paper introduces a\nunified framework for the Neural Brain of embodied agents, addressing two\nfundamental challenges: (1) defining the core components of Neural Brain and\n(2) bridging the gap between static AI models and the dynamic adaptability\nrequired for real-world deployment. To this end, we propose a biologically\ninspired architecture that integrates multimodal active sensing,\nperception-cognition-action function, neuroplasticity-based memory storage and\nupdating, and neuromorphic hardware/software optimization. Furthermore, we also\nreview the latest research on embodied agents across these four aspects and\nanalyze the gap between current AI systems and human intelligence. By\nsynthesizing insights from neuroscience, we outline a roadmap towards the\ndevelopment of generalizable, autonomous agents capable of human-level\nintelligence in real-world scenarios.", "published": "2025-05-12 15:05:34", "link": "http://arxiv.org/abs/2505.07634v1", "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Bang for the Buck: Vector Search on Cloud CPUs", "abstract": "Vector databases have emerged as a new type of systems that support efficient\nquerying of high-dimensional vectors. Many of these offer their database as a\nservice in the cloud. However, the variety of available CPUs and the lack of\nvector search benchmarks across CPUs make it difficult for users to choose one.\nIn this study, we show that CPU microarchitectures available in the cloud\nperform significantly differently across vector search scenarios. For instance,\nin an IVF index on float32 vectors, AMD's Zen4 gives almost 3x more queries per\nsecond (QPS) compared to Intel's Sapphire Rapids, but for HNSW indexes, the\ntables turn. However, when looking at the number of queries per dollar (QP$),\nGraviton3 is the best option for most indexes and quantization settings, even\nover Graviton4 (Table 1). With this work, we hope to guide users in getting the\nbest \"bang for the buck\" when deploying vector search systems.", "published": "2025-05-12 14:44:21", "link": "http://arxiv.org/abs/2505.07621v1", "categories": ["cs.DB", "cs.AI"], "primary_category": "cs.DB"}
{"title": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models", "abstract": "Text-to-audio models have recently emerged as a powerful technology for\ngenerating sound from textual descriptions. However, their high computational\ndemands raise concerns about energy consumption and environmental impact. In\nthis paper, we conduct an analysis of the energy usage of 7 state-of-the-art\ntext-to-audio diffusion-based generative models, evaluating to what extent\nvariations in generation parameters affect energy consumption at inference\ntime. We also aim to identify an optimal balance between audio quality and\nenergy consumption by considering Pareto-optimal solutions across all selected\nmodels. Our findings provide insights into the trade-offs between performance\nand environmental impact, contributing to the development of more efficient\ngenerative audio models.", "published": "2025-05-12 14:36:47", "link": "http://arxiv.org/abs/2505.07615v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models", "abstract": "Leveraging large language model (LLM) based agents to simulate human social\nbehaviors has recently gained significant attention. In this paper, we\nintroduce a novel social simulator called YuLan-OneSim. Compared to previous\nworks, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free\nscenario construction: Users can simply describe and refine their simulation\nscenarios through natural language interactions with our simulator. All\nsimulation code is automatically generated, significantly reducing the need for\nprogramming expertise. (2) Comprehensive default scenarios: We implement 50\ndefault simulation scenarios spanning 8 domains, including economics,\nsociology, politics, psychology, organization, demographics, law, and\ncommunication, broadening access for a diverse range of social researchers. (3)\nEvolvable simulation: Our simulator is capable of receiving external feedback\nand automatically fine-tuning the backbone LLMs, significantly enhancing the\nsimulation quality. (4) Large-scale simulation: By developing a fully\nresponsive agent framework and a distributed simulation architecture, our\nsimulator can handle up to 100,000 agents, ensuring more stable and reliable\nsimulation results. (5) AI social researcher: Leveraging the above features, we\ndevelop an AI social researcher. Users only need to propose a research topic,\nand the AI researcher will automatically analyze the input, construct\nsimulation environments, summarize results, generate technical reports, review\nand refine the reports--completing the social science research loop. To\ndemonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate\nthe quality of the automatically generated scenarios, the reliability,\nefficiency, and scalability of the simulation process, as well as the\nperformance of the AI social researcher.", "published": "2025-05-12 14:05:17", "link": "http://arxiv.org/abs/2505.07581v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Evaluating Modern Visual Anomaly Detection Approaches in Semiconductor Manufacturing: A Comparative Study", "abstract": "Semiconductor manufacturing is a complex, multistage process. Automated\nvisual inspection of Scanning Electron Microscope (SEM) images is indispensable\nfor minimizing equipment downtime and containing costs. Most previous research\nconsiders supervised approaches, assuming a sufficient number of anomalously\nlabeled samples. On the contrary, Visual Anomaly Detection (VAD), an emerging\nresearch domain, focuses on unsupervised learning, avoiding the costly defect\ncollection phase while providing explanations of the predictions. We introduce\na benchmark for VAD in the semiconductor domain by leveraging the MIIC dataset.\nOur results demonstrate the efficacy of modern VAD approaches in this field.", "published": "2025-05-12 13:56:59", "link": "http://arxiv.org/abs/2505.07576v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework", "abstract": "Kidney abnormality segmentation has important potential to enhance the\nclinical workflow, especially in settings requiring quantitative assessments.\nKidney volume could serve as an important biomarker for renal diseases, with\nchanges in volume correlating directly with kidney function. Currently,\nclinical practice often relies on subjective visual assessment for evaluating\nkidney size and abnormalities, including tumors and cysts, which are typically\nstaged based on diameter, volume, and anatomical location. To support a more\nobjective and reproducible approach, this research aims to develop a robust,\nthoroughly validated kidney abnormality segmentation algorithm, made publicly\navailable for clinical and research use. We employ publicly available training\ndatasets and leverage the state-of-the-art medical image segmentation framework\nnnU-Net. Validation is conducted using both proprietary and public test\ndatasets, with segmentation performance quantified by Dice coefficient and the\n95th percentile Hausdorff distance. Furthermore, we analyze robustness across\nsubgroups based on patient sex, age, CT contrast phases, and tumor histologic\nsubtypes. Our findings demonstrate that our segmentation algorithm, trained\nexclusively on publicly available data, generalizes effectively to external\ntest sets and outperforms existing state-of-the-art models across all tested\ndatasets. Subgroup analyses reveal consistent high performance, indicating\nstrong robustness and reliability. The developed algorithm and associated code\nare publicly accessible at\nhttps://github.com/DIAGNijmegen/oncology-kidney-abnormality-segmentation.", "published": "2025-05-12 13:53:19", "link": "http://arxiv.org/abs/2505.07573v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Towards Requirements Engineering for RAG Systems", "abstract": "This short paper explores how a maritime company develops and integrates\nlarge-language models (LLM). Specifically by looking at the requirements\nengineering for Retrieval Augmented Generation (RAG) systems in expert\nsettings. Through a case study at a maritime service provider, we demonstrate\nhow data scientists face a fundamental tension between user expectations of AI\nperfection and the correctness of the generated outputs. Our findings reveal\nthat data scientists must identify context-specific \"retrieval requirements\"\nthrough iterative experimentation together with users because they are the ones\nwho can determine correctness. We present an empirical process model describing\nhow data scientists practically elicited these \"retrieval requirements\" and\nmanaged system limitations. This work advances software engineering knowledge\nby providing insights into the specialized requirements engineering processes\nfor implementing RAG systems in complex domain-specific applications.", "published": "2025-05-12 13:30:44", "link": "http://arxiv.org/abs/2505.07553v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "Automated Visual Attention Detection using Mobile Eye Tracking in Behavioral Classroom Studies", "abstract": "Teachers' visual attention and its distribution across the students in\nclassrooms can constitute important implications for student engagement,\nachievement, and professional teacher training. Despite that, inferring the\ninformation about where and which student teachers focus on is not trivial.\nMobile eye tracking can provide vital help to solve this issue; however, the\nuse of mobile eye tracking alone requires a significant amount of manual\nannotations. To address this limitation, we present an automated processing\npipeline concept that requires minimal manually annotated data to recognize\nwhich student the teachers focus on. To this end, we utilize state-of-the-art\nface detection models and face recognition feature embeddings to train face\nrecognition models with transfer learning in the classroom context and combine\nthese models with the teachers' gaze from mobile eye trackers. We evaluated our\napproach with data collected from four different classrooms, and our results\nshow that while it is possible to estimate the visually focused students with\nreasonable performance in all of our classroom setups, U-shaped and small\nclassrooms led to the best results with accuracies of approximately 0.7 and\n0.9, respectively. While we did not evaluate our method for teacher-student\ninteractions and focused on the validity of the technical approach, as our\nmethodology does not require a vast amount of manually annotated data and\noffers a non-intrusive way of handling teachers' visual attention, it could\nhelp improve instructional strategies, enhance classroom management, and\nprovide feedback for professional teacher development.", "published": "2025-05-12 13:30:30", "link": "http://arxiv.org/abs/2505.07552v1", "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "cs.CV"}
{"title": "Noise Optimized Conditional Diffusion for Domain Adaptation", "abstract": "Pseudo-labeling is a cornerstone of Unsupervised Domain Adaptation (UDA), yet\nthe scarcity of High-Confidence Pseudo-Labeled Target Domain Samples\n(\\textbf{hcpl-tds}) often leads to inaccurate cross-domain statistical\nalignment, causing DA failures. To address this challenge, we propose\n\\textbf{N}oise \\textbf{O}ptimized \\textbf{C}onditional \\textbf{D}iffusion for\n\\textbf{D}omain \\textbf{A}daptation (\\textbf{NOCDDA}), which seamlessly\nintegrates the generative capabilities of conditional diffusion models with the\ndecision-making requirements of DA to achieve task-coupled optimization for\nefficient adaptation. For robust cross-domain consistency, we modify the DA\nclassifier to align with the conditional diffusion classifier within a unified\noptimization framework, enabling forward training on noise-varying cross-domain\nsamples. Furthermore, we argue that the conventional \\( \\mathcal{N}(\\mathbf{0},\n\\mathbf{I}) \\) initialization in diffusion models often generates\nclass-confused hcpl-tds, compromising discriminative DA. To resolve this, we\nintroduce a class-aware noise optimization strategy that refines sampling\nregions for reverse class-specific hcpl-tds generation, effectively enhancing\ncross-domain alignment. Extensive experiments across 5 benchmark datasets and\n29 DA tasks demonstrate significant performance gains of \\textbf{NOCDDA} over\n31 state-of-the-art methods, validating its robustness and effectiveness.", "published": "2025-05-12 13:28:31", "link": "http://arxiv.org/abs/2505.07548v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "GRADA: Graph-based Reranker against Adversarial Documents Attack", "abstract": "Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large\nlanguage models (LLMs) by integrating external knowledge from retrieved\ndocuments, thereby overcoming the limitations of models' static intrinsic\nknowledge. However, these systems are susceptible to adversarial attacks that\nmanipulate the retrieval process by introducing documents that are adversarial\nyet semantically similar to the query. Notably, while these adversarial\ndocuments resemble the query, they exhibit weak similarity to benign documents\nin the retrieval set. Thus, we propose a simple yet effective Graph-based\nReranking against Adversarial Document Attacks (GRADA) framework aiming at\npreserving retrieval quality while significantly reducing the success of\nadversaries. Our study evaluates the effectiveness of our approach through\nexperiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b,\nLlama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with\nresults from the Natural Questions dataset demonstrating up to an 80% reduction\nin attack success rates while maintaining minimal loss in accuracy.", "published": "2025-05-12 13:27:35", "link": "http://arxiv.org/abs/2505.07546v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "The Human-Data-Model Interaction Canvas for Visual Analytics", "abstract": "Visual Analytics (VA) integrates humans, data, and models as key actors in\ninsight generation and data-driven decision-making. This position paper values\nand reflects on 16 VA process models and frameworks and makes nine high-level\nobservations that motivate a fresh perspective on VA. The contribution is the\nHDMI Canvas, a perspective to VA that complements the strengths of existing VA\nprocess models and frameworks. It systematically characterizes diverse roles of\nhumans, data, and models, and how these actors benefit from and contribute to\nVA processes. The descriptive power of the HDMI Canvas eases the\ndifferentiation between a series of VA building blocks, rather than describing\ngeneral VA principles only. The canvas includes modern human-centered\nmethodologies, including human knowledge externalization and forms of feedback\nloops, while interpretable and explainable AI highlight model contributions\nbeyond their conventional outputs. The HDMI Canvas has generative power,\nguiding the design of new VA processes and is optimized for external\nstakeholders, improving VA outreach, interdisciplinary collaboration, and\nuser-centered design. The utility of the HDMI Canvas is demonstrated through\ntwo preliminary case studies.", "published": "2025-05-12 13:15:31", "link": "http://arxiv.org/abs/2505.07534v1", "categories": ["cs.HC", "cs.AI", "cs.LG"], "primary_category": "cs.HC"}
{"title": "IKrNet: A Neural Network for Detecting Specific Drug-Induced Patterns in Electrocardiograms Amidst Physiological Variability", "abstract": "Monitoring and analyzing electrocardiogram (ECG) signals, even under varying\nphysiological conditions, including those influenced by physical activity,\ndrugs and stress, is crucial to accurately assess cardiac health. However,\ncurrent AI-based methods often fail to account for how these factors interact\nand alter ECG patterns, ultimately limiting their applicability in real-world\nsettings. This study introduces IKrNet, a novel neural network model, which\nidentifies drug-specific patterns in ECGs amidst certain physiological\nconditions. IKrNet's architecture incorporates spatial and temporal dynamics by\nusing a convolutional backbone with varying receptive field size to capture\nspatial features. A bi-directional Long Short-Term Memory module is also\nemployed to model temporal dependencies. By treating heart rate variability as\na surrogate for physiological fluctuations, we evaluated IKrNet's performance\nacross diverse scenarios, including conditions with physical stress, drug\nintake alone, and a baseline without drug presence. Our assessment follows a\nclinical protocol in which 990 healthy volunteers were administered 80mg of\nSotalol, a drug which is known to be a precursor to Torsades-de-Pointes, a\nlife-threatening arrhythmia. We show that IKrNet outperforms state-of-the-art\nmodels' accuracy and stability in varying physiological conditions,\nunderscoring its clinical viability.", "published": "2025-05-12 13:14:47", "link": "http://arxiv.org/abs/2505.07533v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads", "abstract": "We present QuantX: a tailored suite of recipes for LLM and VLM quantization.\nIt is capable of quantizing down to 3-bit resolutions with minimal loss in\nperformance. The quantization strategies in QuantX take into account\nhardware-specific constraints to achieve efficient dequantization during\ninference ensuring flexible trade-off between runtime speed, memory requirement\nand model accuracy. Our results demonstrate that QuantX achieves performance\nwithin 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for\nmultiple end user tasks and outperforms recently published state-of-the-art\nquantization techniques. This manuscript provides insights into the LLM\nquantization process that motivated the range of recipes and options that are\nincorporated in QuantX.", "published": "2025-05-12 13:13:06", "link": "http://arxiv.org/abs/2505.07531v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MAIS: Memory-Attention for Interactive Segmentation", "abstract": "Interactive medical segmentation reduces annotation effort by refining\npredictions through user feedback. Vision Transformer (ViT)-based models, such\nas the Segment Anything Model (SAM), achieve state-of-the-art performance using\nuser clicks and prior masks as prompts. However, existing methods treat\ninteractions as independent events, leading to redundant corrections and\nlimited refinement gains. We address this by introducing MAIS, a\nMemory-Attention mechanism for Interactive Segmentation that stores past user\ninputs and segmentation states, enabling temporal context integration. Our\napproach enhances ViT-based segmentation across diverse imaging modalities,\nachieving more efficient and accurate refinements.", "published": "2025-05-12 12:48:27", "link": "http://arxiv.org/abs/2505.07511v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "HALO: Half Life-Based Outdated Fact Filtering in Temporal Knowledge Graphs", "abstract": "Outdated facts in temporal knowledge graphs (TKGs) result from exceeding the\nexpiration date of facts, which negatively impact reasoning performance on\nTKGs. However, existing reasoning methods primarily focus on positive\nimportance of historical facts, neglecting adverse effects of outdated facts.\nBesides, training on these outdated facts yields extra computational cost. To\naddress these challenges, we propose an outdated fact filtering framework named\nHALO, which quantifies the temporal validity of historical facts by exploring\nthe half-life theory to filter outdated facts in TKGs. HALO consists of three\nmodules: the temporal fact attention module, the dynamic relation-aware encoder\nmodule, and the outdated fact filtering module. Firstly, the temporal fact\nattention module captures the evolution of historical facts over time to\nidentify relevant facts. Secondly, the dynamic relation-aware encoder module is\ndesigned for efficiently predicting the half life of each fact. Finally, we\nconstruct a time decay function based on the half-life theory to quantify the\ntemporal validity of facts and filter outdated facts. Experimental results show\nthat HALO outperforms the state-of-the-art TKG reasoning methods on three\npublic datasets, demonstrating its effectiveness in detecting and filtering\noutdated facts (Codes are available at\nhttps://github.com/yushuowiki/K-Half/tree/main ).", "published": "2025-05-12 12:47:20", "link": "http://arxiv.org/abs/2505.07509v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "EAGLE: Contrastive Learning for Efficient Graph Anomaly Detection", "abstract": "Graph anomaly detection is a popular and vital task in various real-world\nscenarios, which has been studied for several decades. Recently, many studies\nextending deep learning-based methods have shown preferable performance on\ngraph anomaly detection. However, existing methods are lack of efficiency that\nis definitely necessary for embedded devices. Towards this end, we propose an\nEfficient Anomaly detection model on heterogeneous Graphs via contrastive\nLEarning (EAGLE) by contrasting abnormal nodes with normal ones in terms of\ntheir distances to the local context. The proposed method first samples\ninstance pairs on meta path-level for contrastive learning. Then, a graph\nautoencoder-based model is applied to learn informative node embeddings in an\nunsupervised way, which will be further combined with the discriminator to\npredict the anomaly scores of nodes. Experimental results show that EAGLE\noutperforms the state-of-the-art methods on three heterogeneous network\ndatasets.", "published": "2025-05-12 12:45:07", "link": "http://arxiv.org/abs/2505.07508v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks", "abstract": "The application of large language models (LLMs) in the field of coding is\nevolving rapidly: from code assistants, to autonomous coding agents, and then\nto generating complete projects through natural language. Early LLM code\nbenchmarks primarily focused on code generation accuracy, but these benchmarks\nhave gradually become saturated. Benchmark saturation weakens their guiding\nrole for LLMs. For example, HumanEval Pass@1 has reached 99.4% and MBPP 94.2%.\nAmong various attempts to address benchmark saturation, approaches based on\nsoftware engineering have stood out, but the saturation of existing software\nengineering benchmarks is rapidly increasing. To address this, we propose a new\nbenchmark, Web-Bench, which contains 50 projects, each consisting of 20 tasks\nwith sequential dependencies. The tasks implement project features in sequence,\nsimulating real-world human development workflows. When designing Web-Bench, we\naim to cover the foundational elements of Web development: Web Standards and\nWeb Frameworks. Given the scale and complexity of these projects, which were\ndesigned by engineers with 5 to 10 years of experience, each presents a\nsignificant challenge. On average, a single project takes 4 to 8 hours for a\nsenior engineer to complete. On our given benchmark agent (Web-Agent), SOTA\n(Claude 3.7 Sonnet) achieves only 25.1% Pass@1, significantly lower (better)\nthan SWE-Bench's Verified (65.4%) and Full (33.8%) scores. Finally, we discuss\nthat in any development field, Standards and Frameworks represent foundational\nknowledge and efficiency tools, respectively, and LLMs require optimization\ntailored to them.", "published": "2025-05-12 12:06:23", "link": "http://arxiv.org/abs/2505.07473v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Can Generative AI agents behave like humans? Evidence from laboratory market experiments", "abstract": "We explore the potential of Large Language Models (LLMs) to replicate human\nbehavior in economic market experiments. Compared to previous studies, we focus\non dynamic feedback between LLM agents: the decisions of each LLM impact the\nmarket price at the current step, and so affect the decisions of the other LLMs\nat the next step. We compare LLM behavior to market dynamics observed in\nlaboratory settings and assess their alignment with human participants'\nbehavior. Our findings indicate that LLMs do not adhere strictly to rational\nexpectations, displaying instead bounded rationality, similarly to human\nparticipants. Providing a minimal context window i.e. memory of three previous\ntime steps, combined with a high variability setting capturing response\nheterogeneity, allows LLMs to replicate broad trends seen in human experiments,\nsuch as the distinction between positive and negative feedback markets.\nHowever, differences remain at a granular level--LLMs exhibit less\nheterogeneity in behavior than humans. These results suggest that LLMs hold\npromise as tools for simulating realistic human behavior in economic contexts,\nthough further research is needed to refine their accuracy and increase\nbehavioral diversity.", "published": "2025-05-12 11:44:46", "link": "http://arxiv.org/abs/2505.07457v1", "categories": ["econ.GN", "cs.AI", "q-fin.EC"], "primary_category": "econ.GN"}
{"title": "How well do LLMs reason over tabular data, really?", "abstract": "Large Language Models (LLMs) excel in natural language tasks, but less is\nknown about their reasoning capabilities over tabular data. Prior analyses\ndevise evaluation strategies that poorly reflect an LLM's realistic performance\non tabular queries. Moreover, we have a limited understanding of the robustness\nof LLMs towards realistic variations in tabular inputs. Therefore, we ask: Can\ngeneral-purpose LLMs reason over tabular data, really?, and focus on two\nquestions 1) are tabular reasoning capabilities of general-purpose LLMs robust\nto real-world characteristics of tabular inputs, and 2) how can we\nrealistically evaluate an LLM's performance on analytical tabular queries?\nBuilding on a recent tabular reasoning benchmark, we first surface shortcomings\nof its multiple-choice prompt evaluation strategy, as well as commonly used\nfree-form text metrics such as SacreBleu and BERT-score. We show that an\nLLM-as-a-judge procedure yields more reliable performance insights and unveil a\nsignificant deficit in tabular reasoning performance of LLMs. We then extend\nthe tabular inputs reflecting three common characteristics in practice: 1)\nmissing values, 2) duplicate entities, and 3) structural variations.\nExperiments show that the tabular reasoning capabilities of general-purpose\nLLMs suffer from these variations, stressing the importance of improving their\nrobustness for realistic tabular inputs.", "published": "2025-05-12 11:35:28", "link": "http://arxiv.org/abs/2505.07453v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Prototype Augmented Hypernetworks for Continual Learning", "abstract": "Continual learning (CL) aims to learn a sequence of tasks without forgetting\nprior knowledge, but gradient updates for a new task often overwrite the\nweights learned earlier, causing catastrophic forgetting (CF). We propose\nPrototype-Augmented Hypernetworks (PAH), a framework where a single\nhypernetwork, conditioned on learnable task prototypes, dynamically generates\ntask-specific classifier heads on demand. To mitigate forgetting, PAH combines\ncross-entropy with dual distillation losses, one to align logits and another to\nalign prototypes, ensuring stable feature representations across tasks.\nEvaluations on Split-CIFAR100 and TinyImageNet demonstrate that PAH achieves\nstate-of-the-art performance, reaching 74.5 % and 63.7 % accuracy with only 1.7\n% and 4.4 % forgetting, respectively, surpassing prior methods without storing\nsamples or heads.", "published": "2025-05-12 11:25:54", "link": "http://arxiv.org/abs/2505.07450v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Unified Continuous Generative Models", "abstract": "Recent advances in continuous generative models, including multi-step\napproaches like diffusion and flow-matching (typically requiring 8-1000\nsampling steps) and few-step methods such as consistency models (typically 1-8\nsteps), have demonstrated impressive generative performance. However, existing\nwork often treats these approaches as distinct paradigms, resulting in separate\ntraining and sampling methodologies. We introduce a unified framework for\ntraining, sampling, and analyzing these models. Our implementation, the Unified\nContinuous Generative Models Trainer and Sampler (UCGM-{T,S}), achieves\nstate-of-the-art (SOTA) performance. For example, on ImageNet 256x256 using a\n675M diffusion transformer, UCGM-T trains a multi-step model achieving 1.30 FID\nin 20 steps and a few-step model reaching 1.42 FID in just 2 steps.\nAdditionally, applying UCGM-S to a pre-trained model (previously 1.26 FID at\n250 steps) improves performance to 1.06 FID in only 40 steps. Code is available\nat: https://github.com/LINs-lab/UCGM.", "published": "2025-05-12 11:15:39", "link": "http://arxiv.org/abs/2505.07447v1", "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "cs.LG"}
{"title": "LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning", "abstract": "Instruction tuning has emerged as a critical paradigm for improving the\ncapabilities and alignment of large language models (LLMs). However, existing\niterative model-aware data selection methods incur significant computational\noverhead, as they rely on repeatedly performing full-dataset model inference to\nestimate sample utility for subsequent training iterations, creating a\nfundamental efficiency bottleneck. In this paper, we propose LEAD, an efficient\niterative data selection framework that accurately estimates sample utility\nentirely within the standard training loop, eliminating the need for costly\nadditional model inference. At its core, LEAD introduces Instance-Level Dynamic\nUncertainty (IDU), a theoretically grounded utility function combining\ninstantaneous training loss, gradient-based approximation of loss changes, and\nexponential smoothing of historical loss signals. To further scale efficiently\nto large datasets, LEAD employs a two-stage, coarse-to-fine selection strategy,\nadaptively prioritizing informative clusters through a multi-armed bandit\nmechanism, followed by precise fine-grained selection of high-utility samples\nusing IDU. Extensive experiments across four diverse benchmarks show that LEAD\nsignificantly outperforms state-of-the-art methods, improving average model\nperformance by 6.1%-10.8% while using only 2.5% of the training data and\nreducing overall training time by 5-10x.", "published": "2025-05-12 10:57:51", "link": "http://arxiv.org/abs/2505.07437v1", "categories": ["cs.LG", "cs.AI", "cs.DB"], "primary_category": "cs.LG"}
{"title": "AI in Money Matters", "abstract": "In November 2022, Europe and the world by and large were stunned by the birth\nof a new large language model : ChatGPT. Ever since then, both academic and\npopulist discussions have taken place in various public spheres such as\nLinkedIn and X(formerly known as Twitter) with the view to both understand the\ntool and its benefits for the society. The views of real actors in professional\nspaces, especially in regulated industries such as finance and law have been\nlargely missing. We aim to begin to close this gap by presenting results from\nan empirical investigation conducted through interviews with professional\nactors in the Fintech industry. The paper asks the question, how and to what\nextent are large language models in general and ChatGPT in particular being\nadopted and used in the Fintech industry? The results show that while the\nfintech experts we spoke with see a potential in using large language models in\nthe future, a lot of questions marks remain concerning how they are policed and\ntherefore might be adopted in a regulated industry such as Fintech. This paper\naims to add to the existing academic discussing around large language models,\nwith a contribution to our understanding of professional viewpoints.", "published": "2025-05-12 09:43:51", "link": "http://arxiv.org/abs/2505.07393v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Few-shot Semantic Encoding and Decoding for Video Surveillance", "abstract": "With the continuous increase in the number and resolution of video\nsurveillance cameras, the burden of transmitting and storing surveillance video\nis growing. Traditional communication methods based on Shannon's theory are\nfacing optimization bottlenecks. Semantic communication, as an emerging\ncommunication method, is expected to break through this bottleneck and reduce\nthe storage and transmission consumption of video. Existing semantic decoding\nmethods often require many samples to train the neural network for each scene,\nwhich is time-consuming and labor-intensive. In this study, a semantic encoding\nand decoding method for surveillance video is proposed. First, the sketch was\nextracted as semantic information, and a sketch compression method was proposed\nto reduce the bit rate of semantic information. Then, an image translation\nnetwork was proposed to translate the sketch into a video frame with a\nreference frame. Finally, a few-shot sketch decoding network was proposed to\nreconstruct video from sketch. Experimental results showed that the proposed\nmethod achieved significantly better video reconstruction performance than\nbaseline methods. The sketch compression method could effectively reduce the\nstorage and transmission consumption of semantic information with little\ncompromise on video quality. The proposed method provides a novel semantic\nencoding and decoding method that only needs a few training samples for each\nsurveillance scene, thus improving the practicality of the semantic\ncommunication system.", "published": "2025-05-12 09:27:28", "link": "http://arxiv.org/abs/2505.07381v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Examining the Role of LLM-Driven Interactions on Attention and Cognitive Engagement in Virtual Classrooms", "abstract": "Transforming educational technologies through the integration of large\nlanguage models (LLMs) and virtual reality (VR) offers the potential for\nimmersive and interactive learning experiences. However, the effects of LLMs on\nuser engagement and attention in educational environments remain open\nquestions. In this study, we utilized a fully LLM-driven virtual learning\nenvironment, where peers and teachers were LLM-driven, to examine how students\nbehaved in such settings. Specifically, we investigate how peer question-asking\nbehaviors influenced student engagement, attention, cognitive load, and\nlearning outcomes and found that, in conditions where LLM-driven peer learners\nasked questions, students exhibited more targeted visual scanpaths, with their\nattention directed toward the learning content, particularly in complex\nsubjects. Our results suggest that peer questions did not introduce extraneous\ncognitive load directly, as the cognitive load is strongly correlated with\nincreased attention to the learning material. Considering these findings, we\nprovide design recommendations for optimizing VR learning spaces.", "published": "2025-05-12 09:21:19", "link": "http://arxiv.org/abs/2505.07377v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "AIS Data-Driven Maritime Monitoring Based on Transformer: A Comprehensive Review", "abstract": "With the increasing demands for safety, efficiency, and sustainability in\nglobal shipping, Automatic Identification System (AIS) data plays an\nincreasingly important role in maritime monitoring. AIS data contains\nspatial-temporal variation patterns of vessels that hold significant research\nvalue in the marine domain. However, due to its massive scale, the full\npotential of AIS data has long remained untapped. With its powerful sequence\nmodeling capabilities, particularly its ability to capture long-range\ndependencies and complex temporal dynamics, the Transformer model has emerged\nas an effective tool for processing AIS data. Therefore, this paper reviews the\nresearch on Transformer-based AIS data-driven maritime monitoring, providing a\ncomprehensive overview of the current applications of Transformer models in the\nmarine field. The focus is on Transformer-based trajectory prediction methods,\nbehavior detection, and prediction techniques. Additionally, this paper\ncollects and organizes publicly available AIS datasets from the reviewed\npapers, performing data filtering, cleaning, and statistical analysis. The\nstatistical results reveal the operational characteristics of different vessel\ntypes, providing data support for further research on maritime monitoring\ntasks. Finally, we offer valuable suggestions for future research, identifying\ntwo promising research directions. Datasets are available at\nhttps://github.com/eyesofworld/Maritime-Monitoring.", "published": "2025-05-12 09:17:43", "link": "http://arxiv.org/abs/2505.07374v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data", "abstract": "This paper presents a novel methodology for enhancing Automated Program\nRepair (APR) through synthetic data generation utilizing Large Language Models\n(LLMs). Current APR systems are constrained by the limited availability of\nhigh-quality training data encompassing diverse bug types across multiple\nprogramming languages. The proposed approach addresses this limitation through\na two-phase process: a synthetic sample generation followed by a rigorous\nquality assessment. Multiple state-of-the-art LLMs were employed to generate\napproximately 30,000 paired examples of buggy and fixed code across 12\nprogramming languages and 13 bug categories. Subsequently, these samples\nunderwent cross-model evaluation against five criteria: correctness, code\nquality, security, performance, and completeness. Experimental evaluation on\nthe VulRepair test set dataset showed statistically significant improvements in\nPerfect Prediction rates, with the quality-filtered synthetic dataset\noutperforming both baseline and real-world commit data configurations in\ncertain scenarios. The methodology was validated through rigorous statistical\ntesting, including ANOVA and post-hoc Tukey's Honest Significant Difference\nanalysis. Furthermore, the best-performing configurations surpassed existing\nsystems despite using a less computationally intensive decoding strategy. This\nresearch establishes a self-bootstrapping paradigm in which LLMs generate and\nevaluate their own training data, potentially transforming approaches to data\nscarcity across software engineering tasks and advancing the development of\nrobust, adaptable tools for automated code maintenance.", "published": "2025-05-12 09:14:20", "link": "http://arxiv.org/abs/2505.07372v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "GAN-based synthetic FDG PET images from T1 brain MRI can serve to improve performance of deep unsupervised anomaly detection models", "abstract": "Background and Objective. Research in the cross-modal medical image\ntranslation domain has been very productive over the past few years in tackling\nthe scarce availability of large curated multimodality datasets with the\npromising performance of GAN-based architectures. However, only a few of these\nstudies assessed task-based related performance of these synthetic data,\nespecially for the training of deep models. Method. We design and compare\ndifferent GAN-based frameworks for generating synthetic brain\n[18F]fluorodeoxyglucose (FDG) PET images from T1 weighted MRI data. We first\nperform standard qualitative and quantitative visual quality evaluation. Then,\nwe explore further impact of using these fake PET data in the training of a\ndeep unsupervised anomaly detection (UAD) model designed to detect subtle\nepilepsy lesions in T1 MRI and FDG PET images. We introduce novel diagnostic\ntask-oriented quality metrics of the synthetic FDG PET data tailored to our\nunsupervised detection task, then use these fake data to train a use case UAD\nmodel combining a deep representation learning based on siamese autoencoders\nwith a OC-SVM density support estimation model. This model is trained on normal\nsubjects only and allows the detection of any variation from the pattern of the\nnormal population. We compare the detection performance of models trained on 35\npaired real MR T1 of normal subjects paired either on 35 true PET images or on\n35 synthetic PET images generated from the best performing generative models.\nPerformance analysis is conducted on 17 exams of epilepsy patients undergoing\nsurgery. Results. The best performing GAN-based models allow generating\nrealistic fake PET images of control subject with SSIM and PSNR values around\n0.9 and 23.8, respectively and in distribution (ID) with regard to the true\ncontrol dataset. The best UAD model trained on these synthetic normative PET\ndata allows reaching 74% sensitivity. Conclusion. Our results confirm that\nGAN-based models are the best suited for MR T1 to FDG PET translation,\noutperforming transformer or diffusion models. We also demonstrate the\ndiagnostic value of these synthetic data for the training of UAD models and\nevaluation on clinical exams of epilepsy patients. Our code and the normative\nimage dataset are available.", "published": "2025-05-12 09:00:03", "link": "http://arxiv.org/abs/2505.07364v1", "categories": ["eess.IV", "cs.AI"], "primary_category": "eess.IV"}
{"title": "Generative Pre-trained Autoregressive Diffusion Transformer", "abstract": "In this work, we present GPDiT, a Generative Pre-trained Autoregressive\nDiffusion Transformer that unifies the strengths of diffusion and\nautoregressive modeling for long-range video synthesis, within a continuous\nlatent space. Instead of predicting discrete tokens, GPDiT autoregressively\npredicts future latent frames using a diffusion loss, enabling natural modeling\nof motion dynamics and semantic consistency across frames. This continuous\nautoregressive framework not only enhances generation quality but also endows\nthe model with representation capabilities. Additionally, we introduce a\nlightweight causal attention variant and a parameter-free rotation-based\ntime-conditioning mechanism, improving both the training and inference\nefficiency. Extensive experiments demonstrate that GPDiT achieves strong\nperformance in video generation quality, video representation ability, and\nfew-shot learning tasks, highlighting its potential as an effective framework\nfor video modeling in continuous space.", "published": "2025-05-12 08:32:39", "link": "http://arxiv.org/abs/2505.07344v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Laypeople's Attitudes Towards Fair, Affirmative, and Discriminatory Decision-Making Algorithms", "abstract": "Affirmative algorithms have emerged as a potential answer to algorithmic\ndiscrimination, seeking to redress past harms and rectify the source of\nhistorical injustices. We present the results of two experiments ($N$$=$$1193$)\ncapturing laypeople's perceptions of affirmative algorithms -- those which\nexplicitly prioritize the historically marginalized -- in hiring and criminal\njustice. We contrast these opinions about affirmative algorithms with folk\nattitudes towards algorithms that prioritize the privileged (i.e.,\ndiscriminatory) and systems that make decisions independently of demographic\ngroups (i.e., fair). We find that people -- regardless of their political\nleaning and identity -- view fair algorithms favorably and denounce\ndiscriminatory systems. In contrast, we identify disagreements concerning\naffirmative algorithms: liberals and racial minorities rate affirmative systems\nas positively as their fair counterparts, whereas conservatives and those from\nthe dominant racial group evaluate affirmative algorithms as negatively as\ndiscriminatory systems. We identify a source of these divisions: people have\nvarying beliefs about who (if anyone) is marginalized, shaping their views of\naffirmative algorithms. We discuss the possibility of bridging these\ndisagreements to bring people together towards affirmative algorithms.", "published": "2025-05-12 08:25:15", "link": "http://arxiv.org/abs/2505.07339v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "SAEN-BGS: Energy-Efficient Spiking AutoEncoder Network for Background Subtraction", "abstract": "Background subtraction (BGS) is utilized to detect moving objects in a video\nand is commonly employed at the onset of object tracking and human recognition\nprocesses. Nevertheless, existing BGS techniques utilizing deep learning still\nencounter challenges with various background noises in videos, including\nvariations in lighting, shifts in camera angles, and disturbances like air\nturbulence or swaying trees. To address this problem, we design a spiking\nautoencoder network, termed SAEN-BGS, based on noise resilience and\ntime-sequence sensitivity of spiking neural networks (SNNs) to enhance the\nseparation of foreground and background. To eliminate unnecessary background\nnoise and preserve the important foreground elements, we begin by creating the\ncontinuous spiking conv-and-dconv block, which serves as the fundamental\nbuilding block for the decoder in SAEN-BGS. Moreover, in striving for enhanced\nenergy efficiency, we introduce a novel self-distillation spiking supervised\nlearning method grounded in ANN-to-SNN frameworks, resulting in decreased power\nconsumption. In extensive experiments conducted on CDnet-2014 and DAVIS-2016\ndatasets, our approach demonstrates superior segmentation performance relative\nto other baseline methods, even when challenged by complex scenarios with\ndynamic backgrounds.", "published": "2025-05-12 08:21:47", "link": "http://arxiv.org/abs/2505.07336v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Dynamical Label Augmentation and Calibration for Noisy Electronic Health Records", "abstract": "Medical research, particularly in predicting patient outcomes, heavily relies\non medical time series data extracted from Electronic Health Records (EHR),\nwhich provide extensive information on patient histories. Despite rigorous\nexamination, labeling errors are inevitable and can significantly impede\naccurate predictions of patient outcome. To address this challenge, we propose\nan \\textbf{A}ttention-based Learning Framework with Dynamic\n\\textbf{C}alibration and Augmentation for \\textbf{T}ime series Noisy\n\\textbf{L}abel \\textbf{L}earning (ACTLL). This framework leverages a\ntwo-component Beta mixture model to identify the certain and uncertain sets of\ninstances based on the fitness distribution of each class, and it captures\nglobal temporal dynamics while dynamically calibrating labels from the\nuncertain set or augmenting confident instances from the certain set.\nExperimental results on large-scale EHR datasets eICU and MIMIC-IV-ED, and\nseveral benchmark datasets from the UCR and UEA repositories, demonstrate that\nour model ACTLL has achieved state-of-the-art performance, especially under\nhigh noise levels.", "published": "2025-05-12 08:06:16", "link": "http://arxiv.org/abs/2505.07320v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "How Do Companies Manage the Environmental Sustainability of AI? An Interview Study About Green AI Efforts and Regulations", "abstract": "With the ever-growing adoption of artificial intelligence (AI), AI-based\nsoftware and its negative impact on the environment are no longer negligible,\nand studying and mitigating this impact has become a critical area of research.\nHowever, it is currently unclear which role environmental sustainability plays\nduring AI adoption in industry and how AI regulations influence Green AI\npractices and decision-making in industry. We therefore aim to investigate the\nGreen AI perception and management of industry practitioners. To this end, we\nconducted a total of 11 interviews with participants from 10 different\norganizations that adopted AI-based software. The interviews explored three\nmain themes: AI adoption, current efforts in mitigating the negative\nenvironmental impact of AI, and the influence of the EU AI Act and the\nCorporate Sustainability Reporting Directive (CSRD). Our findings indicate that\n9 of 11 participants prioritized business efficiency during AI adoption, with\nminimal consideration of environmental sustainability. Monitoring and\nmitigation of AI's environmental impact were very limited. Only one participant\nmonitored negative environmental effects. Regarding applied mitigation\npractices, six participants reported no actions, with the others sporadically\nmentioning techniques like prompt engineering, relying on smaller models, or\nnot overusing AI. Awareness and compliance with the EU AI Act are low, with\nonly one participant reporting on its influence, while the CSRD drove\nsustainability reporting efforts primarily in larger companies. All in all, our\nfindings reflect a lack of urgency and priority for sustainable AI among these\ncompanies. We suggest that current regulations are not very effective, which\nhas implications for policymakers. Additionally, there is a need to raise\nindustry awareness, but also to provide user-friendly techniques and tools for\nGreen AI practices.", "published": "2025-05-12 08:03:55", "link": "http://arxiv.org/abs/2505.07317v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "FedIFL: A federated cross-domain diagnostic framework for motor-driven systems with inconsistent fault modes", "abstract": "Due to the scarcity of industrial data, individual equipment users,\nparticularly start-ups, struggle to independently train a comprehensive fault\ndiagnosis model; federated learning enables collaborative training while\nensuring data privacy, making it an ideal solution. However, the diversity of\nworking conditions leads to variations in fault modes, resulting in\ninconsistent label spaces across different clients. In federated diagnostic\nscenarios, label space inconsistency leads to local models focus on\nclient-specific fault modes and causes local models from different clients to\nmap different failure modes to similar feature representations, which weakens\nthe aggregated global model's generalization. To tackle this issue, this\narticle proposed a federated cross-domain diagnostic framework termed Federated\nInvariant Features Learning (FedIFL). In intra-client training, prototype\ncontrastive learning mitigates intra-client domain shifts, subsequently,\nfeature generating ensures local models can access distributions of other\nclients in a privacy-friendly manner. Besides, in cross-client training, a\nfeature disentanglement mechanism is introduced to mitigate cross-client domain\nshifts, specifically, an instance-level federated instance consistency loss is\ndesigned to ensure the instance-level consistency of invariant features between\ndifferent clients, furthermore, a federated instance personalization loss and\nan orthogonal loss are constructed to distinguish specific features that from\nthe invariant features. Eventually, the aggregated model achieves promising\ngeneralization among global label spaces, enabling accurate fault diagnosis for\ntarget clients' Motor Driven Systems (MDSs) with inconsistent label spaces.\nExperiments on real-world MDSs validate the effectiveness and superiority of\nFedIFL in federated cross-domain diagnosis with inconsistent fault modes.", "published": "2025-05-12 08:00:49", "link": "http://arxiv.org/abs/2505.07315v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Interpretable Event Diagnosis in Water Distribution Networks", "abstract": "The increasing penetration of information and communication technologies in\nthe design, monitoring, and control of water systems enables the use of\nalgorithms for detecting and identifying unanticipated events (such as leakages\nor water contamination) using sensor measurements. However, data-driven\nmethodologies do not always give accurate results and are often not trusted by\noperators, who may prefer to use their engineering judgment and experience to\ndeal with such events.\n  In this work, we propose a framework for interpretable event diagnosis -- an\napproach that assists the operators in associating the results of algorithmic\nevent diagnosis methodologies with their own intuition and experience. This is\nachieved by providing contrasting (i.e., counterfactual) explanations of the\nresults provided by fault diagnosis algorithms; their aim is to improve the\nunderstanding of the algorithm's inner workings by the operators, thus enabling\nthem to take a more informed decision by combining the results with their\npersonal experiences. Specifically, we propose counterfactual event\nfingerprints, a representation of the difference between the current event\ndiagnosis and the closest alternative explanation, which can be presented in a\ngraphical way. The proposed methodology is applied and evaluated on a realistic\nuse case using the L-Town benchmark.", "published": "2025-05-12 07:36:00", "link": "http://arxiv.org/abs/2505.07299v1", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "HuB: Learning Extreme Humanoid Balance", "abstract": "The human body demonstrates exceptional motor capabilities-such as standing\nsteadily on one foot or performing a high kick with the leg raised over 1.5\nmeters-both requiring precise balance control. While recent research on\nhumanoid control has leveraged reinforcement learning to track human motions\nfor skill acquisition, applying this paradigm to balance-intensive tasks\nremains challenging. In this work, we identify three key obstacles: instability\nfrom reference motion errors, learning difficulties due to morphological\nmismatch, and the sim-to-real gap caused by sensor noise and unmodeled\ndynamics. To address these challenges, we propose HuB (Humanoid Balance), a\nunified framework that integrates reference motion refinement, balance-aware\npolicy learning, and sim-to-real robustness training, with each component\ntargeting a specific challenge. We validate our approach on the Unitree G1\nhumanoid robot across challenging quasi-static balance tasks, including extreme\nsingle-legged poses such as Swallow Balance and Bruce Lee's Kick. Our policy\nremains stable even under strong physical disturbances-such as a forceful\nsoccer strike-while baseline methods consistently fail to complete these tasks.\nProject website: https://hub-robot.github.io", "published": "2025-05-12 07:31:42", "link": "http://arxiv.org/abs/2505.07294v1", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "Piloting Structure-Based Drug Design via Modality-Specific Optimal Schedule", "abstract": "Structure-Based Drug Design (SBDD) is crucial for identifying bioactive\nmolecules. Recent deep generative models are faced with challenges in geometric\nstructure modeling. A major bottleneck lies in the twisted probability path of\nmulti-modalities -- continuous 3D positions and discrete 2D topologies -- which\njointly determine molecular geometries. By establishing the fact that noise\nschedules decide the Variational Lower Bound (VLB) for the twisted probability\npath, we propose VLB-Optimal Scheduling (VOS) strategy in this under-explored\narea, which optimizes VLB as a path integral for SBDD. Our model effectively\nenhances molecular geometries and interaction modeling, achieving\nstate-of-the-art PoseBusters passing rate of 95.9% on CrossDock, more than 10%\nimprovement upon strong baselines, while maintaining high affinities and robust\nintramolecular validity evaluated on held-out test set.", "published": "2025-05-12 07:18:09", "link": "http://arxiv.org/abs/2505.07286v1", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "Predicting Music Track Popularity by Convolutional Neural Networks on Spotify Features and Spectrogram of Audio Waveform", "abstract": "In the digital streaming landscape, it's becoming increasingly challenging\nfor artists and industry experts to predict the success of music tracks. This\nstudy introduces a pioneering methodology that uses Convolutional Neural\nNetworks (CNNs) and Spotify data analysis to forecast the popularity of music\ntracks. Our approach takes advantage of Spotify's wide range of features,\nincluding acoustic attributes based on the spectrogram of audio waveform,\nmetadata, and user engagement metrics, to capture the complex patterns and\nrelationships that influence a track's popularity. Using a large dataset\ncovering various genres and demographics, our CNN-based model shows impressive\neffectiveness in predicting the popularity of music tracks. Additionally, we've\nconducted extensive experiments to assess the strength and adaptability of our\nmodel across different musical styles and time periods, with promising results\nyielding a 97\\% F1 score. Our study not only offers valuable insights into the\ndynamic landscape of digital music consumption but also provides the music\nindustry with advanced predictive tools for assessing and predicting the\nsuccess of music tracks.", "published": "2025-05-12 07:03:17", "link": "http://arxiv.org/abs/2505.07280v1", "categories": ["cs.SD", "cs.AI", "68T05, 68T10, 68T37", "I.2.6; I.2.1"], "primary_category": "cs.SD"}
{"title": "CHD: Coupled Hierarchical Diffusion for Long-Horizon Tasks", "abstract": "Diffusion-based planners have shown strong performance in short-horizon tasks\nbut often fail in complex, long-horizon settings. We trace the failure to loose\ncoupling between high-level (HL) sub-goal selection and low-level (LL)\ntrajectory generation, which leads to incoherent plans and degraded\nperformance. We propose Coupled Hierarchical Diffusion (CHD), a framework that\nmodels HL sub-goals and LL trajectories jointly within a unified diffusion\nprocess. A shared classifier passes LL feedback upstream so that sub-goals\nself-correct while sampling proceeds. This tight HL-LL coupling improves\ntrajectory coherence and enables scalable long-horizon diffusion planning.\nExperiments across maze navigation, tabletop manipulation, and household\nenvironments show that CHD consistently outperforms both flat and hierarchical\ndiffusion baselines.", "published": "2025-05-12 06:21:48", "link": "http://arxiv.org/abs/2505.07261v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "UMoE: Unifying Attention and FFN with Shared Experts", "abstract": "Sparse Mixture of Experts (MoE) architectures have emerged as a promising\napproach for scaling Transformer models. While initial works primarily\nincorporated MoE into feed-forward network (FFN) layers, recent studies have\nexplored extending the MoE paradigm to attention layers to enhance model\nperformance. However, existing attention-based MoE layers require specialized\nimplementations and demonstrate suboptimal performance compared to their\nFFN-based counterparts. In this paper, we aim to unify the MoE designs in\nattention and FFN layers by introducing a novel reformulation of the attention\nmechanism, revealing an underlying FFN-like structure within attention modules.\nOur proposed architecture, UMoE, achieves superior performance through\nattention-based MoE layers while enabling efficient parameter sharing between\nFFN and attention components.", "published": "2025-05-12 06:21:44", "link": "http://arxiv.org/abs/2505.07260v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Incomplete In-context Learning", "abstract": "Large vision language models (LVLMs) achieve remarkable performance through\nVision In-context Learning (VICL), a process that depends significantly on\ndemonstrations retrieved from an extensive collection of annotated examples\n(retrieval database). Existing studies often assume that the retrieval database\ncontains annotated examples for all labels. However, in real-world scenarios,\ndelays in database updates or incomplete data annotation may result in the\nretrieval database containing labeled samples for only a subset of classes. We\nrefer to this phenomenon as an \\textbf{incomplete retrieval database} and\ndefine the in-context learning under this condition as \\textbf{Incomplete\nIn-context Learning (IICL)}. To address this challenge, we propose\n\\textbf{Iterative Judgments and Integrated Prediction (IJIP)}, a two-stage\nframework designed to mitigate the limitations of IICL. The Iterative Judgments\nStage reformulates an \\(\\boldsymbol{m}\\)-class classification problem into a\nseries of \\(\\boldsymbol{m}\\) binary classification tasks, effectively\nconverting the IICL setting into a standard VICL scenario. The Integrated\nPrediction Stage further refines the classification process by leveraging both\nthe input image and the predictions from the Iterative Judgments Stage to\nenhance overall classification accuracy. IJIP demonstrates considerable\nperformance across two LVLMs and two datasets under three distinct conditions\nof label incompleteness, achieving the highest accuracy of 93.9\\%. Notably,\neven in scenarios where labels are fully available, IJIP still achieves the\nbest performance of all six baselines. Furthermore, IJIP can be directly\napplied to \\textbf{Prompt Learning} and is adaptable to the \\textbf{text\ndomain}.", "published": "2025-05-12 05:57:39", "link": "http://arxiv.org/abs/2505.07251v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "REMEDI: Relative Feature Enhanced Meta-Learning with Distillation for Imbalanced Prediction", "abstract": "Predicting future vehicle purchases among existing owners presents a critical\nchallenge due to extreme class imbalance (<0.5% positive rate) and complex\nbehavioral patterns. We propose REMEDI (Relative feature Enhanced Meta-learning\nwith Distillation for Imbalanced prediction), a novel multi-stage framework\naddressing these challenges. REMEDI first trains diverse base models to capture\ncomplementary aspects of user behavior. Second, inspired by comparative\nop-timization techniques, we introduce relative performance meta-features\n(deviation from ensemble mean, rank among peers) for effective model fusion\nthrough a hybrid-expert architecture. Third, we distill the ensemble's\nknowledge into a single efficient model via supervised fine-tuning with MSE\nloss, enabling practical deployment. Evaluated on approximately 800,000 vehicle\nowners, REMEDI significantly outperforms baseline approaches, achieving the\nbusiness target of identifying ~50% of actual buyers within the top 60,000\nrecommendations at ~10% precision. The distilled model preserves the ensemble's\npredictive power while maintaining deployment efficiency, demonstrating\nREMEDI's effectiveness for imbalanced prediction in industry settings.", "published": "2025-05-12 05:40:20", "link": "http://arxiv.org/abs/2505.07245v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity", "abstract": "With the growing use of large language models (LLMs) hosted on cloud\nplatforms to offer inference services, privacy concerns about the potential\nleakage of sensitive information are escalating. Secure multi-party computation\n(MPC) is a promising solution to protect the privacy in LLM inference. However,\nMPC requires frequent inter-server communication, causing high performance\noverhead.\n  Inspired by the prevalent activation sparsity of LLMs, where most neuron are\nnot activated after non-linear activation functions, we propose an efficient\nprivate inference system, Comet. This system employs an accurate and fast\npredictor to predict the sparsity distribution of activation function output.\nAdditionally, we introduce a new private inference protocol. It efficiently and\nsecurely avoids computations involving zero values by exploiting the spatial\nlocality of the predicted sparse distribution. While this computation-avoidance\napproach impacts the spatiotemporal continuity of KV cache entries, we address\nthis challenge with a low-communication overhead cache refilling strategy that\nmerges miss requests and incorporates a prefetching mechanism. Finally, we\nevaluate Comet on four common LLMs and compare it with six state-of-the-art\nprivate inference systems. Comet achieves a 1.87x-2.63x speedup and a\n1.94x-2.64x communication reduction.", "published": "2025-05-12 05:29:30", "link": "http://arxiv.org/abs/2505.07239v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning", "abstract": "We present UAV-CodeAgents, a scalable multi-agent framework for autonomous\nUAV mission generation, built on large language and vision-language models\n(LLMs/VLMs). The system leverages the ReAct (Reason + Act) paradigm to\ninterpret satellite imagery, ground high-level natural language instructions,\nand collaboratively generate UAV trajectories with minimal human supervision. A\ncore component is a vision-grounded, pixel-pointing mechanism that enables\nprecise localization of semantic targets on aerial maps. To support real-time\nadaptability, we introduce a reactive thinking loop, allowing agents to\niteratively reflect on observations, revise mission goals, and coordinate\ndynamically in evolving environments.\n  UAV-CodeAgents is evaluated on large-scale mission scenarios involving\nindustrial and environmental fire detection. Our results show that a lower\ndecoding temperature (0.5) yields higher planning reliability and reduced\nexecution time, with an average mission creation time of 96.96 seconds and a\nsuccess rate of 93%. We further fine-tune Qwen2.5VL-7B on 9,000 annotated\nsatellite images, achieving strong spatial grounding across diverse visual\ncategories. To foster reproducibility and future research, we will release the\nfull codebase and a novel benchmark dataset for vision-language-based UAV\nplanning.", "published": "2025-05-12 05:23:51", "link": "http://arxiv.org/abs/2505.07236v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Measuring General Intelligence with Generated Games", "abstract": "We present gg-bench, a collection of game environments designed to evaluate\ngeneral reasoning capabilities in language models. Unlike most static\nbenchmarks, gg-bench is a data generating process where new evaluation\ninstances can be generated at will. In particular, gg-bench is synthetically\ngenerated by (1) using a large language model (LLM) to generate natural\nlanguage descriptions of novel games, (2) using the LLM to implement each game\nin code as a Gym environment, and (3) training reinforcement learning (RL)\nagents via self-play on the generated games. We evaluate language models by\ntheir winrate against these RL agents by prompting models with the game\ndescription, current board state, and a list of valid moves, after which models\noutput the moves they wish to take. gg-bench is challenging: state-of-the-art\nLLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench\nusing in-context learning, while reasoning models such as o1, o3-mini and\nDeepSeek-R1 achieve average winrates of 31-36%. We release the generated games,\ndata generation process, and evaluation code in order to support future\nmodeling work and expansion of our benchmark.", "published": "2025-05-12 04:01:03", "link": "http://arxiv.org/abs/2505.07215v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Towards user-centered interactive medical image segmentation in VR with an assistive AI agent", "abstract": "Crucial in disease analysis and surgical planning, manual segmentation of\nvolumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and\nchallenging to master, while fully automatic algorithms can benefit from\nuser-feedback. Therefore, with the complementary power of the latest\nradiological AI foundation models and virtual reality (VR)'s intuitive data\ninteraction, we propose SAMIRA, a novel conversational AI agent that assists\nusers with localizing, segmenting, and visualizing 3D medical concepts in VR.\nThrough speech-based interaction, the agent helps users understand radiological\nfeatures, locate clinical targets, and generate segmentation masks that can be\nrefined with just a few point prompts. The system also supports true-to-scale\n3D visualization of segmented pathology to enhance patient-specific anatomical\nunderstanding. Furthermore, to determine the optimal interaction paradigm under\nnear-far attention-switching for refining segmentation masks in an immersive,\nhuman-in-the-loop workflow, we compare VR controller pointing, head pointing,\nand eye tracking as input modes. With a user study, evaluations demonstrated a\nhigh usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as\nstrong support for the proposed VR system's guidance, training potential, and\nintegration of AI in radiological segmentation tasks.", "published": "2025-05-12 03:47:05", "link": "http://arxiv.org/abs/2505.07214v1", "categories": ["cs.HC", "cs.AI", "cs.CV"], "primary_category": "cs.HC"}
{"title": "Accountability of Generative AI: Exploring a Precautionary Approach for \"Artificially Created Nature\"", "abstract": "The rapid development of generative artificial intelligence (AI) technologies\nraises concerns about the accountability of sociotechnical systems. Current\ngenerative AI systems rely on complex mechanisms that make it difficult for\neven experts to fully trace the reasons behind the outputs. This paper first\nexamines existing research on AI transparency and accountability and argues\nthat transparency is not a sufficient condition for accountability but can\ncontribute to its improvement. We then discuss that if it is not possible to\nmake generative AI transparent, generative AI technology becomes ``artificially\ncreated nature'' in a metaphorical sense, and suggest using the precautionary\nprinciple approach to consider AI risks. Finally, we propose that a platform\nfor citizen participation is needed to address the risks of generative AI.", "published": "2025-05-12 02:10:55", "link": "http://arxiv.org/abs/2505.07178v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Internet of Agents: Fundamentals, Applications, and Challenges", "abstract": "With the rapid proliferation of large language models and vision-language\nmodels, AI agents have evolved from isolated, task-specific systems into\nautonomous, interactive entities capable of perceiving, reasoning, and acting\nwithout human intervention. As these agents proliferate across virtual and\nphysical environments, from virtual assistants to embodied robots, the need for\na unified, agent-centric infrastructure becomes paramount. In this survey, we\nintroduce the Internet of Agents (IoA) as a foundational framework that enables\nseamless interconnection, dynamic discovery, and collaborative orchestration\namong heterogeneous agents at scale. We begin by presenting a general IoA\narchitecture, highlighting its hierarchical organization, distinguishing\nfeatures relative to the traditional Internet, and emerging applications. Next,\nwe analyze the key operational enablers of IoA, including capability\nnotification and discovery, adaptive communication protocols, dynamic task\nmatching, consensus and conflict-resolution mechanisms, and incentive models.\nFinally, we identify open research directions toward building resilient and\ntrustworthy IoA ecosystems.", "published": "2025-05-12 02:04:37", "link": "http://arxiv.org/abs/2505.07176v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "ReCDAP: Relation-Based Conditional Diffusion with Attention Pooling for Few-Shot Knowledge Graph Completion", "abstract": "Knowledge Graphs (KGs), composed of triples in the form of (head, relation,\ntail) and consisting of entities and relations, play a key role in information\nretrieval systems such as question answering, entity search, and\nrecommendation. In real-world KGs, although many entities exist, the relations\nexhibit a long-tail distribution, which can hinder information retrieval\nperformance. Previous few-shot knowledge graph completion studies focused\nexclusively on the positive triple information that exists in the graph or,\nwhen negative triples were incorporated, used them merely as a signal to\nindicate incorrect triples. To overcome this limitation, we propose\nRelation-Based Conditional Diffusion with Attention Pooling (ReCDAP). First,\nnegative triples are generated by randomly replacing the tail entity in the\nsupport set. By conditionally incorporating positive information in the KG and\nnon-existent negative information into the diffusion process, the model\nseparately estimates the latent distributions for positive and negative\nrelations. Moreover, including an attention pooler enables the model to\nleverage the differences between positive and negative cases explicitly.\nExperiments on two widely used datasets demonstrate that our method outperforms\nexisting approaches, achieving state-of-the-art performance. The code is\navailable at https://github.com/hou27/ReCDAP-FKGC.", "published": "2025-05-12 01:49:52", "link": "http://arxiv.org/abs/2505.07171v1", "categories": ["cs.AI", "cs.IR"], "primary_category": "cs.AI"}
{"title": "DanceGRPO: Unleashing GRPO on Visual Generation", "abstract": "Recent breakthroughs in generative models-particularly diffusion models and\nrectified flows-have revolutionized visual content creation, yet aligning model\noutputs with human preferences remains a critical challenge. Existing\nreinforcement learning (RL)-based methods for visual generation face critical\nlimitations: incompatibility with modern Ordinary Differential Equations\n(ODEs)-based sampling paradigms, instability in large-scale training, and lack\nof validation for video generation. This paper introduces DanceGRPO, the first\nunified framework to adapt Group Relative Policy Optimization (GRPO) to visual\ngeneration paradigms, unleashing one unified RL algorithm across two generative\nparadigms (diffusion models and rectified flows), three tasks (text-to-image,\ntext-to-video, image-to-video), four foundation models (Stable Diffusion,\nHunyuanVideo, FLUX, SkyReel-I2V), and five reward models (image/video\naesthetics, text-image alignment, video motion quality, and binary reward). To\nour knowledge, DanceGRPO is the first RL-based unified framework capable of\nseamless adaptation across diverse generative paradigms, tasks, foundational\nmodels, and reward models. DanceGRPO demonstrates consistent and substantial\nimprovements, which outperform baselines by up to 181% on benchmarks such as\nHPS-v2.1, CLIP Score, VideoAlign, and GenEval. Notably, DanceGRPO not only can\nstabilize policy optimization for complex video generation, but also enables\ngenerative policy to better capture denoising trajectories for Best-of-N\ninference scaling and learn from sparse binary feedback. Our results establish\nDanceGRPO as a robust and versatile solution for scaling Reinforcement Learning\nfrom Human Feedback (RLHF) tasks in visual generation, offering new insights\ninto harmonizing reinforcement learning and visual synthesis. The code will be\nreleased.", "published": "2025-05-12 17:59:34", "link": "http://arxiv.org/abs/2505.07818v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Pixel Motion as Universal Representation for Robot Control", "abstract": "We present LangToMo, a vision-language-action framework structured as a\ndual-system architecture that uses pixel motion forecasts as intermediate\nrepresentations. Our high-level System 2, an image diffusion model, generates\ntext-conditioned pixel motion sequences from a single frame to guide robot\ncontrol. Pixel motion-a universal, interpretable, and motion-centric\nrepresentation-can be extracted from videos in a self-supervised manner,\nenabling diffusion model training on web-scale video-caption data. Treating\ngenerated pixel motion as learned universal representations, our low level\nSystem 1 module translates these into robot actions via motion-to-action\nmapping functions, which can be either hand-crafted or learned with minimal\nsupervision. System 2 operates as a high-level policy applied at sparse\ntemporal intervals, while System 1 acts as a low-level policy at dense temporal\nintervals. This hierarchical decoupling enables flexible, scalable, and\ngeneralizable robot control under both unsupervised and supervised settings,\nbridging the gap between language, motion, and action. Checkout\nhttps://kahnchana.github.io/LangToMo for visualizations.", "published": "2025-05-12 17:59:32", "link": "http://arxiv.org/abs/2505.07817v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models", "abstract": "Exploration is essential for general-purpose robotic learning, especially in\nopen-ended environments where dense rewards, explicit goals, or task-specific\nsupervision are scarce. Vision-language models (VLMs), with their semantic\nreasoning over objects, spatial relations, and potential outcomes, present a\ncompelling foundation for generating high-level exploratory behaviors. However,\ntheir outputs are often ungrounded, making it difficult to determine whether\nimagined transitions are physically feasible or informative. To bridge the gap\nbetween imagination and execution, we present IVE (Imagine, Verify, Execute),\nan agentic exploration framework inspired by human curiosity. Human exploration\nis often driven by the desire to discover novel scene configurations and to\ndeepen understanding of the environment. Similarly, IVE leverages VLMs to\nabstract RGB-D observations into semantic scene graphs, imagine novel scenes,\npredict their physical plausibility, and generate executable skill sequences\nthrough action tools. We evaluate IVE in both simulated and real-world tabletop\nenvironments. The results show that IVE enables more diverse and meaningful\nexploration than RL baselines, as evidenced by a 4.1 to 7.8x increase in the\nentropy of visited states. Moreover, the collected experience supports\ndownstream learning, producing policies that closely match or exceed the\nperformance of those trained on human-collected demonstrations.", "published": "2025-05-12 17:59:11", "link": "http://arxiv.org/abs/2505.07815v1", "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Continuous Visual Autoregressive Generation via Score Maximization", "abstract": "Conventional wisdom suggests that autoregressive models are used to process\ndiscrete data. When applied to continuous modalities such as visual data,\nVisual AutoRegressive modeling (VAR) typically resorts to quantization-based\napproaches to cast the data into a discrete space, which can introduce\nsignificant information loss. To tackle this issue, we introduce a Continuous\nVAR framework that enables direct visual autoregressive generation without\nvector quantization. The underlying theoretical foundation is strictly proper\nscoring rules, which provide powerful statistical tools capable of evaluating\nhow well a generative model approximates the true distribution. Within this\nframework, all we need is to select a strictly proper score and set it as the\ntraining objective to optimize. We primarily explore a class of training\nobjectives based on the energy score, which is likelihood-free and thus\novercomes the difficulty of making probabilistic predictions in the continuous\nspace. Previous efforts on continuous autoregressive generation, such as GIVT\nand diffusion loss, can also be derived from our framework using other strictly\nproper scores. Source code: https://github.com/shaochenze/EAR.", "published": "2025-05-12 17:58:14", "link": "http://arxiv.org/abs/2505.07812v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Privacy Risks of Robot Vision: A User Study on Image Modalities and Resolution", "abstract": "User privacy is a crucial concern in robotic applications, especially when\nmobile service robots are deployed in personal or sensitive environments.\nHowever, many robotic downstream tasks require the use of cameras, which may\nraise privacy risks. To better understand user perceptions of privacy in\nrelation to visual data, we conducted a user study investigating how different\nimage modalities and image resolutions affect users' privacy concerns. The\nresults show that depth images are broadly viewed as privacy-safe, and a\nsimilarly high proportion of respondents feel the same about semantic\nsegmentation images. Additionally, the majority of participants consider 32*32\nresolution RGB images to be almost sufficiently privacy-preserving, while most\nbelieve that 16*16 resolution can fully guarantee privacy protection.", "published": "2025-05-12 17:16:12", "link": "http://arxiv.org/abs/2505.07766v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Skeletonization of neuronal processes using Discrete Morse techniques from computational topology", "abstract": "To understand biological intelligence we need to map neuronal networks in\nvertebrate brains. Mapping mesoscale neural circuitry is done using injections\nof tracers that label groups of neurons whose axons project to different brain\nregions. Since many neurons are labeled, it is difficult to follow individual\naxons. Previous approaches have instead quantified the regional projections\nusing the total label intensity within a region. However, such a quantification\nis not biologically meaningful. We propose a new approach better connected to\nthe underlying neurons by skeletonizing labeled axon fragments and then\nestimating a volumetric length density. Our approach uses a combination of deep\nnets and the Discrete Morse (DM) technique from computational topology. This\ntechnique takes into account nonlocal connectivity information and therefore\nprovides noise-robustness. We demonstrate the utility and scalability of the\napproach on whole-brain tracer injected data. We also define and illustrate an\ninformation theoretic measure that quantifies the additional information\nobtained, compared to the skeletonized tracer injection fragments, when\nindividual axon morphologies are available. Our approach is the first\napplication of the DM technique to computational neuroanatomy. It can help\nbridge between single-axon skeletons and tracer injections, two important data\ntypes in mapping neural networks in vertebrates.", "published": "2025-05-12 16:59:36", "link": "http://arxiv.org/abs/2505.07754v1", "categories": ["q-bio.NC", "cs.CV"], "primary_category": "q-bio.NC"}
{"title": "Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets", "abstract": "While generative artificial intelligence has advanced significantly across\ntext, image, audio, and video domains, 3D generation remains comparatively\nunderdeveloped due to fundamental challenges such as data scarcity, algorithmic\nlimitations, and ecosystem fragmentation. To this end, we present Step1X-3D, an\nopen framework addressing these challenges through: (1) a rigorous data\ncuration pipeline processing >5M assets to create a 2M high-quality dataset\nwith standardized geometric and textural properties; (2) a two-stage 3D-native\narchitecture combining a hybrid VAE-DiT geometry generator with an\ndiffusion-based texture synthesis module; and (3) the full open-source release\nof models, training code, and adaptation modules. For geometry generation, the\nhybrid VAE-DiT component produces TSDF representations by employing\nperceiver-based latent encoding with sharp edge sampling for detail\npreservation. The diffusion-based texture synthesis module then ensures\ncross-view consistency through geometric conditioning and latent-space\nsynchronization. Benchmark results demonstrate state-of-the-art performance\nthat exceeds existing open-source methods, while also achieving competitive\nquality with proprietary solutions. Notably, the framework uniquely bridges the\n2D and 3D generation paradigms by supporting direct transfer of 2D control\ntechniques~(e.g., LoRA) to 3D synthesis. By simultaneously advancing data\nquality, algorithmic fidelity, and reproducibility, Step1X-3D aims to establish\nnew standards for open research in controllable 3D asset generation.", "published": "2025-05-12 16:56:30", "link": "http://arxiv.org/abs/2505.07747v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "BodyGPS: Anatomical Positioning System", "abstract": "We introduce a new type of foundational model for parsing human anatomy in\nmedical images that works for different modalities. It supports supervised or\nunsupervised training and can perform matching, registration, classification,\nor segmentation with or without user interaction. We achieve this by training a\nneural network estimator that maps query locations to atlas coordinates via\nregression. Efficiency is improved by sparsely sampling the input, enabling\nresponse times of less than 1 ms without additional accelerator hardware. We\ndemonstrate the utility of the algorithm in both CT and MRI modalities.", "published": "2025-05-12 16:53:41", "link": "http://arxiv.org/abs/2505.07744v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "LAMM-ViT: AI Face Detection via Layer-Aware Modulation of Region-Guided Attention", "abstract": "Detecting AI-synthetic faces presents a critical challenge: it is hard to\ncapture consistent structural relationships between facial regions across\ndiverse generation techniques. Current methods, which focus on specific\nartifacts rather than fundamental inconsistencies, often fail when confronted\nwith novel generative models. To address this limitation, we introduce\nLayer-aware Mask Modulation Vision Transformer (LAMM-ViT), a Vision Transformer\ndesigned for robust facial forgery detection. This model integrates distinct\nRegion-Guided Multi-Head Attention (RG-MHA) and Layer-aware Mask Modulation\n(LAMM) components within each layer. RG-MHA utilizes facial landmarks to create\nregional attention masks, guiding the model to scrutinize architectural\ninconsistencies across different facial areas. Crucially, the separate LAMM\nmodule dynamically generates layer-specific parameters, including mask weights\nand gating values, based on network context. These parameters then modulate the\nbehavior of RG-MHA, enabling adaptive adjustment of regional focus across\nnetwork depths. This architecture facilitates the capture of subtle,\nhierarchical forgery cues ubiquitous among diverse generation techniques, such\nas GANs and Diffusion Models. In cross-model generalization tests, LAMM-ViT\ndemonstrates superior performance, achieving 94.09% mean ACC (a +5.45%\nimprovement over SoTA) and 98.62% mean AP (a +3.09% improvement). These results\ndemonstrate LAMM-ViT's exceptional ability to generalize and its potential for\nreliable deployment against evolving synthetic media threats.", "published": "2025-05-12 16:42:19", "link": "http://arxiv.org/abs/2505.07734v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Gameplay Highlights Generation", "abstract": "In this work, we enable gamers to share their gaming experience on social\nmedia by automatically generating eye-catching highlight reels from their\ngameplay session Our automation will save time for gamers while increasing\naudience engagement. We approach the highlight generation problem by first\nidentifying intervals in the video where interesting events occur and then\nconcatenate them. We developed an in-house gameplay event detection dataset\ncontaining interesting events annotated by humans using VIA video annotator.\nTraditional techniques for highlight detection such as game engine integration\nrequires expensive collaboration with game developers. OCR techniques which\ndetect patches of specific images or texts require expensive per game\nengineering and may not generalize across game UI and different language. We\nfinetuned a multimodal general purpose video understanding model such as X-CLIP\nusing our dataset which generalizes across multiple games in a genre without\nper game engineering. Prompt engineering was performed to improve the\nclassification performance of this multimodal model. Our evaluation showed that\nsuch a finetuned model can detect interesting events in first person shooting\ngames from unseen gameplay footage with more than 90% accuracy. Moreover, our\nmodel performed significantly better on low resource games (small dataset) when\ntrained along with high resource games, showing signs of transfer learning. To\nmake the model production ready, we used ONNX libraries to enable cross\nplatform inference. These libraries also provide post training quantization\ntools to reduce model size and inference time for deployment. ONNX runtime\nlibraries with DirectML backend were used to perform efficient inference on\nWindows OS. We show that natural language supervision in the X-CLIP model leads\nto data efficient and highly performant video recognition models.", "published": "2025-05-12 16:28:22", "link": "http://arxiv.org/abs/2505.07721v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Feedback-Driven Pseudo-Label Reliability Assessment: Redefining Thresholding for Semi-Supervised Semantic Segmentation", "abstract": "Semi-supervised learning leverages unlabeled data to enhance model\nperformance, addressing the limitations of fully supervised approaches. Among\nits strategies, pseudo-supervision has proven highly effective, typically\nrelying on one or multiple teacher networks to refine pseudo-labels before\ntraining a student network. A common practice in pseudo-supervision is\nfiltering pseudo-labels based on pre-defined confidence thresholds or entropy.\nHowever, selecting optimal thresholds requires large labeled datasets, which\nare often scarce in real-world semi-supervised scenarios. To overcome this\nchallenge, we propose Ensemble-of-Confidence Reinforcement (ENCORE), a dynamic\nfeedback-driven thresholding strategy for pseudo-label selection. Instead of\nrelying on static confidence thresholds, ENCORE estimates class-wise\ntrue-positive confidence within the unlabeled dataset and continuously adjusts\nthresholds based on the model's response to different levels of pseudo-label\nfiltering. This feedback-driven mechanism ensures the retention of informative\npseudo-labels while filtering unreliable ones, enhancing model training without\nmanual threshold tuning. Our method seamlessly integrates into existing\npseudo-supervision frameworks and significantly improves segmentation\nperformance, particularly in data-scarce conditions. Extensive experiments\ndemonstrate that integrating ENCORE with existing pseudo-supervision frameworks\nenhances performance across multiple datasets and network architectures,\nvalidating its effectiveness in semi-supervised learning.", "published": "2025-05-12 15:58:08", "link": "http://arxiv.org/abs/2505.07691v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond CLIP Generalization: Against Forward&Backward Forgetting Adapter for Continual Learning of Vision-Language Models", "abstract": "This study aims to address the problem of multi-domain task incremental\nlearning~(MTIL), which requires that vision-language models~(VLMs) continuously\nacquire new knowledge while maintaining their inherent zero-shot recognition\ncapability. Existing paradigms delegate the testing of unseen-domain samples to\nthe original CLIP, which only prevents the degradation of the model's zero-shot\ncapability but fails to enhance the generalization of the VLM further. To this\nend, we propose a novel MTIL framework, named AFA, which comprises two core\nmodules: (1) an against forward-forgetting adapter that learns task-invariant\ninformation for each dataset in the incremental tasks to enhance the zero-shot\nrecognition ability of VLMs; (2) an against backward-forgetting adapter that\nstrengthens the few-shot learning capability of VLMs while supporting\nincremental learning. Extensive experiments demonstrate that the AFA method\nsignificantly outperforms existing state-of-the-art approaches, especially in\nfew-shot MTIL tasks, and surpasses the inherent zero-shot performance of CLIP\nin terms of transferability. The code is provided in the Supplementary\nMaterial.", "published": "2025-05-12 15:56:23", "link": "http://arxiv.org/abs/2505.07690v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Anatomical Attention Alignment representation for Radiology Report Generation", "abstract": "Automated Radiology report generation (RRG) aims at producing detailed\ndescriptions of medical images, reducing radiologists' workload and improving\naccess to high-quality diagnostic services. Existing encoder-decoder models\nonly rely on visual features extracted from raw input images, which can limit\nthe understanding of spatial structures and semantic relationships, often\nresulting in suboptimal text generation. To address this, we propose Anatomical\nAttention Alignment Network (A3Net), a framework that enhance visual-textual\nunderstanding by constructing hyper-visual representations. Our approach\nintegrates a knowledge dictionary of anatomical structures with patch-level\nvisual features, enabling the model to effectively associate image regions with\ntheir corresponding anatomical entities. This structured representation\nimproves semantic reasoning, interpretability, and cross-modal alignment,\nultimately enhancing the accuracy and clinical relevance of generated reports.\nExperimental results on IU X-Ray and MIMIC-CXR datasets demonstrate that A3Net\nsignificantly improves both visual perception and text generation quality. Our\ncode is available at \\href{https://github.com/Vinh-AI/A3Net}{GitHub}.", "published": "2025-05-12 15:54:50", "link": "http://arxiv.org/abs/2505.07689v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ABS-Mamba: SAM2-Driven Bidirectional Spiral Mamba Network for Medical Image Translation", "abstract": "Accurate multi-modal medical image translation requires ha-rmonizing global\nanatomical semantics and local structural fidelity, a challenge complicated by\nintermodality information loss and structural distortion. We propose ABS-Mamba,\na novel architecture integrating the Segment Anything Model 2 (SAM2) for\norgan-aware semantic representation, specialized convolutional neural networks\n(CNNs) for preserving modality-specific edge and texture details, and Mamba's\nselective state-space modeling for efficient long- and short-range feature\ndependencies. Structurally, our dual-resolution framework leverages SAM2's\nimage encoder to capture organ-scale semantics from high-resolution inputs,\nwhile a parallel CNNs branch extracts fine-grained local features. The Robust\nFeature Fusion Network (RFFN) integrates these epresentations, and the\nBidirectional Mamba Residual Network (BMRN) models spatial dependencies using\nspiral scanning and bidirectional state-space dynamics. A three-stage skip\nfusion decoder enhances edge and texture fidelity. We employ Efficient Low-Rank\nAdaptation (LoRA+) fine-tuning to enable precise domain specialization while\nmaintaining the foundational capabilities of the pre-trained components.\nExtensive experimental validation on the SynthRAD2023 and BraTS2019 datasets\ndemonstrates that ABS-Mamba outperforms state-of-the-art methods, delivering\nhigh-fidelity cross-modal synthesis that preserves anatomical semantics and\nstructural details to enhance diagnostic accuracy in clinical applications. The\ncode is available at https://github.com/gatina-yone/ABS-Mamba", "published": "2025-05-12 15:51:15", "link": "http://arxiv.org/abs/2505.07687v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Hierarchical Sparse Attention Framework for Computationally Efficient Classification of Biological Cells", "abstract": "We present SparseAttnNet, a new hierarchical attention-driven framework for\nefficient image classification that adaptively selects and processes only the\nmost informative pixels from images. Traditional convolutional neural networks\ntypically process the entire images regardless of information density, leading\nto computational inefficiency and potential focus on irrelevant features. Our\napproach leverages a dynamic selection mechanism that uses coarse attention\ndistilled by fine multi-head attention from the downstream layers of the model,\nallowing the model to identify and extract the most salient k pixels, where k\nis adaptively learned during training based on loss convergence trends. Once\nthe top-k pixels are selected, the model processes only these pixels, embedding\nthem as words in a language model to capture their semantics, followed by\nmulti-head attention to incorporate global context. For biological cell images,\nwe demonstrate that SparseAttnNet can process approximately 15% of the pixels\ninstead of the full image. Applied to cell classification tasks using white\nblood cells images from the following modalities: optical path difference (OPD)\nimages from digital holography for stain-free cells, images from\nmotion-sensitive (event) camera from stain-free cells, and brightfield\nmicroscopy images of stained cells, For all three imaging modalities,\nSparseAttnNet achieves competitive accuracy while drastically reducing\ncomputational requirements in terms of both parameters and floating-point\noperations per second, compared to traditional CNNs and Vision Transformers.\nSince the model focuses on biologically relevant regions, it also offers\nimproved explainability. The adaptive and lightweight nature of SparseAttnNet\nmakes it ideal for deployment in resource-constrained and high-throughput\nsettings, including imaging flow cytometry.", "published": "2025-05-12 15:29:08", "link": "http://arxiv.org/abs/2505.07661v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Breast Cancer Classification in Deep Ultraviolet Fluorescence Images Using a Patch-Level Vision Transformer Framework", "abstract": "Breast-conserving surgery (BCS) aims to completely remove malignant lesions\nwhile maximizing healthy tissue preservation. Intraoperative margin assessment\nis essential to achieve a balance between thorough cancer resection and tissue\nconservation. A deep ultraviolet fluorescence scanning microscope (DUV-FSM)\nenables rapid acquisition of whole surface images (WSIs) for excised tissue,\nproviding contrast between malignant and normal tissues. However, breast cancer\nclassification with DUV WSIs is challenged by high resolutions and complex\nhistopathological features. This study introduces a DUV WSI classification\nframework using a patch-level vision transformer (ViT) model, capturing local\nand global features. Grad-CAM++ saliency weighting highlights relevant spatial\nregions, enhances result interpretability, and improves diagnostic accuracy for\nbenign and malignant tissue classification. A comprehensive 5-fold\ncross-validation demonstrates the proposed approach significantly outperforms\nconventional deep learning methods, achieving a classification accuracy of\n98.33%.", "published": "2025-05-12 15:22:54", "link": "http://arxiv.org/abs/2505.07654v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "ShotAdapter: Text-to-Multi-Shot Video Generation with Diffusion Models", "abstract": "Current diffusion-based text-to-video methods are limited to producing short\nvideo clips of a single shot and lack the capability to generate multi-shot\nvideos with discrete transitions where the same character performs distinct\nactivities across the same or different backgrounds. To address this limitation\nwe propose a framework that includes a dataset collection pipeline and\narchitectural extensions to video diffusion models to enable text-to-multi-shot\nvideo generation. Our approach enables generation of multi-shot videos as a\nsingle video with full attention across all frames of all shots, ensuring\ncharacter and background consistency, and allows users to control the number,\nduration, and content of shots through shot-specific conditioning. This is\nachieved by incorporating a transition token into the text-to-video model to\ncontrol at which frames a new shot begins and a local attention masking\nstrategy which controls the transition token's effect and allows shot-specific\nprompting. To obtain training data we propose a novel data collection pipeline\nto construct a multi-shot video dataset from existing single-shot video\ndatasets. Extensive experiments demonstrate that fine-tuning a pre-trained\ntext-to-video model for a few thousand iterations is enough for the model to\nsubsequently be able to generate multi-shot videos with shot-specific control,\noutperforming the baselines. You can find more details in\nhttps://shotadapter.github.io/", "published": "2025-05-12 15:22:28", "link": "http://arxiv.org/abs/2505.07652v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "A Unified Hierarchical Framework for Fine-grained Cross-view Geo-localization over Large-scale Scenarios", "abstract": "Cross-view geo-localization is a promising solution for large-scale\nlocalization problems, requiring the sequential execution of retrieval and\nmetric localization tasks to achieve fine-grained predictions. However,\nexisting methods typically focus on designing standalone models for these two\ntasks, resulting in inefficient collaboration and increased training overhead.\nIn this paper, we propose UnifyGeo, a novel unified hierarchical\ngeo-localization framework that integrates retrieval and metric localization\ntasks into a single network. Specifically, we first employ a unified learning\nstrategy with shared parameters to jointly learn multi-granularity\nrepresentation, facilitating mutual reinforcement between these two tasks.\nSubsequently, we design a re-ranking mechanism guided by a dedicated loss\nfunction, which enhances geo-localization performance by improving both\nretrieval accuracy and metric localization references. Extensive experiments\ndemonstrate that UnifyGeo significantly outperforms the state-of-the-arts in\nboth task-isolated and task-associated settings. Remarkably, on the challenging\nVIGOR benchmark, which supports fine-grained localization evaluation, the\n1-meter-level localization recall rate improves from 1.53\\% to 39.64\\% and from\n0.43\\% to 25.58\\% under same-area and cross-area evaluations, respectively.\nCode will be made publicly available.", "published": "2025-05-12 14:44:31", "link": "http://arxiv.org/abs/2505.07622v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Higher-Order Convolution Improves Neural Predictivity in the Retina", "abstract": "We present a novel approach to neural response prediction that incorporates\nhigher-order operations directly within convolutional neural networks (CNNs).\nOur model extends traditional 3D CNNs by embedding higher-order operations\nwithin the convolutional operator itself, enabling direct modeling of\nmultiplicative interactions between neighboring pixels across space and time.\nOur model increases the representational power of CNNs without increasing their\ndepth, therefore addressing the architectural disparity between deep artificial\nnetworks and the relatively shallow processing hierarchy of biological visual\nsystems. We evaluate our approach on two distinct datasets: salamander retinal\nganglion cell (RGC) responses to natural scenes, and a new dataset of mouse RGC\nresponses to controlled geometric transformations. Our higher-order CNN (HoCNN)\nachieves superior performance while requiring only half the training data\ncompared to standard architectures, demonstrating correlation coefficients up\nto 0.75 with neural responses (against 0.80$\\pm$0.02 retinal reliability). When\nintegrated into state-of-the-art architectures, our approach consistently\nimproves performance across different species and stimulus conditions. Analysis\nof the learned representations reveals that our network naturally encodes\nfundamental geometric transformations, particularly scaling parameters that\ncharacterize object expansion and contraction. This capability is especially\nrelevant for specific cell types, such as transient OFF-alpha and transient ON\ncells, which are known to detect looming objects and object motion\nrespectively, and where our model shows marked improvement in response\nprediction. The correlation coefficients for scaling parameters are more than\ntwice as high in HoCNN (0.72) compared to baseline models (0.32).", "published": "2025-05-12 14:43:32", "link": "http://arxiv.org/abs/2505.07620v1", "categories": ["cs.CV", "cs.LG", "q-bio.NC"], "primary_category": "cs.CV"}
{"title": "Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A Comprehensive Review of Methods,Datasets,and Future Directions", "abstract": "Traffic accident prediction and detection are critical for enhancing road\nsafety,and vision-based traffic accident anticipation (Vision-TAA) has emerged\nas a promising approach in the era of deep learning.This paper reviews 147\nrecent studies,focusing on the application of supervised,unsupervised,and\nhybrid deep learning models for accident prediction,alongside the use of\nreal-world and synthetic datasets.Current methodologies are categorized into\nfour key approaches: image and video feature-based prediction, spatiotemporal\nfeature-based prediction, scene understanding,and multimodal data fusion.While\nthese methods demonstrate significant potential,challenges such as data\nscarcity,limited generalization to complex scenarios,and real-time performance\nconstraints remain prevalent. This review highlights opportunities for future\nresearch,including the integration of multimodal data fusion, self-supervised\nlearning,and Transformer-based architectures to enhance prediction accuracy and\nscalability.By synthesizing existing advancements and identifying critical\ngaps, this paper provides a foundational reference for developing robust and\nadaptive Vision-TAA systems,contributing to road safety and traffic management.", "published": "2025-05-12 14:34:22", "link": "http://arxiv.org/abs/2505.07611v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Beyond Static Perception: Integrating Temporal Context into VLMs for Cloth Folding", "abstract": "Manipulating clothes is challenging due to their complex dynamics, high\ndeformability, and frequent self-occlusions. Garments exhibit a nearly infinite\nnumber of configurations, making explicit state representations difficult to\ndefine. In this paper, we analyze BiFold, a model that predicts\nlanguage-conditioned pick-and-place actions from visual observations, while\nimplicitly encoding garment state through end-to-end learning. To address\nscenarios such as crumpled garments or recovery from failed manipulations,\nBiFold leverages temporal context to improve state estimation. We examine the\ninternal representations of the model and present evidence that its fine-tuning\nand temporal context enable effective alignment between text and image regions,\nas well as temporal consistency.", "published": "2025-05-12 14:24:03", "link": "http://arxiv.org/abs/2505.07600v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Self-Supervised Event Representations: Towards Accurate, Real-Time Perception on SoC FPGAs", "abstract": "Event cameras offer significant advantages over traditional frame-based\nsensors. These include microsecond temporal resolution, robustness under\nvarying lighting conditions and low power consumption. Nevertheless, the\neffective processing of their sparse, asynchronous event streams remains\nchallenging. Existing approaches to this problem can be categorised into two\ndistinct groups. The first group involves the direct processing of event data\nwith neural models, such as Spiking Neural Networks or Graph Convolutional\nNeural Networks. However, this approach is often accompanied by a compromise in\nterms of qualitative performance. The second group involves the conversion of\nevents into dense representations with handcrafted aggregation functions, which\ncan boost accuracy at the cost of temporal fidelity. This paper introduces a\nnovel Self-Supervised Event Representation (SSER) method leveraging Gated\nRecurrent Unit (GRU) networks to achieve precise per-pixel encoding of event\ntimestamps and polarities without temporal discretisation. The recurrent layers\nare trained in a self-supervised manner to maximise the fidelity of event-time\nencoding. The inference is performed with event representations generated\nasynchronously, thus ensuring compatibility with high-throughput sensors. The\nexperimental validation demonstrates that SSER outperforms aggregation-based\nbaselines, achieving improvements of 2.4% mAP and 0.6% on the Gen1 and 1 Mpx\nobject detection datasets. Furthermore, the paper presents the first hardware\nimplementation of recurrent representation for event data on a System-on-Chip\nFPGA, achieving sub-microsecond latency and power consumption between 1-2 W,\nsuitable for real-time, power-efficient applications. Code is available at\nhttps://github.com/vision-agh/RecRepEvent.", "published": "2025-05-12 13:32:08", "link": "http://arxiv.org/abs/2505.07556v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SynID: Passport Synthetic Dataset for Presentation Attack Detection", "abstract": "The demand for Presentation Attack Detection (PAD) to identify fraudulent ID\ndocuments in remote verification systems has significantly risen in recent\nyears. This increase is driven by several factors, including the rise of remote\nwork, online purchasing, migration, and advancements in synthetic images.\nAdditionally, we have noticed a surge in the number of attacks aimed at the\nenrolment process. Training a PAD to detect fake ID documents is very\nchallenging because of the limited number of ID documents available due to\nprivacy concerns. This work proposes a new passport dataset generated from a\nhybrid method that combines synthetic data and open-access information using\nthe ICAO requirement to obtain realistic training and testing images.", "published": "2025-05-12 13:24:54", "link": "http://arxiv.org/abs/2505.07540v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "GIFStream: 4D Gaussian-based Immersive Video with Feature Stream", "abstract": "Immersive video offers a 6-Dof-free viewing experience, potentially playing a\nkey role in future video technology. Recently, 4D Gaussian Splatting has gained\nattention as an effective approach for immersive video due to its high\nrendering efficiency and quality, though maintaining quality with manageable\nstorage remains challenging. To address this, we introduce GIFStream, a novel\n4D Gaussian representation using a canonical space and a deformation field\nenhanced with time-dependent feature streams. These feature streams enable\ncomplex motion modeling and allow efficient compression by leveraging temporal\ncorrespondence and motion-aware pruning. Additionally, we incorporate both\ntemporal and spatial compression networks for end-to-end compression.\nExperimental results show that GIFStream delivers high-quality immersive video\nat 30 Mbps, with real-time rendering and fast decoding on an RTX 4090. Project\npage: https://xdimlab.github.io/GIFStream", "published": "2025-05-12 13:24:36", "link": "http://arxiv.org/abs/2505.07539v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning", "abstract": "We completely discard the conventional spatial prior in image representation\nand introduce a novel discrete visual tokenizer: Self-consistency Tokenizer\n(Selftok). At its design core, we compose an autoregressive (AR) prior --\nmirroring the causal structure of language -- into visual tokens by using the\nreverse diffusion process of image generation. The AR property makes Selftok\nfundamentally distinct from traditional spatial tokens in the following two key\nways: - Selftok offers an elegant and minimalist approach to unify diffusion\nand AR for vision-language models (VLMs): By representing images with Selftok\ntokens, we can train a VLM using a purely discrete autoregressive architecture\n-- like that in LLMs -- without requiring additional modules or training\nobjectives. - We theoretically show that the AR prior satisfies the Bellman\nequation, whereas the spatial prior does not. Therefore, Selftok supports\nreinforcement learning (RL) for visual generation with effectiveness comparable\nto that achieved in LLMs. Besides the AR property, Selftok is also a SoTA\ntokenizer that achieves a favorable trade-off between high-quality\nreconstruction and compression rate. We use Selftok to build a pure AR VLM for\nboth visual comprehension and generation tasks. Impressively, without using any\ntext-image training pairs, a simple policy gradient RL working in the visual\ntokens can significantly boost the visual generation benchmark, surpassing all\nthe existing models by a large margin. Therefore, we believe that Selftok\neffectively addresses the long-standing challenge that visual tokens cannot\nsupport effective RL. When combined with the well-established strengths of RL\nin LLMs, this brings us one step closer to realizing a truly multimodal LLM.\nProject Page: https://selftok-team.github.io/report/.", "published": "2025-05-12 13:19:08", "link": "http://arxiv.org/abs/2505.07538v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images", "abstract": "Synthetic face datasets are increasingly used to overcome the limitations of\nreal-world biometric data, including privacy concerns, demographic imbalance,\nand high collection costs. However, many existing methods lack fine-grained\ncontrol over identity attributes and fail to produce paired,\nidentity-consistent images under structured capture conditions. We introduce\nFLUXSynID, a framework for generating high-resolution synthetic face datasets\nwith user-defined identity attribute distributions and paired document-style\nand trusted live capture images. The dataset generated using the FLUXSynID\nframework shows improved alignment with real-world identity distributions and\ngreater inter-set diversity compared to prior work. The FLUXSynID framework for\ngenerating custom datasets, along with a dataset of 14,889 synthetic\nidentities, is publicly released to support biometric research, including face\nrecognition and morphing attack detection.", "published": "2025-05-12 13:12:33", "link": "http://arxiv.org/abs/2505.07530v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models", "abstract": "The remote embodied referring expression (REVERIE) task requires an agent to\nnavigate through complex indoor environments and localize a remote object\nspecified by high-level instructions, such as \"bring me a spoon\", without\npre-exploration. Hence, an efficient navigation plan is essential for the final\nsuccess. This paper proposes a novel parameter-efficient action planner using\nlarge language models (PEAP-LLM) to generate a single-step instruction at each\nlocation. The proposed model consists of two modules, LLM goal planner (LGP)\nand LoRA action planner (LAP). Initially, LGP extracts the goal-oriented plan\nfrom REVERIE instructions, including the target object and room. Then, LAP\ngenerates a single-step instruction with the goal-oriented plan, high-level\ninstruction, and current visual observation as input. PEAP-LLM enables the\nembodied agent to interact with LAP as the path planner on the fly. A simple\ndirect application of LLMs hardly achieves good performance. Also, existing\nhard-prompt-based methods are error-prone in complicated scenarios and need\nhuman intervention. To address these issues and prevent the LLM from generating\nhallucinations and biased information, we propose a novel two-stage method for\nfine-tuning the LLM, consisting of supervised fine-tuning (STF) and direct\npreference optimization (DPO). SFT improves the quality of generated\ninstructions, while DPO utilizes environmental feedback. Experimental results\nshow the superiority of our proposed model on REVERIE compared to the previous\nstate-of-the-art.", "published": "2025-05-12 12:38:20", "link": "http://arxiv.org/abs/2505.07500v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DocVXQA: Context-Aware Visual Explanations for Document Question Answering", "abstract": "We propose DocVXQA, a novel framework for visually self-explainable document\nquestion answering. The framework is designed not only to produce accurate\nanswers to questions but also to learn visual heatmaps that highlight\ncontextually critical regions, thereby offering interpretable justifications\nfor the model's decisions. To integrate explanations into the learning process,\nwe quantitatively formulate explainability principles as explicit learning\nobjectives. Unlike conventional methods that emphasize only the regions\npertinent to the answer, our framework delivers explanations that are\n\\textit{contextually sufficient} while remaining\n\\textit{representation-efficient}. This fosters user trust while achieving a\nbalance between predictive performance and interpretability in DocVQA\napplications. Extensive experiments, including human evaluation, provide strong\nevidence supporting the effectiveness of our method. The code is available at\nhttps://github.com/dali92002/DocVXQA.", "published": "2025-05-12 12:30:16", "link": "http://arxiv.org/abs/2505.07496v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Addressing degeneracies in latent interpolation for diffusion models", "abstract": "There is an increasing interest in using image-generating diffusion models\nfor deep data augmentation and image morphing. In this context, it is useful to\ninterpolate between latents produced by inverting a set of input images, in\norder to generate new images representing some mixture of the inputs. We\nobserve that such interpolation can easily lead to degenerate results when the\nnumber of inputs is large. We analyze the cause of this effect theoretically\nand experimentally, and suggest a suitable remedy. The suggested approach is a\nrelatively simple normalization scheme that is easy to use whenever\ninterpolation between latents is needed. We measure image quality using FID and\nCLIP embedding distance and show experimentally that baseline interpolation\nmethods lead to a drop in quality metrics long before the degeneration issue is\nclearly visible. In contrast, our method significantly reduces the degeneration\neffect and leads to improved quality metrics also in non-degenerate situations.", "published": "2025-05-12 12:12:57", "link": "http://arxiv.org/abs/2505.07481v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "You Only Look One Step: Accelerating Backpropagation in Diffusion Sampling with Gradient Shortcuts", "abstract": "Diffusion models (DMs) have recently demonstrated remarkable success in\nmodeling large-scale data distributions. However, many downstream tasks require\nguiding the generated content based on specific differentiable metrics,\ntypically necessitating backpropagation during the generation process. This\napproach is computationally expensive, as generating with DMs often demands\ntens to hundreds of recursive network calls, resulting in high memory usage and\nsignificant time consumption. In this paper, we propose a more efficient\nalternative that approaches the problem from the perspective of parallel\ndenoising. We show that full backpropagation throughout the entire generation\nprocess is unnecessary. The downstream metrics can be optimized by retaining\nthe computational graph of only one step during generation, thus providing a\nshortcut for gradient propagation. The resulting method, which we call Shortcut\nDiffusion Optimization (SDO), is generic, high-performance, and computationally\nlightweight, capable of optimizing all parameter types in diffusion sampling.\nWe demonstrate the effectiveness of SDO on several real-world tasks, including\ncontrolling generation by optimizing latent and aligning the DMs by fine-tuning\nnetwork parameters. Compared to full backpropagation, our approach reduces\ncomputational costs by $\\sim 90\\%$ while maintaining superior performance. Code\nis available at https://github.com/deng-ai-lab/SDO.", "published": "2025-05-12 12:09:11", "link": "http://arxiv.org/abs/2505.07477v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model", "abstract": "In ophthalmic surgery, developing an AI system capable of interpreting\nsurgical videos and predicting subsequent operations requires numerous\nophthalmic surgical videos with high-quality annotations, which are difficult\nto collect due to privacy concerns and labor consumption. Text-guided video\ngeneration (T2V) emerges as a promising solution to overcome this issue by\ngenerating ophthalmic surgical videos based on surgeon instructions. In this\npaper, we present Ophora, a pioneering model that can generate ophthalmic\nsurgical videos following natural language instructions. To construct Ophora,\nwe first propose a Comprehensive Data Curation pipeline to convert narrative\nophthalmic surgical videos into a large-scale, high-quality dataset comprising\nover 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive\nVideo-Instruction Tuning scheme to transfer rich spatial-temporal knowledge\nfrom a T2V model pre-trained on natural video-text datasets for\nprivacy-preserved ophthalmic surgical video generation based on Ophora-160K.\nExperiments on video quality evaluation via quantitative analysis and\nophthalmologist feedback demonstrate that Ophora can generate realistic and\nreliable ophthalmic surgical videos based on surgeon instructions. We also\nvalidate the capability of Ophora for empowering downstream tasks of ophthalmic\nsurgical workflow understanding. Code is available at\nhttps://github.com/mar-cry/Ophora.", "published": "2025-05-12 11:23:37", "link": "http://arxiv.org/abs/2505.07449v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Lightweight Multispectral Crop-Weed Segmentation for Precision Agriculture", "abstract": "Efficient crop-weed segmentation is critical for site-specific weed control\nin precision agriculture. Conventional CNN-based methods struggle to generalize\nand rely on RGB imagery, limiting performance under complex field conditions.\nTo address these challenges, we propose a lightweight transformer-CNN hybrid.\nIt processes RGB, Near-Infrared (NIR), and Red-Edge (RE) bands using\nspecialized encoders and dynamic modality integration. Evaluated on the\nWeedsGalore dataset, the model achieves a segmentation accuracy (mean IoU) of\n78.88%, outperforming RGB-only models by 15.8 percentage points. With only 8.7\nmillion parameters, the model offers high accuracy, computational efficiency,\nand potential for real-time deployment on Unmanned Aerial Vehicles (UAVs) and\nedge devices, advancing precision weed management.", "published": "2025-05-12 11:08:42", "link": "http://arxiv.org/abs/2505.07444v1", "categories": ["cs.CV", "I.4.6"], "primary_category": "cs.CV"}
{"title": "ICE-Pruning: An Iterative Cost-Efficient Pruning Pipeline for Deep Neural Networks", "abstract": "Pruning is a widely used method for compressing Deep Neural Networks (DNNs),\nwhere less relevant parameters are removed from a DNN model to reduce its size.\nHowever, removing parameters reduces model accuracy, so pruning is typically\ncombined with fine-tuning, and sometimes other operations such as rewinding\nweights, to recover accuracy. A common approach is to repeatedly prune and then\nfine-tune, with increasing amounts of model parameters being removed in each\nstep. While straightforward to implement, pruning pipelines that follow this\napproach are computationally expensive due to the need for repeated\nfine-tuning.\n  In this paper we propose ICE-Pruning, an iterative pruning pipeline for DNNs\nthat significantly decreases the time required for pruning by reducing the\noverall cost of fine-tuning, while maintaining a similar accuracy to existing\npruning pipelines. ICE-Pruning is based on three main components: i) an\nautomatic mechanism to determine after which pruning steps fine-tuning should\nbe performed; ii) a freezing strategy for faster fine-tuning in each pruning\nstep; and iii) a custom pruning-aware learning rate scheduler to further\nimprove the accuracy of each pruning step and reduce the overall time\nconsumption. We also propose an efficient auto-tuning stage for the\nhyperparameters (e.g., freezing percentage) introduced by the three components.\nWe evaluate ICE-Pruning on several DNN models and datasets, showing that it can\naccelerate pruning by up to 9.61x. Code is available at\nhttps://github.com/gicLAB/ICE-Pruning", "published": "2025-05-12 10:07:23", "link": "http://arxiv.org/abs/2505.07411v1", "categories": ["cs.LG", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "DepthFusion: Depth-Aware Hybrid Feature Fusion for LiDAR-Camera 3D Object Detection", "abstract": "State-of-the-art LiDAR-camera 3D object detectors usually focus on feature\nfusion. However, they neglect the factor of depth while designing the fusion\nstrategy. In this work, we are the first to observe that different modalities\nplay different roles as depth varies via statistical analysis and\nvisualization. Based on this finding, we propose a Depth-Aware Hybrid Feature\nFusion (DepthFusion) strategy that guides the weights of point cloud and RGB\nimage modalities by introducing depth encoding at both global and local levels.\nSpecifically, the Depth-GFusion module adaptively adjusts the weights of image\nBird's-Eye-View (BEV) features in multi-modal global features via depth\nencoding. Furthermore, to compensate for the information lost when transferring\nraw features to the BEV space, we propose a Depth-LFusion module, which\nadaptively adjusts the weights of original voxel features and multi-view image\nfeatures in multi-modal local features via depth encoding. Extensive\nexperiments on the nuScenes and KITTI datasets demonstrate that our DepthFusion\nmethod surpasses previous state-of-the-art methods. Moreover, our DepthFusion\nis more robust to various kinds of corruptions, outperforming previous methods\non the nuScenes-C dataset.", "published": "2025-05-12 09:53:00", "link": "http://arxiv.org/abs/2505.07398v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset", "abstract": "Urban Digital Twins (UDTs) have become essential for managing cities and\nintegrating complex, heterogeneous data from diverse sources. Creating UDTs\ninvolves challenges at multiple process stages, including acquiring accurate 3D\nsource data, reconstructing high-fidelity 3D models, maintaining models'\nupdates, and ensuring seamless interoperability to downstream tasks. Current\ndatasets are usually limited to one part of the processing chain, hampering\ncomprehensive UDTs validation. To address these challenges, we introduce the\nfirst comprehensive multimodal Urban Digital Twin benchmark dataset: TUM2TWIN.\nThis dataset includes georeferenced, semantically aligned 3D models and\nnetworks along with various terrestrial, mobile, aerial, and satellite\nobservations boasting 32 data subsets over roughly 100,000 $m^2$ and currently\n767 GB of data. By ensuring georeferenced indoor-outdoor acquisition, high\naccuracy, and multimodal data integration, the benchmark supports robust\nanalysis of sensors and the development of advanced reconstruction methods.\nAdditionally, we explore downstream tasks demonstrating the potential of\nTUM2TWIN, including novel view synthesis of NeRF and Gaussian Splatting, solar\npotential analysis, point cloud semantic segmentation, and LoD3 building\nreconstruction. We are convinced this contribution lays a foundation for\novercoming current limitations in UDT creation, fostering new research\ndirections and practical solutions for smarter, data-driven urban environments.\nThe project is available under: https://tum2t.win", "published": "2025-05-12 09:48:32", "link": "http://arxiv.org/abs/2505.07396v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Feature Visualization in 3D Convolutional Neural Networks", "abstract": "Understanding the computations of convolutional neural networks requires\neffective visualization of their kernels. While maximal activation methods have\nproven successful in highlighting the preferred features of 2D convolutional\nkernels, directly applying these techniques to 3D convolutions often leads to\nuninterpretable results due to the higher dimensionality and complexity of 3D\nfeatures. To address this challenge, we propose a novel visualization approach\nfor 3D convolutional kernels that disentangles their texture and motion\npreferences. Our method begins with a data-driven decomposition of the optimal\ninput that maximally activates a given kernel. We then introduce a two-stage\noptimization strategy to extract distinct texture and motion components from\nthis input. Applying our approach to visualize kernels at various depths of\nseveral pre-trained models, we find that the resulting\nvisualizations--particularly those capturing motion--clearly reveal the\npreferred dynamic patterns encoded by 3D kernels. These results demonstrate the\neffectiveness of our method in providing interpretable insights into 3D\nconvolutional operations. Code is available at\nhttps://github.com/YatangLiLab/3DKernelVisualizer.", "published": "2025-05-12 09:31:31", "link": "http://arxiv.org/abs/2505.07387v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Apple's Synthetic Defocus Noise Pattern: Characterization and Forensic Applications", "abstract": "iPhone portrait-mode images contain a distinctive pattern in out-of-focus\nregions simulating the bokeh effect, which we term Apple's Synthetic Defocus\nNoise Pattern (SDNP). If overlooked, this pattern can interfere with blind\nforensic analyses, especially PRNU-based camera source verification, as noted\nin earlier works. Since Apple's SDNP remains underexplored, we provide a\ndetailed characterization, proposing a method for its precise estimation,\nmodeling its dependence on scene brightness, ISO settings, and other factors.\nLeveraging this characterization, we explore forensic applications of the SDNP,\nincluding traceability of portrait-mode images across iPhone models and iOS\nversions in open-set scenarios, assessing its robustness under post-processing.\nFurthermore, we show that masking SDNP-affected regions in PRNU-based camera\nsource verification significantly reduces false positives, overcoming a\ncritical limitation in camera attribution, and improving state-of-the-art\ntechniques.", "published": "2025-05-12 09:27:20", "link": "http://arxiv.org/abs/2505.07380v1", "categories": ["cs.CV", "cs.CR", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Boosting Global-Local Feature Matching via Anomaly Synthesis for Multi-Class Point Cloud Anomaly Detection", "abstract": "Point cloud anomaly detection is essential for various industrial\napplications. The huge computation and storage costs caused by the increasing\nproduct classes limit the application of single-class unsupervised methods,\nnecessitating the development of multi-class unsupervised methods. However, the\nfeature similarity between normal and anomalous points from different class\ndata leads to the feature confusion problem, which greatly hinders the\nperformance of multi-class methods. Therefore, we introduce a multi-class point\ncloud anomaly detection method, named GLFM, leveraging global-local feature\nmatching to progressively separate data that are prone to confusion across\nmultiple classes. Specifically, GLFM is structured into three stages: Stage-I\nproposes an anomaly synthesis pipeline that stretches point clouds to create\nabundant anomaly data that are utilized to adapt the point cloud feature\nextractor for better feature representation. Stage-II establishes the global\nand local memory banks according to the global and local feature distributions\nof all the training data, weakening the impact of feature confusion on the\nestablishment of the memory bank. Stage-III implements anomaly detection of\ntest data leveraging its feature distance from global and local memory banks.\nExtensive experiments on the MVTec 3D-AD, Real3D-AD and actual industry parts\ndataset showcase our proposed GLFM's superior point cloud anomaly detection\nperformance. The code is available at\nhttps://github.com/hustCYQ/GLFM-Multi-class-3DAD.", "published": "2025-05-12 09:19:25", "link": "http://arxiv.org/abs/2505.07375v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild", "abstract": "Neural implicit surface reconstruction using volume rendering techniques has\nrecently achieved significant advancements in creating high-fidelity surfaces\nfrom multiple 2D images. However, current methods primarily target scenes with\nconsistent illumination and struggle to accurately reconstruct 3D geometry in\nuncontrolled environments with transient occlusions or varying appearances.\nWhile some neural radiance field (NeRF)-based variants can better manage\nphotometric variations and transient objects in complex scenes, they are\ndesigned for novel view synthesis rather than precise surface reconstruction\ndue to limited surface constraints. To overcome this limitation, we introduce a\nnovel approach that applies multiple geometric constraints to the implicit\nsurface optimization process, enabling more accurate reconstructions from\nunconstrained image collections. First, we utilize sparse 3D points from\nstructure-from-motion (SfM) to refine the signed distance function estimation\nfor the reconstructed surface, with a displacement compensation to accommodate\nnoise in the sparse points. Additionally, we employ robust normal priors\nderived from a normal predictor, enhanced by edge prior filtering and\nmulti-view consistency constraints, to improve alignment with the actual\nsurface geometry. Extensive testing on the Heritage-Recon benchmark and other\ndatasets has shown that the proposed method can accurately reconstruct surfaces\nfrom in-the-wild images, yielding geometries with superior accuracy and\ngranularity compared to existing techniques. Our approach enables high-quality\n3D reconstruction of various landmarks, making it applicable to diverse\nscenarios such as digital preservation of cultural heritage sites.", "published": "2025-05-12 09:17:30", "link": "http://arxiv.org/abs/2505.07373v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Plane Vision Transformer for Hemorrhage Classification Using Axial and Sagittal MRI Data", "abstract": "Identifying brain hemorrhages from magnetic resonance imaging (MRI) is a\ncritical task for healthcare professionals. The diverse nature of MRI\nacquisitions with varying contrasts and orientation introduce complexity in\nidentifying hemorrhage using neural networks. For acquisitions with varying\norientations, traditional methods often involve resampling images to a fixed\nplane, which can lead to information loss. To address this, we propose a 3D\nmulti-plane vision transformer (MP-ViT) for hemorrhage classification with\nvarying orientation data. It employs two separate transformer encoders for\naxial and sagittal contrasts, using cross-attention to integrate information\nacross orientations. MP-ViT also includes a modality indication vector to\nprovide missing contrast information to the model. The effectiveness of the\nproposed model is demonstrated with extensive experiments on real world\nclinical dataset consists of 10,084 training, 1,289 validation and 1,496 test\nsubjects. MP-ViT achieved substantial improvement in area under the curve\n(AUC), outperforming the vision transformer (ViT) by 5.5% and CNN-based\narchitectures by 1.8%. These results highlight the potential of MP-ViT in\nimproving performance for hemorrhage detection when different orientation\ncontrasts are needed.", "published": "2025-05-12 08:43:43", "link": "http://arxiv.org/abs/2505.07349v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "AI-Enabled Accurate Non-Invasive Assessment of Pulmonary Hypertension Progression via Multi-Modal Echocardiography", "abstract": "Echocardiographers can detect pulmonary hypertension using Doppler\nechocardiography; however, accurately assessing its progression often proves\nchallenging. Right heart catheterization (RHC), the gold standard for precise\nevaluation, is invasive and unsuitable for routine use, limiting its\npracticality for timely diagnosis and monitoring of pulmonary hypertension\nprogression. Here, we propose MePH, a multi-view, multi-modal vision-language\nmodel to accurately assess pulmonary hypertension progression using\nnon-invasive echocardiography. We constructed a large dataset comprising paired\nstandardized echocardiogram videos, spectral images and RHC data, covering\n1,237 patient cases from 12 medical centers. For the first time, MePH precisely\nmodels the correlation between non-invasive multi-view, multi-modal\nechocardiography and the pressure and resistance obtained via RHC. We show that\nMePH significantly outperforms echocardiographers' assessments using\nechocardiography, reducing the mean absolute error in estimating mean pulmonary\narterial pressure (mPAP) and pulmonary vascular resistance (PVR) by 49.73% and\n43.81%, respectively. In eight independent external hospitals, MePH achieved a\nmean absolute error of 3.147 for PVR assessment. Furthermore, MePH achieved an\narea under the curve of 0.921, surpassing echocardiographers (area under the\ncurve of 0.842) in accurately predicting the severity of pulmonary\nhypertension, whether mild or severe. A prospective study demonstrated that\nMePH can predict treatment efficacy for patients. Our work provides pulmonary\nhypertension patients with a non-invasive and timely method for monitoring\ndisease progression, improving the accuracy and efficiency of pulmonary\nhypertension management while enabling earlier interventions and more\npersonalized treatment decisions.", "published": "2025-05-12 08:38:39", "link": "http://arxiv.org/abs/2505.07347v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Link to the Past: Temporal Propagation for Fast 3D Human Reconstruction from Monocular Video", "abstract": "Fast 3D clothed human reconstruction from monocular video remains a\nsignificant challenge in computer vision, particularly in balancing\ncomputational efficiency with reconstruction quality. Current approaches are\neither focused on static image reconstruction but too computationally\nintensive, or achieve high quality through per-video optimization that requires\nminutes to hours of processing, making them unsuitable for real-time\napplications. To this end, we present TemPoFast3D, a novel method that\nleverages temporal coherency of human appearance to reduce redundant\ncomputation while maintaining reconstruction quality. Our approach is a\n\"plug-and play\" solution that uniquely transforms pixel-aligned reconstruction\nnetworks to handle continuous video streams by maintaining and refining a\ncanonical appearance representation through efficient coordinate mapping.\nExtensive experiments demonstrate that TemPoFast3D matches or exceeds\nstate-of-the-art methods across standard metrics while providing high-quality\ntextured reconstruction across diverse pose and appearance, with a maximum\nspeed of 12 FPS.", "published": "2025-05-12 08:16:19", "link": "http://arxiv.org/abs/2505.07333v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RealRep: Generalized SDR-to-HDR Conversion with Style Disentangled Representation Learning", "abstract": "High-Dynamic-Range Wide-Color-Gamut (HDR-WCG) technology is becoming\nincreasingly prevalent, intensifying the demand for converting Standard Dynamic\nRange (SDR) content to HDR. Existing methods primarily rely on fixed tone\nmapping operators, which are inadequate for handling SDR inputs with diverse\nstyles commonly found in real-world scenarios. To address this challenge, we\npropose a generalized SDR-to-HDR method that handles diverse styles in\nreal-world SDR content, termed Realistic Style Disentangled Representation\nLearning (RealRep). By disentangling luminance and chrominance, we analyze the\nintrinsic differences between contents with varying styles and propose a\ndisentangled multi-view style representation learning method. This approach\ncaptures the guidance prior of true luminance and chrominance distributions\nacross different styles, even when the SDR style distributions exhibit\nsignificant variations, thereby establishing a robust embedding space for\ninverse tone mapping. Motivated by the difficulty of directly utilizing\ndegradation representation priors, we further introduce the Degradation-Domain\nAware Controlled Mapping Network (DDACMNet), a two-stage framework that\nperforms adaptive hierarchical mapping guided by a control-aware normalization\nmechanism. DDACMNet dynamically modulates the mapping process via\ndegradation-conditioned hierarchical features, enabling robust adaptation\nacross diverse degradation domains. Extensive experiments show that RealRep\nconsistently outperforms state-of-the-art methods with superior generalization\nand perceptually faithful HDR color gamut reconstruction.", "published": "2025-05-12 08:08:58", "link": "http://arxiv.org/abs/2505.07322v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enabling Privacy-Aware AI-Based Ergonomic Analysis", "abstract": "Musculoskeletal disorders (MSDs) are a leading cause of injury and\nproductivity loss in the manufacturing industry, incurring substantial economic\ncosts. Ergonomic assessments can mitigate these risks by identifying workplace\nadjustments that improve posture and reduce strain. Camera-based systems offer\na non-intrusive, cost-effective method for continuous ergonomic tracking, but\nthey also raise significant privacy concerns. To address this, we propose a\nprivacy-aware ergonomic assessment framework utilizing machine learning\ntechniques. Our approach employs adversarial training to develop a lightweight\nneural network that obfuscates video data, preserving only the essential\ninformation needed for human pose estimation. This obfuscation ensures\ncompatibility with standard pose estimation algorithms, maintaining high\naccuracy while protecting privacy. The obfuscated video data is transmitted to\na central server, where state-of-the-art keypoint detection algorithms extract\nbody landmarks. Using multi-view integration, 3D keypoints are reconstructed\nand evaluated with the Rapid Entire Body Assessment (REBA) method. Our system\nprovides a secure, effective solution for ergonomic monitoring in industrial\nenvironments, addressing both privacy and workplace safety concerns.", "published": "2025-05-12 07:52:48", "link": "http://arxiv.org/abs/2505.07306v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Human Motion Prediction via Test-domain-aware Adaptation with Easily-available Human Motions Estimated from Videos", "abstract": "In 3D Human Motion Prediction (HMP), conventional methods train HMP models\nwith expensive motion capture data. However, the data collection cost of such\nmotion capture data limits the data diversity, which leads to poor\ngeneralizability to unseen motions or subjects. To address this issue, this\npaper proposes to enhance HMP with additional learning using estimated poses\nfrom easily available videos. The 2D poses estimated from the monocular videos\nare carefully transformed into motion capture-style 3D motions through our\npipeline. By additional learning with the obtained motions, the HMP model is\nadapted to the test domain. The experimental results demonstrate the\nquantitative and qualitative impact of our method.", "published": "2025-05-12 07:45:57", "link": "http://arxiv.org/abs/2505.07301v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "L-SWAG: Layer-Sample Wise Activation with Gradients information for Zero-Shot NAS on Vision Transformers", "abstract": "Training-free Neural Architecture Search (NAS) efficiently identifies\nhigh-performing neural networks using zero-cost (ZC) proxies. Unlike multi-shot\nand one-shot NAS approaches, ZC-NAS is both (i) time-efficient, eliminating the\nneed for model training, and (ii) interpretable, with proxy designs often\ntheoretically grounded. Despite rapid developments in the field, current SOTA\nZC proxies are typically constrained to well-established convolutional search\nspaces. With the rise of Large Language Models shaping the future of deep\nlearning, this work extends ZC proxy applicability to Vision Transformers\n(ViTs). We present a new benchmark using the Autoformer search space evaluated\non 6 distinct tasks and propose Layer-Sample Wise Activation with Gradients\ninformation (L-SWAG), a novel, generalizable metric that characterizes both\nconvolutional and transformer architectures across 14 tasks. Additionally,\nprevious works highlighted how different proxies contain complementary\ninformation, motivating the need for a ML model to identify useful\ncombinations. To further enhance ZC-NAS, we therefore introduce LIBRA-NAS (Low\nInformation gain and Bias Re-Alignment), a method that strategically combines\nproxies to best represent a specific benchmark. Integrated into the NAS search,\nLIBRA-NAS outperforms evolution and gradient-based NAS techniques by\nidentifying an architecture with a 17.0% test error on ImageNet1k in just 0.1\nGPU days.", "published": "2025-05-12 07:44:52", "link": "http://arxiv.org/abs/2505.07300v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Skywork-VL Reward: An Effective Reward Model for Multimodal Understanding and Reasoning", "abstract": "We propose Skywork-VL Reward, a multimodal reward model that provides reward\nsignals for both multimodal understanding and reasoning tasks. Our technical\napproach comprises two key components: First, we construct a large-scale\nmultimodal preference dataset that covers a wide range of tasks and scenarios,\nwith responses collected from both standard vision-language models (VLMs) and\nadvanced VLM reasoners. Second, we design a reward model architecture based on\nQwen2.5-VL-7B-Instruct, integrating a reward head and applying multi-stage\nfine-tuning using pairwise ranking loss on pairwise preference data.\nExperimental evaluations show that Skywork-VL Reward achieves state-of-the-art\nresults on multimodal VL-RewardBench and exhibits competitive performance on\nthe text-only RewardBench benchmark. Furthermore, preference data constructed\nbased on our Skywork-VL Reward proves highly effective for training Mixed\nPreference Optimization (MPO), leading to significant improvements in\nmultimodal reasoning capabilities. Our results underscore Skywork-VL Reward as\na significant advancement toward general-purpose, reliable reward models for\nmultimodal alignment. Our model has been publicly released to promote\ntransparency and reproducibility.", "published": "2025-05-12 06:23:08", "link": "http://arxiv.org/abs/2505.07263v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Synthetic Similarity Search in Automotive Production", "abstract": "Visual quality inspection in automotive production is essential for ensuring\nthe safety and reliability of vehicles. Computer vision (CV) has become a\npopular solution for these inspections due to its cost-effectiveness and\nreliability. However, CV models require large, annotated datasets, which are\ncostly and time-consuming to collect. To reduce the need for extensive training\ndata, we propose a novel image classification pipeline that combines similarity\nsearch using a vision-based foundation model with synthetic data. Our approach\nleverages a DINOv2 model to transform input images into feature vectors, which\nare then compared to pre-classified reference images using cosine distance\nmeasurements. By utilizing synthetic data instead of real images as references,\nour pipeline achieves high classification accuracy without relying on real\ndata. We evaluate this approach in eight real-world inspection scenarios and\ndemonstrate that it meets the high performance requirements of production\nenvironments.", "published": "2025-05-12 06:10:48", "link": "http://arxiv.org/abs/2505.07256v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Towards Accurate State Estimation: Kalman Filter Incorporating Motion Dynamics for 3D Multi-Object Tracking", "abstract": "This work addresses the critical lack of precision in state estimation in the\nKalman filter for 3D multi-object tracking (MOT) and the ongoing challenge of\nselecting the appropriate motion model. Existing literature commonly relies on\nconstant motion models for estimating the states of objects, neglecting the\ncomplex motion dynamics unique to each object. Consequently, trajectory\ndivision and imprecise object localization arise, especially under occlusion\nconditions. The core of these challenges lies in the limitations of the current\nKalman filter formulation, which fails to account for the variability of motion\ndynamics as objects navigate their environments. This work introduces a novel\nformulation of the Kalman filter that incorporates motion dynamics, allowing\nthe motion model to adaptively adjust according to changes in the object's\nmovement. The proposed Kalman filter substantially improves state estimation,\nlocalization, and trajectory prediction compared to the traditional Kalman\nfilter. This is reflected in tracking performance that surpasses recent\nbenchmarks on the KITTI and Waymo Open Datasets, with margins of 0.56\\% and\n0.81\\% in higher order tracking accuracy (HOTA) and multi-object tracking\naccuracy (MOTA), respectively. Furthermore, the proposed Kalman filter\nconsistently outperforms the baseline across various detectors. Additionally,\nit shows an enhanced capability in managing long occlusions compared to the\nbaseline Kalman filter, achieving margins of 1.22\\% in higher order tracking\naccuracy (HOTA) and 1.55\\% in multi-object tracking accuracy (MOTA) on the\nKITTI dataset. The formulation's efficiency is evident, with an additional\nprocessing time of only approximately 0.078 ms per frame, ensuring its\napplicability in real-time applications.", "published": "2025-05-12 06:09:32", "link": "http://arxiv.org/abs/2505.07254v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "When Dance Video Archives Challenge Computer Vision", "abstract": "The accuracy and efficiency of human body pose estimation depend on the\nquality of the data to be processed and of the particularities of these data.\nTo demonstrate how dance videos can challenge pose estimation techniques, we\nproposed a new 3D human body pose estimation pipeline which combined up-to-date\ntechniques and methods that had not been yet used in dance analysis. Second, we\nperformed tests and extensive experimentations from dance video archives, and\nused visual analytic tools to evaluate the impact of several data parameters on\nhuman body pose. Our results are publicly available for research at\nhttps://www.couleur.org/articles/arXiv-1-2025/", "published": "2025-05-12 05:51:09", "link": "http://arxiv.org/abs/2505.07249v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Language-Driven Dual Style Mixing for Single-Domain Generalized Object Detection", "abstract": "Generalizing an object detector trained on a single domain to multiple unseen\ndomains is a challenging task. Existing methods typically introduce image or\nfeature augmentation to diversify the source domain to raise the robustness of\nthe detector. Vision-Language Model (VLM)-based augmentation techniques have\nbeen proven to be effective, but they require that the detector's backbone has\nthe same structure as the image encoder of VLM, limiting the detector framework\nselection. To address this problem, we propose Language-Driven Dual Style\nMixing (LDDS) for single-domain generalization, which diversifies the source\ndomain by fully utilizing the semantic information of the VLM. Specifically, we\nfirst construct prompts to transfer style semantics embedded in the VLM to an\nimage translation network. This facilitates the generation of style diversified\nimages with explicit semantic information. Then, we propose image-level style\nmixing between the diversified images and source domain images. This\neffectively mines the semantic information for image augmentation without\nrelying on specific augmentation selections. Finally, we propose feature-level\nstyle mixing in a double-pipeline manner, allowing feature augmentation to be\nmodel-agnostic and can work seamlessly with the mainstream detector frameworks,\nincluding the one-stage, two-stage, and transformer-based detectors. Extensive\nexperiments demonstrate the effectiveness of our approach across various\nbenchmark datasets, including real to cartoon and normal to adverse weather\ntasks. The source code and pre-trained models will be publicly available at\nhttps://github.com/qinhongda8/LDDS.", "published": "2025-05-12 04:15:27", "link": "http://arxiv.org/abs/2505.07219v1", "categories": ["cs.CV", "cs.RO", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Discovering Fine-Grained Visual-Concept Relations by Disentangled Optimal Transport Concept Bottleneck Models", "abstract": "Concept Bottleneck Models (CBMs) try to make the decision-making process\ntransparent by exploring an intermediate concept space between the input image\nand the output prediction. Existing CBMs just learn coarse-grained relations\nbetween the whole image and the concepts, less considering local image\ninformation, leading to two main drawbacks: i) they often produce spurious\nvisual-concept relations, hence decreasing model reliability; and ii) though\nCBMs could explain the importance of every concept to the final prediction, it\nis still challenging to tell which visual region produces the prediction. To\nsolve these problems, this paper proposes a Disentangled Optimal Transport CBM\n(DOT-CBM) framework to explore fine-grained visual-concept relations between\nlocal image patches and concepts. Specifically, we model the concept prediction\nprocess as a transportation problem between the patches and concepts, thereby\nachieving explicit fine-grained feature alignment. We also incorporate\northogonal projection losses within the modality to enhance local feature\ndisentanglement. To further address the shortcut issues caused by statistical\nbiases in the data, we utilize the visual saliency map and concept label\nstatistics as transportation priors. Thus, DOT-CBM can visualize inversion\nheatmaps, provide more reliable concept predictions, and produce more accurate\nclass predictions. Comprehensive experiments demonstrate that our proposed\nDOT-CBM achieves SOTA performance on several tasks, including image\nclassification, local part detection and out-of-distribution generalization.", "published": "2025-05-12 03:31:57", "link": "http://arxiv.org/abs/2505.07209v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Ranking-aware Continual Learning for LiDAR Place Recognition", "abstract": "Place recognition plays a significant role in SLAM, robot navigation, and\nautonomous driving applications. Benefiting from deep learning, the performance\nof LiDAR place recognition (LPR) has been greatly improved. However, many\nexisting learning-based LPR methods suffer from catastrophic forgetting, which\nseverely harms the performance of LPR on previously trained places after\ntraining on a new environment. In this paper, we introduce a continual learning\nframework for LPR via Knowledge Distillation and Fusion (KDF) to alleviate\nforgetting. Inspired by the ranking process of place recognition retrieval, we\npresent a ranking-aware knowledge distillation loss that encourages the network\nto preserve the high-level place recognition knowledge. We also introduce a\nknowledge fusion module to integrate the knowledge of old and new models for\nLiDAR place recognition. Our extensive experiments demonstrate that KDF can be\napplied to different networks to overcome catastrophic forgetting, surpassing\nthe state-of-the-art methods in terms of mean Recall@1 and forgetting score.", "published": "2025-05-12 03:06:29", "link": "http://arxiv.org/abs/2505.07198v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Metrics that matter: Evaluating image quality metrics for medical image generation", "abstract": "Evaluating generative models for synthetic medical imaging is crucial yet\nchallenging, especially given the high standards of fidelity, anatomical\naccuracy, and safety required for clinical applications. Standard evaluation of\ngenerated images often relies on no-reference image quality metrics when ground\ntruth images are unavailable, but their reliability in this complex domain is\nnot well established. This study comprehensively assesses commonly used\nno-reference image quality metrics using brain MRI data, including tumour and\nvascular images, providing a representative exemplar for the field. We\nsystematically evaluate metric sensitivity to a range of challenges, including\nnoise, distribution shifts, and, critically, localised morphological\nalterations designed to mimic clinically relevant inaccuracies. We then compare\nthese metric scores against model performance on a relevant downstream\nsegmentation task, analysing results across both controlled image perturbations\nand outputs from different generative model architectures. Our findings reveal\nsignificant limitations: many widely-used no-reference image quality metrics\ncorrelate poorly with downstream task suitability and exhibit a profound\ninsensitivity to localised anatomical details crucial for clinical validity.\nFurthermore, these metrics can yield misleading scores regarding distribution\nshifts, e.g. data memorisation. This reveals the risk of misjudging model\nreadiness, potentially leading to the deployment of flawed tools that could\ncompromise patient safety. We conclude that ensuring generative models are\ntruly fit for clinical purpose requires a multifaceted validation framework,\nintegrating performance on relevant downstream tasks with the cautious\ninterpretation of carefully selected no-reference image quality metrics.", "published": "2025-05-12 01:57:25", "link": "http://arxiv.org/abs/2505.07175v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Critique Before Thinking: Mitigating Hallucination through Rationale-Augmented Instruction Tuning", "abstract": "Despite significant advancements in multimodal reasoning tasks, existing\nLarge Vision-Language Models (LVLMs) are prone to producing visually ungrounded\nresponses when interpreting associated images. In contrast, when humans embark\non learning new knowledge, they often rely on a set of fundamental pre-study\nprinciples: reviewing outlines to grasp core concepts, summarizing key points\nto guide their focus and enhance understanding. However, such preparatory\nactions are notably absent in the current instruction tuning processes. This\npaper presents Re-Critic, an easily scalable rationale-augmented framework\ndesigned to incorporate fundamental rules and chain-of-thought (CoT) as a\nbridge to enhance reasoning abilities. Specifically, Re-Critic develops a\nvisual rationale synthesizer that scalably augments raw instructions with\nrationale explanation. To probe more contextually grounded responses, Re-Critic\nemploys an in-context self-critic mechanism to select response pairs for\npreference tuning. Experiments demonstrate that models fine-tuned with our\nrationale-augmented dataset yield gains that extend beyond\nhallucination-specific tasks to broader multimodal reasoning tasks.", "published": "2025-05-12 01:51:50", "link": "http://arxiv.org/abs/2505.07172v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Generalizable Pancreas Segmentation via a Dual Self-Supervised Learning Framework", "abstract": "Recently, numerous pancreas segmentation methods have achieved promising\nperformance on local single-source datasets. However, these methods don't\nadequately account for generalizability issues, and hence typically show\nlimited performance and low stability on test data from other sources.\nConsidering the limited availability of distinct data sources, we seek to\nimprove the generalization performance of a pancreas segmentation model trained\nwith a single-source dataset, i.e., the single source generalization task. In\nparticular, we propose a dual self-supervised learning model that incorporates\nboth global and local anatomical contexts. Our model aims to fully exploit the\nanatomical features of the intra-pancreatic and extra-pancreatic regions, and\nhence enhance the characterization of the high-uncertainty regions for more\nrobust generalization. Specifically, we first construct a global-feature\ncontrastive self-supervised learning module that is guided by the pancreatic\nspatial structure. This module obtains complete and consistent pancreatic\nfeatures through promoting intra-class cohesion, and also extracts more\ndiscriminative features for differentiating between pancreatic and\nnon-pancreatic tissues through maximizing inter-class separation. It mitigates\nthe influence of surrounding tissue on the segmentation outcomes in\nhigh-uncertainty regions. Subsequently, a local-image restoration\nself-supervised learning module is introduced to further enhance the\ncharacterization of the high uncertainty regions. In this module, informative\nanatomical contexts are actually learned to recover randomly corrupted\nappearance patterns in those regions.", "published": "2025-05-12 01:23:37", "link": "http://arxiv.org/abs/2505.07165v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Skull stripping with purely synthetic data", "abstract": "While many skull stripping algorithms have been developed for multi-modal and\nmulti-species cases, there is still a lack of a fundamentally generalizable\napproach. We present PUMBA(PUrely synthetic Multimodal/species invariant Brain\nextrAction), a strategy to train a model for brain extraction with no real\nbrain images or labels. Our results show that even without any real images or\nanatomical priors, the model achieves comparable accuracy in multi-modal,\nmulti-species and pathological cases. This work presents a new direction of\nresearch for any generalizable medical image segmentation task.", "published": "2025-05-12 00:36:56", "link": "http://arxiv.org/abs/2505.07159v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Isomorphisms of unit distance graphs of layers", "abstract": "For any $\\varepsilon\\in (0,+\\infty)$, consider the metric spaces $\\mathbb{R}\n\\times [0,\\varepsilon]$ in the Euclidean plane named layers or strips. B.\nBaslaugh in 1998 found the minimal width $\\varepsilon \\in (0,1)$ of a layer\nsuch that its unit distance graph contains a cycle of a given odd length $k$.\nThe first of the main results of this paper is the fact that the unit distance\ngraphs of two layers $\\mathbb{R} \\times [0,\\varepsilon_1], \\mathbb{R} \\times\n[0,\\varepsilon_2]$ are non-isomorphic for any different values\n$\\varepsilon_1,\\varepsilon_2 \\in (0,+\\infty)$. We also get a multidimensional\nanalogue of this theorem. For given $n,m \\in \\mathbb{N}, p \\in (1,+\\infty),\n\\varepsilon \\in (0,+\\infty)$, we say that the metric space on $\\mathbb{R}^n\n\\times [0,\\varepsilon]^m$ with the metric space distance generated by\n$l_p$-norm in $\\mathbb{R}^{n+m}$ is a layer $L(n,m,p,\\varepsilon)$. We show\nthat the unit distance graphs of multi-layers $L(n,m,p,\\varepsilon_1),\nL(n,m,p,\\varepsilon_2)$ are non-isomorphic for $\\varepsilon_1 \\neq\n\\varepsilon_2$.", "published": "2025-05-12 17:49:06", "link": "http://arxiv.org/abs/2505.07799v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "On core of categorical product of (di)graphs", "abstract": "The core of a graph is the smallest graph (in terms of number of vertices) to\nwhich it is homomorphically equivalent.\n  The question of the possible order of the core of the tensor product (also\nknown as categorical, Heidetnemi or direct product) of two graphs captures some\nwell known problems. For instance, the recent counterexample to the Hedetniemi\nconjecture for 5-chromatic graphs is equivalent to saying that there are cores\nof order at least 5 whose product has a core of order 4.\n  In this work, motivated by a question from Leonid Libkin in the area of graph\ndatabases, we first present methods of building cores whose categorical product\nis also a core. Extending on this we present sufficient conditions for a set of\ncores to have a product which is also a core. Presenting an example of such a\nfamily of digraphs, we construct a family of $\\binom{2n}{n}$ digraphs, where\nthe number of vertices of each is between $n^2+5n+2$ and $3n^2+3n+2$ and the\nproduct is a core. We then present a method of transforming the example into a\nfamily of graphs.", "published": "2025-05-12 11:52:24", "link": "http://arxiv.org/abs/2505.07463v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Efficient Lifting of Discrete Logarithms Modulo Prime Powers", "abstract": "We present a deterministic algorithm that, given a prime $p$ and a solution\n$x \\in \\mathbb Z$ to the discrete logarithm problem $a^x \\equiv b \\pmod p$ with\n$p\\nmid a$, efficiently lifts it to a solution modulo $p^k$, i.e., $a^x \\equiv\nb \\pmod {p^k}$, for any fixed $k \\geq 1$.\n  The algorithm performs $k(\\lceil \\log_2 p\\rceil +2)+O(\\log p)$\nmultiplications modulo $p^k$ in the worst case, improving upon prior lifting\nmethods by at least a factor of 8.", "published": "2025-05-12 10:52:19", "link": "http://arxiv.org/abs/2505.07434v1", "categories": ["math.NT", "cs.DM"], "primary_category": "math.NT"}
{"title": "Revisiting Sparse Matrix Coloring and Bicoloring", "abstract": "Sparse matrix coloring and bicoloring are fundamental building blocks of\nsparse automatic differentiation. Bicoloring is particularly advantageous for\nrectangular Jacobian matrices with at least one dense row and column. Indeed,\nin such cases, unidirectional row or column coloring demands a number of colors\nequal to the number of rows or columns. We introduce a new strategy for\nbicoloring that encompasses both direct and substitution-based decompression\napproaches. Our method reformulates the two variants of bicoloring as star and\nacyclic colorings of an augmented symmetric matrix. We extend the concept of\nneutral colors, previously exclusive to bicoloring, to symmetric colorings, and\nwe propose a post-processing routine that neutralizes colors to further reduce\nthe overall color count. We also present the Julia package\nSparseMatrixColorings, which includes these new bicoloring algorithms alongside\nall standard coloring methods for sparse derivative matrix computation.\nCompared to ColPack, the Julia package also offers enhanced implementations for\nstar and acyclic coloring, vertex ordering, as well as decompression.", "published": "2025-05-12 07:54:06", "link": "http://arxiv.org/abs/2505.07308v1", "categories": ["math.NA", "cs.DM", "cs.MS", "cs.NA", "math.CO", "05C15 (Primary), 65F50, 65D25, 68R10, 90C06 (Secondary)"], "primary_category": "math.NA"}
{"title": "Reflexive Composition of Elementary State Machines, with an Application to the Reversal of Cellular Automata Rule 90", "abstract": "We explore the dynamics of a one-dimensional lattice of state machines on two\nstates and two symbols sequentially updated via a process of \"reflexive\ncomposition.\" The space of 256 machines exhibits a variety of behavior,\nincluding substitution, reversible \"billiard ball\" dynamics, and fractal\nnesting. We show that one machine generates the Sierpinski Triangle and, for a\nsubset of boundary conditions, is isomorphic to cellular automata Rule 90 in\nWolfram's naming scheme. More surprisingly, two other machines follow\ntrajectories that map to Rule 90 in reverse. Whereas previous techniques have\nbeen developed to uncover preimages of Rule 90, this is the first study to\nproduce such inverse dynamics naturally from the formalism itself. We argue\nthat the system's symmetric treatment of state and message underlies its\nexpressive power.", "published": "2025-05-12 02:28:46", "link": "http://arxiv.org/abs/2505.07186v1", "categories": ["cs.DM", "cs.FL", "nlin.CG"], "primary_category": "cs.DM"}
{"title": "Exact Spin Elimination in Ising Hamiltonians and Energy-Based Machine Learning", "abstract": "We present an exact spin-elimination technique that reduces the\ndimensionality of both quadratic and k-local Ising Hamiltonians while\npreserving their original ground-state configurations. By systematically\nreplacing each removed spin with an effective interaction among its neighbors,\nour method lowers the total spin count without invoking approximations or\niterative recalculations. This capability is especially beneficial for\nhardware-constrained platforms, classical or quantum, that can directly\nimplement multi-body interactions but have limited qubit or spin resources. We\ndemonstrate three key advances enabled by this technique. First, we handle\nlarger instances of benchmark problems such as Max-Cut on cubic graphs without\nexceeding a 2-local interaction limit. Second, we reduce qubit requirements in\nQAOA-based integer factorization on near-term quantum devices, thus extending\nthe feasible range of integers to be factorized. Third, we improve memory\ncapacity in Hopfield associative memories and enhance memory retrieval by\nsuppressing spurious attractors, enhancing retrieval performance. Our\nspin-elimination procedure trades local spin complexity for higher-order\ncouplings or higher node degrees in a single pass, opening new avenues for\nscaling up combinatorial optimization and energy-based machine learning on\nnear-term hardware. Finally, these results underscore that the next-generation\nphysical spin machines will likely capitalize on k-local spin Hamiltonians to\noffer an alternative to classical computations.", "published": "2025-05-12 01:04:24", "link": "http://arxiv.org/abs/2505.07163v1", "categories": ["quant-ph", "cs.DM", "cs.DS", "cs.ET", "cs.LG"], "primary_category": "quant-ph"}
{"title": "Reproducibility, Replicability, and Insights into Visual Document Retrieval with Late Interaction", "abstract": "Visual Document Retrieval (VDR) is an emerging research area that focuses on\nencoding and retrieving document images directly, bypassing the dependence on\nOptical Character Recognition (OCR) for document search. A recent advance in\nVDR was introduced by ColPali, which significantly improved retrieval\neffectiveness through a late interaction mechanism. ColPali's approach\ndemonstrated substantial performance gains over existing baselines that do not\nuse late interaction on an established benchmark. In this study, we investigate\nthe reproducibility and replicability of VDR methods with and without late\ninteraction mechanisms by systematically evaluating their performance across\nmultiple pre-trained vision-language models. Our findings confirm that late\ninteraction yields considerable improvements in retrieval effectiveness;\nhowever, it also introduces computational inefficiencies during inference.\nAdditionally, we examine the adaptability of VDR models to textual inputs and\nassess their robustness across text-intensive datasets within the proposed\nbenchmark, particularly when scaling the indexing mechanism. Furthermore, our\nresearch investigates the specific contributions of late interaction by looking\ninto query-patch matching in the context of visual document retrieval. We find\nthat although query tokens cannot explicitly match image patches as in the text\nretrieval scenario, they tend to match the patch contains visually similar\ntokens or their surrounding patches.", "published": "2025-05-12 16:37:47", "link": "http://arxiv.org/abs/2505.07730v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "KAQG: A Knowledge-Graph-Enhanced RAG for Difficulty-Controlled Question Generation", "abstract": "KAQG introduces a decisive breakthrough for Retrieval-Augmented Generation\n(RAG) by explicitly tackling the two chronic weaknesses of current pipelines:\ntransparent multi-step reasoning and fine-grained cognitive difficulty control.\nThis transforms RAG from a passive retriever into an accountable generator of\ncalibrated exam items. Technically, the framework fuses knowledge graphs, RAG\nretrieval, and educational assessment theory into a single pipeline. Domain\npassages are parsed into a structured graph; graph-aware retrieval feeds fact\nchains to an LLM; and an assessment layer governed by Bloom's Taxonomy levels\nand Item Response Theory (IRT) transforms those chains into psychometrically\nsound questions. This cross-disciplinary marriage yields two scholarly\ncontributions: it shows how semantic graph contexts guide LLM reasoning paths,\nand it operationalizes difficulty metrics within the generation process,\nproducing items whose IRT parameters match expert benchmarks. Every module,\nfrom KG construction scripts to the multi-agent reasoning scheduler and the\nautomatic IRT validator, is openly released on GitHub. This enables peer\nlaboratories to replicate experiments, benchmark against baselines, and extend\nindividual components without licensing barriers. Its reproducible design paves\nthe way for rigorous ablation studies, cross-domain transfer experiments, and\nshared leaderboards on multi-step reasoning benchmarks.", "published": "2025-05-12 14:42:19", "link": "http://arxiv.org/abs/2505.07618v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "From raw affiliations to organization identifiers", "abstract": "Accurate affiliation matching, which links affiliation strings to\nstandardized organization identifiers, is critical for improving research\nmetadata quality, facilitating comprehensive bibliometric analyses, and\nsupporting data interoperability across scholarly knowledge bases. Existing\napproaches fail to handle the complexity of affiliation strings that often\ninclude mentions of multiple organizations or extraneous information. In this\npaper, we present AffRo, a novel approach designed to address these challenges,\nleveraging advanced parsing and disambiguation techniques. We also introduce\nAffRoDB, an expert-curated dataset to systematically evaluate affiliation\nmatching algorithms, ensuring robust benchmarking. Results demonstrate the\neffectiveness of AffRp in accurately identifying organizations from complex\naffiliation strings.", "published": "2025-05-12 13:57:47", "link": "http://arxiv.org/abs/2505.07577v1", "categories": ["cs.DL", "cs.IR"], "primary_category": "cs.DL"}
{"title": "Injecting Knowledge Graphs into Large Language Models", "abstract": "Integrating structured knowledge from Knowledge Graphs (KGs) into Large\nLanguage Models (LLMs) remains a key challenge for symbolic reasoning. Existing\nmethods mainly rely on prompt engineering or fine-tuning, which lose structural\nfidelity or incur high computational costs. Building on recent encoding\ntechniques which integrate graph embeddings within the LLM input as tokens, we\nextend this paradigm to the KG domain by leveraging Knowledge Graph Embedding\n(KGE) models, thus enabling graph-aware reasoning. Our approach is\nmodel-agnostic, resource-efficient, and compatible with any LLMs. Extensive\nexperimentation on synthetic and real-world datasets shows that our method\nimproves reasoning performance over established baselines, further achieving\nthe best trade-off in terms of accuracy and efficiency against state-of-the-art\nLLMs.", "published": "2025-05-12 13:31:26", "link": "http://arxiv.org/abs/2505.07554v1", "categories": ["cs.LG", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Why Uncertainty Estimation Methods Fall Short in RAG: An Axiomatic Analysis", "abstract": "Large Language Models (LLMs) are valued for their strong performance across\nvarious tasks, but they also produce inaccurate or misleading outputs.\nUncertainty Estimation (UE) quantifies the model's confidence and helps users\nassess response reliability. However, existing UE methods have not been\nthoroughly examined in scenarios like Retrieval-Augmented Generation (RAG),\nwhere the input prompt includes non-parametric knowledge. This paper shows that\ncurrent UE methods cannot reliably assess correctness in the RAG setting. We\nfurther propose an axiomatic framework to identify deficiencies in existing\nmethods and guide the development of improved approaches. Our framework\nintroduces five constraints that an effective UE method should meet after\nincorporating retrieved documents into the LLM's prompt. Experimental results\nreveal that no existing UE method fully satisfies all the axioms, explaining\ntheir suboptimal performance in RAG. We further introduce a simple yet\neffective calibration function based on our framework, which not only satisfies\nmore axioms than baseline methods but also improves the correlation between\nuncertainty estimates and correctness.", "published": "2025-05-12 11:47:42", "link": "http://arxiv.org/abs/2505.07459v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Diffusion-driven SpatioTemporal Graph KANsformer for Medical Examination Recommendation", "abstract": "Recommendation systems in AI-based medical diagnostics and treatment\nconstitute a critical component of AI in healthcare. Although some studies have\nexplored this area and made notable progress, healthcare recommendation systems\nremain in their nascent stage. And these researches mainly target the treatment\nprocess such as drug or disease recommendations. In addition to the treatment\nprocess, the diagnostic process, particularly determining which medical\nexaminations are necessary to evaluate the condition, also urgently requires\nintelligent decision support. To bridge this gap, we first formalize the task\nof medical examination recommendations. Compared to traditional\nrecommendations, the medical examination recommendation involves more complex\ninteractions. This complexity arises from two folds: 1) The historical medical\nrecords for examination recommendations are heterogeneous and redundant, which\nmakes the recommendation results susceptible to noise. 2) The correlation\nbetween the medical history of patients is often irregular, making it\nchallenging to model spatiotemporal dependencies. Motivated by the above\nobservation, we propose a novel Diffusion-driven SpatioTemporal Graph\nKANsformer for Medical Examination Recommendation (DST-GKAN) with a two-stage\nlearning paradigm to solve the above challenges. In the first stage, we exploit\na task-adaptive diffusion model to distill recommendation-oriented information\nby reducing the noises in heterogeneous medical data. In the second stage, a\nspatiotemporal graph KANsformer is proposed to simultaneously model the complex\nspatial and temporal relationships. Moreover, to facilitate the medical\nexamination recommendation research, we introduce a comprehensive dataset. The\nexperimental results demonstrate the state-of-the-art performance of the\nproposed method compared to various competitive baselines.", "published": "2025-05-12 10:47:59", "link": "http://arxiv.org/abs/2505.07431v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "DARLR: Dual-Agent Offline Reinforcement Learning for Recommender Systems with Dynamic Reward", "abstract": "Model-based offline reinforcement learning (RL) has emerged as a promising\napproach for recommender systems, enabling effective policy learning by\ninteracting with frozen world models. However, the reward functions in these\nworld models, trained on sparse offline logs, often suffer from inaccuracies.\nSpecifically, existing methods face two major limitations in addressing this\nchallenge: (1) deterministic use of reward functions as static look-up tables,\nwhich propagates inaccuracies during policy learning, and (2) static\nuncertainty designs that fail to effectively capture decision risks and\nmitigate the impact of these inaccuracies. In this work, a dual-agent\nframework, DARLR, is proposed to dynamically update world models to enhance\nrecommendation policies. To achieve this, a \\textbf{\\textit{selector}} is\nintroduced to identify reference users by balancing similarity and diversity so\nthat the \\textbf{\\textit{recommender}} can aggregate information from these\nusers and iteratively refine reward estimations for dynamic reward shaping.\nFurther, the statistical features of the selected users guide the dynamic\nadaptation of an uncertainty penalty to better align with evolving\nrecommendation requirements. Extensive experiments on four benchmark datasets\ndemonstrate the superior performance of DARLR, validating its effectiveness.\nThe code is available at https://github.com/ArronDZhang/DARLR.", "published": "2025-05-12 06:18:31", "link": "http://arxiv.org/abs/2505.07257v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Generative Re-ranking Model for List-level Multi-objective Optimization at Taobao", "abstract": "E-commerce recommendation systems aim to generate ordered lists of items for\ncustomers, optimizing multiple business objectives, such as clicks, conversions\nand Gross Merchandise Volume (GMV). Traditional multi-objective optimization\nmethods like formulas or Learning-to-rank (LTR) models take effect at\nitem-level, neglecting dynamic user intent and contextual item interactions.\nList-level multi-objective optimization in the re-ranking stage can overcome\nthis limitation, but most current re-ranking models focus more on accuracy\nimprovement with context. In addition, re-ranking is faced with the challenges\nof time complexity and diversity. In light of this, we propose a novel\nend-to-end generative re-ranking model named Sequential Ordered Regression\nTransformer-Generator (SORT-Gen) for the less-studied list-level\nmulti-objective optimization problem. Specifically, SORT-Gen is divided into\ntwo parts: 1)Sequential Ordered Regression Transformer innovatively uses\nTransformer and ordered regression to accurately estimate multi-objective\nvalues for variable-length sub-lists. 2)Mask-Driven Fast Generation Algorithm\ncombines multi-objective candidate queues, efficient item selection and\ndiversity mechanism into model inference, providing a fast online list\ngeneration method. Comprehensive online experiments demonstrate that SORT-Gen\nbrings +4.13% CLCK and +8.10% GMV for Baiyibutie, a notable Mini-app of Taobao.\nCurrently, SORT-Gen has been successfully deployed in multiple scenarios of\nTaobao App, serving for a vast number of users.", "published": "2025-05-12 03:01:14", "link": "http://arxiv.org/abs/2505.07197v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Schrijver's $\\vartheta$-function is not an upper bound on the Shannon capacity of a graph: a counterexample", "abstract": "This note addresses an open question concerning a variant of the Lov\\'{a}sz\n$\\vartheta$-function, introduced by Schrijver and independently by McEliece et\nal. (1978). It provides a complete and detailed presentation of a\ncounterexample demonstrating that this variant does not universally upper bound\nthe Shannon capacity of a graph, in contrast to the Lov\\'{a}sz\n$\\vartheta$-function. The counterexample, previously introduced in Example 5.24\nof a recent paper by the author, entitled: Observations on graph invariants\nwith the Lov\\'{a}sz $\\vartheta$-function (AIMS Mathematics, vol. 9, pp.\n15385--15468, April 2024, https://doi.org/10.3934/math.2024747), is revisited\nand fully detailed here. By resolving this question, the note clarifies a\nsubtle but significant distinction between these two closely related graph\ninvariants.", "published": "2025-05-12 17:30:18", "link": "http://arxiv.org/abs/2505.07778v1", "categories": ["math.CO", "cs.IT", "math.IT"], "primary_category": "math.CO"}
{"title": "A Robust Design for BackCom Assisted Hybrid NOMA", "abstract": "Hybrid non-orthogonal multiple access (H-NOMA) is inherently an enabler of\nmassive machine type communications, a key use case for sixth-generation (6G)\nsystems. Together with backscatter communication (BackCom), it seamlessly\nintegrates with the traditional orthogonal multiple access (OMA) techniques to\nyield superior performance gains. In this paper, we study BackCom assisted\nH-NOMA uplink transmission with the aim of minimizing power with imperfect\nchannel state information (CSI), where a generalized representation for channel\nestimation error models is used. The considered power minimization problem with\naggregate data constraints is both non-convex and intractable. For the\nconsidered imperfect CSI models, we use Lagrange duality and the\nmajorization-minimization principle to produce a conservative approximation of\nthe original problem. The conservative formulation is relaxed by incorporating\nslack variables and a penalized objective. We solve the penalized tractable\napproximation using a provably convergent algorithm with polynomial complexity.\nOur results highlight that, despite being conservative, the proposed solution\nresults in a similar power consumption as for the nominal power minimization\nproblem without channel uncertainties. Additionally, robust H-NOMA is shown to\nalmost always yield more power efficiency than the OMA case. Moreover, the\nrobustness of the proposed solution is manifested by a high probability of\nfeasibility of the robust design compared to the OMA and the nominal one.", "published": "2025-05-12 17:09:59", "link": "http://arxiv.org/abs/2505.07762v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Mode Mismatch Mitigation in Gaussian-Modulated CV-QKD", "abstract": "Technical limitations in pulse shaping lead to mode mismatch, which\nsignificantly reduces the secure key rate in CV-QKD systems. To address this, a\nmachine learning approach is employed to optimize the transmitter pulse-shape,\neffectively minimizing mode mismatch and yielding substantial performance\nimprovements.", "published": "2025-05-12 16:35:01", "link": "http://arxiv.org/abs/2505.07726v1", "categories": ["cs.IT", "math.IT", "quant-ph"], "primary_category": "cs.IT"}
{"title": "The generalized trifference problem", "abstract": "We study the problem of finding the largest number $T(n, m)$ of ternary\nvectors of length $n$ such that for any three distinct vectors there are at\nleast $m$ coordinates where they pairwise differ.\n  For $m = 1$, this is the classical trifference problem which is wide open.\n  We prove upper and lower bounds on $T(n, m)$ for various ranges of the\nparameter $m$ and determine the phase transition threshold on $m=m(n)$ where\n$T(n, m)$ jumps from constant to exponential in $n$.\n  By relating the linear version of this problem to a problem on blocking sets\nin finite geometry, we give explicit constructions and probabilistic lower\nbounds.\n  We also compute the exact values of this function and its linear variation\nfor small parameters.", "published": "2025-05-12 16:14:09", "link": "http://arxiv.org/abs/2505.07706v1", "categories": ["math.CO", "cs.IT", "math.IT"], "primary_category": "math.CO"}
{"title": "Pinching-Antenna Systems (PASS) Aided Over-the-air Computation", "abstract": "Over-the-air computation (AirComp) enables fast data aggregation for edge\nintelligence applications. However the performance of AirComp can be severely\ndegraded by channel misalignments. Pinching antenna systems (PASS) have\nrecently emerged as a promising solution for physically reshaping favorable\nwireless channels to reduce misalignments and thus AirComp errors, via\nlow-cost, fully passive, and highly reconfigurable antenna deployment.\nMotivated by these benefits, we propose a novel PASS-aided AirComp system that\nintroduces new design degrees of freedom through flexible pinching antenna (PA)\nplacement. To improve performance, we consider a mean squared error (MSE)\nminimization problem by jointly optimizing the PA position, transmit power, and\ndecoding vector. To solve this highly non-convex problem, we propose an\nalternating optimization based framework with Gauss-Seidel based PA position\nupdates. Simulation results show that our proposed joint PA position and\ncommunication design significantly outperforms various benchmark schemes in\nAirComp accuracy.", "published": "2025-05-12 13:37:51", "link": "http://arxiv.org/abs/2505.07559v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Energy-Efficient Resource Allocation for NOMA-Assisted Uplink Pinching-Antenna Systems", "abstract": "The pinching-antenna architecture has emerged as a promising solution for\nreconfiguring wireless propagation environments and enhancing system\nperformance. While prior research has primarily focused on sum-rate\nmaximization or transmit power minimization of pinching-antenna systems, the\ncritical aspect of energy efficiency (EE) has received limited attention. Given\nthe increasing importance of EE in future wireless communication networks, this\nwork investigates EE optimization in a non-orthogonal multiple access\n(NOMA)-assisted multi-user pinching-antenna uplink system. The problem entails\nthe joint optimization of the users' transmit power and the pinching-antenna\nposition. The resulting optimization problem is non-convex due to tightly\ncoupled variables. To tackle this, we employ an alternating optimization\nframework to decompose the original problem into two subproblems: one focusing\non power allocation and the other on antenna positioning. A low-complexity\noptimal solution is derived for the power allocation subproblem, while the\npinching-antenna positioning subproblem is addressed using a particle swarm\noptimization algorithm to obtain a high-quality near-optimal solution.\nSimulation results demonstrate that the proposed scheme significantly\noutperforms both conventional-antenna configurations and orthogonal multiple\naccess-based pinching-antenna systems in terms of EE.", "published": "2025-05-12 13:31:55", "link": "http://arxiv.org/abs/2505.07555v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Compression, Regularity, Randomness and Emergent Structure: Rethinking Physical Complexity in the Data-Driven Era", "abstract": "Complexity science offers a wide range of measures for quantifying\nunpredictability, structure, and information. Yet, a systematic conceptual\norganization of these measures is still missing.\n  We present a unified framework that locates statistical, algorithmic, and\ndynamical measures along three axes (regularity, randomness, and complexity)\nand situates them in a common conceptual space. We map statistical,\nalgorithmic, and dynamical measures into this conceptual space, discussing\ntheir computational accessibility and approximability.\n  This taxonomy reveals the deep challenges posed by uncomputability and\nhighlights the emergence of modern data-driven methods (including autoencoders,\nlatent dynamical models, symbolic regression, and physics-informed neural\nnetworks) as pragmatic approximations to classical complexity ideals. Latent\nspaces emerge as operational arenas where regularity extraction, noise\nmanagement, and structured compression converge, bridging theoretical\nfoundations with practical modeling in high-dimensional systems.\n  We close by outlining implications for physics-informed AI and AI-guided\ndiscovery in complex physical systems, arguing that classical questions of\ncomplexity remain central to next-generation scientific modeling.", "published": "2025-05-12 04:30:42", "link": "http://arxiv.org/abs/2505.07222v1", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.IT", "math.IT", "physics.bio-ph", "physics.data-an"], "primary_category": "cs.LG"}
{"title": "Automatically Differentiable Model Updating (ADiMU): conventional, hybrid, and neural network material model discovery including history-dependency", "abstract": "We introduce the first Automatically Differentiable Model Updating (ADiMU)\nframework that finds any history-dependent material model from full-field\ndisplacement and global force data (global, indirect discovery) or from\nstrain-stress data (local, direct discovery). We show that ADiMU can update\nconventional (physics-based), neural network (data-driven), and hybrid material\nmodels. Moreover, this framework requires no fine-tuning of hyperparameters or\nadditional quantities beyond those inherent to the user-selected material model\narchitecture and optimizer. The robustness and versatility of ADiMU is\nextensively exemplified by updating different models spanning tens to millions\nof parameters, in both local and global discovery settings. Relying on fully\ndifferentiable code, the algorithmic implementation leverages vectorizing maps\nthat enable history-dependent automatic differentiation via efficient batched\nexecution of shared computation graphs. This contribution also aims to\nfacilitate the integration, evaluation and application of future material model\narchitectures by openly supporting the research community. Therefore, ADiMU is\nreleased as an open-source computational tool, integrated into a carefully\ndesigned and documented software named HookeAI.", "published": "2025-05-12 17:49:54", "link": "http://arxiv.org/abs/2505.07801v1", "categories": ["math.NA", "cs.LG", "cs.NA", "physics.comp-ph"], "primary_category": "math.NA"}
{"title": "A Theoretical Framework for Explaining Reinforcement Learning with Shapley Values", "abstract": "Reinforcement learning agents can achieve superhuman performance, but their\ndecisions are often difficult to interpret. This lack of transparency limits\ndeployment, especially in safety-critical settings where human trust and\naccountability are essential. In this work, we develop a theoretical framework\nfor explaining reinforcement learning through the influence of state features,\nwhich represent what the agent observes in its environment. We identify three\ncore elements of the agent-environment interaction that benefit from\nexplanation: behaviour (what the agent does), performance (what the agent\nachieves), and value estimation (what the agent expects to achieve). We treat\nstate features as players cooperating to produce each element and apply Shapley\nvalues, a principled method from cooperative game theory, to identify the\ninfluence of each feature. This approach yields a family of mathematically\ngrounded explanations with clear semantics and theoretical guarantees. We use\nillustrative examples to show how these explanations align with human intuition\nand reveal novel insights. Our framework unifies and extends prior work, making\nexplicit the assumptions behind existing approaches, and offers a principled\nfoundation for more interpretable and trustworthy reinforcement learning.", "published": "2025-05-12 17:48:28", "link": "http://arxiv.org/abs/2505.07797v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Analytic theory of dropout regularization", "abstract": "Dropout is a regularization technique widely used in training artificial\nneural networks to mitigate overfitting. It consists of dynamically\ndeactivating subsets of the network during training to promote more robust\nrepresentations. Despite its widespread adoption, dropout probabilities are\noften selected heuristically, and theoretical explanations of its success\nremain sparse. Here, we analytically study dropout in two-layer neural networks\ntrained with online stochastic gradient descent. In the high-dimensional limit,\nwe derive a set of ordinary differential equations that fully characterize the\nevolution of the network during training and capture the effects of dropout. We\nobtain a number of exact results describing the generalization error and the\noptimal dropout probability at short, intermediate, and long training times.\nOur analysis shows that dropout reduces detrimental correlations between hidden\nnodes, mitigates the impact of label noise, and that the optimal dropout\nprobability increases with the level of noise in the data. Our results are\nvalidated by extensive numerical simulations.", "published": "2025-05-12 17:45:02", "link": "http://arxiv.org/abs/2505.07792v1", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Relative Overfitting and Accept-Reject Framework", "abstract": "Currently, the scaling law of Large Language Models (LLMs) faces challenges\nand bottlenecks. This paper posits that noise effects, stemming from changes in\nthe signal-to-noise ratio under diminishing marginal returns, are the root\ncause of these issues. To control this noise, we investigated the differences\nbetween models with performance advantages and disadvantages, introducing the\nconcept of \"relative overfitting.\" Based on their complementary strengths, we\nhave proposed an application framework, Accept-Reject (AR). In Natural Language\nProcessing (NLP), we use LLMs and Small Language Models (SLMs) as the medium\nfor discussion. This framework enables SLMs to exert a universal positive\ninfluence on LLM decision outputs, rather than the intuitively expected\nnegative influence. We validated our approach using self-built models based on\nmainstream architectures and pre-trained mainstream models across multiple\ndatasets, including basic language modeling, long-context tasks, subject\nexamination, and question-answering (QA) benchmarks. The results demonstrate\nthat through our structure, compared to increasing the LLM's parameters, we can\nachieve better performance improvements with significantly lower parameter and\ncomputational costs in many scenarios. These improvements are universal,\nstable, and effective. Furthermore, we explore the potential of \"relative\noverfitting\" and the AR framework in other machine learning domains, such as\ncomputer vision (CV) and AI for science. We hope the proposed approach can help\nscale laws overcome existing bottlenecks.", "published": "2025-05-12 17:36:14", "link": "http://arxiv.org/abs/2505.07783v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering", "abstract": "We introduce MLE-Dojo, a Gym-style framework for systematically reinforcement\nlearning, evaluating, and improving autonomous large language model (LLM)\nagents in iterative machine learning engineering (MLE) workflows. Unlike\nexisting benchmarks that primarily rely on static datasets or single-attempt\nevaluations, MLE-Dojo provides an interactive environment enabling agents to\niteratively experiment, debug, and refine solutions through structured feedback\nloops. Built upon 200+ real-world Kaggle challenges, MLE-Dojo covers diverse,\nopen-ended MLE tasks carefully curated to reflect realistic engineering\nscenarios such as data processing, architecture search, hyperparameter tuning,\nand code debugging. Its fully executable environment supports comprehensive\nagent training via both supervised fine-tuning and reinforcement learning,\nfacilitating iterative experimentation, realistic data sampling, and real-time\noutcome verification. Extensive evaluations of eight frontier LLMs reveal that\nwhile current models achieve meaningful iterative improvements, they still\nexhibit significant limitations in autonomously generating long-horizon\nsolutions and efficiently resolving complex errors. Furthermore, MLE-Dojo's\nflexible and extensible architecture seamlessly integrates diverse data\nsources, tools, and evaluation protocols, uniquely enabling model-based agent\ntuning and promoting interoperability, scalability, and reproducibility. We\nopen-source our framework and benchmarks to foster community-driven innovation\ntowards next-generation MLE agents.", "published": "2025-05-12 17:35:43", "link": "http://arxiv.org/abs/2505.07782v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Synthesizing Diverse Network Flow Datasets with Scalable Dynamic Multigraph Generation", "abstract": "Obtaining real-world network datasets is often challenging because of\nprivacy, security, and computational constraints. In the absence of such\ndatasets, graph generative models become essential tools for creating synthetic\ndatasets. In this paper, we introduce a novel machine learning model for\ngenerating high-fidelity synthetic network flow datasets that are\nrepresentative of real-world networks. Our approach involves the generation of\ndynamic multigraphs using a stochastic Kronecker graph generator for structure\ngeneration and a tabular generative adversarial network for feature generation.\nWe further employ an XGBoost (eXtreme Gradient Boosting) model for graph\nalignment, ensuring accurate overlay of features onto the generated graph\nstructure. We evaluate our model using new metrics that assess both the\naccuracy and diversity of the synthetic graphs. Our results demonstrate\nimprovements in accuracy over previous large-scale graph generation methods\nwhile maintaining similar efficiency. We also explore the trade-off between\naccuracy and diversity in synthetic graph dataset creation, a topic not\nextensively covered in related works. Our contributions include the synthesis\nand evaluation of large real-world netflow datasets and the definition of new\nmetrics for evaluating synthetic graph generative models.", "published": "2025-05-12 17:26:48", "link": "http://arxiv.org/abs/2505.07777v1", "categories": ["cs.LG", "cs.NI"], "primary_category": "cs.LG"}
{"title": "Tagging fully hadronic exotic decays of the vectorlike $\\mathbf{B}$ quark using a graph neural network", "abstract": "Following up on our earlier study in [J. Bardhan et al., Machine\nlearning-enhanced search for a vectorlike singlet B quark decaying to a singlet\nscalar or pseudoscalar, Phys. Rev. D 107 (2023) 115001; arXiv:2212.02442], we\ninvestigate the LHC prospects of pair-produced vectorlike $B$ quarks decaying\nexotically to a new gauge-singlet (pseudo)scalar field $\\Phi$ and a $b$ quark.\nAfter the electroweak symmetry breaking, the $\\Phi$ decays predominantly to\n$gg/bb$ final states, leading to a fully hadronic $2b+4j$ or $6b$ signature.\nBecause of the large Standard Model background and the lack of leptonic\nhandles, it is a difficult channel to probe. To overcome the challenge, we\nemploy a hybrid deep learning model containing a graph neural network followed\nby a deep neural network. We estimate that such a state-of-the-art deep\nlearning analysis pipeline can lead to a performance comparable to that in the\nsemi-leptonic mode, taking the discovery (exclusion) reach up to about\n$M_B=1.8\\:(2.4)$~TeV at HL-LHC when $B$ decays fully exotically, i.e., BR$(B\n\\to b\\Phi) = 100\\%$.", "published": "2025-05-12 17:20:34", "link": "http://arxiv.org/abs/2505.07769v1", "categories": ["hep-ph", "cs.LG", "hep-ex"], "primary_category": "hep-ph"}
{"title": "Solving Nonlinear PDEs with Sparse Radial Basis Function Networks", "abstract": "We propose a novel framework for solving nonlinear PDEs using sparse radial\nbasis function (RBF) networks. Sparsity-promoting regularization is employed to\nprevent over-parameterization and reduce redundant features. This work is\nmotivated by longstanding challenges in traditional RBF collocation methods,\nalong with the limitations of physics-informed neural networks (PINNs) and\nGaussian process (GP) approaches, aiming to blend their respective strengths in\na unified framework. The theoretical foundation of our approach lies in the\nfunction space of Reproducing Kernel Banach Spaces (RKBS) induced by\none-hidden-layer neural networks of possibly infinite width. We prove a\nrepresenter theorem showing that the solution to the sparse optimization\nproblem in the RKBS admits a finite solution and establishes error bounds that\noffer a foundation for generalizing classical numerical analysis. The\nalgorithmic framework is based on a three-phase algorithm to maintain\ncomputational efficiency through adaptive feature selection, second-order\noptimization, and pruning of inactive neurons. Numerical experiments\ndemonstrate the effectiveness of our method and highlight cases where it offers\nnotable advantages over GP approaches. This work opens new directions for\nadaptive PDE solvers grounded in rigorous analysis with efficient,\nlearning-inspired implementation.", "published": "2025-05-12 17:12:53", "link": "http://arxiv.org/abs/2505.07765v1", "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "math.NA"}
{"title": "The Pitfalls of Benchmarking in Algorithm Selection: What We Are Getting Wrong", "abstract": "Algorithm selection, aiming to identify the best algorithm for a given\nproblem, plays a pivotal role in continuous black-box optimization. A common\napproach involves representing optimization functions using a set of features,\nwhich are then used to train a machine learning meta-model for selecting\nsuitable algorithms. Various approaches have demonstrated the effectiveness of\nthese algorithm selection meta-models. However, not all evaluation approaches\nare equally valid for assessing the performance of meta-models. We highlight\nmethodological issues that frequently occur in the community and should be\naddressed when evaluating algorithm selection approaches. First, we identify\nflaws with the \"leave-instance-out\" evaluation technique. We show that\nnon-informative features and meta-models can achieve high accuracy, which\nshould not be the case with a well-designed evaluation framework. Second, we\ndemonstrate that measuring the performance of optimization algorithms with\nmetrics sensitive to the scale of the objective function requires careful\nconsideration of how this impacts the construction of the meta-model, its\npredictions, and the model's error. Such metrics can falsely present overly\noptimistic performance assessments of the meta-models. This paper emphasizes\nthe importance of careful evaluation, as loosely defined methodologies can\nmislead researchers, divert efforts, and introduce noise into the field", "published": "2025-05-12 16:57:45", "link": "http://arxiv.org/abs/2505.07750v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Assessing the Chemical Intelligence of Large Language Models", "abstract": "Large Language Models are versatile, general-purpose tools with a wide range\nof applications. Recently, the advent of \"reasoning models\" has led to\nsubstantial improvements in their abilities in advanced problem-solving domains\nsuch as mathematics and software engineering. In this work, we assessed the\nability of reasoning models to directly perform chemistry tasks, without any\nassistance from external tools. We created a novel benchmark, called ChemIQ,\nwhich consists of 796 questions assessing core concepts in organic chemistry,\nfocused on molecular comprehension and chemical reasoning. Unlike previous\nbenchmarks, which primarily use multiple choice formats, our approach requires\nmodels to construct short-answer responses, more closely reflecting real-world\napplications. The reasoning models, exemplified by OpenAI's o3-mini, correctly\nanswered 28%-59% of questions depending on the reasoning level used, with\nhigher reasoning levels significantly increasing performance on all tasks.\nThese models substantially outperformed the non-reasoning model, GPT-4o, which\nachieved only 7% accuracy. We found that Large Language Models can now convert\nSMILES strings to IUPAC names, a task earlier models were unable to perform.\nAdditionally, we show that the latest reasoning models can elucidate structures\nfrom 1H and 13C NMR data, correctly generating SMILES strings for 74% of\nmolecules containing up to 10 heavy atoms, and in one case solving a structure\ncomprising 21 heavy atoms. For each task, we found evidence that the reasoning\nprocess mirrors that of a human chemist. Our results demonstrate that the\nlatest reasoning models have the ability to perform advanced chemical\nreasoning.", "published": "2025-05-12 16:44:38", "link": "http://arxiv.org/abs/2505.07735v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Training neural control variates using correlated configurations", "abstract": "Neural control variates (NCVs) have emerged as a powerful tool for variance\nreduction in Monte Carlo (MC) simulations, particularly in high-dimensional\nproblems where traditional control variates are difficult to construct\nanalytically. By training neural networks to learn auxiliary functions\ncorrelated with the target observable, NCVs can significantly reduce estimator\nvariance while preserving unbiasedness. However, a critical but often\noverlooked aspect of NCV training is the role of autocorrelated samples\ngenerated by Markov Chain Monte Carlo (MCMC). While such samples are typically\ndiscarded for error estimation due to their statistical redundancy, they may\ncontain useful information about the structure of the underlying probability\ndistribution that can benefit the training process. In this work, we\nsystematically examine the effect of using correlated configurations in\ntraining neural control variates. We demonstrate, both conceptually and\nnumerically, that training on correlated data can improve control variate\nperformance, especially in settings with limited computational resources. Our\nanalysis includes empirical results from $U(1)$ gauge theory and scalar field\ntheory, illustrating when and how autocorrelated samples enhance NCV\nconstruction. These findings provide practical guidance for the efficient use\nof MCMC data in training neural networks.", "published": "2025-05-12 16:25:00", "link": "http://arxiv.org/abs/2505.07719v1", "categories": ["hep-lat", "cs.LG", "nucl-th"], "primary_category": "hep-lat"}
{"title": "SmartUT: Receive Beamforming for Spectral Coexistence of NGSO Satellite Systems", "abstract": "In this paper, we investigate downlink co-frequency interference (CFI)\nmitigation in non-geostationary satellites orbits (NGSOs) co-existing systems.\nTraditional mitigation techniques, such as Zero-forcing (ZF), produce a null\ntowards the direction of arrivals (DOAs) of the interfering signals, but they\nsuffer from high computational complexity due to matrix inversions and required\nknowledge of the channel state information (CSI). Furthermore, adaptive\nbeamformers, such as sample matrix inversion (SMI)-based minimum variance,\nprovide poor performance when the available snapshots are limited. We propose a\nMamba-based beamformer (MambaBF) that leverages an unsupervised deep learning\n(DL) approach and can be deployed on the user terminal (UT) antenna array, for\nassisting downlink beamforming and CFI mitigation using only a limited number\nof available array snapshots as input, and without CSI knowledge. Simulation\nresults demonstrate that MambaBF consistently outperforms conventional\nbeamforming techniques in mitigating interference and maximizing the\nsignal-to-interference-plus-noise ratio (SINR), particularly under challenging\nconditions characterized by low SINR, limited snapshots, and imperfect CSI.", "published": "2025-05-12 16:19:06", "link": "http://arxiv.org/abs/2505.07714v1", "categories": ["eess.SP", "cs.ET", "cs.LG"], "primary_category": "eess.SP"}
{"title": "ISAC: An Invertible and Stable Auditory Filter Bank with Customizable Kernels for ML Integration", "abstract": "This paper introduces ISAC, an invertible and stable, perceptually-motivated\nfilter bank that is specifically designed to be integrated into machine\nlearning paradigms. More precisely, the center frequencies and bandwidths of\nthe filters are chosen to follow a non-linear, auditory frequency scale, the\nfilter kernels have user-defined maximum temporal support and may serve as\nlearnable convolutional kernels, and there exists a corresponding filter bank\nsuch that both form a perfect reconstruction pair. ISAC provides a powerful and\nuser-friendly audio front-end suitable for any application, including\nanalysis-synthesis schemes.", "published": "2025-05-12 16:15:59", "link": "http://arxiv.org/abs/2505.07709v1", "categories": ["cs.SD", "cs.LG"], "primary_category": "cs.SD"}
{"title": "4TaStiC: Time and trend traveling time series clustering for classifying long-term type 2 diabetes patients", "abstract": "Diabetes is one of the most prevalent diseases worldwide, characterized by\npersistently high blood sugar levels, capable of damaging various internal\norgans and systems. Diabetes patients require routine check-ups, resulting in a\ntime series of laboratory records, such as hemoglobin A1c, which reflects each\npatient's health behavior over time and informs their doctor's recommendations.\nClustering patients into groups based on their entire time series data assists\ndoctors in making recommendations and choosing treatments without the need to\nreview all records. However, time series clustering of this type of dataset\nintroduces some challenges; patients visit their doctors at different time\npoints, making it difficult to capture and match trends, peaks, and patterns.\nAdditionally, two aspects must be considered: differences in the levels of\nlaboratory results and differences in trends and patterns. To address these\nchallenges, we introduce a new clustering algorithm called Time and Trend\nTraveling Time Series Clustering (4TaStiC), using a base dissimilarity measure\ncombined with Euclidean and Pearson correlation metrics. We evaluated this\nalgorithm on artificial datasets, comparing its performance with that of seven\nexisting methods. The results show that 4TaStiC outperformed the other methods\non the targeted datasets. Finally, we applied 4TaStiC to cluster a cohort of\n1,989 type 2 diabetes patients at Siriraj Hospital. Each group of patients\nexhibits clear characteristics that will benefit doctors in making efficient\nclinical decisions. Furthermore, the proposed algorithm can be applied to\ncontexts outside the medical field.", "published": "2025-05-12 16:10:32", "link": "http://arxiv.org/abs/2505.07702v1", "categories": ["cs.LG", "cs.CY", "62H30 (Primary) 62M10, 92C50 (Secondary)"], "primary_category": "cs.LG"}
{"title": "Heterogeneous Data Game: Characterizing the Model Competition Across Multiple Data Sources", "abstract": "Data heterogeneity across multiple sources is common in real-world machine\nlearning (ML) settings. Although many methods focus on enabling a single model\nto handle diverse data, real-world markets often comprise multiple competing ML\nproviders. In this paper, we propose a game-theoretic framework -- the\nHeterogeneous Data Game -- to analyze how such providers compete across\nheterogeneous data sources. We investigate the resulting pure Nash equilibria\n(PNE), showing that they can be non-existent, homogeneous (all providers\nconverge on the same model), or heterogeneous (providers specialize in distinct\ndata sources). Our analysis spans monopolistic, duopolistic, and more general\nmarkets, illustrating how factors such as the \"temperature\" of data-source\nchoice models and the dominance of certain data sources shape equilibrium\noutcomes. We offer theoretical insights into both homogeneous and heterogeneous\nPNEs, guiding regulatory policies and practical strategies for competitive ML\nmarketplaces.", "published": "2025-05-12 15:51:31", "link": "http://arxiv.org/abs/2505.07688v1", "categories": ["cs.GT", "cs.LG"], "primary_category": "cs.GT"}
{"title": "SpecRouter: Adaptive Routing for Multi-Level Speculative Decoding in Large Language Models", "abstract": "Large Language Models (LLMs) present a critical trade-off between inference\nquality and computational cost: larger models offer superior capabilities but\nincur significant latency, while smaller models are faster but less powerful.\nExisting serving strategies often employ fixed model scales or static two-stage\nspeculative decoding, failing to dynamically adapt to the varying complexities\nof user requests or fluctuations in system performance. This paper introduces\n\\systemname{}, a novel framework that reimagines LLM inference as an adaptive\nrouting problem solved through multi-level speculative decoding. \\systemname{}\ndynamically constructs and optimizes inference \"paths\" (chains of models) based\non real-time feedback, addressing the limitations of static approaches. Our\ncontributions are threefold: (1) An \\textbf{adaptive model chain scheduling}\nmechanism that leverages performance profiling (execution times) and predictive\nsimilarity metrics (derived from token distribution divergence) to continuously\nselect the optimal sequence of draft and verifier models, minimizing predicted\nlatency per generated token. (2) A \\textbf{multi-level collaborative\nverification} framework where intermediate models within the selected chain can\nvalidate speculative tokens, reducing the verification burden on the final,\nmost powerful target model. (3) A \\textbf{synchronized state management} system\nproviding efficient, consistent KV cache handling across heterogeneous models\nin the chain, including precise, low-overhead rollbacks tailored for\nasynchronous batch processing inherent in multi-level speculation. Preliminary\nexperiments demonstrate the validity of our method.", "published": "2025-05-12 15:46:28", "link": "http://arxiv.org/abs/2505.07680v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Transfer Learning Across Fixed-Income Product Classes", "abstract": "We propose a framework for transfer learning of discount curves across\ndifferent fixed-income product classes. Motivated by challenges in estimating\ndiscount curves from sparse or noisy data, we extend kernel ridge regression\n(KR) to a vector-valued setting, formulating a convex optimization problem in a\nvector-valued reproducing kernel Hilbert space (RKHS). Each component of the\nsolution corresponds to the discount curve implied by a specific product class.\nWe introduce an additional regularization term motivated by economic\nprinciples, promoting smoothness of spread curves between product classes, and\nshow that it leads to a valid separable kernel structure. A main theoretical\ncontribution is a decomposition of the vector-valued RKHS norm induced by\nseparable kernels. We further provide a Gaussian process interpretation of\nvector-valued KR, enabling quantification of estimation uncertainty.\nIllustrative examples demonstrate that transfer learning significantly improves\nextrapolation performance and tightens confidence intervals compared to\nsingle-curve estimation.", "published": "2025-05-12 15:43:29", "link": "http://arxiv.org/abs/2505.07676v1", "categories": ["stat.ML", "cs.LG", "q-fin.CP", "q-fin.MF"], "primary_category": "stat.ML"}
{"title": "Joint Graph Convolution and Sequential Modeling for Scalable Network Traffic Estimation", "abstract": "This study focuses on the challenge of predicting network traffic within\ncomplex topological environments. It introduces a spatiotemporal modeling\napproach that integrates Graph Convolutional Networks (GCN) with Gated\nRecurrent Units (GRU). The GCN component captures spatial dependencies among\nnetwork nodes, while the GRU component models the temporal evolution of traffic\ndata. This combination allows for precise forecasting of future traffic\npatterns. The effectiveness of the proposed model is validated through\ncomprehensive experiments on the real-world Abilene network traffic dataset.\nThe model is benchmarked against several popular deep learning methods.\nFurthermore, a set of ablation experiments is conducted to examine the\ninfluence of various components on performance, including changes in the number\nof graph convolution layers, different temporal modeling strategies, and\nmethods for constructing the adjacency matrix. Results indicate that the\nproposed approach achieves superior performance across multiple metrics,\ndemonstrating robust stability and strong generalization capabilities in\ncomplex network traffic forecasting scenarios.", "published": "2025-05-12 15:38:19", "link": "http://arxiv.org/abs/2505.07674v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Convergence of Time-Averaged Mean Field Gradient Descent Dynamics for Continuous Multi-Player Zero-Sum Games", "abstract": "The approximation of mixed Nash equilibria (MNE) for zero-sum games with\nmean-field interacting players has recently raised much interest in machine\nlearning. In this paper we propose a mean-field gradient descent dynamics for\nfinding the MNE of zero-sum games involving $K$ players with $K\\geq 2$. The\nevolution of the players' strategy distributions follows coupled mean-field\ngradient descent flows with momentum, incorporating an exponentially discounted\ntime-averaging of gradients. First, in the case of a fixed entropic\nregularization, we prove an exponential convergence rate for the mean-field\ndynamics to the mixed Nash equilibrium with respect to the total variation\nmetric. This improves a previous polynomial convergence rate for a similar\ntime-averaged dynamics with different averaging factors. Moreover, unlike\nprevious two-scale approaches for finding the MNE, our approach treats all\nplayer types on the same time scale. We also show that with a suitable choice\nof decreasing temperature, a simulated annealing version of the mean-field\ndynamics converges to an MNE of the initial unregularized problem.", "published": "2025-05-12 15:12:27", "link": "http://arxiv.org/abs/2505.07642v1", "categories": ["math.OC", "cs.LG", "math.AP", "math.PR", "stat.ML", "35Q89, 49N80, 91A16, 90C47"], "primary_category": "math.OC"}
{"title": "Certified Data Removal Under High-dimensional Settings", "abstract": "Machine unlearning focuses on the computationally efficient removal of\nspecific training data from trained models, ensuring that the influence of\nforgotten data is effectively eliminated without the need for full retraining.\nDespite advances in low-dimensional settings, where the number of parameters \\(\np \\) is much smaller than the sample size \\( n \\), extending similar\ntheoretical guarantees to high-dimensional regimes remains challenging. We\npropose an unlearning algorithm that starts from the original model parameters\nand performs a theory-guided sequence of Newton steps \\( T \\in \\{ 1,2\\}\\).\nAfter this update, carefully scaled isotropic Laplacian noise is added to the\nestimate to ensure that any (potential) residual influence of forget data is\ncompletely removed. We show that when both \\( n, p \\to \\infty \\) with a fixed\nratio \\( n/p \\), significant theoretical and computational obstacles arise due\nto the interplay between the complexity of the model and the finite\nsignal-to-noise ratio. Finally, we show that, unlike in low-dimensional\nsettings, a single Newton step is insufficient for effective unlearning in\nhigh-dimensional problems -- however, two steps are enough to achieve the\ndesired certifiebility. We provide numerical experiments to support the\ncertifiability and accuracy claims of this approach.", "published": "2025-05-12 15:11:13", "link": "http://arxiv.org/abs/2505.07640v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Generating Skyline Explanations for Graph Neural Networks", "abstract": "This paper proposes a novel approach to generate subgraph explanations for\ngraph neural networks GNNs that simultaneously optimize multiple measures for\nexplainability. Existing GNN explanation methods often compute subgraphs\n(called ``explanatory subgraphs'') that optimize a pre-defined, single\nexplainability measure, such as fidelity or conciseness. This can lead to\nbiased explanations that cannot provide a comprehensive explanation to clarify\nthe output of GNN models. We introduce skyline explanation, a GNN explanation\nparadigm that aims to identify k explanatory subgraphs by simultaneously\noptimizing multiple explainability measures. (1) We formulate skyline\nexplanation generation as a multi-objective optimization problem, and pursue\nexplanations that approximate a skyline set of explanatory subgraphs. We show\nthe hardness for skyline explanation generation. (2) We design efficient\nalgorithms with an onion-peeling approach that strategically removes edges from\nneighbors of nodes of interests, and incrementally improves explanations as it\nexplores an interpretation domain, with provable quality guarantees. (3) We\nfurther develop an algorithm to diversify explanations to provide more\ncomprehensive perspectives. Using real-world graphs, we empirically verify the\neffectiveness, efficiency, and scalability of our algorithms.", "published": "2025-05-12 15:05:46", "link": "http://arxiv.org/abs/2505.07635v1", "categories": ["cs.LG", "cs.DB"], "primary_category": "cs.LG"}
{"title": "Enhancing Federated Learning with Kolmogorov-Arnold Networks: A Comparative Study Across Diverse Aggregation Strategies", "abstract": "Multilayer Perceptron (MLP), as a simple yet powerful model, continues to be\nwidely used in classification and regression tasks. However, traditional MLPs\noften struggle to efficiently capture nonlinear relationships in load data when\ndealing with complex datasets. Kolmogorov-Arnold Networks (KAN), inspired by\nthe Kolmogorov-Arnold representation theorem, have shown promising capabilities\nin modeling complex nonlinear relationships. In this study, we explore the\nperformance of KANs within federated learning (FL) frameworks and compare them\nto traditional Multilayer Perceptrons. Our experiments, conducted across four\ndiverse datasets demonstrate that KANs consistently outperform MLPs in terms of\naccuracy, stability, and convergence efficiency. KANs exhibit remarkable\nrobustness under varying client numbers and non-IID data distributions,\nmaintaining superior performance even as client heterogeneity increases.\nNotably, KANs require fewer communication rounds to converge compared to MLPs,\nhighlighting their efficiency in FL scenarios. Additionally, we evaluate\nmultiple parameter aggregation strategies, with trimmed mean and FedProx\nemerging as the most effective for optimizing KAN performance. These findings\nestablish KANs as a robust and scalable alternative to MLPs for federated\nlearning tasks, paving the way for their application in decentralized and\nprivacy-preserving environments.", "published": "2025-05-12 14:56:27", "link": "http://arxiv.org/abs/2505.07629v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Trial and Trust: Addressing Byzantine Attacks with Comprehensive Defense Strategy", "abstract": "Recent advancements in machine learning have improved performance while also\nincreasing computational demands. While federated and distributed setups\naddress these issues, their structure is vulnerable to malicious influences. In\nthis paper, we address a specific threat, Byzantine attacks, where compromised\nclients inject adversarial updates to derail global convergence. We combine the\ntrust scores concept with trial function methodology to dynamically filter\noutliers. Our methods address the critical limitations of previous approaches,\nallowing functionality even when Byzantine nodes are in the majority. Moreover,\nour algorithms adapt to widely used scaled methods like Adam and RMSProp, as\nwell as practical scenarios, including local training and partial\nparticipation. We validate the robustness of our methods by conducting\nextensive experiments on both synthetic and real ECG data collected from\nmedical institutions. Furthermore, we provide a broad theoretical analysis of\nour algorithms and their extensions to aforementioned practical setups. The\nconvergence guarantees of our methods are comparable to those of classical\nalgorithms developed without Byzantine interference.", "published": "2025-05-12 14:36:45", "link": "http://arxiv.org/abs/2505.07614v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "TACOS: Temporally-aligned Audio CaptiOnS for Language-Audio Pretraining", "abstract": "Learning to associate audio with textual descriptions is valuable for a range\nof tasks, including pretraining, zero-shot classification, audio retrieval,\naudio captioning, and text-conditioned audio generation. Existing contrastive\nlanguage-audio pretrained models are typically trained using global, clip-level\ndescriptions, which provide only weak temporal supervision. We hypothesize that\nCLAP-like language-audio models - particularly, if they are expected to produce\nframe-level embeddings - can benefit from a stronger temporal supervision. To\nconfirm our hypothesis, we curate a novel dataset of approximately 12,000 audio\nrecordings from Freesound, each annotated with single-sentence free-text\ndescriptions linked to a specific temporal segment in an audio recording. We\nuse large language models to clean these annotations by removing references to\nnon-audible events, transcribed speech, typos, and annotator language bias. We\nfurther propose a frame-wise contrastive training strategy that learns to align\ntext descriptions with temporal regions in an audio recording and demonstrate\nthat our model has better temporal text-audio alignment abilities compared to\nmodels trained only on global captions when evaluated on the AudioSet Strong\nbenchmark. The dataset and our source code are available on Zenodo and GitHub,\nrespectively.", "published": "2025-05-12 14:30:39", "link": "http://arxiv.org/abs/2505.07609v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Multi-Objective Reinforcement Learning for Energy-Efficient Industrial Control", "abstract": "Industrial automation increasingly demands energy-efficient control\nstrategies to balance performance with environmental and cost constraints. In\nthis work, we present a multi-objective reinforcement learning (MORL) framework\nfor energy-efficient control of the Quanser Aero 2 testbed in its\none-degree-of-freedom configuration. We design a composite reward function that\nsimultaneously penalizes tracking error and electrical power consumption.\nPreliminary experiments explore the influence of varying the Energy penalty\nweight, alpha, on the trade-off between pitch tracking and energy savings. Our\nresults reveal a marked performance shift for alpha values between 0.0 and\n0.25, with non-Pareto optimal solutions emerging at lower alpha values, on both\nthe simulation and the real system. We hypothesize that these effects may be\nattributed to artifacts introduced by the adaptive behavior of the Adam\noptimizer, which could bias the learning process and favor bang-bang control\nstrategies. Future work will focus on automating alpha selection through\nGaussian Process-based Pareto front modeling and transitioning the approach\nfrom simulation to real-world deployment.", "published": "2025-05-12 14:28:42", "link": "http://arxiv.org/abs/2505.07607v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Finite-Sample-Based Reachability for Safe Control with Gaussian Process Dynamics", "abstract": "Gaussian Process (GP) regression is shown to be effective for learning\nunknown dynamics, enabling efficient and safety-aware control strategies across\ndiverse applications. However, existing GP-based model predictive control\n(GP-MPC) methods either rely on approximations, thus lacking guarantees, or are\noverly conservative, which limits their practical utility. To close this gap,\nwe present a sampling-based framework that efficiently propagates the model's\nepistemic uncertainty while avoiding conservatism. We establish a novel sample\ncomplexity result that enables the construction of a reachable set using a\nfinite number of dynamics functions sampled from the GP posterior. Building on\nthis, we design a sampling-based GP-MPC scheme that is recursively feasible and\nguarantees closed-loop safety and stability with high probability. Finally, we\nshowcase the effectiveness of our method on two numerical examples,\nhighlighting accurate reachable set over-approximation and safe closed-loop\nperformance.", "published": "2025-05-12 14:20:20", "link": "http://arxiv.org/abs/2505.07594v1", "categories": ["eess.SY", "cs.LG", "cs.SY", "math.OC"], "primary_category": "eess.SY"}
{"title": "Personalized Federated Learning under Model Dissimilarity Constraints", "abstract": "One of the defining challenges in federated learning is that of statistical\nheterogeneity among clients. We address this problem with KARULA, a regularized\nstrategy for personalized federated learning, which constrains the pairwise\nmodel dissimilarities between clients based on the difference in their\ndistributions, as measured by a surrogate for the 1-Wasserstein distance\nadapted for the federated setting. This allows the strategy to adapt to highly\ncomplex interrelations between clients, that e.g., clustered approaches fail to\ncapture. We propose an inexact projected stochastic gradient algorithm to solve\nthe constrained problem that the strategy defines, and show theoretically that\nit converges with smooth, possibly non-convex losses to a neighborhood of a\nstationary point with rate O(1/K). We demonstrate the effectiveness of KARULA\non synthetic and real federated data sets.", "published": "2025-05-12 13:54:55", "link": "http://arxiv.org/abs/2505.07575v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Kalman Filter Enhanced GRPO for Reinforcement Learning-Based Language Model Reasoning", "abstract": "Reward baseline is important for Reinforcement Learning (RL) algorithms to\nreduce variance in policy gradient estimates. Recently, for language modeling,\nGroup Relative Policy Optimization (GRPO) is proposed to compute the advantage\nfor each output by subtracting the mean reward, as the baseline, for all\noutputs in the group. However, it can lead to inaccurate advantage estimates in\nenvironments with highly noisy rewards, potentially introducing bias. In this\nwork, we propose a model, called Kalman Filter Enhanced Group Relative Policy\nOptimization (KRPO), by using lightweight Kalman filtering to dynamically\nestimate the latent reward mean and variance. This filtering technique replaces\nthe naive batch mean baseline, enabling more adaptive advantage normalization.\nOur method does not require additional learned parameters over GRPO. This\napproach offers a simple yet effective way to incorporate multiple outputs of\nGRPO into advantage estimation, improving policy optimization in settings where\nhighly dynamic reward signals are difficult to model for language models.\nThrough experiments and analyses, we show that using a more adaptive advantage\nestimation model, KRPO can improve the stability and performance of GRPO. The\ncode is available at https://github.com/billhhh/KRPO_LLMs_RL", "published": "2025-05-12 13:09:49", "link": "http://arxiv.org/abs/2505.07527v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Adaptive Latent-Space Constraints in Personalized FL", "abstract": "Federated learning (FL) has become an effective and widely used approach to\ntraining deep learning models on decentralized datasets held by distinct\nclients. FL also strengthens both security and privacy protections for training\ndata. Common challenges associated with statistical heterogeneity between\ndistributed datasets have spurred significant interest in personalized FL (pFL)\nmethods, where models combine aspects of global learning with local modeling\nspecific to each client's unique characteristics. In this work, the efficacy of\ntheoretically supported, adaptive MMD measures within the Ditto framework, a\nstate-of-the-art technique in pFL, are investigated. The use of such measures\nsignificantly improves model performance across a variety of tasks, especially\nthose with pronounced feature heterogeneity. While the Ditto algorithm is\nspecifically considered, such measures are directly applicable to a number of\nother pFL settings, and the results motivate the use of constraints tailored to\nthe various kinds of heterogeneity expected in FL systems.", "published": "2025-05-12 13:08:54", "link": "http://arxiv.org/abs/2505.07525v1", "categories": ["cs.LG", "68T07", "I.2.0; I.2.11; I.2.6"], "primary_category": "cs.LG"}
{"title": "Identifying Causal Direction via Variational Bayesian Compression", "abstract": "Telling apart the cause and effect between two random variables with purely\nobservational data is a challenging problem that finds applications in various\nscientific disciplines. A key principle utilized in this task is the\nalgorithmic Markov condition, which postulates that the joint distribution,\nwhen factorized according to the causal direction, yields a more succinct\ncodelength compared to the anti-causal direction. Previous approaches\napproximate these codelengths by relying on simple functions or Gaussian\nprocesses (GPs) with easily evaluable complexity, compromising between model\nfitness and computational complexity. To overcome these limitations, we propose\nleveraging the variational Bayesian learning of neural networks as an\ninterpretation of the codelengths. Consequently, we can enhance the model\nfitness while promoting the succinctness of the codelengths, while avoiding the\nsignificant computational complexity of the GP-based approaches. Extensive\nexperiments on both synthetic and real-world benchmarks in cause-effect\nidentification demonstrate the effectiveness of our proposed method, surpassing\nthe overall performance of related complexity-based and structural causal model\nregression-based approaches.", "published": "2025-05-12 12:40:15", "link": "http://arxiv.org/abs/2505.07503v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Linux Kernel Configurations at Scale: A Dataset for Performance and Evolution Analysis", "abstract": "Configuring the Linux kernel to meet specific requirements, such as binary\nsize, is highly challenging due to its immense complexity-with over 15,000\ninterdependent options evolving rapidly across different versions. Although\nseveral studies have explored sampling strategies and machine learning methods\nto understand and predict the impact of configuration options, the literature\nstill lacks a comprehensive and large-scale dataset encompassing multiple\nkernel versions along with detailed quantitative measurements. To bridge this\ngap, we introduce LinuxData, an accessible collection of kernel configurations\nspanning several kernel releases, specifically from versions 4.13 to 5.8. This\ndataset, gathered through automated tools and build processes, comprises over\n240,000 kernel configurations systematically labeled with compilation outcomes\nand binary sizes. By providing detailed records of configuration evolution and\ncapturing the intricate interplay among kernel options, our dataset enables\ninnovative research in feature subset selection, prediction models based on\nmachine learning, and transfer learning across kernel versions. Throughout this\npaper, we describe how the dataset has been made easily accessible via OpenML\nand illustrate how it can be leveraged using only a few lines of Python code to\nevaluate AI-based techniques, such as supervised machine learning. We\nanticipate that this dataset will significantly enhance reproducibility and\nfoster new insights into configuration-space analysis at a scale that presents\nunique opportunities and inherent challenges, thereby advancing our\nunderstanding of the Linux kernel's configurability and evolution.", "published": "2025-05-12 12:19:46", "link": "http://arxiv.org/abs/2505.07487v1", "categories": ["cs.SE", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Learning Penalty for Optimal Partitioning via Automatic Feature Extraction", "abstract": "Changepoint detection identifies significant shifts in data sequences, making\nit important in areas like finance, genetics, and healthcare. The Optimal\nPartitioning algorithms efficiently detect these changes, using a penalty\nparameter to limit the changepoints number. Determining the appropriate value\nfor this penalty can be challenging. Traditionally, this process involved\nmanually extracting statistical features, such as sequence length or variance\nto make the prediction. This study proposes a novel approach that uses\nrecurrent neural networks to learn this penalty directly from raw sequences by\nautomatically extracting features. Experiments conducted on 20 benchmark\ngenomic datasets show that this novel method surpasses traditional methods in\npartitioning accuracy in most cases.", "published": "2025-05-12 10:07:55", "link": "http://arxiv.org/abs/2505.07413v1", "categories": ["cs.LG", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Generalization Bounds and Stopping Rules for Learning with Self-Selected Data", "abstract": "Many learning paradigms self-select training data in light of previously\nlearned parameters. Examples include active learning, semi-supervised learning,\nbandits, or boosting. Rodemann et al. (2024) unify them under the framework of\n\"reciprocal learning\". In this article, we address the question of how well\nthese methods can generalize from their self-selected samples. In particular,\nwe prove universal generalization bounds for reciprocal learning using covering\nnumbers and Wasserstein ambiguity sets. Our results require no assumptions on\nthe distribution of self-selected data, only verifiable conditions on the\nalgorithms. We prove results for both convergent and finite iteration\nsolutions. The latter are anytime valid, thereby giving rise to stopping rules\nfor a practitioner seeking to guarantee the out-of-sample performance of their\nreciprocal learning algorithm. Finally, we illustrate our bounds and stopping\nrules for reciprocal learning's special case of semi-supervised learning.", "published": "2025-05-12 09:06:39", "link": "http://arxiv.org/abs/2505.07367v1", "categories": ["cs.LG", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "From Search To Sampling: Generative Models For Robust Algorithmic Recourse", "abstract": "Algorithmic Recourse provides recommendations to individuals who are\nadversely impacted by automated model decisions, on how to alter their profiles\nto achieve a favorable outcome. Effective recourse methods must balance three\nconflicting goals: proximity to the original profile to minimize cost,\nplausibility for realistic recourse, and validity to ensure the desired\noutcome. We show that existing methods train for these objectives separately\nand then search for recourse through a joint optimization over the recourse\ngoals during inference, leading to poor recourse recommendations. We introduce\nGenRe, a generative recourse model designed to train the three recourse\nobjectives jointly. Training such generative models is non-trivial due to lack\nof direct recourse supervision. We propose efficient ways to synthesize such\nsupervision and further show that GenRe's training leads to a consistent\nestimator. Unlike most prior methods, that employ non-robust gradient descent\nbased search during inference, GenRe simply performs a forward sampling over\nthe generative model to produce minimum cost recourse, leading to superior\nperformance across multiple metrics. We also demonstrate GenRe provides the\nbest trade-off between cost, plausibility and validity, compared to\nstate-of-art baselines. Our code is available at:\nhttps://github.com/prateekgargx/genre.", "published": "2025-05-12 08:44:28", "link": "http://arxiv.org/abs/2505.07351v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption", "abstract": "Preserving data confidentiality during the fine-tuning of open-source Large\nLanguage Models (LLMs) is crucial for sensitive applications. This work\nintroduces an interactive protocol adapting the Low-Rank Adaptation (LoRA)\ntechnique for private fine-tuning. Homomorphic Encryption (HE) protects the\nconfidentiality of training data and gradients handled by remote worker nodes\nperforming the bulk of computations involving the base model weights. The data\nowner orchestrates training, requiring minimal local computing power and\nmemory, thus alleviating the need for expensive client-side GPUs. We\ndemonstrate feasibility by fine-tuning a Llama-3.2-1B model, presenting\nconvergence results using HE-compatible quantization and performance benchmarks\nfor HE computations on GPU hardware. This approach enables applications such as\nconfidential knowledge base question answering, private codebase fine-tuning\nfor AI code assistants, AI agents for drafting emails based on a company's\nemail archive, and adapting models to analyze sensitive legal or healthcare\ndocuments.", "published": "2025-05-12 08:14:33", "link": "http://arxiv.org/abs/2505.07329v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Uncertainty Profiles for LLMs: Uncertainty Source Decomposition and Adaptive Model-Metric Selection", "abstract": "Large language models (LLMs) often generate fluent but factually incorrect\noutputs, known as hallucinations, which undermine their reliability in\nreal-world applications. While uncertainty estimation has emerged as a\npromising strategy for detecting such errors, current metrics offer limited\ninterpretability and lack clarity about the types of uncertainty they capture.\nIn this paper, we present a systematic framework for decomposing LLM\nuncertainty into four distinct sources, inspired by previous research. We\ndevelop a source-specific estimation pipeline to quantify these uncertainty\ntypes and evaluate how existing metrics relate to each source across tasks and\nmodels. Our results show that metrics, task, and model exhibit systematic\nvariation in uncertainty characteristic. Building on this, we propose a method\nfor task specific metric/model selection guided by the alignment or divergence\nbetween their uncertainty characteristics and that of a given task. Our\nexperiments across datasets and models demonstrate that our uncertainty-aware\nselection strategy consistently outperforms baseline strategies, helping us\nselect appropriate models or uncertainty metrics, and contributing to more\nreliable and efficient deployment in uncertainty estimation.", "published": "2025-05-12 07:55:22", "link": "http://arxiv.org/abs/2505.07309v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Online Episodic Convex Reinforcement Learning", "abstract": "We study online learning in episodic finite-horizon Markov decision processes\n(MDPs) with convex objective functions, known as the concave utility\nreinforcement learning (CURL) problem. This setting generalizes RL from linear\nto convex losses on the state-action distribution induced by the agent's\npolicy. The non-linearity of CURL invalidates classical Bellman equations and\nrequires new algorithmic approaches. We introduce the first algorithm achieving\nnear-optimal regret bounds for online CURL without any prior knowledge on the\ntransition function. To achieve this, we use an online mirror descent algorithm\nwith varying constraint sets and a carefully designed exploration bonus. We\nthen address for the first time a bandit version of CURL, where the only\nfeedback is the value of the objective function on the state-action\ndistribution induced by the agent's policy. We achieve a sub-linear regret\nbound for this more challenging problem by adapting techniques from bandit\nconvex optimization to the MDP setting.", "published": "2025-05-12 07:47:49", "link": "http://arxiv.org/abs/2505.07303v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning", "abstract": "We introduce INTELLECT-2, the first globally distributed reinforcement\nlearning (RL) training run of a 32 billion parameter language model. Unlike\ntraditional centralized training efforts, INTELLECT-2 trains a reasoning model\nusing fully asynchronous RL across a dynamic, heterogeneous swarm of\npermissionless compute contributors.\n  To enable a training run with this unique infrastructure, we built various\ncomponents from scratch: we introduce PRIME-RL, our training framework\npurpose-built for distributed asynchronous reinforcement learning, based on top\nof novel components such as TOPLOC, which verifies rollouts from untrusted\ninference workers, and SHARDCAST, which efficiently broadcasts policy weights\nfrom training nodes to inference workers.\n  Beyond infrastructure components, we propose modifications to the standard\nGRPO training recipe and data filtering techniques that were crucial to achieve\ntraining stability and ensure that our model successfully learned its training\nobjective, thus improving upon QwQ-32B, the state of the art reasoning model in\nthe 32B parameter range.\n  We open-source INTELLECT-2 along with all of our code and data, hoping to\nencourage and enable more open research in the field of decentralized training.", "published": "2025-05-12 07:24:33", "link": "http://arxiv.org/abs/2505.07291v1", "categories": ["cs.LG", "cs.DC"], "primary_category": "cs.LG"}
{"title": "Cache-Efficient Posterior Sampling for Reinforcement Learning with LLM-Derived Priors Across Discrete and Continuous Domains", "abstract": "Integrating large language models (LLMs) as priors in reinforcement learning\n(RL) offers significant advantages but comes with substantial computational\ncosts. We present a principled cache-efficient framework for posterior sampling\nwith LLM-derived priors that dramatically reduces these costs while maintaining\nhigh performance. At the core of our approach is an adaptive caching mechanism,\nwhere cache parameters are meta-optimized using surrogate gradients derived\nfrom policy performance. This design enables efficient inference across both\ndiscrete text environments (e.g., TextWorld, ALFWorld) and continuous control\ndomains (e.g., MuJoCo), achieving a 3.8--4.7$\\times$ reduction in LLM queries\nand 4.0--12.0$\\times$ lower median latencies (85--93\\,ms on a consumer GPU)\nwhile retaining 96--98\\% of uncached performance. Our theoretical analysis\nprovides KL divergence bounds on approximation quality, validated empirically.\nThe framework extends to offline RL, where our CQL-Prior variant improves\nperformance by 14--29\\% and reduces training time by 38--40\\%. Extensive\nevaluations across a diverse suite of eight tasks demonstrate the\ngeneralizability and practical viability of LLM-guided RL in\nresource-constrained settings.", "published": "2025-05-12 06:53:24", "link": "http://arxiv.org/abs/2505.07274v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "ALPCAH: Subspace Learning for Sample-wise Heteroscedastic Data", "abstract": "Principal component analysis (PCA) is a key tool in the field of data\ndimensionality reduction. However, some applications involve heterogeneous data\nthat vary in quality due to noise characteristics associated with each data\nsample. Heteroscedastic methods aim to deal with such mixed data quality. This\npaper develops a subspace learning method, named ALPCAH, that can estimate the\nsample-wise noise variances and use this information to improve the estimate of\nthe subspace basis associated with the low-rank structure of the data. Our\nmethod makes no distributional assumptions of the low-rank component and does\nnot assume that the noise variances are known. Further, this method uses a soft\nrank constraint that does not require subspace dimension to be known.\nAdditionally, this paper develops a matrix factorized version of ALPCAH, named\nLR-ALPCAH, that is much faster and more memory efficient at the cost of\nrequiring subspace dimension to be known or estimated. Simulations and real\ndata experiments show the effectiveness of accounting for data\nheteroscedasticity compared to existing algorithms. Code available at\nhttps://github.com/javiersc1/ALPCAH.", "published": "2025-05-12 06:49:47", "link": "http://arxiv.org/abs/2505.07272v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Adaptive, Robust and Scalable Bayesian Filtering for Online Learning", "abstract": "In this thesis, we introduce Bayesian filtering as a principled framework for\ntackling diverse sequential machine learning problems, including online\n(continual) learning, prequential (one-step-ahead) forecasting, and contextual\nbandits. To this end, this thesis addresses key challenges in applying Bayesian\nfiltering to these problems: adaptivity to non-stationary environments,\nrobustness to model misspecification and outliers, and scalability to the\nhigh-dimensional parameter space of deep neural networks. We develop novel\ntools within the Bayesian filtering framework to address each of these\nchallenges, including: (i) a modular framework that enables the development\nadaptive approaches for online learning; (ii) a novel, provably robust filter\nwith similar computational cost to standard filters, that employs Generalised\nBayes; and (iii) a set of tools for sequentially updating model parameters\nusing approximate second-order optimisation methods that exploit the\noverparametrisation of high-dimensional parametric models such as neural\nnetworks. Theoretical analysis and empirical results demonstrate the improved\nperformance of our methods in dynamic, high-dimensional, and misspecified\nmodels.", "published": "2025-05-12 06:40:29", "link": "http://arxiv.org/abs/2505.07267v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "The Influence of the Memory Capacity of Neural DDEs on the Universal Approximation Property", "abstract": "Neural Ordinary Differential Equations (Neural ODEs), which are the\ncontinuous-time analog of Residual Neural Networks (ResNets), have gained\nsignificant attention in recent years. Similarly, Neural Delay Differential\nEquations (Neural DDEs) can be interpreted as an infinite depth limit of\nDensely Connected Residual Neural Networks (DenseResNets). In contrast to\ntraditional ResNet architectures, DenseResNets are feed-forward networks that\nallow for shortcut connections across all layers. These additional connections\nintroduce memory in the network architecture, as typical in many modern\narchitectures. In this work, we explore how the memory capacity in neural DDEs\ninfluences the universal approximation property. The key parameter for studying\nthe memory capacity is the product $K \\tau$ of the Lipschitz constant and the\ndelay of the DDE. In the case of non-augmented architectures, where the network\nwidth is not larger than the input and output dimensions, neural ODEs and\nclassical feed-forward neural networks cannot have the universal approximation\nproperty. We show that if the memory capacity $K\\tau$ is sufficiently small,\nthe dynamics of the neural DDE can be approximated by a neural ODE.\nConsequently, non-augmented neural DDEs with a small memory capacity also lack\nthe universal approximation property. In contrast, if the memory capacity\n$K\\tau$ is sufficiently large, we can establish the universal approximation\nproperty of neural DDEs for continuous functions. If the neural DDE\narchitecture is augmented, we can expand the parameter regions in which\nuniversal approximation is possible. Overall, our results show that by\nincreasing the memory capacity $K\\tau$, the infinite-dimensional phase space of\nDDEs with positive delay $\\tau>0$ is not sufficient to guarantee a direct jump\ntransition to universal approximation, but only after a certain memory\nthreshold, universal approximation holds.", "published": "2025-05-12 05:36:39", "link": "http://arxiv.org/abs/2505.07244v1", "categories": ["math.DS", "cs.LG", "cs.NE"], "primary_category": "math.DS"}
{"title": "Causal View of Time Series Imputation: Some Identification Results on Missing Mechanism", "abstract": "Time series imputation is one of the most challenge problems and has broad\napplications in various fields like health care and the Internet of Things.\nExisting methods mainly aim to model the temporally latent dependencies and the\ngeneration process from the observed time series data. In real-world scenarios,\ndifferent types of missing mechanisms, like MAR (Missing At Random), and MNAR\n(Missing Not At Random) can occur in time series data. However, existing\nmethods often overlook the difference among the aforementioned missing\nmechanisms and use a single model for time series imputation, which can easily\nlead to misleading results due to mechanism mismatching. In this paper, we\npropose a framework for time series imputation problem by exploring Different\nMissing Mechanisms (DMM in short) and tailoring solutions accordingly.\nSpecifically, we first analyze the data generation processes with temporal\nlatent states and missing cause variables for different mechanisms.\nSequentially, we model these generation processes via variational inference and\nestimate prior distributions of latent variables via normalizing flow-based\nneural architecture. Furthermore, we establish identifiability results under\nthe nonlinear independent component analysis framework to show that latent\nvariables are identifiable. Experimental results show that our method surpasses\nexisting time series imputation techniques across various datasets with\ndifferent missing mechanisms, demonstrating its effectiveness in real-world\napplications.", "published": "2025-05-12 02:13:14", "link": "http://arxiv.org/abs/2505.07180v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "RAI: Flexible Agent Framework for Embodied AI", "abstract": "With an increase in the capabilities of generative language models, a growing\ninterest in embodied AI has followed. This contribution introduces RAI - a\nframework for creating embodied Multi Agent Systems for robotics. The proposed\nframework implements tools for Agents' integration with robotic stacks, Large\nLanguage Models, and simulations. It provides out-of-the-box integration with\nstate-of-the-art systems like ROS 2. It also comes with dedicated mechanisms\nfor the embodiment of Agents. These mechanisms have been tested on a physical\nrobot, Husarion ROSBot XL, which was coupled with its digital twin, for rapid\nprototyping. Furthermore, these mechanisms have been deployed in two\nsimulations: (1) robot arm manipulator and (2) tractor controller. All of these\ndeployments have been evaluated in terms of their control capabilities,\neffectiveness of embodiment, and perception ability. The proposed framework has\nbeen used successfully to build systems with multiple agents. It has\ndemonstrated effectiveness in all the aforementioned tasks. It also enabled\nidentifying and addressing the shortcomings of the generative models used for\nembodied AI.", "published": "2025-05-12 13:13:47", "link": "http://arxiv.org/abs/2505.07532v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "The Complexity of Pure Strategy Relevant Equilibria in Concurrent Games", "abstract": "We study rational synthesis problems for concurrent games with\n$\\omega$-regular objectives. Our model of rationality considers only pure\nstrategy Nash equilibria that satisfy either a social welfare or Pareto\noptimality condition with respect to an $\\omega$-regular objective for each\nagent. This extends earlier work on equilibria in concurrent games, without\nconsideration about their quality. Our results show that the existence of Nash\nequilibria satisfying social welfare conditions can be computed as efficiently\nas the constrained Nash equilibrium existence problem. On the other hand, the\nexistence of Nash equilibria satisfying the Pareto optimality condition\npossibly involves a higher upper bound, except in the case of B\\\"uchi and\nMuller games, for which all three problems are in the classes P and\nPSPACE-complete, respectively.", "published": "2025-05-12 12:38:28", "link": "http://arxiv.org/abs/2505.07501v1", "categories": ["cs.GT", "cs.FL", "cs.LO", "cs.MA"], "primary_category": "cs.GT"}
{"title": "Continuous-Time Control Synthesis for Multiple Quadrotors under Signal Temporal Logic Specifications", "abstract": "Ensuring continuous-time control of multiple quadrotors in constrained\nenvironments under signal temporal logic (STL) specifications is challenging\ndue to nonlinear dynamics, safety constraints, and disturbances. This letter\nproposes a two-stage framework to address this challenge. First, exponentially\ndecaying tracking error bounds are derived with multidimensional geometric\ncontrol gains obtained via differential evolution. These bounds are less\nconservative, while the resulting tracking errors exhibit smaller oscillations\nand improved transient performance. Second, leveraging the time-varying bounds,\na mixed-integer convex programming (MICP) formulation generates piecewise\nB\\'ezier reference trajectories that satisfy STL and velocity limits, while\nensuring inter-agent safety through convex-hull properties. Simulation results\ndemonstrate that the proposed approach enables formally verifiable multi-agent\ncoordination in constrained environments, with provable tracking guarantees\nunder bounded disturbances.", "published": "2025-05-12 05:30:08", "link": "http://arxiv.org/abs/2505.07240v1", "categories": ["eess.SY", "cs.MA", "cs.SY"], "primary_category": "eess.SY"}
{"title": "Hypergraph Coordination Networks with Dynamic Grouping for Multi-Agent Reinforcement Learning", "abstract": "Cooperative multi-agent reinforcement learning faces significant challenges\nin effectively organizing agent relationships and facilitating information\nexchange, particularly when agents need to adapt their coordination patterns\ndynamically. This paper presents a novel framework that integrates dynamic\nspectral clustering with hypergraph neural networks to enable adaptive group\nformation and efficient information processing in multi-agent systems. The\nproposed framework dynamically constructs and updates hypergraph structures\nthrough spectral clustering on agents' state histories, enabling higher-order\nrelationships to emerge naturally from agent interactions. The hypergraph\nstructure is enhanced with attention mechanisms for selective information\nprocessing, providing an expressive and efficient way to model complex agent\nrelationships. This architecture can be implemented in both value-based and\npolicy-based paradigms through a unified objective combining task performance\nwith structural regularization. Extensive experiments on challenging\ncooperative tasks demonstrate that our method significantly outperforms\nstate-of-the-art approaches in both sample efficiency and final performance.", "published": "2025-05-12 03:31:26", "link": "http://arxiv.org/abs/2505.07207v1", "categories": ["cs.MA"], "primary_category": "cs.MA"}
{"title": "On the choice of optimization norm for Anderson acceleration of the Picard iteration for Navier-Stokes equations", "abstract": "Recently developed convergence theory for Anderson acceleration (AA) assumes\nthat the AA optimization norm matches the norm of the Hilbert space that the\nfixed point function is defined on. While this seems a natural assumption, it\nmay not be the optimal choice in terms of convergence of the iteration or\ncomputational efficiency. For the Picard iteration for the Navier-Stokes\nequations (NSE), the associated Hilbert space norm is $H^1_0(\\Omega),$ which is\ninefficient to implement in a large scale HPC setting since it requires\nmultiplication of global coefficient vectors by the stiffness matrix. Motivated\nby recent numerical tests that show using the $\\ell^2$ norm produces similar\nconvergence behavior as $H^1_0$ does, we revisit the convergence theory of\n[Pollock et al, {\\it SINUM} 2019] and find that i) it can be improved with a\nsharper treatment of the nonlinear terms; and ii) in the case that the AA\noptimization norm is changed to $L^2$ (and by extension $\\ell^2$ or $L^2$ using\na diagonally lumped mass matrix), a new convergence theory is developed that\nprovides an essentially equivalent estimate as the $H^1_0$ case. Several\nnumerical tests illustrate the new theory, and the theory and tests reveal that\none can interchangeably use the norms $H^1_0$, $L^2$, $\\ell^2$ or $L^2$ with\ndiagonally lumped mass matrix for the AA optimization problem without\nsignificantly affecting the overall convergence behavior. Thus, one is\njustified to use $\\ell^2$ or diagonally lumped $L^2$ for the AA optimization\nnorm in Anderson accelerated Picard iterations for large scale NSE problems.", "published": "2025-05-12 15:21:40", "link": "http://arxiv.org/abs/2505.07650v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "An Approximation Framework for Subspace-based Methods in Spectral Analysis with Accuracy Guarantees", "abstract": "A mathematical framework for the approximation of eigenvalues of self-adjoint\noperators through subspace-based methods is presented.\n  The framework contains spectral inequalities that extend to unbounded\noperators and account for multiple error sources.\n  We include conceptual remarks, on how such framework addresses contemporary\nchallenges towards a more complete approximation theory for quantum physics.\n  Further analysis considers the computational operation of subspace-based\nmethods and proposes new numerical practices.\n  In particular, analytical guarantees on dimension detection of spectral\nsubspaces in the presence of noise are introduced.\n  The generality of the framework invites application to a broad class of\nnumerical methods, and its utility is demonstrated through recent advances in\nsignal processing.", "published": "2025-05-12 12:51:35", "link": "http://arxiv.org/abs/2505.07513v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "math.SP", "65F15, 47A70, 47A58, 00A73", "G.1.2"], "primary_category": "math.NA"}
{"title": "Trigonometric Interpolation Based Approach for Second Order ODE with Mixed Boundary Conditions", "abstract": "This paper proposes a trigonometric interpolation-based approach (TIBA) to\napproximate solutions of mixed boundary value problems of second-order ODEs.\nTIBA leverages the analytic attractiveness of a trigonometric polynomial to\nreformulate the dynamics of $y, y',y''$ implied by ODE and boundary conditions.\nTIBA is particularly attractive for a linear ODE where the solution can be\nobtained directly by solving a linear system. The framework can be used to\nsolve integro-differential equations. Numerical tests have been conducted to\nassess TIBA's performance regarding convergence, existence, and uniqueness of\nsolution under various boundary conditions with expected results.", "published": "2025-05-12 02:16:55", "link": "http://arxiv.org/abs/2505.07183v1", "categories": ["math.NA", "cs.NA", "Primary 65T40, Secondary 65T50"], "primary_category": "math.NA"}
{"title": "Field of values analysis that includes zero for preconditioned nonsymmetric saddle-point systems", "abstract": "We present a field-of-values (FOV) analysis for preconditioned nonsymmetric\nsaddle-point linear systems, where zero is included in the field of values of\nthe matrix. We rely on recent results of Crouzeix and Greenbaum [Spectral sets:\nnumerical range and beyond. SIAM Journal on Matrix Analysis and Applications,\n40(3):1087-1001, 2019], showing that a convex region with a circular hole is a\nspectral set. Sufficient conditions are derived for convergence independent of\nthe matrix dimensions. We apply our results to preconditioned nonsymmetric\nsaddle-point systems, and show their applicability to families of block\npreconditioners that have not been previously covered by existing FOV analysis.\nA limitation of our theory is that the preconditioned matrix is required to\nhave a small skew-symmetric part in norm. Consequently, our analysis may not be\napplicable, for example, to fluid flow problems characterized by a small\nviscosity coefficient. Some numerical results illustrate our findings.", "published": "2025-05-12 00:17:07", "link": "http://arxiv.org/abs/2505.07156v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "The Exploratory Multi-Asset Mean-Variance Portfolio Selection using Reinforcement Learning", "abstract": "In this paper, we study the continuous-time multi-asset mean-variance (MV)\nportfolio selection using a reinforcement learning (RL) algorithm, specifically\nthe soft actor-critic (SAC) algorithm, in the time-varying financial market. A\nfamily of Gaussian portfolio selections is derived, and a policy iteration\nprocess is crafted to learn the optimal exploratory portfolio selection. We\nprove the convergence of the policy iteration process theoretically, based on\nwhich the SAC algorithm is developed. To improve the algorithm's stability and\nthe learning accuracy in the multi-asset scenario, we divide the model\nparameters that influence the optimal portfolio selection into three parts, and\nlearn each part progressively. Numerical studies in the simulated and real\nfinancial markets confirm the superior performance of the proposed SAC\nalgorithm under various criteria.", "published": "2025-05-12 13:18:49", "link": "http://arxiv.org/abs/2505.07537v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Measuring Financial Resilience Using Backward Stochastic Differential Equations", "abstract": "We propose the resilience rate as a measure of financial resilience. It\ncaptures the rate at which a dynamic risk evaluation recovers, i.e., bounces\nback, after the risk-acceptance set is breached. We develop the associated\nstochastic calculus by establishing representation theorems of a suitable\ntime-derivative of solutions to backward stochastic differential equations\n(BSDEs) with jumps, evaluated at stopping times. These results reveal that our\nresilience rate can be represented as an expectation of the generator of the\nBSDE. We also introduce resilience-acceptance sets and study their properties\nin relation to both the resilience rate and the dynamic risk measure. We\nillustrate our results in several examples.", "published": "2025-05-12 12:38:55", "link": "http://arxiv.org/abs/2505.07502v1", "categories": ["q-fin.MF", "60H10, 60H30, 91B06, 91B30, 62P05"], "primary_category": "q-fin.MF"}
{"title": "Mean Field Portfolio Games with Epstein-Zin Preferences", "abstract": "We study mean field portfolio games under Epstein-Zin preferences, which\nnaturally encompass the classical time-additive power utility as a special\ncase. In a general non-Markovian framework, we establish a uniqueness result by\nproving a one-to-one correspondence between Nash equilibria and the solutions\nto a class of BSDEs. A key ingredient in our approach is a necessary stochastic\nmaximum principle tailored to Epstein-Zin utility and a nonlinear\ntransformation. In the deterministic setting, we further derive an explicit\nclosed-form solution for the equilibrium investment and consumption policies.", "published": "2025-05-12 05:06:59", "link": "http://arxiv.org/abs/2505.07231v1", "categories": ["q-fin.MF"], "primary_category": "q-fin.MF"}
{"title": "Revisiting the Excess Volatility Puzzle Through the Lens of the Chiarella Model", "abstract": "We amend and extend the Chiarella model of financial markets to deal with\narbitrary long-term value drifts in a consistent way. This allows us to improve\nupon existing calibration schemes, opening the possibility of calibrating\nindividual monthly time series instead of classes of time series. The technique\nis employed on spot prices of four asset classes from ca. 1800 onward (stock\nindices, bonds, commodities, currencies). The so-called fundamental value is a\ndirect output of the calibration, which allows us to (a) quantify the amount of\nexcess volatility in these markets, which we find to be large (e.g. a factor\n$\\approx$ 4 for stock indices) and consistent with previous estimates; and (b)\ndetermine the distribution of mispricings (i.e. the difference between market\nprice and value), which we find in many cases to be bimodal. Both findings are\nstrongly at odds with the Efficient Market Hypothesis. We also study in detail\nthe 'sloppiness' of the calibration, that is, the directions in parameter space\nthat are weakly constrained by data. The main conclusions of our study are\nremarkably consistent across different asset classes, and reinforce the\nhypothesis that the medium-term fate of financial markets is determined by a\ntug-of-war between trend followers and fundamentalists.", "published": "2025-05-12 17:59:46", "link": "http://arxiv.org/abs/2505.07820v1", "categories": ["q-fin.TR", "econ.GN", "q-fin.EC", "q-fin.PM"], "primary_category": "q-fin.TR"}
{"title": "Nonparametric Instrumental Variable Inference with Many Weak Instruments", "abstract": "We study inference on linear functionals in the nonparametric instrumental\nvariable (NPIV) problem with a discretely-valued instrument under a\nmany-weak-instruments asymptotic regime, where the number of instrument values\ngrows with the sample size. A key motivating example is estimating long-term\ncausal effects in a new experiment with only short-term outcomes, using past\nexperiments to instrument for the effect of short- on long-term outcomes. Here,\nthe assignment to a past experiment serves as the instrument: we have many past\nexperiments but only a limited number of units in each. Since the structural\nfunction is nonparametric but constrained by only finitely many moment\nrestrictions, point identification typically fails. To address this, we\nconsider linear functionals of the minimum-norm solution to the moment\nrestrictions, which is always well-defined. As the number of instrument levels\ngrows, these functionals define an approximating sequence to a target\nfunctional, replacing point identification with a weaker asymptotic notion\nsuited to discrete instruments. Extending the Jackknife Instrumental Variable\nEstimator (JIVE) beyond the classical parametric setting, we propose npJIVE, a\nnonparametric estimator for solutions to linear inverse problems with many weak\ninstruments. We construct automatic debiased machine learning estimators for\nlinear functionals of both the structural function and its minimum-norm\nprojection, and establish their efficiency in the many-weak-instruments regime.", "published": "2025-05-12 16:36:55", "link": "http://arxiv.org/abs/2505.07729v1", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "primary_category": "stat.ME"}
{"title": "Langevin Diffusion Approximation to Same Marginal Schr\u00f6dinger Bridge", "abstract": "We introduce a novel approximation to the same marginal Schr\\\"{o}dinger\nbridge using the Langevin diffusion. As $\\varepsilon \\downarrow 0$, it is known\nthat the barycentric projection (also known as the entropic Brenier map) of the\nSchr\\\"{o}dinger bridge converges to the Brenier map, which is the identity. Our\ndiffusion approximation is leveraged to show that, under suitable assumptions,\nthe difference between the two is $\\varepsilon$ times the gradient of the\nmarginal log density (i.e., the score function), in $\\mathbf{L}^2$. More\ngenerally, we show that the family of Markov operators, indexed by $\\varepsilon\n> 0$, derived from integrating test functions against the conditional density\nof the static Schr\\\"{o}dinger bridge at temperature $\\varepsilon$, admits a\nderivative at $\\varepsilon=0$ given by the generator of the Langevin semigroup.\nHence, these operators satisfy an approximate semigroup property at low\ntemperatures.", "published": "2025-05-12 15:19:45", "link": "http://arxiv.org/abs/2505.07647v1", "categories": ["math.PR", "stat.ML", "49N99, 49Q22, 60J60"], "primary_category": "math.PR"}
{"title": "Modelling higher education dropouts using sparse and interpretable post-clustering logistic regression", "abstract": "Higher education dropout constitutes a critical challenge for tertiary\neducation systems worldwide. While machine learning techniques can achieve high\npredictive accuracy on selected datasets, their adoption by policymakers\nremains limited and unsatisfactory, particularly when the objective is the\nunsupervised identification and characterization of student subgroups at\nelevated risk of dropout. The model introduced in this paper is a specialized\nform of logistic regression, specifically adapted to the context of university\ndropout analysis. Logistic regression continues to serve as a foundational tool\namong reliable statistical models, primarily due to the ease with which its\nparameters can be interpreted in terms of odds ratios. Our approach\nsignificantly extends this framework by incorporating heterogeneity within the\nstudent population. This is achieved through the application of a preliminary\nclustering algorithm that identifies latent subgroups, each characterized by\ndistinct dropout propensities, which are then modeled via cluster-specific\neffects. We provide a detailed interpretation of the model parameters within\nthis extended framework and enhance interpretability by imposing sparsity\nthrough a tailored variant of the LASSO algorithm. To demonstrate the practical\napplicability of the proposed methodology, we present an extensive case study\nbased on the Italian university system, in which all the developed tools are\nsystematically applied", "published": "2025-05-12 14:05:23", "link": "http://arxiv.org/abs/2505.07582v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Causal mediation analysis with one or multiple mediators: a comparative study", "abstract": "Mediation analysis breaks down the causal effect of a treatment on an outcome\ninto an indirect effect, acting through a third group of variables called\nmediators, and a direct effect, operating through other mechanisms. Mediation\nanalysis is hard because confounders between treatment, mediators, and outcome\nblur effect estimates in observational studies. Many estimators have been\nproposed to adjust on those confounders and provide accurate causal estimates.\nWe consider parametric and non-parametric implementations of classical\nestimators and provide a thorough evaluation for the estimation of the direct\nand indirect effects in the context of causal mediation analysis for binary,\ncontinuous, and multi-dimensional mediators. We assess several approaches in a\ncomprehensive benchmark on simulated data. Our results show that advanced\nstatistical approaches such as the multiply robust and the double machine\nlearning estimators achieve good performances in most of the simulated settings\nand on real data. As an example of application, we propose a thorough analysis\nof factors known to influence cognitive functions to assess if the mechanism\ninvolves modifications in brain morphology using the UK Biobank brain imaging\ncohort. This analysis shows that for several physiological factors, such as\nhypertension and obesity, a substantial part of the effect is mediated by\nchanges in the brain structure. This work provides guidance to the practitioner\nfrom the formulation of a valid causal mediation problem, including the\nverification of the identification assumptions, to the choice of an adequate\nestimator.", "published": "2025-05-12 08:10:50", "link": "http://arxiv.org/abs/2505.07323v1", "categories": ["stat.AP", "stat.ML"], "primary_category": "stat.AP"}
{"title": "Adaptive Learning-based Surrogate Method for Stochastic Programs with Implicitly Decision-dependent Uncertainty", "abstract": "We consider a class of stochastic programming problems where the implicitly\ndecision-dependent random variable follows a nonparametric regression model\nwith heteroscedastic error. The Clarke subdifferential and surrogate functions\nare not readily obtainable due to the latent decision dependency. To deal with\nsuch a computational difficulty, we develop an adaptive learning-based\nsurrogate method that integrates the simulation scheme and statistical\nestimates to construct estimation-based surrogate functions in a way that the\nsimulation process is adaptively guided by the algorithmic procedure. We\nestablish the non-asymptotic convergence rate analysis in terms of $(\\nu,\n\\delta)$-near stationarity in expectation under variable proximal parameters\nand batch sizes, which exhibits the superior convergence performance and\nenhanced stability in both theory and practice. We provide numerical results\nwith both synthetic and real data which illustrate the benefits of the proposed\nalgorithm in terms of algorithmic stability and efficiency.", "published": "2025-05-12 07:35:06", "link": "http://arxiv.org/abs/2505.07298v1", "categories": ["math.OC", "stat.ML"], "primary_category": "math.OC"}
{"title": "FCPCA: Fuzzy clustering of high-dimensional time series based on common principal component analysis", "abstract": "Clustering multivariate time series data is a crucial task in many domains,\nas it enables the identification of meaningful patterns and groups in\ntime-evolving data. Traditional approaches, such as crisp clustering, rely on\nthe assumption that clusters are sufficiently separated with little overlap.\nHowever, real-world data often defy this assumption, exhibiting overlapping\ndistributions or overlapping clouds of points and blurred boundaries between\nclusters. Fuzzy clustering offers a compelling alternative by allowing partial\nmembership in multiple clusters, making it well-suited for these ambiguous\nscenarios. Despite its advantages, current fuzzy clustering methods primarily\nfocus on univariate time series, and for multivariate cases, even datasets of\nmoderate dimensionality become computationally prohibitive. This challenge is\nfurther exacerbated when dealing with time series of varying lengths, leaving a\nclear gap in addressing the complexities of modern datasets. This work\nintroduces a novel fuzzy clustering approach based on common principal\ncomponent analysis to address the aforementioned shortcomings. Our method has\nthe advantage of efficiently handling high-dimensional multivariate time series\nby reducing dimensionality while preserving critical temporal features.\nExtensive numerical results show that our proposed clustering method\noutperforms several existing approaches in the literature. An interesting\napplication involving brain signals from different drivers recorded from a\nsimulated driving experiment illustrates the potential of the approach.", "published": "2025-05-12 06:59:17", "link": "http://arxiv.org/abs/2505.07276v1", "categories": ["stat.ME", "stat.AP", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Is MixIT Really Unsuitable for Correlated Sources? Exploring MixIT for Unsupervised Pre-training in Music Source Separation", "abstract": "In music source separation (MSS), obtaining isolated sources or stems is\nhighly costly, making pre-training on unlabeled data a promising approach.\nAlthough source-agnostic unsupervised learning like mixture-invariant training\n(MixIT) has been explored in general sound separation, they have been largely\noverlooked in MSS due to its implicit assumption of source independence. We\nhypothesize, however, that the difficulty of applying MixIT to MSS arises from\nthe ill-posed nature of MSS itself, where stem definitions are\napplication-dependent and models lack explicit knowledge of what should or\nshould not be separated, rather than from high inter-source correlation. While\nMixIT does not assume any source model and struggles with such ambiguities, our\npreliminary experiments show that it can still separate instruments to some\nextent, suggesting its potential for unsupervised pre-training. Motivated by\nthese insights, this study investigates MixIT-based pre-training for MSS. We\nfirst pre-train a model on in-the-wild, unlabeled data from the Free Music\nArchive using MixIT, and then fine-tune it on MUSDB18 with supervision. Using\nthe band-split TF-Locoformer, one of the state-of-the-art MSS models, we\ndemonstrate that MixIT-based pre-training improves the performance over\ntraining from scratch.", "published": "2025-05-12 14:58:55", "link": "http://arxiv.org/abs/2505.07631v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Multi-band Frequency Reconstruction for Neural Psychoacoustic Coding", "abstract": "Achieving high-fidelity audio compression while preserving perceptual quality\nacross diverse content remains a key challenge in Neural Audio Coding (NAC). We\nintroduce MUFFIN, a fully convolutional Neural Psychoacoustic Coding (NPC)\nframework that leverages psychoacoustically guided multi-band frequency\nreconstruction. At its core is a Multi-Band Spectral Residual Vector\nQuantization (MBS-RVQ) module that allocates bitrate across frequency bands\nbased on perceptual salience. This design enables efficient compression while\ndisentangling speaker identity from content using distinct codebooks. MUFFIN\nincorporates a transformer-inspired convolutional backbone and a modified snake\nactivation to enhance resolution in fine-grained spectral regions. Experimental\nresults on multiple benchmarks demonstrate that MUFFIN consistently outperforms\nexisting approaches in reconstruction quality. A high-compression variant\nachieves a state-of-the-art 12.5 Hz rate with minimal loss. MUFFIN also proves\neffective in downstream generative tasks, highlighting its promise as a token\nrepresentation for integration with language models. Audio samples and code are\navailable.", "published": "2025-05-12 05:20:43", "link": "http://arxiv.org/abs/2505.07235v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "When Near Becomes Far: From Rayleigh to Optimal Near-Field and Far-Field Boundaries", "abstract": "The transition toward 6G is pushing wireless communication into a regime\nwhere the classical plane-wave assumption no longer holds. Millimeter-wave and\nsub-THz frequencies shrink wavelengths to millimeters, while meter-scale arrays\nfeaturing hundreds of antenna elements dramatically enlarge the aperture.\nTogether, these trends collapse the classical Rayleigh far-field boundary from\nkilometers to mere single-digit meters. Consequently, most practical 6G indoor,\nvehicular, and industrial deployments will inherently operate within the\nradiating near-field, where reliance on the plane-wave approximation leads to\nsevere array-gain losses, degraded localization accuracy, and excessive pilot\noverhead. This paper re-examines the fundamental question: Where does the\nfar-field truly begin? Rather than adopting purely geometric definitions, we\nintroduce an application-oriented approach based on user-defined error budgets\nand a rigorous Fresnel-zone analysis that fully accounts for both amplitude and\nphase curvature. We propose three practical mismatch metrics: worst-case\nelement mismatch, worst-case normalized mean square error, and spectral\nefficiency loss. For each metric, we derive a provably optimal transition\ndistance--the minimal range beyond which mismatch permanently remains below a\ngiven tolerance--and provide closed-form solutions. Extensive numerical\nevaluations across diverse frequencies and antenna-array dimensions show that\nour proposed thresholds can exceed the Rayleigh distance by more than an order\nof magnitude. By transforming the near-field from a design nuisance into a\nprecise, quantifiable tool, our results provide a clear roadmap for enabling\nreliable and resource-efficient near-field communications and sensing in\nemerging 6G systems.", "published": "2025-05-12 16:51:22", "link": "http://arxiv.org/abs/2505.07743v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Channel Estimation for Wideband XL-MIMO: A Constrained Deep Unrolling Approach", "abstract": "Extremely large-scale multiple-input multipleoutput (XL-MIMO) enables the\nformation of narrow beams, effectively mitigating path loss in high-frequency\ncommunications. This capability makes the integration of wideband\nhigh-frequency communications with XL-MIMO a key enabler for future 6G\nnetworks. Realizing the full potential of such wideband XL-MIMO systems\ncritically depends on acquiring accurate channel state information. However,\nthis acquisition is significantly challenged by inherent wideband XLMIMO\nchannel characteristics, including near-field propagation effects, beam split,\nand spatial non-stationarity. We formulate the channel estimation as a maximum\na posteriori problem and propose an unrolled proximal gradient descent network.\nThe network integrates learnable step sizes and replaces the proximal operator\nwith a neural network to implicitly learn channel prior knowledge without\nrequiring explicit regularization terms. To enhance the convergence behavior,\nwe incorporated a monotonic descent constraint on the layer-wise estimation\nerror during training. This constrained learning problem is addressed using a\nprimal-dual training approach. Theoretical analysis is provided to characterize\nthe duality gap and convergence behavior of the proposed method. Furthermore,\nsimulation results are presented to validate its effectiveness, demonstrating\ngains in estimation accuracy over both traditional and deep learning-based\nmethods.", "published": "2025-05-12 16:22:45", "link": "http://arxiv.org/abs/2505.07717v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Simultaneous Intrusion Detection and Localization Using ISAC Network", "abstract": "The rapid increase in utilization of smart home technologies has introduced\nnew paradigms to ensure the security and privacy of inhabitants. In this study,\nwe propose a novel approach to detect and localize physical intrusions in\nindoor environments. The proposed method leverages signals from access points\n(APs) and an anchor node (AN) to achieve accurate intrusion detection and\nlocalization. We evaluate its performance through simulations under different\nintruder scenarios. The proposed method achieved a high accuracy of 92% for\nboth intrusion detection and localization. Our simulations demonstrated a low\nfalse positive rate of less than 5% and a false negative rate of around 3%,\nhighlighting the reliability of our approach in identifying security threats\nwhile minimizing unnecessary alerts. This performance underscores the\neffectiveness of integrating Wi-Fi sensing with advanced signal processing\ntechniques for enhanced smart home security.", "published": "2025-05-12 15:23:49", "link": "http://arxiv.org/abs/2505.07656v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Approximate MLE of High-Dimensional STAP Covariance Matrices with Banded & Spiked Structure -- A Convex Relaxation Approach", "abstract": "Estimating the clutter-plus-noise covariance matrix in high-dimensional STAP\nis challenging in the presence of Internal Clutter Motion (ICM) and a high\nnoise floor. The problem becomes more difficult in low-sample regimes, where\nthe Sample Covariance Matrix (SCM) becomes ill-conditioned. To capture the ICM\nand high noise floor, we model the covariance matrix using a ``Banded+Spiked''\nstructure. Since the Maximum Likelihood Estimation (MLE) for this model is\nnon-convex, we propose a convex relaxation which is formulated as a Frobenius\nnorm minimization with non-smooth convex constraints enforcing banded sparsity.\nThis relaxation serves as a provable upper bound for the non-convex likelihood\nmaximization and extends to cases where the covariance matrix dimension exceeds\nthe number of samples. We derive a variational inequality-based bound to assess\nits quality. We introduce a novel algorithm to jointly estimate the banded\nclutter covariance and noise power. Additionally, we establish conditions\nensuring the estimated covariance matrix remains positive definite and the\nbandsize is accurately recovered. Numerical results using the high-fidelity\nRFView radar simulation environment demonstrate that our algorithm achieves a\nhigher Signal-to-Clutter-plus-Noise Ratio (SCNR) than state-of-the-art methods,\nincluding TABASCO, Spiked Covariance Stein Shrinkage, and Diagonal Loading,\nparticularly when the covariance matrix dimension exceeds the number of\nsamples.", "published": "2025-05-12 15:13:22", "link": "http://arxiv.org/abs/2505.07643v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Wireless Link Scheduling with State-Augmented Graph Neural Networks", "abstract": "We consider the problem of optimal link scheduling in large-scale wireless ad\nhoc networks. We specifically aim for the maximum long-term average\nperformance, subject to a minimum transmission requirement for each link to\nensure fairness. With a graph structure utilized to represent the conflicts of\nlinks, we formulate a constrained optimization problem to learn the scheduling\npolicy, which is parameterized with a graph neural network (GNN). To address\nthe challenge of long-term performance, we use the state-augmentation\ntechnique. In particular, by augmenting the Lagrangian dual variables as\ndynamic inputs to the scheduling policy, the GNN can be trained to gradually\nadapt the scheduling decisions to achieve the minimum transmission\nrequirements. We verify the efficacy of our proposed policy through numerical\nsimulations and compare its performance with several baselines in various\nnetwork settings.", "published": "2025-05-12 14:22:36", "link": "http://arxiv.org/abs/2505.07598v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Physics-Informed Topological Signal Processing for Water Distribution Network Monitoring", "abstract": "Water management is one of the most critical aspects of our society, together\nwith population increase and climate change. Water scarcity requires a better\ncharacterization and monitoring of Water Distribution Networks (WDNs). This\npaper presents a novel framework for monitoring Water Distribution Networks\n(WDNs) by integrating physics-informed modeling of the nonlinear interactions\nbetween pressure and flow data with Topological Signal Processing (TSP)\ntechniques. We represent pressure and flow data as signals defined over a\nsecond-order cell complex, enabling accurate estimation of water pressures and\nflows throughout the entire network from sparse sensor measurements. By\nformalizing hydraulic conservation laws through the TSP framework, we provide a\ncomprehensive representation of nodal pressures and edge flows that incorporate\nhigher-order interactions captured through the formalism of cell complexes.\nThis provides a principled way to decompose the water flows in WDNs in three\northogonal signal components (irrotational, solenoidal and harmonic). The\nspectral representations of these components inherently reflect the\nconservation laws governing the water pressures and flows. Sparse\nrepresentation in the spectral domain enable topology-based sampling and\nreconstruction of nodal pressures and water flows from sparse measurements. Our\nresults demonstrate that employing cell complex-based signal representations\nenhances the accuracy of edge signal reconstruction, due to proper modeling of\nboth conservative and non-conservative flows along the polygonal cells.", "published": "2025-05-12 13:43:05", "link": "http://arxiv.org/abs/2505.07560v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Space-Time Beamforming for LEO Satellite Communications", "abstract": "Inter-beam interference poses a significant challenge in low Earth orbit\n(LEO) satellite communications due to dense satellite constellations. To\naddress this issue, we introduce spacetime beamforming, a novel paradigm that\nleverages the spacetime channel vector, uniquely determined by the angle of\narrival (AoA) and relative Doppler shift, to optimize beamforming between a\nmoving satellite transmitter and a ground station user. We propose two\nspace-time beamforming techniques: spacetime zero-forcing (ST-ZF) and\nspace-time signal-to-leakage-plus-noise ratio (ST-SLNR) maximization. In a\npartially connected interference channel, ST-ZF achieves a 3dB SNR gain over\nthe conventional interference avoidance method using maximum ratio transmission\nbeamforming. Moreover, in general interference networks, ST-SLNR beamforming\nsignificantly enhances sum spectral efficiency compared to conventional\ninterference management approaches. These results demonstrate the effectiveness\nof space-time beamforming in improving spectral efficiency and interference\nmitigation for next-generation LEO satellite networks.", "published": "2025-05-12 13:28:09", "link": "http://arxiv.org/abs/2505.07547v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Evaluating the Scalability of Binary and Ternary CNN Workloads on RRAM-based Compute-in-Memory Accelerators", "abstract": "The increasing computational demand of Convolutional Neural Networks (CNNs)\nnecessitates energy-efficient acceleration strategies. Compute-in-Memory (CIM)\narchitectures based on Resistive Random Access Memory (RRAM) offer a promising\nsolution by reducing data movement and enabling low-power in-situ computations.\nHowever, their efficiency is limited by the high cost of peripheral circuits,\nparticularly Analog-to-Digital Converters (ADCs). Large crossbars and low ADC\nresolutions are often used to mitigate this, potentially compromising accuracy.\nThis work introduces novel simulation methods to model the impact of resistive\nwire parasitics and limited ADC resolution on RRAM crossbars. Our parasitics\nmodel employs a vectorised algorithm to compute crossbar output currents with\nerrors below 0.15% compared to SPICE. Additionally, we propose a variable\nstep-size ADC and a calibration methodology that significantly reduces ADC\nresolution requirements. These accuracy models are integrated with a\nstatistics-based energy model. Using our framework, we conduct a comparative\nanalysis of binary and ternary CNNs. Experimental results demonstrate that the\nternary CNNs exhibit greater resilience to wire parasitics and lower ADC\nresolution but suffer a 40% reduction in energy efficiency. These findings\nprovide valuable insights for optimising RRAM-based CIM accelerators for\nenergy-efficient deep learning.", "published": "2025-05-12 12:21:31", "link": "http://arxiv.org/abs/2505.07490v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Cognitive Non-Coherent Jamming Techniques for Frequency Selective Attacks", "abstract": "This paper deals with the design of non-coherent jamming strategies capable\nof ensuring spectral compatibility with friendly radio frequency (RF) emitters.\nThe goal is achieved via a cognitive approach, which, after recognizing the\npresence of friendly RF systems within the bandwidth of interest (perception),\nsynthesizes a jamming waveform (action) with spectral notches, that allows to\ninterfere exclusively with opposite emissions. Two methods are proposed for the\nsynthesis of the jamming signal. The former leverages optimization techniques\nfor quadratically constrained quadratic problems (QCQP) where each constraint\nembeds the interference level tolerable by a specific friendly RF system. The\nlatter is a very computationally efficient approach based on simple\nprojections, allowing a control over the spectral notch positions and widths.\nAt the analysis stage, the performance of the devised jamming techniques is\nfirstly numerically analyzed in terms of spectral occupancy and autocorrelation\ncharacteristics. The impact of the quantization process involved in the\ndigital-to-analog conversion (DAC) of the jamming waveforms is also examined,\nwith a particular focus on the spectral shaping impairments resulting from\nreduced DAC resolution. Finally, waveform transmission and reception is\nexperimentally assessed with software defined radio (SDR) devices.", "published": "2025-05-12 10:37:23", "link": "http://arxiv.org/abs/2505.07429v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pilot-Based End-to-End Radio Positioning and Mapping for ISAC: Beyond Point-Based Landmarks", "abstract": "Integrated sensing and communication enables simultaneous communication and\nsensing tasks, including precise radio positioning and mapping, essential for\nfuture 6G networks. Current methods typically model environmental landmarks as\nisolated incidence points or small reflection areas, lacking detailed\nattributes essential for advanced environmental interpretation. This paper\naddresses these limitations by developing an end-to-end cooperative uplink\nframework involving multiple base stations and users. Our method uniquely\nestimates extended landmark objects and incorporates obstruction-based outlier\nremoval to mitigate multi-bounce signal effects. Validation using realistic\nray-tracing data demonstrates substantial improvements in the richness of the\nestimated environmental map.", "published": "2025-05-12 09:54:46", "link": "http://arxiv.org/abs/2505.07402v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "High Performance Signal Design for ACO-OFDM Systems using Variational Autoencoder", "abstract": "This letter proposes a design of low peak-to-average power ratio (PAPR), low\nsymbol error rate (SER), and high data rate signal for asymmetrically clipped\noptical orthogonal frequency division multiplexing (ACO-OFDM) systems. The\nproposed design leverages a variational autoencoder (VAE) incorporating gradual\nloss learning to jointly optimize the geometry and probability of the\nconstellation's symbols. This not only enhances mutual information (MI) but\nalso effectively reduces the PAPR while maintaining a low SER for reliable\ntransmission. We evaluate the performance of the proposed VAE-based design by\ncomparing the MI, SER, and PAPR against existing techniques. Simulation results\ndemonstrate that the proposed method achieves a considerably lower PAPR while\nmaintaining superior SER and MI performance for a wide range of SNRs.", "published": "2025-05-12 08:57:29", "link": "http://arxiv.org/abs/2505.07362v1", "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "eess.SY"}
{"title": "Computational Imaging-Based ISAC Method with Large Pixel Division", "abstract": "One of the key points in designing an integrated sensing and communication\n(ISAC) system using computational imaging is the division size of imaging\npixels. If the size is too small, it leads to a high number of pixels that need\nprocessing. On the contrary, it usually causes large processing errors since\neach pixel is no longer uniformly coherent. In this paper, a novel method is\nproposed to address such a problem in environment sensing in millimeter-wave\nwireless cellular networks, which effectively cancels the severe errors caused\nby large pixel division as in conventional computational imaging algorithms. To\nthis end, a novel computational imaging model in an integral form is\nintroduced, which leverages the continuous characteristics of object surfaces\nin the environment and takes into account the different phases associated with\nthe different parts of the pixel. The proposed algorithm extends computational\nimaging to large wireless communication scenarios for the first time. The\nperformance of the proposed method is then analyzed, and extensive numerical\nresults verify its effectiveness.", "published": "2025-05-12 08:47:11", "link": "http://arxiv.org/abs/2505.07355v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Swarm Antenna Arrays: From Deterministic to Stochastic Modeling", "abstract": "Swarm antenna arrays, composed of spatially distributed antennas mounted on\nunmanned agents, offer unprecedented flexibility and adaptability for wireless\nsensing and communication. However, their reconfigurable architecture,\nsusceptibility to collisions, and inherently stochastic nature present\nsignificant challenges to realizing collaborative gain. It remains unclear how\nspatial coordination, positional perturbations, and large-scale topological\nconfigurations affect coherent signal aggregation and overall system\nperformance. This paper investigates the feasibility of achieving coherent\nbeamforming in such systems from both deterministic and stochastic\nperspectives. First, we develop a rigorous theoretical framework that\ncharacterizes the necessary and sufficient conditions for the emergence of\ngrating lobes in multiple linear configurations. Notably, we show that for dual\nlinear arrays, the classical half-wavelength spacing constraint can be safely\nrelaxed without introducing spatial aliasing. This result challenges\ntraditional array design principles and enables more flexible, collision-aware\ntopologies. Second, we present a theoretical analysis, supported by empirical\nvalidation, demonstrating that coherent gain can be approximately preserved\nunder realistic positional perturbations. Our results reveal that spatial\nperturbations introduce measurable degradation in the main lobe, an effect that\ncannot be mitigated merely by increasing the number of antennas. Instead, the\nprimary benefit of scaling lies in reducing the variance of\nperturbation-induced fluctuations.", "published": "2025-05-12 08:21:20", "link": "http://arxiv.org/abs/2505.07335v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Sparse Arrays Enable Near-Field Constant-Distance Focusing with Reduced Focal Shift", "abstract": "In near-field beam focusing for finite-sized arrays, focal shift is a\nnon-negligible issue. The actual focal point often appears closer to the array\nthan the predefined focal distance, significantly degrading the focusing\nperformance of finite aperture arrays. Moreover, when the focus point is\nscanned across different locations, the degradation becomes even more\npronounced, leading not only to positional deviation but also to substantial\nenergy loss. To address this issue, we revisit the problem from the perspective\nof communication degrees of freedom. We demonstrate that a properly designed\nsparse array with optimized element spacing can effectively mitigate focal\nshift while enabling stable control of the focusing height during beam\nscanning. Simulation results based on dipole antennas with different\npolarizations and patch antennas validate our findings. Notably, with optimized\ninter-element distances, the energy distribution across focal points becomes\nnearly uniform, and highly accurate focusing positions are achieved.", "published": "2025-05-12 07:13:37", "link": "http://arxiv.org/abs/2505.07285v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "A Unified Deterministic Channel Model for Multi-Type RIS with Reflective, Transmissive, and Polarization Operations", "abstract": "Reconfigurable Intelligent Surface (RIS) technologies have been considered as\na promising enabler for 6G, enabling advantageous control of electromagnetic\n(EM) propagation. RIS can be categorized into multiple types based on their\nreflective/transmissive modes and polarization control capabilities, all of\nwhich are expected to be widely deployed in practical environments. A reliable\nRIS channel model is essential for the design and development of RIS\ncommunication systems. While deterministic modeling approaches such as\nray-tracing (RT) offer significant benefits, a unified model that accommodates\nall RIS types is still lacking. This paper addresses this gap by developing a\nhigh-precision deterministic channel model based on RT, supporting multiple RIS\ntypes: reflective, transmissive, hybrid, and three polarization operation\nmodes. To achieve this, a unified EM response model for the aforementioned RIS\ntypes is developed. The reflection and transmission coefficients of RIS\nelements are derived using a tensor-based equivalent impedance approach,\nfollowed by calculating the scattered fields of the RIS to establish an EM\nresponse model. The performance of different RIS types is compared through\nsimulations in typical scenarios. During this process, passive and lossless\nconstraints on the reflection and transmission coefficients are incorporated to\nensure fairness in the performance evaluation. Simulation results validate the\nframework's accuracy in characterizing the RIS channel, and specific cases\ntailored for dual-polarization independent control and polarization rotating\nRISs are highlighted as insights for their future deployment. This work can be\nhelpful for the evaluation and optimization of RIS-enabled wireless\ncommunication systems.", "published": "2025-05-12 02:41:53", "link": "http://arxiv.org/abs/2505.07191v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Codifying Character Logic in Role-Playing", "abstract": "This paper introduces Codified Profiles for role-playing, a novel approach\nthat represents character logic as structured, executable functions for\nbehavioral decision-making. Each profile defines a set of functions\nparse_by_scene(scene) that outputs a list of logic-grounded assertions\ntriggered_statements, using both explicit control structures (e.g.,\nif-then-else) and condition checks like check_condition(scene, question), where\neach question is a semantically meaningful prompt about the scene (e.g., \"Is\nthe character in danger?\") discriminated by the role-playing LLM as true,\nfalse, or unknown. This explicit representation offers three key advantages\nover traditional prompt-based profiles, which append character descriptions\ndirectly into text prompts: (1) Persistence, by enforcing complete and\nconsistent execution of character logic, rather than relying on the model's\nimplicit reasoning; (2) Updatability, through systematic inspection and\nrevision of behavioral logic, which is difficult to track or debug in\nprompt-only approaches; (3) Controllable Randomness, by supporting stochastic\nbehavior directly within the logic, enabling fine-grained variability that\nprompting alone struggles to achieve. To validate these advantages, we\nintroduce a new benchmark constructed from 83 characters and 5,141 scenes\ncurated from Fandom, using NLI-based scoring to compare character responses\nagainst ground-truth actions. Our experiments demonstrate the significant\nbenefits of codified profiles in improving persistence, updatability, and\nbehavioral diversity. Notably, by offloading a significant portion of reasoning\nto preprocessing, codified profiles enable even 1B-parameter models to perform\nhigh-quality role-playing, providing a scalable and efficient foundation for\nlocal deployment of role-play agents.", "published": "2025-05-12 16:12:42", "link": "http://arxiv.org/abs/2505.07705v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit", "abstract": "We present OnPrem$.$LLM, a Python-based toolkit for applying large language\nmodels (LLMs) to sensitive, non-public data in offline or restricted\nenvironments. The system is designed for privacy-preserving use cases and\nprovides prebuilt pipelines for document processing and storage,\nretrieval-augmented generation (RAG), information extraction, summarization,\nclassification, and prompt/output processing with minimal configuration.\nOnPrem$.$LLM supports multiple LLM backends -- including llama$.$cpp, Ollama,\nvLLM, and Hugging Face Transformers -- with quantized model support, GPU\nacceleration, and seamless backend switching. Although designed for fully local\nexecution, OnPrem$.$LLM also supports integration with a wide range of cloud\nLLM providers when permitted, enabling hybrid deployments that balance\nperformance with data control. A no-code web interface extends accessibility to\nnon-technical users.", "published": "2025-05-12 15:36:27", "link": "http://arxiv.org/abs/2505.07672v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Prototype Augmented Hypernetworks for Continual Learning", "abstract": "Continual learning (CL) aims to learn a sequence of tasks without forgetting\nprior knowledge, but gradient updates for a new task often overwrite the\nweights learned earlier, causing catastrophic forgetting (CF). We propose\nPrototype-Augmented Hypernetworks (PAH), a framework where a single\nhypernetwork, conditioned on learnable task prototypes, dynamically generates\ntask-specific classifier heads on demand. To mitigate forgetting, PAH combines\ncross-entropy with dual distillation losses, one to align logits and another to\nalign prototypes, ensuring stable feature representations across tasks.\nEvaluations on Split-CIFAR100 and TinyImageNet demonstrate that PAH achieves\nstate-of-the-art performance, reaching 74.5 % and 63.7 % accuracy with only 1.7\n% and 4.4 % forgetting, respectively, surpassing prior methods without storing\nsamples or heads.", "published": "2025-05-12 11:25:54", "link": "http://arxiv.org/abs/2505.07450v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "CHD: Coupled Hierarchical Diffusion for Long-Horizon Tasks", "abstract": "Diffusion-based planners have shown strong performance in short-horizon tasks\nbut often fail in complex, long-horizon settings. We trace the failure to loose\ncoupling between high-level (HL) sub-goal selection and low-level (LL)\ntrajectory generation, which leads to incoherent plans and degraded\nperformance. We propose Coupled Hierarchical Diffusion (CHD), a framework that\nmodels HL sub-goals and LL trajectories jointly within a unified diffusion\nprocess. A shared classifier passes LL feedback upstream so that sub-goals\nself-correct while sampling proceeds. This tight HL-LL coupling improves\ntrajectory coherence and enables scalable long-horizon diffusion planning.\nExperiments across maze navigation, tabletop manipulation, and household\nenvironments show that CHD consistently outperforms both flat and hierarchical\ndiffusion baselines. Our website is: https://sites.google.com/view/chd2025/home", "published": "2025-05-12 06:21:48", "link": "http://arxiv.org/abs/2505.07261v2", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "FLUXSynID: A Framework for Identity-Controlled Synthetic Face Generation with Document and Live Images", "abstract": "Synthetic face datasets are increasingly used to overcome the limitations of\nreal-world biometric data, including privacy concerns, demographic imbalance,\nand high collection costs. However, many existing methods lack fine-grained\ncontrol over identity attributes and fail to produce paired,\nidentity-consistent images under structured capture conditions. We introduce\nFLUXSynID, a framework for generating high-resolution synthetic face datasets\nwith user-defined identity attribute distributions and paired document-style\nand trusted live capture images. The dataset generated using the FLUXSynID\nframework shows improved alignment with real-world identity distributions and\ngreater inter-set diversity compared to prior work. The FLUXSynID framework for\ngenerating custom datasets, along with a dataset of 14,889 synthetic\nidentities, is publicly released to support biometric research, including face\nrecognition and morphing attack detection.", "published": "2025-05-12 13:12:33", "link": "http://arxiv.org/abs/2505.07530v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Ophora: A Large-Scale Data-Driven Text-Guided Ophthalmic Surgical Video Generation Model", "abstract": "In ophthalmic surgery, developing an AI system capable of interpreting\nsurgical videos and predicting subsequent operations requires numerous\nophthalmic surgical videos with high-quality annotations, which are difficult\nto collect due to privacy concerns and labor consumption. Text-guided video\ngeneration (T2V) emerges as a promising solution to overcome this issue by\ngenerating ophthalmic surgical videos based on surgeon instructions. In this\npaper, we present Ophora, a pioneering model that can generate ophthalmic\nsurgical videos following natural language instructions. To construct Ophora,\nwe first propose a Comprehensive Data Curation pipeline to convert narrative\nophthalmic surgical videos into a large-scale, high-quality dataset comprising\nover 160K video-instruction pairs, Ophora-160K. Then, we propose a Progressive\nVideo-Instruction Tuning scheme to transfer rich spatial-temporal knowledge\nfrom a T2V model pre-trained on natural video-text datasets for\nprivacy-preserved ophthalmic surgical video generation based on Ophora-160K.\nExperiments on video quality evaluation via quantitative analysis and\nophthalmologist feedback demonstrate that Ophora can generate realistic and\nreliable ophthalmic surgical videos based on surgeon instructions. We also\nvalidate the capability of Ophora for empowering downstream tasks of ophthalmic\nsurgical workflow understanding. Code is available at\nhttps://github.com/mar-cry/Ophora.", "published": "2025-05-12 11:23:37", "link": "http://arxiv.org/abs/2505.07449v2", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset", "abstract": "Urban Digital Twins (UDTs) have become essential for managing cities and\nintegrating complex, heterogeneous data from diverse sources. Creating UDTs\ninvolves challenges at multiple process stages, including acquiring accurate 3D\nsource data, reconstructing high-fidelity 3D models, maintaining models'\nupdates, and ensuring seamless interoperability to downstream tasks. Current\ndatasets are usually limited to one part of the processing chain, hampering\ncomprehensive UDTs validation. To address these challenges, we introduce the\nfirst comprehensive multimodal Urban Digital Twin benchmark dataset: TUM2TWIN.\nThis dataset includes georeferenced, semantically aligned 3D models and\nnetworks along with various terrestrial, mobile, aerial, and satellite\nobservations boasting 32 data subsets over roughly 100,000 $m^2$ and currently\n767 GB of data. By ensuring georeferenced indoor-outdoor acquisition, high\naccuracy, and multimodal data integration, the benchmark supports robust\nanalysis of sensors and the development of advanced reconstruction methods.\nAdditionally, we explore downstream tasks demonstrating the potential of\nTUM2TWIN, including novel view synthesis of NeRF and Gaussian Splatting, solar\npotential analysis, point cloud semantic segmentation, and LoD3 building\nreconstruction. We are convinced this contribution lays a foundation for\novercoming current limitations in UDT creation, fostering new research\ndirections and practical solutions for smarter, data-driven urban environments.\nThe project is available under: https://tum2t.win", "published": "2025-05-12 09:48:32", "link": "http://arxiv.org/abs/2505.07396v2", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Human Motion Prediction via Test-domain-aware Adaptation with Easily-available Human Motions Estimated from Videos", "abstract": "In 3D Human Motion Prediction (HMP), conventional methods train HMP models\nwith expensive motion capture data. However, the data collection cost of such\nmotion capture data limits the data diversity, which leads to poor\ngeneralizability to unseen motions or subjects. To address this issue, this\npaper proposes to enhance HMP with additional learning using estimated poses\nfrom easily available videos. The 2D poses estimated from the monocular videos\nare carefully transformed into motion capture-style 3D motions through our\npipeline. By additional learning with the obtained motions, the HMP model is\nadapted to the test domain. The experimental results demonstrate the\nquantitative and qualitative impact of our method.", "published": "2025-05-12 07:45:57", "link": "http://arxiv.org/abs/2505.07301v2", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Reflexive Composition of Elementary State Machines, with an Application to the Reversal of Cellular Automata Rule 90", "abstract": "We explore the dynamics of a one-dimensional lattice of state machines on two\nstates and two symbols sequentially updated via a process of \"reflexive\ncomposition.\" The space of 256 machines exhibits a variety of behavior,\nincluding substitution, reversible \"billiard ball\" dynamics, and fractal\nnesting. We show that one machine generates the Sierpinski Triangle and, for a\nsubset of boundary conditions, is isomorphic to cellular automata Rule 90 in\nWolfram's naming scheme. More surprisingly, two other machines follow\ntrajectories that map to Rule 90 in reverse. Whereas previous techniques have\nbeen developed to uncover preimages of Rule 90, this is the first study to\nproduce such inverse dynamics naturally from the formalism itself. We argue\nthat the system's symmetric treatment of state and message underlies its\nexpressive power.", "published": "2025-05-12 02:28:46", "link": "http://arxiv.org/abs/2505.07186v2", "categories": ["cs.DM", "cs.FL", "nlin.CG"], "primary_category": "cs.DM"}
{"title": "From raw affiliations to organization identifiers", "abstract": "Accurate affiliation matching, which links affiliation strings to\nstandardized organization identifiers, is critical for improving research\nmetadata quality, facilitating comprehensive bibliometric analyses, and\nsupporting data interoperability across scholarly knowledge bases. Existing\napproaches fail to handle the complexity of affiliation strings that often\ninclude mentions of multiple organizations or extraneous information. In this\npaper, we present AffRo, a novel approach designed to address these challenges,\nleveraging advanced parsing and disambiguation techniques. We also introduce\nAffRoDB, an expert-curated dataset to systematically evaluate affiliation\nmatching algorithms, ensuring robust benchmarking. Results demonstrate the\neffectiveness of AffRp in accurately identifying organizations from complex\naffiliation strings.", "published": "2025-05-12 13:57:47", "link": "http://arxiv.org/abs/2505.07577v2", "categories": ["cs.DL", "cs.IR"], "primary_category": "cs.DL"}
{"title": "Putting It All into Context: Simplifying Agents with LCLMs", "abstract": "Recent advances in language model (LM) agents have demonstrated significant\npotential for automating complex real-world tasks. To make progress on these\ndifficult tasks, LM agent architectures have become increasingly complex, often\nincorporating multi-step retrieval tools, multiple agents, and scaffolding\nadapted to the underlying LM. In this work, we investigate whether all of this\ncomplexity is necessary, or if parts of these scaffolds can be removed on\nchallenging tasks like SWE-bench. We show that in the case of SWE-bench, simply\nputting the entire environment into the context of a long context language\nmodel (LCLM) and properly prompting the model makes it competitive with\ncarefully tuned, complex agent scaffolds. We show that a Gemini-1.5-Pro model\nwithout any scaffolding or tools achieves 38% on SWE-Bench-Verified, comparable\nwith approaches using carefully tuned agent scaffolds (32%). While the\nunscaffolded approach with Gemini-1.5-Pro falls short of the strongest agentic\narchitectures, we demonstrate that the more capable Gemini-2.5-Pro using the\nsame unscaffolded approach directly attains a 50.8% solve rate. Additionally, a\ntwo-stage approach combining Gemini-1.5-Pro with Claude-3.7 achieves a\ncompetitive 48.6% solve rate.", "published": "2025-05-12 23:22:27", "link": "http://arxiv.org/abs/2505.08120v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Are LLMs complicated ethical dilemma analyzers?", "abstract": "One open question in the study of Large Language Models (LLMs) is whether\nthey can emulate human ethical reasoning and act as believable proxies for\nhuman judgment. To investigate this, we introduce a benchmark dataset\ncomprising 196 real-world ethical dilemmas and expert opinions, each segmented\ninto five structured components: Introduction, Key Factors, Historical\nTheoretical Perspectives, Resolution Strategies, and Key Takeaways. We also\ncollect non-expert human responses for comparison, limited to the Key Factors\nsection due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini,\nClaude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric\nframework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine\nsimilarity, and Universal Sentence Encoder similarity. Metric weights are\ncomputed through an inversion-based ranking alignment and pairwise AHP\nanalysis, enabling fine-grained comparison of model outputs to expert\nresponses. Our results show that LLMs generally outperform non-expert humans in\nlexical and structural alignment, with GPT-4o-mini performing most consistently\nacross all sections. However, all models struggle with historical grounding and\nproposing nuanced resolution strategies, which require contextual abstraction.\nHuman responses, while less structured, occasionally achieve comparable\nsemantic similarity, suggesting intuitive moral reasoning. These findings\nhighlight both the strengths and current limitations of LLMs in ethical\ndecision-making.", "published": "2025-05-12 22:35:07", "link": "http://arxiv.org/abs/2505.08106v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders", "abstract": "Sparse Autoencoders (SAEs) have recently emerged as powerful tools for\ninterpreting and steering the internal representations of large language models\n(LLMs). However, conventional approaches to analyzing SAEs typically rely\nsolely on input-side activations, without considering the causal influence\nbetween each latent feature and the model's output. This work is built on two\nkey hypotheses: (1) activated latents do not contribute equally to the\nconstruction of the model's output, and (2) only latents with high causal\ninfluence are effective for model steering. To validate these hypotheses, we\npropose Gradient Sparse Autoencoder (GradSAE), a simple yet effective method\nthat identifies the most influential latents by incorporating output-side\ngradient information.", "published": "2025-05-12 21:29:12", "link": "http://arxiv.org/abs/2505.08080v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "HYPERNYM MERCURY: Token Optimization through Semantic Field Constriction and Reconstruction from Hypernyms. A New Text Compression Method", "abstract": "Compute optimization using token reduction of LLM prompts is an emerging task\nin the fields of NLP and next generation, agentic AI. In this white paper, we\nintroduce a novel (patent pending) text representation scheme and a\nfirst-of-its-kind word-level semantic compression of paragraphs that can lead\nto over 90\\% token reduction, while retaining high semantic similarity to the\nsource text. We explain how this novel compression technique can be lossless\nand how the detail granularity is controllable. We discuss benchmark results\nover open source data (i.e. Bram Stoker's Dracula available through Project\nGutenberg) and show how our results hold at the paragraph level, across\nmultiple genres and models.", "published": "2025-05-12 20:49:50", "link": "http://arxiv.org/abs/2505.08058v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning", "abstract": "Safety alignment approaches in large language models (LLMs) often lead to the\nover-refusal of benign queries, significantly diminishing their utility in\nsensitive scenarios. To address this challenge, we introduce FalseReject, a\ncomprehensive resource containing 16k seemingly toxic queries accompanied by\nstructured responses across 44 safety-related categories. We propose a\ngraph-informed adversarial multi-agent interaction framework to generate\ndiverse and complex prompts, while structuring responses with explicit\nreasoning to aid models in accurately distinguishing safe from unsafe contexts.\nFalseReject includes training datasets tailored for both standard\ninstruction-tuned models and reasoning-oriented models, as well as a\nhuman-annotated benchmark test set. Our extensive benchmarking on 29\nstate-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges.\nEmpirical results demonstrate that supervised finetuning with FalseReject\nsubstantially reduces unnecessary refusals without compromising overall safety\nor general language capabilities.", "published": "2025-05-12 20:45:25", "link": "http://arxiv.org/abs/2505.08054v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NAZM: Network Analysis of Zonal Metrics in Persian Poetic Tradition", "abstract": "This study formalizes a computational model to simulate classical Persian\npoets' dynamics of influence through constructing a multi-dimensional\nsimilarity network. Using a rigorously curated dataset based on Ganjoor's\ncorpus, we draw upon semantic, lexical, stylistic, thematic, and metrical\nfeatures to demarcate each poet's corpus. Each is contained within weighted\nsimilarity matrices, which are then appended to generate an aggregate graph\nshowing poet-to-poet influence. Further network investigation is carried out to\nidentify key poets, style hubs, and bridging poets by calculating degree,\ncloseness, betweenness, eigenvector, and Katz centrality measures. Further, for\ntypological insight, we use the Louvain community detection algorithm to\ndemarcate clusters of poets sharing both style and theme coherence, which\ncorrespond closely to acknowledged schools of literature like Sabk-e Hindi,\nSabk-e Khorasani, and the Bazgasht-e Adabi phenomenon. Our findings provide a\nnew data-driven view of Persian literature distinguished between canonical\nsignificance and interextual influence, thus highlighting relatively\nlesser-known figures who hold great structural significance. Combining\ncomputational linguistics with literary study, this paper produces an\ninterpretable and scalable model for poetic tradition, enabling retrospective\nreflection as well as forward-looking research within digital humanities.", "published": "2025-05-12 20:39:53", "link": "http://arxiv.org/abs/2505.08052v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "TiSpell: A Semi-Masked Methodology for Tibetan Spelling Correction covering Multi-Level Error with Data Augmentation", "abstract": "Multi-level Tibetan spelling correction addresses errors at both the\ncharacter and syllable levels within a unified model. Existing methods focus\nmainly on single-level correction and lack effective integration of both\nlevels. Moreover, there are no open-source datasets or augmentation methods\ntailored for this task in Tibetan. To tackle this, we propose a data\naugmentation approach using unlabeled text to generate multi-level corruptions,\nand introduce TiSpell, a semi-masked model capable of correcting both\ncharacter- and syllable-level errors. Although syllable-level correction is\nmore challenging due to its reliance on global context, our semi-masked\nstrategy simplifies this process. We synthesize nine types of corruptions on\nclean sentences to create a robust training set. Experiments on both simulated\nand real-world data demonstrate that TiSpell, trained on our dataset,\noutperforms baseline models and matches the performance of state-of-the-art\napproaches, confirming its effectiveness.", "published": "2025-05-12 20:08:05", "link": "http://arxiv.org/abs/2505.08037v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models and Arabic Content: A Review", "abstract": "Over the past three years, the rapid advancement of Large Language Models\n(LLMs) has had a profound impact on multiple areas of Artificial Intelligence\n(AI), particularly in Natural Language Processing (NLP) across diverse\nlanguages, including Arabic. Although Arabic is considered one of the most\nwidely spoken languages across 27 countries in the Arabic world and used as a\nsecond language in some other non-Arabic countries as well, there is still a\nscarcity of Arabic resources, datasets, and tools. Arabic NLP tasks face\nvarious challenges due to the complexities of the Arabic language, including\nits rich morphology, intricate structure, and diverse writing standards, among\nother factors. Researchers have been actively addressing these challenges,\ndemonstrating that pre-trained Large Language Models (LLMs) trained on\nmultilingual corpora achieve significant success in various Arabic NLP tasks.\nThis study provides an overview of using large language models (LLMs) for the\nArabic language, highlighting early pre-trained Arabic Language models across\nvarious NLP applications and their ability to handle diverse Arabic content\ntasks and dialects. It also provides an overview of how techniques like\nfinetuning and prompt engineering can enhance the performance of these models.\nAdditionally, the study summarizes common Arabic benchmarks and datasets while\npresenting our observations on the persistent upward trend in the adoption of\nLLMs.", "published": "2025-05-12 19:09:12", "link": "http://arxiv.org/abs/2505.08004v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Task-Adaptive Semantic Communications with Controllable Diffusion-based Data Regeneration", "abstract": "Semantic communications represent a new paradigm of next-generation\nnetworking that shifts bit-wise data delivery to conveying the semantic\nmeanings for bandwidth efficiency. To effectively accommodate various potential\ndownstream tasks at the receiver side, one should adaptively convey the most\ncritical semantic information. This work presents a novel task-adaptive\nsemantic communication framework based on diffusion models that is capable of\ndynamically adjusting the semantic message delivery according to various\ndownstream tasks. Specifically, we initialize the transmission of a\ndeep-compressed general semantic representation from the transmitter to enable\ndiffusion-based coarse data reconstruction at the receiver. The receiver\nidentifies the task-specific demands and generates textual prompts as feedback.\nIntegrated with the attention mechanism, the transmitter updates the semantic\ntransmission with more details to better align with the objectives of the\nintended receivers. Our test results demonstrate the efficacy of the proposed\nmethod in adaptively preserving critical task-relevant information for semantic\ncommunications while preserving high compression efficiency.", "published": "2025-05-12 18:23:53", "link": "http://arxiv.org/abs/2505.07980v1", "categories": ["cs.CL", "C.2.1; I.4.8"], "primary_category": "cs.CL"}
{"title": "Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models", "abstract": "Large Language Models (LLMs) have great potential in the field of health\ncare, yet they face great challenges in adapting to rapidly evolving medical\nknowledge. This can lead to outdated or contradictory treatment suggestions.\nThis study investigated how LLMs respond to evolving clinical guidelines,\nfocusing on concept drift and internal inconsistencies. We developed the\nDriftMedQA benchmark to simulate guideline evolution and assessed the temporal\nreliability of various LLMs. Our evaluation of seven state-of-the-art models\nacross 4,290 scenarios demonstrated difficulties in rejecting outdated\nrecommendations and frequently endorsing conflicting guidance. Additionally, we\nexplored two mitigation strategies: Retrieval-Augmented Generation and\npreference fine-tuning via Direct Preference Optimization. While each method\nimproved model performance, their combination led to the most consistent and\nreliable results. These findings underscore the need to improve LLM robustness\nto temporal shifts to ensure more dependable applications in clinical practice.", "published": "2025-05-12 18:08:02", "link": "http://arxiv.org/abs/2505.07968v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Re$^2$: A Consistency-ensured Dataset for Full-stage Peer Review and Multi-turn Rebuttal Discussions", "abstract": "Peer review is a critical component of scientific progress in the fields like\nAI, but the rapid increase in submission volume has strained the reviewing\nsystem, which inevitably leads to reviewer shortages and declines review\nquality. Besides the growing research popularity, another key factor in this\noverload is the repeated resubmission of substandard manuscripts, largely due\nto the lack of effective tools for authors to self-evaluate their work before\nsubmission. Large Language Models (LLMs) show great promise in assisting both\nauthors and reviewers, and their performance is fundamentally limited by the\nquality of the peer review data. However, existing peer review datasets face\nthree major limitations: (1) limited data diversity, (2) inconsistent and\nlow-quality data due to the use of revised rather than initial submissions, and\n(3) insufficient support for tasks involving rebuttal and reviewer-author\ninteractions. To address these challenges, we introduce the largest\nconsistency-ensured peer review and rebuttal dataset named Re^2, which\ncomprises 19,926 initial submissions, 70,668 review comments, and 53,818\nrebuttals from 24 conferences and 21 workshops on OpenReview. Moreover, the\nrebuttal and discussion stage is framed as a multi-turn conversation paradigm\nto support both traditional static review tasks and dynamic interactive LLM\nassistants, providing more practical guidance for authors to refine their\nmanuscripts and helping alleviate the growing review burden. Our data and code\nare available in https://anonymous.4open.science/r/ReviewBench_anon/.", "published": "2025-05-12 16:02:52", "link": "http://arxiv.org/abs/2505.07920v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "SciCom Wiki: Fact-Checking and FAIR Knowledge Distribution for Scientific Videos and Podcasts", "abstract": "Democratic societies need accessible, reliable information. Videos and\nPodcasts have established themselves as the medium of choice for civic\ndissemination, but also as carriers of misinformation. The emerging Science\nCommunication Knowledge Infrastructure (SciCom KI) curating non-textual media\nis still fragmented and not adequately equipped to scale against the content\nflood. Our work sets out to support the SciCom KI with a central, collaborative\nplatform, the SciCom Wiki, to facilitate FAIR (findable, accessible,\ninteroperable, reusable) media representation and the fact-checking of their\ncontent, particularly for videos and podcasts. Building an open-source service\nsystem centered around Wikibase, we survey requirements from 53 stakeholders,\nrefine these in 11 interviews, and evaluate our prototype based on these\nrequirements with another 14 participants. To address the most requested\nfeature, fact-checking, we developed a neurosymbolic computational\nfact-checking approach, converting heterogenous media into knowledge graphs.\nThis increases machine-readability and allows comparing statements against\nequally represented ground-truth. Our computational fact-checking tool was\niteratively evaluated through 10 expert interviews, a public user survey with\n43 participants verified the necessity and usability of our tool. Overall, our\nfindings identified several needs to systematically support the SciCom KI. The\nSciCom Wiki, as a FAIR digital library complementing our neurosymbolic\ncomputational fact-checking framework, was found suitable to address the raised\nrequirements. Further, we identified that the SciCom KI is severely\nunderdeveloped regarding FAIR knowledge and related systems facilitating its\ncollaborative creation and curation. Our system can provide a central knowledge\nnode, yet a collaborative effort is required to scale against the imminent\n(mis-)information flood.", "published": "2025-05-12 13:38:20", "link": "http://arxiv.org/abs/2505.07912v1", "categories": ["cs.DL", "cs.CL", "cs.MM"], "primary_category": "cs.DL"}
{"title": "A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny", "abstract": "In this reproduction study, we revisit recent claims that self-attention\nimplements kernel principal component analysis (KPCA) (Teo et al., 2024),\npositing that (i) value vectors $V$ capture the eigenvectors of the Gram matrix\nof the keys, and (ii) that self-attention projects queries onto the principal\ncomponent axes of the key matrix $K$ in a feature space. Our analysis reveals\nthree critical inconsistencies: (1) No alignment exists between learned\nself-attention value vectors and what is proposed in the KPCA perspective, with\naverage similarity metrics (optimal cosine similarity $\\leq 0.32$, linear CKA\n(Centered Kernel Alignment) $\\leq 0.11$, kernel CKA $\\leq 0.32$) indicating\nnegligible correspondence; (2) Reported decreases in reconstruction loss\n$J_\\text{proj}$, arguably justifying the claim that the self-attention\nminimizes the projection error of KPCA, are misinterpreted, as the quantities\ninvolved differ by orders of magnitude ($\\sim\\!10^3$); (3) Gram matrix\neigenvalue statistics, introduced to justify that $V$ captures the eigenvector\nof the gram matrix, are irreproducible without undocumented\nimplementation-specific adjustments. Across 10 transformer architectures, we\nconclude that the KPCA interpretation of self-attention lacks empirical\nsupport.", "published": "2025-05-12 12:38:46", "link": "http://arxiv.org/abs/2505.07908v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "SEM: Reinforcement Learning for Search-Efficient Large Language Models", "abstract": "Recent advancements in Large Language Models(LLMs) have demonstrated their\ncapabilities not only in reasoning but also in invoking external tools,\nparticularly search engines. However, teaching models to discern when to invoke\nsearch and when to rely on their internal knowledge remains a significant\nchallenge. Existing reinforcement learning approaches often lead to redundant\nsearch behaviors, resulting in inefficiencies and over-cost. In this paper, we\npropose SEM, a novel post-training reinforcement learning framework that\nexplicitly trains LLMs to optimize search usage. By constructing a balanced\ndataset combining MuSiQue and MMLU, we create scenarios where the model must\nlearn to distinguish between questions it can answer directly and those\nrequiring external retrieval. We design a structured reasoning template and\nemploy Group Relative Policy Optimization(GRPO) to post-train the model's\nsearch behaviors. Our reward function encourages accurate answering without\nunnecessary search while promoting effective retrieval when needed.\nExperimental results demonstrate that our method significantly reduces\nredundant search operations while maintaining or improving answer accuracy\nacross multiple challenging benchmarks. This framework advances the model's\nreasoning efficiency and extends its capability to judiciously leverage\nexternal knowledge.", "published": "2025-05-12 09:45:40", "link": "http://arxiv.org/abs/2505.07903v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multimodal Assessment of Classroom Discourse Quality: A Text-Centered Attention-Based Multi-Task Learning Approach", "abstract": "Classroom discourse is an essential vehicle through which teaching and\nlearning take place. Assessing different characteristics of discursive\npractices and linking them to student learning achievement enhances the\nunderstanding of teaching quality. Traditional assessments rely on manual\ncoding of classroom observation protocols, which is time-consuming and costly.\nDespite many studies utilizing AI techniques to analyze classroom discourse at\nthe utterance level, investigations into the evaluation of discursive practices\nthroughout an entire lesson segment remain limited. To address this gap, our\nstudy proposes a novel text-centered multimodal fusion architecture to assess\nthe quality of three discourse components grounded in the Global Teaching\nInSights (GTI) observation protocol: Nature of Discourse, Questioning, and\nExplanations. First, we employ attention mechanisms to capture inter- and\nintra-modal interactions from transcript, audio, and video streams. Second, a\nmulti-task learning approach is adopted to jointly predict the quality scores\nof the three components. Third, we formulate the task as an ordinal\nclassification problem to account for rating level order. The effectiveness of\nthese designed elements is demonstrated through an ablation study on the GTI\nGermany dataset containing 92 videotaped math lessons. Our results highlight\nthe dominant role of text modality in approaching this task. Integrating\nacoustic features enhances the model's consistency with human ratings,\nachieving an overall Quadratic Weighted Kappa score of 0.384, comparable to\nhuman inter-rater reliability (0.326). Our study lays the groundwork for the\nfuture development of automated discourse quality assessment to support teacher\nprofessional development through timely feedback on multidimensional discourse\npractices.", "published": "2025-05-12 09:24:21", "link": "http://arxiv.org/abs/2505.07902v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise", "abstract": "Sequential knowledge editing techniques aim to continuously update the\nknowledge in large language models at a low cost, preventing the models from\ngenerating outdated or incorrect information. However, existing sequential\nediting methods suffer from a significant decline in editing success rates\nafter long-term editing. Through theoretical analysis and experiments, we\nidentify that as the number of edits increases, the model's output increasingly\ndeviates from the desired target, leading to a drop in editing success rates.\nWe refer to this issue as the accumulation of superimposed noise problem. To\naddress this, we identify the factors contributing to this deviation and\npropose DeltaEdit, a novel method that optimizes update parameters through a\ndynamic orthogonal constraints strategy, effectively reducing interference\nbetween edits to mitigate deviation. Experimental results demonstrate that\nDeltaEdit significantly outperforms existing methods in edit success rates and\nthe retention of generalization capabilities, ensuring stable and reliable\nmodel performance even under extensive sequential editing.", "published": "2025-05-12 07:11:26", "link": "http://arxiv.org/abs/2505.07899v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LongCodeBench: Evaluating Coding LLMs at 1M Context Windows", "abstract": "Context lengths for models have grown rapidly, from thousands to millions of\ntokens in just a few years. The extreme context sizes of modern long-context\nmodels have made it difficult to construct realistic long-context benchmarks --\nnot only due to the cost of collecting million-context tasks but also in\nidentifying realistic scenarios that require significant contexts. We identify\ncode comprehension and repair as a natural testbed and challenge task for\nlong-context models and introduce LongCodeBench (LCB), a benchmark to test LLM\ncoding abilities in long-context scenarios. Our benchmark tests both the\ncomprehension and repair capabilities of LCLMs in realistic and important\nsettings by drawing from real-world GitHub issues and constructing QA\n(LongCodeQA) and bug fixing (LongSWE-Bench) tasks. We carefully stratify the\ncomplexity of our benchmark, enabling us to evaluate models across different\nscales -- ranging from Qwen2.5 14B Instruct to Google's flagship Gemini model.\nWe find that long-context remains a weakness for all models, with performance\ndrops such as from 29% to 3% for Claude 3.5 Sonnet, or from 70.2% to 40% for\nQwen2.5.", "published": "2025-05-12 05:38:03", "link": "http://arxiv.org/abs/2505.07897v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SLAG: Scalable Language-Augmented Gaussian Splatting", "abstract": "Language-augmented scene representations hold great promise for large-scale\nrobotics applications such as search-and-rescue, smart cities, and mining. Many\nof these scenarios are time-sensitive, requiring rapid scene encoding while\nalso being data-intensive, necessitating scalable solutions. Deploying these\nrepresentations on robots with limited computational resources further adds to\nthe challenge. To address this, we introduce SLAG, a multi-GPU framework for\nlanguage-augmented Gaussian splatting that enhances the speed and scalability\nof embedding large scenes. Our method integrates 2D visual-language model\nfeatures into 3D scenes using SAM and CLIP. Unlike prior approaches, SLAG\neliminates the need for a loss function to compute per-Gaussian language\nembeddings. Instead, it derives embeddings from 3D Gaussian scene parameters\nvia a normalized weighted average, enabling highly parallelized scene encoding.\nAdditionally, we introduce a vector database for efficient embedding storage\nand retrieval. Our experiments show that SLAG achieves an 18 times speedup in\nembedding computation on a 16-GPU setup compared to OpenGaussian, while\npreserving embedding quality on the ScanNet and LERF datasets. For more\ndetails, visit our project website: https://slag-project.github.io/.", "published": "2025-05-12 23:32:24", "link": "http://arxiv.org/abs/2505.08124v1", "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "cs.CV"}
{"title": "JSover: Joint Spectrum Estimation and Multi-Material Decomposition from Single-Energy CT Projections", "abstract": "Multi-material decomposition (MMD) enables quantitative reconstruction of\ntissue compositions in the human body, supporting a wide range of clinical\napplications. However, traditional MMD typically requires spectral CT scanners\nand pre-measured X-ray energy spectra, significantly limiting clinical\napplicability. To this end, various methods have been developed to perform MMD\nusing conventional (i.e., single-energy, SE) CT systems, commonly referred to\nas SEMMD. Despite promising progress, most SEMMD methods follow a two-step\nimage decomposition pipeline, which first reconstructs monochromatic CT images\nusing algorithms such as FBP, and then performs decomposition on these images.\nThe initial reconstruction step, however, neglects the energy-dependent\nattenuation of human tissues, introducing severe nonlinear beam hardening\nartifacts and noise into the subsequent decomposition. This paper proposes\nJSover, a fundamentally reformulated one-step SEMMD framework that jointly\nreconstructs multi-material compositions and estimates the energy spectrum\ndirectly from SECT projections. By explicitly incorporating physics-informed\nspectral priors into the SEMMD process, JSover accurately simulates a virtual\nspectral CT system from SE acquisitions, thereby improving the reliability and\naccuracy of decomposition. Furthermore, we introduce implicit neural\nrepresentation (INR) as an unsupervised deep learning solver for representing\nthe underlying material maps. The inductive bias of INR toward continuous image\npatterns constrains the solution space and further enhances estimation quality.\nExtensive experiments on both simulated and real CT datasets show that JSover\noutperforms state-of-the-art SEMMD methods in accuracy and computational\nefficiency.", "published": "2025-05-12 23:32:21", "link": "http://arxiv.org/abs/2505.08123v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Asynchronous Multi-Object Tracking with an Event Camera", "abstract": "Events cameras are ideal sensors for enabling robots to detect and track\nobjects in highly dynamic environments due to their low latency output, high\ntemporal resolution, and high dynamic range. In this paper, we present the\nAsynchronous Event Multi-Object Tracking (AEMOT) algorithm for detecting and\ntracking multiple objects by processing individual raw events asynchronously.\nAEMOT detects salient event blob features by identifying regions of consistent\noptical flow using a novel Field of Active Flow Directions built from the\nSurface of Active Events. Detected features are tracked as candidate objects\nusing the recently proposed Asynchronous Event Blob (AEB) tracker in order to\nconstruct small intensity patches of each candidate object. A novel learnt\nvalidation stage promotes or discards candidate objects based on classification\nof their intensity patches, with promoted objects having their position,\nvelocity, size, and orientation estimated at their event rate. We evaluate\nAEMOT on a new Bee Swarm Dataset, where it tracks dozens of small bees with\nprecision and recall performance exceeding that of alternative event-based\ndetection and tracking algorithms by over 37%. Source code and the labelled\nevent Bee Swarm Dataset will be open sourced", "published": "2025-05-12 23:53:08", "link": "http://arxiv.org/abs/2505.08126v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Now you see it, Now you don't: Damage Label Agreement in Drone & Satellite Post-Disaster Imagery", "abstract": "This paper audits damage labels derived from coincident satellite and drone\naerial imagery for 15,814 buildings across Hurricanes Ian, Michael, and Harvey,\nfinding 29.02% label disagreement and significantly different distributions\nbetween the two sources, which presents risks and potential harms during the\ndeployment of machine learning damage assessment systems. Currently, there is\nno known study of label agreement between drone and satellite imagery for\nbuilding damage assessment. The only prior work that could be used to infer if\nsuch imagery-derived labels agree is limited by differing damage label schemas,\nmisaligned building locations, and low data quantities. This work overcomes\nthese limitations by comparing damage labels using the same damage label\nschemas and building locations from three hurricanes, with the 15,814 buildings\nrepresenting 19.05 times more buildings considered than the most relevant prior\nwork. The analysis finds satellite-derived labels significantly under-report\ndamage by at least 20.43% compared to drone-derived labels (p<1.2x10^-117), and\nsatellite- and drone-derived labels represent significantly different\ndistributions (p<5.1x10^-175). This indicates that computer vision and machine\nlearning (CV/ML) models trained on at least one of these distributions will\nmisrepresent actual conditions, as the differing satellite and drone-derived\ndistributions cannot simultaneously represent the distribution of actual\nconditions in a scene. This potential misrepresentation poses ethical risks and\npotential societal harm if not managed. To reduce the risk of future societal\nharms, this paper offers four recommendations to improve reliability and\ntransparency to decisio-makers when deploying CV/ML damage assessment systems\nin practice", "published": "2025-05-12 23:17:00", "link": "http://arxiv.org/abs/2505.08117v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Sleep Position Classification using Transfer Learning for Bed-based Pressure Sensors", "abstract": "Bed-based pressure-sensitive mats (PSMs) offer a non-intrusive way of\nmonitoring patients during sleep. We focus on four-way sleep position\nclassification using data collected from a PSM placed under a mattress in a\nsleep clinic. Sleep positions can affect sleep quality and the prevalence of\nsleep disorders, such as apnea. Measurements were performed on patients with\nsuspected sleep disorders referred for assessments at a sleep clinic. Training\ndeep learning models can be challenging in clinical settings due to the need\nfor large amounts of labeled data. To overcome the shortage of labeled training\ndata, we utilize transfer learning to adapt pre-trained deep learning models to\naccurately estimate sleep positions from a low-resolution PSM dataset collected\nin a polysomnography sleep lab. Our approach leverages Vision Transformer\nmodels pre-trained on ImageNet using masked autoencoding (ViTMAE) and a\npre-trained model for human pose estimation (ViTPose). These approaches\noutperform previous work from PSM-based sleep pose classification using deep\nlearning (TCN) as well as traditional machine learning models (SVM, XGBoost,\nRandom Forest) that use engineered features. We evaluate the performance of\nsleep position classification from 112 nights of patient recordings and\nvalidate it on a higher resolution 13-patient dataset. Despite the challenges\nof differentiating between sleep positions from low-resolution PSM data, our\napproach shows promise for real-world deployment in clinical settings", "published": "2025-05-12 22:54:03", "link": "http://arxiv.org/abs/2505.08111v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Topology-Guided Knowledge Distillation for Efficient Point Cloud Processing", "abstract": "Point cloud processing has gained significant attention due to its critical\nrole in applications such as autonomous driving and 3D object recognition.\nHowever, deploying high-performance models like Point Transformer V3 in\nresource-constrained environments remains challenging due to their high\ncomputational and memory demands. This work introduces a novel distillation\nframework that leverages topology-aware representations and gradient-guided\nknowledge distillation to effectively transfer knowledge from a high-capacity\nteacher to a lightweight student model. Our approach captures the underlying\ngeometric structures of point clouds while selectively guiding the student\nmodel's learning process through gradient-based feature alignment. Experimental\nresults in the Nuscenes, SemanticKITTI, and Waymo datasets demonstrate that the\nproposed method achieves competitive performance, with an approximately 16x\nreduction in model size and a nearly 1.9x decrease in inference time compared\nto its teacher model. Notably, on NuScenes, our method achieves\nstate-of-the-art performance among knowledge distillation techniques trained\nsolely on LiDAR data, surpassing prior knowledge distillation baselines in\nsegmentation performance. Our implementation is available publicly at:\n  https://github.com/HySonLab/PointDistill", "published": "2025-05-12 22:15:54", "link": "http://arxiv.org/abs/2505.08101v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Multi-modal wound classification using wound image and location by Xception and Gaussian Mixture Recurrent Neural Network (GMRNN)", "abstract": "The effective diagnosis of acute and hard-to-heal wounds is crucial for wound\ncare practitioners to provide effective patient care. Poor clinical outcomes\nare often linked to infection, peripheral vascular disease, and increasing\nwound depth, which collectively exacerbate these comorbidities. However,\ndiagnostic tools based on Artificial Intelligence (AI) speed up the\ninterpretation of medical images and improve early detection of disease. In\nthis article, we propose a multi-modal AI model based on transfer learning\n(TL), which combines two state-of-the-art architectures, Xception and GMRNN,\nfor wound classification. The multi-modal network is developed by concatenating\nthe features extracted by a transfer learning algorithm and location features\nto classify the wound types of diabetic, pressure, surgical, and venous ulcers.\nThe proposed method is comprehensively compared with deep neural networks (DNN)\nfor medical image analysis. The experimental results demonstrate a notable\nwound-class classifications (containing only diabetic, pressure, surgical, and\nvenous) vary from 78.77 to 100\\% in various experiments. The results presented\nin this study showcase the exceptional accuracy of the proposed methodology in\naccurately classifying the most commonly occurring wound types using wound\nimages and their corresponding locations.", "published": "2025-05-12 21:44:03", "link": "http://arxiv.org/abs/2505.08086v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Visually Interpretable Subtask Reasoning for Visual Question Answering", "abstract": "Answering complex visual questions like `Which red furniture can be used for\nsitting?' requires multi-step reasoning, including object recognition,\nattribute filtering, and relational understanding. Recent work improves\ninterpretability in multimodal large language models (MLLMs) by decomposing\ntasks into sub-task programs, but these methods are computationally expensive\nand less accurate due to poor adaptation to target data. To address this, we\nintroduce VISTAR (Visually Interpretable Subtask-Aware Reasoning Model), a\nsubtask-driven training framework that enhances both interpretability and\nreasoning by generating textual and visual explanations within MLLMs. Instead\nof relying on external models, VISTAR fine-tunes MLLMs to produce structured\nSubtask-of-Thought rationales (step-by-step reasoning sequences). Experiments\non two benchmarks show that VISTAR consistently improves reasoning accuracy\nwhile maintaining interpretability. Our code and dataset will be available at\nhttps://github.com/ChengJade/VISTAR.", "published": "2025-05-12 21:37:06", "link": "http://arxiv.org/abs/2505.08084v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Fr\u00e9chet Power-Scenario Distance: A Metric for Evaluating Generative AI Models across Multiple Time-Scales in Smart Grids", "abstract": "Generative artificial intelligence (AI) models in smart grids have advanced\nsignificantly in recent years due to their ability to generate large amounts of\nsynthetic data, which would otherwise be difficult to obtain in the real world\ndue to confidentiality constraints. A key challenge in utilizing such synthetic\ndata is how to assess the data quality produced from such generative models.\nTraditional Euclidean distance-based metrics only reflect pair-wise relations\nbetween two individual samples, and could fail in evaluating quality\ndifferences between groups of synthetic datasets. In this work, we propose a\nnovel metric based on the Fr\\'{e}chet Distance (FD) estimated between two\ndatasets in a learned feature space. The proposed method evaluates the quality\nof generation from a distributional perspective. Empirical results demonstrate\nthe superiority of the proposed metric across timescales and models, enhancing\nthe reliability of data-driven decision-making in smart grid operations.", "published": "2025-05-12 21:32:23", "link": "http://arxiv.org/abs/2505.08082v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.SP"], "primary_category": "cs.LG"}
{"title": "RDD: Robust Feature Detector and Descriptor using Deformable Transformer", "abstract": "As a core step in structure-from-motion and SLAM, robust feature detection\nand description under challenging scenarios such as significant viewpoint\nchanges remain unresolved despite their ubiquity. While recent works have\nidentified the importance of local features in modeling geometric\ntransformations, these methods fail to learn the visual cues present in\nlong-range relationships. We present Robust Deformable Detector (RDD), a novel\nand robust keypoint detector/descriptor leveraging the deformable transformer,\nwhich captures global context and geometric invariance through deformable\nself-attention mechanisms. Specifically, we observed that deformable attention\nfocuses on key locations, effectively reducing the search space complexity and\nmodeling the geometric invariance. Furthermore, we collected an Air-to-Ground\ndataset for training in addition to the standard MegaDepth dataset. Our\nproposed method outperforms all state-of-the-art keypoint detection/description\nmethods in sparse matching tasks and is also capable of semi-dense matching. To\nensure comprehensive evaluation, we introduce two challenging benchmarks: one\nemphasizing large viewpoint and scale variations, and the other being an\nAir-to-Ground benchmark -- an evaluation setting that has recently gaining\npopularity for 3D reconstruction across different altitudes.", "published": "2025-05-12 19:24:45", "link": "http://arxiv.org/abs/2505.08013v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Vision Foundation Model Embedding-Based Semantic Anomaly Detection", "abstract": "Semantic anomalies are contextually invalid or unusual combinations of\nfamiliar visual elements that can cause undefined behavior and failures in\nsystem-level reasoning for autonomous systems. This work explores semantic\nanomaly detection by leveraging the semantic priors of state-of-the-art vision\nfoundation models, operating directly on the image. We propose a framework that\ncompares local vision embeddings from runtime images to a database of nominal\nscenarios in which the autonomous system is deemed safe and performant. In this\nwork, we consider two variants of the proposed framework: one using raw\ngrid-based embeddings, and another leveraging instance segmentation for\nobject-centric representations. To further improve robustness, we introduce a\nsimple filtering mechanism to suppress false positives. Our evaluations on\nCARLA-simulated anomalies show that the instance-based method with filtering\nachieves performance comparable to GPT-4o, while providing precise anomaly\nlocalization. These results highlight the potential utility of vision\nembeddings from foundation models for real-time anomaly detection in autonomous\nsystems.", "published": "2025-05-12 19:00:29", "link": "http://arxiv.org/abs/2505.07998v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MilChat: Introducing Chain of Thought Reasoning and GRPO to a Multimodal Small Language Model for Remote Sensing", "abstract": "Remarkable capabilities in understanding and generating text-image content\nhave been demonstrated by recent advancements in multimodal large language\nmodels (MLLMs). However, their effectiveness in specialized\ndomains-particularly those requiring resource-efficient and domain-specific\nadaptations-has remained limited. In this work, a lightweight multimodal\nlanguage model termed MilChat is introduced, specifically adapted to analyze\nremote sensing imagery in secluded areas, including challenging missile launch\nsites. A new dataset, MilData, was compiled by verifying hundreds of aerial\nimages through expert review, and subtle military installations were\nhighlighted via detailed captions. Supervised fine-tuning on a 2B-parameter\nopen-source MLLM with chain-of-thought (CoT) reasoning annotations was\nperformed, enabling more accurate and interpretable explanations. Additionally,\nGroup Relative Policy Optimization (GRPO) was leveraged to enhance the model's\nability to detect critical domain-specific cues-such as defensive layouts and\nkey military structures-while minimizing false positives on civilian scenes.\nThrough empirical evaluations, it has been shown that MilChat significantly\noutperforms both larger, general-purpose multimodal models and existing remote\nsensing-adapted approaches on open-ended captioning and classification metrics.\nOver 80% recall and 98% precision were achieved on the newly proposed MilData\nbenchmark, underscoring the potency of targeted fine-tuning and reinforcement\nlearning in specialized real-world applications.", "published": "2025-05-12 18:30:02", "link": "http://arxiv.org/abs/2505.07984v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "QUEST: QUantum-Enhanced Shared Transportation", "abstract": "We introduce ``Windbreaking-as-a-Service'' (WaaS) as an innovative approach\nto shared transportation in which larger ``windbreaker'' vehicles provide\naerodynamic shelter for ``windsurfer'' vehicles, thereby reducing drag and fuel\nconsumption. As a computational framework to solve the large-scale matching and\nassignment problems that arise in WaaS, we present \\textbf{QUEST}\n(Quantum-Enhanced Shared Transportation). Specifically, we formulate the\npairing of windbreakers and windsurfers -- subject to timing, speed, and\nvehicle-class constraints -- as a mixed-integer quadratic problem (MIQP).\nFocusing on a single-segment prototype, we verify the solution classically via\nthe Hungarian Algorithm, a Gurobi-based solver, and brute-force enumeration of\nbinary vectors. We then encode the problem as a Quadratic Unconstrained Binary\nOptimization (QUBO) and map it to an Ising Hamiltonian, enabling the use of the\nQuantum Approximate Optimization Algorithm (QAOA) and other quantum and\nclassical annealing technologies. Our quantum implementation successfully\nrecovers the optimal assignment identified by the classical methods, confirming\nthe soundness of the QUEST pipeline for a controlled prototype. While QAOA and\nother quantum heuristics do not guarantee a resolution of the fundamental\ncomplexity barriers, this study illustrates how the WaaS problem can be\nsystematically translated into a quantum-ready model. It also lays the\ngroundwork for addressing multi-segment scenarios and potentially leveraging\nquantum advantage for large-scale shared-transportation instances.", "published": "2025-05-12 21:19:19", "link": "http://arxiv.org/abs/2505.08074v1", "categories": ["quant-ph", "cs.CE", "cs.DM", "physics.app-ph", "physics.comp-ph"], "primary_category": "quant-ph"}
{"title": "Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation", "abstract": "Biomedical question-answering (QA) systems require effective retrieval and\ngeneration components to ensure accuracy, efficiency, and scalability. This\nstudy systematically examines a Retrieval-Augmented Generation (RAG) system for\nbiomedical QA, evaluating retrieval strategies and response time trade-offs. We\nfirst assess state-of-the-art retrieval methods, including BM25, BioBERT,\nMedCPT, and a hybrid approach, alongside common data stores such as\nElasticsearch, MongoDB, and FAISS, on a ~10% subset of PubMed (2.4M documents)\nto measure indexing efficiency, retrieval latency, and retriever performance in\nthe end-to-end RAG system. Based on these insights, we deploy the final RAG\nsystem on the full 24M PubMed corpus, comparing different retrievers' impact on\noverall performance. Evaluations of the retrieval depth show that retrieving 50\ndocuments with BM25 before reranking with MedCPT optimally balances accuracy\n(0.90), recall (0.90), and response time (1.91s). BM25 retrieval time remains\nstable (82ms), while MedCPT incurs the main computational cost. These results\nhighlight previously not well-known trade-offs in retrieval depth, efficiency,\nand scalability for biomedical QA. With open-source code, the system is fully\nreproducible and extensible.", "published": "2025-05-12 14:51:47", "link": "http://arxiv.org/abs/2505.07917v1", "categories": ["cs.IR", "cs.AI", "cs.DB", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Zak-OTFS for Spread Spectrum Communication", "abstract": "An attractive feature of spread spectrum technologies such as code division\nmultiple access (CDMA) is that it is harder to intercept or jam signals, and\nthis feature was lost when orthogonal frequency domain modulation prevailed\nover CDMA in wireless standards. Legacy spread carrier waveforms are not\nmatched to delay and Doppler shifts characteristic of 6G wireless environments,\nand this makes equalization very challenging. Zak-OTFS modulation is a\ncommunication framework that parameterizes the wireless channel in the\ndelay-Doppler (DD) domain, where the parameters map directly to physical\nattributes of the scatterers that comprise the scattering environment. Hence,\nthe channel can be efficiently acquired and equalized. The Zak-OTFS carrier is\na pulse in the DD domain, and the Zak transform converts it to a pulse train\nmodulated by a tone (pulsone) in the time domain. The pulsone waveform is\nlocalized rather than spread, and it suffers from high PAPR. We describe how to\ntransform Zak-OTFS into a spread spectrum communication system, where the\nspread carrier waveforms have low PAPR and are matched to the delay and Doppler\ncharacteristics of the wireless channel. This transformation is realized by a\nunitary transform that is a generalization of the discrete affine Fourier\ntransform. The transform maps a pulsone to a time domain waveform which yields\na CAZAC sequence after sampling. The family of CAZAC sequences includes the\nZadoff-Chu sequences incorporated in LTE and 5G-NR standards. We describe the\nend-to-end time-domain transceiver signal processing, comprising channel\nestimation and data demodulation, for the proposed system. We quantify system\nperformance through BER simulations using a six-path Veh-A channel model,\nshowing that the proposed system achieves similar uncoded BER as pulsone-based\nZak-OTFS, where the PAPR of each spread carrier waveform is only 3.58 dB.", "published": "2025-05-12 21:28:14", "link": "http://arxiv.org/abs/2505.08079v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "eess.SP"}
{"title": "Intelligent Polarforming Antenna Enhanced Sensing and Communication: Modeling and Optimization", "abstract": "In this paper, we propose a novel intelligent polarforming antenna (IPA) to\nachieve cost-effective wireless sensing and communication. Specifically, the\nIPA can enable polarforming by adaptively controlling the antenna's\npolarization electrically as well as its position/rotation mechanically, so as\nto effectively exploit polarization and spatial diversity to reconfigure\nwireless channels for improving sensing and communication performance. We study\nan IPA-enhanced integrated sensing and communication (ISAC) system that\nutilizes user location sensing to facilitate communication between an\nIPA-equipped base station (BS) and IPA-equipped users. First, we model the IPA\nchannel in terms of transceiver antenna polarforming vectors and antenna\npositions/rotations. We then propose a two-timescale ISAC protocol, where in\nthe slow timescale, user localization is first performed, followed by the\noptimization of the BS antennas' positions and rotations based on the sensed\nuser locations; subsequently, in the fast timescale, transceiver polarforming\nis adapted to cater to the instantaneous channel state information (CSI), with\nthe optimized BS antennas' positions and rotations. We propose a new\npolarforming-based user localization method that uses a structured time-domain\npattern of pilot-polarforming vectors to extract the common stable components\nin the IPA channel across different polarizations based on the parallel factor\n(PARAFAC) tensor model. Moreover, we maximize the achievable average sum-rate\nof users by jointly optimizing the fast-timescale transceiver polarforming,\nincluding phase shifts and amplitude variations, along with the slow-timescale\nantenna rotations and positions at the BS. Simulation results validate the\neffectiveness of polarforming-based localization algorithm and demonstrate the\nperformance advantages of polarforming, antenna placement, and their joint\ndesign.", "published": "2025-05-12 21:15:40", "link": "http://arxiv.org/abs/2505.08070v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Generalized LDPC codes with low-complexity decoding and fast convergence", "abstract": "We consider generalized low-density parity-check (GLDPC) codes with component\ncodes that are duals of Cordaro-Wagner codes. Two efficient decoding algorithms\nare proposed: one based on Hartmann-Rudolph processing, analogous to\nSum-Product decoding, and another based on evaluating two hypotheses per bit,\nreferred to as the Min-Sum decoder. Both algorithms are derived using latent\nvariables and an appropriate message-passing schedule. A quantized,\nprotograph-based density evolution procedure is used to optimize GLDPC codes\nfor Min-Sum decoding. Compared to 5G LDPC codes, the proposed GLDPC codes offer\nsimilar performance at 50 iterations and significantly better convergence and\nperformance at 10 iterations.", "published": "2025-05-12 19:54:59", "link": "http://arxiv.org/abs/2505.08030v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Limitations to Computing Quadratic Functions on Reed-Solomon Encoded Data", "abstract": "We study the problem of low-bandwidth non-linear computation on Reed-Solomon\nencoded data. Given an $[n,k]$ Reed-Solomon encoding of a message vector\n$\\vec{f} \\in \\mathbb{F}_q^k$, and a polynomial $g \\in \\mathbb{F}_q[X_1, X_2,\n\\ldots, X_k]$, a user wishing to evaluate $g(\\vec{f})$ is given local query\naccess to each codeword symbol. The query response is allowed to be the output\nof an arbitrary function evaluated locally on the codeword symbol, and the\nuser's aim is to minimize the total information downloaded in order to compute\n$g(\\vec{f})$.\n  We show that when $k=2$ and $q = p^e$ for odd $e$ and prime $p$ satisfying\n$p\\equiv 3 \\mod 4$, then any scheme that evaluates the quadratic monomial\n$g(X_1, X_2) := X_1 X_2$ must download at least $2\\lceil \\log_2(q-1) \\rceil -\n3$ bits of information. Compare this with the straightforward scheme of\nReed-Solomon interpolation which recovers $\\vec{f}$ in its entirety, which\ndownloads $2 \\lceil \\log_2(q) \\rceil$ bits. Our result shows that dimension-2\nReed-Solomon codes do not admit any meaningful low-bandwidth scheme for the\nevaluation of quadratic functions over the encoded data. This contrasts sharply\nwith prior work for low-bandwidth evaluation of linear functions $g(\\vec{f})$\nover Reed-Solomon encoded data, for which it is possible to substantially\nimprove upon the naive bound of $k \\lceil \\log_2(q) \\rceil$ bits.", "published": "2025-05-12 19:02:08", "link": "http://arxiv.org/abs/2505.08000v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sharp Gaussian approximations for Decentralized Federated Learning", "abstract": "Federated Learning has gained traction in privacy-sensitive collaborative\nenvironments, with local SGD emerging as a key optimization method in\ndecentralized settings. While its convergence properties are well-studied,\nasymptotic statistical guarantees beyond convergence remain limited. In this\npaper, we present two generalized Gaussian approximation results for local SGD\nand explore their implications. First, we prove a Berry-Esseen theorem for the\nfinal local SGD iterates, enabling valid multiplier bootstrap procedures.\nSecond, motivated by robustness considerations, we introduce two distinct\ntime-uniform Gaussian approximations for the entire trajectory of local SGD.\nThe time-uniform approximations support Gaussian bootstrap-based tests for\ndetecting adversarial attacks. Extensive simulations are provided to support\nour theoretical results.", "published": "2025-05-12 23:40:13", "link": "http://arxiv.org/abs/2505.08125v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Fused3S: Fast Sparse Attention on Tensor Cores", "abstract": "Sparse attention is a core building block in many leading neural network\nmodels, from graph-structured learning to sparse sequence modeling. It can be\ndecomposed into a sequence of three sparse matrix operations (3S): sampled\ndense-dense matrix multiplication (SDDMM), softmax normalization, and sparse\nmatrix multiplication (SpMM). Efficiently executing the 3S computational\npattern on modern GPUs remains challenging due to (a) the mismatch between\nunstructured sparsity and tensor cores optimized for dense operations, and (b)\nthe high cost of data movement. Previous works have optimized these sparse\noperations individually or addressed one of these challenges. This paper\nintroduces Fused3S, the first fused 3S algorithm that jointly maximizes tensor\ncore utilization and minimizes data movement. Across real-world graph datasets,\nFused3S achieves $1.6- 16.3\\times$ and $1.5-14\\times$ speedup over\nstate-of-the-art on H100 and A30 GPUs. Furthermore, integrating Fused3S into\nGraph Transformer inference accelerates end-to-end performance by\n$1.05-5.36\\times$, consistently outperforming all 3S baselines across diverse\ndatasets (single and batched graphs) and GPU architectures.", "published": "2025-05-12 22:09:05", "link": "http://arxiv.org/abs/2505.08098v1", "categories": ["cs.DC", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories", "abstract": "Indoor positioning systems (IPSs) are increasingly vital for location-based\nservices in complex multi-storey environments. This study proposes a novel\ngraph-based approach for floor separation using Wi-Fi fingerprint trajectories,\naddressing the challenge of vertical localization in indoor settings. We\nconstruct a graph where nodes represent Wi-Fi fingerprints, and edges are\nweighted by signal similarity and contextual transitions. Node2Vec is employed\nto generate low-dimensional embeddings, which are subsequently clustered using\nK-means to identify distinct floors. Evaluated on the Huawei University\nChallenge 2021 dataset, our method outperforms traditional community detection\nalgorithms, achieving an accuracy of 68.97%, an F1- score of 61.99%, and an\nAdjusted Rand Index of 57.19%. By publicly releasing the preprocessed dataset\nand implementation code, this work contributes to advancing research in indoor\npositioning. The proposed approach demonstrates robustness to signal noise and\narchitectural complexities, offering a scalable solution for floor-level\nlocalization.", "published": "2025-05-12 21:46:36", "link": "http://arxiv.org/abs/2505.08088v1", "categories": ["cs.NI", "cs.AI", "cs.CR", "cs.LG", "cs.RO"], "primary_category": "cs.NI"}
{"title": "Manifold Learning with Normalizing Flows: Towards Regularity, Expressivity and Iso-Riemannian Geometry", "abstract": "Modern machine learning increasingly leverages the insight that\nhigh-dimensional data often lie near low-dimensional, non-linear manifolds, an\nidea known as the manifold hypothesis. By explicitly modeling the geometric\nstructure of data through learning Riemannian geometry algorithms can achieve\nimproved performance and interpretability in tasks like clustering,\ndimensionality reduction, and interpolation. In particular, learned pullback\ngeometry has recently undergone transformative developments that now make it\nscalable to learn and scalable to evaluate, which further opens the door for\nprincipled non-linear data analysis and interpretable machine learning.\nHowever, there are still steps to be taken when considering real-world\nmulti-modal data. This work focuses on addressing distortions and modeling\nerrors that can arise in the multi-modal setting and proposes to alleviate both\nchallenges through isometrizing the learned Riemannian structure and balancing\nregularity and expressivity of the diffeomorphism parametrization. We showcase\nthe effectiveness of the synergy of the proposed approaches in several\nnumerical experiments with both synthetic and real data.", "published": "2025-05-12 21:44:42", "link": "http://arxiv.org/abs/2505.08087v1", "categories": ["cs.LG", "math.DG"], "primary_category": "cs.LG"}
{"title": "A Federated Random Forest Solution for Secure Distributed Machine Learning", "abstract": "Privacy and regulatory barriers often hinder centralized machine learning\nsolutions, particularly in sectors like healthcare where data cannot be freely\nshared. Federated learning has emerged as a powerful paradigm to address these\nconcerns; however, existing frameworks primarily support gradient-based models,\nleaving a gap for more interpretable, tree-based approaches. This paper\nintroduces a federated learning framework for Random Forest classifiers that\npreserves data privacy and provides robust performance in distributed settings.\nBy leveraging PySyft for secure, privacy-aware computation, our method enables\nmultiple institutions to collaboratively train Random Forest models on locally\nstored data without exposing sensitive information. The framework supports\nweighted model averaging to account for varying data distributions, incremental\nlearning to progressively refine models, and local evaluation to assess\nperformance across heterogeneous datasets. Experiments on two real-world\nhealthcare benchmarks demonstrate that the federated approach maintains\ncompetitive predictive accuracy - within a maximum 9\\% margin of centralized\nmethods - while satisfying stringent privacy requirements. These findings\nunderscore the viability of tree-based federated learning for scenarios where\ndata cannot be centralized due to regulatory, competitive, or technical\nconstraints. The proposed solution addresses a notable gap in existing\nfederated learning libraries, offering an adaptable tool for secure distributed\nmachine learning tasks that demand both transparency and reliable performance.\nThe tool is available at https://github.com/ieeta-pt/fed_rf.", "published": "2025-05-12 21:40:35", "link": "http://arxiv.org/abs/2505.08085v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Land-Coverage Aware Path-Planning for Multi-UAV Swarms in Search and Rescue Scenarios", "abstract": "Unmanned Aerial Vehicles (UAVs) have become vital in search-and-rescue (SAR)\nmissions, with autonomous mission planning improving response times and\ncoverage efficiency. Early approaches primarily used path planning techniques\nsuch as A*, potential-fields, or Dijkstra's algorithm, while recent approaches\nhave incorporated meta-heuristic frameworks like genetic algorithms and\nparticle swarm optimization to balance competing objectives such as network\nconnectivity, energy efficiency, and strategic placement of charging stations.\nHowever, terrain-aware path planning remains under-explored, despite its\ncritical role in optimizing UAV SAR deployments. To address this gap, we\npresent a computer-vision based terrain-aware mission planner that autonomously\nextracts and analyzes terrain topology to enhance SAR pre-flight planning. Our\nframework uses a deep segmentation network fine-tuned on our own collection of\nlandcover datasets to transform satellite imagery into a structured, grid-based\nrepresentation of the operational area. This classification enables\nterrain-specific UAV-task allocation, improving deployment strategies in\ncomplex environments. We address the challenge of irregular terrain partitions,\nby introducing a two-stage partitioning scheme that first evaluates terrain\nmonotonicity along coordinate axes before applying a cost-based recursive\npartitioning process, minimizing unnecessary splits and optimizing path\nefficiency. Empirical validation in a high-fidelity simulation environment\ndemonstrates that our approach improves search and dispatch time over multiple\nmeta-heuristic techniques and against a competing state-of-the-art method.\nThese results highlight its potential for large-scale SAR operations, where\nrapid response and efficient UAV coordination are critical.", "published": "2025-05-12 20:56:52", "link": "http://arxiv.org/abs/2505.08060v1", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks", "abstract": "Deployment of neural networks on resource-constrained devices demands models\nthat are both compact and robust to adversarial inputs. However, compression\nand adversarial robustness often conflict. In this work, we introduce a\ndynamical low-rank training scheme enhanced with a novel spectral regularizer\nthat controls the condition number of the low-rank core in each layer. This\napproach mitigates the sensitivity of compressed models to adversarial\nperturbations without sacrificing clean accuracy. The method is model- and\ndata-agnostic, computationally efficient, and supports rank adaptivity to\nautomatically compress the network at hand. Extensive experiments across\nstandard architectures, datasets, and adversarial attacks show the regularized\nnetworks can achieve over 94% compression while recovering or improving\nadversarial accuracy relative to uncompressed baselines.", "published": "2025-05-12 19:46:29", "link": "http://arxiv.org/abs/2505.08022v1", "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "cs.LG"}
{"title": "Convergence Properties of PINNs for the Navier-Stokes-Cahn-Hilliard System", "abstract": "Approximating solutions to differential equations using neural networks has\nbecome increasingly popular and shows significant promise. In this paper, we\npropose a simplified framework for analyzing the potential of neural networks\nto simulate differential equations based on the properties of the equations\nthemselves. We apply this framework to the Cahn-Hilliard and\nNavier-Stokes-Cahn-Hilliard systems, presenting both theoretical analysis and\npractical implementations. We then conduct numerical experiments on toy\nproblems to validate the framework's efficacy in accurately capturing the\ndesired properties of these systems and numerically estimate relevant\nconvergence properties.", "published": "2025-05-12 18:05:57", "link": "http://arxiv.org/abs/2505.07964v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "DeFi Liquidation Risk Modeling Using the Reflection Principle for Zero-Drift Brownian Motion", "abstract": "In this paper, we propose an analytical method to compute the collateral\nliquidation probability in decentralized finance (DeFi) stablecoin\nsingle-collateral lending. Our approach models the collateral exchange rate as\na zero-drift geometric Brownian motion, converts it into a regular zero-drift\nBrownian motion, and employs the reflection principle to derive the liquidation\nprobability. Unlike most existing methods that rely on computationally\nintensive simulations such as Monte Carlo, our formula provides a lightweight,\nexact solution. This advancement offers a more efficient alternative for risk\nassessment in DeFi platforms.", "published": "2025-05-12 22:13:44", "link": "http://arxiv.org/abs/2505.08100v1", "categories": ["q-fin.RM", "q-fin.CP", "q-fin.MF"], "primary_category": "q-fin.RM"}
{"title": "Doubly Robust Fusion of Many Treatments for Policy Learning", "abstract": "Individualized treatment rules/recommendations (ITRs) aim to improve patient\noutcomes by tailoring treatments to the characteristics of each individual.\nHowever, when there are many treatment groups, existing methods face\nsignificant challenges due to data sparsity within treatment groups and highly\nunbalanced covariate distributions across groups. To address these challenges,\nwe propose a novel calibration-weighted treatment fusion procedure that\nrobustly balances covariates across treatment groups and fuses similar\ntreatments using a penalized working model. The fusion procedure ensures the\nrecovery of latent treatment group structures when either the calibration model\nor the outcome model is correctly specified. In the fused treatment space,\npractitioners can seamlessly apply state-of-the-art ITR learning methods with\nthe flexibility to utilize a subset of covariates, thereby achieving robustness\nwhile addressing practical concerns such as fairness. We establish theoretical\nguarantees, including consistency, the oracle property of treatment fusion, and\nregret bounds when integrated with multi-armed ITR learning methods such as\npolicy trees. Simulation studies show superior group recovery and policy value\ncompared to existing approaches. We illustrate the practical utility of our\nmethod using a nationwide electronic health record-derived de-identified\ndatabase containing data from patients with Chronic Lymphocytic Leukemia and\nSmall Lymphocytic Lymphoma.", "published": "2025-05-12 21:55:57", "link": "http://arxiv.org/abs/2505.08092v1", "categories": ["stat.ME", "stat.ML"], "primary_category": "stat.ME"}
{"title": "Wasserstein Distributionally Robust Nonparametric Regression", "abstract": "Distributionally robust optimization has become a powerful tool for\nprediction and decision-making under model uncertainty. By focusing on the\nlocal worst-case risk, it enhances robustness by identifying the most\nunfavorable distribution within a predefined ambiguity set. While extensive\nresearch has been conducted in parametric settings, studies on nonparametric\nframeworks remain limited. This paper studies the generalization properties of\nWasserstein distributionally robust nonparametric estimators, with particular\nattention to the impact of model misspecification, where non-negligible\ndiscrepancies between the estimation function space and target function can\nimpair generalization performance. We establish non-asymptotic error bounds for\nthe excess local worst-case risk by analyzing the regularization effects\ninduced by distributional perturbations and employing feedforward neural\nnetworks with Lipschitz constraints. These bounds illustrate how uncertainty\nlevels and neural network structures influence generalization performance and\nare applicable to both Lipschitz and quadratic loss functions. Furthermore, we\ninvestigate the Lagrangian relaxation of the local worst-case risk and derive\ncorresponding non-asymptotic error bounds for these estimators. The robustness\nof the proposed estimator is evaluated through simulation studies and\nillustrated with an application to the MNIST dataset.", "published": "2025-05-12 18:07:37", "link": "http://arxiv.org/abs/2505.07967v1", "categories": ["stat.ML", "cs.LG", "62G05, 62G08, 68T07"], "primary_category": "stat.ML"}
{"title": "OLinear: A Linear Model for Time Series Forecasting in Orthogonally Transformed Domain", "abstract": "This paper presents $\\mathbf{OLinear}$, a $\\mathbf{linear}$-based\nmultivariate time series forecasting model that operates in an\n$\\mathbf{o}$rthogonally transformed domain. Recent forecasting models typically\nadopt the temporal forecast (TF) paradigm, which directly encode and decode\ntime series in the time domain. However, the entangled step-wise dependencies\nin series data can hinder the performance of TF. To address this, some\nforecasters conduct encoding and decoding in the transformed domain using\nfixed, dataset-independent bases (e.g., sine and cosine signals in the Fourier\ntransform). In contrast, we utilize $\\mathbf{OrthoTrans}$, a data-adaptive\ntransformation based on an orthogonal matrix that diagonalizes the series'\ntemporal Pearson correlation matrix. This approach enables more effective\nencoding and decoding in the decorrelated feature domain and can serve as a\nplug-in module to enhance existing forecasters. To enhance the representation\nlearning for multivariate time series, we introduce a customized linear layer,\n$\\mathbf{NormLin}$, which employs a normalized weight matrix to capture\nmultivariate dependencies. Empirically, the NormLin module shows a surprising\nperformance advantage over multi-head self-attention, while requiring nearly\nhalf the FLOPs. Extensive experiments on 24 benchmarks and 140 forecasting\ntasks demonstrate that OLinear consistently achieves state-of-the-art\nperformance with high efficiency. Notably, as a plug-in replacement for\nself-attention, the NormLin module consistently enhances Transformer-based\nforecasters. The code and datasets are available at\nhttps://anonymous.4open.science/r/OLinear", "published": "2025-05-12 10:39:37", "link": "http://arxiv.org/abs/2505.08550v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MiniMax-Speech: Intrinsic Zero-Shot Text-to-Speech with a Learnable Speaker Encoder", "abstract": "We introduce MiniMax-Speech, an autoregressive Transformer-based\nText-to-Speech (TTS) model that generates high-quality speech. A key innovation\nis our learnable speaker encoder, which extracts timbre features from a\nreference audio without requiring its transcription. This enables\nMiniMax-Speech to produce highly expressive speech with timbre consistent with\nthe reference in a zero-shot manner, while also supporting one-shot voice\ncloning with exceptionally high similarity to the reference voice. In addition,\nthe overall quality of the synthesized audio is enhanced through the proposed\nFlow-VAE. Our model supports 32 languages and demonstrates excellent\nperformance across multiple objective and subjective evaluations metrics.\nNotably, it achieves state-of-the-art (SOTA) results on objective voice cloning\nmetrics (Word Error Rate and Speaker Similarity) and has secured the top\nposition on the public TTS Arena leaderboard. Another key strength of\nMiniMax-Speech, granted by the robust and disentangled representations from the\nspeaker encoder, is its extensibility without modifying the base model,\nenabling various applications such as: arbitrary voice emotion control via\nLoRA; text to voice (T2V) by synthesizing timbre features directly from text\ndescription; and professional voice cloning (PVC) by fine-tuning timbre\nfeatures with additional data. We encourage readers to visit\nhttps://minimax-ai.github.io/tts_tech_report for more examples.", "published": "2025-05-12 14:25:20", "link": "http://arxiv.org/abs/2505.07916v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "QubitLens: An Interactive Learning Tool for Quantum State Tomography", "abstract": "Quantum state tomography is a fundamental task in quantum computing,\ninvolving the reconstruction of an unknown quantum state from measurement\noutcomes. Although essential, it is typically introduced at the graduate level\ndue to its reliance on advanced concepts such as the density matrix formalism,\ntensor product structures, and partial trace operations. This complexity often\ncreates a barrier for students and early learners. In this work, we introduce\nQubitLens, an interactive visualization tool designed to make quantum state\ntomography more accessible and intuitive. QubitLens leverages maximum\nlikelihood estimation (MLE), a classical statistical method, to estimate pure\nquantum states from projective measurement outcomes in the X, Y, and Z bases.\nThe tool emphasizes conceptual clarity through visual representations,\nincluding Bloch sphere plots of true and reconstructed qubit states, bar charts\ncomparing parameter estimates, and fidelity gauges that quantify reconstruction\naccuracy. QubitLens offers a hands-on approach to learning quantum tomography\nwithout requiring deep prior knowledge of density matrices or optimization\ntheory. The tool supports both single- and multi-qubit systems and is intended\nto bridge the gap between theory and practice in quantum computing education.", "published": "2025-05-12 20:48:47", "link": "http://arxiv.org/abs/2505.08056v1", "categories": ["quant-ph", "eess.SP"], "primary_category": "quant-ph"}
{"title": "Mobile Jamming Mitigation in 5G Networks: A MUSIC-Based Adaptive Beamforming Approach", "abstract": "Mobile jammers pose a critical threat to 5G networks, particularly in\nmilitary communications. We propose an intelligent anti-jamming framework that\nintegrates Multiple Signal Classification (MUSIC) for high-resolution\nDirection-of-Arrival (DoA) estimation, Minimum Variance Distortionless Response\n(MVDR) beamforming for adaptive interference suppression, and machine learning\n(ML) to enhance DoA prediction for mobile jammers. Extensive simulations in a\nrealistic highway scenario demonstrate that our hybrid approach achieves an\naverage Signal-to-Noise Ratio (SNR) improvement of 9.58 dB (maximum 11.08 dB)\nand up to 99.8% DoA estimation accuracy. The framework's computational\nefficiency and adaptability to dynamic jammer mobility patterns outperform\nconventional anti-jamming techniques, making it a robust solution for securing\n5G communications in contested environments.", "published": "2025-05-12 20:31:31", "link": "http://arxiv.org/abs/2505.08046v1", "categories": ["cs.NI", "cs.LG", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Statistical CSI-Based Distributed Precoding Design for OFDM-Cooperative Multi-Satellite Systems", "abstract": "This paper investigates the design of distributed precoding for\nmulti-satellite massive MIMO transmissions. We first conduct a detailed\nanalysis of the transceiver model, in which delay and Doppler precompensation\nis introduced to ensure coherent transmission. In this analysis, we examine the\nimpact of precompensation errors on the transmission model, emphasize the\nnear-independence of inter-satellite interference, and ultimately derive the\nreceived signal model. Based on such signal model, we formulate an approximate\nexpected rate maximization problem that considers both statistical channel\nstate information (sCSI) and compensation errors. Unlike conventional\napproaches that recast such problems as weighted minimum mean square error\n(WMMSE) minimization, we demonstrate that this transformation fails to maintain\nequivalence in the considered scenario. To address this, we introduce an\nequivalent covariance decomposition-based WMMSE (CDWMMSE) formulation derived\nbased on channel covariance matrix decomposition. Taking advantage of the\nchannel characteristics, we develop a low-complexity decomposition method and\npropose an optimization algorithm. To further reduce computational complexity,\nwe introduce a model-driven scalable deep learning (DL) approach that leverages\nthe equivariance of the mapping from sCSI to the unknown variables in the\noptimal closed-form solution, enhancing performance through novel dense\nTransformer network and scaling-invariant loss function design. Simulation\nresults validate the effectiveness and robustness of the proposed method in\nsome practical scenarios. We also demonstrate that the DL approach can adapt to\ndynamic settings with varying numbers of users and satellites.", "published": "2025-05-12 20:08:41", "link": "http://arxiv.org/abs/2505.08038v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "An Ultra-Sub-Wavelength Microwave Polarization Switch Implemented with Directed Surface Acoustic Waves in a Magnonic Crystal", "abstract": "The ability to switch the polarization of a transmitted electromagnetic wave\nfrom vertical to horizontal, or vice versa, is of great technological interest\nbecause of its many applications in long distance communication. Binary bits\ncan be encoded in two orthogonal polarizations and transmitted securely from\npoint to point. Polarization switches, however, are usually much larger than\nthe wavelength of the electromagnetic wave. Consequently, most research in this\narea has focused on the optical regime where the wavelength is relatively short\n(~1 micron), so that the switch being much larger than the wavelength is not\ntoo inconvenient. However, this changes in the microwave regime where the\nwavelength is much larger (typically > 1 cm). That makes a microwave\nultra-sub-wavelength polarization switch very attractive. Here, we report such\na switch made of an array of magnetostrictive nanomagnets (~100 nm lateral\ndimension) deposited on a piezoelectric substrate to make an \"artificial\nmagnonic crystal\". A surface acoustic wave (SAW) launched in the substrate with\nsuitable electrodes excites spin waves in the nanomagnets via phonon-magnon\ncoupling, resulting in radiation of electromagnetic waves via magnon-photon\ncoupling. The polarization of the beam radiated in a given direction at a given\nfrequency can be rotated through ~90 degrees by changing the direction of SAW\npropagation in the substrate to implement the polarization switch.", "published": "2025-05-12 18:49:48", "link": "http://arxiv.org/abs/2505.07996v1", "categories": ["cond-mat.mes-hall", "eess.SP"], "primary_category": "cond-mat.mes-hall"}
{"title": "Near-Field Beamfocusing, Localization, and Channel Estimation with Modular Linear Arrays", "abstract": "This paper investigates how near-field beamfocusing can be achieved using a\nmodular linear array (MLA), composed of multiple widely spaced uniform linear\narrays (ULAs). The MLA architecture extends the aperture length of a standard\nULA without adding additional antennas, thereby enabling near-field\nbeamfocusing without increasing processing complexity. Unlike conventional\nfar-field beamforming, near-field beamfocusing enables simultaneous data\ntransmission to multiple users at different distances in the same angular\ninterval, offering significant multiplexing gains. We present a detailed\nmathematical analysis of the beamwidth and beamdepth achievable with the MLA\nand show that by appropriately selecting the number of antennas in each\nconstituent ULA, ideal near-field beamfocusing can be realized. In addition, we\npropose a computationally efficient localization method that fuses estimates\nfrom each ULA, enabling efficient parametric channel estimation. Simulation\nresults confirm the accuracy of the analytical expressions and that MLAs\nachieve near-field beamfocusing with a limited number of antennas, making them\na promising solution for next-generation wireless systems.", "published": "2025-05-12 18:42:25", "link": "http://arxiv.org/abs/2505.07991v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "EnvCDiff: Joint Refinement of Environmental Information and Channel Fingerprints via Conditional Generative Diffusion Model", "abstract": "The paradigm shift from environment-unaware communication to intelligent\nenvironment-aware communication is expected to facilitate the acquisition of\nchannel state information for future wireless communications. Channel\nFingerprint (CF), as an emerging enabling technology for environment-aware\ncommunication, provides channel-related knowledge for potential locations\nwithin the target communication area. However, due to the limited availability\nof practical devices for sensing environmental information and measuring\nchannel-related knowledge, most of the acquired environmental information and\nCF are coarse-grained, insufficient to guide the design of wireless\ntransmissions. To address this, this paper proposes a deep conditional\ngenerative learning approach, namely a customized conditional generative\ndiffusion model (CDiff). The proposed CDiff simultaneously refines\nenvironmental information and CF, reconstructing a fine-grained CF that\nincorporates environmental information, referred to as EnvCF, from its\ncoarse-grained counterpart. Experimental results show that the proposed\napproach significantly improves the performance of EnvCF construction compared\nto the baselines.", "published": "2025-05-12 01:36:18", "link": "http://arxiv.org/abs/2505.07894v1", "categories": ["cs.NI", "cs.ET", "cs.LG", "eess.SP", "math.ST", "stat.TH"], "primary_category": "cs.NI"}
{"title": "Channel Fingerprint Construction for Massive MIMO: A Deep Conditional Generative Approach", "abstract": "Accurate channel state information (CSI) acquisition for massive\nmultiple-input multiple-output (MIMO) systems is essential for future mobile\ncommunication networks. Channel fingerprint (CF), also referred to as channel\nknowledge map, is a key enabler for intelligent environment-aware communication\nand can facilitate CSI acquisition. However, due to the cost limitations of\npractical sensing nodes and test vehicles, the resulting CF is typically\ncoarse-grained, making it insufficient for wireless transceiver design. In this\nwork, we introduce the concept of CF twins and design a conditional generative\ndiffusion model (CGDM) with strong implicit prior learning capabilities as the\ncomputational core of the CF twin to establish the connection between coarse-\nand fine-grained CFs. Specifically, we employ a variational inference technique\nto derive the evidence lower bound (ELBO) for the log-marginal distribution of\nthe observed fine-grained CF conditioned on the coarse-grained CF, enabling the\nCGDM to learn the complicated distribution of the target data. During the\ndenoising neural network optimization, the coarse-grained CF is introduced as\nside information to accurately guide the conditioned generation of the CGDM. To\nmake the proposed CGDM lightweight, we further leverage the additivity of\nnetwork layers and introduce a one-shot pruning approach along with a\nmulti-objective knowledge distillation technique. Experimental results show\nthat the proposed approach exhibits significant improvement in reconstruction\nperformance compared to the baselines. Additionally, zero-shot testing on\nreconstruction tasks with different magnification factors further demonstrates\nthe scalability and generalization ability of the proposed approach.", "published": "2025-05-12 01:36:06", "link": "http://arxiv.org/abs/2505.07893v1", "categories": ["cs.NI", "cs.LG", "eess.SP", "math.PR", "math.ST", "stat.TH"], "primary_category": "cs.NI"}
{"title": "TiSpell: A Semi-Masked Methodology for Tibetan Spelling Correction covering Multi-Level Error with Data Augmentation", "abstract": "Multi-level Tibetan spelling correction addresses errors at both the\ncharacter and syllable levels within a unified model. Existing methods focus\nmainly on single-level correction and lack effective integration of both\nlevels. Moreover, there are no open-source datasets or augmentation methods\ntailored for this task in Tibetan. To tackle this, we propose a data\naugmentation approach using unlabeled text to generate multi-level corruptions,\nand introduce TiSpell, a semi-masked model capable of correcting both\ncharacter- and syllable-level errors. Although syllable-level correction is\nmore challenging due to its reliance on global context, our semi-masked\nstrategy simplifies this process. We synthesize nine types of corruptions on\nclean sentences to create a robust training set. Experiments on both simulated\nand real-world data demonstrate that TiSpell, trained on our dataset,\noutperforms baseline models and matches the performance of state-of-the-art\napproaches, confirming its effectiveness.", "published": "2025-05-12 20:08:05", "link": "http://arxiv.org/abs/2505.08037v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Efficient Lifting of Discrete Logarithms Modulo Prime Powers", "abstract": "We present a deterministic algorithm that, given a prime $p$ and a solution\n$x \\in \\mathbb Z$ to the discrete logarithm problem $a^x \\equiv b \\pmod p$ with\n$p\\nmid a$, efficiently lifts it to a solution modulo $p^k$, i.e., $a^x \\equiv\nb \\pmod {p^k}$, for any fixed $k \\geq 1$.\n  The algorithm performs $k(\\lceil \\log_2 p\\rceil +2)+O(\\log p)$\nmultiplications modulo $p^k$ in the worst case, improving upon prior lifting\nmethods by at least a factor of 8.", "published": "2025-05-12 10:52:19", "link": "http://arxiv.org/abs/2505.07434v2", "categories": ["math.NT", "cs.DM"], "primary_category": "math.NT"}
{"title": "OLinear: A Linear Model for Time Series Forecasting in Orthogonally Transformed Domain", "abstract": "This paper presents $\\mathbf{OLinear}$, a $\\mathbf{linear}$-based\nmultivariate time series forecasting model that operates in an\n$\\mathbf{o}$rthogonally transformed domain. Recent forecasting models typically\nadopt the temporal forecast (TF) paradigm, which directly encode and decode\ntime series in the time domain. However, the entangled step-wise dependencies\nin series data can hinder the performance of TF. To address this, some\nforecasters conduct encoding and decoding in the transformed domain using\nfixed, dataset-independent bases (e.g., sine and cosine signals in the Fourier\ntransform). In contrast, we utilize $\\mathbf{OrthoTrans}$, a data-adaptive\ntransformation based on an orthogonal matrix that diagonalizes the series'\ntemporal Pearson correlation matrix. This approach enables more effective\nencoding and decoding in the decorrelated feature domain and can serve as a\nplug-in module to enhance existing forecasters. To enhance the representation\nlearning for multivariate time series, we introduce a customized linear layer,\n$\\mathbf{NormLin}$, which employs a normalized weight matrix to capture\nmultivariate dependencies. Empirically, the NormLin module shows a surprising\nperformance advantage over multi-head self-attention, while requiring nearly\nhalf the FLOPs. Extensive experiments on 24 benchmarks and 140 forecasting\ntasks demonstrate that OLinear consistently achieves state-of-the-art\nperformance with high efficiency. Notably, as a plug-in replacement for\nself-attention, the NormLin module consistently enhances Transformer-based\nforecasters. The code and datasets are available at\nhttps://anonymous.4open.science/r/OLinear", "published": "2025-05-12 10:39:37", "link": "http://arxiv.org/abs/2505.08550v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits", "abstract": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical.", "published": "2025-05-12 21:14:29", "link": "http://arxiv.org/abs/2505.08823v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Reconfiguration of List Colourings", "abstract": "Given a proper (list) colouring of a graph $G$, a recolouring step changes\nthe colour at a single vertex to another colour (in its list) that is currently\nunused on its neighbours, hence maintaining a proper colouring. Suppose that\neach vertex $v$ has its own private list $L(v)$ of allowed colours such that\n$|L(v)|\\ge \\mbox{deg}(v)+1$. We prove that if $G$ is connected and its maximum\ndegree $\\Delta$ is at least $3$, then for any two proper $L$-colourings in\nwhich at least one vertex can be recoloured, one can be transformed to the\nother by a sequence of $O(|V(G)|^2)$ recolouring steps. We also show that\nreducing the list-size of a single vertex $w$ to $\\mbox{deg}(w)$ can lead to\nsituations where the space of proper $L$-colourings is `shattered'. Our results\ncan be interpreted as showing a sharp phase transition in the Glauber dynamics\nof proper $L$-colourings of graphs. This constitutes a `local' strengthening\nand generalisation of a result of Feghali, Johnson, and Paulusma, which\nconsidered the situation where the lists are all identical to\n$\\{1,\\ldots,\\Delta+1\\}$.", "published": "2025-05-12 19:41:48", "link": "http://arxiv.org/abs/2505.08020v1", "categories": ["math.CO", "cs.DM", "cs.DS"], "primary_category": "math.CO"}
{"title": "Multi-source Plume Tracing via Multi-Agent Reinforcement Learning", "abstract": "Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon\ngas leak (2015) demonstrate the urgent need for rapid and reliable plume\ntracing algorithms to protect public health and the environment. Traditional\nmethods, such as gradient-based or biologically inspired approaches, often fail\nin realistic, turbulent conditions. To address these challenges, we present a\nMulti-Agent Reinforcement Learning (MARL) algorithm designed for localizing\nmultiple airborne pollution sources using a swarm of small uncrewed aerial\nsystems (sUAS). Our method models the problem as a Partially Observable Markov\nGame (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific\nDouble Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical\naction-observation pairs, effectively approximating latent states. Unlike prior\nwork, we use a general-purpose simulation environment based on the Gaussian\nPlume Model (GPM), incorporating realistic elements such as a three-dimensional\nenvironment, sensor noise, multiple interacting agents, and multiple plume\nsources. The incorporation of action histories as part of the inputs further\nenhances the adaptability of our model in complex, partially observable\nenvironments. Extensive simulations show that our algorithm significantly\noutperforms conventional approaches. Specifically, our model allows agents to\nexplore only 1.29\\% of the environment to successfully locate pollution\nsources.", "published": "2025-05-12 21:33:15", "link": "http://arxiv.org/abs/2505.08825v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Hypernym Mercury: Token Optimization Through Semantic Field Constriction And Reconstruction From Hypernyms. A New Text Compression Method", "abstract": "Compute optimization using token reduction of LLM prompts is an emerging task\nin the fields of NLP and next generation, agentic AI. In this white paper, we\nintroduce a novel (patent pending) text representation scheme and a\nfirst-of-its-kind word-level semantic compression of paragraphs that can lead\nto over 90% token reduction, while retaining high semantic similarity to the\nsource text. We explain how this novel compression technique can be lossless\nand how the detail granularity is controllable. We discuss benchmark results\nover open source data (i.e. Bram Stoker's Dracula available through Project\nGutenberg) and show how our results hold at the paragraph level, across\nmultiple genres and models.", "published": "2025-05-12 20:49:50", "link": "http://arxiv.org/abs/2505.08058v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Unbiased Low-Rank Approximation with Minimum Distortion", "abstract": "We describe an algorithm for sampling a low-rank random matrix $Q$ that best\napproximates a fixed target matrix $P\\in\\mathbb{C}^{n\\times m}$ in the\nfollowing sense: $Q$ is unbiased, i.e., $\\mathbb{E}[Q] = P$;\n$\\mathsf{rank}(Q)\\leq r$; and $Q$ minimizes the expected Frobenius norm error\n$\\mathbb{E}\\|P-Q\\|_F^2$. Our algorithm mirrors the solution to the efficient\nunbiased sparsification problem for vectors, except applied to the singular\ncomponents of the matrix $P$. Optimality is proven by showing that our\nalgorithm matches the error from an existing lower bound.", "published": "2025-05-12 20:52:28", "link": "http://arxiv.org/abs/2505.09647v1", "categories": ["cs.DS", "cs.IT", "cs.LG", "math.IT", "math.PR", "math.ST", "stat.TH"], "primary_category": "cs.DS"}
{"title": "Isomorphisms of unit distance graphs of layers", "abstract": "For any $\\varepsilon\\in (0,+\\infty)$, consider the metric spaces $\\mathbb{R}\n\\times [0,\\varepsilon]$ in the Euclidean plane named layers or strips. B.\nBaslaugh in 1998 found the minimal width $\\varepsilon \\in (0,1)$ of a layer\nsuch that its unit distance graph contains a cycle of a given odd length $k$.\nThe first of the main results of this paper is the fact that the unit distance\ngraphs of two layers $\\mathbb{R} \\times [0,\\varepsilon_1], \\mathbb{R} \\times\n[0,\\varepsilon_2]$ are non-isomorphic for any different values\n$\\varepsilon_1,\\varepsilon_2 \\in (0,+\\infty)$. We also get a multidimensional\nanalogue of this theorem. For given $n,m \\in \\mathbb{N}, p \\in (1,+\\infty),\n\\varepsilon \\in (0,+\\infty)$, we say that the metric space on $\\mathbb{R}^n\n\\times [0,\\varepsilon]^m$ with the metric space distance generated by\n$l_p$-norm in $\\mathbb{R}^{n+m}$ is a layer $L(n,m,p,\\varepsilon)$. We show\nthat the unit distance graphs of multi-layers $L(n,m,p,\\varepsilon_1),\nL(n,m,p,\\varepsilon_2)$ are non-isomorphic for $\\varepsilon_1 \\neq\n\\varepsilon_2$. This result is related to the Beckman-Quarles theorem of 1953\nthat any unit-preserving mapping of $\\mathbb{R}^n$ is an isometry, and to the\nrational analogue of this theorem obtained by A. Sokolov in 2023.", "published": "2025-05-12 17:49:06", "link": "http://arxiv.org/abs/2505.07799v2", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "CASL-HJX: A Comprehensive Guide to Solving Deterministic and Stochastic Hamilton-Jacobi Equations", "abstract": "CASL-HJX is a computational framework designed for solving deterministic and\nstochastic Hamilton-Jacobi equations in two spatial dimensions. It provides a\nflexible and efficient approach to modeling front propagation problems, optimal\ncontrol problems, and stochastic Hamilton-Jacobi Bellman equations. The\nframework integrates numerical methods for hyperbolic PDEs with operator\nsplitting techniques and implements implicit methods for second-order\nderivative terms, ensuring convergence to viscosity solutions while achieving\nglobal rather than local optimization. Built with a high-performance C++ core,\nCASL-HJX efficiently handles mixed-order derivative systems with time-varying\ndynamics, making it suitable for real-world applications across multiple\ndomains. We demonstrate the solver's versatility through tutorial examples\ncovering various PDEs and through applications in neuroscience, where it\nenables the design of energy-efficient controllers for regulating neural\npopulations to mitigate pathological synchrony. While our examples focus on\nthese applications, the mathematical foundation of the solver makes it\napplicable to problems in finance, engineering, and machine learning. The\nmodular architecture allows researchers to define computational domains,\nconfigure problems, and execute simulations with high numerical accuracy.\nCASL-HJX bridges the gap between deterministic control methods and stochastic\nmodels, providing a robust tool for managing uncertainty in complex dynamical\nsystems.", "published": "2025-05-12 23:55:40", "link": "http://arxiv.org/abs/2505.11527v1", "categories": ["math.OC", "cs.CE", "cs.NA", "math.NA", "35Q93 (Primary), 49L25, 65M06, 65M70 (Secondary)", "G.1.8; I.6.1; J.3"], "primary_category": "math.OC"}
{"title": "CASL-HJX: A Comprehensive Guide to Solving Deterministic and Stochastic Hamilton-Jacobi Equations", "abstract": "CASL-HJX is a computational framework designed for solving deterministic and\nstochastic Hamilton-Jacobi equations in two spatial dimensions. It provides a\nflexible and efficient approach to modeling front propagation problems, optimal\ncontrol problems, and stochastic Hamilton-Jacobi Bellman equations. The\nframework integrates numerical methods for hyperbolic PDEs with operator\nsplitting techniques and implements implicit methods for second-order\nderivative terms, ensuring convergence to viscosity solutions while achieving\nglobal rather than local optimization. Built with a high-performance C++ core,\nCASL-HJX efficiently handles mixed-order derivative systems with time-varying\ndynamics, making it suitable for real-world applications across multiple\ndomains. We demonstrate the solver's versatility through tutorial examples\ncovering various PDEs and through applications in neuroscience, where it\nenables the design of energy-efficient controllers for regulating neural\npopulations to mitigate pathological synchrony. While our examples focus on\nthese applications, the mathematical foundation of the solver makes it\napplicable to problems in finance, engineering, and machine learning. The\nmodular architecture allows researchers to define computational domains,\nconfigure problems, and execute simulations with high numerical accuracy.\nCASL-HJX bridges the gap between deterministic control methods and stochastic\nmodels, providing a robust tool for managing uncertainty in complex dynamical\nsystems.", "published": "2025-05-12 23:55:40", "link": "http://arxiv.org/abs/2505.11527v2", "categories": ["math.OC", "cs.CE", "cs.NA", "math.NA", "35Q93 (Primary), 49L25, 65M06, 65M70 (Secondary)", "G.1.8; I.6.1; J.3"], "primary_category": "math.OC"}
{"title": "Isomorphisms of unit distance graphs of layers", "abstract": "For any $\\varepsilon \\in (0,+\\infty)$, consider the metric spaces $\\mathbb{R}\n\\times [0,\\varepsilon]$ in the Euclidean plane named layers or strips. B.\nBaslaugh in 1998 found the minimal width $\\varepsilon \\in (0,1)$ of a layer\nsuch that its unit distance graph contains a cycle of a given odd length $k$.\nThe first of the main results of this paper is the fact that the unit distance\ngraphs of two layers $\\mathbb{R} \\times [0,\\varepsilon_1], \\mathbb{R} \\times\n[0,\\varepsilon_2]$ are non-isomorphic for any different values\n$\\varepsilon_1,\\varepsilon_2 \\in (0,+\\infty)$.\n  We also get a multidimensional analogue of this theorem. For given $n,m \\in\n\\mathbb{N}, p \\in (1,+\\infty), \\varepsilon \\in (0,+\\infty)$, we say that the\nmetric space on $\\mathbb{R}^n \\times [0,\\varepsilon]^m$ with the metric space\ndistance generated by $l_p$-norm in $\\mathbb{R}^{n+m}$ is a layer\n$L(n,m,p,\\varepsilon)$. We show that the unit distance graphs of layers\n$L(n,m,p,\\varepsilon_1), L(n,m,p,\\varepsilon_2)$ are non-isomorphic for\n$\\varepsilon_1 \\neq \\varepsilon_2$.\n  The third main result of this paper is the theorem that, for $n \\geq 2,\n\\varepsilon > 0$, any automorphism $\\phi$ of the unit distance graph of layer\n$L = L(n,1,2,\\varepsilon) = \\mathbb{R}^n \\times [0,\\varepsilon]$ is an\nisometry. This is related to the Beckman-Quarles theorem of 1953, which states\nthat any unit-preserving mapping of $\\mathbb{R}^n$ is an isometry, and to the\nrational analogue of this theorem obtained by A. Sokolov in 2023.", "published": "2025-05-12 17:49:06", "link": "http://arxiv.org/abs/2505.07799v3", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "HYGMA: Hypergraph Coordination Networks with Dynamic Grouping for Multi-Agent Reinforcement Learning", "abstract": "Cooperative multi-agent reinforcement learning faces significant challenges\nin effectively organizing agent relationships and facilitating information\nexchange, particularly when agents need to adapt their coordination patterns\ndynamically. This paper presents a novel framework that integrates dynamic\nspectral clustering with hypergraph neural networks to enable adaptive group\nformation and efficient information processing in multi-agent systems. The\nproposed framework dynamically constructs and updates hypergraph structures\nthrough spectral clustering on agents' state histories, enabling higher-order\nrelationships to emerge naturally from agent interactions. The hypergraph\nstructure is enhanced with attention mechanisms for selective information\nprocessing, providing an expressive and efficient way to model complex agent\nrelationships. This architecture can be implemented in both value-based and\npolicy-based paradigms through a unified objective combining task performance\nwith structural regularization. Extensive experiments on challenging\ncooperative tasks demonstrate that our method significantly outperforms\nstate-of-the-art approaches in both sample efficiency and final performance.", "published": "2025-05-12 03:31:26", "link": "http://arxiv.org/abs/2505.07207v2", "categories": ["cs.MA"], "primary_category": "cs.MA"}
