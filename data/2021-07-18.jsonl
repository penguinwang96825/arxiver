{"title": "Proactive Retrieval-based Chatbots based on Relevant Knowledge and Goals", "abstract": "A proactive dialogue system has the ability to proactively lead the\nconversation. Different from the general chatbots which only react to the user,\nproactive dialogue systems can be used to achieve some goals, e.g., to\nrecommend some items to the user. Background knowledge is essential to enable\nsmooth and natural transitions in dialogue. In this paper, we propose a new\nmulti-task learning framework for retrieval-based knowledge-grounded proactive\ndialogue. To determine the relevant knowledge to be used, we frame knowledge\nprediction as a complementary task and use explicit signals to supervise its\nlearning. The final response is selected according to the predicted knowledge,\nthe goal to achieve, and the context. Experimental results show that explicit\nmodeling of knowledge prediction and goal selection can greatly improve the\nfinal response selection. Our code is available at\nhttps://github.com/DaoD/KPN/.", "published": "2021-07-18 00:27:31", "link": "http://arxiv.org/abs/2107.08329v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Argument Linking: A Survey and Forecast", "abstract": "Semantic role labeling (SRL) -- identifying the semantic relationships\nbetween a predicate and other constituents in the same sentence -- is a\nwell-studied task in natural language understanding (NLU). However, many of\nthese relationships are evident only at the level of the document, as a role\nfor a predicate in one sentence may often be filled by an argument in a\ndifferent one. This more general task, known as implicit semantic role labeling\nor argument linking, has received increased attention in recent years, as\nresearchers have recognized its centrality to information extraction and NLU.\nThis paper surveys the literature on argument linking and identifies several\nnotable shortcomings of existing approaches that indicate the paths along which\nfuture research effort could most profitably be spent.", "published": "2021-07-18 19:28:20", "link": "http://arxiv.org/abs/2107.08523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond a binary of (non)racist tweets: A four-dimensional categorical\n  detection and analysis of racist and xenophobic opinions on Twitter in early\n  Covid-19", "abstract": "Transcending the binary categorization of racist and xenophobic texts, this\nresearch takes cues from social science theories to develop a four dimensional\ncategory for racism and xenophobia detection, namely stigmatization,\noffensiveness, blame, and exclusion. With the aid of deep learning techniques,\nthis categorical detection enables insights into the nuances of emergent topics\nreflected in racist and xenophobic expression on Twitter. Moreover, a stage\nwise analysis is applied to capture the dynamic changes of the topics across\nthe stages of early development of Covid-19 from a domestic epidemic to an\ninternational public health emergency, and later to a global pandemic. The main\ncontributions of this research include, first the methodological advancement.\nBy bridging the state-of-the-art computational methods with social science\nperspective, this research provides a meaningful approach for future research\nto gain insight into the underlying subtlety of racist and xenophobic\ndiscussion on digital platforms. Second, by enabling a more accurate\ncomprehension and even prediction of public opinions and actions, this research\npaves the way for the enactment of effective intervention policies to combat\nracist crimes and social exclusion under Covid-19.", "published": "2021-07-18 02:37:31", "link": "http://arxiv.org/abs/2107.08347v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "As Easy as 1, 2, 3: Behavioural Testing of NMT Systems for Numerical\n  Translation", "abstract": "Mistranslated numbers have the potential to cause serious effects, such as\nfinancial loss or medical misinformation. In this work we develop comprehensive\nassessments of the robustness of neural machine translation systems to\nnumerical text via behavioural testing. We explore a variety of numerical\ntranslation capabilities a system is expected to exhibit and design effective\ntest examples to expose system underperformance. We find that numerical\nmistranslation is a general issue: major commercial systems and\nstate-of-the-art research models fail on many of our test examples, for high-\nand low-resource languages. Our tests reveal novel errors that have not\npreviously been reported in NMT systems, to the best of our knowledge. Lastly,\nwe discuss strategies to mitigate numerical mistranslation.", "published": "2021-07-18 04:09:47", "link": "http://arxiv.org/abs/2107.08357v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "A pattern recognition approach for distinguishing between prose and\n  poetry", "abstract": "Poetry and prose are written artistic expressions that help us to appreciate\nthe reality we live. Each of these styles has its own set of subjective\nproperties, such as rhyme and rhythm, which are easily caught by a human\nreader's eye and ear. With the recent advances in artificial intelligence, the\ngap between humans and machines may have decreased, and today we observe\nalgorithms mastering tasks that were once exclusively performed by humans. In\nthis paper, we propose an automated method to distinguish between poetry and\nprose based solely on aural and rhythmic properties. In other to compare prose\nand poetry rhythms, we represent the rhymes and phones as temporal sequences\nand thus we propose a procedure for extracting rhythmic features from these\nsequences. The classification of the considered texts using the set of features\nextracted resulted in a best accuracy of 0.78, obtained with a neural network.\nInterestingly, by using an approach based on complex networks to visualize the\nsimilarities between the different texts considered, we found that the patterns\nof poetry vary much more than prose. Consequently, a much richer and complex\nset of rhythmic possibilities tends to be found in that modality.", "published": "2021-07-18 18:44:17", "link": "http://arxiv.org/abs/2107.08512v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Exploring the Potential of Lexical Paraphrases for Mitigating\n  Noise-Induced Comprehension Errors", "abstract": "Listening in noisy environments can be difficult even for individuals with a\nnormal hearing thresholds. The speech signal can be masked by noise, which may\nlead to word misperceptions on the side of the listener, and overall difficulty\nto understand the message. To mitigate hearing difficulties on listeners, a\nco-operative speaker utilizes voice modulation strategies like Lombard speech\nto generate noise-robust utterances, and similar solutions have been developed\nfor speech synthesis systems. In this work, we propose an alternate solution of\nchoosing noise-robust lexical paraphrases to represent an intended meaning. Our\nresults show that lexical paraphrases differ in their intelligibility in noise.\nWe evaluate the intelligibility of synonyms in context and find that choosing a\nlexical unit that is less risky to be misheard than its synonym introduced an\naverage gain in comprehension of 37% at SNR -5 dB and 21% at SNR 0 dB for\nbabble noise.", "published": "2021-07-18 01:16:33", "link": "http://arxiv.org/abs/2107.08337v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "DeHumor: Visual Analytics for Decomposing Humor", "abstract": "Despite being a critical communication skill, grasping humor is challenging\n-- a successful use of humor requires a mixture of both engaging content\nbuild-up and an appropriate vocal delivery (e.g., pause). Prior studies on\ncomputational humor emphasize the textual and audio features immediately next\nto the punchline, yet overlooking longer-term context setup. Moreover, the\ntheories are usually too abstract for understanding each concrete humor\nsnippet. To fill in the gap, we develop DeHumor, a visual analytical system for\nanalyzing humorous behaviors in public speaking. To intuitively reveal the\nbuilding blocks of each concrete example, DeHumor decomposes each humorous\nvideo into multimodal features and provides inline annotations of them on the\nvideo script. In particular, to better capture the build-ups, we introduce\ncontent repetition as a complement to features introduced in theories of\ncomputational humor and visualize them in a context linking graph. To help\nusers locate the punchlines that have the desired features to learn, we\nsummarize the content (with keywords) and humor feature statistics on an\naugmented time matrix. With case studies on stand-up comedy shows and TED\ntalks, we show that DeHumor is able to highlight various building blocks of\nhumor examples. In addition, expert interviews with communication coaches and\nhumor researchers demonstrate the effectiveness of DeHumor for multimodal humor\nanalysis of speech content and vocal delivery.", "published": "2021-07-18 04:01:07", "link": "http://arxiv.org/abs/2107.08356v1", "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.MM", "I.2.7; I.7.0; H.4.2; J.4"], "primary_category": "cs.CL"}
{"title": "Pre-trained Language Models as Prior Knowledge for Playing Text-based\n  Games", "abstract": "Recently, text world games have been proposed to enable artificial agents to\nunderstand and reason about real-world scenarios. These text-based games are\nchallenging for artificial agents, as it requires an understanding of and\ninteraction using natural language in a partially observable environment.\nAgents observe the environment via textual descriptions designed to be\nchallenging enough for even human players. Past approaches have not paid enough\nattention to the language understanding capability of the proposed agents.\nTypically, these approaches train from scratch, an agent that learns both\ntextual representations and the gameplay online during training using a\ntemporal loss function. Given the sample-inefficiency of RL approaches, it is\ninefficient to learn rich enough textual representations to be able to\nunderstand and reason using the textual observation in such a complicated game\nenvironment setting. In this paper, we improve the semantic understanding of\nthe agent by proposing a simple RL with LM framework where we use\ntransformer-based language models with Deep RL models. We perform a detailed\nstudy of our framework to demonstrate how our model outperforms all existing\nagents on the popular game, Zork1, to achieve a score of 44.7, which is 1.6\nhigher than the state-of-the-art model. Overall, our proposed approach\noutperforms 4 games out of the 14 text-based games, while performing comparable\nto the state-of-the-art models on the remaining games.", "published": "2021-07-18 10:28:48", "link": "http://arxiv.org/abs/2107.08408v2", "categories": ["cs.CL", "cs.AI", "cs.MA", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Stock price prediction using BERT and GAN", "abstract": "The stock market has been a popular topic of interest in the recent past. The\ngrowth in the inflation rate has compelled people to invest in the stock and\ncommodity markets and other areas rather than saving. Further, the ability of\nDeep Learning models to make predictions on the time series data has been\nproven time and again. Technical analysis on the stock market with the help of\ntechnical indicators has been the most common practice among traders and\ninvestors. One more aspect is the sentiment analysis - the emotion of the\ninvestors that shows the willingness to invest. A variety of techniques have\nbeen used by people around the globe involving basic Machine Learning and\nNeural Networks. Ranging from the basic linear regression to the advanced\nneural networks people have experimented with all possible techniques to\npredict the stock market. It's evident from recent events how news and\nheadlines affect the stock markets and cryptocurrencies. This paper proposes an\nensemble of state-of-the-art methods for predicting stock prices. Firstly\nsentiment analysis of the news and the headlines for the company Apple Inc,\nlisted on the NASDAQ is performed using a version of BERT, which is a\npre-trained transformer model by Google for Natural Language Processing (NLP).\nAfterward, a Generative Adversarial Network (GAN) predicts the stock price for\nApple Inc using the technical indicators, stock indexes of various countries,\nsome commodities, and historical prices along with the sentiment scores.\nComparison is done with baseline models like - Long Short Term Memory (LSTM),\nGated Recurrent Units (GRU), vanilla GAN, and Auto-Regressive Integrated Moving\nAverage (ARIMA) model.", "published": "2021-07-18 18:31:43", "link": "http://arxiv.org/abs/2107.09055v1", "categories": ["q-fin.ST", "cs.CL", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Residual Attention Based Network for Automatic Classification of\n  Phonation Modes", "abstract": "Phonation mode is an essential characteristic of singing style as well as an\nimportant expression of performance. It can be classified into four categories,\ncalled neutral, breathy, pressed and flow. Previous studies used voice quality\nfeatures and feature engineering for classification. While deep learning has\nachieved significant progress in other fields of music information retrieval\n(MIR), there are few attempts in the classification of phonation modes. In this\nstudy, a Residual Attention based network is proposed for automatic\nclassification of phonation modes. The network consists of a convolutional\nnetwork performing feature processing and a soft mask branch enabling the\nnetwork focus on a specific area. In comparison experiments, the models with\nproposed network achieve better results in three of the four datasets than\nprevious works, among which the highest classification accuracy is 94.58%,\n2.29% higher than the baseline.", "published": "2021-07-18 12:37:00", "link": "http://arxiv.org/abs/2107.08425v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An Improved StarGAN for Emotional Voice Conversion: Enhancing Voice\n  Quality and Data Augmentation", "abstract": "Emotional Voice Conversion (EVC) aims to convert the emotional style of a\nsource speech signal to a target style while preserving its content and speaker\nidentity information. Previous emotional conversion studies do not disentangle\nemotional information from emotion-independent information that should be\npreserved, thus transforming it all in a monolithic manner and generating audio\nof low quality, with linguistic distortions. To address this distortion\nproblem, we propose a novel StarGAN framework along with a two-stage training\nprocess that separates emotional features from those independent of emotion by\nusing an autoencoder with two encoders as the generator of the Generative\nAdversarial Network (GAN). The proposed model achieves favourable results in\nboth the objective evaluation and the subjective evaluation in terms of\ndistortion, which reveals that the proposed model can effectively reduce\ndistortion. Furthermore, in data augmentation experiments for end-to-end speech\nemotion recognition, the proposed StarGAN model achieves an increase of 2% in\nMicro-F1 and 5% in Macro-F1 compared to the baseline StarGAN model, which\nindicates that the proposed model is more valuable for data augmentation.", "published": "2021-07-18 04:28:47", "link": "http://arxiv.org/abs/2107.08361v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
