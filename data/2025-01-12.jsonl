{"title": "Discrete-time weak approximation of a Black-Scholes model with drift and volatility Markov switching", "abstract": "We consider a continuous-time financial market with an asset whose price is\nmodeled by a linear stochastic differential equation with drift and volatility\nswitching driven by a uniformly ergodic jump Markov process with a countable\nstate space (in fact, this is a Black-Scholes model with Markov switching). We\nconstruct a multiplicative scheme of series of discrete-time markets with\ndiscrete-time Markov switching. First, we establish that the discrete-time\nswitching Markov chains weakly converge to the limit continuous-time Markov\nprocess. Second, having this in hand, we apply conditioning on Markov chains\nand prove that the discrete-time market models themselves weakly converge to\nthe Black-Scholes model with Markov switching. The convergence is proved under\nvery general assumptions both on the discrete-time net profits and on a\ngenerator of a continuous-time Markov switching process.", "published": "2025-01-12 18:08:27", "link": "http://arxiv.org/abs/2501.06895v1", "categories": ["math.PR", "q-fin.MF"], "primary_category": "math.PR"}
{"title": "Pricing American options under rough volatility using deep-signatures and signature-kernels", "abstract": "We extend the signature-based primal and dual solutions to the optimal\nstopping problem recently introduced in [Bayer et al.: Primal and dual optimal\nstopping with signatures, to appear in Finance & Stochastics 2025], by\nintegrating deep-signature and signature-kernel learning methodologies. These\napproaches are designed for non-Markovian frameworks, in particular enabling\nthe pricing of American options under rough volatility. We demonstrate and\ncompare the performance within the popular rough Heston and rough Bergomi\nmodels.", "published": "2025-01-12 09:40:49", "link": "http://arxiv.org/abs/2501.06758v1", "categories": ["q-fin.MF", "60G40, 60L10, 91G20, 91G60"], "primary_category": "q-fin.MF"}
{"title": "Sequential Portfolio Selection under Latent Side Information-Dependence Structure: Optimality and Universal Learning Algorithms", "abstract": "This paper investigates the investment problem of constructing an optimal\nno-short sequential portfolio strategy in a market with a latent dependence\nstructure between asset prices and partly unobservable side information, which\nis often high-dimensional. The results demonstrate that a dynamic strategy,\nwhich forms a portfolio based on perfect knowledge of the dependence structure\nand full market information over time, may not grow at a higher rate infinitely\noften than a constant strategy, which remains invariant over time.\nSpecifically, if the market is stationary, implying that the dependence\nstructure is statistically stable, the growth rate of an optimal dynamic\nstrategy, utilizing the maximum capacity of the entire market information,\nalmost surely decays over time into an equilibrium state, asymptotically\nconverging to the growth rate of a constant strategy.\n  Technically, this work reassesses the common belief that a constant strategy\nonly attains the optimal limiting growth rate of dynamic strategies when the\nmarket process is identically and independently distributed. By analyzing the\ndynamic log-optimal portfolio strategy as the optimal benchmark in a stationary\nmarket with side information, we show that a random optimal constant strategy\nalmost surely exists, even when a limiting growth rate for the dynamic strategy\ndoes not. Consequently, two approaches to learning algorithms for portfolio\nconstruction are discussed, demonstrating the safety of removing side\ninformation from the learning process while still guaranteeing an asymptotic\ngrowth rate comparable to that of the optimal dynamic strategy.", "published": "2025-01-12 03:49:47", "link": "http://arxiv.org/abs/2501.06701v2", "categories": ["q-fin.MF", "cs.IT", "cs.LG", "math.IT", "math.PR", "q-fin.PM"], "primary_category": "q-fin.MF"}
{"title": "TAPO: Task-Referenced Adaptation for Prompt Optimization", "abstract": "Prompt engineering can significantly improve the performance of large\nlanguage models (LLMs), with automated prompt optimization (APO) gaining\nsignificant attention due to the time-consuming and laborious nature of manual\nprompt design. However, much of the existing work in APO overlooks\ntask-specific characteristics, resulting in prompts that lack domain\nspecificity and are not well-suited for task-specific optimization. In this\npaper, we introduce TAPO, a multitask-aware prompt optimization framework\ncomposed of three key modules. First, a task-aware metric selection module is\nproposed to enhance task-specific prompt generation capabilities. Second, we\npresent a multi-metrics evaluation module to jointly evaluate prompts from\nmultiple perspectives. Third, an evolution-based optimization framework is\nintroduced for automatic prompt refinement, which improves adaptability across\nvarious tasks. Extensive experiments on six datasets demonstrate the\neffectiveness of our approach, and our code is publicly available.", "published": "2025-01-12 02:43:59", "link": "http://arxiv.org/abs/2501.06689v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring the Robustness of Reference-Free Dialogue Evaluation Systems", "abstract": "Advancements in dialogue systems powered by large language models (LLMs) have\noutpaced the development of reliable evaluation metrics, particularly for\ndiverse and creative responses. We present a benchmark for evaluating the\nrobustness of reference-free dialogue metrics against four categories of\nadversarial attacks: speaker tag prefixes, static responses, ungrammatical\nresponses, and repeated conversational context. We analyze metrics such as\nDialogRPT, UniEval, and PromptEval -- a prompt-based method leveraging LLMs --\nacross grounded and ungrounded datasets. By examining both their correlation\nwith human judgment and susceptibility to adversarial attacks, we find that\nthese two axes are not always aligned; metrics that appear to be equivalent\nwhen judged by traditional benchmarks may, in fact, vary in their scores of\nadversarial responses. These findings motivate the development of nuanced\nevaluation frameworks to address real-world dialogue challenges.", "published": "2025-01-12 06:41:52", "link": "http://arxiv.org/abs/2501.06728v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Divide-and-Conquer for Fine-Grained Alignment in LLM-Based\n  Medical Evaluation", "abstract": "In the rapidly evolving landscape of large language models (LLMs) for medical\napplications, ensuring the reliability and accuracy of these models in clinical\nsettings is paramount. Existing benchmarks often focus on fixed-format tasks\nlike multiple-choice QA, which fail to capture the complexity of real-world\nclinical diagnostics. Moreover, traditional evaluation metrics and LLM-based\nevaluators struggle with misalignment, often providing oversimplified\nassessments that do not adequately reflect human judgment. To address these\nchallenges, we introduce HDCEval, a Hierarchical Divide-and-Conquer Evaluation\nframework tailored for fine-grained alignment in medical evaluation. HDCEval is\nbuilt on a set of fine-grained medical evaluation guidelines developed in\ncollaboration with professional doctors, encompassing Patient Question\nRelevance, Medical Knowledge Correctness, and Expression. The framework\ndecomposes complex evaluation tasks into specialized subtasks, each evaluated\nby expert models trained through Attribute-Driven Token Optimization (ADTO) on\na meticulously curated preference dataset. This hierarchical approach ensures\nthat each aspect of the evaluation is handled with expert precision, leading to\na significant improvement in alignment with human evaluators.", "published": "2025-01-12 07:30:49", "link": "http://arxiv.org/abs/2501.06741v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Event Argument Extraction with Enriched Prompts", "abstract": "This work aims to delve deeper into prompt-based event argument extraction\n(EAE) models. We explore the impact of incorporating various types of\ninformation into the prompt on model performance, including trigger, other role\narguments for the same event, and role arguments across multiple events within\nthe same document. Further, we provide the best possible performance that the\nprompt-based EAE model can attain and demonstrate such models can be further\noptimized from the perspective of the training objective. Experiments are\ncarried out on three small language models and two large language models in\nRAMS.", "published": "2025-01-12 14:38:51", "link": "http://arxiv.org/abs/2501.06825v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Fusion for Parameter-Efficient Cross-lingual Transfer", "abstract": "Limited availability of multilingual text corpora for training language\nmodels often leads to poor performance on downstream tasks due to undertrained\nrepresentation spaces for languages other than English. This\n'under-representation' has motivated recent cross-lingual transfer methods to\nleverage the English representation space by e.g. mixing English and\n'non-English' tokens at the input level or extending model parameters to\naccommodate new languages. However, these approaches often come at the cost of\nincreased computational complexity. We propose Fusion forLanguage\nRepresentations (FLARE) in adapters, a novel method that enhances\nrepresentation quality and downstream performance for languages other than\nEnglish while maintaining parameter efficiency. FLARE integrates source and\ntarget language representations within low-rank (LoRA) adapters using\nlightweight linear transformations, maintaining parameter efficiency while\nimproving transfer performance. A series of experiments across representative\ncross-lingual natural language understanding tasks, including natural language\ninference, question-answering and sentiment analysis, demonstrate FLARE's\neffectiveness. FLARE achieves performance improvements of 4.9% for Llama 3.1\nand 2.2% for Gemma~2 compared to standard LoRA fine-tuning on\nquestion-answering tasks, as measured by the exact match metric.", "published": "2025-01-12 18:02:29", "link": "http://arxiv.org/abs/2501.06892v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning ChatGPT for Automatic Scoring of Written Scientific\n  Explanations in Chinese", "abstract": "The development of explanations for scientific phenomena is essential in\nscience assessment, but scoring student-written explanations remains\nchallenging and resource-intensive. Large language models (LLMs) have shown\npromise in addressing this issue, particularly in alphabetic languages like\nEnglish. However, their applicability to logographic languages is less\nexplored. This study investigates the potential of fine-tuning ChatGPT, a\nleading LLM, to automatically score scientific explanations written in Chinese.\nStudent responses to seven scientific explanation tasks were collected and\nautomatically scored, with scoring accuracy examined in relation to reasoning\ncomplexity using the Kendall correlation. A qualitative analysis explored how\nlinguistic features influenced scoring accuracy. The results show that\ndomain-specific adaptation enables ChatGPT to score Chinese scientific\nexplanations with accuracy. However, scoring accuracy correlates with reasoning\ncomplexity: a negative correlation for lower-level responses and a positive one\nfor higher-level responses. The model overrates complex reasoning in low-level\nresponses with intricate sentence structures and underrates high-level\nresponses using concise causal reasoning. These correlations stem from\nlinguistic features--simplicity and clarity enhance accuracy for lower-level\nresponses, while comprehensiveness improves accuracy for higher-level ones.\nSimpler, shorter responses tend to score more accurately at lower levels,\nwhereas longer, information-rich responses yield better accuracy at higher\nlevels. These findings demonstrate the effectiveness of LLMs in automatic\nscoring within a Chinese context and emphasize the importance of linguistic\nfeatures and reasoning complexity in fine-tuning scoring models for educational\nassessments.", "published": "2025-01-12 04:10:56", "link": "http://arxiv.org/abs/2501.06704v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ZNO-Eval: Benchmarking reasoning capabilities of large language models\n  in Ukrainian", "abstract": "As the usage of large language models for problems outside of simple text\nunderstanding or generation increases, assessing their abilities and\nlimitations becomes crucial. While significant progress has been made in this\narea over the last few years, most research has focused on benchmarking\nEnglish, leaving other languages underexplored. This makes evaluating the\nreasoning and robustness level of language models in Ukrainian particularly\nchallenging. The purpose of this work is to establish a comprehensive benchmark\nfor the reasoning capabilities evaluation of large language models in the\nUkrainian language. This paper presents the ZNO-Eval benchmark based on real\nexam tasks from Ukraine's standardized educational testing system: the External\nIndependent Evaluation and the National Multi-subject Test. With single-answer\noptions, multiple-choice, matching, and open-ended questions from diverse\nsubjects, including Ukrainian language, mathematics, history, and geography,\nthis dataset paves the way toward a thorough analysis of reasoning capabilities\nacross different domains and complexities. Evaluation of several well-known\nlanguage models, such as GPT-3.5-Turbo, GPT-4o, GPT-4-Turbo, Mistral Large,\nClaude 3 Opus, and Gemini-1.5 Pro on this benchmark demonstrated the\nsuperiority of GPT-4o in both common knowledge reasoning and intricate language\ntasks. At the same time, Gemini Pro and GPT-4 Turbo excelled in the arithmetic\ndomain, leading in single-answer and open-ended math problems. While all models\nwere close to max performance in text-only common knowledge tasks like history\nand geography, there still is a gap for Ukrainian language and math, thus\nhighlighting the importance of developing specialized language benchmarks for\nmore accurate assessments of model capabilities and limitations across\ndifferent languages and contexts.", "published": "2025-01-12 04:49:06", "link": "http://arxiv.org/abs/2501.06715v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Better Prompt Compression Without Multi-Layer Perceptrons", "abstract": "Prompt compression is a promising approach to speeding up language model\ninference without altering the generative model. Prior works compress prompts\ninto smaller sequences of learned tokens using an encoder that is trained as a\nLowRank Adaptation (LoRA) of the inference language model. However, we show\nthat the encoder does not need to keep the original language model's\narchitecture to achieve useful compression. We introduce the Attention-Only\nCompressor (AOC), which learns a prompt compression encoder after removing the\nmultilayer perceptron (MLP) layers in the Transformer blocks of a language\nmodel, resulting in an encoder with roughly 67% less parameters compared to the\noriginal model. Intriguingly we find that, across a range of compression ratios\nup to 480x, AOC can better regenerate prompts and outperform a baseline\ncompression encoder that is a LoRA of the inference language model without\nremoving MLP layers. These results demonstrate that the architecture of prompt\ncompression encoders does not need to be identical to that of the original\ndecoder language model, paving the way for further research into architectures\nand approaches for prompt compression.", "published": "2025-01-12 06:57:06", "link": "http://arxiv.org/abs/2501.06730v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ZOQO: Zero-Order Quantized Optimization", "abstract": "The increasing computational and memory demands in deep learning present\nsignificant challenges, especially in resource-constrained environments. We\nintroduce a zero-order quantized optimization (ZOQO) method designed for\ntraining models with quantized parameters and operations. Our approach\nleverages zero-order approximations of the gradient sign and adapts the\nlearning process to maintain the parameters' quantization without the need for\nfull-precision gradient calculations. We demonstrate the effectiveness of ZOQO\nthrough experiments in fine-tuning of large language models and black-box\nadversarial attacks. Despite the limitations of zero-order and quantized\noperations training, our method achieves competitive performance compared to\nfull-precision methods, highlighting its potential for low-resource\nenvironments.", "published": "2025-01-12 07:15:55", "link": "http://arxiv.org/abs/2501.06736v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Padding Tone: A Mechanistic Analysis of Padding Tokens in T2I Models", "abstract": "Text-to-image (T2I) diffusion models rely on encoded prompts to guide the\nimage generation process. Typically, these prompts are extended to a fixed\nlength by adding padding tokens before text encoding. Despite being a default\npractice, the influence of padding tokens on the image generation process has\nnot been investigated. In this work, we conduct the first in-depth analysis of\nthe role padding tokens play in T2I models. We develop two causal techniques to\nanalyze how information is encoded in the representation of tokens across\ndifferent components of the T2I pipeline. Using these techniques, we\ninvestigate when and how padding tokens impact the image generation process.\nOur findings reveal three distinct scenarios: padding tokens may affect the\nmodel's output during text encoding, during the diffusion process, or be\neffectively ignored. Moreover, we identify key relationships between these\nscenarios and the model's architecture (cross or self-attention) and its\ntraining process (frozen or trained text encoder). These insights contribute to\na deeper understanding of the mechanisms of padding tokens, potentially\ninforming future model design and training practices in T2I systems.", "published": "2025-01-12 08:36:38", "link": "http://arxiv.org/abs/2501.06751v2", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "3DCoMPaT200: Language-Grounded Compositional Understanding of Parts and\n  Materials of 3D Shapes", "abstract": "Understanding objects in 3D at the part level is essential for humans and\nrobots to navigate and interact with the environment. Current datasets for\npart-level 3D object understanding encompass a limited range of categories. For\ninstance, the ShapeNet-Part and PartNet datasets only include 16, and 24 object\ncategories respectively. The 3DCoMPaT dataset, specifically designed for\ncompositional understanding of parts and materials, contains only 42 object\ncategories. To foster richer and fine-grained part-level 3D understanding, we\nintroduce 3DCoMPaT200, a large-scale dataset tailored for compositional\nunderstanding of object parts and materials, with 200 object categories with\n$\\approx$5 times larger object vocabulary compared to 3DCoMPaT and $\\approx$ 4\ntimes larger part categories. Concretely, 3DCoMPaT200 significantly expands\nupon 3DCoMPaT, featuring 1,031 fine-grained part categories and 293 distinct\nmaterial classes for compositional application to 3D object parts.\nAdditionally, to address the complexities of compositional 3D modeling, we\npropose a novel task of Compositional Part Shape Retrieval using ULIP to\nprovide a strong 3D foundational model for 3D Compositional Understanding. This\nmethod evaluates the model shape retrieval performance given one, three, or six\nparts described in text format. These results show that the model's performance\nimproves with an increasing number of style compositions, highlighting the\ncritical role of the compositional dataset. Such results underscore the\ndataset's effectiveness in enhancing models' capability to understand complex\n3D shapes from a compositional perspective. Code and Data can be found at\nhttp://github.com/3DCoMPaT200/3DCoMPaT200", "published": "2025-01-12 11:46:07", "link": "http://arxiv.org/abs/2501.06785v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Bridging the Fairness Gap: Enhancing Pre-trained Models with\n  LLM-Generated Sentences", "abstract": "Pre-trained language models (PLMs) are trained on data that inherently\ncontains gender biases, leading to undesirable impacts. Traditional debiasing\nmethods often rely on external corpora, which may lack quality, diversity, or\ndemographic balance, affecting the effectiveness of debiasing. With the rise of\nlarge language models and their extensive knowledge, we propose enhancing\nfairness (Fair-Gender) in PLMs by absorbing coherent, attribute-balanced, and\nsemantically rich sentences. However, these sentences cannot be directly used\nfor debiasing due to alignment issues and the risk of negative transfer. We\naddress this by applying causal analysis to estimate causal effects, filtering\nout unaligned sentences, and identifying aligned ones for incorporation into\nPLMs, thereby ensuring positive transfer. Experiments show that our approach\nsignificantly reduces gender biases in PLMs while preserving their language\nexpressiveness.", "published": "2025-01-12 12:32:43", "link": "http://arxiv.org/abs/2501.06795v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Correcting Annotator Bias in Training Data: Population-Aligned Instance\n  Replication (PAIR)", "abstract": "Models trained on crowdsourced labels may not reflect broader population\nviews, because those who work as annotators do not represent the population. We\npropose Population-Aligned Instance Replication (PAIR), a method to address\nbias caused by non-representative annotator pools. Using a simulation study of\noffensive language and hate speech, we create two types of annotators with\ndifferent labeling tendencies and generate datasets with varying proportions of\nthe types. We observe that models trained on unbalanced annotator pools show\npoor calibration compared to those trained on representative data. By\nduplicating labels from underrepresented annotator groups to match population\nproportions, PAIR reduces bias without collecting additional annotations. These\nresults suggest that statistical techniques from survey research can improve\nmodel performance. We conclude with practical recommendations for improving the\nrepresentativity of training data and model performance.", "published": "2025-01-12 14:39:26", "link": "http://arxiv.org/abs/2501.06826v2", "categories": ["stat.ME", "cs.CL"], "primary_category": "stat.ME"}
{"title": "A Comprehensive Evaluation of Large Language Models on Mental Illnesses\n  in Arabic Context", "abstract": "Mental health disorders pose a growing public health concern in the Arab\nworld, emphasizing the need for accessible diagnostic and intervention tools.\nLarge language models (LLMs) offer a promising approach, but their application\nin Arabic contexts faces challenges including limited labeled datasets,\nlinguistic complexity, and translation biases. This study comprehensively\nevaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual\nones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA),\ninvestigating the impact of prompt design, language configuration (native\nArabic vs. translated English, and vice versa), and few-shot prompting on\ndiagnostic performance. We find that prompt engineering significantly\ninfluences LLM scores mainly due to reduced instruction following, with our\nstructured prompt outperforming a less structured variant on multi-class\ndatasets, with an average difference of 14.5\\%. While language influence on\nperformance was modest, model selection proved crucial: Phi-3.5 MoE excelled in\nbalanced accuracy, particularly for binary classification, while Mistral NeMo\nshowed superior performance in mean absolute error for severity prediction\ntasks. Few-shot prompting consistently improved performance, with particularly\nsubstantial gains observed for GPT-4o Mini on multi-class classification,\nboosting accuracy by an average factor of 1.58. These findings underscore the\nimportance of prompt optimization, multilingual analysis, and few-shot learning\nfor developing culturally sensitive and effective LLM-based mental health tools\nfor Arabic-speaking populations.", "published": "2025-01-12 16:17:25", "link": "http://arxiv.org/abs/2501.06859v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Risk-Averse Finetuning of Large Language Models", "abstract": "We consider the challenge of mitigating the generation of negative or toxic\ncontent by the Large Language Models (LLMs) in response to certain prompts. We\npropose integrating risk-averse principles into LLM fine-tuning to minimize the\noccurrence of harmful outputs, particularly rare but significant events. By\noptimizing the risk measure of Conditional Value at Risk (CVaR), our\nmethodology trains LLMs to exhibit superior performance in avoiding toxic\noutputs while maintaining effectiveness in generative tasks. Empirical\nevaluations on sentiment modification and toxicity mitigation tasks demonstrate\nthe efficacy of risk-averse reinforcement learning with human feedback (RLHF)\nin promoting a safer and more constructive online discourse environment.", "published": "2025-01-12 19:48:21", "link": "http://arxiv.org/abs/2501.06911v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Improving Cross-Lingual Phonetic Representation of Low-Resource\n  Languages Through Language Similarity Analysis", "abstract": "This paper examines how linguistic similarity affects cross-lingual phonetic\nrepresentation in speech processing for low-resource languages, emphasizing\neffective source language selection. Previous cross-lingual research has used\nvarious source languages to enhance performance for the target low-resource\nlanguage without thorough consideration of selection. Our study stands out by\nproviding an in-depth analysis of language selection, supported by a practical\napproach to assess phonetic proximity among multiple language families. We\ninvestigate how within-family similarity impacts performance in multilingual\ntraining, which aids in understanding language dynamics. We also evaluate the\neffect of using phonologically similar languages, regardless of family. For the\nphoneme recognition task, utilizing phonologically similar languages\nconsistently achieves a relative improvement of 55.6% over monolingual\ntraining, even surpassing the performance of a large-scale self-supervised\nlearning model. Multilingual training within the same language family\ndemonstrates that higher phonological similarity enhances performance, while\nlower similarity results in degraded performance compared to monolingual\ntraining.", "published": "2025-01-12 13:29:24", "link": "http://arxiv.org/abs/2501.06810v1", "categories": ["eess.AS", "cs.CL", "cs.SD", "I.2.7; J.5; H.5.5; I.5.4"], "primary_category": "eess.AS"}
{"title": "LLMs Model Non-WEIRD Populations: Experiments with Synthetic Cultural\n  Agents", "abstract": "Despite its importance, studying economic behavior across diverse, non-WEIRD\n(Western, Educated, Industrialized, Rich, and Democratic) populations presents\nsignificant challenges. We address this issue by introducing a novel\nmethodology that uses Large Language Models (LLMs) to create synthetic cultural\nagents (SCAs) representing these populations. We subject these SCAs to classic\nbehavioral experiments, including the dictator and ultimatum games. Our results\ndemonstrate substantial cross-cultural variability in experimental behavior.\nNotably, for populations with available data, SCAs' behaviors qualitatively\nresemble those of real human subjects. For unstudied populations, our method\ncan generate novel, testable hypotheses about economic behavior. By integrating\nAI into experimental economics, this approach offers an effective and ethical\nmethod to pilot experiments and refine protocols for hard-to-reach populations.\nOur study provides a new tool for cross-cultural economic studies and\ndemonstrates how LLMs can help experimental behavioral research.", "published": "2025-01-12 15:06:28", "link": "http://arxiv.org/abs/2501.06834v1", "categories": ["cs.AI", "cs.CL", "econ.GN", "q-fin.EC"], "primary_category": "cs.AI"}
{"title": "SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training", "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance across\ndiverse tasks, yet their training remains highly resource-intensive and\nsusceptible to critical challenges such as training instability. A predominant\nsource of this instability stems from gradient and loss spikes, which disrupt\nthe learning process, often leading to costly interventions like checkpoint\nrecovery and experiment restarts, further amplifying inefficiencies. This paper\npresents a comprehensive investigation into gradient spikes observed during LLM\ntraining, revealing their prevalence across multiple architectures and\ndatasets. Our analysis shows that these spikes can be up to $1000\\times$ larger\nthan typical gradients, substantially deteriorating model performance. To\naddress this issue, we propose Spike-Aware Adam with Momentum Reset SPAM, a\nnovel optimizer designed to counteract gradient spikes through momentum reset\nand spike-aware gradient clipping. Extensive experiments, including both\npre-training and fine-tuning, demonstrate that SPAM consistently surpasses Adam\nand its variants across various tasks, including (1) LLM pre-training from 60M\nto 1B, (2) 4-bit LLM pre-training,(3) reinforcement learning, and (4) Time\nSeries Forecasting. Additionally, SPAM facilitates memory-efficient training by\nenabling sparse momentum, where only a subset of momentum terms are maintained\nand updated. When operating under memory constraints, SPAM outperforms\nstate-of-the-art memory-efficient optimizers such as GaLore and Adam-Mini. Our\nwork underscores the importance of mitigating gradient spikes in LLM training\nand introduces an effective optimization strategy that enhances both training\nstability and resource efficiency at scale. Code is available at\nhttps://github.com/TianjinYellow/SPAM-Optimizer.git", "published": "2025-01-12 15:21:22", "link": "http://arxiv.org/abs/2501.06842v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A General Framework for Inference-time Scaling and Steering of Diffusion\n  Models", "abstract": "Diffusion models produce impressive results in modalities ranging from images\nand video to protein design and text. However, generating samples with\nuser-specified properties remains a challenge. Recent research proposes\nfine-tuning models to maximize rewards that capture desired properties, but\nthese methods require expensive training and are prone to mode collapse. In\nthis work, we propose Feynman Kac (FK) steering, an inference-time framework\nfor steering diffusion models with reward functions. FK steering works by\nsampling a system of multiple interacting diffusion processes, called\nparticles, and resampling particles at intermediate steps based on scores\ncomputed using functions called potentials. Potentials are defined using\nrewards for intermediate states and are selected such that a high value\nindicates that the particle will yield a high-reward sample. We explore various\nchoices of potentials, intermediate rewards, and samplers. We evaluate FK\nsteering on text-to-image and text diffusion models. For steering text-to-image\nmodels with a human preference reward, we find that FK steering a 0.8B\nparameter model outperforms a 2.6B parameter fine-tuned model on prompt\nfidelity, with faster sampling and no training. For steering text diffusion\nmodels with rewards for text quality and specific text attributes, we find that\nFK steering generates lower perplexity, more linguistically acceptable outputs\nand enables gradient-free control of attributes like toxicity. Our results\ndemonstrate that inference-time scaling and steering of diffusion models, even\nwith off-the-shelf rewards, can provide significant sample quality gains and\ncontrollability benefits. Code is available at\nhttps://github.com/zacharyhorvitz/Fk-Diffusion-Steering .", "published": "2025-01-12 15:34:24", "link": "http://arxiv.org/abs/2501.06848v3", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Transfer Learning of Tabular Data by Finetuning Large Language Models", "abstract": "Despite the artificial intelligence (AI) revolution, deep learning has yet to\nachieve much success with tabular data due to heterogeneous feature space and\nlimited sample sizes without viable transfer learning. The new era of\ngenerative AI, powered by large language models (LLM), brings unprecedented\nlearning opportunities to diverse data and domains. This paper investigates the\neffectiveness of an LLM application programming interface (API) and transfer\nlearning of LLM in tabular data classification. LLM APIs respond to input text\nprompts with tokenized data and instructions, whereas transfer learning\nfinetunes an LLM for a target classification task. This paper proposes an\nend-to-end finetuning of LLM to demonstrate cross-data transfer learning on ten\nbenchmark data sets when large pre-trained tabular data models do not exist to\nfacilitate transfer learning. The proposed LLM finetuning method outperforms\nstate-of-the-art machine and deep learning methods on tabular data with less\nthan ten features - a standard feature size for tabular data sets. The transfer\nlearning approach uses a fraction of the computational cost of other deep\nlearning or API-based solutions while ensuring competitive or superior\nclassification performance.", "published": "2025-01-12 16:23:18", "link": "http://arxiv.org/abs/2501.06863v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Harnessing Large Language Models for Disaster Management: A Survey", "abstract": "Large language models (LLMs) have revolutionized scientific research with\ntheir exceptional capabilities and transformed various fields. Among their\npractical applications, LLMs have been playing a crucial role in mitigating\nthreats to human life, infrastructure, and the environment. Despite growing\nresearch in disaster LLMs, there remains a lack of systematic review and\nin-depth analysis of LLMs for natural disaster management. To address the gap,\nthis paper presents a comprehensive survey of existing LLMs in natural disaster\nmanagement, along with a taxonomy that categorizes existing works based on\ndisaster phases and application scenarios. By collecting public datasets and\nidentifying key challenges and opportunities, this study aims to guide the\nprofessional community in developing advanced LLMs for disaster management to\nenhance the resilience against natural disasters.", "published": "2025-01-12 21:00:50", "link": "http://arxiv.org/abs/2501.06932v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Causal Claims in Economics", "abstract": "We analyze over 44,000 NBER and CEPR working papers from 1980 to 2023 using a\ncustom language model to construct knowledge graphs that map economic concepts\nand their relationships. We distinguish between general claims and those\ndocumented via causal inference methods (e.g., DiD, IV, RDD, RCTs). We document\na substantial rise in the share of causal claims-from roughly 4% in 1990 to\nnearly 28% in 2020-reflecting the growing influence of the \"credibility\nrevolution.\" We find that causal narrative complexity (e.g., the depth of\ncausal chains) strongly predicts both publication in top-5 journals and higher\ncitation counts, whereas non-causal complexity tends to be uncorrelated or\nnegatively associated with these outcomes. Novelty is also pivotal for top-5\npublication, but only when grounded in credible causal methods: introducing\ngenuinely new causal edges or paths markedly increases both the likelihood of\nacceptance at leading outlets and long-run citations, while non-causal novelty\nexhibits weak or even negative effects. Papers engaging with central, widely\nrecognized concepts tend to attract more citations, highlighting a divergence\nbetween factors driving publication success and long-term academic impact.\nFinally, bridging underexplored concept pairs is rewarded primarily when\ngrounded in causal methods, yet such gap filling exhibits no consistent link\nwith future citations. Overall, our findings suggest that methodological rigor\nand causal innovation are key drivers of academic recognition, but sustained\nimpact may require balancing novel contributions with conceptual integration\ninto established economic discourse.", "published": "2025-01-12 17:03:45", "link": "http://arxiv.org/abs/2501.06873v1", "categories": ["econ.GN", "cs.CL", "cs.IR", "cs.SI", "q-fin.EC", "stat.ME"], "primary_category": "econ.GN"}
{"title": "Integrating Pause Information with Word Embeddings in Language Models\n  for Alzheimer's Disease Detection from Spontaneous Speech", "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder\ncharacterized by cognitive decline and memory loss. Early detection of AD is\ncrucial for effective intervention and treatment. In this paper, we propose a\nnovel approach to AD detection from spontaneous speech, which incorporates\npause information into language models. Our method involves encoding pause\ninformation into embeddings and integrating them into the typical\ntransformer-based language model, enabling it to capture both semantic and\ntemporal features of speech data. We conduct experiments on the Alzheimer's\nDementia Recognition through Spontaneous Speech (ADReSS) dataset and its\nextension, the ADReSSo dataset, comparing our method with existing approaches.\nOur method achieves an accuracy of 83.1% in the ADReSSo test set. The results\ndemonstrate the effectiveness of our approach in discriminating between AD\npatients and healthy individuals, highlighting the potential of pauses as a\nvaluable indicator for AD detection. By leveraging speech analysis as a\nnon-invasive and cost-effective tool for AD detection, our research contributes\nto early diagnosis and improved management of this debilitating disease.", "published": "2025-01-12 06:34:38", "link": "http://arxiv.org/abs/2501.06727v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Sanidha: A Studio Quality Multi-Modal Dataset for Carnatic Music", "abstract": "Music source separation demixes a piece of music into its individual sound\nsources (vocals, percussion, melodic instruments, etc.), a task with no simple\nmathematical solution. It requires deep learning methods involving training on\nlarge datasets of isolated music stems. The most commonly available datasets\nare made from commercial Western music, limiting the models' applications to\nnon-Western genres like Carnatic music. Carnatic music is a live tradition,\nwith the available multi-track recordings containing overlapping sounds and\nbleeds between the sources. This poses a challenge to commercially available\nsource separation models like Spleeter and Hybrid Demucs. In this work, we\nintroduce 'Sanidha', the first open-source novel dataset for Carnatic music,\noffering studio-quality, multi-track recordings with minimal to no overlap or\nbleed. Along with the audio files, we provide high-definition videos of the\nartists' performances. Additionally, we fine-tuned Spleeter, one of the most\ncommonly used source separation models, on our dataset and observed improved\nSDR performance compared to fine-tuning on a pre-existing Carnatic multi-track\ndataset. The outputs of the fine-tuned model with 'Sanidha' are evaluated\nthrough a listening study.", "published": "2025-01-12 22:39:58", "link": "http://arxiv.org/abs/2501.06959v1", "categories": ["cs.SD", "cs.DL", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
