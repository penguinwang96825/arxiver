{"title": "Semantics or spelling? Probing contextual word embeddings with\n  orthographic noise", "abstract": "Pretrained language model (PLM) hidden states are frequently employed as\ncontextual word embeddings (CWE): high-dimensional representations that encode\nsemantic information given linguistic context. Across many areas of\ncomputational linguistics research, similarity between CWEs is interpreted as\nsemantic similarity. However, it remains unclear exactly what information is\nencoded in PLM hidden states. We investigate this practice by probing PLM\nrepresentations using minimal orthographic noise. We expect that if CWEs\nprimarily encode semantic information, a single character swap in the input\nword will not drastically affect the resulting representation,given sufficient\nlinguistic context. Surprisingly, we find that CWEs generated by popular PLMs\nare highly sensitive to noise in input data, and that this sensitivity is\nrelated to subword tokenization: the fewer tokens used to represent a word at\ninput, the more sensitive its corresponding CWE. This suggests that CWEs\ncapture information unrelated to word-level meaning and can be manipulated\nthrough trivial modifications of input data. We conclude that these PLM-derived\nCWEs may not be reliable semantic proxies, and that caution is warranted when\ninterpreting representational similarity", "published": "2024-08-08 02:07:25", "link": "http://arxiv.org/abs/2408.04162v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "mbrs: A Library for Minimum Bayes Risk Decoding", "abstract": "Minimum Bayes risk (MBR) decoding is a decision rule of text generation tasks\nthat outperforms conventional maximum a posterior (MAP) decoding using beam\nsearch by selecting high-quality outputs based on a utility function rather\nthan those with high-probability. Typically, it finds the most suitable\nhypothesis from the set of hypotheses under the sampled pseudo-references. mbrs\nis a library of MBR decoding, which can flexibly combine various metrics,\nalternative expectation estimations, and algorithmic variants. It is designed\nwith a focus on speed measurement and calling count of code blocks,\ntransparency, reproducibility, and extensibility, which are essential for\nresearchers and developers. We published our mbrs as an MIT-licensed\nopen-source project, and the code is available on GitHub.\n  GitHub: https://github.com/naist-nlp/mbrs", "published": "2024-08-08 02:28:32", "link": "http://arxiv.org/abs/2408.04167v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Simplifying Translations for Children: Iterative Simplification\n  Considering Age of Acquisition with LLMs", "abstract": "In recent years, neural machine translation (NMT) has been widely used in\neveryday life. However, the current NMT lacks a mechanism to adjust the\ndifficulty level of translations to match the user's language level.\nAdditionally, due to the bias in the training data for NMT, translations of\nsimple source sentences are often produced with complex words. In particular,\nthis could pose a problem for children, who may not be able to understand the\nmeaning of the translations correctly. In this study, we propose a method that\nreplaces words with high Age of Acquisitions (AoA) in translations with simpler\nwords to match the translations to the user's level. We achieve this by using\nlarge language models (LLMs), providing a triple of a source sentence, a\ntranslation, and a target word to be replaced. We create a benchmark dataset\nusing back-translation on Simple English Wikipedia. The experimental results\nobtained from the dataset show that our method effectively replaces high-AoA\nwords with lower-AoA words and, moreover, can iteratively replace most of the\nhigh-AoA words while still maintaining high BLEU and COMET scores.", "published": "2024-08-08 04:57:36", "link": "http://arxiv.org/abs/2408.04217v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mathfish: Evaluating Language Model Math Reasoning via Grounding in\n  Educational Curricula", "abstract": "To ensure that math curriculum is grade-appropriate and aligns with critical\nskills or concepts in accordance with educational standards, pedagogical\nexperts can spend months carefully reviewing published math problems. Drawing\ninspiration from this process, our work presents a novel angle for evaluating\nlanguage models' (LMs) mathematical abilities, by investigating whether they\ncan discern skills and concepts enabled by math content. We contribute two\ndatasets: one consisting of 385 fine-grained descriptions of K-12 math skills\nand concepts, or standards, from Achieve the Core (ATC), and another of 9.9K\nmath problems labeled with these standards (MathFish). We develop two tasks for\nevaluating LMs' abilities to assess math problems: (1) verifying whether a\nproblem aligns with a given standard, and (2) tagging a problem with all\naligned standards. Working with experienced teachers, we find that LMs struggle\nto tag and verify standards linked to problems, and instead predict labels that\nare close to ground truth, but differ in subtle ways. We also show that LMs\noften generate problems that do not fully align with standards described in\nprompts, suggesting the need for careful scrutiny on use cases involving LMs\nfor generating curricular materials. Finally, we categorize problems in GSM8k\nusing math standards, allowing us to better understand why some problems are\nmore difficult to solve for models than others.", "published": "2024-08-08 05:28:34", "link": "http://arxiv.org/abs/2408.04226v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Rewrite: Generalized LLM-Generated Text Detection", "abstract": "Large language models (LLMs) present significant risks when used to generate\nnon-factual content and spread disinformation at scale. Detecting such\nLLM-generated content is crucial, yet current detectors often struggle to\ngeneralize in open-world contexts. We introduce Learning2Rewrite, a novel\nframework for detecting AI-generated text with exceptional generalization to\nunseen domains. Our method leverages the insight that LLMs inherently modify\nAI-generated content less than human-written text when tasked with rewriting.\nBy training LLMs to minimize alterations on AI-generated inputs, we amplify\nthis disparity, yielding a more distinguishable and generalizable edit distance\nacross diverse text distributions. Extensive experiments on data from 21\nindependent domains and four major LLMs (GPT-3.5, GPT-4, Gemini, and Llama-3)\ndemonstrate that our detector outperforms state-of-the-art detection methods by\nup to 23.04% in AUROC for in-distribution tests, 37.26% for out-of-distribution\ntests, and 48.66% under adversarial attacks. Our unique training objective\nensures better generalizability compared to directly training for\nclassification, when leveraging the same amount of parameters. Our findings\nsuggest that reinforcing LLMs' inherent rewriting tendencies offers a robust\nand scalable solution for detecting AI-generated text.", "published": "2024-08-08 05:53:39", "link": "http://arxiv.org/abs/2408.04237v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Explicating the Implicit: Argument Detection Beyond Sentence Boundaries", "abstract": "Detecting semantic arguments of a predicate word has been conventionally\nmodeled as a sentence-level task. The typical reader, however, perfectly\ninterprets predicate-argument relations in a much wider context than just the\nsentence where the predicate was evoked. In this work, we reformulate the\nproblem of argument detection through textual entailment to capture semantic\nrelations across sentence boundaries. We propose a method that tests whether\nsome semantic relation can be inferred from a full passage by first encoding it\ninto a simple and standalone proposition and then testing for entailment\nagainst the passage. Our method does not require direct supervision, which is\ngenerally absent due to dataset scarcity, but instead builds on existing NLI\nand sentence-level SRL resources. Such a method can potentially explicate\npragmatically understood relations into a set of explicit sentences. We\ndemonstrate it on a recent document-level benchmark, outperforming some\nsupervised methods and contemporary language models.", "published": "2024-08-08 06:18:24", "link": "http://arxiv.org/abs/2408.04246v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Analysis of Argument Structure Constructions in the Large Language Model\n  BERT", "abstract": "This study investigates how BERT processes and represents Argument Structure\nConstructions (ASCs), extending previous LSTM analyses. Using a dataset of 2000\nsentences across four ASC types (transitive, ditransitive, caused-motion,\nresultative), we analyzed BERT's token embeddings across 12 layers.\nVisualizations with MDS and t-SNE and clustering quantified by Generalized\nDiscrimination Value (GDV) were used. Feedforward classifiers (probes)\npredicted construction categories from embeddings. CLS token embeddings\nclustered best in layers 2-4, decreased in intermediate layers, and slightly\nincreased in final layers. DET and SUBJ embeddings showed consistent clustering\nin intermediate layers, VERB embeddings increased in clustering from layer 1 to\n12, and OBJ embeddings peaked in layer 10. Probe accuracies indicated low\nconstruction information in layer 1, with over 90 percent accuracy from layer 2\nonward, revealing latent construction information beyond GDV clustering. Fisher\nDiscriminant Ratio (FDR) analysis of attention weights showed OBJ tokens were\ncrucial for differentiating ASCs, followed by VERB and DET tokens. SUBJ, CLS,\nand SEP tokens had insignificant FDR scores. This study highlights BERT's\nlayered processing of linguistic constructions and its differences from LSTMs.\nFuture research will compare these findings with neuroimaging data to\nunderstand the neural correlates of ASC processing. This research underscores\nneural language models' potential to mirror linguistic processing in the human\nbrain, offering insights into the computational and neural mechanisms\nunderlying language understanding.", "published": "2024-08-08 07:12:46", "link": "http://arxiv.org/abs/2408.04270v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LaDiMo: Layer-wise Distillation Inspired MoEfier", "abstract": "The advent of large language models has revolutionized natural language\nprocessing, but their increasing complexity has led to substantial training\ncosts, resource demands, and environmental impacts. In response, sparse\nMixture-of-Experts (MoE) models have emerged as a promising alternative to\ndense models. Since training MoE models from scratch can be prohibitively\nexpensive, recent studies have explored leveraging knowledge from pre-trained\nnon-MoE models. However, existing approaches have limitations, such as\nrequiring significant hardware resources and data. We propose a novel\nalgorithm, LaDiMo, which efficiently converts a Transformer-based non-MoE model\ninto a MoE model with minimal additional training cost. LaDiMo consists of two\nstages: layer-wise expert construction and routing policy decision. By\nharnessing the concept of Knowledge Distillation, we compress the model and\nrapidly recover its performance. Furthermore, we develop an adaptive router\nthat optimizes inference efficiency by profiling the distribution of routing\nweights and determining a layer-wise policy that balances accuracy and latency.\nWe demonstrate the effectiveness of our method by converting the LLaMA2-7B\nmodel to a MoE model using only 100K tokens, reducing activated parameters by\nover 20% while keeping accuracy. Our approach offers a flexible and efficient\nsolution for building and deploying MoE models.", "published": "2024-08-08 07:37:26", "link": "http://arxiv.org/abs/2408.04278v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection", "abstract": "The ease of access to large language models (LLMs) has enabled a widespread\nof machine-generated texts, and now it is often hard to tell whether a piece of\ntext was human-written or machine-generated. This raises concerns about\npotential misuse, particularly within educational and academic domains. Thus,\nit is important to develop practical systems that can automate the process.\nHere, we present one such system, LLM-DetectAIve, designed for fine-grained\ndetection. Unlike most previous work on machine-generated text detection, which\nfocused on binary classification, LLM-DetectAIve supports four categories: (i)\nhuman-written, (ii) machine-generated, (iii) machine-written, then\nmachine-humanized, and (iv) human-written, then machine-polished. Category\n(iii) aims to detect attempts to obfuscate the fact that a text was\nmachine-generated, while category (iv) looks for cases where the LLM was used\nto polish a human-written text, which is typically acceptable in academic\nwriting, but not in education. Our experiments show that LLM-DetectAIve can\neffectively identify the above four categories, which makes it a potentially\nuseful tool in education, academia, and other domains.\n  LLM-DetectAIve is publicly accessible at\nhttps://github.com/mbzuai-nlp/LLM-DetectAIve. The video describing our system\nis available at https://youtu.be/E8eT_bE7k8c.", "published": "2024-08-08 07:43:17", "link": "http://arxiv.org/abs/2408.04284v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EMTeC: A Corpus of Eye Movements on Machine-Generated Texts", "abstract": "The Eye Movements on Machine-Generated Texts Corpus (EMTeC) is a naturalistic\neye-movements-while-reading corpus of 107 native English speakers reading\nmachine-generated texts. The texts are generated by three large language models\nusing five different decoding strategies, and they fall into six different text\ntype categories. EMTeC entails the eye movement data at all stages of\npre-processing, i.e., the raw coordinate data sampled at 2000 Hz, the fixation\nsequences, and the reading measures. It further provides both the original and\na corrected version of the fixation sequences, accounting for vertical\ncalibration drift. Moreover, the corpus includes the language models' internals\nthat underlie the generation of the stimulus texts: the transition scores, the\nattention scores, and the hidden states. The stimuli are annotated for a range\nof linguistic features both at text and at word level. We anticipate EMTeC to\nbe utilized for a variety of use cases such as, but not restricted to, the\ninvestigation of reading behavior on machine-generated text and the impact of\ndifferent decoding strategies; reading behavior on different text types; the\ndevelopment of new pre-processing, data filtering, and drift correction\nalgorithms; the cognitive interpretability and enhancement of language models;\nand the assessment of the predictive power of surprisal and entropy for human\nreading times. The data at all stages of pre-processing, the model internals,\nand the code to reproduce the stimulus generation, data pre-processing and\nanalyses can be accessed via https://github.com/DiLi-Lab/EMTeC/.", "published": "2024-08-08 08:00:45", "link": "http://arxiv.org/abs/2408.04289v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overview of the NLPCC 2024 Shared Task on Chinese Metaphor Generation", "abstract": "This paper presents the results of the shared task on Chinese metaphor\ngeneration, hosted at the 13th CCF Conference on Natural Language Processing\nand Chinese Computing (NLPCC 2024). The goal of this shared task is to generate\nChinese metaphors using machine learning techniques and effectively identifying\nbasic components of metaphorical sentences. It is divided into two subtasks: 1)\nMetaphor Generation, which involves creating a metaphor from a provided tuple\nconsisting of TENOR, GROUND, and VEHICLE. The goal here is to synthesize a\nmetaphor that connects the subject (i.e. TENOR) with the object (i.e. VEHICLE),\nguided by the concept of the GROUND. 2) Metaphor Components Identification,\nwhich extracts the most fitting TENORs, GROUNDs, and VEHICLEs from a\nmetaphorical sentence. This component requires the identification of the most\nfitting metaphor elements that correspond to the specified grounds. In addition\nto overall results, we report on the setup and insights from the metaphor\ngeneration shared task, which attracted a total of 4 participating teams across\nboth subtasks.", "published": "2024-08-08 11:29:43", "link": "http://arxiv.org/abs/2408.04378v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Open-domain Implicit Format Control for Large Language Model Generation", "abstract": "Controlling the format of outputs generated by large language models (LLMs)\nis a critical functionality in various applications. Current methods typically\nemploy constrained decoding with rule-based automata or fine-tuning with\nmanually crafted format instructions, both of which struggle with open-domain\nformat requirements. To address this limitation, we introduce a novel framework\nfor controlled generation in LLMs, leveraging user-provided, one-shot QA pairs.\nThis study investigates LLMs' capabilities to follow open-domain, one-shot\nconstraints and replicate the format of the example answers. We observe that\nthis is a non-trivial problem for current LLMs. We also develop a dataset\ncollection methodology for supervised fine-tuning that enhances the open-domain\nformat control of LLMs without degrading output quality, as well as a benchmark\non which we evaluate both the helpfulness and format correctness of LLM\noutputs. The resulting datasets, named OIFC-SFT, along with the related code,\nwill be made publicly available at https://github.com/cofe-ai/OIFC.", "published": "2024-08-08 11:51:45", "link": "http://arxiv.org/abs/2408.04392v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recognizing Emotion Regulation Strategies from Human Behavior with Large\n  Language Models", "abstract": "Human emotions are often not expressed directly, but regulated according to\ninternal processes and social display rules. For affective computing systems,\nan understanding of how users regulate their emotions can be highly useful, for\nexample to provide feedback in job interview training, or in psychotherapeutic\nscenarios. However, at present no method to automatically classify different\nemotion regulation strategies in a cross-user scenario exists. At the same\ntime, recent studies showed that instruction-tuned Large Language Models (LLMs)\ncan reach impressive performance across a variety of affect recognition tasks\nsuch as categorical emotion recognition or sentiment analysis. While these\nresults are promising, it remains unclear to what extent the representational\npower of LLMs can be utilized in the more subtle task of classifying users'\ninternal emotion regulation strategy. To close this gap, we make use of the\nrecently introduced \\textsc{Deep} corpus for modeling the social display of the\nemotion shame, where each point in time is annotated with one of seven\ndifferent emotion regulation classes. We fine-tune Llama2-7B as well as the\nrecently introduced Gemma model using Low-rank Optimization on prompts\ngenerated from different sources of information on the \\textsc{Deep} corpus.\nThese include verbal and nonverbal behavior, person factors, as well as the\nresults of an in-depth interview after the interaction. Our results show, that\na fine-tuned Llama2-7B LLM is able to classify the utilized emotion regulation\nstrategy with high accuracy (0.84) without needing access to data from\npost-interaction interviews. This represents a significant improvement over\nprevious approaches based on Bayesian Networks and highlights the importance of\nmodeling verbal behavior in emotion regulation.", "published": "2024-08-08 12:47:10", "link": "http://arxiv.org/abs/2408.04420v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AcrosticSleuth: Probabilistic Identification and Ranking of Acrostics in\n  Multilingual Corpora", "abstract": "For centuries, writers have hidden messages in their texts as acrostics,\nwhere initial letters of consecutive lines or paragraphs form meaningful words\nor phrases. Scholars searching for acrostics manually can only focus on a few\nauthors at a time and often favor qualitative arguments in discussing\nintentionally. We aim to put the study of acrostics on firmer statistical\nfooting by presenting AcrosticSleuth, a first-of-its-kind tool that\nautomatically identifies acrostics and ranks them by the probability that the\nsequence of characters does not occur by chance (and therefore may have been\ninserted intentionally). Acrostics are rare, so we formalize the problem as a\nbinary classification task in the presence of extreme class imbalance. To\nevaluate AcrosticSleuth, we present the Acrostic Identification Dataset\n(AcrostID), a collection of acrostics from the WikiSource online database.\nDespite the class imbalance, AcrosticSleuth achieves F1 scores of 0.39, 0.59,\nand 0.66 on French, English, and Russian subdomains of WikiSource,\nrespectively. We further demonstrate that AcrosticSleuth can identify\npreviously unknown high-profile instances of wordplay, such as the acrostic\nspelling ARSPOETICA (``art of poetry\") by Italian Humanist Albertino Mussato\nand English philosopher Thomas Hobbes' signature in the opening paragraphs of\nThe Elements of Law.", "published": "2024-08-08 12:53:26", "link": "http://arxiv.org/abs/2408.04427v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Crowd Intelligence for Early Misinformation Prediction on Social Media", "abstract": "Misinformation spreads rapidly on social media, causing serious damage by\ninfluencing public opinion, promoting dangerous behavior, or eroding trust in\nreliable sources. It spreads too fast for traditional fact-checking, stressing\nthe need for predictive methods. We introduce CROWDSHIELD, a crowd\nintelligence-based method for early misinformation prediction. We hypothesize\nthat the crowd's reactions to misinformation reveal its accuracy. Furthermore,\nwe hinge upon exaggerated assertions/claims and replies with particular\npositions/stances on the source post within a conversation thread. We employ\nQ-learning to capture the two dimensions -- stances and claims. We utilize deep\nQ-learning due to its proficiency in navigating complex decision spaces and\neffectively learning network properties. Additionally, we use a\ntransformer-based encoder to develop a comprehensive understanding of both\ncontent and context. This multifaceted approach helps ensure the model pays\nattention to user interaction and stays anchored in the communication's\ncontent. We propose MIST, a manually annotated misinformation detection Twitter\ncorpus comprising nearly 200 conversation threads with more than 14K replies.\nIn experiments, CROWDSHIELD outperformed ten baseline systems, achieving an\nimprovement of ~4% macro-F1 score. We conduct an ablation study and error\nanalysis to validate our proposed model's performance. The source code and\ndataset are available at https://github.com/LCS2-IIITD/CrowdShield.git.", "published": "2024-08-08 13:45:23", "link": "http://arxiv.org/abs/2408.04463v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for\n  Competitive Debate", "abstract": "Competitive debate is a complex task of computational argumentation. Large\nLanguage Models (LLMs) suffer from hallucinations and lack competitiveness in\nthis field. To address these challenges, we introduce Agent for Debate\n(Agent4Debate), a dynamic multi-agent framework based on LLMs designed to\nenhance their capabilities in competitive debate. Drawing inspiration from\nhuman behavior in debate preparation and execution, Agent4Debate employs a\ncollaborative architecture where four specialized agents, involving Searcher,\nAnalyzer, Writer, and Reviewer, dynamically interact and cooperate. These\nagents work throughout the debate process, covering multiple stages from\ninitial research and argument formulation to rebuttal and summary. To\ncomprehensively evaluate framework performance, we construct the Competitive\nDebate Arena, comprising 66 carefully selected Chinese debate motions. We\nrecruit ten experienced human debaters and collect records of 200 debates\ninvolving Agent4Debate, baseline models, and humans. The evaluation employs the\nDebatrix automatic scoring system and professional human reviewers based on the\nestablished Debatrix-Elo and Human-Elo ranking. Experimental results indicate\nthat the state-of-the-art Agent4Debate exhibits capabilities comparable to\nthose of humans. Furthermore, ablation studies demonstrate the effectiveness of\neach component in the agent structure.", "published": "2024-08-08 14:02:45", "link": "http://arxiv.org/abs/2408.04472v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large\n  Language Models", "abstract": "As diverse linguistic communities and users adopt large language models\n(LLMs), assessing their safety across languages becomes critical. Despite\nongoing efforts to make LLMs safe, they can still be made to behave unsafely\nwith jailbreaking, a technique in which models are prompted to act outside\ntheir operational guidelines. Research on LLM safety and jailbreaking, however,\nhas so far mostly focused on English, limiting our understanding of LLM safety\nin other languages. We contribute towards closing this gap by investigating the\neffectiveness of many-shot jailbreaking, where models are prompted with unsafe\ndemonstrations to induce unsafe behaviour, in Italian. To enable our analysis,\nwe create a new dataset of unsafe Italian question-answer pairs. With this\ndataset, we identify clear safety vulnerabilities in four families of\nopen-weight LLMs. We find that the models exhibit unsafe behaviors even when\nprompted with few unsafe demonstrations, and -- more alarmingly -- that this\ntendency rapidly escalates with more demonstrations.", "published": "2024-08-08 15:24:03", "link": "http://arxiv.org/abs/2408.04522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic\n  Text with Persuasion Techniques Identification", "abstract": "This paper focuses on detecting propagandistic spans and persuasion\ntechniques in Arabic text from tweets and news paragraphs. Each entry in the\ndataset contains a text sample and corresponding labels that indicate the start\nand end positions of propaganda techniques within the text. Tokens falling\nwithin a labeled span were assigned \"B\" (Begin) or \"I\" (Inside), \"O\",\ncorresponding to the specific propaganda technique. Using attention masks, we\ncreated uniform lengths for each span and assigned BIO tags to each token based\non the provided labels. Then, we used AraBERT-base pre-trained model for Arabic\ntext tokenization and embeddings with a token classification layer to identify\npropaganda techniques. Our training process involves a two-phase fine-tuning\napproach. First, we train only the classification layer for a few epochs,\nfollowed by full model fine-tuning, updating all parameters. This methodology\nallows the model to adapt to the specific characteristics of the propaganda\ndetection task while leveraging the knowledge captured by the pre-trained\nAraBERT model. Our approach achieved an F1 score of 0.2774, securing the 3rd\nposition in the leaderboard of Task 1.", "published": "2024-08-08 15:49:01", "link": "http://arxiv.org/abs/2408.04540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Moly\u00e9: A Corpus-based Approach to Language Contact in Colonial France", "abstract": "Whether or not several Creole languages which developed during the early\nmodern period can be considered genetic descendants of European languages has\nbeen the subject of intense debate. This is in large part due to the absence of\nevidence of intermediate forms. This work introduces a new open corpus, the\nMoly\\'e corpus, which combines stereotypical representations of three kinds of\nlanguage variation in Europe with early attestations of French-based Creole\nlanguages across a period of 400 years. It is intended to facilitate future\nresearch on the continuity between contact situations in Europe and Creolophone\n(former) colonies.", "published": "2024-08-08 16:09:40", "link": "http://arxiv.org/abs/2408.04554v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Conversational Prompt Engineering", "abstract": "Prompts are how humans communicate with LLMs. Informative prompts are\nessential for guiding LLMs to produce the desired output. However, prompt\nengineering is often tedious and time-consuming, requiring significant\nexpertise, limiting its widespread use. We propose Conversational Prompt\nEngineering (CPE), a user-friendly tool that helps users create personalized\nprompts for their specific tasks. CPE uses a chat model to briefly interact\nwith users, helping them articulate their output preferences and integrating\nthese into the prompt. The process includes two main stages: first, the model\nuses user-provided unlabeled data to generate data-driven questions and utilize\nuser responses to shape the initial instruction. Then, the model shares the\noutputs generated by the instruction and uses user feedback to further refine\nthe instruction and the outputs. The final result is a few-shot prompt, where\nthe outputs approved by the user serve as few-shot examples. A user study on\nsummarization tasks demonstrates the value of CPE in creating personalized,\nhigh-performing prompts. The results suggest that the zero-shot prompt obtained\nis comparable to its - much longer - few-shot counterpart, indicating\nsignificant savings in scenarios involving repetitive tasks with large text\nvolumes.", "published": "2024-08-08 16:18:39", "link": "http://arxiv.org/abs/2408.04560v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency,\n  Performance, and Adversarial Robustness", "abstract": "With the increasing demand for practical applications of Large Language\nModels (LLMs), many attention-efficient models have been developed to balance\nperformance and computational cost. However, the adversarial robustness of\nthese models remains under-explored. In this work, we design a framework to\ninvestigate the trade-off between efficiency, performance, and adversarial\nrobustness of LLMs and conduct extensive experiments on three prominent models\nwith varying levels of complexity and efficiency -- Transformer++, Gated Linear\nAttention (GLA) Transformer, and MatMul-Free LM -- utilizing the GLUE and\nAdvGLUE datasets. The AdvGLUE dataset extends the GLUE dataset with adversarial\nsamples designed to challenge model robustness. Our results show that while the\nGLA Transformer and MatMul-Free LM achieve slightly lower accuracy on GLUE\ntasks, they demonstrate higher efficiency and either superior or comparative\nrobustness on AdvGLUE tasks compared to Transformer++ across different attack\nlevels. These findings highlight the potential of simplified architectures to\nachieve a compelling balance between efficiency, performance, and adversarial\nrobustness, offering valuable insights for applications where resource\nconstraints and resilience to adversarial attacks are critical.", "published": "2024-08-08 16:54:40", "link": "http://arxiv.org/abs/2408.04585v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code-switching in text and speech reveals information-theoretic audience\n  design", "abstract": "In this work, we use language modeling to investigate the factors that\ninfluence code-switching. Code-switching occurs when a speaker alternates\nbetween one language variety (the primary language) and another (the secondary\nlanguage), and is widely observed in multilingual contexts. Recent work has\nshown that code-switching is often correlated with areas of high information\nload in the primary language, but it is unclear whether high primary language\nload only makes the secondary language relatively easier to produce at\ncode-switching points (speaker-driven code-switching), or whether\ncode-switching is additionally used by speakers to signal the need for greater\nattention on the part of listeners (audience-driven code-switching). In this\npaper, we use bilingual Chinese-English online forum posts and transcripts of\nspontaneous Chinese-English speech to replicate prior findings that high\nprimary language (Chinese) information load is correlated with switches to the\nsecondary language (English). We then demonstrate that the information load of\nthe English productions is even higher than that of meaning equivalent Chinese\nalternatives, and these are therefore not easier to produce, providing evidence\nof audience-driven influences in code-switching at the level of the\ncommunication channel, not just at the sociolinguistic level, in both writing\nand speech.", "published": "2024-08-08 17:14:12", "link": "http://arxiv.org/abs/2408.04596v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Healthcare through Large Language Models: A Study on Medical\n  Question Answering", "abstract": "In recent years, the application of Large Language Models (LLMs) in\nhealthcare has shown significant promise in improving the accessibility and\ndissemination of medical knowledge. This paper presents a detailed study of\nvarious LLMs trained on the MedQuAD medical question-answering dataset, with a\nfocus on identifying the most effective model for providing accurate medical\ninformation. Among the models tested, the Sentence-t5 combined with Mistral 7B\ndemonstrated superior performance, achieving a precision score of 0.762. This\nmodel's enhanced capabilities are attributed to its advanced pretraining\ntechniques, robust architecture, and effective prompt construction\nmethodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B\nmodel excels in understanding and generating precise medical answers. Our\nfindings highlight the potential of integrating sophisticated LLMs in medical\ncontexts to facilitate efficient and accurate medical knowledge retrieval, thus\nsignificantly enhancing patient education and support.", "published": "2024-08-08 00:35:39", "link": "http://arxiv.org/abs/2408.04138v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UNLEARN Efficient Removal of Knowledge in Large Language Models", "abstract": "Given the prevalence of large language models (LLMs) and the prohibitive cost\nof training these models from scratch, dynamically forgetting specific\nknowledge e.g., private or proprietary, without retraining the model has become\nan important capability. This paper proposes a novel method to achieve this\nobjective called UNLEARN. The approach builds upon subspace methods to identify\nand specifically target the removal of knowledge without adversely affecting\nother knowledge in the LLM. Results demonstrate 96% of targeted knowledge can\nbe forgotten while maintaining performance on other knowledge within 2.5% of\nthe original model, significantly outperforming the discriminatory abilities of\nthe previous state-of-the-art. A dual method called LEARN is also proposed for\ntargeted knowledge addition. Results show LEARN can match the fine-tuning\naccuracy of Low-Rank Adaptation (LoRA) without adversely affecting similar\ntasks.", "published": "2024-08-08 00:53:31", "link": "http://arxiv.org/abs/2408.04140v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MMREC: LLM Based Multi-Modal Recommender System", "abstract": "The importance of recommender systems is growing rapidly due to the\nexponential increase in the volume of content generated daily. This surge in\ncontent presents unique challenges for designing effective recommender systems.\nKey among these challenges is the need to effectively leverage the vast amounts\nof natural language data and images that represent user preferences. This paper\npresents a novel approach to enhancing recommender systems by leveraging Large\nLanguage Models (LLMs) and deep learning techniques. The proposed framework\naims to improve the accuracy and relevance of recommendations by incorporating\nmulti-modal information processing and by the use of unified latent space\nrepresentation. The study explores the potential of LLMs to better understand\nand utilize natural language data in recommendation contexts, addressing the\nlimitations of previous methods. The framework efficiently extracts and\nintegrates text and image information through LLMs, unifying diverse modalities\nin a latent space to simplify the learning process for the ranking model.\nExperimental results demonstrate the enhanced discriminative power of the model\nwhen utilizing multi-modal information. This research contributes to the\nevolving field of recommender systems by showcasing the potential of LLMs and\nmulti-modal data integration to create more personalized and contextually\nrelevant recommendations.", "published": "2024-08-08 04:31:29", "link": "http://arxiv.org/abs/2408.04211v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Attention Mechanism and Context Modeling System for Text Mining Machine\n  Translation", "abstract": "This paper advances a novel architectural schema anchored upon the\nTransformer paradigm and innovatively amalgamates the K-means categorization\nalgorithm to augment the contextual apprehension capabilities of the schema.\nThe transformer model performs well in machine translation tasks due to its\nparallel computing power and multi-head attention mechanism. However, it may\nencounter contextual ambiguity or ignore local features when dealing with\nhighly complex language structures. To circumvent this constraint, this\nexposition incorporates the K-Means algorithm, which is used to stratify the\nlexis and idioms of the input textual matter, thereby facilitating superior\nidentification and preservation of the local structure and contextual\nintelligence of the language. The advantage of this combination is that K-Means\ncan automatically discover the topic or concept regions in the text, which may\nbe directly related to translation quality. Consequently, the schema contrived\nherein enlists K-Means as a preparatory phase antecedent to the Transformer and\nrecalibrates the multi-head attention weights to assist in the discrimination\nof lexis and idioms bearing analogous semantics or functionalities. This\nensures the schema accords heightened regard to the contextual intelligence\nembodied by these clusters during the training phase, rather than merely\nfocusing on locational intelligence.", "published": "2024-08-08 04:52:10", "link": "http://arxiv.org/abs/2408.04216v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Diffusion Guided Language Modeling", "abstract": "Current language models demonstrate remarkable proficiency in text\ngeneration. However, for many applications it is desirable to control\nattributes, such as sentiment, or toxicity, of the generated language --\nideally tailored towards each specific use case and target audience. For\nauto-regressive language models, existing guidance methods are prone to\ndecoding errors that cascade during generation and degrade performance. In\ncontrast, text diffusion models can easily be guided with, for example, a\nsimple linear sentiment classifier -- however they do suffer from significantly\nhigher perplexity than auto-regressive alternatives. In this paper we use a\nguided diffusion model to produce a latent proposal that steers an\nauto-regressive language model to generate text with desired properties. Our\nmodel inherits the unmatched fluency of the auto-regressive approach and the\nplug-and-play flexibility of diffusion. We show that it outperforms previous\nplug-and-play guidance methods across a wide range of benchmark data sets.\nFurther, controlling a new attribute in our framework is reduced to training a\nsingle logistic regression classifier.", "published": "2024-08-08 05:06:22", "link": "http://arxiv.org/abs/2408.04220v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EfficientRAG: Efficient Retriever for Multi-Hop Question Answering", "abstract": "Retrieval-augmented generation (RAG) methods encounter difficulties when\naddressing complex questions like multi-hop queries. While iterative retrieval\nmethods improve performance by gathering additional information, current\napproaches often rely on multiple calls of large language models (LLMs). In\nthis paper, we introduce EfficientRAG, an efficient retriever for multi-hop\nquestion answering. EfficientRAG iteratively generates new queries without the\nneed for LLM calls at each iteration and filters out irrelevant information.\nExperimental results demonstrate that EfficientRAG surpasses existing RAG\nmethods on three open-domain multi-hop question-answering datasets.", "published": "2024-08-08 06:57:49", "link": "http://arxiv.org/abs/2408.04259v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Are Social Sentiments Inherent in LLMs? An Empirical Study on Extraction\n  of Inter-demographic Sentiments", "abstract": "Large language models (LLMs) are supposed to acquire unconscious human\nknowledge and feelings, such as social common sense and biases, by training\nmodels from large amounts of text. However, it is not clear how much the\nsentiments of specific social groups can be captured in various LLMs. In this\nstudy, we focus on social groups defined in terms of nationality, religion, and\nrace/ethnicity, and validate the extent to which sentiments between social\ngroups can be captured in and extracted from LLMs. Specifically, we input\nquestions regarding sentiments from one group to another into LLMs, apply\nsentiment analysis to the responses, and compare the results with social\nsurveys. The validation results using five representative LLMs showed higher\ncorrelations with relatively small p-values for nationalities and religions,\nwhose number of data points were relatively large. This result indicates that\nthe LLM responses including the inter-group sentiments align well with actual\nsocial survey results.", "published": "2024-08-08 08:13:25", "link": "http://arxiv.org/abs/2408.04293v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language\n  Adaptation of LLMs for Low-Resource NLP", "abstract": "The development of monolingual language models for low and mid-resource\nlanguages continues to be hindered by the difficulty in sourcing high-quality\ntraining data. In this study, we present a novel cross-lingual vocabulary\ntransfer strategy, trans-tokenization, designed to tackle this challenge and\nenable more efficient language adaptation. Our approach focuses on adapting a\nhigh-resource monolingual LLM to an unseen target language by initializing the\ntoken embeddings of the target language using a weighted average of\nsemantically similar token embeddings from the source language. For this, we\nleverage a translation resource covering both the source and target languages.\nWe validate our method with the Tweeties, a series of trans-tokenized LLMs, and\ndemonstrate their competitive performance on various downstream tasks across a\nsmall but diverse set of languages. Additionally, we introduce Hydra LLMs,\nmodels with multiple swappable language modeling heads and embedding tables,\nwhich further extend the capabilities of our trans-tokenization strategy. By\ndesigning a Hydra LLM based on the multilingual model TowerInstruct, we\ndeveloped a state-of-the-art machine translation model for Tatar, in a\nzero-shot manner, completely bypassing the need for high-quality parallel data.\nThis breakthrough is particularly significant for low-resource languages like\nTatar, where high-quality parallel data is hard to come by. By lowering the\ndata and time requirements for training high-quality models, our\ntrans-tokenization strategy allows for the development of LLMs for a wider\nrange of languages, especially those with limited resources. We hope that our\nwork will inspire further research and collaboration in the field of\ncross-lingual vocabulary transfer and contribute to the empowerment of\nlanguages on a global scale.", "published": "2024-08-08 08:37:28", "link": "http://arxiv.org/abs/2408.04303v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HydraFormer: One Encoder For All Subsampling Rates", "abstract": "In automatic speech recognition, subsampling is essential for tackling\ndiverse scenarios. However, the inadequacy of a single subsampling rate to\naddress various real-world situations often necessitates training and deploying\nmultiple models, consequently increasing associated costs. To address this\nissue, we propose HydraFormer, comprising HydraSub, a Conformer-based encoder,\nand a BiTransformer-based decoder. HydraSub encompasses multiple branches, each\nrepresenting a distinct subsampling rate, allowing for the flexible selection\nof any branch during inference based on the specific use case. HydraFormer can\nefficiently manage different subsampling rates, significantly reducing training\nand deployment expenses. Experiments on AISHELL-1 and LibriSpeech datasets\nreveal that HydraFormer effectively adapts to various subsampling rates and\nlanguages while maintaining high recognition performance. Additionally,\nHydraFormer showcases exceptional stability, sustaining consistent performance\nunder various initialization conditions, and exhibits robust transferability by\nlearning from pretrained single subsampling rate automatic speech recognition\nmodels\\footnote{Model code and scripts:\nhttps://github.com/HydraFormer/hydraformer}.", "published": "2024-08-08 09:08:27", "link": "http://arxiv.org/abs/2408.04325v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Enhancing Journalism with AI: A Study of Contextualized Image Captioning\n  for News Articles using LLMs and LMMs", "abstract": "Large language models (LLMs) and large multimodal models (LMMs) have\nsignificantly impacted the AI community, industry, and various economic\nsectors. In journalism, integrating AI poses unique challenges and\nopportunities, particularly in enhancing the quality and efficiency of news\nreporting. This study explores how LLMs and LMMs can assist journalistic\npractice by generating contextualised captions for images accompanying news\narticles. We conducted experiments using the GoodNews dataset to evaluate the\nability of LMMs (BLIP-2, GPT-4v, or LLaVA) to incorporate one of two types of\ncontext: entire news articles, or extracted named entities. In addition, we\ncompared their performance to a two-stage pipeline composed of a captioning\nmodel (BLIP-2, OFA, or ViT-GPT2) with post-hoc contextualisation with LLMs\n(GPT-4 or LLaMA). We assess a diversity of models, and we find that while the\nchoice of contextualisation model is a significant factor for the two-stage\npipelines, this is not the case in the LMMs, where smaller, open-source models\nperform well compared to proprietary, GPT-powered ones. Additionally, we found\nthat controlling the amount of provided context enhances performance. These\nresults highlight the limitations of a fully automated approach and underscore\nthe necessity for an interactive, human-in-the-loop strategy.", "published": "2024-08-08 09:31:24", "link": "http://arxiv.org/abs/2408.04331v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Simulating Articulatory Trajectories with Phonological Feature\n  Interpolation", "abstract": "As a first step towards a complete computational model of speech learning\ninvolving perception-production loops, we investigate the forward mapping\nbetween pseudo-motor commands and articulatory trajectories. Two phonological\nfeature sets, based respectively on generative and articulatory phonology, are\nused to encode a phonetic target sequence. Different interpolation techniques\nare compared to generate smooth trajectories in these feature spaces, with a\npotential optimisation of the target value and timing to capture\nco-articulation effects. We report the Pearson correlation between a linear\nprojection of the generated trajectories and articulatory data derived from a\nmulti-speaker dataset of electromagnetic articulography (EMA) recordings. A\ncorrelation of 0.67 is obtained with an extended feature set based on\ngenerative phonology and a linear interpolation technique. We discuss the\nimplications of our results for our understanding of the dynamics of biological\nmotion.", "published": "2024-08-08 10:51:16", "link": "http://arxiv.org/abs/2408.04363v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Analyzing Consumer Reviews for Understanding Drivers of Hotels Ratings:\n  An Indian Perspective", "abstract": "In the internet era, almost every business entity is trying to have its\ndigital footprint in digital media and other social media platforms. For these\nentities, word of mouse is also very important. Particularly, this is quite\ncrucial for the hospitality sector dealing with hotels, restaurants etc.\nConsumers do read other consumers reviews before making final decisions. This\nis where it becomes very important to understand which aspects are affecting\nmost in the minds of the consumers while giving their ratings. The current\nstudy focuses on the consumer reviews of Indian hotels to extract aspects\nimportant for final ratings. The study involves gathering data using web\nscraping methods, analyzing the texts using Latent Dirichlet Allocation for\ntopic extraction and sentiment analysis for aspect-specific sentiment mapping.\nFinally, it incorporates Random Forest to understand the importance of the\naspects in predicting the final rating of a user.", "published": "2024-08-08 10:58:33", "link": "http://arxiv.org/abs/2408.04369v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Automated Educational Question Generation at Different Bloom's Skill\n  Levels using Large Language Models: Strategies and Evaluation", "abstract": "Developing questions that are pedagogically sound, relevant, and promote\nlearning is a challenging and time-consuming task for educators. Modern-day\nlarge language models (LLMs) generate high-quality content across multiple\ndomains, potentially helping educators to develop high-quality questions.\nAutomated educational question generation (AEQG) is important in scaling online\neducation catering to a diverse student population. Past attempts at AEQG have\nshown limited abilities to generate questions at higher cognitive levels. In\nthis study, we examine the ability of five state-of-the-art LLMs of different\nsizes to generate diverse and high-quality questions of different cognitive\nlevels, as defined by Bloom's taxonomy. We use advanced prompting techniques\nwith varying complexity for AEQG. We conducted expert and LLM-based evaluations\nto assess the linguistic and pedagogical relevance and quality of the\nquestions. Our findings suggest that LLms can generate relevant and\nhigh-quality educational questions of different cognitive levels when prompted\nwith adequate information, although there is a significant variance in the\nperformance of the five LLms considered. We also show that automated evaluation\nis not on par with human evaluation.", "published": "2024-08-08 11:56:57", "link": "http://arxiv.org/abs/2408.04394v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring Reasoning Biases in Large Language Models Through Syllogism:\n  Insights from the NeuBAROCO Dataset", "abstract": "This paper explores the question of how accurately current large language\nmodels can perform logical reasoning in natural language, with an emphasis on\nwhether these models exhibit reasoning biases similar to humans. Specifically,\nour study focuses on syllogistic reasoning, a form of deductive reasoning\nextensively studied in cognitive science as a natural form of human reasoning.\nWe present a syllogism dataset called NeuBAROCO, which consists of syllogistic\nreasoning problems in English and Japanese. This dataset was originally\ndesigned for psychological experiments to assess human reasoning capabilities\nusing various forms of syllogisms. Our experiments with leading large language\nmodels indicate that these models exhibit reasoning biases similar to humans,\nalong with other error tendencies. Notably, there is significant room for\nimprovement in reasoning problems where the relationship between premises and\nhypotheses is neither entailment nor contradiction. We also present\nexperimental results and in-depth analysis using a new Chain-of-Thought\nprompting method, which asks LLMs to translate syllogisms into abstract logical\nexpressions and then explain their reasoning process. Our analysis using this\nmethod suggests that the primary limitations of LLMs lie in the reasoning\nprocess itself rather than the interpretation of syllogisms.", "published": "2024-08-08 12:10:50", "link": "http://arxiv.org/abs/2408.04403v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Robustness of Retrieval-Augmented Language Models with\n  In-Context Learning", "abstract": "Retrieval-Augmented Language Models (RALMs) have significantly improved\nperformance in open-domain question answering (QA) by leveraging external\nknowledge. However, RALMs still struggle with unanswerable queries, where the\nretrieved contexts do not contain the correct answer, and with conflicting\ninformation, where different sources provide contradictory answers due to\nimperfect retrieval. This study introduces an in-context learning-based\napproach to enhance the reasoning capabilities of RALMs, making them more\nrobust in imperfect retrieval scenarios. Our method incorporates Machine\nReading Comprehension (MRC) demonstrations, referred to as cases, to boost the\nmodel's capabilities to identify unanswerabilities and conflicts among the\nretrieved contexts. Experiments on two open-domain QA datasets show that our\napproach increases accuracy in identifying unanswerable and conflicting\nscenarios without requiring additional fine-tuning. This work demonstrates that\nin-context learning can effectively enhance the robustness of RALMs in\nopen-domain QA tasks.", "published": "2024-08-08 12:42:43", "link": "http://arxiv.org/abs/2408.04414v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BA-LoRA: Bias-Alleviating Low-Rank Adaptation to Mitigate Catastrophic\n  Inheritance in Large Language Models", "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency across\nvarious natural language processing (NLP) tasks. However, adapting LLMs to\ndownstream applications requires computationally intensive and memory-demanding\nfine-tuning procedures. To alleviate these burdens, parameter-efficient\nfine-tuning (PEFT) techniques have emerged as a promising approach to tailor\nLLMs with minimal computational overhead. While PEFT methods offer substantial\nadvantages, they do not fully address the pervasive issue of bias propagation\nfrom pre-training data. This work introduces Bias-Alleviating Low-Rank\nAdaptation (BA-LoRA), a novel PEFT method designed to counteract bias\ninheritance. BA-LoRA incorporates three distinct regularization terms: (1) a\nconsistency regularizer, (2) a diversity regularizer, and (3) a singular value\ndecomposition regularizer. These regularizers aim to enhance the models'\nconsistency, diversity, and generalization capabilities during fine-tuning. We\nconduct extensive experiments on natural language understanding (NLU) and\nnatural language generation (NLG) tasks using prominent LLMs such as LLaMA,\nMistral, and Gemma. The results demonstrate that BA-LoRA outperforms LoRA and\nits state-of-the-art variants. Moreover, our method effectively mitigates the\nadverse effects of pre-training bias, leading to more reliable and robust model\noutputs. The code is available at https://github.com/cyp-jlu-ai/BA-LoRA.", "published": "2024-08-08 16:13:26", "link": "http://arxiv.org/abs/2408.04556v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning Fine-Grained Grounded Citations for Attributed Large Language\n  Models", "abstract": "Despite the impressive performance on information-seeking tasks, large\nlanguage models (LLMs) still struggle with hallucinations. Attributed LLMs,\nwhich augment generated text with in-line citations, have shown potential in\nmitigating hallucinations and improving verifiability. However, current\napproaches suffer from suboptimal citation quality due to their reliance on\nin-context learning. Furthermore, the practice of citing only coarse document\nidentifiers makes it challenging for users to perform fine-grained\nverification. In this work, we introduce FRONT, a training framework designed\nto teach LLMs to generate Fine-Grained Grounded Citations. By grounding model\noutputs in fine-grained supporting quotes, these quotes guide the generation of\ngrounded and consistent responses, not only improving citation quality but also\nfacilitating fine-grained verification. Experiments on the ALCE benchmark\ndemonstrate the efficacy of FRONT in generating superior grounded responses and\nhighly supportive citations. With LLaMA-2-7B, the framework significantly\noutperforms all the baselines, achieving an average of 14.21% improvement in\ncitation quality across all datasets, even surpassing ChatGPT.", "published": "2024-08-08 16:28:22", "link": "http://arxiv.org/abs/2408.04568v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals", "abstract": "Explainable Artificial Intelligence (XAI) plays a crucial role in enhancing\nthe transparency and accountability of AI models, particularly in natural\nlanguage processing (NLP) tasks. However, popular XAI methods such as LIME and\nSHAP have been found to be unstable and potentially misleading, underscoring\nthe need for a standardized evaluation approach. This paper introduces SCENE\n(Soft Counterfactual Evaluation for Natural language Explainability), a novel\nevaluation method that leverages large language models (LLMs) to generate Soft\nCounterfactual explanations in a zero-shot manner. By focusing on token-based\nsubstitutions, SCENE creates contextually appropriate and semantically\nmeaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts\nValiditysoft and Csoft metrics to assess the effectiveness of model-agnostic\nXAI methods in text classification tasks. Applied to CNN, RNN, and Transformer\narchitectures, SCENE provides valuable insights into the strengths and\nlimitations of various XAI techniques.", "published": "2024-08-08 16:36:24", "link": "http://arxiv.org/abs/2408.04575v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Arctic-TILT. Business Document Understanding at Sub-Billion Scale", "abstract": "The vast portion of workloads employing LLMs involves answering questions\ngrounded on PDF or scan content. We introduce the Arctic-TILT achieving\naccuracy on par with models 1000$\\times$ its size on these use cases. It can be\nfine-tuned and deployed on a single 24GB GPU, lowering operational costs while\nprocessing Visually Rich Documents with up to 400k tokens. The model\nestablishes state-of-the-art results on seven diverse Document Understanding\nbenchmarks, as well as provides reliable confidence scores and quick inference,\nwhich are essential for processing files in large-scale or time-sensitive\nenterprise environments.", "published": "2024-08-08 17:59:46", "link": "http://arxiv.org/abs/2408.04632v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Multi-Turn Context Jailbreak Attack on Large Language Models From First\n  Principles", "abstract": "Large language models (LLMs) have significantly enhanced the performance of\nnumerous applications, from intelligent conversations to text generation.\nHowever, their inherent security vulnerabilities have become an increasingly\nsignificant challenge, especially with respect to jailbreak attacks. Attackers\ncan circumvent the security mechanisms of these LLMs, breaching security\nconstraints and causing harmful outputs. Focusing on multi-turn semantic\njailbreak attacks, we observe that existing methods lack specific\nconsiderations for the role of multiturn dialogues in attack strategies,\nleading to semantic deviations during continuous interactions. Therefore, in\nthis paper, we establish a theoretical foundation for multi-turn attacks by\nconsidering their support in jailbreak attacks, and based on this, propose a\ncontext-based contextual fusion black-box jailbreak attack method, named\nContext Fusion Attack (CFA). This method approach involves filtering and\nextracting key terms from the target, constructing contextual scenarios around\nthese terms, dynamically integrating the target into the scenarios, replacing\nmalicious key terms within the target, and thereby concealing the direct\nmalicious intent. Through comparisons on various mainstream LLMs and red team\ndatasets, we have demonstrated CFA's superior success rate, divergence, and\nharmfulness compared to other multi-turn attack strategies, particularly\nshowcasing significant advantages on Llama3 and GPT-4.", "published": "2024-08-08 09:18:47", "link": "http://arxiv.org/abs/2408.04686v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Hybrid Student-Teacher Large Language Model Refinement for Cancer\n  Toxicity Symptom Extraction", "abstract": "Large Language Models (LLMs) offer significant potential for clinical symptom\nextraction, but their deployment in healthcare settings is constrained by\nprivacy concerns, computational limitations, and operational costs. This study\ninvestigates the optimization of compact LLMs for cancer toxicity symptom\nextraction using a novel iterative refinement approach. We employ a\nstudent-teacher architecture, utilizing Zephyr-7b-beta and Phi3-mini-128 as\nstudent models and GPT-4o as the teacher, to dynamically select between prompt\nrefinement, Retrieval-Augmented Generation (RAG), and fine-tuning strategies.\nOur experiments on 294 clinical notes covering 12 post-radiotherapy toxicity\nsymptoms demonstrate the effectiveness of this approach. The RAG method proved\nmost efficient, improving average accuracy scores from 0.32 to 0.73 for\nZephyr-7b-beta and from 0.40 to 0.87 for Phi3-mini-128 during refinement. In\nthe test set, both models showed an approximate 0.20 increase in accuracy\nacross symptoms. Notably, this improvement was achieved at a cost 45 times\nlower than GPT-4o for Zephyr and 79 times lower for Phi-3. These results\nhighlight the potential of iterative refinement techniques in enhancing the\ncapabilities of compact LLMs for clinical applications, offering a balance\nbetween performance, cost-effectiveness, and privacy preservation in healthcare\nsettings.", "published": "2024-08-08 22:18:01", "link": "http://arxiv.org/abs/2408.04775v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Using generative AI to support standardization work -- the case of 3GPP", "abstract": "Standardization processes build upon consensus between partners, which\ndepends on their ability to identify points of disagreement and resolving them.\nLarge standardization organizations, like the 3GPP or ISO, rely on leaders of\nwork packages who can correctly, and efficiently, identify disagreements,\ndiscuss them and reach a consensus. This task, however, is effort-,\nlabor-intensive and costly. In this paper, we address the problem of\nidentifying similarities, dissimilarities and discussion points using large\nlanguage models. In a design science research study, we work with one of the\norganizations which leads several workgroups in the 3GPP standard. Our goal is\nto understand how well the language models can support the standardization\nprocess in becoming more cost-efficient, faster and more reliable. Our results\nshow that generic models for text summarization correlate well with domain\nexpert's and delegate's assessments (Pearson correlation between 0.66 and\n0.98), but that there is a need for domain-specific models to provide better\ndiscussion materials for the standardization groups.", "published": "2024-08-08 09:18:03", "link": "http://arxiv.org/abs/2408.12611v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Articulatory Configurations across Genders and Periods in French Radio\n  and TV archives", "abstract": "This paper studies changes in articulatory configurations across genders and\nperiods using an inversion from acoustic to articulatory parameters. From a\ndiachronic corpus based on French media archives spanning 60 years from 1955 to\n2015, automatic transcription and forced alignment allowed extracting the\ncentral frame of each vowel. More than one million frames were obtained from\nover a thousand speakers across gender and age categories. Their formants were\nused from these vocalic frames to fit the parameters of Maeda's articulatory\nmodel. Evaluations of the quality of these processes are provided. We focus\nhere on two parameters of Maeda's model linked to total vocal tract length: the\nrelative position of the larynx (higher for females) and the lips protrusion\n(more protruded for males). Implications for voice quality across genders are\ndiscussed. The effect across periods seems gender independent; thus, the\nassertion that females lowered their pitch with time is not supported.", "published": "2024-08-08 15:20:39", "link": "http://arxiv.org/abs/2408.04519v1", "categories": ["eess.AS", "cs.CL", "cs.CY", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Better Alignment with Instruction Back-and-Forth Translation", "abstract": "We propose a new method, instruction back-and-forth translation, to construct\nhigh-quality synthetic data grounded in world knowledge for aligning large\nlanguage models (LLMs). Given documents from a web corpus, we generate and\ncurate synthetic instructions using the backtranslation approach proposed by Li\net al.(2023a), and rewrite the responses to improve their quality further based\non the initial documents. Fine-tuning with the resulting (backtranslated\ninstruction, rewritten response) pairs yields higher win rates on AlpacaEval\nthan using other common instruction datasets such as Humpback, ShareGPT, Open\nOrca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the\nresponses with an LLM outperforms direct distillation, and the two generated\ntext distributions exhibit significant distinction in embedding space. Further\nanalysis shows that our backtranslated instructions are of higher quality than\nother sources of synthetic instructions, while our responses are more diverse\nand complex than those obtained from distillation. Overall we find that\ninstruction back-and-forth translation combines the best of both worlds --\nmaking use of the information diversity and quantity found on the web, while\nensuring the quality of the responses which is necessary for effective\nalignment.", "published": "2024-08-08 17:42:32", "link": "http://arxiv.org/abs/2408.04614v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Transformer Explainer: Interactive Learning of Text-Generative Models", "abstract": "Transformers have revolutionized machine learning, yet their inner workings\nremain opaque to many. We present Transformer Explainer, an interactive\nvisualization tool designed for non-experts to learn about Transformers through\nthe GPT-2 model. Our tool helps users understand complex Transformer concepts\nby integrating a model overview and enabling smooth transitions across\nabstraction levels of mathematical operations and model structures. It runs a\nlive GPT-2 instance locally in the user's browser, empowering users to\nexperiment with their own input and observe in real-time how the internal\ncomponents and parameters of the Transformer work together to predict the next\ntokens. Our tool requires no installation or special hardware, broadening the\npublic's education access to modern generative AI techniques. Our open-sourced\ntool is available at https://poloclub.github.io/transformer-explainer/. A video\ndemo is available at https://youtu.be/ECR4oAwocjs.", "published": "2024-08-08 17:49:07", "link": "http://arxiv.org/abs/2408.04619v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "LogogramNLP: Comparing Visual and Textual Representations of Ancient\n  Logographic Writing Systems for NLP", "abstract": "Standard natural language processing (NLP) pipelines operate on symbolic\nrepresentations of language, which typically consist of sequences of discrete\ntokens. However, creating an analogous representation for ancient logographic\nwriting systems is an extremely labor intensive process that requires expert\nknowledge. At present, a large portion of logographic data persists in a purely\nvisual form due to the absence of transcription -- this issue poses a\nbottleneck for researchers seeking to apply NLP toolkits to study ancient\nlogographic languages: most of the relevant data are images of writing.\n  This paper investigates whether direct processing of visual representations\nof language offers a potential solution. We introduce LogogramNLP, the first\nbenchmark enabling NLP analysis of ancient logographic languages, featuring\nboth transcribed and visual datasets for four writing systems along with\nannotations for tasks like classification, translation, and parsing. Our\nexperiments compare systems that employ recent visual and text encoding\nstrategies as backbones. The results demonstrate that visual representations\noutperform textual representations for some investigated tasks, suggesting that\nvisual processing pipelines may unlock a large amount of cultural heritage data\nof logographic languages for NLP-based analyses.", "published": "2024-08-08 17:58:06", "link": "http://arxiv.org/abs/2408.04628v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "CREST: Effectively Compacting a Datastore For Retrieval-Based\n  Speculative Decoding", "abstract": "We present CREST (Compact Retrieval-Based Speculative Decoding), a redesign\nof REST that allows it to be effectively \"compacted\". REST is a drafting\ntechnique for speculative decoding based on retrieving exact n-gram matches of\nthe most recent n tokens generated by the target LLM from a datastore. The key\nidea of CREST is to only store a subset of the smallest and most common n-grams\nin the datastore with the hope of achieving comparable performance with less\nstorage space. We found that storing a subset of n-grams both reduces storage\nspace and improves performance. CREST matches REST's accepted token length with\n10.6-13.5x less storage space and achieves a 16.5-17.1% higher acceptance\nlength than REST using the same storage space on the HumanEval and MT Bench\nbenchmarks.", "published": "2024-08-08 03:38:49", "link": "http://arxiv.org/abs/2408.04678v1", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Towards Linguistic Neural Representation Learning and Sentence Retrieval\n  from Electroencephalogram Recordings", "abstract": "Decoding linguistic information from non-invasive brain signals using EEG has\ngained increasing research attention due to its vast applicational potential.\nRecently, a number of works have adopted a generative-based framework to decode\nelectroencephalogram (EEG) signals into sentences by utilizing the power\ngenerative capacity of pretrained large language models (LLMs). However, this\napproach has several drawbacks that hinder the further development of\nlinguistic applications for brain-computer interfaces (BCIs). Specifically, the\nability of the EEG encoder to learn semantic information from EEG data remains\nquestionable, and the LLM decoder's tendency to generate sentences based on its\ntraining memory can be hard to avoid. These issues necessitate a novel approach\nfor converting EEG signals into sentences. In this paper, we propose a novel\ntwo-step pipeline that addresses these limitations and enhances the validity of\nlinguistic EEG decoding research. We first confirm that word-level semantic\ninformation can be learned from EEG data recorded during natural reading by\ntraining a Conformer encoder via a masked contrastive objective for word-level\nclassification. To achieve sentence decoding results, we employ a training-free\nretrieval method to retrieve sentences based on the predictions from the EEG\nencoder. Extensive experiments and ablation studies were conducted in this\npaper for a comprehensive evaluation of the proposed approach. Visualization of\nthe top prediction candidates reveals that our model effectively groups EEG\nsegments into semantic categories with similar meanings, thereby validating its\nability to learn patterns from unspoken EEG recordings. Despite the exploratory\nnature of this work, these results suggest that our method holds promise for\nproviding more reliable solutions for converting EEG signals into text.", "published": "2024-08-08 03:40:25", "link": "http://arxiv.org/abs/2408.04679v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications", "abstract": "The ability of large language models (LLMs) to transform, interpret, and\ncomprehend vast quantities of heterogeneous data presents a significant\nopportunity to enhance data-driven care delivery. However, the sensitive nature\nof protected health information (PHI) raises valid concerns about data privacy\nand trust in remote LLM platforms. In addition, the cost associated with\ncloud-based artificial intelligence (AI) services continues to impede\nwidespread adoption. To address these challenges, we propose a shift in the LLM\nexecution environment from opaque, centralized cloud providers to a\ndecentralized and dynamic fog computing architecture. By executing open-weight\nLLMs in more trusted environments, such as the user's edge device or a fog\nlayer within a local network, we aim to mitigate the privacy, trust, and\nfinancial challenges associated with cloud-based LLMs. We further present\nSpeziLLM, an open-source framework designed to facilitate rapid and seamless\nleveraging of different LLM execution layers and lowering barriers to LLM\nintegration in digital health applications. We demonstrate SpeziLLM's broad\napplicability across six digital health applications, showcasing its\nversatility in various healthcare settings.", "published": "2024-08-08 04:49:21", "link": "http://arxiv.org/abs/2408.04680v2", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Conversational AI Powered by Large Language Models Amplifies False\n  Memories in Witness Interviews", "abstract": "This study examines the impact of AI on human false memories -- recollections\nof events that did not occur or deviate from actual occurrences. It explores\nfalse memory induction through suggestive questioning in Human-AI interactions,\nsimulating crime witness interviews. Four conditions were tested: control,\nsurvey-based, pre-scripted chatbot, and generative chatbot using a large\nlanguage model (LLM). Participants (N=200) watched a crime video, then\ninteracted with their assigned AI interviewer or survey, answering questions\nincluding five misleading ones. False memories were assessed immediately and\nafter one week. Results show the generative chatbot condition significantly\nincreased false memory formation, inducing over 3 times more immediate false\nmemories than the control and 1.7 times more than the survey method. 36.4% of\nusers' responses to the generative chatbot were misled through the interaction.\nAfter one week, the number of false memories induced by generative chatbots\nremained constant. However, confidence in these false memories remained higher\nthan the control after one week. Moderating factors were explored: users who\nwere less familiar with chatbots but more familiar with AI technology, and more\ninterested in crime investigations, were more susceptible to false memories.\nThese findings highlight the potential risks of using advanced AI in sensitive\ncontexts, like police interviews, emphasizing the need for ethical\nconsiderations.", "published": "2024-08-08 04:55:03", "link": "http://arxiv.org/abs/2408.04681v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.CL"}
{"title": "ToolSandbox: A Stateful, Conversational, Interactive Evaluation\n  Benchmark for LLM Tool Use Capabilities", "abstract": "Recent large language models (LLMs) advancements sparked a growing research\ninterest in tool assisted LLMs solving real-world challenges, which calls for\ncomprehensive evaluation of tool-use capabilities. While previous works focused\non either evaluating over stateless web services (RESTful API), based on a\nsingle turn user prompt, or an off-policy dialog trajectory, ToolSandbox\nincludes stateful tool execution, implicit state dependencies between tools, a\nbuilt-in user simulator supporting on-policy conversational evaluation and a\ndynamic evaluation strategy for intermediate and final milestones over an\narbitrary trajectory. We show that open source and proprietary models have a\nsignificant performance gap, and complex tasks like State Dependency,\nCanonicalization and Insufficient Information defined in ToolSandbox are\nchallenging even the most capable SOTA LLMs, providing brand-new insights into\ntool-use LLM capabilities. ToolSandbox evaluation framework is released at\nhttps://github.com/apple/ToolSandbox", "published": "2024-08-08 05:45:42", "link": "http://arxiv.org/abs/2408.04682v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Synthetic SQL Column Descriptions and Their Impact on Text-to-SQL\n  Performance", "abstract": "Relational databases often suffer from uninformative descriptors of table\ncontents, such as ambiguous columns and hard-to-interpret values, impacting\nboth human users and text-to-SQL models. In this paper, we explore the use of\nlarge language models (LLMs) to automatically generate detailed natural\nlanguage descriptions for SQL database columns, aiming to improve text-to-SQL\nperformance and automate metadata creation. We create a dataset of gold column\ndescriptions based on the BIRD-Bench benchmark, manually refining its column\ndescriptions and creating a taxonomy for categorizing column difficulty. We\nthen evaluate several different LLMs in generating column descriptions across\nthe columns and different difficulties in the dataset, finding that models\nunsurprisingly struggle with columns that exhibit inherent ambiguity,\nhighlighting the need for manual expert input. We also find that incorporating\nsuch generated column descriptions consistently enhances text-to-SQL model\nperformance, particularly for larger models like GPT-4o, Qwen2 72B and Mixtral\n22Bx8. Notably, Qwen2-generated descriptions, containing by annotators deemed\nsuperfluous information, outperform manually curated gold descriptions,\nsuggesting that models benefit from more detailed metadata than humans expect.\nFuture work will investigate the specific features of these high-performing\ndescriptions and explore other types of metadata, such as numerical reasoning\nand synonyms, to further improve text-to-SQL systems. The dataset, annotations\nand code will all be made available.", "published": "2024-08-08 13:10:51", "link": "http://arxiv.org/abs/2408.04691v4", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Understanding the Performance and Estimating the Cost of LLM Fine-Tuning", "abstract": "Due to the cost-prohibitive nature of training Large Language Models (LLMs),\nfine-tuning has emerged as an attractive alternative for specializing LLMs for\nspecific tasks using limited compute resources in a cost-effective manner. In\nthis paper, we characterize sparse Mixture of Experts (MoE) based LLM\nfine-tuning to understand their accuracy and runtime performance on a single\nGPU. Our evaluation provides unique insights into the training efficacy of\nsparse and dense versions of MoE models, as well as their runtime\ncharacteristics, including maximum batch size, execution time breakdown,\nend-to-end throughput, GPU hardware utilization, and load distribution. Our\nstudy identifies the optimization of the MoE layer as crucial for further\nimproving the performance of LLM fine-tuning. Using our profiling results, we\nalso develop and validate an analytical model to estimate the cost of LLM\nfine-tuning on the cloud. This model, based on parameters of the model and GPU\narchitecture, estimates LLM throughput and the cost of training, aiding\npractitioners in industry and academia to budget the cost of fine-tuning a\nspecific model.", "published": "2024-08-08 16:26:07", "link": "http://arxiv.org/abs/2408.04693v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Survey: Transformer-based Models in Data Modality Conversion", "abstract": "Transformers have made significant strides across various artificial\nintelligence domains, including natural language processing, computer vision,\nand audio processing. This success has naturally garnered considerable interest\nfrom both academic and industry researchers. Consequently, numerous Transformer\nvariants (often referred to as X-formers) have been developed for these fields.\nHowever, a thorough and systematic review of these modality-specific\nconversions remains lacking. Modality Conversion involves the transformation of\ndata from one form of representation to another, mimicking the way humans\nintegrate and interpret sensory information. This paper provides a\ncomprehensive review of transformer-based models applied to the primary\nmodalities of text, vision, and speech, discussing their architectures,\nconversion methodologies, and applications. By synthesizing the literature on\nmodality conversion, this survey aims to underline the versatility and\nscalability of transformers in advancing AI-driven content generation and\nunderstanding.", "published": "2024-08-08 18:39:14", "link": "http://arxiv.org/abs/2408.04723v1", "categories": ["eess.IV", "cs.AI", "cs.CL", "eess.SP"], "primary_category": "eess.IV"}
{"title": "wav2graph: A Framework for Supervised Learning Knowledge Graph from\n  Speech", "abstract": "Knowledge graphs (KGs) enhance the performance of large language models\n(LLMs) and search engines by providing structured, interconnected data that\nimproves reasoning and context-awareness. However, KGs only focus on text data,\nthereby neglecting other modalities such as speech. In this work, we introduce\nwav2graph, the first framework for supervised learning knowledge graph from\nspeech data. Our pipeline are straightforward: (1) constructing a KG based on\ntranscribed spoken utterances and a named entity database, (2) converting KG\ninto embedding vectors, and (3) training graph neural networks (GNNs) for node\nclassification and link prediction tasks. Through extensive experiments\nconducted in inductive and transductive learning contexts using\nstate-of-the-art GNN models, we provide baseline results and error analysis for\nnode classification and link prediction tasks on human transcripts and\nautomatic speech recognition (ASR) transcripts, including evaluations using\nboth encoder-based and decoder-based node embeddings, as well as monolingual\nand multilingual acoustic pre-trained models. All related code, data, and\nmodels are published online.", "published": "2024-08-08 02:36:04", "link": "http://arxiv.org/abs/2408.04174v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Preserving spoken content in voice anonymisation with character-level\n  vocoder conditioning", "abstract": "Voice anonymisation can be used to help protect speaker privacy when speech\ndata is shared with untrusted others. In most practical applications, while the\nvoice identity should be sanitised, other attributes such as the spoken content\nshould be preserved. There is always a trade-off; all approaches reported thus\nfar sacrifice spoken content for anonymisation performance. We report what is,\nto the best of our knowledge, the first attempt to actively preserve spoken\ncontent in voice anonymisation. We show how the output of an auxiliary\nautomatic speech recognition model can be used to condition the vocoder module\nof an anonymisation system using a set of learnable embedding dictionaries in\norder to preserve spoken content. Relative to a baseline approach, and for only\na modest cost in anonymisation performance, the technique is successful in\ndecreasing the word error rate computed from anonymised utterances by almost\n60%.", "published": "2024-08-08 08:40:05", "link": "http://arxiv.org/abs/2408.04306v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Distil-DCCRN: A Small-footprint DCCRN Leveraging Feature-based Knowledge\n  Distillation in Speech Enhancement", "abstract": "The deep complex convolution recurrent network (DCCRN) achieves excellent\nspeech enhancement performance by utilizing the audio spectrum's complex\nfeatures. However, it has a large number of model parameters. We propose a\nsmaller model, Distil-DCCRN, which has only 30% of the parameters compared to\nthe DCCRN. To ensure that the performance of Distil-DCCRN matches that of the\nDCCRN, we employ the knowledge distillation (KD) method to use a larger teacher\nmodel to help train a smaller student model. We design a knowledge distillation\n(KD) method, integrating attention transfer and Kullback-Leibler divergence\n(AT-KL) to train the student model Distil-DCCRN. Additionally, we use a model\nwith better performance and a more complicated structure, Uformer, as the\nteacher model. Unlike previous KD approaches that mainly focus on model\noutputs, our method also leverages the intermediate features from the models'\nmiddle layers, facilitating rich knowledge transfer across different structured\nmodels despite variations in layer configurations and discrepancies in the\nchannel and time dimensions of intermediate features. Employing our AT-KL\napproach, Distil-DCCRN outperforms DCCRN as well as several other competitive\nmodels in both PESQ and SI-SNR metrics on the DNS test set and achieves\ncomparable results to DCCRN in DNSMOS.", "published": "2024-08-08 07:10:23", "link": "http://arxiv.org/abs/2408.04267v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Assessing the Potential Impact of Direction-Dependent HRTF Selection on\n  Sound Localization Accuracy", "abstract": "This study investigates the approach of direction-dependent selection of\nHead-Related Transfer Functions (HRTFs) and its impact on sound localization\naccuracy. For applications such as virtual reality (VR) and teleconferencing,\nobtaining individualized HRTFs can be beneficial yet challenging, the objective\nof this work is therefore to assess whether incorporating HRTFs in a\ndirection-dependent manner could improve localization precision without the\nneed to obtain individualized HRTFs. A localization experiment conducted with a\nVR headset assessed localization errors, comparing an overall best HRTF from a\nset, against selecting the best HRTF based on average performance in each\ndirection. The results demonstrate a substantial improvement in elevation\nlocalization error with the method motivated by direction-dependent HRTF\nselection, while revealing insignificant differences in azimuth errors.", "published": "2024-08-08 07:55:26", "link": "http://arxiv.org/abs/2408.04288v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "NeuralMultiling: A Novel Neural Architecture Search for Smartphone based\n  Multilingual Speaker Verification", "abstract": "Multilingual speaker verification introduces the challenge of verifying a\nspeaker in multiple languages. Existing systems were built using\ni-vector/x-vector approaches along with Bi-LSTMs, which were trained to\ndiscriminate speakers, irrespective of the language. Instead of exploring the\ndesign space manually, we propose a neural architecture search for multilingual\nspeaker verification suitable for mobile devices, called\n\\textbf{NeuralMultiling}. First, our algorithm searches for an optimal\noperational combination of neural cells with different architectures for normal\ncells and reduction cells and then derives a CNN model by stacking neural\ncells. Using the derived architecture, we performed two different studies:1)\nlanguage agnostic condition and 2) interoperability between languages and\ndevices on the publicly available Multilingual Audio-Visual Smartphone (MAVS)\ndataset. The experimental results suggest that the derived architecture\nsignificantly outperforms the existing Autospeech method by a 5-6\\% reduction\nin the Equal Error Rate (EER) with fewer model parameters.", "published": "2024-08-08 10:49:17", "link": "http://arxiv.org/abs/2408.04362v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Exploiting Consistency-Preserving Loss and Perceptual Contrast\n  Stretching to Boost SSL-based Speech Enhancement", "abstract": "Self-supervised representation learning (SSL) has attained SOTA results on\nseveral downstream speech tasks, but SSL-based speech enhancement (SE)\nsolutions still lag behind. To address this issue, we exploit three main ideas:\n(i) Transformer-based masking generation, (ii) consistency-preserving loss, and\n(iii) perceptual contrast stretching (PCS). In detail, conformer layers,\nleveraging an attention mechanism, are introduced to effectively model\nframe-level representations and obtain the Ideal Ratio Mask (IRM) for SE.\nMoreover, we incorporate consistency in the loss function, which processes the\ninput to account for the inconsistency effects of signal reconstruction from\nthe spectrogram. Finally, PCS is employed to improve the contrast of input and\ntarget features according to perceptual importance. Evaluated on the\nVoiceBank-DEMAND task, the proposed solution outperforms previously SSL-based\nSE solutions when tested on several objective metrics, attaining a SOTA PESQ\nscore of 3.54.", "published": "2024-08-08 22:11:43", "link": "http://arxiv.org/abs/2408.04773v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "TheGlueNote: Learned Representations for Robust and Flexible Note\n  Alignment", "abstract": "Note alignment refers to the task of matching individual notes of two\nversions of the same symbolically encoded piece. Methods addressing this task\ncommonly rely on sequence alignment algorithms such as Hidden Markov Models or\nDynamic Time Warping (DTW) applied directly to note or onset sequences. While\nsuccessful in many cases, such methods struggle with large mismatches between\nthe versions. In this work, we learn note-wise representations from data\naugmented with various complex mismatch cases, e.g. repeats, skips, block\ninsertions, and long trills. At the heart of our approach lies a transformer\nencoder network - TheGlueNote - which predicts pairwise note similarities for\ntwo 512 note subsequences. We postprocess the predicted similarities using\nflavors of weightedDTW and pitch-separated onsetDTW to retrieve note matches\nfor two sequences of arbitrary length. Our approach performs on par with the\nstate of the art in terms of note alignment accuracy, is considerably more\nrobust to version mismatches, and works directly on any pair of MIDI files.", "published": "2024-08-08 08:42:30", "link": "http://arxiv.org/abs/2408.04309v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MulliVC: Multi-lingual Voice Conversion With Cycle Consistency", "abstract": "Voice conversion aims to modify the source speaker's voice to resemble the\ntarget speaker while preserving the original speech content. Despite notable\nadvancements in voice conversion these days, multi-lingual voice conversion\n(including both monolingual and cross-lingual scenarios) has yet to be\nextensively studied. It faces two main challenges: 1) the considerable\nvariability in prosody and articulation habits across languages; and 2) the\nrarity of paired multi-lingual datasets from the same speaker. In this paper,\nwe propose MulliVC, a novel voice conversion system that only converts timbre\nand keeps original content and source language prosody without multi-lingual\npaired data. Specifically, each training step of MulliVC contains three\nsubsteps: In step one the model is trained with monolingual speech data; then,\nsteps two and three take inspiration from back translation, construct a\ncyclical process to disentangle the timbre and other information (content,\nprosody, and other language-related information) in the absence of\nmulti-lingual data from the same speaker. Both objective and subjective results\nindicate that MulliVC significantly surpasses other methods in both monolingual\nand cross-lingual contexts, demonstrating the system's efficacy and the\nviability of the three-step approach with cycle consistency. Audio samples can\nbe found on our demo page (mullivc.github.io).", "published": "2024-08-08 18:12:51", "link": "http://arxiv.org/abs/2408.04708v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quantifying the Corpus Bias Problem in Automatic Music Transcription\n  Systems", "abstract": "Automatic Music Transcription (AMT) is the task of recognizing notes in audio\nrecordings of music. The State-of-the-Art (SotA) benchmarks have been dominated\nby deep learning systems. Due to the scarcity of high quality data, they are\nusually trained and evaluated exclusively or predominantly on classical piano\nmusic. Unfortunately, that hinders our ability to understand how they\ngeneralize to other music. Previous works have revealed several aspects of\nmemorization and overfitting in these systems. We identify two primary sources\nof distribution shift: the music, and the sound. Complementing recent results\non the sound axis (i.e. acoustics, timbre), we investigate the musical one\n(i.e. note combinations, dynamics, genre). We evaluate the performance of\nseveral SotA AMT systems on two new experimental test sets which we carefully\nconstruct to emulate different levels of musical distribution shift. Our\nresults reveal a stark performance gap, shedding further light on the Corpus\nBias problem, and the extent to which it continues to trouble these systems.", "published": "2024-08-08 19:40:28", "link": "http://arxiv.org/abs/2408.04737v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
