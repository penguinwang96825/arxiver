{"title": "Weakly Supervised Neuro-Symbolic Module Networks for Numerical Reasoning", "abstract": "Neural Module Networks (NMNs) have been quite successful in incorporating\nexplicit reasoning as learnable modules in various question answering tasks,\nincluding the most generic form of numerical reasoning over text in Machine\nReading Comprehension (MRC). However, to achieve this, contemporary NMNs need\nstrong supervision in executing the query as a specialized program over\nreasoning modules and fail to generalize to more open-ended settings without\nsuch supervision. Hence we propose Weakly-Supervised Neuro-Symbolic Module\nNetwork (WNSMN) trained with answers as the sole supervision for numerical\nreasoning based MRC. It learns to execute a noisy heuristic program obtained\nfrom the dependency parsing of the query, as discrete actions over both neural\nand symbolic reasoning modules and trains it end-to-end in a reinforcement\nlearning framework with discrete reward from answer matching. On the\nnumerical-answer subset of DROP, WNSMN out-performs NMN by 32% and the\nreasoning-free language model GenBERT by 8% in exact match accuracy when\ntrained under comparable weak supervised settings. This showcases the\neffectiveness and generalizability of modular networks that can handle explicit\ndiscrete reasoning over noisy programs in an end-to-end manner.", "published": "2021-01-28 03:36:09", "link": "http://arxiv.org/abs/2101.11802v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LESA: Linguistic Encapsulation and Semantic Amalgamation Based\n  Generalised Claim Detection from Online Content", "abstract": "The conceptualization of a claim lies at the core of argument mining. The\nsegregation of claims is complex, owing to the divergence in textual syntax and\ncontext across different distributions. Another pressing issue is the\nunavailability of labeled unstructured text for experimentation. In this paper,\nwe propose LESA, a framework which aims at advancing headfirst into expunging\nthe former issue by assembling a source-independent generalized model that\ncaptures syntactic features through part-of-speech and dependency embeddings,\nas well as contextual features through a fine-tuned language model. We resolve\nthe latter issue by annotating a Twitter dataset which aims at providing a\ntesting ground on a large unstructured dataset. Experimental results show that\nLESA improves upon the state-of-the-art performance across six benchmark claim\ndatasets by an average of 3 claim-F1 points for in-domain experiments and by 2\nclaim-F1 points for general-domain experiments. On our dataset too, LESA\noutperforms existing baselines by 1 claim-F1 point on the in-domain experiments\nand 2 claim-F1 points on the general-domain experiments. We also release\ncomprehensive data annotation guidelines compiled during the annotation phase\n(which was missing in the current literature).", "published": "2021-01-28 09:51:30", "link": "http://arxiv.org/abs/2101.11891v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Attention Guided Dialogue State Tracking with Sparse Supervision", "abstract": "Existing approaches to Dialogue State Tracking (DST) rely on turn level\ndialogue state annotations, which are expensive to acquire in large scale. In\ncall centers, for tasks like managing bookings or subscriptions, the user goal\ncan be associated with actions (e.g.~API calls) issued by customer service\nagents. These action logs are available in large volumes and can be utilized\nfor learning dialogue states. However, unlike turn-level annotations, such\nlogged actions are only available sparsely across the dialogue, providing only\na form of weak supervision for DST models. To efficiently learn DST with sparse\nlabels, we extend a state-of-the-art encoder-decoder model. The model learns a\nslot-aware representation of dialogue history, which focuses on relevant turns\nto guide the decoder. We present results on two public multi-domain DST\ndatasets (MultiWOZ and Schema Guided Dialogue) in both settings i.e. training\nwith turn-level and with sparse supervision. The proposed approach improves\nover baseline in both settings. More importantly, our model trained with sparse\nsupervision is competitive in performance to fully supervised baselines, while\nbeing more data and cost efficient.", "published": "2021-01-28 12:18:39", "link": "http://arxiv.org/abs/2101.11958v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntactic Nuclei in Dependency Parsing -- A Multilingual Exploration", "abstract": "Standard models for syntactic dependency parsing take words to be the\nelementary units that enter into dependency relations. In this paper, we\ninvestigate whether there are any benefits from enriching these models with the\nmore abstract notion of nucleus proposed by Tesni\\`{e}re. We do this by showing\nhow the concept of nucleus can be defined in the framework of Universal\nDependencies and how we can use composition functions to make a\ntransition-based dependency parser aware of this concept. Experiments on 12\nlanguages show that nucleus composition gives small but significant\nimprovements in parsing accuracy. Further analysis reveals that the improvement\nmainly concerns a small number of dependency relations, including nominal\nmodifiers, relations of coordination, main predicates, and direct objects.", "published": "2021-01-28 12:22:30", "link": "http://arxiv.org/abs/2101.11959v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-automatic Generation of Multilingual Datasets for Stance Detection\n  in Twitter", "abstract": "Popular social media networks provide the perfect environment to study the\nopinions and attitudes expressed by users. While interactions in social media\nsuch as Twitter occur in many natural languages, research on stance detection\n(the position or attitude expressed with respect to a specific topic) within\nthe Natural Language Processing field has largely been done for English.\nAlthough some efforts have recently been made to develop annotated data in\nother languages, there is a telling lack of resources to facilitate\nmultilingual and crosslingual research on stance detection. This is partially\ndue to the fact that manually annotating a corpus of social media texts is a\ndifficult, slow and costly process. Furthermore, as stance is a highly domain-\nand topic-specific phenomenon, the need for annotated data is specially\ndemanding. As a result, most of the manually labeled resources are hindered by\ntheir relatively small size and skewed class distribution. This paper presents\na method to obtain multilingual datasets for stance detection in Twitter.\nInstead of manually annotating on a per tweet basis, we leverage user-based\ninformation to semi-automatically label large amounts of tweets. Empirical\nmonolingual and cross-lingual experimentation and qualitative analysis show\nthat our method helps to overcome the aforementioned difficulties to build\nlarge, balanced and multilingual labeled corpora. We believe that our method\ncan be easily adapted to easily generate labeled social media data for other\nNatural Language Processing tasks and domains.", "published": "2021-01-28 13:05:09", "link": "http://arxiv.org/abs/2101.11978v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A transformer based approach for fighting COVID-19 fake news", "abstract": "The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n\"Constraint@AAAI2021 - COVID19 Fake News Detection in English\" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.", "published": "2021-01-28 14:43:42", "link": "http://arxiv.org/abs/2101.12027v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing Sequence-to-Sequence Neural Lemmatization with External\n  Resources", "abstract": "We propose a novel hybrid approach to lemmatization that enhances the seq2seq\nneural model with additional lemmas extracted from an external lexicon or a\nrule-based system. During training, the enhanced lemmatizer learns both to\ngenerate lemmas via a sequential decoder and copy the lemma characters from the\nexternal candidates supplied during run-time. Our lemmatizer enhanced with\ncandidates extracted from the Apertium morphological analyzer achieves\nstatistically significant improvements compared to baseline models not\nutilizing additional lemma information, achieves an average accuracy of 97.25%\non a set of 23 UD languages, which is 0.55% higher than obtained with the\nStanford Stanza model on the same set of languages. We also compare with other\nmethods of integrating external data into lemmatization and show that our\nenhanced system performs considerably better than a simple lexicon extension\nmethod based on the Stanza system, and it achieves complementary improvements\nw.r.t. the data augmentation method.", "published": "2021-01-28 15:14:20", "link": "http://arxiv.org/abs/2101.12056v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Neural Few-Shot Text Classification Reality Check", "abstract": "Modern classification models tend to struggle when the amount of annotated\ndata is scarce. To overcome this issue, several neural few-shot classification\nmodels have emerged, yielding significant progress over time, both in Computer\nVision and Natural Language Processing. In the latter, such models used to rely\non fixed word embeddings before the advent of transformers. Additionally, some\nmodels used in Computer Vision are yet to be tested in NLP applications. In\nthis paper, we compare all these models, first adapting those made in the field\nof image processing to NLP, and second providing them access to transformers.\nWe then test these models equipped with the same transformer-based encoder on\nthe intent detection task, known for having a large number of classes. Our\nresults reveal that while methods perform almost equally on the ARSC dataset,\nthis is not the case for the Intent Detection task, where the most recent and\nsupposedly best competitors perform worse than older and simpler ones (while\nall are given access to transformers). We also show that a simple baseline is\nsurprisingly strong. All the new developed models, as well as the evaluation\nframework, are made publicly available.", "published": "2021-01-28 15:46:14", "link": "http://arxiv.org/abs/2101.12073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Context in Answer Sentence Selection Systems on a Latency\n  Budget", "abstract": "Answer Sentence Selection (AS2) is an efficient approach for the design of\nopen-domain Question Answering (QA) systems. In order to achieve low latency,\ntraditional AS2 models score question-answer pairs individually, ignoring any\ninformation from the document each potential answer was extracted from. In\ncontrast, more computationally expensive models designed for machine reading\ncomprehension tasks typically receive one or more passages as input, which\noften results in better accuracy. In this work, we present an approach to\nefficiently incorporate contextual information in AS2 models. For each answer\ncandidate, we first use unsupervised similarity techniques to extract relevant\nsentences from its source document, which we then feed into an efficient\ntransformer architecture fine-tuned for AS2. Our best approach, which leverages\na multi-way attention architecture to efficiently encode context, improves 6%\nto 11% over noncontextual state of the art in AS2 with minimal impact on system\nlatency. All experiments in this work were conducted in English.", "published": "2021-01-28 16:24:48", "link": "http://arxiv.org/abs/2101.12093v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LOME: Large Ontology Multilingual Extraction", "abstract": "We present LOME, a system for performing multilingual information extraction.\nGiven a text document as input, our core system identifies spans of textual\nentity and event mentions with a FrameNet (Baker et al., 1998) parser. It\nsubsequently performs coreference resolution, fine-grained entity typing, and\ntemporal relation prediction between events. By doing so, the system constructs\nan event and entity focused knowledge graph. We can further apply third-party\nmodules for other types of annotation, like relation extraction. Our\n(multilingual) first-party modules either outperform or are competitive with\nthe (monolingual) state-of-the-art. We achieve this through the use of\nmultilingual encoders like XLM-R (Conneau et al., 2020) and leveraging\nmultilingual training data. LOME is available as a Docker container on Docker\nHub. In addition, a lightweight version of the system is accessible as a web\ndemo.", "published": "2021-01-28 18:28:59", "link": "http://arxiv.org/abs/2101.12175v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Combining pre-trained language models and structured knowledge", "abstract": "In recent years, transformer-based language models have achieved state of the\nart performance in various NLP benchmarks. These models are able to extract\nmostly distributional information with some semantics from unstructured text,\nhowever it has proven challenging to integrate structured information, such as\nknowledge graphs into these models. We examine a variety of approaches to\nintegrate structured knowledge into current language models and determine\nchallenges, and possible opportunities to leverage both structured and\nunstructured information sources. From our survey, we find that there are still\nopportunities at exploiting adapter-based injections and that it may be\npossible to further combine various of the explored approaches into one system.", "published": "2021-01-28 21:54:03", "link": "http://arxiv.org/abs/2101.12294v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LSTM-SAKT: LSTM-Encoded SAKT-like Transformer for Knowledge Tracing", "abstract": "This paper introduces the 2nd place solution for the Riiid! Answer\nCorrectness Prediction in Kaggle, the world's largest data science competition\nwebsite. This competition was held from October 16, 2020, to January 7, 2021,\nwith 3395 teams and 4387 competitors. The main insights and contributions of\nthis paper are as follows. (i) We pointed out existing Transformer-based models\nare suffering from a problem that the information which their query/key/value\ncan contain is limited. To solve this problem, we proposed a method that uses\nLSTM to obtain query/key/value and verified its effectiveness. (ii) We pointed\nout 'inter-container' leakage problem, which happens in datasets where\nquestions are sometimes served together. To solve this problem, we showed\nspecial indexing/masking techniques that are useful when using RNN-variants and\nTransformer. (iii) We found additional hand-crafted features are effective to\novercome the limits of Transformer, which can never consider the samples older\nthan the sequence length.", "published": "2021-01-28 11:21:46", "link": "http://arxiv.org/abs/2102.00845v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProtoDA: Efficient Transfer Learning for Few-Shot Intent Classification", "abstract": "Practical sequence classification tasks in natural language processing often\nsuffer from low training data availability for target classes. Recent works\ntowards mitigating this problem have focused on transfer learning using\nembeddings pre-trained on often unrelated tasks, for instance, language\nmodeling. We adopt an alternative approach by transfer learning on an ensemble\nof related tasks using prototypical networks under the meta-learning paradigm.\nUsing intent classification as a case study, we demonstrate that increasing\nvariability in training tasks can significantly improve classification\nperformance. Further, we apply data augmentation in conjunction with\nmeta-learning to reduce sampling bias. We make use of a conditional generator\nfor data augmentation that is trained directly using the meta-learning\nobjective and simultaneously with prototypical networks, hence ensuring that\ndata augmentation is customized to the task. We explore augmentation in the\nsentence embedding space as well as prototypical embedding space. Combining\nmeta-learning with augmentation provides upto 6.49% and 8.53% relative F1-score\nimprovements over the best performing systems in the 5-shot and 10-shot\nlearning, respectively.", "published": "2021-01-28 00:19:13", "link": "http://arxiv.org/abs/2101.11753v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Does Typological Blinding Impede Cross-Lingual Sharing?", "abstract": "Bridging the performance gap between high- and low-resource languages has\nbeen the focus of much previous work. Typological features from databases such\nas the World Atlas of Language Structures (WALS) are a prime candidate for\nthis, as such data exists even for very low-resource languages. However,\nprevious work has only found minor benefits from using typological information.\nOur hypothesis is that a model trained in a cross-lingual setting will pick up\non typological cues from the input data, thus overshadowing the utility of\nexplicitly using such features. We verify this hypothesis by blinding a model\nto typological information, and investigate how cross-lingual sharing and\nperformance is impacted. Our model is based on a cross-lingual architecture in\nwhich the latent weights governing the sharing between languages is learnt\nduring training. We show that (i) preventing this model from exploiting\ntypology severely reduces performance, while a control experiment reaffirms\nthat (ii) encouraging sharing according to typology somewhat improves\nperformance.", "published": "2021-01-28 09:32:08", "link": "http://arxiv.org/abs/2101.11888v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Explaining Natural Language Processing Classifiers with Occlusion and\n  Language Modeling", "abstract": "Deep neural networks are powerful statistical learners. However, their\npredictions do not come with an explanation of their process. To analyze these\nmodels, explanation methods are being developed. We present a novel explanation\nmethod, called OLM, for natural language processing classifiers. This method\ncombines occlusion and language modeling, which are techniques central to\nexplainability and NLP, respectively. OLM gives explanations that are\ntheoretically sound and easy to understand.\n  We make several contributions to the theory of explanation methods. Axioms\nfor explanation methods are an interesting theoretical concept to explore their\nbasics and deduce methods. We introduce a new axiom, give its intuition and\nshow it contradicts another existing axiom. Additionally, we point out\ntheoretical difficulties of existing gradient-based and some occlusion-based\nexplanation methods in natural language processing. We provide an extensive\nargument why evaluation of explanation methods is difficult. We compare OLM to\nother explanation methods and underline its uniqueness experimentally. Finally,\nwe investigate corner cases of OLM and discuss its validity and possible\nimprovements.", "published": "2021-01-28 09:44:04", "link": "http://arxiv.org/abs/2101.11889v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Role of Syntactic Planning in Compositional Image Captioning", "abstract": "Image captioning has focused on generalizing to images drawn from the same\ndistribution as the training set, and not to the more challenging problem of\ngeneralizing to different distributions of images. Recently, Nikolaus et al.\n(2019) introduced a dataset to assess compositional generalization in image\ncaptioning, where models are evaluated on their ability to describe images with\nunseen adjective-noun and noun-verb compositions. In this work, we investigate\ndifferent methods to improve compositional generalization by planning the\nsyntactic structure of a caption. Our experiments show that jointly modeling\ntokens and syntactic tags enhances generalization in both RNN- and\nTransformer-based models, while also improving performance on standard metrics.", "published": "2021-01-28 10:26:08", "link": "http://arxiv.org/abs/2101.11911v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Us vs. Them: A Dataset of Populist Attitudes, News Bias and Emotions", "abstract": "Computational modelling of political discourse tasks has become an\nincreasingly important area of research in natural language processing.\nPopulist rhetoric has risen across the political sphere in recent years;\nhowever, computational approaches to it have been scarce due to its complex\nnature. In this paper, we present the new $\\textit{Us vs. Them}$ dataset,\nconsisting of 6861 Reddit comments annotated for populist attitudes and the\nfirst large-scale computational models of this phenomenon. We investigate the\nrelationship between populist mindsets and social groups, as well as a range of\nemotions typically associated with these. We set a baseline for two tasks\nrelated to populist attitudes and present a set of multi-task learning models\nthat leverage and demonstrate the importance of emotion and group\nidentification as auxiliary tasks.", "published": "2021-01-28 12:18:19", "link": "http://arxiv.org/abs/2101.11956v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "VX2TEXT: End-to-End Learning of Video-Based Text Generation From\n  Multimodal Inputs", "abstract": "We present \\textsc{Vx2Text}, a framework for text generation from multimodal\ninputs consisting of video plus text, speech, or audio. In order to leverage\ntransformer networks, which have been shown to be effective at modeling\nlanguage, each modality is first converted into a set of language embeddings by\na learnable tokenizer. This allows our approach to perform multimodal fusion in\nthe language space, thus eliminating the need for ad-hoc cross-modal fusion\nmodules. To address the non-differentiability of tokenization on continuous\ninputs (e.g., video or audio), we utilize a relaxation scheme that enables\nend-to-end training. Furthermore, unlike prior encoder-only models, our network\nincludes an autoregressive decoder to generate open-ended text from the\nmultimodal embeddings fused by the language encoder. This renders our approach\nfully generative and makes it directly applicable to different \"video+$x$ to\ntext\" problems without the need to design specialized network heads for each\ntask. The proposed framework is not only conceptually simple but also\nremarkably effective: experiments demonstrate that our approach based on a\nsingle architecture outperforms the state-of-the-art on three video-based\ntext-generation tasks -- captioning, question answering and audio-visual\nscene-aware dialog.", "published": "2021-01-28 15:22:36", "link": "http://arxiv.org/abs/2101.12059v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "VRoC: Variational Autoencoder-aided Multi-task Rumor Classifier Based on\n  Text", "abstract": "Social media became popular and percolated almost all aspects of our daily\nlives. While online posting proves very convenient for individual users, it\nalso fosters fast-spreading of various rumors. The rapid and wide percolation\nof rumors can cause persistent adverse or detrimental impacts. Therefore,\nresearchers invest great efforts on reducing the negative impacts of rumors.\nTowards this end, the rumor classification system aims to detect, track, and\nverify rumors in social media. Such systems typically include four components:\n(i) a rumor detector, (ii) a rumor tracker, (iii) a stance classifier, and (iv)\na veracity classifier. In order to improve the state-of-the-art in rumor\ndetection, tracking, and verification, we propose VRoC, a tweet-level\nvariational autoencoder-based rumor classification system. VRoC consists of a\nco-train engine that trains variational autoencoders (VAEs) and rumor\nclassification components. The co-train engine helps the VAEs to tune their\nlatent representations to be classifier-friendly. We also show that VRoC is\nable to classify unseen rumors with high levels of accuracy. For the PHEME\ndataset, VRoC consistently outperforms several state-of-the-art techniques, on\nboth observed and unobserved rumors, by up to 26.9%, in terms of macro-F1\nscores.", "published": "2021-01-28 03:26:57", "link": "http://arxiv.org/abs/2102.00816v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "DRAG: Director-Generator Language Modelling Framework for Non-Parallel\n  Author Stylized Rewriting", "abstract": "Author stylized rewriting is the task of rewriting an input text in a\nparticular author's style. Recent works in this area have leveraged\nTransformer-based language models in a denoising autoencoder setup to generate\nauthor stylized text without relying on a parallel corpus of data. However,\nthese approaches are limited by the lack of explicit control of target\nattributes and being entirely data-driven. In this paper, we propose a\nDirector-Generator framework to rewrite content in the target author's style,\nspecifically focusing on certain target attributes. We show that our proposed\nframework works well even with a limited-sized target author corpus. Our\nexperiments on corpora consisting of relatively small-sized text authored by\nthree distinct authors show significant improvements upon existing works to\nrewrite input texts in target author's style. Our quantitative and qualitative\nanalyses further show that our model has better meaning retention and results\nin more fluent generations.", "published": "2021-01-28 06:52:40", "link": "http://arxiv.org/abs/2101.11836v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Identifying COVID-19 Fake News in Social Media", "abstract": "The evolution of social media platforms have empowered everyone to access\ninformation easily. Social media users can easily share information with the\nrest of the world. This may sometimes encourage spread of fake news, which can\nresult in undesirable consequences. In this work, we train models which can\nidentify health news related to COVID-19 pandemic as real or fake. Our models\nachieve a high F1-score of 98.64%. Our models achieve second place on the\nleaderboard, tailing the first position with a very narrow margin 0.05% points.", "published": "2021-01-28 12:12:50", "link": "http://arxiv.org/abs/2101.11954v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Disembodied Machine Learning: On the Illusion of Objectivity in NLP", "abstract": "Machine Learning seeks to identify and encode bodies of knowledge within\nprovided datasets. However, data encodes subjective content, which determines\nthe possible outcomes of the models trained on it. Because such subjectivity\nenables marginalisation of parts of society, it is termed (social) `bias' and\nsought to be removed. In this paper, we contextualise this discourse of bias in\nthe ML community against the subjective choices in the development process.\nThrough a consideration of how choices in data and model development construct\nsubjectivity, or biases that are represented in a model, we argue that\naddressing and mitigating biases is near-impossible. This is because both data\nand ML models are objects for which meaning is made in each step of the\ndevelopment pipeline, from data selection over annotation to model training and\nanalysis. Accordingly, we find the prevalent discourse of bias limiting in its\nability to address social marginalisation. We recommend to be conscientious of\nthis, and to accept that de-biasing methods only correct for a fraction of\nbiases.", "published": "2021-01-28 12:58:39", "link": "http://arxiv.org/abs/2101.11974v1", "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "cs.AI"}
{"title": "BERTa\u00fa: Ita\u00fa BERT for digital customer service", "abstract": "In the last few years, three major topics received increased interest: deep\nlearning, NLP and conversational agents. Bringing these three topics together\nto create an amazing digital customer experience and indeed deploy in\nproduction and solve real-world problems is something innovative and\ndisruptive. We introduce a new Portuguese financial domain language\nrepresentation model called BERTa\\'u. BERTa\\'u is an uncased BERT-base trained\nfrom scratch with data from the Ita\\'u virtual assistant chatbot solution. Our\nnovel contribution is that BERTa\\'u pretrained language model requires less\ndata, reached state-of-the-art performance in three NLP tasks, and generates a\nsmaller and lighter model that makes the deployment feasible. We developed\nthree tasks to validate our model: information retrieval with Frequently Asked\nQuestions (FAQ) from Ita\\'u bank, sentiment analysis from our virtual assistant\ndata, and a NER solution. All proposed tasks are real-world solutions in\nproduction on our environment and the usage of a specialist model proved to be\neffective when compared to Google BERT multilingual and the DPRQuestionEncoder\nfrom Facebook, available at Hugging Face. The BERTa\\'u improves the performance\nin 22% of FAQ Retrieval MRR metric, 2.1% in Sentiment Analysis F1 score, 4.4%\nin NER F1 score and can also represent the same sequence in up to 66% fewer\ntokens when compared to \"shelf models\".", "published": "2021-01-28 14:29:03", "link": "http://arxiv.org/abs/2101.12015v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
