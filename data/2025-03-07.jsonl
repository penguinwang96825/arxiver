{"title": "SINdex: Semantic INconsistency Index for Hallucination Detection in LLMs", "abstract": "Large language models (LLMs) are increasingly deployed across diverse\ndomains, yet they are prone to generating factually incorrect outputs -\ncommonly known as \"hallucinations.\" Among existing mitigation strategies,\nuncertainty-based methods are particularly attractive due to their ease of\nimplementation, independence from external data, and compatibility with\nstandard LLMs. In this work, we introduce a novel and scalable\nuncertainty-based semantic clustering framework for automated hallucination\ndetection. Our approach leverages sentence embeddings and hierarchical\nclustering alongside a newly proposed inconsistency measure, SINdex, to yield\nmore homogeneous clusters and more accurate detection of hallucination\nphenomena across various LLMs. Evaluations on prominent open- and closed-book\nQA datasets demonstrate that our method achieves AUROC improvements of up to\n9.3% over state-of-the-art techniques. Extensive ablation studies further\nvalidate the effectiveness of each component in our framework.", "published": "2025-03-07 23:25:19", "link": "http://arxiv.org/abs/2503.05980v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SANDWiCH: Semantical Analysis of Neighbours for Disambiguating Words in Context ad Hoc", "abstract": "The rise of generative chat-based Large Language Models (LLMs) over the past\ntwo years has spurred a race to develop systems that promise near-human\nconversational and reasoning experiences. However, recent studies indicate that\nthe language understanding offered by these models remains limited and far from\nhuman-like performance, particularly in grasping the contextual meanings of\nwords, an essential aspect of reasoning. In this paper, we present a simple yet\ncomputationally efficient framework for multilingual Word Sense Disambiguation\n(WSD). Our approach reframes the WSD task as a cluster discrimination analysis\nover a semantic network refined from BabelNet using group algebra. We validate\nour methodology across multiple WSD benchmarks, achieving a new state of the\nart for all languages and tasks, as well as in individual assessments by part\nof speech. Notably, our model significantly surpasses the performance of\ncurrent alternatives, even in low-resource languages, while reducing the\nparameter count by 72%.", "published": "2025-03-07 21:52:32", "link": "http://arxiv.org/abs/2503.05958v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language modelling techniques for analysing the impact of human genetic variation", "abstract": "Interpreting the effects of variants within the human genome and proteome is\nessential for analysing disease risk, predicting medication response, and\ndeveloping personalised health interventions. Due to the intrinsic similarities\nbetween the structure of natural languages and genetic sequences, natural\nlanguage processing techniques have demonstrated great applicability in\ncomputational variant effect prediction. In particular, the advent of the\nTransformer has led to significant advancements in the field. However,\nTransformer-based models are not without their limitations, and a number of\nextensions and alternatives have been developed to improve results and enhance\ncomputational efficiency. This review explores the use of language models for\ncomputational variant effect prediction over the past decade, analysing the\nmain architectures, and identifying key trends and future directions.", "published": "2025-03-07 21:34:17", "link": "http://arxiv.org/abs/2503.10655v1", "categories": ["cs.CL", "cs.AI", "q-bio.BM"], "primary_category": "cs.CL"}
{"title": "DETQUS: Decomposition-Enhanced Transformers for QUery-focused Summarization", "abstract": "Query-focused tabular summarization is an emerging task in table-to-text\ngeneration that synthesizes a summary response from tabular data based on user\nqueries. Traditional transformer-based approaches face challenges due to token\nlimitations and the complexity of reasoning over large tables. To address these\nchallenges, we introduce DETQUS (Decomposition-Enhanced Transformers for\nQUery-focused Summarization), a system designed to improve summarization\naccuracy by leveraging tabular decomposition alongside a fine-tuned\nencoder-decoder model. DETQUS employs a large language model to selectively\nreduce table size, retaining only query-relevant columns while preserving\nessential information. This strategy enables more efficient processing of large\ntables and enhances summary quality. Our approach, equipped with table-based QA\nmodel Omnitab, achieves a ROUGE-L score of 0.4437, outperforming the previous\nstate-of-the-art REFACTOR model (ROUGE-L: 0.422). These results highlight\nDETQUS as a scalable and effective solution for query-focused tabular\nsummarization, offering a structured alternative to more complex architectures.", "published": "2025-03-07 21:11:35", "link": "http://arxiv.org/abs/2503.05935v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Training and Inference Efficiency of Encoder-Decoder Speech Models", "abstract": "Attention encoder-decoder model architecture is the backbone of several\nrecent top performing foundation speech models: Whisper, Seamless, OWSM, and\nCanary-1B. However, the reported data and compute requirements for their\ntraining are prohibitive for many in the research community. In this work, we\nfocus on the efficiency angle and ask the questions of whether we are training\nthese speech models efficiently, and what can we do to improve? We argue that a\nmajor, if not the most severe, detrimental factor for training efficiency is\nrelated to the sampling strategy of sequential data. We show that negligence in\nmini-batch sampling leads to more than 50% computation being spent on padding.\nTo that end, we study, profile, and optimize Canary-1B training to show gradual\nimprovement in GPU utilization leading up to 5x increase in average batch sizes\nversus its original training settings. This in turn allows us to train an\nequivalent model using 4x less GPUs in the same wall time, or leverage the\noriginal resources and train it in 2x shorter wall time. Finally, we observe\nthat the major inference bottleneck lies in the autoregressive decoder steps.\nWe find that adjusting the model architecture to transfer model parameters from\nthe decoder to the encoder results in a 3x inference speedup as measured by\ninverse real-time factor (RTFx) while preserving the accuracy and compute\nrequirements for convergence. The training code and models will be available as\nopen-source.", "published": "2025-03-07 20:57:43", "link": "http://arxiv.org/abs/2503.05931v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "From Style to Facts: Mapping the Boundaries of Knowledge Injection with Finetuning", "abstract": "Finetuning provides a scalable and cost-effective means of customizing\nlanguage models for specific tasks or response styles, with greater reliability\nthan prompting or in-context learning. In contrast, the conventional wisdom is\nthat injecting knowledge via finetuning results in brittle performance and poor\ngeneralization. We argue that the dichotomy of \"task customization\" (e.g.,\ninstruction tuning) and \"knowledge injection\" (e.g., teaching new facts) is a\ndistinction without a difference. We instead identify concrete factors that\nexplain the heterogeneous effectiveness observed with finetuning. To this end,\nwe conduct a large-scale experimental study of finetuning the frontier Gemini\nv1.5 model family on a spectrum of datasets that are artificially engineered to\ninterpolate between the strengths and failure modes of finetuning. Our findings\nindicate that question-answer training data formats provide much stronger\nknowledge generalization than document/article-style training data, numerical\ninformation can be harder for finetuning to retain than categorical\ninformation, and models struggle to apply finetuned knowledge during multi-step\nreasoning even when trained on similar examples -- all factors that render\n\"knowledge injection\" to be especially difficult, even after controlling for\nconsiderations like data augmentation and information volume. On the other\nhand, our findings also indicate that it is not fundamentally more difficult to\nfinetune information about a real-world event than information about what a\nmodel's writing style should be.", "published": "2025-03-07 20:35:31", "link": "http://arxiv.org/abs/2503.05919v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "IDEA Prune: An Integrated Enlarge-and-Prune Pipeline in Generative Language Model Pretraining", "abstract": "Recent advancements in large language models have intensified the need for\nefficient and deployable models within limited inference budgets. Structured\npruning pipelines have shown promise in token efficiency compared to training\ntarget-size models from scratch. In this paper, we advocate incorporating\nenlarged model pretraining, which is often ignored in previous works, into\npruning. We study the enlarge-and-prune pipeline as an integrated system to\naddress two critical questions: whether it is worth pretraining an enlarged\nmodel even when the model is never deployed, and how to optimize the entire\npipeline for better pruned models. We propose an integrated enlarge-and-prune\npipeline, which combines enlarge model training, pruning, and recovery under a\nsingle cosine annealing learning rate schedule. This approach is further\ncomplemented by a novel iterative structured pruning method for gradual\nparameter removal. The proposed method helps to mitigate the knowledge loss\ncaused by the rising learning rate in naive enlarge-and-prune pipelines and\nenable effective redistribution of model capacity among surviving neurons,\nfacilitating smooth compression and enhanced performance. We conduct\ncomprehensive experiments on compressing 2.8B models to 1.3B with up to 2T\ntokens in pretraining. It demonstrates the integrated approach not only\nprovides insights into the token efficiency of enlarged model pretraining but\nalso achieves superior performance of pruned models.", "published": "2025-03-07 20:35:31", "link": "http://arxiv.org/abs/2503.05920v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving RAG Retrieval via Propositional Content Extraction: a Speech Act Theory Approach", "abstract": "When users formulate queries, they often include not only the information\nthey seek, but also pragmatic markers such as interrogative phrasing or polite\nrequests. Although these speech act indicators communicate the\nuser\\textquotesingle s intent -- whether it is asking a question, making a\nrequest, or stating a fact -- they do not necessarily add to the core\ninformational content of the query itself. This paper investigates whether\nextracting the underlying propositional content from user utterances --\nessentially stripping away the linguistic markers of intent -- can improve\nretrieval quality in Retrieval-Augmented Generation (RAG) systems. Drawing upon\nfoundational insights from speech act theory, we propose a practical method for\nautomatically transforming queries into their propositional equivalents before\nembedding. To assess the efficacy of this approach, we conducted an\nexperimental study involving 63 user queries related to a Brazilian\ntelecommunications news corpus with precomputed semantic embeddings. Results\ndemonstrate clear improvements in semantic similarity between query embeddings\nand document embeddings at top ranks, confirming that queries stripped of\nspeech act indicators more effectively retrieve relevant content.", "published": "2025-03-07 20:15:40", "link": "http://arxiv.org/abs/2503.10654v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MastermindEval: A Simple But Scalable Reasoning Benchmark", "abstract": "Recent advancements in large language models (LLMs) have led to remarkable\nperformance across a wide range of language understanding and mathematical\ntasks. As a result, increasing attention has been given to assessing the true\nreasoning capabilities of LLMs, driving research into commonsense, numerical,\nlogical, and qualitative reasoning. However, with the rapid progress of\nreasoning-focused models such as OpenAI's o1 and DeepSeek's R1, there has been\na growing demand for reasoning benchmarks that can keep pace with ongoing model\ndevelopments. In this paper, we introduce MastermindEval, a simple, scalable,\nand interpretable deductive reasoning benchmark inspired by the board game\nMastermind. Our benchmark supports two evaluation paradigms: (1) agentic\nevaluation, in which the model autonomously plays the game, and (2) deductive\nreasoning evaluation, in which the model is given a pre-played game state with\nonly one possible valid code to infer. In our experimental results we (1) find\nthat even easy Mastermind instances are difficult for current models and (2)\ndemonstrate that the benchmark is scalable to possibly more advanced models in\nthe future Furthermore, we investigate possible reasons why models cannot\ndeduce the final solution and find that current models are limited in deducing\nthe concealed code as the number of statement to combine information from is\nincreasing.", "published": "2025-03-07 19:24:59", "link": "http://arxiv.org/abs/2503.05891v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation", "abstract": "While the Question Generation (QG) task has been increasingly adopted in\neducational assessments, its evaluation remains limited by approaches that lack\na clear connection to the educational values of test items. In this work, we\nintroduce test item analysis, a method frequently used by educators to assess\ntest question quality, into QG evaluation. Specifically, we construct pairs of\ncandidate questions that differ in quality across dimensions such as topic\ncoverage, item difficulty, item discrimination, and distractor efficiency. We\nthen examine whether existing QG evaluation approaches can effectively\ndistinguish these differences. Our findings reveal significant shortcomings in\nthese approaches with respect to accurately assessing test item quality in\nrelation to student performance. To address this gap, we propose a novel QG\nevaluation framework, QG-SMS, which leverages Large Language Model for Student\nModeling and Simulation to perform test item analysis. As demonstrated in our\nextensive experiments and human evaluation study, the additional perspectives\nintroduced by the simulated student profiles lead to a more effective and\nrobust assessment of test items.", "published": "2025-03-07 19:21:59", "link": "http://arxiv.org/abs/2503.05888v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Understanding the Limits of Lifelong Knowledge Editing in LLMs", "abstract": "Keeping large language models factually up-to-date is crucial for deployment,\nyet costly retraining remains a challenge. Knowledge editing offers a promising\nalternative, but methods are only tested on small-scale or synthetic edit\nbenchmarks. In this work, we aim to bridge research into lifelong knowledge\nediting to real-world edits at practically relevant scale. We first introduce\nWikiBigEdit; a large-scale benchmark of real-world Wikidata edits, built to\nautomatically extend lifelong for future-proof benchmarking. In its first\ninstance, it includes over 500K question-answer pairs for knowledge editing\nalongside a comprehensive evaluation pipeline. Finally, we use WikiBigEdit to\nstudy existing knowledge editing techniques' ability to incorporate large\nvolumes of real-world facts and contrast their capabilities to generic\nmodification techniques such as retrieval augmentation and continual finetuning\nto acquire a complete picture of the practical extent of current lifelong\nknowledge editing.", "published": "2025-03-07 18:45:42", "link": "http://arxiv.org/abs/2503.05683v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for Heterogeneous Reasoning", "abstract": "Combining existing pre-trained expert LLMs is a promising avenue for scalably\ntackling large-scale and diverse tasks. However, selecting experts at the task\nlevel is often too coarse-grained, as heterogeneous tasks may require different\nexpertise for each instance. To enable adaptive instance-level mixing of\npre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and\ngradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained\napproach to selection by emphasizing skills, e.g., algebra in math or molecular\nbiology in biomedical reasoning. We propose a skill-based recruiting strategy\nthat dynamically selects the most relevant set of expert LLMs for diverse\nreasoning tasks based on their strengths. Each selected expert then generates\nits own reasoning, resulting in k outputs from k experts, which are then\nsynthesized into a final high-quality response by an aggregator chosen based on\nits ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's\ninstance-level expert selection improves performance by a large margin but --\nwhen implemented naively -- can introduce a high computational overhead due to\nthe need for constant model loading and offloading. To address this, we\nimplement a batch inference strategy that groups instances based on their\nassigned experts, loading each model only once. This allows us to integrate 16\nexpert models on 1 GPU with a time cost comparable to or better than prior\nmulti-agent baselines using 4 GPUs. Through extensive evaluations on diverse\nbenchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that\nSymbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent\napproaches, with an absolute average improvement of 8.15% over the best\nmulti-agent baseline. Moreover, Symbolic-MoE removes the need for expensive\nmulti-round discussions, outperforming discussion baselines with less\ncomputation.", "published": "2025-03-07 18:03:13", "link": "http://arxiv.org/abs/2503.05641v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning LLM Preference over Intra-Dialogue Pairs: A Framework for Utterance-level Understandings", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nhandling complex dialogue tasks without requiring use case-specific\nfine-tuning. However, analyzing live dialogues in real-time necessitates\nlow-latency processing systems, making it impractical to deploy models with\nbillions of parameters due to latency constraints. As a result, practitioners\noften prefer smaller models with millions of parameters, trained on\nhigh-quality, human-annotated datasets. Yet, curating such datasets is both\ntime-consuming and costly. Consequently, there is a growing need to combine the\nscalability of LLM-generated labels with the precision of human annotations,\nenabling fine-tuned smaller models to achieve both higher speed and accuracy\ncomparable to larger models. In this paper, we introduce a simple yet effective\nframework to address this challenge. Our approach is specifically designed for\nper-utterance classification problems, which encompass tasks such as intent\ndetection, dialogue state tracking, and more. To mitigate the impact of\nlabeling errors from LLMs -- the primary source of inaccuracies in student\nmodels -- we propose a noise-reduced preference learning loss. Experimental\nresults demonstrate that our method significantly improves accuracy across\nutterance-level dialogue tasks, including sentiment detection (over $2\\%$),\ndialogue act classification (over $1.5\\%$), etc.", "published": "2025-03-07 17:46:13", "link": "http://arxiv.org/abs/2503.05620v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models", "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nyet their internal mechanisms remain largely opaque. Recently, mechanistic\ninterpretability has attracted significant attention from the research\ncommunity as a means to understand the inner workings of LLMs. Among various\nmechanistic interpretability approaches, Sparse Autoencoders (SAEs) have\nemerged as a particularly promising method due to their ability to disentangle\nthe complex, superimposed features within LLMs into more interpretable\ncomponents. This paper presents a comprehensive examination of SAEs as a\npromising approach to interpreting and understanding LLMs. We provide a\nsystematic overview of SAE principles, architectures, and applications\nspecifically tailored for LLM analysis, covering theoretical foundations,\nimplementation strategies, and recent developments in sparsity mechanisms. We\nalso explore how SAEs can be leveraged to explain the internal workings of\nLLMs, steer model behaviors in desired directions, and develop more transparent\ntraining methodologies for future models. Despite the challenges that remain\naround SAE implementation and scaling, they continue to provide valuable tools\nfor understanding the internal mechanisms of large language models.", "published": "2025-03-07 17:38:00", "link": "http://arxiv.org/abs/2503.05613v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning", "abstract": "Existing Large Reasoning Models (LRMs) have shown the potential of\nreinforcement learning (RL) to enhance the complex reasoning capabilities of\nLarge Language Models~(LLMs). While they achieve remarkable performance on\nchallenging tasks such as mathematics and coding, they often rely on their\ninternal knowledge to solve problems, which can be inadequate for\ntime-sensitive or knowledge-intensive questions, leading to inaccuracies and\nhallucinations. To address this, we propose \\textbf{R1-Searcher}, a novel\ntwo-stage outcome-based RL approach designed to enhance the search capabilities\nof LLMs. This method allows LLMs to autonomously invoke external search systems\nto access additional knowledge during the reasoning process. Our framework\nrelies exclusively on RL, without requiring process rewards or distillation for\na cold start. % effectively generalizing to out-of-domain datasets and\nsupporting both Base and Instruct models. Our experiments demonstrate that our\nmethod significantly outperforms previous strong RAG methods, even when\ncompared to the closed-source GPT-4o-mini.", "published": "2025-03-07 17:14:44", "link": "http://arxiv.org/abs/2503.05592v2", "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Quantifying the Robustness of Retrieval-Augmented Language Models Against Spurious Features in Grounding Data", "abstract": "Robustness has become a critical attribute for the deployment of RAG systems\nin real-world applications. Existing research focuses on robustness to explicit\nnoise (e.g., document semantics) but overlooks spurious features (a.k.a.\nimplicit noise). While previous works have explored spurious features in LLMs,\nthey are limited to specific features (e.g., formats) and narrow scenarios\n(e.g., ICL). In this work, we statistically confirm the presence of spurious\nfeatures in the RAG paradigm, a robustness problem caused by the sensitivity of\nLLMs to semantic-agnostic features. Moreover, we provide a comprehensive\ntaxonomy of spurious features and empirically quantify their impact through\ncontrolled experiments. Further analysis reveals that not all spurious features\nare harmful and they can even be beneficial sometimes. Extensive evaluation\nresults across multiple LLMs suggest that spurious features are a widespread\nand challenging problem in the field of RAG. The code and dataset will be\nreleased to facilitate future research. We release all codes and data at:\n$\\\\\\href{https://github.com/maybenotime/RAG-SpuriousFeatures}{https://github.com/maybenotime/RAG-SpuriousFeatures}$.", "published": "2025-03-07 17:11:34", "link": "http://arxiv.org/abs/2503.05587v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating open-source Large Language Models for automated fact-checking", "abstract": "The increasing prevalence of online misinformation has heightened the demand\nfor automated fact-checking solutions. Large Language Models (LLMs) have\nemerged as potential tools for assisting in this task, but their effectiveness\nremains uncertain. This study evaluates the fact-checking capabilities of\nvarious open-source LLMs, focusing on their ability to assess claims with\ndifferent levels of contextual information. We conduct three key experiments:\n(1) evaluating whether LLMs can identify the semantic relationship between a\nclaim and a fact-checking article, (2) assessing models' accuracy in verifying\nclaims when given a related fact-checking article, and (3) testing LLMs'\nfact-checking abilities when leveraging data from external knowledge sources\nsuch as Google and Wikipedia. Our results indicate that LLMs perform well in\nidentifying claim-article connections and verifying fact-checked stories but\nstruggle with confirming factual news, where they are outperformed by\ntraditional fine-tuned models such as RoBERTa. Additionally, the introduction\nof external knowledge does not significantly enhance LLMs' performance, calling\nfor more tailored approaches. Our findings highlight both the potential and\nlimitations of LLMs in automated fact-checking, emphasizing the need for\nfurther refinements before they can reliably replace human fact-checkers.", "published": "2025-03-07 16:45:33", "link": "http://arxiv.org/abs/2503.05565v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Pi-GPS: Enhancing Geometry Problem Solving by Unleashing the Power of Diagrammatic Information", "abstract": "Geometry problem solving has garnered increasing attention due to its\npotential applications in intelligent education field. Inspired by the\nobservation that text often introduces ambiguities that diagrams can clarify,\nthis paper presents Pi-GPS, a novel framework that unleashes the power of\ndiagrammatic information to resolve textual ambiguities, an aspect largely\noverlooked in prior research. Specifically, we design a micro module comprising\na rectifier and verifier: the rectifier employs MLLMs to disambiguate text\nbased on the diagrammatic context, while the verifier ensures the rectified\noutput adherence to geometric rules, mitigating model hallucinations.\nAdditionally, we explore the impact of LLMs in theorem predictor based on the\ndisambiguated formal language. Empirical results demonstrate that Pi-GPS\nsurpasses state-of-the-art models, achieving a nearly 10\\% improvement on\nGeometry3K over prior neural-symbolic approaches. We hope this work highlights\nthe significance of resolving textual ambiguity in multimodal mathematical\nreasoning, a crucial factor limiting performance.", "published": "2025-03-07 16:15:00", "link": "http://arxiv.org/abs/2503.05543v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Cognitive Bias Detection Using Advanced Prompt Engineering", "abstract": "Cognitive biases, systematic deviations from rationality in judgment, pose\nsignificant challenges in generating objective content. This paper introduces a\nnovel approach for real-time cognitive bias detection in user-generated text\nusing large language models (LLMs) and advanced prompt engineering techniques.\nThe proposed system analyzes textual data to identify common cognitive biases\nsuch as confirmation bias, circular reasoning, and hidden assumption. By\ndesigning tailored prompts, the system effectively leverages LLMs' capabilities\nto both recognize and mitigate these biases, improving the quality of\nhuman-generated content (e.g., news, media, reports). Experimental results\ndemonstrate the high accuracy of our approach in identifying cognitive biases,\noffering a valuable tool for enhancing content objectivity and reducing the\nrisks of biased decision-making.", "published": "2025-03-07 15:35:37", "link": "http://arxiv.org/abs/2503.05516v1", "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.CY"}
{"title": "Statistical Guarantees of Correctness Coverage for Medical Multiple-Choice Question Answering", "abstract": "Large language models (LLMs) are increasingly deployed in real-world\nquestion-answering (QA) applications. However, LLMs have been proven to\ngenerate hallucinations and nonfactual information, undermining their\ntrustworthiness in high-stakes medical tasks. Conformal prediction (CP) is\nwell-known to be model-agnostic and distribution-free, which creates\nstatistically rigorous prediction sets in classification tasks. In this work,\nwe for the first time adapt the CP framework to medical multiple-choice\nquestion-answering (MCQA) tasks, by correlating the nonconformity score with\nthe frequency score of correct options grounded in self-consistency theory,\nassuming no access to internal model information. Considering that the adapted\nCP framework can only control the (mis)coverage rate, we employ a risk control\nframework, which can manage task-specific metrics by devising a monotonically\ndecreasing loss function. We evaluate our framework on 3 popular medical MCQA\ndatasets utilizing 4 ``off-the-shelf'' LLMs. Empirical results demonstrate that\nwe achieve user-specified average (or marginal) error rates on the test set.\nFurthermore, we observe that the average prediction set size (APSS) on the test\nset decreases as the risk level increases, which concludes a promising\nevaluation metric for the uncertainty of LLMs.", "published": "2025-03-07 15:22:10", "link": "http://arxiv.org/abs/2503.05505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EuroBERT: Scaling Multilingual Encoders for European Languages", "abstract": "General-purpose multilingual vector representations, used in retrieval,\nregression and classification, are traditionally obtained from bidirectional\nencoder models. Despite their wide applicability, encoders have been recently\novershadowed by advances in generative decoder-only models. However, many\ninnovations driving this progress are not inherently tied to decoders. In this\npaper, we revisit the development of multilingual encoders through the lens of\nthese advances, and introduce EuroBERT, a family of multilingual encoders\ncovering European and widely spoken global languages. Our models outperform\nexisting alternatives across a diverse range of tasks, spanning multilingual\ncapabilities, mathematics, and coding, and natively supporting sequences of up\nto 8,192 tokens. We also examine the design decisions behind EuroBERT, offering\ninsights into our dataset composition and training pipeline. We publicly\nrelease the EuroBERT models, including intermediate training checkpoints,\ntogether with our training framework.", "published": "2025-03-07 15:13:58", "link": "http://arxiv.org/abs/2503.05500v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Benchmarking LLMs in Recommendation Tasks: A Comparative Evaluation with Conventional Recommenders", "abstract": "In recent years, integrating large language models (LLMs) into recommender\nsystems has created new opportunities for improving recommendation quality.\nHowever, a comprehensive benchmark is needed to thoroughly evaluate and compare\nthe recommendation capabilities of LLMs with traditional recommender systems.\nIn this paper, we introduce RecBench, which systematically investigates various\nitem representation forms (including unique identifier, text, semantic\nembedding, and semantic identifier) and evaluates two primary recommendation\ntasks, i.e., click-through rate prediction (CTR) and sequential recommendation\n(SeqRec). Our extensive experiments cover up to 17 large models and are\nconducted across five diverse datasets from fashion, news, video, books, and\nmusic domains. Our findings indicate that LLM-based recommenders outperform\nconventional recommenders, achieving up to a 5% AUC improvement in the CTR\nscenario and up to a 170% NDCG@10 improvement in the SeqRec scenario. However,\nthese substantial performance gains come at the expense of significantly\nreduced inference efficiency, rendering the LLM-as-RS paradigm impractical for\nreal-time recommendation environments. We aim for our findings to inspire\nfuture research, including recommendation-specific model acceleration methods.\nWe will release our code, data, configurations, and platform to enable other\nresearchers to reproduce and build upon our experimental results.", "published": "2025-03-07 15:05:23", "link": "http://arxiv.org/abs/2503.05493v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "KIEval: Evaluation Metric for Document Key Information Extraction", "abstract": "Document Key Information Extraction (KIE) is a technology that transforms\nvaluable information in document images into structured data, and it has become\nan essential function in industrial settings. However, current evaluation\nmetrics of this technology do not accurately reflect the critical attributes of\nits industrial applications. In this paper, we present KIEval, a novel\napplication-centric evaluation metric for Document KIE models. Unlike prior\nmetrics, KIEval assesses Document KIE models not just on the extraction of\nindividual information (entity) but also of the structured information\n(grouping). Evaluation of structured information provides assessment of\nDocument KIE models that are more reflective of extracting grouped information\nfrom documents in industrial settings. Designed with industrial application in\nmind, we believe that KIEval can become a standard evaluation metric for\ndeveloping or applying Document KIE models in practice. The code will be\npublicly available.", "published": "2025-03-07 14:58:14", "link": "http://arxiv.org/abs/2503.05488v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "This Is Your Doge, If It Please You: Exploring Deception and Robustness in Mixture of LLMs", "abstract": "Mixture of large language model (LLMs) Agents (MoA) architectures achieve\nstate-of-the-art performance on prominent benchmarks like AlpacaEval 2.0 by\nleveraging the collaboration of multiple LLMs at inference time. Despite these\nsuccesses, an evaluation of the safety and reliability of MoA is missing. We\npresent the first comprehensive study of MoA's robustness against deceptive LLM\nagents that deliberately provide misleading responses. We examine factors like\nthe propagation of deceptive information, model size, and information\navailability, and uncover critical vulnerabilities. On AlpacaEval 2.0, the\npopular LLaMA 3.1-70B model achieves a length-controlled Win Rate (LC WR) of\n49.2% when coupled with 3-layer MoA (6 LLM agents). However, we demonstrate\nthat introducing only a $\\textit{single}$ carefully-instructed deceptive agent\ninto the MoA can reduce performance to 37.9%, effectively nullifying all MoA\ngains. On QuALITY, a multiple-choice comprehension task, the impact is also\nsevere, with accuracy plummeting by a staggering 48.5%. Inspired in part by the\nhistorical Doge of Venice voting process, designed to minimize influence and\ndeception, we propose a range of unsupervised defense mechanisms that recover\nmost of the lost performance.", "published": "2025-03-07 14:46:39", "link": "http://arxiv.org/abs/2503.05856v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts", "abstract": "Linear Sequence Modeling (LSM) like linear attention, state space models and\nlinear RNNs, and Mixture-of-Experts (MoE) have recently emerged as significant\narchitectural improvements. In this paper, we introduce Linear-MoE, a\nproduction-level system for modeling and training large-scale models that\nintegrate LSM with MoE. Linear-MoE leverages the advantages of both LSM modules\nfor linear-complexity sequence modeling and MoE layers for sparsely activation,\naiming to offer high performance with efficient training. The Linear-MoE system\ncomprises: 1) Modeling subsystem, which provides a unified framework supporting\nall instances of LSM. and 2) Training subsystem, which facilitates efficient\ntraining by incorporating various advanced parallelism technologies,\nparticularly Sequence Parallelism designed for Linear-MoE models. Additionally,\nwe explore hybrid models that combine Linear-MoE layers with standard\nTransformer-MoE layers with its Sequence Parallelism to further enhance model\nflexibility and performance. Evaluations on two model series, A0.3B-2B and\nA1B-7B, demonstrate Linear-MoE achieves efficiency gains while maintaining\ncompetitive performance on various benchmarks, showcasing its potential as a\nnext-generation foundational model architecture. Code:\nhttps://github.com/OpenSparseLLMs/Linear-MoE.", "published": "2025-03-07 14:17:45", "link": "http://arxiv.org/abs/2503.05447v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "An Empirical Study of Conformal Prediction in LLM with ASP Scaffolds for Robust Reasoning", "abstract": "In this paper, we examine the use of Conformal Language Modelling (CLM)\nalongside Answer Set Programming (ASP) to enhance the performance of standard\nopen-weight LLMs on complex multi-step reasoning tasks. Using the StepGame\ndataset, which requires spatial reasoning, we apply CLM to generate sets of ASP\nprograms from an LLM, providing statistical guarantees on the correctness of\nthe outputs. Experimental results show that CLM significantly outperforms\nbaseline models that use standard sampling methods, achieving substantial\naccuracy improvements across different levels of reasoning complexity.\nAdditionally, the LLM-as-Judge metric enhances CLM's performance, especially in\nassessing structurally and logically correct ASP outputs. However, calibrating\nCLM with diverse calibration sets did not improve generalizability for tasks\nrequiring much longer reasoning steps, indicating limitations in handling more\ncomplex tasks.", "published": "2025-03-07 14:10:10", "link": "http://arxiv.org/abs/2503.05439v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi Agent based Medical Assistant for Edge Devices", "abstract": "Large Action Models (LAMs) have revolutionized intelligent automation, but\ntheir application in healthcare faces challenges due to privacy concerns,\nlatency, and dependency on internet access. This report introduces an ondevice,\nmulti-agent healthcare assistant that overcomes these limitations. The system\nutilizes smaller, task-specific agents to optimize resources, ensure\nscalability and high performance. Our proposed system acts as a one-stop\nsolution for health care needs with features like appointment booking, health\nmonitoring, medication reminders, and daily health reporting. Powered by the\nQwen Code Instruct 2.5 7B model, the Planner and Caller Agents achieve an\naverage RougeL score of 85.5 for planning and 96.5 for calling for our tasks\nwhile being lightweight for on-device deployment. This innovative approach\ncombines the benefits of ondevice systems with multi-agent architectures,\npaving the way for user-centric healthcare solutions.", "published": "2025-03-07 13:20:12", "link": "http://arxiv.org/abs/2503.05397v1", "categories": ["cs.MA", "cs.CL"], "primary_category": "cs.MA"}
{"title": "Leveraging Semantic Type Dependencies for Clinical Named Entity Recognition", "abstract": "Previous work on clinical relation extraction from free-text sentences\nleveraged information about semantic types from clinical knowledge bases as a\npart of entity representations. In this paper, we exploit additional evidence\nby also making use of domain-specific semantic type dependencies. We encode the\nrelation between a span of tokens matching a Unified Medical Language System\n(UMLS) concept and other tokens in the sentence. We implement our method and\ncompare against different named entity recognition (NER) architectures (i.e.,\nBiLSTM-CRF and BiLSTM-GCN-CRF) using different pre-trained clinical embeddings\n(i.e., BERT, BioBERT, UMLSBert). Our experimental results on clinical datasets\nshow that in some cases NER effectiveness can be significantly improved by\nmaking use of domain-specific semantic type dependencies. Our work is also the\nfirst study generating a matrix encoding to make use of more than three\ndependencies in one pass for the NER task.", "published": "2025-03-07 12:29:21", "link": "http://arxiv.org/abs/2503.05373v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Shifting Perspectives: Steering Vector Ensembles for Robust Bias Mitigation in LLMs", "abstract": "We present a novel approach to bias mitigation in large language models\n(LLMs) by applying steering vectors to modify model activations in forward\npasses. We employ Bayesian optimization to systematically identify effective\ncontrastive pair datasets across nine bias axes. When optimized on the BBQ\ndataset, our individually tuned steering vectors achieve average improvements\nof 12.2%, 4.7%, and 3.2% over the baseline for Mistral, Llama, and Qwen,\nrespectively. Building on these promising results, we introduce Steering Vector\nEnsembles (SVE), a method that averages multiple individually optimized\nsteering vectors, each targeting a specific bias axis such as age, race, or\ngender. By leveraging their collective strength, SVE outperforms individual\nsteering vectors in both bias reduction and maintaining model performance. The\nwork presents the first systematic investigation of steering vectors for bias\nmitigation, and we demonstrate that SVE is a powerful and computationally\nefficient strategy for reducing bias in LLMs, with broader implications for\nenhancing AI safety.", "published": "2025-03-07 12:25:29", "link": "http://arxiv.org/abs/2503.05371v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Chain of Strategy Optimization Makes Large Language Models Better Emotional Supporter", "abstract": "The growing emotional stress in modern society has increased the demand for\nEmotional Support Conversations (ESC). While Large Language Models (LLMs) show\npromise for ESC, they face two key challenges: (1) low strategy selection\naccuracy, and (2) preference bias, limiting their adaptability to emotional\nneeds of users. Existing supervised fine-tuning (SFT) struggles to address\nthese issues, as it rigidly trains models on single gold-standard responses\nwithout modeling nuanced strategy trade-offs. To overcome these limitations, we\npropose Chain-of-Strategy Optimization (CSO), a novel approach that optimizes\nstrategy selection preferences at each dialogue turn. We first leverage Monte\nCarlo Tree Search to construct ESC-Pro, a high-quality preference dataset with\nturn-level strategy-response pairs. Training on ESC-Pro with CSO improves both\nstrategy accuracy and bias mitigation, enabling LLMs to generate more\nempathetic and contextually appropriate responses. Experiments on LLaMA-3.1-8B,\nGemma-2-9B, and Qwen2.5-7B demonstrate that CSO outperforms standard SFT,\nhighlighting the efficacy of fine-grained, turn-level preference modeling in\nESC.", "published": "2025-03-07 12:07:59", "link": "http://arxiv.org/abs/2503.05362v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Hate Speech Classification with Cross-Taxonomy Dataset Integration", "abstract": "Algorithmic hate speech detection faces significant challenges due to the\ndiverse definitions and datasets used in research and practice. Social media\nplatforms, legal frameworks, and institutions each apply distinct yet\noverlapping definitions, complicating classification efforts. This study\naddresses these challenges by demonstrating that existing datasets and\ntaxonomies can be integrated into a unified model, enhancing prediction\nperformance and reducing reliance on multiple specialized classifiers. The work\nintroduces a universal taxonomy and a hate speech classifier capable of\ndetecting a wide range of definitions within a single framework. Our approach\nis validated by combining two widely used but differently annotated datasets,\nshowing improved classification performance on an independent test set. This\nwork highlights the potential of dataset and taxonomy integration in advancing\nhate speech detection, increasing efficiency, and ensuring broader\napplicability across contexts.", "published": "2025-03-07 12:01:02", "link": "http://arxiv.org/abs/2503.05357v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "primary_category": "cs.CL"}
{"title": "GEMA-Score: Granular Explainable Multi-Agent Score for Radiology Report Evaluation", "abstract": "Automatic medical report generation supports clinical diagnosis, reduces the\nworkload of radiologists, and holds the promise of improving diagnosis\nconsistency. However, existing evaluation metrics primarily assess the accuracy\nof key medical information coverage in generated reports compared to\nhuman-written reports, while overlooking crucial details such as the location\nand certainty of reported abnormalities. These limitations hinder the\ncomprehensive assessment of the reliability of generated reports and pose risks\nin their selection for clinical use. Therefore, we propose a Granular\nExplainable Multi-Agent Score (GEMA-Score) in this paper, which conducts both\nobjective quantification and subjective evaluation through a large language\nmodel-based multi-agent workflow. Our GEMA-Score parses structured reports and\nemploys NER-F1 calculations through interactive exchanges of information among\nagents to assess disease diagnosis, location, severity, and uncertainty.\nAdditionally, an LLM-based scoring agent evaluates completeness, readability,\nand clinical terminology while providing explanatory feedback. Extensive\nexperiments validate that GEMA-Score achieves the highest correlation with\nhuman expert evaluations on a public dataset, demonstrating its effectiveness\nin clinical scoring (Kendall coefficient = 0.70 for Rexval dataset and Kendall\ncoefficient = 0.54 for RadEvalX dataset). The anonymous project demo is\navailable at: https://github.com/Zhenxuan-Zhang/GEMA_score.", "published": "2025-03-07 11:42:22", "link": "http://arxiv.org/abs/2503.05347v1", "categories": ["cs.CL", "cs.MA"], "primary_category": "cs.CL"}
{"title": "AutoIOT: LLM-Driven Automated Natural Language Programming for AIoT Applications", "abstract": "The advent of Large Language Models (LLMs) has profoundly transformed our\nlives, revolutionizing interactions with AI and lowering the barrier to AI\nusage. While LLMs are primarily designed for natural language interaction, the\nextensive embedded knowledge empowers them to comprehend digital sensor data.\nThis capability enables LLMs to engage with the physical world through IoT\nsensors and actuators, performing a myriad of AIoT tasks. Consequently, this\nevolution triggers a paradigm shift in conventional AIoT application\ndevelopment, democratizing its accessibility to all by facilitating the design\nand development of AIoT applications via natural language. However, some\nlimitations need to be addressed to unlock the full potential of LLMs in AIoT\napplication development. First, existing solutions often require transferring\nraw sensor data to LLM servers, which raises privacy concerns, incurs high\nquery fees, and is limited by token size. Moreover, the reasoning processes of\nLLMs are opaque to users, making it difficult to verify the robustness and\ncorrectness of inference results. This paper introduces AutoIOT, an LLM-based\nautomated program generator for AIoT applications. AutoIOT enables users to\nspecify their requirements using natural language (input) and automatically\nsynthesizes interpretable programs with documentation (output). AutoIOT\nautomates the iterative optimization to enhance the quality of generated code\nwith minimum user involvement. AutoIOT not only makes the execution of AIoT\ntasks more explainable but also mitigates privacy concerns and reduces token\ncosts with local execution of synthesized programs. Extensive experiments and\nuser studies demonstrate AutoIOT's remarkable capability in program synthesis\nfor various AIoT tasks. The synthesized programs can match and even outperform\nsome representative baselines.", "published": "2025-03-07 11:40:52", "link": "http://arxiv.org/abs/2503.05346v1", "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Speculative Decoding for Multi-Sample Inference", "abstract": "We propose a novel speculative decoding method tailored for multi-sample\nreasoning scenarios, such as self-consistency and Best-of-N sampling. Our\nmethod exploits the intrinsic consensus of parallel generation paths to\nsynthesize high-quality draft tokens without requiring auxiliary models or\nexternal databases. By dynamically analyzing structural patterns across\nparallel reasoning paths through a probabilistic aggregation mechanism, it\nidentifies consensus token sequences that align with the decoding distribution.\nEvaluations on mathematical reasoning benchmarks demonstrate a substantial\nimprovement in draft acceptance rates over baselines, while reducing the\nlatency in draft token construction. This work establishes a paradigm shift for\nefficient multi-sample inference, enabling seamless integration of speculative\ndecoding with sampling-based reasoning techniques.", "published": "2025-03-07 11:15:36", "link": "http://arxiv.org/abs/2503.05330v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models", "abstract": "This paper investigates the role of dynamic external knowledge integration in\nimproving counter-argument generation using Large Language Models (LLMs). While\nLLMs have shown promise in argumentative tasks, their tendency to generate\nlengthy, potentially unfactual responses highlights the need for more\ncontrolled and evidence-based approaches. We introduce a new manually curated\ndataset of argument and counter-argument pairs specifically designed to balance\nargumentative complexity with evaluative feasibility. We also propose a new\nLLM-as-a-Judge evaluation methodology that shows a stronger correlation with\nhuman judgments compared to traditional reference-based metrics. Our\nexperimental results demonstrate that integrating dynamic external knowledge\nfrom the web significantly improves the quality of generated counter-arguments,\nparticularly in terms of relatedness, persuasiveness, and factuality. The\nfindings suggest that combining LLMs with real-time external knowledge\nretrieval offers a promising direction for developing more effective and\nreliable counter-argumentation systems.", "published": "2025-03-07 11:13:33", "link": "http://arxiv.org/abs/2503.05328v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fine-Grained Evaluation for Implicit Discourse Relation Recognition", "abstract": "Implicit discourse relation recognition is a challenging task in discourse\nanalysis due to the absence of explicit discourse connectives between spans of\ntext. Recent pre-trained language models have achieved great success on this\ntask. However, there is no fine-grained analysis of the performance of these\npre-trained language models for this task. Therefore, the difficulty and\npossible directions of this task is unclear. In this paper, we deeply analyze\nthe model prediction, attempting to find out the difficulty for the pre-trained\nlanguage models and the possible directions of this task. In addition to having\nan in-depth analysis for this task by using pre-trained language models, we\nsemi-manually annotate data to add relatively high-quality data for the\nrelations with few annotated examples in PDTB 3.0. The annotated data\nsignificantly help improve implicit discourse relation recognition for level-2\nsenses.", "published": "2025-03-07 11:10:33", "link": "http://arxiv.org/abs/2503.05326v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncertainty-Aware Decoding with Minimum Bayes Risk", "abstract": "Despite their outstanding performance in the majority of scenarios,\ncontemporary language models still occasionally generate undesirable outputs,\nfor example, hallucinated text. While such behaviors have previously been\nlinked to uncertainty, there is a notable lack of methods that actively\nconsider uncertainty during text generation. In this work, we show how Minimum\nBayes Risk (MBR) decoding, which selects model generations according to an\nexpected risk, can be generalized into a principled uncertainty-aware decoding\nmethod. In short, we account for model uncertainty during decoding by\nincorporating a posterior over model parameters into MBR's computation of\nexpected risk. We show that this modified expected risk is useful for both\nchoosing outputs and deciding when to abstain from generation and can provide\nimprovements without incurring overhead. We benchmark different methods for\nlearning posteriors and show that performance improves with prediction\ndiversity. We release our code publicly.", "published": "2025-03-07 10:55:12", "link": "http://arxiv.org/abs/2503.05318v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluating Local and Cloud-Based Large Language Models for Simulating Consumer Choices in Energy Stated Preference Surveys", "abstract": "Survey research is essential in energy demand studies for capturing consumer\npreferences and informing policy decisions. Stated preference (SP) surveys, in\nparticular, analyse how individuals make trade-offs in hypothetical scenarios.\nHowever, traditional survey methods are costly, time-consuming, and affected by\nbiases and respondent fatigue. Large language models (LLMs) have emerged as a\npotential tool to address these challenges by generating human-like textual\nresponses. This study investigates the ability of LLMs to simulate consumer\nchoices in energy-related SP surveys. A series of test scenarios evaluated the\nsimulation performance of LLMs at both individual and aggregated levels,\nconsidering factors in the prompt, in-context learning (ICL), chain-of-thought\n(CoT) reasoning, the comparison between local and cloud-based LLMs, integration\nwith traditional choice models, and potential biases. Results indicate that\nwhile LLMs achieve an average accuracy of up to 48%, surpassing random\nguessing, their performance remains insufficient for practical application.\nLocal and cloud-based LLMs perform similarly in simulation accuracy but exhibit\ndifferences in adherence to prompt requirements and susceptibility to social\ndesirability biases. Findings suggest that previous SP choices are the most\neffective input factor, while longer prompts with varied factor formats may\nreduce accuracy. Furthermore, the traditional mixed logit choice model\noutperforms LLMs and provides insights for refining LLM prompts. Despite their\nlimitations, LLMs provide scalability and efficiency advantages, requiring\nminimal historical data compared to traditional survey methods. Future research\nshould refine prompt structures, further investigate CoT reasoning, and explore\nfine-tuning techniques to improve LLM-based energy survey simulations.", "published": "2025-03-07 10:37:31", "link": "http://arxiv.org/abs/2503.10652v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Coreference as an indicator of context scope in multimodal narrative", "abstract": "We demonstrate that large multimodal language models differ substantially\nfrom humans in the distribution of coreferential expressions in a visual\nstorytelling task. We introduce a number of metrics to quantify the\ncharacteristics of coreferential patterns in both human- and machine-written\ntexts. Humans distribute coreferential expressions in a way that maintains\nconsistency across texts and images, interleaving references to different\nentities in a highly varied way. Machines are less able to track mixed\nreferences, despite achieving perceived improvements in generation quality.", "published": "2025-03-07 10:23:22", "link": "http://arxiv.org/abs/2503.05298v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Similarity-Based Domain Adaptation with LLMs", "abstract": "Unsupervised domain adaptation leverages abundant labeled data from various\nsource domains to generalize onto unlabeled target data. Prior research has\nprimarily focused on learning domain-invariant features across the source and\ntarget domains. However, these methods often require training a model using\nsource domain data, which is time-consuming and can limit model usage for\napplications with different source data. This paper introduces a simple\nframework that utilizes the impressive generalization capabilities of Large\nLanguage Models (LLMs) for target data annotation without the need of source\nmodel training, followed by a novel similarity-based knowledge distillation\nloss. Our extensive experiments on cross-domain text classification reveal that\nour framework achieves impressive performance, specifically, 2.44\\% accuracy\nimprovement when compared to the SOTA method.", "published": "2025-03-07 09:51:07", "link": "http://arxiv.org/abs/2503.05281v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Revealing Hidden Mechanisms of Cross-Country Content Moderation with Natural Language Processing", "abstract": "The ability of Natural Language Processing (NLP) methods to categorize text\ninto multiple classes has motivated their use in online content moderation\ntasks, such as hate speech and fake news detection. However, there is limited\nunderstanding of how or why these methods make such decisions, or why certain\ncontent is moderated in the first place. To investigate the hidden mechanisms\nbehind content moderation, we explore multiple directions: 1) training\nclassifiers to reverse-engineer content moderation decisions across countries;\n2) explaining content moderation decisions by analyzing Shapley values and\nLLM-guided explanations. Our primary focus is on content moderation decisions\nmade across countries, using pre-existing corpora sampled from the Twitter\nStream Grab. Our experiments reveal interesting patterns in censored posts,\nboth across countries and over time. Through human evaluations of LLM-generated\nexplanations across three LLMs, we assess the effectiveness of using LLMs in\ncontent moderation. Finally, we discuss potential future directions, as well as\nthe limitations and ethical considerations of this work. Our code and data are\navailable at https://github.com/causalNLP/censorship", "published": "2025-03-07 09:49:31", "link": "http://arxiv.org/abs/2503.05280v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ZOGRASCOPE: A New Benchmark for Property Graphs", "abstract": "Natural language interfaces to knowledge graphs have become increasingly\nimportant in recent years, enabling easy and efficient access to structured\ndata. In particular property graphs have seen growing adoption. However, these\nkind of graphs remain relatively underrepresented in research, which has\nfocused in large part on RDF-style graphs. As a matter of fact there is a lack\nof resources for evaluating systems on property graphs, with many existing\ndatasets featuring relatively simple queries. To address this gap, we introduce\nZOGRASCOPE, a benchmark designed specifically for the cypher query language.\nThe benchmark includes a diverse set of manually annotated queries of varying\ncomplexity. We complement this paper with a set of experiments that test the\nperformance of out-of-the-box LLMs of different sizes. Our experiments show\nthat semantic parsing over graphs is still a challenging open problem that can\nnot be solved by prompting LLMs alone.", "published": "2025-03-07 09:33:30", "link": "http://arxiv.org/abs/2503.05268v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PhiloBERTA: A Transformer-Based Cross-Lingual Analysis of Greek and Latin Lexicons", "abstract": "We present PhiloBERTA, a cross-lingual transformer model that measures\nsemantic relationships between ancient Greek and Latin lexicons. Through\nanalysis of selected term pairs from classical texts, we use contextual\nembeddings and angular similarity metrics to identify precise semantic\nalignments. Our results show that etymologically related pairs demonstrate\nsignificantly higher similarity scores, particularly for abstract philosophical\nconcepts such as epist\\=em\\=e (scientia) and dikaiosyn\\=e (iustitia).\nStatistical analysis reveals consistent patterns in these relationships (p =\n0.012), with etymologically related pairs showing remarkably stable semantic\npreservation compared to control pairs. These findings establish a quantitative\nframework for examining how philosophical concepts moved between Greek and\nLatin traditions, offering new methods for classical philological research.", "published": "2025-03-07 09:30:16", "link": "http://arxiv.org/abs/2503.05265v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "WritingBench: A Comprehensive Benchmark for Generative Writing", "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced text generation capabilities, yet evaluating their performance in\ngenerative writing remains a challenge. Existing benchmarks primarily focus on\ngeneric text generation or limited in writing tasks, failing to capture the\ndiverse requirements of high-quality written contents across various domains.\nTo bridge this gap, we present WritingBench, a comprehensive benchmark designed\nto evaluate LLMs across 6 core writing domains and 100 subdomains, encompassing\ncreative, persuasive, informative, and technical writing. We further propose a\nquery-dependent evaluation framework that empowers LLMs to dynamically generate\ninstance-specific assessment criteria. This framework is complemented by a\nfine-tuned critic model for criteria-aware scoring, enabling evaluations in\nstyle, format and length. The framework's validity is further demonstrated by\nits data curation capability, which enables 7B-parameter models to approach\nstate-of-the-art (SOTA) performance. We open-source the benchmark, along with\nevaluation tools and modular framework components, to advance the development\nof LLMs in writing.", "published": "2025-03-07 08:56:20", "link": "http://arxiv.org/abs/2503.05244v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio", "abstract": "The rapid advancement of large language models (LLMs) and artificial\nintelligence-generated content (AIGC) has accelerated AI-native applications,\nsuch as AI-based storybooks that automate engaging story production for\nchildren. However, challenges remain in improving story attractiveness,\nenriching storytelling expressiveness, and developing open-source evaluation\nbenchmarks and frameworks. Therefore, we propose and opensource MM-StoryAgent,\nwhich creates immersive narrated video storybooks with refined plots,\nrole-consistent images, and multi-channel audio. MM-StoryAgent designs a\nmulti-agent framework that employs LLMs and diverse expert tools (generative\nmodels and APIs) across several modalities to produce expressive storytelling\nvideos. The framework enhances story attractiveness through a multi-stage\nwriting pipeline. In addition, it improves the immersive storytelling\nexperience by integrating sound effects with visual, music and narrative\nassets. MM-StoryAgent offers a flexible, open-source platform for further\ndevelopment, where generative modules can be substituted. Both objective and\nsubjective evaluation regarding textual story quality and alignment between\nmodalities validate the effectiveness of our proposed MM-StoryAgent system. The\ndemo and source code are available.", "published": "2025-03-07 08:53:10", "link": "http://arxiv.org/abs/2503.05242v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalized Text Generation with Contrastive Activation Steering", "abstract": "Personalized text generation aims to infer users' writing style preferences\nfrom their historical texts and generate outputs that faithfully reflect these\nstylistic characteristics. Existing solutions primarily adopt two paradigms:\nretrieval-augmented generation (RAG) and parameter-efficient fine-tuning\n(PEFT). While these approaches have advanced the field, they suffer from two\ncritical limitations: (1) the entanglement of content semantics and stylistic\npatterns in historical texts impedes accurate modeling of user-specific writing\npreferences; and (2) scalability challenges arising from both RAG's inference\nlatency by retrieval operations and PEFT's parameter storage requirements for\nper user model. To overcome these limitations, we propose StyleVector, a\ntraining-free framework that disentangles and represents personalized writing\nstyle as a vector in LLM's activation space, enabling style-steered generation\nduring inference without requiring costly retrieval or parameter storage.\nComprehensive experiments demonstrate that our framework achieves a significant\n8% relative improvement in personalized generation while reducing storage\nrequirements by 1700 times over PEFT method.", "published": "2025-03-07 08:07:15", "link": "http://arxiv.org/abs/2503.05213v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Updating? No More Model Editing! Just Selective Contextual Reasoning", "abstract": "As real-world knowledge evolves, the information embedded within large\nlanguage models (LLMs) can become outdated, inadequate, or erroneous. Model\nediting has emerged as a prominent approach for updating LLMs' knowledge with\nminimal computational costs and parameter changes. This approach typically\nidentifies and adjusts specific model parameters associated with newly acquired\nknowledge. However, existing methods often underestimate the adverse effects\nthat parameter modifications can have on broadly distributed knowledge. More\ncritically, post-edit LLMs frequently struggle with multi-hop reasoning and\ncontinuous knowledge updates. Although various studies have discussed these\nshortcomings, there is a lack of comprehensive evaluation. In this paper, we\nprovide an evaluation of ten model editing methods along four dimensions:\nreliability, generalization, locality, and portability. Results confirm that\nall ten popular model editing methods show significant shortcomings across\nmultiple dimensions, suggesting model editing is less promising. We then\npropose a straightforward method called Selective Contextual Reasoning (SCR),\nfor knowledge updating. SCR does not modify model parameters but harnesses\nLLM's inherent contextual reasoning capabilities utilizing the updated\nknowledge pieces. Under SCR, an LLM first assesses whether an incoming query\nfalls within the scope of an external knowledge base. If it does, the relevant\nexternal knowledge texts are contextualized to enhance reasoning; otherwise,\nthe query is answered directly. We evaluate SCR against the ten model editing\nmethods on two counterfactual datasets with three backbone LLMs. Empirical\nresults confirm the effectiveness and efficiency of contextual reasoning for\nknowledge updating.", "published": "2025-03-07 08:04:25", "link": "http://arxiv.org/abs/2503.05212v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Path Pooling: Train-Free Structure Enhancement for Efficient Knowledge Graph Retrieval-Augmented Generation", "abstract": "Although Large Language Models achieve strong success in many tasks, they\nstill suffer from hallucinations and knowledge deficiencies in real-world\napplications. Many knowledge graph-based retrieval-augmented generation\n(KG-RAG) methods enhance the quality and credibility of LLMs by leveraging\nstructure and semantic information in KGs as external knowledge bases. However,\nthese methods struggle to effectively incorporate structure information, either\nincurring high computational costs or underutilizing available knowledge.\nInspired by smoothing operations in graph representation learning, we propose\npath pooling, a simple, train-free strategy that introduces structure\ninformation through a novel path-centric pooling operation. It seamlessly\nintegrates into existing KG-RAG methods in a plug-and-play manner, enabling\nricher structure information utilization. Extensive experiments demonstrate\nthat incorporating the path pooling into the state-of-the-art KG-RAG method\nconsistently improves performance across various settings while introducing\nnegligible additional cost. Code is coming soon at\nhttps://github.com/hrwang00/path-pooling.", "published": "2025-03-07 07:48:30", "link": "http://arxiv.org/abs/2503.05203v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "ORANSight-2.0: Foundational LLMs for O-RAN", "abstract": "Despite the transformative impact of Large Language Models (LLMs) across\ncritical domains such as healthcare, customer service, and business marketing,\ntheir integration into Open Radio Access Networks (O-RAN) remains limited. This\ngap is primarily due to the absence of domain-specific foundational models,\nwith existing solutions often relying on general-purpose LLMs that fail to\naddress the unique challenges and technical intricacies of O-RAN. To bridge\nthis gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative\naimed at developing specialized foundational LLMs tailored for O-RAN. Built on\n18 LLMs spanning five open-source LLM frameworks, ORANSight-2.0 fine-tunes\nmodels ranging from 1 to 70B parameters, significantly reducing reliance on\nproprietary, closed-source models while enhancing performance for O-RAN. At the\ncore of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation\n(RAG) based instruction-tuning framework that employs two LLM agents to create\nhigh-quality instruction-tuning datasets. The generated dataset is then used to\nfine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate\nORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code\ngeneration and codebase understanding in the context of srsRAN, a widely used\n5G O-RAN stack. We also leverage ORANBench13K, an existing benchmark for\nassessing O-RAN-specific knowledge. Our comprehensive evaluations demonstrate\nthat ORANSight-2.0 models outperform general-purpose and closed-source models,\nsuch as ChatGPT-4o and Gemini, by 5.421% on ORANBench and 18.465% on\nsrsRANBench, achieving superior performance while maintaining lower\ncomputational and energy costs. We also experiment with RAG-augmented variants\nof ORANSight-2.0 LLMs and thoroughly evaluate their energy characteristics,\ndemonstrating costs for training, standard inference, and RAG-augmented\ninference.", "published": "2025-03-07 07:44:31", "link": "http://arxiv.org/abs/2503.05200v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NI"], "primary_category": "cs.CL"}
{"title": "Memory-augmented Query Reconstruction for LLM-based Knowledge Graph Reasoning", "abstract": "Large language models (LLMs) have achieved remarkable performance on\nknowledge graph question answering (KGQA) tasks by planning and interacting\nwith knowledge graphs. However, existing methods often confuse tool utilization\nwith knowledge reasoning, harming readability of model outputs and giving rise\nto hallucinatory tool invocations, which hinder the advancement of KGQA. To\naddress this issue, we propose Memory-augmented Query Reconstruction for\nLLM-based Knowledge Graph Reasoning (MemQ) to decouple LLM from tool invocation\ntasks using LLM-built query memory. By establishing a memory module with\nexplicit descriptions of query statements, the proposed MemQ facilitates the\nKGQA process with natural language reasoning and memory-augmented query\nreconstruction. Meanwhile, we design an effective and readable reasoning to\nenhance the LLM's reasoning capability in KGQA. Experimental results that MemQ\nachieves state-of-the-art performance on widely used benchmarks WebQSP and CWQ.", "published": "2025-03-07 07:28:32", "link": "http://arxiv.org/abs/2503.05193v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rewarding Curse: Analyze and Mitigate Reward Modeling Issues for LLM Reasoning", "abstract": "Chain-of-thought (CoT) prompting demonstrates varying performance under\ndifferent reasoning tasks. Previous work attempts to evaluate it but falls\nshort in providing an in-depth analysis of patterns that influence the CoT. In\nthis paper, we study the CoT performance from the perspective of effectiveness\nand faithfulness. For the former, we identify key factors that influence CoT\neffectiveness on performance improvement, including problem difficulty,\ninformation gain, and information flow. For the latter, we interpret the\nunfaithful CoT issue by conducting a joint analysis of the information\ninteraction among the question, CoT, and answer. The result demonstrates that,\nwhen the LLM predicts answers, it can recall correct information missing in the\nCoT from the question, leading to the problem. Finally, we propose a novel\nalgorithm to mitigate this issue, in which we recall extra information from the\nquestion to enhance the CoT generation and evaluate CoTs based on their\ninformation gain. Extensive experiments demonstrate that our approach enhances\nboth the faithfulness and effectiveness of CoT.", "published": "2025-03-07 07:20:24", "link": "http://arxiv.org/abs/2503.05188v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching", "abstract": "Recent advances in large language models have demonstrated remarkable\nreasoning capabilities through Chain of Thought (CoT) prompting, but often at\nthe cost of excessive verbosity in their intermediate outputs, which increases\ncomputational overhead. We introduce Sketch-of-Thought (SoT), a novel prompting\nframework that combines cognitive-inspired reasoning paradigms with linguistic\nconstraints to minimize token usage while preserving reasoning accuracy. SoT is\ndesigned as a flexible framework that can incorporate any custom reasoning\nparadigms based on cognitive science, and we instantiate it with three such\nparadigms - Conceptual Chaining, Chunked Symbolism, and Expert Lexicons - each\ntailored to different reasoning tasks and selected dynamically via a\nlightweight routing model. Through comprehensive evaluation across 15 reasoning\ndatasets with multiple languages and multimodal scenarios, we demonstrate that\nSoT achieves token reductions of 76% with negligible accuracy impact. In\ncertain domains like mathematical and multi-hop reasoning, it even improves\naccuracy while using significantly fewer tokens. Our code is publicly\navailable: https://www.github.com/SimonAytes/SoT.", "published": "2025-03-07 06:57:17", "link": "http://arxiv.org/abs/2503.05179v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extracting and Emulsifying Cultural Explanation to Improve Multilingual Capability of LLMs", "abstract": "Large Language Models (LLMs) have achieved remarkable success, but their\nEnglish-centric training data limits performance in non-English languages,\nhighlighting the need for enhancements in their multilingual capabilities.\nWhile some work on multilingual prompting methods handles non-English queries\nby utilizing English translations or restructuring them to more closely align\nwith LLM reasoning patterns, these works often overlook the importance of\ncultural context, limiting their effectiveness. To address this limitation, we\npropose EMCEI, a simple yet effective approach that improves LLMs' multilingual\ncapabilities by incorporating cultural context for more accurate and\nappropriate responses. Specifically, EMCEI follows a two-step process that\nfirst extracts relevant cultural context from the LLM's parametric knowledge\nvia prompting. Then, EMCEI employs an LLM-as-Judge mechanism to select the most\nappropriate response by balancing cultural relevance and reasoning ability.\nExperiments on diverse multilingual benchmarks show that EMCEI outperforms\nexisting baselines, demonstrating its effectiveness in handling multilingual\nqueries with LLMs.", "published": "2025-03-07 06:05:34", "link": "http://arxiv.org/abs/2503.05846v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting Accuracy", "abstract": "Language models are strong few-shot learners and achieve good overall\naccuracy in text classification tasks, masking the fact that their results\nsuffer from great class accuracy imbalance. We believe that the pursuit of\noverall accuracy should not come from enriching the strong classes, but from\nraising up the weak ones. To address the imbalance, we propose a Heaviside step\nfunction based ensemble debiasing method, which enables flexible rectifications\nof in-context learned class probabilities at both class and sample levels.\nEvaluations with Llama-2-13B on seven text classification benchmarks show that\nour approach achieves state-of-the-art overall accuracy gains with balanced\nclass accuracies. More importantly, we perform analyses on the resulted\nprobability correction scheme, showing that sample-level corrections are\nnecessary to elevate weak classes. Due to effectively correcting weak classes,\nour method also brings significant performance gains to a larger model variant,\nLlama-2-70B, especially on a biomedical domain task, further demonstrating the\nnecessity of ensemble debiasing at both levels.", "published": "2025-03-07 05:34:31", "link": "http://arxiv.org/abs/2503.05157v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Interpersonal Memory Matters: A New Task for Proactive Dialogue Utilizing Conversational History", "abstract": "Proactive dialogue systems aim to empower chatbots with the capability of\nleading conversations towards specific targets, thereby enhancing user\nengagement and service autonomy. Existing systems typically target pre-defined\nkeywords or entities, neglecting user attributes and preferences implicit in\ndialogue history, hindering the development of long-term user intimacy. To\naddress these challenges, we take a radical step towards building a more\nhuman-like conversational agent by integrating proactive dialogue systems with\nlong-term memory into a unified framework. Specifically, we define a novel task\nnamed Memory-aware Proactive Dialogue (MapDia). By decomposing the task, we\nthen propose an automatic data construction method and create the first Chinese\nMemory-aware Proactive Dataset (ChMapData). Furthermore, we introduce a joint\nframework based on Retrieval Augmented Generation (RAG), featuring three\nmodules: Topic Summarization, Topic Retrieval, and Proactive Topic-shifting\nDetection and Generation, designed to steer dialogues towards relevant\nhistorical topics at the right time. The effectiveness of our dataset and\nmodels is validated through both automatic and human evaluations. We release\nthe open-source framework and dataset at\nhttps://github.com/FrontierLabs/MapDia.", "published": "2025-03-07 05:19:17", "link": "http://arxiv.org/abs/2503.05150v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RocketEval: Efficient Automated LLM Evaluation via Grading Checklist", "abstract": "Evaluating large language models (LLMs) in diverse and challenging scenarios\nis essential to align them with human preferences. To mitigate the prohibitive\ncosts associated with human evaluations, utilizing a powerful LLM as a judge\nhas emerged as a favored approach. Nevertheless, this methodology encounters\nseveral challenges, including substantial expenses, concerns regarding privacy\nand security, and reproducibility. In this paper, we propose a straightforward,\nreplicable, and accurate automated evaluation method by leveraging a\nlightweight LLM as the judge, named RocketEval. Initially, we identify that the\nperformance disparity between lightweight and powerful LLMs in evaluation tasks\nprimarily stems from their ability to conduct comprehensive analyses, which is\nnot easily enhanced through techniques such as chain-of-thought reasoning. By\nreframing the evaluation task as a multi-faceted Q&A using an instance-specific\nchecklist, we demonstrate that the limited judgment accuracy of lightweight\nLLMs is largely attributes to high uncertainty and positional bias. To address\nthese challenges, we introduce an automated evaluation process grounded in\nchecklist grading, which is designed to accommodate a variety of scenarios and\nquestions. This process encompasses the creation of checklists, the grading of\nthese checklists by lightweight LLMs, and the reweighting of checklist items to\nalign with the supervised annotations. Our experiments carried out on the\nautomated evaluation benchmarks, MT-Bench and WildBench datasets, reveal that\nRocketEval, when using Gemma-2-2B as the judge, achieves a high correlation\n(0.965) with human preferences, which is comparable to GPT-4o. Moreover,\nRocketEval provides a cost reduction exceeding 50-fold for large-scale\nevaluation and comparison scenarios. Our code is available at\nhttps://github.com/Joinn99/RocketEval-ICLR .", "published": "2025-03-07 04:51:30", "link": "http://arxiv.org/abs/2503.05142v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without Premium GPUs", "abstract": "In this technical report, we tackle the challenges of training large-scale\nMixture of Experts (MoE) models, focusing on overcoming cost inefficiency and\nresource limitations prevalent in such systems. To address these issues, we\npresent two differently sized MoE large language models (LLMs), namely\nLing-Lite and Ling-Plus (referred to as \"Bailing\" in Chinese, spelled\nB\\v{a}il\\'ing in Pinyin). Ling-Lite contains 16.8 billion parameters with 2.75\nbillion activated parameters, while Ling-Plus boasts 290 billion parameters\nwith 28.8 billion activated parameters. Both models exhibit comparable\nperformance to leading industry benchmarks. This report offers actionable\ninsights to improve the efficiency and accessibility of AI development in\nresource-constrained settings, promoting more scalable and sustainable\ntechnologies. Specifically, to reduce training costs for large-scale MoE\nmodels, we propose innovative methods for (1) optimization of model\narchitecture and training processes, (2) refinement of training anomaly\nhandling, and (3) enhancement of model evaluation efficiency. Additionally,\nleveraging high-quality data generated from knowledge graphs, our models\ndemonstrate superior capabilities in tool use compared to other models.\nUltimately, our experimental findings demonstrate that a 300B MoE LLM can be\neffectively trained on lower-performance devices while achieving comparable\nperformance to models of a similar scale, including dense and MoE models.\nCompared to high-performance devices, utilizing a lower-specification hardware\nsystem during the pre-training phase demonstrates significant cost savings,\nreducing computing costs by approximately 20%. The models can be accessed at\nhttps://huggingface.co/inclusionAI.", "published": "2025-03-07 04:43:39", "link": "http://arxiv.org/abs/2503.05139v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "AutoTestForge: A Multidimensional Automated Testing Framework for Natural Language Processing Models", "abstract": "In recent years, the application of behavioral testing in Natural Language\nProcessing (NLP) model evaluation has experienced a remarkable and substantial\ngrowth. However, the existing methods continue to be restricted by the\nrequirements for manual labor and the limited scope of capability assessment.\nTo address these limitations, we introduce AutoTestForge, an automated and\nmultidimensional testing framework for NLP models in this paper. Within\nAutoTestForge, through the utilization of Large Language Models (LLMs) to\nautomatically generate test templates and instantiate them, manual involvement\nis significantly reduced. Additionally, a mechanism for the validation of test\ncase labels based on differential testing is implemented which makes use of a\nmulti-model voting system to guarantee the quality of test cases. The framework\nalso extends the test suite across three dimensions, taxonomy, fairness, and\nrobustness, offering a comprehensive evaluation of the capabilities of NLP\nmodels. This expansion enables a more in-depth and thorough assessment of the\nmodels, providing valuable insights into their strengths and weaknesses. A\ncomprehensive evaluation across sentiment analysis (SA) and semantic textual\nsimilarity (STS) tasks demonstrates that AutoTestForge consistently outperforms\nexisting datasets and testing tools, achieving higher error detection rates (an\naverage of $30.89\\%$ for SA and $34.58\\%$ for STS). Moreover, different\ngeneration strategies exhibit stable effectiveness, with error detection rates\nranging from $29.03\\% - 36.82\\%$.", "published": "2025-03-07 02:44:17", "link": "http://arxiv.org/abs/2503.05102v1", "categories": ["cs.SE", "cs.CL", "cs.CR"], "primary_category": "cs.SE"}
{"title": "SpecServe: Efficient and SLO-Aware Large Language Model Serving with Adaptive Speculative Decoding", "abstract": "Large Language Model (LLM) services often face challenges in achieving low\ninference latency and meeting Service Level Objectives (SLOs) under dynamic\nrequest patterns. Speculative decoding, which exploits lightweight models for\ndrafting and LLMs for verification, has emerged as a compelling technique to\naccelerate LLM inference. However, existing speculative decoding solutions\noften fail to adapt to varying workloads and system environments, resulting in\nperformance variability and SLO violations. In this paper, we introduce\nSpecServe, an efficient LLM inference system that dynamically adjusts\nspeculative strategies according to real-time request loads and system\nconfigurations. SpecServe proposes a theoretical model to understand and\npredict the efficiency of speculative decoding across diverse scenarios.\nAdditionally, it implements intelligent drafting and verification algorithms to\nguarantee optimal performance while achieving high SLO attainment. Experimental\nresults on real-world LLM traces demonstrate that SpecServe consistently meets\nSLOs and achieves substantial performance improvements, yielding\n1.14$\\times$-14.3$\\times$ speedups over state-of-the-art speculative inference\nsystems.", "published": "2025-03-07 02:27:51", "link": "http://arxiv.org/abs/2503.05096v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "S2S-Arena, Evaluating Speech2Speech Protocols on Instruction Following with Paralinguistic Information", "abstract": "The rapid development of large language models (LLMs) has brought significant\nattention to speech models, particularly recent progress in speech2speech\nprotocols supporting speech input and output. However, the existing benchmarks\nadopt automatic text-based evaluators for evaluating the instruction following\nability of these models lack consideration for paralinguistic information in\nboth speech understanding and generation. To address these issues, we introduce\nS2S-Arena, a novel arena-style S2S benchmark that evaluates\ninstruction-following capabilities with paralinguistic information in both\nspeech-in and speech-out across real-world tasks. We design 154 samples that\nfused TTS and live recordings in four domains with 21 tasks and manually\nevaluate existing popular speech models in an arena-style manner. The\nexperimental results show that: (1) in addition to the superior performance of\nGPT-4o, the speech model of cascaded ASR, LLM, and TTS outperforms the jointly\ntrained model after text-speech alignment in speech2speech protocols; (2)\nconsidering paralinguistic information, the knowledgeability of the speech\nmodel mainly depends on the LLM backbone, and the multilingual support of that\nis limited by the speech module; (3) excellent speech models can already\nunderstand the paralinguistic information in speech input, but generating\nappropriate audio with paralinguistic information is still a challenge.", "published": "2025-03-07 02:07:00", "link": "http://arxiv.org/abs/2503.05085v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of Experts", "abstract": "The Mixture of Experts (MoE) is an effective architecture for scaling large\nlanguage models by leveraging sparse expert activation, optimizing the\ntrade-off between performance and efficiency. However, under expert\nparallelism, MoE suffers from inference inefficiencies due to imbalanced\ntoken-to-expert assignment, where some experts are overloaded while others\nremain underutilized. This imbalance leads to poor resource utilization and\nincreased latency, as the most burdened expert dictates the overall delay, a\nphenomenon we define as the \\textbf{\\textit{Straggler Effect}}. To mitigate\nthis, we propose Capacity-Aware Inference, including two key techniques: (1)\n\\textbf{\\textit{Capacity-Aware Token Drop}}, which discards overloaded tokens\nto regulate the maximum latency of MoE, and (2) \\textbf{\\textit{Capacity-Aware\nToken Reroute}}, which reallocates overflowed tokens to underutilized experts,\nbalancing the token distribution. These techniques collectively optimize both\nhigh-load and low-load expert utilization, leading to a more efficient MoE\ninference pipeline. Extensive experiments demonstrate the effectiveness of our\nmethods, showing significant improvements in inference efficiency, e.g., 0.2\\%\naverage performance increase and a 1.94$\\times$ inference speedup on\nMixtral-8$\\times$7B-Instruct.", "published": "2025-03-07 01:11:39", "link": "http://arxiv.org/abs/2503.05066v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The study of short texts in digital politics: Document aggregation for topic modeling", "abstract": "Statistical topic modeling is widely used in political science to study text.\nResearchers examine documents of varying lengths, from tweets to speeches.\nThere is ongoing debate on how document length affects the interpretability of\ntopic models. We investigate the effects of aggregating short documents into\nlarger ones based on natural units that partition the corpus. In our study, we\nanalyze one million tweets by U.S. state legislators from April 2016 to\nSeptember 2020. We find that for documents aggregated at the account level,\ntopics are more associated with individual states than when using individual\ntweets. This finding is replicated with Wikipedia pages aggregated by birth\ncities, showing how document definitions can impact topic modeling results.", "published": "2025-03-07 01:05:46", "link": "http://arxiv.org/abs/2503.05065v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "No Free Labels: Limitations of LLM-as-a-Judge Without Human Grounding", "abstract": "LLM-as-a-Judge is a framework that uses an LLM (large language model) to\nevaluate the quality of natural language text - typically text that is also\ngenerated by an LLM. This framework holds great promise due to its relative\nlow-cost, ease of use, and strong correlations with human stylistic\npreferences. However, LLM Judges have been shown to exhibit biases that can\ndistort their judgments. We evaluate how well LLM Judges can grade whether a\ngiven response to a conversational question is correct, an ability crucial to\nsoundly estimating the overall response quality. To do so, we create and\npublicly release a human-annotated dataset with labels of correctness for 1,200\nLLM responses. We source questions from a combination of existing datasets and\na novel, challenging benchmark (BFF-Bench) created for this analysis. We\ndemonstrate a strong connection between an LLM's ability to correctly answer a\nquestion and grade responses to that question. Although aggregate level\nstatistics might imply a judge has high agreement with human annotators, it\nwill struggle on the subset of questions it could not answer. To address this\nissue, we recommend a simple solution: provide the judge with a correct,\nhuman-written reference answer. We perform an in-depth analysis on how\nreference quality can affect the performance of an LLM Judge. We show that\nproviding a weaker judge (e.g. Qwen 2.5 7B) with higher quality references\nreaches better agreement with human annotators than a stronger judge (e.g.\nGPT-4o) with synthetic references.", "published": "2025-03-07 00:42:08", "link": "http://arxiv.org/abs/2503.05061v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ModernBERT is More Efficient than Conventional BERT for Chest CT Findings Classification in Japanese Radiology Reports", "abstract": "Objective: This study aims to evaluate and compare the performance of two\nJapanese language models-conventional Bidirectional Encoder Representations\nfrom Transformers (BERT) and the newer ModernBERT-in classifying findings from\nchest CT reports, with a focus on tokenization efficiency, processing time, and\nclassification performance. Methods: We conducted a retrospective study using\nthe CT-RATE-JPN dataset containing 22,778 training reports and 150 test\nreports. Both models were fine-tuned for multi-label classification of 18\ncommon chest CT conditions. The training data was split in 18,222:4,556 for\ntraining and validation. Performance was evaluated using F1 scores for each\ncondition and exact match accuracy across all 18 labels. Results: ModernBERT\ndemonstrated superior tokenization efficiency, requiring 24.0% fewer tokens per\ndocument (258.1 vs. 339.6) compared to BERT Base. This translated to\nsignificant performance improvements, with ModernBERT completing training in\n1877.67 seconds versus BERT's 3090.54 seconds (39% reduction). ModernBERT\nprocessed 38.82 samples per second during training (1.65x faster) and 139.90\nsamples per second during inference (1.66x faster). Despite these efficiency\ngains, classification performance remained comparable, with ModernBERT\nachieving superior F1 scores in 8 conditions, while BERT performed better in 4\nconditions. Overall exact match accuracy was slightly higher for ModernBERT\n(74.67% vs. 72.67%), though this difference was not statistically significant\n(p=0.6291). Conclusion: ModernBERT offers substantial improvements in\ntokenization efficiency and training speed without sacrificing classification\nperformance. These results suggest that ModernBERT is a promising candidate for\nclinical applications in Japanese radiology reports analysis.", "published": "2025-03-07 00:28:08", "link": "http://arxiv.org/abs/2503.05060v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Forming Coordinated Teams that Balance Task Coverage and Expert Workload", "abstract": "We study a new formulation of the team-formation problem, where the goal is\nto form teams to work on a given set of tasks requiring different skills.\nDeviating from the classic problem setting where one is asking to cover all\nskills of each given task, we aim to cover as many skills as possible while\nalso trying to minimize the maximum workload among the experts. We do this by\ncombining penalization terms for the coverage and load constraints into one\nobjective. We call the corresponding assignment problem\n$\\texttt{Balanced-Coverage}$, and show that it is NP-hard. We also consider a\nvariant of this problem, where the experts are organized into a graph, which\nencodes how well they work together. Utilizing such a coordination graph, we\naim to find teams to assign to tasks such that each team's radius does not\nexceed a given threshold. We refer to this problem as\n$\\texttt{Network-Balanced-Coverage}$. We develop a generic template algorithm\nfor approximating both problems in polynomial time, and we show that our\ntemplate algorithm for $\\texttt{Balanced-Coverage}$ has provable guarantees. We\ndescribe a set of computational speedups that we can apply to our algorithms\nand make them scale for reasonably large datasets. From the practical point of\nview, we demonstrate how to efficiently tune the two parts of the objective and\ntailor their importance to a particular application. Our experiments with a\nvariety of real-world datasets demonstrate the utility of our problem\nformulation as well as the efficiency of our algorithms in practice.", "published": "2025-03-07 19:34:25", "link": "http://arxiv.org/abs/2503.05898v1", "categories": ["cs.SI", "cs.DM"], "primary_category": "cs.SI"}
{"title": "On Almost Fair and Equitable Allocations of Indivisible Items for Non-monotone Valuations", "abstract": "In this work, we revisit well-studied problems of fair allocation of\nindivisible items among agents with general, non-monotone valuations. We\nexplore the existence and efficient computation of allocations that satisfy\neither fairness or equity constraints. The fairness notions we consider ensure\nthat each agent values her bundle at least as much as others', allowing for\n(any or some) item removal, while the equity guarantees roughly equal\nvaluations among agents, with similar adjustments. For objective valuations\nwhere items are classified as either goods or chores, we present a\npseudo-polynomial local-search algorithm computing an\n``equitable-up-to-any-good-or-any-chore'' (EQX*) allocation, a weaker version\nof an ``equitable-up-to-any-item\" (EQX) allocation. Additionally, we provide a\npolynomial-time greedy algorithm that computes an ``equitable-up-to-one-item\"\n(EQ1) allocation, and a similar algorithm returning an EQX* allocation when the\nvaluations are also additive. As a key technical contribution of this work, by\nleveraging fixed-point theorems (such as Sperner's Lemma and its variants), we\nestablish the existence of ``equitable-up-to-one-good-and-one-chore'' (EQ1*)\nand ``envy-free-up-to-one-good-and-one-chore'' (EF1*) allocations for\nnon-negative (and possibly non-objective and non-monotone) valuations. This\nholds even when items are arranged in a path and bundles must form connected\nsub-paths. Additionally, we present a polynomial-time dynamic-programming\nalgorithm that computes an EQ1* allocation. Finally, we extend the EF1* and\nEQ1* results to non-positive valuations using a novel multi-coloring variant of\nSperner's lemma, a combinatorial result of independent interest. For monotone\nnon-increasing valuations and path-connected bundles, this implies the\nexistence of EF1 and EQ1 allocations, with EQ1 allocations being efficiently\ncomputable.", "published": "2025-03-07 18:58:18", "link": "http://arxiv.org/abs/2503.05695v1", "categories": ["cs.GT", "cs.DM", "cs.DS"], "primary_category": "cs.GT"}
{"title": "Graph parameters that are coarsely equivalent to path-length", "abstract": "Two graph parameters are said to be coarsely equivalent if they are within\nconstant factors from each other for every graph $G$. Recently, several graph\nparameters were shown to be coarsely equivalent to tree-length. Recall that the\nlength of a tree-decomposition ${\\cal T}(G)$ of a graph $G$ is the largest\ndiameter of a bag in ${\\cal T}(G)$, and the tree-length $tl(G)$ of $G$ is the\nminimum of the length, over all tree-decompositions of $G$. Similarly, the\nlength of a path-decomposition ${\\cal P}(G)$ of a graph $G$ is the largest\ndiameter of a bag in ${\\cal P}(G)$, and the path-length $pl(G)$ of $G$ is the\nminimum of the length, over all path-decompositions of $G$. In this paper, we\npresent several graph parameters that are coarsely equivalent to path-length.\nAmong other results, we show that the path-length of a graph $G$ is small if\nand only if one of the following equivalent conditions is true: (a) $G$ can be\nembedded to an unweighted caterpillar tree (equivalently, to a graph of\npath-width one) with a small additive distortion; (b) there is a constant $r\\ge\n0$ such that for every triple of vertices $u,v,w$ of $G$, disk of radius $r$\ncentered at one of them intercepts all paths connecting two others; (c) $G$ has\na $k$-dominating shortest path with small $k\\ge 0$; (d) $G$ has a\n$k'$-dominating pair with small $k'\\ge 0$; (e) some power $G^\\mu$ of $G$ is an\nAT-free (or even a cocomparability) graph for a small integer $\\mu\\ge 0$.", "published": "2025-03-07 18:23:40", "link": "http://arxiv.org/abs/2503.05661v2", "categories": ["math.CO", "cs.DM", "cs.DS"], "primary_category": "math.CO"}
{"title": "On graph classes with constant domination-packing ratio", "abstract": "The dominating number $\\gamma(G)$ of a graph $G$ is the minimum size of a\nvertex set whose closed neighborhood covers all the vertices of the graph. The\npacking number $\\rho(G)$ of $G$ is the maximum size of a vertex set whose\nclosed neighborhoods are pairwise disjoint. In this paper we study graph\nclasses ${\\cal G}$ such that $\\gamma(G)/\\rho(G)$ is bounded by a constant\n$c_{\\cal G}$ for each $G\\in {\\cal G}$. We propose an inductive proof technique\nto prove that if $\\cal G$ is the class of $2$-degenerate graphs, then there is\nsuch a constant bound $c_{\\cal G}$. We note that this is the first monotone,\ndense graph class that is shown to have constant ratio. We also show that the\nclasses of AT-free and unit-disk graphs have bounded ratio.\n  In addition, our technique gives improved bounds on $c_{\\cal G}$ for planar\ngraphs, graphs of bounded treewidth or bounded twin-width. Finally, we provide\nsome new examples of graph classes where the ratio is unbounded.", "published": "2025-03-07 16:40:09", "link": "http://arxiv.org/abs/2503.05562v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "The Beginner's Textbook for Fully Homomorphic Encryption", "abstract": "Fully Homomorphic Encryption (FHE) is a cryptographic scheme that enables\ncomputations to be performed directly on encrypted data, as if the data were in\nplaintext. After all computations are performed on the encrypted data, it can\nbe decrypted to reveal the result. The decrypted value matches the result that\nwould have been obtained if the same computations were applied to the plaintext\ndata.\n  FHE supports basic operations such as addition and multiplication on\nencrypted numbers. Using these fundamental operations, more complex\ncomputations can be constructed, including subtraction, division, logic gates\n(e.g., AND, OR, XOR, NAND, MUX), and even advanced mathematical functions such\nas ReLU, sigmoid, and trigonometric functions (e.g., sin, cos). These functions\ncan be implemented either as exact formulas or as approximations, depending on\nthe trade-off between computational efficiency and accuracy.\n  Fully Homomorphic Encryption (FHE) enables privacy-preserving machine\nlearning by allowing a server to process the client's data in its encrypted\nform through an ML model. With FHE, the server learns neither the plaintext\nversion of the input features nor the inference results. Only the client, using\ntheir secret key, can decrypt and access the results at the end of the service\nprotocol.FHE can also be applied to confidential blockchain services, ensuring\nthat sensitive data in smart contracts remains encrypted and confidential while\nmaintaining the transparency and integrity of the execution process. Other\napplications of FHE include secure outsourcing of data analytics, encrypted\ndatabase queries, privacy-preserving searches, efficient multi-party\ncomputation for digital signatures, and more.\n  This article is designed to help the reader understand how FHE works from the\nmathematical level.", "published": "2025-03-07 04:29:11", "link": "http://arxiv.org/abs/2503.05136v3", "categories": ["cs.CR", "cs.DM"], "primary_category": "cs.CR"}
{"title": "Small-Scale Testbeds for Connected and Automated Vehicles and Robot Swarms: Challenges and a Roadmap", "abstract": "This article proposes a roadmap to address the current challenges in\nsmall-scale testbeds for Connected and Automated Vehicles (CAVs) and robot\nswarms. The roadmap is a joint effort of participants in the workshop \"1st\nWorkshop on Small-Scale Testbeds for Connected and Automated Vehicles and Robot\nSwarms,\" held on June 2 at the IEEE Intelligent Vehicles Symposium (IV) 2024 in\nJeju, South Korea. The roadmap contains three parts: 1) enhancing accessibility\nand diversity, especially for underrepresented communities, 2) sharing best\npractices for the development and maintenance of testbeds, and 3) connecting\ntestbeds through an abstraction layer to support collaboration. The workshop\nfeatures eight invited speakers, four contributed papers [1]-[4], and a\npresentation of a survey paper on testbeds [5]. The survey paper provides an\nonline comparative table of more than 25 testbeds, available at\nhttps://bassamlab.github.io/testbeds-survey. The workshop's own website is\navailable at https://cpm-remote.lrt.unibw-muenchen.de/iv24-workshop.", "published": "2025-03-07 18:18:30", "link": "http://arxiv.org/abs/2503.05656v2", "categories": ["cs.RO", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Controllable Complementarity: Subjective Preferences in Human-AI Collaboration", "abstract": "Research on human-AI collaboration often prioritizes objective performance.\nHowever, understanding human subjective preferences is essential to improving\nhuman-AI complementarity and human experiences. We investigate human\npreferences for controllability in a shared workspace task with AI partners\nusing Behavior Shaping (BS), a reinforcement learning algorithm that allows\nhumans explicit control over AI behavior.\n  In one experiment, we validate the robustness of BS in producing effective AI\npolicies relative to self-play policies, when controls are hidden. In another\nexperiment, we enable human control, showing that participants perceive AI\npartners as more effective and enjoyable when they can directly dictate AI\nbehavior. Our findings highlight the need to design AI that prioritizes both\ntask performance and subjective human preferences. By aligning AI behavior with\nhuman preferences, we demonstrate how human-AI complementarity can extend\nbeyond objective outcomes to include subjective preferences.", "published": "2025-03-07 14:27:48", "link": "http://arxiv.org/abs/2503.05455v1", "categories": ["cs.HC", "cs.AI", "cs.MA"], "primary_category": "cs.HC"}
{"title": "Accelerating Earth Science Discovery via Multi-Agent LLM Systems", "abstract": "This Perspective explores the transformative potential of Multi-Agent Systems\n(MAS) powered by Large Language Models (LLMs) in the geosciences. Users of\ngeoscientific data repositories face challenges due to the complexity and\ndiversity of data formats, inconsistent metadata practices, and a considerable\nnumber of unprocessed datasets. MAS possesses transformative potential for\nimproving scientists' interaction with geoscientific data by enabling\nintelligent data processing, natural language interfaces, and collaborative\nproblem-solving capabilities. We illustrate this approach with \"PANGAEA GPT\", a\nspecialized MAS pipeline integrated with the diverse PANGAEA database for Earth\nand Environmental Science, demonstrating how MAS-driven workflows can\neffectively manage complex datasets and accelerate scientific discovery. We\ndiscuss how MAS can address current data challenges in geosciences, highlight\nadvancements in other scientific fields, and propose future directions for\nintegrating MAS into geoscientific data processing pipelines. In this\nPerspective, we show how MAS can fundamentally improve data accessibility,\npromote cross-disciplinary collaboration, and accelerate geoscientific\ndiscoveries.", "published": "2025-03-07 13:25:56", "link": "http://arxiv.org/abs/2503.05854v1", "categories": ["cs.MA", "cs.AI", "I.2.11"], "primary_category": "cs.MA"}
{"title": "AVA: Attentive VLM Agent for Mastering StarCraft II", "abstract": "We introduce Attentive VLM Agent (AVA), a multimodal StarCraft II agent that\naligns artificial agent perception with the human gameplay experience.\nTraditional frameworks such as SMAC rely on abstract state representations that\ndiverge significantly from human perception, limiting the ecological validity\nof agent behavior. Our agent addresses this limitation by incorporating RGB\nvisual inputs and natural language observations that more closely simulate\nhuman cognitive processes during gameplay. The AVA architecture consists of\nthree integrated components: (1) a vision-language model enhanced with\nspecialized self-attention mechanisms for strategic unit targeting and\nbattlefield assessment, (2) a retrieval-augmented generation system that\nleverages domain-specific StarCraft II knowledge to inform tactical decisions,\nand (3) a dynamic role-based task distribution system that enables coordinated\nmulti-agent behavior. The experimental evaluation in our proposed AVACraft\nenvironment, which contains 21 multimodal StarCraft II scenarios, demonstrates\nthat AVA powered by foundation models (specifically Qwen-VL and GPT-4o) can\nexecute complex tactical maneuvers without explicit training, achieving\ncomparable performance to traditional MARL methods that require substantial\ntraining iterations. This work establishes a foundation for developing\nhuman-aligned StarCraft II agents and advances the broader research agenda of\nmultimodal game AI. Our implementation is available at\nhttps://github.com/camel-ai/VLM-Play-StarCraft2.", "published": "2025-03-07 12:54:25", "link": "http://arxiv.org/abs/2503.05383v3", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "The Multi-Trip Time-Dependent Mix Vehicle Routing Problem for Hybrid Autonomous Shared Delivery Location and Traditional Door-to-Door Delivery Modes", "abstract": "Rising labor costs and increasing logistical demands pose significant\nchallenges to modern delivery systems. Automated Electric Vehicles (AEVs) could\nreduce reliance on delivery personnel and increase route flexibility, but their\nadoption is limited due to varying customer acceptance and integration\ncomplexities. Shared Distribution Locations (SDLs) offer an alternative to\ndoor-to-door (D2D) delivery by providing a wider delivery window and serving\nmultiple community customers, thereby improving last-mile logistics through\nreduced delivery time, lower costs, and higher customer satisfaction.This paper\nintroduces the Multi-Trip Time-Dependent Hybrid Vehicle Routing Problem\n(MTTD-MVRP), a challenging variant of the Vehicle Routing Problem (VRP) that\ncombines Autonomous Electric Vehicles (AEVs) with conventional vehicles. The\nproblem's complexity arises from factors such as time-dependent travel speeds,\nstrict time windows, battery limitations, and driver labor constraints, while\nintegrating both SDLs and D2D deliveries. To solve the MTTD-MVRP efficiently,\nwe develop a tailored meta-heuristic based on Adaptive Large Neighborhood\nSearch (ALNS) augmented with column generation (CG). This approach intensively\nexplores the solution space using problem-specific operators and adaptively\nrefines solutions, balancing high-quality outcomes with computational effort.\nExtensive experiments show that the proposed method delivers near-optimal\nsolutions for large-scale instances within practical time limits.From a\nmanagerial perspective, our findings highlight the importance of integrating\nautonomous and human-driven vehicles in last-mile logistics. Decision-makers\ncan leverage SDLs to reduce operational costs and carbon footprints while still\naccommodating customers who require or prefer D2D services.", "published": "2025-03-07 04:36:16", "link": "http://arxiv.org/abs/2503.05842v1", "categories": ["cs.MA", "cs.RO", "stat.ME"], "primary_category": "cs.MA"}
{"title": "FinTMMBench: Benchmarking Temporal-Aware Multi-Modal RAG in Finance", "abstract": "Finance decision-making often relies on in-depth data analysis across various\ndata sources, including financial tables, news articles, stock prices, etc. In\nthis work, we introduce FinTMMBench, the first comprehensive benchmark for\nevaluating temporal-aware multi-modal Retrieval-Augmented Generation (RAG)\nsystems in finance. Built from heterologous data of NASDAQ 100 companies,\nFinTMMBench offers three significant advantages. 1) Multi-modal Corpus: It\nencompasses a hybrid of financial tables, news articles, daily stock prices,\nand visual technical charts as the corpus. 2) Temporal-aware Questions: Each\nquestion requires the retrieval and interpretation of its relevant data over a\nspecific time period, including daily, weekly, monthly, quarterly, and annual\nperiods. 3) Diverse Financial Analysis Tasks: The questions involve 10\ndifferent tasks, including information extraction, trend analysis, sentiment\nanalysis and event detection, etc. We further propose a novel TMMHybridRAG\nmethod, which first leverages LLMs to convert data from other modalities (e.g.,\ntabular, visual and time-series data) into textual format and then incorporates\ntemporal information in each node when constructing graphs and dense indexes.\nIts effectiveness has been validated in extensive experiments, but notable gaps\nremain, highlighting the challenges presented by our FinTMMBench.", "published": "2025-03-07 07:13:59", "link": "http://arxiv.org/abs/2503.05185v1", "categories": ["q-fin.CP", "cs.AI", "cs.MM"], "primary_category": "q-fin.CP"}
{"title": "Multi-asset optimal trade execution with stochastic cross-effects: An Obizhaeva-Wang-type framework", "abstract": "We analyze a continuous-time optimal trade execution problem in multiple\nassets where the price impact and the resilience can be matrix-valued\nstochastic processes that incorporate cross-impact effects. In addition, we\nallow for stochastic terminal and running targets. Initially, we formulate the\noptimal trade execution task as a stochastic control problem with a\nfinite-variation control process that acts as an integrator both in the state\ndynamics and in the cost functional. We then extend this problem continuously\nto a stochastic control problem with progressively measurable controls. By\nidentifying this extended problem as equivalent to a certain linear-quadratic\nstochastic control problem, we can use established results in linear-quadratic\nstochastic control to solve the extended problem. This work generalizes\n[Ackermann, Kruse, Urusov; FinancStoch'24] from the single-asset setting to the\nmulti-asset case. In particular, we reveal cross-hedging effects, showing that\nit can be optimal to trade in an asset despite having no initial position.\nMoreover, as a subsetting we discuss a multi-asset variant of the model in\n[Obizhaeva, Wang; JFinancMark'13].", "published": "2025-03-07 17:22:33", "link": "http://arxiv.org/abs/2503.05594v1", "categories": ["math.OC", "math.PR", "q-fin.MF", "q-fin.TR"], "primary_category": "math.OC"}
{"title": "Distortion risk measures of sums of two counter-monotonic risks", "abstract": "In this paper, we will show that under certain conditions, associated to any\nfixed distortion function $g$, the distortion risk measure of a sum of two\ncounter-monotonic risks can be expressed as the sum of two related distortion\nrisk measures of the marginals involved, one associated to the original\ndistortion function $g$ and the other associated to the dual distortion\nfunction of $g$. This result extends some of the work in \\cite{Chaoubi et al.\n(2020)} and \\cite{HLD} since the class of distortion risk measures includes the\nrisk measure of VaR and TVaR as special cases.", "published": "2025-03-07 09:14:28", "link": "http://arxiv.org/abs/2503.05256v1", "categories": ["q-fin.MF", "math.PR"], "primary_category": "q-fin.MF"}
{"title": "Modeling metaorder impact with a Non-Markovian Zero Intelligence model", "abstract": "Devising models of the limit order book that realistically reproduce the\nmarket response to exogenous trades is extremely challenging and fundamental in\norder to test trading strategies. We propose a novel explainable model for\nsmall tick assets, the Non-Markovian Zero Intelligence, which is a variant of\nthe well-known Zero Intelligence model. The main modification is that the\nprobability of limit orders' signs (buy/sell) is not constant but is a function\nof the exponentially weighted mid-price return, representing the past price\ndynamics, and can be interpreted as the reaction of traders with reservation\nprices to the price trend. With numerical simulations and analytical arguments,\nwe show that the model predicts a concave price path during a metaorder\nexecution and to a price reversion after the execution ends, as empirically\nobserved. We analyze in-depth the mechanism at the root of the arising\nconcavity, the components which constitute the price impact in our model, and\nthe dependence of the results on the two main parameters, namely the time scale\nand the strength of the reaction of traders to the price trend.", "published": "2025-03-07 09:10:31", "link": "http://arxiv.org/abs/2503.05254v2", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Audio-to-Image Encoding for Improved Voice Characteristic Detection Using Deep Convolutional Neural Networks", "abstract": "This paper introduces a novel audio-to-image encoding framework that\nintegrates multiple dimensions of voice characteristics into a single RGB image\nfor speaker recognition. In this method, the green channel encodes raw audio\ndata, the red channel embeds statistical descriptors of the voice signal\n(including key metrics such as median and mean values for fundamental\nfrequency, spectral centroid, bandwidth, rolloff, zero-crossing rate, MFCCs,\nRMS energy, spectral flatness, spectral contrast, chroma, and harmonic-to-noise\nratio), and the blue channel comprises subframes representing these features in\na spatially organized format. A deep convolutional neural network trained on\nthese composite images achieves 98% accuracy in speaker classification across\ntwo speakers, suggesting that this integrated multi-channel representation can\nprovide a more discriminative input for voice recognition tasks.", "published": "2025-03-07 20:49:56", "link": "http://arxiv.org/abs/2503.05929v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker Characteristics And Intelligibility", "abstract": "Video-to-speech (V2S) synthesis, the task of generating speech directly from\nsilent video input, is inherently more challenging than other speech synthesis\ntasks due to the need to accurately reconstruct both speech content and speaker\ncharacteristics from visual cues alone. Recently, audio-visual pre-training has\neliminated the need for additional acoustic hints in V2S, which previous\nmethods often relied on to ensure training convergence. However, even with\npre-training, existing methods continue to face challenges in achieving a\nbalance between acoustic intelligibility and the preservation of\nspeaker-specific characteristics. We analyzed this limitation and were\nmotivated to introduce DiVISe (Direct Visual-Input Speech Synthesis), an\nend-to-end V2S model that predicts Mel-spectrograms directly from video frames\nalone. Despite not taking any acoustic hints, DiVISe effectively preserves\nspeaker characteristics in the generated audio, and achieves superior\nperformance on both objective and subjective metrics across the LRS2 and LRS3\ndatasets. Our results demonstrate that DiVISe not only outperforms existing V2S\nmodels in acoustic intelligibility but also scales more effectively with\nincreased data and model parameters. Code and weights can be found at\nhttps://github.com/PussyCat0700/DiVISe.", "published": "2025-03-07 08:21:48", "link": "http://arxiv.org/abs/2503.05223v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "UniArray: Unified Spectral-Spatial Modeling for Array-Geometry-Agnostic Speech Separation", "abstract": "Array-geometry-agnostic speech separation (AGA-SS) aims to develop an\neffective separation method regardless of the microphone array geometry.\nConventional methods rely on permutation-free operations, such as summation or\nattention mechanisms, to capture spatial information. However, these approaches\noften incur high computational costs or disrupt the effective use of spatial\ninformation during intra- and inter-channel interactions, leading to suboptimal\nperformance. To address these issues, we propose UniArray, a novel approach\nthat abandons the conventional interleaving manner. UniArray consists of three\nkey components: a virtual microphone estimation (VME) module, a feature\nextraction and fusion module, and a hierarchical dual-path separator. The VME\nensures robust performance across arrays with varying channel numbers. The\nfeature extraction and fusion module leverages a spectral feature extraction\nmodule and a spatial dictionary learning (SDL) module to extract and fuse\nfrequency-bin-level features, allowing the separator to focus on using the\nfused features. The hierarchical dual-path separator models feature\ndependencies along the time and frequency axes while maintaining computational\nefficiency. Experimental results show that UniArray outperforms\nstate-of-the-art methods in SI-SDRi, WB-PESQ, NB-PESQ, and STOI across both\nseen and unseen array geometries.", "published": "2025-03-07 03:11:04", "link": "http://arxiv.org/abs/2503.05110v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
