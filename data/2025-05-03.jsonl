{"title": "Explainability by design: an experimental analysis of the legal coding process", "abstract": "Behind a set of rules in Deontic Defeasible Logic, there is a mapping process\nof normative background fragments. This process goes from text to rules and\nimplicitly encompasses an explanation of the coded fragments.\n  In this paper we deliver a methodology for \\textit{legal coding} that starts\nwith a fragment and goes onto a set of Deontic Defeasible Logic rules,\ninvolving a set of \\textit{scenarios} to test the correctness of the coded\nfragments. The methodology is illustrated by the coding process of an example\ntext. We then show the results of a series of experiments conducted with humans\nencoding a variety of normative backgrounds and corresponding cases in which we\nhave measured the efforts made in the coding process, as related to some\nmeasurable features. To process these examples, a recently developed\ntechnology, Houdini, that allows reasoning in Deontic Defeasible Logic, has\nbeen employed.\n  Finally we provide a technique to forecast time required in coding, that\ndepends on factors such as knowledge of the legal domain, knowledge of the\ncoding processes, length of the text, and a measure of \\textit{depth} that\nrefers to the length of the paths of legal references.", "published": "2025-05-03 23:18:05", "link": "http://arxiv.org/abs/2505.01944v1", "categories": ["cs.LO", "cs.AI", "cs.CL"], "primary_category": "cs.LO"}
{"title": "CAMOUFLAGE: Exploiting Misinformation Detection Systems Through LLM-driven Adversarial Claim Transformation", "abstract": "Automated evidence-based misinformation detection systems, which evaluate the\nveracity of short claims against evidence, lack comprehensive analysis of their\nadversarial vulnerabilities. Existing black-box text-based adversarial attacks\nare ill-suited for evidence-based misinformation detection systems, as these\nattacks primarily focus on token-level substitutions involving gradient or\nlogit-based optimization strategies, which are incapable of fooling the\nmulti-component nature of these detection systems. These systems incorporate\nboth retrieval and claim-evidence comparison modules, which requires attacks to\nbreak the retrieval of evidence and/or the comparison module so that it draws\nincorrect inferences. We present CAMOUFLAGE, an iterative, LLM-driven approach\nthat employs a two-agent system, a Prompt Optimization Agent and an Attacker\nAgent, to create adversarial claim rewritings that manipulate evidence\nretrieval and mislead claim-evidence comparison, effectively bypassing the\nsystem without altering the meaning of the claim. The Attacker Agent produces\nsemantically equivalent rewrites that attempt to mislead detectors, while the\nPrompt Optimization Agent analyzes failed attack attempts and refines the\nprompt of the Attacker to guide subsequent rewrites. This enables larger\nstructural and stylistic transformations of the text rather than token-level\nsubstitutions, adapting the magnitude of changes based on previous outcomes.\nUnlike existing approaches, CAMOUFLAGE optimizes its attack solely based on\nbinary model decisions to guide its rewriting process, eliminating the need for\nclassifier logits or extensive querying. We evaluate CAMOUFLAGE on four\nsystems, including two recent academic systems and two real-world APIs, with an\naverage attack success rate of 46.92\\% while preserving textual coherence and\nsemantic equivalence to the original claims.", "published": "2025-05-03 19:14:24", "link": "http://arxiv.org/abs/2505.01900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Sentiment Classification and Topic Discovery in Large-Scale Social Media Streams", "abstract": "We present a framework for large-scale sentiment and topic analysis of\nTwitter discourse. Our pipeline begins with targeted data collection using\nconflict-specific keywords, followed by automated sentiment labeling via\nmultiple pre-trained models to improve annotation robustness. We examine the\nrelationship between sentiment and contextual features such as timestamp,\ngeolocation, and lexical content. To identify latent themes, we apply Latent\nDirichlet Allocation (LDA) on partitioned subsets grouped by sentiment and\nmetadata attributes. Finally, we develop an interactive visualization interface\nto support exploration of sentiment trends and topic distributions across time\nand regions. This work contributes a scalable methodology for social media\nanalysis in dynamic geopolitical contexts.", "published": "2025-05-03 18:04:57", "link": "http://arxiv.org/abs/2505.01883v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Humans can learn to detect AI-generated texts, or at least learn when they can't", "abstract": "This study investigates whether individuals can learn to accurately\ndiscriminate between human-written and AI-produced texts when provided with\nimmediate feedback, and if they can use this feedback to recalibrate their\nself-perceived competence. We also explore the specific criteria individuals\nrely upon when making these decisions, focusing on textual style and perceived\nreadability.\n  We used GPT-4o to generate several hundred texts across various genres and\ntext types comparable to Koditex, a multi-register corpus of human-written\ntexts. We then presented randomized text pairs to 255 Czech native speakers who\nidentified which text was human-written and which was AI-generated.\nParticipants were randomly assigned to two conditions: one receiving immediate\nfeedback after each trial, the other receiving no feedback until experiment\ncompletion. We recorded accuracy in identification, confidence levels, response\ntimes, and judgments about text readability along with demographic data and\nparticipants' engagement with AI technologies prior to the experiment.\n  Participants receiving immediate feedback showed significant improvement in\naccuracy and confidence calibration. Participants initially held incorrect\nassumptions about AI-generated text features, including expectations about\nstylistic rigidity and readability. Notably, without feedback, participants\nmade the most errors precisely when feeling most confident -- an issue largely\nresolved among the feedback group.\n  The ability to differentiate between human and AI-generated texts can be\neffectively learned through targeted training with explicit feedback, which\nhelps correct misconceptions about AI stylistic features and readability, as\nwell as potential other variables that were not explored, while facilitating\nmore accurate self-assessment. This finding might be particularly important in\neducational contexts.", "published": "2025-05-03 17:42:49", "link": "http://arxiv.org/abs/2505.01877v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Positional Attention for Efficient BERT-Based Named Entity Recognition", "abstract": "This paper presents a framework for Named Entity Recognition (NER) leveraging\nthe Bidirectional Encoder Representations from Transformers (BERT) model in\nnatural language processing (NLP). NER is a fundamental task in NLP with broad\napplicability across downstream applications. While BERT has established itself\nas a state-of-the-art model for entity recognition, fine-tuning it from scratch\nfor each new application is computationally expensive and time-consuming. To\naddress this, we propose a cost-efficient approach that integrates positional\nattention mechanisms into the entity recognition process and enables effective\ncustomization using pre-trained parameters. The framework is evaluated on a\nKaggle dataset derived from the Groningen Meaning Bank corpus and achieves\nstrong performance with fewer training epochs. This work contributes to the\nfield by offering a practical solution for reducing the training cost of\nBERT-based NER systems while maintaining high accuracy.", "published": "2025-05-03 17:17:05", "link": "http://arxiv.org/abs/2505.01868v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Intra-Layer Recurrence in Transformers for Language Modeling", "abstract": "Transformer models have established new benchmarks in natural language\nprocessing; however, their increasing depth results in substantial growth in\nparameter counts. While existing recurrent transformer methods address this\nissue by reprocessing layers multiple times, they often apply recurrence\nindiscriminately across entire blocks of layers. In this work, we investigate\nIntra-Layer Recurrence (ILR), a more targeted approach that applies recurrence\nselectively to individual layers within a single forward pass. Our experiments\nshow that allocating more iterations to earlier layers yields optimal results.\nThese findings suggest that ILR offers a promising direction for optimizing\nrecurrent structures in transformer architectures.", "published": "2025-05-03 16:16:55", "link": "http://arxiv.org/abs/2505.01855v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "$\\textit{New News}$: System-2 Fine-tuning for Robust Integration of New Knowledge", "abstract": "Humans and intelligent animals can effortlessly internalize new information\n(\"news\") and accurately extract the implications for performing downstream\ntasks. While large language models (LLMs) can achieve this through in-context\nlearning (ICL) when the news is explicitly given as context, fine-tuning\nremains challenging for the models to consolidate learning in weights. In this\npaper, we introduce $\\textit{New News}$, a dataset composed of hypothetical yet\nplausible news spanning multiple domains (mathematics, coding, discoveries,\nleaderboards, events), accompanied by downstream evaluation questions whose\ncorrect answers critically depend on understanding and internalizing the news.\nWe first demonstrate a substantial gap between naive fine-tuning and in-context\nlearning (FT-ICL gap) on our news dataset. To address this gap, we explore a\nsuite of self-play data generation protocols -- paraphrases, implications and\nSelf-QAs -- designed to distill the knowledge from the model with context into\nthe weights of the model without the context, which we term $\\textit{System-2\nFine-tuning}$ (Sys2-FT). We systematically evaluate ICL and Sys2-FT performance\nacross data domains and model scales with the Qwen 2.5 family of models. Our\nresults demonstrate that the self-QA protocol of Sys2-FT significantly improves\nmodels' in-weight learning of the news. Furthermore, we discover the\n$\\textit{contexual shadowing effect}$, where training with the news $\\textit{in\ncontext}$ followed by its rephrases or QAs degrade learning of the news.\nFinally, we show preliminary evidence of an emerging scaling law of Sys2-FT.", "published": "2025-05-03 12:49:35", "link": "http://arxiv.org/abs/2505.01812v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Distinguishing AI-Generated and Human-Written Text Through Psycholinguistic Analysis", "abstract": "The increasing sophistication of AI-generated texts highlights the urgent\nneed for accurate and transparent detection tools, especially in educational\nsettings, where verifying authorship is essential. Existing literature has\ndemonstrated that the application of stylometric features with machine learning\nclassifiers can yield excellent results. Building on this foundation, this\nstudy proposes a comprehensive framework that integrates stylometric analysis\nwith psycholinguistic theories, offering a clear and interpretable approach to\ndistinguishing between AI-generated and human-written texts. This research\nspecifically maps 31 distinct stylometric features to cognitive processes such\nas lexical retrieval, discourse planning, cognitive load management, and\nmetacognitive self-monitoring. In doing so, it highlights the unique\npsycholinguistic patterns found in human writing. Through the intersection of\ncomputational linguistics and cognitive science, this framework contributes to\nthe development of reliable tools aimed at preserving academic integrity in the\nera of generative AI.", "published": "2025-05-03 12:06:53", "link": "http://arxiv.org/abs/2505.01800v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Multimodal Framework for Explainable Evaluation of Soft Skills in Educational Environments", "abstract": "In the rapidly evolving educational landscape, the unbiased assessment of\nsoft skills is a significant challenge, particularly in higher education. This\npaper presents a fuzzy logic approach that employs a Granular Linguistic Model\nof Phenomena integrated with multimodal analysis to evaluate soft skills in\nundergraduate students. By leveraging computational perceptions, this approach\nenables a structured breakdown of complex soft skill expressions, capturing\nnuanced behaviours with high granularity and addressing their inherent\nuncertainties, thereby enhancing interpretability and reliability. Experiments\nwere conducted with undergraduate students using a developed tool that assesses\nsoft skills such as decision-making, communication, and creativity. This tool\nidentifies and quantifies subtle aspects of human interaction, such as facial\nexpressions and gesture recognition. The findings reveal that the framework\neffectively consolidates multiple data inputs to produce meaningful and\nconsistent assessments of soft skills, showing that integrating multiple\nmodalities into the evaluation process significantly improves the quality of\nsoft skills scores, making the assessment work transparent and understandable\nto educational stakeholders.", "published": "2025-05-03 11:54:35", "link": "http://arxiv.org/abs/2505.01794v1", "categories": ["cs.CL", "cs.AI", "cs.MM"], "primary_category": "cs.CL"}
{"title": "Enhancing the Learning Experience: Using Vision-Language Models to Generate Questions for Educational Videos", "abstract": "Web-based educational videos offer flexible learning opportunities and are\nbecoming increasingly popular. However, improving user engagement and knowledge\nretention remains a challenge. Automatically generated questions can activate\nlearners and support their knowledge acquisition. Further, they can help\nteachers and learners assess their understanding. While large language and\nvision-language models have been employed in various tasks, their application\nto question generation for educational videos remains underexplored. In this\npaper, we investigate the capabilities of current vision-language models for\ngenerating learning-oriented questions for educational video content. We assess\n(1) out-of-the-box models' performance; (2) fine-tuning effects on\ncontent-specific question generation; (3) the impact of different video\nmodalities on question quality; and (4) in a qualitative study, question\nrelevance, answerability, and difficulty levels of generated questions. Our\nfindings delineate the capabilities of current vision-language models,\nhighlighting the need for fine-tuning and addressing challenges in question\ndiversity and relevance. We identify requirements for future multimodal\ndatasets and outline promising research directions.", "published": "2025-05-03 11:37:31", "link": "http://arxiv.org/abs/2505.01790v1", "categories": ["cs.CV", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Same evaluation, more tokens: On the effect of input length for machine translation evaluation using Large Language Models", "abstract": "Accurately evaluating machine-translated text remains a long-standing\nchallenge, particularly for long documents. Recent work has shown that large\nlanguage models (LLMs) can serve as reliable and interpretable sentence-level\ntranslation evaluators via MQM error span annotations. With modern LLMs\nsupporting larger context windows, a natural question arises: can we feed\nentire document translations into an LLM for quality assessment? Ideally,\nevaluation should be invariant to text length, producing consistent error spans\nregardless of input granularity. However, our analysis shows that text length\nsignificantly impacts evaluation: longer texts lead to fewer error spans and\nreduced system ranking accuracy. To address this limitation, we evaluate\nseveral strategies, including granularity-aligned prompting, Focus Sentence\nPrompting (FSP), and a fine-tuning approach to better align LLMs with the\nevaluation task. The latter two methods largely mitigate this length bias,\nmaking LLMs more reliable for long-form translation evaluation.", "published": "2025-05-03 09:30:26", "link": "http://arxiv.org/abs/2505.01761v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unraveling Media Perspectives: A Comprehensive Methodology Combining Large Language Models, Topic Modeling, Sentiment Analysis, and Ontology Learning to Analyse Media Bias", "abstract": "Biased news reporting poses a significant threat to informed decision-making\nand the functioning of democracies. This study introduces a novel methodology\nfor scalable, minimally biased analysis of media bias in political news. The\nproposed approach examines event selection, labeling, word choice, and\ncommission and omission biases across news sources by leveraging natural\nlanguage processing techniques, including hierarchical topic modeling,\nsentiment analysis, and ontology learning with large language models. Through\nthree case studies related to current political events, we demonstrate the\nmethodology's effectiveness in identifying biases across news sources at\nvarious levels of granularity. This work represents a significant step towards\nscalable, minimally biased media bias analysis, laying the groundwork for tools\nto help news consumers navigate an increasingly complex media landscape.", "published": "2025-05-03 09:09:34", "link": "http://arxiv.org/abs/2505.01754v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG", "cs.MA", "68T09, 68T50, 68T05, 62R07, 68U15, 68T27, 68T20 68T09, 68T50, 68T05,\n  62R07, 68U15, 68T27, 68T20 68T09, 68T50, 68T05, 62R07, 68U15, 68T27, 68T20", "I.2; H.3; I.5; I.7; H.5; H.1"], "primary_category": "cs.AI"}
{"title": "Efficient Shapley Value-based Non-Uniform Pruning of Large Language Models", "abstract": "Pruning large language models (LLMs) is a promising solution for reducing\nmodel sizes and computational complexity while preserving performance.\nTraditional layer-wise pruning methods often adopt a uniform sparsity approach\nacross all layers, which leads to suboptimal performance due to the varying\nsignificance of individual transformer layers within the model not being\naccounted for. To this end, we propose the \\underline{S}hapley\n\\underline{V}alue-based \\underline{N}on-\\underline{U}niform \\underline{P}runing\n(\\methodname{}) method for LLMs. This approach quantifies the contribution of\neach transformer layer to the overall model performance, enabling the\nassignment of tailored pruning budgets to different layers to retain critical\nparameters. To further improve efficiency, we design the Sliding Window-based\nShapley Value approximation method. It substantially reduces computational\noverhead compared to exact SV calculation methods. Extensive experiments on\nvarious LLMs including LLaMA-v1, LLaMA-v2 and OPT demonstrate the effectiveness\nof the proposed approach. The results reveal that non-uniform pruning\nsignificantly enhances the performance of pruned models. Notably, \\methodname{}\nachieves a reduction in perplexity (PPL) of 18.01\\% and 19.55\\% on LLaMA-7B and\nLLaMA-13B, respectively, compared to SparseGPT at 70\\% sparsity.", "published": "2025-05-03 07:57:02", "link": "http://arxiv.org/abs/2505.01731v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Inducing Robustness in a 2 Dimensional Direct Preference Optimization Paradigm", "abstract": "Direct Preference Optimisation (DPO) has emerged as a powerful method for\naligning Large Language Models (LLMs) with human preferences, offering a stable\nand efficient alternative to approaches that use Reinforcement learning via\nHuman Feedback. In this work, we investigate the performance of DPO using\nopen-source preference datasets. One of the major drawbacks of DPO is that it\ndoesn't induce granular scoring and treats all the segments of the responses\nwith equal propensity. However, this is not practically true for human\npreferences since even \"good\" responses have segments that may not be preferred\nby the annotator. To resolve this, a 2-dimensional scoring for DPO alignment\ncalled 2D-DPO was proposed. We explore the 2D-DPO alignment paradigm and the\nadvantages it provides over the standard DPO by comparing their win rates. It\nis observed that these methods, even though effective, are not robust to\nlabel/score noise. To counter this, we propose an approach of incorporating\nsegment-level score noise robustness to the 2D-DPO algorithm. Along with\ntheoretical backing, we also provide empirical verification in favour of the\nalgorithm and introduce other noise models that can be present.", "published": "2025-05-03 05:59:13", "link": "http://arxiv.org/abs/2505.01706v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "High-Fidelity Pseudo-label Generation by Large Language Models for Training Robust Radiology Report Classifiers", "abstract": "Automated labeling of chest X-ray reports is essential for enabling\ndownstream tasks such as training image-based diagnostic models, population\nhealth studies, and clinical decision support. However, the high variability,\ncomplexity, and prevalence of negation and uncertainty in these free-text\nreports pose significant challenges for traditional Natural Language Processing\nmethods. While large language models (LLMs) demonstrate strong text\nunderstanding, their direct application for large-scale, efficient labeling is\nlimited by computational cost and speed. This paper introduces DeBERTa-RAD, a\nnovel two-stage framework that combines the power of state-of-the-art LLM\npseudo-labeling with efficient DeBERTa-based knowledge distillation for\naccurate and fast chest X-ray report labeling. We leverage an advanced LLM to\ngenerate high-quality pseudo-labels, including certainty statuses, for a large\ncorpus of reports. Subsequently, a DeBERTa-Base model is trained on this\npseudo-labeled data using a tailored knowledge distillation strategy. Evaluated\non the expert-annotated MIMIC-500 benchmark, DeBERTa-RAD achieves a\nstate-of-the-art Macro F1 score of 0.9120, significantly outperforming\nestablished rule-based systems, fine-tuned transformer models, and direct LLM\ninference, while maintaining a practical inference speed suitable for\nhigh-throughput applications. Our analysis shows particular strength in\nhandling uncertain findings. This work demonstrates a promising path to\novercome data annotation bottlenecks and achieve high-performance medical text\nprocessing through the strategic combination of LLM capabilities and efficient\nstudent models trained via distillation.", "published": "2025-05-03 04:50:55", "link": "http://arxiv.org/abs/2505.01693v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency", "abstract": "Large language models (LLMs) are widely applied in chatbots, code generators,\nand search engines. Workloads such as chain-of-thought, complex reasoning, and\nagent services significantly increase the inference cost by invoking the model\nrepeatedly. Optimization methods such as parallelism, compression, and caching\nhave been adopted to reduce costs, but the diverse service requirements make it\nhard to select the right method. Recently, specialized LLM inference engines\nhave emerged as a key component for integrating the optimization methods into\nservice-oriented infrastructures. However, a systematic study on inference\nengines is still lacking. This paper provides a comprehensive evaluation of 25\nopen-source and commercial inference engines. We examine each inference engine\nin terms of ease-of-use, ease-of-deployment, general-purpose support,\nscalability, and suitability for throughput- and latency-aware computation.\nFurthermore, we explore the design goals of each inference engine by\ninvestigating the optimization techniques it supports. In addition, we assess\nthe ecosystem maturity of open source inference engines and handle the\nperformance and cost policy of commercial solutions. We outline future research\ndirections that include support for complex LLM-based services, support of\nvarious hardware, and enhanced security, offering practical guidance to\nresearchers and developers in selecting and designing optimized LLM inference\nengines. We also provide a public repository to continually track developments\nin this fast-evolving field:\nhttps://github.com/sihyeong/Awesome-LLM-Inference-Engine", "published": "2025-05-03 02:47:43", "link": "http://arxiv.org/abs/2505.01658v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and task generalization. However, their\napplication to structured data analysis remains fragile due to inconsistencies\nin schema interpretation, misalignment between user intent and model output,\nand limited mechanisms for self-correction when failures occur. This paper\nintroduces the STROT Framework (Structured Task Reasoning and Output\nTransformation), a method for structured prompting and feedback-driven\ntransformation logic generation aimed at improving the reliability and semantic\nalignment of LLM-based analytical workflows. STROT begins with lightweight\nschema introspection and sample-based field classification, enabling dynamic\ncontext construction that captures both the structure and statistical profile\nof the input data. This contextual information is embedded in structured\nprompts that guide the model toward generating task-specific, interpretable\noutputs. To address common failure modes in complex queries, STROT incorporates\na refinement mechanism in which the model iteratively revises its outputs based\non execution feedback and validation signals. Unlike conventional approaches\nthat rely on static prompts or single-shot inference, STROT treats the LLM as a\nreasoning agent embedded within a controlled analysis loop -- capable of\nadjusting its output trajectory through planning and correction. The result is\na robust and reproducible framework for reasoning over structured data with\nLLMs, applicable to diverse data exploration and analysis tasks where\ninterpretability, stability, and correctness are essential.", "published": "2025-05-03 00:05:01", "link": "http://arxiv.org/abs/2505.01636v1", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.7; H.2.8; D.2.13"], "primary_category": "cs.AI"}
{"title": "Embedding based retrieval for long tail search queries in ecommerce", "abstract": "In this abstract we present a series of optimizations we performed on the\ntwo-tower model architecture [14], training and evaluation datasets to\nimplement semantic product search at Best Buy. Search queries on bestbuy.com\nfollow the pareto distribution whereby a minority of them account for most\nsearches. This leaves us with a long tail of search queries that have low\nfrequency of issuance. The queries in the long tail suffer from very spare\ninteraction signals. Our current work focuses on building a model to serve the\nlong tail queries. We present a series of optimizations we have done to this\nmodel to maximize conversion for the purpose of retrieval from the catalog. The\nfirst optimization we present is using a large language model to improve the\nsparsity of conversion signals. The second optimization is pretraining an\noff-the-shelf transformer-based model on the Best Buy catalog data. The third\noptimization we present is on the finetuning front. We use query-to-query pairs\nin addition to query-to-product pairs and combining the above strategies for\nfinetuning the model. We also demonstrate how merging the weights of these\nfinetuned models improves the evaluation metrics. Finally, we provide a recipe\nfor curating an evaluation dataset for continuous monitoring of model\nperformance with human-in-the-loop evaluation. We found that adding this recall\nmechanism to our current term match-based recall improved conversion by 3% in\nan online A/B test.", "published": "2025-05-03 23:47:15", "link": "http://arxiv.org/abs/2505.01946v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "A Generalised and Adaptable Reinforcement Learning Stopping Method", "abstract": "This paper presents a Technology Assisted Review (TAR) stopping approach\nbased on Reinforcement Learning (RL). Previous such approaches offered limited\ncontrol over stopping behaviour, such as fixing the target recall and tradeoff\nbetween preferring to maximise recall or cost. These limitations are overcome\nby introducing a novel RL environment, GRLStop, that allows a single model to\nbe applied to multiple target recalls, balances the recall/cost tradeoff and\nintegrates a classifier. Experiments were carried out on six benchmark datasets\n(CLEF e-Health datasets 2017-9, TREC Total Recall, TREC Legal and Reuters RCV1)\nat multiple target recall levels. Results showed that the proposed approach to\nbe effective compared to multiple baselines in addition to offering greater\nflexibility.", "published": "2025-05-03 19:24:40", "link": "http://arxiv.org/abs/2505.01907v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Exploring the Role of Diversity in Example Selection for In-Context Learning", "abstract": "In-Context Learning (ICL) has gained prominence due to its ability to perform\ntasks without requiring extensive training data and its robustness to noisy\nlabels. A typical ICL workflow involves selecting localized examples relevant\nto a given input using sparse or dense embedding-based similarity functions.\nHowever, relying solely on similarity-based selection may introduce topical\nbiases in the retrieved contexts, potentially leading to suboptimal downstream\nperformance. We posit that reranking the retrieved context to enhance topical\ndiversity can improve downstream task performance. To achieve this, we leverage\nmaximum marginal relevance (MMR) which balances topical similarity with\ninter-example diversity. Our experimental results demonstrate that diversifying\nthe selected examples leads to consistent improvements in downstream\nperformance across various context sizes and similarity functions. The\nimplementation of our approach is made available at\nhttps://github.com/janak11111/Diverse-ICL.", "published": "2025-05-03 15:13:58", "link": "http://arxiv.org/abs/2505.01842v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "SimAug: Enhancing Recommendation with Pretrained Language Models for Dense and Balanced Data Augmentation", "abstract": "Deep Neural Networks (DNNs) are extensively used in collaborative filtering\ndue to their impressive effectiveness. These systems depend on interaction data\nto learn user and item embeddings that are crucial for recommendations.\nHowever, the data often suffers from sparsity and imbalance issues: limited\nobservations of user-item interactions can result in sub-optimal performance,\nand a predominance of interactions with popular items may introduce\nrecommendation bias. To address these challenges, we employ Pretrained Language\nModels (PLMs) to enhance the interaction data with textual information, leading\nto a denser and more balanced dataset. Specifically, we propose a simple yet\neffective data augmentation method (SimAug) based on the textual similarity\nfrom PLMs, which can be seamlessly integrated to any systems as a lightweight,\nplug-and-play component in the pre-processing stage. Our experiments across\nnine datasets consistently demonstrate improvements in both utility and\nfairness when training with the augmented data generated by SimAug. The code is\navailable at https://github.com/YuyingZhao/SimAug.", "published": "2025-05-03 04:59:12", "link": "http://arxiv.org/abs/2505.01695v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "RAGAR: Retrieval Augment Personalized Image Generation Guided by Recommendation", "abstract": "Personalized image generation is crucial for improving the user experience,\nas it renders reference images into preferred ones according to user visual\npreferences. Although effective, existing methods face two main issues. First,\nexisting methods treat all items in the user historical sequence equally when\nextracting user preferences, overlooking the varying semantic similarities\nbetween historical items and the reference item. Disproportionately high\nweights for low-similarity items distort users' visual preferences for the\nreference item. Second, existing methods heavily rely on consistency between\ngenerated and reference images to optimize the generation, which leads to\nunderfitting user preferences and hinders personalization. To address these\nissues, we propose Retrieval Augment Personalized Image GenerAtion guided by\nRecommendation (RAGAR). Our approach uses a retrieval mechanism to assign\ndifferent weights to historical items according to their similarities to the\nreference item, thereby extracting more refined users' visual preferences for\nthe reference item. Then we introduce a novel rank task based on the\nmulti-modal ranking model to optimize the personalization of the generated\nimages instead of forcing depend on consistency. Extensive experiments and\nhuman evaluations on three real-world datasets demonstrate that RAGAR achieves\nsignificant improvements in both personalization and semantic metrics compared\nto five baselines.", "published": "2025-05-03 02:20:30", "link": "http://arxiv.org/abs/2505.01657v1", "categories": ["cs.IR", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Continuously Ordered Hierarchies of Algorithmic Information in Digital Twinning and Signal Processing", "abstract": "We consider a fractional-calculus example of a continuous hierarchy of\nalgorithmic information in the context of its potential applications in digital\ntwinning. Digital twinning refers to different emerging methodologies in\ncontrol engineering that involve the creation of a digital replica of some\nphysical entity. From the perspective of computability theory, the problem of\nensuring the digital twin's integrity -- i.e., keeping it in a state where it\nmatches its physical counterpart -- entails a notion of algorithmic information\nthat determines which of the physical system's properties we can reliably\ndeduce by algorithmically analyzing its digital twin. The present work\ninvestigates the fractional calculus of periodic functions -- particularly, we\nconsider the Wiener algebra -- as an exemplary application of the\nalgorithmic-information concept. We establish a continuously ordered hierarchy\nof algorithmic information among spaces of periodic functions -- depending on\ntheir fractional degree of smoothness -- in which the ordering relation\ndetermines whether a certain representation of some function contains ``more''\nor ``less'' information than another. Additionally, we establish an analogous\nhierarchy among lp-spaces, which form a cornerstone of (traditional) digital\nsignal processing. Notably, both hierarchies are (mathematically) ``dual'' to\neach other. From a practical perspective, our approach ultimately falls into\nthe category of formal verification and (general) formal methods.", "published": "2025-05-03 21:43:39", "link": "http://arxiv.org/abs/2505.01927v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "ResiTok: A Resilient Tokenization-Enabled Framework for Ultra-Low-Rate and Robust Image Transmission", "abstract": "Real-time transmission of visual data over wireless networks remains highly\nchallenging, even when leveraging advanced deep neural networks, particularly\nunder severe channel conditions such as limited bandwidth and weak\nconnectivity. In this paper, we propose a novel Resilient Tokenization-Enabled\n(ResiTok) framework designed for ultra-low-rate image transmission that\nachieves exceptional robustness while maintaining high reconstruction quality.\nBy reorganizing visual information into hierarchical token groups consisting of\nessential key tokens and supplementary detail tokens, ResiTok enables\nprogressive encoding and graceful degradation of visual quality under\nconstrained channel conditions. A key contribution is our resilient 1D\ntokenization method integrated with a specialized zero-out training strategy,\nwhich systematically simulates token loss during training, empowering the\nneural network to effectively compress and reconstruct images from incomplete\ntoken sets. Furthermore, the channel-adaptive coding and modulation design\ndynamically allocates coding resources according to prevailing channel\nconditions, yielding superior semantic fidelity and structural consistency even\nat extremely low channel bandwidth ratios. Evaluation results demonstrate that\nResiTok outperforms state-of-the-art methods in both semantic similarity and\nvisual quality, with significant advantages under challenging channel\nconditions.", "published": "2025-05-03 17:20:49", "link": "http://arxiv.org/abs/2505.01870v1", "categories": ["cs.IT", "eess.IV", "math.IT"], "primary_category": "cs.IT"}
{"title": "Semantics-Aware Unified Terrestrial Non-Terrestrial 6G Networks", "abstract": "The integration of Terrestrial and Non-Terrestrial Networks (TN-NTNs), which\nwas introduced in 5G, is progressing toward a unified and seamless network of\nnetworks in Sixth-Generation (6G). This evolution leads to a significant\nincrease in the volume of generated and communicated data, imposing technical\nand operational requirements accompanied by a higher cost and energy\nconsumption. Efficiently managing the generation and transmission of data in\nthese highly complex unified networks has become essential. In this article, we\ninvestigate the semantics-aware information handling problem within unified\nTN-NTNs, where data communication between the distant TN nodes is enabled via\nan NTN. To this end, an Internet of Things (IoT) monitoring system is employed,\nwhere status updates from a remote IoT device are communicated to a destination\nmonitor via a constellation of Low Earth Orbit (LEO) satellites. We leverage\nsemantic metrics that capture the timeliness, relevance, and utility of\ninformation to provide the most informative data for timely and informed\ndecision-making and eventually reduce the volume of transmitted and processed\ndata. The outcome is significantly lower energy consumption, memory, control,\nand processing requirements (up to 73% lower energy charging demands compared\nto the state-of-the-art), all without compromising the conveyed information.", "published": "2025-05-03 11:57:38", "link": "http://arxiv.org/abs/2505.01796v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "cs.NI"}
{"title": "Context-Aware Online Conformal Anomaly Detection with Prediction-Powered Data Acquisition", "abstract": "Online anomaly detection is essential in fields such as cybersecurity,\nhealthcare, and industrial monitoring, where promptly identifying deviations\nfrom expected behavior can avert critical failures or security breaches. While\nnumerous anomaly scoring methods based on supervised or unsupervised learning\nhave been proposed, current approaches typically rely on a continuous stream of\nreal-world calibration data to provide assumption-free guarantees on the false\ndiscovery rate (FDR). To address the inherent challenges posed by limited real\ncalibration data, we introduce context-aware prediction-powered conformal\nonline anomaly detection (C-PP-COAD). Our framework strategically leverages\nsynthetic calibration data to mitigate data scarcity, while adaptively\nintegrating real data based on contextual cues. C-PP-COAD utilizes conformal\np-values, active p-value statistics, and online FDR control mechanisms to\nmaintain rigorous and reliable anomaly detection performance over time.\nExperiments conducted on both synthetic and real-world datasets demonstrate\nthat C-PP-COAD significantly reduces dependency on real calibration data\nwithout compromising guaranteed FDR control.", "published": "2025-05-03 10:58:05", "link": "http://arxiv.org/abs/2505.01783v1", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Improved ALOHA-based URA with Index Modulation: Efficient Decoding and Analysis", "abstract": "In this paper, an improved ALOHA-based unsourced random access (URA) scheme\nis proposed in MIMO channels. The channel coherent interval is divided into\nmultiple sub-slots and each active user selects several sub-slots to send its\ncodeword, namely, the channel access pattern. To be more specific, the data\nstream of each active user is divided into three parts. The first part is\nmapped as the compressed sensing (CS) pilot, which also serves for the\nconsequent channel estimation. The second part is modulated by binary phase\nshift keying (BPSK). The obtained CS pilot and the antipodal BPSK signal are\nconcatenated as its codeword. After that, the codeword of each active user is\nsent repeatedly based on its channel access pattern, which is determined by the\nthird part of the information bits, namely, index modulation (IM). On the\nreceiver side, a hard decision-based decoder is proposed which includes the CS\ndecoder, maximal likelihood (ML)-based superposed codeword decomposer (SCD),\nand IM demodulator. To further reduce the complexity of the proposed decoder, a\nsimplified SCD based on convex approximation is considered. The performance\nanalysis is also provided. The exhaustive computer simulations confirm the\nsuperiority of our proposal.", "published": "2025-05-03 07:45:01", "link": "http://arxiv.org/abs/2505.01728v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Sensing Safety Analysis for Vehicular Networks with Integrated Sensing and Communication (ISAC)", "abstract": "Integrated sensing and communication (ISAC) emerged as a key feature of\nnext-generation 6G wireless systems, allowing them to achieve high data rates\nand sensing accuracy. While prior research has primarily focused on addressing\ncommunication safety in ISAC systems, the equally critical issue of sensing\nsafety remains largely ignored. In this paper, a novel threat to the sensing\nsafety of ISAC vehicle networks is studied, whereby a malicious reconfigurable\nintelligent surface (RIS) is deployed to compromise the sensing functionality\nof a roadside unit (RSU). Specifically, a malicious attacker dynamically\nadjusts the phase shifts of an RIS to spoof the sensing outcomes of a vehicular\nuser (VU)'s echo delay, Doppler shift, and angle-of-departure (AoD). To achieve\nspoofing on Doppler shift estimation, a time-varying phase shift design on the\nRIS is proposed. Furthermore, the feasible spoofing frequency set with respect\nto the Doppler shift is analytical derived. Analytical results also demonstrate\nthat the maximum likelihood estimator (MLE) of the AoD can be significantly\nmisled under spoofed Doppler shift estimation. Simulation results validate our\ntheoretical findings, showing that the RIS can induce a spoofed velocity\nestimation from 0.1 m/s to 14.9 m/s for a VU with velocity of 10 m/s, and can\ncause an AoD estimation error of up to 65^{\\circ} with only a 5^{\\circ} beam\nmisalignment.", "published": "2025-05-03 04:39:57", "link": "http://arxiv.org/abs/2505.01688v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Resilient Vehicular Communications under Imperfect Channel State Information", "abstract": "Cellular vehicle-to-everything (C-V2X) networks provide a promising solution\nto improve road safety and traffic efficiency. One key challenge in such\nsystems lies in meeting quality-of-service (QoS) requirements of vehicular\ncommunication links given limited network resources, particularly under\nimperfect channel state information (CSI) conditions caused by the highly\ndynamic environment. In this paper, a novel two-phase framework is proposed to\ninstill resilience into C-V2X networks under unknown imperfect CSI. The\nresilience of the C-V2X network is defined, quantified, and optimized the first\ntime through two principal dimensions: absorption phase and adaptation phase.\nSpecifically, the probability distribution function (PDF) of the imperfect CSI\nis estimated during the absorption phase through dedicated absorption power\nscheme and resource block (RB) assignment. The estimated PDF is further used to\nanalyze the interplay and reveal the tradeoff between these two phases. Then, a\nnovel metric named hazard rate (HR) is exploited to balance the C-V2X network's\nprioritization on absorption and adaptation. Finally, the estimated PDF is\nexploited in the adaptation phase to recover the network's QoS through a\nreal-time power allocation optimization. Simulation results demonstrate the\nsuperior capability of the proposed framework in sustaining the QoS of the\nC-V2X network under imperfect CSI. Specifically, in the adaptation phase, the\nproposed design reduces the vehicle-tovehicle (V2V) delay that exceeds QoS\nrequirement by 35% and 56%, and improves the average vehicle-to-infrastructure\n(V2I) throughput by 14% and 16% compared to the model-based and data-driven\nbenchmarks, respectively, without compromising the network's QoS in the\nabsorption phase.", "published": "2025-05-03 04:33:56", "link": "http://arxiv.org/abs/2505.01687v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Act Natural! Extending Naturalistic Projection to Multimodal Behavior Scenarios", "abstract": "Autonomous agents operating in public spaces must consider how their\nbehaviors might affect the humans around them, even when not directly\ninteracting with them. To this end, it is often beneficial to be predictable\nand appear naturalistic. Existing methods for this purpose use human actor\nintent modeling or imitation learning techniques, but these approaches rarely\ncapture all possible motivations for human behavior and/or require significant\namounts of data. Our work extends a technique for modeling unimodal\nnaturalistic behaviors with an explicit convex set representation, to account\nfor multimodal behavior by using multiple convex sets. This more flexible\nrepresentation provides a higher degree of fidelity in data-driven modeling of\nnaturalistic behavior that arises in real-world scenarios in which human\nbehavior is, in some sense, discrete, e.g. whether or not to yield at a\nroundabout. Equipped with this new set representation, we develop an\noptimization-based filter to project arbitrary trajectories into the set so\nthat they appear naturalistic to humans in the scene, while also satisfying\nvehicle dynamics, actuator limits, etc. We demonstrate our methods on\nreal-world human driving data from the inD (intersection) and rounD\n(roundabout) datasets.", "published": "2025-05-03 23:28:46", "link": "http://arxiv.org/abs/2505.01945v1", "categories": ["cs.MA", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Pathfinders in the Sky: Formal Decision-Making Models for Collaborative Air Traffic Control in Convective Weather", "abstract": "Air traffic can be significantly disrupted by weather. Pathfinder operations\ninvolve assigning a designated aircraft to assess whether airspace that was\npreviously impacted by weather can be safely traversed through. Despite\nrelatively routine use in air traffic control, there is little research on the\nunderlying multi-agent decision-making problem. We seek to address this gap\nherein by formulating decision models to capture the operational dynamics and\nimplications of pathfinders. Specifically, we construct a Markov chain to\nrepresent the stochastic transitions between key operational states (e.g.,\npathfinder selection). We then analyze its steady-state behavior to understand\nlong-term system dynamics. We also propose models to characterize\nflight-specific acceptance behaviors (based on utility trade-offs) and\npathfinder selection strategies (based on sequential offer allocations). We\nthen conduct a worst-case scenario analysis that highlights risks from\ncollective rejection and explores how selfless behavior and uncertainty affect\nsystem resilience. Empirical analysis of data from the US Federal Aviation\nAdministration demonstrates the real-world significance of pathfinder\noperations and informs future model calibration.", "published": "2025-05-03 12:20:24", "link": "http://arxiv.org/abs/2505.01804v1", "categories": ["cs.MA", "math.OC"], "primary_category": "cs.MA"}
{"title": "On the Design of Resilient Distributed Single Time-Scale Estimators: A Graph-Theoretic Approach", "abstract": "Distributed estimation in interconnected systems has gained increasing\nattention due to its relevance in diverse applications such as sensor networks,\nautonomous vehicles, and cloud computing. In real practice, the sensor network\nmay suffer from communication and/or sensor failures. This might be due to\ncyber-attacks, faults, or environmental conditions. Distributed estimation\nresilient to such conditions is the topic of this paper. By representing the\nsensor network as a graph and exploiting its inherent structural properties, we\nintroduce novel techniques that enhance the robustness of distributed\nestimators. As compared to the literature, the proposed estimator (i) relaxes\nthe network connectivity of most existing single time-scale estimators and (ii)\nreduces the communication load of the existing double time-scale estimators by\navoiding the inner consensus loop.\n  On the other hand, the sensors might be subject to faults or attacks,\nresulting in biased measurements. Removing these sensor data may result in\nobservability loss. Therefore, we propose resilient design on the definitions\nof $q$-node-connectivity and $q$-link-connectivity, which capture robust\nstrong-connectivity under link or sensor node failure. By proper design of the\nsensor network, we prove Schur stability of the proposed distributed estimation\nprotocol under failure of up to $q$ sensors or $q$ communication links.", "published": "2025-05-03 09:16:44", "link": "http://arxiv.org/abs/2505.01757v1", "categories": ["eess.SY", "cs.DC", "cs.MA", "cs.SY", "eess.SP", "math.OC"], "primary_category": "eess.SY"}
{"title": "Human-AI Governance (HAIG): A Trust-Utility Approach", "abstract": "This paper introduces the HAIG framework for analysing trust dynamics across\nevolving human-AI relationships. Current categorical frameworks (e.g.,\n\"human-in-the-loop\" models) inadequately capture how AI systems evolve from\ntools to partners, particularly as foundation models demonstrate emergent\ncapabilities and multi-agent systems exhibit autonomous goal-setting\nbehaviours. As systems advance, agency redistributes in complex patterns that\nare better represented as positions along continua rather than discrete\ncategories, though progression may include both gradual shifts and significant\nstep changes. The HAIG framework operates across three levels: dimensions\n(Decision Authority Distribution, Process Autonomy, and Accountability\nConfiguration), continua (gradual shifts along each dimension), and thresholds\n(critical points requiring governance adaptation). Unlike risk-based or\nprinciple-based approaches, HAIG adopts a trust-utility orientation, focusing\non maintaining appropriate trust relationships that maximise utility while\nensuring sufficient safeguards. Our analysis reveals how technical advances in\nself-supervision, reasoning authority, and distributed decision-making drive\nnon-uniform trust evolution across both contextual variation and technological\nadvancement. Case studies in healthcare and European regulation demonstrate how\nHAIG complements existing frameworks while offering a foundation for\nalternative approaches that anticipate governance challenges before they\nemerge.", "published": "2025-05-03 01:57:08", "link": "http://arxiv.org/abs/2505.01651v1", "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MA", "cs.SI"], "primary_category": "cs.AI"}
{"title": "3D neuron growth and neurodevelopmental disorder modeling based on truncated hierarchical B-splines with multi-level local refinements", "abstract": "3D neuron growth and neurodevelopmental disorders (NDDs) deterioration\nexhibit complex morphological transformations as neurites differentiate into\naxons and dendrites, forming intricate networks driven by tubulin\nconcentrations and neurotrophin signals. Conventional 2D models fall short of\ncapturing such morphological complexity, prompting the need and development of\nadvanced 3D computational approaches. In this paper, we present a complex 3D\nneuron growth model based on isogeometric analysis (IGA) and the phase field\nmethod, utilizing locally refined truncated hierarchical B-splines\n(THB-splines). IGA offers isoparametric representation and higher-order\ncontinuity, which are essential for simulating the smooth, evolving interfaces\nof phase field neurites. In contrast, the phase field method can automatically\nhandle diffuse interfaces and complex topological changes without explicit\nboundary tracking. This IGA-based phase field method enables accurate and\nefficient simulation of neurite extensions, branching, and retraction in a\nfully 3D setting. The THB-spline implementation supports multi-level local\nrefinement, focusing computational resources on regions of active growth, while\ndynamic domain expansion adapts the simulation domain to extend with growing\nneurites. KD-tree-based interpolation ensures that phase field variables are\naccurately transferred onto newly refined meshes. NDDs associated neurite\ndeterioration is simulated by modulating the driving force term within the\nphase field model to induce interface retraction. This comprehensive 3D\nframework enhances the accuracy of neurite morphology simulations, advancing\nthe study of complex neuron development, network formation and NDDs.", "published": "2025-05-03 22:24:41", "link": "http://arxiv.org/abs/2505.01940v1", "categories": ["physics.med-ph", "cs.NA", "math.NA"], "primary_category": "physics.med-ph"}
{"title": "Priorconditioned Sparsity-Promoting Projection Methods for Deterministic and Bayesian Linear Inverse Problems", "abstract": "High-quality reconstructions of signals and images with sharp edges are\nneeded in a wide range of applications. To overcome the large dimensionality of\nthe parameter space and the complexity of the regularization functional,\n{sparisty-promoting} techniques for both deterministic and hierarchical\nBayesian regularization rely on solving a sequence of high-dimensional\niteratively reweighted least squares (IRLS) problems on a lower-dimensional\nsubspace. Generalized Krylov subspace (GKS) methods are a particularly potent\nclass of hybrid Krylov schemes that efficiently solve sequences of IRLS\nproblems by projecting large-scale problems into a relatively small subspace\nand successively enlarging it. We refer to methods that promote sparsity and\nuse GKS as S-GKS. A disadvantage of S-GKS methods is their slow convergence. In\nthis work, we propose techniques that improve the convergence of S-GKS methods\nby combining them with priorconditioning, which we refer to as PS-GKS.\nSpecifically, integrating the PS-GKS method into the IAS algorithm allows us to\nautomatically select the shape/rate parameter of the involved generalized gamma\nhyper-prior, which is often fine-tuned otherwise. Furthermore, we proposed and\ninvestigated variations of the proposed PS-GKS method, including restarting and\nrecycling (resPS-GKS and recPS-GKS). These respectively leverage restarted and\nrecycled subspaces to overcome situations when memory limitations of storing\nthe basis vectors are a concern. We provide a thorough theoretical analysis\nshowing the benefits of priorconditioning for sparsity-promoting inverse\nproblems. Numerical experiment are used to illustrate that the proposed PS-GKS\nmethod and its variants are competitive with or outperform other existing\nhybrid Krylov methods.", "published": "2025-05-03 14:06:36", "link": "http://arxiv.org/abs/2505.01827v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Surrogate to Poincar\u00e9 inequalities on manifolds for dimension reduction in nonlinear feature spaces", "abstract": "We aim to approximate a continuously differentiable function $u:\\mathbb{R}^d\n\\rightarrow \\mathbb{R}$ by a composition of functions $f\\circ g$ where\n$g:\\mathbb{R}^d \\rightarrow \\mathbb{R}^m$, $m\\leq d$, and $f : \\mathbb{R}^m\n\\rightarrow \\mathbb{R}$ are built in a two stage procedure. For a fixed $g$, we\nbuild $f$ using classical regression methods, involving evaluations of $u$.\nRecent works proposed to build a nonlinear $g$ by minimizing a loss function\n$\\mathcal{J}(g)$ derived from Poincar\\'e inequalities on manifolds, involving\nevaluations of the gradient of $u$. A problem is that minimizing $\\mathcal{J}$\nmay be a challenging task. Hence in this work, we introduce new convex\nsurrogates to $\\mathcal{J}$. Leveraging concentration inequalities, we provide\nsub-optimality results for a class of functions $g$, including polynomials, and\na wide class of input probability measures. We investigate performances on\ndifferent benchmarks for various training sample sizes. We show that our\napproach outperforms standard iterative methods for minimizing the training\nPoincar\\'e inequality based loss, often resulting in better approximation\nerrors, especially for rather small training sets and $m=1$.", "published": "2025-05-03 12:37:27", "link": "http://arxiv.org/abs/2505.01807v1", "categories": ["math.NA", "cs.LG", "cs.NA", "65D40, 65D15, 41A10, 41A63, 60F10"], "primary_category": "math.NA"}
{"title": "Multilayer Perceptron Neural Network Models in Asset Pricing: An Empirical Study on Large-Cap US Stocks", "abstract": "In this study, MLP models with dynamic structure are applied to factor models\nfor asset pricing tasks. Concretely, the MLP pyramid model structure was\nemployed on firm-characteristic-sorted portfolio factors for modelling the\nlarge-capital US stocks. It was further developed as a practicable factor\ninvesting strategy based on the predictions. The main findings in this chapter\nwere evaluated from two angles: model performance and investing performance,\nwhich were compared from the periods with and without COVID-19. The empirical\nresults indicated that with the restrictions of the data size, the MLP models\nno longer perform \"deeper, better\", while the proposed MLP models with two and\nthree hidden layers have higher flexibility to model the factors in this case.\nThis study also verified the idea of previous works that MLP models for factor\ninvesting have more meaning in the downside risk control than in pursuing the\nabsolute annual returns.", "published": "2025-05-03 20:55:40", "link": "http://arxiv.org/abs/2505.01921v1", "categories": ["q-fin.PR", "q-fin.CP", "q-fin.RM", "91G10, 91G60, 62M45, 62P05", "J.4; G.3; I.2.6"], "primary_category": "q-fin.PR"}
{"title": "Meyer-Zheng topology and multi-asset behavioral portfolio selection under transaction costs", "abstract": "The paper addresses a singular control problem, where controls are processes\nof finite variation, with a focus on portfolio investment under transaction\ncosts. We establish the existence of an optimal strategy in the class of\nrandomized strategies for a range of goal functionals, including cumulative\nprospect theory preferences, subject to the nonnegativity constraint on the\nportfolio wealth. Unlike the existing approaches, we employ a metrizable\nMeyer-Zheng topology. Additionally, we investigate the applicability of the\nSkorokhod convergence for processes, adapted to a specific filtration. The\npresented framework provides a clear distinction between constraints imposed on\nthe market model and on the goal functional.", "published": "2025-05-03 17:37:28", "link": "http://arxiv.org/abs/2505.01876v1", "categories": ["q-fin.MF", "math.PR", "60B10 (Primary), 91G10, 93E20 (Secondary)"], "primary_category": "q-fin.MF"}
{"title": "Faster logconcave sampling from a cold start in high dimension", "abstract": "We present a faster algorithm to generate a warm start for sampling an\narbitrary logconcave density specified by an evaluation oracle, leading to the\nfirst sub-cubic sampling algorithms for inputs in (near-)isotropic position. A\nlong line of prior work incurred a warm-start penalty of at least linear in the\ndimension, hitting a cubic barrier, even for the special case of uniform\nsampling from convex bodies.\n  Our improvement relies on two key ingredients of independent interest. (1) We\nshow how to sample given a warm start in weaker notions of distance, in\nparticular $q$-R\\'enyi divergence for $q=\\widetilde{\\mathcal{O}}(1)$, whereas\nprevious analyses required stringent $\\infty$-R\\'enyi divergence (with the\nexception of Hit-and-Run, whose known mixing time is higher). This marks the\nfirst improvement in the required warmness since Lov\\'asz and Simonovits\n(1991). (2) We refine and generalize the log-Sobolev inequality of Lee and\nVempala (2018), originally established for isotropic logconcave distributions\nin terms of the diameter of the support, to logconcave distributions in terms\nof a geometric average of the support diameter and the largest eigenvalue of\nthe covariance matrix.", "published": "2025-05-03 22:14:04", "link": "http://arxiv.org/abs/2505.01937v1", "categories": ["cs.DS", "cs.LG", "math.FA", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.DS"}
{"title": "Bayesian learning of the optimal action-value function in a Markov decision process", "abstract": "The Markov Decision Process (MDP) is a popular framework for sequential\ndecision-making problems, and uncertainty quantification is an essential\ncomponent of it to learn optimal decision-making strategies. In particular, a\nBayesian framework is used to maintain beliefs about the optimal decisions and\nthe unknown ingredients of the model, which are also to be learned from the\ndata, such as the rewards and state dynamics. However, many existing Bayesian\napproaches for learning the optimal decision-making strategy are based on\nunrealistic modelling assumptions and utilise approximate inference techniques.\nThis raises doubts whether the benefits of Bayesian uncertainty quantification\nare fully realised or can be relied upon.\n  We focus on infinite-horizon and undiscounted MDPs, with finite state and\naction spaces, and a terminal state. We provide a full Bayesian framework, from\nmodelling to inference to decision-making. For modelling, we introduce a\nlikelihood function with minimal assumptions for learning the optimal\naction-value function based on Bellman's optimality equations, analyse its\nproperties, and clarify connections to existing works. For deterministic\nrewards, the likelihood is degenerate and we introduce artificial observation\nnoise to relax it, in a controlled manner, to facilitate more efficient Monte\nCarlo-based inference. For inference, we propose an adaptive sequential Monte\nCarlo algorithm to both sample from and adjust the sequence of relaxed\nposterior distributions. For decision-making, we choose actions using samples\nfrom the posterior distribution over the optimal strategies. While commonly\ndone, we provide new insight that clearly shows that it is a generalisation of\nThompson sampling from multi-arm bandit problems. Finally, we evaluate our\nframework on the Deep Sea benchmark problem and demonstrate the exploration\nbenefits of posterior sampling in MDPs.", "published": "2025-05-03 16:37:14", "link": "http://arxiv.org/abs/2505.01859v1", "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Rank-One Modified Value Iteration", "abstract": "In this paper, we provide a novel algorithm for solving planning and learning\nproblems of Markov decision processes. The proposed algorithm follows a policy\niteration-type update by using a rank-one approximation of the transition\nprobability matrix in the policy evaluation step. This rank-one approximation\nis closely related to the stationary distribution of the corresponding\ntransition probability matrix, which is approximated using the power method. We\nprovide theoretical guarantees for the convergence of the proposed algorithm to\noptimal (action-)value function with the same rate and computational complexity\nas the value iteration algorithm in the planning problem and as the Q-learning\nalgorithm in the learning problem. Through our extensive numerical simulations,\nhowever, we show that the proposed algorithm consistently outperforms\nfirst-order algorithms and their accelerated versions for both planning and\nlearning problems.", "published": "2025-05-03 14:06:50", "link": "http://arxiv.org/abs/2505.01828v1", "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "math.OC"}
{"title": "TV-SurvCaus: Dynamic Representation Balancing for Causal Survival Analysis", "abstract": "Estimating the causal effect of time-varying treatments on survival outcomes\nis a challenging task in many domains, particularly in medicine where treatment\nprotocols adapt over time. While recent advances in representation learning\nhave improved causal inference for static treatments, extending these methods\nto dynamic treatment regimes with survival outcomes remains under-explored. In\nthis paper, we introduce TV-SurvCaus, a novel framework that extends\nrepresentation balancing techniques to the time-varying treatment setting for\nsurvival analysis. We provide theoretical guarantees through (1) a generalized\nbound for time-varying precision in estimation of heterogeneous effects, (2)\nvariance control via sequential balancing weights, (3) consistency results for\ndynamic treatment regimes, (4) convergence rates for representation learning\nwith temporal dependencies, and (5) a formal bound on the bias due to\ntreatment-confounder feedback. Our neural architecture incorporates sequence\nmodeling to handle temporal dependencies while balancing time-dependent\nrepresentations. Through extensive experiments on both synthetic and real-world\ndatasets, we demonstrate that TV-SurvCaus outperforms existing methods in\nestimating individualized treatment effects with time-varying covariates and\ntreatments. Our framework advances the field of causal inference by enabling\nmore accurate estimation of treatment effects in dynamic, longitudinal settings\nwith survival outcomes.", "published": "2025-05-03 11:04:52", "link": "http://arxiv.org/abs/2505.01785v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Fast Likelihood-Free Parameter Estimation for L\u00e9vy Processes", "abstract": "L\\'evy processes are widely used in financial modeling due to their ability\nto capture discontinuities and heavy tails, which are common in high-frequency\nasset return data. However, parameter estimation remains a challenge when\nassociated likelihoods are unavailable or costly to compute. We propose a fast\nand accurate method for L\\'evy parameter estimation using the neural Bayes\nestimation (NBE) framework -- a simulation-based, likelihood-free approach that\nleverages permutation-invariant neural networks to approximate Bayes\nestimators. Through extensive simulations across several L\\'evy models, we show\nthat NBE outperforms traditional methods in both accuracy and runtime, while\nalso enabling rapid bootstrap-based uncertainty quantification. We illustrate\nour approach on a challenging high-frequency cryptocurrency return dataset,\nwhere the method captures evolving parameter dynamics and delivers reliable and\ninterpretable inference at a fraction of the computational cost of traditional\nmethods. NBE provides a scalable and practical solution for inference in\ncomplex financial models, enabling parameter estimation and uncertainty\nquantification over an entire year of data in just seconds. We additionally\ninvestigate nearly a decade of high-frequency Bitcoin returns, requiring less\nthan one minute to estimate parameters under the proposed approach.", "published": "2025-05-03 00:37:58", "link": "http://arxiv.org/abs/2505.01639v1", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Weakly-supervised Audio Temporal Forgery Localization via Progressive Audio-language Co-learning Network", "abstract": "Audio temporal forgery localization (ATFL) aims to find the precise forgery\nregions of the partial spoof audio that is purposefully modified. Existing ATFL\nmethods rely on training efficient networks using fine-grained annotations,\nwhich are obtained costly and challenging in real-world scenarios. To meet this\nchallenge, in this paper, we propose a progressive audio-language co-learning\nnetwork (LOCO) that adopts co-learning and self-supervision manners to prompt\nlocalization performance under weak supervision scenarios. Specifically, an\naudio-language co-learning module is first designed to capture forgery\nconsensus features by aligning semantics from temporal and global perspectives.\nIn this module, forgery-aware prompts are constructed by using utterance-level\nannotations together with learnable prompts, which can incorporate semantic\npriors into temporal content features dynamically. In addition, a forgery\nlocalization module is applied to produce forgery proposals based on fused\nforgery-class activation sequences. Finally, a progressive refinement strategy\nis introduced to generate pseudo frame-level labels and leverage supervised\nsemantic contrastive learning to amplify the semantic distinction between real\nand fake content, thereby continuously optimizing forgery-aware features.\nExtensive experiments show that the proposed LOCO achieves SOTA performance on\nthree public benchmarks.", "published": "2025-05-03 17:57:57", "link": "http://arxiv.org/abs/2505.01880v1", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "FLOWER: Flow-Based Estimated Gaussian Guidance for General Speech Restoration", "abstract": "We introduce FLOWER, a novel conditioning method designed for speech\nrestoration that integrates Gaussian guidance into generative frameworks. By\ntransforming clean speech into a predefined prior distribution (e.g., Gaussian\ndistribution) using a normalizing flow network, FLOWER extracts critical\ninformation to guide generative models. This guidance is incorporated into each\nblock of the generative network, enabling precise restoration control.\nExperimental results demonstrate the effectiveness of FLOWER in improving\nperformance across various general speech restoration tasks.", "published": "2025-05-03 08:57:10", "link": "http://arxiv.org/abs/2505.01750v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Low-Complexity Acoustic Scene Classification with Device Information in the DCASE 2025 Challenge", "abstract": "This paper presents the Low-Complexity Acoustic Scene Classification with\nDevice Information Task of the DCASE 2025 Challenge and its baseline system.\nContinuing the focus on low-complexity models, data efficiency, and device\nmismatch from previous editions (2022--2024), this year's task introduces a key\nchange: recording device information is now provided at inference time. This\nenables the development of device-specific models that leverage device\ncharacteristics -- reflecting real-world deployment scenarios in which a model\nis designed with awareness of the underlying hardware. The training set matches\nthe 25% subset used in the corresponding DCASE 2024 challenge, with no\nrestrictions on external data use, highlighting transfer learning as a central\ntopic. The baseline achieves 50.72% accuracy on this ten-class problem with a\ndevice-general model, improving to 51.89% when using the available device\ninformation.", "published": "2025-05-03 08:52:18", "link": "http://arxiv.org/abs/2505.01747v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Predictive and Proactive Power Allocation For Energy Efficiency in Dynamic OWC Networks", "abstract": "Driven by the exponential growth in data traffic and the limitations of Radio\nFrequency (RF) networks, Optical Wireless Communication (OWC) has emerged as a\npromising solution for high data rate communication. However, the inherently\ndynamic nature of OWC environments resulting from user mobility, and\ntime-varying user demands poses significant challenges for enhanced and\nsustainable performance. Energy efficiency (EE) is a critical metric for the\nsustainable operation of next generation wireless networks. Achieving high EE\nin dynamic OWC environments, especially under time-varying user distributions\nand heterogeneous service requirements, remains a complex task. In this work,\nwe formulate a discrete-time EE optimisation problem in a dynamic OWC to\nmaximise energy efficiency through determining user connectivity and power\nallocation. Solving this problem in real time is computationally demanding due\nto the coupling of user association and power allocation variables over\ndiscrete time slots. Therefore, we propose a Probabilistic Demand Prediction\nand Optimised Power Allocation (PDP-OPA) framework which predicts user\narrivals, departures, and traffic demands. Based on these predictions, the\nframework proactively determines AP-user associations and allocates power\ndynamically using a Lagrangian-based optimisation strategy. Simulation results\ndemonstrate that the proposed PDP-OPA significantly enhances system\nperformance, providing solutions close to the optimal ones. The proposed\nframework improves energy efficiency, sum rate, and bit error rate (BER)\ncompared to distance-based user association and uniform power allocation,\nvalidating its effectiveness for real time and adaptive resource management in\ndynamic OWC systems.", "published": "2025-05-03 20:28:53", "link": "http://arxiv.org/abs/2505.01916v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Securing 5G and Beyond-Enabled UAV Networks: Resilience Through Multiagent Learning and Transformers Detection", "abstract": "Achieving resilience remains a significant challenge for Unmanned Aerial\nVehicle (UAV) communications in 5G and 6G networks. Although UAVs benefit from\nsuperior positioning capabilities, rate optimization techniques, and extensive\nline-of-sight (LoS) range, these advantages alone cannot guarantee high\nreliability across diverse UAV use cases. This limitation becomes particularly\nevident in urban environments, where UAVs face vulnerability to jamming attacks\nand where LoS connectivity is frequently compromised by buildings and other\nphysical obstructions. This paper introduces DET-FAIR- WINGS (\nDetection-Enhanced Transformer Framework for AI-Resilient Wireless Networks in\nGround UAV Systems), a novel solution designed to enhance reliability in UAV\ncommunications under attacks. Our system leverages multi-agent reinforcement\nlearning (MARL) and transformer-based detection algorithms to identify attack\npatterns within the network and subsequently select the most appropriate\nmechanisms to strengthen reliability in authenticated UAV-Base Station links.\nThe DET-FAIR-WINGS approach integrates both discrete and continuous parameters.\nDiscrete parameters include retransmission attempts, bandwidth partitioning,\nand notching mechanisms, while continuous parameters encompass beam angles and\nelevations from both the Base Station (BS) and user devices. The detection part\nintegrates a transformer in the agents to speed up training. Our findings\ndemonstrate that replacing fixed retransmission counts with AI-integrated\nflexible approaches in 5G networks significantly reduces latency by optimizing\ndecision-making processes within 5G layers.", "published": "2025-05-03 18:27:00", "link": "http://arxiv.org/abs/2505.01885v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Artificial Intelligence implementation of onboard flexible payload and adaptive beamforming using commercial off-the-shelf devices", "abstract": "Very High Throughput satellites typically provide multibeam coverage,\nhowever, a common problem is that there can be a mismatch between the capacity\nof each beam and the traffic demand: some beams may fall short, while others\nexceed the requirements. This challenge can be addressed by integrating machine\nlearning with flexible payload and adaptive beamforming techniques. These\nmethods allow for dynamic allocation of payload resources based on real-time\ncapacity needs. As artificial intelligence advances, its ability to automate\ntasks, enhance efficiency, and increase precision is proving invaluable,\nespecially in satellite communications, where traditional optimization methods\nare often computationally intensive. AI-driven solutions offer faster, more\neffective ways to handle complex satellite communication tasks. Artificial\nintelligence in space has more constraints than other fields, considering the\nradiation effects, the spaceship power capabilities, mass, and area. Current\nonboard processing uses legacy space-certified general-purpose processors,\ncostly application-specific integrated circuits, or field-programmable gate\narrays subjected to a highly stringent certification process. The increased\nperformance demands of onboard processors to satisfy the accelerated data rates\nand autonomy requirements have rendered current space-graded processors\nobsolete. This work is focused on transforming the satellite payload using\nartificial intelligence and machine learning methodologies over available\ncommercial off-the-shelf chips for onboard processing. The objectives include\nvalidating artificial intelligence-driven scenarios, focusing on flexible\npayload and adaptive beamforming as machine learning models onboard. Results\nshow that machine learning models significantly improve signal quality,\nspectral efficiency, and throughput compared to conventional payload.", "published": "2025-05-03 16:13:42", "link": "http://arxiv.org/abs/2505.01853v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Near-field 5D Pose Estimation using Reconfigurable Intelligent Surfaces", "abstract": "The advent of 6G is expected to enable many use cases which may rely on\naccurate knowledge of the location and orientation of user equipment (UE). The\nconventional localization methods suffer from limitations such as\nsynchronization and high power consumption required for multiple active\nanchors. This can be mitigated by utilizing a large dimensional passive\nreconfigurable intelligent surface (RIS). This paper presents a novel\nlow-complexity approach for the estimation of 5D pose (i.e. 3D location and 2D\norientation) of a UE in near-field RIS-assisted multiple-input multiple-output\n(MIMO) systems. The proposed approach exploits the symmetric arrangement of\nuniform planar array of RIS and uniform linear array of UE to decouple the 5D\nproblem into five 1D sub-problems. Further, we solve these sub-problems using a\ntotal least squares ESPRIT inspired approach to obtain closed-form solutions.", "published": "2025-05-03 14:10:58", "link": "http://arxiv.org/abs/2505.01829v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Rate-Limited Closed-Loop Distributed ISAC Systems: An Autoencoder Approach", "abstract": "In closed-loop distributed multi-sensor integrated sensing and communication\n(ISAC) systems, performance often hinges on transmitting high-dimensional\nsensor observations over rate-limited networks. In this paper, we first present\na general framework for rate-limited closed-loop distributed ISAC systems, and\nthen propose an autoencoder-based observation compression method to overcome\nthe constraints imposed by limited transmission capacity. Building on this\nframework, we conduct a case study using a closed-loop linear quadratic\nregulator (LQR) system to analyze how the interplay among observation,\ncompression, and state dimensions affects reconstruction accuracy, state\nestimation error, and control performance. In multi-sensor scenarios, our\nresults further show that optimal resource allocation initially prioritizes\nlow-noise sensors until the compression becomes lossless, after which resources\nare reallocated to high-noise sensors.", "published": "2025-05-03 10:52:39", "link": "http://arxiv.org/abs/2505.01780v1", "categories": ["eess.SP", "cs.AI", "cs.NI", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Spreading the Wave: Low-Complexity PAPR Reduction for AFDM and OCDM in 6G Networks", "abstract": "High Peak-to-Average Power Ratio (PAPR) is still a common issue in\nmulticarrier signal modulation systems such as Orthogonal Chirp Division\nMultiplexing (OCDM) and Affine Frequency Division Multiplexing (AFDM), which\nare envisioned to play a central role in 6G networks. To this end, this paper\naims to investigate a novel and low-complexity solution towards minimizing the\nPAPR with the aid of a unified premodulation data spreading paradigm. It\nanalyze four spreading techniques namely, Walsh-Hadamard transform (WHT),\nDiscrete Cosine transform (DCT), Zadoff-Chu transform (ZC), and Interleaved\nDiscrete Fourier transform (IDFT), which assist in preallocating energy prior\nto OCDM and AFDM modulation. The proposed method takes advantage of the\ninherent characteristics of chirp-based modulation to achieve a notable\nreduction in PAPR at minimal computational load and no side information as\ncompared to past solutions, such as Partial Transmit Sequence (PTS) or Selected\nMapping (SLM), which suffers with a high computational complexity. The proposed\nmethod has an additional benefit of achieving an improvement in phase\nselectivity by increasing chirp parameters of AFDM and quadratic phase of OCDM,\nwhich amplifies the robustness in doubly dispersive channels. It further\nreduces interference by smoothing the output spread signal. The analytical and\nsimulation results demonstrate an improvement in the overall energy efficiency\nand scalability of large ioT sensor networks.", "published": "2025-05-03 10:37:35", "link": "http://arxiv.org/abs/2505.01778v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Pinching Antenna-enabled ISAC Systems: Exploiting Look-Angle Dependence of RCS for Target Diversity", "abstract": "We investigate a novel integrated sensing and communication (ISAC) system\nsupported by pinching antennas (PAs), which can be dynamically activated along\na dielectric waveguide to collect spatially diverse observations. This\ncapability allows different PAs to view the same target from different angles\nacross time, thereby introducing target diversity, which is a key advantage\nover conventional fixed antenna arrays. To quantify the sensing reliability, we\nadopt the outage probability as a performance metric, capturing the likelihood\nthat the accumulated radar echo signal power falls below a detection threshold.\nIn contrast to traditional ISAC models that assume deterministic sensing\nchannels, we explicitly account for the look-angle dependence of radar\ncross-section (RCS) by modeling it as a random variable. We ensure the\nlong-term quality-of-service (QoS) for communication users by enforcing an\naccumulated data rate constraint over time. We derive an exact closed-form\nexpression for the sensing outage probability based on the distribution of\nweighted sums of exponentially distributed random variables. Since the\nresulting expression is highly non-convex and intractable for optimization, we\nuse a tractable upper bound based on the Chernoff inequality and formulate a PA\nactivation optimization problem. A successive convex approximation (SCA)\nframework is proposed to efficiently solve the formulated problem. Numerical\nresults show that dynamically activating different PAs across time slots\nsignificantly enhances sensing reliability compared to repeatedly activating\nthe same PA at a fixed position and conventional antenna selection schemes,\nrespectively. These findings highlight the benefits of integrating outage-based\nreliability metrics and target diversity into ISAC systems using PAs.", "published": "2025-05-03 10:32:23", "link": "http://arxiv.org/abs/2505.01777v1", "categories": ["eess.SP", "math.OC"], "primary_category": "eess.SP"}
{"title": "Real-Time, Single-Ear, Wearable ECG Reconstruction, R-Peak Detection, and HR/HRV Monitoring", "abstract": "Biosignal monitoring, in particular heart activity through heart rate (HR)\nand heart rate variability (HRV) tracking, is vital in enabling continuous,\nnon-invasive tracking of physiological and cognitive states. Recent studies\nhave explored compact, head-worn devices for HR and HRV monitoring to improve\nusability and reduce stigma. However, this approach is challenged by the\ncurrent reliance on wet electrodes, which limits usability, the weakness of\near-derived signals, making HR/HRV extraction more complex, and the\nincompatibility of current algorithms for embedded deployment. This work\nintroduces a single-ear wearable system for real-time ECG (Electrocardiogram)\nparameter estimation, which directly runs on BioGAP, an energy-efficient device\nfor biosignal acquisition and processing. By combining SoA in-ear electrode\ntechnology, an optimized DeepMF algorithm, and BioGAP, our proposed\nsubject-independent approach allows for robust extraction of HR/HRV parameters\ndirectly on the device with just 36.7 uJ/inference at comparable performance\nwith respect to the current state-of-the-art architecture, achieving 0.49 bpm\nand 25.82 ms for HR/HRV mean errors, respectively and an estimated battery life\nof 36h with a total system power consumption of 7.6 mW. Clinical relevance: The\nability to reconstruct ECG signals and extract HR and HRV paves the way for\ncontinuous, unobtrusive cardiovascular monitoring with head-worn devices. In\nparticular, the integration of cardiovascular measurements in everyday-use\ndevices (such as earbuds) has potential in continuous at-home monitoring to\nenable early detection of cardiovascular irregularities.", "published": "2025-05-03 08:28:26", "link": "http://arxiv.org/abs/2505.01738v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "A brain-inspired generative model for EEG-based cognitive state identification", "abstract": "This article proposes a brain-inspired generative (BIG) model that merges an\nimpulsive-attention neural network and a variational autoencoder (VAE) for\nidentifying cognitive states based on electroencephalography (EEG) data. A\nhybrid learning method is presented for training the model by integrating\ngradient-based learning and heteroassociative memory. The BIG model is capable\nof achieving multi-task objectives: classification, generating new EEG, and\nbrain network interpretation, alleviating the limitations of excessive data\ntraining and high computational cost in conventional approaches. Experimental\nresults on two public EEG datasets demonstrate that the BIG model achieves a\nclassification accuracy above 89\\%, comparable with state-of-the-art methods,\nwhile reducing computational cost by nearly 11\\% over the baseline EEGNet.\nIncorporating the generated EEG data for training, the BIG model exhibits\ncomparative performance in a few-shot pattern.Ablation studies justify the\npoised brain-inspired characteristic regarding the impulsive-attention module\nand the hybrid learning method. Thanks to the performance advantages with\ninterpretable outputs, this BIG model has application potential for building\ndigital twins of the brain.", "published": "2025-05-03 04:29:27", "link": "http://arxiv.org/abs/2505.01685v1", "categories": ["eess.SP", "cs.NE"], "primary_category": "eess.SP"}
{"title": "Data-Driven Structural State Estimation via Multi-Fidelity Gaussian Process Models", "abstract": "Guided wave-based techniques have been used extensively in Structural Health\nMonitoring (SHM). Models using guided waves can provide information from both\ntime and frequency domains to make themselves accurate and robust.\nProbabilistic SHM models, which have the ability to account for uncertainties,\nare developed when decision confidence intervals are of interest. Most\nactive-sensing guided-wave methods rely on the assumption that a large dataset\ncan be collected, making them impractical when data collection is constrained\nby time or environmental factors. Meanwhile, although simulation results may\nlack the accuracy of real-world data, they are easier to obtain. In this\ncontext, models that integrate data from multiple sources have the potential to\ncombine the accuracy of experimental data with the convenience of simulated\ndata, without requiring large and potentially costly experimental datasets. The\ngoal of this work is to introduce and assess a probabilistic multi-fidelity\nGaussian process regression framework for damage state estimation via the use\nof both experimental and simulated guided waves. The main differences from\nprevious works include the integration of damage-sensitive features (damage\nindices, DIs) extracted from both experimental and numerical sources, as well\nas the use of a relatively small amount of real-world data. The proposed model\nwas validated by two test cases where multiple data sources exist. For each\ntest case, experimental data were collected from a piezoelectric sensor network\nattached to an aluminum plate with various structural conditions, while\nsimulated data were generated using either multiphysics finite element model\n(FEM) or physics-based signal reconstruction approaches under the same\nconditions.", "published": "2025-05-03 03:29:44", "link": "http://arxiv.org/abs/2505.01666v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Understanding the Mechanisms Behind Structural Influences on Link Prediction: A Case Study on FB15k-237", "abstract": "FB15k-237 mitigates the data leakage issue by excluding inverse and symmetric\nrelationship triples, however, this has led to substantial performance\ndegradation and slow improvement progress. Traditional approaches demonstrate\nlimited effectiveness on FB15k-237, primarily because the underlying mechanism\nby which structural features of the dataset influence model performance remains\nunexplored. To bridge this gap, we systematically investigate the impact\nmechanism of dataset structural features on link prediction performance.\nFirstly, we design a structured subgraph sampling strategy that ensures\nconnectivity while constructing subgraphs with distinct structural features.\nThen, through correlation and sensitivity analyses conducted across several\nmainstream models, we observe that the distribution of relationship categories\nwithin subgraphs significantly affects performance, followed by the size of\nstrongly connected components. Further exploration using the LIME model\nclarifies the intrinsic mechanism by which relationship categories influence\nlink prediction performance, revealing that relationship categories primarily\nmodulate the relative importance between entity embeddings and relationship\nembeddings and relationship embeddings, thereby affecting link prediction\noutcomes. These findings provide theoretical insights for addressing\nperformance bottlenecks on FB15k-237, while the proposed analytical framework\nalso offers methodological guidance for future studies dealing with\nstructurally constrained datasets.", "published": "2025-05-03 02:18:30", "link": "http://arxiv.org/abs/2505.01655v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Humans can learn to detect AI-generated texts, or at least learn when they can't", "abstract": "This study investigates whether individuals can learn to accurately\ndiscriminate between human-written and AI-produced texts when provided with\nimmediate feedback, and if they can use this feedback to recalibrate their\nself-perceived competence. We also explore the specific criteria individuals\nrely upon when making these decisions, focusing on textual style and perceived\nreadability.\n  We used GPT-4o to generate several hundred texts across various genres and\ntext types comparable to Koditex, a multi-register corpus of human-written\ntexts. We then presented randomized text pairs to 255 Czech native speakers who\nidentified which text was human-written and which was AI-generated.\nParticipants were randomly assigned to two conditions: one receiving immediate\nfeedback after each trial, the other receiving no feedback until experiment\ncompletion. We recorded accuracy in identification, confidence levels, response\ntimes, and judgments about text readability along with demographic data and\nparticipants' engagement with AI technologies prior to the experiment.\n  Participants receiving immediate feedback showed significant improvement in\naccuracy and confidence calibration. Participants initially held incorrect\nassumptions about AI-generated text features, including expectations about\nstylistic rigidity and readability. Notably, without feedback, participants\nmade the most errors precisely when feeling most confident -- an issue largely\nresolved among the feedback group.\n  The ability to differentiate between human and AI-generated texts can be\neffectively learned through targeted training with explicit feedback, which\nhelps correct misconceptions about AI stylistic features and readability, as\nwell as potential other variables that were not explored, while facilitating\nmore accurate self-assessment. This finding might be particularly important in\neducational contexts.", "published": "2025-05-03 17:42:49", "link": "http://arxiv.org/abs/2505.01877v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exploring the Role of Diversity in Example Selection for In-Context Learning", "abstract": "In-Context Learning (ICL) has gained prominence due to its ability to perform\ntasks without requiring extensive training data and its robustness to noisy\nlabels. A typical ICL workflow involves selecting localized examples relevant\nto a given input using sparse or dense embedding-based similarity functions.\nHowever, relying solely on similarity-based selection may introduce topical\nbiases in the retrieved contexts, potentially leading to suboptimal downstream\nperformance. We posit that reranking the retrieved context to enhance topical\ndiversity can improve downstream task performance. To achieve this, we leverage\nmaximum marginal relevance (MMR) which balances topical similarity with\ninter-example diversity. Our experimental results demonstrate that diversifying\nthe selected examples leads to consistent improvements in downstream\nperformance across various context sizes and similarity functions. The\nimplementation of our approach is made available at\nhttps://github.com/janak11111/Diverse-ICL.", "published": "2025-05-03 15:13:58", "link": "http://arxiv.org/abs/2505.01842v2", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Multilayer Perceptron Neural Network Models in Asset Pricing: An Empirical Study on Large-Cap US Stocks", "abstract": "In this study, MLP models with dynamic structure are applied to factor models\nfor asset pricing tasks. Concretely, the MLP pyramid model structure was\nemployed on firm-characteristic-sorted portfolio factors for modelling the\nlarge-capital US stocks. It was further developed as a practicable factor\ninvesting strategy based on the predictions. The main findings in this chapter\nwere evaluated from two angles: model performance and investing performance,\nwhich were compared from the periods with and without COVID-19. The empirical\nresults indicated that with the restrictions of the data size, the MLP models\nno longer perform \"deeper, better\", while the proposed MLP models with two and\nthree hidden layers have higher flexibility to model the factors in this case.\nThis study also verified the idea of previous works that MLP models for factor\ninvesting have more meaning in the downside risk control than in pursuing the\nabsolute annual returns.", "published": "2025-05-03 20:55:40", "link": "http://arxiv.org/abs/2505.01921v2", "categories": ["q-fin.PR", "q-fin.CP", "q-fin.RM", "91G10, 91G60, 62M45, 62P05", "J.4; G.3; I.2.6"], "primary_category": "q-fin.PR"}
{"title": "Accelerating Large Language Model Reasoning via Speculative Search", "abstract": "Tree-search-based reasoning methods have significantly enhanced the reasoning\ncapability of large language models (LLMs) by facilitating the exploration of\nmultiple intermediate reasoning steps, i.e., thoughts. However, these methods\nsuffer from substantial inference latency, as they have to generate numerous\nreasoning thoughts, severely limiting LLM applicability. To address this\nchallenge, we propose a novel Speculative Search (SpecSearch) framework that\nsignificantly accelerates LLM reasoning by optimizing thought generation.\nSpecifically, SpecSearch utilizes a small model to strategically collaborate\nwith a large model at both thought and token levels, efficiently generating\nhigh-quality reasoning thoughts. The major pillar of SpecSearch is a novel\nquality-preserving rejection mechanism, which effectively filters out thoughts\nwhose quality falls below that of the large model's outputs. Moreover, we show\nthat SpecSearch preserves comparable reasoning quality to the large model.\nExperiments on both the Qwen and Llama models demonstrate that SpecSearch\nsignificantly outperforms state-of-the-art approaches, achieving up to\n2.12$\\times$ speedup with comparable reasoning quality.", "published": "2025-05-03 12:14:08", "link": "http://arxiv.org/abs/2505.02865v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Neural Orchestration for Multi-Agent Systems: A Deep Learning Framework for Optimal Agent Selection in Multi-Domain Task Environments", "abstract": "Multi-agent systems (MAS) are foundational in simulating complex real-world\nscenarios involving autonomous, interacting entities. However, traditional MAS\narchitectures often suffer from rigid coordination mechanisms and difficulty\nadapting to dynamic tasks. We propose MetaOrch, a neural orchestration\nframework for optimal agent selection in multi-domain task environments. Our\nsystem implements a supervised learning approach that models task context,\nagent histories, and expected response quality to select the most appropriate\nagent for each task. A novel fuzzy evaluation module scores agent responses\nalong completeness, relevance, and confidence dimensions, generating soft\nsupervision labels for training the orchestrator. Unlike previous methods that\nhard-code agent-task mappings, MetaOrch dynamically predicts the most suitable\nagent while estimating selection confidence. Experiments in simulated\nenvironments with heterogeneous agents demonstrate that our approach achieves\n86.3% selection accuracy, significantly outperforming baseline strategies\nincluding random selection and round-robin scheduling. The modular architecture\nemphasizes extensibility, allowing agents to be registered, updated, and\nqueried independently. Results suggest that neural orchestration offers a\npowerful approach to enhancing the autonomy, interpretability, and adaptability\nof multi-agent systems across diverse task domains.", "published": "2025-05-03 02:58:25", "link": "http://arxiv.org/abs/2505.02861v1", "categories": ["cs.MA", "cs.AI", "cs.NE"], "primary_category": "cs.MA"}
{"title": "Antenna Activation and Resource Allocation in Multi-Waveguide Pinching-Antenna Systems", "abstract": "Pinching antennas, as a novel flexible-antenna technology capable of\nestablishing line of sight (LoS) connections and effectively mitigating\nlarge-scale path loss, have recently attracted considerable research interests.\nHowever, the implementation of ideal pinching-antenna systems involves\ndetermining and adjusting pinching antennas to an arbitrary position on\nwaveguides, which presents challenges to both practical deployment and related\noptimization. This paper investigates a practical pinching-antennas system in\nmulti-waveguide scenarios, where pinching antennas are installed at\npre-configured discrete positions to serve downlink users with non-orthogonal\nmultiple access (NOMA). To improve system throughput, a sophisticated\noptimization problem is formulated by jointly considering waveguide assignment,\nantenna activation, successive interference cancellation (SIC) decoding order\ndesign, and power allocation. By treating waveguide assignment and antenna\nactivation as two coalition-formation games, a novel game-theoretic algorithm\nis developed, in which the optimal decoding order is derived and incorporated.\nFor power allocation, monotonic optimization and successive convex\napproximation (SCA) are employed to construct global optimal and low-complexity\nsolutions, respectively. Simulation results demonstrate that the NOMA-based\npinching-antenna system exhibits superior performance compared to the\nconsidered benchmark systems, and the proposed solutions provide significant\nimprovement in terms of sum rate and outage probability.", "published": "2025-05-03 11:05:17", "link": "http://arxiv.org/abs/2505.02864v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Weakly-supervised Audio Temporal Forgery Localization via Progressive Audio-language Co-learning Network", "abstract": "Audio temporal forgery localization (ATFL) aims to find the precise forgery\nregions of the partial spoof audio that is purposefully modified. Existing ATFL\nmethods rely on training efficient networks using fine-grained annotations,\nwhich are obtained costly and challenging in real-world scenarios. To meet this\nchallenge, in this paper, we propose a progressive audio-language co-learning\nnetwork (LOCO) that adopts co-learning and self-supervision manners to prompt\nlocalization performance under weak supervision scenarios. Specifically, an\naudio-language co-learning module is first designed to capture forgery\nconsensus features by aligning semantics from temporal and global perspectives.\nIn this module, forgery-aware prompts are constructed by using utterance-level\nannotations together with learnable prompts, which can incorporate semantic\npriors into temporal content features dynamically. In addition, a forgery\nlocalization module is applied to produce forgery proposals based on fused\nforgery-class activation sequences. Finally, a progressive refinement strategy\nis introduced to generate pseudo frame-level labels and leverage supervised\nsemantic contrastive learning to amplify the semantic distinction between real\nand fake content, thereby continuously optimizing forgery-aware features.\nExtensive experiments show that the proposed LOCO achieves SOTA performance on\nthree public benchmarks.", "published": "2025-05-03 17:57:57", "link": "http://arxiv.org/abs/2505.01880v2", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
