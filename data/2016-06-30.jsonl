{"title": "Relation extraction from clinical texts using domain invariant\n  convolutional neural network", "abstract": "In recent years extracting relevant information from biomedical and clinical\ntexts such as research articles, discharge summaries, or electronic health\nrecords have been a subject of many research efforts and shared challenges.\nRelation extraction is the process of detecting and classifying the semantic\nrelation among entities in a given piece of texts. Existing models for this\ntask in biomedical domain use either manually engineered features or kernel\nmethods to create feature vector. These features are then fed to classifier for\nthe prediction of the correct class. It turns out that the results of these\nmethods are highly dependent on quality of user designed features and also\nsuffer from curse of dimensionality. In this work we focus on extracting\nrelations from clinical discharge summaries. Our main objective is to exploit\nthe power of convolution neural network (CNN) to learn features automatically\nand thus reduce the dependency on manual feature engineering. We evaluate\nperformance of the proposed model on i2b2-2010 clinical relation extraction\nchallenge dataset. Our results indicate that convolution neural network can be\na good model for relation exaction in clinical text without being dependent on\nexpert's knowledge on defining quality features.", "published": "2016-06-30 07:10:07", "link": "http://arxiv.org/abs/1606.09370v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recurrent neural network models for disease name recognition using\n  domain invariant features", "abstract": "Hand-crafted features based on linguistic and domain-knowledge play crucial\nrole in determining the performance of disease name recognition systems. Such\nmethods are further limited by the scope of these features or in other words,\ntheir ability to cover the contexts or word dependencies within a sentence. In\nthis work, we focus on reducing such dependencies and propose a\ndomain-invariant framework for the disease name recognition task. In\nparticular, we propose various end-to-end recurrent neural network (RNN) models\nfor the tasks of disease name recognition and their classification into four\npre-defined categories. We also utilize convolution neural network (CNN) in\ncascade of RNN to get character-based embedded features and employ it with\nword-embedded features in our model. We compare our models with the\nstate-of-the-art results for the two tasks on NCBI disease dataset. Our results\nfor the disease mention recognition task indicate that state-of-the-art\nperformance can be obtained without relying on feature engineering. Further the\nproposed models obtained improved performance on the classification task of\ndisease names.", "published": "2016-06-30 07:15:56", "link": "http://arxiv.org/abs/1606.09371v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Network-based Word Alignment through Score Aggregation", "abstract": "We present a simple neural network for word alignment that builds source and\ntarget word window representations to compute alignment scores for sentence\npairs. To enable unsupervised training, we use an aggregation operation that\nsummarizes the alignment scores for a given target word. A soft-margin\nobjective increases scores for true target words while decreasing scores for\ntarget words that are not present. Compared to the popular Fast Align model,\nour approach improves alignment accuracy by 7 AER on English-Czech, by 6 AER on\nRomanian-English and by 1.7 AER on English-French alignment.", "published": "2016-06-30 16:32:00", "link": "http://arxiv.org/abs/1606.09560v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Prediction Uncertainty in Machine Translation Quality\n  Estimation", "abstract": "Machine Translation Quality Estimation is a notoriously difficult task, which\nlessens its usefulness in real-world translation environments. Such scenarios\ncan be improved if quality predictions are accompanied by a measure of\nuncertainty. However, models in this task are traditionally evaluated only in\nterms of point estimate metrics, which do not take prediction uncertainty into\naccount. We investigate probabilistic methods for Quality Estimation that can\nprovide well-calibrated uncertainty estimates and evaluate them in terms of\ntheir full posterior predictive distributions. We also show how this posterior\ninformation can be useful in an asymmetric risk scenario, which aims to capture\ntypical situations in translation workflows.", "published": "2016-06-30 18:10:46", "link": "http://arxiv.org/abs/1606.09600v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SnapToGrid: From Statistical to Interpretable Models for Biomedical\n  Information Extraction", "abstract": "We propose an approach for biomedical information extraction that marries the\nadvantages of machine learning models, e.g., learning directly from data, with\nthe benefits of rule-based approaches, e.g., interpretability. Our approach\nstarts by training a feature-based statistical model, then converts this model\nto a rule-based variant by converting its features to rules, and \"snapping to\ngrid\" the feature weights to discrete votes. In doing so, our proposal takes\nadvantage of the large body of work in machine learning, but it produces an\ninterpretable model, which can be directly edited by experts. We evaluate our\napproach on the BioNLP 2009 event extraction task. Our results show that there\nis a small performance penalty when converting the statistical model to rules,\nbut the gain in interpretability compensates for that: with minimal effort,\nhuman experts improve this model to have similar performance to the statistical\nmodel that served as starting point.", "published": "2016-06-30 18:23:47", "link": "http://arxiv.org/abs/1606.09604v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Representation of texts as complex networks: a mesoscopic approach", "abstract": "Statistical techniques that analyze texts, referred to as text analytics,\nhave departed from the use of simple word count statistics towards a new\nparadigm. Text mining now hinges on a more sophisticated set of methods,\nincluding the representations in terms of complex networks. While\nwell-established word-adjacency (co-occurrence) methods successfully grasp\nsyntactical features of written texts, they are unable to represent important\naspects of textual data, such as its topical structure, i.e. the sequence of\nsubjects developing at a mesoscopic level along the text. Such aspects are\noften overlooked by current methodologies. In order to grasp the mesoscopic\ncharacteristics of semantical content in written texts, we devised a network\nmodel which is able to analyze documents in a multi-scale fashion. In the\nproposed model, a limited amount of adjacent paragraphs are represented as\nnodes, which are connected whenever they share a minimum semantical content. To\nillustrate the capabilities of our model, we present, as a case example, a\nqualitative analysis of \"Alice's Adventures in Wonderland\". We show that the\nmesoscopic structure of a document, modeled as a network, reveals many semantic\ntraits of texts. Such an approach paves the way to a myriad of semantic-based\napplications. In addition, our approach is illustrated in a machine learning\ncontext, in which texts are classified among real texts and randomized\ninstances.", "published": "2016-06-30 19:47:17", "link": "http://arxiv.org/abs/1606.09636v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HUME: Human UCCA-Based Evaluation of Machine Translation", "abstract": "Human evaluation of machine translation normally uses sentence-level measures\nsuch as relative ranking or adequacy scales. However, these provide no insight\ninto possible errors, and do not scale well with sentence length. We argue for\na semantics-based evaluation, which captures what meaning components are\nretained in the MT output, thus providing a more fine-grained analysis of\ntranslation quality, and enabling the construction and tuning of\nsemantics-based MT. We present a novel human semantic evaluation measure, Human\nUCCA-based MT Evaluation (HUME), building on the UCCA semantic representation\nscheme. HUME covers a wider range of semantic phenomena than previous methods\nand does not rely on semantic annotation of the potentially garbled MT output.\nWe experiment with four language pairs, demonstrating HUME's broad\napplicability, and report good inter-annotator agreement rates and correlation\nwith human adequacy scores.", "published": "2016-06-30 20:35:47", "link": "http://arxiv.org/abs/1607.00030v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue\n  Systems", "abstract": "User simulation is essential for generating enough data to train a\nstatistical spoken dialogue system. Previous models for user simulation suffer\nfrom several drawbacks, such as the inability to take dialogue history into\naccount, the need of rigid structure to ensure coherent user behaviour, heavy\ndependence on a specific domain, the inability to output several user\nintentions during one dialogue turn, or the requirement of a summarized action\nspace for tractability. This paper introduces a data-driven user simulator\nbased on an encoder-decoder recurrent neural network. The model takes as input\na sequence of dialogue contexts and outputs a sequence of dialogue acts\ncorresponding to user intentions. The dialogue contexts include information\nabout the machine acts and the status of the user goal. We show on the Dialogue\nState Tracking Challenge 2 (DSTC2) dataset that the sequence-to-sequence model\noutperforms an agenda-based simulator and an n-gram simulator, according to\nF-score. Furthermore, we show how this model can be used on the original action\nspace and thereby models user behaviour with finer granularity.", "published": "2016-06-30 22:51:00", "link": "http://arxiv.org/abs/1607.00070v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Crosslingual Word Embeddings without Bilingual Corpora", "abstract": "Crosslingual word embeddings represent lexical items from different languages\nin the same vector space, enabling transfer of NLP tools. However, previous\nattempts had expensive resource requirements, difficulty incorporating\nmonolingual data or were unable to handle polysemy. We address these drawbacks\nin our method which takes advantage of a high coverage dictionary in an EM\nstyle training algorithm over monolingual corpora in two languages. Our model\nachieves state-of-the-art performance on bilingual lexicon induction task\nexceeding models using large bilingual corpora, and competitive results on the\nmonolingual word similarity and cross-lingual document classification task.", "published": "2016-06-30 09:18:53", "link": "http://arxiv.org/abs/1606.09403v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
