{"title": "ThinkSum: Probabilistic reasoning over sets using large language models", "abstract": "Large language models (LLMs) have a substantial capacity for high-level\nanalogical reasoning: reproducing patterns in linear text that occur in their\ntraining data (zero-shot evaluation) or in the provided context (few-shot\nin-context learning). However, recent studies show that even the more advanced\nLLMs fail in scenarios that require reasoning over multiple objects or facts\nand making sequences of logical deductions. We propose a two-stage\nprobabilistic inference paradigm, ThinkSum, which reasons over sets of objects\nor facts in a structured manner. In the first stage (Think - retrieval of\nassociations), a LLM is queried in parallel over a set of phrases extracted\nfrom the prompt or an auxiliary model call. In the second stage (Sum -\nprobabilistic inference or reasoning), the results of these queries are\naggregated to make the final prediction. We demonstrate the possibilities and\nadvantages of ThinkSum on the BIG-bench suite of LLM evaluation tasks,\nachieving improvements over the state of the art using GPT-family models on\nthirteen difficult tasks, often with far smaller model variants. We also\ncompare and contrast ThinkSum with other proposed modifications to direct\nprompting of LLMs, such as variants of chain-of-thought prompting. Our results\nsuggest that because the probabilistic inference in ThinkSum is performed\noutside of calls to the LLM, ThinkSum is less sensitive to prompt design,\nyields more interpretable predictions, and can be flexibly combined with latent\nvariable models to extract structured knowledge from LLMs. Overall, our\nproposed paradigm represents a promising approach for enhancing the reasoning\ncapabilities of LLMs.", "published": "2022-10-04 00:34:01", "link": "http://arxiv.org/abs/2210.01293v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Surprising Computational Power of Nondeterministic Stack RNNs", "abstract": "Traditional recurrent neural networks (RNNs) have a fixed, finite number of\nmemory cells. In theory (assuming bounded range and precision), this limits\ntheir formal language recognition power to regular languages, and in practice,\nRNNs have been shown to be unable to learn many context-free languages (CFLs).\nIn order to expand the class of languages RNNs recognize, prior work has\naugmented RNNs with a nondeterministic stack data structure, putting them on\npar with pushdown automata and increasing their language recognition power to\nCFLs. Nondeterminism is needed for recognizing all CFLs (not just deterministic\nCFLs), but in this paper, we show that nondeterminism and the neural controller\ninteract to produce two more unexpected abilities. First, the nondeterministic\nstack RNN can recognize not only CFLs, but also many non-context-free\nlanguages. Second, it can recognize languages with much larger alphabet sizes\nthan one might expect given the size of its stack alphabet. Finally, to\nincrease the information capacity in the stack and allow it to solve more\ncomplicated tasks with large alphabet sizes, we propose a new version of the\nnondeterministic stack that simulates stacks of vectors rather than discrete\nsymbols. We demonstrate perplexity improvements with this new model on the Penn\nTreebank language modeling benchmark.", "published": "2022-10-04 03:18:19", "link": "http://arxiv.org/abs/2210.01343v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Unlearning for Mitigating Privacy Risks in Language Models", "abstract": "Pretrained Language Models (LMs) memorize a vast amount of knowledge during\ninitial pretraining, including information that may violate the privacy of\npersonal lives and identities. Previous work addressing privacy issues for\nlanguage models has mostly focused on data preprocessing and differential\nprivacy methods, both requiring re-training the underlying LM. We propose\nknowledge unlearning as an alternative method to reduce privacy risks for LMs\npost hoc. We show that simply performing gradient ascent on target token\nsequences is effective at forgetting them with little to no degradation of\ngeneral language modeling performances for larger LMs; it sometimes even\nsubstantially improves the underlying LM with just a few iterations. We also\nfind that sequential unlearning is better than trying to unlearn all the data\nat once and that unlearning is highly dependent on which kind of data (domain)\nis forgotten. By showing comparisons with a previous data preprocessing method\nand a decoding method known to mitigate privacy risks for LMs, we show that\nunlearning can give a stronger empirical privacy guarantee in scenarios where\nthe data vulnerable to extraction attacks are known a priori while being much\nmore efficient and robust. We release the code and dataset needed to replicate\nour results at https://github.com/joeljang/knowledge-unlearning.", "published": "2022-10-04 10:18:11", "link": "http://arxiv.org/abs/2210.01504v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How Masterly Are People at Playing with Their Vocabulary? Analysis of\n  the Wordle Game for Latvian", "abstract": "In this paper, we describe adaptation of a simple word guessing game that\noccupied the hearts and minds of people around the world. There are versions\nfor all three Baltic countries and even several versions of each. We\nspecifically pay attention to the Latvian version and look into how people form\ntheir guesses given any already uncovered hints. The paper analyses guess\npatterns, easy and difficult word characteristics, and player behaviour and\nresponse.", "published": "2022-10-04 10:25:24", "link": "http://arxiv.org/abs/2210.01508v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mintaka: A Complex, Natural, and Multilingual Dataset for End-to-End\n  Question Answering", "abstract": "We introduce Mintaka, a complex, natural, and multilingual dataset designed\nfor experimenting with end-to-end question-answering models. Mintaka is\ncomposed of 20,000 question-answer pairs collected in English, annotated with\nWikidata entities, and translated into Arabic, French, German, Hindi, Italian,\nJapanese, Portuguese, and Spanish for a total of 180,000 samples. Mintaka\nincludes 8 types of complex questions, including superlative, intersection, and\nmulti-hop questions, which were naturally elicited from crowd workers. We run\nbaselines over Mintaka, the best of which achieves 38% hits@1 in English and\n31% hits@1 multilingually, showing that existing models have room for\nimprovement. We release Mintaka at https://github.com/amazon-research/mintaka.", "published": "2022-10-04 13:54:29", "link": "http://arxiv.org/abs/2210.01613v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mining Duplicate Questions of Stack Overflow", "abstract": "There has a been a significant rise in the use of Community Question\nAnswering sites (CQAs) over the last decade owing primarily to their ability to\nleverage the wisdom of the crowd. Duplicate questions have a crippling effect\non the quality of these sites. Tackling duplicate questions is therefore an\nimportant step towards improving quality of CQAs. In this regard, we propose\ntwo neural network based architectures for duplicate question detection on\nStack Overflow. We also propose explicitly modeling the code present in\nquestions to achieve results that surpass the state of the art.", "published": "2022-10-04 14:34:59", "link": "http://arxiv.org/abs/2210.01637v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Improving Faithfulness in Abstractive Summarization", "abstract": "Despite the success achieved in neural abstractive summarization based on\npre-trained language models, one unresolved issue is that the generated\nsummaries are not always faithful to the input document. There are two possible\ncauses of the unfaithfulness problem: (1) the summarization model fails to\nunderstand or capture the gist of the input text, and (2) the model over-relies\non the language model to generate fluent but inadequate words. In this work, we\npropose a Faithfulness Enhanced Summarization model (FES), which is designed\nfor addressing these two problems and improving faithfulness in abstractive\nsummarization. For the first problem, we propose to use question-answering (QA)\nto examine whether the encoder fully grasps the input document and can answer\nthe questions on the key information in the input. The QA attention on the\nproper input words can also be used to stipulate how the decoder should attend\nto the source. For the second problem, we introduce a max-margin loss defined\non the difference between the language and the summarization model, aiming to\nprevent the overconfidence of the language model. Extensive experiments on two\nbenchmark summarization datasets, CNN/DM and XSum, demonstrate that our model\nsignificantly outperforms strong baselines. The evaluation of factual\nconsistency also shows that our model generates more faithful summaries than\nbaselines.", "published": "2022-10-04 19:52:09", "link": "http://arxiv.org/abs/2210.01877v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recitation-Augmented Language Models", "abstract": "We propose a new paradigm to help Large Language Models (LLMs) generate more\naccurate factual knowledge without retrieving from an external corpus, called\nRECITation-augmented gEneration (RECITE). Different from retrieval-augmented\nlanguage models that retrieve relevant documents before generating the outputs,\ngiven an input, RECITE first recites one or several relevant passages from\nLLMs' own memory via sampling, and then produces the final answers. We show\nthat RECITE is a powerful paradigm for knowledge-intensive NLP tasks.\nSpecifically, we show that by utilizing recitation as the intermediate step, a\nrecite-and-answer scheme can achieve new state-of-the-art performance in\nvarious closed-book question answering (CBQA) tasks. In experiments, we verify\nthe effectiveness of \\method~on four pre-trained models (PaLM, UL2, OPT, and\nCodex) and three CBQA tasks (Natural Questions, TriviaQA, and HotpotQA). Our\ncode is available at \"https://github.com/Edward-Sun/RECITE\".", "published": "2022-10-04 00:49:20", "link": "http://arxiv.org/abs/2210.01296v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to Collocate Visual-Linguistic Neural Modules for Image\n  Captioning", "abstract": "Humans tend to decompose a sentence into different parts like \\textsc{sth do\nsth at someplace} and then fill each part with certain content. Inspired by\nthis, we follow the \\textit{principle of modular design} to propose a novel\nimage captioner: learning to Collocate Visual-Linguistic Neural Modules\n(CVLNM). Unlike the \\re{widely used} neural module networks in VQA, where the\nlanguage (\\ie, question) is fully observable, \\re{the task of collocating\nvisual-linguistic modules is more challenging.} This is because the language is\nonly partially observable, for which we need to dynamically collocate the\nmodules during the process of image captioning. To sum up, we make the\nfollowing technical contributions to design and train our CVLNM: 1)\n\\textit{distinguishable module design} -- \\re{four modules in the encoder}\nincluding one linguistic module for function words and three visual modules for\ndifferent content words (\\ie, noun, adjective, and verb) and another linguistic\none in the decoder for commonsense reasoning, 2) a self-attention based\n\\textit{module controller} for robustifying the visual reasoning, 3) a\npart-of-speech based \\textit{syntax loss} imposed on the module controller for\nfurther regularizing the training of our CVLNM. Extensive experiments on the\nMS-COCO dataset show that our CVLNM is more effective, \\eg, achieving a new\nstate-of-the-art 129.5 CIDEr-D, and more robust, \\eg, being less likely to\noverfit to dataset bias and suffering less when fewer training samples are\navailable. Codes are available at \\url{https://github.com/GCYZSL/CVLMN}", "published": "2022-10-04 03:09:50", "link": "http://arxiv.org/abs/2210.01338v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "A Study on the Efficiency and Generalization of Light Hybrid Retrievers", "abstract": "Hybrid retrievers can take advantage of both sparse and dense retrievers.\nPrevious hybrid retrievers leverage indexing-heavy dense retrievers. In this\nwork, we study \"Is it possible to reduce the indexing memory of hybrid\nretrievers without sacrificing performance\"? Driven by this question, we\nleverage an indexing-efficient dense retriever (i.e. DrBoost) and introduce a\nLITE retriever that further reduces the memory of DrBoost. LITE is jointly\ntrained on contrastive learning and knowledge distillation from DrBoost. Then,\nwe integrate BM25, a sparse retriever, with either LITE or DrBoost to form\nlight hybrid retrievers. Our Hybrid-LITE retriever saves 13X memory while\nmaintaining 98.0% performance of the hybrid retriever of BM25 and DPR. In\naddition, we study the generalization capacity of our light hybrid retrievers\non out-of-domain dataset and a set of adversarial attacks datasets. Experiments\nshowcase that light hybrid retrievers achieve better generalization performance\nthan individual sparse and dense retrievers. Nevertheless, our analysis shows\nthat there is a large room to improve the robustness of retrievers, suggesting\na new research direction.", "published": "2022-10-04 04:22:46", "link": "http://arxiv.org/abs/2210.01371v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Unveiling the Black Box of PLMs with Semantic Anchors: Towards\n  Interpretable Neural Semantic Parsing", "abstract": "The recent prevalence of pretrained language models (PLMs) has dramatically\nshifted the paradigm of semantic parsing, where the mapping from natural\nlanguage utterances to structured logical forms is now formulated as a Seq2Seq\ntask. Despite the promising performance, previous PLM-based approaches often\nsuffer from hallucination problems due to their negligence of the structural\ninformation contained in the sentence, which essentially constitutes the key\nsemantics of the logical forms. Furthermore, most works treat PLM as a black\nbox in which the generation process of the target logical form is hidden\nbeneath the decoder modules, which greatly hinders the model's intrinsic\ninterpretability. To address these two issues, we propose to incorporate the\ncurrent PLMs with a hierarchical decoder network. By taking the first-principle\nstructures as the semantic anchors, we propose two novel intermediate\nsupervision tasks, namely Semantic Anchor Extraction and Semantic Anchor\nAlignment, for training the hierarchical decoders and probing the model\nintermediate representations in a self-adaptive manner alongside the\nfine-tuning process. We conduct intensive experiments on several semantic\nparsing benchmarks and demonstrate that our approach can consistently\noutperform the baselines. More importantly, by analyzing the intermediate\nrepresentations of the hierarchical decoders, our approach also makes a huge\nstep toward the intrinsic interpretability of PLMs in the domain of semantic\nparsing.", "published": "2022-10-04 07:27:29", "link": "http://arxiv.org/abs/2210.01425v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Causal Intervention-based Prompt Debiasing for Event Argument Extraction", "abstract": "Prompt-based methods have become increasingly popular among information\nextraction tasks, especially in low-data scenarios. By formatting a finetune\ntask into a pre-training objective, prompt-based methods resolve the data\nscarce problem effectively. However, seldom do previous research investigate\nthe discrepancy among different prompt formulating strategies. In this work, we\ncompare two kinds of prompts, name-based prompt and ontology-base prompt, and\nreveal how ontology-base prompt methods exceed its counterpart in zero-shot\nevent argument extraction (EAE) . Furthermore, we analyse the potential risk in\nontology-base prompts via a causal view and propose a debias method by causal\nintervention. Experiments on two benchmarks demonstrate that modified by our\ndebias method, the baseline model becomes both more effective and robust, with\nsignificant improvement in the resistance to adversarial attacks.", "published": "2022-10-04 12:32:00", "link": "http://arxiv.org/abs/2210.01561v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Text Characterization Toolkit", "abstract": "In NLP, models are usually evaluated by reporting single-number performance\nscores on a number of readily available benchmarks, without much deeper\nanalysis. Here, we argue that - especially given the well-known fact that\nbenchmarks often contain biases, artefacts, and spurious correlations - deeper\nresults analysis should become the de-facto standard when presenting new models\nor benchmarks. We present a tool that researchers can use to study properties\nof the dataset and the influence of those properties on their models'\nbehaviour. Our Text Characterization Toolkit includes both an easy-to-use\nannotation tool, as well as off-the-shelf scripts that can be used for specific\nanalyses. We also present use-cases from three different domains: we use the\ntool to predict what are difficult examples for given well-known trained models\nand identify (potentially harmful) biases and heuristics that are present in a\ndataset.", "published": "2022-10-04 16:54:11", "link": "http://arxiv.org/abs/2210.01734v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Modular Approach to Machine Reading Comprehension: Mixture of Task-Aware\n  Experts", "abstract": "In this work we present a Mixture of Task-Aware Experts Network for Machine\nReading Comprehension on a relatively small dataset. We particularly focus on\nthe issue of common-sense learning, enforcing the common ground knowledge by\nspecifically training different expert networks to capture different kinds of\nrelationships between each passage, question and choice triplet. Moreover, we\ntake inspi ration on the recent advancements of multitask and transfer learning\nby training each network a relevant focused task. By making the\nmixture-of-networks aware of a specific goal by enforcing a task and a\nrelationship, we achieve state-of-the-art results and reduce over-fitting.", "published": "2022-10-04 17:13:41", "link": "http://arxiv.org/abs/2210.01750v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Memory in humans and deep language models: Linking hypotheses for model\n  augmentation", "abstract": "The computational complexity of the self-attention mechanism in Transformer\nmodels significantly limits their ability to generalize over long temporal\ndurations. Memory-augmentation, or the explicit storing of past information in\nexternal memory for subsequent predictions, has become a constructive avenue\nfor mitigating this limitation. We argue that memory-augmented Transformers can\nbenefit substantially from considering insights from the memory literature in\nhumans. We detail an approach for integrating evidence from the human memory\nsystem through the specification of cross-domain linking hypotheses. We then\nprovide an empirical demonstration to evaluate the use of surprisal as a\nlinking hypothesis, and further identify the limitations of this approach to\ninform future research.", "published": "2022-10-04 19:35:11", "link": "http://arxiv.org/abs/2210.01869v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Affection: Learning Affective Explanations for Real-World Visual Data", "abstract": "In this work, we explore the emotional reactions that real-world images tend\nto induce by using natural language as the medium to express the rationale\nbehind an affective response to a given visual stimulus. To embark on this\njourney, we introduce and share with the research community a large-scale\ndataset that contains emotional reactions and free-form textual explanations\nfor 85,007 publicly available images, analyzed by 6,283 annotators who were\nasked to indicate and explain how and why they felt in a particular way when\nobserving a specific image, producing a total of 526,749 responses. Even though\nemotional reactions are subjective and sensitive to context (personal mood,\nsocial status, past experiences) - we show that there is significant common\nground to capture potentially plausible emotional responses with a large\nsupport in the subject population. In light of this crucial observation, we ask\nthe following questions: i) Can we develop multi-modal neural networks that\nprovide reasonable affective responses to real-world visual data, explained\nwith language? ii) Can we steer such methods towards producing explanations\nwith varying degrees of pragmatic language or justifying different emotional\nreactions while adapting to the underlying visual stimulus? Finally, iii) How\ncan we evaluate the performance of such methods for this novel task? With this\nwork, we take the first steps in addressing all of these questions, thus paving\nthe way for richer, more human-centric, and emotionally-aware image analysis\nsystems. Our introduced dataset and all developed methods are available on\nhttps://affective-explanations.org", "published": "2022-10-04 22:44:17", "link": "http://arxiv.org/abs/2210.01946v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Less is More: Task-aware Layer-wise Distillation for Language Model\n  Compression", "abstract": "Layer-wise distillation is a powerful tool to compress large models (i.e.\nteacher models) into small ones (i.e., student models). The student distills\nknowledge from the teacher by mimicking the hidden representations of the\nteacher at every intermediate layer. However, layer-wise distillation is\ndifficult. Since the student has a smaller model capacity than the teacher, it\nis often under-fitted. Furthermore, the hidden representations of the teacher\ncontain redundant information that the student does not necessarily need for\nthe target task's learning. To address these challenges, we propose a novel\nTask-aware layEr-wise Distillation (TED). TED designs task-aware filters to\nalign the hidden representations of the student and the teacher at each layer.\nThe filters select the knowledge that is useful for the target task from the\nhidden representations. As such, TED reduces the knowledge gap between the two\nmodels and helps the student to fit better on the target task. We evaluate TED\nin two scenarios: continual pre-training and fine-tuning. TED demonstrates\nsignificant and consistent improvements over existing distillation methods in\nboth scenarios. Code is available at\nhttps://github.com/cliang1453/task-aware-distillation.", "published": "2022-10-04 03:36:53", "link": "http://arxiv.org/abs/2210.01351v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "When to Make Exceptions: Exploring Language Models as Accounts of Human\n  Moral Judgment", "abstract": "AI systems are becoming increasingly intertwined with human life. In order to\neffectively collaborate with humans and ensure safety, AI systems need to be\nable to understand, interpret and predict human moral judgments and decisions.\nHuman moral judgments are often guided by rules, but not always. A central\nchallenge for AI safety is capturing the flexibility of the human moral mind --\nthe ability to determine when a rule should be broken, especially in novel or\nunusual situations. In this paper, we present a novel challenge set consisting\nof rule-breaking question answering (RBQA) of cases that involve potentially\npermissible rule-breaking -- inspired by recent moral psychology studies. Using\na state-of-the-art large language model (LLM) as a basis, we propose a novel\nmoral chain of thought (MORALCOT) prompting strategy that combines the\nstrengths of LLMs with theories of moral reasoning developed in cognitive\nscience to predict human moral judgments. MORALCOT outperforms seven existing\nLLMs by 6.2% F1, suggesting that modeling human reasoning might be necessary to\ncapture the flexibility of the human moral mind. We also conduct a detailed\nerror analysis to suggest directions for future work to improve AI safety using\nRBQA. Our data is open-sourced at\nhttps://huggingface.co/datasets/feradauto/MoralExceptQA and code at\nhttps://github.com/feradauto/MoralCoT", "published": "2022-10-04 09:04:27", "link": "http://arxiv.org/abs/2210.01478v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Code-Switching without Switching: Language Agnostic End-to-End Speech\n  Translation", "abstract": "We propose a) a Language Agnostic end-to-end Speech Translation model (LAST),\nand b) a data augmentation strategy to increase code-switching (CS)\nperformance. With increasing globalization, multiple languages are increasingly\nused interchangeably during fluent speech. Such CS complicates traditional\nspeech recognition and translation, as we must recognize which language was\nspoken first and then apply a language-dependent recognizer and subsequent\ntranslation component to generate the desired target language output. Such a\npipeline introduces latency and errors. In this paper, we eliminate the need\nfor that, by treating speech recognition and translation as one unified\nend-to-end speech translation problem. By training LAST with both input\nlanguages, we decode speech into one target language, regardless of the input\nlanguage. LAST delivers comparable recognition and speech translation accuracy\nin monolingual usage, while reducing latency and error rate considerably when\nCS is observed.", "published": "2022-10-04 10:34:25", "link": "http://arxiv.org/abs/2210.01512v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Neural-Symbolic Recursive Machine for Systematic Generalization", "abstract": "Current learning models often struggle with human-like systematic\ngeneralization, particularly in learning compositional rules from limited data\nand extrapolating them to novel combinations. We introduce the Neural-Symbolic\nRecursive Machine (NSR), whose core is a Grounded Symbol System (GSS), allowing\nfor the emergence of combinatorial syntax and semantics directly from training\ndata. The NSR employs a modular design that integrates neural perception,\nsyntactic parsing, and semantic reasoning. These components are synergistically\ntrained through a novel deduction-abduction algorithm. Our findings demonstrate\nthat NSR's design, imbued with the inductive biases of equivariance and\ncompositionality, grants it the expressiveness to adeptly handle diverse\nsequence-to-sequence tasks and achieve unparalleled systematic generalization.\nWe evaluate NSR's efficacy across four challenging benchmarks designed to probe\nsystematic generalization capabilities: SCAN for semantic parsing, PCFG for\nstring manipulation, HINT for arithmetic reasoning, and a compositional machine\ntranslation task. The results affirm NSR's superiority over contemporary neural\nand hybrid models in terms of generalization and transferability.", "published": "2022-10-04 13:27:38", "link": "http://arxiv.org/abs/2210.01603v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "When and why vision-language models behave like bags-of-words, and what\n  to do about it?", "abstract": "Despite the success of large vision and language models (VLMs) in many\ndownstream applications, it is unclear how well they encode compositional\ninformation. Here, we create the Attribution, Relation, and Order (ARO)\nbenchmark to systematically evaluate the ability of VLMs to understand\ndifferent types of relationships, attributes, and order. ARO consists of Visual\nGenome Attribution, to test the understanding of objects' properties; Visual\nGenome Relation, to test for relational understanding; and COCO &\nFlickr30k-Order, to test for order sensitivity. ARO is orders of magnitude\nlarger than previous benchmarks of compositionality, with more than 50,000 test\ncases. We show where state-of-the-art VLMs have poor relational understanding,\ncan blunder when linking objects to their attributes, and demonstrate a severe\nlack of order sensitivity. VLMs are predominantly trained and evaluated on\nlarge datasets with rich compositional structure in the images and captions.\nYet, training on these datasets has not been enough to address the lack of\ncompositional understanding, and evaluating on these datasets has failed to\nsurface this deficiency. To understand why these limitations emerge and are not\nrepresented in the standard tests, we zoom into the evaluation and training\nprocedures. We demonstrate that it is possible to perform well on retrieval\nover existing datasets without using the composition and order information.\nGiven that contrastive pretraining optimizes for retrieval on datasets with\nsimilar shortcuts, we hypothesize that this can explain why the models do not\nneed to learn to represent compositional information. This finding suggests a\nnatural solution: composition-aware hard negative mining. We show that a\nsimple-to-implement modification of contrastive learning significantly improves\nthe performance on tasks requiring understanding of order and compositionality.", "published": "2022-10-04 22:13:25", "link": "http://arxiv.org/abs/2210.01936v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Detect, Retrieve, Comprehend: A Flexible Framework for Zero-Shot\n  Document-Level Question Answering", "abstract": "Researchers produce thousands of scholarly documents containing valuable\ntechnical knowledge. The community faces the laborious task of reading these\ndocuments to identify, extract, and synthesize information. To automate\ninformation gathering, document-level question answering (QA) offers a flexible\nframework where human-posed questions can be adapted to extract diverse\nknowledge. Finetuning QA systems requires access to labeled data (tuples of\ncontext, question and answer). However, data curation for document QA is\nuniquely challenging because the context (i.e. answer evidence passage) needs\nto be retrieved from potentially long, ill-formatted documents. Existing QA\ndatasets sidestep this challenge by providing short, well-defined contexts that\nare unrealistic in real-world applications. We present a three-stage document\nQA approach: (1) text extraction from PDF; (2) evidence retrieval from\nextracted texts to form well-posed contexts; (3) QA to extract knowledge from\ncontexts to return high-quality answers -- extractive, abstractive, or Boolean.\nUsing QASPER for evaluation, our detect-retrieve-comprehend (DRC) system\nachieves a +7.19 improvement in Answer-F1 over existing baselines while\ndelivering superior context selection. Our results demonstrate that DRC holds\ntremendous promise as a flexible framework for practical scientific document\nQA.", "published": "2022-10-04 23:33:52", "link": "http://arxiv.org/abs/2210.01959v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Explaining Patterns in Data with Language Models via Interpretable\n  Autoprompting", "abstract": "Large language models (LLMs) have displayed an impressive ability to harness\nnatural language to perform complex tasks. In this work, we explore whether we\ncan leverage this learned ability to find and explain patterns in data.\nSpecifically, given a pre-trained LLM and data examples, we introduce\ninterpretable autoprompting (iPrompt), an algorithm that generates a\nnatural-language string explaining the data. iPrompt iteratively alternates\nbetween generating explanations with an LLM and reranking them based on their\nperformance when used as a prompt. Experiments on a wide range of datasets,\nfrom synthetic mathematics to natural-language understanding, show that iPrompt\ncan yield meaningful insights by accurately finding groundtruth dataset\ndescriptions. Moreover, the prompts produced by iPrompt are simultaneously\nhuman-interpretable and highly effective for generalization: on real-world\nsentiment classification datasets, iPrompt produces prompts that match or even\nimprove upon human-written prompts for GPT-3. Finally, experiments with an fMRI\ndataset show the potential for iPrompt to aid in scientific discovery. All code\nfor using the methods and data here is made available on Github.", "published": "2022-10-04 18:32:14", "link": "http://arxiv.org/abs/2210.01848v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.NC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Grounding Language with Visual Affordances over Unstructured Data", "abstract": "Recent works have shown that Large Language Models (LLMs) can be applied to\nground natural language to a wide variety of robot skills. However, in\npractice, learning multi-task, language-conditioned robotic skills typically\nrequires large-scale data collection and frequent human intervention to reset\nthe environment or help correcting the current policies. In this work, we\npropose a novel approach to efficiently learn general-purpose\nlanguage-conditioned robot skills from unstructured, offline and reset-free\ndata in the real world by exploiting a self-supervised visuo-lingual affordance\nmodel, which requires annotating as little as 1% of the total data with\nlanguage. We evaluate our method in extensive experiments both in simulated and\nreal-world robotic tasks, achieving state-of-the-art performance on the\nchallenging CALVIN benchmark and learning over 25 distinct visuomotor\nmanipulation tasks with a single policy in the real world. We find that when\npaired with LLMs to break down abstract natural language instructions into\nsubgoals via few-shot prompting, our method is capable of completing\nlong-horizon, multi-tier tasks in the real world, while requiring an order of\nmagnitude less data than previous approaches. Code and videos are available at\nhttp://hulc2.cs.uni-freiburg.de", "published": "2022-10-04 21:16:48", "link": "http://arxiv.org/abs/2210.01911v3", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "The DKU-DukeECE Diarization System for the VoxCeleb Speaker Recognition\n  Challenge 2022", "abstract": "This paper discribes the DKU-DukeECE submission to the 4th track of the\nVoxCeleb Speaker Recognition Challenge 2022 (VoxSRC-22). Our system contains a\nfused voice activity detection model, a clustering-based diarization model, and\na target-speaker voice activity detection-based overlap detection model.\nOverall, the submitted system is similar to our previous year's system in\nVoxSRC-21. The difference is that we use a much better speaker embedding and a\nfused voice activity detection, which significantly improves the performance.\nFinally, we fuse 4 different systems using DOVER-lap and achieve 4.75 of the\ndiarization error rate, which ranks the 1st place in track 4.", "published": "2022-10-04 15:22:00", "link": "http://arxiv.org/abs/2210.01677v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Pay Self-Attention to Audio-Visual Navigation", "abstract": "Audio-visual embodied navigation, as a hot research topic, aims training a\nrobot to reach an audio target using egocentric visual (from the sensors\nmounted on the robot) and audio (emitted from the target) input. The\naudio-visual information fusion strategy is naturally important to the\nnavigation performance, but the state-of-the-art methods still simply\nconcatenate the visual and audio features, potentially ignoring the direct\nimpact of context. Moreover, the existing approaches requires either phase-wise\ntraining or additional aid (e.g. topology graph and sound semantics). Up till\nthis date, the work that deals with the more challenging setup with moving\ntarget(s) is still rare. As a result, we propose an end-to-end framework FSAAVN\n(feature self-attention audio-visual navigation) to learn chasing after a\nmoving audio target using a context-aware audio-visual fusion strategy\nimplemented as a self-attention module. Our thorough experiments validate the\nsuperior performance (both quantitatively and qualitatively) of FSAAVN in\ncomparison with the state-of-the-arts, and also provide unique insights about\nthe choice of visual modalities, visual/audio encoder backbones and fusion\npatterns.", "published": "2022-10-04 03:42:36", "link": "http://arxiv.org/abs/2210.01353v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Label-Deficient Keyword Spotting Through Self-Supervised\n  Pretraining", "abstract": "Keyword Spotting (KWS) models are becoming increasingly integrated into\nvarious systems, e.g. voice assistants. To achieve satisfactory performance,\nthese models typically rely on a large amount of labelled data, limiting their\napplications only to situations where such data is available. Self-supervised\nLearning (SSL) methods can mitigate such a reliance by leveraging\nreadily-available unlabelled data. Most SSL methods for speech have primarily\nbeen studied for large models, whereas this is not ideal, as compact KWS models\nare generally required. This paper explores the effectiveness of SSL on small\nmodels for KWS and establishes that SSL can enhance the performance of small\nKWS models when labelled data is scarce. We pretrain three compact\ntransformer-based KWS models using Data2Vec, and fine-tune them on a\nlabel-deficient setup of the Google Speech Commands data set. It is found that\nData2Vec pretraining leads to a significant increase in accuracy, with\nlabel-deficient scenarios showing an improvement of 8.22% 11.18% absolute\naccuracy.", "published": "2022-10-04 15:56:27", "link": "http://arxiv.org/abs/2210.01703v3", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS", "68T10", "I.2.6"], "primary_category": "cs.SD"}
{"title": "Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with\n  Hierarchical Neural Embeddings", "abstract": "Automatic synthesis of realistic co-speech gestures is an increasingly\nimportant yet challenging task in artificial embodied agent creation. Previous\nsystems mainly focus on generating gestures in an end-to-end manner, which\nleads to difficulties in mining the clear rhythm and semantics due to the\ncomplex yet subtle harmony between speech and gestures. We present a novel\nco-speech gesture synthesis method that achieves convincing results both on the\nrhythm and semantics. For the rhythm, our system contains a robust rhythm-based\nsegmentation pipeline to ensure the temporal coherence between the vocalization\nand gestures explicitly. For the gesture semantics, we devise a mechanism to\neffectively disentangle both low- and high-level neural embeddings of speech\nand motion based on linguistic theory. The high-level embedding corresponds to\nsemantics, while the low-level embedding relates to subtle variations. Lastly,\nwe build correspondence between the hierarchical embeddings of the speech and\nthe motion, resulting in rhythm- and semantics-aware gesture synthesis.\nEvaluations with existing objective metrics, a newly proposed rhythmic metric,\nand human feedback show that our method outperforms state-of-the-art systems by\na clear margin.", "published": "2022-10-04 08:19:06", "link": "http://arxiv.org/abs/2210.01448v3", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.GR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Temporal Resolution in Spectrogram for Audio Classification", "abstract": "The audio spectrogram is a time-frequency representation that has been widely\nused for audio classification. One of the key attributes of the audio\nspectrogram is the temporal resolution, which depends on the hop size used in\nthe Short-Time Fourier Transform (STFT). Previous works generally assume the\nhop size should be a constant value (e.g., 10 ms). However, a fixed temporal\nresolution is not always optimal for different types of sound. The temporal\nresolution affects not only classification accuracy but also computational\ncost. This paper proposes a novel method, DiffRes, that enables differentiable\ntemporal resolution modeling for audio classification. Given a spectrogram\ncalculated with a fixed hop size, DiffRes merges non-essential time frames\nwhile preserving important frames. DiffRes acts as a \"drop-in\" module between\nan audio spectrogram and a classifier and can be jointly optimized with the\nclassification task. We evaluate DiffRes on five audio classification tasks,\nusing mel-spectrograms as the acoustic features, followed by off-the-shelf\nclassifier backbones. Compared with previous methods using the fixed temporal\nresolution, the DiffRes-based method can achieve the equivalent or better\nclassification accuracy with at least 25% computational cost reduction. We\nfurther show that DiffRes can improve classification accuracy by increasing the\ntemporal resolution of input acoustic features, without adding to the\ncomputational cost.", "published": "2022-10-04 16:18:50", "link": "http://arxiv.org/abs/2210.01719v3", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
