{"title": "Correct implied volatility shapes and reliable pricing in the rough Heston model", "abstract": "We use modifications of the Adams method and very fast and accurate\nsinh-acceleration method of the Fourier inversion (iFT) (S.Boyarchenko and\nLevendorski\\u{i}, IJTAF 2019, v.22) to evaluate prices of vanilla options; for\noptions of moderate and long maturities and strikes not very far from the spot,\nthousands of prices can be calculated in several msec. with relative errors of\nthe order of 0.5\\% and smaller running Matlab on a Mac with moderate\ncharacteristics. We demonstrate that for the calibrated set of parameters in\nEuch and Rosenbaum, Math. Finance 2019, v. 29, the correct implied volatility\nsurface is significantly flatter and fits the data very poorly, hence, the\ncalibration results in op.cit. is an example of the {\\em ghost calibration}\n(M.Boyarchenko and Levendorki\\u{i}, Quantitative Finance 2015, v. 15): the\nerrors of the model and numerical method almost cancel one another. We explain\nhow calibration errors of this sort are generated by each of popular versions\nof numerical realizations of iFT (Carr-Madan, Lipton-Lewis and COS methods)\nwith prefixed parameters of a numerical method, resulting in spurious\nvolatility smiles and skews. We suggest a general {\\em Conformal Bootstrap\nprinciple} which allows one to avoid ghost calibration errors. We outline\nschemes of application of Conformal Bootstrap principle and the method of the\npaper to the design of accurate and fast calibration procedures.", "published": "2024-12-20 17:10:18", "link": "http://arxiv.org/abs/2412.16067v1", "categories": ["q-fin.MF", "q-fin.CP", "60-08, 60E10, 60G10, 60G22, 65C20, 65D30, 65G20, 91G20, 91G60"], "primary_category": "q-fin.MF"}
{"title": "Small-time central limit theorems for stochastic Volterra integral equations and their Markovian lifts", "abstract": "We study small-time central limit theorems for stochastic Volterra integral\nequations with H\\\"older continuous coefficients and general locally square\nintegrable Volterra kernels. We prove the convergence of the finite-dimensional\ndistributions, a functional CLT, and limit theorems for smooth transformations\nof the process, which covers a large class of Volterra kernels that includes\nrough models based on Riemann-Liouville kernels with short- and long-range\ndependencies. To illustrate our results, we derive asymptotic pricing formulae\nfor digital calls on the realized variance in three different regimes. The\nlatter provides a robust and model-independent pricing method for small\nmaturities in rough volatility models. Finally, for the case of completely\nmonotone kernels, we introduce a flexible framework of Hilbert space-valued\nMarkovian lifts and derive analogous limit theorems for such lifts.", "published": "2024-12-20 15:15:38", "link": "http://arxiv.org/abs/2412.15971v1", "categories": ["math.PR", "q-fin.MF", "60F05, 60F17, 60H15, 60H20, 60G15, 60G22, 91G20"], "primary_category": "math.PR"}
{"title": "Optimizing Fintech Marketing: A Comparative Study of Logistic Regression and XGBoost", "abstract": "As several studies have shown, predicting credit risk is still a major\nconcern for the financial services industry and is receiving a lot of scholarly\ninterest. This area of study is crucial because it aids financial organizations\nin determining the probability that borrowers would default, which has a direct\nbearing on lending choices and risk management tactics. Despite the progress\nmade in this domain, there is still a substantial knowledge gap concerning\nconsumer actions that take place prior to the filing of credit card\napplications. The objective of this study is to predict customer responses to\nmail campaigns and assess the likelihood of default among those who engage.\nThis research employs advanced machine learning techniques, specifically\nlogistic regression and XGBoost, to analyze consumer behavior and predict\nresponses to direct mail campaigns. By integrating different data preprocessing\nstrategies, including imputation and binning, we enhance the robustness and\naccuracy of our predictive models. The results indicate that XGBoost\nconsistently outperforms logistic regression across various metrics,\nparticularly in scenarios using categorical binning and custom imputation.\nThese findings suggest that XGBoost is particularly effective in handling\ncomplex data structures and provides a strong predictive capability in\nassessing credit risk.", "published": "2024-12-20 20:45:42", "link": "http://arxiv.org/abs/2412.16333v1", "categories": ["cs.LG", "cs.AI", "q-fin.ST", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Differentially Private Federated Learning of Diffusion Models for Synthetic Tabular Data Generation", "abstract": "The increasing demand for privacy-preserving data analytics in finance\nnecessitates solutions for synthetic data generation that rigorously uphold\nprivacy standards. We introduce DP-Fed-FinDiff framework, a novel integration\nof Differential Privacy, Federated Learning and Denoising Diffusion\nProbabilistic Models designed to generate high-fidelity synthetic tabular data.\nThis framework ensures compliance with stringent privacy regulations while\nmaintaining data utility. We demonstrate the effectiveness of DP-Fed-FinDiff on\nmultiple real-world financial datasets, achieving significant improvements in\nprivacy guarantees without compromising data quality. Our empirical evaluations\nreveal the optimal trade-offs between privacy budgets, client configurations,\nand federated optimization strategies. The results affirm the potential of\nDP-Fed-FinDiff to enable secure data sharing and robust analytics in highly\nregulated domains, paving the way for further advances in federated learning\nand privacy-preserving data synthesis.", "published": "2024-12-20 17:30:58", "link": "http://arxiv.org/abs/2412.16083v1", "categories": ["cs.LG", "q-fin.ST"], "primary_category": "cs.LG"}
{"title": "Battery valuation on electricity intraday markets with liquidity costs", "abstract": "In this paper, we propose a complete modelling framework to value several\nbatteries in the electricity intraday market at the trading session scale. The\nmodel consists of a stochastic model for the 24 mid-prices (one price per\ndelivery hour) combined with a deterministic model for the liquidity costs\n(representing the cost of going deeper in the order book). A stochastic\noptimisation framework based on dynamic programming is used to calculate the\nvalue of the batteries. We carry out a back test for the years 2021, 2022 and\n2023 for the German market and for the French market. We show that it is\nessential to take liquidity into account, especially when the number of\nbatteries is large: it allows much higher profits and avoids high losses using\nour liquidity model. The use of our stochastic model for the mid-price also\nsignificantly improves the results (compared to a deterministic framework where\nthe mid-price forecast is the spot price).", "published": "2024-12-20 14:52:51", "link": "http://arxiv.org/abs/2412.15959v1", "categories": ["q-fin.TR", "q-fin.ST"], "primary_category": "q-fin.TR"}
{"title": "A Review of the Marathi Natural Language Processing", "abstract": "Marathi is one of the most widely used languages in the world. One might\nexpect that the latest advances in NLP research in languages like English reach\nsuch a large community. However, NLP advancements in English didn't immediately\nreach Indian languages like Marathi. There were several reasons for this. They\nincluded diversity of scripts used, lack of (publicly available) resources like\ntokenization strategies, high quality datasets \\& benchmarks, and evaluation\nmetrics. In addition to this, the morphologically rich nature of Marathi, made\nNLP tasks challenging. Advances in Neural Network (NN) based models and tools\nsince the early 2000s helped improve this situation and make NLP research more\naccessible. In the past 10 years, significant efforts were made to improve\nlanguage resources for all 22 scheduled languages of India. This paper presents\na broad overview of evolution of NLP research in Indic languages with a focus\non Marathi and state-of-the-art resources and tools available to the research\ncommunity. It also provides an overview of tools \\& techniques associated with\nMarathi NLP tasks.", "published": "2024-12-20 00:56:13", "link": "http://arxiv.org/abs/2412.15471v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Multi-LLM Text Summarization", "abstract": "In this work, we propose a Multi-LLM summarization framework, and investigate\ntwo different multi-LLM strategies including centralized and decentralized. Our\nmulti-LLM summarization framework has two fundamentally important steps at each\nround of conversation: generation and evaluation. These steps are different\ndepending on whether our multi-LLM decentralized summarization is used or\ncentralized. In both our multi-LLM decentralized and centralized strategies, we\nhave k different LLMs that generate diverse summaries of the text. However,\nduring evaluation, our multi-LLM centralized summarization approach leverages a\nsingle LLM to evaluate the summaries and select the best one whereas k LLMs are\nused for decentralized multi-LLM summarization. Overall, we find that our\nmulti-LLM summarization approaches significantly outperform the baselines that\nleverage only a single LLM by up to 3x. These results indicate the\neffectiveness of multi-LLM approaches for summarization.", "published": "2024-12-20 01:55:26", "link": "http://arxiv.org/abs/2412.15487v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mitigating Social Bias in Large Language Models: A Multi-Objective\n  Approach within a Multi-Agent Framework", "abstract": "Natural language processing (NLP) has seen remarkable advancements with the\ndevelopment of large language models (LLMs). Despite these advancements, LLMs\noften produce socially biased outputs. Recent studies have mainly addressed\nthis problem by prompting LLMs to behave ethically, but this approach results\nin unacceptable performance degradation. In this paper, we propose a\nmulti-objective approach within a multi-agent framework (MOMA) to mitigate\nsocial bias in LLMs without significantly compromising their performance. The\nkey idea of MOMA involves deploying multiple agents to perform causal\ninterventions on bias-related contents of the input questions, breaking the\nshortcut connection between these contents and the corresponding answers.\nUnlike traditional debiasing techniques leading to performance degradation,\nMOMA substantially reduces bias while maintaining accuracy in downstream tasks.\nOur experiments conducted on two datasets and two models demonstrate that MOMA\nreduces bias scores by up to 87.7%, with only a marginal performance\ndegradation of up to 6.8% in the BBQ dataset. Additionally, it significantly\nenhances the multi-objective metric icat in the StereoSet dataset by up to\n58.1%. Code will be made available at https://github.com/Cortantse/MOMA.", "published": "2024-12-20 02:35:39", "link": "http://arxiv.org/abs/2412.15504v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MRAG: A Modular Retrieval Framework for Time-Sensitive Question\n  Answering", "abstract": "Understanding temporal relations and answering time-sensitive questions is\ncrucial yet a challenging task for question-answering systems powered by large\nlanguage models (LLMs). Existing approaches either update the parametric\nknowledge of LLMs with new facts, which is resource-intensive and often\nimpractical, or integrate LLMs with external knowledge retrieval (i.e.,\nretrieval-augmented generation). However, off-the-shelf retrievers often\nstruggle to identify relevant documents that require intensive temporal\nreasoning. To systematically study time-sensitive question answering, we\nintroduce the TempRAGEval benchmark, which repurposes existing datasets by\nincorporating temporal perturbations and gold evidence labels. As anticipated,\nall existing retrieval methods struggle with these temporal reasoning-intensive\nquestions. We further propose Modular Retrieval (MRAG), a trainless framework\nthat includes three modules: (1) Question Processing that decomposes question\ninto a main content and a temporal constraint; (2) Retrieval and Summarization\nthat retrieves evidence and uses LLMs to summarize according to the main\ncontent; (3) Semantic-Temporal Hybrid Ranking that scores each evidence\nsummarization based on both semantic and temporal relevance. On TempRAGEval,\nMRAG significantly outperforms baseline retrievers in retrieval performance,\nleading to further improvements in final answer accuracy.", "published": "2024-12-20 03:58:27", "link": "http://arxiv.org/abs/2412.15540v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional\n  Generalization", "abstract": "Compositional generalization is crucial for artificial intelligence agents to\nsolve complex vision-language reasoning tasks. Neuro-symbolic approaches have\ndemonstrated promise in capturing compositional structures, but they face\ncritical challenges: (a) reliance on predefined predicates for symbolic\nrepresentations that limit adaptability, (b) difficulty in extracting\npredicates from raw data, and (c) using non-differentiable operations for\ncombining primitive concepts. To address these issues, we propose NeSyCoCo, a\nneuro-symbolic framework that leverages large language models (LLMs) to\ngenerate symbolic representations and map them to differentiable neural\ncomputations. NeSyCoCo introduces three innovations: (a) augmenting natural\nlanguage inputs with dependency structures to enhance the alignment with\nsymbolic representations, (b) employing distributed word representations to\nlink diverse, linguistically motivated logical predicates to neural modules,\nand (c) using the soft composition of normalized predicate scores to align\nsymbolic and differentiable reasoning. Our framework achieves state-of-the-art\nresults on the ReaSCAN and CLEVR-CoGenT compositional generalization benchmarks\nand demonstrates robust performance with novel concepts in the CLEVR-SYN\nbenchmark.", "published": "2024-12-20 05:48:58", "link": "http://arxiv.org/abs/2412.15588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Template-Driven LLM-Paraphrased Framework for Tabular Math Word Problem\n  Generation", "abstract": "Solving tabular math word problems (TMWPs) has become a critical role in\nevaluating the mathematical reasoning ability of large language models (LLMs),\nwhere large-scale TMWP samples are commonly required for LLM fine-tuning. Since\nthe collection of high-quality TMWP datasets is costly and time-consuming,\nrecent research has concentrated on automatic TMWP generation. However, current\ngenerated samples usually suffer from issues of either correctness or\ndiversity. In this paper, we propose a Template-driven LLM-paraphrased (TeLL)\nframework for generating high-quality TMWP samples with diverse backgrounds and\naccurate tables, questions, answers, and solutions. To this end, we first\nextract templates from existing real samples to generate initial problems,\nensuring correctness. Then, we adopt an LLM to extend templates and paraphrase\nproblems, obtaining diverse TMWP samples. Furthermore, we find the reasoning\nannotation is important for solving TMWPs. Therefore, we propose to enrich each\nsolution with illustrative reasoning steps. Through the proposed framework, we\nconstruct a high-quality dataset TabMWP-TeLL by adhering to the question types\nin the TabMWP dataset, and we conduct extensive experiments on a variety of\nLLMs to demonstrate the effectiveness of TabMWP-TeLL in improving TMWP solving\nperformance. The code and data of this paper are available at:\nhttps://github.com/Jason8Kang/TELL.", "published": "2024-12-20 06:34:57", "link": "http://arxiv.org/abs/2412.15594v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dynamic Label Name Refinement for Few-Shot Dialogue Intent\n  Classification", "abstract": "Dialogue intent classification aims to identify the underlying purpose or\nintent of a user's input in a conversation. Current intent classification\nsystems encounter considerable challenges, primarily due to the vast number of\npossible intents and the significant semantic overlap among similar intent\nclasses. In this paper, we propose a novel approach to few-shot dialogue intent\nclassification through in-context learning, incorporating dynamic label\nrefinement to address these challenges. Our method retrieves relevant examples\nfor a test input from the training set and leverages a large language model to\ndynamically refine intent labels based on semantic understanding, ensuring that\nintents are clearly distinguishable from one another. Experimental results\ndemonstrate that our approach effectively resolves confusion between\nsemantically similar intents, resulting in significantly enhanced performance\nacross multiple datasets compared to baselines. We also show that our method\ngenerates more interpretable intent labels, and has a better semantic coherence\nin capturing underlying user intents compared to baselines.", "published": "2024-12-20 06:53:57", "link": "http://arxiv.org/abs/2412.15603v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Don't Do RAG: When Cache-Augmented Generation is All You Need for\n  Knowledge Tasks", "abstract": "Retrieval-augmented generation (RAG) has gained traction as a powerful\napproach for enhancing language models by integrating external knowledge\nsources. However, RAG introduces challenges such as retrieval latency,\npotential errors in document selection, and increased system complexity. With\nthe advent of large language models (LLMs) featuring significantly extended\ncontext windows, this paper proposes an alternative paradigm, cache-augmented\ngeneration (CAG) that bypasses real-time retrieval. Our method involves\npreloading all relevant resources, especially when the documents or knowledge\nfor retrieval are of a limited and manageable size, into the LLM's extended\ncontext and caching its runtime parameters. During inference, the model\nutilizes these preloaded parameters to answer queries without additional\nretrieval steps. Comparative analyses reveal that CAG eliminates retrieval\nlatency and minimizes retrieval errors while maintaining context relevance.\nPerformance evaluations across multiple benchmarks highlight scenarios where\nlong-context LLMs either outperform or complement traditional RAG pipelines.\nThese findings suggest that, for certain applications, particularly those with\na constrained knowledge base, CAG provide a streamlined and efficient\nalternative to RAG, achieving comparable or superior results with reduced\ncomplexity.", "published": "2024-12-20 06:58:32", "link": "http://arxiv.org/abs/2412.15605v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Input Attributions Interpret the Inductive Reasoning Process in\n  In-Context Learning?", "abstract": "Interpreting the internal process of neural models has long been a challenge.\nThis challenge remains relevant in the era of large language models (LLMs) and\nin-context learning (ICL); for example, ICL poses a new issue of interpreting\nwhich example in the few-shot examples contributed to identifying/solving the\ntask. To this end, in this paper, we design synthetic diagnostic tasks of\ninductive reasoning, inspired by the generalization tests in linguistics; here,\nmost in-context examples are ambiguous w.r.t. their underlying rule, and one\ncritical example disambiguates the task demonstrated. The question is whether\nconventional input attribution (IA) methods can track such a reasoning process,\ni.e., identify the influential example, in ICL. Our experiments provide several\npractical findings; for example, a certain simple IA method works the best, and\nthe larger the model, the generally harder it is to interpret the ICL with\ngradient-based IA methods.", "published": "2024-12-20 07:35:42", "link": "http://arxiv.org/abs/2412.15628v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Error-driven Data-efficient Large Multimodal Model Tuning", "abstract": "Large Multimodal Models (LMMs) have demonstrated impressive performance\nacross numerous academic benchmarks. However, fine-tuning still remains\nessential to achieve satisfactory performance on downstream tasks, while the\ntask-specific tuning samples are usually not readily available or expensive and\ntime-consuming to obtain. To address this, we propose an error-driven\ndata-efficient tuning framework that aims to efficiently adapt generic LMMs to\nnewly emerging tasks without requiring any task-specific training samples. In\nour approach, a generic LMM, acting as a student model, is first evaluated on a\nsmall validation set of the target task, and then a more powerful model, acting\nas a teacher model, identifies the erroneous steps within the student model's\nreasoning steps and analyzes its capability gaps from fully addressing the\ntarget task. Based on these gaps, targeted training samples are further\nretrieved from existing task-agnostic datasets to tune the student model and\ntailor it to the target task. We perform extensive experiments across three\ndifferent training data scales and seven tasks, demonstrating that our training\nparadigm significantly and efficiently improves LMM's performance on downstream\ntasks, achieving an average performance boost of 7.01%.", "published": "2024-12-20 08:07:11", "link": "http://arxiv.org/abs/2412.15652v1", "categories": ["cs.CL", "H.m"], "primary_category": "cs.CL"}
{"title": "Variability Need Not Imply Error: The Case of Adequate but Semantically\n  Distinct Responses", "abstract": "With the broader use of language models (LMs) comes the need to estimate\ntheir ability to respond reliably to prompts (e.g., are generated responses\nlikely to be correct?). Uncertainty quantification tools (notions of confidence\nand entropy, i.a.) can be used to that end (e.g., to reject a response when the\nmodel is `uncertain'). For example, Kuhn et al. (semantic entropy; 2022b)\nregard semantic variation amongst sampled responses as evidence that the model\n`struggles' with the prompt and that the LM is likely to err. We argue that\nsemantic variability need not imply error--this being especially intuitive in\nopen-ended settings, where prompts elicit multiple adequate but semantically\ndistinct responses. Hence, we propose to annotate sampled responses for their\nadequacy to the prompt (e.g., using a classifier) and estimate the Probability\nthe model assigns to Adequate Responses (PROBAR), which we then regard as an\nindicator of the model's reliability at the instance level. We evaluate PROBAR\nas a measure of confidence in selective prediction with OPT models (in two QA\ndatasets and in next-word prediction, for English) and find PROBAR to\noutperform semantic entropy across prompts with varying degrees of\nambiguity/open-endedness.", "published": "2024-12-20 09:02:26", "link": "http://arxiv.org/abs/2412.15683v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning from Impairment: Leveraging Insights from Clinical Linguistics\n  in Language Modelling Research", "abstract": "This position paper investigates the potential of integrating insights from\nlanguage impairment research and its clinical treatment to develop\nhuman-inspired learning strategies and evaluation frameworks for language\nmodels (LMs). We inspect the theoretical underpinnings underlying some\ninfluential linguistically motivated training approaches derived from\nneurolinguistics and, particularly, aphasiology, aimed at enhancing the\nrecovery and generalization of linguistic skills in aphasia treatment, with a\nprimary focus on those targeting the syntactic domain. We highlight how these\ninsights can inform the design of rigorous assessments for LMs, specifically in\ntheir handling of complex syntactic phenomena, as well as their implications\nfor developing human-like learning strategies, aligning with efforts to create\nmore sustainable and cognitively plausible natural language processing (NLP)\nmodels.", "published": "2024-12-20 10:53:21", "link": "http://arxiv.org/abs/2412.15785v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ensembling Large Language Models with Process Reward-Guided Tree Search\n  for Better Complex Reasoning", "abstract": "Despite recent advances in large language models, open-source models often\nstruggle to consistently perform well on complex reasoning tasks. Existing\nensemble methods, whether applied at the token or output levels, fail to\naddress these challenges. In response, we present Language model Ensemble with\nMonte Carlo Tree Search (LE-MCTS), a novel framework for process-level\nensembling of language models. LE-MCTS formulates step-by-step reasoning with\nan ensemble of language models as a Markov decision process. In this framework,\nstates represent intermediate reasoning paths, while actions consist of\ngenerating the next reasoning step using one of the language models selected\nfrom a predefined pool. Guided by a process-based reward model, LE-MCTS\nperforms a tree search over the reasoning steps generated by different language\nmodels, identifying the most accurate reasoning chain. Experimental results on\nfive mathematical reasoning benchmarks demonstrate that our approach\noutperforms both single language model decoding algorithms and language model\nensemble methods. Notably, LE-MCTS improves performance by 3.6% and 4.3% on the\nMATH and MQA datasets, respectively, highlighting its effectiveness in solving\ncomplex reasoning problems.", "published": "2024-12-20 11:14:29", "link": "http://arxiv.org/abs/2412.15797v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Thorough Investigation into the Application of Deep CNN for Enhancing\n  Natural Language Processing Capabilities", "abstract": "Natural Language Processing (NLP) is widely used in fields like machine\ntranslation and sentiment analysis. However, traditional NLP models struggle\nwith accuracy and efficiency. This paper introduces Deep Convolutional Neural\nNetworks (DCNN) into NLP to address these issues. By integrating DCNN, machine\nlearning (ML) algorithms, and generative adversarial networks (GAN), the study\nimproves language understanding, reduces ambiguity, and enhances task\nperformance. The high-performance NLP model shows a 10% improvement in\nsegmentation accuracy and a 4% increase in recall rate compared to traditional\nmodels. This integrated approach excels in tasks such as word segmentation,\npart-of-speech tagging, machine translation, and text classification, offering\nbetter recognition accuracy and processing efficiency.", "published": "2024-12-20 13:53:41", "link": "http://arxiv.org/abs/2412.15900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BabyHGRN: Exploring RNNs for Sample-Efficient Training of Language\n  Models", "abstract": "This paper explores the potential of recurrent neural networks (RNNs) and\nother subquadratic architectures as competitive alternatives to\ntransformer-based models in low-resource language modeling scenarios. We\nutilize HGRN2 (Qin et al., 2024), a recently proposed RNN-based architecture,\nand comparatively evaluate its effectiveness against transformer-based\nbaselines and other subquadratic architectures (LSTM, xLSTM, Mamba). Our\nexperimental results show that BABYHGRN, our HGRN2 language model, outperforms\ntransformer-based models in both the 10M and 100M word tracks of the challenge,\nas measured by their performance on the BLiMP, EWoK, GLUE and BEAR benchmarks.\nFurther, we show the positive impact of knowledge distillation. Our findings\nchallenge the prevailing focus on transformer architectures and indicate the\nviability of RNN-based models, particularly in resource-constrained\nenvironments.", "published": "2024-12-20 15:21:41", "link": "http://arxiv.org/abs/2412.15978v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fearful Falcons and Angry Llamas: Emotion Category Annotations of\n  Arguments by Humans and LLMs", "abstract": "Arguments evoke emotions, influencing the effect of the argument itself. Not\nonly the emotional intensity but also the category influence the argument's\neffects, for instance, the willingness to adapt stances. While binary\nemotionality has been studied in arguments, there is no work on discrete\nemotion categories (e.g., \"Anger\") in such data. To fill this gap, we\ncrowdsource subjective annotations of emotion categories in a German argument\ncorpus and evaluate automatic LLM-based labeling methods. Specifically, we\ncompare three prompting strategies (zero-shot, one-shot, chain-of-thought) on\nthree large instruction-tuned language models (Falcon-7b-instruct,\nLlama-3.1-8B-instruct, GPT-4o-mini). We further vary the definition of the\noutput space to be binary (is there emotionality in the argument?),\nclosed-domain (which emotion from a given label set is in the argument?), or\nopen-domain (which emotion is in the argument?). We find that emotion\ncategories enhance the prediction of emotionality in arguments, emphasizing the\nneed for discrete emotion annotations in arguments. Across all prompt settings\nand models, automatic predictions show a high recall but low precision for\npredicting anger and fear, indicating a strong bias toward negative emotions.", "published": "2024-12-20 15:41:47", "link": "http://arxiv.org/abs/2412.15993v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Logical Consistency of Large Language Models in Fact-checking", "abstract": "In recent years, large language models (LLMs) have demonstrated significant\nsuccess in performing varied natural language tasks such as language\ntranslation, question-answering, summarizing, fact-checking, etc. Despite LLMs'\nimpressive ability to generate human-like texts, LLMs are infamous for their\ninconsistent responses - a meaning-preserving change in the input query results\nin an inconsistent response and attributes to vulnerabilities of LLMs such as\nhallucination. Consequently, existing research focuses on simple\nparaphrasing-based consistency assessment of LLMs, and ignores complex queries\nthat necessitate an even better understanding of logical reasoning by an LLM.\nOur work therefore addresses the logical inconsistency of LLMs under complex\nlogical queries with primitive logical operators, e.g., negation, conjunction,\nand disjunction. As a test bed, we consider retrieval-augmented LLMs on a\nfact-checking task involving propositional logic queries from knowledge graphs\n(KGs). Our contributions are threefold. Benchmark: We introduce three logical\nfact-checking datasets over KGs for community development towards logically\nconsistent LLMs. Assessment: We propose consistency measures of LLMs on\npropositional logic queries and demonstrate that existing LLMs lack logical\nconsistency, especially on complex queries. Improvement: We employ supervised\nfine-tuning to improve the logical consistency of LLMs on the complex\nfact-checking task with KG contexts. We have made our source code and\nbenchmarks available.", "published": "2024-12-20 17:42:25", "link": "http://arxiv.org/abs/2412.16100v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PromptOptMe: Error-Aware Prompt Compression for LLM-based MT Evaluation\n  Metrics", "abstract": "Evaluating the quality of machine-generated natural language content is a\nchallenging task in Natural Language Processing (NLP). Recently, large language\nmodels (LLMs) like GPT-4 have been employed for this purpose, but they are\ncomputationally expensive due to the extensive token usage required by complex\nevaluation prompts. In this paper, we propose a prompt optimization approach\nthat uses a smaller, fine-tuned language model to compress input data for\nevaluation prompt, thus reducing token usage and computational cost when using\nlarger LLMs for downstream evaluation. Our method involves a two-stage\nfine-tuning process: supervised fine-tuning followed by preference optimization\nto refine the model's outputs based on human preferences. We focus on Machine\nTranslation (MT) evaluation and utilize the GEMBA-MQM metric as a starting\npoint. Our results show a $2.37\\times$ reduction in token usage without any\nloss in evaluation quality. This work makes state-of-the-art LLM-based metrics\nlike GEMBA-MQM more cost-effective and efficient, enhancing their accessibility\nfor broader use.", "published": "2024-12-20 18:08:02", "link": "http://arxiv.org/abs/2412.16120v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KRAIL: A Knowledge-Driven Framework for Base Human Reliability Analysis\n  Integrating IDHEAS and Large Language Models", "abstract": "Human reliability analysis (HRA) is crucial for evaluating and improving the\nsafety of complex systems. Recent efforts have focused on estimating human\nerror probability (HEP), but existing methods often rely heavily on expert\nknowledge,which can be subjective and time-consuming. Inspired by the success\nof large language models (LLMs) in natural language processing, this paper\nintroduces a novel two-stage framework for knowledge-driven reliability\nanalysis, integrating IDHEAS and LLMs (KRAIL). This innovative framework\nenables the semi-automated computation of base HEP values. Additionally,\nknowledge graphs are utilized as a form of retrieval-augmented generation (RAG)\nfor enhancing the framework' s capability to retrieve and process relevant data\nefficiently. Experiments are systematically conducted and evaluated on\nauthoritative datasets of human reliability. The experimental results of the\nproposed methodology demonstrate its superior performance on base HEP\nestimation under partial information for reliability assessment.", "published": "2024-12-20 06:21:34", "link": "http://arxiv.org/abs/2412.18627v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Continual Learning Using Only Large Language Model Prompting", "abstract": "We introduce CLOB, a novel continual learning (CL) paradigm wherein a large\nlanguage model (LLM) is regarded as a black box. Learning is done incrementally\nvia only verbal prompting. CLOB does not fine-tune any part of the LLM or add\nany trainable parameters to it. It is particularly suitable for LLMs that are\naccessible via APIs. We also propose a new CL technique, called CIS, based on\nincremental summarization that also overcomes the LLM's input length limit.\nExperiments show CIS outperforms baselines by a very large margin.", "published": "2024-12-20 01:21:57", "link": "http://arxiv.org/abs/2412.15479v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TL-Training: A Task-Feature-Based Framework for Training Large Language\n  Models in Tool Use", "abstract": "Large language models (LLMs) achieve remarkable advancements by leveraging\ntools to interact with external environments, a critical step toward\ngeneralized AI. However, the standard supervised fine-tuning (SFT) approach,\nwhich relies on large-scale datasets, often overlooks task-specific\ncharacteristics in tool use, leading to performance bottlenecks. To address\nthis issue, we analyze three existing LLMs and uncover key insights: training\ndata can inadvertently impede tool-use behavior, token importance is\ndistributed unevenly, and errors in tool calls fall into a small set of\ndistinct categories. Building on these findings, we propose TL-Training, a\ntask-feature-based framework that mitigates the effects of suboptimal training\ndata, dynamically adjusts token weights to prioritize key tokens during SFT,\nand incorporates a robust reward mechanism tailored to error categories,\noptimized through proximal policy optimization. We validate TL-Training by\ntraining CodeLLaMA-2-7B and evaluating it on four diverse open-source test\nsets. Our results demonstrate that the LLM trained by our method matches or\nsurpasses both open- and closed-source LLMs in tool-use performance using only\n1,217 training data points. Additionally, our method enhances robustness in\nnoisy environments and improves general task performance, offering a scalable\nand efficient paradigm for tool-use training in LLMs. The code and data are\navailable at https://github.com/Junjie-Ye/TL-Training.", "published": "2024-12-20 02:21:36", "link": "http://arxiv.org/abs/2412.15495v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lexicography Saves Lives (LSL): Automatically Translating\n  Suicide-Related Language", "abstract": "Recent years have seen a marked increase in research that aims to identify or\npredict risk, intention or ideation of suicide. The majority of new tasks,\ndatasets, language models and other resources focus on English and on suicide\nin the context of Western culture. However, suicide is global issue and\nreducing suicide rate by 2030 is one of the key goals of the UN's Sustainable\nDevelopment Goals. Previous work has used English dictionaries related to\nsuicide to translate into different target languages due to lack of other\navailable resources. Naturally, this leads to a variety of ethical tensions\n(e.g.: linguistic misrepresentation), where discourse around suicide is not\npresent in a particular culture or country. In this work, we introduce the\n'Lexicography Saves Lives Project' to address this issue and make three\ndistinct contributions. First, we outline ethical consideration and provide\noverview guidelines to mitigate harm in developing suicide-related resources.\nNext, we translate an existing dictionary related to suicidal ideation into 200\ndifferent languages and conduct human evaluations on a subset of translated\ndictionaries. Finally, we introduce a public website to make our resources\navailable and enable community participation.", "published": "2024-12-20 02:23:36", "link": "http://arxiv.org/abs/2412.15497v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The First Multilingual Model For The Detection of Suicide Texts", "abstract": "Suicidal ideation is a serious health problem affecting millions of people\nworldwide. Social networks provide information about these mental health\nproblems through users' emotional expressions. We propose a multilingual model\nleveraging transformer architectures like mBERT, XML-R, and mT5 to detect\nsuicidal text across posts in six languages - Spanish, English, German,\nCatalan, Portuguese and Italian. A Spanish suicide ideation tweet dataset was\ntranslated into five other languages using SeamlessM4T. Each model was\nfine-tuned on this multilingual data and evaluated across classification\nmetrics. Results showed mT5 achieving the best performance overall with F1\nscores above 85%, highlighting capabilities for cross-lingual transfer\nlearning. The English and Spanish translations also displayed high quality\nbased on perplexity. Our exploration underscores the importance of considering\nlinguistic diversity in developing automated multilingual tools to identify\nsuicidal risk. Limitations exist around semantic fidelity in translations and\nethical implications which provide guidance for future human-in-the-loop\nevaluations.", "published": "2024-12-20 02:23:59", "link": "http://arxiv.org/abs/2412.15498v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Humanlike Cognitive Patterns as Emergent Phenomena in Large Language\n  Models", "abstract": "Research on emergent patterns in Large Language Models (LLMs) has gained\nsignificant traction in both psychology and artificial intelligence, motivating\nthe need for a comprehensive review that offers a synthesis of this complex\nlandscape. In this article, we systematically review LLMs' capabilities across\nthree important cognitive domains: decision-making biases, reasoning, and\ncreativity. We use empirical studies drawing on established psychological tests\nand compare LLMs' performance to human benchmarks. On decision-making, our\nsynthesis reveals that while LLMs demonstrate several human-like biases, some\nbiases observed in humans are absent, indicating cognitive patterns that only\npartially align with human decision-making. On reasoning, advanced LLMs like\nGPT-4 exhibit deliberative reasoning akin to human System-2 thinking, while\nsmaller models fall short of human-level performance. A distinct dichotomy\nemerges in creativity: while LLMs excel in language-based creative tasks, such\nas storytelling, they struggle with divergent thinking tasks that require\nreal-world context. Nonetheless, studies suggest that LLMs hold considerable\npotential as collaborators, augmenting creativity in human-machine\nproblem-solving settings. Discussing key limitations, we also offer guidance\nfor future research in areas such as memory, attention, and open-source model\ndevelopment.", "published": "2024-12-20 02:26:56", "link": "http://arxiv.org/abs/2412.15501v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ADEQA: A Question Answer based approach for joint ADE-Suspect Extraction\n  using Sequence-To-Sequence Transformers", "abstract": "Early identification of Adverse Drug Events (ADE) is critical for taking\nprompt actions while introducing new drugs into the market. These ADEs\ninformation are available through various unstructured data sources like\nclinical study reports, patient health records, social media posts, etc.\nExtracting ADEs and the related suspect drugs using machine learning is a\nchallenging task due to the complex linguistic relations between drug ADE pairs\nin textual data and unavailability of large corpus of labelled datasets. This\npaper introduces ADEQA, a question-answer(QA) based approach using quasi\nsupervised labelled data and sequence-to-sequence transformers to extract ADEs,\ndrug suspects and the relationships between them. Unlike traditional QA models,\nnatural language generation (NLG) based models don't require extensive token\nlevel labelling and thereby reduces the adoption barrier significantly. On a\npublic ADE corpus, we were able to achieve state-of-the-art results with an F1\nscore of 94% on establishing the relationships between ADEs and the respective\nsuspects.", "published": "2024-12-20 02:48:59", "link": "http://arxiv.org/abs/2412.15510v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "HREF: Human Response-Guided Evaluation of Instruction Following in\n  Language Models", "abstract": "Evaluating the capability of Large Language Models (LLMs) in following\ninstructions has heavily relied on a powerful LLM as the judge, introducing\nunresolved biases that deviate the judgments from human judges. In this work,\nwe reevaluate various choices for automatic evaluation on a wide range of\ninstruction-following tasks. We experiment with methods that leverage\nhuman-written responses and observe that they enhance the reliability of\nautomatic evaluations across a wide range of tasks, resulting in up to a 3.2%\nimprovement in agreement with human judges. We also discovered that\nhuman-written responses offer an orthogonal perspective to model-generated\nresponses in following instructions and should be used as an additional context\nwhen comparing model responses. Based on these observations, we develop a new\nevaluation benchmark, Human Response-Guided Evaluation of Instruction Following\n(HREF), comprising 4,258 samples across 11 task categories with a composite\nevaluation setup, employing a composite evaluation setup that selects the most\nreliable method for each category. In addition to providing reliable\nevaluation, HREF emphasizes individual task performance and is free from\ncontamination. Finally, we study the impact of key design choices in HREF,\nincluding the size of the evaluation set, the judge model, the baseline model,\nand the prompt template. We host a live leaderboard that evaluates LLMs on the\nprivate evaluation set of HREF.", "published": "2024-12-20 03:26:47", "link": "http://arxiv.org/abs/2412.15524v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "XRAG: eXamining the Core -- Benchmarking Foundational Components in\n  Advanced Retrieval-Augmented Generation", "abstract": "Retrieval-augmented generation (RAG) synergizes the retrieval of pertinent\ndata with the generative capabilities of Large Language Models (LLMs), ensuring\nthat the generated output is not only contextually relevant but also accurate\nand current. We introduce XRAG, an open-source, modular codebase that\nfacilitates exhaustive evaluation of the performance of foundational components\nof advanced RAG modules. These components are systematically categorized into\nfour core phases: pre-retrieval, retrieval, post-retrieval, and generation. We\nsystematically analyse them across reconfigured datasets, providing a\ncomprehensive benchmark for their effectiveness. As the complexity of RAG\nsystems continues to escalate, we underscore the critical need to identify\npotential failure points in RAG systems. We formulate a suite of experimental\nmethodologies and diagnostic testing protocols to dissect the failure points\ninherent in RAG engineering. Subsequently, we proffer bespoke solutions aimed\nat bolstering the overall performance of these modules. Our work thoroughly\nevaluates the performance of advanced core components in RAG systems, providing\ninsights into optimizations for prevalent failure points.", "published": "2024-12-20 03:37:07", "link": "http://arxiv.org/abs/2412.15529v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MORTAR: Metamorphic Multi-turn Testing for LLM-based Dialogue Systems", "abstract": "With the widespread application of LLM-based dialogue systems in daily life,\nquality assurance has become more important than ever. Recent research has\nsuccessfully introduced methods to identify unexpected behaviour in single-turn\nscenarios. However, multi-turn dialogue testing remains underexplored, with the\nOracle problem in multi-turn testing posing a persistent challenge for dialogue\nsystem developers and researchers. In this paper, we propose MORTAR, a\nMetamORphic multi-TuRn diAlogue testing appRoach, which mitigates the test\noracle problem in the assessment of LLM-based dialogue systems. MORTAR\nautomates the generation of follow-up question-answer (QA) dialogue test cases\nwith multiple dialogue-level perturbations and metamorphic relations. MORTAR\nemploys a novel knowledge graph-based dialogue information model which\neffectively generates perturbed dialogue test datasets and detects bugs of\nmulti-turn dialogue systems in a low-cost manner. The proposed approach does\nnot require an LLM as a judge, eliminating potential of any biases in the\nevaluation step. According to the experiment results on multiple LLM-based\ndialogue systems and comparisons with single-turn metamorphic testing\napproaches, MORTAR explores more unique bugs in LLM-based dialogue systems,\nespecially for severe bugs that MORTAR detects up to four times more unique\nbugs than the most effective existing metamorphic testing approach.", "published": "2024-12-20 04:31:03", "link": "http://arxiv.org/abs/2412.15557v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "A Fusion Approach of Dependency Syntax and Sentiment Polarity for\n  Feature Label Extraction in Commodity Reviews", "abstract": "This study analyzes 13,218 product reviews from JD.com, covering four\ncategories: mobile phones, computers, cosmetics, and food. A novel method for\nfeature label extraction is proposed by integrating dependency parsing and\nsentiment polarity analysis. The proposed method addresses the challenges of\nlow robustness in existing extraction algorithms and significantly enhances\nextraction accuracy. Experimental results show that the method achieves an\naccuracy of 0.7, with recall and F-score both stabilizing at 0.8, demonstrating\nits effectiveness. However, challenges such as dependence on matching\ndictionaries and the limited scope of extracted feature tags require further\ninvestigation in future research.", "published": "2024-12-20 07:07:18", "link": "http://arxiv.org/abs/2412.15610v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical\n  Speech-to-Formula", "abstract": "In various academic and professional settings, such as mathematics lectures\nor research presentations, it is often necessary to convey mathematical\nexpressions orally. However, reading mathematical expressions aloud without\naccompanying visuals can significantly hinder comprehension, especially for\nthose who are hearing-impaired or rely on subtitles due to language barriers.\nFor instance, when a presenter reads Euler's Formula, current Automatic Speech\nRecognition (ASR) models often produce a verbose and error-prone textual\ndescription (e.g., e to the power of i x equals cosine of x plus i\n$\\textit{side}$ of x), instead of the concise $\\LaTeX{}$ format (i.e., $ e^{ix}\n= \\cos(x) + i\\sin(x) $), which hampers clear understanding and communication.\nTo address this issue, we introduce MathSpeech, a novel pipeline that\nintegrates ASR models with small Language Models (sLMs) to correct errors in\nmathematical expressions and accurately convert spoken expressions into\nstructured $\\LaTeX{}$ representations. Evaluated on a new dataset derived from\nlecture recordings, MathSpeech demonstrates $\\LaTeX{}$ generation capabilities\ncomparable to leading commercial Large Language Models (LLMs), while leveraging\nfine-tuned small language models of only 120M parameters. Specifically, in\nterms of CER, BLEU, and ROUGE scores for $\\LaTeX{}$ translation, MathSpeech\ndemonstrated significantly superior capabilities compared to GPT-4o. We\nobserved a decrease in CER from 0.390 to 0.298, and higher ROUGE/BLEU scores\ncompared to GPT-4o.", "published": "2024-12-20 08:13:05", "link": "http://arxiv.org/abs/2412.15655v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Contrastive Learning for Task-Independent SpeechLLM-Pretraining", "abstract": "Large language models (LLMs) excel in natural language processing but\nadapting these LLMs to speech processing tasks efficiently is not\nstraightforward. Direct task-specific fine-tuning is limited by overfitting\nrisks, data requirements, and computational costs. To address these challenges,\nwe propose a scalable, two-stage training approach: (1) A task-independent\nspeech pretraining stage using contrastive learning to align text and speech\nrepresentations over all layers, followed by (2) a task-specific fine-tuning\nstage requiring minimal data. This approach outperforms traditional ASR\npretraining and enables the model to surpass models specialized on speech\ntranslation and question answering while being trained on only 10% of the\ntask-specific data.", "published": "2024-12-20 09:33:31", "link": "http://arxiv.org/abs/2412.15712v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Fine-tuning Whisper on Low-Resource Languages for Real-World\n  Applications", "abstract": "This paper presents a new approach to fine-tuning OpenAI's Whisper model for\nlow-resource languages by introducing a novel data generation method that\nconverts sentence-level data into a long-form corpus, using Swiss German as a\ncase study. Non-sentence-level data, which could improve the performance of\nlong-form audio, is difficult to obtain and often restricted by copyright laws.\nOur method bridges this gap by transforming more accessible sentence-level data\ninto a format that preserves the model's ability to handle long-form audio and\nperform segmentation without requiring non-sentence-level data. Our data\ngeneration process improves performance in several real-world applications and\nleads to the development of a new state-of-the-art speech-to-text (STT) model\nfor Swiss German. We compare our model with a non-fine-tuned Whisper and our\nprevious state-of-the-art Swiss German STT models, where our new model achieves\nhigher BLEU scores. Our results also indicate that the proposed method is\nadaptable to other low-resource languages, supported by written guidance and\ncode that allows the creation of fine-tuned Whisper models, which keep\nsegmentation capabilities and allow the transcription of longer audio files\nusing only sentence-level data with high quality.", "published": "2024-12-20 09:49:02", "link": "http://arxiv.org/abs/2412.15726v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Linguistic Features Extracted by GPT-4 Improve Alzheimer's Disease\n  Detection based on Spontaneous Speech", "abstract": "Alzheimer's Disease (AD) is a significant and growing public health concern.\nInvestigating alterations in speech and language patterns offers a promising\npath towards cost-effective and non-invasive early detection of AD on a large\nscale. Large language models (LLMs), such as GPT, have enabled powerful new\npossibilities for semantic text analysis. In this study, we leverage GPT-4 to\nextract five semantic features from transcripts of spontaneous patient speech.\nThe features capture known symptoms of AD, but they are difficult to quantify\neffectively using traditional methods of computational linguistics. We\ndemonstrate the clinical significance of these features and further validate\none of them (\"Word-Finding Difficulties\") against a proxy measure and human\nraters. When combined with established linguistic features and a Random Forest\nclassifier, the GPT-derived features significantly improve the detection of AD.\nOur approach proves effective for both manually transcribed and automatically\ngenerated transcripts, representing a novel and impactful use of recent\nadvancements in LLMs for AD speech analysis.", "published": "2024-12-20 10:43:42", "link": "http://arxiv.org/abs/2412.15772v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "$\u03c0$-yalli: un nouveau corpus pour le nahuatl", "abstract": "The NAHU$^2$ project is a Franco-Mexican collaboration aimed at building the\n$\\pi$-YALLI corpus adapted to machine learning, which will subsequently be used\nto develop computer resources for the Nahuatl language. Nahuatl is a language\nwith few computational resources, even though it is a living language spoken by\naround 2 million people. We have decided to build $\\pi$-YALLI, a corpus that\nwill enable to carry out research on Nahuatl in order to develop Language\nModels (LM), whether dynamic or not, which will make it possible to in turn\nenable the development of Natural Language Processing (NLP) tools such as: a) a\ngrapheme unifier, b) a word segmenter, c) a POS grammatical analyser, d) a\ncontent-based Automatic Text Summarization; and possibly, e) a translator\ntranslator (probabilistic or learning-based).", "published": "2024-12-20 12:03:10", "link": "http://arxiv.org/abs/2412.15821v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enriching Social Science Research via Survey Item Linking", "abstract": "Questions within surveys, called survey items, are used in the social\nsciences to study latent concepts, such as the factors influencing life\nsatisfaction. Instead of using explicit citations, researchers paraphrase the\ncontent of the survey items they use in-text. However, this makes it\nchallenging to find survey items of interest when comparing related work.\nAutomatically parsing and linking these implicit mentions to survey items in a\nknowledge base can provide more fine-grained references. We model this task,\ncalled Survey Item Linking (SIL), in two stages: mention detection and entity\ndisambiguation. Due to an imprecise definition of the task, existing datasets\nused for evaluating the performance for SIL are too small and of low-quality.\nWe argue that latent concepts and survey item mentions should be\ndifferentiated. To this end, we create a high-quality and richly annotated\ndataset consisting of 20,454 English and German sentences. By benchmarking deep\nlearning systems for each of the two stages independently and sequentially, we\ndemonstrate that the task is feasible, but observe that errors propagate from\nthe first stage, leading to a lower overall task performance. Moreover,\nmentions that require the context of multiple sentences are more challenging to\nidentify for models in the first stage. Modeling the entire context of a\ndocument and combining the two stages into an end-to-end system could mitigate\nthese problems in future work, and errors could additionally be reduced by\ncollecting more diverse data and by improving the quality of the knowledge\nbase. The data and code are available at https://github.com/e-tornike/SIL .", "published": "2024-12-20 12:14:33", "link": "http://arxiv.org/abs/2412.15831v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "Align Anything: Training All-Modality Models to Follow Instructions with\n  Language Feedback", "abstract": "Reinforcement learning from human feedback (RLHF) has proven effective in\nenhancing the instruction-following capabilities of large language models;\nhowever, it remains underexplored in the cross-modality domain. As the number\nof modalities increases, aligning all-modality models with human intentions --\nsuch as instruction following -- becomes a pressing challenge. In this work, we\nmake the first attempt to fine-tune all-modality models (i.e. input and output\nwith any modality, also named any-to-any models) using human preference data\nacross all modalities (including text, image, audio, and video), ensuring its\nbehavior aligns with human intentions. This endeavor presents several\nchallenges. First, there is no large-scale all-modality human preference data\nin existing open-source resources, as most datasets are limited to specific\nmodalities, predominantly text and image. Secondly, the effectiveness of binary\npreferences in RLHF for post-training alignment in complex all-modality\nscenarios remains an unexplored area. Finally, there is a lack of a systematic\nframework to evaluate the capabilities of all-modality models, particularly\nregarding modality selection and synergy. To address these challenges, we\npropose the align-anything framework, which includes meticulously annotated\n200k all-modality human preference data. Then, we introduce an alignment method\nthat learns from unified language feedback, effectively capturing complex\nmodality-specific human preferences and enhancing the model's\ninstruction-following capabilities. Furthermore, to assess performance\nimprovements in all-modality models after post-training alignment, we construct\na challenging all-modality capability evaluation framework -- eval-anything.\nAll data, models, and code frameworks have been open-sourced for the community.\nFor more details, please refer to\nhttps://github.com/PKU-Alignment/align-anything.", "published": "2024-12-20 12:27:16", "link": "http://arxiv.org/abs/2412.15838v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "TelcoLM: collecting data, adapting, and benchmarking language models for\n  the telecommunication domain", "abstract": "Despite outstanding processes in many tasks, Large Language Models (LLMs)\nstill lack accuracy when dealing with highly technical domains. Especially,\ntelecommunications (telco) is a particularly challenging domain due the large\namount of lexical, semantic and conceptual peculiarities. Yet, this domain\nholds many valuable use cases, directly linked to industrial needs. Hence, this\npaper studies how LLMs can be adapted to the telco domain. It reports our\neffort to (i) collect a massive corpus of domain-specific data (800M tokens,\n80K instructions), (ii) perform adaptation using various methodologies, and\n(iii) benchmark them against larger generalist models in downstream tasks that\nrequire extensive knowledge of telecommunications. Our experiments on\nLlama-2-7b show that domain-adapted models can challenge the large generalist\nmodels. They also suggest that adaptation can be restricted to a unique\ninstruction-tuning step, dicarding the need for any fine-tuning on raw texts\nbeforehand.", "published": "2024-12-20 13:47:02", "link": "http://arxiv.org/abs/2412.15891v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Suitability of pre-trained foundational LLMs for Analysis in\n  German Legal Education", "abstract": "We show that current open-source foundational LLMs possess instruction\ncapability and German legal background knowledge that is sufficient for some\nlegal analysis in an educational context. However, model capability breaks down\nin very specific tasks, such as the classification of \"Gutachtenstil\" appraisal\nstyle components, or with complex contexts, such as complete legal opinions.\nEven with extended context and effective prompting strategies, they cannot\nmatch the Bag-of-Words baseline. To combat this, we introduce a Retrieval\nAugmented Generation based prompt example selection method that substantially\nimproves predictions in high data availability scenarios. We further evaluate\nthe performance of pre-trained LLMs on two standard tasks for argument mining\nand automated essay scoring and find it to be more adequate. Throughout,\npre-trained LLMs improve upon the baseline in scenarios with little or no\nlabeled data with Chain-of-Thought prompting further helping in the zero-shot\ncase.", "published": "2024-12-20 13:54:57", "link": "http://arxiv.org/abs/2412.15902v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Development of a Large-scale Dataset of Chest Computed Tomography\n  Reports in Japanese and a High-performance Finding Classification Model", "abstract": "Background: Recent advances in large language models highlight the need for\nhigh-quality multilingual medical datasets. While Japan leads globally in CT\nscanner deployment and utilization, the lack of large-scale Japanese radiology\ndatasets has hindered the development of specialized language models for\nmedical imaging analysis. Objective: To develop a comprehensive Japanese CT\nreport dataset through machine translation and establish a specialized language\nmodel for structured finding classification. Additionally, to create a\nrigorously validated evaluation dataset through expert radiologist review.\nMethods: We translated the CT-RATE dataset (24,283 CT reports from 21,304\npatients) into Japanese using GPT-4o mini. The training dataset consisted of\n22,778 machine-translated reports, while the validation dataset included 150\nradiologist-revised reports. We developed CT-BERT-JPN based on\n\"tohoku-nlp/bert-base-japanese-v3\" architecture for extracting 18 structured\nfindings from Japanese radiology reports. Results: Translation metrics showed\nstrong performance with BLEU scores of 0.731 and 0.690, and ROUGE scores\nranging from 0.770 to 0.876 for Findings and from 0.748 to 0.857 for Impression\nsections. CT-BERT-JPN demonstrated superior performance compared to GPT-4o in\n11 out of 18 conditions, including lymphadenopathy (+14.2%), interlobular\nseptal thickening (+10.9%), and atelectasis (+7.4%). The model maintained F1\nscores exceeding 0.95 in 14 out of 18 conditions and achieved perfect scores in\nfour conditions. Conclusions: Our study establishes a robust Japanese CT report\ndataset and demonstrates the effectiveness of a specialized language model for\nstructured finding classification. The hybrid approach of machine translation\nand expert validation enables the creation of large-scale medical datasets\nwhile maintaining high quality.", "published": "2024-12-20 13:59:11", "link": "http://arxiv.org/abs/2412.15907v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "The Only Way is Ethics: A Guide to Ethical Research with Large Language\n  Models", "abstract": "There is a significant body of work looking at the ethical considerations of\nlarge language models (LLMs): critiquing tools to measure performance and\nharms; proposing toolkits to aid in ideation; discussing the risks to workers;\nconsidering legislation around privacy and security etc. As yet there is no\nwork that integrates these resources into a single practical guide that focuses\non LLMs; we attempt this ambitious goal. We introduce 'LLM Ethics Whitepaper',\nwhich we provide as an open and living resource for NLP practitioners, and\nthose tasked with evaluating the ethical implications of others' work. Our goal\nis to translate ethics literature into concrete recommendations and\nprovocations for thinking with clear first steps, aimed at computer scientists.\n'LLM Ethics Whitepaper' distils a thorough literature review into clear Do's\nand Don'ts, which we present also in this paper. We likewise identify useful\ntoolkits to support ethical work. We refer the interested reader to the full\nLLM Ethics Whitepaper, which provides a succinct discussion of ethical\nconsiderations at each stage in a project lifecycle, as well as citations for\nthe hundreds of papers from which we drew our recommendations. The present\npaper can be thought of as a pocket guide to conducting ethical research with\nLLMs.", "published": "2024-12-20 16:14:43", "link": "http://arxiv.org/abs/2412.16022v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adversarial Robustness through Dynamic Ensemble Learning", "abstract": "Adversarial attacks pose a significant threat to the reliability of\npre-trained language models (PLMs) such as GPT, BERT, RoBERTa, and T5. This\npaper presents Adversarial Robustness through Dynamic Ensemble Learning\n(ARDEL), a novel scheme designed to enhance the robustness of PLMs against such\nattacks. ARDEL leverages the diversity of multiple PLMs and dynamically adjusts\nthe ensemble configuration based on input characteristics and detected\nadversarial patterns. Key components of ARDEL include a meta-model for dynamic\nweighting, an adversarial pattern detection module, and adversarial training\nwith regularization techniques. Comprehensive evaluations using standardized\ndatasets and various adversarial attack scenarios demonstrate that ARDEL\nsignificantly improves robustness compared to existing methods. By dynamically\nreconfiguring the ensemble to prioritize the most robust models for each input,\nARDEL effectively reduces attack success rates and maintains higher accuracy\nunder adversarial conditions. This work contributes to the broader goal of\ndeveloping more secure and trustworthy AI systems for real-world NLP\napplications, offering a practical and scalable solution to enhance adversarial\nresilience in PLMs.", "published": "2024-12-20 05:36:19", "link": "http://arxiv.org/abs/2412.16254v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Benchmarking LLMs and SLMs for patient reported outcomes", "abstract": "LLMs have transformed the execution of numerous tasks, including those in the\nmedical domain. Among these, summarizing patient-reported outcomes (PROs) into\nconcise natural language reports is of particular interest to clinicians, as it\nenables them to focus on critical patient concerns and spend more time in\nmeaningful discussions. While existing work with LLMs like GPT-4 has shown\nimpressive results, real breakthroughs could arise from leveraging SLMs as they\noffer the advantage of being deployable locally, ensuring patient data privacy\nand compliance with healthcare regulations. This study benchmarks several SLMs\nagainst LLMs for summarizing patient-reported Q\\&A forms in the context of\nradiotherapy. Using various metrics, we evaluate their precision and\nreliability. The findings highlight both the promise and limitations of SLMs\nfor high-stakes medical tasks, fostering more efficient and privacy-preserving\nAI-driven healthcare solutions.", "published": "2024-12-20 19:01:25", "link": "http://arxiv.org/abs/2412.16291v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Decoding Linguistic Nuances in Mental Health Text Classification Using\n  Expressive Narrative Stories", "abstract": "Recent advancements in NLP have spurred significant interest in analyzing\nsocial media text data for identifying linguistic features indicative of mental\nhealth issues. However, the domain of Expressive Narrative Stories (ENS)-deeply\npersonal and emotionally charged narratives that offer rich psychological\ninsights-remains underexplored. This study bridges this gap by utilizing a\ndataset sourced from Reddit, focusing on ENS from individuals with and without\nself-declared depression. Our research evaluates the utility of advanced\nlanguage models, BERT and MentalBERT, against traditional models. We find that\ntraditional models are sensitive to the absence of explicit topic-related\nwords, which could risk their potential to extend applications to ENS that lack\nclear mental health terminology. Despite MentalBERT is design to better handle\npsychiatric contexts, it demonstrated a dependency on specific topic words for\nclassification accuracy, raising concerns about its application when explicit\nmental health terms are sparse (P-value<0.05). In contrast, BERT exhibited\nminimal sensitivity to the absence of topic words in ENS, suggesting its\nsuperior capability to understand deeper linguistic features, making it more\neffective for real-world applications. Both BERT and MentalBERT excel at\nrecognizing linguistic nuances and maintaining classification accuracy even\nwhen narrative order is disrupted. This resilience is statistically\nsignificant, with sentence shuffling showing substantial impacts on model\nperformance (P-value<0.05), especially evident in ENS comparisons between\nindividuals with and without mental health declarations. These findings\nunderscore the importance of exploring ENS for deeper insights into mental\nhealth-related narratives, advocating for a nuanced approach to mental health\ntext analysis that moves beyond mere keyword detection.", "published": "2024-12-20 19:29:21", "link": "http://arxiv.org/abs/2412.16302v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Machine Learning Approach for Emergency Detection in Medical Scenarios\n  Using Large Language Models", "abstract": "The rapid identification of medical emergencies through digital communication\nchannels remains a critical challenge in modern healthcare delivery,\nparticularly with the increasing prevalence of telemedicine. This paper\npresents a novel approach leveraging large language models (LLMs) and prompt\nengineering techniques for automated emergency detection in medical\ncommunications. We developed and evaluated a comprehensive system using\nmultiple LLaMA model variants (1B, 3B, and 7B parameters) to classify medical\nscenarios as emergency or non-emergency situations. Our methodology\nincorporated both system prompts and in-prompt training approaches, evaluated\nacross different hardware configurations. The results demonstrate exceptional\nperformance, with the LLaMA 2 (7B) model achieving 99.7% accuracy and the LLaMA\n3.2 (3B) model reaching 99.6% accuracy with optimal prompt engineering. Through\nsystematic testing of training examples within the prompts, we identified that\nincluding 10 example scenarios in the model prompts yielded optimal\nclassification performance. Processing speeds varied significantly between\nplatforms, ranging from 0.05 to 2.2 seconds per request. The system showed\nparticular strength in minimizing high-risk false negatives in emergency\nscenarios, which is crucial for patient safety. The code implementation and\nevaluation framework are publicly available on GitHub, facilitating further\nresearch and development in this crucial area of healthcare technology.", "published": "2024-12-20 21:03:24", "link": "http://arxiv.org/abs/2412.16341v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Human-Readable Adversarial Prompts: An Investigation into LLM\n  Vulnerabilities Using Situational Context", "abstract": "Previous studies that uncovered vulnerabilities in large language models\n(LLMs) frequently employed nonsensical adversarial prompts. However, such\nprompts can now be readily identified using automated detection techniques. To\nfurther strengthen adversarial attacks, we focus on human-readable adversarial\nprompts, which are more realistic and potent threats. Our key contributions are\n(1) situation-driven attacks leveraging movie scripts as context to create\nhuman-readable prompts that successfully deceive LLMs, (2) adversarial suffix\nconversion to transform nonsensical adversarial suffixes into independent\nmeaningful text, and (3) AdvPrompter with p-nucleus sampling, a method to\ngenerate diverse, human-readable adversarial suffixes, improving attack\nefficacy in models like GPT-3.5 and Gemma 7B.", "published": "2024-12-20 21:43:52", "link": "http://arxiv.org/abs/2412.16359v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A High-Quality Text-Rich Image Instruction Tuning Dataset via Hybrid\n  Instruction Generation", "abstract": "Large multimodal models still struggle with text-rich images because of\ninadequate training data. Self-Instruct provides an annotation-free way for\ngenerating instruction data, but its quality is poor, as multimodal alignment\nremains a hurdle even for the largest models. In this work, we propose\nLLaVAR-2, to enhance multimodal alignment for text-rich images through hybrid\ninstruction generation between human annotators and large language models.\nSpecifically, it involves detailed image captions from human annotators,\nfollowed by the use of these annotations in tailored text prompts for GPT-4o to\ncurate a dataset. It also implements several mechanisms to filter out\nlow-quality data, and the resulting dataset comprises 424k high-quality pairs\nof instructions. Empirical results show that models fine-tuned on this dataset\nexhibit impressive enhancements over those trained with self-instruct data.", "published": "2024-12-20 21:55:15", "link": "http://arxiv.org/abs/2412.16364v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Overview of the First Workshop on Language Models for Low-Resource\n  Languages (LoResLM 2025)", "abstract": "The first Workshop on Language Models for Low-Resource Languages (LoResLM\n2025) was held in conjunction with the 31st International Conference on\nComputational Linguistics (COLING 2025) in Abu Dhabi, United Arab Emirates.\nThis workshop mainly aimed to provide a forum for researchers to share and\ndiscuss their ongoing work on language models (LMs) focusing on low-resource\nlanguages, following the recent advancements in neural language models and\ntheir linguistic biases towards high-resource languages. LoResLM 2025 attracted\nnotable interest from the natural language processing (NLP) community,\nresulting in 35 accepted papers from 52 submissions. These contributions cover\na broad range of low-resource languages from eight language families and 13\ndiverse research areas, paving the way for future possibilities and promoting\nlinguistic inclusivity in NLP.", "published": "2024-12-20 21:55:32", "link": "http://arxiv.org/abs/2412.16365v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NGQA: A Nutritional Graph Question Answering Benchmark for Personalized\n  Health-aware Nutritional Reasoning", "abstract": "Diet plays a critical role in human health, yet tailoring dietary reasoning\nto individual health conditions remains a major challenge. Nutrition Question\nAnswering (QA) has emerged as a popular method for addressing this problem.\nHowever, current research faces two critical limitations. On one hand, the\nabsence of datasets involving user-specific medical information severely limits\n\\textit{personalization}. This challenge is further compounded by the wide\nvariability in individual health needs. On the other hand, while large language\nmodels (LLMs), a popular solution for this task, demonstrate strong reasoning\nabilities, they struggle with the domain-specific complexities of personalized\nhealthy dietary reasoning, and existing benchmarks fail to capture these\nchallenges. To address these gaps, we introduce the Nutritional Graph Question\nAnswering (NGQA) benchmark, the first graph question answering dataset designed\nfor personalized nutritional health reasoning. NGQA leverages data from the\nNational Health and Nutrition Examination Survey (NHANES) and the Food and\nNutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is\nhealthy for a specific user, supported by explanations of the key contributing\nnutrients. The benchmark incorporates three question complexity settings and\nevaluates reasoning across three downstream tasks. Extensive experiments with\nLLM backbones and baseline models demonstrate that the NGQA benchmark\neffectively challenges existing models. In sum, NGQA addresses a critical\nreal-world problem while advancing GraphQA research with a novel\ndomain-specific benchmark.", "published": "2024-12-20 04:13:46", "link": "http://arxiv.org/abs/2412.15547v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "In-context Continual Learning Assisted by an External Continual Learner", "abstract": "Existing continual learning (CL) methods mainly rely on fine-tuning or\nadapting large language models (LLMs). They still suffer from catastrophic\nforgetting (CF). Little work has been done to exploit in-context learning (ICL)\nto leverage the extensive knowledge within LLMs for CL without updating any\nparameters. However, incrementally learning each new task in ICL necessitates\nadding training examples from each class of the task to the prompt, which\nhampers scalability as the prompt length increases. This issue not only leads\nto excessively long prompts that exceed the input token limit of the underlying\nLLM but also degrades the model's performance due to the overextended context.\nTo address this, we introduce InCA, a novel approach that integrates an\nexternal continual learner (ECL) with ICL to enable scalable CL without CF. The\nECL is built incrementally to pre-select a small subset of likely classes for\neach test instance. By restricting the ICL prompt to only these selected\nclasses, InCA prevents prompt lengths from becoming excessively long, while\nmaintaining high performance. Experimental results demonstrate that InCA\nsignificantly outperforms existing CL baselines, achieving substantial\nperformance gains.", "published": "2024-12-20 04:44:41", "link": "http://arxiv.org/abs/2412.15563v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Continual Learning Using a Kernel-Based Method Over Foundation Models", "abstract": "Continual learning (CL) learns a sequence of tasks incrementally. This paper\nstudies the challenging CL setting of class-incremental learning (CIL). CIL has\ntwo key challenges: catastrophic forgetting (CF) and inter-task class\nseparation (ICS). Despite numerous proposed methods, these issues remain\npersistent obstacles. This paper proposes a novel CIL method, called Kernel\nLinear Discriminant Analysis (KLDA), that can effectively avoid CF and ICS\nproblems. It leverages only the powerful features learned in a foundation model\n(FM). However, directly using these features proves suboptimal. To address\nthis, KLDA incorporates the Radial Basis Function (RBF) kernel and its Random\nFourier Features (RFF) to enhance the feature representations from the FM,\nleading to improved performance. When a new task arrives, KLDA computes only\nthe mean for each class in the task and updates a shared covariance matrix for\nall learned classes based on the kernelized features. Classification is\nperformed using Linear Discriminant Analysis. Our empirical evaluation using\ntext and image classification datasets demonstrates that KLDA significantly\noutperforms baselines. Remarkably, without relying on replay data, KLDA\nachieves accuracy comparable to joint training of all classes, which is\nconsidered the upper bound for CIL performance. The KLDA code is available at\nhttps://github.com/salehmomeni/klda.", "published": "2024-12-20 05:09:18", "link": "http://arxiv.org/abs/2412.15571v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "TouchASP: Elastic Automatic Speech Perception that Everyone Can Touch", "abstract": "Large Automatic Speech Recognition (ASR) models demand a vast number of\nparameters, copious amounts of data, and significant computational resources\nduring the training process. However, such models can merely be deployed on\nhigh-compute cloud platforms and are only capable of performing speech\nrecognition tasks. This leads to high costs and restricted capabilities. In\nthis report, we initially propose the elastic mixture of the expert (eMoE)\nmodel. This model can be trained just once and then be elastically scaled in\naccordance with deployment requirements. Secondly, we devise an unsupervised\ndata creation and validation procedure and gather millions of hours of audio\ndata from diverse domains for training. Using these two techniques, our system\nachieves elastic deployment capabilities while reducing the Character Error\nRate (CER) on the SpeechIO testsets from 4.98\\% to 2.45\\%. Thirdly, our model\nis not only competent in Mandarin speech recognition but also proficient in\nmultilingual, multi-dialect, emotion, gender, and sound event perception. We\nrefer to this as Automatic Speech Perception (ASP), and the perception results\nare presented in the experimental section.", "published": "2024-12-20 07:28:04", "link": "http://arxiv.org/abs/2412.15622v1", "categories": ["eess.AS", "cs.CL", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Adaptable and Precise: Enterprise-Scenario LLM Function-Calling\n  Capability Training Pipeline", "abstract": "Enterprises possess a vast array of API assets scattered across various\nfunctions, forming the backbone of existing business processes. By leveraging\nthese APIs as functional tools, enterprises can design diverse,\nscenario-specific agent applications, driven by on-premise function-calling\nmodels as the core engine. However, generic models often fail to meet\nenterprise requirements in terms of computational efficiency, output accuracy,\nand stability, necessitating scenario-specific adaptation. In this paper, we\npropose a training pipeline for function-calling capabilities tailored to\nreal-world business scenarios. This pipeline includes the synthesis and\naugmentation of scenario-specific function-calling data, model fine-tuning, and\nperformance evaluation and analysis. Using this pipeline, we generated 1,260\nfully AI-generated samples and 1,035 augmented manually-labeled samples in\ndigital HR agent scenario. The Qwen2.5-Coder-7B-Instruct model was employed as\nthe base model and fine-tuned using the LoRA method on four GPUs with 24GB\nVRAM. Our fine-tuned model demonstrated outstanding performance in evaluations\nand practical applications, surpassing GPT-4 and GPT-4o in accuracy on the test\nset. These results validate the reliability of the proposed pipeline for\ntraining scenario-specific function-calling models.", "published": "2024-12-20 08:20:21", "link": "http://arxiv.org/abs/2412.15660v1", "categories": ["cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent\n  Collaboration", "abstract": "Recent advancements in language models (LMs) have sparked growing interest in\ndeveloping LM agents. While fully autonomous agents could excel in many\nscenarios, numerous use cases inherently require them to collaborate with\nhumans due to humans' latent preferences, domain expertise, or need for\ncontrol. To facilitate the study of human-agent collaboration, we present\nCollaborative Gym (Co-Gym), a general framework enabling asynchronous,\ntripartite interaction among agents, humans, and task environments. We\ninstantiate Co-Gym with three representative tasks in both simulated and\nreal-world conditions, and propose an evaluation framework that assesses both\nthe collaboration outcomes and processes. Our findings reveal that\ncollaborative agents consistently outperform their fully autonomous\ncounterparts in task performance within those delivered cases, achieving win\nrates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related\nWork when evaluated by real users. However, our study also highlights\nsignificant challenges in developing collaborative agents, requiring\nadvancements in core aspects of intelligence -- communication capabilities,\nsituational awareness, and balancing autonomy and human control.", "published": "2024-12-20 09:21:15", "link": "http://arxiv.org/abs/2412.15701v2", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "AutoLife: Automatic Life Journaling with Smartphones and LLMs", "abstract": "This paper introduces a novel mobile sensing application - life journaling -\ndesigned to generate semantic descriptions of users' daily lives. We present\nAutoLife, an automatic life journaling system based on commercial smartphones.\nAutoLife only inputs low-cost sensor data (without photos or audio) from\nsmartphones and can automatically generate comprehensive life journals for\nusers. To achieve this, we first derive time, motion, and location contexts\nfrom multimodal sensor data, and harness the zero-shot capabilities of Large\nLanguage Models (LLMs), enriched with commonsense knowledge about human lives,\nto interpret diverse contexts and generate life journals. To manage the task\ncomplexity and long sensing duration, a multilayer framework is proposed, which\ndecomposes tasks and seamlessly integrates LLMs with other techniques for life\njournaling. This study establishes a real-life dataset as a benchmark and\nextensive experiment results demonstrate that AutoLife produces accurate and\nreliable life journals.", "published": "2024-12-20 09:37:02", "link": "http://arxiv.org/abs/2412.15714v2", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "Critique of Impure Reason: Unveiling the reasoning behaviour of medical\n  Large Language Models", "abstract": "Background: Despite the current ubiquity of Large Language Models (LLMs)\nacross the medical domain, there is a surprising lack of studies which address\ntheir reasoning behaviour. We emphasise the importance of understanding\nreasoning behaviour as opposed to high-level prediction accuracies, since it is\nequivalent to explainable AI (XAI) in this context. In particular, achieving\nXAI in medical LLMs used in the clinical domain will have a significant impact\nacross the healthcare sector. Results: Therefore, we define the concept of\nreasoning behaviour in the specific context of medical LLMs. We then categorise\nand discuss the current state of the art of methods which evaluate reasoning\nbehaviour in medical LLMs. Finally, we propose theoretical frameworks which can\nempower medical professionals or machine learning engineers to gain insight\ninto the low-level reasoning operations of these previously obscure models.\nConclusion: The subsequent increased transparency and trust in medical machine\nlearning models by clinicians as well as patients will accelerate the\nintegration, application as well as further development of medical AI for the\nhealthcare system as a whole", "published": "2024-12-20 10:06:52", "link": "http://arxiv.org/abs/2412.15748v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "S$^2$DN: Learning to Denoise Unconvincing Knowledge for Inductive\n  Knowledge Graph Completion", "abstract": "Inductive Knowledge Graph Completion (KGC) aims to infer missing facts\nbetween newly emerged entities within knowledge graphs (KGs), posing a\nsignificant challenge. While recent studies have shown promising results in\ninferring such entities through knowledge subgraph reasoning, they suffer from\n(i) the semantic inconsistencies of similar relations, and (ii) noisy\ninteractions inherent in KGs due to the presence of unconvincing knowledge for\nemerging entities. To address these challenges, we propose a Semantic\nStructure-aware Denoising Network (S$^2$DN) for inductive KGC. Our goal is to\nlearn adaptable general semantics and reliable structures to distill consistent\nsemantic knowledge while preserving reliable interactions within KGs.\nSpecifically, we introduce a semantic smoothing module over the enclosing\nsubgraphs to retain the universal semantic knowledge of relations. We\nincorporate a structure refining module to filter out unreliable interactions\nand offer additional knowledge, retaining robust structure surrounding target\nlinks. Extensive experiments conducted on three benchmark KGs demonstrate that\nS$^2$DN surpasses the performance of state-of-the-art models. These results\ndemonstrate the effectiveness of S$^2$DN in preserving semantic consistency and\nenhancing the robustness of filtering out unreliable interactions in\ncontaminated KGs.", "published": "2024-12-20 12:03:33", "link": "http://arxiv.org/abs/2412.15822v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "From General to Specific: Tailoring Large Language Models for\n  Personalized Healthcare", "abstract": "The rapid development of large language models (LLMs) has transformed many\nindustries, including healthcare. However, previous medical LLMs have largely\nfocused on leveraging general medical knowledge to provide responses, without\naccounting for patient variability and lacking true personalization at the\nindividual level. To address this, we propose a novel method called\npersonalized medical language model (PMLM), which explores and optimizes\npersonalized LLMs through recommendation systems and reinforcement learning\n(RL). Specifically, by utilizing self-informed and peer-informed\npersonalization, PMLM captures changes in behaviors and preferences to design\ninitial personalized prompts tailored to individual needs. We further refine\nthese initial personalized prompts through RL, ultimately enhancing the\nprecision of LLM guidance. Notably, the personalized prompt are hard prompt,\nwhich grants PMLM high adaptability and reusability, allowing it to directly\nleverage high-quality proprietary LLMs. We evaluate PMLM using real-world\nobstetrics and gynecology data, and the experimental results demonstrate that\nPMLM achieves personalized responses, and it provides more refined and\nindividualized services, offering a potential way for personalized medical\nLLMs.", "published": "2024-12-20 14:51:12", "link": "http://arxiv.org/abs/2412.15957v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Data-Centric Improvements for Enhancing Multi-Modal Understanding in\n  Spoken Conversation Modeling", "abstract": "Conversational assistants are increasingly popular across diverse real-world\napplications, highlighting the need for advanced multimodal speech modeling.\nSpeech, as a natural mode of communication, encodes rich user-specific\ncharacteristics such as speaking rate and pitch, making it critical for\neffective interaction. Our work introduces a data-centric customization\napproach for efficiently enhancing multimodal understanding in conversational\nspeech modeling. Central to our contributions is a novel multi-task learning\nparadigm that involves designing auxiliary tasks to utilize a small amount of\nspeech data. Our approach achieves state-of-the-art performance on the\nSpoken-SQuAD benchmark, using only 10% of the training data with open-weight\nmodels, establishing a robust and efficient framework for audio-centric\nconversational modeling. We also introduce ASK-QA, the first dataset for\nmulti-turn spoken dialogue with ambiguous user requests and dynamic evaluation\ninputs. Code and data forthcoming.", "published": "2024-12-20 15:43:09", "link": "http://arxiv.org/abs/2412.15995v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models\n  into Assembly Code Obfuscation", "abstract": "Malware authors often employ code obfuscations to make their malware harder\nto detect. Existing tools for generating obfuscated code often require access\nto the original source code (e.g., C++ or Java), and adding new obfuscations is\na non-trivial, labor-intensive process. In this study, we ask the following\nquestion: Can Large Language Models (LLMs) potentially generate a new\nobfuscated assembly code? If so, this poses a risk to anti-virus engines and\npotentially increases the flexibility of attackers to create new obfuscation\npatterns. We answer this in the affirmative by developing the MetamorphASM\nbenchmark comprising MetamorphASM Dataset (MAD) along with three code\nobfuscation techniques: dead code, register substitution, and control flow\nchange. The MetamorphASM systematically evaluates the ability of LLMs to\ngenerate and analyze obfuscated code using MAD, which contains 328,200\nobfuscated assembly code samples. We release this dataset and analyze the\nsuccess rate of various LLMs (e.g., GPT-3.5/4, GPT-4o-mini, Starcoder,\nCodeGemma, CodeLlama, CodeT5, and LLaMA 3.1) in generating obfuscated assembly\ncode. The evaluation was performed using established information-theoretic\nmetrics and manual human review to ensure correctness and provide the\nfoundation for researchers to study and develop remediations to this risk.", "published": "2024-12-20 18:31:24", "link": "http://arxiv.org/abs/2412.16135v3", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Offline Reinforcement Learning for LLM Multi-Step Reasoning", "abstract": "Improving the multi-step reasoning ability of large language models (LLMs)\nwith offline reinforcement learning (RL) is essential for quickly adapting them\nto complex tasks. While Direct Preference Optimization (DPO) has shown promise\nin aligning LLMs with human preferences, it is less suitable for multi-step\nreasoning tasks because (1) DPO relies on paired preference data, which is not\nreadily available for multi-step reasoning tasks, and (2) it treats all tokens\nuniformly, making it ineffective for credit assignment in multi-step reasoning\ntasks, which often come with sparse reward. In this work, we propose OREO\n(Offline Reasoning Optimization), an offline RL method for enhancing LLM\nmulti-step reasoning. Building on insights from previous works of maximum\nentropy reinforcement learning, it jointly learns a policy model and value\nfunction by optimizing the soft Bellman Equation. We show in principle that it\nreduces the need to collect pairwise data and enables better credit assignment.\nEmpirically, OREO surpasses existing offline learning methods on multi-step\nreasoning benchmarks, including mathematical reasoning tasks (GSM8K, MATH) and\nembodied agent control (ALFWorld). The approach can be extended to a\nmulti-iteration framework when additional resources are available. Furthermore,\nthe learned value function can be leveraged to guide the tree search for free,\nwhich can further boost performance during test time.", "published": "2024-12-20 18:49:45", "link": "http://arxiv.org/abs/2412.16145v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Inference Scaling vs Reasoning: An Empirical Analysis of Compute-Optimal\n  LLM Problem-Solving", "abstract": "Recent advances in large language models (LLMs) have predominantly focused on\nmaximizing accuracy and reasoning capabilities, often overlooking crucial\ncomputational efficiency considerations. While this approach has yielded\nimpressive accuracy improvements, it has led to methods that may be impractical\nfor real-world deployment due to computational overhead and latency\nconstraints. This paper investigates the potential synergy between reasoning\nenhancement and computational efficiency by analyzing the integration of two\ncontrasting approaches: Quiet-STaR (Self-Taught Reasoner) and REBASE (REward\nBAlanced SEarch). Through comprehensive empirical analysis using the Mistral-7B\nmodel on the GSM8K dataset, we demonstrate that while each method excels in its\nprimary objective-Quiet-STaR achieving superior accuracy (32.03%) despite high\ncomputational cost (554.66s runtime, 12.73T FLOPs), and REBASE providing\nexceptional efficiency (8.47s runtime, 2.35T FLOPs) while maintaining\nbaseline-comparable accuracy (10.94%)-their integration reveals fundamental\nchallenges in reconciling reasoning depth with computational efficiency. The\ncombined approach unexpectedly results in degraded performance (9.38% accuracy,\n143.66s runtime), highlighting critical insights about the complex interplay\nbetween reasoning enhancement and efficiency optimization in LLMs. Our findings\nilluminate the need for novel architectures and algorithms specifically\ndesigned to bridge the gap between these competing objectives, while providing\nconcrete directions for future research in compute-efficient reasoning methods.", "published": "2024-12-20 08:42:45", "link": "http://arxiv.org/abs/2412.16260v1", "categories": ["cs.LG", "cs.CC", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Deliberative Alignment: Reasoning Enables Safer Language Models", "abstract": "As large-scale language models increasingly impact safety-critical domains,\nensuring their reliable adherence to well-defined principles remains a\nfundamental challenge. We introduce Deliberative Alignment, a new paradigm that\ndirectly teaches the model safety specifications and trains it to explicitly\nrecall and accurately reason over the specifications before answering. We used\nthis approach to align OpenAI's o-series models, and achieved highly precise\nadherence to OpenAI's safety policies, without requiring human-written\nchain-of-thoughts or answers. Deliberative Alignment pushes the Pareto frontier\nby simultaneously increasing robustness to jailbreaks while decreasing\noverrefusal rates, and also improves out-of-distribution generalization. We\ndemonstrate that reasoning over explicitly specified policies enables more\nscalable, trustworthy, and interpretable alignment.", "published": "2024-12-20 21:00:11", "link": "http://arxiv.org/abs/2412.16339v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "REFA: Reference Free Alignment for multi-preference optimization", "abstract": "We introduce $\\textbf{REFA}$, a family of reference-free alignment methods\nthat optimize over multiple user preferences while enforcing fine-grained\nlength control. Our approach integrates deviation-based weighting to emphasize\nhigh-quality responses, length normalization to prevent trivial short-response\nsolutions, and an EOS-probability regularizer to mitigate dataset-induced\nbrevity biases. Theoretically, we show that under the Uncertainty Reduction\nwith Sequence Length Assertion (URSLA) framework, naive length normalization\ncan still incentivize length-based shortcuts. In contrast, REFA corrects these\nsubtle incentives, guiding models toward genuinely more informative and\nhigher-quality outputs. Empirically, REFA achieves a new\n$\\textbf{state-of-the-art}$ among reference-free alignment methods, generating\nricher responses that align more closely with human preferences. Notably, REFA\nimproves performance on the AlpacaEval2 benchmark, achieving a $\\textbf{26.6%}$\nLength-Controlled Win Rate (LC-WR) and $\\textbf{24.2%}$ Win Rate (WR).", "published": "2024-12-20 22:25:23", "link": "http://arxiv.org/abs/2412.16378v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "A Breadth-First Catalog of Text Processing, Speech Processing and\n  Multimodal Research in South Asian Languages", "abstract": "We review the recent literature (January 2022- October 2024) in South Asian\nlanguages on text-based language processing, multimodal models, and speech\nprocessing, and provide a spotlight analysis focused on 21 low-resource South\nAsian languages, namely Saraiki, Assamese, Balochi, Bhojpuri, Bodo, Burmese,\nChhattisgarhi, Dhivehi, Gujarati, Kannada, Kashmiri, Konkani, Khasi, Malayalam,\nMeitei, Nepali, Odia, Pashto, Rajasthani, Sindhi, and Telugu. We identify\ntrends, challenges, and future research directions, using a step-wise approach\nthat incorporates relevance classification and clustering based on large\nlanguage models (LLMs). Our goal is to provide a breadth-first overview of the\nrecent developments in South Asian language technologies to NLP researchers\ninterested in working with South Asian languages.", "published": "2024-12-20 20:08:48", "link": "http://arxiv.org/abs/2501.00029v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Level-Navi Agent: A Framework and benchmark for Chinese Web Search\n  Agents", "abstract": "Large language models (LLMs), adopted to understand human language, drive the\ndevelopment of artificial intelligence (AI) web search agents. Compared to\ntraditional search engines, LLM-powered AI search agents are capable of\nunderstanding and responding to complex queries with greater depth, enabling\nmore accurate operations and better context recognition. However, little\nattention and effort has been paid to the Chinese web search, which results in\nthat the capabilities of open-source models have not been uniformly and fairly\nevaluated. The difficulty lies in lacking three aspects: an unified agent\nframework, an accurately labeled dataset, and a suitable evaluation metric. To\naddress these issues, we propose a general-purpose and training-free web search\nagent by level-aware navigation, Level-Navi Agent, accompanied by a\nwell-annotated dataset (Web24) and a suitable evaluation metric. Level-Navi\nAgent can think through complex user questions and conduct searches across\nvarious levels on the internet to gather information for questions. Meanwhile,\nwe provide a comprehensive evaluation of state-of-the-art LLMs under fair\nsettings. To further facilitate future research, source code is available at\nGithub.", "published": "2024-12-20 08:03:12", "link": "http://arxiv.org/abs/2502.15690v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Towards Interpretable Radiology Report Generation via Concept\n  Bottlenecks using a Multi-Agentic RAG", "abstract": "Deep learning has advanced medical image classification, but interpretability\nchallenges hinder its clinical adoption. This study enhances interpretability\nin Chest X-ray (CXR) classification by using concept bottleneck models (CBMs)\nand a multi-agent Retrieval-Augmented Generation (RAG) system for report\ngeneration. By modeling relationships between visual features and clinical\nconcepts, we create interpretable concept vectors that guide a multi-agent RAG\nsystem to generate radiology reports, enhancing clinical relevance,\nexplainability, and transparency. Evaluation of the generated reports using an\nLLM-as-a-judge confirmed the interpretability and clinical utility of our\nmodel's outputs. On the COVID-QU dataset, our model achieved 81% classification\naccuracy and demonstrated robust report generation performance, with five key\nmetrics ranging between 84% and 90%. This interpretable multi-agent framework\nbridges the gap between high-performance AI and the explainability required for\nreliable AI-driven CXR analysis in clinical settings. Our code is available at\nhttps://github.com/tifat58/IRR-with-CBM-RAG.git.", "published": "2024-12-20 17:33:50", "link": "http://arxiv.org/abs/2412.16086v2", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.CV", "eess.IV"], "primary_category": "cs.IR"}
{"title": "SLAM-Omni: Timbre-Controllable Voice Interaction System with\n  Single-Stage Training", "abstract": "Recent advancements highlight the potential of end-to-end real-time spoken\ndialogue systems, showcasing their low latency and high quality. In this paper,\nwe introduce SLAM-Omni, a timbre-controllable, end-to-end voice interaction\nsystem with single-stage training. SLAM-Omni achieves zero-shot timbre control\nby modeling spoken language with semantic tokens and decoupling speaker\ninformation to a vocoder. By predicting grouped speech semantic tokens at each\nstep, our method significantly reduces the sequence length of audio tokens,\naccelerating both training and inference. Additionally, we propose historical\ntext prompting to compress dialogue history, facilitating efficient multi-round\ninteractions. Comprehensive evaluations reveal that SLAM-Omni outperforms prior\nmodels of similar scale, requiring only 15 hours of training on 4 GPUs with\nlimited data. Notably, it is the first spoken dialogue system to achieve\ncompetitive performance with a single-stage training approach, eliminating the\nneed for pre-training on TTS or ASR tasks. Further experiments validate its\nmultilingual and multi-turn dialogue capabilities on larger datasets.", "published": "2024-12-20 08:05:55", "link": "http://arxiv.org/abs/2412.15649v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Interleaved Speech-Text Language Models are Simple Streaming Text to\n  Speech Synthesizers", "abstract": "This paper introduces Interleaved Speech-Text Language Model (IST-LM) for\nstreaming zero-shot Text-to-Speech (TTS). Unlike many previous approaches,\nIST-LM is directly trained on interleaved sequences of text and speech tokens\nwith a fixed ratio, eliminating the need for additional efforts in duration\nprediction and grapheme-to-phoneme alignment. The ratio of text chunk size to\nspeech chunk size is crucial for the performance of IST-LM. To explore this, we\nconducted a comprehensive series of statistical analyses on the training data\nand performed correlation analysis with the final performance, uncovering\nseveral key factors: 1) the distance between speech tokens and their\ncorresponding text tokens, 2) the number of future text tokens accessible to\neach speech token, and 3) the frequency of speech tokens precedes their\ncorresponding text tokens. Experimental results demonstrate how to achieve an\noptimal streaming TTS system without complicated engineering optimization,\nwhich has a limited gap with the non-streaming system. IST-LM is conceptually\nsimple and empirically powerful, paving the way for streaming TTS with minimal\noverhead while largely maintaining performance, showcasing broad prospects\ncoupled with real-time text stream from LLMs.", "published": "2024-12-20 17:43:50", "link": "http://arxiv.org/abs/2412.16102v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "RiTTA: Modeling Event Relations in Text-to-Audio Generation", "abstract": "Despite significant advancements in Text-to-Audio (TTA) generation models\nachieving high-fidelity audio with fine-grained context understanding, they\nstruggle to model the relations between audio events described in the input\ntext. However, previous TTA methods have not systematically explored audio\nevent relation modeling, nor have they proposed frameworks to enhance this\ncapability. In this work, we systematically study audio event relation modeling\nin TTA generation models. We first establish a benchmark for this task by: 1.\nproposing a comprehensive relation corpus covering all potential relations in\nreal-world scenarios; 2. introducing a new audio event corpus encompassing\ncommonly heard audios; and 3. proposing new evaluation metrics to assess audio\nevent relation modeling from various perspectives. Furthermore, we propose a\nfinetuning framework to enhance existing TTA models ability to model audio\nevents relation. Code is available at: https://github.com/yuhanghe01/RiTTA", "published": "2024-12-20 14:14:00", "link": "http://arxiv.org/abs/2412.15922v3", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "A Classification Benchmark for Artificial Intelligence Detection of\n  Laryngeal Cancer from Patient Speech", "abstract": "Cases of laryngeal cancer are predicted to rise significantly in the coming\nyears. Current diagnostic pathways cause many patients to be incorrectly\nreferred to urgent suspected cancer pathways, putting undue stress on both\npatients and the medical system.\n  Artificial intelligence offers a promising solution by enabling non-invasive\ndetection of laryngeal cancer from patient speech, which could help prioritise\nreferrals more effectively and reduce inappropriate referrals of non-cancer\npatients. To realise this potential, open science is crucial. A major barrier\nin this field is the lack of open-source datasets and reproducible benchmarks,\nforcing researchers to start from scratch. Our work addresses this challenge by\nintroducing a benchmark suite comprising 36 models trained and evaluated on\nopen-source datasets. These models are accessible in a public repository,\nproviding a foundation for future research. They evaluate three different\nalgorithms and three audio feature sets, offering a comprehensive benchmarking\nframework. We propose standardised metrics and evaluation methodologies to\nensure consistent and comparable results across future studies.\n  The presented models include both audio-only inputs and multimodal inputs\nthat incorporate demographic and symptom data, enabling their application to\ndatasets with diverse patient information. By providing these benchmarks,\nfuture researchers can evaluate their datasets, refine the models, and use them\nas a foundation for more advanced approaches. This work aims to provide a\nbaseline for establishing reproducible benchmarks, enabling researchers to\ncompare new methods against these standards and ultimately advancing the\ndevelopment of AI tools for detecting laryngeal cancer.", "published": "2024-12-20 10:34:03", "link": "http://arxiv.org/abs/2412.16267v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "q-bio.QM"], "primary_category": "cs.SD"}
{"title": "Predicting Artificial Neural Network Representations to Learn\n  Recognition Model for Music Identification from Brain Recordings", "abstract": "Recent studies have demonstrated that the representations of artificial\nneural networks (ANNs) can exhibit notable similarities to cortical\nrepresentations when subjected to identical auditory sensory inputs. In these\nstudies, the ability to predict cortical representations is probed by\nregressing from ANN representations to cortical representations. Building upon\nthis concept, our approach reverses the direction of prediction: we utilize ANN\nrepresentations as a supervisory signal to train recognition models using noisy\nbrain recordings obtained through non-invasive measurements. Specifically, we\nfocus on constructing a recognition model for music identification, where\nelectroencephalography (EEG) brain recordings collected during music listening\nserve as input. By training an EEG recognition model to predict ANN\nrepresentations-representations associated with music identification-we\nobserved a substantial improvement in classification accuracy. This study\nintroduces a novel approach to developing recognition models for brain\nrecordings in response to external auditory stimuli. It holds promise for\nadvancing brain-computer interfaces (BCI), neural decoding techniques, and our\nunderstanding of music cognition. Furthermore, it provides new insights into\nthe relationship between auditory brain activity and ANN representations.", "published": "2024-12-20 04:37:26", "link": "http://arxiv.org/abs/2412.15560v1", "categories": ["q-bio.NC", "cs.LG", "cs.SD", "eess.AS", "eess.SP"], "primary_category": "q-bio.NC"}
{"title": "Music Genre Classification: Ensemble Learning with Subcomponents-level\n  Attention", "abstract": "Music Genre Classification is one of the most popular topics in the fields of\nMusic Information Retrieval (MIR) and digital signal processing. Deep Learning\nhas emerged as the top performer for classifying music genres among various\nmethods. The letter introduces a novel approach by combining ensemble learning\nwith attention to sub-components, aiming to enhance the accuracy of identifying\nmusic genres. The core innovation of our work is the proposal to classify the\nsubcomponents of the music pieces separately, allowing our model to capture\ndistinct characteristics from those sub components. By applying ensemble\nlearning techniques to these individual classifications, we make the final\nclassification decision on the genre of the music. The proposed method has\nsuperior advantages in terms of accuracy compared to the other state-of-the-art\ntechniques trained and tested on the GTZAN dataset.", "published": "2024-12-20 06:50:31", "link": "http://arxiv.org/abs/2412.15602v1", "categories": ["cs.SD", "cs.IR", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
