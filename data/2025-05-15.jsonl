{"title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "abstract": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder.", "published": "2025-05-15 17:59:21", "link": "http://arxiv.org/abs/2505.10557v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models", "abstract": "Large reasoning models (LRMs) already possess a latent capacity for long\nchain-of-thought reasoning. Prior work has shown that outcome-based\nreinforcement learning (RL) can incidentally elicit advanced reasoning\nbehaviors such as self-correction, backtracking, and verification phenomena\noften referred to as the model's \"aha moment\". However, the timing and\nconsistency of these emergent behaviors remain unpredictable and\nuncontrollable, limiting the scalability and reliability of LRMs' reasoning\ncapabilities. To address these limitations, we move beyond reliance on prompts\nand coincidental \"aha moments\". Instead, we explicitly align models with three\nmeta-abilities: deduction, induction, and abduction, using automatically\ngenerated, self-verifiable tasks. Our three stage-pipeline individual\nalignment, parameter-space merging, and domain-specific reinforcement learning,\nboosting performance by over 10\\% relative to instruction-tuned baselines.\nFurthermore, domain-specific RL from the aligned checkpoint yields an\nadditional 2\\% average gain in the performance ceiling across math, coding, and\nscience benchmarks, demonstrating that explicit meta-ability alignment offers a\nscalable and dependable foundation for reasoning. Code is available at:\nhttps://github.com/zhiyuanhubj/Meta-Ability-Alignment", "published": "2025-05-15 17:58:33", "link": "http://arxiv.org/abs/2505.10554v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "abstract": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning.", "published": "2025-05-15 17:53:47", "link": "http://arxiv.org/abs/2505.10543v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "WorldPM: Scaling Human Preference Modeling", "abstract": "Motivated by scaling laws in language modeling that demonstrate how test loss\nscales as a power law with model and dataset sizes, we find that similar laws\nexist in preference modeling. We propose World Preference Modeling$ (WorldPM)\nto emphasize this scaling potential, where World Preference embodies a unified\nrepresentation of human preferences. In this paper, we collect preference data\nfrom public forums covering diverse user communities, and conduct extensive\ntraining using 15M-scale data across models ranging from 1.5B to 72B\nparameters. We observe distinct patterns across different evaluation metrics:\n(1) Adversarial metrics (ability to identify deceptive features) consistently\nscale up with increased training data and base model size; (2) Objective\nmetrics (objective knowledge with well-defined answers) show emergent behavior\nin larger language models, highlighting WorldPM's scalability potential; (3)\nSubjective metrics (subjective preferences from a limited number of humans or\nAI) do not demonstrate scaling trends. Further experiments validate the\neffectiveness of WorldPM as a foundation for preference fine-tuning. Through\nevaluations on 7 benchmarks with 20 subtasks, we find that WorldPM broadly\nimproves the generalization performance across human preference datasets of\nvarying sizes (7K, 100K and 800K samples), with performance gains exceeding 5%\non many key subtasks. Integrating WorldPM into our internal RLHF pipeline, we\nobserve significant improvements on both in-house and public evaluation sets,\nwith notable gains of 4% to 8% in our in-house evaluations.", "published": "2025-05-15 17:38:37", "link": "http://arxiv.org/abs/2505.10527v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "abstract": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs.", "published": "2025-05-15 17:37:00", "link": "http://arxiv.org/abs/2505.10526v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Multi-Token Prediction Needs Registers", "abstract": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR.", "published": "2025-05-15 17:25:03", "link": "http://arxiv.org/abs/2505.10518v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks", "abstract": "Translation-based strategies for cross-lingual transfer XLT such as\ntranslate-train -- training on noisy target language data translated from the\nsource language -- and translate-test -- evaluating on noisy source language\ndata translated from the target language -- are competitive XLT baselines. In\nXLT for token classification tasks, however, these strategies include label\nprojection, the challenging step of mapping the labels from each token in the\noriginal sentence to its counterpart(s) in the translation. Although word\naligners (WAs) are commonly used for label projection, the low-level design\ndecisions for applying them to translation-based XLT have not been\nsystematically investigated. Moreover, recent marker-based methods, which\nproject labeled spans by inserting tags around them before (or after)\ntranslation, claim to outperform WAs in label projection for XLT. In this work,\nwe revisit WAs for label projection, systematically investigating the effects\nof low-level design decisions on token-level XLT: (i) the algorithm for\nprojecting labels between (multi-)token spans, (ii) filtering strategies to\nreduce the number of noisily mapped labels, and (iii) the pre-tokenization of\nthe translated sentences. We find that all of these substantially impact\ntranslation-based XLT performance and show that, with optimized choices, XLT\nwith WA offers performance at least comparable to that of marker-based methods.\nWe then introduce a new projection strategy that ensembles translate-train and\ntranslate-test predictions and demonstrate that it substantially outperforms\nthe marker-based projection. Crucially, we show that our proposed ensembling\nalso reduces sensitivity to low-level WA design choices, resulting in more\nrobust XLT for token classification tasks.", "published": "2025-05-15 17:10:50", "link": "http://arxiv.org/abs/2505.10507v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "abstract": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks.", "published": "2025-05-15 16:53:45", "link": "http://arxiv.org/abs/2505.10495v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective", "abstract": "Code security and usability are both essential for various coding assistant\napplications driven by large language models (LLMs). Current code security\nbenchmarks focus solely on single evaluation task and paradigm, such as code\ncompletion and generation, lacking comprehensive assessment across dimensions\nlike secure code generation, vulnerability repair and discrimination. In this\npaper, we first propose CoV-Eval, a multi-task benchmark covering various tasks\nsuch as code completion, vulnerability repair, vulnerability detection and\nclassification, for comprehensive evaluation of LLM code security. Besides, we\ndeveloped VC-Judge, an improved judgment model that aligns closely with human\nexperts and can review LLM-generated programs for vulnerabilities in a more\nefficient and reliable way. We conduct a comprehensive evaluation of 20\nproprietary and open-source LLMs. Overall, while most LLMs identify vulnerable\ncodes well, they still tend to generate insecure codes and struggle with\nrecognizing specific vulnerability types and performing repairs. Extensive\nexperiments and qualitative analyses reveal key challenges and optimization\ndirections, offering insights for future research in LLM code security.", "published": "2025-05-15 16:53:41", "link": "http://arxiv.org/abs/2505.10494v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning", "abstract": "Retrieval-Augmented Generation (RAG) is an effective method to enhance the\ncapabilities of large language models (LLMs). Existing methods focus on\noptimizing the retriever or generator in the RAG system by directly utilizing\nthe top-k retrieved documents. However, the documents effectiveness are various\nsignificantly across user queries, i.e. some documents provide valuable\nknowledge while others totally lack critical information. It hinders the\nretriever and generator's adaptation during training. Inspired by human\ncognitive learning, curriculum learning trains models using samples progressing\nfrom easy to difficult, thus enhancing their generalization ability, and we\nintegrate this effective paradigm to the training of the RAG system. In this\npaper, we propose a multi-stage Curriculum Learning based RAG system training\nframework, named CL-RAG. We first construct training data with multiple\ndifficulty levels for the retriever and generator separately through sample\nevolution. Then, we train the model in stages based on the curriculum learning\napproach, thereby optimizing the overall performance and generalization of the\nRAG system more effectively. Our CL-RAG framework demonstrates consistent\neffectiveness across four open-domain QA datasets, achieving performance gains\nof 2% to 4% over multiple advanced methods.", "published": "2025-05-15 16:53:04", "link": "http://arxiv.org/abs/2505.10493v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parallel Scaling Law for Language Models", "abstract": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning.", "published": "2025-05-15 16:24:45", "link": "http://arxiv.org/abs/2505.10475v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Superposition Yields Robust Neural Scaling", "abstract": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters.", "published": "2025-05-15 16:18:13", "link": "http://arxiv.org/abs/2505.10465v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models", "abstract": "We introduce the \\emph{Diffusion Chain of Lateral Thought (DCoLT)}, a\nreasoning framework for diffusion language models. DCoLT treats each\nintermediate step in the reverse diffusion process as a latent \"thinking\"\naction and optimizes the entire reasoning trajectory to maximize the reward on\nthe correctness of the final answer with outcome-based Reinforcement Learning\n(RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal,\nlinear thinking process, DCoLT allows bidirectional, non-linear reasoning with\nno strict rule on grammatical correctness amid its intermediate steps of\nthought. We implement DCoLT on two representative Diffusion Language Models\n(DLMs). First, we choose SEDD as a representative continuous-time discrete\ndiffusion model, where its concrete score derives a probabilistic policy to\nmaximize the RL reward over the entire sequence of intermediate diffusion\nsteps. We further consider the discrete-time masked diffusion language model --\nLLaDA, and find that the order to predict and unmask tokens plays an essential\nrole to optimize its RL action resulting from the ranking-based Unmasking\nPolicy Module (UPM) defined by the Plackett-Luce model. Experiments on both\nmath and code generation tasks show that using only public data and 16 H800\nGPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even\nboth. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%,\n+5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval.", "published": "2025-05-15 16:06:32", "link": "http://arxiv.org/abs/2505.10446v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Document Refinement for Long-context Retrieval-augmented Generation", "abstract": "Real-world RAG applications often encounter long-context input scenarios,\nwhere redundant information and noise results in higher inference costs and\nreduced performance. To address these challenges, we propose LongRefiner, an\nefficient plug-and-play refiner that leverages the inherent structural\ncharacteristics of long documents. LongRefiner employs dual-level query\nanalysis, hierarchical document structuring, and adaptive refinement through\nmulti-task learning on a single foundation model. Experiments on seven QA\ndatasets demonstrate that LongRefiner achieves competitive performance in\nvarious scenarios while using 10x fewer computational costs and latency\ncompared to the best baseline. Further analysis validates that LongRefiner is\nscalable, efficient, and effective, providing practical insights for real-world\nlong-text RAG applications. Our code is available at\nhttps://github.com/ignorejjj/LongRefiner.", "published": "2025-05-15 15:34:15", "link": "http://arxiv.org/abs/2505.10413v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation", "abstract": "Plain language summaries (PLSs) are essential for facilitating effective\ncommunication between clinicians and patients by making complex medical\ninformation easier for laypeople to understand and act upon. Large language\nmodels (LLMs) have recently shown promise in automating PLS generation, but\ntheir effectiveness in supporting health information comprehension remains\nunclear. Prior evaluations have generally relied on automated scores that do\nnot measure understandability directly, or subjective Likert-scale ratings from\nconvenience samples with limited generalizability. To address these gaps, we\nconducted a large-scale crowdsourced evaluation of LLM-generated PLSs using\nAmazon Mechanical Turk with 150 participants. We assessed PLS quality through\nsubjective Likert-scale ratings focusing on simplicity, informativeness,\ncoherence, and faithfulness; and objective multiple-choice comprehension and\nrecall measures of reader understanding. Additionally, we examined the\nalignment between 10 automated evaluation metrics and human judgments. Our\nfindings indicate that while LLMs can generate PLSs that appear\nindistinguishable from human-written ones in subjective evaluations,\nhuman-written PLSs lead to significantly better comprehension. Furthermore,\nautomated evaluation metrics fail to reflect human judgment, calling into\nquestion their suitability for evaluating PLSs. This is the first study to\nsystematically evaluate LLM-generated PLSs based on both reader preferences and\ncomprehension outcomes. Our findings highlight the need for evaluation\nframeworks that move beyond surface-level quality and for generation methods\nthat explicitly optimize for layperson comprehension.", "published": "2025-05-15 15:31:17", "link": "http://arxiv.org/abs/2505.10409v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Repetition Problems of LLMs in Code Generation", "abstract": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code.", "published": "2025-05-15 15:26:32", "link": "http://arxiv.org/abs/2505.10402v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples", "abstract": "This paper explores the design of an aspect-based sentiment analysis system\nusing large language models (LLMs) for real-world use. We focus on quadruple\nopinion extraction -- identifying aspect categories, sentiment polarity,\ntargets, and opinion expressions from text data across different domains and\nlanguages. Using internal datasets, we investigate whether a single fine-tuned\nmodel can effectively handle multiple domain-specific taxonomies\nsimultaneously. We demonstrate that a combined multi-domain model achieves\nperformance comparable to specialized single-domain models while reducing\noperational complexity. We also share lessons learned for handling\nnon-extractive predictions and evaluating various failure modes when developing\nLLM-based systems for structured prediction tasks.", "published": "2025-05-15 15:11:48", "link": "http://arxiv.org/abs/2505.10389v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Coherent Language Reconstruction from Brain Recordings with Flexible Multi-Modal Input Stimuli", "abstract": "Decoding thoughts from brain activity offers valuable insights into human\ncognition and enables promising applications in brain-computer interaction.\nWhile prior studies have explored language reconstruction from fMRI data, they\nare typically limited to single-modality inputs such as images or audio. In\ncontrast, human thought is inherently multimodal. To bridge this gap, we\npropose a unified and flexible framework for reconstructing coherent language\nfrom brain recordings elicited by diverse input modalities-visual, auditory,\nand textual. Our approach leverages visual-language models (VLMs), using\nmodality-specific experts to jointly interpret information across modalities.\nExperiments demonstrate that our method achieves performance comparable to\nstate-of-the-art systems while remaining adaptable and extensible. This work\nadvances toward more ecologically valid and generalizable mind decoding.", "published": "2025-05-15 14:46:45", "link": "http://arxiv.org/abs/2505.10356v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations", "abstract": "Semantic text representation is a fundamental task in the field of natural\nlanguage processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have\ndemonstrated excellent performance, but the values of each dimension are\ndifficult to trace and interpret. Bag-of-words, as classic sparse interpretable\nembeddings, suffers from poor performance. Recently, Benara et al. (2024)\npropose interpretable text embeddings using large language models, which forms\n\"0/1\" embeddings based on responses to a series of questions. These\ninterpretable text embeddings are typically high-dimensional (larger than\n10,000). In this work, we propose Low-dimensional (lower than 500) Dense and\nInterpretable text embeddings with Relative representations (LDIR). The\nnumerical values of its dimensions indicate semantic relatedness to different\nanchor texts through farthest point sampling, offering both semantic\nrepresentation as well as a certain level of traceability and interpretability.\nWe validate LDIR on multiple semantic textual similarity, retrieval, and\nclustering tasks. Extensive experimental results show that LDIR performs close\nto the black-box baseline models and outperforms the interpretable embeddings\nbaselines with much fewer dimensions. Code is available at\nhttps://github.com/szu-tera/LDIR.", "published": "2025-05-15 14:45:45", "link": "http://arxiv.org/abs/2505.10354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "abstract": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses.", "published": "2025-05-15 14:05:15", "link": "http://arxiv.org/abs/2505.10320v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "abstract": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model.", "published": "2025-05-15 13:42:14", "link": "http://arxiv.org/abs/2505.10292v1", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "primary_category": "cs.CV"}
{"title": "From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making", "abstract": "Clinical evidence, derived from rigorous research and data analysis, provides\nhealthcare professionals with reliable scientific foundations for informed\ndecision-making. Integrating clinical evidence into real-time practice is\nchallenging due to the enormous workload, complex professional processes, and\ntime constraints. This highlights the need for tools that automate evidence\nsynthesis to support more efficient and accurate decision making in clinical\nsettings. This study introduces Quicker, an evidence-based clinical decision\nsupport system powered by large language models (LLMs), designed to automate\nevidence synthesis and generate clinical recommendations modeled after standard\nclinical guideline development processes. Quicker implements a fully automated\nchain that covers all phases, from questions to clinical recommendations, and\nfurther enables customized decision-making through integrated tools and\ninteractive user interfaces. To evaluate Quicker's capabilities, we developed\nthe Q2CRBench-3 benchmark dataset, based on clinical guideline development\nrecords for three different diseases. Experimental results highlighted\nQuicker's strong performance, with fine-grained question decomposition tailored\nto user preferences, retrieval sensitivities comparable to human experts, and\nliterature screening performance approaching comprehensive inclusion of\nrelevant studies. In addition, Quicker-assisted evidence assessment effectively\nsupported human reviewers, while Quicker's recommendations were more\ncomprehensive and logically coherent than those of clinicians. In system-level\ntesting, collaboration between a single reviewer and Quicker reduced the time\nrequired for recommendation development to 20-40 minutes. In general, our\nfindings affirm the potential of Quicker to help physicians make quicker and\nmore reliable evidence-based clinical decisions.", "published": "2025-05-15 13:30:39", "link": "http://arxiv.org/abs/2505.10282v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "abstract": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications.", "published": "2025-05-15 13:11:14", "link": "http://arxiv.org/abs/2505.10261v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "abstract": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios.", "published": "2025-05-15 13:10:47", "link": "http://arxiv.org/abs/2505.10260v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "abstract": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner.", "published": "2025-05-15 12:43:23", "link": "http://arxiv.org/abs/2505.10231v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "abstract": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism.", "published": "2025-05-15 12:30:33", "link": "http://arxiv.org/abs/2505.10222v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward", "abstract": "Role-playing conversational agents (RPCAs) face persistent challenges in\nmaintaining role consistency. To address this, we propose RAIDEN-R1, a novel\nreinforcement learning framework that integrates Verifiable Role-Awareness\nReward (VRAR). The method introduces both singular and multi-term mining\nstrategies to generate quantifiable rewards by assessing role-specific keys.\nAdditionally, we construct a high-quality, role-aware Chain-of-Thought dataset\nthrough multi-LLM collaboration, and implement experiments to enhance reasoning\ncoherence. Experiments on the RAIDEN benchmark demonstrate RAIDEN-R1's\nsuperiority: our 14B-GRPO model achieves 88.04% and 88.65% accuracy on\nScript-Based Knowledge and Conversation Memory metrics, respectively,\noutperforming baseline models while maintaining robustness. Case analyses\nfurther reveal the model's enhanced ability to resolve conflicting contextual\ncues and sustain first-person narrative consistency. This work bridges the\nnon-quantifiability gap in RPCA training and provides insights into role-aware\nreasoning patterns, advancing the development of RPCAs.", "published": "2025-05-15 12:22:10", "link": "http://arxiv.org/abs/2505.10218v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits", "abstract": "Large Language Models (LLMs) have achieved remarkable success but face\nsignificant computational and memory challenges, particularly due to their\nextensive output vocabularies. The final linear projection layer, mapping\nhidden states to vocabulary-sized logits, often constitutes a substantial\nportion of the model's parameters and computational cost during inference.\nExisting methods like adaptive softmax or hierarchical softmax introduce\nstructural complexities. In this paper, we propose VQ-Logits, a novel approach\nthat leverages Vector Quantization (VQ) to drastically reduce the parameter\ncount and computational load of the LLM output layer. VQ-Logits replaces the\nlarge V * dmodel output embedding matrix with a small, shared codebook of K\nembedding vectors (K << V ). Each token in the vocabulary is mapped to one of\nthese K codebook vectors. The LLM predicts logits over this compact codebook,\nwhich are then efficiently \"scattered\" to the full vocabulary space using the\nlearned or preassigned mapping. We demonstrate through extensive experiments on\nstandard language modeling benchmarks (e.g., WikiText-103, C4) that VQ-Logits\ncan achieve up to 99% parameter reduction in the output layer and 6x speedup in\nlogit computation, with only a marginal 4% increase in perplexity compared to\nfull softmax baselines. We further provide detailed ablation studies on\ncodebook size, initialization, and learning strategies, showcasing the\nrobustness and effectiveness of our approach.", "published": "2025-05-15 11:58:04", "link": "http://arxiv.org/abs/2505.10202v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "abstract": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design.", "published": "2025-05-15 11:31:02", "link": "http://arxiv.org/abs/2505.10185v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "abstract": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty.", "published": "2025-05-15 11:29:01", "link": "http://arxiv.org/abs/2505.10182v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs", "abstract": "Large Language Models are now key assistants in human decision-making\nprocesses. However, a common note always seems to follow: \"LLMs can make\nmistakes. Be careful with important info.\" This points to the reality that not\nall outputs from LLMs are dependable, and users must evaluate them manually.\nThe challenge deepens as hallucinated responses, often presented with seemingly\nplausible explanations, create complications and raise trust issues among\nusers. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph\nenhanced retrieval-augmented generation framework to provide Evidence-based\nresponse generation. Specifically, when the user uploads a material document, a\nknowledge graph will be created, which helps construct a retrieval-augmented\nagent, enhancing the agent's responses with additional knowledge beyond its\ntraining corpus. Then we leverage Chain-of-Thought (CoT) logic generation,\nn-hop sub-graph searching, and entailment-based sentence generation to realize\naccurate evidence retrieval. We demonstrate that our method improves the\nexisting models' performance in terms of identifying the exact evidence in a\nfree-form context, providing a reliable way to examine the resources of LLM's\nconclusion and help with the judgment of the trustworthiness.", "published": "2025-05-15 10:17:35", "link": "http://arxiv.org/abs/2505.10143v1", "categories": ["cs.CL", "68T50, 68T30", "I.2.7; I.2.4; H.3.3"], "primary_category": "cs.CL"}
{"title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "abstract": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks.", "published": "2025-05-15 09:43:28", "link": "http://arxiv.org/abs/2505.10118v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "abstract": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments.", "published": "2025-05-15 09:42:11", "link": "http://arxiv.org/abs/2505.10117v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs", "abstract": "In this paper, we introduce S-MedQA, an English medical question-answering\n(QA) dataset for benchmarking large language models in fine-grained clinical\nspecialties. We use S-MedQA to check the applicability of a popular hypothesis\nrelated to knowledge injection in the knowledge-intense scenario of medical QA,\nand show that: 1) training on data from a speciality does not necessarily lead\nto best performance on that specialty and 2) regardless of the specialty\nfine-tuned on, token probabilities of clinically relevant terms for all\nspecialties increase consistently. Thus, we believe improvement gains come\nmostly from domain shifting (e.g., general to medical) rather than knowledge\ninjection and suggest rethinking the role of fine-tuning data in the medical\ndomain. We release S-MedQA and all code needed to reproduce all our experiments\nto the research community.", "published": "2025-05-15 09:35:26", "link": "http://arxiv.org/abs/2505.10113v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "abstract": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems.", "published": "2025-05-15 08:51:53", "link": "http://arxiv.org/abs/2505.10093v1", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "primary_category": "cs.AI"}
{"title": "XRAG: Cross-lingual Retrieval-Augmented Generation", "abstract": "We propose XRAG, a novel benchmark designed to evaluate the generation\nabilities of LLMs in cross-lingual Retrieval-Augmented Generation (RAG)\nsettings where the user language does not match the retrieval results. XRAG is\nconstructed from recent news articles to ensure that its questions require\nexternal knowledge to be answered. It covers the real-world scenarios of\nmonolingual and multilingual retrieval, and provides relevancy annotations for\neach retrieved document. Our novel dataset construction pipeline results in\nquestions that require complex reasoning, as evidenced by the significant gap\nbetween human and LLM performance. Consequently, XRAG serves as a valuable\nbenchmark for studying LLM reasoning abilities, even before considering the\nadditional cross-lingual complexity. Experimental results on five LLMs uncover\ntwo previously unreported challenges in cross-lingual RAG: 1) in the\nmonolingual retrieval setting, all evaluated models struggle with response\nlanguage correctness; 2) in the multilingual retrieval setting, the main\nchallenge lies in reasoning over retrieved information across languages rather\nthan generation of non-English text.", "published": "2025-05-15 08:47:55", "link": "http://arxiv.org/abs/2505.10089v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Designing and Contextualising Probes for African Languages", "abstract": "Pretrained language models (PLMs) for African languages are continually\nimproving, but the reasons behind these advances remain unclear. This paper\npresents the first systematic investigation into probing PLMs for linguistic\nknowledge about African languages. We train layer-wise probes for six\ntypologically diverse African languages to analyse how linguistic features are\ndistributed. We also design control tasks, a way to interpret probe\nperformance, for the MasakhaPOS dataset. We find PLMs adapted for African\nlanguages to encode more linguistic information about target languages than\nmassively multilingual PLMs. Our results reaffirm previous findings that\ntoken-level syntactic information concentrates in middle-to-last layers, while\nsentence-level semantic information is distributed across all layers. Through\ncontrol tasks and probing baselines, we confirm that performance reflects the\ninternal knowledge of PLMs rather than probe memorisation. Our study applies\nestablished interpretability techniques to African-language PLMs. In doing so,\nwe highlight the internal mechanisms underlying the success of strategies like\nactive learning and multilingual adaptation.", "published": "2025-05-15 08:35:14", "link": "http://arxiv.org/abs/2505.10081v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "abstract": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated.", "published": "2025-05-15 08:07:04", "link": "http://arxiv.org/abs/2505.10066v1", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "primary_category": "cs.CL"}
{"title": "CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability", "abstract": "Advancements in Large Language Models (LLMs) have extended their input\ncontext length, yet they still struggle with retrieval and reasoning in\nlong-context inputs. Existing methods propose to utilize the prompt strategy\nand retrieval head to alleviate this limitation. However, they still face\nchallenges in balancing retrieval precision and recall, impacting their\nefficacy in answering questions. To address this, we introduce $\\textbf{CAFE}$,\na two-stage coarse-to-fine method to enhance multi-document question-answering\ncapacities. By gradually eliminating the negative impacts of background and\ndistracting documents, CAFE makes the responses more reliant on the evidence\ndocuments. Initially, a coarse-grained filtering method leverages retrieval\nheads to identify and rank relevant documents. Then, a fine-grained steering\nmethod guides attention to the most relevant content. Experiments across\nbenchmarks show CAFE outperforms baselines, achieving up to 22.1% and 13.7%\nSubEM improvement over SFT and RAG methods on the Mistral model, respectively.", "published": "2025-05-15 08:05:12", "link": "http://arxiv.org/abs/2505.10063v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs", "abstract": "As Large Language Models (LLMs) have risen in prominence over the past few\nyears, there has been concern over the potential biases in LLMs inherited from\nthe training data. Previous studies have examined how LLMs exhibit implicit\nbias, such as when response generation changes when different social contexts\nare introduced. We argue that this implicit bias is not only an ethical, but\nalso a technical issue, as it reveals an inability of LLMs to accommodate\nextraneous information. However, unlike other measures of LLM intelligence,\nthere are no standard methods to benchmark this specific subset of LLM bias. To\nbridge this gap, we developed a method for calculating an easily interpretable\nbenchmark, DIF (Demographic Implicit Fairness), by evaluating preexisting LLM\nlogic and math problem datasets with sociodemographic personas. We demonstrate\nthat this method can statistically validate the presence of implicit bias in\nLLM behavior and find an inverse trend between question answering accuracy and\nimplicit bias, supporting our argument.", "published": "2025-05-15 06:53:37", "link": "http://arxiv.org/abs/2505.10013v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "abstract": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices.", "published": "2025-05-15 04:07:55", "link": "http://arxiv.org/abs/2505.09949v1", "categories": ["cs.LG", "cs.CL", "stat.AP"], "primary_category": "cs.LG"}
{"title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "abstract": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time.", "published": "2025-05-15 04:01:58", "link": "http://arxiv.org/abs/2505.09945v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Rethinking Prompt Optimizers: From Prompt Merits to Optimization", "abstract": "Prompt optimization (PO) offers a practical alternative to fine-tuning large\nlanguage models (LLMs), enabling performance improvements without altering\nmodel weights. Existing methods typically rely on advanced, large-scale LLMs\nlike GPT-4 to generate optimized prompts. However, due to limited downward\ncompatibility, verbose, instruction-heavy prompts from advanced LLMs can\noverwhelm lightweight inference models and degrade response quality. In this\nwork, we rethink prompt optimization through the lens of interpretable design.\nWe first identify a set of model-agnostic prompt quality merits and empirically\nvalidate their effectiveness in enhancing prompt and response quality. We then\nintroduce MePO, a merit-guided, lightweight, and locally deployable prompt\noptimizer trained on our preference dataset built from merit-aligned prompts\ngenerated by a lightweight LLM. Unlike prior work, MePO avoids online\noptimization reliance, reduces cost and privacy concerns, and, by learning\nclear, interpretable merits, generalizes effectively to both large-scale and\nlightweight inference models. Experiments demonstrate that MePO achieves better\nresults across diverse tasks and model types, offering a scalable and robust\nsolution for real-world deployment. Our model and dataset are available at:\nhttps://github.com/MidiyaZhu/MePO", "published": "2025-05-15 03:31:37", "link": "http://arxiv.org/abs/2505.09930v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models", "abstract": "The rise of Large Language Models (LLMs) has heightened concerns about the\nmisuse of AI-generated text, making watermarking a promising solution.\nMainstream watermarking schemes for LLMs fall into two categories: logits-based\nand sampling-based. However, current schemes entail trade-offs among\nrobustness, text quality, and security. To mitigate this, we integrate\nlogits-based and sampling-based schemes, harnessing their respective strengths\nto achieve synergy. In this paper, we propose a versatile symbiotic\nwatermarking framework with three strategies: serial, parallel, and hybrid. The\nhybrid framework adaptively embeds watermarks using token entropy and semantic\nentropy, optimizing the balance between detectability, robustness, text\nquality, and security. Furthermore, we validate our approach through\ncomprehensive experiments on various datasets and models. Experimental results\nindicate that our method outperforms existing baselines and achieves\nstate-of-the-art (SOTA) performance. We believe this framework provides novel\ninsights into diverse watermarking paradigms. Our code is available at\n\\href{https://github.com/redwyd/SymMark}{https://github.com/redwyd/SymMark}.", "published": "2025-05-15 03:12:36", "link": "http://arxiv.org/abs/2505.09924v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization", "abstract": "Large Language Models (LLMs) excel in various domains but pose inherent\nprivacy risks. Existing methods to evaluate privacy leakage in LLMs often use\nmemorized prefixes or simple instructions to extract data, both of which\nwell-alignment models can easily block. Meanwhile, Jailbreak attacks bypass LLM\nsafety mechanisms to generate harmful content, but their role in privacy\nscenarios remains underexplored. In this paper, we examine the effectiveness of\njailbreak attacks in extracting sensitive information, bridging privacy leakage\nand jailbreak attacks in LLMs. Moreover, we propose PIG, a novel framework\ntargeting Personally Identifiable Information (PII) and addressing the\nlimitations of current jailbreak methods. Specifically, PIG identifies PII\nentities and their types in privacy queries, uses in-context learning to build\na privacy context, and iteratively updates it with three gradient-based\nstrategies to elicit target PII. We evaluate PIG and existing jailbreak methods\nusing two privacy-related datasets. Experiments on four white-box and two\nblack-box LLMs show that PIG outperforms baseline methods and achieves\nstate-of-the-art (SoTA) results. The results underscore significant privacy\nrisks in LLMs, emphasizing the need for stronger safeguards. Our code is\navailble at\n\\href{https://github.com/redwyd/PrivacyJailbreak}{https://github.com/redwyd/PrivacyJailbreak}.", "published": "2025-05-15 03:11:57", "link": "http://arxiv.org/abs/2505.09921v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries", "abstract": "Large language models are, by definition, based on language. In an effort to\nunderscore the critical need for regional localized models, this paper examines\nprimary differences between variants of written Spanish across Latin America\nand Spain, with an in-depth sociocultural and linguistic contextualization\ntherein. We argue that these differences effectively constitute significant\ngaps in the quotidian use of Spanish among dialectal groups by creating\nsociolinguistic dissonances, to the extent that locale-sensitive AI models\nwould play a pivotal role in bridging these divides. In doing so, this approach\ninforms better and more efficient localization strategies that also serve to\nmore adequately meet inclusivity goals, while securing sustainable active daily\nuser growth in a major low-risk investment geographic area. Therefore,\nimplementing at least the proposed five sub variants of Spanish addresses two\nlines of action: to foment user trust and reliance on AI language models while\nalso demonstrating a level of cultural, historical, and sociolinguistic\nawareness that reflects positively on any internationalization strategy.", "published": "2025-05-15 02:09:19", "link": "http://arxiv.org/abs/2505.09902v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "abstract": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements.", "published": "2025-05-15 02:09:18", "link": "http://arxiv.org/abs/2505.09901v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Neural Thermodynamic Laws for Large Language Model Training", "abstract": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules.", "published": "2025-05-15 17:59:22", "link": "http://arxiv.org/abs/2505.10559v1", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "abstract": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets.", "published": "2025-05-15 17:57:38", "link": "http://arxiv.org/abs/2505.10551v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning", "abstract": "Foundation models can provide robust high-level reasoning on appropriate\nsafety interventions in hazardous scenarios beyond a robot's training data,\ni.e. out-of-distribution (OOD) failures. However, due to the high inference\nlatency of Large Vision and Language Models, current methods rely on manually\ndefined intervention policies to enact fallbacks, thereby lacking the ability\nto plan generalizable, semantically safe motions. To overcome these challenges\nwe present FORTRESS, a framework that generates and reasons about semantically\nsafe fallback strategies in real time to prevent OOD failures. At a low\nfrequency in nominal operations, FORTRESS uses multi-modal reasoners to\nidentify goals and anticipate failure modes. When a runtime monitor triggers a\nfallback response, FORTRESS rapidly synthesizes plans to fallback goals while\ninferring and avoiding semantically unsafe regions in real time. By bridging\nopen-world, multi-modal reasoning with dynamics-aware planning, we eliminate\nthe need for hard-coded fallbacks and human safety interventions. FORTRESS\noutperforms on-the-fly prompting of slow reasoning models in safety\nclassification accuracy on synthetic benchmarks and real-world ANYmal robot\ndata, and further improves system safety and planning success in simulation and\non quadrotor hardware for urban navigation.", "published": "2025-05-15 17:55:28", "link": "http://arxiv.org/abs/2505.10547v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps", "abstract": "The O-RAN architecture is transforming cellular networks by adopting RAN\nsoftwarization and disaggregation concepts to enable data-driven monitoring and\ncontrol of the network. Such management is enabled by RICs, which facilitate\nnear-real-time and non-real-time network control through xApps and rApps.\nHowever, they face limitations, including latency overhead in data exchange\nbetween the RAN and RIC, restricting real-time monitoring, and the inability to\naccess user plain data due to privacy and security constraints, hindering use\ncases like beamforming and spectrum classification. In this paper, we leverage\nthe dApps concept to enable real-time RF spectrum classification with LibIQ, a\nnovel library for RF signals that facilitates efficient spectrum monitoring and\nsignal classification by providing functionalities to read I/Q samples as\ntime-series, create datasets and visualize time-series data through plots and\nspectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to\ndetect external RF signals, which are subsequently classified using a CNN\ninside the library. To achieve accurate spectrum analysis, we created an\nextensive dataset of time-series-based I/Q samples, representing distinct\nsignal types captured using a custom dApp running on a 5G deployment over the\nColosseum network emulator and an OTA testbed. We evaluate our model by\ndeploying LibIQ in heterogeneous scenarios with varying center frequencies,\ntime windows, and external RF signals. In real-time analysis, the model\nclassifies the processed I/Q samples, achieving an average accuracy of\napproximately 97.8\\% in identifying signal types across all scenarios. We\npledge to release both LibIQ and the dataset created as a publicly available\nframework upon acceptance.", "published": "2025-05-15 17:47:30", "link": "http://arxiv.org/abs/2505.10537v1", "categories": ["cs.NI", "cs.AI"], "primary_category": "cs.NI"}
{"title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation", "abstract": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic\nmanipulation but faces challenges in sample inefficiency and lack of\ninterpretability, limiting its applicability in real world scenarios. Enabling\nthe agent to gain a deeper understanding and adapt more efficiently to diverse\nworking scenarios is crucial, and strategic knowledge utilization is a key\nfactor in this process. This paper proposes a Knowledge Capture, Adaptation,\nand Composition (KCAC) framework to systematically integrate knowledge transfer\ninto RL through cross-task curriculum learning. KCAC is evaluated using a two\nblock stacking task in the CausalWorld benchmark, a complex robotic\nmanipulation environment. To our knowledge, existing RL approaches fail to\nsolve this task effectively, reflecting deficiencies in knowledge capture. In\nthis work, we redesign the benchmark reward function by removing rigid\nconstraints and strict ordering, allowing the agent to maximize total rewards\nconcurrently and enabling flexible task completion. Furthermore, we define two\nself-designed sub-tasks and implement a structured cross-task curriculum to\nfacilitate efficient learning. As a result, our KCAC approach achieves a 40\npercent reduction in training time while improving task success rates by 10\npercent compared to traditional RL methods. Through extensive evaluation, we\nidentify key curriculum design parameters subtask selection, transition timing,\nand learning rate that optimize learning efficiency and provide conceptual\nguidance for curriculum based RL frameworks. This work offers valuable insights\ninto curriculum design in RL and robotic learning.", "published": "2025-05-15 17:30:29", "link": "http://arxiv.org/abs/2505.10522v1", "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "cs.RO"}
{"title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "abstract": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance.", "published": "2025-05-15 17:21:54", "link": "http://arxiv.org/abs/2505.10515v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "abstract": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values.", "published": "2025-05-15 16:34:50", "link": "http://arxiv.org/abs/2505.10483v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "abstract": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy.", "published": "2025-05-15 16:33:44", "link": "http://arxiv.org/abs/2505.10482v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge", "abstract": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications", "published": "2025-05-15 16:21:33", "link": "http://arxiv.org/abs/2505.10468v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "SEAL: Searching Expandable Architectures for Incremental Learning", "abstract": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios.", "published": "2025-05-15 16:14:18", "link": "http://arxiv.org/abs/2505.10457v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "primary_category": "cs.LG"}
{"title": "Vision language models have difficulty recognizing virtual objects", "abstract": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate.", "published": "2025-05-15 16:11:33", "link": "http://arxiv.org/abs/2505.10453v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?", "abstract": "Understanding the reasoning and robustness of Large Language Models (LLMs) is\ncritical for their reliable use in programming tasks. While recent studies have\nassessed LLMs' ability to predict program outputs, most focus solely on the\naccuracy of those predictions, without evaluating the reasoning behind them.\nMoreover, it has been observed on mathematical reasoning tasks that LLMs can\narrive at correct answers through flawed logic, raising concerns about similar\nissues in code understanding.\n  In this work, we evaluate whether state-of-the-art LLMs with up to 8B\nparameters can reason about Python programs or are simply guessing. We apply\nfive semantics-preserving code mutations: renaming variables, mirroring\ncomparison expressions, swapping if-else branches, converting for loops to\nwhile, and loop unrolling. These mutations maintain program semantics while\naltering its syntax. We evaluated six LLMs and performed a human expert\nanalysis using LiveCodeBench to assess whether the correct predictions are\nbased on sound reasoning. We also evaluated prediction stability across\ndifferent code mutations on LiveCodeBench and CruxEval. Our findings show that\nsome LLMs, such as Llama3.2, produce correct predictions based on flawed\nreasoning in up to 61% of cases. Furthermore, LLMs often change predictions in\nresponse to our code mutations, indicating limited robustness in their semantic\nunderstanding.", "published": "2025-05-15 16:04:25", "link": "http://arxiv.org/abs/2505.10443v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning", "abstract": "Imitation learning (IL) and reinforcement learning (RL) each offer distinct\nadvantages for robotics policy learning: IL provides stable learning from\ndemonstrations, and RL promotes generalization through exploration. While\nexisting robot learning approaches using IL-based pre-training followed by\nRL-based fine-tuning are promising, this two-step learning paradigm often\nsuffers from instability and poor sample efficiency during the RL fine-tuning\nphase. In this work, we introduce IN-RIL, INterleaved Reinforcement learning\nand Imitation Learning, for policy fine-tuning, which periodically injects IL\nupdates after multiple RL updates and hence can benefit from the stability of\nIL and the guidance of expert data for more efficient exploration throughout\nthe entire fine-tuning process. Since IL and RL involve different optimization\nobjectives, we develop gradient separation mechanisms to prevent destructive\ninterference during \\ABBR fine-tuning, by separating possibly conflicting\ngradient updates in orthogonal subspaces. Furthermore, we conduct rigorous\nanalysis, and our findings shed light on why interleaving IL with RL stabilizes\nlearning and improves sample-efficiency. Extensive experiments on 14 robot\nmanipulation and locomotion tasks across 3 benchmarks, including\nFurnitureBench, OpenAI Gym, and Robomimic, demonstrate that \\ABBR can\nsignificantly improve sample efficiency and mitigate performance collapse\nduring online finetuning in both long- and short-horizon tasks with either\nsparse or dense rewards. IN-RIL, as a general plug-in compatible with various\nstate-of-the-art RL algorithms, can significantly improve RL fine-tuning, e.g.,\nfrom 12\\% to 88\\% with 6.3x improvement in the success rate on Robomimic\nTransport. Project page: https://github.com/ucd-dare/IN-RIL.", "published": "2025-05-15 16:01:21", "link": "http://arxiv.org/abs/2505.10442v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "PIF: Anomaly detection via preference embedding", "abstract": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space.", "published": "2025-05-15 16:00:31", "link": "http://arxiv.org/abs/2505.10441v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learned Lightweight Smartphone ISP with Unpaired Data", "abstract": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data .", "published": "2025-05-15 15:37:51", "link": "http://arxiv.org/abs/2505.10420v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding", "abstract": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores.", "published": "2025-05-15 15:28:32", "link": "http://arxiv.org/abs/2505.10405v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Evaluating Model Explanations without Ground Truth", "abstract": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth.", "published": "2025-05-15 15:22:06", "link": "http://arxiv.org/abs/2505.10399v1", "categories": ["cs.AI", "cs.LG", "I.2.6"], "primary_category": "cs.AI"}
{"title": "Inconsistency Handling in DatalogMTL", "abstract": "In this paper, we explore the issue of inconsistency handling in DatalogMTL,\nan extension of Datalog with metric temporal operators. Since facts are\nassociated with time intervals, there are different manners to restore\nconsistency when they contradict the rules, such as removing facts or modifying\ntheir time intervals. Our first contribution is the definition of relevant\nnotions of conflicts (minimal explanations for inconsistency) and repairs\n(possible ways of restoring consistency) for this setting and the study of the\nproperties of these notions and the associated inconsistency-tolerant\nsemantics. Our second contribution is a data complexity analysis of the tasks\nof generating a single conflict / repair and query entailment under\nrepair-based semantics.", "published": "2025-05-15 15:17:09", "link": "http://arxiv.org/abs/2505.10394v1", "categories": ["cs.LO", "cs.AI", "cs.DB"], "primary_category": "cs.LO"}
{"title": "Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training", "abstract": "We investigate the efficient learning of magnetic phases using artificial\nneural networks trained on synthetic data, combining computational simplicity\nwith physics-informed strategies. Focusing on the diluted Ising model, which\nlacks an exact analytical solution, we explore two complementary approaches: a\nsupervised classification using simple dense neural networks, and an\nunsupervised detection of phase transitions using convolutional autoencoders\ntrained solely on idealized spin configurations.\n  To enhance model performance, we incorporate two key forms of\nphysics-informed guidance. First, we exploit architectural biases which\npreferentially amplify features related to symmetry breaking. Second, we\ninclude training configurations that explicitly break $\\mathbb{Z}_2$ symmetry,\nreinforcing the network's ability to detect ordered phases. These mechanisms,\nacting in tandem, increase the network's sensitivity to phase structure even in\nthe absence of explicit labels. We validate the machine learning predictions\nthrough comparison with direct numerical estimates of critical temperatures and\npercolation thresholds.\n  Our results show that synthetic, structured, and computationally efficient\ntraining schemes can reveal physically meaningful phase boundaries, even in\ncomplex systems. This framework offers a low-cost and robust alternative to\nconventional methods, with potential applications in broader condensed matter\nand statistical physics contexts.", "published": "2025-05-15 15:16:16", "link": "http://arxiv.org/abs/2505.10393v1", "categories": ["cond-mat.str-el", "cs.AI"], "primary_category": "cond-mat.str-el"}
{"title": "Schreier-Coset Graph Propagation", "abstract": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications.", "published": "2025-05-15 15:14:02", "link": "http://arxiv.org/abs/2505.10392v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Multi-Agent Path Finding For Large Agents Is Intractable", "abstract": "The multi-agent path finding (MAPF) problem asks to find a set of paths on a\ngraph such that when synchronously following these paths the agents never\nencounter a conflict. In the most widespread MAPF formulation, the so-called\nClassical MAPF, the agents sizes are neglected and two types of conflicts are\nconsidered: occupying the same vertex or using the same edge at the same time\nstep. Meanwhile in numerous practical applications, e.g. in robotics, taking\ninto account the agents' sizes is vital to ensure that the MAPF solutions can\nbe safely executed. Introducing large agents yields an additional type of\nconflict arising when one agent follows an edge and its body overlaps with the\nbody of another agent that is actually not using this same edge (e.g. staying\nstill at some distinct vertex of the graph). Until now it was not clear how\nharder the problem gets when such conflicts are to be considered while\nplanning. Specifically, it was known that Classical MAPF problem on an\nundirected graph can be solved in polynomial time, however no complete\npolynomial-time algorithm was presented to solve MAPF with large agents. In\nthis paper we, for the first time, establish that the latter problem is NP-hard\nand, thus, if P!=NP no polynomial algorithm for it can, unfortunately, be\npresented. Our proof is based on the prevalent in the field technique of\nreducing the seminal 3SAT problem (which is known to be an NP-complete problem)\nto the problem at hand. In particular, for an arbitrary 3SAT formula we\nprocedurally construct a dedicated graph with specific start and goal vertices\nand show that the given 3SAT formula is satisfiable iff the corresponding path\nfinding instance has a solution.", "published": "2025-05-15 15:07:40", "link": "http://arxiv.org/abs/2505.10387v1", "categories": ["cs.MA", "cs.AI", "cs.CC"], "primary_category": "cs.MA"}
{"title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?", "abstract": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision.", "published": "2025-05-15 14:59:17", "link": "http://arxiv.org/abs/2505.10375v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks", "abstract": "The Spiking Neural Network (SNN) has drawn increasing attention for its\nenergy-efficient, event-driven processing and biological plausibility. To train\nSNNs via backpropagation, surrogate gradients are used to approximate the\nnon-differentiable spike function, but they only maintain nonzero derivatives\nwithin a narrow range of membrane potentials near the firing threshold,\nreferred to as the surrogate gradient support width gamma. We identify a major\nchallenge, termed the dilemma of gamma: a relatively large gamma leads to\noveractivation, characterized by excessive neuron firing, which in turn\nincreases energy consumption, whereas a small gamma causes vanishing gradients\nand weakens temporal dependencies. To address this, we propose a temporal\nInhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological\ninhibitory mechanisms. This model incorporates interconnected inhibitory units\nfor membrane potential and current, effectively mitigating overactivation while\npreserving gradient propagation. Theoretical analysis demonstrates ILIF\neffectiveness in overcoming the gamma dilemma, and extensive experiments on\nmultiple datasets show that ILIF improves energy efficiency by reducing firing\nrates, stabilizes training, and enhances accuracy. The code is available at\ngithub.com/kaisun1/ILIF.", "published": "2025-05-15 14:56:06", "link": "http://arxiv.org/abs/2505.10371v1", "categories": ["cs.NE", "cs.AI", "cs.LG", "q-bio.NC"], "primary_category": "cs.NE"}
{"title": "Plasticity as the Mirror of Empowerment", "abstract": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency.", "published": "2025-05-15 14:52:16", "link": "http://arxiv.org/abs/2505.10361v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "abstract": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support.", "published": "2025-05-15 14:51:22", "link": "http://arxiv.org/abs/2505.10360v1", "categories": ["cs.LG", "cs.AI", "stat.AP"], "primary_category": "cs.LG"}
{"title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "abstract": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer", "published": "2025-05-15 14:43:35", "link": "http://arxiv.org/abs/2505.10352v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "abstract": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available.", "published": "2025-05-15 14:34:36", "link": "http://arxiv.org/abs/2505.10347v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Emergence of Structure in Ensembles of Random Neural Networks", "abstract": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon.", "published": "2025-05-15 14:20:02", "link": "http://arxiv.org/abs/2505.10331v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "abstract": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components.", "published": "2025-05-15 14:19:01", "link": "http://arxiv.org/abs/2505.10330v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Comparative Study of SMT and MILP for the Nurse Rostering Problem", "abstract": "The effects of personnel scheduling on the quality of care and working\nconditions for healthcare personnel have been thoroughly documented. However,\nthe ever-present demand and large variation of constraints make healthcare\nscheduling particularly challenging. This problem has been studied for decades,\nwith limited research aimed at applying Satisfiability Modulo Theories (SMT).\nSMT has gained momentum within the formal verification community in the last\ndecades, leading to the advancement of SMT solvers that have been shown to\noutperform standard mathematical programming techniques.\n  In this work, we propose generic constraint formulations that can model a\nwide range of real-world scheduling constraints. Then, the generic constraints\nare formulated as SMT and MILP problems and used to compare the respective\nstate-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired\nrostering problems. Experimental results show how each solver excels for\ncertain types of problems; the MILP solver generally performs better when the\nproblem is highly constrained or infeasible, while the SMT solver performs\nbetter otherwise. On real-world inspired problems containing a more varied set\nof shifts and personnel, the SMT solver excels. Additionally, it was noted\nduring experimentation that the SMT solver was more sensitive to the way the\ngeneric constraints were formulated, requiring careful consideration and\nexperimentation to achieve better performance. We conclude that SMT-based\nmethods present a promising avenue for future research within the domain of\npersonnel scheduling.", "published": "2025-05-15 14:12:39", "link": "http://arxiv.org/abs/2505.10328v1", "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "abstract": "A recent area of increasing research is the use of Large Language Models\n(LLMs) in penetration testing, which promises to reduce costs and thus allow\nfor higher frequency. We conduct a review of related work, identifying best\npractices and common evaluation issues. We then present AutoPentest, an\napplication for performing black-box penetration tests with a high degree of\nautonomy. AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent\nframework LangChain. It can perform complex multi-step tasks, augmented by\nexternal tools and knowledge bases. We conduct a study on three\ncapture-the-flag style Hack The Box (HTB) machines, comparing our\nimplementation AutoPentest with the baseline approach of manually using the\nChatGPT-4o user interface. Both approaches are able to complete 15-25 % of the\nsubtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.\nWe measure a total cost of \\$96.20 US when using AutoPentest across all\nexperiments, while a one-month subscription to ChatGPT Plus costs \\$20. The\nresults show that further implementation efforts and the use of more powerful\nLLMs released in the future are likely to make this a viable part of\nvulnerability management.", "published": "2025-05-15 14:06:00", "link": "http://arxiv.org/abs/2505.10321v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Private Transformer Inference in MLaaS: A Survey", "abstract": "Transformer models have revolutionized AI, powering applications like content\ngeneration and sentiment analysis. However, their deployment in Machine\nLearning as a Service (MLaaS) raises significant privacy concerns, primarily\ndue to the centralized processing of sensitive user data. Private Transformer\nInference (PTI) offers a solution by utilizing cryptographic techniques such as\nsecure multi-party computation and homomorphic encryption, enabling inference\nwhile preserving both user data and model privacy. This paper reviews recent\nPTI advancements, highlighting state-of-the-art solutions and challenges. We\nalso introduce a structured taxonomy and evaluation framework for PTI, focusing\non balancing resource efficiency with privacy and bridging the gap between\nhigh-performance inference and data privacy.", "published": "2025-05-15 14:00:19", "link": "http://arxiv.org/abs/2505.10315v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments", "abstract": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a novel\nmethod for evaluating common sense in artificial intelligence (AI),\nspecifically in large language models (LLMs), that incorporates empirically\nobserved heterogeneity among humans by measuring the correspondence between a\nmodel's judgment and that of a human population. We first find that, when\ntreated as independent survey respondents, most LLMs remain below the human\nmedian in their individual commonsense competence. Second, when used as\nsimulators of a hypothetical population, LLMs correlate with real humans only\nmodestly in the extent to which they agree on the same set of statements. In\nboth cases, smaller, open-weight models are surprisingly more competitive than\nlarger, proprietary frontier models. Our evaluation framework, which ties\ncommonsense intelligence to its cultural basis, contributes to the growing call\nfor adapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge.", "published": "2025-05-15 13:55:27", "link": "http://arxiv.org/abs/2505.10309v1", "categories": ["cs.AI", "cs.HC", "cs.SI"], "primary_category": "cs.AI"}
{"title": "AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages", "abstract": "Responsible AI (RAI) efforts increasingly emphasize the importance of\naddressing potential harms early in the AI development lifecycle through\nsocial-technical lenses. However, in cross-functional industry teams, this work\nis often stalled by a persistent knowledge handoff challenge: the difficulty of\ntransferring high-level, early-stage technical design rationales from technical\nexperts to non-technical or user-facing roles for ethical evaluation and harm\nidentification. Through literature review and a co-design study with 8\npractitioners, we unpack how this challenge manifests -- technical design\nchoices are rarely handed off in ways that support meaningful engagement by\nnon-technical roles; collaborative workflows lack shared, visual structures to\nsupport mutual understanding; and non-technical practitioners are left without\nscaffolds for systematic harm evaluation. Existing tools like JIRA or Google\nDocs, while useful for product tracking, are ill-suited for supporting joint\nharm identification across roles, often requiring significant extra effort to\nalign understanding. To address this, we developed AI LEGO, a web-based\nprototype that supports cross-functional AI practitioners in effectively\nfacilitating knowledge handoff and identifying harmful design choices in the\nearly design stages. Technical roles use interactive blocks to draft\ndevelopment plans, while non-technical roles engage with those blocks through\nstage-specific checklists and LLM-driven persona simulations to surface\npotential harms. In a study with 18 cross-functional practitioners, AI LEGO\nincreased the volume and likelihood of harms identified compared to baseline\nworksheets. Participants found that its modular structure and persona prompts\nmade harm identification more accessible, fostering clearer and more\ncollaborative RAI practices in early design.", "published": "2025-05-15 13:49:02", "link": "http://arxiv.org/abs/2505.10300v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "abstract": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments.", "published": "2025-05-15 13:44:32", "link": "http://arxiv.org/abs/2505.10297v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction", "abstract": "LLM-based multi-agent has gained significant attention for their potential in\nsimulation and enhancing performance. However, existing works are limited to\npure simulations or are constrained by predefined workflows, restricting their\napplicability and effectiveness. In this paper, we introduce the Multi-Agent\nScaling Simulation (MASS) for portfolio construction. MASS achieves stable and\ncontinuous excess returns by progressively increasing the number of agents for\nlarge-scale simulations to gain a superior understanding of the market and\noptimizing agent distribution end-to-end through a reverse optimization\nprocess, rather than relying on a fixed workflow. We demonstrate its\nsuperiority through performance experiments, ablation studies, backtesting\nexperiments, experiments on updated data and stock pools, scaling experiments,\nparameter sensitivity experiments, and visualization experiments, conducted in\ncomparison with 6 state-of-the-art baselines on 3 challenging A-share stock\npools. We expect the paradigm established by MASS to expand to other tasks with\nsimilar characteristics. The implementation of MASS has been open-sourced at\nhttps://github.com/gta0804/MASS.", "published": "2025-05-15 13:27:18", "link": "http://arxiv.org/abs/2505.10278v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons", "abstract": "Vehicle platooning, with vehicles traveling in close formation coordinated\nthrough Vehicle-to-Everything (V2X) communications, offers significant benefits\nin fuel efficiency and road utilization. However, it is vulnerable to\nsophisticated falsification attacks by authenticated insiders that can\ndestabilize the formation and potentially cause catastrophic collisions. This\npaper addresses this challenge: misbehavior detection in vehicle platooning\nsystems. We present AttentionGuard, a transformer-based framework for\nmisbehavior detection that leverages the self-attention mechanism to identify\nanomalous patterns in mobility data. Our proposal employs a multi-head\ntransformer-encoder to process sequential kinematic information, enabling\neffective differentiation between normal mobility patterns and falsification\nattacks across diverse platooning scenarios, including steady-state\n(no-maneuver) operation, join, and exit maneuvers. Our evaluation uses an\nextensive simulation dataset featuring various attack vectors (constant,\ngradual, and combined falsifications) and operational parameters (controller\ntypes, vehicle speeds, and attacker positions). Experimental results\ndemonstrate that AttentionGuard achieves up to 0.95 F1-score in attack\ndetection, with robust performance maintained during complex maneuvers.\nNotably, our system performs effectively with minimal latency (100ms decision\nintervals), making it suitable for real-time transportation safety\napplications. Comparative analysis reveals superior detection capabilities and\nestablishes the transformer-encoder as a promising approach for securing\nCooperative Intelligent Transport Systems (C-ITS) against sophisticated insider\nthreats.", "published": "2025-05-15 13:24:09", "link": "http://arxiv.org/abs/2505.10273v1", "categories": ["cs.CR", "cs.AI", "cs.NI"], "primary_category": "cs.CR"}
{"title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "abstract": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art.", "published": "2025-05-15 13:16:32", "link": "http://arxiv.org/abs/2505.10264v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M", "abstract": "Large Language Models (LLMs) have become increasingly central to\nrecommendation scenarios due to their remarkable natural language understanding\nand generation capabilities. Although significant research has explored the use\nof LLMs for various recommendation tasks, little effort has been dedicated to\nverifying whether they have memorized public recommendation dataset as part of\ntheir training data. This is undesirable because memorization reduces the\ngeneralizability of research findings, as benchmarking on memorized datasets\ndoes not guarantee generalization to unseen datasets. Furthermore, memorization\ncan amplify biases, for example, some popular items may be recommended more\nfrequently than others.\n  In this work, we investigate whether LLMs have memorized public\nrecommendation datasets. Specifically, we examine two model families (GPT and\nLlama) across multiple sizes, focusing on one of the most widely used dataset\nin recommender systems: MovieLens-1M. First, we define dataset memorization as\nthe extent to which item attributes, user profiles, and user-item interactions\ncan be retrieved by prompting the LLMs. Second, we analyze the impact of\nmemorization on recommendation performance. Lastly, we examine whether\nmemorization varies across model families and model sizes. Our results reveal\nthat all models exhibit some degree of memorization of MovieLens-1M, and that\nrecommendation performance is related to the extent of memorization. We have\nmade all the code publicly available at:\nhttps://github.com/sisinflab/LLM-MemoryInspector", "published": "2025-05-15 12:16:36", "link": "http://arxiv.org/abs/2505.10212v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "A Fine-Grained Complexity View on Propositional Abduction -- Algorithms and Lower Bounds", "abstract": "The Boolean satisfiability problem (SAT) is a well-known example of monotonic\nreasoning, of intense practical interest due to fast solvers, complemented by\nrigorous fine-grained complexity results. However, for non-monotonic reasoning,\ne.g., abductive reasoning, comparably little is known outside classic\ncomplexity theory. In this paper we take a first step of bridging the gap\nbetween monotonic and non-monotonic reasoning by analyzing the complexity of\nintractable abduction problems under the seemingly overlooked but natural\nparameter n: the number of variables in the knowledge base. We obtain several\npositive results for $\\Sigma^P_2$- as well as NP- and coNP-complete fragments,\nwhich implies the first example of beating exhaustive search for a\n$\\Sigma^P_2$-complete problem (to the best of our knowledge). We complement\nthis with lower bounds and for many fragments rule out improvements under the\n(strong) exponential-time hypothesis.", "published": "2025-05-15 11:56:19", "link": "http://arxiv.org/abs/2505.10201v1", "categories": ["cs.CC", "cs.AI", "F.2.2"], "primary_category": "cs.CC"}
{"title": "Advancing Community Detection with Graph Convolutional Neural Networks: Bridging Topological and Attributive Cohesion", "abstract": "Community detection, a vital technology for real-world applications, uncovers\ncohesive node groups (communities) by leveraging both topological and attribute\nsimilarities in social networks. However, existing Graph Convolutional Networks\n(GCNs) trained to maximize modularity often converge to suboptimal solutions.\nAdditionally, directly using human-labeled communities for training can\nundermine topological cohesiveness by grouping disconnected nodes based solely\non node attributes. We address these issues by proposing a novel Topological\nand Attributive Similarity-based Community detection (TAS-Com) method. TAS-Com\nintroduces a novel loss function that exploits the highly effective and\nscalable Leiden algorithm to detect community structures with global optimal\nmodularity. Leiden is further utilized to refine human-labeled communities to\nensure connectivity within each community, enabling TAS-Com to detect community\nstructures with desirable trade-offs between modularity and compliance with\nhuman labels. Experimental results on multiple benchmark networks confirm that\nTAS-Com can significantly outperform several state-of-the-art algorithms.", "published": "2025-05-15 11:53:33", "link": "http://arxiv.org/abs/2505.10197v1", "categories": ["cs.SI", "cs.AI"], "primary_category": "cs.SI"}
{"title": "LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting", "abstract": "Mesoscale eddies dominate the spatiotemporal multiscale variability of the\nocean, and their impact on the energy cascade of the global ocean cannot be\nignored. Eddy-resolving ocean forecasting is providing more reliable protection\nfor fisheries and navigational safety, but also presents significant scientific\nchallenges and high computational costs for traditional numerical models.\nArtificial intelligence (AI)-based weather and ocean forecasting systems are\nbecoming powerful tools that balance forecast performance with computational\nefficiency. However, the complex multiscale features in the ocean dynamical\nsystem make AI models still face many challenges in mesoscale eddy forecasting\n(especially regional modelling). Here, we develop LanTu, a regional\neddy-resolving ocean forecasting system based on dynamics-enhanced deep\nlearning. We incorporate cross-scale interactions into LanTu and construct\nmultiscale physical constraint for optimising LanTu guided by knowledge of eddy\ndynamics in order to improve the forecasting skill of LanTu for mesoscale\nevolution. The results show that LanTu outperforms the existing advanced\noperational numerical ocean forecasting system (NOFS) and AI-based ocean\nforecasting system (AI-OFS) in temperature, salinity, sea level anomaly and\ncurrent prediction, with a lead time of more than 10 days. Our study highlights\nthat dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for\neddy-resolving ocean forecasting.", "published": "2025-05-15 11:47:54", "link": "http://arxiv.org/abs/2505.10191v1", "categories": ["physics.ao-ph", "cs.AI", "cs.LG", "nlin.CD"], "primary_category": "physics.ao-ph"}
{"title": "A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support", "abstract": "As the field of healthcare increasingly adopts artificial intelligence, it\nbecomes important to understand which types of explanations increase\ntransparency and empower users to develop confidence and trust in the\npredictions made by machine learning (ML) systems. In shared decision-making\nscenarios where doctors cooperate with ML systems to reach an appropriate\ndecision, establishing mutual trust is crucial. In this paper, we explore\ndifferent approaches to generating explanations in eXplainable AI (XAI) and\nmake their underlying arguments explicit so that they can be evaluated by\nmedical experts. In particular, we present the findings of a user study\nconducted with physicians to investigate their perceptions of various types of\nAI-generated explanations in the context of diagnostic decision support. The\nstudy aims to identify the most effective and useful explanations that enhance\nthe diagnostic process. In the study, medical doctors filled out a survey to\nassess different types of explanations. Further, an interview was carried out\npost-survey to gain qualitative insights on the requirements of explanations\nincorporated in diagnostic decision support. Overall, the insights gained from\nthis study contribute to understanding the types of explanations that are most\neffective.", "published": "2025-05-15 11:42:24", "link": "http://arxiv.org/abs/2505.10188v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems", "abstract": "Embodied Artificial Intelligence (AI) systems, such as autonomous robots and\nintelligent vehicles, are increasingly reliant on diverse heterogeneous\naccelerators (e.g., GPGPUs, NPUs, FPGAs) to meet stringent real-time processing\nand energy-efficiency demands. However, the proliferation of vendor-specific\nproprietary communication libraries creates significant interoperability\nbarriers, hindering seamless collaboration between different accelerator types\nand leading to suboptimal resource utilization and performance bottlenecks in\ndistributed AI workloads. This paper introduces KAITIAN, a novel distributed\ncommunication framework designed to bridge this gap. KAITIAN provides a unified\nabstraction layer that intelligently integrates vendor-optimized communication\nlibraries for intra-group efficiency with general-purpose communication\nprotocols for inter-group interoperability. Crucially, it incorporates a\nload-adaptive scheduling mechanism that dynamically balances computational\ntasks across heterogeneous devices based on their real-time performance\ncharacteristics. Implemented as an extension to PyTorch and rigorously\nevaluated on a testbed featuring NVIDIA GPUs and Cambricon MLUs, KAITIAN\ndemonstrates significant improvements in resource utilization and scalability\nfor distributed training tasks. Experimental results show that KAITIAN can\naccelerate training time by up to 42% compared to baseline homogeneous systems,\nwhile incurring minimal communication overhead (2.8--4.3%) and maintaining\nmodel accuracy. KAITIAN paves the way for more flexible and powerful\nheterogeneous computing in complex embodied AI applications.", "published": "2025-05-15 11:29:43", "link": "http://arxiv.org/abs/2505.10183v1", "categories": ["cs.DC", "cs.AI"], "primary_category": "cs.DC"}
{"title": "Does Scaling Law Apply in Time Series Forecasting?", "abstract": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling.", "published": "2025-05-15 11:04:39", "link": "http://arxiv.org/abs/2505.10172v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Modeling Saliency Dataset Bias", "abstract": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes.", "published": "2025-05-15 10:55:47", "link": "http://arxiv.org/abs/2505.10169v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "abstract": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology.", "published": "2025-05-15 10:51:34", "link": "http://arxiv.org/abs/2505.10167v1", "categories": ["cs.LG", "cs.AI", "quant-ph"], "primary_category": "cs.LG"}
{"title": "Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks", "abstract": "Accurate and robust localization is a critical enabler for emerging 5G and 6G\napplications, including autonomous driving, extended reality (XR), and smart\nmanufacturing. While data-driven approaches have shown promise, most existing\nmodels require large amounts of labeled data and struggle to generalize across\ndeployment scenarios and wireless configurations. To address these limitations,\nwe propose a foundation-model-based solution tailored for wireless\nlocalization. We first analyze how different self-supervised learning (SSL)\ntasks acquire general-purpose and task-specific semantic features based on\ninformation bottleneck (IB) theory. Building on this foundation, we design a\npretraining methodology for the proposed Large Wireless Localization Model\n(LWLM). Specifically, we propose an SSL framework that jointly optimizes three\ncomplementary objectives: (i) spatial-frequency masked channel modeling\n(SF-MCM), (ii) domain-transformation invariance (DTI), and (iii)\nposition-invariant contrastive learning (PICL). These objectives jointly\ncapture the underlying semantics of wireless channel from multiple\nperspectives. We further design lightweight decoders for key downstream tasks,\nincluding time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation,\nsingle base station (BS) localization, and multiple BS localization.\nComprehensive experimental results confirm that LWLM consistently surpasses\nboth model-based and supervised learning baselines across all localization\ntasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer\nmodels without pretraining, and exhibits strong generalization under\nlabel-limited fine-tuning and unseen BS configurations, confirming its\npotential as a foundation model for wireless localization.", "published": "2025-05-15 10:04:44", "link": "http://arxiv.org/abs/2505.10134v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "abstract": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance.", "published": "2025-05-15 09:53:14", "link": "http://arxiv.org/abs/2505.10128v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "All You Need Is Synthetic Task Augmentation", "abstract": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining.", "published": "2025-05-15 09:46:27", "link": "http://arxiv.org/abs/2505.10120v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation", "abstract": "We present EmbodiedMAE, a unified 3D multi-modal representation for robot\nmanipulation. Current approaches suffer from significant domain gaps between\ntraining datasets and robot manipulation tasks, while also lacking model\narchitectures that can effectively incorporate 3D information. To overcome\nthese limitations, we enhance the DROID dataset with high-quality depth maps\nand point clouds, constructing DROID-3D as a valuable supplement for 3D\nembodied vision research. Then we develop EmbodiedMAE, a multi-modal masked\nautoencoder that simultaneously learns representations across RGB, depth, and\npoint cloud modalities through stochastic masking and cross-modal fusion.\nTrained on DROID-3D, EmbodiedMAE consistently outperforms state-of-the-art\nvision foundation models (VFMs) in both training efficiency and final\nperformance across 70 simulation tasks and 20 real-world robot manipulation\ntasks on two robot platforms. The model exhibits strong scaling behavior with\nsize and promotes effective policy learning from 3D inputs. Experimental\nresults establish EmbodiedMAE as a reliable unified 3D multi-modal VFM for\nembodied AI systems, particularly in precise tabletop manipulation settings\nwhere spatial perception is critical.", "published": "2025-05-15 09:12:17", "link": "http://arxiv.org/abs/2505.10105v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "LAV: Audio-Driven Dynamic Visual Generation with Neural Compression and StyleGAN2", "abstract": "This paper introduces LAV (Latent Audio-Visual), a system that integrates\nEnCodec's neural audio compression with StyleGAN2's generative capabilities to\nproduce visually dynamic outputs driven by pre-recorded audio. Unlike previous\nworks that rely on explicit feature mappings, LAV uses EnCodec embeddings as\nlatent representations, directly transformed into StyleGAN2's style latent\nspace via randomly initialized linear mapping. This approach preserves semantic\nrichness in the transformation, enabling nuanced and semantically coherent\naudio-visual translations. The framework demonstrates the potential of using\npretrained audio compression models for artistic and computational\napplications.", "published": "2025-05-15 09:04:12", "link": "http://arxiv.org/abs/2505.10101v1", "categories": ["cs.SD", "cs.AI", "cs.GR", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs", "abstract": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience.", "published": "2025-05-15 08:24:47", "link": "http://arxiv.org/abs/2505.10074v1", "categories": ["cs.AI", "cs.CY"], "primary_category": "cs.AI"}
{"title": "Multi-Robot Task Allocation for Homogeneous Tasks with Collision Avoidance via Spatial Clustering", "abstract": "In this paper, a novel framework is presented that achieves a combined\nsolution based on Multi-Robot Task Allocation (MRTA) and collision avoidance\nwith respect to homogeneous measurement tasks taking place in industrial\nenvironments. The spatial clustering we propose offers to simultaneously solve\nthe task allocation problem and deal with collision risks by cutting the\nworkspace into distinguishable operational zones for each robot. To divide task\nsites and to schedule robot routes within corresponding clusters, we use\nK-means clustering and the 2-Opt algorithm. The presented framework shows\nsatisfactory performance, where up to 93\\% time reduction (1.24s against\n17.62s) with a solution quality improvement of up to 7\\% compared to the best\nperforming method is demonstrated. Our method also completely eliminates\ncollision points that persist in comparative methods in a most significant\nsense. Theoretical analysis agrees with the claim that spatial partitioning\nunifies the apparently disjoint tasks allocation and collision avoidance\nproblems under conditions of many identical tasks to be distributed over sparse\ngeographical areas. Ultimately, the findings in this work are of substantial\nimportance for real world applications where both computational efficiency and\noperation free from collisions is of paramount importance.", "published": "2025-05-15 08:20:57", "link": "http://arxiv.org/abs/2505.10073v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "abstract": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR.", "published": "2025-05-15 07:58:38", "link": "http://arxiv.org/abs/2505.10055v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "abstract": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection.", "published": "2025-05-15 07:53:02", "link": "http://arxiv.org/abs/2505.10050v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights", "abstract": "Charts are crucial for data analysis and decision-making.Text-to-chart\nretrieval systems have become increasingly important for Business Intelligence\n(BI), where users need to find relevant charts that match their analytical\nneeds. These needs can be categorized into precise queries that are\nwell-specified and fuzzy queries that are more exploratory -- both require\nunderstanding the semantics and context of the charts. However, existing\ntext-to-chart retrieval solutions often fail to capture the semantic content\nand contextual information of charts, primarily due to the lack of\ncomprehensive metadata (or semantic insights). To address this limitation, we\npropose a training data development pipeline that automatically synthesizes\nhierarchical semantic insights for charts, covering visual patterns\n(visual-oriented), statistical properties (statistics-oriented), and practical\napplications (task-oriented), which produces 207,498 semantic insights for\n69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to\nlearn better representations of charts for text-to-chart retrieval. Our method\nleverages rich semantic insights during the training phase to develop a model\nthat understands both visual and semantic aspects of charts.To evaluate\ntext-to-chart retrieval performance, we curate the first benchmark, CRBench,\nfor this task with 21,862 charts and 326 text queries from real-world BI\napplications, with ground-truth labels verified by the crowd\nworkers.Experiments show that ChartFinder significantly outperforms existing\nmethods in text-to-chart retrieval tasks across various settings. For precise\nqueries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than\nstate-of-the-art models. In fuzzy query tasks, our method also demonstrates\nconsistent improvements, with an average increase of 5% across nearly all\nmetrics.", "published": "2025-05-15 07:41:14", "link": "http://arxiv.org/abs/2505.10043v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "abstract": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers.", "published": "2025-05-15 07:33:41", "link": "http://arxiv.org/abs/2505.10037v1", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "primary_category": "cs.LG"}
{"title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection", "abstract": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io.", "published": "2025-05-15 07:29:33", "link": "http://arxiv.org/abs/2505.10034v1", "categories": ["cs.AI", "68T07", "I.2.0; H.5.1"], "primary_category": "cs.AI"}
{"title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "abstract": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes.", "published": "2025-05-15 07:17:03", "link": "http://arxiv.org/abs/2505.10027v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "abstract": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection.", "published": "2025-05-15 06:58:45", "link": "http://arxiv.org/abs/2505.10016v1", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "primary_category": "cs.CV"}
{"title": "Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering", "abstract": "Recent advances in artificial intelligence (AI) and quantum computing are\naccelerating automation in scientific and engineering processes, fundamentally\nreshaping research methodologies. This perspective highlights parallels between\nscientific automation and established Computer-Aided Engineering (CAE)\npractices, introducing Quantum CAE as a framework that leverages quantum\nalgorithms for simulation, optimization, and machine learning within\nengineering design. Practical implementations of Quantum CAE are illustrated\nthrough case studies for combinatorial optimization problems. Further\ndiscussions include advancements toward higher automation levels, highlighting\nthe critical role of specialized AI agents proficient in quantum algorithm\ndesign. The integration of quantum computing with AI raises significant\nquestions about the collaborative dynamics among human scientists and\nengineers, AI systems, and quantum computational resources, underscoring a\ntransformative future for automated discovery and innovation.", "published": "2025-05-15 06:53:30", "link": "http://arxiv.org/abs/2505.10012v1", "categories": ["quant-ph", "cs.AI"], "primary_category": "quant-ph"}
{"title": "AI Greenferencing: Routing AI Inferencing to Green Modular Data Centers with Heron", "abstract": "AI power demand is growing unprecedentedly thanks to the high power density\nof AI compute and the emerging inferencing workload. On the supply side,\nabundant wind power is waiting for grid access in interconnection queues. In\nthis light, this paper argues bringing AI workload to modular compute clusters\nco-located in wind farms. Our deployment right-sizing strategy makes it\neconomically viable to deploy more than 6 million high-end GPUs today that\ncould consume cheap, green power at its source. We built Heron, a cross-site\nsoftware router, that could efficiently leverage the complementarity of power\ngeneration across wind farms by routing AI inferencing workload around power\ndrops. Using 1-week ofcoding and conversation production traces from Azure and\n(real) variable wind power traces, we show how Heron improves aggregate goodput\nof AI compute by up to 80% compared to the state-of-the-art.", "published": "2025-05-15 06:03:47", "link": "http://arxiv.org/abs/2505.09989v1", "categories": ["cs.DC", "cs.AI", "cs.NI"], "primary_category": "cs.DC"}
{"title": "Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data", "abstract": "The integration of large language models (LLMs) into cyber security\napplications presents significant opportunities, such as enhancing threat\nanalysis and malware detection, but can also introduce critical risks and\nsafety concerns, including personal data leakage and automated generation of\nnew malware. We present a systematic evaluation of safety risks in fine-tuned\nLLMs for cyber security applications. Using the OWASP Top 10 for LLM\nApplications framework, we assessed seven open-source LLMs: Phi 3 Mini 3.8B,\nMistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B.\nOur evaluation shows that fine-tuning reduces safety resilience across all\ntested LLMs (e.g., the safety score of Llama 3.1 8B against prompt injection\ndrops from 0.95 to 0.15). We propose and evaluate a safety alignment approach\nthat carefully rewords instruction-response pairs to include explicit safety\nprecautions and ethical considerations. This approach demonstrates that it is\npossible to maintain or even improve model safety while preserving technical\nutility, offering a practical path forward for developing safer fine-tuning\nmethodologies. This work offers a systematic evaluation for safety risks in\nLLMs, enabling safer adoption of generative AI in sensitive domains, and\ncontributing towards the development of secure, trustworthy, and ethically\naligned LLMs.", "published": "2025-05-15 05:22:53", "link": "http://arxiv.org/abs/2505.09974v1", "categories": ["cs.CR", "cs.AI"], "primary_category": "cs.CR"}
{"title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "abstract": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has\nbecome the foundation of modern agentic systems. Recent LLMs, such as\nDeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through\nthe generation of ample intermediate tokens, which help build a strong premise\nbefore producing the final output tokens. In this paper, we introduce Pre-Act,\na novel approach that enhances the agent's performance by creating a multi-step\nexecution plan along with the detailed reasoning for the given user input. This\nplan incrementally incorporates previous steps and tool outputs, refining\nitself after each step execution until the final response is obtained. Our\napproach is applicable to both conversational and non-conversational agents. To\nmeasure the performance of task-oriented agents comprehensively, we propose a\ntwo-level evaluation framework: (1) turn level and (2) end-to-end. Our\nturn-level evaluation, averaged across five models, shows that our approach,\nPre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While\nthis approach is effective for larger models, smaller models crucial for\npractical applications, where latency and cost are key constraints, often\nstruggle with complex reasoning tasks required for agentic systems. To address\nthis limitation, we fine-tune relatively small models such as Llama 3.1 (8B &\n70B) using the proposed Pre-Act approach. Our experiments show that the\nfine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action\naccuracy (turn-level) and a 28% improvement in goal completion rate\n(end-to-end) on the Almita (out-of-domain) dataset.", "published": "2025-05-15 05:17:47", "link": "http://arxiv.org/abs/2505.09970v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "abstract": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics.", "published": "2025-05-15 05:13:38", "link": "http://arxiv.org/abs/2505.09969v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "abstract": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices.", "published": "2025-05-15 04:27:48", "link": "http://arxiv.org/abs/2505.09955v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "abstract": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach.", "published": "2025-05-15 04:22:35", "link": "http://arxiv.org/abs/2505.09952v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "abstract": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users.", "published": "2025-05-15 03:40:29", "link": "http://arxiv.org/abs/2505.09935v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Demystifying AI Agents: The Final Generation of Intelligence", "abstract": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence.", "published": "2025-05-15 03:35:12", "link": "http://arxiv.org/abs/2505.09932v1", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "primary_category": "cs.AI"}
{"title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "abstract": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP.", "published": "2025-05-15 03:24:28", "link": "http://arxiv.org/abs/2505.09926v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "abstract": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods.", "published": "2025-05-15 03:22:03", "link": "http://arxiv.org/abs/2505.09925v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "\"There Is No Such Thing as a Dumb Question,\" But There Are Good Ones", "abstract": "Questioning has become increasingly crucial for both humans and artificial\nintelligence, yet there remains limited research comprehensively assessing\nquestion quality. In response, this study defines good questions and presents a\nsystematic evaluation framework. We propose two key evaluation dimensions:\nappropriateness (sociolinguistic competence in context) and effectiveness\n(strategic competence in goal achievement). Based on these foundational\ndimensions, a rubric-based scoring system was developed. By incorporating\ndynamic contextual variables, our evaluation framework achieves structure and\nflexibility through semi-adaptive criteria. The methodology was validated using\nthe CAUS and SQUARE datasets, demonstrating the ability of the framework to\naccess both well-formed and problematic questions while adapting to varied\ncontexts. As we establish a flexible and comprehensive framework for question\nevaluation, this study takes a significant step toward integrating questioning\nbehavior with structured analytical methods grounded in the intrinsic nature of\nquestioning.", "published": "2025-05-15 03:12:28", "link": "http://arxiv.org/abs/2505.09923v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Offline Reinforcement Learning for Microgrid Voltage Regulation", "abstract": "This paper presents a study on using different offline reinforcement learning\nalgorithms for microgrid voltage regulation with solar power penetration. When\nenvironment interaction is unviable due to technical or safety reasons, the\nproposed approach can still obtain an applicable model through offline-style\ntraining on a previously collected dataset, lowering the negative impact of\nlacking online environment interactions. Experiment results on the IEEE 33-bus\nsystem demonstrate the feasibility and effectiveness of the proposed approach\non different offline datasets, including the one with merely low-quality\nexperience.", "published": "2025-05-15 03:10:18", "link": "http://arxiv.org/abs/2505.09920v1", "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "cs.AI"}
{"title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "abstract": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization.", "published": "2025-05-15 02:26:22", "link": "http://arxiv.org/abs/2505.09907v1", "categories": ["cs.LG", "cs.AI", "cs.CE"], "primary_category": "cs.LG"}
{"title": "Which Demographic Features Are Relevant for Individual Fairness Evaluation of U.S. Recidivism Risk Assessment Tools?", "abstract": "Despite its U.S. constitutional foundation, the technical ``individual\nfairness'' criterion has not been operationalized in state or federal\nstatutes/regulations. We conduct a human subjects experiment to address this\ngap, evaluating which demographic features are relevant for individual fairness\nevaluation of recidivism risk assessment (RRA) tools. Our analyses conclude\nthat the individual similarity function should consider age and sex, but it\nshould ignore race.", "published": "2025-05-15 00:07:07", "link": "http://arxiv.org/abs/2505.09868v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "cs.CY"}
{"title": "3D-Fixup: Advancing Photo Editing with 3D Priors", "abstract": "Despite significant advances in modeling image priors via diffusion models,\n3D-aware image editing remains challenging, in part because the object is only\nspecified via a single image. To tackle this challenge, we propose 3D-Fixup, a\nnew framework for editing 2D images guided by learned 3D priors. The framework\nsupports difficult editing situations such as object translation and 3D\nrotation. To achieve this, we leverage a training-based approach that harnesses\nthe generative power of diffusion models. As video data naturally encodes\nreal-world physical dynamics, we turn to video data for generating training\ndata pairs, i.e., a source and a target frame. Rather than relying solely on a\nsingle trained model to infer transformations between source and target frames,\nwe incorporate 3D guidance from an Image-to-3D model, which bridges this\nchallenging task by explicitly projecting 2D information into 3D space. We\ndesign a data generation pipeline to ensure high-quality 3D guidance throughout\ntraining. Results show that by integrating these 3D priors, 3D-Fixup\neffectively supports complex, identity coherent 3D-aware edits, achieving\nhigh-quality results and advancing the application of diffusion models in\nrealistic image manipulation. The code is provided at\nhttps://3dfixup.github.io/", "published": "2025-05-15 17:59:51", "link": "http://arxiv.org/abs/2505.10566v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Depth Anything with Any Prior", "abstract": "This work presents Prior Depth Anything, a framework that combines incomplete\nbut precise metric information in depth measurement with relative but complete\ngeometric structures in depth prediction, generating accurate, dense, and\ndetailed metric depth maps for any scene. To this end, we design a\ncoarse-to-fine pipeline to progressively integrate the two complementary depth\nsources. First, we introduce pixel-level metric alignment and distance-aware\nweighting to pre-fill diverse metric priors by explicitly using depth\nprediction. It effectively narrows the domain gap between prior patterns,\nenhancing generalization across varying scenarios. Second, we develop a\nconditioned monocular depth estimation (MDE) model to refine the inherent noise\nof depth priors. By conditioning on the normalized pre-filled prior and\nprediction, the model further implicitly merges the two complementary depth\nsources. Our model showcases impressive zero-shot generalization across depth\ncompletion, super-resolution, and inpainting over 7 real-world datasets,\nmatching or even surpassing previous task-specific methods. More importantly,\nit performs well on challenging, unseen mixed priors and enables test-time\nimprovements by switching prediction models, providing a flexible\naccuracy-efficiency trade-off while evolving with advancements in MDE models.", "published": "2025-05-15 17:59:50", "link": "http://arxiv.org/abs/2505.10565v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "End-to-End Vision Tokenizer Tuning", "abstract": "Existing vision tokenization isolates the optimization of vision tokenizers\nfrom downstream training, implicitly assuming the visual tokens can generalize\nwell across various tasks, e.g., image generation and visual question\nanswering. The vision tokenizer optimized for low-level reconstruction is\nagnostic to downstream tasks requiring varied representations and semantics.\nThis decoupled paradigm introduces a critical misalignment: The loss of the\nvision tokenization can be the representation bottleneck for target tasks. For\nexample, errors in tokenizing text in a given image lead to poor results when\nrecognizing or generating them. To address this, we propose ETT, an end-to-end\nvision tokenizer tuning approach that enables joint optimization between vision\ntokenization and target autoregressive tasks. Unlike prior autoregressive\nmodels that use only discrete indices from a frozen vision tokenizer, ETT\nleverages the visual embeddings of the tokenizer codebook, and optimizes the\nvision tokenizers end-to-end with both reconstruction and caption objectives.\nETT can be seamlessly integrated into existing training pipelines with minimal\narchitecture modifications. Our ETT is simple to implement and integrate,\nwithout the need to adjust the original codebooks or architectures of the\nemployed large language models. Extensive experiments demonstrate that our\nproposed end-to-end vision tokenizer tuning unlocks significant performance\ngains, i.e., 2-6% for multimodal understanding and visual generation tasks\ncompared to frozen tokenizer baselines, while preserving the original\nreconstruction capability. We hope this very simple and strong method can\nempower multimodal foundation models besides image generation and\nunderstanding.", "published": "2025-05-15 17:59:39", "link": "http://arxiv.org/abs/2505.10562v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Style Customization of Text-to-Vector Generation with Image Diffusion Priors", "abstract": "Scalable Vector Graphics (SVGs) are highly favored by designers due to their\nresolution independence and well-organized layer structure. Although existing\ntext-to-vector (T2V) generation methods can create SVGs from text prompts, they\noften overlook an important need in practical applications: style\ncustomization, which is vital for producing a collection of vector graphics\nwith consistent visual appearance and coherent aesthetics. Extending existing\nT2V methods for style customization poses certain challenges.\nOptimization-based T2V models can utilize the priors of text-to-image (T2I)\nmodels for customization, but struggle with maintaining structural regularity.\nOn the other hand, feed-forward T2V models can ensure structural regularity,\nyet they encounter difficulties in disentangling content and style due to\nlimited SVG training data.\n  To address these challenges, we propose a novel two-stage style customization\npipeline for SVG generation, making use of the advantages of both feed-forward\nT2V models and T2I image priors. In the first stage, we train a T2V diffusion\nmodel with a path-level representation to ensure the structural regularity of\nSVGs while preserving diverse expressive capabilities. In the second stage, we\ncustomize the T2V diffusion model to different styles by distilling customized\nT2I models. By integrating these techniques, our pipeline can generate\nhigh-quality and diverse SVGs in custom styles based on text prompts in an\nefficient feed-forward manner. The effectiveness of our method has been\nvalidated through extensive experiments. The project page is\nhttps://customsvg.github.io.", "published": "2025-05-15 17:59:21", "link": "http://arxiv.org/abs/2505.10558v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis", "abstract": "Recent advancements have enhanced the capability of Multimodal Large Language\nModels (MLLMs) to comprehend multi-image information. However, existing\nbenchmarks primarily evaluate answer correctness, overlooking whether models\ngenuinely comprehend the visual input. To address this, we define implicit\nvisual misunderstanding (IVM), where MLLMs provide correct answers without\nfully comprehending the visual input. Through our analysis, we decouple the\nvisual and textual modalities within the causal attention module, revealing\nthat attention distribution increasingly converges on the image associated with\nthe correct answer as the network layers deepen. This insight leads to the\nintroduction of a scale-agnostic metric, \\textit{attention accuracy}, and a\nnovel benchmark for quantifying IVMs. Attention accuracy directly evaluates the\nmodel's visual understanding via internal mechanisms, remaining robust to\npositional biases for more reliable assessments. Furthermore, we extend our\napproach to finer granularities and demonstrate its effectiveness in unimodal\nscenarios, underscoring its versatility and generalizability.", "published": "2025-05-15 17:52:40", "link": "http://arxiv.org/abs/2505.10541v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "abstract": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes.", "published": "2025-05-15 17:41:52", "link": "http://arxiv.org/abs/2505.10533v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks", "abstract": "Face recognition has evolved significantly with the advancement of deep\nlearning techniques, enabling its widespread adoption in various applications\nrequiring secure authentication. However, this progress has also increased its\nexposure to presentation attacks, including face morphing, which poses a\nserious security threat by allowing one identity to impersonate another.\nTherefore, modern face recognition systems must be robust against such attacks.\n  In this work, we propose a novel approach for training deep networks for face\nrecognition with enhanced robustness to face morphing attacks. Our method\nmodifies the classification task by introducing a dual-branch classification\nstrategy that effectively handles the ambiguity in the labeling of face morphs.\nThis adaptation allows the model to incorporate morph images into the training\nprocess, improving its ability to distinguish them from bona fide samples.\n  Our strategy has been validated on public benchmarks, demonstrating its\neffectiveness in enhancing robustness against face morphing attacks.\nFurthermore, our approach is universally applicable and can be integrated into\nexisting face recognition training pipelines to improve classification-based\nrecognition methods.", "published": "2025-05-15 17:00:16", "link": "http://arxiv.org/abs/2505.10497v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs", "abstract": "We introduce CheXGenBench, a rigorous and multifaceted evaluation framework\nfor synthetic chest radiograph generation that simultaneously assesses\nfidelity, privacy risks, and clinical utility across state-of-the-art\ntext-to-image generative models. Despite rapid advancements in generative AI\nfor real-world imagery, medical domain evaluations have been hindered by\nmethodological inconsistencies, outdated architectural comparisons, and\ndisconnected assessment criteria that rarely address the practical clinical\nvalue of synthetic samples. CheXGenBench overcomes these limitations through\nstandardised data partitioning and a unified evaluation protocol comprising\nover 20 quantitative metrics that systematically analyse generation quality,\npotential privacy vulnerabilities, and downstream clinical applicability across\n11 leading text-to-image architectures. Our results reveal critical\ninefficiencies in the existing evaluation protocols, particularly in assessing\ngenerative fidelity, leading to inconsistent and uninformative comparisons. Our\nframework establishes a standardised benchmark for the medical AI community,\nenabling objective and reproducible comparisons while facilitating seamless\nintegration of both existing and future generative models. Additionally, we\nrelease a high-quality, synthetic dataset, SynthCheX-75K, comprising 75K\nradiographs generated by the top-performing model (Sana 0.6B) in our benchmark\nto support further research in this critical domain. Through CheXGenBench, we\nestablish a new state-of-the-art and release our framework, models, and\nSynthCheX-75K dataset at https://raman1121.github.io/CheXGenBench/", "published": "2025-05-15 16:59:17", "link": "http://arxiv.org/abs/2505.10496v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-contrast laser endoscopy for in vivo gastrointestinal imaging", "abstract": "White light endoscopy is the clinical gold standard for detecting diseases in\nthe gastrointestinal tract. Most applications involve identifying visual\nabnormalities in tissue color, texture, and shape. Unfortunately, the contrast\nof these features is often subtle, causing many clinically relevant cases to go\nundetected. To overcome this challenge, we introduce Multi-contrast Laser\nEndoscopy (MLE): a platform for widefield clinical imaging with rapidly tunable\nspectral, coherent, and directional illumination. We demonstrate three\ncapabilities of MLE: enhancing tissue chromophore contrast with multispectral\ndiffuse reflectance, quantifying blood flow using laser speckle contrast\nimaging, and characterizing mucosal topography using photometric stereo. We\nvalidate MLE with benchtop models, then demonstrate MLE in vivo during clinical\ncolonoscopies. MLE images from 31 polyps demonstrate an approximate three-fold\nimprovement in contrast and a five-fold improvement in color difference\ncompared to white light and narrow band imaging. With the ability to reveal\nmultiple complementary types of tissue contrast while seamlessly integrating\ninto the clinical environment, MLE shows promise as an investigative tool to\nimprove gastrointestinal imaging.", "published": "2025-05-15 16:47:24", "link": "http://arxiv.org/abs/2505.10492v1", "categories": ["eess.IV", "cs.CV", "physics.med-ph", "physics.optics"], "primary_category": "eess.IV"}
{"title": "Logos as a Well-Tempered Pre-train for Sign Language Recognition", "abstract": "This paper examines two aspects of the isolated sign language recognition\n(ISLR) task. First, despite the availability of a number of datasets, the\namount of data for most individual sign languages is limited. It poses the\nchallenge of cross-language ISLR model training, including transfer learning.\nSecond, similar signs can have different semantic meanings. It leads to\nambiguity in dataset labeling and raises the question of the best policy for\nannotating such signs. To address these issues, this study presents Logos, a\nnovel Russian Sign Language (RSL) dataset, the most extensive ISLR dataset by\nthe number of signers and one of the largest available datasets while also the\nlargest RSL dataset in size and vocabulary. It is shown that a model,\npre-trained on the Logos dataset can be used as a universal encoder for other\nlanguage SLR tasks, including few-shot learning. We explore cross-language\ntransfer learning approaches and find that joint training using multiple\nclassification heads benefits accuracy for the target lowresource datasets the\nmost. The key feature of the Logos dataset is explicitly annotated visually\nsimilar sign groups. We show that explicitly labeling visually similar signs\nimproves trained model quality as a visual encoder for downstream tasks. Based\non the proposed contributions, we outperform current state-of-the-art results\nfor the WLASL dataset and get competitive results for the AUTSL dataset, with a\nsingle stream model processing solely RGB video. The source code, dataset, and\npre-trained models are publicly available.", "published": "2025-05-15 16:31:49", "link": "http://arxiv.org/abs/2505.10481v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting", "abstract": "To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks\nto minimize the number of Gaussians used while preserving high rendering\nquality, introducing an inherent trade-off between Gaussian quantity and\nrendering quality. Existing methods strive for better quantity-quality\nperformance, but lack the ability for users to intuitively adjust this\ntrade-off to suit practical needs such as model deployment under diverse\nhardware and communication constraints. Here, we present ControlGS, a 3DGS\noptimization method that achieves semantically meaningful and cross-scene\nconsistent quantity-quality control while maintaining strong quantity-quality\nperformance. Through a single training run using a fixed setup and a\nuser-specified hyperparameter reflecting quantity-quality preference, ControlGS\ncan automatically find desirable quantity-quality trade-off points across\ndiverse scenes, from compact objects to large outdoor scenes. It also\noutperforms baselines by achieving higher rendering quality with fewer\nGaussians, and supports a broad adjustment range with stepless control over the\ntrade-off.", "published": "2025-05-15 16:23:51", "link": "http://arxiv.org/abs/2505.10473v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "HWA-UNETR: Hierarchical Window Aggregate UNETR for 3D Multimodal Gastric Lesion Segmentation", "abstract": "Multimodal medical image segmentation faces significant challenges in the\ncontext of gastric cancer lesion analysis. This clinical context is defined by\nthe scarcity of independent multimodal datasets and the imperative to\namalgamate inherently misaligned modalities. As a result, algorithms are\nconstrained to train on approximate data and depend on application migration,\nleading to substantial resource expenditure and a potential decline in analysis\naccuracy. To address those challenges, we have made two major contributions:\nFirst, we publicly disseminate the GCM 2025 dataset, which serves as the first\nlarge-scale, open-source collection of gastric cancer multimodal MRI scans,\nfeaturing professionally annotated FS-T2W, CE-T1W, and ADC images from 500\npatients. Second, we introduce HWA-UNETR, a novel 3D segmentation framework\nthat employs an original HWA block with learnable window aggregation layers to\nestablish dynamic feature correspondences between different modalities'\nanatomical structures, and leverages the innovative tri-orientated fusion mamba\nmechanism for context modeling and capturing long-range spatial dependencies.\nExtensive experiments on our GCM 2025 dataset and the publicly BraTS 2021\ndataset validate the performance of our framework, demonstrating that the new\napproach surpasses existing methods by up to 1.68\\% in the Dice score while\nmaintaining solid robustness. The dataset and code are public via\nhttps://github.com/JeMing-creater/HWA-UNETR.", "published": "2025-05-15 16:18:00", "link": "http://arxiv.org/abs/2505.10464v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability", "abstract": "Self-supervised learning shows promise in harnessing extensive unlabeled\ndata, but it also confronts significant privacy concerns, especially in vision.\nIn this paper, we perform membership inference on visual self-supervised models\nin a more realistic setting: self-supervised training method and details are\nunknown for an adversary when attacking as he usually faces a black-box system\nin practice. In this setting, considering that self-supervised model could be\ntrained by completely different self-supervised paradigms, e.g., masked image\nmodeling and contrastive learning, with complex training details, we propose a\nunified membership inference method called PartCrop. It is motivated by the\nshared part-aware capability among models and stronger part response on the\ntraining data. Specifically, PartCrop crops parts of objects in an image to\nquery responses within the image in representation space. We conduct extensive\nattacks on self-supervised models with different training protocols and\nstructures using three widely used image datasets. The results verify the\neffectiveness and generalization of PartCrop. Moreover, to defend against\nPartCrop, we evaluate two common approaches, i.e., early stop and differential\nprivacy, and propose a tailored method called shrinking crop scale range. The\ndefense experiments indicate that all of them are effective. Finally, besides\nprototype testing on toy visual encoders and small-scale image datasets, we\nquantitatively study the impacts of scaling from both data and model aspects in\na realistic scenario and propose a scalable PartCrop-v2 by introducing two\nstructural improvements to PartCrop. Our code is at\nhttps://github.com/JiePKU/PartCrop.", "published": "2025-05-15 14:43:34", "link": "http://arxiv.org/abs/2505.10351v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "SOS: A Shuffle Order Strategy for Data Augmentation in Industrial Human Activity Recognition", "abstract": "In the realm of Human Activity Recognition (HAR), obtaining high quality and\nvariance data is still a persistent challenge due to high costs and the\ninherent variability of real-world activities. This study introduces a\ngeneration dataset by deep learning approaches (Attention Autoencoder and\nconditional Generative Adversarial Networks). Another problem that data\nheterogeneity is a critical challenge, one of the solutions is to shuffle the\ndata to homogenize the distribution. Experimental results demonstrate that the\nrandom sequence strategy significantly improves classification performance,\nachieving an accuracy of up to 0.70 $\\pm$ 0.03 and a macro F1 score of 0.64\n$\\pm$ 0.01. For that, disrupting temporal dependencies through random sequence\nreordering compels the model to focus on instantaneous recognition, thereby\nimproving robustness against activity transitions. This approach not only\nbroadens the effective training dataset but also offers promising avenues for\nenhancing HAR systems in complex, real-world scenarios.", "published": "2025-05-15 13:56:14", "link": "http://arxiv.org/abs/2505.10312v1", "categories": ["cs.HC", "cs.CV"], "primary_category": "cs.HC"}
{"title": "MIPHEI-ViT: Multiplex Immunofluorescence Prediction from H&E Images using ViT Foundation Models", "abstract": "Histopathological analysis is a cornerstone of cancer diagnosis, with\nHematoxylin and Eosin (H&E) staining routinely acquired for every patient to\nvisualize cell morphology and tissue architecture. On the other hand, multiplex\nimmunofluorescence (mIF) enables more precise cell type identification via\nproteomic markers, but has yet to achieve widespread clinical adoption due to\ncost and logistical constraints. To bridge this gap, we introduce MIPHEI\n(Multiplex Immunofluorescence Prediction from H&E), a U-Net-inspired\narchitecture that integrates state-of-the-art ViT foundation models as encoders\nto predict mIF signals from H&E images. MIPHEI targets a comprehensive panel of\nmarkers spanning nuclear content, immune lineages (T cells, B cells, myeloid),\nepithelium, stroma, vasculature, and proliferation. We train our model using\nthe publicly available ORION dataset of restained H&E and mIF images from\ncolorectal cancer tissue, and validate it on two independent datasets. MIPHEI\nachieves accurate cell-type classification from H&E alone, with F1 scores of\n0.88 for Pan-CK, 0.57 for CD3e, 0.56 for SMA, 0.36 for CD68, and 0.30 for CD20,\nsubstantially outperforming both a state-of-the-art baseline and a random\nclassifier for most markers. Our results indicate that our model effectively\ncaptures the complex relationships between nuclear morphologies in their tissue\ncontext, as visible in H&E images and molecular markers defining specific cell\ntypes. MIPHEI offers a promising step toward enabling cell-type-aware analysis\nof large-scale H&E datasets, in view of uncovering relationships between\nspatial cellular organization and patient outcomes.", "published": "2025-05-15 13:42:48", "link": "http://arxiv.org/abs/2505.10294v1", "categories": ["cs.CV", "q-bio.TO", "68T07 (Primary), 92C55 (Secondary)", "I.4.9; I.2.10; I.5.4; J.3"], "primary_category": "cs.CV"}
{"title": "MSCI: Addressing CLIP's Inherent Limitations for Compositional Zero-Shot Learning", "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen state-object\ncombinations by leveraging known combinations. Existing studies basically rely\non the cross-modal alignment capabilities of CLIP but tend to overlook its\nlimitations in capturing fine-grained local features, which arise from its\narchitectural and training paradigm. To address this issue, we propose a\nMulti-Stage Cross-modal Interaction (MSCI) model that effectively explores and\nutilizes intermediate-layer information from CLIP's visual encoder.\nSpecifically, we design two self-adaptive aggregators to extract local\ninformation from low-level visual features and integrate global information\nfrom high-level visual features, respectively. These key information are\nprogressively incorporated into textual representations through a\nstage-by-stage interaction mechanism, significantly enhancing the model's\nperception capability for fine-grained local visual information. Additionally,\nMSCI dynamically adjusts the attention weights between global and local visual\ninformation based on different combinations, as well as different elements\nwithin the same combination, allowing it to flexibly adapt to diverse\nscenarios. Experiments on three widely used datasets fully validate the\neffectiveness and superiority of the proposed model. Data and code are\navailable at https://github.com/ltpwy/MSCI.", "published": "2025-05-15 13:36:42", "link": "http://arxiv.org/abs/2505.10289v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting", "abstract": "Deep learning approaches for marine fog detection and forecasting have\noutperformed traditional methods, demonstrating significant scientific and\npractical importance. However, the limited availability of open-source datasets\nremains a major challenge. Existing datasets, often focused on a single region\nor satellite, restrict the ability to evaluate model performance across diverse\nconditions and hinder the exploration of intrinsic marine fog characteristics.\nTo address these limitations, we introduce \\textbf{MFogHub}, the first\nmulti-regional and multi-satellite dataset to integrate annotated marine fog\nobservations from 15 coastal fog-prone regions and six geostationary\nsatellites, comprising over 68,000 high-resolution samples. By encompassing\ndiverse regions and satellite perspectives, MFogHub facilitates rigorous\nevaluation of both detection and forecasting methods under varying conditions.\nExtensive experiments with 16 baseline models demonstrate that MFogHub can\nreveal generalization fluctuations due to regional and satellite discrepancy,\nwhile also serving as a valuable resource for the development of targeted and\nscalable fog prediction techniques. Through MFogHub, we aim to advance both the\npractical monitoring and scientific understanding of marine fog dynamics on a\nglobal scale. The dataset and code are at\n\\href{https://github.com/kaka0910/MFogHub}{https://github.com/kaka0910/MFogHub}.", "published": "2025-05-15 13:29:40", "link": "http://arxiv.org/abs/2505.10281v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "abstract": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency.", "published": "2025-05-15 13:22:20", "link": "http://arxiv.org/abs/2505.10271v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "abstract": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available.", "published": "2025-05-15 13:18:37", "link": "http://arxiv.org/abs/2505.10267v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Inferring Driving Maps by Deep Learning-based Trail Map Extraction", "abstract": "High-definition (HD) maps offer extensive and accurate environmental\ninformation about the driving scene, making them a crucial and essential\nelement for planning within autonomous driving systems. To avoid extensive\nefforts from manual labeling, methods for automating the map creation have\nemerged. Recent trends have moved from offline mapping to online mapping,\nensuring availability and actuality of the utilized maps. While the performance\nhas increased in recent years, online mapping still faces challenges regarding\ntemporal consistency, sensor occlusion, runtime, and generalization. We propose\na novel offline mapping approach that integrates trails - informal routes used\nby drivers - into the map creation process. Our method aggregates trail data\nfrom the ego vehicle and other traffic participants to construct a\ncomprehensive global map using transformer-based deep learning models. Unlike\ntraditional offline mapping, our approach enables continuous updates while\nremaining sensor-agnostic, facilitating efficient data transfer. Our method\ndemonstrates superior performance compared to state-of-the-art online mapping\napproaches, achieving improved generalization to previously unseen environments\nand sensor configurations. We validate our approach on two benchmark datasets,\nhighlighting its robustness and applicability in autonomous driving systems.", "published": "2025-05-15 13:09:19", "link": "http://arxiv.org/abs/2505.10258v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "Sage Deer: A Super-Aligned Driving Generalist Is Your Copilot", "abstract": "The intelligent driving cockpit, an important part of intelligent driving,\nneeds to match different users' comfort, interaction, and safety needs. This\npaper aims to build a Super-Aligned and GEneralist DRiving agent, SAGE DeeR.\nSage Deer achieves three highlights: (1) Super alignment: It achieves different\nreactions according to different people's preferences and biases. (2)\nGeneralist: It can understand the multi-view and multi-mode inputs to reason\nthe user's physiological indicators, facial emotions, hand movements, body\nmovements, driving scenarios, and behavioral decisions. (3) Self-Eliciting: It\ncan elicit implicit thought chains in the language space to further increase\ngeneralist and super-aligned abilities. Besides, we collected multiple data\nsets and built a large-scale benchmark. This benchmark measures the deer's\nperceptual decision-making ability and the super alignment's accuracy.", "published": "2025-05-15 13:08:44", "link": "http://arxiv.org/abs/2505.10257v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization", "abstract": "Human mesh recovery (HMR) from a single image is inherently ill-posed due to\ndepth ambiguity and occlusions. Probabilistic methods have tried to solve this\nby generating numerous plausible 3D human mesh predictions, but they often\nexhibit misalignment with 2D image observations and weak robustness to\nin-the-wild images. To address these issues, we propose ADHMR, a framework that\nAligns a Diffusion-based HMR model in a preference optimization manner. First,\nwe train a human mesh prediction assessment model, HMR-Scorer, capable of\nevaluating predictions even for in-the-wild images without 3D annotations. We\nthen use HMR-Scorer to create a preference dataset, where each input image has\na pair of winner and loser mesh predictions. This dataset is used to finetune\nthe base model using direct preference optimization. Moreover, HMR-Scorer also\nhelps improve existing HMR models by data cleaning, even with fewer training\nsamples. Extensive experiments show that ADHMR outperforms current\nstate-of-the-art methods. Code is available at:\nhttps://github.com/shenwenhao01/ADHMR.", "published": "2025-05-15 13:04:51", "link": "http://arxiv.org/abs/2505.10250v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation", "abstract": "Human image animation has gained increasing attention and developed rapidly\ndue to its broad applications in digital humans. However, existing methods rely\nlargely on 2D-rendered pose images for motion guidance, which limits\ngeneralization and discards essential 3D information for open-world animation.\nTo tackle this problem, we propose MTVCrafter (Motion Tokenization Video\nCrafter), the first framework that directly models raw 3D motion sequences\n(i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT\n(4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens.\nCompared to 2D-rendered pose images, 4D motion tokens offer more robust\nspatio-temporal cues and avoid strict pixel-level alignment between pose image\nand character, enabling more flexible and disentangled control. Then, we\nintroduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention\nwith 4D positional encodings, MV-DiT can effectively leverage motion tokens as\n4D compact yet expressive context for human image animation in the complex 3D\nworld. Hence, it marks a significant step forward in this field and opens a new\ndirection for pose-guided human video generation. Experiments show that our\nMTVCrafter achieves state-of-the-art results with an FID-VID of 6.98,\nsurpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter\nalso generalizes well to diverse open-world characters (single/multiple,\nfull/half-body) across various styles and scenarios. Our video demos and code\nare provided in the supplementary material and at this anonymous GitHub link:\nhttps://anonymous.4open.science/r/MTVCrafter-1B13.", "published": "2025-05-15 12:50:29", "link": "http://arxiv.org/abs/2505.10238v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "abstract": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications.", "published": "2025-05-15 12:32:02", "link": "http://arxiv.org/abs/2505.10223v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation", "abstract": "Accurate food volume estimation is crucial for medical nutrition management\nand health monitoring applications, but current food volume estimation methods\nare often limited by mononuclear data, leveraging single-purpose hardware such\nas 3D scanners, gathering sensor-oriented information such as depth\ninformation, or relying on camera calibration using a reference object. In this\npaper, we present VolE, a novel framework that leverages mobile device-driven\n3D reconstruction to estimate food volume. VolE captures images and camera\nlocations in free motion to generate precise 3D models, thanks to AR-capable\nmobile devices. To achieve real-world measurement, VolE is a reference- and\ndepth-free framework that leverages food video segmentation for food mask\ngeneration. We also introduce a new food dataset encompassing the challenging\nscenarios absent in the previous benchmarks. Our experiments demonstrate that\nVolE outperforms the existing volume estimation techniques across multiple\ndatasets by achieving 2.22 % MAPE, highlighting its superior performance in\nfood volume estimation.", "published": "2025-05-15 12:03:05", "link": "http://arxiv.org/abs/2505.10205v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization", "abstract": "Federated domain generalization aims to learn a generalizable model from\nmultiple decentralized source domains for deploying on the unseen target\ndomain. The style augmentation methods have achieved great progress on domain\ngeneralization. However, the existing style augmentation methods either explore\nthe data styles within isolated source domain or interpolate the style\ninformation across existing source domains under the data decentralization\nscenario, which leads to limited style space. To address this issue, we propose\na Multi-source Collaborative Style Augmentation and Domain-invariant learning\nmethod (MCSAD) for federated domain generalization. Specifically, we propose a\nmulti-source collaborative style augmentation module to generate data in the\nbroader style space. Furthermore, we conduct domain-invariant learning between\nthe original data and augmented data by cross-domain feature alignment within\nthe same class and classes relation ensemble distillation between different\nclasses to learn a domain-invariant model. By alternatively conducting\ncollaborative style augmentation and domain-invariant learning, the model can\ngeneralize well on unseen target domain. Extensive experiments on multiple\ndomain generalization datasets indicate that our method significantly\noutperforms the state-of-the-art federated domain generalization methods.", "published": "2025-05-15 10:26:17", "link": "http://arxiv.org/abs/2505.10152v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "VRSplat: Fast and Robust Gaussian Splatting for Virtual Reality", "abstract": "3D Gaussian Splatting (3DGS) has rapidly become a leading technique for\nnovel-view synthesis, providing exceptional performance through efficient\nsoftware-based GPU rasterization. Its versatility enables real-time\napplications, including on mobile and lower-powered devices. However, 3DGS\nfaces key challenges in virtual reality (VR): (1) temporal artifacts, such as\npopping during head movements, (2) projection-based distortions that result in\ndisturbing and view-inconsistent floaters, and (3) reduced framerates when\nrendering large numbers of Gaussians, falling below the critical threshold for\nVR. Compared to desktop environments, these issues are drastically amplified by\nlarge field-of-view, constant head movements, and high resolution of\nhead-mounted displays (HMDs). In this work, we introduce VRSplat: we combine\nand extend several recent advancements in 3DGS to address challenges of VR\nholistically. We show how the ideas of Mini-Splatting, StopThePop, and Optimal\nProjection can complement each other, by modifying the individual techniques\nand core 3DGS rasterizer. Additionally, we propose an efficient foveated\nrasterizer that handles focus and peripheral areas in a single GPU launch,\navoiding redundant computations and improving GPU utilization. Our method also\nincorporates a fine-tuning step that optimizes Gaussian parameters based on\nStopThePop depth evaluations and Optimal Projection. We validate our method\nthrough a controlled user study with 25 participants, showing a strong\npreference for VRSplat over other configurations of Mini-Splatting. VRSplat is\nthe first, systematically evaluated 3DGS approach capable of supporting modern\nVR applications, achieving 72+ FPS while eliminating popping and\nstereo-disrupting floaters.", "published": "2025-05-15 10:17:48", "link": "http://arxiv.org/abs/2505.10144v1", "categories": ["cs.GR", "cs.CV"], "primary_category": "cs.GR"}
{"title": "IMITATE: Image Registration with Context for unknown time frame recovery", "abstract": "In this paper, we formulate a novel image registration formalism dedicated to\nthe estimation of unknown condition-related images, based on two or more known\nimages and their associated conditions. We show how to practically model this\nformalism by using a new conditional U-Net architecture, which fully takes into\naccount the conditional information and does not need any fixed image. Our\nformalism is then applied to image moving tumors for radiotherapy treatment at\ndifferent breathing amplitude using 4D-CT (3D+t) scans in thoracoabdominal\nregions. This driving application is particularly complex as it requires to\nstitch a collection of sequential 2D slices into several 3D volumes at\ndifferent organ positions. Movement interpolation with standard methods then\ngenerates well known reconstruction artefacts in the assembled volumes due to\nirregular patient breathing, hysteresis and poor correlation of breathing\nsignal to internal motion. Results obtained on 4D-CT clinical data showcase\nartefact-free volumes achieved through real-time latencies. The code is\npublicly available at https://github.com/Kheil-Z/IMITATE .", "published": "2025-05-15 09:51:05", "link": "http://arxiv.org/abs/2505.10124v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models", "abstract": "Large-scale pre-trained Vision-Language Models (VLMs) have significantly\nadvanced transfer learning across diverse tasks. However, adapting these models\nwith limited few-shot data often leads to overfitting, undermining their\nability to generalize to new tasks. To address this, we propose Multi-Modal\nRepresentation Learning (MMRL), which introduces a shared, learnable,\nmodality-agnostic representation space. MMRL generates space tokens projected\ninto both text and image encoders as representation tokens, enabling more\neffective cross-modal interactions. Unlike prior methods that mainly optimize\nclass token features, MMRL inserts representation tokens into higher encoder\nlayers--where task-specific features are more prominent--while preserving\ngeneral knowledge in the lower layers. During training, both class and\nrepresentation features are jointly optimized: a trainable projection layer is\napplied to representation tokens for task adaptation, while the projection\nlayer for class token remains frozen to retain pre-trained knowledge. To\nfurther promote generalization, we introduce a regularization term aligning\nclass and text features with the frozen VLM's zero-shot features. At inference,\na decoupling strategy uses both class and representation features for base\ntasks, but only class features for novel tasks due to their stronger\ngeneralization. Building upon this, we propose MMRL++, a parameter-efficient\nand interaction-aware extension that significantly reduces trainable parameters\nand enhances intra-modal interactions--particularly across the layers of\nrepresentation tokens--allowing gradient sharing and instance-specific\ninformation to propagate more effectively through the network. Extensive\nexperiments on 15 datasets demonstrate that MMRL and MMRL++ consistently\noutperform state-of-the-art methods, achieving a strong balance between\ntask-specific adaptation and generalization.", "published": "2025-05-15 08:43:53", "link": "http://arxiv.org/abs/2505.10088v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation", "abstract": "This paper investigates training better visual world models for robot\nmanipulation, i.e., models that can predict future visual observations by\nconditioning on past frames and robot actions. Specifically, we consider world\nmodels that operate on RGB-D frames (RGB-D world models). As opposed to\ncanonical approaches that handle dynamics prediction mostly implicitly and\nreconcile it with visual rendering in a single model, we introduce FlowDreamer,\nwhich adopts 3D scene flow as explicit motion representations. FlowDreamer\nfirst predicts 3D scene flow from past frame and action conditions with a\nU-Net, and then a diffusion model will predict the future frame utilizing the\nscene flow. FlowDreamer is trained end-to-end despite its modularized nature.\nWe conduct experiments on 4 different benchmarks, covering both video\nprediction and visual planning tasks. The results demonstrate that FlowDreamer\nachieves better performance compared to other baseline RGB-D world models by 7%\non semantic similarity, 11% on pixel quality, and 6% on success rate in various\nrobot manipulation domains.", "published": "2025-05-15 08:27:16", "link": "http://arxiv.org/abs/2505.10075v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars", "abstract": "The introduction of 3D Gaussian blendshapes has enabled the real-time\nreconstruction of animatable head avatars from monocular video. Toonify, a\nStyleGAN-based framework, has become widely used for facial image stylization.\nTo extend Toonify for synthesizing diverse stylized 3D head avatars using\nGaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB.\nIn Stage 1 (stylized video generation), we employ an improved StyleGAN to\ngenerate the stylized video from the input video frames, which addresses the\nlimitation of cropping aligned faces at a fixed resolution as preprocessing for\nnormal StyleGAN. This process provides a more stable video, which enables\nGaussian blendshapes to better capture the high-frequency details of the video\nframes, and efficiently generate high-quality animation in the next stage. In\nStage 2 (Gaussian blendshapes synthesis), we learn a stylized neutral head\nmodel and a set of expression blendshapes from the generated video. By\ncombining the neutral head model with expression blendshapes, ToonifyGB can\nefficiently render stylized avatars with arbitrary expressions. We validate the\neffectiveness of ToonifyGB on the benchmark dataset using two styles: Arcane\nand Pixar.", "published": "2025-05-15 08:16:12", "link": "http://arxiv.org/abs/2505.10072v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field", "abstract": "Dynamic scene representation and reconstruction have undergone transformative\nadvances in recent years, catalyzed by breakthroughs in neural radiance fields\nand 3D Gaussian splatting techniques. While initially developed for static\nenvironments, these methodologies have rapidly evolved to address the\ncomplexities inherent in 4D dynamic scenes through an expansive body of\nresearch. Coupled with innovations in differentiable volumetric rendering,\nthese approaches have significantly enhanced the quality of motion\nrepresentation and dynamic scene reconstruction, thereby garnering substantial\nattention from the computer vision and graphics communities. This survey\npresents a systematic analysis of over 200 papers focused on dynamic scene\nrepresentation using radiance field, spanning the spectrum from implicit neural\nrepresentations to explicit Gaussian primitives. We categorize and evaluate\nthese works through multiple critical lenses: motion representation paradigms,\nreconstruction techniques for varied scene dynamics, auxiliary information\nintegration strategies, and regularization approaches that ensure temporal\nconsistency and physical plausibility. We organize diverse methodological\napproaches under a unified representational framework, concluding with a\ncritical examination of persistent challenges and promising research\ndirections. By providing this comprehensive overview, we aim to establish a\ndefinitive reference for researchers entering this rapidly evolving field while\noffering experienced practitioners a systematic understanding of both\nconceptual principles and practical frontiers in dynamic scene reconstruction.", "published": "2025-05-15 07:51:08", "link": "http://arxiv.org/abs/2505.10049v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis", "abstract": "This paper does not describe a new method; instead, it provides a thorough\nexploration of an important yet understudied design space related to recent\nadvances in text-to-image synthesis -- specifically, the deep fusion of large\nlanguage models (LLMs) and diffusion transformers (DiTs) for multi-modal\ngeneration. Previous studies mainly focused on overall system performance\nrather than detailed comparisons with alternative methods, and key design\ndetails and training recipes were often left undisclosed. These gaps create\nuncertainty about the real potential of this approach. To fill these gaps, we\nconduct an empirical study on text-to-image generation, performing controlled\ncomparisons with established baselines, analyzing important design choices, and\nproviding a clear, reproducible recipe for training at scale. We hope this work\noffers meaningful data points and practical guidelines for future research in\nmulti-modal generation.", "published": "2025-05-15 07:43:23", "link": "http://arxiv.org/abs/2505.10046v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "abstract": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system.", "published": "2025-05-15 07:25:43", "link": "http://arxiv.org/abs/2505.10030v1", "categories": ["cs.CV", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching", "abstract": "In the era of immersive consumer electronics, such as AR/VR headsets and\nsmart devices, people increasingly seek ways to express their identity through\nvirtual fashion. However, existing 3D garment design tools remain inaccessible\nto everyday users due to steep technical barriers and limited data. In this\nwork, we introduce a 3D sketch-driven 3D garment generation framework that\nempowers ordinary users - even those without design experience - to create\nhigh-quality digital clothing through simple 3D sketches in AR/VR environments.\nBy combining a conditional diffusion model, a sketch encoder trained in a\nshared latent space, and an adaptive curriculum learning strategy, our system\ninterprets imprecise, free-hand input and produces realistic, personalized\ngarments. To address the scarcity of training data, we also introduce\nKO3DClothes, a new dataset of paired 3D garments and user-created sketches.\nExtensive experiments and user studies confirm that our method significantly\noutperforms existing baselines in both fidelity and usability, demonstrating\nits promise for democratized fashion design on next-generation consumer\nplatforms.", "published": "2025-05-15 06:22:24", "link": "http://arxiv.org/abs/2505.09998v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Descriptive Image-Text Matching with Graded Contextual Similarity", "abstract": "Image-text matching aims to build correspondences between visual and textual\ndata by learning their pairwise similarities. Most existing approaches have\nadopted sparse binary supervision, indicating whether a pair of images and\nsentences matches or not. However, such sparse supervision covers a limited\nsubset of image-text relationships, neglecting their inherent many-to-many\ncorrespondences; an image can be described in numerous texts at different\ndescriptive levels. Moreover, existing approaches overlook the implicit\nconnections from general to specific descriptions, which form the underlying\nrationale for the many-to-many relationships between vision and language. In\nthis work, we propose descriptive image-text matching, called DITM, to learn\nthe graded contextual similarity between image and text by exploring the\ndescriptive flexibility of language. We formulate the descriptiveness score of\neach sentence with cumulative term frequency-inverse document frequency\n(TF-IDF) to balance the pairwise similarity according to the keywords in the\nsentence. Our method leverages sentence descriptiveness to learn robust\nimage-text matching in two key ways: (1) to refine the false negative labeling,\ndynamically relaxing the connectivity between positive and negative pairs, and\n(2) to build more precise matching, aligning a set of relevant sentences in a\ngeneric-to-specific order. By moving beyond rigid binary supervision, DITM\nenhances the discovery of both optimal matches and potential positive pairs.\nExtensive experiments on MS-COCO, Flickr30K, and CxC datasets demonstrate the\neffectiveness of our method in representing complex image-text relationships\ncompared to state-of-the-art approaches. In addition, DITM enhances the\nhierarchical reasoning ability of the model, supported by the extensive\nanalysis on HierarCaps benchmark.", "published": "2025-05-15 06:21:00", "link": "http://arxiv.org/abs/2505.09997v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "PointArena: Probing Multimodal Grounding Through Language-Guided Pointing", "abstract": "Pointing serves as a fundamental and intuitive mechanism for grounding\nlanguage within visual contexts, with applications spanning robotics, assistive\ntechnologies, and interactive AI systems. While recent multimodal models have\nstarted to support pointing capabilities, existing benchmarks typically focus\nonly on referential object localization tasks. We introduce PointArena, a\ncomprehensive platform for evaluating multimodal pointing across diverse\nreasoning scenarios. PointArena comprises three components: (1) Point-Bench, a\ncurated dataset containing approximately 1,000 pointing tasks across five\nreasoning categories; (2) Point-Battle, an interactive, web-based arena\nfacilitating blind, pairwise model comparisons, which has already gathered over\n4,500 anonymized votes; and (3) Point-Act, a real-world robotic manipulation\nsystem allowing users to directly evaluate multimodal model pointing\ncapabilities in practical settings. We conducted extensive evaluations of both\nstate-of-the-art open-source and proprietary multimodal models. Results\nindicate that Molmo-72B consistently outperforms other models, though\nproprietary models increasingly demonstrate comparable performance.\nAdditionally, we find that supervised training specifically targeting pointing\ntasks significantly enhances model performance. Across our multi-stage\nevaluation pipeline, we also observe strong correlations, underscoring the\ncritical role of precise pointing capabilities in enabling multimodal models to\neffectively bridge abstract reasoning with concrete, real-world actions.\nProject page: https://pointarena.github.io/", "published": "2025-05-15 06:04:42", "link": "http://arxiv.org/abs/2505.09990v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "High Quality Underwater Image Compression with Adaptive Correction and Codebook-based Augmentation", "abstract": "With the increasing exploration and exploitation of the underwater world,\nunderwater images have become a critical medium for human interaction with\nmarine environments, driving extensive research into their efficient\ntransmission and storage. However, contemporary underwater image compression\nalgorithms fail to fully leverage the unique characteristics distinguishing\nunderwater scenes from terrestrial images, resulting in suboptimal performance.\nTo address this limitation, we introduce HQUIC, designed to exploit\nunderwater-image-specific features for enhanced compression efficiency. HQUIC\nemploys an ALTC module to adaptively predict the attenuation coefficients and\nglobal light information of the images, which effectively mitigates the issues\ncaused by the differences in lighting and tone existing in underwater images.\nSubsequently, HQUIC employs a codebook as an auxiliary branch to extract the\ncommon objects within underwater images and enhances the performance of the\nmain branch. Furthermore, HQUIC dynamically weights multi-scale frequency\ncomponents, prioritizing information critical for distortion quality while\ndiscarding redundant details. Extensive evaluations on diverse underwater\ndatasets demonstrate that HQUIC outperforms state-of-the-art compression\nmethods.", "published": "2025-05-15 05:52:11", "link": "http://arxiv.org/abs/2505.09986v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "Ordered-subsets Multi-diffusion Model for Sparse-view CT Reconstruction", "abstract": "Score-based diffusion models have shown significant promise in the field of\nsparse-view CT reconstruction. However, the projection dataset is large and\nriddled with redundancy. Consequently, applying the diffusion model to\nunprocessed data results in lower learning effectiveness and higher learning\ndifficulty, frequently leading to reconstructed images that lack fine details.\nTo address these issues, we propose the ordered-subsets multi-diffusion model\n(OSMM) for sparse-view CT reconstruction. The OSMM innovatively divides the CT\nprojection data into equal subsets and employs multi-subsets diffusion model\n(MSDM) to learn from each subset independently. This targeted learning approach\nreduces complexity and enhances the reconstruction of fine details.\nFurthermore, the integration of one-whole diffusion model (OWDM) with complete\nsinogram data acts as a global information constraint, which can reduce the\npossibility of generating erroneous or inconsistent sinogram information.\nMoreover, the OSMM's unsupervised learning framework provides strong robustness\nand generalizability, adapting seamlessly to varying sparsity levels of CT\nsinograms. This ensures consistent and reliable performance across different\nclinical scenarios. Experimental results demonstrate that OSMM outperforms\ntraditional diffusion models in terms of image quality and noise resilience,\noffering a powerful and versatile solution for advanced CT imaging in\nsparse-view scenarios.", "published": "2025-05-15 05:50:35", "link": "http://arxiv.org/abs/2505.09985v1", "categories": ["eess.IV", "cs.CV"], "primary_category": "eess.IV"}
{"title": "APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds", "abstract": "Airborne laser scanning (ALS) point cloud segmentation is a fundamental task\nfor large-scale 3D scene understanding. In real-world applications, models are\ntypically fixed after training. However, domain shifts caused by changes in the\nenvironment, sensor types, or sensor degradation often lead to a decline in\nmodel performance. Continuous Test-Time Adaptation (CTTA) offers a solution by\nadapting a source-pretrained model to evolving, unlabeled target domains.\nDespite its potential, research on ALS point clouds remains limited, facing\nchallenges such as the absence of standardized datasets and the risk of\ncatastrophic forgetting and error accumulation during prolonged adaptation. To\ntackle these challenges, we propose APCoTTA, the first CTTA method tailored for\nALS point cloud semantic segmentation. We propose a dynamic trainable layer\nselection module. This module utilizes gradient information to select\nlow-confidence layers for training, and the remaining layers are kept frozen,\nmitigating catastrophic forgetting. To further reduce error accumulation, we\npropose an entropy-based consistency loss. By losing such samples based on\nentropy, we apply consistency loss only to the reliable samples, enhancing\nmodel stability. In addition, we propose a random parameter interpolation\nmechanism, which randomly blends parameters from the selected trainable layers\nwith those of the source model. This approach helps balance target adaptation\nand source knowledge retention, further alleviating forgetting. Finally, we\nconstruct two benchmarks, ISPRSC and H3DC, to address the lack of CTTA\nbenchmarks for ALS point cloud segmentation. Experimental results demonstrate\nthat APCoTTA achieves the best performance on two benchmarks, with mIoU\nimprovements of approximately 9% and 14% over direct inference. The new\nbenchmarks and code are available at https://github.com/Gaoyuan2/APCoTTA.", "published": "2025-05-15 05:21:16", "link": "http://arxiv.org/abs/2505.09971v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition", "abstract": "Facial expression recognition (FER) in the wild remains a challenging task\ndue to the subtle and localized nature of expression-related features, as well\nas the complex variations in facial appearance. In this paper, we introduce a\nnovel framework that explicitly focuses on Texture Key Driver Factors (TKDF),\nlocalized texture regions that exhibit strong discriminative power across\nemotional categories. By carefully observing facial image patterns, we identify\nthat certain texture cues, such as micro-changes in skin around the brows,\neyes, and mouth, serve as primary indicators of emotional dynamics. To\neffectively capture and leverage these cues, we propose a FER architecture\ncomprising a Texture-Aware Feature Extractor (TAFE) and Dual Contextual\nInformation Filtering (DCIF). TAFE employs a ResNet-based backbone enhanced\nwith multi-branch attention to extract fine-grained texture representations,\nwhile DCIF refines these features by filtering context through adaptive pooling\nand attention mechanisms. Experimental results on RAF-DB and KDEF datasets\ndemonstrate that our method achieves state-of-the-art performance, verifying\nthe effectiveness and robustness of incorporating TKDFs into FER pipelines.", "published": "2025-05-15 05:07:00", "link": "http://arxiv.org/abs/2505.09967v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction", "abstract": "Modelling disease progression in precision medicine requires capturing\ncomplex spatio-temporal dynamics while preserving anatomical integrity.\nExisting methods often struggle with longitudinal dependencies and structural\nconsistency in progressive disorders. To address these limitations, we\nintroduce MambaControl, a novel framework that integrates selective state-space\nmodelling with diffusion processes for high-fidelity prediction of medical\nimage trajectories. To better capture subtle structural changes over time while\nmaintaining anatomical consistency, MambaControl combines Mamba-based\nlong-range modelling with graph-guided anatomical control to more effectively\nrepresent anatomical correlations. Furthermore, we introduce Fourier-enhanced\nspectral graph representations to capture spatial coherence and multiscale\ndetail, enabling MambaControl to achieve state-of-the-art performance in\nAlzheimer's disease prediction. Quantitative and regional evaluations\ndemonstrate improved progression prediction quality and anatomical fidelity,\nhighlighting its potential for personalised prognosis and clinical decision\nsupport.", "published": "2025-05-15 04:59:02", "link": "http://arxiv.org/abs/2505.09965v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection", "abstract": "Infrared small target detection (ISTD) plays a critical role in a wide range\nof civilian and military applications. Existing methods suffer from\ndeficiencies in the localization of dim targets and the perception of contour\ninformation under dense clutter environments, severely limiting their detection\nperformance. To tackle these issues, we propose a contour-aware and saliency\npriors embedding network (CSPENet) for ISTD. We first design a\nsurround-convergent prior extraction module (SCPEM) that effectively captures\nthe intrinsic characteristic of target contour pixel gradients converging\ntoward their center. This module concurrently extracts two collaborative\npriors: a boosted saliency prior for accurate target localization and\nmulti-scale structural priors for comprehensively enriching contour detail\nrepresentation. Building upon this, we propose a dual-branch priors embedding\narchitecture (DBPEA) that establishes differentiated feature fusion pathways,\nembedding these two priors at optimal network positions to achieve performance\nenhancement. Finally, we develop an attention-guided feature enhancement module\n(AGFEM) to refine feature representations and improve saliency estimation\naccuracy. Experimental results on public datasets NUDT-SIRST, IRSTD-1k, and\nNUAA-SIRST demonstrate that our CSPENet outperforms other state-of-the-art\nmethods in detection performance. The code is available at\nhttps://github.com/IDIP2025/CSPENet.", "published": "2025-05-15 03:56:36", "link": "http://arxiv.org/abs/2505.09943v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Non-Registration Change Detection: A Novel Change Detection Task and Benchmark Dataset", "abstract": "In this study, we propose a novel remote sensing change detection task,\nnon-registration change detection, to address the increasing number of\nemergencies such as natural disasters, anthropogenic accidents, and military\nstrikes. First, in light of the limited discourse on the issue of\nnon-registration change detection, we systematically propose eight scenarios\nthat could arise in the real world and potentially contribute to the occurrence\nof non-registration problems. Second, we develop distinct image transformation\nschemes tailored to various scenarios to convert the available registration\nchange detection dataset into a non-registration version. Finally, we\ndemonstrate that non-registration change detection can cause catastrophic\ndamage to the state-of-the-art methods. Our code and dataset are available at\nhttps://github.com/ShanZard/NRCD.", "published": "2025-05-15 03:52:42", "link": "http://arxiv.org/abs/2505.09939v1", "categories": ["cs.CV", "eess.IV"], "primary_category": "cs.CV"}
{"title": "DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation", "abstract": "Domain adaptation addresses the challenge of model performance degradation\ncaused by domain gaps. In the typical setup for unsupervised domain adaptation,\nlabeled data from a source domain and unlabeled data from a target domain are\nused to train a target model. However, access to labeled source domain data,\nparticularly in medical datasets, can be restricted due to privacy policies. As\na result, research has increasingly shifted to source-free domain adaptation\n(SFDA), which requires only a pretrained model from the source domain and\nunlabeled data from the target domain data for adaptation. Existing SFDA\nmethods often rely on domain-specific image style translation and\nself-supervision techniques to bridge the domain gap and train the target\ndomain model. However, the quality of domain-specific style-translated images\nand pseudo-labels produced by these methods still leaves room for improvement.\nMoreover, training the entire model during adaptation can be inefficient under\nlimited supervision. In this paper, we propose a novel SFDA framework to\naddress these challenges. Specifically, to effectively mitigate the impact of\ndomain gap in the initial training phase, we introduce preadaptation to\ngenerate a preadapted model, which serves as an initialization of target model\nand allows for the generation of high-quality enhanced pseudo-labels without\nintroducing extra parameters. Additionally, we propose a data-dependent\nfrequency prompt to more effectively translate target domain images into a\nsource-like style. To further enhance adaptation, we employ a style-related\nlayer fine-tuning strategy, specifically designed for SFDA, to train the target\nmodel using the prompted target domain images and pseudo-labels. Extensive\nexperiments on cross-modality abdominal and cardiac SFDA segmentation tasks\ndemonstrate that our proposed method outperforms existing state-of-the-art\nmethods.", "published": "2025-05-15 03:24:54", "link": "http://arxiv.org/abs/2505.09927v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Large-Scale Gaussian Splatting SLAM", "abstract": "The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian\nSplatting (3DGS) have shown encouraging and impressive results for visual SLAM.\nHowever, most representative methods require RGBD sensors and are only\navailable for indoor environments. The robustness of reconstruction in\nlarge-scale outdoor scenarios remains unexplored. This paper introduces a\nlarge-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The\nproposed LSG-SLAM employs a multi-modality strategy to estimate prior poses\nunder large view changes. In tracking, we introduce feature-alignment warping\nconstraints to alleviate the adverse effects of appearance similarity in\nrendering losses. For the scalability of large-scale scenarios, we introduce\ncontinuous Gaussian Splatting submaps to tackle unbounded scenes with limited\nmemory. Loops are detected between GS submaps by place recognition and the\nrelative pose between looped keyframes is optimized utilizing rendering and\nfeature warping losses. After the global optimization of camera poses and\nGaussian points, a structure refinement module enhances the reconstruction\nquality. With extensive evaluations on the EuRoc and KITTI datasets, LSG-SLAM\nachieves superior performance over existing Neural, 3DGS-based, and even\ntraditional approaches. Project page: https://lsg-slam.github.io.", "published": "2025-05-15 03:00:32", "link": "http://arxiv.org/abs/2505.09915v1", "categories": ["cs.CV", "cs.RO"], "primary_category": "cs.CV"}
{"title": "How to Color Temporal Graphs to Ensure Proper Transitions", "abstract": "Graph Coloring consists in assigning colors to vertices ensuring that two\nadjacent vertices do not have the same color. In dynamic graphs, this notion is\nnot well defined, as we need to decide if different colors for adjacent\nvertices must happen all the time or not, and how to go from a coloring in one\ntime to the next one.\n  In this paper, we define a coloring notion for Temporal Graphs where at each\nstep, the coloring must be proper. It uses a notion of compatibility between\ntwo consecutive snapshots that implies that the coloring stays proper while the\ntransition happens. Given a graph, the minimum number of colors needed to\nensure that such coloring exists is the \\emph{Temporal Chromatic Number} of\nthis graph.\n  With those notions, we provide some lower and upper bounds for the temporal\nchromatic number in the general case. We then dive into some specific classes\nof graphs such as trees, graphs with bounded degree or bounded degeneracy.\nFinally, we consider temporal graphs where grow pace is one, that is, a single\nedge can be added and a single other one can be removed between two time steps.\nIn that case, we consider bipartite and bounded degree graphs.\n  Even though the problem is defined with full knowledge of the temporal graph,\nour results also work in the case where future snapshots are given online: we\nneed to choose the coloring of the next snapshot after having computed the\ncurrent one, not knowing what", "published": "2025-05-15 12:03:56", "link": "http://arxiv.org/abs/2505.10207v1", "categories": ["cs.DM"], "primary_category": "cs.DM"}
{"title": "The Tangent Space Attack", "abstract": "We propose a new method for retrieving the algebraic structure of a generic\nalternant code given an arbitrary generator matrix, provided certain conditions\nare met. We then discuss how this challenges the security of the McEliece\ncryptosystem instantiated with this family of codes. The central object of our\nwork is the quadratic hull related to a linear code, defined as the\nintersection of all quadrics passing through the columns of a given generator\nor parity-check matrix, where the columns are considered as points in the\naffine or projective space. The geometric properties of this object reveal\nimportant information about the internal algebraic structure of the code. This\nis particularly evident in the case of generalized Reed-Solomon codes, whose\nquadratic hull is deeply linked to a well-known algebraic variety called the\nrational normal curve. By utilizing the concept of Weil restriction of affine\nvarieties, we demonstrate that the quadratic hull of a generic dual alternant\ncode inherits many interesting features from the rational normal curve, on\naccount of the fact that alternant codes are subfield-subcodes of generalized\nReed-Solomon codes. If the rate of the generic alternant code is sufficiently\nhigh, this allows us to construct a polynomial-time algorithm for retrieving\nthe underlying generalized Reed-Solomon code from which the alternant code is\ndefined, which leads to an efficient key-recovery attack against the McEliece\ncryptosystem when instantiated with this class of codes. Finally, we discuss\nthe generalization of this approach to Algebraic-Geometry codes and Goppa\ncodes.", "published": "2025-05-15 11:30:46", "link": "http://arxiv.org/abs/2505.10184v1", "categories": ["cs.IT", "cs.CR", "math.IT", "11T71, 11T06"], "primary_category": "cs.IT"}
{"title": "The Schur product of evaluation codes and its application to CSS-T quantum codes and private information retrieval", "abstract": "In this work, we study the componentwise (Schur) product of\nmonomial-Cartesian codes by exploiting its correspondence with the Minkowski\nsum of their defining exponent sets. We show that $ J$-affine variety codes are\nwell suited for such products, generalizing earlier results for cyclic,\nReed-Muller, hyperbolic, and toric codes. Using this correspondence, we\nconstruct CSS-T quantum codes from weighted Reed-Muller codes and from binary\nsubfield-subcodes of $ J$-affine variety codes, leading to codes with better\nparameters than previously known. Finally, we present Private Information\nRetrieval (PIR) constructions for multiple colluding servers based on\nhyperbolic codes and subfield-subcodes of $ J$-affine variety codes, and show\nthat they outperform existing PIR schemes.", "published": "2025-05-15 08:09:21", "link": "http://arxiv.org/abs/2505.10068v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Low-Complexity Decoding for Low-Rate Block Codes of Short Length Based on Concatenated Coding Structure", "abstract": "To decode a short linear block code, ordered statics decoding (OSD) and/or\nthe $A^*$ decoding are usually considered. Either OSD or the $A^*$ decoding\nutilizes the magnitudes of the received symbols to establish the most reliable\nand independent positions (MRIP) frame. A restricted searched space can be\nemployed to achieve near-optimum decoding with reduced decoding complexity. For\na low-rate code with large minimum distance, the restricted search space is\nstill very huge.\n  We propose to use concatenated coding to further restrict the search space by\nproposing an improved MRIP frame. The improved MRIP frame is founded according\nto magnitudes of log likelihood ratios (LLRs) obtained by the soft-in soft-out\n(SISO) decoder for the inner code.\n  We focus on the construction and decoding of several $(n,k)$ = (128,36)\nbinary linear block codes based on concatenated coding. We use the (128,36)\nextended BCH (eBCH) code as a benchmark for comparison. Simulation shows that\nthere exist constructed concatenated codes which are much more efficient than\nthe (128,36) eBCH code. Some other codes of length 128 or close to 128 are also\nconstructed to demonstrate the efficiency of the proposed scheme.", "published": "2025-05-15 05:32:03", "link": "http://arxiv.org/abs/2505.09978v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Low-Complexity Hybrid Beamforming for Multi-Cell mmWave Massive MIMO: A Primitive Kronecker Decomposition Approach", "abstract": "To circumvent the high path loss of mmWave propagation and reduce the\nhardware cost of massive multiple-input multiple-output antenna systems,\nfull-dimensional hybrid beamforming is critical in 5G and beyond wireless\ncommunications. Concerning an uplink multi-cell system with a large-scale\nuniform planar antenna array, this paper designs an efficient hybrid beamformer\nusing primitive Kronecker decomposition and dynamic factor allocation, where\nthe analog beamformer applies to null the inter-cell interference and\nsimultaneously enhances the desired signals. In contrast, the digital\nbeamformer mitigates the intra-cell interference using the minimum mean square\nerror (MMSE) criterion. Then, due to the low accuracy of phase shifters\ninherent in the analog beamformer, a low-complexity hybrid beamformer is\ndeveloped to slow its adjustment speed. Next, an optimality analysis from a\nsubspace perspective is performed, and a sufficient condition for optimal\nantenna configuration is established. Finally, simulation results demonstrate\nthat the achievable sum rate of the proposed beamformer approaches that of the\noptimal pure digital MMSE scheme, yet with much lower computational complexity\nand hardware cost.", "published": "2025-05-15 03:54:16", "link": "http://arxiv.org/abs/2505.09940v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "On null completely regular codes in Manhattan metric", "abstract": "We investigate the class of completely regular codes in graphs with a\ndistance partition C_0,..., C_\\rho, where each set C_i, for 0<=i<=r-1, is an\nindependent set. This work focuses on the existence problem for such codes in\nthe n-dimensional infinite grid. We demonstrate that several parameter families\nof such codes necessarily arise from binary or ternary Hamming graphs or do not\nexist. Furthermore, employing binary linear programming techniques, we explore\ncompletely regular codes in infinite grids of dimensions 3 and 4 for the cases\nr=1 and r=2.", "published": "2025-05-15 01:31:29", "link": "http://arxiv.org/abs/2505.09893v1", "categories": ["math.CO", "cs.IT", "math.IT", "94B60"], "primary_category": "math.CO"}
{"title": "An AI-driven framework for the prediction of personalised health response to air pollution", "abstract": "Air pollution poses a significant threat to public health, causing or\nexacerbating many respiratory and cardiovascular diseases. In addition, climate\nchange is bringing about more extreme weather events such as wildfires and\nheatwaves, which can increase levels of pollution and worsen the effects of\npollution exposure. Recent advances in personal sensing have transformed the\ncollection of behavioural and physiological data, leading to the potential for\nnew improvements in healthcare. We wish to capitalise on this data, alongside\nnew capabilities in AI for making time series predictions, in order to monitor\nand predict health outcomes for an individual. Thus, we present a novel\nworkflow for predicting personalised health responses to pollution by\nintegrating physiological data from wearable fitness devices with real-time\nenvironmental exposures. The data is collected from various sources in a secure\nand ethical manner, and is used to train an AI model to predict individual\nhealth responses to pollution exposure within a cloud-based, modular framework.\nWe demonstrate that the AI model -- an Adversarial Autoencoder neural network\nin this case -- accurately reconstructs time-dependent health signals and\ncaptures nonlinear responses to pollution. Transfer learning is applied using\ndata from a personal smartwatch, which increases the generalisation abilities\nof the AI model and illustrates the adaptability of the approach to real-world,\nuser-generated data.", "published": "2025-05-15 17:59:07", "link": "http://arxiv.org/abs/2505.10556v1", "categories": ["cs.LG", "physics.ao-ph"], "primary_category": "cs.LG"}
{"title": "Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design", "abstract": "Developing bioactive molecules remains a central, time- and cost-heavy\nchallenge in drug discovery, particularly for novel targets lacking structural\nor functional data. Pharmacophore modeling presents an alternative for\ncapturing the key features required for molecular bioactivity against a\nbiological target. In this work, we present PharmaDiff, a\npharmacophore-conditioned diffusion model for 3D molecular generation.\nPharmaDiff employs a transformer-based architecture to integrate an atom-based\nrepresentation of the 3D pharmacophore into the generative process, enabling\nthe precise generation of 3D molecular graphs that align with predefined\npharmacophore hypotheses. Through comprehensive testing, PharmaDiff\ndemonstrates superior performance in matching 3D pharmacophore constraints\ncompared to ligand-based drug design methods. Additionally, it achieves higher\ndocking scores across a range of proteins in structure-based drug design,\nwithout the need for target protein structures. By integrating pharmacophore\nmodeling with 3D generative techniques, PharmaDiff offers a powerful and\nflexible framework for rational drug design.", "published": "2025-05-15 17:54:29", "link": "http://arxiv.org/abs/2505.10545v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Learning Nonlinear Dynamics in Physical Modelling Synthesis using Neural Ordinary Differential Equations", "abstract": "Modal synthesis methods are a long-standing approach for modelling\ndistributed musical systems. In some cases extensions are possible in order to\nhandle geometric nonlinearities. One such case is the high-amplitude vibration\nof a string, where geometric nonlinear effects lead to perceptually important\neffects including pitch glides and a dependence of brightness on striking\namplitude. A modal decomposition leads to a coupled nonlinear system of\nordinary differential equations. Recent work in applied machine learning\napproaches (in particular neural ordinary differential equations) has been used\nto model lumped dynamic systems such as electronic circuits automatically from\ndata. In this work, we examine how modal decomposition can be combined with\nneural ordinary differential equations for modelling distributed musical\nsystems. The proposed model leverages the analytical solution for linear\nvibration of system's modes and employs a neural network to account for\nnonlinear dynamic behaviour. Physical parameters of a system remain easily\naccessible after the training without the need for a parameter encoder in the\nnetwork architecture. As an initial proof of concept, we generate synthetic\ndata for a nonlinear transverse string and show that the model can be trained\nto reproduce the nonlinear dynamics of the system. Sound examples are\npresented.", "published": "2025-05-15 17:17:21", "link": "http://arxiv.org/abs/2505.10511v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "primary_category": "cs.SD"}
{"title": "Batched Nonparametric Bandits via k-Nearest Neighbor UCB", "abstract": "We study sequential decision-making in batched nonparametric contextual\nbandits, where actions are selected over a finite horizon divided into a small\nnumber of batches. Motivated by constraints in domains such as medicine and\nmarketing -- where online feedback is limited -- we propose a nonparametric\nalgorithm that combines adaptive k-nearest neighbor (k-NN) regression with the\nupper confidence bound (UCB) principle. Our method, BaNk-UCB, is fully\nnonparametric, adapts to the context dimension, and is simple to implement.\nUnlike prior work relying on parametric or binning-based estimators, BaNk-UCB\nuses local geometry to estimate rewards and adaptively balances exploration and\nexploitation. We provide near-optimal regret guarantees under standard\nLipschitz smoothness and margin assumptions, using a theoretically motivated\nbatch schedule that balances regret across batches and achieves minimax-optimal\nrates. Empirical evaluations on synthetic and real-world datasets demonstrate\nthat BaNk-UCB consistently outperforms binning-based baselines.", "published": "2025-05-15 17:00:51", "link": "http://arxiv.org/abs/2505.10498v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH", "68T05, 62L05, 62G08, 68Q32", "F.2.2; I.2.6"], "primary_category": "stat.ML"}
{"title": "Fixing Incomplete Value Function Decomposition for Multi-Agent Reinforcement Learning", "abstract": "Value function decomposition methods for cooperative multi-agent\nreinforcement learning compose joint values from individual per-agent\nutilities, and train them using a joint objective. To ensure that the action\nselection process between individual utilities and joint values remains\nconsistent, it is imperative for the composition to satisfy the\nindividual-global max (IGM) property. Although satisfying IGM itself is\nstraightforward, most existing methods (e.g., VDN, QMIX) have limited\nrepresentation capabilities and are unable to represent the full class of IGM\nvalues, and the one exception that has no such limitation (QPLEX) is\nunnecessarily complex. In this work, we present a simple formulation of the\nfull class of IGM values that naturally leads to the derivation of QFIX, a\nnovel family of value function decomposition models that expand the\nrepresentation capabilities of prior models by means of a thin \"fixing\" layer.\nWe derive multiple variants of QFIX, and implement three variants in two\nwell-known multi-agent frameworks. We perform an empirical evaluation on\nmultiple SMACv2 and Overcooked environments, which confirms that QFIX (i)\nsucceeds in enhancing the performance of prior methods, (ii) learns more stably\nand performs better than its main competitor QPLEX, and (iii) achieves this\nwhile employing the simplest and smallest mixing models.", "published": "2025-05-15 16:36:18", "link": "http://arxiv.org/abs/2505.10484v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI", "abstract": "Effective communication about breast and cervical cancers remains a\npersistent health challenge, with significant gaps in public understanding of\ncancer prevention, screening, and treatment, potentially leading to delayed\ndiagnoses and inadequate treatments. This study evaluates the capabilities and\nlimitations of Large Language Models (LLMs) in generating accurate, safe, and\naccessible cancer-related information to support patient understanding. We\nevaluated five general-purpose and three medical LLMs using a mixed-methods\nevaluation framework across linguistic quality, safety and trustworthiness, and\ncommunication accessibility and affectiveness. Our approach utilized\nquantitative metrics, qualitative expert ratings, and statistical analysis\nusing Welch's ANOVA, Games-Howell, and Hedges' g. Our results show that\ngeneral-purpose LLMs produced outputs of higher linguistic quality and\naffectiveness, while medical LLMs demonstrate greater communication\naccessibility. However, medical LLMs tend to exhibit higher levels of potential\nharm, toxicity, and bias, reducing their performance in safety and\ntrustworthiness. Our findings indicate a duality between domain-specific\nknowledge and safety in health communications. The results highlight the need\nfor intentional model design with targeted improvements, particularly in\nmitigating harm and bias, and improving safety and affectiveness. This study\nprovides a comprehensive evaluation of LLMs for cancer communication, offering\ncritical insights for improving AI-generated health content and informing\nfuture development of accurate, safe, and accessible digital health tools.", "published": "2025-05-15 16:23:21", "link": "http://arxiv.org/abs/2505.10472v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FlowVAT: Normalizing Flow Variational Inference with Affine-Invariant Tempering", "abstract": "Multi-modal and high-dimensional posteriors present significant challenges\nfor variational inference, causing mode-seeking behavior and collapse despite\nthe theoretical expressiveness of normalizing flows. Traditional annealing\nmethods require temperature schedules and hyperparameter tuning, falling short\nof the goal of truly black-box variational inference. We introduce FlowVAT, a\nconditional tempering approach for normalizing flow variational inference that\naddresses these limitations. Our method tempers both the base and target\ndistributions simultaneously, maintaining affine-invariance under tempering. By\nconditioning the normalizing flow on temperature, we leverage overparameterized\nneural networks' generalization capabilities to train a single flow\nrepresenting the posterior across a range of temperatures. This preserves modes\nidentified at higher temperatures when sampling from the variational posterior\nat $T = 1$, mitigating standard variational methods' mode-seeking behavior. In\nexperiments with 2, 10, and 20 dimensional multi-modal distributions, FlowVAT\noutperforms traditional and adaptive annealing methods, finding more modes and\nachieving better ELBO values, particularly in higher dimensions where existing\napproaches fail. Our method requires minimal hyperparameter tuning and does not\nrequire an annealing schedule, advancing toward fully-automatic black-box\nvariational inference for complicated posteriors.", "published": "2025-05-15 16:20:36", "link": "http://arxiv.org/abs/2505.10466v1", "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "stat.ML"}
{"title": "Efficient MCMC Sampling with Expensive-to-Compute and Irregular Likelihoods", "abstract": "Bayesian inference with Markov Chain Monte Carlo (MCMC) is challenging when\nthe likelihood function is irregular and expensive to compute. We explore\nseveral sampling algorithms that make use of subset evaluations to reduce\ncomputational overhead. We adapt the subset samplers for this setting where\ngradient information is not available or is unreliable. To achieve this, we\nintroduce data-driven proxies in place of Taylor expansions and define a novel\ncomputation-cost aware adaptive controller. We undertake an extensive\nevaluation for a challenging disease modelling task and a configurable task\nwith similar irregularity in the likelihood surface. We find our improved\nversion of Hierarchical Importance with Nested Training Samples (HINTS), with\nadaptive proposals and a data-driven proxy, obtains the best sampling error in\na fixed computational budget. We conclude that subset evaluations can provide\ncheap and naturally-tempered exploration, while a data-driven proxy can\npre-screen proposals successfully in explored regions of the state space. These\ntwo elements combine through hierarchical delayed acceptance to achieve\nefficient, exact sampling.", "published": "2025-05-15 16:06:44", "link": "http://arxiv.org/abs/2505.10448v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Inferring entropy production in many-body systems using nonequilibrium MaxEnt", "abstract": "We propose a method for inferring entropy production (EP) in high-dimensional\nstochastic systems, including many-body systems and non-Markovian systems with\nlong memory. Standard techniques for estimating EP become intractable in such\nsystems due to computational and statistical limitations. We infer\ntrajectory-level EP and lower bounds on average EP by exploiting a\nnonequilibrium analogue of the Maximum Entropy principle, along with convex\nduality. Our approach uses only samples of trajectory observables (such as\nspatiotemporal correlation functions). It does not require reconstruction of\nhigh-dimensional probability distributions or rate matrices, nor any special\nassumptions such as discrete states or multipartite dynamics. It may be used to\ncompute a hierarchical decomposition of EP, reflecting contributions from\ndifferent kinds of interactions, and it has an intuitive physical\ninterpretation as a thermodynamic uncertainty relation. We demonstrate its\nnumerical performance on a disordered nonequilibrium spin model with 1000 spins\nand a large neural spike-train dataset.", "published": "2025-05-15 16:05:50", "link": "http://arxiv.org/abs/2505.10444v1", "categories": ["cond-mat.stat-mech", "cs.LG", "nlin.AO", "q-bio.NC"], "primary_category": "cond-mat.stat-mech"}
{"title": "Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model", "abstract": "Gas turbine engines represent complex highly nonlinear dynamical systems.\nDeriving their physics-based models can be challenging as it requires\nperformance characteristics, that are not always available, and one often has\nto make many simplifying assumptions. In this paper, the limitations of\nconventional experimental methods used to derive component-level and locally\nlinear parameter-varying models are discussed and addressed by employing\nidentification techniques based on data collected from standard engine\noperation under closed-loop control. The rotor dynamics were estimated using\nthe sparse identification of nonlinear dynamics. Subsequently, the autonomous\npart of the dynamics was mapped into an optimally constructed Koopman\neigenfunction space. The process included eigenvalue optimization using\nmetaheuristic algorithms and temporal projection, followed by gradient-based\neigenfunction identification. The resulting Koopman model was validated against\nan in-house reference component-level model. A globally optimal nonlinear\nfeedback controller and a Kalman estimator were then designed in the\neigenfunction space and compared to the classical and gain-scheduled\nproportional-integral controllers, as well as a proposed internal model control\napproach. The eigenmode structure allowed targeting individual modes during the\noptimization process, resulting in a better performance tuning. The results\nshowed that the Koopman-based controller outperformed the other benchmark\ncontrollers in both reference tracking and disturbance rejection, under\nsea-level and varying flight conditions, due to its global nature.", "published": "2025-05-15 15:55:13", "link": "http://arxiv.org/abs/2505.10438v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Score-based diffusion nowcasting of GOES imagery", "abstract": "Clouds and precipitation are important for understanding weather and climate.\nSimulating clouds and precipitation with traditional numerical weather\nprediction is challenging because of the sub-grid parameterizations required.\nMachine learning has been explored for forecasting clouds and precipitation,\nbut early machine learning methods often created blurry forecasts. In this\npaper we explore a newer method, named score-based diffusion, to nowcast (zero\nto three hour forecast) clouds and precipitation. We discuss the background and\nintuition of score-based diffusion models - thus providing a starting point for\nthe community - while exploring the methodology's use for nowcasting\ngeostationary infrared imagery. We experiment with three main types of\ndiffusion models: a standard score-based diffusion model (Diff); a residual\ncorrection diffusion model (CorrDiff); and a latent diffusion model (LDM). Our\nresults show that the diffusion models are able to not only advect existing\nclouds, but also generate and decay clouds, including convective initiation.\nThese results are surprising because the forecasts are initiated with only the\npast 20 mins of infrared satellite imagery. A case study qualitatively shows\nthe preservation of high resolution features longer into the forecast than a\nconventional mean-squared error trained U-Net. The best of the three diffusion\nmodels tested was the CorrDiff approach, outperforming all other diffusion\nmodels, the traditional U-Net, and a persistence forecast by one to two kelvin\non root mean squared error. The diffusion models also enable out-of-the-box\nensemble generation, which shows skillful calibration, with the spread of the\nensemble correlating well to the error.", "published": "2025-05-15 15:51:41", "link": "http://arxiv.org/abs/2505.10432v1", "categories": ["cs.LG", "physics.ao-ph"], "primary_category": "cs.LG"}
{"title": "Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs", "abstract": "Large language models (LLMs) excel at complex tasks thanks to advances in\nreasoning abilities. However, existing methods overlook the trade-off between\nreasoning effectiveness and computational efficiency, often encouraging\nunnecessarily long reasoning chains and wasting tokens. To address this, we\npropose Learning to Think (L2T), an information-theoretic reinforcement\nfine-tuning framework for LLMs to make the models achieve optimal reasoning\nwith fewer tokens. Specifically, L2T treats each query-response interaction as\na hierarchical session of multiple episodes and proposes a universal dense\nprocess reward, i.e., quantifies the episode-wise information gain in\nparameters, requiring no extra annotations or task-specific evaluators. We\npropose a method to quickly estimate this reward based on PAC-Bayes bounds and\nthe Fisher information matrix. Theoretical analyses show that it significantly\nreduces computational complexity with high estimation accuracy. By immediately\nrewarding each episode's contribution and penalizing excessive updates, L2T\noptimizes the model via reinforcement learning to maximize the use of each\nepisode and achieve effective updates. Empirical results on various reasoning\nbenchmarks and base models demonstrate the advantage of L2T across different\ntasks, boosting both reasoning effectiveness and efficiency.", "published": "2025-05-15 15:40:25", "link": "http://arxiv.org/abs/2505.10425v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "The Power of Random Features and the Limits of Distribution-Free Gradient Descent", "abstract": "We study the relationship between gradient-based optimization of parametric\nmodels (e.g., neural networks) and optimization of linear combinations of\nrandom features. Our main result shows that if a parametric model can be\nlearned using mini-batch stochastic gradient descent (bSGD) without making\nassumptions about the data distribution, then with high probability, the target\nfunction can also be approximated using a polynomial-sized combination of\nrandom features. The size of this combination depends on the number of gradient\nsteps and numerical precision used in the bSGD process. This finding reveals\nfundamental limitations of distribution-free learning in neural networks\ntrained by gradient descent, highlighting why making assumptions about data\ndistributions is often crucial in practice. Along the way, we also introduce a\nnew theoretical framework called average probabilistic dimension complexity\n(adc), which extends the probabilistic dimension complexity developed by Kamath\net al. (2020). We prove that adc has a polynomial relationship with statistical\nquery dimension, and use this relationship to demonstrate an infinite\nseparation between adc and standard dimension complexity.", "published": "2025-05-15 15:39:28", "link": "http://arxiv.org/abs/2505.10423v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Decomposed Inductive Procedure Learning: Learning Academic Tasks with Human-Like Data Efficiency", "abstract": "Human learning relies on specialization -- distinct cognitive mechanisms\nworking together to enable rapid learning. In contrast, most modern neural\nnetworks rely on a single mechanism: gradient descent over an objective\nfunction. This raises the question: might human learners' relatively rapid\nlearning from just tens of examples instead of tens of thousands in data-driven\ndeep learning arise from our ability to use multiple specialized mechanisms of\nlearning in combination? We investigate this question through an ablation\nanalysis of inductive human learning simulations in online tutoring\nenvironments. Comparing reinforcement learning to a more data-efficient\n3-mechanism symbolic rule induction approach, we find that decomposing learning\ninto multiple distinct mechanisms significantly improves data efficiency,\nbringing it in line with human learning. Furthermore, we show that this\ndecomposition has a greater impact on efficiency than the distinction between\nsymbolic and subsymbolic learning alone. Efforts to align data-driven machine\nlearning with human learning often overlook the stark difference in learning\nefficiency. Our findings suggest that integrating multiple specialized learning\nmechanisms may be key to bridging this gap.", "published": "2025-05-15 15:39:09", "link": "http://arxiv.org/abs/2505.10422v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Two-Stage Generative Model for Intracranial Aneurysm Meshes with Morphological Marker Conditioning", "abstract": "A generative model for the mesh geometry of intracranial aneurysms (IA) is\ncrucial for training networks to predict blood flow forces in real time, which\nis a key factor affecting disease progression. This need is necessitated by the\nabsence of a large IA image datasets. Existing shape generation methods\nstruggle to capture realistic IA features and ignore the relationship between\nIA pouches and parent vessels, limiting physiological realism and their\ngeneration cannot be controlled to have specific morphological measurements. We\npropose AneuG, a two-stage Variational Autoencoder (VAE)-based IA mesh\ngenerator. In the first stage, AneuG generates low-dimensional Graph Harmonic\nDeformation (GHD) tokens to encode and reconstruct aneurysm pouch shapes,\nconstrained to morphing energy statistics truths. GHD enables more accurate\nshape encoding than alternatives. In the second stage, AneuG generates parent\nvessels conditioned on GHD tokens, by generating vascular centreline and\npropagating the cross-section. AneuG's IA shape generation can further be\nconditioned to have specific clinically relevant morphological measurements.\nThis is useful for studies to understand shape variations represented by\nclinical measurements, and for flow simulation studies to understand effects of\nspecific clinical shape parameters on fluid dynamics. Source code and\nimplementation details are available at\nhttps://github.com/anonymousaneug/AneuG.", "published": "2025-05-15 15:30:41", "link": "http://arxiv.org/abs/2505.10407v1", "categories": ["cs.LG", "68T07"], "primary_category": "cs.LG"}
{"title": "AutoCam: Hierarchical Path Planning for an Autonomous Auxiliary Camera in Surgical Robotics", "abstract": "Incorporating an autonomous auxiliary camera into robot-assisted minimally\ninvasive surgery (RAMIS) enhances spatial awareness and eliminates manual\nviewpoint control. Existing path planning methods for auxiliary cameras track\ntwo-dimensional surgical features but do not simultaneously account for camera\norientation, workspace constraints, and robot joint limits. This study presents\nAutoCam: an automatic auxiliary camera placement method to improve\nvisualization in RAMIS. Implemented on the da Vinci Research Kit, the system\nuses a priority-based, workspace-constrained control algorithm that combines\nheuristic geometric placement with nonlinear optimization to ensure robust\ncamera tracking. A user study (N=6) demonstrated that the system maintained\n99.84% visibility of a salient feature and achieved a pose error of 4.36 $\\pm$\n2.11 degrees and 1.95 $\\pm$ 5.66 mm. The controller was computationally\nefficient, with a loop time of 6.8 $\\pm$ 12.8 ms. An additional pilot study\n(N=6), where novices completed a Fundamentals of Laparoscopic Surgery training\ntask, suggests that users can teleoperate just as effectively from AutoCam's\nviewpoint as from the endoscope's while still benefiting from AutoCam's\nimproved visual coverage of the scene. These results indicate that an auxiliary\ncamera can be autonomously controlled using the da Vinci patient-side\nmanipulators to track a salient feature, laying the groundwork for new\nmulti-camera visualization methods in RAMIS.", "published": "2025-05-15 15:21:46", "link": "http://arxiv.org/abs/2505.10398v1", "categories": ["cs.RO", "cs.HC", "cs.LG", "cs.SY", "eess.SP", "eess.SY", "J.3.2; J.2.7; I.2.9"], "primary_category": "cs.RO"}
{"title": "A Hybrid Strategy for Aggregated Probabilistic Forecasting and Energy Trading in HEFTCom2024", "abstract": "Obtaining accurate probabilistic energy forecasts and making effective\ndecisions amid diverse uncertainties are routine challenges in future energy\nsystems. This paper presents the solution of team GEB, which ranked 3rd in\ntrading, 4th in forecasting, and 1st among student teams in the IEEE Hybrid\nEnergy Forecasting and Trading Competition 2024 (HEFTCom2024). The solution\nprovides accurate probabilistic forecasts for a wind-solar hybrid system, and\nachieves substantial trading revenue in the day-ahead electricity market. Key\ncomponents include: (1) a stacking-based approach combining sister forecasts\nfrom various Numerical Weather Predictions (NWPs) to provide wind power\nforecasts, (2) an online solar post-processing model to address the\ndistribution shift in the online test set caused by increased solar capacity,\n(3) a probabilistic aggregation method for accurate quantile forecasts of\nhybrid generation, and (4) a stochastic trading strategy to maximize expected\ntrading revenue considering uncertainties in electricity prices. This paper\nalso explores the potential of end-to-end learning to further enhance the\ntrading revenue by adjusting the distribution of forecast errors. Detailed case\nstudies are provided to validate the effectiveness of these proposed methods.\nCode for all mentioned methods is available for reproduction and further\nresearch in both industry and academia.", "published": "2025-05-15 14:55:11", "link": "http://arxiv.org/abs/2505.10367v1", "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "eess.SY"}
{"title": "An Introduction to Discrete Variational Autoencoders", "abstract": "Variational Autoencoders (VAEs) are well-established as a principled approach\nto probabilistic unsupervised learning with neural networks. Typically, an\nencoder network defines the parameters of a Gaussian distributed latent space\nfrom which we can sample and pass realizations to a decoder network. This model\nis trained to reconstruct its inputs and is optimized through the evidence\nlower bound. In recent years, discrete latent spaces have grown in popularity,\nsuggesting that they may be a natural choice for many data modalities (e.g.\ntext). In this tutorial, we provide a rigorous, yet practical, introduction to\ndiscrete variational autoencoders -- specifically, VAEs in which the latent\nspace is made up of latent variables that follow a categorical distribution. We\nassume only a basic mathematical background with which we carefully derive each\nstep from first principles. From there, we develop a concrete training recipe\nand provide an example implementation, hosted at\nhttps://github.com/alanjeffares/discreteVAE.", "published": "2025-05-15 14:33:31", "link": "http://arxiv.org/abs/2505.10344v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Representation Learning Approach to Feature Drift Detection in Wireless Networks", "abstract": "AI is foreseen to be a centerpiece in next generation wireless networks\nenabling enabling ubiquitous communication as well as new services. However, in\nreal deployment, feature distribution changes may degrade the performance of AI\nmodels and lead to undesired behaviors. To counter for undetected model\ndegradation, we propose ALERT; a method that can detect feature distribution\nchanges and trigger model re-training that works well on two wireless network\nuse cases: wireless fingerprinting and link anomaly detection. ALERT includes\nthree components: representation learning, statistical testing and utility\nassessment. We rely on MLP for designing the representation learning component,\non Kolmogorov-Smirnov and Population Stability Index tests for designing the\nstatistical testing and a new function for utility assessment. We show the\nsuperiority of the proposed method against ten standard drift detection methods\navailable in the literature on two wireless network use cases.", "published": "2025-05-15 14:08:00", "link": "http://arxiv.org/abs/2505.10325v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework", "abstract": "Decentralized optimization has become vital for leveraging distributed data\nwithout central control, enhancing scalability and privacy. However, practical\ndeployments face fundamental challenges due to heterogeneous computation speeds\nand unpredictable communication delays. This paper introduces a refined model\nof Asynchronous Decentralized Stochastic Gradient Descent (ADSGD) under\npractical assumptions of bounded computation and communication times. To\nunderstand the convergence of ADSGD, we first analyze Asynchronous Stochastic\nBlock Coordinate Descent (ASBCD) as a tool, and then show that ADSGD converges\nunder computation-delay-independent step sizes. The convergence result is\nestablished without assuming bounded data heterogeneity. Empirical experiments\nreveal that ADSGD outperforms existing methods in wall-clock convergence time\nacross various scenarios. With its simplicity, efficiency in memory and\ncommunication, and resilience to communication and computation delays, ADSGD is\nwell-suited for real-world decentralized learning tasks.", "published": "2025-05-15 14:06:38", "link": "http://arxiv.org/abs/2505.10322v1", "categories": ["cs.LG", "math.OC"], "primary_category": "cs.LG"}
{"title": "Deconstructing Subset Construction -- Reducing While Determinizing", "abstract": "We present a novel perspective on the NFA canonization problem, which\nintroduces intermediate minimization steps to reduce the exploration space\non-the-fly. Essential to our approach are so-called equivalence registries\nwhich manage information about equivalent states and allow for incorporating\nfurther optimization techniques such as convexity closures or simulation to\nboost performance. Due to the generality of our approach, these concepts can be\nembedded in classic subset construction or Brzozowski's approach. We evaluate\nour approach on a set of real-world examples from automatic sequences and\nobserve that we are able to improve especially worst-case scenarios. We\nimplement our approach in an open-source library for users to experiment with.", "published": "2025-05-15 14:04:02", "link": "http://arxiv.org/abs/2505.10319v1", "categories": ["cs.FL", "cs.LG"], "primary_category": "cs.FL"}
{"title": "Negative Metric Learning for Graphs", "abstract": "Graph contrastive learning (GCL) often suffers from false negatives, which\ndegrades the performance on downstream tasks. The existing methods addressing\nthe false negative issue usually rely on human prior knowledge, still leading\nGCL to suboptimal results. In this paper, we propose a novel Negative Metric\nLearning (NML) enhanced GCL (NML-GCL). NML-GCL employs a learnable Negative\nMetric Network (NMN) to build a negative metric space, in which false negatives\ncan be distinguished better from true negatives based on their distance to\nanchor node. To overcome the lack of explicit supervision signals for NML, we\npropose a joint training scheme with bi-level optimization objective, which\nimplicitly utilizes the self-supervision signals to iteratively optimize the\nencoder and the negative metric network. The solid theoretical analysis and the\nextensive experiments conducted on widely used benchmarks verify the\nsuperiority of the proposed method.", "published": "2025-05-15 13:53:48", "link": "http://arxiv.org/abs/2505.10307v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Optimizing Electric Bus Charging Scheduling with Uncertainties Using Hierarchical Deep Reinforcement Learning", "abstract": "The growing adoption of Electric Buses (EBs) represents a significant step\ntoward sustainable development. By utilizing Internet of Things (IoT) systems,\ncharging stations can autonomously determine charging schedules based on\nreal-time data. However, optimizing EB charging schedules remains a critical\nchallenge due to uncertainties in travel time, energy consumption, and\nfluctuating electricity prices. Moreover, to address real-world complexities,\ncharging policies must make decisions efficiently across multiple time scales\nand remain scalable for large EB fleets. In this paper, we propose a\nHierarchical Deep Reinforcement Learning (HDRL) approach that reformulates the\noriginal Markov Decision Process (MDP) into two augmented MDPs. To solve these\nMDPs and enable multi-timescale decision-making, we introduce a novel HDRL\nalgorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization\nEnhancement (DAC-MAPPO-E). Scalability challenges of the Double Actor-Critic\n(DAC) algorithm for large-scale EB fleets are addressed through enhancements at\nboth decision levels. At the high level, we redesign the decentralized actor\nnetwork and integrate an attention mechanism to extract relevant global state\ninformation for each EB, decreasing the size of neural networks. At the low\nlevel, the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm is\nincorporated into the DAC framework, enabling decentralized and coordinated\ncharging power decisions, reducing computational complexity and enhancing\nconvergence speed. Extensive experiments with real-world data demonstrate the\nsuperior performance and scalability of DAC-MAPPO-E in optimizing EB fleet\ncharging schedules.", "published": "2025-05-15 13:44:27", "link": "http://arxiv.org/abs/2505.10296v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Estimating the number of household TV profiles based in customer behaviour using Gaussian mixture model averaging", "abstract": "TV customers today face many choices from many live channels and on-demand\nservices. Providing a personalised experience that saves customers time when\ndiscovering content is essential for TV providers. However, a reliable\nunderstanding of their behaviour and preferences is key. When creating\npersonalised recommendations for TV, the biggest challenge is understanding\nviewing behaviour within households when multiple people are watching. The\nobjective is to detect and combine individual profiles to make\nbetter-personalised recommendations for group viewing. Our challenge is that we\nhave little explicit information about who is watching the devices at any time\n(individuals or groups). Also, we do not have a way to combine more than one\nindividual profile to make better recommendations for group viewing. We propose\na novel framework using a Gaussian mixture model averaging to obtain point\nestimates for the number of household TV profiles and a Bayesian random walk\nmodel to introduce uncertainty. We applied our approach using data from real\ncustomers whose TV-watching data totalled approximately half a million\nobservations. Our results indicate that combining our framework with the\nselected features provides a means to estimate the number of household TV\nprofiles and their characteristics, including shifts over time and\nquantification of uncertainty.", "published": "2025-05-15 13:27:32", "link": "http://arxiv.org/abs/2505.10279v1", "categories": ["stat.ME", "cs.LG"], "primary_category": "stat.ME"}
{"title": "Spike-timing-dependent Hebbian learning as noisy gradient descent", "abstract": "Hebbian learning is a key principle underlying learning in biological neural\nnetworks. It postulates that synaptic changes occur locally, depending on the\nactivities of pre- and postsynaptic neurons. While Hebbian learning based on\nneuronal firing rates is well explored, much less is known about learning rules\nthat account for precise spike-timing. We relate a Hebbian\nspike-timing-dependent plasticity rule to noisy gradient descent with respect\nto a natural loss function on the probability simplex. This connection allows\nus to prove that the learning rule eventually identifies the presynaptic neuron\nwith the highest activity. We also discover an intrinsic connection to noisy\nmirror descent.", "published": "2025-05-15 13:23:16", "link": "http://arxiv.org/abs/2505.10272v1", "categories": ["cs.LG", "math.ST", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Electric Bus Charging Schedules Relying on Real Data-Driven Targets Based on Hierarchical Deep Reinforcement Learning", "abstract": "The charging scheduling problem of Electric Buses (EBs) is investigated based\non Deep Reinforcement Learning (DRL). A Markov Decision Process (MDP) is\nconceived, where the time horizon includes multiple charging and operating\nperiods in a day, while each period is further divided into multiple time\nsteps. To overcome the challenge of long-range multi-phase planning with sparse\nreward, we conceive Hierarchical DRL (HDRL) for decoupling the original MDP\ninto a high-level Semi-MDP (SMDP) and multiple low-level MDPs. The Hierarchical\nDouble Deep Q-Network (HDDQN)-Hindsight Experience Replay (HER) algorithm is\nproposed for simultaneously solving the decision problems arising at different\ntemporal resolutions. As a result, the high-level agent learns an effective\npolicy for prescribing the charging targets for every charging period, while\nthe low-level agent learns an optimal policy for setting the charging power of\nevery time step within a single charging period, with the aim of minimizing the\ncharging costs while meeting the charging target. It is proved that the flat\npolicy constructed by superimposing the optimal high-level policy and the\noptimal low-level policy performs as well as the optimal policy of the original\nMDP. Since jointly learning both levels of policies is challenging due to the\nnon-stationarity of the high-level agent and the sampling inefficiency of the\nlow-level agent, we divide the joint learning process into two phases and\nexploit our new HER algorithm to manipulate the experience replay buffers for\nboth levels of agents. Numerical experiments are performed with the aid of\nreal-world data to evaluate the performance of the proposed algorithm.", "published": "2025-05-15 13:13:41", "link": "http://arxiv.org/abs/2505.10262v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices", "abstract": "Efficient LLM inference on resource-constrained devices presents significant\nchallenges in compute and memory utilization. Due to limited GPU memory,\nexisting systems offload model weights to CPU memory, incurring substantial I/O\noverhead between the CPU and GPU. This leads to two major inefficiencies: (1)\nGPU cores are underutilized, often remaining idle while waiting for data to be\nloaded; and (2) GPU memory has low impact on performance, as reducing its\ncapacity has minimal effect on overall throughput.In this paper, we propose\nSpecOffload, a high-throughput inference engine that embeds speculative\ndecoding into offloading. Our key idea is to unlock latent GPU resources for\nstoring and executing a draft model used for speculative decoding, thus\naccelerating inference at near-zero additional cost. To support this, we\ncarefully orchestrate the interleaved execution of target and draft models in\nspeculative decoding within the offloading pipeline, and propose a planner to\nmanage tensor placement and select optimal parameters. Compared to the best\nbaseline, SpecOffload improves GPU core utilization by 4.49x and boosts\ninference throughput by 2.54x. Our code is available at\nhttps://github.com/MobiSense/SpecOffload .", "published": "2025-05-15 13:10:31", "link": "http://arxiv.org/abs/2505.10259v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting", "abstract": "With the widespread adoption of Large Language Models (LLMs), there is a\ngrowing need to establish best practices for leveraging their capabilities\nbeyond traditional natural language tasks. In this paper, a novel cross-domain\nknowledge transfer framework is proposed to enhance the performance of LLMs in\ntime series forecasting -- a task of increasing relevance in fields such as\nenergy systems, finance, and healthcare. The approach systematically infuses\nLLMs with structured temporal information to improve their forecasting\naccuracy. This study evaluates the proposed method on a real-world time series\ndataset and compares it to a naive baseline where the LLM receives no auxiliary\ninformation. Results show that knowledge-informed forecasting significantly\noutperforms the uninformed baseline in terms of predictive accuracy and\ngeneralization. These findings highlight the potential of knowledge transfer\nstrategies to bridge the gap between LLMs and domain-specific forecasting\ntasks.", "published": "2025-05-15 12:17:52", "link": "http://arxiv.org/abs/2505.10213v1", "categories": ["cs.LG", "stat.AP"], "primary_category": "cs.LG"}
{"title": "A multi-head deep fusion model for recognition of cattle foraging events using sound and movement signals", "abstract": "Monitoring feeding behaviour is a relevant task for efficient herd management\nand the effective use of available resources in grazing cattle. The ability to\nautomatically recognise animals' feeding activities through the identification\nof specific jaw movements allows for the improvement of diet formulation, as\nwell as early detection of metabolic problems and symptoms of animal\ndiscomfort, among other benefits. The use of sensors to obtain signals for such\nmonitoring has become popular in the last two decades. The most frequently\nemployed sensors include accelerometers, microphones, and cameras, each with\nits own set of advantages and drawbacks. An unexplored aspect is the\nsimultaneous use of multiple sensors with the aim of combining signals in order\nto enhance the precision of the estimations. In this direction, this work\nintroduces a deep neural network based on the fusion of acoustic and inertial\nsignals, composed of convolutional, recurrent, and dense layers. The main\nadvantage of this model is the combination of signals through the automatic\nextraction of features independently from each of them. The model has emerged\nfrom an exploration and comparison of different neural network architectures\nproposed in this work, which carry out information fusion at different levels.\nFeature-level fusion has outperformed data and decision-level fusion by at\nleast a 0.14 based on the F1-score metric. Moreover, a comparison with\nstate-of-the-art machine learning methods is presented, including traditional\nand deep learning approaches. The proposed model yielded an F1-score value of\n0.802, representing a 14% increase compared to previous methods. Finally,\nresults from an ablation study and post-training quantization evaluation are\nalso reported.", "published": "2025-05-15 11:55:16", "link": "http://arxiv.org/abs/2505.10198v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Defect Detection in Photolithographic Patterns Using Deep Learning Models Trained on Synthetic Data", "abstract": "In the photolithographic process vital to semiconductor manufacturing,\nvarious types of defects appear during EUV pattering. Due to ever-shrinking\npattern size, these defects are extremely small and cause false or missed\ndetection during inspection. Specifically, the lack of defect-annotated quality\ndata with good representation of smaller defects has prohibited deployment of\ndeep learning based defect detection models in fabrication lines. To resolve\nthe problem of data unavailability, we artificially generate scanning electron\nmicroscopy (SEM) images of line patterns with known distribution of defects and\nautonomously annotate them. We then employ state-of-the-art object detection\nmodels to investigate defect detection performance as a function of defect\nsize, much smaller than the pitch width. We find that the real-time object\ndetector YOLOv8 has the best mean average precision of 96% as compared to\nEfficientNet, 83%, and SSD, 77%, with the ability to detect smaller defects. We\nreport the smallest defect size that can be detected reliably. When tested on\nreal SEM data, the YOLOv8 model correctly detected 84.6% of Bridge defects and\n78.3% of Break defects across all relevant instances. These promising results\nsuggest that synthetic data can be used as an alternative to real-world data in\norder to develop robust machine-learning models.", "published": "2025-05-15 11:50:02", "link": "http://arxiv.org/abs/2505.10192v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "One-Stage Top-$k$ Learning-to-Defer: Score-Based Surrogates with Theoretical Guarantees", "abstract": "We introduce the first one-stage Top-$k$ Learning-to-Defer framework, which\nunifies prediction and deferral by learning a shared score-based model that\nselects the $k$ most cost-effective entities-labels or experts-per input. While\nexisting one-stage L2D methods are limited to deferring to a single expert, our\napproach jointly optimizes prediction and deferral across multiple entities\nthrough a single end-to-end objective. We define a cost-sensitive loss and\nderive a novel convex surrogate that is independent of the cardinality\nparameter $k$, enabling generalization across Top-$k$ regimes without\nretraining. Our formulation recovers the Top-1 deferral policy of prior\nscore-based methods as a special case, and we prove that our surrogate is both\nBayes-consistent and $\\mathcal{H}$-consistent under mild assumptions. We\nfurther introduce an adaptive variant, Top-$k(x)$, which dynamically selects\nthe number of consulted entities per input to balance predictive accuracy and\nconsultation cost. Experiments on CIFAR-10 and SVHN confirm that our one-stage\nTop-$k$ method strictly outperforms Top-1 deferral, while Top-$k(x)$ achieves\nsuperior accuracy-cost trade-offs by tailoring allocations to input complexity.", "published": "2025-05-15 10:41:16", "link": "http://arxiv.org/abs/2505.10160v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Near Optimal Best Arm Identification for Clustered Bandits", "abstract": "This work investigates the problem of best arm identification for multi-agent\nmulti-armed bandits. We consider $N$ agents grouped into $M$ clusters, where\neach cluster solves a stochastic bandit problem. The mapping between agents and\nbandits is a priori unknown. Each bandit is associated with $K$ arms, and the\ngoal is to identify the best arm for each agent under a $\\delta$-probably\ncorrect ($\\delta$-PC) framework, while minimizing sample complexity and\ncommunication overhead.\n  We propose two novel algorithms: Clustering then Best Arm Identification\n(Cl-BAI) and Best Arm Identification then Clustering (BAI-Cl). Cl-BAI uses a\ntwo-phase approach that first clusters agents based on the bandit problems they\nare learning, followed by identifying the best arm for each cluster. BAI-Cl\nreverses the sequence by identifying the best arms first and then clustering\nagents accordingly. Both algorithms leverage the successive elimination\nframework to ensure computational efficiency and high accuracy.\n  We establish $\\delta$-PC guarantees for both methods, derive bounds on their\nsample complexity, and provide a lower bound for this problem class. Moreover,\nwhen $M$ is small (a constant), we show that the sample complexity of a variant\nof BAI-Cl is minimax optimal in an order-wise sense. Experiments on synthetic\nand real-world datasets (MovieLens, Yelp) demonstrate the superior performance\nof the proposed algorithms in terms of sample and communication efficiency,\nparticularly in settings where $M \\ll N$.", "published": "2025-05-15 10:20:26", "link": "http://arxiv.org/abs/2505.10147v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Path Gradients after Flow Matching", "abstract": "Boltzmann Generators have emerged as a promising machine learning tool for\ngenerating samples from equilibrium distributions of molecular systems using\nNormalizing Flows and importance weighting. Recently, Flow Matching has helped\nspeed up Continuous Normalizing Flows (CNFs), scale them to more complex\nmolecular systems, and minimize the length of the flow integration\ntrajectories. We investigate the benefits of using path gradients to fine-tune\nCNFs initially trained by Flow Matching, in the setting where a target energy\nis known. Our experiments show that this hybrid approach yields up to a\nthreefold increase in sampling efficiency for molecular systems, all while\nusing the same model, a similar computational budget and without the need for\nadditional sampling. Furthermore, by measuring the length of the flow\ntrajectories during fine-tuning, we show that path gradients largely preserve\nthe learned structure of the flow.", "published": "2025-05-15 10:13:45", "link": "http://arxiv.org/abs/2505.10139v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning", "abstract": "Federated learning enables the clients to collaboratively train a global\nmodel, which is aggregated from local models. Due to the heterogeneous data\ndistributions over clients and data privacy in federated learning, it is\ndifficult to train local models to achieve a well-performed global model. In\nthis paper, we introduce the adaptability of local models, i.e., the average\nperformance of local models on data distributions over clients, and enhance the\nperformance of the global model by improving the adaptability of local models.\nSince each client does not know the data distributions over other clients, the\nadaptability of the local model cannot be directly optimized. First, we provide\nthe property of an appropriate local model which has good adaptability on the\ndata distributions over clients. Then, we formalize the property into the local\ntraining objective with a constraint and propose a feasible solution to train\nthe local model. Extensive experiments on federated learning benchmarks\ndemonstrate that our method significantly improves the adaptability of local\nmodels and achieves a well-performed global model that consistently outperforms\nthe baseline methods.", "published": "2025-05-15 09:51:47", "link": "http://arxiv.org/abs/2505.10125v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "A Scalable Gradient-Based Optimization Framework for Sparse Minimum-Variance Portfolio Selection", "abstract": "Portfolio optimization involves selecting asset weights to minimize a\nrisk-reward objective, such as the portfolio variance in the classical\nminimum-variance framework. Sparse portfolio selection extends this by imposing\na cardinality constraint: only $k$ assets from a universe of $p$ may be\nincluded. The standard approach models this problem as a mixed-integer\nquadratic program and relies on commercial solvers to find the optimal\nsolution. However, the computational costs of such methods increase\nexponentially with $k$ and $p$, making them too slow for problems of even\nmoderate size. We propose a fast and scalable gradient-based approach that\ntransforms the combinatorial sparse selection problem into a constrained\ncontinuous optimization task via Boolean relaxation, while preserving\nequivalence with the original problem on the set of binary points. Our\nalgorithm employs a tunable parameter that transmutes the auxiliary objective\nfrom a convex to a concave function. This allows a stable convex starting\npoint, followed by a controlled path toward a sparse binary solution as the\ntuning parameter increases and the objective moves toward concavity. In\npractice, our method matches commercial solvers in asset selection for most\ninstances and, in rare instances, the solution differs by a few assets whilst\nshowing a negligible error in portfolio variance.", "published": "2025-05-15 09:01:07", "link": "http://arxiv.org/abs/2505.10099v1", "categories": ["stat.ML", "cs.LG", "math.OC", "q-fin.PM"], "primary_category": "stat.ML"}
{"title": "ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data", "abstract": "Conventional forecasting methods rely on unimodal time series data, limiting\ntheir ability to exploit rich textual information. Recently, large language\nmodels (LLMs) and time series foundation models (TSFMs) have demonstrated\npowerful capability in textual reasoning and temporal modeling, respectively.\nIntegrating the strengths of both to construct a multimodal model that\nconcurrently leverages both temporal and textual information for future\ninference has emerged as a critical research challenge. To address the scarcity\nof event-series paired data, we propose a decoupled framework: an LLM is\nemployed to transform textual events into revision instructions, which are then\nused to steer the output of TSFM. To implement this framework, we introduce\nChronoSteer, a multimodal TSFM that can be steered through textual revision\ninstructions, effectively bridging LLM and TSFM. Moreover, to mitigate the\nshortage of cross-modal instruction-series paired data, we devise a two-stage\ntraining strategy based on synthetic data. In addition, we also construct a\nhigh-quality multimodal time series forecasting benchmark to address the\ninformation leakage concerns during evaluation. After integrating with an LLM,\nChronoSteer, which is trained exclusively on synthetic data, achieves a 25.7%\nimprovement in prediction accuracy compared to the unimodal backbone and a\n22.5% gain over the previous state-of-the-art multimodal method.", "published": "2025-05-15 08:37:23", "link": "http://arxiv.org/abs/2505.10083v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Role of scrambling and noise in temporal information processing with quantum systems", "abstract": "Scrambling quantum systems have been demonstrated as effective substrates for\ntemporal information processing. While their role in providing rich feature\nmaps has been widely studied, a theoretical understanding of their performance\nin temporal tasks is still lacking. Here we consider a general quantum\nreservoir processing framework that captures a broad range of physical\ncomputing models with quantum systems. We examine the scalability and memory\nretention of the model with scrambling reservoirs modelled by high-order\nunitary designs in both noiseless and noisy settings. In the former regime, we\nshow that measurement readouts become exponentially concentrated with\nincreasing reservoir size, yet strikingly do not worsen with the reservoir\niterations. Thus, while repeatedly reusing a small scrambling reservoir with\nquantum data might be viable, scaling up the problem size deteriorates\ngeneralization unless one can afford an exponential shot overhead. In contrast,\nthe memory of early inputs and initial states decays exponentially in both\nreservoir size and reservoir iterations. In the noisy regime, we also prove\nexponential memory decays with iterations for local noisy channels. Proving\nthese results required us to introduce new proof techniques for bounding\nconcentration in temporal quantum learning models.", "published": "2025-05-15 08:35:10", "link": "http://arxiv.org/abs/2505.10080v1", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.LG", "cs.NE", "stat.ML"], "primary_category": "quant-ph"}
{"title": "JointDistill: Adaptive Multi-Task Distillation for Joint Depth Estimation and Scene Segmentation", "abstract": "Depth estimation and scene segmentation are two important tasks in\nintelligent transportation systems. A joint modeling of these two tasks will\nreduce the requirement for both the storage and training efforts. This work\nexplores how the multi-task distillation could be used to improve such unified\nmodeling. While existing solutions transfer multiple teachers' knowledge in a\nstatic way, we propose a self-adaptive distillation method that can dynamically\nadjust the knowledge amount from each teacher according to the student's\ncurrent learning ability. Furthermore, as multiple teachers exist, the\nstudent's gradient update direction in the distillation is more prone to be\nerroneous where knowledge forgetting may occur. To avoid this, we propose a\nknowledge trajectory to record the most essential information that a model has\nlearnt in the past, based on which a trajectory-based distillation loss is\ndesigned to guide the student to follow the learning curve similarly in a\ncost-effective way. We evaluate our method on multiple benchmarking datasets\nincluding Cityscapes and NYU-v2. Compared to the state-of-the-art solutions,\nour method achieves a clearly improvement. The code is provided in the\nsupplementary materials.", "published": "2025-05-15 08:00:48", "link": "http://arxiv.org/abs/2505.10057v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning", "abstract": "Graph Neural Networks (GNN) endure catastrophic forgetting, undermining their\ncapacity to preserve previously acquired knowledge amid the assimilation of\nnovel information. Rehearsal-based techniques revisit historical examples,\nadopted as a principal strategy to alleviate this phenomenon. However, memory\nexplosion and privacy infringements impose significant constraints on their\nutility. Non-Exemplar methods circumvent the prior issues through Prototype\nReplay (PR), yet feature drift presents new challenges. In this paper, our\nempirical findings reveal that Prototype Contrastive Learning (PCL) exhibits\nless pronounced drift than conventional PR. Drawing upon PCL, we propose\nInstance-Prototype Affinity Learning (IPAL), a novel paradigm for Non-Exemplar\nContinual Graph Learning (NECGL). Exploiting graph structural information, we\nformulate Topology-Integrated Gaussian Prototypes (TIGP), guiding feature\ndistributions towards high-impact nodes to augment the model's capacity for\nassimilating new knowledge. Instance-Prototype Affinity Distillation (IPAD)\nsafeguards task memory by regularizing discontinuities in class relationships.\nMoreover, we embed a Decision Boundary Perception (DBP) mechanism within PCL,\nfostering greater inter-class discriminability. Evaluations on four node\nclassification benchmark datasets demonstrate that our method outperforms\nexisting state-of-the-art methods, achieving a better trade-off between\nplasticity and stability.", "published": "2025-05-15 07:35:27", "link": "http://arxiv.org/abs/2505.10040v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates", "abstract": "Circuit discovery has gradually become one of the prominent methods for\nmechanistic interpretability, and research on circuit completeness has also\ngarnered increasing attention. Methods of circuit discovery that do not\nguarantee completeness not only result in circuits that are not fixed across\ndifferent runs but also cause key mechanisms to be omitted. The nature of\nincompleteness arises from the presence of OR gates within the circuit, which\nare often only partially detected in standard circuit discovery methods. To\nthis end, we systematically introduce three types of logic gates: AND, OR, and\nADDER gates, and decompose the circuit into combinations of these logical\ngates. Through the concept of these gates, we derive the minimum requirements\nnecessary to achieve faithfulness and completeness. Furthermore, we propose a\nframework that combines noising-based and denoising-based interventions, which\ncan be easily integrated into existing circuit discovery methods without\nsignificantly increasing computational complexity. This framework is capable of\nfully identifying the logic gates and distinguishing them within the circuit.\nIn addition to the extensive experimental validation of the framework's ability\nto restore the faithfulness, completeness, and sparsity of circuits, using this\nframework, we uncover fundamental properties of the three logic gates, such as\ntheir proportions and contributions to the output, and explore how they behave\namong the functionalities of language models.", "published": "2025-05-15 07:35:14", "link": "http://arxiv.org/abs/2505.10039v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests", "abstract": "Despite significant advancements in Deep Reinforcement Learning (DRL) for\nAutonomous Surface Vehicles (ASVs), their robustness in real-world conditions,\nparticularly under external disturbances, remains insufficiently explored. In\nthis paper, we evaluate the resilience of a DRL-based agent designed to capture\nfloating waste under various perturbations. We train the agent using domain\nrandomization and evaluate its performance in real-world field tests, assessing\nits ability to handle unexpected disturbances such as asymmetric drag and an\noff-center payload. We assess the agent's performance under these perturbations\nin both simulation and real-world experiments, quantifying performance\ndegradation and benchmarking it against an MPC baseline. Results indicate that\nthe DRL agent performs reliably despite significant disturbances. Along with\nthe open-source release of our implementation, we provide insights into\neffective training strategies, real-world challenges, and practical\nconsiderations for deploying DRLbased ASV controllers.", "published": "2025-05-15 07:29:16", "link": "http://arxiv.org/abs/2505.10033v1", "categories": ["cs.RO", "cs.LG"], "primary_category": "cs.RO"}
{"title": "ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts", "abstract": "A central challenge in reinforcement learning (RL) is its dependence on\nextensive real-world interaction data to learn task-specific policies. While\nrecent work demonstrates that large language models (LLMs) can mitigate this\nlimitation by generating synthetic experience (noted as imaginary rollouts) for\nmastering novel tasks, progress in this emerging field is hindered due to the\nlack of a standard benchmark. To bridge this gap, we introduce ImagineBench,\nthe first comprehensive benchmark for evaluating offline RL algorithms that\nleverage both real rollouts and LLM-imaginary rollouts. The key features of\nImagineBench include: (1) datasets comprising environment-collected and\nLLM-imaginary rollouts; (2) diverse domains of environments covering\nlocomotion, robotic manipulation, and navigation tasks; and (3) natural\nlanguage task instructions with varying complexity levels to facilitate\nlanguage-conditioned policy learning. Through systematic evaluation of\nstate-of-the-art offline RL algorithms, we observe that simply applying\nexisting offline RL algorithms leads to suboptimal performance on unseen tasks,\nachieving 35.44% success rate in hard tasks in contrast to 64.37% of method\ntraining on real rollouts for hard tasks. This result highlights the need for\nalgorithm advancements to better leverage LLM-imaginary rollouts. Additionally,\nwe identify key opportunities for future research: including better utilization\nof imaginary rollouts, fast online adaptation and continual learning, and\nextension to multi-modal tasks. Our code is publicly available at\nhttps://github.com/LAMDA-RL/ImagineBench.", "published": "2025-05-15 06:45:37", "link": "http://arxiv.org/abs/2505.10010v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning", "abstract": "Motivated by practical applications where stable long-term performance is\ncritical-such as robotics, operations research, and healthcare-we study the\nproblem of distributionally robust (DR) average-reward reinforcement learning.\nWe propose two algorithms that achieve near-optimal sample complexity. The\nfirst reduces the problem to a DR discounted Markov decision process (MDP),\nwhile the second, Anchored DR Average-Reward MDP, introduces an anchoring state\nto stabilize the controlled transition kernels within the uncertainty set.\nAssuming the nominal MDP is uniformly ergodic, we prove that both algorithms\nattain a sample complexity of $\\widetilde{O}\\left(|\\mathbf{S}||\\mathbf{A}|\nt_{\\mathrm{mix}}^2\\varepsilon^{-2}\\right)$ for estimating the optimal policy as\nwell as the robust average reward under KL and $f_k$-divergence-based\nuncertainty sets, provided the uncertainty radius is sufficiently small. Here,\n$\\varepsilon$ is the target accuracy, $|\\mathbf{S}|$ and $|\\mathbf{A}|$ denote\nthe sizes of the state and action spaces, and $t_{\\mathrm{mix}}$ is the mixing\ntime of the nominal MDP. This represents the first finite-sample convergence\nguarantee for DR average-reward reinforcement learning. We further validate the\nconvergence rates of our algorithms through numerical experiments.", "published": "2025-05-15 06:42:25", "link": "http://arxiv.org/abs/2505.10007v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model", "abstract": "Designing a 6G-oriented universal model capable of processing multi-modal\ndata and executing diverse air interface tasks has emerged as a common goal in\nfuture wireless systems. Building on our prior work in communication\nmulti-modal alignment and telecom large language model (LLM), we propose a\nscalable, task-aware artificial intelligence-air interface multi-modal\nuniversal model (AI2MMUM), which flexibility and effectively perform various\nphysical layer tasks according to subtle task instructions. The LLM backbone\nprovides robust contextual comprehension and generalization capabilities, while\na fine-tuning approach is adopted to incorporate domain-specific knowledge. To\nenhance task adaptability, task instructions consist of fixed task keywords and\nlearnable, implicit prefix prompts. Frozen radio modality encoders extract\nuniversal representations and adapter layers subsequently bridge radio and\nlanguage modalities. Moreover, lightweight task-specific heads are designed to\ndirectly output task objectives. Comprehensive evaluations demonstrate that\nAI2MMUM achieves SOTA performance across five representative physical\nenvironment/wireless channel-based downstream tasks using the WAIR-D and\nDeepMIMO datasets.", "published": "2025-05-15 06:32:59", "link": "http://arxiv.org/abs/2505.10003v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Sybil-based Virtual Data Poisoning Attacks in Federated Learning", "abstract": "Federated learning is vulnerable to poisoning attacks by malicious\nadversaries. Existing methods often involve high costs to achieve effective\nattacks. To address this challenge, we propose a sybil-based virtual data\npoisoning attack, where a malicious client generates sybil nodes to amplify the\npoisoning model's impact. To reduce neural network computational complexity, we\ndevelop a virtual data generation method based on gradient matching. We also\ndesign three schemes for target model acquisition, applicable to online local,\nonline global, and offline scenarios. In simulation, our method outperforms\nother attack algorithms since our method can obtain a global target model under\nnon-independent uniformly distributed data.", "published": "2025-05-15 05:46:59", "link": "http://arxiv.org/abs/2505.09983v1", "categories": ["cs.CR", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Who Said What WSW 2.0? Enhanced Automated Analysis of Preschool Classroom Speech", "abstract": "This paper introduces an automated framework WSW2.0 for analyzing vocal\ninteractions in preschool classrooms, enhancing both accuracy and scalability\nthrough the integration of wav2vec2-based speaker classification and Whisper\n(large-v2 and large-v3) speech transcription. A total of 235 minutes of audio\nrecordings (160 minutes from 12 children and 75 minutes from 5 teachers), were\nused to compare system outputs to expert human annotations. WSW2.0 achieves a\nweighted F1 score of .845, accuracy of .846, and an error-corrected kappa of\n.672 for speaker classification (child vs. teacher). Transcription quality is\nmoderate to high with word error rates of .119 for teachers and .238 for\nchildren. WSW2.0 exhibits relatively high absolute agreement intraclass\ncorrelations (ICC) with expert transcriptions for a range of classroom language\nfeatures. These include teacher and child mean utterance length, lexical\ndiversity, question asking, and responses to questions and other utterances,\nwhich show absolute agreement intraclass correlations between .64 and .98. To\nestablish scalability, we apply the framework to an extensive dataset spanning\ntwo years and over 1,592 hours of classroom audio recordings, demonstrating the\nframework's robustness for broad real-world applications. These findings\nhighlight the potential of deep learning and natural language processing\ntechniques to revolutionize educational research by providing accurate measures\nof key features of preschool classroom speech, ultimately guiding more\neffective intervention strategies and supporting early childhood language\ndevelopment.", "published": "2025-05-15 05:21:34", "link": "http://arxiv.org/abs/2505.09972v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Approximated Behavioral Metric-based State Projection for Federated Reinforcement Learning", "abstract": "Federated reinforcement learning (FRL) methods usually share the encrypted\nlocal state or policy information and help each client to learn from others\nwhile preserving everyone's privacy. In this work, we propose that sharing the\napproximated behavior metric-based state projection function is a promising way\nto enhance the performance of FRL and concurrently provides an effective\nprotection of sensitive information. We introduce FedRAG, a FRL framework to\nlearn a computationally practical projection function of states for each client\nand aggregating the parameters of projection functions at a central server. The\nFedRAG approach shares no sensitive task-specific information, yet provides\ninformation gain for each client. We conduct extensive experiments on the\nDeepMind Control Suite to demonstrate insightful results.", "published": "2025-05-15 04:41:21", "link": "http://arxiv.org/abs/2505.09959v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity", "abstract": "Euclidean diffusion models have achieved remarkable success in generative\nmodeling across diverse domains, and they have been extended to manifold case\nin recent advances. Instead of explicitly utilizing the structure of special\nmanifolds as studied in previous works, we investigate direct sampling of the\nEuclidean diffusion models for general manifold-constrained data in this paper.\nWe reveal the multiscale singularity of the score function in the embedded\nspace of manifold, which hinders the accuracy of diffusion-generated samples.\nWe then present an elaborate theoretical analysis of the singularity structure\nof the score function by separating it along the tangential and normal\ndirections of the manifold. To mitigate the singularity and improve the\nsampling accuracy, we propose two novel methods: (1) Niso-DM, which introduces\nnon-isotropic noise along the normal direction to reduce scale discrepancies,\nand (2) Tango-DM, which trains only the tangential component of the score\nfunction using a tangential-only loss function. Numerical experiments\ndemonstrate that our methods achieve superior performance on distributions over\nvarious manifolds with complex geometries.", "published": "2025-05-15 03:12:27", "link": "http://arxiv.org/abs/2505.09922v1", "categories": ["cs.LG"], "primary_category": "cs.LG"}
{"title": "pc-dbCBS: Kinodynamic Motion Planning of Physically-Coupled Robot Teams", "abstract": "Motion planning problems for physically-coupled multi-robot systems in\ncluttered environments are challenging due to their high dimensionality.\nExisting methods combining sampling-based planners with trajectory optimization\nproduce suboptimal results and lack theoretical guarantees. We propose\nPhysically-coupled discontinuity-bounded Conflict-Based Search (pc-dbCBS), an\nanytime kinodynamic motion planner, that extends discontinuity-bounded CBS to\nrigidly-coupled systems. Our approach proposes a tri-level conflict detection\nand resolution framework that includes the physical coupling between the\nrobots. Moreover, pc-dbCBS alternates iteratively between state space\nrepresentations, thereby preserving probabilistic completeness and asymptotic\noptimality while relying only on single-robot motion primitives. Across 25\nsimulated and six real-world problems involving multirotors carrying a\ncable-suspended payload and differential-drive robots linked by rigid rods,\npc-dbCBS solves up to 92% more instances than a state-of-the-art baseline and\nplans trajectories that are 50-60% faster while reducing planning time by an\norder of magnitude.", "published": "2025-05-15 14:46:19", "link": "http://arxiv.org/abs/2505.10355v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "cs.RO"}
{"title": "CartoAgent: a multimodal large language model-powered multi-agent cartographic framework for map style transfer and evaluation", "abstract": "The rapid development of generative artificial intelligence (GenAI) presents\nnew opportunities to advance the cartographic process. Previous studies have\neither overlooked the artistic aspects of maps or faced challenges in creating\nboth accurate and informative maps. In this study, we propose CartoAgent, a\nnovel multi-agent cartographic framework powered by multimodal large language\nmodels (MLLMs). This framework simulates three key stages in cartographic\npractice: preparation, map design, and evaluation. At each stage, different\nMLLMs act as agents with distinct roles to collaborate, discuss, and utilize\ntools for specific purposes. In particular, CartoAgent leverages MLLMs' visual\naesthetic capability and world knowledge to generate maps that are both\nvisually appealing and informative. By separating style from geographic data,\nit can focus on designing stylesheets without modifying the vector-based data,\nthereby ensuring geographic accuracy. We applied CartoAgent to a specific task\ncentered on map restyling-namely, map style transfer and evaluation. The\neffectiveness of this framework was validated through extensive experiments and\na human evaluation study. CartoAgent can be extended to support a variety of\ncartographic design decisions and inform future integrations of GenAI in\ncartography.", "published": "2025-05-15 03:45:10", "link": "http://arxiv.org/abs/2505.09936v1", "categories": ["cs.HC", "cs.GR", "cs.MA", "cs.MM"], "primary_category": "cs.HC"}
{"title": "A general regularization strategy for singular Stokes problems and convergence analysis for corresponding discretization and iterative solution", "abstract": "A general regularization strategy is considered for the efficient iterative\nsolution of the lowest-order weak Galerkin approximation of singular Stokes\nproblems. The strategy adds a rank-one regularization term to the zero (2,2)\nblock of the underlying singular saddle point system. This strategy includes\nthe existing pressure pinning and mean-zero enforcement regularization as\nspecial examples. It is shown that the numerical error maintains the\noptimal-order convergence provided that the nonzero Dirichlet boundary datum is\napproximated numerically with sufficient accuracy. Inexact block diagonal and\ntriangular Schur complement preconditioners are considered for the regularized\nsystem. The convergence analysis for MINRES and GMRES with corresponding block\npreconditioners is provided for different choices of the regularization term.\nNumerical experiments in two and three dimensions are presented to verify the\ntheoretical findings and the effectiveness of the preconditioning for solving\nthe regularized system.", "published": "2025-05-15 15:28:18", "link": "http://arxiv.org/abs/2505.10404v1", "categories": ["math.NA", "cs.NA", "65N30, 65F08, 65F10, 76D07"], "primary_category": "math.NA"}
{"title": "Discrete Geodesic Calculus in the Space of Sobolev Curves", "abstract": "The Riemannian manifold of curves with a Sobolev metric is an important and\nfrequently studied model in the theory of shape spaces. Various numerical\napproaches have been proposed to compute geodesics, but so far elude a rigorous\nconvergence theory. By a slick modification of a temporal Galerkin\ndiscretization we manage to preserve coercivity and compactness properties of\nthe continuous model and thereby are able to prove convergence for the geodesic\nboundary value problem. Likewise, for the numerical analysis of the geodesic\ninitial value problem we are able to exploit the geodesic completeness of the\nunderlying continuous model for the error control of a time-stepping\napproximation. In fact, we develop a convergent discretization of a\ncomprehensive Riemannian calculus that in addition includes parallel transport,\ncovariant differentiation, the Riemann curvature tensor, and sectional\ncurvature, all important tools to explore the geometry of the space of curves.\nSelected numerical examples confirm the theoretical findings and show the\nqualitative behaviour. To this end, a low-dimensional submanifold of Sobolev\ncurves with explicit formulas for ground truth covariant derivatives and\ncurvatures are considered.", "published": "2025-05-15 13:46:25", "link": "http://arxiv.org/abs/2505.10298v1", "categories": ["math.NA", "cs.NA", "65D18, 65K10, 65N30, 58E10"], "primary_category": "math.NA"}
{"title": "The finiteness conjecture for $3 \\times 3$ binary matrices", "abstract": "The invariant polytope algorithm was a breakthrough in the joint spectral\nradius computation, allowing to find the exact value of the joint spectral\nradius for most matrix families~\\cite{GP2013,GP2016}. This algorithm found many\napplications in problems of functional analysis, approximation theory,\ncombinatorics, etc. In this paper we propose a modification of the invariant\npolytope algorithm enlarging the class of problems to which it is applicable.\nPrecisely, we introduce mixed numeric and symbolic computations. A further\nminor modification of augmenting the input set with additional matrices speeds\nup the algorithm in certain cases. With this modifications we are able to\nautomatically prove the finiteness conjecture for all pairs of binary $3\\times\n3$ matrices and sign $2\\times 2$ matrices.", "published": "2025-05-15 11:22:40", "link": "http://arxiv.org/abs/2505.10178v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A generalized discontinuous Hamilton Monte Carlo for transdimensional sampling", "abstract": "In this paper, we propose a discontinuous Hamilton Monte Carlo (DHMC) to\nsample from dimensional varying distributions, and particularly the grand\ncanonical ensemble. The DHMC was proposed in [Biometrika, 107(2)] for\ndiscontinuous potential where the variable has a fixed dimension. When the\ndimension changes, there is no clear explanation of the volume-preserving\nproperty, and the conservation of energy is also not necessary. We use a random\nsampling for the extra dimensions, which corresponds to a measure transform. We\nshow that when the energy is corrected suitably for the trans-dimensional\nHamiltonian dynamics, the detailed balance condition is then satisfied. For the\ngrand canonical ensemble, such a procedure can be explained very naturally to\nbe the extra free energy change brought by the newly added particles, which\njustifies the rationality of our approach. To sample the grand canonical\nensemble for interacting particle systems, the DHMC is then combined with the\nrandom batch method to yield an efficient sampling method. In experiments, we\nshow that the proposed DHMC combined with the random batch method generates\nsamples with much less correlation when compared with the traditional\nMetropolis-Hastings method.", "published": "2025-05-15 09:21:54", "link": "http://arxiv.org/abs/2505.10108v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Error Estimates and Graded Mesh Refinement for Isogeometric Analysis on Polar Domains with Corners", "abstract": "Isogeometric analysis (IGA) enables exact representations of computational\ngeometries and higher-order approximation of PDEs. In non-smooth domains,\nhowever, singularities near corners limit the effectiveness of IGA, since\nstandard methods typically fail to achieve optimal convergence rates. These\nconstraints can be addressed through local mesh refinement, but existing\napproaches require breaking the tensor-product structure of splines, which\nleads to increased implementation complexity.\n  This work introduces a novel local refinement strategy based on a polar\nparameterization, in which one edge of the parametric square is collapsed into\nthe corner. By grading the standard mesh toward the collapsing edge, the\ndesired locality near the singularity is obtained while maintaining the\ntensor-product structure. A mathematical analysis and numerical tests show that\nthe resulting isogeometric approximation achieves optimal convergence rates\nwith suitable grading parameters.\n  Polar parameterizations, however, suffer from a lack of regularity at the\npolar point, making existing standard isogeometric approximation theory\ninapplicable. To address this, a new framework is developed for deriving error\nestimates on polar domains with corners. This involves the construction of\npolar function spaces on the parametric domain and a modified projection\noperator onto the space of $C^0$-smooth polar splines. The theoretical results\nare verified by numerical experiments confirming both the accuracy and\nefficiency of the proposed approach.", "published": "2025-05-15 08:54:13", "link": "http://arxiv.org/abs/2505.10095v1", "categories": ["math.NA", "cs.NA", "65N30, 65N50, 65N25, 65D07, 35A21"], "primary_category": "math.NA"}
{"title": "On the critical length conjecture for spherical Bessel functions in CAGD", "abstract": "A conjecture of J.M. Carnicer, E. Mainar and J.M. Pe\\~{n}a states that the\ncritical length of the space $P_{n}\\odot C_{1}$ generated by the functions\n$x^{k}\\sin x$ and $x^{k}\\cos x$ for $k=0,...n$ is equal to the first positive\nzero $j_{n+\\frac{1}{2},1}$ of the Bessel function $J_{n+\\frac{1}{2}}$ of the\nfirst kind. It is known that the conjecture implies the following statement\n(D3): the determinant of the Hankel matrix \\begin{equation} \\left(\n\\begin{array} [c]{ccc} f & f^{\\prime} & f^{\\prime\\prime}\\\\ f^{\\prime} &\nf^{\\prime\\prime} & f^{\\left( 3\\right) }\\\\ f^{\\prime\\prime} &\nf^{\\prime\\prime\\prime} & f^{\\left( 4\\right) } \\end{array} \\right)\n\\label{eqabstract} \\end{equation} does not have a zero in the interval\n$(0,j_{n+\\frac{1}{2},1})$ whenever $f=f_{n}$ is given by $f_{n}\\left( x\\right)\n=\\sqrt{\\frac{\\pi}{2}} x^{n+\\frac{1}{2}}J_{n+\\frac{1}{2}}\\left( x\\right) .$ In\nthis paper we shall prove (D3) and various generalizations.", "published": "2025-05-15 04:58:31", "link": "http://arxiv.org/abs/2505.09964v1", "categories": ["math.CA", "cs.NA", "math.NA", "41A05, 41A10, 42A10, 65D05, 65D17"], "primary_category": "math.CA"}
{"title": "Discontinuous hybrid neural networks for the one-dimensional partial differential equations", "abstract": "A feedforward neural network, including hidden layers, motivated by nonlinear\nfunctions (such as Tanh, ReLU, and Sigmoid functions), exhibits uniform\napproximation properties in Sobolev space, and discontinuous neural networks\ncan reduce computational complexity. In this work, we present a discontinuous\nhybrid neural network method for solving the partial differential equations,\nconstruct a new hybrid loss functional that incorporates the variational of the\napproximation equation, interface jump stencil and boundary constraints. The\nRMSprop algorithm and discontinuous Galerkin method are employed to update the\nnonlinear parameters and linear parameters in neural networks, respectively.\nThis approach guarantees the convergence of the loss functional and provides an\napproximate solution with high accuracy.", "published": "2025-05-15 02:43:06", "link": "http://arxiv.org/abs/2505.09911v1", "categories": ["math.NA", "cs.NA", "65N30, 65N55, 68T07"], "primary_category": "math.NA"}
{"title": "Reproducing the first and second moment of empirical degree distributions", "abstract": "The study of probabilistic models for the analysis of complex networks\nrepresents a flourishing research field. Among the former, Exponential Random\nGraphs (ERGs) have gained increasing attention over the years. So far, only\nlinear ERGs have been extensively employed to gain insight into the structural\norganisation of real-world complex networks. None, however, is capable of\naccounting for the variance of the empirical degree distribution. To this aim,\nnon-linear ERGs must be considered. After showing that the usual mean-field\napproximation forces the degree-corrected version of the two-star model to\ndegenerate, we define a fitness-induced variant of it. Such a `softened' model\nis capable of reproducing the sample variance, while retaining the explanatory\npower of its linear counterpart, within a purely canonical framework.", "published": "2025-05-15 14:56:34", "link": "http://arxiv.org/abs/2505.10373v1", "categories": ["physics.soc-ph", "cs.SI", "physics.data-an", "q-fin.ST"], "primary_category": "physics.soc-ph"}
{"title": "Whitened Score Diffusion: A Structured Prior for Imaging Inverse Problems", "abstract": "Conventional score-based diffusion models (DMs) may struggle with anisotropic\nGaussian diffusion processes due to the required inversion of covariance\nmatrices in the denoising score matching training objective\n\\cite{vincent_connection_2011}. We propose Whitened Score (WS) diffusion\nmodels, a novel SDE-based framework that learns the Whitened Score function\ninstead of the standard score. This approach circumvents covariance inversion,\nextending score-based DMs by enabling stable training of DMs on arbitrary\nGaussian forward noising processes. WS DMs establish equivalence with FM for\narbitrary Gaussian noise, allow for tailored spectral inductive biases, and\nprovide strong Bayesian priors for imaging inverse problems with structured\nnoise. We experiment with a variety of computational imaging tasks using the\nCIFAR and CelebA ($64\\times64$) datasets and demonstrate that WS diffusion\npriors trained on anisotropic Gaussian noising processes consistently\noutperform conventional diffusion priors based on isotropic Gaussian noise.", "published": "2025-05-15 13:55:55", "link": "http://arxiv.org/abs/2505.10311v1", "categories": ["eess.IV", "eess.SP", "stat.AP", "stat.ML"], "primary_category": "eess.IV"}
{"title": "Topology-driven identification of repetitions in multi-variate time series", "abstract": "Many multi-variate time series obtained in the natural sciences and\nengineering possess a repetitive behavior, as for instance state-space\ntrajectories of industrial machines in discrete automation. Recovering the\ntimes of recurrence from such a multi-variate time series is of a fundamental\nimportance for many monitoring and control tasks. For a periodic time series\nthis is equivalent to determining its period length. In this work we present a\npersistent homology framework to estimate recurrence times in multi-variate\ntime series with different generalizations of cyclic behavior (periodic,\nrepetitive, and recurring). To this end, we provide three specialized methods\nwithin our framework that are provably stable and validate them using\nreal-world data, including a new benchmark dataset from an injection molding\nmachine.", "published": "2025-05-15 06:35:32", "link": "http://arxiv.org/abs/2505.10004v1", "categories": ["cs.CG", "eess.SP", "math.AT", "stat.ML"], "primary_category": "cs.CG"}
{"title": "T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback", "abstract": "Text-to-audio (T2A) generation has achieved remarkable progress in generating\na variety of audio outputs from language prompts. However, current\nstate-of-the-art T2A models still struggle to satisfy human preferences for\nprompt-following and acoustic quality when generating complex multi-event\naudio. To improve the performance of the model in these high-level\napplications, we propose to enhance the basic capabilities of the model with AI\nfeedback learning. First, we introduce fine-grained AI audio scoring pipelines\nto: 1) verify whether each event in the text prompt is present in the audio\n(Event Occurrence Score), 2) detect deviations in event sequences from the\nlanguage description (Event Sequence Score), and 3) assess the overall acoustic\nand harmonic quality of the generated audio (Acoustic&Harmonic Quality). We\nevaluate these three automatic scoring pipelines and find that they correlate\nsignificantly better with human preferences than other evaluation metrics. This\nhighlights their value as both feedback signals and evaluation metrics.\nUtilizing our robust scoring pipelines, we construct a large audio preference\ndataset, T2A-FeedBack, which contains 41k prompts and 249k audios, each\naccompanied by detailed scores. Moreover, we introduce T2A-EpicBench, a\nbenchmark that focuses on long captions, multi-events, and story-telling\nscenarios, aiming to evaluate the advanced capabilities of T2A models. Finally,\nwe demonstrate how T2A-FeedBack can enhance current state-of-the-art audio\nmodel. With simple preference tuning, the audio generation model exhibits\nsignificant improvements in both simple (AudioCaps test set) and complex\n(T2A-EpicBench) scenarios.", "published": "2025-05-15 17:59:29", "link": "http://arxiv.org/abs/2505.10561v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quantized Approximate Signal Processing (QASP): Towards Homomorphic Encryption for audio", "abstract": "Audio and speech data are increasingly used in machine learning applications\nsuch as speech recognition, speaker identification, and mental health\nmonitoring. However, the passive collection of this data by audio listening\ndevices raises significant privacy concerns. Fully homomorphic encryption (FHE)\noffers a promising solution by enabling computations on encrypted data and\npreserving user privacy. Despite its potential, prior attempts to apply FHE to\naudio processing have faced challenges, particularly in securely computing time\nfrequency representations, a critical step in many audio tasks.\n  Here, we addressed this gap by introducing a fully secure pipeline that\ncomputes, with FHE and quantized neural network operations, four fundamental\ntime-frequency representations: Short-Time Fourier Transform (STFT), Mel\nfilterbanks, Mel-frequency cepstral coefficients (MFCCs), and gammatone\nfilters. Our methods also support the private computation of audio descriptors\nand convolutional neural network (CNN) classifiers. Besides, we proposed\napproximate STFT algorithms that lighten computation and bit use for\nstatistical and machine learning analyses.\n  We ran experiments on the VocalSet and OxVoc datasets demonstrating the fully\nprivate computation of our approach. We showed significant performance\nimprovements with STFT approximation in private statistical analysis of audio\nmarkers, and for vocal exercise classification with CNNs. Our results reveal\nthat our approximations substantially reduce error rates compared to\nconventional STFT implementations in FHE. We also demonstrated a fully private\nclassification based on the raw audio for gender and vocal exercise\nclassification. Finally, we provided a practical heuristic for parameter\nselection, making quantized approximate signal processing accessible to\nresearchers and practitioners aiming to protect sensitive audio data.", "published": "2025-05-15 17:01:52", "link": "http://arxiv.org/abs/2505.10500v1", "categories": ["eess.AS", "cs.CR", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Spatially Selective Active Noise Control for Open-fitting Hearables with Acausal Optimization", "abstract": "Recent advances in active noise control have enabled the development of\nhearables with spatial selectivity, which actively suppress undesired noise\nwhile preserving desired sound from specific directions. In this work, we\npropose an improved approach to spatially selective active noise control that\nincorporates acausal relative impulse responses into the optimization process,\nresulting in significantly improved performance over the causal design. We\nevaluate the system through simulations using a pair of open-fitting hearables\nwith spatially localized speech and noise sources in an anechoic environment.\nPerformance is evaluated in terms of speech distortion, noise reduction, and\nsignal-to-noise ratio improvement across different delays and degrees of\nacausality. Results show that the proposed acausal optimization consistently\noutperforms the causal approach across all metrics and scenarios, as acausal\nfilters more effectively characterize the response of the desired source.", "published": "2025-05-15 14:56:15", "link": "http://arxiv.org/abs/2505.10372v1", "categories": ["eess.AS", "cs.SD", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "eess.AS"}
{"title": "ListenNet: A Lightweight Spatio-Temporal Enhancement Nested Network for Auditory Attention Detection", "abstract": "Auditory attention detection (AAD) aims to identify the direction of the\nattended speaker in multi-speaker environments from brain signals, such as\nElectroencephalography (EEG) signals. However, existing EEG-based AAD methods\noverlook the spatio-temporal dependencies of EEG signals, limiting their\ndecoding and generalization abilities. To address these issues, this paper\nproposes a Lightweight Spatio-Temporal Enhancement Nested Network (ListenNet)\nfor AAD. The ListenNet has three key components: Spatio-temporal Dependency\nEncoder (STDE), Multi-scale Temporal Enhancement (MSTE), and Cross-Nested\nAttention (CNA). The STDE reconstructs dependencies between consecutive time\nwindows across channels, improving the robustness of dynamic pattern\nextraction. The MSTE captures temporal features at multiple scales to represent\nboth fine-grained and long-range temporal patterns. In addition, the CNA\nintegrates hierarchical features more effectively through novel dynamic\nattention mechanisms to capture deep spatio-temporal correlations. Experimental\nresults on three public datasets demonstrate the superiority of ListenNet over\nstate-of-the-art methods in both subject-dependent and challenging\nsubject-independent settings, while reducing the trainable parameter count by\napproximately 7 times. Code is available\nat:https://github.com/fchest/ListenNet.", "published": "2025-05-15 14:35:42", "link": "http://arxiv.org/abs/2505.10348v1", "categories": ["cs.HC", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "Analog Self-Interference Cancellation in Full-Duplex Radios: A Fundamental Limit Perspective", "abstract": "Analog self-interference cancellation (A-SIC) plays a crucial role in the\nimplementation of in-band full-duplex (IBFD) radios, due to the fact that the\ninherent transmit (Tx) noise can only be addressed in the analog domain. It is\nthus natural to ask what the performance limit of A-SIC is in practical\nsystems, which is still quite underexplored so far. In this paper, we aim to\nclose this gap by characterizing the fundamental performance of A-SIC which\nemploys the common multi-tap delay (MTD) architecture, by accounting for the\nfollowing practical issues: 1) Nonstationarity of the Tx signal; 2) Nonlinear\ndistortions on the Tx signal; 3) Multipath channel corresponding to the\nself-interference (SI); 4) Maximum amplitude constraint on the MTD tap weights.\nOur findings include: 1) The average approximation error for the\ncyclostationary Tx signals is equal to that for the stationary white Gaussian\nprocess, thus greatly simplifying the performance analysis and the optimization\nprocedure. 2) The approximation error for the multipath SI channel can be\ndecomposed as the sum of the approximation error for the single-path scenario.\nBy leveraging these structural results, the optimization framework and\nalgorithms which characterize the fundamental limit of A-SIC, by taking into\naccount all the aforementioned practical factors, are provided.", "published": "2025-05-15 15:36:57", "link": "http://arxiv.org/abs/2505.10419v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Ray Antenna Array Achieves Uniform Angular Resolution Cost-Effectively for Low-Altitude UAV Swarm ISAC", "abstract": "Ray antenna array (RAA) is a novel multi-antenna architecture comprising\nmassive low-cost antenna elements and a few radio-frequency (RF) chains. The\nantenna elements are arranged in a novel ray-like structure, where each ray\ncorresponds to a simple uniform linear array (sULA) with deliberately designed\norientation and all its antenna elements are directly connected. By further\ndesigning a ray selection network (RSN), appropriate sULAs are selected to\nconnect to the RF chains for further baseband processing. RAA has three\nappealing advantages: (i) dramatically reduced hardware cost since no phase\nshifters are needed; (ii) enhanced beamforming gain as antenna elements with\nhigher directivity can be used; (iii) uniform angular resolution across all\nsignal directions. Such benefits make RAA especially appealing for integrated\nsensing and communication (ISAC), particularly for low-altitude unmanned aerial\nvehicle (UAV) swarm ISAC, where high-mobility aerial targets may easily move\naway from the boresight of conventional antenna arrays, causing severe\ncommunication and sensing performance degradation. Therefore, this paper\nstudies RAA-based ISAC for low-altitude UAV swarm systems. First, we establish\nan input-output mathematical model for RAA-based UAV ISAC and rigorously show\nthat RAA achieves uniform angular resolution for all directions. Besides, we\ndesign the RAA orientation and RSN. Furthermore, RAA-based ISAC with orthogonal\nfrequency division multiplexing (OFDM) for UAV swarm is studied, and efficient\nalgorithm is proposed for sensing target parameter estimation. Extensive\nsimulation results demonstrate the significant performance improvement by RAA\nsystem over the conventional antenna arrays, in terms of sensing angular\nresolution and communication spectral efficiency, highlighting the great\npotential of the novel RAA system to meet the growing demands of low-altitude\nUAV ISAC.", "published": "2025-05-15 13:53:33", "link": "http://arxiv.org/abs/2505.10306v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "ISAC Channel Modelling -- Perspectives from ETSI", "abstract": "Integrated Sensing and Communications (ISAC) is defined as one of six usage\nscenarios in the ITU-R International Mobile Telecommunications (IMT) 2030\nframework for 6G. ISAC is envisioned to introduce the sensing capability into\nthe cellular network, where sensing may be obtained using the cellular radio\nfrequency (RF) signals with or without additional auxiliary sensors. To enable\nISAC, specification bodies such as European Telecommunications Standards\nInstitute (ETSI) and Third Generation Partnership Project (3GPP) have already\nstarted to look into detailed ISAC use cases, their requirements, and the\nchannel models and evaluation methodologies that are necessary to design and\nevaluate ISAC performance. With focus on the channel model, the current\ncommunication-centric channel models like those specified in 3GPP technical\nreport (TR) 38.901 do not cover the RF signals interactions between the\ntransmitter, target object, receiver and their surrounding environment. To\nbridge this gap, 3GPP has been looking into the basic changes that are\nnecessary to make to their TR38.901 channel model with focus on selected use\ncases from the 3GPP SA1 5G-Advanced feasibility study. In parallel, ETSI ISAC\nIndustry Specification Group (ISG) has been studying the more advanced ISAC\nchannel modelling features that are needed to support the variety of ISAC use\ncases envisioned in 6G. In this paper, we present the baseline and advanced\nfeatures developed thus far in 3GPP and ETSI ISAC ISG, respectively, towards a\ncomprehensive view of the ISAC channel model in 6G.", "published": "2025-05-15 13:24:28", "link": "http://arxiv.org/abs/2505.10275v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "UAV-Enabled Passive 6DMA for ISAC: Joint Location, Orientation, and Reflection Optimization", "abstract": "Improving the fundamental performance trade-off in integrated sensing and\ncommunication (ISAC) systems has been deemed as one of the most significant\nchallenges. To address it, we propose in this letter a novel ISAC system that\nleverages an unmanned aerial vehicle (UAV)-mounted intelligent reflecting\nsurface (IRS) and the UAV's maneuverability in six-dimensional (6D) space,\ni.e., three-dimensional (3D) location and 3D rotation, thus referred to as\npassive 6D movable antenna (6DMA). We aim to maximize the signal-to-noise ratio\n(SNR) for sensing a single target while ensuring a minimum SNR at a\ncommunication user equipment (UE), by jointly optimizing the transmit\nbeamforming at the ISAC base station (BS), the 3D location and orientation as\nwell as the reflection coefficients of the IRS. To solve this challenging\nnon-convex optimization problem, we propose a two-stage approach. In the first\nstage, we aim to optimize the IRS's 3D location, 3D orientation, and reflection\ncoefficients to enhance both the channel correlations and power gains for\nsensing and communication. Given their optimized parameters, the optimal\ntransmit beamforming at the ISAC BS is derived in closed form. Simulation\nresults demonstrate that the proposed passive 6DMA-enabled ISAC system\nsignificantly improves the sensing and communication trade-off by\nsimultaneously enhancing channel correlations and power gains, and outperforms\nother baseline schemes.", "published": "2025-05-15 12:23:12", "link": "http://arxiv.org/abs/2505.10220v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Passive Channel Charting: Locating Passive Targets using a UWB Mesh", "abstract": "Fingerprint-based passive localization enables high localization accuracy\nusing low-cost UWB IoT radio sensors. However, fingerprinting demands extensive\neffort for data acquisition. The concept of channel charting reduces this\neffort by modeling and projecting the manifold of \\ac{csi} onto a 2D coordinate\nspace. So far, researchers only applied this concept to active radio\nlocalization, where a mobile device intentionally and actively emits a specific\nsignal. In this paper, we apply channel charting to passive localization. We\nuse a pedestrian dead reckoning (PDR) system to estimate a target's velocity\nand derive a distance matrix from it. We then use this matrix to learn a\ndistance-preserving embedding in 2D space, which serves as a fingerprinting\nmodel. In our experiments, we deploy six nodes in a fully connected\nultra-wideband (UWB) mesh network to show that our method achieves high\nlocalization accuracy, with an average error of just 0.24\\,m, even when we\ntrain and test on different targets.", "published": "2025-05-15 11:50:41", "link": "http://arxiv.org/abs/2505.10194v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Rate Region of ISAC for Pinching-Antenna Systems", "abstract": "The Pinching-Antenna SyStem (PASS) reconstructs wireless channels through\n\\emph{pinching beamforming}, wherein the activated positions of pinching\nantennas along dielectric waveguides are optimized to shape the radiation\npattern. The aim of this article is to analyze the performance limits of\nemploying PASS in integrated sensing and communications (ISAC). Specifically, a\nPASS-assisted ISAC system is considered, where a pinched waveguide is utilized\nto simultaneously communicate with a user and sense a target. Closed-form\nexpressions for the achievable communication rate (CR) and sensing rate (SR)\nare derived to characterize the information-theoretic limits of this\ndual-functional operation. \\romannumeral1) For the single-pinch case,\nclosed-form solutions for the optimal pinching antenna location are derived\nunder \\emph{sensing-centric (S-C)}, \\emph{communications-centric (C-C)}, and\n\\emph{Pareto-optimal} designs. On this basis, the CR-SR trade-off is\ncharacterized by deriving the full CR-SR rate region, which is shown to\nencompass that of conventional fixed-antenna systems. \\romannumeral2) For the\nmultiple-pinch case, an antenna location refinement method is applied to obtain\nthe optimal C-C and S-C pinching beamformers. As a further advance, inner and\nouter bounds on the achievable CR-SR region are derived using an element-wise\nalternating optimization technique and by invoking Cauchy-Schwarz and\nKaramata's inequalities, respectively. Numerical results demonstrate that:\n\\romannumeral1) the derived bounds closely approximate the true CR-SR region;\nand \\romannumeral2) PASS can achieve a significantly larger rate region than\nconventional-antenna systems.", "published": "2025-05-15 11:27:10", "link": "http://arxiv.org/abs/2505.10179v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Subspace-Based Super-Resolution Sensing for Bi-Static ISAC with Clock Asynchronism", "abstract": "Bi-static sensing is an attractive configuration for integrated sensing and\ncommunications (ISAC) systems; however, clock asynchronism between widely\nseparated transmitters and receivers introduces time-varying time offsets (TO)\nand phase offsets (PO), posing significant challenges. This paper introduces a\nsignal-subspace-based framework that estimates decoupled angles, delays, and\ncomplex gain sequences (CGS)-- the target-reflected signals -- for multiple\ndynamic target paths. The proposed framework begins with a novel TO alignment\nalgorithm, leveraging signal subspace or covariance, to mitigate TO variations\nacross temporal snapshots, enabling coherent delay-domain analysis.\nSubsequently, subspace-based methods are developed to compensate for TO\nresiduals and to perform joint angle-delay estimation. Finally, leveraging the\nhigh resolution in the joint angle-delay domain, the framework compensates for\nthe PO and estimates the CGS for each target. The framework can be applied to\nboth single-antenna and multi-antenna systems. Extensive simulations and\nexperiments using commercial Wi-Fi devices demonstrate that the proposed\nframework significantly surpasses existing solutions in parameter estimation\naccuracy and delay resolution. Notably, it uniquely achieves a super-resolution\nin the delay domain, with a probability-of-resolution curve tightly approaching\nthat in synchronized systems.", "published": "2025-05-15 11:07:47", "link": "http://arxiv.org/abs/2505.10174v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "CFARNet: Learning-Based High-Resolution Multi-Target Detection for Rainbow Beam Radar", "abstract": "Millimeter-wave (mmWave) OFDM radar equipped with rainbow beamforming,\nenabled by joint phase-time arrays (JPTAs), provides wide-angle coverage and is\nwell-suited for fast real-time target detection and tracking. However, accurate\ndetection of multiple closely spaced targets remains a key challenge for\nconventional signal processing pipelines, particularly those relying on\nconstant false alarm rate (CFAR) detectors. This paper presents CFARNet, a\nlearning-based processing framework that replaces CFAR with a convolutional\nneural network (CNN) for peak detection in the angle-Doppler domain. The\nnetwork predicts target subcarrier indices, which guide angle estimation via a\nknown frequency-angle mapping and enable high-resolution range and velocity\nestimation using the MUSIC algorithm. Extensive simulations demonstrate that\nCFARNet significantly outperforms a CFAR+MUSIC baseline, especially under low\ntransmit power and dense multi-target conditions. The proposed method offers\nsuperior angular resolution, enhanced robustness in low-SNR scenarios, and\nimproved computational efficiency, highlighting the potential of data-driven\napproaches for high-resolution mmWave radar sensing.", "published": "2025-05-15 10:23:09", "link": "http://arxiv.org/abs/2505.10150v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Angle diversity receiver as a key enabler for reliable ORIS-based Visible Light Communication", "abstract": "Visible Light Communication (VLC) offers a promising solution to satisfy the\nincreasing demand for wireless data. However, link blockages remain a\nsignificant challenge. This paper addresses this issue by investigating the\ncombined use of angle diversity receivers (ADRs) and optical reconfigurable\nintelligent surfaces (ORISs) in multiuser VLC systems. We consider ORIS\nelements as small movable mirrors. We demonstrate the complementarity of ADR\nand ORIS in mitigating link blockages, as well as the advantages of using a\nlarger number of ORIS elements due to the increased field-of-view (FoV) at the\nreceiver enabled by the ADR. An optimization algorithm is proposed to maximize\nthe minimum signal-to-noise power ratio (SNR) to deploy a fair communication\nnetwork. Numerical results show that integrating ADR and ORIS significantly\nenhances VLC communication performance, achieving an SNR gain of up to 30 dB\ncompared to a system without ORIS, and mitigating communication outages\nproduced by link blockages or out-of-FoV received signals. We also prove that\nan ADR with a single tier of photodiodes is sufficient to complement\nORIS-assisted VLC.", "published": "2025-05-15 09:56:01", "link": "http://arxiv.org/abs/2505.10129v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Energy-Efficient and Reliable Data Collection in Receiver-Initiated Wake-up Radio Enabled IoT Networks", "abstract": "In unmanned aerial vehicle (UAV)-assisted wake-up radio (WuR)-enabled\ninternet of things (IoT) networks, UAVs can instantly activate the main radios\n(MRs) of the sensor nodes (SNs) with a wake-up call (WuC) for efficient data\ncollection in mission-driven data collection scenarios. However, the\nspontaneous response of numerous SNs to the UAV's WuC can lead to significant\npacket loss and collisions, as WuR does not exhibit its superiority for\nhigh-traffic loads. To address this challenge, we propose an innovative\nreceiver-initiated WuR UAV-assisted clustering (RI-WuR-UAC) medium access\ncontrol (MAC) protocol to achieve low latency and high reliability in ultra-low\npower consumption applications. We model the proposed protocol using the\n$M/G/1/2$ queuing framework and derive expressions for key performance metrics,\ni.e., channel busyness probability, probability of successful clustering,\naverage SN energy consumption, and average transmission delay. The RI-WuR-UAC\nprotocol employs three distinct data flow models, tailored to different network\ntraffic conditions, which perform three MAC mechanisms: channel assessment\n(CCA) clustering for light traffic loads, backoff plus CCA clustering for dense\nand heavy traffic, and adaptive clustering for variable traffic loads.\nSimulation results demonstrate that the RI-WuR-UAC protocol significantly\noutperforms the benchmark sub-carrier modulation clustering protocol. By\nvarying the network load, we capture the trade-offs among the performance\nmetrics, showcasing the superior efficiency and reliability of the RI-WuR-UAC\nprotocol.", "published": "2025-05-15 09:48:39", "link": "http://arxiv.org/abs/2505.10122v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Range Resolution of Near-field MIMO Sensing", "abstract": "The radiative near-field and integration of sensing capabilities are seen as\ntwo key components of the next generation of wireless communication systems. In\nthis paper, the sensing performance of a narrowband near-field system is\ninvestigated for several practical antenna array geometries and configurations,\nnamely SIMO/MISO and MIMO. In the SIMO/MISO configuration, the antenna aperture\nis exploited only a single time for either transmit or receive signal\nprocessing, while the MIMO configuration exploits both TX and RX processing.\nAnalytical derivations, supported by simulations, show that the MIMO processing\nimproves the maximum near-field range and sensing resolution by approximately a\nfactor of 1.4 as compared to single-aperture systems. The value of the\nimprovement factor is consistent for all considered array geometries. Finally,\nusing a quadratic approximation of the array factor, an analytical improvement\nfactor of $\\sqrt{2}$ is derived, clarifying the observed improvements and\nvalidating the numerical results.", "published": "2025-05-15 07:56:33", "link": "http://arxiv.org/abs/2505.10053v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Constrained Multimodal Sensing-Aided Communications: A Dynamic Beamforming Design", "abstract": "Using multimodal sensory data can enhance communications systems by reducing\nthe overhead and latency in beam training. However, processing such data incurs\nhigh computational complexity, and continuous sensing results in significant\npower and bandwidth consumption. This gives rise to a tradeoff between the\n(multimodal) sensing data acquisition rate and communications performance. In\nthis work, we develop a constrained multimodal sensing-aided communications\nframework where dynamic sensing and beamforming are performed under a sensing\nbudget. Specifically, we formulate an optimization problem that maximizes the\naverage received signal-to-noise ratio (SNR) of user equipment, subject to\nconstraints on the average number of sensing actions and power budget. Using\nthe Saleh-Valenzuela mmWave channel model, we construct the channel primarily\nbased on position information obtained via multimodal sensing. Stricter sensing\nconstraints reduce the availability of position data, leading to degraded\nchannel estimation and thus lower performance. We apply Lyapunov optimization\nto solve the problem and derive a dynamic sensing and beamforming algorithm.\nNumerical evaluations on the DeepSense and Raymobtime datasets show that\nhalving sensing times leads to only up to 7.7% loss in average SNR.", "published": "2025-05-15 06:57:30", "link": "http://arxiv.org/abs/2505.10015v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Enriched K-Tier Heterogeneous Satellite Networks Model with User Association Policies", "abstract": "In the rapid evolution of the non-terrestrial networks (NTNs), satellite\ncommunication has emerged as a focal area of research due to its critical role\nin enabling seamless global connectivity. In this paper, we investigate two\nrepresentative user association policies (UAPs) for multi-tier heterogeneous\nsatellite networks (HetSatNets), namely the nearest satellite UAP and the\nmaximum signal-to-interference-plus-noise-ratio (max-SINR) satellite UAP, where\neach tier is characterized by a distinct constellation configuration and\ntransmission pattern. Employing stochastic geometric, we analyze various\nintermediate system aspects, including the probability of a typical user\naccessing each satellite tier, the aggregated interference power, and their\ncorresponding Laplace transforms (LTs) under both UAPs. Subsequently, we derive\nexplicit expressions for coverage probability (CP), non-handover probability\n(NHP), and time delay outage probability (DOP) of the typical user.\nFurthermore, we propose a novel weighted metric (WM) that integrates CP, NHP,\nand DOP to explore their trade-offs in the system design. The robustness of the\ntheoretical framework is verified is verified through Monte Carlo simulations\ncalibrated with the actual Starlink constellation, affirming the precision of\nour analytical approach. The empirical findings underscore an optimal UAP in\nvarious HetSatNet scenarios regarding CP, NHP, and DOP..", "published": "2025-05-15 03:04:36", "link": "http://arxiv.org/abs/2505.09917v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Dynamic Beam-Stabilized, Additive-Printed Flexible Antenna Arrays with On-Chip Rapid Insight Generation", "abstract": "Conformal phased arrays promise shape-changing properties, multiple degrees\nof freedom to the scan angle, and novel applications in wearables, aerospace,\ndefense, vehicles, and ships. However, they have suffered from two critical\nlimitations. (1) Although most applications require on-the-move communication\nand sensing, prior conformal arrays have suffered from dynamic\ndeformation-induced beam pointing errors. We introduce a Dynamic\nBeam-Stabilized (DBS) processor capable of beam adaptation through on-chip\nreal-time control of fundamental gain, phase, and delay for each element. (2)\nPrior conformal arrays have leveraged additive printing to enhance flexibility,\nbut conventional printable inks based on silver are expensive, and those based\non copper suffer from spontaneous metal oxidation that alters trace impedance\nand degrades beamforming performance. We instead leverage a low-cost Copper\nMolecular Decomposition (CuMOD) ink with < 0.1% variation per degree C with\ntemperature and strain and correct any residual deformity in real-time using\nthe DBS processor. Demonstrating unified material and physical deformation\ncorrection, our CMOS DBS processor is low power, low-area, and easily scalable\ndue to a tile architecture, thereby ideal for on-device implementations.", "published": "2025-05-15 00:20:24", "link": "http://arxiv.org/abs/2505.09870v1", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "NVSPolicy: Adaptive Novel-View Synthesis for Generalizable Language-Conditioned Policy Learning", "abstract": "Recent advances in deep generative models demonstrate unprecedented zero-shot\ngeneralization capabilities, offering great potential for robot manipulation in\nunstructured environments. Given a partial observation of a scene, deep\ngenerative models could generate the unseen regions and therefore provide more\ncontext, which enhances the capability of robots to generalize across unseen\nenvironments. However, due to the visual artifacts in generated images and\ninefficient integration of multi-modal features in policy learning, this\ndirection remains an open challenge. We introduce NVSPolicy, a generalizable\nlanguage-conditioned policy learning method that couples an adaptive novel-view\nsynthesis module with a hierarchical policy network. Given an input image,\nNVSPolicy dynamically selects an informative viewpoint and synthesizes an\nadaptive novel-view image to enrich the visual context. To mitigate the impact\nof the imperfect synthesized images, we adopt a cycle-consistent VAE mechanism\nthat disentangles the visual features into the semantic feature and the\nremaining feature. The two features are then fed into the hierarchical policy\nnetwork respectively: the semantic feature informs the high-level meta-skill\nselection, and the remaining feature guides low-level action estimation.\nMoreover, we propose several practical mechanisms to make the proposed method\nefficient. Extensive experiments on CALVIN demonstrate the state-of-the-art\nperformance of our method. Specifically, it achieves an average success rate of\n90.4\\% across all tasks, greatly outperforming the recent methods. Ablation\nstudies confirm the significance of our adaptive novel-view synthesis paradigm.\nIn addition, we evaluate NVSPolicy on a real-world robotic platform to\ndemonstrate its practical applicability.", "published": "2025-05-15 14:51:14", "link": "http://arxiv.org/abs/2505.10359v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval", "abstract": "The rapid spread of online disinformation presents a global challenge, and\nmachine learning has been widely explored as a potential solution. However,\nmultilingual settings and low-resource languages are often neglected in this\nfield. To address this gap, we conducted a shared task on multilingual claim\nretrieval at SemEval 2025, aimed at identifying fact-checked claims that match\nnewly encountered claims expressed in social media posts across different\nlanguages. The task includes two subtracks: (1) a monolingual track, where\nsocial posts and claims are in the same language, and (2) a crosslingual track,\nwhere social posts and claims might be in different languages. A total of 179\nparticipants registered for the task contributing to 52 test submissions. 23\nout of 31 teams have submitted their system papers. In this paper, we report\nthe best-performing systems as well as the most common and the most effective\napproaches across both subtracks. This shared task, along with its dataset and\nparticipating systems, provides valuable insights into multilingual claim\nretrieval and automated fact-checking, supporting future research in this\nfield.", "published": "2025-05-15 23:04:46", "link": "http://arxiv.org/abs/2505.10740v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Model Performance-Guided Evaluation Data Selection for Effective Prompt Optimization", "abstract": "Optimizing Large Language Model (LLM) performance requires well-crafted\nprompts, but manual prompt engineering is labor-intensive and often\nineffective. Automated prompt optimization techniques address this challenge\nbut the majority of them rely on randomly selected evaluation subsets, which\nfail to represent the full dataset, leading to unreliable evaluations and\nsuboptimal prompts. Existing coreset selection methods, designed for LLM\nbenchmarking, are unsuitable for prompt optimization due to challenges in\nclustering similar samples, high data collection costs, and the unavailability\nof performance data for new or private datasets. To overcome these issues, we\npropose IPOMP, an Iterative evaluation data selection for effective Prompt\nOptimization using real-time Model Performance. IPOMP is a two-stage approach\nthat selects representative and diverse samples using semantic clustering and\nboundary analysis, followed by iterative refinement with real-time model\nperformance data to replace redundant samples. Evaluations on the BIG-bench\ndataset show that IPOMP improves effectiveness by 1.6% to 5.3% and stability by\nat least 57% compared with SOTA baselines, with minimal computational overhead\nbelow 1%. Furthermore, the results demonstrate that our real-time\nperformance-guided refinement approach can be universally applied to enhance\nexisting coreset selection methods.", "published": "2025-05-15 22:41:30", "link": "http://arxiv.org/abs/2505.10736v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Tracr-Injection: Distilling Algorithms into Pre-trained Language Models", "abstract": "Motivated by the surge of large language models, there has been a push to\nformally characterize the symbolic abilities intrinsic to the transformer\narchitecture. A programming language, called RASP, has been proposed, which can\nbe directly compiled into transformer weights to implement these algorithms.\nHowever, the tasks that can be implemented in RASP are often uncommon to learn\nfrom natural unsupervised data, showing a mismatch between theoretical\ncapabilities of the transformer architecture, and the practical learnability of\nthese capabilities from unsupervised data. We propose tracr-injection, a method\nthat allows us to distill algorithms written in RASP directly into a\npre-trained language model. We showcase our method by injecting 3 different\nalgorithms into a language model. We show how our method creates an\ninterpretable subspace within the model's residual stream, which can be decoded\ninto the variables present in the code of the RASP algorithm. Additionally, we\nfound that the proposed method can improve out of distribution performance\ncompared to our baseline, indicating that indeed a more symbolic mechanism is\ntaking place in the inner workings of the model. We release the code used to\nrun our experiments.", "published": "2025-05-15 21:43:51", "link": "http://arxiv.org/abs/2505.10719v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AI-enhanced semantic feature norms for 786 concepts", "abstract": "Semantic feature norms have been foundational in the study of human\nconceptual knowledge, yet traditional methods face trade-offs between\nconcept/feature coverage and verifiability of quality due to the\nlabor-intensive nature of norming studies. Here, we introduce a novel approach\nthat augments a dataset of human-generated feature norms with responses from\nlarge language models (LLMs) while verifying the quality of norms against\nreliable human judgments. We find that our AI-enhanced feature norm dataset,\nNOVA: Norms Optimized Via AI, shows much higher feature density and overlap\namong concepts while outperforming a comparable human-only norm dataset and\nword-embedding models in predicting people's semantic similarity judgments.\nTaken together, we demonstrate that human conceptual knowledge is richer than\ncaptured in previous norm datasets and show that, with proper validation, LLMs\ncan serve as powerful tools for cognitive science research.", "published": "2025-05-15 21:43:34", "link": "http://arxiv.org/abs/2505.10718v1", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment", "abstract": "High computation costs and latency of large language models such as GPT-4\nhave limited their deployment in clinical settings. Small language models\n(SLMs) offer a cost-effective alternative, but their limited capacity requires\nbiomedical domain adaptation, which remains challenging. An additional\nbottleneck is the unavailability and high sensitivity of clinical data. To\naddress these challenges, we propose a novel framework for adapting SLMs into\nhigh-performing clinical models. We introduce the MediPhi collection of\n3.8B-parameter SLMs developed with our novel framework: pre-instruction tuning\nof experts on relevant medical and clinical corpora (PMC, Medical Guideline,\nMedWiki, etc.), model merging, and clinical-tasks alignment. To cover most\nclinical tasks, we extended the CLUE benchmark to CLUE+, doubling its size. Our\nexpert models deliver relative improvements on this benchmark over the base\nmodel without any task-specific fine-tuning: 64.3% on medical entities, 49.5%\non radiology reports, and 44% on ICD-10 coding (outperforming GPT-4-0125 by\n14%). We unify the expert models into MediPhi via model merging, preserving\ngains across benchmarks. Furthermore, we built the MediFlow collection, a\nsynthetic dataset of 2.5 million high-quality instructions on 14 medical NLP\ntasks, 98 fine-grained document types, and JSON format support. Alignment of\nMediPhi using supervised fine-tuning and direct preference optimization\nachieves further gains of 18.9% on average.", "published": "2025-05-15 21:40:21", "link": "http://arxiv.org/abs/2505.10717v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GeoGrid-Bench: Can Foundation Models Understand Multimodal Gridded Geo-Spatial Data?", "abstract": "We present GeoGrid-Bench, a benchmark designed to evaluate the ability of\nfoundation models to understand geo-spatial data in the grid structure.\nGeo-spatial datasets pose distinct challenges due to their dense numerical\nvalues, strong spatial and temporal dependencies, and unique multimodal\nrepresentations including tabular data, heatmaps, and geographic\nvisualizations. To assess how foundation models can support scientific research\nin this domain, GeoGrid-Bench features large-scale, real-world data covering 16\nclimate variables across 150 locations and extended time frames. The benchmark\nincludes approximately 3,200 question-answer pairs, systematically generated\nfrom 8 domain expert-curated templates to reflect practical tasks encountered\nby human scientists. These range from basic queries at a single location and\ntime to complex spatiotemporal comparisons across regions and periods. Our\nevaluation reveals that vision-language models perform best overall, and we\nprovide a fine-grained analysis of the strengths and limitations of different\nfoundation models in different geo-spatial tasks. This benchmark offers clearer\ninsights into how foundation models can be effectively applied to geo-spatial\ndata analysis and used to support scientific research.", "published": "2025-05-15 21:31:44", "link": "http://arxiv.org/abs/2505.10714v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Artificial Intelligence Bias on English Language Learners in Automatic Scoring", "abstract": "This study investigated potential scoring biases and disparities toward\nEnglish Language Learners (ELLs) when using automatic scoring systems for\nmiddle school students' written responses to science assessments. We\nspecifically focus on examining how unbalanced training data with ELLs\ncontributes to scoring bias and disparities. We fine-tuned BERT with four\ndatasets: responses from (1) ELLs, (2) non-ELLs, (3) a mixed dataset reflecting\nthe real-world proportion of ELLs and non-ELLs (unbalanced), and (4) a balanced\nmixed dataset with equal representation of both groups. The study analyzed 21\nassessment items: 10 items with about 30,000 ELL responses, five items with\nabout 1,000 ELL responses, and six items with about 200 ELL responses. Scoring\naccuracy (Acc) was calculated and compared to identify bias using Friedman\ntests. We measured the Mean Score Gaps (MSGs) between ELLs and non-ELLs and\nthen calculated the differences in MSGs generated through both the human and AI\nmodels to identify the scoring disparities. We found that no AI bias and\ndistorted disparities between ELLs and non-ELLs were found when the training\ndataset was large enough (ELL = 30,000 and ELL = 1,000), but concerns could\nexist if the sample size is limited (ELL = 200).", "published": "2025-05-15 18:32:24", "link": "http://arxiv.org/abs/2505.10643v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly", "abstract": "The rapid extension of context windows in large vision-language models has\ngiven rise to long-context vision-language models (LCVLMs), which are capable\nof handling hundreds of images with interleaved text tokens in a single forward\npass. In this work, we introduce MMLongBench, the first benchmark covering a\ndiverse set of long-context vision-language tasks, to evaluate LCVLMs\neffectively and thoroughly. MMLongBench is composed of 13,331 examples spanning\nfive different categories of downstream tasks, such as Visual RAG and Many-Shot\nICL. It also provides broad coverage of image types, including various natural\nand synthetic images. To assess the robustness of the models to different input\nlengths, all examples are delivered at five standardized input lengths (8K-128K\ntokens) via a cross-modal tokenization scheme that combines vision patches and\ntext tokens. Through a thorough benchmarking of 46 closed-source and\nopen-source LCVLMs, we provide a comprehensive analysis of the current models'\nvision-language long-context ability. Our results show that: i) performance on\na single task is a weak proxy for overall long-context capability; ii) both\nclosed-source and open-source models face challenges in long-context\nvision-language tasks, indicating substantial room for future improvement; iii)\nmodels with stronger reasoning ability tend to exhibit better long-context\nperformance. By offering wide task coverage, various image types, and rigorous\nlength control, MMLongBench provides the missing foundation for diagnosing and\nadvancing the next generation of LCVLMs.", "published": "2025-05-15 17:52:54", "link": "http://arxiv.org/abs/2505.10610v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations", "abstract": "Semantic text representation is a fundamental task in the field of natural\nlanguage processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have\ndemonstrated excellent performance, but the values of each dimension are\ndifficult to trace and interpret. Bag-of-words, as classic sparse interpretable\nembeddings, suffers from poor performance. Recently, Benara et al. (2024)\npropose interpretable text embeddings using large language models, which forms\n\"0/1\" embeddings based on responses to a series of questions. These\ninterpretable text embeddings are typically high-dimensional (larger than\n10,000). In this work, we propose Low-dimensional (lower than 500) Dense and\nInterpretable text embeddings with Relative representations (LDIR). The\nnumerical values of its dimensions indicate semantic relatedness to different\nanchor texts through farthest point sampling, offering both semantic\nrepresentation as well as a certain level of traceability and interpretability.\nWe validate LDIR on multiple semantic textual similarity, retrieval, and\nclustering tasks. Extensive experimental results show that LDIR performs close\nto the black-box baseline models and outperforms the interpretable embeddings\nbaselines with much fewer dimensions. Code is available at\nhttps://github.com/szu-tera/LDIR.", "published": "2025-05-15 14:45:45", "link": "http://arxiv.org/abs/2505.10354v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mapping Semantic Segmentation to Point Clouds Using Structure from Motion for Forest Analysis", "abstract": "Although the use of remote sensing technologies for monitoring forested\nenvironments has gained increasing attention, publicly available point cloud\ndatasets remain scarce due to the high costs, sensor requirements, and\ntime-intensive nature of their acquisition. Moreover, as far as we are aware,\nthere are no public annotated datasets generated through Structure From Motion\n(SfM) algorithms applied to imagery, which may be due to the lack of SfM\nalgorithms that can map semantic segmentation information into an accurate\npoint cloud, especially in a challenging environment like forests.\n  In this work, we present a novel pipeline for generating semantically\nsegmented point clouds of forest environments. Using a custom-built forest\nsimulator, we generate realistic RGB images of diverse forest scenes along with\ntheir corresponding semantic segmentation masks. These labeled images are then\nprocessed using modified open-source SfM software capable of preserving\nsemantic information during 3D reconstruction. The resulting point clouds\nprovide both geometric and semantic detail, offering a valuable resource for\ntraining and evaluating deep learning models aimed at segmenting real forest\npoint clouds obtained via SfM.", "published": "2025-05-15 23:34:55", "link": "http://arxiv.org/abs/2505.10751v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "IMAGE-ALCHEMY: Advancing subject fidelity in personalised text-to-image generation", "abstract": "Recent advances in text-to-image diffusion models, particularly Stable\nDiffusion, have enabled the generation of highly detailed and semantically rich\nimages. However, personalizing these models to represent novel subjects based\non a few reference images remains challenging. This often leads to catastrophic\nforgetting, overfitting, or large computational overhead.We propose a two-stage\npipeline that addresses these limitations by leveraging LoRA-based fine-tuning\non the attention weights within the U-Net of the Stable Diffusion XL (SDXL)\nmodel. First, we use the unmodified SDXL to generate a generic scene by\nreplacing the subject with its class label. Then, we selectively insert the\npersonalized subject through a segmentation-driven image-to-image (Img2Img)\npipeline that uses the trained LoRA weights.This framework isolates the subject\nencoding from the overall composition, thus preserving SDXL's broader\ngenerative capabilities while integrating the new subject in a high-fidelity\nmanner. Our method achieves a DINO similarity score of 0.789 on SDXL,\noutperforming existing personalized text-to-image approaches.", "published": "2025-05-15 23:08:52", "link": "http://arxiv.org/abs/2505.10743v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Automated Detection of Salvin's Albatrosses: Improving Deep Learning Tools for Aerial Wildlife Surveys", "abstract": "Recent advancements in deep learning and aerial imaging have transformed\nwildlife monitoring, enabling researchers to survey wildlife populations at\nunprecedented scales. Unmanned Aerial Vehicles (UAVs) provide a cost-effective\nmeans of capturing high-resolution imagery, particularly for monitoring densely\npopulated seabird colonies. In this study, we assess the performance of a\ngeneral-purpose avian detection model, BirdDetector, in estimating the breeding\npopulation of Salvin's albatross (Thalassarche salvini) on the Bounty Islands,\nNew Zealand. Using drone-derived imagery, we evaluate the model's effectiveness\nin both zero-shot and fine-tuned settings, incorporating enhanced inference\ntechniques and stronger augmentation methods. Our findings indicate that while\napplying the model in a zero-shot setting offers a strong baseline, fine-tuning\nwith annotations from the target domain and stronger image augmentation leads\nto marked improvements in detection accuracy. These results highlight the\npotential of leveraging pre-trained deep-learning models for species-specific\nmonitoring in remote and challenging environments.", "published": "2025-05-15 22:42:44", "link": "http://arxiv.org/abs/2505.10737v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Adaptive Spatial Transcriptomics Interpolation via Cross-modal Cross-slice Modeling", "abstract": "Spatial transcriptomics (ST) is a promising technique that characterizes the\nspatial gene profiling patterns within the tissue context. Comprehensive ST\nanalysis depends on consecutive slices for 3D spatial insights, whereas the\nmissing intermediate tissue sections and high costs limit the practical\nfeasibility of generating multi-slice ST. In this paper, we propose C2-STi, the\nfirst attempt for interpolating missing ST slices at arbitrary intermediate\npositions between adjacent ST slices. Despite intuitive, effective ST\ninterpolation presents significant challenges, including 1) limited continuity\nacross heterogeneous tissue sections, 2) complex intrinsic correlation across\ngenes, and 3) intricate cellular structures and biological semantics within\neach tissue section. To mitigate these challenges, in C2-STi, we design 1) a\ndistance-aware local structural modulation module to adaptively capture\ncross-slice deformations and enhance positional correlations between ST slices,\n2) a pyramid gene co-expression correlation module to capture multi-scale\nbiological associations among genes, and 3) a cross-modal alignment module that\nintegrates the ST-paired hematoxylin and eosin (H&E)-stained images to filter\nand align the essential cellular features across ST and H\\&E images. Extensive\nexperiments on the public dataset demonstrate our superiority over\nstate-of-the-art approaches on both single-slice and multi-slice ST\ninterpolation. Codes are available at\nhttps://github.com/XiaofeiWang2018/C2-STi.", "published": "2025-05-15 22:14:39", "link": "http://arxiv.org/abs/2505.10729v1", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "primary_category": "eess.IV"}
{"title": "TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation", "abstract": "We present TartanGround, a large-scale, multi-modal dataset to advance the\nperception and autonomy of ground robots operating in diverse environments.\nThis dataset, collected in various photorealistic simulation environments\nincludes multiple RGB stereo cameras for 360-degree coverage, along with depth,\noptical flow, stereo disparity, LiDAR point clouds, ground truth poses,\nsemantic segmented images, and occupancy maps with semantic labels. Data is\ncollected using an integrated automatic pipeline, which generates trajectories\nmimicking the motion patterns of various ground robot platforms, including\nwheeled and legged robots. We collect 910 trajectories across 70 environments,\nresulting in 1.5 million samples. Evaluations on occupancy prediction and SLAM\ntasks reveal that state-of-the-art methods trained on existing datasets\nstruggle to generalize across diverse scenes. TartanGround can serve as a\ntestbed for training and evaluation of a broad range of learning-based tasks,\nincluding occupancy prediction, SLAM, neural scene representation,\nperception-based navigation, and more, enabling advancements in robotic\nperception and autonomy towards achieving robust models generalizable to more\ndiverse scenarios. The dataset and codebase for data collection will be made\npublicly available upon acceptance. Webpage: https://tartanair.org/tartanground", "published": "2025-05-15 20:35:06", "link": "http://arxiv.org/abs/2505.10696v1", "categories": ["cs.RO", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Predicting Risk of Pulmonary Fibrosis Formation in PASC Patients", "abstract": "While the acute phase of the COVID-19 pandemic has subsided, its long-term\neffects persist through Post-Acute Sequelae of COVID-19 (PASC), commonly known\nas Long COVID. There remains substantial uncertainty regarding both its\nduration and optimal management strategies. PASC manifests as a diverse array\nof persistent or newly emerging symptoms--ranging from fatigue, dyspnea, and\nneurologic impairments (e.g., brain fog), to cardiovascular, pulmonary, and\nmusculoskeletal abnormalities--that extend beyond the acute infection phase.\nThis heterogeneous presentation poses substantial challenges for clinical\nassessment, diagnosis, and treatment planning. In this paper, we focus on\nimaging findings that may suggest fibrotic damage in the lungs, a critical\nmanifestation characterized by scarring of lung tissue, which can potentially\naffect long-term respiratory function in patients with PASC. This study\nintroduces a novel multi-center chest CT analysis framework that combines deep\nlearning and radiomics for fibrosis prediction. Our approach leverages\nconvolutional neural networks (CNNs) and interpretable feature extraction,\nachieving 82.2% accuracy and 85.5% AUC in classification tasks. We demonstrate\nthe effectiveness of Grad-CAM visualization and radiomics-based feature\nanalysis in providing clinically relevant insights for PASC-related lung\nfibrosis prediction. Our findings highlight the potential of deep\nlearning-driven computational methods for early detection and risk assessment\nof PASC-related lung fibrosis--presented for the first time in the literature.", "published": "2025-05-15 20:30:21", "link": "http://arxiv.org/abs/2505.10691v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A probabilistic framework for dynamic quantization", "abstract": "We propose a probabilistic framework for dynamic quantization of neural\nnetworks that allows for a computationally efficient input-adaptive rescaling\nof the quantization parameters. Our framework applies a probabilistic model to\nthe network's pre-activations through a lightweight surrogate, enabling the\nadaptive adjustment of the quantization parameters on a per-input basis without\nsignificant memory overhead. We validate our approach on a set of popular\ncomputer vision tasks and models, observing only a negligible loss in\nperformance. Our method strikes the best performance and computational overhead\ntradeoff compared to standard quantization strategies.", "published": "2025-05-15 20:26:46", "link": "http://arxiv.org/abs/2505.10689v1", "categories": ["cs.LG", "cs.CV"], "primary_category": "cs.LG"}
{"title": "ROIsGAN: A Region Guided Generative Adversarial Framework for Murine Hippocampal Subregion Segmentation", "abstract": "The hippocampus, a critical brain structure involved in memory processing and\nvarious neurodegenerative and psychiatric disorders, comprises three key\nsubregions: the dentate gyrus (DG), Cornu Ammonis 1 (CA1), and Cornu Ammonis 3\n(CA3). Accurate segmentation of these subregions from histological tissue\nimages is essential for advancing our understanding of disease mechanisms,\ndevelopmental dynamics, and therapeutic interventions. However, no existing\nmethods address the automated segmentation of hippocampal subregions from\ntissue images, particularly from immunohistochemistry (IHC) images. To bridge\nthis gap, we introduce a novel set of four comprehensive murine hippocampal IHC\ndatasets featuring distinct staining modalities: cFos, NeuN, and multiplexed\nstains combining cFos, NeuN, and either {\\Delta}FosB or GAD67, capturing\nstructural, neuronal activity, and plasticity associated information.\nAdditionally, we propose ROIsGAN, a region-guided U-Net-based generative\nadversarial network tailored for hippocampal subregion segmentation. By\nleveraging adversarial learning, ROIsGAN enhances boundary delineation and\nstructural detail refinement through a novel region-guided discriminator loss\ncombining Dice and binary cross-entropy loss. Evaluated across DG, CA1, and CA3\nsubregions, ROIsGAN consistently outperforms conventional segmentation models,\nachieving performance gains ranging from 1-10% in Dice score and up to 11% in\nIntersection over Union (IoU), particularly under challenging staining\nconditions. Our work establishes foundational datasets and methods for\nautomated hippocampal segmentation, enabling scalable, high-precision analysis\nof tissue images in neuroscience research. Our generated datasets, proposed\nmodel as a standalone tool, and its corresponding source code are publicly\navailable at: https://github.com/MehediAzim/ROIsGAN", "published": "2025-05-15 20:11:50", "link": "http://arxiv.org/abs/2505.10687v1", "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.NC"], "primary_category": "eess.IV"}
{"title": "GaussianFormer3D: Multi-Modal Gaussian-based Semantic Occupancy Prediction with 3D Deformable Attention", "abstract": "3D semantic occupancy prediction is critical for achieving safe and reliable\nautonomous driving. Compared to camera-only perception systems, multi-modal\npipelines, especially LiDAR-camera fusion methods, can produce more accurate\nand detailed predictions. Although most existing works utilize a dense\ngrid-based representation, in which the entire 3D space is uniformly divided\ninto discrete voxels, the emergence of 3D Gaussians provides a compact and\ncontinuous object-centric representation. In this work, we propose a\nmulti-modal Gaussian-based semantic occupancy prediction framework utilizing 3D\ndeformable attention, named as GaussianFormer3D. We introduce a\nvoxel-to-Gaussian initialization strategy to provide 3D Gaussians with geometry\npriors from LiDAR data, and design a LiDAR-guided 3D deformable attention\nmechanism for refining 3D Gaussians with LiDAR-camera fusion features in a\nlifted 3D space. We conducted extensive experiments on both on-road and\noff-road datasets, demonstrating that our GaussianFormer3D achieves high\nprediction accuracy that is comparable to state-of-the-art multi-modal\nfusion-based methods with reduced memory consumption and improved efficiency.", "published": "2025-05-15 20:05:08", "link": "http://arxiv.org/abs/2505.10685v1", "categories": ["cs.CV"], "primary_category": "cs.CV"}
{"title": "Prefix-bounded matrices", "abstract": "By unifying various earlier extensions of alternating sign matrices (ASMs),\nwe introduce the notion of prefix-bounded matrices (PBMs). It is shown that the\nconvex hull of these matrices forms the intersection of two special (called\nlaminar) g-polymatroids. This implies (in a more general form) that the linear\ninequality system given by Behrend and Knight and by Striker for describing the\npolytope of alternating sign matrices is TDI, confirming a recent conjecture of\nEdmonds. By relying on the polymatroidal approach, we derive a characterization\nfor the existence of prefix-bounded matrices meeting upper and lower bound\nrequirements on their entries.\n  Furthermore, we point out that the constraint matrix of the linear system\ndescribing the convex hull of PBMs (in particular, ASMs) is a network matrix.\nThis implies that (a) standard network flow techniques can be used to manage\nalgorithmically optimization and structural results on PBMs obtained via\ng-polymatroids, (b) the linear system is actually box-TDI, and (c) the convex\nhull of PBMs has (a sharpened form of) the integer Carath\\'eodory property, in\nparticular, the integer decomposition property. This latter feature makes it\npossible to confirm (in an extended form) an elegant conjecture of Brualdi and\nDahl on the decomposability of a so-called $k$-regular alternating sign matrix\nas the sum of $k$ pattern-disjoint ASMs.", "published": "2025-05-15 22:52:43", "link": "http://arxiv.org/abs/2505.10739v1", "categories": ["math.CO", "cs.DM", "cs.DS", "math.OC"], "primary_category": "math.CO"}
{"title": "Impact of (a)Synchronism on ECA: Towards a New Classification", "abstract": "In this paper, we study the effect of (a)synchronism on the dynamics of\nelementary cellular automata. Within the framework of our study, we choose five\ndistinct update schemes, selected from the family of periodic update modes:\nparallel, sequential, block-sequential, block-parallel, and local clocks. Our\nmain measure of complexity is the maximum period of the limit cycles in the\ndynamics of each rule. In this context, we present a classification of the ECA\nrule landscape. We classified most elementary rules into three distinct\nregimes: constant, linear, and superpolynomial. Surprisingly, while some rules\nexhibit more complex behavior under a broader class of update schemes, others\nshow similar behavior across all the considered update schemes. Although we are\nable to derive upper and lower bounds for the maximum period of the limit\ncycles in most cases, the analysis of some rules remains open. To complement\nthe study of the 88 elementary rules, we introduce a numerical simulation\nframework based on two main measurements: the energy and density of the\nconfigurations. In this context, we observe that some rules exhibit significant\nvariability depending on the update scheme, while others remain stable,\nconfirming what was observed as a result of the classification obtained in the\ntheoretical analysis.", "published": "2025-05-15 18:35:43", "link": "http://arxiv.org/abs/2505.10645v1", "categories": ["cs.DM", "math.DS", "nlin.CG", "68 (Primary)", "G.2.0"], "primary_category": "cs.DM"}
{"title": "Decision Making in Urban Traffic: A Game Theoretic Approach for Autonomous Vehicles Adhering to Traffic Rules", "abstract": "One of the primary challenges in urban autonomous vehicle decision-making and\nplanning lies in effectively managing intricate interactions with diverse\ntraffic participants characterized by unpredictable movement patterns.\nAdditionally, interpreting and adhering to traffic regulations within rapidly\nevolving traffic scenarios pose significant hurdles. This paper proposed a\nrule-based autonomous vehicle decision-making and planning framework which\nextracts right-of-way from traffic rules to generate behavioural parameters,\nintegrating them to effectively adhere to and navigate through traffic\nregulations. The framework considers the strong interaction between traffic\nparticipants mathematically by formulating the decision-making and planning\nproblem into a differential game. By finding the Nash equilibrium of the\nproblem, the autonomous vehicle is able to find optimal decisions. The proposed\nframework was tested under simulation as well as full-size vehicle platform,\nthe results show that the ego vehicle is able to safely interact with\nsurrounding traffic participants while adhering to traffic rules.", "published": "2025-05-15 20:26:54", "link": "http://arxiv.org/abs/2505.10690v1", "categories": ["cs.MA", "cs.GT", "cs.RO"], "primary_category": "cs.MA"}
{"title": "Agent Name Service (ANS): A Universal Directory for Secure AI Agent Discovery and Interoperability", "abstract": "The proliferation of AI agents requires robust mechanisms for secure\ndiscovery. This paper introduces the Agent Name Service (ANS), a novel\narchitecture based on DNS addressing the lack of a public agent discovery\nframework. ANS provides a protocol-agnostic registry infrastructure that\nleverages Public Key Infrastructure (PKI) certificates for verifiable agent\nidentity and trust. The architecture features several key innovations: a\nformalized agent registration and renewal mechanism for lifecycle management;\nDNS-inspired naming conventions with capability-aware resolution; a modular\nProtocol Adapter Layer supporting diverse communication standards (A2A, MCP,\nACP etc.); and precisely defined algorithms for secure resolution. We implement\nstructured communication using JSON Schema and conduct a comprehensive threat\nanalysis of our proposal. The result is a foundational directory service\naddressing the core challenges of secured discovery and interaction in\nmulti-agent systems, paving the way for future interoperable, trustworthy, and\nscalable agent ecosystems.", "published": "2025-05-15 17:49:36", "link": "http://arxiv.org/abs/2505.10609v1", "categories": ["cs.CR", "cs.AI", "cs.MA", "cs.NI"], "primary_category": "cs.CR"}
{"title": "Maximum likelihood discretization of the transport equation", "abstract": "The transport of positive quantities underlies countless physical processes,\nincluding fluid, gas, and plasma dynamics. Discretizing the associated partial\ndifferential equations with Galerkin methods can result in spurious\nnonpositivity of solutions. We observe that these methods amount to performing\nstatistical inference using the method of moments (MoM) and that the loss of\npositivity arises from MoM's susceptibility to producing estimates inconsistent\nwith the observed data. We overcome this problem by replacing MoM with maximum\nlikelihood estimation, introducing $\\textit{maximum likelihood discretization}\n$(MLD). In the continuous limit, MLD simplifies to the Fisher-Rao Galerkin\n(FRG) semidiscretization, which replaces the $L^2$ inner product in Galerkin\nprojection with the Fisher-Rao metric of probability distributions. We show\nempirically that FRG preserves positivity. We prove rigorously that it yields\nerror bounds in the Kullback-Leibler divergence.", "published": "2025-05-15 21:22:57", "link": "http://arxiv.org/abs/2505.10713v1", "categories": ["math.NA", "cs.NA", "stat.CO", "35L65, 76L05, 65M25, 76J20, 58B20"], "primary_category": "math.NA"}
{"title": "Surface stability of a layered magnetoelastic half-space", "abstract": "We evaluate the conditions for surface stability of a layered magnetoelastic\nhalf-space subjected to large deformations and a magnetic field. After\nreviewing the fundamental measures of deformation and summarizing the\nmagnetostatic equations in Eulerian and Lagrangian forms, we derive the\nconstitutive relations from a total energy function dependent on the\ndeformation gradient and Lagrangian magnetic induction. Energy principles yield\nthe equilibrium equations, magnetic field equations, and boundary conditions.\nThe second variation of the energy functional provides the incremental\nequations and conditions for stability analysis. Surface instability is studied\nby linearizing increments of deformation and magnetic induction about a\nfinitely deformed state under a magnetic field normal to the surface. Four\nillustrative cases are considered: (i) a layered non-magnetizable half-space\nwith varying stiffness contrast; (ii) the critical stretch of a magnetoelastic\nhalf-space as a function of magnetic induction; (iii) surface stability of a\nmagneto-sensitive layer atop a non-magnetizable substrate; and (iv) bifurcation\nconditions in a two-layered magnetoelastic solid with different stiffness\nratios. Graphical results are provided throughout.", "published": "2025-05-15 19:10:05", "link": "http://arxiv.org/abs/2505.10660v1", "categories": ["math.NA", "cond-mat.mtrl-sci", "cs.NA", "math-ph", "math.MP"], "primary_category": "math.NA"}
{"title": "Asymptotically-Optimal Gaussian Bandits with Side Observations", "abstract": "We study the problem of Gaussian bandits with general side information, as\nfirst introduced by Wu, Szepesvari, and Gyorgy. In this setting, the play of an\narm reveals information about other arms, according to an arbitrary a priori\nknown side information matrix: each element of this matrix encodes the fidelity\nof the information that the ``row'' arm reveals about the ``column'' arm. In\nthe case of Gaussian noise, this model subsumes standard bandits,\nfull-feedback, and graph-structured feedback as special cases. In this work, we\nfirst construct an LP-based asymptotic instance-dependent lower bound on the\nregret. The LP optimizes the cost (regret) required to reliably estimate the\nsuboptimality gap of each arm. This LP lower bound motivates our main\ncontribution: the first known asymptotically optimal algorithm for this general\nsetting.", "published": "2025-05-15 20:43:42", "link": "http://arxiv.org/abs/2505.10698v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Minimax learning rates for estimating binary classifiers under margin conditions", "abstract": "We study classification problems using binary estimators where the decision\nboundary is described by horizon functions and where the data distribution\nsatisfies a geometric margin condition. We establish upper and lower bounds for\nthe minimax learning rate over broad function classes with bounded Kolmogorov\nentropy in Lebesgue norms. A key novelty of our work is the derivation of lower\nbounds on the worst-case learning rates under a geometric margin condition -- a\nsetting that is almost universally satisfied in practice but remains\ntheoretically challenging. Moreover, our results deal with the noiseless\nsetting, where lower bounds are particularly hard to establish. We apply our\ngeneral results to classification problems with decision boundaries belonging\nto several function classes: for Barron-regular functions, and for\nH\\\"older-continuous functions with strong margins, we identify optimal rates\nclose to the fast learning rates of $\\mathcal{O}(n^{-1})$ for $n \\in\n\\mathbb{N}$ samples. Also for merely convex decision boundaries, in a strong\nmargin case optimal rates near $\\mathcal{O}(n^{-1/2})$ can be achieved.", "published": "2025-05-15 18:05:10", "link": "http://arxiv.org/abs/2505.10628v1", "categories": ["stat.ML", "cs.LG", "math.PR", "68T05, 62C20, 41A25, 41A46"], "primary_category": "stat.ML"}
{"title": "An Exponential Averaging Process with Strong Convergence Properties", "abstract": "Averaging, or smoothing, is a fundamental approach to obtain stable,\nde-noised estimates from noisy observations. In certain scenarios, observations\nmade along trajectories of random dynamical systems are of particular interest.\nOne popular smoothing technique for such a scenario is exponential moving\naveraging (EMA), which assigns observations a weight that decreases\nexponentially in their age, thus giving younger observations a larger weight.\nHowever, EMA fails to enjoy strong stochastic convergence properties, which\nstems from the fact that the weight assigned to the youngest observation is\nconstant over time, preventing the noise in the averaged quantity from\ndecreasing to zero. In this work, we consider an adaptation to EMA, which we\ncall $p$-EMA, where the weights assigned to the last observations decrease to\nzero at a subharmonic rate. We provide stochastic convergence guarantees for\nthis kind of averaging under mild assumptions on the autocorrelations of the\nunderlying random dynamical system. We further discuss the implications of our\nresults for a recently introduced adaptive step size control for Stochastic\nGradient Descent (SGD), which uses $p$-EMA for averaging noisy observations.", "published": "2025-05-15 16:19:58", "link": "http://arxiv.org/abs/2505.10605v1", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.TH", "60F15 (Primary) 60G10, 60J20, 68T05, 90C15 (Secondary)"], "primary_category": "stat.ML"}
{"title": "Whitened Score Diffusion: A Structured Prior for Imaging Inverse Problems", "abstract": "Conventional score-based diffusion models (DMs) may struggle with anisotropic\nGaussian diffusion processes due to the required inversion of covariance\nmatrices in the denoising score matching training objective\n\\cite{vincent_connection_2011}. We propose Whitened Score (WS) diffusion\nmodels, a novel SDE-based framework that learns the Whitened Score function\ninstead of the standard score. This approach circumvents covariance inversion,\nextending score-based DMs by enabling stable training of DMs on arbitrary\nGaussian forward noising processes. WS DMs establish equivalence with FM for\narbitrary Gaussian noise, allow for tailored spectral inductive biases, and\nprovide strong Bayesian priors for imaging inverse problems with structured\nnoise. We experiment with a variety of computational imaging tasks using the\nCIFAR and CelebA ($64\\times64$) datasets and demonstrate that WS diffusion\npriors trained on anisotropic Gaussian noising processes consistently\noutperform conventional diffusion priors based on isotropic Gaussian noise.", "published": "2025-05-15 13:55:55", "link": "http://arxiv.org/abs/2505.10311v2", "categories": ["eess.IV", "eess.SP", "stat.AP", "stat.ML"], "primary_category": "eess.IV"}
{"title": "NeoLightning: A Modern Reimagination of Gesture-Based Sound Design", "abstract": "This paper introduces NeoLightning, a modern reinterpretation of the Buchla\nLightning. NeoLightning preserves the innovative spirit of Don Buchla's \"Buchla\nLightning\" (introduced in the 1990s) while making its gesture-based interaction\naccessible to contemporary users. While the original Buchla Lightning and many\nother historical instruments were groundbreaking in their time, they are now\nlargely unsupported, limiting user interaction to indirect experiences. To\naddress this, NeoLightning leverages MediaPipe for deep learning-based gesture\nrecognition and employs Max/MSP and Processing for real-time multimedia\nprocessing. The redesigned system offers precise, low-latency gesture\nrecognition and immersive 3D interaction. By merging the creative spirit of the\noriginal Lightning with modern advancements, NeoLightning redefines\ngesture-based musical interaction, expanding possibilities for expressive\nperformance and interactive sound design.", "published": "2025-05-15 20:09:00", "link": "http://arxiv.org/abs/2505.10686v1", "categories": ["cs.HC", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.HC"}
{"title": "From noisy observables to accurate ground state energies: a quantum classical signal subspace approach with denoising", "abstract": "We propose a hybrid quantum-classical algorithm for ground state energy (GSE)\nestimation that remains robust to highly noisy data and exhibits low\nsensitivity to hyperparameter tuning. Our approach -- Fourier Denoising\nObservable Dynamic Mode Decomposition (FDODMD) -- combines Fourier-based\ndenoising thresholding to suppress spurious noise modes with observable dynamic\nmode decomposition (ODMD), a quantum-classical signal subspace method. By\napplying ODMD to an ensemble of denoised time-domain trajectories, FDODMD\nreliably estimates the system's eigenfrequencies. We also provide an error\nanalysis of FDODMD. Numerical experiments on molecular systems demonstrate that\nFDODMD achieves convergence in high-noise regimes inaccessible to baseline\nmethods under a limited quantum computational budget, while accelerating\nspectral estimation in intermediate-noise regimes. Importantly, this\nperformance gain is entirely classical, requiring no additional quantum\noverhead and significantly reducing overall quantum resource demands.", "published": "2025-05-15 22:37:44", "link": "http://arxiv.org/abs/2505.10735v1", "categories": ["quant-ph", "cs.SY", "eess.SP", "eess.SY", "physics.comp-ph"], "primary_category": "quant-ph"}
{"title": "Clustering Rooftop PV Systems via Probabilistic Embeddings", "abstract": "As the number of rooftop photovoltaic (PV) installations increases,\naggregators and system operators are required to monitor and analyze these\nsystems, raising the challenge of integration and management of large,\nspatially distributed time-series data that are both high-dimensional and\naffected by missing values. In this work, a probabilistic entity\nembedding-based clustering framework is proposed to address these problems.\nThis method encodes each PV system's characteristic power generation patterns\nand uncertainty as a probability distribution, then groups systems by their\nstatistical distances and agglomerative clustering. Applied to a multi-year\nresidential PV dataset, it produces concise, uncertainty-aware cluster profiles\nthat outperform a physics-based baseline in representativeness and robustness,\nand support reliable missing-value imputation. A systematic hyperparameter\nstudy further offers practical guidance for balancing model performance and\nrobustness.", "published": "2025-05-15 20:44:45", "link": "http://arxiv.org/abs/2505.10699v1", "categories": ["cs.LG", "eess.SP"], "primary_category": "cs.LG"}
{"title": "Variational Bayesian Inference for Time-Varying Massive MIMO Channels: Estimation and Detection", "abstract": "Massive multiple-input multiple-output (MIMO) stands as a key technology for\nadvancing performance metrics such as data rate, reliability, and spectrum\nefficiency in the fifth generation (5G) and beyond of wireless networks.\nHowever, its efficiency depends greatly on obtaining accurate channel state\ninformation. This task becomes particularly challenging with increasing user\nmobility. In this paper, we focus on an uplink scenario in which a massive MIMO\nbase station serves multiple high-mobility users. We leverage variational\nBayesian(VB) inference for joint channel estimation and data detection(JED),\ntailored for time-varying channels. In particular, we use the VB framework to\nprovide approximations of the true posterior distributions. To cover more\nreal-world scenarios, we assume the time correlation coefficients associated\nwith the channels are unknown. Our simulations demonstrate the efficacy of our\nproposed VB-based approach in tracking these unknown time correlation\ncoefficients. We present two processing strategies within the VB framework:\nonline and block processing strategies. The online strategy offers a\nlow-complexity solution for a given time slot, requiring only the knowledge of\nthe parameters/statistics within that time slot. In contrast, the block\nprocessing strategy focuses on the entire communication block and processes all\nreceived signals together to reduce channel estimation errors. Additionally, we\nintroduce an interleaved structure for the online processing strategy to\nfurther enhance its performance. Finally, we conduct a comparative analysis of\nour VB approach against the linear minimum mean squared error(LMMSE), the\nKalman Filter(KF), and the expectation propagation(EP) methods in terms of\nsymbol error rate(SER) and channel normalized mean squared error(NMSE). Our\nfindings reveal that our VB framework surpasses these benchmarks across the\nperformance metrics.", "published": "2025-05-15 19:33:48", "link": "http://arxiv.org/abs/2505.10673v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Analog Self-Interference Cancellation in Full-Duplex Radios: A Fundamental Limit Perspective", "abstract": "Analog self-interference cancellation (A-SIC) plays a crucial role in the\nimplementation of in-band full-duplex (IBFD) radios, due to the fact that the\ninherent transmit (Tx) noise can only be addressed in the analog domain. It is\nthus natural to ask what the performance limit of A-SIC is in practical\nsystems, which is still quite underexplored so far. In this paper, we aim to\nclose this gap by characterizing the fundamental performance of A-SIC which\nemploys the common multi-tap delay (MTD) architecture, by accounting for the\nfollowing practical issues: 1) Nonstationarity of the Tx signal; 2) Nonlinear\ndistortions on the Tx signal; 3) Multipath channel corresponding to the\nself-interference (SI); 4) Maximum amplitude constraint on the MTD tap weights.\nOur findings include: 1) The average approximation error for the\ncyclostationary Tx signals is equal to that for the stationary white Gaussian\nprocess, thus greatly simplifying the performance analysis and the optimization\nprocedure. 2) The approximation error for the multipath SI channel can be\ndecomposed as the sum of the approximation error for the single-path scenario.\nBy leveraging these structural results, the optimization framework and\nalgorithms which characterize the fundamental limit of A-SIC, by taking into\naccount all the aforementioned practical factors, are provided.", "published": "2025-05-15 15:36:57", "link": "http://arxiv.org/abs/2505.10419v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Enriched K-Tier Heterogeneous Satellite Networks Model with User Association Policies", "abstract": "In the rapid evolution of the non-terrestrial networks (NTNs), satellite\ncommunication has emerged as a focal area of research due to its critical role\nin enabling seamless global connectivity. In this paper, we investigate two\nrepresentative user association policies (UAPs) for multi-tier heterogeneous\nsatellite networks (HetSatNets), namely the nearest satellite UAP and the\nmaximum signal-to-interference-plus-noise-ratio (max-SINR) satellite UAP, where\neach tier is characterized by a distinct constellation configuration and\ntransmission pattern. Employing stochastic geometric, we analyze various\nintermediate system aspects, including the probability of a typical user\naccessing each satellite tier, the aggregated interference power, and their\ncorresponding Laplace transforms (LTs) under both UAPs. Subsequently, we derive\nexplicit expressions for coverage probability (CP), non-handover probability\n(NHP), and time delay outage probability (DOP) of the typical user.\nFurthermore, we propose a novel weighted metric (WM) that integrates CP, NHP,\nand DOP to explore their trade-offs in the system design. The robustness of the\ntheoretical framework is verified is verified through Monte Carlo simulations\ncalibrated with the actual Starlink constellation, affirming the precision of\nour analytical approach. The empirical findings underscore an optimal UAP in\nvarious HetSatNet scenarios regarding CP, NHP, and DOP..", "published": "2025-05-15 03:04:36", "link": "http://arxiv.org/abs/2505.09917v2", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Dynamic Beam-Stabilized, Additive-Printed Flexible Antenna Arrays with On-Chip Rapid Insight Generation", "abstract": "Conformal phased arrays promise shape-changing properties, multiple degrees\nof freedom to the scan angle, and novel applications in wearables, aerospace,\ndefense, vehicles, and ships. However, they have suffered from two critical\nlimitations. (1) Although most applications require on-the-move communication\nand sensing, prior conformal arrays have suffered from dynamic\ndeformation-induced beam pointing errors. We introduce a Dynamic\nBeam-Stabilized (DBS) processor capable of beam adaptation through on-chip\nreal-time control of fundamental gain, phase, and delay for each element. (2)\nPrior conformal arrays have leveraged additive printing to enhance flexibility,\nbut conventional printable inks based on silver are expensive, and those based\non copper suffer from spontaneous metal oxidation that alters trace impedance\nand degrades beamforming performance. We instead leverage a low-cost Copper\nMolecular Decomposition (CuMOD) ink with < 0.1% variation per degree C with\ntemperature and strain and correct any residual deformity in real-time using\nthe DBS processor. Demonstrating unified material and physical deformation\ncorrection, our CMOS DBS processor is low power, low-area, and easily scalable\ndue to a tile architecture, thereby ideal for on-device implementations.", "published": "2025-05-15 00:20:24", "link": "http://arxiv.org/abs/2505.09870v2", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Tracr-Injection: Distilling Algorithms into Pre-trained Language Models", "abstract": "Motivated by the surge of large language models, there has been a push to\nformally characterize the symbolic abilities intrinsic to the transformer\narchitecture. A programming language, called RASP, has been proposed, which can\nbe directly compiled into transformer weights to implement these algorithms.\nHowever, the tasks that can be implemented in RASP are often uncommon to learn\nfrom natural unsupervised data, showing a mismatch between theoretical\ncapabilities of the transformer architecture, and the practical learnability of\nthese capabilities from unsupervised data. We propose tracr-injection, a method\nthat allows us to distill algorithms written in RASP directly into a\npre-trained language model. We showcase our method by injecting 3 different\nalgorithms into a language model. We show how our method creates an\ninterpretable subspace within the model's residual stream, which can be decoded\ninto the variables present in the code of the RASP algorithm. Additionally, we\nfound that the proposed method can improve out-of-distribution performance\ncompared to our baseline, indicating that indeed a more symbolic mechanism is\ntaking place in the inner workings of the model. We release the code used to\nrun our experiments.", "published": "2025-05-15 21:43:51", "link": "http://arxiv.org/abs/2505.10719v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WorldPM: Scaling Human Preference Modeling", "abstract": "Motivated by scaling laws in language modeling that demonstrate how test loss\nscales as a power law with model and dataset sizes, we find that similar laws\nexist in preference modeling. We propose World Preference Modeling$ (WorldPM)\nto emphasize this scaling potential, where World Preference embodies a unified\nrepresentation of human preferences. In this paper, we collect preference data\nfrom public forums covering diverse user communities, and conduct extensive\ntraining using 15M-scale data across models ranging from 1.5B to 72B\nparameters. We observe distinct patterns across different evaluation metrics:\n(1) Adversarial metrics (ability to identify deceptive features) consistently\nscale up with increased training data and base model size; (2) Objective\nmetrics (objective knowledge with well-defined answers) show emergent behavior\nin larger language models, highlighting WorldPM's scalability potential; (3)\nSubjective metrics (subjective preferences from a limited number of humans or\nAI) do not demonstrate scaling trends. Further experiments validate the\neffectiveness of WorldPM as a foundation for preference fine-tuning. Through\nevaluations on 7 benchmarks with 20 subtasks, we find that WorldPM broadly\nimproves the generalization performance across human preference datasets of\nvarying sizes (7K, 100K and 800K samples), with performance gains exceeding 5%\non many key subtasks. Integrating WorldPM into our internal RLHF pipeline, we\nobserve significant improvements on both in-house and public evaluation sets,\nwith notable gains of 4% to 8% in our in-house evaluations.", "published": "2025-05-15 17:38:37", "link": "http://arxiv.org/abs/2505.10527v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "abstract": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs.", "published": "2025-05-15 17:37:00", "link": "http://arxiv.org/abs/2505.10526v2", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Superposition Yields Robust Neural Scaling", "abstract": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters.", "published": "2025-05-15 16:18:13", "link": "http://arxiv.org/abs/2505.10465v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Topology-driven identification of repetitions in multi-variate time series", "abstract": "Many multi-variate time series obtained in the natural sciences and\nengineering possess a repetitive behavior, as for instance state-space\ntrajectories of industrial machines in discrete automation. Recovering the\ntimes of recurrence from such a multi-variate time series is of a fundamental\nimportance for many monitoring and control tasks. For a periodic time series\nthis is equivalent to determining its period length. In this work we present a\npersistent homology framework to estimate recurrence times in multi-variate\ntime series with different generalizations of cyclic behavior (periodic,\nrepetitive, and recurring). To this end, we provide three specialized methods\nwithin our framework that are provably stable and validate them using\nreal-world data, including a new benchmark dataset from an injection molding\nmachine.", "published": "2025-05-15 06:35:32", "link": "http://arxiv.org/abs/2505.10004v2", "categories": ["cs.CG", "eess.SP", "math.AT", "stat.ML"], "primary_category": "cs.CG"}
{"title": "GSPRec: Temporal-Aware Graph Spectral Filtering for Recommendation", "abstract": "Graph-based recommendation systems are effective at modeling collaborative\npatterns but often suffer from two limitations: overreliance on low-pass\nfiltering, which suppresses user-specific signals, and omission of sequential\ndynamics in graph construction. We introduce GSPRec, a graph spectral model\nthat integrates temporal transitions through sequentially-informed graph\nconstruction and applies frequency-aware filtering in the spectral domain.\nGSPRec encodes item transitions via multi-hop diffusion to enable the use of\nsymmetric Laplacians for spectral processing. To capture user preferences, we\ndesign a dual-filtering mechanism: a Gaussian bandpass filter to extract\nmid-frequency, user-level patterns, and a low-pass filter to retain global\ntrends. Extensive experiments on four public datasets show that GSPRec\nconsistently outperforms baselines, with an average improvement of 6.77% in\nNDCG@10. Ablation studies show the complementary benefits of both sequential\ngraph augmentation and bandpass filtering.", "published": "2025-05-15 15:49:56", "link": "http://arxiv.org/abs/2505.11552v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Assessing Collective Reasoning in Multi-Agent LLMs via Hidden Profile Tasks", "abstract": "Multi-agent systems built on large language models (LLMs) promise enhanced\nproblem-solving through distributed information integration, but also risk\nreplicating collective reasoning failures observed in human groups. Yet, no\ntheory-grounded benchmark exists to systematically evaluate such failures. In\nthis paper, we introduce the Hidden Profile paradigm from social psychology as\na diagnostic testbed for multi-agent LLM systems. By distributing critical\ninformation asymmetrically across agents, the paradigm reveals how inter-agent\ndynamics support or hinder collective reasoning. We first formalize the\nparadigm for multi-agent decision-making under distributed knowledge and\ninstantiate it as a benchmark with nine tasks spanning diverse scenarios,\nincluding adaptations from prior human studies. We then conduct experiments\nwith GPT-4.1 and five other leading LLMs, including reasoning-enhanced\nvariants, showing that multi-agent systems across all models fail to match the\naccuracy of single agents given complete information. While agents' collective\nperformance is broadly comparable to that of human groups, nuanced behavioral\ndifferences emerge, such as increased sensitivity to social desirability.\nFinally, we demonstrate the paradigm's diagnostic utility by exploring a\ncooperation-contradiction trade-off in multi-agent LLM systems. We find that\nwhile cooperative agents are prone to over-coordination in collective settings,\nincreased contradiction impairs group convergence. This work contributes a\nreproducible framework for evaluating multi-agent LLM systems and motivates\nfuture research on artificial collective intelligence and human-AI interaction.", "published": "2025-05-15 19:22:54", "link": "http://arxiv.org/abs/2505.11556v1", "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "cs.CL"}
{"title": "Whitened Score Diffusion: A Structured Prior for Imaging Inverse Problems", "abstract": "Conventional score-based diffusion models (DMs) may struggle with anisotropic\nGaussian diffusion processes due to the required inversion of covariance\nmatrices in the denoising score matching training objective\n\\cite{vincent_connection_2011}. We propose Whitened Score (WS) diffusion\nmodels, a novel framework based on stochastic differential equations that\nlearns the Whitened Score function instead of the standard score. This approach\ncircumvents covariance inversion, extending score-based DMs by enabling stable\ntraining of DMs on arbitrary Gaussian forward noising processes. WS DMs\nestablish equivalence with flow matching for arbitrary Gaussian noise, allow\nfor tailored spectral inductive biases, and provide strong Bayesian priors for\nimaging inverse problems with structured noise. We experiment with a variety of\ncomputational imaging tasks using the CIFAR and CelebA ($64\\times64$) datasets\nand demonstrate that WS diffusion priors trained on anisotropic Gaussian\nnoising processes consistently outperform conventional diffusion priors based\non isotropic Gaussian noise. Our code is open-sourced at\n\\href{https://github.com/jeffreyalido/wsdiffusion}{\\texttt{github.com/jeffreyalido/wsdiffusion}}.", "published": "2025-05-15 13:55:55", "link": "http://arxiv.org/abs/2505.10311v3", "categories": ["eess.IV", "eess.SP", "stat.AP", "stat.ML"], "primary_category": "eess.IV"}
{"title": "Dynamic Beam-Stabilized, Additive-Printed Flexible Antenna Arrays with On-Chip Rapid Insight Generation", "abstract": "Conformal phased arrays promise shape-changing properties, multiple degrees\nof freedom to the scan angle, and novel applications in wearables, aerospace,\ndefense, vehicles, and ships. However, they have suffered from two critical\nlimitations. (1) Although most applications require on-the-move communication\nand sensing, prior conformal arrays have suffered from dynamic\ndeformation-induced beam pointing errors. We introduce a Dynamic\nBeam-Stabilized (DBS) processor capable of beam adaptation through on-chip\nreal-time control of fundamental gain, phase, and delay for each element. (2)\nPrior conformal arrays have leveraged additive printing to enhance flexibility,\nbut conventional printable inks based on silver are expensive, and those based\non copper suffer from spontaneous metal oxidation that alters trace impedance\nand degrades beamforming performance. We instead leverage a low-cost Copper\nMolecular Decomposition (CuMOD) ink with < 0.1% variation per degree C with\ntemperature and strain and correct any residual deformity in real-time using\nthe DBS processor. Demonstrating unified material and physical deformation\ncorrection, our CMOS DBS processor is low power, low-area, and easily scalable\ndue to a tile architecture, thereby ideal for on-device implementations.", "published": "2025-05-15 00:20:24", "link": "http://arxiv.org/abs/2505.09870v3", "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "eess.SP"}
{"title": "Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights", "abstract": "Charts are crucial for data analysis and decision-making.Text-to-chart\nretrieval systems have become increasingly important for Business Intelligence\n(BI), where users need to find relevant charts that match their analytical\nneeds. These needs can be categorized into precise queries that are\nwell-specified and fuzzy queries that are more exploratory -- both require\nunderstanding the semantics and context of the charts. However, existing\ntext-to-chart retrieval solutions often fail to capture the semantic content\nand contextual information of charts, primarily due to the lack of\ncomprehensive metadata (or semantic insights). To address this limitation, we\npropose a training data development pipeline that automatically synthesizes\nhierarchical semantic insights for charts, covering visual patterns\n(visual-oriented), statistical properties (statistics-oriented), and practical\napplications (task-oriented), which produces 207,498 semantic insights for\n69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to\nlearn better representations of charts for text-to-chart retrieval. Our method\nleverages rich semantic insights during the training phase to develop a model\nthat understands both visual and semantic aspects of charts.To evaluate\ntext-to-chart retrieval performance, we curate the first benchmark, CRBench,\nfor this task with 21,862 charts and 326 text queries from real-world BI\napplications, with ground-truth labels verified by the crowd\nworkers.Experiments show that ChartFinder significantly outperforms existing\nmethods in text-to-chart retrieval tasks across various settings. For precise\nqueries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than\nstate-of-the-art models. In fuzzy query tasks, our method also demonstrates\nconsistent improvements, with an average increase of 5% across nearly all\nmetrics.", "published": "2025-05-15 07:41:14", "link": "http://arxiv.org/abs/2505.10043v2", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Words That Unite The World: A Unified Framework for Deciphering Central Bank Communications Globally", "abstract": "Central banks around the world play a crucial role in maintaining economic\nstability. Deciphering policy implications in their communications is\nessential, especially as misinterpretations can disproportionately impact\nvulnerable populations. To address this, we introduce the World Central Banks\n(WCB) dataset, the most comprehensive monetary policy corpus to date,\ncomprising over 380k sentences from 25 central banks across diverse geographic\nregions, spanning 28 years of historical data. After uniformly sampling 1k\nsentences per bank (25k total) across all available years, we annotate and\nreview each sentence using dual annotators, disagreement resolutions, and\nsecondary expert reviews. We define three tasks: Stance Detection, Temporal\nClassification, and Uncertainty Estimation, with each sentence annotated for\nall three. We benchmark seven Pretrained Language Models (PLMs) and nine Large\nLanguage Models (LLMs) (Zero-Shot, Few-Shot, and with annotation guide) on\nthese tasks, running 15,075 benchmarking experiments. We find that a model\ntrained on aggregated data across banks significantly surpasses a model trained\non an individual bank's data, confirming the principle \"the whole is greater\nthan the sum of its parts.\" Additionally, rigorous human evaluations, error\nanalyses, and predictive tasks validate our framework's economic utility. Our\nartifacts are accessible through the HuggingFace and GitHub under the\nCC-BY-NC-SA 4.0 license.", "published": "2025-05-15 19:49:20", "link": "http://arxiv.org/abs/2505.17048v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "q-fin.CP", "q-fin.GN"], "primary_category": "cs.CL"}
{"title": "Reproducing the first and second moment of empirical degree distributions", "abstract": "The study of probabilistic models for the analysis of complex networks\nrepresents a flourishing research field. Among the former, Exponential Random\nGraphs (ERGs) have gained increasing attention over the years. So far, only\nlinear ERGs have been extensively employed to gain insight into the structural\norganisation of real-world complex networks. None, however, is capable of\naccounting for the variance of the empirical degree distribution. To this aim,\nnon-linear ERGs must be considered. After showing that the usual mean-field\napproximation forces the degree-corrected version of the two-star model to\ndegenerate, we define a fitness-induced variant of it. Such a `softened' model\nis capable of reproducing the sample variance, while retaining the explanatory\npower of its linear counterpart, within a purely canonical framework.", "published": "2025-05-15 14:56:34", "link": "http://arxiv.org/abs/2505.10373v2", "categories": ["physics.soc-ph", "cs.SI", "physics.data-an", "q-fin.ST"], "primary_category": "physics.soc-ph"}
