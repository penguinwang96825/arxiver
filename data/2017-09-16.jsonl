{"title": "Order-Preserving Abstractive Summarization for Spoken Content Based on\n  Connectionist Temporal Classification", "abstract": "Connectionist temporal classification (CTC) is a powerful approach for\nsequence-to-sequence learning, and has been popularly used in speech\nrecognition. The central ideas of CTC include adding a label \"blank\" during\ntraining. With this mechanism, CTC eliminates the need of segment alignment,\nand hence has been applied to various sequence-to-sequence learning problems.\nIn this work, we applied CTC to abstractive summarization for spoken content.\nThe \"blank\" in this case implies the corresponding input data are less\nimportant or noisy; thus it can be ignored. This approach was shown to\noutperform the existing methods in term of ROUGE scores over Chinese Gigaword\nand MATBN corpora. This approach also has the nice property that the ordering\nof words or characters in the input documents can be better preserved in the\ngenerated summaries.", "published": "2017-09-16 07:39:53", "link": "http://arxiv.org/abs/1709.05475v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Role of Morphology Injection in Statistical Machine Translation", "abstract": "Phrase-based Statistical models are more commonly used as they perform\noptimally in terms of both, translation quality and complexity of the system.\nHindi and in general all Indian languages are morphologically richer than\nEnglish. Hence, even though Phrase-based systems perform very well for the less\ndivergent language pairs, for English to Indian language translation, we need\nmore linguistic information (such as morphology, parse tree, parts of speech\ntags, etc.) on the source side. Factored models seem to be useful in this case,\nas Factored models consider word as a vector of factors. These factors can\ncontain any information about the surface word and use it while translating.\nHence, the objective of this work is to handle morphological inflections in\nHindi and Marathi using Factored translation models while translating from\nEnglish. SMT approaches face the problem of data sparsity while translating\ninto a morphologically rich language. It is very unlikely for a parallel corpus\nto contain all morphological forms of words. We propose a solution to generate\nthese unseen morphological forms and inject them into original training\ncorpora. In this paper, we study factored models and the problem of sparseness\nin context of translation to morphologically rich languages. We propose a\nsimple and effective solution which is based on enriching the input with\nvarious morphological forms of words. We observe that morphology injection\nimproves the quality of translation in terms of both adequacy and fluency. We\nverify this with the experiments on two morphologically rich languages: Hindi\nand Marathi, while translating from English.", "published": "2017-09-16 09:40:36", "link": "http://arxiv.org/abs/1709.05487v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AISHELL-1: An Open-Source Mandarin Speech Corpus and A Speech\n  Recognition Baseline", "abstract": "An open-source Mandarin speech corpus called AISHELL-1 is released. It is by\nfar the largest corpus which is suitable for conducting the speech recognition\nresearch and building speech recognition systems for Mandarin. The recording\nprocedure, including audio capturing devices and environments are presented in\ndetails. The preparation of the related resources, including transcriptions and\nlexicon are described. The corpus is released with a Kaldi recipe. Experimental\nresults implies that the quality of audio recordings and transcriptions are\npromising.", "published": "2017-09-16 14:33:27", "link": "http://arxiv.org/abs/1709.05522v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data Innovation for International Development: An overview of natural\n  language processing for qualitative data analysis", "abstract": "Availability, collection and access to quantitative data, as well as its\nlimitations, often make qualitative data the resource upon which development\nprograms heavily rely. Both traditional interview data and social media\nanalysis can provide rich contextual information and are essential for\nresearch, appraisal, monitoring and evaluation. These data may be difficult to\nprocess and analyze both systematically and at scale. This, in turn, limits the\nability of timely data driven decision-making which is essential in fast\nevolving complex social systems. In this paper, we discuss the potential of\nusing natural language processing to systematize analysis of qualitative data,\nand to inform quick decision-making in the development context. We illustrate\nthis with interview data generated in a format of micro-narratives for the UNDP\nFragments of Impact project.", "published": "2017-09-16 20:16:56", "link": "http://arxiv.org/abs/1709.05563v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Augmenting End-to-End Dialog Systems with Commonsense Knowledge", "abstract": "Building dialog agents that can converse naturally with humans is a\nchallenging yet intriguing problem of artificial intelligence. In open-domain\nhuman-computer conversation, where the conversational agent is expected to\nrespond to human responses in an interesting and engaging way, commonsense\nknowledge has to be integrated into the model effectively. In this paper, we\ninvestigate the impact of providing commonsense knowledge about the concepts\ncovered in the dialog. Our model represents the first attempt to integrating a\nlarge commonsense knowledge base into end-to-end conversational models. In the\nretrieval-based scenario, we propose the Tri-LSTM model to jointly take into\naccount message and commonsense for selecting an appropriate response. Our\nexperiments suggest that the knowledge-augmented models are superior to their\nknowledge-free counterparts in automatic evaluation.", "published": "2017-09-16 04:14:53", "link": "http://arxiv.org/abs/1709.05453v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Acquiring Background Knowledge to Improve Moral Value Prediction", "abstract": "In this paper, we address the problem of detecting expressions of moral\nvalues in tweets using content analysis. This is a particularly challenging\nproblem because moral values are often only implicitly signaled in language,\nand tweets contain little contextual information due to length constraints. To\naddress these obstacles, we present a novel approach to automatically acquire\nbackground knowledge from an external knowledge base to enrich input texts and\nthus improve moral value prediction. By combining basic text features with\nbackground knowledge, our overall context-aware framework achieves performance\ncomparable to a single human annotator. To the best of our knowledge, this is\nthe first attempt to incorporate background knowledge for the prediction of\nimplicit psychological variables in the area of computational social science.", "published": "2017-09-16 05:54:54", "link": "http://arxiv.org/abs/1709.05467v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "SKOS Concepts and Natural Language Concepts: an Analysis of Latent\n  Relationships in KOSs", "abstract": "The vehicle to represent Knowledge Organization Systems (KOSs) in the\nenvironment of the Semantic Web and linked data is the Simple Knowledge\nOrganization System (SKOS). SKOS provides a way to assign a URI to each\nconcept, and this URI functions as a surrogate for the concept. This fact makes\nof main concern the need to clarify the URIs' ontological meaning. The aim of\nthis study is to investigate the relation between the ontological substance of\nKOS concepts and concepts revealed through the grammatical and syntactic\nformalisms of natural language. For this purpose, we examined the dividableness\nof concepts in specific KOSs (i.e. a thesaurus, a subject headings system and a\nclassification scheme) by applying Natural Language Processing (NLP) techniques\n(i.e. morphosyntactic analysis) to the lexical representations (i.e. RDF\nliterals) of SKOS concepts. The results of the comparative analysis reveal\nthat, despite the use of multi-word units, thesauri tend to represent concepts\nin a way that can hardly be further divided conceptually, while Subject\nHeadings and Classification Schemes - to a certain extent - comprise terms that\ncan be decomposed into more conceptual constituents. Consequently, SKOS\nconcepts deriving from thesauri are more likely to represent atomic conceptual\nunits and thus be more appropriate tools for inference and reasoning. Since\nidentifiers represent the meaning of a concept, complex concepts are neither\nthe most appropriate nor the most efficient way of modelling a KOS for the\nSemantic Web.", "published": "2017-09-16 22:58:13", "link": "http://arxiv.org/abs/1709.05576v1", "categories": ["cs.DL", "cs.AI", "cs.CL"], "primary_category": "cs.DL"}
