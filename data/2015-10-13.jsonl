{"title": "Bridge Correlational Neural Networks for Multilingual Multimodal\n  Representation Learning", "abstract": "Recently there has been a lot of interest in learning common representations\nfor multiple views of data. Typically, such common representations are learned\nusing a parallel corpus between the two views (say, 1M images and their English\ncaptions). In this work, we address a real-world scenario where no direct\nparallel data is available between two views of interest (say, $V_1$ and $V_2$)\nbut parallel data is available between each of these views and a pivot view\n($V_3$). We propose a model for learning a common representation for $V_1$,\n$V_2$ and $V_3$ using only the parallel data available between $V_1V_3$ and\n$V_2V_3$. The proposed model is generic and even works when there are $n$ views\nof interest and only one pivot view which acts as a bridge between them. There\nare two specific downstream applications that we focus on (i) transfer learning\nbetween languages $L_1$,$L_2$,...,$L_n$ using a pivot language $L$ and (ii)\ncross modal access between images and a language $L_1$ using a pivot language\n$L_2$. Our model achieves state-of-the-art performance in multilingual document\nclassification on the publicly available multilingual TED corpus and promising\nresults in multilingual multimodal retrieval on a new dataset created and\nreleased as a part of this work.", "published": "2015-10-13 03:25:18", "link": "http://arxiv.org/abs/1510.03519v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hybrid Dialog State Tracker", "abstract": "This paper presents a hybrid dialog state tracker that combines a rule based\nand a machine learning based approach to belief state tracking. Therefore, we\ncall it a hybrid tracker. The machine learning in our tracker is realized by a\nLong Short Term Memory (LSTM) network. To our knowledge, our hybrid tracker\nsets a new state-of-the-art result for the Dialog State Tracking Challenge\n(DSTC) 2 dataset when the system uses only live SLU as its input.", "published": "2015-10-13 14:44:01", "link": "http://arxiv.org/abs/1510.03710v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved Deep Learning Baselines for Ubuntu Corpus Dialogs", "abstract": "This paper presents results of our experiments for the next utterance ranking\non the Ubuntu Dialog Corpus -- the largest publicly available multi-turn dialog\ncorpus. First, we use an in-house implementation of previously reported models\nto do an independent evaluation using the same data. Second, we evaluate the\nperformances of various LSTMs, Bi-LSTMs and CNNs on the dataset. Third, we\ncreate an ensemble by averaging predictions of multiple models. The ensemble\nfurther improves the performance and it achieves a state-of-the-art result for\nthe next utterance ranking on this dataset. Finally, we discuss our future\nplans using this corpus.", "published": "2015-10-13 15:56:26", "link": "http://arxiv.org/abs/1510.03753v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A language model based approach towards large scale and lightweight\n  language identification systems", "abstract": "Multilingual spoken dialogue systems have gained prominence in the recent\npast necessitating the requirement for a front-end Language Identification\n(LID) system. Most of the existing LID systems rely on modeling the language\ndiscriminative information from low-level acoustic features. Due to the\nvariabilities of speech (speaker and emotional variabilities, etc.),\nlarge-scale LID systems developed using low-level acoustic features suffer from\na degradation in the performance. In this approach, we have attempted to model\nthe higher level language discriminative phonotactic information for developing\nan LID system. In this paper, the input speech signal is tokenized to phone\nsequences by using a language independent phone recognizer. The language\ndiscriminative phonotactic information in the obtained phone sequences are\nmodeled using statistical and recurrent neural network based language modeling\napproaches. As this approach, relies on higher level phonotactical information\nit is more robust to variabilities of speech. Proposed approach is\ncomputationally light weight, highly scalable and it can be used in complement\nwith the existing LID systems.", "published": "2015-10-13 09:51:23", "link": "http://arxiv.org/abs/1510.03602v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Complex Politics: A Quantitative Semantic and Topological Analysis of UK\n  House of Commons Debates", "abstract": "This study is a first, exploratory attempt to use quantitative semantics\ntechniques and topological analysis to analyze systemic patterns arising in a\ncomplex political system. In particular, we use a rich data set covering all\nspeeches and debates in the UK House of Commons between 1975 and 2014. By the\nuse of dynamic topic modeling (DTM) and topological data analysis (TDA) we show\nthat both members and parties feature specific roles within the system,\nconsistent over time, and extract global patterns indicating levels of\npolitical cohesion. Our results provide a wide array of novel hypotheses about\nthe complex dynamics of political systems, with valuable policy applications.", "published": "2015-10-13 17:49:09", "link": "http://arxiv.org/abs/1510.03797v1", "categories": ["physics.soc-ph", "cs.CL", "cs.SI", "91F10"], "primary_category": "physics.soc-ph"}
{"title": "A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional\n  Neural Networks for Sentence Classification", "abstract": "Convolutional Neural Networks (CNNs) have recently achieved remarkably strong\nperformance on the practically important task of sentence classification (kim\n2014, kalchbrenner 2014, johnson 2014). However, these models require\npractitioners to specify an exact model architecture and set accompanying\nhyperparameters, including the filter region size, regularization parameters,\nand so on. It is currently unknown how sensitive model performance is to\nchanges in these configurations for the task of sentence classification. We\nthus conduct a sensitivity analysis of one-layer CNNs to explore the effect of\narchitecture components on model performance; our aim is to distinguish between\nimportant and comparatively inconsequential design decisions for sentence\nclassification. We focus on one-layer CNNs (to the exclusion of more complex\nmodels) due to their comparative simplicity and strong empirical performance,\nwhich makes it a modern standard baseline method akin to Support Vector Machine\n(SVMs) and logistic regression. We derive practical advice from our extensive\nempirical results for those interested in getting the most out of CNNs for\nsentence classification in real world settings.", "published": "2015-10-13 19:00:57", "link": "http://arxiv.org/abs/1510.03820v4", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
