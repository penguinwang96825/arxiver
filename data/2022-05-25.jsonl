{"title": "Counterfactual Data Augmentation improves Factuality of Abstractive\n  Summarization", "abstract": "Abstractive summarization systems based on pretrained language models often\ngenerate coherent but factually inconsistent sentences. In this paper, we\npresent a counterfactual data augmentation approach where we augment data with\nperturbed summaries that increase the training data diversity. Specifically, we\npresent three augmentation approaches based on replacing (i) entities from\nother and the same category and (ii) nouns with their corresponding WordNet\nhypernyms. We show that augmenting the training data with our approach improves\nthe factual correctness of summaries without significantly affecting the ROUGE\nscore. We show that in two commonly used summarization datasets (CNN/Dailymail\nand XSum), we improve the factual correctness by about 2.5 points on average", "published": "2022-05-25 00:00:35", "link": "http://arxiv.org/abs/2205.12416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning Action Conditions from Instructional Manuals for Instruction\n  Understanding", "abstract": "The ability to infer pre- and postconditions of an action is vital for\ncomprehending complex instructions, and is essential for applications such as\nautonomous instruction-guided agents and assistive AI that supports humans to\nperform physical tasks. In this work, we propose a task dubbed action condition\ninference, and collecting a high-quality, human annotated dataset of\npreconditions and postconditions of actions in instructional manuals. We\npropose a weakly supervised approach to automatically construct large-scale\ntraining instances from online instructional manuals, and curate a densely\nhuman-annotated and validated dataset to study how well the current NLP models\ncan infer action-condition dependencies in the instruction texts. We design two\ntypes of models differ by whether contextualized and global information is\nleveraged, as well as various combinations of heuristics to construct the weak\nsupervisions. Our experimental results show a >20% F1-score improvement with\nconsidering the entire instruction contexts and a >6% F1-score benefit with the\nproposed heuristics.", "published": "2022-05-25 00:19:59", "link": "http://arxiv.org/abs/2205.12420v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Know Where You're Going: Meta-Learning for Parameter-Efficient\n  Fine-Tuning", "abstract": "A recent family of techniques, dubbed lightweight fine-tuning methods,\nfacilitates parameter-efficient transfer learning by updating only a small set\nof additional parameters while keeping the parameters of the pretrained\nlanguage model frozen. While proven to be an effective method, there are no\nexisting studies on if and how such knowledge of the downstream fine-tuning\napproach should affect the pretraining stage. In this work, we show that taking\nthe ultimate choice of fine-tuning method into consideration boosts the\nperformance of parameter-efficient fine-tuning. By relying on\noptimization-based meta-learning using MAML with certain modifications for our\ndistinct purpose, we prime the pretrained model specifically for\nparameter-efficient fine-tuning, resulting in gains of up to 1.7 points on\ncross-lingual NER fine-tuning. Our ablation settings and analyses further\nreveal that the tweaks we introduce in MAML are crucial for the attained gains.", "published": "2022-05-25 02:51:57", "link": "http://arxiv.org/abs/2205.12453v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "R2D2: Robust Data-to-Text with Replacement Detection", "abstract": "Unfaithful text generation is a common problem for text generation systems.\nIn the case of Data-to-Text (D2T) systems, the factuality of the generated text\nis particularly crucial for any real-world applications. We introduce R2D2, a\ntraining framework that addresses unfaithful Data-to-Text generation by\ntraining a system both as a generator and a faithfulness discriminator with\nadditional replacement detection and unlikelihood learning tasks. To facilitate\nsuch training, we propose two methods for sampling unfaithful sentences. We\nargue that the poor entity retrieval capability of D2T systems is one of the\nprimary sources of unfaithfulness, so in addition to the existing metrics, we\nfurther propose NER-based metrics to evaluate the fidelity of D2T generations.\nOur experimental results show that R2D2 systems could effectively mitigate the\nunfaithful text generation, and they achieve new state-of-the-art results on\nFeTaQA, LogicNLG, and ToTTo, all with significant improvements.", "published": "2022-05-25 03:29:25", "link": "http://arxiv.org/abs/2205.12467v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Logical Satisfiability of Counterfactuals for Faithful Explanations in\n  NLI", "abstract": "Evaluating an explanation's faithfulness is desired for many reasons such as\ntrust, interpretability and diagnosing the sources of model's errors. In this\nwork, which focuses on the NLI task, we introduce the methodology of\nFaithfulness-through-Counterfactuals, which first generates a counterfactual\nhypothesis based on the logical predicates expressed in the explanation, and\nthen evaluates if the model's prediction on the counterfactual is consistent\nwith that expressed logic (i.e. if the new formula is \\textit{logically\nsatisfiable}). In contrast to existing approaches, this does not require any\nexplanations for training a separate verification model. We first validate the\nefficacy of automatic counterfactual hypothesis generation, leveraging on the\nfew-shot priming paradigm. Next, we show that our proposed metric distinguishes\nbetween human-model agreement and disagreement on new counterfactual input. In\naddition, we conduct a sensitivity analysis to validate that our metric is\nsensitive to unfaithful explanations.", "published": "2022-05-25 03:40:59", "link": "http://arxiv.org/abs/2205.12469v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning a Better Initialization for Soft Prompts via Meta-Learning", "abstract": "Prompt tuning (PT) is an effective approach to adapting pre-trained language\nmodels to downstream tasks. Without a good initialization, prompt tuning\ndoesn't perform well under few-shot settings. So pre-trained prompt tuning\n(PPT) is proposed to initialize prompts by leveraging pre-training data. We\npropose MetaPT (Meta-learned Prompt Tuning) to further improve PPT's\ninitialization by considering latent structure within the pre-training data.\nSpecifically, we introduce the structure by first clustering pre-training data\ninto different auxiliary tasks with unsupervised methods. Then we use these\ntasks to pre-train prompts with a meta-learning algorithm. Such a process can\nmake prompts learn a better initialization by discovering commonalities among\nthese auxiliary tasks. We evaluate our method on seven downstream tasks. Our\nMetaPT achieves better and more stable performance than the state-of-the-art\nmethod.", "published": "2022-05-25 03:50:23", "link": "http://arxiv.org/abs/2205.12471v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Locality in Abstractive Text Summarization", "abstract": "Neural attention models have achieved significant improvements on many\nnatural language processing tasks. However, the quadratic memory complexity of\nthe self-attention module with respect to the input length hinders their\napplications in long text summarization. Instead of designing more efficient\nattention modules, we approach this problem by investigating if models with a\nrestricted context can have competitive performance compared with the\nmemory-efficient attention models that maintain a global context by treating\nthe input as a single sequence. Our model is applied to individual pages which\ncontain parts of inputs grouped by the principle of locality during both\nencoding and decoding. We empirically investigated three kinds of locality in\ntext summarization at different levels of granularity, ranging from sentences\nto documents. Our experimental results show that our model has a better\nperformance compared with strong baselines with efficient attention modules,\nand our analysis provides further insights into our locality-aware modeling\nstrategy.", "published": "2022-05-25 03:59:24", "link": "http://arxiv.org/abs/2205.12476v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Factorizing Content and Budget Decisions in Abstractive Summarization of\n  Long Documents", "abstract": "We argue that disentangling content selection from the budget used to cover\nsalient content improves the performance and applicability of abstractive\nsummarizers. Our method, FactorSum, does this disentanglement by factorizing\nsummarization into two steps through an energy function: (1) generation of\nabstractive summary views; (2) combination of these views into a final summary,\nfollowing a budget and content guidance. This guidance may come from different\nsources, including from an advisor model such as BART or BigBird, or in oracle\nmode -- from the reference. This factorization achieves significantly higher\nROUGE scores on multiple benchmarks for long document summarization, namely\nPubMed, arXiv, and GovReport. Most notably, our model is effective for domain\nadaptation. When trained only on PubMed samples, it achieves a 46.29 ROUGE-1\nscore on arXiv, which indicates a strong performance due to more flexible\nbudget adaptation and content selection less dependent on domain-specific\ntextual structure.", "published": "2022-05-25 04:27:33", "link": "http://arxiv.org/abs/2205.12486v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-End Multimodal Fact-Checking and Explanation Generation: A\n  Challenging Dataset and Models", "abstract": "We propose end-to-end multimodal fact-checking and explanation generation,\nwhere the input is a claim and a large collection of web sources, including\narticles, images, videos, and tweets, and the goal is to assess the\ntruthfulness of the claim by retrieving relevant evidence and predicting a\ntruthfulness label (e.g., support, refute or not enough information), and to\ngenerate a statement to summarize and explain the reasoning and ruling process.\nTo support this research, we construct Mocheg, a large-scale dataset consisting\nof 15,601 claims where each claim is annotated with a truthfulness label and a\nruling statement, and 33,880 textual paragraphs and 12,112 images in total as\nevidence. To establish baseline performances on Mocheg, we experiment with\nseveral state-of-the-art neural architectures on the three pipelined subtasks:\nmultimodal evidence retrieval, claim verification, and explanation generation,\nand demonstrate that the performance of the state-of-the-art end-to-end\nmultimodal fact-checking does not provide satisfactory outcomes. To the best of\nour knowledge, we are the first to build the benchmark dataset and solutions\nfor end-to-end multimodal fact-checking and explanation generation. The\ndataset, source code and model checkpoints are available at\nhttps://github.com/VT-NLP/Mocheg.", "published": "2022-05-25 04:36:46", "link": "http://arxiv.org/abs/2205.12487v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-grained Contrastive Learning for Relation Extraction", "abstract": "Recent relation extraction (RE) works have shown encouraging improvements by\nconducting contrastive learning on silver labels generated by distant\nsupervision before fine-tuning on gold labels. Existing methods typically\nassume all these silver labels are accurate and treat them equally; however,\ndistant supervision is inevitably noisy -- some silver labels are more reliable\nthan others. In this paper, we propose fine-grained contrastive learning\n(FineCL) for RE, which leverages fine-grained information about which silver\nlabels are and are not noisy to improve the quality of learned relationship\nrepresentations for RE. We first assess the quality of silver labels via a\nsimple and automatic approach we call \"learning order denoising,\" where we\ntrain a language model to learn these relations and record the order of learned\ntraining instances. We show that learning order largely corresponds to label\naccuracy -- early-learned silver labels have, on average, more accurate labels\nthan later-learned silver labels. Then, during pre-training, we increase the\nweights of accurate labels within a novel contrastive learning objective.\nExperiments on several RE benchmarks show that FineCL makes consistent and\nsignificant performance gains over state-of-the-art methods.", "published": "2022-05-25 05:03:01", "link": "http://arxiv.org/abs/2205.12491v2", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate\n  Speech Detection", "abstract": "Hate speech detection is complex; it relies on commonsense reasoning,\nknowledge of stereotypes, and an understanding of social nuance that differs\nfrom one culture to the next. It is also difficult to collect a large-scale\nhate speech annotated dataset. In this work, we frame this problem as a\nfew-shot learning task, and show significant gains with decomposing the task\ninto its \"constituent\" parts. In addition, we see that infusing knowledge from\nreasoning datasets (e.g. Atomic2020) improves the performance even further.\nMoreover, we observe that the trained models generalize to out-of-distribution\ndatasets, showing the superiority of task decomposition and knowledge infusion\ncompared to previously used methods. Concretely, our method outperforms the\nbaseline by 17.83% absolute gain in the 16-shot case.", "published": "2022-05-25 05:10:08", "link": "http://arxiv.org/abs/2205.12495v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GENEVA: Benchmarking Generalizability for Event Argument Extraction with\n  Hundreds of Event Types and Argument Roles", "abstract": "Recent works in Event Argument Extraction (EAE) have focused on improving\nmodel generalizability to cater to new events and domains. However, standard\nbenchmarking datasets like ACE and ERE cover less than 40 event types and 25\nentity-centric argument roles. Limited diversity and coverage hinder these\ndatasets from adequately evaluating the generalizability of EAE models. In this\npaper, we first contribute by creating a large and diverse EAE ontology. This\nontology is created by transforming FrameNet, a comprehensive semantic role\nlabeling (SRL) dataset for EAE, by exploiting the similarity between these two\ntasks. Then, exhaustive human expert annotations are collected to build the\nontology, concluding with 115 events and 220 argument roles, with a significant\nportion of roles not being entities. We utilize this ontology to further\nintroduce GENEVA, a diverse generalizability benchmarking dataset comprising\nfour test suites, aimed at evaluating models' ability to handle limited data\nand unseen event type generalization. We benchmark six EAE models from various\nfamilies. The results show that owing to non-entity argument roles, even the\nbest-performing model can only achieve 39% F1 score, indicating how GENEVA\nprovides new challenges for generalization in EAE. Overall, our large and\ndiverse EAE ontology can aid in creating more comprehensive future resources,\nwhile GENEVA is a challenging benchmarking dataset encouraging further research\nfor improving generalizability in EAE. The code and data can be found at\nhttps://github.com/PlusLabNLP/GENEVA.", "published": "2022-05-25 05:46:28", "link": "http://arxiv.org/abs/2205.12505v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Re-Examining Calibration: The Case of Question Answering", "abstract": "For users to trust model predictions, they need to understand model outputs,\nparticularly their confidence - calibration aims to adjust (calibrate) models'\nconfidence to match expected accuracy. We argue that the traditional\ncalibration evaluation does not promote effective calibrations: for example, it\ncan encourage always assigning a mediocre confidence score to all predictions,\nwhich does not help users distinguish correct predictions from wrong ones.\nBuilding on those observations, we propose a new calibration metric, MacroCE,\nthat better captures whether the model assigns low confidence to wrong\npredictions and high confidence to correct predictions. Focusing on the\npractical application of open-domain question answering, we examine\nconventional calibration methods applied on the widely-used retriever-reader\npipeline, all of which do not bring significant gains under our new MacroCE\nmetric. Toward better calibration, we propose a new calibration method\n(ConsCal) that uses not just final model predictions but whether multiple model\ncheckpoints make consistent predictions. Altogether, we provide an alternative\nview of calibration along with a new metric, re-evaluation of existing\ncalibration methods on our metric, and proposal of a more effective calibration\nmethod.", "published": "2022-05-25 05:49:56", "link": "http://arxiv.org/abs/2205.12507v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Machine Translation Robustness to Natural Asemantic Variation", "abstract": "Current Machine Translation (MT) models still struggle with more challenging\ninput, such as noisy data and tail-end words and phrases. Several works have\naddressed this robustness issue by identifying specific categories of noise and\nvariation then tuning models to perform better on them. An important yet\nunder-studied category involves minor variations in nuance (non-typos) that\npreserve meaning w.r.t. the target language. We introduce and formalize this\ncategory as Natural Asemantic Variation (NAV) and investigate it in the context\nof MT robustness. We find that existing MT models fail when presented with NAV\ndata, but we demonstrate strategies to improve performance on NAV by\nfine-tuning them with human-generated variations. We also show that NAV\nrobustness can be transferred across languages and find that synthetic\nperturbations can achieve some but not all of the benefits of organic NAV data.", "published": "2022-05-25 06:06:06", "link": "http://arxiv.org/abs/2205.12514v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Segmenting Numerical Substitution Ciphers", "abstract": "Deciphering historical substitution ciphers is a challenging problem. Example\nproblems that have been previously studied include detecting cipher type,\ndetecting plaintext language, and acquiring the substitution key for segmented\nciphers. However, attacking unsegmented, space-free ciphers is still a\nchallenging task. Segmentation (i.e. finding substitution units) is the first\nstep towards cracking those ciphers. In this work, we propose the first\nautomatic methods to segment those ciphers using Byte Pair Encoding (BPE) and\nunigram language models. Our methods achieve an average segmentation error of\n2\\% on 100 randomly-generated monoalphabetic ciphers and 27\\% on 3 real\nhomophonic ciphers. We also propose a method for solving non-deterministic\nciphers with existing keys using a lattice and a pretrained language model. Our\nmethod leads to the full solution of the IA cipher; a real historical cipher\nthat has not been fully solved until this work.", "published": "2022-05-25 06:45:59", "link": "http://arxiv.org/abs/2205.12527v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LOPS: Learning Order Inspired Pseudo-Label Selection for Weakly\n  Supervised Text Classification", "abstract": "Weakly supervised text classification methods typically train a deep neural\nclassifier based on pseudo-labels. The quality of pseudo-labels is crucial to\nfinal performance but they are inevitably noisy due to their heuristic nature,\nso selecting the correct ones has a huge potential for performance boost. One\nstraightforward solution is to select samples based on the softmax probability\nscores in the neural classifier corresponding to their pseudo-labels. However,\nwe show through our experiments that such solutions are ineffective and\nunstable due to the erroneously high-confidence predictions from poorly\ncalibrated models. Recent studies on the memorization effects of deep neural\nmodels suggest that these models first memorize training samples with clean\nlabels and then those with noisy labels. Inspired by this observation, we\npropose a novel pseudo-label selection method LOPS that takes learning order of\nsamples into consideration. We hypothesize that the learning order reflects the\nprobability of wrong annotation in terms of ranking, and therefore, propose to\nselect the samples that are learnt earlier. LOPS can be viewed as a strong\nperformance-boost plug-in to most of existing weakly-supervised text\nclassification methods, as confirmed in extensive experiments on four\nreal-world datasets.", "published": "2022-05-25 06:46:48", "link": "http://arxiv.org/abs/2205.12528v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ER-Test: Evaluating Explanation Regularization Methods for Language\n  Models", "abstract": "By explaining how humans would solve a given task, human rationales can\nprovide strong learning signal for neural language models (LMs). Explanation\nregularization (ER) aims to improve LM generalization by pushing the LM's\nmachine rationales (Which input tokens did the LM focus on?) to align with\nhuman rationales (Which input tokens would humans focus on?). Though prior\nworks primarily study ER via in-distribution (ID) evaluation,\nout-of-distribution (OOD) generalization is often more critical in real-world\nscenarios, yet ER's effect on OOD generalization has been underexplored. In\nthis paper, we introduce ER-Test, a framework for evaluating ER models' OOD\ngeneralization along three dimensions: unseen dataset tests, contrast set\ntests, and functional tests. Using ER-Test, we extensively analyze how ER\nmodels' OOD generalization varies with different ER design choices. Across two\ntasks and six datasets, ER-Test shows that ER has little impact on ID\nperformance but can yield large OOD performance gains. Also, we find that ER\ncan improve OOD performance even with limited rationale supervision. ER-Test's\nresults help demonstrate ER's utility and establish best practices for using ER\neffectively.", "published": "2022-05-25 07:31:43", "link": "http://arxiv.org/abs/2205.12542v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gradient-Based Constrained Sampling from Language Models", "abstract": "Large pretrained language models generate fluent text but are notoriously\nhard to controllably sample from. In this work, we study constrained sampling\nfrom such language models: generating text that satisfies user-defined\nconstraints, while maintaining fluency and the model's performance in a\ndownstream task. We propose MuCoLa -- a sampling procedure that combines the\nlog-likelihood of the language model with arbitrary (differentiable)\nconstraints in a single energy function, and then generates samples in a\nnon-autoregressive manner. Specifically, it initializes the entire output\nsequence with noise and follows a Markov chain defined by Langevin Dynamics\nusing the gradients of the energy function. We evaluate MuCoLa on text\ngeneration with soft and hard constraints as well as their combinations\nobtaining significant improvements over competitive baselines for toxicity\navoidance, sentiment control, and keyword-guided generation.", "published": "2022-05-25 08:09:03", "link": "http://arxiv.org/abs/2205.12558v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EDIN: An End-to-end Benchmark and Pipeline for Unknown Entity Discovery\n  and Indexing", "abstract": "Existing work on Entity Linking mostly assumes that the reference knowledge\nbase is complete, and therefore all mentions can be linked. In practice this is\nhardly ever the case, as knowledge bases are incomplete and because novel\nconcepts arise constantly. This paper created the Unknown Entity Discovery and\nIndexing (EDIN) benchmark where unknown entities, that is entities without a\ndescription in the knowledge base and labeled mentions, have to be integrated\ninto an existing entity linking system. By contrasting EDIN with zero-shot\nentity linking, we provide insight on the additional challenges it poses.\nBuilding on dense-retrieval based entity linking, we introduce the end-to-end\nEDIN pipeline that detects, clusters, and indexes mentions of unknown entities\nin context. Experiments show that indexing a single embedding per entity\nunifying the information of multiple mentions works better than indexing\nmentions independently.", "published": "2022-05-25 08:29:39", "link": "http://arxiv.org/abs/2205.12570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText\n  Generators", "abstract": "In this paper, we study the task of improving the cohesion and coherence of\nlong-form text generated by language models. To this end, we propose RSTGen, a\nframework that utilises Rhetorical Structure Theory (RST), a classical language\ntheory, to control the discourse structure, semantics and topics of generated\ntext. Firstly, we demonstrate our model's ability to control structural\ndiscourse and semantic features of generated text in open generation\nevaluation. Then we experiment on the two challenging long-form text tasks of\nargument generation and story generation. Evaluation using automated metrics\nand a metric with high correlation to human evaluation, shows that our model\nperforms competitively against existing models, while offering significantly\nmore controls over generated text than alternative methods.", "published": "2022-05-25 09:06:04", "link": "http://arxiv.org/abs/2205.12590v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious\n  Feature-Label Correlation", "abstract": "Recent research has revealed that deep neural networks often take dataset\nbiases as a shortcut to make decisions rather than understand tasks, leading to\nfailures in real-world applications. In this study, we focus on the spurious\ncorrelation between word features and labels that models learn from the biased\ndata distribution of training data. In particular, we define the word highly\nco-occurring with a specific label as biased word, and the example containing\nbiased word as biased example. Our analysis shows that biased examples are\neasier for models to learn, while at the time of prediction, biased words make\na significantly higher contribution to the models' predictions, and models tend\nto assign predicted labels over-relying on the spurious correlation between\nwords and labels. To mitigate models' over-reliance on the shortcut (i.e.\nspurious correlation), we propose a training strategy Less-Learn-Shortcut\n(LLS): our strategy quantifies the biased degree of the biased examples and\ndown-weights them accordingly. Experimental results on Question Matching,\nNatural Language Inference and Sentiment Analysis tasks show that LLS is a\ntask-agnostic strategy and can improve the model performance on adversarial\ndata while maintaining good performance on in-domain data.", "published": "2022-05-25 09:08:35", "link": "http://arxiv.org/abs/2205.12593v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging QA Datasets to Improve Generative Data Augmentation", "abstract": "The ability of generative language models (GLMs) to generate text has\nimproved considerably in the last few years, enabling their use for generative\ndata augmentation. In this work, we propose CONDA, an approach to further\nimprove GLMs' ability to generate synthetic data by reformulating data\ngeneration as context generation for a given question-answer (QA) pair and\nleveraging QA datasets for training context generators. Then, we cast\ndownstream tasks into the same question answering format and adapt the\nfine-tuned context generators to the target task domain. Finally, we use the\nfine-tuned GLM to generate relevant contexts, which are in turn used as\nsynthetic training data for their corresponding tasks. We perform extensive\nexperiments on multiple classification datasets and demonstrate substantial\nimprovements in performance for both few- and zero-shot settings. Our analysis\nreveals that QA datasets that require high-level reasoning abilities (e.g.,\nabstractive and common-sense QA datasets) tend to give the best boost in\nperformance in both few-shot and zero-shot settings.", "published": "2022-05-25 09:28:21", "link": "http://arxiv.org/abs/2205.12604v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generating Information-Seeking Conversations from Unlabeled Documents", "abstract": "In this paper, we introduce a novel framework, SIMSEEK, (Simulating\ninformation-Seeking conversation from unlabeled documents), and compare its two\nvariants. In our baseline SIMSEEK-SYM, a questioner generates follow-up\nquestions upon the predetermined answer by an answerer. On the contrary,\nSIMSEEK-ASYM first generates the question and then finds its corresponding\nanswer under the conversational context. Our experiments show that they can\nsynthesize effective training resources for CQA and conversational search\ntasks. As a result, conversations from SIMSEEK-ASYM not only make more\nimprovements in our experiments but also are favorably reviewed in a human\nevaluation. We finally release a large-scale resource of synthetic\nconversations, WIKI-SIMSEEK, containing 2 million CQA pairs built upon\nWikipedia documents. With the dataset, our CQA model achieves state-of-the-art\nperformance on a recent CQA benchmark, QuAC.", "published": "2022-05-25 09:33:00", "link": "http://arxiv.org/abs/2205.12609v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Zipf's Law-based Text Generation Approach for Addressing Imbalance in\n  Entity Extraction", "abstract": "Entity extraction is critical in the intelligent advancement across diverse\ndomains. Nevertheless, a challenge to its effectiveness arises from the data\nimbalance. This paper proposes a novel approach by viewing the issue through\nthe quantitative information, recognizing that entities exhibit certain levels\nof commonality while others are scarce, which can be reflected in the\nquantifiable distribution of words. The Zipf's Law emerges as a well-suited\nadoption, and to transition from words to entities, words within the documents\nare classified as common and rare ones. Subsequently, sentences are classified\ninto common and rare ones, and are further processed by text generation models\naccordingly. Rare entities within the generated sentences are then labeled\nusing human-designed rules, serving as a supplement to the raw dataset, thereby\nmitigating the imbalance problem. The study presents a case of extracting\nentities from technical documents, and experimental results from two datasets\nprove the effectiveness of the proposed method. Furthermore, the significance\nof Zipf's law in driving the progress of AI is discussed, broadening the reach\nand coverage of Informetrics. This paper presents a successful demonstration of\nextending Informetrics to interface with AI through Zipf's Law.", "published": "2022-05-25 10:22:14", "link": "http://arxiv.org/abs/2205.12636v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating\n  Spurious Correlations in Entity Typing", "abstract": "Entity typing aims at predicting one or more words that describe the type(s)\nof a specific mention in a sentence. Due to shortcuts from surface patterns to\nannotated entity labels and biased training, existing entity typing models are\nsubject to the problem of spurious correlations. To comprehensively investigate\nthe faithfulness and reliability of entity typing methods, we first\nsystematically define distinct kinds of model biases that are reflected mainly\nfrom spurious correlations. Particularly, we identify six types of existing\nmodel biases, including mention-context bias, lexical overlapping bias, named\nentity bias, pronoun bias, dependency bias, and overgeneralization bias. To\nmitigate model biases, we then introduce a counterfactual data augmentation\nmethod. By augmenting the original training set with their debiased\ncounterparts, models are forced to fully comprehend sentences and discover the\nfundamental cues for entity typing, rather than relying on spurious\ncorrelations for shortcuts. Experimental results on the UFET dataset show our\ncounterfactual data augmentation approach helps improve generalization of\ndifferent entity typing models with consistently better performance on both the\noriginal and debiased test sets.", "published": "2022-05-25 10:34:22", "link": "http://arxiv.org/abs/2205.12640v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Asking the Right Questions in Low Resource Template Extraction", "abstract": "Information Extraction (IE) researchers are mapping tasks to Question\nAnswering (QA) in order to leverage existing large QA resources, and thereby\nimprove data efficiency. Especially in template extraction (TE), mapping an\nontology to a set of questions can be more time-efficient than collecting\nlabeled examples. We ask whether end users of TE systems can design these\nquestions, and whether it is beneficial to involve an NLP practitioner in the\nprocess. We compare questions to other ways of phrasing natural language\nprompts for TE. We propose a novel model to perform TE with prompts, and find\nit benefits from questions over other styles of prompts, and that they do not\nrequire an NLP background to author.", "published": "2022-05-25 10:39:09", "link": "http://arxiv.org/abs/2205.12643v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LingMess: Linguistically Informed Multi Expert Scorers for Coreference\n  Resolution", "abstract": "While coreference resolution typically involves various linguistic\nchallenges, recent models are based on a single pairwise scorer for all types\nof pairs. We present LingMess, a new coreference model that defines different\ncategories of coreference cases and optimize multiple pairwise scorers, where\neach scorer learns a specific set of linguistic challenges. Our model\nsubstantially improves pairwise scores for most categories and outperforms\ncluster-level performance on Ontonotes and 5 additional datasets. Our model is\navailable in https://github.com/shon-otmazgin/lingmess-coref", "published": "2022-05-25 10:39:46", "link": "http://arxiv.org/abs/2205.12644v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation", "abstract": "In this paper, we explore the challenging problem of performing a generative\ntask in a target language when labeled data is only available in English, using\nsummarization as a case study. We assume a strict setting with no access to\nparallel data or machine translation and find that common transfer learning\napproaches struggle in this setting, as a generative multilingual model\nfine-tuned purely on English catastrophically forgets how to generate\nnon-English. Given the recent rise of parameter-efficient adaptation\ntechniques, we conduct the first investigation into how one such method, prompt\ntuning (Lester et al., 2021), can overcome catastrophic forgetting to enable\nzero-shot cross-lingual generation. Our experiments show that\nparameter-efficient prompt tuning provides gains over standard fine-tuning when\ntransferring between less-related languages, e.g., from English to Thai.\nHowever, a significant gap still remains between these methods and\nfully-supervised baselines. To improve cross-lingual transfer further, we\nexplore several approaches, including: (1) mixing in unlabeled multilingual\ndata, and (2) explicitly factoring prompts into recombinable language and task\ncomponents. Our approaches can provide further quality gains, suggesting that\nrobust zero-shot cross-lingual generation is within reach.", "published": "2022-05-25 10:41:34", "link": "http://arxiv.org/abs/2205.12647v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Lexical Replacements for Arabic-English Code-Switched Data\n  Augmentation", "abstract": "Data sparsity is a main problem hindering the development of code-switching\n(CS) NLP systems. In this paper, we investigate data augmentation techniques\nfor synthesizing dialectal Arabic-English CS text. We perform lexical\nreplacements using word-aligned parallel corpora where CS points are either\nrandomly chosen or learnt using a sequence-to-sequence model. We compare these\napproaches against dictionary-based replacements. We assess the quality of the\ngenerated sentences through human evaluation and evaluate the effectiveness of\ndata augmentation on machine translation (MT), automatic speech recognition\n(ASR), and speech translation (ST) tasks. Results show that using a predictive\nmodel results in more natural CS sentences compared to the random approach, as\nreported in human judgements. In the downstream tasks, despite the random\napproach generating more data, both approaches perform equally (outperforming\ndictionary-based replacements). Overall, data augmentation achieves 34%\nimprovement in perplexity, 5.2% relative improvement on WER for ASR task,\n+4.0-5.1 BLEU points on MT task, and +2.1-2.2 BLEU points on ST over a baseline\ntrained on available data without augmentation.", "published": "2022-05-25 10:44:36", "link": "http://arxiv.org/abs/2205.12649v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bitext Mining Using Distilled Sentence Representations for Low-Resource\n  Languages", "abstract": "Scaling multilingual representation learning beyond the hundred most frequent\nlanguages is challenging, in particular to cover the long tail of low-resource\nlanguages. A promising approach has been to train one-for-all multilingual\nmodels capable of cross-lingual transfer, but these models often suffer from\ninsufficient capacity and interference between unrelated languages. Instead, we\nmove away from this approach and focus on training multiple language (family)\nspecific representations, but most prominently enable all languages to still be\nencoded in the same representational space. To achieve this, we focus on\nteacher-student training, allowing all encoders to be mutually compatible for\nbitext mining, and enabling fast learning of new languages. We introduce a new\nteacher-student training scheme which combines supervised and self-supervised\ntraining, allowing encoders to take advantage of monolingual training data,\nwhich is valuable in the low-resource setting.\n  Our approach significantly outperforms the original LASER encoder. We study\nvery low-resource languages and handle 50 African languages, many of which are\nnot covered by any other model. For these languages, we train sentence\nencoders, mine bitexts, and validate the bitexts by training NMT systems.", "published": "2022-05-25 10:53:24", "link": "http://arxiv.org/abs/2205.12654v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DFM: Dialogue Foundation Model for Universal Large-Scale\n  Dialogue-Oriented Task Learning", "abstract": "Building a universal conversational agent has been a long-standing goal of\nthe dialogue research community. Most previous works only focus on a small set\nof dialogue tasks. In this work, we aim to build a unified dialogue foundation\nmodel (DFM) which can be used to solve massive diverse dialogue tasks. To\nachieve this goal, a large-scale well-annotated dialogue dataset with rich task\ndiversity (DialogZoo) is collected. We introduce a framework to unify all\ndialogue tasks and propose novel auxiliary self-supervised tasks to achieve\nstable training of DFM on the highly diverse large scale DialogZoo corpus.\nExperiments show that, compared with models of the same size, DFM can achieve\nstate-of-the-art or competitive performance on very rich cross-domain\ndownstream dialogue tasks. This demonstrates that DFM largely extends the\nability of unified dialogue pre-trained model.", "published": "2022-05-25 11:17:16", "link": "http://arxiv.org/abs/2205.12662v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QAMPARI: An Open-domain Question Answering Benchmark for Questions with\n  Many Answers from Multiple Paragraphs", "abstract": "Existing benchmarks for open-domain question answering (ODQA) typically focus\non questions whose answers can be extracted from a single paragraph. By\ncontrast, many natural questions, such as \"What players were drafted by the\nBrooklyn Nets?\" have a list of answers. Answering such questions requires\nretrieving and reading from many passages, in a large corpus. We introduce\nQAMPARI, an ODQA benchmark, where question answers are lists of entities,\nspread across many paragraphs. We created QAMPARI by (a) generating questions\nwith multiple answers from Wikipedia's knowledge graph and tables, (b)\nautomatically pairing answers with supporting evidence in Wikipedia paragraphs,\nand (c) manually paraphrasing questions and validating each answer. We train\nODQA models from the retrieve-and-read family and find that QAMPARI is\nchallenging in terms of both passage retrieval and answer generation, reaching\nan F1 score of 32.8 at best. Our results highlight the need for developing ODQA\nmodels that handle a broad range of question types, including single and\nmulti-answer questions.", "published": "2022-05-25 11:21:30", "link": "http://arxiv.org/abs/2205.12665v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Discovering Language-neutral Sub-networks in Multilingual Language\n  Models", "abstract": "Multilingual pre-trained language models transfer remarkably well on\ncross-lingual downstream tasks. However, the extent to which they learn\nlanguage-neutral representations (i.e., shared representations that encode\nsimilar phenomena across languages), and the effect of such representations on\ncross-lingual transfer performance, remain open questions. In this work, we\nconceptualize language neutrality of multilingual models as a function of the\noverlap between language-encoding sub-networks of these models. We employ the\nlottery ticket hypothesis to discover sub-networks that are individually\noptimized for various languages and tasks. Our evaluation across three distinct\ntasks and eleven typologically-diverse languages demonstrates that sub-networks\nfor different languages are topologically similar (i.e., language-neutral),\nmaking them effective initializations for cross-lingual transfer with limited\nperformance degradation.", "published": "2022-05-25 11:35:41", "link": "http://arxiv.org/abs/2205.12672v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "InstructDial: Improving Zero and Few-shot Generalization in Dialogue\n  through Instruction Tuning", "abstract": "Instruction tuning is an emergent paradigm in NLP wherein natural language\ninstructions are leveraged with language models to induce zero-shot performance\non unseen tasks. Instructions have been shown to enable good performance on\nunseen tasks and datasets in both large and small language models. Dialogue is\nan especially interesting area to explore instruction tuning because dialogue\nsystems perform multiple kinds of tasks related to language (e.g., natural\nlanguage understanding and generation, domain-specific interaction), yet\ninstruction tuning has not been systematically explored for dialogue-related\ntasks. We introduce InstructDial, an instruction tuning framework for dialogue,\nwhich consists of a repository of 48 diverse dialogue tasks in a unified\ntext-to-text format created from 59 openly available dialogue datasets. Next,\nwe explore cross-task generalization ability on models tuned on InstructDial\nacross diverse dialogue tasks. Our analysis reveals that InstructDial enables\ngood zero-shot performance on unseen datasets and tasks such as dialogue\nevaluation and intent detection, and even better performance in a few-shot\nsetting. To ensure that models adhere to instructions, we introduce novel\nmeta-tasks. We establish benchmark zero-shot and few-shot performance of models\ntrained using the proposed framework on multiple dialogue tasks.", "published": "2022-05-25 11:37:06", "link": "http://arxiv.org/abs/2205.12673v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating the Diversity, Equity and Inclusion of NLP Technology: A Case\n  Study for Indian Languages", "abstract": "In order for NLP technology to be widely applicable, fair, and useful, it\nneeds to serve a diverse set of speakers across the world's languages, be\nequitable, i.e., not unduly biased towards any particular language, and be\ninclusive of all users, particularly in low-resource settings where compute\nconstraints are common. In this paper, we propose an evaluation paradigm that\nassesses NLP technologies across all three dimensions. While diversity and\ninclusion have received attention in recent literature, equity is currently\nunexplored. We propose to address this gap using the Gini coefficient, a\nwell-established metric used for estimating societal wealth inequality. Using\nour paradigm, we highlight the distressed state of current technologies for\nIndian (IN) languages (a linguistically large and diverse set, with a varied\nspeaker population), across all three dimensions. To improve upon these\nmetrics, we demonstrate the importance of region-specific choices in model\nbuilding and dataset creation, and more importantly, propose a novel,\ngeneralisable approach to optimal resource allocation during fine-tuning.\nFinally, we discuss steps to mitigate these biases and encourage the community\nto employ multi-faceted evaluation when building linguistically diverse and\nequitable technologies.", "published": "2022-05-25 11:38:04", "link": "http://arxiv.org/abs/2205.12676v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Anisotropic Cross-Lingual Model Editing", "abstract": "Multilingual pre-trained language models can learn task-specific abilities or\nmemorize facts across multiple languages but inevitably make undesired\npredictions with specific inputs. Under similar observation, model editing aims\nto post-hoc calibrate a model targeted to specific inputs with keeping the\nmodel's raw behavior. However, existing work only studies the monolingual\nscenario, which lacks the cross-lingual transferability to perform editing\nsimultaneously across languages. In this work, we focus on cross-lingual model\nediting. Firstly, we define the cross-lingual model editing task and\ncorresponding metrics, where an edit in one language propagates to the others.\nNext, we propose a framework to naturally adapt monolingual model editing\napproaches to the cross-lingual scenario using parallel corpus. Further, we\npropose language anisotropic editing to improve cross-lingual editing by\namplifying different subsets of parameters for each language. On the newly\ndefined cross-lingual model editing task, we empirically demonstrate the\nfailure of monolingual baselines in propagating the edit to multiple languages\nand the effectiveness of the proposed language anisotropic model editing. Our\ncode is publicly available at https://github.com/franklear/LiME.", "published": "2022-05-25 11:38:12", "link": "http://arxiv.org/abs/2205.12677v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning", "abstract": "There is a rising interest in further exploring the zero-shot learning\npotential of large pre-trained language models (PLMs). A new paradigm called\ndata-generation-based zero-shot learning has achieved impressive success. In\nthis paradigm, the synthesized data from the PLM acts as the carrier of\nknowledge, which is used to train a task-specific model with orders of\nmagnitude fewer parameters than the PLM, achieving both higher performance and\nefficiency than prompt-based zero-shot learning methods on PLMs. The main\nhurdle of this approach is that the synthesized data from PLM usually contains\na significant portion of low-quality samples. Fitting on such data will greatly\nhamper the performance of the task-specific model, making it unreliable for\ndeployment. Previous methods remedy this issue mainly by filtering synthetic\ndata using heuristic metrics(e.g., output confidence), or refining the data\nwith the help of a human expert, which comes with excessive manual tuning or\nexpensive costs. In this paper, we propose a novel noise-robust re-weighting\nframework SunGen to automatically construct high-quality data for zero-shot\nclassification problems. Our framework features the ability to learn the sample\nweights indicating data quality without requiring any human annotation. We\ntheoretically and empirically verify the ability of our method to help\nconstruct good-quality synthetic datasets. Notably, SunGen-LSTM yields a 9.8%\nrelative improvement than the baseline on average accuracy across eight\ndifferent established text classification tasks.", "published": "2022-05-25 11:38:48", "link": "http://arxiv.org/abs/2205.12679v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProsocialDialog: A Prosocial Backbone for Conversational Agents", "abstract": "Most existing dialogue systems fail to respond properly to potentially unsafe\nuser utterances by either ignoring or passively agreeing with them. To address\nthis issue, we introduce ProsocialDialog, the first large-scale multi-turn\ndialogue dataset to teach conversational agents to respond to problematic\ncontent following social norms. Covering diverse unethical, problematic,\nbiased, and toxic situations, ProsocialDialog contains responses that encourage\nprosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb,\nRoTs). Created via a human-AI collaborative framework, ProsocialDialog consists\nof 58K dialogues, with 331K utterances, 160K unique RoTs, and 497K dialogue\nsafety labels accompanied by free-form rationales.\n  With this dataset, we introduce a dialogue safety detection module, Canary,\ncapable of generating RoTs given conversational context, and a\nsocially-informed dialogue agent, Prost. Empirical results show that Prost\ngenerates more socially acceptable dialogues compared to other state-of-the-art\nlanguage and dialogue models in both in-domain and out-of-domain settings.\nAdditionally, Canary effectively guides conversational agents and off-the-shelf\nlanguage models to generate significantly more prosocial responses. Our work\nhighlights the promise and importance of creating and steering conversational\nAI to be socially responsible.", "published": "2022-05-25 11:48:47", "link": "http://arxiv.org/abs/2205.12688v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation", "abstract": "Logical table-to-text generation is a task that involves generating logically\nfaithful sentences from tables, which requires models to derive logical level\nfacts from table records via logical inference. It raises a new challenge on\nthe logical-level content planning of table-to-text models. However, directly\nlearning the logical inference knowledge from table-text pairs is very\ndifficult for neural models because of the ambiguity of natural language and\nthe scarcity of parallel data. Hence even large-scale pre-trained language\nmodels present low logical fidelity on logical table-to-text. In this work, we\npropose a PLOG (Pretrained Logical Form Generator) framework to improve the\ngeneration fidelity. Specifically, PLOG is first pretrained on a\ntable-to-logic-form generation (table-to-logic) task, then finetuned on\ndownstream table-to-text tasks. The formal definition of logical forms enables\nus to collect large amount of accurate logical forms from tables without human\nannotation. In addition, PLOG can learn logical inference from table-logic\npairs much more definitely than from table-text pairs. To evaluate our model,\nwe further collect a controlled logical table-to-text dataset CONTLOG based on\nan existing dataset. On two benchmarks, LOGICNLG and CONTLOG, PLOG outperforms\nstrong baselines by a large margin on the logical fidelity, demonstrating the\neffectiveness of table-to-logic pretraining.", "published": "2022-05-25 11:55:54", "link": "http://arxiv.org/abs/2205.12697v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Empathic Conversations: A Multi-level Dataset of Contextualized\n  Conversations", "abstract": "Empathy is a cognitive and emotional reaction to an observed situation of\nothers. Empathy has recently attracted interest because it has numerous\napplications in psychology and AI, but it is unclear how different forms of\nempathy (e.g., self-report vs counterpart other-report, concern vs. distress)\ninteract with other affective phenomena or demographics like gender and age. To\nbetter understand this, we created the {\\it Empathic Conversations} dataset of\nannotated negative, empathy-eliciting dialogues in which pairs of participants\nconverse about news articles. People differ in their perception of the empathy\nof others. These differences are associated with certain characteristics such\nas personality and demographics. Hence, we collected detailed characterization\nof the participants' traits, their self-reported empathetic response to news\narticles, their conversational partner other-report, and turn-by-turn\nthird-party assessments of the level of self-disclosure, emotion, and empathy\nexpressed. This dataset is the first to present empathy in multiple forms along\nwith personal distress, emotion, personality characteristics, and person-level\ndemographic information. We present baseline models for predicting some of\nthese features from conversations.", "published": "2022-05-25 11:56:29", "link": "http://arxiv.org/abs/2205.12698v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BITE: Textual Backdoor Attacks with Iterative Trigger Injection", "abstract": "Backdoor attacks have become an emerging threat to NLP systems. By providing\npoisoned training data, the adversary can embed a \"backdoor\" into the victim\nmodel, which allows input instances satisfying certain textual patterns (e.g.,\ncontaining a keyword) to be predicted as a target label of the adversary's\nchoice. In this paper, we demonstrate that it is possible to design a backdoor\nattack that is both stealthy (i.e., hard to notice) and effective (i.e., has a\nhigh attack success rate). We propose BITE, a backdoor attack that poisons the\ntraining data to establish strong correlations between the target label and a\nset of \"trigger words\". These trigger words are iteratively identified and\ninjected into the target-label instances through natural word-level\nperturbations. The poisoned training data instruct the victim model to predict\nthe target label on inputs containing trigger words, forming the backdoor.\nExperiments on four text classification datasets show that our proposed attack\nis significantly more effective than baseline methods while maintaining decent\nstealthiness, raising alarm on the usage of untrusted training data. We further\npropose a defense method named DeBITE based on potential trigger word removal,\nwhich outperforms existing methods in defending against BITE and generalizes\nwell to handling other backdoor attacks.", "published": "2022-05-25 11:58:38", "link": "http://arxiv.org/abs/2205.12700v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Label Errors by using Pre-Trained Language Models", "abstract": "We show that large pre-trained language models are inherently highly capable\nof identifying label errors in natural language datasets: simply examining\nout-of-sample data points in descending order of fine-tuned task loss\nsignificantly outperforms more complex error-detection mechanisms proposed in\nprevious work.\n  To this end, we contribute a novel method for introducing realistic,\nhuman-originated label noise into existing crowdsourced datasets such as SNLI\nand TweetNLP. We show that this noise has similar properties to real,\nhand-verified label errors, and is harder to detect than existing synthetic\nnoise, creating challenges for model robustness. We argue that human-originated\nnoise is a better standard for evaluation than synthetic noise.\n  Finally, we use crowdsourced verification to evaluate the detection of real\nerrors on IMDB, Amazon Reviews, and Recon, and confirm that pre-trained models\nperform at a 9-36% higher absolute Area Under the Precision-Recall Curve than\nexisting models.", "published": "2022-05-25 11:59:39", "link": "http://arxiv.org/abs/2205.12702v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "New Intent Discovery with Pre-training and Contrastive Learning", "abstract": "New intent discovery aims to uncover novel intent categories from user\nutterances to expand the set of supported intent classes. It is a critical task\nfor the development and service expansion of a practical dialogue system.\nDespite its importance, this problem remains under-explored in the literature.\nExisting approaches typically rely on a large amount of labeled utterances and\nemploy pseudo-labeling methods for representation learning and clustering,\nwhich are label-intensive, inefficient, and inaccurate. In this paper, we\nprovide new solutions to two important research questions for new intent\ndiscovery: (1) how to learn semantic utterance representations and (2) how to\nbetter cluster utterances. Particularly, we first propose a multi-task\npre-training strategy to leverage rich unlabeled data along with external\nlabeled data for representation learning. Then, we design a new contrastive\nloss to exploit self-supervisory signals in unlabeled data for clustering.\nExtensive experiments on three intent recognition benchmarks demonstrate the\nhigh effectiveness of our proposed method, which outperforms state-of-the-art\nmethods by a large margin in both unsupervised and semi-supervised scenarios.\nThe source code will be available at https://github.com/zhang-yu-wei/MTP-CLNN.", "published": "2022-05-25 17:07:25", "link": "http://arxiv.org/abs/2205.12914v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transcormer: Transformer for Sentence Scoring with Sliding Language\n  Modeling", "abstract": "Sentence scoring aims at measuring the likelihood score of a sentence and is\nwidely used in many natural language processing scenarios, like reranking,\nwhich is to select the best sentence from multiple candidates. Previous works\non sentence scoring mainly adopted either causal language modeling (CLM) like\nGPT or masked language modeling (MLM) like BERT, which have some limitations:\n1) CLM only utilizes unidirectional information for the probability estimation\nof a sentence without considering bidirectional context, which affects the\nscoring quality; 2) MLM can only estimate the probability of partial tokens at\na time and thus requires multiple forward passes to estimate the probability of\nthe whole sentence, which incurs large computation and time cost. In this\npaper, we propose \\textit{Transcormer} -- a Transformer model with a novel\n\\textit{sliding language modeling} (SLM) for sentence scoring. Specifically,\nour SLM adopts a triple-stream self-attention mechanism to estimate the\nprobability of all tokens in a sentence with bidirectional context and only\nrequires a single forward pass. SLM can avoid the limitations of CLM (only\nunidirectional context) and MLM (multiple forward passes) and inherit their\nadvantages, and thus achieve high effectiveness and efficiency in scoring.\nExperimental results on multiple tasks demonstrate that our method achieves\nbetter performance than other language modelings.", "published": "2022-05-25 18:00:09", "link": "http://arxiv.org/abs/2205.12986v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Obj2Sub: Unsupervised Conversion of Objective to Subjective Questions", "abstract": "Exams are conducted to test the learner's understanding of the subject. To\nprevent the learners from guessing or exchanging solutions, the mode of tests\nadministered must have sufficient subjective questions that can gauge whether\nthe learner has understood the concept by mandating a detailed answer. Hence,\nin this paper, we propose a novel hybrid unsupervised approach leveraging\nrule-based methods and pre-trained dense retrievers for the novel task of\nautomatically converting the objective questions to subjective questions. We\nobserve that our approach outperforms the existing data-driven approaches by\n36.45% as measured by Recall@k and Precision@k.", "published": "2022-05-25 11:46:46", "link": "http://arxiv.org/abs/2206.11848v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Do we need Label Regularization to Fine-tune Pre-trained Language\n  Models?", "abstract": "Knowledge Distillation (KD) is a prominent neural model compression technique\nthat heavily relies on teacher network predictions to guide the training of a\nstudent model. Considering the ever-growing size of pre-trained language models\n(PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is\nevident that in KD, deploying the teacher network during training adds to the\nmemory and computational requirements of training. In the computer vision\nliterature, the necessity of the teacher network is put under scrutiny by\nshowing that KD is a label regularization technique that can be replaced with\nlighter teacher-free variants such as the label-smoothing technique. However,\nto the best of our knowledge, this issue is not investigated in NLP. Therefore,\nthis work concerns studying different label regularization techniques and\nwhether we actually need them to improve the fine-tuning of smaller PLM\nnetworks on downstream tasks. In this regard, we did a comprehensive set of\nexperiments on different PLMs such as BERT, RoBERTa, and GPT with more than 600\ndistinct trials and ran each configuration five times. This investigation led\nto a surprising observation that KD and other label regularization techniques\ndo not play any meaningful role over regular fine-tuning when the student model\nis pre-trained. We further explore this phenomenon in different settings of NLP\nand computer vision tasks and demonstrate that pre-training itself acts as a\nkind of regularization, and additional label regularization is unnecessary.", "published": "2022-05-25 01:26:31", "link": "http://arxiv.org/abs/2205.12428v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Sparse*BERT: Sparse Models Generalize To New tasks and Domains", "abstract": "Large Language Models have become the core architecture upon which most\nmodern natural language processing (NLP) systems build. These models can\nconsistently deliver impressive accuracy and robustness across tasks and\ndomains, but their high computational overhead can make inference difficult and\nexpensive. To make using these models less costly, recent work has explored\nleveraging structured and unstructured pruning, quantization, and distillation\nto improve inference speed and decrease size. This paper studies how models\npruned using Gradual Unstructured Magnitude Pruning can transfer between\ndomains and tasks. Our experimentation shows that models that are pruned during\npretraining using general domain masked language models can transfer to novel\ndomains and tasks without extensive hyperparameter exploration or specialized\napproaches. We demonstrate that our general sparse model Sparse*BERT can become\nSparseBioBERT simply by pretraining the compressed architecture on unstructured\nbiomedical text. Moreover, we show that SparseBioBERT can match the quality of\nBioBERT with only 10\\% of the parameters.", "published": "2022-05-25 02:51:12", "link": "http://arxiv.org/abs/2205.12452v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Low Resource Style Transfer via Domain Adaptive Meta Learning", "abstract": "Text style transfer (TST) without parallel data has achieved some practical\nsuccess. However, most of the existing unsupervised text style transfer methods\nsuffer from (i) requiring massive amounts of non-parallel data to guide\ntransferring different text styles. (ii) colossal performance degradation when\nfine-tuning the model in new domains. In this work, we propose DAML-ATM (Domain\nAdaptive Meta-Learning with Adversarial Transfer Model), which consists of two\nparts: DAML and ATM. DAML is a domain adaptive meta-learning approach to learn\ngeneral knowledge in multiple heterogeneous source domains, capable of adapting\nto new unseen domains with a small amount of data. Moreover, we propose a new\nunsupervised TST approach Adversarial Transfer Model (ATM), composed of a\nsequence-to-sequence pre-trained language model and uses adversarial style\ntraining for better content preservation and style transfer. Results on\nmulti-domain datasets demonstrate that our approach generalizes well on unseen\nlow-resource domains, achieving state-of-the-art results against ten strong\nbaselines.", "published": "2022-05-25 03:58:24", "link": "http://arxiv.org/abs/2205.12475v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GisPy: A Tool for Measuring Gist Inference Score in Text", "abstract": "Decision making theories such as Fuzzy-Trace Theory (FTT) suggest that\nindividuals tend to rely on gist, or bottom-line meaning, in the text when\nmaking decisions. In this work, we delineate the process of developing GisPy,\nan open-source tool in Python for measuring the Gist Inference Score (GIS) in\ntext. Evaluation of GisPy on documents in three benchmarks from the news and\nscientific text domains demonstrates that scores generated by our tool\nsignificantly distinguish low vs. high gist documents. Our tool is publicly\navailable to use at: https://github.com/phosseini/GisPy.", "published": "2022-05-25 04:17:09", "link": "http://arxiv.org/abs/2205.12484v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Conditional set generation using Seq2seq models", "abstract": "Conditional set generation learns a mapping from an input sequence of tokens\nto a set. Several NLP tasks, such as entity typing and dialogue emotion\ntagging, are instances of set generation. Seq2Seq models, a popular choice for\nset generation, treat a set as a sequence and do not fully leverage its key\nproperties, namely order-invariance and cardinality. We propose a novel\nalgorithm for effectively sampling informative orders over the combinatorial\nspace of label orders. We jointly model the set cardinality and output by\nprepending the set size and taking advantage of the autoregressive\nfactorization used by Seq2Seq models. Our method is a model-independent data\naugmentation approach that endows any Seq2Seq model with the signals of\norder-invariance and cardinality. Training a Seq2Seq model on this augmented\ndata (without any additional annotations) gets an average relative improvement\nof 20% on four benchmark datasets across various models: BART, T5, and GPT-3.\nCode to use SETAUG available at: https://setgen.structgen.com.", "published": "2022-05-25 04:17:50", "link": "http://arxiv.org/abs/2205.12485v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improve Event Extraction via Self-Training with Gradient Guidance", "abstract": "Data scarcity has been the main factor that hinders the progress of event\nextraction. To overcome this issue, we propose a Self-Training with Feedback\n(STF) framework that leverages the large-scale unlabeled data and acquires\nfeedback for each new event prediction from the unlabeled data by comparing it\nto the Abstract Meaning Representation (AMR) graph of the same sentence.\nSpecifically, STF consists of (1) a base event extraction model trained on\nexisting event annotations and then applied to large-scale unlabeled corpora to\npredict new event mentions as pseudo training samples, and (2) a novel scoring\nmodel that takes in each new predicted event trigger, an argument, its argument\nrole, as well as their paths in the AMR graph to estimate a compatibility score\nindicating the correctness of the pseudo label. The compatibility scores\nfurther act as feedback to encourage or discourage the model learning on the\npseudo labels during self-training. Experimental results on three benchmark\ndatasets, including ACE05-E, ACE05-E+, and ERE, demonstrate the effectiveness\nof the STF framework on event extraction, especially event argument extraction,\nwith significant performance gain over the base event extraction models and\nstrong baselines. Our experimental analysis further shows that STF is a generic\nframework as it can be applied to improve most, if not all, event extraction\nmodels by leveraging large-scale unlabeled data, even when high-quality AMR\ngraph annotations are not available.", "published": "2022-05-25 04:40:17", "link": "http://arxiv.org/abs/2205.12490v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Teaching Broad Reasoning Skills for Multi-Step QA by Generating Hard\n  Contexts", "abstract": "Question-answering datasets require a broad set of reasoning skills. We show\nhow to use question decompositions to teach language models these broad\nreasoning skills in a robust fashion. Specifically, we use widely available\nQDMR representations to programmatically create hard-to-cheat synthetic\ncontexts for real questions in six multi-step reasoning datasets. These\ncontexts are carefully designed to avoid reasoning shortcuts prevalent in real\ncontexts that prevent models from learning the right skills. This results in a\npretraining dataset, named TeaBReaC, containing 525K multi-step questions (with\nassociated formal programs) covering about 900 reasoning patterns. We show that\npretraining standard language models (LMs) on TeaBReaC before fine-tuning them\non target datasets improves their performance by up to 13 F1 points across 4\nmulti-step QA datasets, with up to 21 point gain on more complex questions. The\nresulting models also demonstrate higher robustness, with a 5-8 F1 point\nimprovement on two contrast sets. Furthermore, TeaBReaC pretraining\nsubstantially improves model performance and robustness even when starting with\nnumerate LMs pretrained using recent methods (e.g., PReasM, POET). Our work\nthus shows how to effectively use decomposition-guided contexts to robustly\nteach multi-step reasoning.", "published": "2022-05-25 05:13:21", "link": "http://arxiv.org/abs/2205.12496v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Memorization in NLP Fine-tuning Methods", "abstract": "Large language models are shown to present privacy risks through memorization\nof training data, and several recent works have studied such risks for the\npre-training phase. Little attention, however, has been given to the\nfine-tuning phase and it is not well understood how different fine-tuning\nmethods (such as fine-tuning the full model, the model head, and adapter)\ncompare in terms of memorization risk. This presents increasing concern as the\n\"pre-train and fine-tune\" paradigm proliferates. In this paper, we empirically\nstudy memorization of fine-tuning methods using membership inference and\nextraction attacks, and show that their susceptibility to attacks is very\ndifferent. We observe that fine-tuning the head of the model has the highest\nsusceptibility to attacks, whereas fine-tuning smaller adapters appears to be\nless vulnerable to known extraction attacks.", "published": "2022-05-25 05:49:31", "link": "http://arxiv.org/abs/2205.12506v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset", "abstract": "Research in massively multilingual image captioning has been severely\nhampered by a lack of high-quality evaluation datasets. In this paper we\npresent the Crossmodal-3600 dataset (XM3600 in short), a geographically diverse\nset of 3600 images annotated with human-generated reference captions in 36\nlanguages. The images were selected from across the world, covering regions\nwhere the 36 languages are spoken, and annotated with captions that achieve\nconsistency in terms of style across all languages, while avoiding annotation\nartifacts due to direct translation. We apply this benchmark to model selection\nfor massively multilingual image captioning models, and show superior\ncorrelation results with human evaluations when using XM3600 as golden\nreferences for automatic metrics.", "published": "2022-05-25 06:30:19", "link": "http://arxiv.org/abs/2205.12522v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning", "abstract": "Prompting has shown impressive success in enabling large pretrained language\nmodels (LMs) to perform diverse NLP tasks, especially when only few downstream\ndata are available. Automatically finding the optimal prompt for each task,\nhowever, is challenging. Most existing work resorts to tuning soft prompt\n(e.g., embeddings) which falls short of interpretability, reusability across\nLMs, and applicability when gradients are not accessible. Discrete prompt, on\nthe other hand, is difficult to optimize, and is often created by \"enumeration\n(e.g., paraphrasing)-then-selection\" heuristics that do not explore the prompt\nspace systematically. This paper proposes RLPrompt, an efficient discrete\nprompt optimization approach with reinforcement learning (RL). RLPrompt\nformulates a parameter-efficient policy network that generates the desired\ndiscrete prompt after training with reward. To overcome the complexity and\nstochasticity of reward signals by the large LM environment, we incorporate\neffective reward stabilization that substantially enhances the training\nefficiency. RLPrompt is flexibly applicable to different types of LMs, such as\nmasked (e.g., BERT) and left-to-right models (e.g., GPTs), for both\nclassification and generation tasks. Experiments on few-shot classification and\nunsupervised text style transfer show superior performance over a wide range of\nexisting finetuning or prompting methods. Interestingly, the resulting\noptimized prompts are often ungrammatical gibberish text; and surprisingly,\nthose gibberish prompts are transferrable between different LMs to retain\nsignificant performance, indicating LM prompting may not follow human language\npatterns.", "published": "2022-05-25 07:50:31", "link": "http://arxiv.org/abs/2205.12548v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Are Akpans Trick or Treat: Unveiling Helpful Biases in Assistant Systems", "abstract": "Information-seeking AI assistant systems aim to answer users' queries about\nknowledge in a timely manner. However, both the human-perceived helpfulness of\ninformation-seeking assistant systems and its fairness implication are\nunder-explored. In this paper, we study computational measurements of\nhelpfulness. We collect human annotations on the helpfulness of dialogue\nresponses, develop models for automatic helpfulness evaluation, and then\npropose to use the helpfulness level of a dialogue system towards different\nuser queries to gauge the fairness of a dialogue system. Experiments with\nstate-of-the-art dialogue systems, including ChatGPT, under three\ninformation-seeking scenarios reveal that existing systems tend to be more\nhelpful for questions regarding concepts from highly-developed countries than\nless-developed countries, uncovering potential fairness concerns underlying the\ncurrent information-seeking assistant systems.", "published": "2022-05-25 07:58:38", "link": "http://arxiv.org/abs/2205.12554v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TAGPRIME: A Unified Framework for Relational Structure Extraction", "abstract": "Many tasks in natural language processing require the extraction of\nrelationship information for a given condition, such as event argument\nextraction, relation extraction, and task-oriented semantic parsing. Recent\nworks usually propose sophisticated models for each task independently and pay\nless attention to the commonality of these tasks and to have a unified\nframework for all the tasks. In this work, we propose to take a unified view of\nall these tasks and introduce TAGPRIME to address relational structure\nextraction problems. TAGPRIME is a sequence tagging model that appends priming\nwords about the information of the given condition (such as an event trigger)\nto the input text. With the self-attention mechanism in pre-trained language\nmodels, the priming words make the output contextualized representations\ncontain more information about the given condition, and hence become more\nsuitable for extracting specific relationships for the condition. Extensive\nexperiments and analyses on three different tasks that cover ten datasets\nacross five different languages demonstrate the generality and effectiveness of\nTAGPRIME.", "published": "2022-05-25 08:57:46", "link": "http://arxiv.org/abs/2205.12585v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Perturbation Augmentation for Fairer NLP", "abstract": "Unwanted and often harmful social biases are becoming ever more salient in\nNLP research, affecting both models and datasets. In this work, we ask whether\ntraining on demographically perturbed data leads to fairer language models. We\ncollect a large dataset of human annotated text perturbations and train a\nneural perturbation model, which we show outperforms heuristic alternatives. We\nfind that (i) language models (LMs) pre-trained on demographically perturbed\ncorpora are typically more fair, and (ii) LMs finetuned on perturbed GLUE\ndatasets exhibit less demographic bias on downstream tasks, and (iii) fairness\nimprovements do not come at the expense of performance on downstream tasks.\nLastly, we discuss outstanding questions about how best to evaluate the\n(un)fairness of large language models. We hope that this exploration of neural\ndemographic perturbation will help drive more improvement towards fairer NLP.", "published": "2022-05-25 09:00:29", "link": "http://arxiv.org/abs/2205.12586v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ORCA: Interpreting Prompted Language Models via Locating Supporting Data\n  Evidence in the Ocean of Pretraining Data", "abstract": "Large pretrained language models have been performing increasingly well in a\nvariety of downstream tasks via prompting. However, it remains unclear from\nwhere the model learns the task-specific knowledge, especially in a zero-shot\nsetup. In this work, we want to find evidence of the model's task-specific\ncompetence from pretraining and are specifically interested in locating a very\nsmall subset of pretraining data that directly supports the model in the task.\nWe call such a subset supporting data evidence and propose a novel method ORCA\nto effectively identify it, by iteratively using gradient information related\nto the downstream task. This supporting data evidence offers interesting\ninsights about the prompted language models: in the tasks of sentiment analysis\nand textual entailment, BERT shows a substantial reliance on BookCorpus, the\nsmaller corpus of BERT's two pretraining corpora, as well as on pretraining\nexamples that mask out synonyms to the task verbalizers.", "published": "2022-05-25 09:25:06", "link": "http://arxiv.org/abs/2205.12600v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Unbiased and Efficient Sampling of Dependency Trees", "abstract": "Most computational models of dependency syntax consist of distributions over\nspanning trees. However, the majority of dependency treebanks require that\nevery valid dependency tree has a single edge coming out of the ROOT node, a\nconstraint that is not part of the definition of spanning trees. For this\nreason all standard inference algorithms for spanning trees are suboptimal for\ninference over dependency trees.\n  Zmigrod et al. (2021b) proposed algorithms for sampling with and without\nreplacement from the dependency tree distribution that incorporate the\nsingle-root constraint. In this paper we show that their fastest algorithm for\nsampling with replacement, Wilson-RC, is in fact producing biased samples and\nwe provide two alternatives that are unbiased. Additionally, we propose two\nalgorithms (one incremental, one parallel) that reduce the asymptotic runtime\nof algorithm for sampling k trees without replacement to O(kn3). These\nalgorithms are both asymptotically and practically more efficient.", "published": "2022-05-25 09:57:28", "link": "http://arxiv.org/abs/2205.12621v2", "categories": ["cs.CL", "cs.DS"], "primary_category": "cs.CL"}
{"title": "Multimodal Knowledge Alignment with Reinforcement Learning", "abstract": "Large language models readily adapt to novel settings, even without\ntask-specific training data. Can their zero-shot capacity be extended to\nmultimodal inputs? In this work, we propose ESPER which extends language-only\nzero-shot models to unseen multimodal tasks, like image and audio captioning.\nOur key novelty is to use reinforcement learning to align multimodal inputs to\nlanguage model generations without direct supervision: for example, in the\nimage case our reward optimization relies only on cosine similarity derived\nfrom CLIP, and thus requires no additional explicitly paired (image, caption)\ndata. Because the parameters of the language model are left unchanged, the\nmodel maintains its capacity for zero-shot generalization. Experiments\ndemonstrate that ESPER outperforms baselines and prior work on a variety of\nzero-shot tasks; these include a new benchmark we collect+release, ESP dataset,\nwhich tasks models with generating several diversely-styled captions for each\nimage.", "published": "2022-05-25 10:12:17", "link": "http://arxiv.org/abs/2205.12630v1", "categories": ["cs.CL", "cs.CV", "I.2.7; I.4.9"], "primary_category": "cs.CL"}
{"title": "Few-shot Reranking for Multi-hop QA via Language Model Prompting", "abstract": "We study few-shot reranking for multi-hop QA with open-domain questions. To\nalleviate the need for a large number of labeled question-document pairs for\nretriever training, we propose PromptRank, which relies on large language\nmodels prompting for multi-hop path reranking. PromptRank first constructs an\ninstruction-based prompt that includes a candidate document path and then\ncomputes the relevance score between a given question and the path based on the\nconditional likelihood of the question given the path prompt according to a\nlanguage model. PromptRank yields strong retrieval performance on HotpotQA with\nonly 128 training examples compared to state-of-the-art methods trained on\nthousands of examples -- 73.6 recall@10 by PromptRank vs. 77.8 by PathRetriever\nand 77.5 by multi-hop dense retrieval. Code available at\nhttps://github.com/mukhal/PromptRank", "published": "2022-05-25 10:45:55", "link": "http://arxiv.org/abs/2205.12650v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Training Language Models with Memory Augmentation", "abstract": "Recent work has improved language models (LMs) remarkably by equipping them\nwith a non-parametric memory component. However, most existing approaches only\nintroduce mem-ories at testing time or represent them using a separately\ntrained encoder, resulting in suboptimal training of the language model. In\nthis work, we present TRIME, a novel yet simple training approach designed for\ntraining LMs with memory augmentation. Our approach uses a training objective\nthat directly takes in-batch examples as accessible memory. We also present new\nmethods for memory construction and data batching, which are used for adapting\nto different sets of memories--local, long-term, and external memory--at\ntesting time. We evaluate TRIME on multiple language modeling and machine\ntranslation benchmarks and show that it is able to achieve significant\nimprovements across all the settings. Concretely, TRIME reduces the perplexity\nfrom 18.70 to 15.37 on WIKITEXT-103, by effectively leveraging a large memory\nset from the training corpus. Compared to standard LM training, TRIME adds\nnegligible computational overhead and is compatible with different neural\narchitectures, making it a versatile solution for training memory-augmented\nLMs.", "published": "2022-05-25 11:37:29", "link": "http://arxiv.org/abs/2205.12674v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Optimizing Test-Time Query Representations for Dense Retrieval", "abstract": "Recent developments of dense retrieval rely on quality representations of\nqueries and contexts from pre-trained query and context encoders. In this\npaper, we introduce TOUR (Test-Time Optimization of Query Representations),\nwhich further optimizes instance-level query representations guided by signals\nfrom test-time retrieval results. We leverage a cross-encoder re-ranker to\nprovide fine-grained pseudo labels over retrieval results and iteratively\noptimize query representations with gradient descent. Our theoretical analysis\nreveals that TOUR can be viewed as a generalization of the classical Rocchio\nalgorithm for pseudo relevance feedback, and we present two variants that\nleverage pseudo-labels as hard binary or soft continuous labels. We first apply\nTOUR on phrase retrieval with our proposed phrase re-ranker, and also evaluate\nits effectiveness on passage retrieval with an off-the-shelf re-ranker. TOUR\ngreatly improves end-to-end open-domain question answering accuracy, as well as\npassage retrieval performance. TOUR also consistently improves direct\nre-ranking by up to 2.0% while running 1.3-2.4x faster with an efficient\nimplementation.", "published": "2022-05-25 11:39:42", "link": "http://arxiv.org/abs/2205.12680v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Large Language Models are Few-Shot Clinical Information Extractors", "abstract": "A long-running goal of the clinical NLP community is the extraction of\nimportant variables trapped in clinical notes. However, roadblocks have\nincluded dataset shift from the general domain and a lack of public clinical\ncorpora and annotations. In this work, we show that large language models, such\nas InstructGPT, perform well at zero- and few-shot information extraction from\nclinical text despite not being trained specifically for the clinical domain.\nWhereas text classification and generation performance have already been\nstudied extensively in such models, here we additionally demonstrate how to\nleverage them to tackle a diverse set of NLP tasks which require more\nstructured outputs, including span identification, token-level sequence\nclassification, and relation extraction. Further, due to the dearth of\navailable data to evaluate these systems, we introduce new datasets for\nbenchmarking few-shot clinical information extraction based on a manual\nre-annotation of the CASI dataset for new tasks. On the clinical extraction\ntasks we studied, the GPT-3 systems significantly outperform existing zero- and\nfew-shot baselines.", "published": "2022-05-25 11:49:58", "link": "http://arxiv.org/abs/2205.12689v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding Natural Language in Context", "abstract": "Recent years have seen an increasing number of applications that have a\nnatural language interface, either in the form of chatbots or via personal\nassistants such as Alexa (Amazon), Google Assistant, Siri (Apple), and Cortana\n(Microsoft). To use these applications, a basic dialog between the robot and\nthe human is required.\n  While this kind of dialog exists today mainly within \"static\" robots that do\nnot make any movement in the household space, the challenge of reasoning about\nthe information conveyed by the environment increases significantly when\ndealing with robots that can move and manipulate objects in our home\nenvironment.\n  In this paper, we focus on cognitive robots, which have some knowledge-based\nmodels of the world and operate by reasoning and planning with this model.\nThus, when the robot and the human communicate, there is already some formalism\nthey can use - the robot's knowledge representation formalism.\n  Our goal in this research is to translate natural language utterances into\nthis robot's formalism, allowing much more complicated household tasks to be\ncompleted. We do so by combining off-the-shelf SOTA language models, planning\ntools, and the robot's knowledge-base for better communication. In addition, we\nanalyze different directive types and illustrate the contribution of the\nworld's context to the translation process.", "published": "2022-05-25 11:52:16", "link": "http://arxiv.org/abs/2205.12691v1", "categories": ["cs.CL", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Revisiting DocRED -- Addressing the False Negative Problem in Relation\n  Extraction", "abstract": "The DocRED dataset is one of the most popular and widely used benchmarks for\ndocument-level relation extraction (RE). It adopts a recommend-revise\nannotation scheme so as to have a large-scale annotated dataset. However, we\nfind that the annotation of DocRED is incomplete, i.e., false negative samples\nare prevalent. We analyze the causes and effects of the overwhelming false\nnegative problem in the DocRED dataset. To address the shortcoming, we\nre-annotate 4,053 documents in the DocRED dataset by adding the missed relation\ntriples back to the original DocRED. We name our revised DocRED dataset\nRe-DocRED. We conduct extensive experiments with state-of-the-art neural models\non both datasets, and the experimental results show that the models trained and\nevaluated on our Re-DocRED achieve performance improvements of around 13 F1\npoints. Moreover, we conduct a comprehensive analysis to identify the potential\nareas for further improvement. Our dataset is publicly available at\nhttps://github.com/tonytan48/Re-DocRED.", "published": "2022-05-25 11:54:48", "link": "http://arxiv.org/abs/2205.12696v3", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Eliciting and Understanding Cross-Task Skills with Task-Level\n  Mixture-of-Experts", "abstract": "Recent works suggest that transformer models are capable of multi-tasking on\ndiverse NLP tasks and adapting to new tasks efficiently. However, the potential\nof these multi-task models may be limited as they use the same set of\nparameters for all tasks. In contrast, humans tackle tasks in a more flexible\nway, by making proper presumptions on what skills and knowledge are relevant\nand executing only the necessary computations. Inspired by this, we propose to\nuse task-level mixture-of-expert models, which has a collection of transformer\nlayers (i.e., experts) and a router component that chooses from these experts\ndynamically and flexibly. We find that these models help improve the average\nperformance gain (ARG) metric by 2.6% when adapting to unseen tasks in the\nfew-shot setting and by 5.6% in the zero-shot generalization setting. Further,\nwe show that the learned routing decisions partly rediscover human\ncategorization of NLP tasks -- certain experts are strongly associated with\nextractive tasks, some with classification tasks, and some with tasks requiring\nworld knowledge.", "published": "2022-05-25 11:59:05", "link": "http://arxiv.org/abs/2205.12701v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Would You Ask it that Way? Measuring and Improving Question Naturalness\n  for Knowledge Graph Question Answering", "abstract": "Knowledge graph question answering (KGQA) facilitates information access by\nleveraging structured data without requiring formal query language expertise\nfrom the user. Instead, users can express their information needs by simply\nasking their questions in natural language (NL). Datasets used to train KGQA\nmodels that would provide such a service are expensive to construct, both in\nterms of expert and crowdsourced labor. Typically, crowdsourced labor is used\nto improve template-based pseudo-natural questions generated from formal\nqueries. However, the resulting datasets often fall short of representing\ngenuinely natural and fluent language. In the present work, we investigate ways\nto characterize and remedy these shortcomings. We create the IQN-KGQA test\ncollection by sampling questions from existing KGQA datasets and evaluating\nthem with regards to five different aspects of naturalness. Then, the questions\nare rewritten to improve their fluency. Finally, the performance of existing\nKGQA models is compared on the original and rewritten versions of the NL\nquestions. We find that some KGQA systems fare worse when presented with more\nrealistic formulations of NL questions. The IQN-KGQA test collection is a\nresource to help evaluate KGQA systems in a more realistic setting. The\nconstruction of this test collection also sheds light on the challenges of\nconstructing large-scale KGQA datasets with genuinely NL questions.", "published": "2022-05-25 13:32:27", "link": "http://arxiv.org/abs/2205.12768v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Does Moral Code Have a Moral Code? Probing Delphi's Moral Philosophy", "abstract": "In an effort to guarantee that machine learning model outputs conform with\nhuman moral values, recent work has begun exploring the possibility of\nexplicitly training models to learn the difference between right and wrong.\nThis is typically done in a bottom-up fashion, by exposing the model to\ndifferent scenarios, annotated with human moral judgements. One question,\nhowever, is whether the trained models actually learn any consistent,\nhigher-level ethical principles from these datasets -- and if so, what? Here,\nwe probe the Allen AI Delphi model with a set of standardized morality\nquestionnaires, and find that, despite some inconsistencies, Delphi tends to\nmirror the moral principles associated with the demographic groups involved in\nthe annotation process. We question whether this is desirable and discuss how\nwe might move forward with this knowledge.", "published": "2022-05-25 13:37:56", "link": "http://arxiv.org/abs/2205.12771v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Automatic question generation based on sentence structure analysis using\n  machine learning approach", "abstract": "Automatic question generation is one of the most challenging tasks of Natural\nLanguage Processing. It requires \"bidirectional\" language processing: firstly,\nthe system has to understand the input text (Natural Language Understanding)\nand it then has to generate questions also in the form of text (Natural\nLanguage Generation). In this article, we introduce our framework for\ngenerating the factual questions from unstructured text in the English\nlanguage. It uses a combination of traditional linguistic approaches based on\nsentence patterns with several machine learning methods. We firstly obtain\nlexical, syntactic and semantic information from an input text and we then\nconstruct a hierarchical set of patterns for each sentence. The set of features\nis extracted from the patterns and it is then used for automated learning of\nnew transformation rules. Our learning process is totally data-driven because\nthe transformation rules are obtained from a set of initial sentence-question\npairs. The advantages of this approach lie in a simple expansion of new\ntransformation rules which allows us to generate various types of questions and\nalso in the continuous improvement of the system by reinforcement learning. The\nframework also includes a question evaluation module which estimates the\nquality of generated questions. It serves as a filter for selecting the best\nquestions and eliminating incorrect ones or duplicates. We have performed\nseveral experiments to evaluate the correctness of generated questions and we\nhave also compared our system with several state-of-the-art systems. Our\nresults indicate that the quality of generated questions outperforms the\nstate-of-the-art systems and our questions are also comparable to questions\ncreated by humans. We have also created and published an interface with all\ncreated datasets and evaluated questions, so it is possible to follow up on our\nwork.", "published": "2022-05-25 14:35:29", "link": "http://arxiv.org/abs/2205.12811v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding Factual Errors in Summarization: Errors, Summarizers,\n  Datasets, Error Detectors", "abstract": "The propensity of abstractive summarization models to make factual errors has\nbeen studied extensively, including design of metrics to detect factual errors\nand annotation of errors in current systems' outputs. However, the\never-evolving nature of summarization systems, metrics, and annotated\nbenchmarks makes factuality evaluation a moving target, and drawing clear\ncomparisons among metrics has become increasingly difficult. In this work, we\naggregate factuality error annotations from nine existing datasets and stratify\nthem according to the underlying summarization model. We compare performance of\nstate-of-the-art factuality metrics, including recent ChatGPT-based metrics, on\nthis stratified benchmark and show that their performance varies significantly\nacross different types of summarization models. Critically, our analysis shows\nthat much of the recent improvement in the factuality detection space has been\non summaries from older (pre-Transformer) models instead of more relevant\nrecent summarization models. We further perform a finer-grained analysis per\nerror-type and find similar performance variance across error types for\ndifferent factuality metrics. Our results show that no one metric is superior\nin all settings or for all error types, and we provide recommendations for best\npractices given these insights.", "published": "2022-05-25 15:26:48", "link": "http://arxiv.org/abs/2205.12854v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Open-Domain Sign Language Translation Learned from Online Video", "abstract": "Existing work on sign language translation - that is, translation from sign\nlanguage videos into sentences in a written language - has focused mainly on\n(1) data collected in a controlled environment or (2) data in a specific\ndomain, which limits the applicability to real-world settings. In this paper,\nwe introduce OpenASL, a large-scale American Sign Language (ASL) - English\ndataset collected from online video sites (e.g., YouTube). OpenASL contains 288\nhours of ASL videos in multiple domains from over 200 signers and is the\nlargest publicly available ASL translation dataset to date. To tackle the\nchallenges of sign language translation in realistic settings and without\nglosses, we propose a set of techniques including sign search as a pretext task\nfor pre-training and fusion of mouthing and handshape features. The proposed\ntechniques produce consistent and large improvements in translation quality,\nover baseline models based on prior work. Our data and code are publicly\navailable at https://github.com/chevalierNoir/OpenASL", "published": "2022-05-25 15:43:31", "link": "http://arxiv.org/abs/2205.12870v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Reasoning over Logically Interacted Conditions for Question Answering", "abstract": "Some questions have multiple answers that are not equally correct, i.e.\nanswers are different under different conditions. Conditions are used to\ndistinguish answers as well as to provide additional information to support\nthem. In this paper, we study a more challenging task where answers are\nconstrained by a list of conditions that logically interact, which requires\nperforming logical reasoning over the conditions to determine the correctness\nof the answers. Even more challenging, we only provide evidences for a subset\nof the conditions, so some questions may not have deterministic answers. In\nsuch cases, models are asked to find probable answers and identify conditions\nthat need to be satisfied to make the answers correct. We propose a new model,\nTReasoner, for this challenging reasoning task. TReasoner consists of an\nentailment module, a reasoning module, and a generation module (if the answers\nare free-form text spans). TReasoner achieves state-of-the-art performance on\ntwo benchmark conditional QA datasets, outperforming the previous\nstate-of-the-art by 3-10 points.", "published": "2022-05-25 16:41:39", "link": "http://arxiv.org/abs/2205.12898v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NaturalProver: Grounded Mathematical Proof Generation with Language\n  Models", "abstract": "Theorem proving in natural mathematical language - the mixture of symbolic\nand natural language used by humans - plays a central role in mathematical\nadvances and education, and tests aspects of reasoning that are core to\nintelligence. Yet it has remained underexplored with modern generative models.\nWe study large-scale language models on two new generation tasks: suggesting\nthe next step in a mathematical proof, and full proof generation. We develop\nNaturalProver, a language model that generates proofs by conditioning on\nbackground references (e.g. theorems and definitions that are either retrieved\nor human-provided), and optionally enforces their presence with constrained\ndecoding. On theorems from the NaturalProofs benchmark, NaturalProver improves\nthe quality of next-step suggestions and generated proofs over fine-tuned\nGPT-3, according to human evaluations from university-level mathematics\nstudents. NaturalProver is capable of proving some theorems that require short\n(2-6 step) proofs, and providing next-step suggestions that are rated as\ncorrect and useful over 40% of the time, which is to our knowledge the first\ndemonstration of these capabilities using neural language models.", "published": "2022-05-25 17:01:18", "link": "http://arxiv.org/abs/2205.12910v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BiT: Robustly Binarized Multi-distilled Transformer", "abstract": "Modern pre-trained transformers have rapidly advanced the state-of-the-art in\nmachine learning, but have also grown in parameters and computational\ncomplexity, making them increasingly difficult to deploy in\nresource-constrained environments. Binarization of the weights and activations\nof the network can significantly alleviate these issues, however, is\ntechnically challenging from an optimization perspective. In this work, we\nidentify a series of improvements that enables binary transformers at a much\nhigher accuracy than what was possible previously. These include a two-set\nbinarization scheme, a novel elastic binary activation function with learned\nparameters, and a method to quantize a network to its limit by successively\ndistilling higher precision models into lower precision students. These\napproaches allow for the first time, fully binarized transformer models that\nare at a practical level of accuracy, approaching a full-precision BERT\nbaseline on the GLUE language understanding benchmark within as little as 5.9%.\nCode and models are available at: https://github.com/facebookresearch/bit.", "published": "2022-05-25 19:01:54", "link": "http://arxiv.org/abs/2205.13016v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Investigating the Benefits of Free-Form Rationales", "abstract": "Free-form rationales aim to aid model interpretability by supplying the\nbackground knowledge that can help understand model decisions. Crowdsourced\nrationales are provided for commonsense QA instances in popular datasets such\nas CoS-E and ECQA, but their utility remains under-investigated. We present\nhuman studies which show that ECQA rationales indeed provide additional\nbackground information to understand a decision, while over 88% of CoS-E\nrationales do not. Inspired by this finding, we ask: can the additional context\nprovided by free-form rationales benefit models, similar to human users? We\ninvestigate the utility of rationales as an additional source of supervision,\nby varying the quantity and quality of rationales during training. After\ncontrolling for instances where rationales leak the correct answer while not\nproviding additional background knowledge, we find that incorporating only 5%\nof rationales during training can boost model performance by 47.22% for CoS-E\nand 57.14% for ECQA during inference. Moreover, we also show that rationale\nquality matters: compared to crowdsourced rationales, T5-generated rationales\nprovide not only weaker supervision to models, but are also not helpful for\nhumans in aiding model interpretability.", "published": "2022-05-25 11:46:11", "link": "http://arxiv.org/abs/2206.11083v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Lifelong Learning Natural Language Processing Approach for Multilingual\n  Data Classification", "abstract": "The abundance of information in digital media, which in today's world is the\nmain source of knowledge about current events for the masses, makes it possible\nto spread disinformation on a larger scale than ever before. Consequently,\nthere is a need to develop novel fake news detection approaches capable of\nadapting to changing factual contexts and generalizing previously or\nconcurrently acquired knowledge. To deal with this problem, we propose a\nlifelong learning-inspired approach, which allows for fake news detection in\nmultiple languages and the mutual transfer of knowledge acquired in each of\nthem. Both classical feature extractors, such as Term frequency-inverse\ndocument frequency or Latent Dirichlet Allocation, and integrated deep NLP\n(Natural Language Processing) BERT (Bidirectional Encoder Representations from\nTransformers) models paired with MLP (Multilayer Perceptron) classifier, were\nemployed. The results of experiments conducted on two datasets dedicated to the\nfake news classification task (in English and Spanish, respectively), supported\nby statistical analysis, confirmed that utilization of additional languages\ncould improve performance for traditional methods. Also, in some cases\nsupplementing the deep learning method with classical ones can positively\nimpact obtained results. The ability of models to generalize the knowledge\nacquired between the analyzed languages was also observed.", "published": "2022-05-25 10:34:04", "link": "http://arxiv.org/abs/2206.11867v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Question Personalization in an Intelligent Tutoring System", "abstract": "This paper investigates personalization in the field of intelligent tutoring\nsystems (ITS). We hypothesize that personalization in the way questions are\nasked improves student learning outcomes. Previous work on dialogue-based ITS\npersonalization has yet to address question phrasing. We show that generating\nversions of the questions suitable for students at different levels of subject\nproficiency improves student learning gains, using variants written by a domain\nexpert and an experimental A/B test. This insight demonstrates that the\nlinguistic realization of questions in an ITS affects the learning outcomes for\nstudents.", "published": "2022-05-25 15:23:51", "link": "http://arxiv.org/abs/2206.14145v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Non-Programmers Can Label Programs Indirectly via Active Examples: A\n  Case Study with Text-to-SQL", "abstract": "Can non-programmers annotate natural language utterances with complex\nprograms that represent their meaning? We introduce APEL, a framework in which\nnon-programmers select among candidate programs generated by a seed semantic\nparser (e.g., Codex). Since they cannot understand the candidate programs, we\nask them to select indirectly by examining the programs' input-ouput examples.\nFor each utterance, APEL actively searches for a simple input on which the\ncandidate programs tend to produce different outputs. It then asks the\nnon-programmers only to choose the appropriate output, thus allowing us to\ninfer which program is correct and could be used to fine-tune the parser. As a\nfirst case study, we recruited human non-programmers to use APEL to re-annotate\nSPIDER, a text-to-SQL dataset. Our approach achieved the same annotation\naccuracy as the original expert annotators (75%) and exposed many subtle errors\nin the original annotations.", "published": "2022-05-25 00:35:12", "link": "http://arxiv.org/abs/2205.12422v3", "categories": ["cs.CL", "cs.AI", "cs.PL"], "primary_category": "cs.CL"}
{"title": "Generating Natural Language Proofs with Verifier-Guided Search", "abstract": "Reasoning over natural language is a challenging problem in NLP. In this\nwork, we focus on proof generation: Given a hypothesis and a set of supporting\nfacts, the model generates a proof tree indicating how to derive the hypothesis\nfrom supporting facts. Compared to generating the entire proof in one shot,\nstepwise generation can better exploit the compositionality and generalize to\nlonger proofs but has achieved limited success on real-world data. Existing\nstepwise methods struggle to generate proof steps that are both logically valid\nand relevant to the hypothesis. Instead, they tend to hallucinate invalid steps\ngiven the hypothesis. In this paper, we present a novel stepwise method,\nNLProofS (Natural Language Proof Search), which learns to generate relevant\nsteps conditioning on the hypothesis. At the core of our approach, we train an\nindependent verifier to check the validity of the proof steps to prevent\nhallucination. Instead of generating steps greedily, we search for proofs\nmaximizing a global proof score judged by the verifier. NLProofS achieves\nstate-of-the-art performance on EntailmentBank and RuleTaker. Specifically, it\nimproves the correctness of predicted proofs from 27.7% to 33.3% in the\ndistractor setting of EntailmentBank, demonstrating the effectiveness of\nNLProofS in generating challenging human-authored proofs.", "published": "2022-05-25 02:22:30", "link": "http://arxiv.org/abs/2205.12443v3", "categories": ["cs.CL", "cs.LG", "cs.LO"], "primary_category": "cs.CL"}
{"title": "FLEURS: Few-shot Learning Evaluation of Universal Representations of\n  Speech", "abstract": "We introduce FLEURS, the Few-shot Learning Evaluation of Universal\nRepresentations of Speech benchmark. FLEURS is an n-way parallel speech dataset\nin 102 languages built on top of the machine translation FLoRes-101 benchmark,\nwith approximately 12 hours of speech supervision per language. FLEURS can be\nused for a variety of speech tasks, including Automatic Speech Recognition\n(ASR), Speech Language Identification (Speech LangID), Translation and\nRetrieval. In this paper, we provide baselines for the tasks based on\nmultilingual pre-trained models like mSLAM. The goal of FLEURS is to enable\nspeech technology in more languages and catalyze research in low-resource\nspeech understanding.", "published": "2022-05-25 02:29:03", "link": "http://arxiv.org/abs/2205.12446v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Investigating Information Inconsistency in Multilingual Open-Domain\n  Question Answering", "abstract": "Retrieval based open-domain QA systems use retrieved documents and\nanswer-span selection over retrieved documents to find best-answer candidates.\nWe hypothesize that multilingual Question Answering (QA) systems are prone to\ninformation inconsistency when it comes to documents written in different\nlanguages, because these documents tend to provide a model with varying\ninformation about the same topic. To understand the effects of the biased\navailability of information and cultural influence, we analyze the behavior of\nmultilingual open-domain question answering models with a focus on retrieval\nbias. We analyze if different retriever models present different passages given\nthe same question in different languages on TyDi QA and XOR-TyDi QA, two\nmultilingualQA datasets. We speculate that the content differences in documents\nacross languages might reflect cultural divergences and/or social biases.", "published": "2022-05-25 02:58:54", "link": "http://arxiv.org/abs/2205.12456v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving CTC-based ASR Models with Gated Interlayer Collaboration", "abstract": "The CTC-based automatic speech recognition (ASR) models without the external\nlanguage model usually lack the capacity to model conditional dependencies and\ntextual interactions. In this paper, we present a Gated Interlayer\nCollaboration (GIC) mechanism to improve the performance of CTC-based models,\nwhich introduces textual information into the model and thus relaxes the\nconditional independence assumption of CTC-based models. Specifically, we\nconsider the weighted sum of token embeddings as the textual representation for\neach position, where the position-specific weights are the softmax probability\ndistribution constructed via inter-layer auxiliary CTC losses. The textual\nrepresentations are then fused with acoustic features by developing a gate\nunit. Experiments on AISHELL-1, TEDLIUM2, and AIDATATANG corpora show that the\nproposed method outperforms several strong baselines.", "published": "2022-05-25 03:21:27", "link": "http://arxiv.org/abs/2205.12462v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "The Dialog Must Go On: Improving Visual Dialog via Generative\n  Self-Training", "abstract": "Visual dialog (VisDial) is a task of answering a sequence of questions\ngrounded in an image, using the dialog history as context. Prior work has\ntrained the dialog agents solely on VisDial data via supervised learning or\nleveraged pre-training on related vision-and-language datasets. This paper\npresents a semi-supervised learning approach for visually-grounded dialog,\ncalled Generative Self-Training (GST), to leverage unlabeled images on the Web.\nSpecifically, GST first retrieves in-domain images through out-of-distribution\ndetection and generates synthetic dialogs regarding the images via multimodal\nconditional text generation. GST then trains a dialog agent on the synthetic\nand the original VisDial data. As a result, GST scales the amount of training\ndata up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For\nrobust training of the synthetic dialogs, we also propose perplexity-based data\nselection and multimodal consistency regularization. Evaluation on VisDial v1.0\nand v0.9 datasets shows that GST achieves new state-of-the-art results on both\ndatasets. We further observe the robustness of GST against both visual and\ntextual adversarial attacks. Finally, GST yields strong performance gains in\nthe low-data regime. Code is available at\nhttps://github.com/gicheonkang/gst-visdial.", "published": "2022-05-25 05:40:00", "link": "http://arxiv.org/abs/2205.12502v2", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation", "abstract": "Direct speech-to-speech translation (S2ST) with discrete units leverages\nrecent progress in speech representation learning. Specifically, a sequence of\ndiscrete representations derived in a self-supervised manner are predicted from\nthe model and passed to a vocoder for speech reconstruction, while still facing\nthe following challenges: 1) Acoustic multimodality: the discrete units derived\nfrom speech with same content could be indeterministic due to the acoustic\nproperty (e.g., rhythm, pitch, and energy), which causes deterioration of\ntranslation accuracy; 2) high latency: current S2ST systems utilize\nautoregressive models which predict each unit conditioned on the sequence\npreviously generated, failing to take full advantage of parallelism. In this\nwork, we propose TranSpeech, a speech-to-speech translation model with\nbilateral perturbation. To alleviate the acoustic multimodal problem, we\npropose bilateral perturbation (BiP), which consists of the style normalization\nand information enhancement stages, to learn only the linguistic information\nfrom speech samples and generate more deterministic representations. With\nreduced multimodality, we step forward and become the first to establish a\nnon-autoregressive S2ST technique, which repeatedly masks and predicts unit\nchoices and produces high-accuracy results in just a few cycles. Experimental\nresults on three language pairs demonstrate that BiP yields an improvement of\n2.9 BLEU on average compared with a baseline textless S2ST model. Moreover, our\nparallel decoding shows a significant reduction of inference latency, enabling\nspeedup up to 21.4x than autoregressive technique. Audio samples are available\nat \\url{https://TranSpeech.github.io/}", "published": "2022-05-25 06:34:14", "link": "http://arxiv.org/abs/2205.12523v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Is a Question Decomposition Unit All We Need?", "abstract": "Large Language Models (LMs) have achieved state-of-the-art performance on\nmany Natural Language Processing (NLP) benchmarks. With the growing number of\nnew benchmarks, we build bigger and more complex LMs. However, building new LMs\nmay not be an ideal option owing to the cost, time and environmental impact\nassociated with it. We explore an alternative route: can we modify data by\nexpressing it in terms of the model's strengths, so that a question becomes\neasier for models to answer? We investigate if humans can decompose a hard\nquestion into a set of simpler questions that are relatively easier for models\nto solve. We analyze a range of datasets involving various forms of reasoning\nand find that it is indeed possible to significantly improve model performance\n(24% for GPT3 and 29% for RoBERTa-SQuAD along with a symbolic calculator) via\ndecomposition. Our approach provides a viable option to involve people in NLP\nresearch in a meaningful way. Our findings indicate that Human-in-the-loop\nQuestion Decomposition (HQD) can potentially provide an alternate path to\nbuilding large LMs. Code and data is available at\nhttps://github.com/Pruthvi98/QuestionDecomposition", "published": "2022-05-25 07:24:09", "link": "http://arxiv.org/abs/2205.12538v2", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RobustLR: Evaluating Robustness to Logical Perturbation in Deductive\n  Reasoning", "abstract": "Transformers have been shown to be able to perform deductive reasoning on a\nlogical rulebase containing rules and statements written in English natural\nlanguage. While the progress is promising, it is currently unclear if these\nmodels indeed perform logical reasoning by understanding the underlying logical\nsemantics in the language. To this end, we propose RobustLR, a suite of\nevaluation datasets that evaluate the robustness of these models to minimal\nlogical edits in rulebases and some standard logical equivalence conditions. In\nour experiments with RoBERTa and T5, we find that the models trained in prior\nworks do not perform consistently on the different perturbations in RobustLR,\nthus showing that the models are not robust to the proposed logical\nperturbations. Further, we find that the models find it especially hard to\nlearn logical negation and disjunction operators. Overall, using our evaluation\nsets, we demonstrate some shortcomings of the deductive reasoning-based\nlanguage models, which can eventually help towards designing better models for\nlogical reasoning over natural language. All the datasets and code base have\nbeen made publicly available.", "published": "2022-05-25 09:23:50", "link": "http://arxiv.org/abs/2205.12598v2", "categories": ["cs.CL", "cs.LG", "cs.LO"], "primary_category": "cs.CL"}
{"title": "DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally\n  Spreading Out Disinformation", "abstract": "Disinformation has become a serious problem on social media. In particular,\ngiven their short format, visual attraction, and humorous nature, memes have a\nsignificant advantage in dissemination among online communities, making them an\neffective vehicle for the spread of disinformation. We present DisinfoMeme to\nhelp detect disinformation memes. The dataset contains memes mined from Reddit\ncovering three current topics: the COVID-19 pandemic, the Black Lives Matter\nmovement, and veganism/vegetarianism. The dataset poses multiple unique\nchallenges: limited data and label imbalance, reliance on external knowledge,\nmultimodal reasoning, layout dependency, and noise from OCR. We test multiple\nwidely-used unimodal and multimodal models on this dataset. The experiments\nshow that the room for improvement is still huge for current models.", "published": "2022-05-25 09:54:59", "link": "http://arxiv.org/abs/2205.12617v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Are Large Pre-Trained Language Models Leaking Your Personal Information?", "abstract": "Are Large Pre-Trained Language Models Leaking Your Personal Information? In\nthis paper, we analyze whether Pre-Trained Language Models (PLMs) are prone to\nleaking personal information. Specifically, we query PLMs for email addresses\nwith contexts of the email address or prompts containing the owner's name. We\nfind that PLMs do leak personal information due to memorization. However, since\nthe models are weak at association, the risk of specific personal information\nbeing extracted by attackers is low. We hope this work could help the community\nto better understand the privacy risk of PLMs and bring new insights to make\nPLMs safe.", "published": "2022-05-25 10:08:45", "link": "http://arxiv.org/abs/2205.12628v2", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Ground-Truth Labels Matter: A Deeper Look into Input-Label\n  Demonstrations", "abstract": "Despite recent explosion of interests in in-context learning, the underlying\nmechanism and the precise impact of the quality of demonstrations remain\nelusive. Intuitively, ground-truth labels should have as much impact in\nin-context learning (ICL) as supervised learning, but recent work reported that\nthe input-label correspondence is significantly less important than previously\nthought. Intrigued by this counter-intuitive observation, we re-examine the\nimportance of ground-truth labels in in-context learning. With the introduction\nof two novel metrics, namely Label-Correctness Sensitivity and Ground-truth\nLabel Effect Ratio (GLER), we were able to conduct quantifiable analysis on the\nimpact of ground-truth label demonstrations. Through extensive analyses, we\nfind that the correct input-label mappings can have varying impacts on the\ndownstream in-context learning performances, depending on the experimental\nconfiguration. Through additional studies, we identify key components, such as\nthe verbosity of prompt templates and the language model size, as the\ncontrolling factor to achieve more noise-resilient ICL.", "published": "2022-05-25 11:45:14", "link": "http://arxiv.org/abs/2205.12685v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Train Flat, Then Compress: Sharpness-Aware Minimization Learns More\n  Compressible Models", "abstract": "Model compression by way of parameter pruning, quantization, or distillation\nhas recently gained popularity as an approach for reducing the computational\nrequirements of modern deep neural network models for NLP. Inspired by prior\nworks suggesting a connection between simpler, more generalizable models and\nthose that lie within wider loss basins, we hypothesize that optimizing for\nflat minima should lead to simpler parameterizations and thus more compressible\nmodels. We propose to combine sharpness-aware minimization (SAM) with various\ntask-specific model compression methods, including iterative magnitude pruning\n(IMP), structured pruning with a distillation objective, and post-training\ndynamic quantization. Empirically, we show that optimizing for flatter minima\nconsistently leads to greater compressibility of parameters compared to vanilla\nAdam when fine-tuning BERT models, with little to no loss in accuracy on the\nGLUE text classification and SQuAD question answering benchmarks. Moreover, SAM\nfinds superior winning tickets during IMP that 1) are amenable to vanilla Adam\noptimization, and 2) transfer more effectively across tasks.", "published": "2022-05-25 11:54:37", "link": "http://arxiv.org/abs/2205.12694v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "On Building Spoken Language Understanding Systems for Low Resourced\n  Languages", "abstract": "Spoken dialog systems are slowly becoming and integral part of the human\nexperience due to their various advantages over textual interfaces. Spoken\nlanguage understanding (SLU) systems are fundamental building blocks of spoken\ndialog systems. But creating SLU systems for low resourced languages is still a\nchallenge. In a large number of low resourced language, we don't have access to\nenough data to build automatic speech recognition (ASR) technologies, which are\nfundamental to any SLU system. Also, ASR based SLU systems do not generalize to\nunwritten languages. In this paper, we present a series of experiments to\nexplore extremely low-resourced settings where we perform intent classification\nwith systems trained on as low as one data-point per intent and with only one\nspeaker in the dataset. We also work in a low-resourced setting where we do not\nuse language specific ASR systems to transcribe input speech, which compounds\nthe challenge of building SLU systems to simulate a true low-resourced setting.\nWe test our system on Belgian Dutch (Flemish) and English and find that using\nphonetic transcriptions to make intent classification systems in such\nlow-resourced setting performs significantly better than using speech features.\nSpecifically, when using a phonetic transcription based system over a feature\nbased system, we see average improvements of 12.37% and 13.08% for binary and\nfour-class classification problems respectively, when averaged over 49\ndifferent experimental settings.", "published": "2022-05-25 14:44:51", "link": "http://arxiv.org/abs/2205.12818v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "On the solvability of weakly linear systems of fuzzy relation equations", "abstract": "Systems of fuzzy relation equations and inequalities in which an unknown\nfuzzy relation is on the one side of the equation or inequality are linear\nsystems. They are the most studied ones, and a vast literature on linear\nsystems focuses on finding solutions and solvability criteria for such systems.\nThe situation is quite different with the so-called weakly linear systems, in\nwhich an unknown fuzzy relation is on both sides of the equation or inequality.\nPrecisely, the scholars have only given the characterization of the set of\nexact solutions to such systems. This paper describes the set of fuzzy\nrelations that solve weakly linear systems to a certain degree and provides\nways to compute them. We pay special attention to developing the algorithms for\ncomputing fuzzy preorders and fuzzy equivalences that are solutions to some\nextent to weakly linear systems. We establish additional properties for the set\nof such approximate solutions over some particular types of complete residuated\nlattices. We demonstrate the advantage of this approach via many examples that\narise from the problem of aggregation of fuzzy networks.", "published": "2022-05-25 16:59:48", "link": "http://arxiv.org/abs/2205.15292v1", "categories": ["cs.AI", "cs.CL", "cs.LO"], "primary_category": "cs.AI"}
{"title": "Predicting Corporate Risk by Jointly Modeling Company Networks and\n  Dialogues in Earnings Conference Calls", "abstract": "Earnings conference calls are significant information events for volatility\nforecasting, which is essential for financial risk management and asset\npricing. Although some recent volatility forecasting models have utilized the\ntextual content of conference calls, the dialogue structures of conference\ncalls and company relationships are almost ignored in extant literature. To\nbridge this gap, we propose a new model called Temporal Virtual Graph Neural\nNetwork (TVGNN) for volatility forecasting by jointly modeling conference call\ndialogues and company networks. Our model differs from existing models in\nseveral important ways. First, we propose to exploit more dialogue structures\nby encoding position, utterance, speaker role, and Q\\&A segments. Second, we\npropose to encode the market states for volatility forecasting by extending the\nGated Recurrent Units (GRU). Third, we propose a new method for constructing\ntemporal company networks in which the messages can only flow from temporally\npreceding to successive nodes, and extend the Graph Attention Networks (GAT)\nfor modeling company relationships. We collect conference call transcripts of\nS\\&P500 companies from 2008 to 2019, and construct a dataset of conference call\ndialogues with additional information on dialogue structures and company\nnetworks. Empirical results on our dataset demonstrate the superiority of our\nmodel over competitive baselines for volatility forecasting. We also conduct\nsupplementary analyses to examine the effectiveness of our model's key\ncomponents and interpretability.", "published": "2022-05-25 17:43:59", "link": "http://arxiv.org/abs/2206.06174v3", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mutual Information Divergence: A Unified Metric for Multimodal\n  Generative Models", "abstract": "Text-to-image generation and image captioning are recently emerged as a new\nexperimental paradigm to assess machine intelligence. They predict continuous\nquantity accompanied by their sampling techniques in the generation, making\nevaluation complicated and intractable to get marginal distributions. Based on\na recent trend that multimodal generative evaluations exploit a\nvison-and-language pre-trained model, we propose the negative Gaussian\ncross-mutual information using the CLIP features as a unified metric, coined by\nMutual Information Divergence (MID). To validate, we extensively compare it\nwith competing metrics using carefully-generated or human-annotated judgments\nin text-to-image generation and image captioning tasks. The proposed MID\nsignificantly outperforms the competitive methods by having consistency across\nbenchmarks, sample parsimony, and robustness toward the exploited CLIP model.\nWe look forward to seeing the underrepresented implications of the Gaussian\ncross-mutual information in multimodal representation learning and the future\nworks based on this novel proposition.", "published": "2022-05-25 09:34:37", "link": "http://arxiv.org/abs/2205.13445v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.CV"}
{"title": "Synthesis of Soundfields through Irregular Loudspeaker Arrays Based on\n  Convolutional Neural Networks", "abstract": "Most soundfield synthesis approaches deal with extensive and regular\nloudspeaker arrays, which are often not suitable for home audio systems, due to\nphysical space constraints. In this article we propose a technique for\nsoundfield synthesis through more easily deployable irregular loudspeaker\narrays, i.e. where the spacing between loudspeakers is not constant, based on\ndeep learning. The input are the driving signals obtained through a plane wave\ndecomposition-based technique. While the considered driving signals are able to\ncorrectly reproduce the soundfield with a regular array, they show degraded\nperformances when using irregular setups. Through a complex-valued\nConvolutional Neural Network (CNN) we modify the driving signals in order to\ncompensate the errors in the reproduction of the desired soundfield. Since no\nground-truth driving signals are available for the compensated ones, we train\nthe model by calculating the loss between the desired soundfield at a number of\ncontrol points and the one obtained through the driving signals estimated by\nthe network. Numerical results show better reproduction accuracy with respect\nto the plane wave decomposition-based technique, pressure-matching approach and\nto linear optimizers for driving signal compensation.", "published": "2022-05-25 15:43:47", "link": "http://arxiv.org/abs/2205.12872v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Audio Data Augmentation for Acoustic-to-articulatory Speech Inversion\n  using Bidirectional Gated RNNs", "abstract": "Data augmentation has proven to be a promising prospect in improving the\nperformance of deep learning models by adding variability to training data. In\nprevious work with developing a noise robust acoustic-to-articulatory speech\ninversion system, we have shown the importance of noise augmentation to improve\nthe performance of speech inversion in noisy speech. In this work, we compare\nand contrast different ways of doing data augmentation and show how this\ntechnique improves the performance of articulatory speech inversion not only on\nnoisy speech, but also on clean speech data. We also propose a Bidirectional\nGated Recurrent Neural Network as the speech inversion system instead of the\npreviously used feed forward neural network. The inversion system uses\nmel-frequency cepstral coefficients (MFCCs) as the input acoustic features and\nsix vocal tract-variables (TVs) as the output articulatory features. The\nPerformance of the system was measured by computing the correlation between\nestimated and actual TVs on the U. Wisc. X-ray Microbeam database. The proposed\nspeech inversion system shows a 5% relative improvement in correlation over the\nbaseline noise robust system for clean speech data. The pre-trained model, when\nadapted to each unseen speaker in the test set, improves the average\ncorrelation by another 6%.", "published": "2022-05-25 23:57:15", "link": "http://arxiv.org/abs/2205.13086v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "An Investigation on Applying Acoustic Feature Conversion to ASR of Adult\n  and Child Speech", "abstract": "The performance of child speech recognition is generally less satisfactory\ncompared to adult speech due to limited amount of training data. Significant\nperformance degradation is expected when applying an automatic speech\nrecognition (ASR) system trained on adult speech to child speech directly, as a\nresult of domain mismatch. The present study is focused on adult-to-child\nacoustic feature conversion to alleviate this mismatch. Different acoustic\nfeature conversion approaches, including deep neural network based and signal\nprocessing based, are investigated and compared under a fair experimental\nsetting, in which converted acoustic features from the same amount of labeled\nadult speech are used to train the ASR models from scratch. Experimental\nresults reveal that not all of the conversion methods lead to ASR performance\ngain. Specifically, as a classic unsupervised domain adaptation method, the\nstatistic matching does not show an effectiveness. A disentanglement-based\nauto-encoder (DAE) conversion framework is found to be useful and the approach\nof F0 normalization achieves the best performance. It is noted that the F0\ndistribution of converted features is an important attribute to reflect the\nconversion quality, while utilizing an adult-child deep classification model to\nmake judgment is shown to be inappropriate.", "published": "2022-05-25 04:00:18", "link": "http://arxiv.org/abs/2205.12477v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Semantic-preserved Communication System for Highly Efficient Speech\n  Transmission", "abstract": "Deep learning (DL) based semantic communication methods have been explored\nfor the efficient transmission of images, text, and speech in recent years. In\ncontrast to traditional wireless communication methods that focus on the\ntransmission of abstract symbols, semantic communication approaches attempt to\nachieve better transmission efficiency by only sending the semantic-related\ninformation of the source data. In this paper, we consider semantic-oriented\nspeech transmission which transmits only the semantic-relevant information over\nthe channel for the speech recognition task, and a compact additional set of\nsemantic-irrelevant information for the speech reconstruction task. We propose\na novel end-to-end DL-based transceiver which extracts and encodes the semantic\ninformation from the input speech spectrums at the transmitter and outputs the\ncorresponding transcriptions from the decoded semantic information at the\nreceiver. For the speech to speech transmission, we further include a CTC\nalignment module that extracts a small number of additional semantic-irrelevant\nbut speech-related information for the better reconstruction of the original\nspeech signals at the receiver. The simulation results confirm that our\nproposed method outperforms current methods in terms of the accuracy of the\npredicted text for the speech to text transmission and the quality of the\nrecovered speech signals for the speech to speech transmission, and\nsignificantly improves transmission efficiency. More specifically, the proposed\nmethod only sends 16% of the amount of the transmitted symbols required by the\nexisting methods while achieving about 10% reduction in WER for the speech to\ntext transmission. For the speech to speech transmission, it results in an even\nmore remarkable improvement in terms of transmission efficiency with only 0.2%\nof the amount of the transmitted symbols required by the existing method.", "published": "2022-05-25 12:38:26", "link": "http://arxiv.org/abs/2205.12727v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Heterogeneous Reservoir Computing Models for Persian Speech Recognition", "abstract": "Over the last decade, deep-learning methods have been gradually incorporated\ninto conventional automatic speech recognition (ASR) frameworks to create\nacoustic, pronunciation, and language models. Although it led to significant\nimprovements in ASRs' recognition accuracy, due to their hard constraints\nrelated to hardware requirements (e.g., computing power and memory usage), it\nis unclear if such approaches are the most computationally- and\nenergy-efficient options for embedded ASR applications. Reservoir computing\n(RC) models (e.g., echo state networks (ESNs) and liquid state machines\n(LSMs)), on the other hand, have been proven inexpensive to train, have vastly\nfewer parameters, and are compatible with emergent hardware technologies.\nHowever, their performance in speech processing tasks is relatively inferior to\nthat of the deep-learning-based models. To enhance the accuracy of the RC in\nASR applications, we propose heterogeneous single and multi-layer ESNs to\ncreate non-linear transformations of the inputs that capture temporal context\nat different scales. To test our models, we performed a speech recognition task\non the Farsdat Persian dataset. Since, to the best of our knowledge, standard\nRC has not yet been employed to conduct any Persian ASR tasks, we also trained\nconventional single-layer and deep ESNs to provide baselines for comparison.\nBesides, we compared the RC performance with a standard long-short-term memory\n(LSTM) model. Heterogeneous RC models (1) show improved performance to the\nstandard RC models; (2) perform on par in terms of recognition accuracy with\nthe LSTM, and (3) reduce the training time considerably.", "published": "2022-05-25 09:15:15", "link": "http://arxiv.org/abs/2205.12594v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Urban Rhapsody: Large-scale exploration of urban soundscapes", "abstract": "Noise is one of the primary quality-of-life issues in urban environments. In\naddition to annoyance, noise negatively impacts public health and educational\nperformance. While low-cost sensors can be deployed to monitor ambient noise\nlevels at high temporal resolutions, the amount of data they produce and the\ncomplexity of these data pose significant analytical challenges. One way to\naddress these challenges is through machine listening techniques, which are\nused to extract features in attempts to classify the source of noise and\nunderstand temporal patterns of a city's noise situation. However, the\noverwhelming number of noise sources in the urban environment and the scarcity\nof labeled data makes it nearly impossible to create classification models with\nlarge enough vocabularies that capture the true dynamism of urban soundscapes\nIn this paper, we first identify a set of requirements in the yet unexplored\ndomain of urban soundscape exploration. To satisfy the requirements and tackle\nthe identified challenges, we propose Urban Rhapsody, a framework that combines\nstate-of-the-art audio representation, machine learning, and visual analytics\nto allow users to interactively create classification models, understand noise\npatterns of a city, and quickly retrieve and label audio excerpts in order to\ncreate a large high-precision annotated database of urban sound recordings. We\ndemonstrate the tool's utility through case studies performed by domain experts\nusing data generated over the five-year deployment of a one-of-a-kind sensor\nnetwork in New York City.", "published": "2022-05-25 22:02:36", "link": "http://arxiv.org/abs/2205.13064v1", "categories": ["cs.CY", "cs.HC", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CY"}
