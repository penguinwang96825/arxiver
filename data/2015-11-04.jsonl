{"title": "Transforming Wikipedia into an Ontology-based Information Retrieval\n  Search Engine for Local Experts using a Third-Party Taxonomy", "abstract": "Wikipedia is widely used for finding general information about a wide variety\nof topics. Its vocation is not to provide local information. For example, it\nprovides plot, cast, and production information about a given movie, but not\nshowing times in your local movie theatre. Here we describe how we can connect\nlocal information to Wikipedia, without altering its content. The case study we\npresent involves finding local scientific experts. Using a third-party\ntaxonomy, independent from Wikipedia's category hierarchy, we index information\nconnected to our local experts, present in their activity reports, and we\nre-index Wikipedia content using the same taxonomy. The connections between\nWikipedia pages and local expert reports are stored in a relational database,\naccessible through as public SPARQL endpoint. A Wikipedia gadget (or plugin)\nactivated by the interested user, accesses the endpoint as each Wikipedia page\nis accessed. An additional tab on the Wikipedia page allows the user to open up\na list of teams of local experts associated with the subject matter in the\nWikipedia page. The technique, though presented here as a way to identify local\nexperts, is generic, in that any third party taxonomy, can be used in this to\nconnect Wikipedia to any non-Wikipedia data source.", "published": "2015-11-04 09:41:31", "link": "http://arxiv.org/abs/1511.01259v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Semi-supervised Sequence Learning", "abstract": "We present two approaches that use unlabeled data to improve sequence\nlearning with recurrent networks. The first approach is to predict what comes\nnext in a sequence, which is a conventional language model in natural language\nprocessing. The second approach is to use a sequence autoencoder, which reads\nthe input sequence into a vector and predicts the input sequence again. These\ntwo algorithms can be used as a \"pretraining\" step for a later supervised\nsequence learning algorithm. In other words, the parameters obtained from the\nunsupervised step can be used as a starting point for other supervised training\nmodels. In our experiments, we find that long short term memory recurrent\nnetworks after being pretrained with the two approaches are more stable and\ngeneralize better. With pretraining, we are able to train long short term\nmemory recurrent networks up to a few hundred timesteps, thereby achieving\nstrong performance in many text classification tasks, such as IMDB, DBpedia and\n20 Newsgroups.", "published": "2015-11-04 18:48:36", "link": "http://arxiv.org/abs/1511.01432v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Approximation of the truncated Zeta distribution and Zipf's law", "abstract": "Zipf's law appears in many application areas but does not have a closed form\nexpression, which may make its use cumbersome. Since it coincides with the\ntruncated version of the Zeta distribution, in this paper we propose three\napproximate closed form expressions for the truncated Zeta distribution, which\nmay be employed for Zipf's law as well. The three approximations are based on\nthe replacement of the sum occurring in Zipf's law with an integral, and are\nnamed respectively the integral approximation, the average integral\napproximation, and the trapezoidal approximation. While the first one is shown\nto be of little use, the trapezoidal approximation exhibits an error which is\ntypically lower than 1\\%, but is as low as 0.1\\% for the range of values of the\nZipf parameter below 1.", "published": "2015-11-04 19:30:27", "link": "http://arxiv.org/abs/1511.01480v1", "categories": ["stat.AP", "cs.CL", "cs.SI"], "primary_category": "stat.AP"}
{"title": "Mining Local Gazetteers of Literary Chinese with CRF and Pattern based\n  Methods for Biographical Information in Chinese History", "abstract": "Person names and location names are essential building blocks for identifying\nevents and social networks in historical documents that were written in\nliterary Chinese. We take the lead to explore the research on algorithmically\nrecognizing named entities in literary Chinese for historical studies with\nlanguage-model based and conditional-random-field based methods, and extend our\nwork to mining the document structures in historical documents. Practical\nevaluations were conducted with texts that were extracted from more than 220\nvolumes of local gazetteers (Difangzhi). Difangzhi is a huge and the single\nmost important collection that contains information about officers who served\nin local government in Chinese history. Our methods performed very well on\nthese realistic tests. Thousands of names and addresses were identified from\nthe texts. A good portion of the extracted names match the biographical\ninformation currently recorded in the China Biographical Database (CBDB) of\nHarvard University, and many others can be verified by historians and will\nbecome as new additions to CBDB.", "published": "2015-11-04 23:39:46", "link": "http://arxiv.org/abs/1511.01556v1", "categories": ["cs.CL", "cs.DL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
