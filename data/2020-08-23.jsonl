{"title": "Predicting Helpfulness of Online Reviews", "abstract": "E-commerce dominates a large part of the world's economy with many websites\ndedicated to online selling products. The vast majority of e-commerce websites\nprovide their customers with the ability to express their opinions about the\nproducts/services they purchase. These feedback in the form of reviews\nrepresent a rich source of information about the users' experiences and level\nof satisfaction, which is of great benefit to both the producer and the\nconsumer. However, not all of these reviews are helpful/useful. The traditional\nway of determining the helpfulness of a review is through the feedback from\nhuman users. However, such a method does not necessarily cover all reviews.\nMoreover, it has many issues like bias, high cost, etc. Thus, there is a need\nto automate this process. This paper presents a set of machine learning (ML)\nmodels to predict the helpfulness online reviews. Mainly, three approaches are\nused: a supervised learning approach (using ML as well as deep learning (DL)\nmodels), a semi-supervised approach (that combines DL models with word\nembeddings), and pre-trained word embedding models that uses transfer learning\n(TL). The latter two approaches are among the unique aspects of this paper as\nthey follow the recent trend of utilizing unlabeled text. The results show that\nthe proposed DL approaches have superiority over the traditional existing ones.\nMoreover, the semi-supervised has a remarkable performance compared with the\nother ones.", "published": "2020-08-23 23:19:17", "link": "http://arxiv.org/abs/2008.10129v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An automated pipeline for the discovery of conspiracy and conspiracy\n  theory narrative frameworks: Bridgegate, Pizzagate and storytelling on the\n  web", "abstract": "Although a great deal of attention has been paid to how conspiracy theories\ncirculate on social media and their factual counterpart conspiracies, there has\nbeen little computational work done on describing their narrative structures.\nWe present an automated pipeline for the discovery and description of the\ngenerative narrative frameworks of conspiracy theories on social media, and\nactual conspiracies reported in the news media. We base this work on two\nseparate repositories of posts and news articles describing the well-known\nconspiracy theory Pizzagate from 2016, and the New Jersey conspiracy Bridgegate\nfrom 2013. We formulate a graphical generative machine learning model where\nnodes represent actors/actants, and multi-edges and self-loops among nodes\ncapture context-specific relationships. Posts and news items are viewed as\nsamples of subgraphs of the hidden narrative network. The problem of\nreconstructing the underlying structure is posed as a latent model estimation\nproblem. We automatically extract and aggregate the actants and their\nrelationships from the posts and articles. We capture context specific actants\nand interactant relationships by developing a system of supernodes and\nsubnodes. We use these to construct a network, which constitutes the underlying\nnarrative framework. We show how the Pizzagate framework relies on the\nconspiracy theorists' interpretation of \"hidden knowledge\" to link otherwise\nunlinked domains of human interaction, and hypothesize that this multi-domain\nfocus is an important feature of conspiracy theories. While Pizzagate relies on\nthe alignment of multiple domains, Bridgegate remains firmly rooted in the\nsingle domain of New Jersey politics. We hypothesize that the narrative\nframework of a conspiracy theory might stabilize quickly in contrast to the\nnarrative framework of an actual one, which may develop more slowly as\nrevelations come to light.", "published": "2020-08-23 05:14:38", "link": "http://arxiv.org/abs/2008.09961v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Emerging App Issue Identification via Online Joint Sentiment-Topic\n  Tracing", "abstract": "Millions of mobile apps are available in app stores, such as Apple's App\nStore and Google Play. For a mobile app, it would be increasingly challenging\nto stand out from the enormous competitors and become prevalent among users.\nGood user experience and well-designed functionalities are the keys to a\nsuccessful app. To achieve this, popular apps usually schedule their updates\nfrequently. If we can capture the critical app issues faced by users in a\ntimely and accurate manner, developers can make timely updates, and good user\nexperience can be ensured. There exist prior studies on analyzing reviews for\ndetecting emerging app issues. These studies are usually based on topic\nmodeling or clustering techniques. However, the short-length characteristics\nand sentiment of user reviews have not been considered. In this paper, we\npropose a novel emerging issue detection approach named MERIT to take into\nconsideration the two aforementioned characteristics. Specifically, we propose\nan Adaptive Online Biterm Sentiment-Topic (AOBST) model for jointly modeling\ntopics and corresponding sentiments that takes into consideration app versions.\nBased on the AOBST model, we infer the topics negatively reflected in user\nreviews for one app version, and automatically interpret the meaning of the\ntopics with most relevant phrases and sentences. Experiments on popular apps\nfrom Google Play and Apple's App Store demonstrate the effectiveness of MERIT\nin identifying emerging app issues, improving the state-of-the-art method by\n22.3% in terms of F1-score. In terms of efficiency, MERIT can return results\nwithin acceptable time.", "published": "2020-08-23 06:34:05", "link": "http://arxiv.org/abs/2008.09976v1", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Deep Bayes Factor Scoring for Authorship Verification", "abstract": "The PAN 2020 authorship verification (AV) challenge focuses on a\ncross-topic/closed-set AV task over a collection of fanfiction texts.\nFanfiction is a fan-written extension of a storyline in which a so-called\nfandom topic describes the principal subject of the document. The data provided\nin the PAN 2020 AV task is quite challenging because authors of texts across\nmultiple/different fandom topics are included. In this work, we present a\nhierarchical fusion of two well-known approaches into a single end-to-end\nlearning procedure: A deep metric learning framework at the bottom aims to\nlearn a pseudo-metric that maps a document of variable length onto a\nfixed-sized feature vector. At the top, we incorporate a probabilistic layer to\nperform Bayes factor scoring in the learned metric space. We also provide text\npreprocessing strategies to deal with the cross-topic issue.", "published": "2020-08-23 21:00:33", "link": "http://arxiv.org/abs/2008.10105v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Variational Inference-Based Dropout in Recurrent Neural Networks for\n  Slot Filling in Spoken Language Understanding", "abstract": "This paper proposes to generalize the variational recurrent neural network\n(RNN) with variational inference (VI)-based dropout regularization employed for\nthe long short-term memory (LSTM) cells to more advanced RNN architectures like\ngated recurrent unit (GRU) and bi-directional LSTM/GRU. The new variational\nRNNs are employed for slot filling, which is an intriguing but challenging task\nin spoken language understanding. The experiments on the ATIS dataset suggest\nthat the variational RNNs with the VI-based dropout regularization can\nsignificantly improve the naive dropout regularization RNNs-based baseline\nsystems in terms of F-measure. Particularly, the variational RNN with\nbi-directional LSTM/GRU obtains the best F-measure score.", "published": "2020-08-23 22:05:54", "link": "http://arxiv.org/abs/2009.01003v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Earnings Call and Stock Price Movement", "abstract": "Earnings calls are hosted by management of public companies to discuss the\ncompany's financial performance with analysts and investors. Information\ndisclosed during an earnings call is an essential source of data for analysts\nand investors to make investment decisions. Thus, we leverage earnings call\ntranscripts to predict future stock price dynamics. We propose to model the\nlanguage in transcripts using a deep learning framework, where an attention\nmechanism is applied to encode the text data into vectors for the\ndiscriminative network classifier to predict stock price movements. Our\nempirical experiments show that the proposed model is superior to the\ntraditional machine learning baselines and earnings call information can boost\nthe stock price prediction performance.", "published": "2020-08-23 20:38:14", "link": "http://arxiv.org/abs/2009.01317v1", "categories": ["q-fin.ST", "cs.CE", "cs.CL", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "Quantum Language Model with Entanglement Embedding for Question\n  Answering", "abstract": "Quantum Language Models (QLMs) in which words are modelled as quantum\nsuperposition of sememes have demonstrated a high level of model transparency\nand good post-hoc interpretability. Nevertheless, in the current literature\nword sequences are basically modelled as a classical mixture of word states,\nwhich cannot fully exploit the potential of a quantum probabilistic\ndescription. A full quantum model is yet to be developed to explicitly capture\nthe non-classical correlations within the word sequences. We propose a neural\nnetwork model with a novel Entanglement Embedding (EE) module, whose function\nis to transform the word sequences into entangled pure states of many-body\nquantum systems. Strong quantum entanglement, which is the central concept of\nquantum information and an indication of parallelized correlations among the\nwords, is observed within the word sequences. Numerical experiments show that\nthe proposed QLM with EE (QLM-EE) achieves superior performance compared with\nthe classical deep neural network models and other QLMs on Question Answering\n(QA) datasets. In addition, the post-hoc interpretability of the model can be\nimproved by quantizing the degree of entanglement among the words.", "published": "2020-08-23 02:34:26", "link": "http://arxiv.org/abs/2008.09943v3", "categories": ["cs.CL", "cs.AI", "quant-ph"], "primary_category": "cs.CL"}
{"title": "COVID-19 Pandemic: Identifying Key Issues using Social Media and Natural\n  Language Processing", "abstract": "The COVID-19 pandemic has affected people's lives in many ways. Social media\ndata can reveal public perceptions and experience with respect to the pandemic,\nand also reveal factors that hamper or support efforts to curb global spread of\nthe disease. In this paper, we analyzed COVID-19-related comments collected\nfrom six social media platforms using Natural Language Processing (NLP)\ntechniques. We identified relevant opinionated keyphrases and their respective\nsentiment polarity (negative or positive) from over 1 million randomly selected\ncomments, and then categorized them into broader themes using thematic\nanalysis. Our results uncover 34 negative themes out of which 17 are economic,\nsocio-political, educational, and political issues. 20 positive themes were\nalso identified. We discuss the negative issues and suggest interventions to\ntackle them based on the positive themes and research evidence.", "published": "2020-08-23 12:05:12", "link": "http://arxiv.org/abs/2008.10022v1", "categories": ["cs.CL", "cs.CY", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Cross-Cultural Polarity and Emotion Detection Using Sentiment Analysis\n  and Deep Learning -- a Case Study on COVID-19", "abstract": "How different cultures react and respond given a crisis is predominant in a\nsociety's norms and political will to combat the situation. Often the decisions\nmade are necessitated by events, social pressure, or the need of the hour,\nwhich may not represent the will of the nation. While some are pleased with it,\nothers might show resentment. Coronavirus (COVID-19) brought a mix of similar\nemotions from the nations towards the decisions taken by their respective\ngovernments. Social media was bombarded with posts containing both positive and\nnegative sentiments on the COVID-19, pandemic, lockdown, hashtags past couple\nof months. Despite geographically close, many neighboring countries reacted\ndifferently to one another. For instance, Denmark and Sweden, which share many\nsimilarities, stood poles apart on the decision taken by their respective\ngovernments. Yet, their nation's support was mostly unanimous, unlike the South\nAsian neighboring countries where people showed a lot of anxiety and\nresentment. This study tends to detect and analyze sentiment polarity and\nemotions demonstrated during the initial phase of the pandemic and the lockdown\nperiod employing natural language processing (NLP) and deep learning techniques\non Twitter posts. Deep long short-term memory (LSTM) models used for estimating\nthe sentiment polarity and emotions from extracted tweets have been trained to\nachieve state-of-the-art accuracy on the sentiment140 dataset. The use of\nemoticons showed a unique and novel way of validating the supervised deep\nlearning models on tweets extracted from Twitter.", "published": "2020-08-23 12:43:26", "link": "http://arxiv.org/abs/2008.10031v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Learn to Talk via Proactive Knowledge Transfer", "abstract": "Knowledge Transfer has been applied in solving a wide variety of problems.\nFor example, knowledge can be transferred between tasks (e.g., learning to\nhandle novel situations by leveraging prior knowledge) or between agents (e.g.,\nlearning from others without direct experience). Without loss of generality, we\nrelate knowledge transfer to KL-divergence minimization, i.e., matching the\n(belief) distributions of learners and teachers. The equivalence gives us a new\nperspective in understanding variants of the KL-divergence by looking at how\nlearners structure their interaction with teachers in order to acquire\nknowledge. In this paper, we provide an in-depth analysis of KL-divergence\nminimization in Forward and Backward orders, which shows that learners are\nreinforced via on-policy learning in Backward. In contrast, learners are\nsupervised in Forward. Moreover, our analysis is gradient-based, so it can be\ngeneralized to arbitrary tasks and help to decide which order to minimize given\nthe property of the task. By replacing Forward with Backward in Knowledge\nDistillation, we observed +0.7-1.1 BLEU gains on the WMT'17 De-En and IWSLT'15\nTh-En machine translation tasks.", "published": "2020-08-23 17:46:04", "link": "http://arxiv.org/abs/2008.10077v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Translating Paintings Into Music Using Neural Networks", "abstract": "We propose a system that learns from artistic pairings of music and\ncorresponding album cover art. The goal is to 'translate' paintings into music\nand, in further stages of development, the converse. We aim to deploy this\nsystem as an artistic tool for real time 'translations' between musicians and\npainters. The system's outputs serve as elements to be employed in a joint live\nperformance of music and painting, or as generative material to be used by the\nartists as inspiration for their improvisation.", "published": "2020-08-23 05:08:39", "link": "http://arxiv.org/abs/2008.09960v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "They are wearing a mask! Identification of Subjects Wearing a Surgical\n  Mask from their Speech by means of x-vectors and Fisher Vectors", "abstract": "Challenges based on Computational Paralinguistics in the INTERSPEECH\nConference have always had a good reception among the attendees owing to its\ncompetitive academic and research demands. This year, the INTERSPEECH 2020\nComputational Paralinguistics Challenge offers three different problems; here,\nthe Mask Sub-Challenge is of specific interest. This challenge involves the\nclassification of speech recorded from subjects while wearing a surgical mask.\nIn this study, to address the above-mentioned problem we employ two different\ntypes of feature extraction methods. The x-vectors embeddings, which is the\ncurrent state-of-the-art approach for Speaker Recognition; and the Fisher\nVector (FV), that is a method originally intended for Image Recognition, but\nhere we utilize it to discriminate utterances. These approaches employ distinct\nframe-level representations: MFCC and PLP. Using Support Vector Machines (SVM)\nas the classifier, we perform a technical comparison between the performances\nof the FV encodings and the x-vector embeddings for this particular\nclassification task. We find that the Fisher vector encodings provide better\nrepresentations of the utterances than the x-vectors do for this specific\ndataset. Moreover, we show that a fusion of our best configurations outperforms\nall the baseline scores of the Mask Sub-Challenge.", "published": "2020-08-23 11:27:11", "link": "http://arxiv.org/abs/2008.10014v1", "categories": ["eess.AS", "cs.LG", "I.2.7; J.3"], "primary_category": "eess.AS"}
{"title": "A Lip Sync Expert Is All You Need for Speech to Lip Generation In The\n  Wild", "abstract": "In this work, we investigate the problem of lip-syncing a talking face video\nof an arbitrary identity to match a target speech segment. Current works excel\nat producing accurate lip movements on a static image or videos of specific\npeople seen during the training phase. However, they fail to accurately morph\nthe lip movements of arbitrary identities in dynamic, unconstrained talking\nface videos, resulting in significant parts of the video being out-of-sync with\nthe new audio. We identify key reasons pertaining to this and hence resolve\nthem by learning from a powerful lip-sync discriminator. Next, we propose new,\nrigorous evaluation benchmarks and metrics to accurately measure lip\nsynchronization in unconstrained videos. Extensive quantitative evaluations on\nour challenging benchmarks show that the lip-sync accuracy of the videos\ngenerated by our Wav2Lip model is almost as good as real synced videos. We\nprovide a demo video clearly showing the substantial impact of our Wav2Lip\nmodel and evaluation benchmarks on our website:\n\\url{cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild}.\nThe code and models are released at this GitHub repository:\n\\url{github.com/Rudrabha/Wav2Lip}. You can also try out the interactive demo at\nthis link: \\url{bhaasha.iiit.ac.in/lipsync}.", "published": "2020-08-23 11:01:25", "link": "http://arxiv.org/abs/2008.10010v1", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Independent Vector Analysis via Log-Quadratically Penalized Quadratic\n  Minimization", "abstract": "We propose a new algorithm for blind source separation (BSS) using\nindependent vector analysis (IVA). This is an improvement over the popular\nauxiliary function based IVA (AuxIVA) with iterative projection (IP) or\niterative source steering (ISS). We introduce iterative projection with\nadjustment (IPA), where we update one demixing filter and jointly adjust all\nthe other sources along its current direction. Each update involves solving a\nnon-convex minimization problem that we term log-quadratically penalized\nquadratic minimization (LQPQM), that we think is of interest beyond this work.\nIn the general case, we show that its global minimum corresponds to the largest\nroot of a univariate function, reminiscent of modified eigenvalue problems. We\npropose a simple procedure based on Newton-Raphson to efficiently compute it.\nNumerical experiments demonstrate the effectiveness of the proposed method.\nFirst, we show that it efficiently decreases the value of the surrogate\nfunction. In further experiments on synthetic mixtures, we study the\nprobability of finding the true demixing matrix and convergence speed. We show\nthat the proposed method combines high success rate and fast convergence.\nFinally, we validate the performance on a reverberant blind speech separation\ntask. We find that all the AuxIVA-based methods perform similarly in terms of\nacoustic BSS metrics. However, AuxIVA-IPA converges faster. We measure up to\n8.5 times speed-up in terms of runtime compared to the next best AuxIVA-based\nmethod, depending on the number of channels and the signal-to-noise ratio\n(SNR).", "published": "2020-08-23 14:21:07", "link": "http://arxiv.org/abs/2008.10048v2", "categories": ["eess.SP", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Independent Vector Analysis with Deep Neural Network Source Priors", "abstract": "This paper studies the density priors for independent vector analysis (IVA)\nwith convolutive speech mixture separation as the exemplary application. Most\nexisting source priors for IVA are too simplified to capture the fine\nstructures of speeches. Here, we first time show that it is possible to\nefficiently estimate the derivative of speech density with universal\napproximators like deep neural networks (DNN) by optimizing certain proxy\nseparation related performance indices. Experimental results suggest that the\nresultant neural network density priors consistently outperform previous ones\nin convergence speed for online implementation and signal-to-interference ratio\n(SIR) for batch implementation.", "published": "2020-08-23 17:13:55", "link": "http://arxiv.org/abs/2008.11273v2", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
