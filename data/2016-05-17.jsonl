{"title": "Recurrent Neural Network for Text Classification with Multi-Task\n  Learning", "abstract": "Neural network based methods have obtained great progress on a variety of\nnatural language processing tasks. However, in most previous works, the models\nare learned based on single-task supervised objectives, which often suffer from\ninsufficient training data. In this paper, we use the multi-task learning\nframework to jointly learn across multiple related tasks. Based on recurrent\nneural network, we propose three different mechanisms of sharing information to\nmodel text with task-specific and shared layers. The entire network is trained\njointly on all these tasks. Experiments on four benchmark text classification\ntasks show that our proposed models can improve the performance of a task with\nthe help of other related tasks.", "published": "2016-05-17 10:43:38", "link": "http://arxiv.org/abs/1605.05101v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Loose-Structured Knowledge into Conversation Modeling via\n  Recall-Gate LSTM", "abstract": "Modeling human conversations is the essence for building satisfying chat-bots\nwith multi-turn dialog ability. Conversation modeling will notably benefit from\ndomain knowledge since the relationships between sentences can be clarified due\nto semantic hints introduced by knowledge. In this paper, a deep neural network\nis proposed to incorporate background knowledge for conversation modeling.\nThrough a specially designed Recall gate, domain knowledge can be transformed\ninto the extra global memory of Long Short-Term Memory (LSTM), so as to enhance\nLSTM by cooperating with its local memory to capture the implicit semantic\nrelevance between sentences within conversations. In addition, this paper\nintroduces the loose structured domain knowledge base, which can be built with\nslight amount of manual work and easily adopted by the Recall gate. Our model\nis evaluated on the context-oriented response selecting task, and experimental\nresults on both two datasets have shown that our approach is promising for\nmodeling human conversations and building key components of automatic chatting\nsystems.", "published": "2016-05-17 11:03:25", "link": "http://arxiv.org/abs/1605.05110v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Siamese convolutional networks based on phonetic features for cognate\n  identification", "abstract": "In this paper, we explore the use of convolutional networks (ConvNets) for\nthe purpose of cognate identification. We compare our architecture with binary\nclassifiers based on string similarity measures on different language families.\nOur experiments show that convolutional networks achieve competitive results\nacross concepts and across language families at the task of cognate\nidentification.", "published": "2016-05-17 14:07:43", "link": "http://arxiv.org/abs/1605.05172v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Word2Vec is a special case of Kernel Correspondence Analysis and Kernels\n  for Natural Language Processing", "abstract": "We show that correspondence analysis (CA) is equivalent to defining a Gini\nindex with appropriately scaled one-hot encoding. Using this relation, we\nintroduce a nonlinear kernel extension to CA. This extended CA gives a known\nanalysis for natural language via specialized kernels that use an appropriate\ncontingency table. We propose a semi-supervised CA, which is a special case of\nthe kernel extension to CA. Because CA requires excessive memory if applied to\nnumerous categories, CA has not been used for natural language processing. We\naddress this problem by introducing delayed evaluation to randomized singular\nvalue decomposition. The memory-efficient CA is then applied to a word-vector\nrepresentation task. We propose a tail-cut kernel, which is an extension to the\nskip-gram within the kernel extension to CA. Our tail-cut kernel outperforms\nexisting word-vector representation methods.", "published": "2016-05-17 10:07:34", "link": "http://arxiv.org/abs/1605.05087v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Tweet Acts: A Speech Act Classifier for Twitter", "abstract": "Speech acts are a way to conceptualize speech as action. This holds true for\ncommunication on any platform, including social media platforms such as\nTwitter. In this paper, we explored speech act recognition on Twitter by\ntreating it as a multi-class classification problem. We created a taxonomy of\nsix speech acts for Twitter and proposed a set of semantic and syntactic\nfeatures. We trained and tested a logistic regression classifier using a data\nset of manually labelled tweets. Our method achieved a state-of-the-art\nperformance with an average F1 score of more than $0.70$. We also explored\nclassifiers with three different granularities (Twitter-wide, type-specific and\ntopic-specific) in order to find the right balance between generalization and\noverfitting for our task.", "published": "2016-05-17 13:31:14", "link": "http://arxiv.org/abs/1605.05156v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Fuzzy Sets Across the Natural Language Generation Pipeline", "abstract": "We explore the implications of using fuzzy techniques (mainly those commonly\nused in the linguistic description/summarization of data discipline) from a\nnatural language generation perspective. For this, we provide an extensive\ndiscussion of some general convergence points and an exploration of the\nrelationship between the different tasks involved in the standard NLG system\npipeline architecture and the most common fuzzy approaches used in linguistic\nsummarization/description of data, such as fuzzy quantified statements,\nevaluation criteria or aggregation operators. Each individual discussion is\nillustrated with a related use case. Recent work made in the context of\ncross-fertilization of both research fields is also referenced. This paper\nencompasses general ideas that emerged as part of the PhD thesis \"Application\nof fuzzy sets in data-to-text systems\". It does not present a specific\napplication or a formal approach, but rather discusses current high-level\nissues and potential usages of fuzzy sets (focused on linguistic summarization\nof data) in natural language generation.", "published": "2016-05-17 19:45:49", "link": "http://arxiv.org/abs/1605.05303v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Semi-automatic Method for Efficient Detection of Stories on Social\n  Media", "abstract": "Twitter has become one of the main sources of news for many people. As\nreal-world events and emergencies unfold, Twitter is abuzz with hundreds of\nthousands of stories about the events. Some of these stories are harmless,\nwhile others could potentially be life-saving or sources of malicious rumors.\nThus, it is critically important to be able to efficiently track stories that\nspread on Twitter during these events. In this paper, we present a novel\nsemi-automatic tool that enables users to efficiently identify and track\nstories about real-world events on Twitter. We ran a user study with 25\nparticipants, demonstrating that compared to more conventional methods, our\ntool can increase the speed and the accuracy with which users can track stories\nabout real-world events.", "published": "2016-05-17 12:33:24", "link": "http://arxiv.org/abs/1605.05134v1", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "Automatic Detection and Categorization of Election-Related Tweets", "abstract": "With the rise in popularity of public social media and micro-blogging\nservices, most notably Twitter, the people have found a venue to hear and be\nheard by their peers without an intermediary. As a consequence, and aided by\nthe public nature of Twitter, political scientists now potentially have the\nmeans to analyse and understand the narratives that organically form, spread\nand decline among the public in a political campaign. However, the volume and\ndiversity of the conversation on Twitter, combined with its noisy and\nidiosyncratic nature, make this a hard task. Thus, advanced data mining and\nlanguage processing techniques are required to process and analyse the data. In\nthis paper, we present and evaluate a technical framework, based on recent\nadvances in deep neural networks, for identifying and analysing\nelection-related conversation on Twitter on a continuous, longitudinal basis.\nOur models can detect election-related tweets with an F-score of 0.92 and can\ncategorize these tweets into 22 topics with an F-score of 0.90.", "published": "2016-05-17 13:06:49", "link": "http://arxiv.org/abs/1605.05150v1", "categories": ["cs.CL", "cs.IT", "cs.SI", "math.IT"], "primary_category": "cs.CL"}
{"title": "Digital Stylometry: Linking Profiles Across Social Networks", "abstract": "There is an ever growing number of users with accounts on multiple social\nmedia and networking sites. Consequently, there is increasing interest in\nmatching user accounts and profiles across different social networks in order\nto create aggregate profiles of users. In this paper, we present models for\nDigital Stylometry, which is a method for matching users through stylometry\ninspired techniques. We experimented with linguistic, temporal, and combined\ntemporal-linguistic models for matching user accounts, using standard and novel\ntechniques. Using publicly available data, our best model, a combined\ntemporal-linguistic one, was able to correctly match the accounts of 31% of\n5,612 distinct users across Twitter and Facebook.", "published": "2016-05-17 13:47:24", "link": "http://arxiv.org/abs/1605.05166v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "Enhanced Twitter Sentiment Classification Using Contextual Information", "abstract": "The rise in popularity and ubiquity of Twitter has made sentiment analysis of\ntweets an important and well-covered area of research. However, the 140\ncharacter limit imposed on tweets makes it hard to use standard linguistic\nmethods for sentiment classification. On the other hand, what tweets lack in\nstructure they make up with sheer volume and rich metadata. This metadata\nincludes geolocation, temporal and author information. We hypothesize that\nsentiment is dependent on all these contextual factors. Different locations,\ntimes and authors have different emotional valences. In this paper, we explored\nthis hypothesis by utilizing distant supervision to collect millions of\nlabelled tweets from different locations, times and authors. We used this data\nto analyse the variation of tweet sentiments across different authors, times\nand locations. Once we explored and understood the relationship between these\nvariables and sentiment, we used a Bayesian approach to combine these variables\nwith more standard linguistic features such as n-grams to create a Twitter\nsentiment classifier. This combined classifier outperforms the purely\nlinguistic classifier, showing that integrating the rich contextual information\navailable on Twitter into sentiment classification is a promising direction of\nresearch.", "published": "2016-05-17 14:51:54", "link": "http://arxiv.org/abs/1605.05195v2", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "Yelp Dataset Challenge: Review Rating Prediction", "abstract": "Review websites, such as TripAdvisor and Yelp, allow users to post online\nreviews for various businesses, products and services, and have been recently\nshown to have a significant influence on consumer shopping behaviour. An online\nreview typically consists of free-form text and a star rating out of 5. The\nproblem of predicting a user's star rating for a product, given the user's text\nreview for that product, is called Review Rating Prediction and has lately\nbecome a popular, albeit hard, problem in machine learning. In this paper, we\ntreat Review Rating Prediction as a multi-class classification problem, and\nbuild sixteen different prediction models by combining four feature extraction\nmethods, (i) unigrams, (ii) bigrams, (iii) trigrams and (iv) Latent Semantic\nIndexing, with four machine learning algorithms, (i) logistic regression, (ii)\nNaive Bayes classification, (iii) perceptrons, and (iv) linear Support Vector\nClassification. We analyse the performance of each of these sixteen models to\ncome up with the best model for predicting the ratings from reviews. We use the\ndataset provided by Yelp for training and testing the models.", "published": "2016-05-17 20:52:33", "link": "http://arxiv.org/abs/1605.05362v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
