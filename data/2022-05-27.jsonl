{"title": "HiJoNLP at SemEval-2022 Task 2: Detecting Idiomaticity of Multiword\n  Expressions using Multilingual Pretrained Language Models", "abstract": "This paper describes an approach to detect idiomaticity only from the\ncontextualized representation of a MWE over multilingual pretrained language\nmodels. Our experiments find that larger models are usually more effective in\nidiomaticity detection. However, using a higher layer of the model may not\nguarantee a better performance. In multilingual scenarios, the convergence of\ndifferent languages are not consistent and rich-resource languages have big\nadvantages over other languages.", "published": "2022-05-27 01:55:59", "link": "http://arxiv.org/abs/2205.13708v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "IGLU 2022: Interactive Grounded Language Understanding in a\n  Collaborative Environment at NeurIPS 2022", "abstract": "Human intelligence has the remarkable ability to adapt to new tasks and\nenvironments quickly. Starting from a very young age, humans acquire new skills\nand learn how to solve new tasks either by imitating the behavior of others or\nby following provided natural language instructions. To facilitate research in\nthis direction, we propose IGLU: Interactive Grounded Language Understanding in\na Collaborative Environment. The primary goal of the competition is to approach\nthe problem of how to develop interactive embodied agents that learn to solve a\ntask while provided with grounded natural language instructions in a\ncollaborative environment. Understanding the complexity of the challenge, we\nsplit it into sub-tasks to make it feasible for participants.\n  This research challenge is naturally related, but not limited, to two fields\nof study that are highly relevant to the NeurIPS community: Natural Language\nUnderstanding and Generation (NLU/G) and Reinforcement Learning (RL).\nTherefore, the suggested challenge can bring two communities together to\napproach one of the crucial challenges in AI. Another critical aspect of the\nchallenge is the dedication to perform a human-in-the-loop evaluation as a\nfinal evaluation for the agents developed by contestants.", "published": "2022-05-27 06:12:48", "link": "http://arxiv.org/abs/2205.13771v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "kNN-Prompt: Nearest Neighbor Zero-Shot Inference", "abstract": "Retrieval-augmented language models (LMs) use non-parametric memory to\nsubstantially outperform their non-retrieval counterparts on perplexity-based\nevaluations, but it is an open question whether they achieve similar gains in\nfew- and zero-shot end-task accuracy. We extensively study one such model, the\nk-nearest neighbor LM (kNN-LM), showing that the gains marginally transfer. The\nmain challenge is to achieve coverage of the verbalizer tokens that define the\ndifferent end-task class labels. To address this challenge, we also introduce\nkNN-Prompt, a simple and effective kNN-LM with automatically expanded fuzzy\nverbalizers (e.g. to expand terrible to also include silly and other\ntask-specific synonyms for sentiment classification). Across nine diverse\nend-tasks, using kNN-Prompt with GPT-2 large yields significant performance\nboosts over strong zero-shot baselines (13.4% absolute improvement over the\nbase LM on average). We also show that other advantages of non-parametric\naugmentation hold for end tasks; kNN-Prompt is effective for domain adaptation\nwith no further training, and gains increase with the size of the retrieval\nmodel.", "published": "2022-05-27 07:00:59", "link": "http://arxiv.org/abs/2205.13792v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semeval-2022 Task 1: CODWOE -- Comparing Dictionaries and Word\n  Embeddings", "abstract": "Word embeddings have advanced the state of the art in NLP across numerous\ntasks. Understanding the contents of dense neural representations is of utmost\ninterest to the computational semantics community. We propose to focus on\nrelating these opaque word vectors with human-readable definitions, as found in\ndictionaries. This problem naturally divides into two subtasks: converting\ndefinitions into embeddings, and converting embeddings into definitions. This\ntask was conducted in a multilingual setting, using comparable sets of\nembeddings trained homogeneously.", "published": "2022-05-27 09:40:33", "link": "http://arxiv.org/abs/2205.13858v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EmoInHindi: A Multi-label Emotion and Intensity Annotated Dataset in\n  Hindi for Emotion Recognition in Dialogues", "abstract": "The long-standing goal of Artificial Intelligence (AI) has been to create\nhuman-like conversational systems. Such systems should have the ability to\ndevelop an emotional connection with the users, hence emotion recognition in\ndialogues is an important task. Emotion detection in dialogues is a challenging\ntask because humans usually convey multiple emotions with varying degrees of\nintensities in a single utterance. Moreover, emotion in an utterance of a\ndialogue may be dependent on previous utterances making the task more complex.\nEmotion recognition has always been in great demand. However, most of the\nexisting datasets for multi-label emotion and intensity detection in\nconversations are in English. To this end, we create a large conversational\ndataset in Hindi named EmoInHindi for multi-label emotion and intensity\nrecognition in conversations containing 1,814 dialogues with a total of 44,247\nutterances. We prepare our dataset in a Wizard-of-Oz manner for mental health\nand legal counselling of crime victims. Each utterance of the dialogue is\nannotated with one or more emotion categories from the 16 emotion classes\nincluding neutral, and their corresponding intensity values. We further propose\nstrong contextual baselines that can detect emotion(s) and the corresponding\nintensity of an utterance given the conversational context.", "published": "2022-05-27 11:23:50", "link": "http://arxiv.org/abs/2205.13908v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Punctuation Restoration in Spanish Customer Support Transcripts using\n  Transfer Learning", "abstract": "Automatic Speech Recognition (ASR) systems typically produce unpunctuated\ntranscripts that have poor readability. In addition, building a punctuation\nrestoration system is challenging for low-resource languages, especially for\ndomain-specific applications. In this paper, we propose a Spanish punctuation\nrestoration system designed for a real-time customer support transcription\nservice. To address the data sparsity of Spanish transcripts in the customer\nsupport domain, we introduce two transfer-learning-based strategies: 1) domain\nadaptation using out-of-domain Spanish text data; 2) cross-lingual transfer\nlearning leveraging in-domain English transcript data. Our experiment results\nshow that these strategies improve the accuracy of the Spanish punctuation\nrestoration system.", "published": "2022-05-27 13:14:23", "link": "http://arxiv.org/abs/2205.13961v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "StereoKG: Data-Driven Knowledge Graph Construction for Cultural\n  Knowledge and Stereotypes", "abstract": "Analyzing ethnic or religious bias is important for improving fairness,\naccountability, and transparency of natural language processing models.\nHowever, many techniques rely on human-compiled lists of bias terms, which are\nexpensive to create and are limited in coverage. In this study, we present a\nfully data-driven pipeline for generating a knowledge graph (KG) of cultural\nknowledge and stereotypes. Our resulting KG covers 5 religious groups and 5\nnationalities and can easily be extended to include more entities. Our human\nevaluation shows that the majority (59.2%) of non-singleton entries are\ncoherent and complete stereotypes. We further show that performing intermediate\nmasked language model training on the verbalized KG leads to a higher level of\ncultural awareness in the model and has the potential to increase\nclassification performance on knowledge-crucial samples on a related task,\ni.e., hate speech detection.", "published": "2022-05-27 15:09:56", "link": "http://arxiv.org/abs/2205.14036v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UAlberta at SemEval 2022 Task 2: Leveraging Glosses and Translations for\n  Multilingual Idiomaticity Detection", "abstract": "We describe the University of Alberta systems for the SemEval-2022 Task 2 on\nmultilingual idiomaticity detection. Working under the assumption that\nidiomatic expressions are noncompositional, our first method integrates\ninformation on the meanings of the individual words of an expression into a\nbinary classifier. Further hypothesizing that literal and idiomatic expressions\ntranslate differently, our second method translates an expression in context,\nand uses a lexical knowledge base to determine if the translation is literal.\nOur approaches are grounded in linguistic phenomena, and leverage existing\nsources of lexical knowledge. Our results offer support for both approaches,\nparticularly the former.", "published": "2022-05-27 16:35:00", "link": "http://arxiv.org/abs/2205.14084v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Patching Leaks in the Charformer for Efficient Character-Level\n  Generation", "abstract": "Character-based representations have important advantages over subword-based\nones for morphologically rich languages. They come with increased robustness to\nnoisy input and do not need a separate tokenization step. However, they also\nhave a crucial disadvantage: they notably increase the length of text\nsequences. The GBST method from Charformer groups (aka downsamples) characters\nto solve this, but allows information to leak when applied to a Transformer\ndecoder. We solve this information leak issue, thereby enabling character\ngrouping in the decoder. We show that Charformer downsampling has no apparent\nbenefits in NMT over previous downsampling methods in terms of translation\nquality, however it can be trained roughly 30% faster. Promising performance on\nEnglish--Turkish translation indicate the potential of character-level models\nfor morphologically-rich languages.", "published": "2022-05-27 16:36:45", "link": "http://arxiv.org/abs/2205.14086v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CEBaB: Estimating the Causal Effects of Real-World Concepts on NLP Model\n  Behavior", "abstract": "The increasing size and complexity of modern ML systems has improved their\npredictive capabilities but made their behavior harder to explain. Many\ntechniques for model explanation have been developed in response, but we lack\nclear criteria for assessing these techniques. In this paper, we cast model\nexplanation as the causal inference problem of estimating causal effects of\nreal-world concepts on the output behavior of ML models given actual input\ndata. We introduce CEBaB, a new benchmark dataset for assessing concept-based\nexplanation methods in Natural Language Processing (NLP). CEBaB consists of\nshort restaurant reviews with human-generated counterfactual reviews in which\nan aspect (food, noise, ambiance, service) of the dining experience was\nmodified. Original and counterfactual reviews are annotated with\nmultiply-validated sentiment ratings at the aspect-level and review-level. The\nrich structure of CEBaB allows us to go beyond input features to study the\neffects of abstract, real-world concepts on model behavior. We use CEBaB to\ncompare the quality of a range of concept-based explanation methods covering\ndifferent assumptions and conceptions of the problem, and we seek to establish\nnatural metrics for comparative assessments of these methods.", "published": "2022-05-27 17:59:14", "link": "http://arxiv.org/abs/2205.14140v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Who is we? Disambiguating the referents of first person plural pronouns\n  in parliamentary debates", "abstract": "This paper investigates the use of first person plural pronouns as a\nrhetorical device in political speeches. We present an annotation schema for\ndisambiguating pronoun references and use our schema to create an annotated\ncorpus of debates from the German Bundestag. We then use our corpus to learn to\nautomatically resolve pronoun referents in parliamentary debates. We explore\nthe use of data augmentation with weak supervision to further expand our corpus\nand report preliminary results.", "published": "2022-05-27 18:18:04", "link": "http://arxiv.org/abs/2205.14182v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Controllable Text Generation with Neurally-Decomposed Oracle", "abstract": "We propose a general and efficient framework to control auto-regressive\ngeneration models with NeurAlly-Decomposed Oracle (NADO). Given a pre-trained\nbase language model and a sequence-level boolean oracle function, we propose to\ndecompose the oracle function into token-level guidance to steer the base model\nin text generation. Specifically, the token-level guidance is approximated by a\nneural model trained with examples sampled from the base model, demanding no\nadditional auxiliary labeled data. Based on posterior regularization, we\npresent the closed-form optimal solution to incorporate the token-level\nguidance into the base model for controllable generation. We further provide a\ntheoretical analysis of how the approximation quality of NADO affects the\ncontrollable generation results. Experiments conducted on two applications: (1)\ntext generation with lexical constraints and (2) machine translation with\nformality control demonstrate that our framework efficiently guides the base\nmodel towards the given oracle while maintaining high generation quality.", "published": "2022-05-27 20:17:53", "link": "http://arxiv.org/abs/2205.14219v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sparse Conditional Hidden Markov Model for Weakly Supervised Named\n  Entity Recognition", "abstract": "Weakly supervised named entity recognition methods train label models to\naggregate the token annotations of multiple noisy labeling functions (LFs)\nwithout seeing any manually annotated labels. To work well, the label model\nneeds to contextually identify and emphasize well-performed LFs while\ndown-weighting the under-performers. However, evaluating the LFs is challenging\ndue to the lack of ground truths. To address this issue, we propose the sparse\nconditional hidden Markov model (Sparse-CHMM). Instead of predicting the entire\nemission matrix as other HMM-based methods, Sparse-CHMM focuses on estimating\nits diagonal elements, which are considered as the reliability scores of the\nLFs. The sparse scores are then expanded to the full-fledged emission matrix\nwith pre-defined expansion functions. We also augment the emission with\nweighted XOR scores, which track the probabilities of an LF observing incorrect\nentities. Sparse-CHMM is optimized through unsupervised learning with a\nthree-stage training pipeline that reduces the training difficulty and prevents\nthe model from falling into local optima. Compared with the baselines in the\nWrench benchmark, Sparse-CHMM achieves a 3.01 average F1 score improvement on\nfive comprehensive datasets. Experiments show that each component of\nSparse-CHMM is effective, and the estimated LF reliabilities strongly correlate\nwith true LF F1 scores.", "published": "2022-05-27 20:47:30", "link": "http://arxiv.org/abs/2205.14228v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-supervised models of audio effectively explain human cortical\n  responses to speech", "abstract": "Self-supervised language models are very effective at predicting high-level\ncortical responses during language comprehension. However, the best current\nmodels of lower-level auditory processing in the human brain rely on either\nhand-constructed acoustic filters or representations from supervised audio\nneural networks. In this work, we capitalize on the progress of self-supervised\nspeech representation learning (SSL) to create new state-of-the-art models of\nthe human auditory system. Compared against acoustic baselines, phonemic\nfeatures, and supervised models, representations from the middle layers of\nself-supervised models (APC, wav2vec, wav2vec 2.0, and HuBERT) consistently\nyield the best prediction performance for fMRI recordings within the auditory\ncortex (AC). Brain areas involved in low-level auditory processing exhibit a\npreference for earlier SSL model layers, whereas higher-level semantic areas\nprefer later layers. We show that these trends are due to the models' ability\nto encode information at multiple linguistic levels (acoustic, phonetic, and\nlexical) along their representation depth. Overall, these results show that\nself-supervised models effectively capture the hierarchy of information\nrelevant to different stages of speech processing in human cortex.", "published": "2022-05-27 22:04:02", "link": "http://arxiv.org/abs/2205.14252v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Foundation Models Help Us Achieve Perfect Secrecy?", "abstract": "A key promise of machine learning is the ability to assist users with\npersonal tasks. Because the personal context required to make accurate\npredictions is often sensitive, we require systems that protect privacy. A gold\nstandard privacy-preserving system will satisfy perfect secrecy, meaning that\ninteractions with the system provably reveal no private information. However,\nprivacy and quality appear to be in tension in existing systems for personal\ntasks. Neural models typically require copious amounts of training to perform\nwell, while individual users typically hold a limited scale of data, so\nfederated learning (FL) systems propose to learn from the aggregate data of\nmultiple users. FL does not provide perfect secrecy, but rather practitioners\napply statistical notions of privacy -- i.e., the probability of learning\nprivate information about a user should be reasonably low. The strength of the\nprivacy guarantee is governed by privacy parameters. Numerous privacy attacks\nhave been demonstrated on FL systems and it can be challenging to reason about\nthe appropriate privacy parameters for a privacy-sensitive use case. Therefore\nour work proposes a simple baseline for FL, which both provides the stronger\nperfect secrecy guarantee and does not require setting any privacy parameters.\nWe initiate the study of when and where an emerging tool in ML -- the\nin-context learning abilities of recent pretrained models -- can be an\neffective baseline alongside FL. We find in-context learning is competitive\nwith strong FL baselines on 6 of 7 popular benchmarks from the privacy\nliterature and a real-world case study, which is disjoint from the pretraining\ndata. We release our code here: https://github.com/simran-arora/focus", "published": "2022-05-27 02:32:26", "link": "http://arxiv.org/abs/2205.13722v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Understanding Long Programming Languages with Structure-Aware Sparse\n  Attention", "abstract": "Programming-based Pre-trained Language Models (PPLMs) such as CodeBERT have\nachieved great success in many downstream code-related tasks. Since the memory\nand computational complexity of self-attention in the Transformer grow\nquadratically with the sequence length, PPLMs typically limit the code length\nto 512. However, codes in real-world applications are generally long, such as\ncode searches, which cannot be processed efficiently by existing PPLMs. To\nsolve this problem, in this paper, we present SASA, a Structure-Aware Sparse\nAttention mechanism, which reduces the complexity and improves performance for\nlong code understanding tasks. The key components in SASA are top-$k$ sparse\nattention and Abstract Syntax Tree (AST)-based structure-aware attention. With\ntop-$k$ sparse attention, the most crucial attention relation can be obtained\nwith a lower computational cost. As the code structure represents the logic of\nthe code statements, which is a complement to the code sequence\ncharacteristics, we further introduce AST structures into attention. Extensive\nexperiments on CodeXGLUE tasks show that SASA achieves better performance than\nthe competing baselines.", "published": "2022-05-27 02:50:57", "link": "http://arxiv.org/abs/2205.13730v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "NLU for Game-based Learning in Real: Initial Evaluations", "abstract": "Intelligent systems designed for play-based interactions should be\ncontextually aware of the users and their surroundings. Spoken Dialogue Systems\n(SDS) are critical for these interactive agents to carry out effective\ngoal-oriented communication with users in real-time. For the real-world (i.e.,\nin-the-wild) deployment of such conversational agents, improving the Natural\nLanguage Understanding (NLU) module of the goal-oriented SDS pipeline is\ncrucial, especially with limited task-specific datasets. This study explores\nthe potential benefits of a recently proposed transformer-based multi-task NLU\narchitecture, mainly to perform Intent Recognition on small-size\ndomain-specific educational game datasets. The evaluation datasets were\ncollected from children practicing basic math concepts via play-based\ninteractions in game-based learning settings. We investigate the NLU\nperformances on the initial proof-of-concept game datasets versus the\nreal-world deployment datasets and observe anticipated performance drops\nin-the-wild. We have shown that compared to the more straightforward baseline\napproaches, Dual Intent and Entity Transformer (DIET) architecture is robust\nenough to handle real-world data to a large extent for the Intent Recognition\ntask on these domain-specific in-the-wild game datasets.", "published": "2022-05-27 03:48:32", "link": "http://arxiv.org/abs/2205.13754v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Text-Based Automatic Personality Prediction Using KGrAt-Net; A Knowledge\n  Graph Attention Network Classifier", "abstract": "Nowadays, a tremendous amount of human communications occur on Internet-based\ncommunication infrastructures, like social networks, email, forums,\norganizational communication platforms, etc. Indeed, the automatic prediction\nor assessment of individuals' personalities through their written or exchanged\ntext would be advantageous to ameliorate their relationships. To this end, this\npaper aims to propose KGrAt-Net, which is a Knowledge Graph Attention Network\ntext classifier. For the first time, it applies the knowledge graph attention\nnetwork to perform Automatic Personality Prediction (APP), according to the Big\nFive personality traits. After performing some preprocessing activities, it\nfirst tries to acquire a knowing-full representation of the knowledge behind\nthe concepts in the input text by building its equivalent knowledge graph. A\nknowledge graph collects interlinked descriptions of concepts, entities, and\nrelationships in a machine-readable form. Practically, it provides a\nmachine-readable cognitive understanding of concepts and semantic relationships\namong them. Then, applying the attention mechanism, it attempts to pay\nattention to the most relevant parts of the graph to predict the personality\ntraits of the input text. We used 2,467 essays from the Essays Dataset. The\nresults demonstrated that KGrAt-Net considerably improved personality\nprediction accuracies (up to 70.26% on average). Furthermore, KGrAt-Net also\nuses knowledge graph embedding to enrich the classification, which makes it\neven more accurate (on average, 72.41%) in APP.", "published": "2022-05-27 06:33:09", "link": "http://arxiv.org/abs/2205.13780v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Learning to Automate Follow-up Question Generation using Process\n  Knowledge for Depression Triage on Reddit Posts", "abstract": "Conversational Agents (CAs) powered with deep language models (DLMs) have\nshown tremendous promise in the domain of mental health. Prominently, the CAs\nhave been used to provide informational or therapeutic services to patients.\nHowever, the utility of CAs to assist in mental health triaging has not been\nexplored in the existing work as it requires a controlled generation of\nfollow-up questions (FQs), which are often initiated and guided by the mental\nhealth professionals (MHPs) in clinical settings. In the context of depression,\nour experiments show that DLMs coupled with process knowledge in a mental\nhealth questionnaire generate 12.54% and 9.37% better FQs based on similarity\nand longest common subsequence matches to questions in the PHQ-9 dataset\nrespectively, when compared with DLMs without process knowledge support.\nDespite coupling with process knowledge, we find that DLMs are still prone to\nhallucination, i.e., generating redundant, irrelevant, and unsafe FQs. We\ndemonstrate the challenge of using existing datasets to train a DLM for\ngenerating FQs that adhere to clinical process knowledge. To address this\nlimitation, we prepared an extended PHQ-9 based dataset, PRIMATE, in\ncollaboration with MHPs. PRIMATE contains annotations regarding whether a\nparticular question in the PHQ-9 dataset has already been answered in the\nuser's initial description of the mental health condition. We used PRIMATE to\ntrain a DLM in a supervised setting to identify which of the PHQ-9 questions\ncan be answered directly from the user's post and which ones would require more\ninformation from the user. Using performance analysis based on MCC scores, we\nshow that PRIMATE is appropriate for identifying questions in PHQ-9 that could\nguide generative DLMs towards controlled FQ generation suitable for aiding\ntriaging. Dataset created as a part of this research:\nhttps://github.com/primate-mh/Primate2022", "published": "2022-05-27 10:33:56", "link": "http://arxiv.org/abs/2205.13884v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Commonsense and Named Entity Aware Knowledge Grounded Dialogue\n  Generation", "abstract": "Grounding dialogue on external knowledge and interpreting linguistic patterns\nin dialogue history context, such as ellipsis, anaphora, and co-references is\ncritical for dialogue comprehension and generation. In this paper, we present a\nnovel open-domain dialogue generation model which effectively utilizes the\nlarge-scale commonsense and named entity based knowledge in addition to the\nunstructured topic-specific knowledge associated with each utterance. We\nenhance the commonsense knowledge with named entity-aware structures using\nco-references. Our proposed model utilizes a multi-hop attention layer to\npreserve the most accurate and critical parts of the dialogue history and the\nassociated knowledge. In addition, we employ a Commonsense and Named Entity\nEnhanced Attention Module, which starts with the extracted triples from various\nsources and gradually finds the relevant supporting set of triples using\nmulti-hop attention with the query vector obtained from the interactive\ndialogue-knowledge module. Empirical results on two benchmark dataset\ndemonstrate that our model significantly outperforms the state-of-the-art\nmethods in terms of both automatic evaluation metrics and human judgment. Our\ncode is publicly available at\n\\href{https://github.com/deekshaVarshney/CNTF}{https://github.com/deekshaVarshney/CNTF};\n\\href{https://www.iitp.ac.in/~ai-nlp-ml/resources/codes/CNTF.zip}{https://www.iitp.ac.in/-ai-nlp-ml/resources/\ncodes/CNTF.zip}.", "published": "2022-05-27 12:11:40", "link": "http://arxiv.org/abs/2205.13928v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fast and Light-Weight Answer Text Retrieval in Dialogue Systems", "abstract": "Dialogue systems can benefit from being able to search through a corpus of\ntext to find information relevant to user requests, especially when\nencountering a request for which no manually curated response is available. The\nstate-of-the-art technology for neural dense retrieval or re-ranking involves\ndeep learning models with hundreds of millions of parameters. However, it is\ndifficult and expensive to get such models to operate at an industrial scale,\nespecially for cloud services that often need to support a big number of\nindividually customized dialogue systems, each with its own text corpus. We\nreport our work on enabling advanced neural dense retrieval systems to operate\neffectively at scale on relatively inexpensive hardware. We compare with\nleading alternative industrial solutions and show that we can provide a\nsolution that is effective, fast, and cost-efficient.", "published": "2022-05-27 20:37:16", "link": "http://arxiv.org/abs/2205.14226v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Defending Against Stealthy Backdoor Attacks", "abstract": "Defenses against security threats have been an interest of recent studies.\nRecent works have shown that it is not difficult to attack a natural language\nprocessing (NLP) model while defending against them is still a cat-mouse game.\nBackdoor attacks are one such attack where a neural network is made to perform\nin a certain way on specific samples containing some triggers while achieving\nnormal results on other samples. In this work, we present a few defense\nstrategies that can be useful to counter against such an attack. We show that\nour defense methodologies significantly decrease the performance on the\nattacked inputs while maintaining similar performance on benign inputs. We also\nshow that some of our defenses have very less runtime and also maintain\nsimilarity with the original inputs.", "published": "2022-05-27 21:38:42", "link": "http://arxiv.org/abs/2205.14246v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "A Sea of Words: An In-Depth Analysis of Anchors for Text Data", "abstract": "Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based interpretability\nmethod. For text data, it proposes to explain a decision by highlighting a\nsmall set of words (an anchor) such that the model to explain has similar\noutputs when they are present in a document. In this paper, we present the\nfirst theoretical analysis of Anchors, considering that the search for the best\nanchor is exhaustive. After formalizing the algorithm for text classification,\nwe present explicit results on different classes of models when the\nvectorization step is TF-IDF, and words are replaced by a fixed\nout-of-dictionary token when removed. Our inquiry covers models such as\nelementary if-then rules and linear classifiers. We then leverage this analysis\nto gain insights on the behavior of Anchors for any differentiable classifiers.\nFor neural networks, we empirically show that the words corresponding to the\nhighest partial derivatives of the model with respect to the input, reweighted\nby the inverse document frequencies, are selected by Anchors.", "published": "2022-05-27 06:57:32", "link": "http://arxiv.org/abs/2205.13789v2", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "What Dense Graph Do You Need for Self-Attention?", "abstract": "Transformers have made progress in miscellaneous tasks, but suffer from\nquadratic computational and memory complexities. Recent works propose sparse\nTransformers with attention on sparse graphs to reduce complexity and remain\nstrong performance. While effective, the crucial parts of how dense a graph\nneeds to be to perform well are not fully explored. In this paper, we propose\nNormalized Information Payload (NIP), a graph scoring function measuring\ninformation transfer on graph, which provides an analysis tool for trade-offs\nbetween performance and complexity. Guided by this theoretical analysis, we\npresent Hypercube Transformer, a sparse Transformer that models token\ninteractions in a hypercube and shows comparable or even better results with\nvanilla Transformer while yielding $O(N\\log N)$ complexity with sequence length\n$N$. Experiments on tasks requiring various sequence lengths lay validation for\nour graph function well.", "published": "2022-05-27 14:36:55", "link": "http://arxiv.org/abs/2205.14014v5", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "StarGraph: Knowledge Representation Learning based on Incomplete Two-hop\n  Subgraph", "abstract": "Conventional representation learning algorithms for knowledge graphs (KG) map\neach entity to a unique embedding vector, ignoring the rich information\ncontained in the neighborhood. We propose a method named StarGraph, which gives\na novel way to utilize the neighborhood information for large-scale knowledge\ngraphs to obtain entity representations. An incomplete two-hop neighborhood\nsubgraph for each target node is at first generated, then processed by a\nmodified self-attention network to obtain the entity representation, which is\nused to replace the entity embedding in conventional methods. We achieved SOTA\nperformance on ogbl-wikikg2 and got competitive results on fb15k-237. The\nexperimental results proves that StarGraph is efficient in parameters, and the\nimprovement made on ogbl-wikikg2 demonstrates its great effectiveness of\nrepresentation learning on large-scale knowledge graphs. The code is now\navailable at \\url{https://github.com/hzli-ucas/StarGraph}.", "published": "2022-05-27 19:32:45", "link": "http://arxiv.org/abs/2205.14209v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Diffusion-LM Improves Controllable Text Generation", "abstract": "Controlling the behavior of language models (LMs) without re-training is a\nmajor open problem in natural language generation. While recent works have\ndemonstrated successes on controlling simple sentence attributes (e.g.,\nsentiment), there has been little progress on complex, fine-grained controls\n(e.g., syntactic structure). To address this challenge, we develop a new\nnon-autoregressive language model based on continuous diffusions that we call\nDiffusion-LM. Building upon the recent successes of diffusion models in\ncontinuous domains, Diffusion-LM iteratively denoises a sequence of Gaussian\nvectors into word vectors, yielding a sequence of intermediate latent\nvariables. The continuous, hierarchical nature of these intermediate variables\nenables a simple gradient-based algorithm to perform complex, controllable\ngeneration tasks. We demonstrate successful control of Diffusion-LM for six\nchallenging fine-grained control tasks, significantly outperforming prior work.", "published": "2022-05-27 20:12:09", "link": "http://arxiv.org/abs/2205.14217v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TURJUMAN: A Public Toolkit for Neural Arabic Machine Translation", "abstract": "We present TURJUMAN, a neural toolkit for translating from 20 languages into\nModern Standard Arabic (MSA). TURJUMAN exploits the recently-introduced\ntext-to-text Transformer AraT5 model, endowing it with a powerful ability to\ndecode into Arabic. The toolkit offers the possibility of employing a number of\ndiverse decoding methods, making it suited for acquiring paraphrases for the\nMSA translations as an added value. To train TURJUMAN, we sample from publicly\navailable parallel data employing a simple semantic similarity method to ensure\ndata quality. This allows us to prepare and release AraOPUS-20, a new machine\ntranslation benchmark. We publicly release our translation toolkit (TURJUMAN)\nas well as our benchmark dataset (AraOPUS-20).", "published": "2022-05-27 18:05:50", "link": "http://arxiv.org/abs/2206.03933v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Multi-modal Protein Knowledge Graph Construction and Applications", "abstract": "Existing data-centric methods for protein science generally cannot\nsufficiently capture and leverage biology knowledge, which may be crucial for\nmany protein tasks. To facilitate research in this field, we create\nProteinKG65, a knowledge graph for protein science. Using gene ontology and\nUniprot knowledge base as a basis, we transform and integrate various kinds of\nknowledge with aligned descriptions and protein sequences, respectively, to GO\nterms and protein entities. ProteinKG65 is mainly dedicated to providing a\nspecialized protein knowledge graph, bringing the knowledge of Gene Ontology to\nprotein function and structure prediction. We also illustrate the potential\napplications of ProteinKG65 with a prototype. Our dataset can be downloaded at\nhttps://w3id.org/proteinkg65.", "published": "2022-05-27 08:18:56", "link": "http://arxiv.org/abs/2207.10080v3", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "q-bio.QM"}
{"title": "Acoustic-to-articulatory Speech Inversion with Multi-task Learning", "abstract": "Multi-task learning (MTL) frameworks have proven to be effective in diverse\nspeech related tasks like automatic speech recognition (ASR) and speech emotion\nrecognition. This paper proposes a MTL framework to perform\nacoustic-to-articulatory speech inversion by simultaneously learning an\nacoustic to phoneme mapping as a shared task. We use the Haskins Production\nRate Comparison (HPRC) database which has both the electromagnetic\narticulography (EMA) data and the corresponding phonetic transcriptions.\nPerformance of the system was measured by computing the correlation between\nestimated and actual tract variables (TVs) from the acoustic to articulatory\nspeech inversion task. The proposed MTL based Bidirectional Gated Recurrent\nNeural Network (RNN) model learns to map the input acoustic features to nine\nTVs while outperforming the baseline model trained to perform only acoustic to\narticulatory inversion.", "published": "2022-05-27 03:52:25", "link": "http://arxiv.org/abs/2205.13755v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Speaker-conditioning Single-channel Target Speaker Extraction using\n  Conformer-based Architectures", "abstract": "Target speaker extraction aims at extracting the target speaker from a\nmixture of multiple speakers exploiting auxiliary information about the target\nspeaker. In this paper, we consider a complete time-domain target speaker\nextraction system consisting of a speaker embedder network and a speaker\nseparator network which are jointly trained in an end-to-end learning process.\nWe propose two different architectures for the speaker separator network which\nare based on the convolutional augmented transformer (conformer). The first\narchitecture uses stacks of conformer and external feed-forward blocks\n(Conformer-FFN), while the second architecture uses stacks of temporal\nconvolutional network (TCN) and conformer blocks (TCN-Conformer). Experimental\nresults for 2-speaker mixtures, 3-speaker mixtures, and noisy mixtures of\n2-speakers show that among the proposed separator networks, the TCN-Conformer\nsignificantly improves the target speaker extraction performance compared to\nthe Conformer-FFN and a TCN-based baseline system.", "published": "2022-05-27 09:27:19", "link": "http://arxiv.org/abs/2205.13851v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Adversarial attacks and defenses in Speaker Recognition Systems: A\n  survey", "abstract": "Speaker recognition has become very popular in many application scenarios,\nsuch as smart homes and smart assistants, due to ease of use for remote control\nand economic-friendly features. The rapid development of SRSs is inseparable\nfrom the advancement of machine learning, especially neural networks. However,\nprevious work has shown that machine learning models are vulnerable to\nadversarial attacks in the image domain, which inspired researchers to explore\nadversarial attacks and defenses in Speaker Recognition Systems (SRS).\nUnfortunately, existing literature lacks a thorough review of this topic. In\nthis paper, we fill this gap by performing a comprehensive survey on\nadversarial attacks and defenses in SRSs. We first introduce the basics of SRSs\nand concepts related to adversarial attacks. Then, we propose two sets of\ncriteria to evaluate the performance of attack methods and defense methods in\nSRSs, respectively. After that, we provide taxonomies of existing attack\nmethods and defense methods, and further review them by employing our proposed\ncriteria. Finally, based on our review, we find some open issues and further\nspecify a number of future directions to motivate the research of SRSs\nsecurity.", "published": "2022-05-27 00:14:29", "link": "http://arxiv.org/abs/2205.13685v1", "categories": ["cs.CR", "cs.SD", "eess.AS", "A.1"], "primary_category": "cs.CR"}
{"title": "MIMII DG: Sound Dataset for Malfunctioning Industrial Machine\n  Investigation and Inspection for Domain Generalization Task", "abstract": "We present a machine sound dataset to benchmark domain generalization\ntechniques for anomalous sound detection (ASD). Domain shifts are differences\nin data distributions that can degrade the detection performance, and handling\nthem is a major issue for the application of ASD systems. While currently\navailable datasets for ASD tasks assume that occurrences of domain shifts are\nknown, in practice, they can be difficult to detect. To handle such domain\nshifts, domain generalization techniques that perform well regardless of the\ndomains should be investigated. In this paper, we present the first ASD dataset\nfor the domain generalization techniques, called MIMII DG. The dataset consists\nof five machine types and three domain shift scenarios for each machine type.\nThe dataset is dedicated to the domain generalization task with features such\nas multiple different values for parameters that cause domain shifts and\nintroduction of domain shifts that can be difficult to detect, such as shifts\nin the background noise. Experimental results using two baseline systems\nindicate that the dataset reproduces domain shift scenarios and is useful for\nbenchmarking domain generalization techniques.", "published": "2022-05-27 10:19:16", "link": "http://arxiv.org/abs/2205.13879v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
