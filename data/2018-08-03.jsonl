{"title": "Efficient Purely Convolutional Text Encoding", "abstract": "In this work, we focus on a lightweight convolutional architecture that\ncreates fixed-size vector embeddings of sentences. Such representations are\nuseful for building NLP systems, including conversational agents. Our work\nderives from a recently proposed recursive convolutional architecture for\nauto-encoding text paragraphs at byte level. We propose alternations that\nsignificantly reduce training time, the number of parameters, and improve\nauto-encoding accuracy. Finally, we evaluate the representations created by our\nmodel on tasks from SentEval benchmark suite, and show that it can serve as a\nbetter, yet fairly low-resource alternative to popular bag-of-words embeddings.", "published": "2018-08-03 11:31:26", "link": "http://arxiv.org/abs/1808.01160v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Multi-task Ensemble Framework for Emotion, Sentiment and Intensity\n  Prediction", "abstract": "In this paper, through multi-task ensemble framework we address three\nproblems of emotion and sentiment analysis i.e. \"emotion classification &\nintensity\", \"valence, arousal & dominance for emotion\" and \"valence & arousal}\nfor sentiment\". The underlying problems cover two granularities (i.e.\ncoarse-grained and fine-grained) and a diverse range of domains (i.e. tweets,\nFacebook posts, news headlines, blogs, letters etc.). The ensemble model aims\nto leverage the learned representations of three deep learning models (i.e.\nCNN, LSTM and GRU) and a hand-crafted feature representation for the\npredictions. Experimental results on the benchmark datasets show the efficacy\nof our proposed multi-task ensemble frameworks. We obtain the performance\nimprovement of 2-3 points on an average over single-task systems for most of\nthe problems and domains.", "published": "2018-08-03 14:58:55", "link": "http://arxiv.org/abs/1808.01216v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Did you take the pill? - Detecting Personal Intake of Medicine from\n  Twitter", "abstract": "Mining social media messages such as tweets, articles, and Facebook posts for\nhealth and drug related information has received significant interest in\npharmacovigilance research. Social media sites (e.g., Twitter), have been used\nfor monitoring drug abuse, adverse reactions of drug usage and analyzing\nexpression of sentiments related to drugs. Most of these studies are based on\naggregated results from a large population rather than specific sets of\nindividuals. In order to conduct studies at an individual level or specific\ncohorts, identifying posts mentioning intake of medicine by the user is\nnecessary. Towards this objective we develop a classifier for identifying\nmentions of personal intake of medicine in tweets. We train a stacked ensemble\nof shallow convolutional neural network (CNN) models on an annotated dataset.\nWe use random search for tuning the hyper-parameters of the CNN models and\npresent an ensemble of best models for the prediction task. Our system produces\nstate-of-the-art result, with a micro-averaged F-score of 0.693. We believe\nthat the developed classifier has direct uses in the areas of psychology,\nhealth informatics, pharmacovigilance and affective computing for tracking\nmoods, emotions and sentiments of patients expressing intake of medicine in\nsocial media.", "published": "2018-08-03 02:39:38", "link": "http://arxiv.org/abs/1808.02082v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Content-driven, unsupervised clustering of news articles through\n  multiscale graph partitioning", "abstract": "The explosion in the amount of news and journalistic content being generated\nacross the globe, coupled with extended and instantaneous access to information\nthrough online media, makes it difficult and time-consuming to monitor news\ndevelopments and opinion formation in real time. There is an increasing need\nfor tools that can pre-process, analyse and classify raw text to extract\ninterpretable content; specifically, identifying topics and content-driven\ngroupings of articles. We present here such a methodology that brings together\npowerful vector embeddings from Natural Language Processing with tools from\nGraph Theory that exploit diffusive dynamics on graphs to reveal natural\npartitions across scales. Our framework uses a recent deep neural network text\nanalysis methodology (Doc2vec) to represent text in vector form and then\napplies a multi-scale community detection method (Markov Stability) to\npartition a similarity graph of document vectors. The method allows us to\nobtain clusters of documents with similar content, at different levels of\nresolution, in an unsupervised manner. We showcase our approach with the\nanalysis of a corpus of 9,000 news articles published by Vox Media over one\nyear. Our results show consistent groupings of documents according to content\nwithout a priori assumptions about the number or type of clusters to be found.\nThe multilevel clustering reveals a quasi-hierarchy of topics and subtopics\nwith increased intelligibility and improved topic coherence as compared to\nexternal taxonomy services and standard topic detection methods.", "published": "2018-08-03 12:57:15", "link": "http://arxiv.org/abs/1808.01175v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "math.SP"], "primary_category": "cs.CL"}
{"title": "Large Scale Language Modeling: Converging on 40GB of Text in Four Hours", "abstract": "Recent work has shown how to train Convolutional Neural Networks (CNNs)\nrapidly on large image datasets, then transfer the knowledge gained from these\nmodels to a variety of tasks. Following [Radford 2017], in this work, we\ndemonstrate similar scalability and transfer for Recurrent Neural Networks\n(RNNs) for Natural Language tasks. By utilizing mixed precision arithmetic and\na 32k batch size distributed across 128 NVIDIA Tesla V100 GPUs, we are able to\ntrain a character-level 4096-dimension multiplicative LSTM (mLSTM) for\nunsupervised text reconstruction over 3 epochs of the 40 GB Amazon Reviews\ndataset in four hours. This runtime compares favorably with previous work\ntaking one month to train the same size and configuration for one epoch over\nthe same dataset. Converging large batch RNN models can be challenging. Recent\nwork has suggested scaling the learning rate as a function of batch size, but\nwe find that simply scaling the learning rate as a function of batch size leads\neither to significantly worse convergence or immediate divergence for this\nproblem. We provide a learning rate schedule that allows our model to converge\nwith a 32k batch size. Since our model converges over the Amazon Reviews\ndataset in hours, and our compute requirement of 128 Tesla V100 GPUs, while\nsubstantial, is commercially available, this work opens up large scale\nunsupervised NLP training to most commercial applications and deep learning\nresearchers. A model can be trained over most public or private text datasets\novernight.", "published": "2018-08-03 21:44:29", "link": "http://arxiv.org/abs/1808.01371v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Visual Reasoning with Multi-hop Feature Modulation", "abstract": "Recent breakthroughs in computer vision and natural language processing have\nspurred interest in challenging multi-modal tasks such as visual\nquestion-answering and visual dialogue. For such tasks, one successful approach\nis to condition image-based convolutional network computation on language via\nFeature-wise Linear Modulation (FiLM) layers, i.e., per-channel scaling and\nshifting. We propose to generate the parameters of FiLM layers going up the\nhierarchy of a convolutional network in a multi-hop fashion rather than all at\nonce, as in prior work. By alternating between attending to the language input\nand generating FiLM layer parameters, this approach is better able to scale to\nsettings with longer input sequences such as dialogue. We demonstrate that\nmulti-hop FiLM generation achieves state-of-the-art for the short input\nsequence task ReferIt --- on-par with single-hop FiLM generation --- while also\nsignificantly outperforming prior state-of-the-art and single-hop FiLM\ngeneration on the GuessWhat?! visual dialogue task.", "published": "2018-08-03 14:32:02", "link": "http://arxiv.org/abs/1808.04446v2", "categories": ["cs.CV", "cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CV"}
