{"title": "SuperCaptioning: Image Captioning Using Two-dimensional Word Embedding", "abstract": "Language and vision are processed as two different modal in current work for\nimage captioning. However, recent work on Super Characters method shows the\neffectiveness of two-dimensional word embedding, which converts text\nclassification problem into image classification problem. In this paper, we\npropose the SuperCaptioning method, which borrows the idea of two-dimensional\nword embedding from Super Characters method, and processes the information of\nlanguage and vision together in one single CNN model. The experimental results\non Flickr30k data shows the proposed method gives high quality image captions.\nAn interactive demo is ready to show at the workshop.", "published": "2019-05-25 03:57:16", "link": "http://arxiv.org/abs/1905.10515v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Soft Contextual Data Augmentation for Neural Machine Translation", "abstract": "While data augmentation is an important trick to boost the accuracy of deep\nlearning methods in computer vision tasks, its study in natural language tasks\nis still very limited. In this paper, we present a novel data augmentation\nmethod for neural machine translation. Different from previous augmentation\nmethods that randomly drop, swap or replace words with other words in a\nsentence, we softly augment a randomly chosen word in a sentence by its\ncontextual mixture of multiple related words. More accurately, we replace the\none-hot representation of a word by a distribution (provided by a language\nmodel) over the vocabulary, i.e., replacing the embedding of this word by a\nweighted combination of multiple semantically similar words. Since the weights\nof those words depend on the contextual information of the word to be replaced,\nthe newly generated sentences capture much richer information than previous\naugmentation methods. Experimental results on both small scale and large scale\nmachine translation datasets demonstrate the superiority of our method over\nstrong baselines.", "published": "2019-05-25 05:28:03", "link": "http://arxiv.org/abs/1905.10523v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Sixteen Heads Really Better than One?", "abstract": "Attention is a powerful and ubiquitous mechanism for allowing neural models\nto focus on particular salient pieces of information by taking their weighted\naverage when making predictions. In particular, multi-headed attention is a\ndriving force behind many recent state-of-the-art NLP models such as\nTransformer-based MT models and BERT. These models apply multiple attention\nmechanisms in parallel, with each attention \"head\" potentially focusing on\ndifferent parts of the input, which makes it possible to express sophisticated\nfunctions beyond the simple weighted average. In this paper we make the\nsurprising observation that even if models have been trained using multiple\nheads, in practice, a large percentage of attention heads can be removed at\ntest time without significantly impacting performance. In fact, some layers can\neven be reduced to a single head. We further examine greedy algorithms for\npruning down models, and the potential speed, memory efficiency, and accuracy\nimprovements obtainable therefrom. Finally, we analyze the results with respect\nto which parts of the model are more reliant on having multiple heads, and\nprovide precursory evidence that training dynamics play a role in the gains\nprovided by multi-head attention.", "published": "2019-05-25 18:27:28", "link": "http://arxiv.org/abs/1905.10650v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ESA: Entity Summarization with Attention", "abstract": "Entity summarization aims at creating brief but informative descriptions of\nentities from knowledge graphs. While previous work mostly focused on\ntraditional techniques such as clustering algorithms and graph models, we ask\nhow to apply deep learning methods into this task. In this paper we propose\nESA, a neural network with supervised attention mechanisms for entity\nsummarization. Specifically, we calculate attention weights for facts in each\nentity, and rank facts to generate reliable summaries. We explore techniques to\nsolve difficult learning problems presented by the ESA, and demonstrate the\neffectiveness of our model in comparison with the state-of-the-art methods.\nExperimental results show that our model improves the quality of the entity\nsummaries in both F-measure and MAP.", "published": "2019-05-25 16:06:42", "link": "http://arxiv.org/abs/1905.10625v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Triple-to-Text: Converting RDF Triples into High-Quality Natural\n  Languages via Optimizing an Inverse KL Divergence", "abstract": "Knowledge base is one of the main forms to represent information in a\nstructured way. A knowledge base typically consists of Resource Description\nFrameworks (RDF) triples which describe the entities and their relations.\nGenerating natural language description of the knowledge base is an important\ntask in NLP, which has been formulated as a conditional language generation\ntask and tackled using the sequence-to-sequence framework. Current works mostly\ntrain the language models by maximum likelihood estimation, which tends to\ngenerate lousy sentences. In this paper, we argue that such a problem of\nmaximum likelihood estimation is intrinsic, which is generally irrevocable via\nchanging network structures. Accordingly, we propose a novel Triple-to-Text\n(T2T) framework, which approximately optimizes the inverse Kullback-Leibler\n(KL) divergence between the distributions of the real and generated sentences.\nDue to the nature that inverse KL imposes large penalty on fake-looking\nsamples, the proposed method can significantly reduce the probability of\ngenerating low-quality sentences. Our experiments on three real-world datasets\ndemonstrate that T2T can generate higher-quality sentences and outperform\nbaseline models in several evaluation metrics.", "published": "2019-05-25 03:05:15", "link": "http://arxiv.org/abs/1906.01965v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Exposure Bias versus Self-Recovery: Are Distortions Really Incremental\n  for Autoregressive Text Generation?", "abstract": "Exposure bias has been regarded as a central problem for auto-regressive\nlanguage models (LM). It claims that teacher forcing would cause the test-time\ngeneration to be incrementally distorted due to the training-generation\ndiscrepancy. Although a lot of algorithms have been proposed to avoid teacher\nforcing and therefore alleviate exposure bias, there is little work showing how\nserious the exposure bias problem actually is. In this work, we focus on the\ntask of open-ended language generation, propose metrics to quantify the impact\nof exposure bias in the aspects of quality, diversity, and consistency. Our key\nintuition is that if we feed ground-truth data prefixes (instead of prefixes\ngenerated by the model itself) into the model and ask it to continue the\ngeneration, the performance should become much better because the\ntraining-generation discrepancy in the prefix is removed. Both automatic and\nhuman evaluations are conducted in our experiments. On the contrary to the\npopular belief in exposure bias, we find that the the distortion induced by the\nprefix discrepancy is limited, and does not seem to be incremental during the\ngeneration. Moreover, our analysis reveals an interesting self-recovery ability\nof the LM, which we hypothesize to be countering the harmful effects from\nexposure bias.", "published": "2019-05-25 15:34:43", "link": "http://arxiv.org/abs/1905.10617v10", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MDE: Multiple Distance Embeddings for Link Prediction in Knowledge\n  Graphs", "abstract": "Over the past decade, knowledge graphs became popular for capturing\nstructured domain knowledge. Relational learning models enable the prediction\nof missing links inside knowledge graphs. More specifically, latent distance\napproaches model the relationships among entities via a distance between latent\nrepresentations. Translating embedding models (e.g., TransE) are among the most\npopular latent distance approaches which use one distance function to learn\nmultiple relation patterns. However, they are mostly inefficient in capturing\nsymmetric relations since the representation vector norm for all the symmetric\nrelations becomes equal to zero. They also lose information when learning\nrelations with reflexive patterns since they become symmetric and transitive.\nWe propose the Multiple Distance Embedding model (MDE) that addresses these\nlimitations and a framework to collaboratively combine variant latent\ndistance-based terms. Our solution is based on two principles: 1) we use a\nlimit-based loss instead of a margin ranking loss and, 2) by learning\nindependent embedding vectors for each of the terms we can collectively train\nand predict using contradicting distance terms. We further demonstrate that MDE\nallows modeling relations with (anti)symmetry, inversion, and composition\npatterns. We propose MDE as a neural network model that allows us to map\nnon-linear relations between the embedding vectors and the expected output of\nthe score function. Our empirical results show that MDE performs competitively\nto state-of-the-art embedding models on several benchmark datasets.", "published": "2019-05-25 23:48:00", "link": "http://arxiv.org/abs/1905.10702v8", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "SemEval-2019 Task 8: Fact Checking in Community Question Answering\n  Forums", "abstract": "We present SemEval-2019 Task 8 on Fact Checking in Community Question\nAnswering Forums, which features two subtasks. Subtask A is about deciding\nwhether a question asks for factual information vs. an opinion/advice vs. just\nsocializing. Subtask B asks to predict whether an answer to a factual question\nis true, false or not a proper answer. We received 17 official submissions for\nsubtask A and 11 official submissions for Subtask B. For subtask A, all systems\nimproved over the majority class baseline. For Subtask B, all systems were\nbelow a majority class baseline, but several systems were very close to it. The\nleaderboard and the data from the competition can be found at\nhttp://competitions.codalab.org/competitions/20022", "published": "2019-05-25 16:46:49", "link": "http://arxiv.org/abs/1906.01727v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "ArSentD-LEV: A Multi-Topic Corpus for Target-based Sentiment Analysis in\n  Arabic Levantine Tweets", "abstract": "Sentiment analysis is a highly subjective and challenging task. Its\ncomplexity further increases when applied to the Arabic language, mainly\nbecause of the large variety of dialects that are unstandardized and widely\nused in the Web, especially in social media. While many datasets have been\nreleased to train sentiment classifiers in Arabic, most of these datasets\ncontain shallow annotation, only marking the sentiment of the text unit, as a\nword, a sentence or a document. In this paper, we present the Arabic Sentiment\nTwitter Dataset for the Levantine dialect (ArSenTD-LEV). Based on findings from\nanalyzing tweets from the Levant region, we created a dataset of 4,000 tweets\nwith the following annotations: the overall sentiment of the tweet, the target\nto which the sentiment was expressed, how the sentiment was expressed, and the\ntopic of the tweet. Results confirm the importance of these annotations at\nimproving the performance of a baseline sentiment classifier. They also confirm\nthe gap of training in a certain domain, and testing in another domain.", "published": "2019-05-25 13:31:52", "link": "http://arxiv.org/abs/1906.01830v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Reconstructing faces from voices", "abstract": "Voice profiling aims at inferring various human parameters from their speech,\ne.g. gender, age, etc. In this paper, we address the challenge posed by a\nsubtask of voice profiling - reconstructing someone's face from their voice.\nThe task is designed to answer the question: given an audio clip spoken by an\nunseen person, can we picture a face that has as many common elements, or\nassociations as possible with the speaker, in terms of identity? To address\nthis problem, we propose a simple but effective computational framework based\non generative adversarial networks (GANs). The network learns to generate faces\nfrom voices by matching the identities of generated faces to those of the\nspeakers, on a training set. We evaluate the performance of the network by\nleveraging a closely related task - cross-modal matching. The results show that\nour model is able to generate faces that match several biometric\ncharacteristics of the speaker, and results in matching accuracies that are\nmuch better than chance.", "published": "2019-05-25 14:33:59", "link": "http://arxiv.org/abs/1905.10604v2", "categories": ["cs.SD", "cs.CV", "cs.LG", "eess.AS", "eess.IV"], "primary_category": "cs.SD"}
