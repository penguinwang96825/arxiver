{"title": "MasonTigers at SemEval-2024 Task 10: Emotion Discovery and Flip\n  Reasoning in Conversation with Ensemble of Transformers and Prompting", "abstract": "In this paper, we present MasonTigers' participation in SemEval-2024 Task 10,\na shared task aimed at identifying emotions and understanding the rationale\nbehind their flips within monolingual English and Hindi-English code-mixed\ndialogues. This task comprises three distinct subtasks - emotion recognition in\nconversation for Hindi-English code-mixed dialogues, emotion flip reasoning for\nHindi-English code-mixed dialogues, and emotion flip reasoning for English\ndialogues. Our team, MasonTigers, contributed to each subtask, focusing on\ndeveloping methods for accurate emotion recognition and reasoning. By\nleveraging our approaches, we attained impressive F1-scores of 0.78 for the\nfirst task and 0.79 for both the second and third tasks. This performance not\nonly underscores the effectiveness of our methods across different aspects of\nthe task but also secured us the top rank in the first and third subtasks, and\nthe 2nd rank in the second subtask. Through extensive experimentation and\nanalysis, we provide insights into our system's performance and contributions\nto each subtask.", "published": "2024-06-30 03:59:04", "link": "http://arxiv.org/abs/2407.00581v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DP-MLM: Differentially Private Text Rewriting Using Masked Language\n  Models", "abstract": "The task of text privatization using Differential Privacy has recently taken\nthe form of $\\textit{text rewriting}$, in which an input text is obfuscated via\nthe use of generative (large) language models. While these methods have shown\npromising results in the ability to preserve privacy, these methods rely on\nautoregressive models which lack a mechanism to contextualize the private\nrewriting process. In response to this, we propose $\\textbf{DP-MLM}$, a new\nmethod for differentially private text rewriting based on leveraging masked\nlanguage models (MLMs) to rewrite text in a semantically similar $\\textit{and}$\nobfuscated manner. We accomplish this with a simple contextualization\ntechnique, whereby we rewrite a text one token at a time. We find that\nutilizing encoder-only MLMs provides better utility preservation at lower\n$\\varepsilon$ levels, as compared to previous methods relying on larger models\nwith a decoder. In addition, MLMs allow for greater customization of the\nrewriting mechanism, as opposed to generative approaches. We make the code for\n$\\textbf{DP-MLM}$ public and reusable, found at https://github.com/sjmeis/DPMLM .", "published": "2024-06-30 09:31:01", "link": "http://arxiv.org/abs/2407.00637v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Collocation-based Method for Addressing Challenges in Word-level\n  Metric Differential Privacy", "abstract": "Applications of Differential Privacy (DP) in NLP must distinguish between the\nsyntactic level on which a proposed mechanism operates, often taking the form\nof $\\textit{word-level}$ or $\\textit{document-level}$ privatization. Recently,\nseveral word-level $\\textit{Metric}$ Differential Privacy approaches have been\nproposed, which rely on this generalized DP notion for operating in word\nembedding spaces. These approaches, however, often fail to produce semantically\ncoherent textual outputs, and their application at the sentence- or\ndocument-level is only possible by a basic composition of word perturbations.\nIn this work, we strive to address these challenges by operating\n$\\textit{between}$ the word and sentence levels, namely with\n$\\textit{collocations}$. By perturbing n-grams rather than single words, we\ndevise a method where composed privatized outputs have higher semantic\ncoherence and variable length. This is accomplished by constructing an\nembedding model based on frequently occurring word groups, in which unigram\nwords co-exist with bi- and trigram collocations. We evaluate our method in\nutility and privacy tests, which make a clear case for tokenization strategies\nbeyond the word level.", "published": "2024-06-30 09:37:34", "link": "http://arxiv.org/abs/2407.00638v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LegalTurk Optimized BERT for Multi-Label Text Classification and NER", "abstract": "The introduction of the Transformer neural network, along with techniques\nlike self-supervised pre-training and transfer learning, has paved the way for\nadvanced models like BERT. Despite BERT's impressive performance, opportunities\nfor further enhancement exist. To our knowledge, most efforts are focusing on\nimproving BERT's performance in English and in general domains, with no study\nspecifically addressing the legal Turkish domain. Our study is primarily\ndedicated to enhancing the BERT model within the legal Turkish domain through\nmodifications in the pre-training phase. In this work, we introduce our\ninnovative modified pre-training approach by combining diverse masking\nstrategies. In the fine-tuning task, we focus on two essential downstream tasks\nin the legal domain: name entity recognition and multi-label text\nclassification. To evaluate our modified pre-training approach, we fine-tuned\nall customized models alongside the original BERT models to compare their\nperformance. Our modified approach demonstrated significant improvements in\nboth NER and multi-label text classification tasks compared to the original\nBERT model. Finally, to showcase the impact of our proposed models, we trained\nour best models with different corpus sizes and compared them with BERTurk\nmodels. The experimental results demonstrate that our innovative approach,\ndespite being pre-trained on a smaller corpus, competes with BERTurk.", "published": "2024-06-30 10:19:54", "link": "http://arxiv.org/abs/2407.00648v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HRDE: Retrieval-Augmented Large Language Models for Chinese Health Rumor\n  Detection and Explainability", "abstract": "As people increasingly prioritize their health, the speed and breadth of\nhealth information dissemination on the internet have also grown. At the same\ntime, the presence of false health information (health rumors) intermingled\nwith genuine content poses a significant potential threat to public health.\nHowever, current research on Chinese health rumors still lacks a large-scale,\npublic, and open-source dataset of health rumor information, as well as\neffective and reliable rumor detection methods. This paper addresses this gap\nby constructing a dataset containing 1.12 million health-related rumors\n(HealthRCN) through web scraping of common health-related questions and a\nseries of data processing steps. HealthRCN is the largest known dataset of\nChinese health information rumors to date. Based on this dataset, we propose\nretrieval-augmented large language models for Chinese health rumor detection\nand explainability (HRDE). This model leverages retrieved relevant information\nto accurately determine whether the input health information is a rumor and\nprovides explanatory responses, effectively aiding users in verifying the\nauthenticity of health information. In evaluation experiments, we compared\nmultiple models and found that HRDE outperformed them all, including\nGPT-4-1106-Preview, in rumor detection accuracy and answer quality. HRDE\nachieved an average accuracy of 91.04% and an F1 score of 91.58%.", "published": "2024-06-30 11:27:50", "link": "http://arxiv.org/abs/2407.00668v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Technology Acceptance Analysis with Large Language Model (LLM)\n  Annotation Systems", "abstract": "Technology acceptance models effectively predict how users will adopt new\ntechnology products. Traditional surveys, often expensive and cumbersome, are\ncommonly used for this assessment. As an alternative to surveys, we explore the\nuse of large language models for annotating online user-generated content, like\ndigital reviews and comments. Our research involved designing an LLM annotation\nsystem that transform reviews into structured data based on the Unified Theory\nof Acceptance and Use of Technology model. We conducted two studies to validate\nthe consistency and accuracy of the annotations. Results showed\nmoderate-to-strong consistency of LLM annotation systems, improving further by\nlowering the model temperature. LLM annotations achieved close agreement with\nhuman expert annotations and outperformed the agreement between experts for\nUTAUT variables. These results suggest that LLMs can be an effective tool for\nanalyzing user sentiment, offering a practical alternative to traditional\nsurvey methods and enabling deeper insights into technology design and\nadoption.", "published": "2024-06-30 14:01:06", "link": "http://arxiv.org/abs/2407.00702v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical\n  Reasoning", "abstract": "Direct Preference Optimization (DPO) has proven effective at improving the\nperformance of large language models (LLMs) on downstream tasks such as\nreasoning and alignment. In this work, we propose Step-Controlled DPO (SCDPO),\na method for automatically providing stepwise error supervision by creating\nnegative samples of mathematical reasoning rationales that start making errors\nat a specified step. By applying these samples in DPO training, SCDPO can\nbetter align the model to understand reasoning errors and output accurate\nreasoning steps. We apply SCDPO to both code-integrated and chain-of-thought\nsolutions, empirically showing that it consistently improves the performance\ncompared to naive DPO on three different SFT models, including one existing SFT\nmodel and two models we finetuned. Qualitative analysis of the credit\nassignment of SCDPO and DPO demonstrates the effectiveness of SCDPO at\nidentifying errors in mathematical solutions. We then apply SCDPO to an\nInternLM2-20B model, resulting in a 20B model that achieves high scores of\n88.5% on GSM8K and 58.1% on MATH, rivaling all other open-source LLMs, showing\nthe great potential of our method.", "published": "2024-06-30 17:59:07", "link": "http://arxiv.org/abs/2407.00782v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language\n  Models by Learning from Knowledge Graphs", "abstract": "Large Language Models (LLMs) have exhibited impressive proficiency in various\nnatural language processing (NLP) tasks, which involve increasingly complex\nreasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving\nnew knowledge from existing one.While it has been widely studied in the context\nof knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.\nIn this paper, we introduce Chain-of-Knowledge, a comprehensive framework for\nknowledge reasoning, including methodologies for both dataset construction and\nmodel learning. For dataset construction, we create KnowReason via rule mining\non KGs. For model learning, we observe rule overfitting induced by naive\ntraining. Hence, we enhance CoK with a trial-and-error mechanism that simulates\nthe human process of internal knowledge exploration. We conduct extensive\nexperiments with KnowReason. Our results show the effectiveness of CoK in\nrefining LLMs in not only knowledge reasoning, but also general reasoning\nbenchmarkms.", "published": "2024-06-30 10:49:32", "link": "http://arxiv.org/abs/2407.00653v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Locate&Edit: Energy-based Text Editing for Efficient, Flexible, and\n  Faithful Controlled Text Generation", "abstract": "Recent approaches to controlled text generation (CTG) often involve\nmanipulating the weights or logits of base language models (LMs) at decoding\ntime. However, these methods are inapplicable to latest black-box LMs and\nineffective at preserving the core semantics of the base LM's original\ngenerations. In this work, we propose Locate&Edit(L&E), an efficient and\nflexible energy-based approach to CTG, which edits text outputs from a base LM\nusing off-the-shelf energy models. Given text outputs from the base LM, L&E\nfirst locates spans that are most relevant to constraints (e.g., toxicity)\nutilizing energy models, and then edits these spans by replacing them with more\nsuitable alternatives. Importantly, our method is compatible with black-box\nLMs, as it requires only the text outputs. Also, since L&E doesn't mandate\nspecific architecture for its component models, it can work with a diverse\ncombination of available off-the-shelf models. Moreover, L&E preserves the base\nLM's original generations, by selectively modifying constraint-related aspects\nof the texts and leaving others unchanged. These targeted edits also ensure\nthat L&E operates efficiently. Our experiments confirm that L&E achieves\nsuperior semantic preservation of the base LM generations and speed, while\nsimultaneously obtaining competitive or improved constraint satisfaction.\nFurthermore, we analyze how the granularity of energy distribution impacts CTG\nperformance and find that fine-grained, regression-based energy models improve\nconstraint satisfaction, compared to conventional binary classifier energy\nmodels.", "published": "2024-06-30 16:04:29", "link": "http://arxiv.org/abs/2407.00740v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Comparative Study of Quality Evaluation Methods for Text Summarization", "abstract": "Evaluating text summarization has been a challenging task in natural language\nprocessing (NLP). Automatic metrics which heavily rely on reference summaries\nare not suitable in many situations, while human evaluation is time-consuming\nand labor-intensive. To bridge this gap, this paper proposes a novel method\nbased on large language models (LLMs) for evaluating text summarization. We\nalso conducts a comparative study on eight automatic metrics, human evaluation,\nand our proposed LLM-based method. Seven different types of state-of-the-art\n(SOTA) summarization models were evaluated. We perform extensive experiments\nand analysis on datasets with patent documents. Our results show that LLMs\nevaluation aligns closely with human evaluation, while widely-used automatic\nmetrics such as ROUGE-2, BERTScore, and SummaC do not and also lack\nconsistency. Based on the empirical comparison, we propose a LLM-powered\nframework for automatically evaluating and improving text summarization, which\nis beneficial and could attract wide attention among the community.", "published": "2024-06-30 16:12:37", "link": "http://arxiv.org/abs/2407.00747v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Characterizing Stereotypical Bias from Privacy-preserving Pre-Training", "abstract": "Differential Privacy (DP) can be applied to raw text by exploiting the\nspatial arrangement of words in an embedding space. We investigate the\nimplications of such text privatization on Language Models (LMs) and their\ntendency towards stereotypical associations. Since previous studies documented\nthat linguistic proficiency correlates with stereotypical bias, one could\nassume that techniques for text privatization, which are known to degrade\nlanguage modeling capabilities, would cancel out undesirable biases. By testing\nBERT models trained on texts containing biased statements primed with varying\ndegrees of privacy, our study reveals that while stereotypical bias generally\ndiminishes when privacy is tightened, text privatization does not uniformly\nequate to diminishing bias across all social domains. This highlights the need\nfor careful diagnosis of bias in LMs that undergo text privatization.", "published": "2024-06-30 16:54:43", "link": "http://arxiv.org/abs/2407.00764v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating and Mitigating the Multimodal Hallucination Snowballing in\n  Large Vision-Language Models", "abstract": "Though advanced in understanding visual information with human languages,\nLarge Vision-Language Models (LVLMs) still suffer from multimodal\nhallucinations. A natural concern is that during multimodal interaction, the\ngenerated hallucinations could influence the LVLMs' subsequent generation.\nThus, we raise a question: When presented with a query relevant to the\npreviously generated hallucination, will LVLMs be misled and respond\nincorrectly, even though the ground visual information exists? To answer this,\nwe propose a framework called MMHalSnowball to evaluate LVLMs' behaviors when\nencountering generated hallucinations, where LVLMs are required to answer\nspecific visual questions within a curated hallucinatory conversation.\nCrucially, our experiment shows that the performance of open-source LVLMs drops\nby at least $31\\%$, indicating that LVLMs are prone to accept the generated\nhallucinations and make false claims that they would not have supported without\ndistractions. We term this phenomenon Multimodal Hallucination Snowballing. To\nmitigate this, we further propose a training-free method called Residual Visual\nDecoding, where we revise the output distribution of LVLMs with the one derived\nfrom the residual visual input, providing models with direct access to the\nvisual information. Experiments show that our method can mitigate more than\n$24\\%$ of the snowballed multimodal hallucination while maintaining\ncapabilities.", "published": "2024-06-30 03:04:11", "link": "http://arxiv.org/abs/2407.00569v4", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Efficient Personalized Text-to-image Generation by Leveraging Textual\n  Subspace", "abstract": "Personalized text-to-image generation has attracted unprecedented attention\nin the recent few years due to its unique capability of generating\nhighly-personalized images via using the input concept dataset and novel\ntextual prompt. However, previous methods solely focus on the performance of\nthe reconstruction task, degrading its ability to combine with different\ntextual prompt. Besides, optimizing in the high-dimensional embedding space\nusually leads to unnecessary time-consuming training process and slow\nconvergence. To address these issues, we propose an efficient method to explore\nthe target embedding in a textual subspace, drawing inspiration from the\nself-expressiveness property. Additionally, we propose an efficient selection\nstrategy for determining the basis vectors of the textual subspace. The\nexperimental evaluations demonstrate that the learned embedding can not only\nfaithfully reconstruct input image, but also significantly improves its\nalignment with novel input textual prompt. Furthermore, we observe that\noptimizing in the textual subspace leads to an significant improvement of the\nrobustness to the initial word, relaxing the constraint that requires users to\ninput the most relevant initial word. Our method opens the door to more\nefficient representation learning for personalized text-to-image generation.", "published": "2024-06-30 06:41:21", "link": "http://arxiv.org/abs/2407.00608v1", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Iterative Nash Policy Optimization: Aligning LLMs with General\n  Preferences via No-Regret Learning", "abstract": "Reinforcement Learning with Human Feedback (RLHF) has achieved great success\nin aligning large language models (LLMs) with human preferences. Prevalent RLHF\napproaches are reward-based, following the Bradley-Terry (BT) model assumption,\nwhich may not fully capture the complexity of human preferences. In this paper,\nwe explore RLHF under a general preference framework and approach it from a\ngame-theoretic perspective. Specifically, we formulate the problem as a\ntwo-player game and propose a novel online algorithm, iterative Nash policy\noptimization (INPO). The key idea is to let the policy play against itself via\nno-regret learning, thereby approximating the Nash policy. Unlike previous\nmethods, INPO bypasses the need for estimating the expected win rate for\nindividual responses, which typically incurs high computational or annotation\ncosts. Instead, we introduce a new loss objective that is directly minimized\nover a preference dataset. We provide theoretical analysis for our approach and\ndemonstrate its effectiveness through experiments on various representative\nbenchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 42.6%\nlength-controlled win rate on AlpacaEval 2.0 and a 37.8% win rate on\nArena-Hard, showing substantial improvement over the state-of-the-art online\nRLHF algorithms.", "published": "2024-06-30 08:00:34", "link": "http://arxiv.org/abs/2407.00617v4", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.GT"], "primary_category": "cs.LG"}
{"title": "CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based\n  Conversations", "abstract": "Visual navigation tasks are critical for household service robots. As these\ntasks become increasingly complex, effective communication and collaboration\namong multiple robots become imperative to ensure successful completion. In\nrecent years, large language models (LLMs) have exhibited remarkable\ncomprehension and planning abilities in the context of embodied agents.\nHowever, their application in household scenarios, specifically in the use of\nmultiple agents collaborating to complete complex navigation tasks through\ncommunication, remains unexplored. Therefore, this paper proposes a framework\nfor decentralized multi-agent navigation, leveraging LLM-enabled communication\nand collaboration. By designing the communication-triggered dynamic leadership\norganization structure, we achieve faster team consensus with fewer\ncommunication instances, leading to better navigation effectiveness and\ncollaborative exploration efficiency. With the proposed novel communication\nscheme, our framework promises to be conflict-free and robust in multi-object\nnavigation tasks, even when there is a surge in team size.", "published": "2024-06-30 09:14:33", "link": "http://arxiv.org/abs/2407.00632v1", "categories": ["cs.RO", "cs.CL", "cs.CV", "cs.MA"], "primary_category": "cs.RO"}
{"title": "BAPO: Base-Anchored Preference Optimization for Overcoming Forgetting in\n  Large Language Models Personalization", "abstract": "While learning to align Large Language Models (LLMs) with human preferences\nhas shown remarkable success, aligning these models to meet the diverse user\npreferences presents further challenges in preserving previous knowledge. This\npaper examines the impact of personalized preference optimization on LLMs,\nrevealing that the extent of knowledge loss varies significantly with\npreference heterogeneity. Although previous approaches have utilized the KL\nconstraint between the reference model and the policy model, we observe that\nthey fail to maintain general knowledge and alignment when facing personalized\npreferences. To this end, we introduce Base-Anchored Preference Optimization\n(BAPO), a simple yet effective approach that utilizes the initial responses of\nreference model to mitigate forgetting while accommodating personalized\nalignment. BAPO effectively adapts to diverse user preferences while minimally\naffecting global knowledge or general alignment. Our experiments demonstrate\nthe efficacy of BAPO in various setups.", "published": "2024-06-30 13:30:04", "link": "http://arxiv.org/abs/2407.00693v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Large Language Models Struggle in Token-Level Clinical Named Entity\n  Recognition", "abstract": "Large Language Models (LLMs) have revolutionized various sectors, including\nhealthcare where they are employed in diverse applications. Their utility is\nparticularly significant in the context of rare diseases, where data scarcity,\ncomplexity, and specificity pose considerable challenges. In the clinical\ndomain, Named Entity Recognition (NER) stands out as an essential task and it\nplays a crucial role in extracting relevant information from clinical texts.\nDespite the promise of LLMs, current research mostly concentrates on\ndocument-level NER, identifying entities in a more general context across\nentire documents, without extracting their precise location. Additionally,\nefforts have been directed towards adapting ChatGPT for token-level NER.\nHowever, there is a significant research gap when it comes to employing\ntoken-level NER for clinical texts, especially with the use of local\nopen-source LLMs. This study aims to bridge this gap by investigating the\neffectiveness of both proprietary and local LLMs in token-level clinical NER.\nEssentially, we delve into the capabilities of these models through a series of\nexperiments involving zero-shot prompting, few-shot prompting,\nretrieval-augmented generation (RAG), and instruction-fine-tuning. Our\nexploration reveals the inherent challenges LLMs face in token-level NER,\nparticularly in the context of rare diseases, and suggests possible\nimprovements for their application in healthcare. This research contributes to\nnarrowing a significant gap in healthcare informatics and offers insights that\ncould lead to a more refined application of LLMs in the healthcare sector.", "published": "2024-06-30 15:38:48", "link": "http://arxiv.org/abs/2407.00731v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NAIST Simultaneous Speech Translation System for IWSLT 2024", "abstract": "This paper describes NAIST's submission to the simultaneous track of the\nIWSLT 2024 Evaluation Campaign: English-to-{German, Japanese, Chinese}\nspeech-to-text translation and English-to-Japanese speech-to-speech\ntranslation. We develop a multilingual end-to-end speech-to-text translation\nmodel combining two pre-trained language models, HuBERT and mBART. We trained\nthis model with two decoding policies, Local Agreement (LA) and AlignAtt. The\nsubmitted models employ the LA policy because it outperformed the AlignAtt\npolicy in previous models. Our speech-to-speech translation method is a cascade\nof the above speech-to-text model and an incremental text-to-speech (TTS)\nmodule that incorporates a phoneme estimation model, a parallel acoustic model,\nand a parallel WaveGAN vocoder. We improved our incremental TTS by applying the\nTransformer architecture with the AlignAtt policy for the estimation model. The\nresults show that our upgraded TTS module contributed to improving the system\nperformance.", "published": "2024-06-30 20:41:02", "link": "http://arxiv.org/abs/2407.00826v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards Robust Speech Representation Learning for Thousands of Languages", "abstract": "Self-supervised learning (SSL) has helped extend speech technologies to more\nlanguages by reducing the need for labeled data. However, models are still far\nfrom supporting the world's 7000+ languages. We propose XEUS, a Cross-lingual\nEncoder for Universal Speech, trained on over 1 million hours of data across\n4057 languages, extending the language coverage of SSL models 4-fold. We\ncombine 1 million hours of speech from existing publicly accessible corpora\nwith a newly created corpus of 7400+ hours from 4057 languages, which will be\npublicly released. To handle the diverse conditions of multilingual speech\ndata, we augment the typical SSL masked prediction approach with a novel\ndereverberation objective, increasing robustness. We evaluate XEUS on several\nbenchmarks, and show that it consistently outperforms or achieves comparable\nresults to state-of-the-art (SOTA) SSL models across a variety of tasks. XEUS\nsets a new SOTA on the ML-SUPERB benchmark: it outperforms MMS 1B and w2v-BERT\n2.0 v2 by 0.8% and 4.4% respectively, despite having less parameters or\npre-training data. Checkpoints, code, and data are found in\nhttps://www.wavlab.org/activities/2024/xeus/.", "published": "2024-06-30 21:40:26", "link": "http://arxiv.org/abs/2407.00837v2", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Actionable Cyber Threat Intelligence using Knowledge Graphs and Large\n  Language Models", "abstract": "Cyber threats are constantly evolving. Extracting actionable insights from\nunstructured Cyber Threat Intelligence (CTI) data is essential to guide\ncybersecurity decisions. Increasingly, organizations like Microsoft, Trend\nMicro, and CrowdStrike are using generative AI to facilitate CTI extraction.\nThis paper addresses the challenge of automating the extraction of actionable\nCTI using advancements in Large Language Models (LLMs) and Knowledge Graphs\n(KGs). We explore the application of state-of-the-art open-source LLMs,\nincluding the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting\nmeaningful triples from CTI texts. Our methodology evaluates techniques such as\nprompt engineering, the guidance framework, and fine-tuning to optimize\ninformation extraction and structuring. The extracted data is then utilized to\nconstruct a KG, offering a structured and queryable representation of threat\nintelligence. Experimental results demonstrate the effectiveness of our\napproach in extracting relevant information, with guidance and fine-tuning\nshowing superior performance over prompt engineering. However, while our\nmethods prove effective in small-scale tests, applying LLMs to large-scale data\nfor KG construction and Link Prediction presents ongoing challenges.", "published": "2024-06-30 13:02:03", "link": "http://arxiv.org/abs/2407.02528v1", "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Understanding Transformers via N-gram Statistics", "abstract": "Transformer based large-language models (LLMs) display extreme proficiency\nwith language yet a precise understanding of how they work remains elusive. One\nway of demystifying transformer predictions would be to describe how they\ndepend on their context in terms of simple template functions. This paper takes\na first step in this direction by considering families of functions (i.e.\nrules) formed out of simple N-gram based statistics of the training data. By\nstudying how well these rulesets approximate transformer predictions, we obtain\na variety of novel discoveries: a simple method to detect overfitting during\ntraining without using a holdout set, a quantitative measure of how\ntransformers progress from learning simple to more complex statistical rules\nover the course of training, a model-variance criterion governing when\ntransformer predictions tend to be described by N-gram rules, and insights into\nhow well transformers can be approximated by N-gram rulesets in the limit where\nthese rulesets become increasingly complex. In this latter direction, we find\nthat for 79% and 68% of LLM next-token distributions on TinyStories and\nWikipedia, respectively, their top-1 predictions agree with those provided by\nour N-gram rulesets.", "published": "2024-06-30 22:18:49", "link": "http://arxiv.org/abs/2407.12034v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "\"I understand why I got this grade\": Automatic Short Answer Grading with\n  Feedback", "abstract": "The demand for efficient and accurate assessment methods has intensified as\neducation systems transition to digital platforms. Providing feedback is\nessential in educational settings and goes beyond simply conveying marks as it\njustifies the assigned marks. In this context, we present a significant\nadvancement in automated grading by introducing Engineering Short Answer\nFeedback (EngSAF) -- a dataset of 5.8k student answers accompanied by reference\nanswers and questions for the Automatic Short Answer Grading (ASAG) task. The\nEngSAF dataset is meticulously curated to cover a diverse range of subjects,\nquestions, and answer patterns from multiple engineering domains. We leverage\nstate-of-the-art large language models' (LLMs) generative capabilities with our\nLabel-Aware Synthetic Feedback Generation (LASFG) strategy to include feedback\nin our dataset. This paper underscores the importance of enhanced feedback in\npractical educational settings, outlines dataset annotation and feedback\ngeneration processes, conducts a thorough EngSAF analysis, and provides\ndifferent LLMs-based zero-shot and finetuned baselines for future comparison.\nAdditionally, we demonstrate the efficiency and effectiveness of the ASAG\nsystem through its deployment in a real-world end-semester exam at the Indian\nInstitute of Technology Bombay (IITB), showcasing its practical viability and\npotential for broader implementation in educational institutions.", "published": "2024-06-30 15:42:18", "link": "http://arxiv.org/abs/2407.12818v1", "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "cs.CL"}
{"title": "FLY-TTS: Fast, Lightweight and High-Quality End-to-End Text-to-Speech\n  Synthesis", "abstract": "While recent advances in Text-To-Speech synthesis have yielded remarkable\nimprovements in generating high-quality speech, research on lightweight and\nfast models is limited. This paper introduces FLY-TTS, a new fast, lightweight\nand high-quality speech synthesis system based on VITS. Specifically, 1) We\nreplace the decoder with ConvNeXt blocks that generate Fourier spectral\ncoefficients followed by the inverse short-time Fourier transform to synthesize\nwaveforms; 2) To compress the model size, we introduce the grouped\nparameter-sharing mechanism to the text encoder and flow-based model; 3) We\nfurther employ the large pre-trained WavLM model for adversarial training to\nimprove synthesis quality. Experimental results show that our model achieves a\nreal-time factor of 0.0139 on an Intel Core i9 CPU, 8.8x faster than the\nbaseline (0.1221), with a 1.6x parameter compression. Objective and subjective\nevaluations indicate that FLY-TTS exhibits comparable speech quality to the\nstrong baseline.", "published": "2024-06-30 16:27:36", "link": "http://arxiv.org/abs/2407.00753v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Less Forgetting for Better Generalization: Exploring Continual-learning\n  Fine-tuning Methods for Speech Self-supervised Representations", "abstract": "Despite being trained on massive and diverse datasets, speech self-supervised\nencoders are generally used for downstream purposes as mere frozen feature\nextractors or model initializers before fine-tuning. The former severely limits\nthe exploitation of large encoders, while the latter hurts the robustness\nacquired during pretraining, especially in low-resource scenarios. This work\nexplores middle-ground solutions, conjecturing that reducing the forgetting of\nthe self-supervised task during the downstream fine-tuning leads to better\ngeneralization. To prove this, focusing on speech recognition, we benchmark\ndifferent continual-learning approaches during fine-tuning and show that they\nimprove both in-domain and out-of-domain generalization abilities. Relative\nperformance gains reach 15.7% and 22.5% with XLSR used as the encoder on two\nEnglish and Danish speech recognition tasks. Further probing experiments show\nthat these gains are indeed linked to less forgetting.", "published": "2024-06-30 16:41:33", "link": "http://arxiv.org/abs/2407.00756v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "An Attribute Interpolation Method in Speech Synthesis by Model Merging", "abstract": "With the development of speech synthesis, recent research has focused on\nchallenging tasks, such as speaker generation and emotion intensity control.\nAttribute interpolation is a common approach to these tasks. However, most\nprevious methods for attribute interpolation require specific modules or\ntraining methods. We propose an attribute interpolation method in speech\nsynthesis by model merging. Model merging is a method that creates new\nparameters by only averaging the parameters of base models. The merged model\ncan generate an output with an intermediate feature of the base models. This\nmethod is easily applicable without specific modules or training methods, as it\nuses only existing trained base models. We merged two text-to-speech models to\nachieve attribute interpolation and evaluated its performance on speaker\ngeneration and emotion intensity control tasks. As a result, our proposed\nmethod achieved smooth attribute interpolation while keeping the linguistic\ncontent in both tasks.", "published": "2024-06-30 17:01:36", "link": "http://arxiv.org/abs/2407.00766v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Improving Real-Time Music Accompaniment Separation with MMDenseNet", "abstract": "Music source separation aims to separate polyphonic music into different\ntypes of sources. Most existing methods focus on enhancing the quality of\nseparated results by using a larger model structure, rendering them unsuitable\nfor deployment on edge devices. Moreover, these methods may produce low-quality\noutput when the input duration is short, making them impractical for real-time\napplications. Therefore, the goal of this paper is to enhance a lightweight\nmodel, MMDenstNet, to strike a balance between separation quality and latency\nfor real-time applications. Different directions of improvement are explored or\nproposed in this paper, including complex ideal ratio mask, self-attention,\nband-merge-split method, and feature look back. Source-to-distortion ratio,\nreal-time factor, and optimal latency are employed to evaluate the performance.\nTo align with our application requirements, the evaluation process in this\npaper focuses on the separation performance of the accompaniment part.\nExperimental results demonstrate that our improvement achieves low real-time\nfactor and optimal latency while maintaining acceptable separation quality.", "published": "2024-06-30 11:00:09", "link": "http://arxiv.org/abs/2407.00657v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
