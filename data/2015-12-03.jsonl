{"title": "Effective LSTMs for Target-Dependent Sentiment Classification", "abstract": "Target-dependent sentiment classification remains a challenge: modeling the\nsemantic relatedness of a target with its context words in a sentence.\nDifferent context words have different influences on determining the sentiment\npolarity of a sentence towards the target. Therefore, it is desirable to\nintegrate the connections between target word and context words when building a\nlearning system. In this paper, we develop two target dependent long short-term\nmemory (LSTM) models, where target information is automatically taken into\naccount. We evaluate our methods on a benchmark dataset from Twitter. Empirical\nresults show that modeling sentence representation with standard LSTM does not\nperform well. Incorporating target information into LSTM can significantly\nboost the classification accuracy. The target-dependent LSTM models achieve\nstate-of-the-art performances without using syntactic parser or external\nsentiment lexicons.", "published": "2015-12-03 14:54:39", "link": "http://arxiv.org/abs/1512.01100v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Predicting the top and bottom ranks of billboard songs using Machine\n  Learning", "abstract": "The music industry is a $130 billion industry. Predicting whether a song\ncatches the pulse of the audience impacts the industry. In this paper we\nanalyze language inside the lyrics of the songs using several computational\nlinguistic algorithms and predict whether a song would make to the top or\nbottom of the billboard rankings based on the language features. We trained and\ntested an SVM classifier with a radial kernel function on the linguistic\nfeatures. Results indicate that we can classify whether a song belongs to top\nand bottom of the billboard charts with a precision of 0.76.", "published": "2015-12-03 23:42:10", "link": "http://arxiv.org/abs/1512.01283v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Neural Enquirer: Learning to Query Tables with Natural Language", "abstract": "We proposed Neural Enquirer as a neural network architecture to execute a\nnatural language (NL) query on a knowledge-base (KB) for answers. Basically,\nNeural Enquirer finds the distributed representation of a query and then\nexecutes it on knowledge-base tables to obtain the answer as one of the values\nin the tables. Unlike similar efforts in end-to-end training of semantic\nparsers, Neural Enquirer is fully \"neuralized\": it not only gives\ndistributional representation of the query and the knowledge-base, but also\nrealizes the execution of compositional queries as a series of differentiable\noperations, with intermediate results (consisting of annotations of the tables\nat different levels) saved on multiple layers of memory. Neural Enquirer can be\ntrained with gradient descent, with which not only the parameters of the\ncontrolling components and semantic parsing component, but also the embeddings\nof the tables and query words can be learned from scratch. The training can be\ndone in an end-to-end fashion, but it can take stronger guidance, e.g., the\nstep-by-step supervision for complicated queries, and benefit from it. Neural\nEnquirer is one step towards building neural network systems which seek to\nunderstand language by executing it on real-world. Our experiments show that\nNeural Enquirer can learn to execute fairly complicated NL queries on tables\nwith rich structures.", "published": "2015-12-03 06:46:27", "link": "http://arxiv.org/abs/1512.00965v2", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.AI"}
{"title": "Approaches for Sentiment Analysis on Twitter: A State-of-Art study", "abstract": "Microbloging is an extremely prevalent broadcast medium amidst the Internet\nfraternity these days. People share their opinions and sentiments about variety\nof subjects like products, news, institutions, etc., every day on microbloging\nwebsites. Sentiment analysis plays a key role in prediction systems, opinion\nmining systems, etc. Twitter, one of the microbloging platforms allows a limit\nof 140 characters to its users. This restriction stimulates users to be very\nconcise about their opinion and twitter an ocean of sentiments to analyze.\nTwitter also provides developer friendly streaming API for data retrieval\npurpose allowing the analyst to search real time tweets from various users. In\nthis paper, we discuss the state-of-art of the works which are focused on\nTwitter, the online social network platform, for sentiment analysis. We survey\nvarious lexical, machine learning and hybrid approaches for sentiment analysis\non Twitter.", "published": "2015-12-03 11:29:36", "link": "http://arxiv.org/abs/1512.01043v1", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
{"title": "Building Memory with Concept Learning Capabilities from Large-scale\n  Knowledge Base", "abstract": "We present a new perspective on neural knowledge base (KB) embeddings, from\nwhich we build a framework that can model symbolic knowledge in the KB together\nwith its learning process. We show that this framework well regularizes\nprevious neural KB embedding model for superior performance in reasoning tasks,\nwhile having the capabilities of dealing with unseen entities, that is, to\nlearn their embeddings from natural language descriptions, which is very like\nhuman's behavior of learning semantic concepts.", "published": "2015-12-03 17:52:50", "link": "http://arxiv.org/abs/1512.01173v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
