{"title": "Option Pricing with Stochastic Volatility, Equity Premium, and Interest Rates", "abstract": "This paper presents a new model for options pricing. The Black-Scholes-Merton\n(BSM) model plays an important role in financial options pricing. However, the\nBSM model assumes that the risk-free interest rate, volatility, and equity\npremium are constant, which is unrealistic in the real market. To address this,\nour paper considers the time-varying characteristics of those parameters. Our\nmodel integrates elements of the BSM model, the Heston (1993) model for\nstochastic variance, the Vasicek model (1977) for stochastic interest rates,\nand the Campbell and Viceira model (1999, 2001) for stochastic equity premium.\nWe derive a linear second-order parabolic PDE and extend our model to encompass\nfixed-strike Asian options, yielding a new PDE. In the absence of closed-form\nsolutions for any options from our new model, we utilize finite difference\nmethods to approximate prices for European call and up-and-out barrier options,\nand outline the numerical implementation for fixed-strike Asian call options.", "published": "2024-08-27 21:45:10", "link": "http://arxiv.org/abs/2408.15416v1", "categories": ["q-fin.MF", "math.AP", "q-fin.CP"], "primary_category": "q-fin.MF"}
{"title": "Leveraging RNNs and LSTMs for Synchronization Analysis in the Indian Stock Market: A Threshold-Based Classification Approach", "abstract": "Our research presents a new approach for forecasting the synchronization of\nstock prices using machine learning and non-linear time-series analysis. To\ncapture the complex non-linear relationships between stock prices, we utilize\nrecurrence plots (RP) and cross-recurrence quantification analysis (CRQA). By\ntransforming Cross Recurrence Plot (CRP) data into a time-series format, we\nenable the use of Recurrent Neural Networks (RNN) and Long Short-Term Memory\n(LSTM) networks for predicting stock price synchronization through both\nregression and classification. We apply this methodology to a dataset of 20\nhighly capitalized stocks from the Indian market over a 21-year period. The\nfindings reveal that our approach can predict stock price synchronization, with\nan accuracy of 0.98 and F1 score of 0.83 offering valuable insights for\ndeveloping effective trading strategies and risk management tools.", "published": "2024-08-27 11:08:37", "link": "http://arxiv.org/abs/2409.06728v1", "categories": ["q-fin.ST", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "GSIFN: A Graph-Structured and Interlaced-Masked Multimodal\n  Transformer-based Fusion Network for Multimodal Sentiment Analysis", "abstract": "Multimodal Sentiment Analysis (MSA) leverages multiple data modals to analyze\nhuman sentiment. Existing MSA models generally employ cutting-edge multimodal\nfusion and representation learning-based methods to promote MSA capability.\nHowever, there are two key challenges: (i) in existing multimodal fusion\nmethods, the decoupling of modal combinations and tremendous parameter\nredundancy, lead to insufficient fusion performance and efficiency; (ii) a\nchallenging trade-off exists between representation capability and\ncomputational overhead in unimodal feature extractors and encoders. Our\nproposed GSIFN incorporates two main components to solve these problems: (i) a\ngraph-structured and interlaced-masked multimodal Transformer. It adopts the\nInterlaced Mask mechanism to construct robust multimodal graph embedding,\nachieve all-modal-in-one Transformer-based fusion, and greatly reduce the\ncomputational overhead; (ii) a self-supervised learning framework with low\ncomputational overhead and high performance, which utilizes a parallelized LSTM\nwith matrix memory to enhance non-verbal modal features for unimodal label\ngeneration. Evaluated on the MSA datasets CMU-MOSI, CMU-MOSEI, and CH-SIMS,\nGSIFN demonstrates superior performance with significantly lower computational\noverhead compared with previous state-of-the-art models.", "published": "2024-08-27 06:44:28", "link": "http://arxiv.org/abs/2408.14809v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AAVENUE: Detecting LLM Biases on NLU Tasks in AAVE via a Novel Benchmark", "abstract": "Detecting biases in natural language understanding (NLU) for African American\nVernacular English (AAVE) is crucial to developing inclusive natural language\nprocessing (NLP) systems. To address dialect-induced performance discrepancies,\nwe introduce AAVENUE ({AAVE} {N}atural Language {U}nderstanding {E}valuation),\na benchmark for evaluating large language model (LLM) performance on NLU tasks\nin AAVE and Standard American English (SAE). AAVENUE builds upon and extends\nexisting benchmarks like VALUE, replacing deterministic syntactic and\nmorphological transformations with a more flexible methodology leveraging\nLLM-based translation with few-shot prompting, improving performance across our\nevaluation metrics when translating key tasks from the GLUE and SuperGLUE\nbenchmarks. We compare AAVENUE and VALUE translations using five popular LLMs\nand a comprehensive set of metrics including fluency, BARTScore, quality,\ncoherence, and understandability. Additionally, we recruit fluent AAVE speakers\nto validate our translations for authenticity. Our evaluations reveal that LLMs\nconsistently perform better on SAE tasks than AAVE-translated versions,\nunderscoring inherent biases and highlighting the need for more inclusive NLP\nmodels. We have open-sourced our source code on GitHub and created a website to\nshowcase our work at https://aavenue.live.", "published": "2024-08-27 07:56:35", "link": "http://arxiv.org/abs/2408.14845v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inverse-Q*: Token Level Reinforcement Learning for Aligning Large\n  Language Models Without Preference Data", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has proven effective in\naligning large language models with human intentions, yet it often relies on\ncomplex methodologies like Proximal Policy Optimization (PPO) that require\nextensive hyper-parameter tuning and present challenges in sample efficiency\nand stability. In this paper, we introduce Inverse-Q*, an innovative framework\nthat transcends traditional RL methods by optimizing token-level reinforcement\nlearning without the need for additional reward or value models. Inverse-Q*\nleverages direct preference optimization techniques but extends them by\nestimating the conditionally optimal policy directly from the model's\nresponses, facilitating more granular and flexible policy shaping. Our approach\nreduces reliance on human annotation and external supervision, making it\nespecially suitable for low-resource settings. We present extensive\nexperimental results demonstrating that Inverse-Q* not only matches but\npotentially exceeds the effectiveness of PPO in terms of convergence speed and\nthe alignment of model responses with human preferences. Our findings suggest\nthat Inverse-Q* offers a practical and robust alternative to conventional RLHF\napproaches, paving the way for more efficient and adaptable model training\napproaches.", "published": "2024-08-27 08:43:32", "link": "http://arxiv.org/abs/2408.14874v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AgentMonitor: A Plug-and-Play Framework for Predictive and Secure\n  Multi-Agent Systems", "abstract": "The rapid advancement of large language models (LLMs) has led to the rise of\nLLM-based agents. Recent research shows that multi-agent systems (MAS), where\neach agent plays a specific role, can outperform individual LLMs. However,\nconfiguring an MAS for a task remains challenging, with performance only\nobservable post-execution. Inspired by scaling laws in LLM development, we\ninvestigate whether MAS performance can be predicted beforehand. We introduce\nAgentMonitor, a framework that integrates at the agent level to capture inputs\nand outputs, transforming them into statistics for training a regression model\nto predict task performance. Additionally, it can further apply real-time\ncorrections to address security risks posed by malicious agents, mitigating\nnegative impacts and enhancing MAS security. Experiments demonstrate that an\nXGBoost model achieves a Spearman correlation of 0.89 in-domain and 0.58 in\nmore challenging scenarios. Furthermore, using AgentMonitor reduces harmful\ncontent by 6.2% and increases helpful content by 1.8% on average, enhancing\nsafety and reliability. Code is available at\n\\url{https://github.com/chanchimin/AgentMonitor}.", "published": "2024-08-27 11:24:38", "link": "http://arxiv.org/abs/2408.14972v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Large Language Models for European Languages", "abstract": "Large Language Models (LLMs) have gained significant attention due to their\nhigh performance on a wide range of natural language tasks since the release of\nChatGPT. The LLMs learn to understand and generate language by training\nbillions of model parameters on vast volumes of text data. Despite being a\nrelatively new field, LLM research is rapidly advancing in various directions.\nIn this paper, we present an overview of LLM families, including LLaMA, PaLM,\nGPT, and MoE, and the methods developed to create and enhance LLMs for official\nEuropean Union (EU) languages. We provide a comprehensive summary of common\nmonolingual and multilingual datasets used for pretraining large language\nmodels.", "published": "2024-08-27 13:10:05", "link": "http://arxiv.org/abs/2408.15040v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-supervised Topic Taxonomy Discovery in the Box Embedding Space", "abstract": "Topic taxonomy discovery aims at uncovering topics of different abstraction\nlevels and constructing hierarchical relations between them. Unfortunately,\nmost of prior work can hardly model semantic scopes of words and topics by\nholding the Euclidean embedding space assumption. What's worse, they infer\nasymmetric hierarchical relations by symmetric distances between topic\nembeddings. As a result, existing methods suffer from problems of low-quality\ntopics at high abstraction levels and inaccurate hierarchical relations. To\nalleviate these problems, this paper develops a Box embedding-based Topic Model\n(BoxTM) that maps words and topics into the box embedding space, where the\nasymmetric metric is defined to properly infer hierarchical relations among\ntopics. Additionally, our BoxTM explicitly infers upper-level topics based on\ncorrelation between specific topics through recursive clustering on topic\nboxes. Finally, extensive experiments validate high-quality of the topic\ntaxonomy learned by BoxTM.", "published": "2024-08-27 13:19:32", "link": "http://arxiv.org/abs/2408.15050v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Relation Also Knows: Rethinking the Recall and Editing of Factual\n  Associations in Auto-Regressive Transformer Language Models", "abstract": "The storage and recall of factual associations in auto-regressive transformer\nlanguage models (LMs) have drawn a great deal of attention, inspiring knowledge\nediting by directly modifying the located model weights. Most editing works\nachieve knowledge editing under the guidance of existing interpretations of\nknowledge recall that mainly focus on subject knowledge. However, these\ninterpretations are seriously flawed, neglecting relation information and\nleading to the over-generalizing problem for editing. In this work, we discover\na novel relation-focused perspective to interpret the knowledge recall of\ntransformer LMs during inference and apply it on single knowledge editing to\navoid over-generalizing. Experimental results on the dataset supplemented with\na new R-Specificity criterion demonstrate that our editing approach\nsignificantly alleviates over-generalizing while remaining competitive on other\ncriteria, breaking the domination of subject-focused editing for future\nresearch.", "published": "2024-08-27 14:22:02", "link": "http://arxiv.org/abs/2408.15091v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring text summarization factuality using atomic facts entailment\n  metrics in the context of retrieval augmented generation", "abstract": "The use of large language models (LLMs) has significantly increased since the\nintroduction of ChatGPT in 2022, demonstrating their value across various\napplications. However, a major challenge for enterprise and commercial adoption\nof LLMs is their tendency to generate inaccurate information, a phenomenon\nknown as \"hallucination.\" This project proposes a method for estimating the\nfactuality of a summary generated by LLMs when compared to a source text. Our\napproach utilizes Naive Bayes classification to assess the accuracy of the\ncontent produced.", "published": "2024-08-27 16:09:56", "link": "http://arxiv.org/abs/2408.15171v1", "categories": ["cs.CL", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Classifying populist language in American presidential and governor\n  speeches using automatic text analysis", "abstract": "Populism is a concept that is often used but notoriously difficult to\nmeasure. Common qualitative measurements like holistic grading or content\nanalysis require great amounts of time and labour, making it difficult to\nquickly scope out which politicians should be classified as populist and which\nshould not, while quantitative methods show mixed results when it comes to\nclassifying populist rhetoric. In this paper, we develop a pipeline to train\nand validate an automated classification model to estimate the use of populist\nlanguage. We train models based on sentences that were identified as populist\nand pluralist in 300 US governors' speeches from 2010 to 2018 and in 45\nspeeches of presidential candidates in 2016. We find that these models classify\nmost speeches correctly, including 84% of governor speeches and 89% of\npresidential speeches. These results extend to different time periods (with 92%\naccuracy on more recent American governors), different amounts of data (with as\nfew as 70 training sentences per category achieving similar results), and when\nclassifying politicians instead of individual speeches. This pipeline is thus\nan effective tool that can optimise the systematic and swift classification of\nthe use of populist language in politicians' speeches.", "published": "2024-08-27 17:19:57", "link": "http://arxiv.org/abs/2408.15213v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pitfalls and Outlooks in Using COMET", "abstract": "The COMET metric has blazed a trail in the machine translation community,\ngiven its strong correlation with human judgements of translation quality. Its\nsuccess stems from being a modified pre-trained multilingual model finetuned\nfor quality assessment. However, it being a machine learning model also gives\nrise to a new set of pitfalls that may not be widely known. We investigate\nthese unexpected behaviours from three aspects: 1) technical: obsolete software\nversions and compute precision; 2) data: empty content, language mismatch, and\ntranslationese at test time as well as distribution and domain biases in\ntraining; 3) usage and reporting: multi-reference support and model referencing\nin the literature. All of these problems imply that COMET scores are not\ncomparable between papers or even technical setups and we put forward our\nperspective on fixing each issue. Furthermore, we release the sacreCOMET\npackage that can generate a signature for the software and model configuration\nas well as an appropriate citation. The goal of this work is to help the\ncommunity make more sound use of the COMET metric.", "published": "2024-08-27 19:03:11", "link": "http://arxiv.org/abs/2408.15366v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DualKanbaFormer: Kolmogorov-Arnold Networks and State Space Model\n  Transformer for Multimodal Aspect-based Sentiment Analysis", "abstract": "Multimodal aspect-based sentiment analysis (MABSA) enhances sentiment\ndetection by combining text with other data types like images. However, despite\nsetting significant benchmarks, attention mechanisms exhibit limitations in\nefficiently modelling long-range dependencies between aspect and opinion\ntargets within the text. They also face challenges in capturing global-context\ndependencies for visual representations. To this end, we propose\nKolmogorov-Arnold Networks (KANs) and Selective State Space model (Mamba)\ntransformer (DualKanbaFormer), a novel architecture to address the above\nissues. We leverage the power of Mamba to capture global context dependencies,\nMulti-head Attention (MHA) to capture local context dependencies, and KANs to\ncapture non-linear modelling patterns for both textual representations (textual\nKanbaFormer) and visual representations (visual KanbaFormer). Furthermore, we\nfuse the textual KanbaFormer and visual KanbaFomer with a gated fusion layer to\ncapture the inter-modality dynamics. According to extensive experimental\nresults, our model outperforms some state-of-the-art (SOTA) studies on two\npublic datasets.", "published": "2024-08-27 19:33:15", "link": "http://arxiv.org/abs/2408.15379v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Awes, Laws, and Flaws From Today's LLM Research", "abstract": "We perform a critical examination of the scientific methodology behind\ncontemporary large language model (LLM) research. For this we assess over 2,000\nresearch works based on criteria typical of what is considered good research\n(e.g. presence of statistical tests and reproducibility) and cross-validate it\nwith arguments that are at the centre of controversy (e.g., claims of emergent\nbehaviour, the use of LLMs as evaluators). We find multiple trends, such as\ndeclines in claims of emergent behaviour and ethics disclaimers; the rise of\nLLMs as evaluators in spite of a lack of consensus from the community about\ntheir useability; and an increase of claims of LLM reasoning abilities,\ntypically without leveraging human evaluation. This paper underscores the need\nfor more scrutiny and rigour by and from this field to live up to the\nfundamentals of a responsible scientific method that is ethical, reproducible,\nsystematic, and open to criticism.", "published": "2024-08-27 21:19:37", "link": "http://arxiv.org/abs/2408.15409v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LyCon: Lyrics Reconstruction from the Bag-of-Words Using Large Language\n  Models", "abstract": "This paper addresses the unique challenge of conducting research in lyric\nstudies, where direct use of lyrics is often restricted due to copyright\nconcerns. Unlike typical data, internet-sourced lyrics are frequently protected\nunder copyright law, necessitating alternative approaches. Our study introduces\na novel method for generating copyright-free lyrics from publicly available\nBag-of-Words (BoW) datasets, which contain the vocabulary of lyrics but not the\nlyrics themselves. Utilizing metadata associated with BoW datasets and large\nlanguage models, we successfully reconstructed lyrics. We have compiled and\nmade available a dataset of reconstructed lyrics, LyCon, aligned with metadata\nfrom renowned sources including the Million Song Dataset, Deezer Mood Detection\nDataset, and AllMusic Genre Dataset, available for public access. We believe\nthat the integration of metadata such as mood annotations or genres enables a\nvariety of academic experiments on lyrics, such as conditional lyric\ngeneration.", "published": "2024-08-27 03:01:48", "link": "http://arxiv.org/abs/2408.14750v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "A global AI community requires language-diverse publishing", "abstract": "In this provocation, we discuss the English dominance of the AI research\ncommunity, arguing that the requirement for English language publishing upholds\nand reinforces broader regimes of extraction in AI. While large language models\nand machine translation have been celebrated as a way to break down barriers,\nwe regard their use as a symptom of linguistic exclusion of scientists and\npotential readers. We propose alternative futures for a healthier publishing\nculture, organized around three themes: administering conferences in the\nlanguages of the country in which they are held, instructing peer reviewers not\nto adjudicate the language appropriateness of papers, and offering\nopportunities to publish and present in multiple languages. We welcome new\ntranslations of this piece. Please contact the authors if you would like to\ncontribute one.", "published": "2024-08-27 04:20:10", "link": "http://arxiv.org/abs/2408.14772v2", "categories": ["cs.CL", "cs.AI", "K.7.0; K.4.2; I.2.m"], "primary_category": "cs.CL"}
{"title": "Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning", "abstract": "We introduce Instruct-SkillMix, an automated approach for creating diverse,\nhigh quality SFT data. The Instruct-SkillMix pipeline involves two stages, each\nleveraging an existing powerful LLM: (1) Skill extraction: uses the LLM to\nextract core \"skills\" for instruction-following, either from existing datasets,\nor by directly prompting the model; (2) Data generation: uses the powerful LLM\nto generate (instruction, response) data that exhibit a randomly chosen pair of\nthese skills. Here, the use of random skill combinations promotes diversity and\ndifficulty.\n  Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from\nInstruct-SkillMix leads to strong gains on instruction following benchmarks\nsuch as AlpacaEval 2.0, MT-Bench, and WildBench. With just $4$K examples,\nLLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0.\nTo our knowledge, this achieves state-of-the-art performance among all models\nthat have only undergone SFT (no RL methods) and competes with proprietary\nmodels such as Claude 3 Opus and LLaMA-3.1-405B-Instruct.\n  Ablation studies also suggest plausible reasons for why creating open\ninstruction-tuning datasets via naive crowd-sourcing has proved difficult.\nIntroducing low quality answers (\"shirkers\") in $20\\%$ of Instruct-SkillMix\nexamples causes performance to plummet, sometimes catastrophically.\n  The Instruct-SkillMix pipeline is flexible and is adaptable to other\nsettings.", "published": "2024-08-27 04:31:58", "link": "http://arxiv.org/abs/2408.14774v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "PolicyLR: A Logic Representation For Privacy Policies", "abstract": "Privacy policies are crucial in the online ecosystem, defining how services\nhandle user data and adhere to regulations such as GDPR and CCPA. However,\ntheir complexity and frequent updates often make them difficult for\nstakeholders to understand and analyze. Current automated analysis methods,\nwhich utilize natural language processing, have limitations. They typically\nfocus on individual tasks and fail to capture the full context of the policies.\nWe propose PolicyLR, a new paradigm that offers a comprehensive\nmachine-readable representation of privacy policies, serving as an all-in-one\nsolution for multiple downstream tasks. PolicyLR converts privacy policies into\na machine-readable format using valuations of atomic formulae, allowing for\nformal definitions of tasks like compliance and consistency. We have developed\na compiler that transforms unstructured policy text into this format using\noff-the-shelf Large Language Models (LLMs). This compiler breaks down the\ntransformation task into a two-stage translation and entailment procedure. This\nprocedure considers the full context of the privacy policy to infer a complex\nformula, where each formula consists of simpler atomic formulae. The advantage\nof this model is that PolicyLR is interpretable by design and grounded in\nsegments of the privacy policy. We evaluated the compiler using ToS;DR, a\ncommunity-annotated privacy policy entailment dataset. Utilizing open-source\nLLMs, our compiler achieves precision and recall values of 0.91 and 0.88,\nrespectively. Finally, we demonstrate the utility of PolicyLR in three privacy\ntasks: Policy Compliance, Inconsistency Detection, and Privacy Comparison\nShopping.", "published": "2024-08-27 07:27:16", "link": "http://arxiv.org/abs/2408.14830v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "Project SHADOW: Symbolic Higher-order Associative Deductive reasoning On\n  Wikidata using LM probing", "abstract": "We introduce SHADOW, a fine-tuned language model trained on an intermediate\ntask using associative deductive reasoning, and measure its performance on a\nknowledge base construction task using Wikidata triple completion. We evaluate\nSHADOW on the LM-KBC 2024 challenge and show that it outperforms the baseline\nsolution by 20% with a F1 score of 68.72%.", "published": "2024-08-27 08:01:13", "link": "http://arxiv.org/abs/2408.14849v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Writing in the Margins: Better Inference Pattern for Long Context\n  Retrieval", "abstract": "In this paper, we introduce Writing in the Margins (WiM), a new inference\npattern for Large Language Models designed to optimize the handling of long\ninput sequences in retrieval-oriented tasks. This approach leverages the\nchunked prefill of the key-value cache to perform segment-wise inference, which\nenables efficient processing of extensive contexts along with the generation\nand classification of intermediate information (\"margins\") that guide the model\ntowards specific tasks. This method increases computational overhead marginally\nwhile significantly enhancing the performance of off-the-shelf models without\nthe need for fine-tuning. Specifically, we observe that WiM provides an average\nenhancement of 7.5% in accuracy for reasoning skills (HotpotQA, MultiHop-RAG)\nand more than a 30.0% increase in the F1-score for aggregation tasks (CWE).\nAdditionally, we show how the proposed pattern fits into an interactive\nretrieval design that provides end-users with ongoing updates about the\nprogress of context processing, and pinpoints the integration of relevant\ninformation into the final response. We release our implementation of WiM using\nHugging Face Transformers library at\nhttps://github.com/writer/writing-in-the-margins.", "published": "2024-08-27 09:34:38", "link": "http://arxiv.org/abs/2408.14906v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Multilingual Arbitrage: Optimizing Data Pools to Accelerate Multilingual\n  Progress", "abstract": "The use of synthetic data has played a critical role in recent state-of-art\nbreakthroughs. However, overly relying on a single oracle teacher model to\ngenerate data has been shown to lead to model collapse and invite propagation\nof biases. These limitations are particularly evident in multilingual settings,\nwhere the absence of a universally effective teacher model that excels across\nall languages presents significant challenges. In this work, we address these\nextreme difference by introducing \"multilingual arbitrage\", which capitalizes\non performance variations between multiple models for a given language. To do\nso, we strategically route samples through a diverse pool of models, each with\nunique strengths in different languages. Across exhaustive experiments on\nstate-of-art models, our work suggests that arbitrage techniques allow for\nspectacular gains in performance that far outperform relying on a single\nteacher. In particular, compared to the best single teacher, we observe gains\nof up to 56.5% improvement in win rates averaged across all languages when\nswitching to multilingual arbitrage. We observe the most significant gains for\nthe least resourced languages in our pool.", "published": "2024-08-27 11:07:15", "link": "http://arxiv.org/abs/2408.14960v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MRSE: An Efficient Multi-modality Retrieval System for Large Scale\n  E-commerce", "abstract": "Providing high-quality item recall for text queries is crucial in large-scale\ne-commerce search systems. Current Embedding-based Retrieval Systems (ERS)\nembed queries and items into a shared low-dimensional space, but uni-modality\nERS rely too heavily on textual features, making them unreliable in complex\ncontexts. While multi-modality ERS incorporate various data sources, they often\noverlook individual preferences for different modalities, leading to suboptimal\nresults. To address these issues, we propose MRSE, a Multi-modality Retrieval\nSystem that integrates text, item images, and user preferences through\nlightweight mixture-of-expert (LMoE) modules to better align features across\nand within modalities. MRSE also builds user profiles at a multi-modality level\nand introduces a novel hybrid loss function that enhances consistency and\nrobustness using hard negative sampling. Experiments on a large-scale dataset\nfrom Shopee and online A/B testing show that MRSE achieves an 18.9% improvement\nin offline relevance and a 3.7% gain in online core metrics compared to\nShopee's state-of-the-art uni-modality system.", "published": "2024-08-27 11:21:19", "link": "http://arxiv.org/abs/2408.14968v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Evidence-Enhanced Triplet Generation Framework for Hallucination\n  Alleviation in Generative Question Answering", "abstract": "To address the hallucination in generative question answering (GQA) where the\nanswer can not be derived from the document, we propose a novel\nevidence-enhanced triplet generation framework, EATQA, encouraging the model to\npredict all the combinations of (Question, Evidence, Answer) triplet by\nflipping the source pair and the target label to understand their logical\nrelationships, i.e., predict Answer(A), Question(Q), and Evidence(E) given a\nQE, EA, and QA pairs, respectively. Furthermore, we bridge the distribution gap\nto distill the knowledge from evidence in inference stage. Our framework\nensures the model to learn the logical relation between query, evidence and\nanswer, which simultaneously improves the evidence generation and query\nanswering. In this paper, we apply EATQA to LLama and it outperforms other\nLLMs-based methods and hallucination mitigation approaches on two challenging\nGQA benchmarks. Further analysis shows that our method not only keeps prior\nknowledge within LLM, but also mitigates hallucination and generates faithful\nanswers.", "published": "2024-08-27 13:07:07", "link": "http://arxiv.org/abs/2408.15037v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "BaichuanSEED: Sharing the Potential of ExtensivE Data Collection and\n  Deduplication by Introducing a Competitive Large Language Model Baseline", "abstract": "The general capabilities of Large Language Models (LLM) highly rely on the\ncomposition and selection on extensive pretraining datasets, treated as\ncommercial secrets by several institutions. To mitigate this issue, we\nopen-source the details of a universally applicable data processing pipeline\nand validate its effectiveness and potential by introducing a competitive LLM\nbaseline. Specifically, the data processing pipeline consists of broad\ncollection to scale up and reweighting to improve quality. We then pretrain a\n7B model BaichuanSEED with 3T tokens processed by our pipeline without any\ndeliberate downstream task-related optimization, followed by an easy but\neffective supervised fine-tuning stage. BaichuanSEED demonstrates consistency\nand predictability throughout training and achieves comparable performance on\ncomprehensive benchmarks with several commercial advanced large language\nmodels, such as Qwen1.5 and Llama3. We also conduct several heuristic\nexperiments to discuss the potential for further optimization of downstream\ntasks, such as mathematics and coding.", "published": "2024-08-27 14:08:23", "link": "http://arxiv.org/abs/2408.15079v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized\n  Implicit Reward Function", "abstract": "An LLM is pretrained on trillions of tokens, but the pretrained LLM may still\ngenerate undesired responses. To solve this problem, alignment techniques such\nas RLHF, DPO and KTO are proposed. However, these alignment techniques have\nlimitations. For example, RLHF requires training the reward model and policy\nseparately, which is complex, time-consuming, memory intensive and unstable\nduring training processes. DPO proposes a mapping between an optimal policy and\na reward, greatly simplifying the training process of RLHF. However, it can not\ntake full advantages of a reward model and it is limited to pairwise preference\ndata.\n  In this paper, we propose \\textbf{UN}ified \\textbf{A}lignment (UNA) which\nunifies RLHF/PPO, DPO and KTO. Firstly, we mathematically prove that given the\nclassical RLHF objective, the optimal policy is induced by a generalize\nimplicit reward function. With this novel mapping between a reward model and an\noptimal policy, UNA can 1. unify RLHF/PPO, DPO and KTO into a supervised\nlearning of minimizing the difference between an implicit reward and an\nexplicit reward; 2. outperform RLHF/PPO while simplify, stabilize, speed up and\nreduce memory burden of RL fine-tuning process; 3. accommodate different\nfeedback types including pairwise, binary and scalar feedback. Downstream\nexperiments show UNA outperforms DPO, KTO and RLHF.", "published": "2024-08-27 18:04:07", "link": "http://arxiv.org/abs/2408.15339v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Implicit Geometry of Next-token Prediction: From Language Sparsity\n  Patterns to Model Representations", "abstract": "Next-token prediction (NTP) over large text corpora has become the go-to\nparadigm to train large language models. Yet, it remains unclear how NTP\ninfluences the mapping of linguistic patterns to geometric properties of the\nresulting model representations. We frame training of large language models as\nsoft-label classification over sparse probabilistic label vectors, coupled with\nan analytical approximation that allows unrestricted generation of context\nembeddings. This approach links NTP training to rank-constrained, nuclear-norm\nregularized optimization in the logit domain, offering a framework for\nanalyzing the geometry of word and context embeddings. In large embedding\nspaces, we find that NTP implicitly favors learning logits with a sparse plus\nlow-rank structure. While the sparse component captures the co-occurrence\nfrequency of context-word pairs, the orthogonal low-rank component, which\nbecomes dominant as training progresses, depends solely on the sparsity pattern\nof the co-occurrence matrix. Consequently, when projected onto an appropriate\nsubspace, representations of contexts that are followed by the same set of\nnext-tokens collapse, a phenomenon we term subspace-collapse. We validate our\nfindings on synthetic and small-scale real language datasets. Finally, we\noutline potential research directions aimed at deepening the understanding of\nNTP's influence on the learning of linguistic patterns and regularities.", "published": "2024-08-27 21:46:47", "link": "http://arxiv.org/abs/2408.15417v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Disease Diagnosis: A Scoping Review", "abstract": "Automatic disease diagnosis has become increasingly valuable in clinical\npractice. The advent of large language models (LLMs) has catalyzed a paradigm\nshift in artificial intelligence, with growing evidence supporting the efficacy\nof LLMs in diagnostic tasks. Despite the increasing attention in this field, a\nholistic view is still lacking. Many critical aspects remain unclear, such as\nthe diseases and clinical data to which LLMs have been applied, the LLM\ntechniques employed, and the evaluation methods used. In this article, we\nperform a comprehensive review of LLM-based methods for disease diagnosis. Our\nreview examines the existing literature across various dimensions, including\ndisease types and associated clinical specialties, clinical data, LLM\ntechniques, and evaluation methods. Additionally, we offer recommendations for\napplying and evaluating LLMs for diagnostic tasks. Furthermore, we assess the\nlimitations of current research and discuss future directions. To our\nknowledge, this is the first comprehensive review for LLM-based disease\ndiagnosis.", "published": "2024-08-27 02:06:45", "link": "http://arxiv.org/abs/2409.00097v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "How to Train Text Summarization Model with Weak Supervisions", "abstract": "Currently, machine learning techniques have seen significant success across\nvarious applications. Most of these techniques rely on supervision from\nhuman-generated labels or a mixture of noisy and imprecise labels from multiple\nsources. However, for certain complex tasks, even noisy or inexact labels are\nunavailable due to the intricacy of the objectives. To tackle this issue, we\npropose a method that breaks down the complex objective into simpler tasks and\ngenerates supervision signals for each one. We then integrate these supervision\nsignals into a manageable form, resulting in a straightforward learning\nprocedure. As a case study, we demonstrate a system used for topic-based\nsummarization. This system leverages rich supervision signals to promote both\nsummarization and topic relevance. Remarkably, we can train the model\nend-to-end without any labels. Experimental results indicate that our approach\nperforms exceptionally well on the CNN and DailyMail datasets.", "published": "2024-08-27 02:35:51", "link": "http://arxiv.org/abs/2409.00098v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Nuance Matters: Probing Epistemic Consistency in Causal Reasoning", "abstract": "To address this gap, our study introduces the concept of causal epistemic\nconsistency, which focuses on the self-consistency of Large Language Models\n(LLMs) in differentiating intermediates with nuanced differences in causal\nreasoning. We propose a suite of novel metrics -- intensity ranking\nconcordance, cross-group position agreement, and intra-group clustering -- to\nevaluate LLMs on this front. Through extensive empirical studies on 21\nhigh-profile LLMs, including GPT-4, Claude3, and LLaMA3-70B, we have favoring\nevidence that current models struggle to maintain epistemic consistency in\nidentifying the polarity and intensity of intermediates in causal reasoning.\nAdditionally, we explore the potential of using internal token probabilities as\nan auxiliary tool to maintain causal epistemic consistency. In summary, our\nstudy bridges a critical gap in AI research by investigating the\nself-consistency over fine-grained intermediates involved in causal reasoning.", "published": "2024-08-27 13:42:34", "link": "http://arxiv.org/abs/2409.00103v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Wait, that's not an option: LLMs Robustness with Incorrect\n  Multiple-Choice Options", "abstract": "Decision-making under full alignment requires balancing between reasoning and\nfaithfulness - a challenge for large language models (LLMs). This study\nexplores whether LLMs prioritize following instructions over reasoning and\ntruth when given \"misleading\" instructions, such as \"Respond solely with A or\nB\", even when neither option is correct. We introduce a new metric called\n\"reflective judgment\", which sheds new light on the relationship between the\npre-training and post-training alignment schemes. In tasks ranging from basic\narithmetic to domain-specific assessments, models like GPT-4o, o1-mini, or\nClaude 3 Opus adhered to instructions correctly but failed to reflect on the\nvalidity of the provided options. Contrary, models from the Llama 3.1 family\n(8B, 70B, 405B) or base Qwen2.5 (7B, 14B, 32B) families exhibit improved\nrefusal rates with size, indicating a scaling effect. We also observed that\nalignment techniques, though intended to enhance reasoning, sometimes weakened\nthe models' ability to reject incorrect instructions, leading them to follow\nflawed prompts uncritically. Finally, we have also conducted a parallel human\nstudy revealing similar patterns in human behavior and annotations. We\nhighlight how popular RLHF datasets might disrupt either training or evaluation\ndue to annotations exhibiting poor reflective judgement.", "published": "2024-08-27 19:27:43", "link": "http://arxiv.org/abs/2409.00113v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "PAT: Pruning-Aware Tuning for Large Language Models", "abstract": "Large language models (LLMs) excel in language tasks, especially with\nsupervised fine-tuning after pre-training. However, their substantial memory\nand computational requirements hinder practical applications. Structural\npruning, which reduces less significant weight dimensions, is one solution.\nYet, traditional post-hoc pruning often leads to significant performance loss,\nwith limited recovery from further fine-tuning due to reduced capacity. Since\nthe model fine-tuning refines the general and chaotic knowledge in pre-trained\nmodels, we aim to incorporate structural pruning with the fine-tuning, and\npropose the Pruning-Aware Tuning (PAT) paradigm to eliminate model redundancy\nwhile preserving the model performance to the maximum extend. Specifically, we\ninsert the innovative Hybrid Sparsification Modules (HSMs) between the\nAttention and FFN components to accordingly sparsify the upstream and\ndownstream linear modules. The HSM comprises a lightweight operator and a\nglobally shared trainable mask. The lightweight operator maintains a training\noverhead comparable to that of LoRA, while the trainable mask unifies the\nchannels to be sparsified, ensuring structural pruning. Additionally, we\npropose the Identity Loss which decouples the transformation and scaling\nproperties of the HSMs to enhance training robustness. Extensive experiments\ndemonstrate that PAT excels in both performance and efficiency. For example,\nour Llama2-7b model with a 25\\% pruning ratio achieves 1.33$\\times$ speedup\nwhile outperforming the LoRA-finetuned model by up to 1.26\\% in accuracy with a\nsimilar training cost. Code:\nhttps://github.com/kriskrisliu/PAT_Pruning-Aware-Tuning", "published": "2024-08-27 01:04:14", "link": "http://arxiv.org/abs/2408.14721v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Measuring Human Contribution in AI-Assisted Content Generation", "abstract": "With the growing prevalence of generative artificial intelligence (AI), an\nincreasing amount of content is no longer exclusively generated by humans but\nby generative AI models with human guidance. This shift presents notable\nchallenges for the delineation of originality due to the varying degrees of\nhuman contribution in AI-assisted works. This study raises the research\nquestion of measuring human contribution in AI-assisted content generation and\nintroduces a framework to address this question that is grounded in information\ntheory. By calculating mutual information between human input and AI-assisted\noutput relative to self-information of AI-assisted output, we quantify the\nproportional information contribution of humans in content generation. Our\nexperimental results demonstrate that the proposed measure effectively\ndiscriminates between varying degrees of human contribution across multiple\ncreative domains. We hope that this work lays a foundation for measuring human\ncontributions in AI-assisted content generation in the era of generative AI.", "published": "2024-08-27 05:56:04", "link": "http://arxiv.org/abs/2408.14792v2", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "From Rule-Based Models to Deep Learning Transformers Architectures for\n  Natural Language Processing and Sign Language Translation Systems: Survey,\n  Taxonomy and Performance Evaluation", "abstract": "With the growing Deaf and Hard of Hearing population worldwide and the\npersistent shortage of certified sign language interpreters, there is a\npressing need for an efficient, signs-driven, integrated end-to-end translation\nsystem, from sign to gloss to text and vice-versa. There has been a wealth of\nresearch on machine translations and related reviews. However, there are few\nworks on sign language machine translation considering the particularity of the\nlanguage being continuous and dynamic. This paper aims to address this void,\nproviding a retrospective analysis of the temporal evolution of sign language\nmachine translation algorithms and a taxonomy of the Transformers\narchitectures, the most used approach in language translation. We also present\nthe requirements of a real-time Quality-of-Service sign language ma-chine\ntranslation system underpinned by accurate deep learning algorithms. We propose\nfuture research directions for sign language translation systems.", "published": "2024-08-27 07:11:45", "link": "http://arxiv.org/abs/2408.14825v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "I.2, I.2.7, I.4, I.4.9"], "primary_category": "cs.AI"}
{"title": "CL4KGE: A Curriculum Learning Method for Knowledge Graph Embedding", "abstract": "Knowledge graph embedding (KGE) constitutes a foundational task, directed\ntowards learning representations for entities and relations within knowledge\ngraphs (KGs), with the objective of crafting representations comprehensive\nenough to approximate the logical and symbolic interconnections among entities.\nIn this paper, we define a metric Z-counts to measure the difficulty of\ntraining each triple ($<$head entity, relation, tail entity$>$) in KGs with\ntheoretical analysis. Based on this metric, we propose \\textbf{CL4KGE}, an\nefficient \\textbf{C}urriculum \\textbf{L}earning based training strategy for\n\\textbf{KGE}. This method includes a difficulty measurer and a training\nscheduler that aids in the training of KGE models. Our approach possesses the\nflexibility to act as a plugin within a wide range of KGE models, with the\nadded advantage of adaptability to the majority of KGs in existence. The\nproposed method has been evaluated on popular KGE models, and the results\ndemonstrate that it enhances the state-of-the-art methods. The use of Z-counts\nas a metric has enabled the identification of challenging triples in KGs, which\nhelps in devising effective training strategies.", "published": "2024-08-27 07:51:26", "link": "http://arxiv.org/abs/2408.14840v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Atoxia: Red-teaming Large Language Models with Target Toxic Answers", "abstract": "Despite the substantial advancements in artificial intelligence, large\nlanguage models (LLMs) remain being challenged by generation safety. With\nadversarial jailbreaking prompts, one can effortlessly induce LLMs to output\nharmful content, causing unexpected negative social impacts. This vulnerability\nhighlights the necessity for robust LLM red-teaming strategies to identify and\nmitigate such risks before large-scale application. To detect specific types of\nrisks, we propose a novel red-teaming method that $\\textbf{A}$ttacks LLMs with\n$\\textbf{T}$arget $\\textbf{Toxi}$c $\\textbf{A}$nswers ($\\textbf{Atoxia}$).\nGiven a particular harmful answer, Atoxia generates a corresponding user query\nand a misleading answer opening to examine the internal defects of a given LLM.\nThe proposed attacker is trained within a reinforcement learning scheme with\nthe LLM outputting probability of the target answer as the reward. We verify\nthe effectiveness of our method on various red-teaming benchmarks, such as\nAdvBench and HH-Harmless. The empirical results demonstrate that Atoxia can\nsuccessfully detect safety risks in not only open-source models but also\nstate-of-the-art black-box models such as GPT-4o.", "published": "2024-08-27 08:12:08", "link": "http://arxiv.org/abs/2408.14853v2", "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Advancing Adversarial Suffix Transfer Learning on Aligned Large Language\n  Models", "abstract": "Language Language Models (LLMs) face safety concerns due to potential misuse\nby malicious users. Recent red-teaming efforts have identified adversarial\nsuffixes capable of jailbreaking LLMs using the gradient-based search algorithm\nGreedy Coordinate Gradient (GCG). However, GCG struggles with computational\ninefficiency, limiting further investigations regarding suffix transferability\nand scalability across models and data. In this work, we bridge the connection\nbetween search efficiency and suffix transferability. We propose a two-stage\ntransfer learning framework, DeGCG, which decouples the search process into\nbehavior-agnostic pre-searching and behavior-relevant post-searching.\nSpecifically, we employ direct first target token optimization in pre-searching\nto facilitate the search process. We apply our approach to cross-model,\ncross-data, and self-transfer scenarios. Furthermore, we introduce an\ninterleaved variant of our approach, i-DeGCG, which iteratively leverages\nself-transferability to accelerate the search process. Experiments on HarmBench\ndemonstrate the efficiency of our approach across various models and domains.\nNotably, our i-DeGCG outperforms the baseline on Llama2-chat-7b with ASRs of\n$43.9$ ($+22.2$) and $39.0$ ($+19.5$) on valid and test sets, respectively.\nFurther analysis on cross-model transfer indicates the pivotal role of first\ntarget token optimization in leveraging suffix transferability for efficient\nsearching.", "published": "2024-08-27 08:38:48", "link": "http://arxiv.org/abs/2408.14866v2", "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Functional Trade-off between Prosodic and Semantic Cues in Conveying\n  Sarcasm", "abstract": "This study investigates the acoustic features of sarcasm and disentangles the\ninterplay between the propensity of an utterance being used sarcastically and\nthe presence of prosodic cues signaling sarcasm. Using a dataset of sarcastic\nutterances compiled from television shows, we analyze the prosodic features\nwithin utterances and key phrases belonging to three distinct sarcasm\ncategories (embedded, propositional, and illocutionary), which vary in the\ndegree of semantic cues present, and compare them to neutral expressions.\nResults show that in phrases where the sarcastic meaning is salient from the\nsemantics, the prosodic cues are less relevant than when the sarcastic meaning\nis not evident from the semantics, suggesting a trade-off between prosodic and\nsemantic cues of sarcasm at the phrase level. These findings highlight a\nlessened reliance on prosodic modulation in semantically dense sarcastic\nexpressions and a nuanced interaction that shapes the communication of\nsarcastic intent.", "published": "2024-08-27 09:07:37", "link": "http://arxiv.org/abs/2408.14892v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view\n  Videos of Daily Activities", "abstract": "Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data\n(e.g., images and videos) into symbols, have attracted attention as resources\nenabling knowledge processing and machine learning across modalities. However,\nthe construction of MMKGs for videos consisting of multiple events, such as\ndaily activities, is still in the early stages. In this paper, we construct an\nMMKG based on synchronized multi-view simulated videos of daily activities.\nBesides representing the content of daily life videos as event-centric\nknowledge, our MMKG also includes frame-by-frame fine-grained changes, such as\nbounding boxes within video frames. In addition, we provide support tools for\nquerying our MMKG. As an application example, we demonstrate that our MMKG\nfacilitates benchmarking vision-language models by providing the necessary\nvision-language datasets for a tailored task.", "published": "2024-08-27 09:18:57", "link": "http://arxiv.org/abs/2408.14895v2", "categories": ["cs.AI", "cs.CL", "cs.CV", "68T30", "I.2.4; H.5.1"], "primary_category": "cs.AI"}
{"title": "Tripl\u00e8toile: Extraction of Knowledge from Microblogging Text", "abstract": "Numerous methods and pipelines have recently emerged for the automatic\nextraction of knowledge graphs from documents such as scientific publications\nand patents. However, adapting these methods to incorporate alternative text\nsources like micro-blogging posts and news has proven challenging as they\nstruggle to model open-domain entities and relations, typically found in these\nsources. In this paper, we propose an enhanced information extraction pipeline\ntailored to the extraction of a knowledge graph comprising open-domain entities\nfrom micro-blogging posts on social media platforms. Our pipeline leverages\ndependency parsing and classifies entity relations in an unsupervised manner\nthrough hierarchical clustering over word embeddings. We provide a use case on\nextracting semantic triples from a corpus of 100 thousand tweets about digital\ntransformation and publicly release the generated knowledge graph. On the same\ndataset, we conduct two experimental evaluations, showing that the system\nproduces triples with precision over 95% and outperforms similar pipelines of\naround 5% in terms of precision, while generating a comparatively higher number\nof triples.", "published": "2024-08-27 09:35:13", "link": "http://arxiv.org/abs/2408.14908v1", "categories": ["cs.IR", "cs.CE", "cs.CL", "68T01, 68T50", "I.2.7; I.2.1"], "primary_category": "cs.IR"}
{"title": "SpikingSSMs: Learning Long Sequences with Sparse and Parallel Spiking\n  State Space Models", "abstract": "Known as low energy consumption networks, spiking neural networks (SNNs) have\ngained a lot of attention within the past decades. While SNNs are increasing\ncompetitive with artificial neural networks (ANNs) for vision tasks, they are\nrarely used for long sequence tasks, despite their intrinsic temporal dynamics.\nIn this work, we develop spiking state space models (SpikingSSMs) for long\nsequence learning by leveraging on the sequence learning abilities of state\nspace models (SSMs). Inspired by dendritic neuron structure, we hierarchically\nintegrate neuronal dynamics with the original SSM block, meanwhile realizing\nsparse synaptic computation. Furthermore, to solve the conflict of event-driven\nneuronal dynamics with parallel computing, we propose a light-weight surrogate\ndynamic network which accurately predicts the after-reset membrane potential\nand compatible to learnable thresholds, enabling orders of acceleration in\ntraining speed compared with conventional iterative methods. On the long range\narena benchmark task, SpikingSSM achieves competitive performance to\nstate-of-the-art SSMs meanwhile realizing on average 90\\% of network sparsity.\nOn language modeling, our network significantly surpasses existing spiking\nlarge language models (spikingLLMs) on the WikiText-103 dataset with only a\nthird of the model size, demonstrating its potential as backbone architecture\nfor low computation cost LLMs.", "published": "2024-08-27 09:35:49", "link": "http://arxiv.org/abs/2408.14909v2", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Speech Recognition Transformers: Topological-lingualism Perspective", "abstract": "Transformers have evolved with great success in various artificial\nintelligence tasks. Thanks to our recent prevalence of self-attention\nmechanisms, which capture long-term dependency, phenomenal outcomes in speech\nprocessing and recognition tasks have been produced. The paper presents a\ncomprehensive survey of transformer techniques oriented in speech modality. The\nmain contents of this survey include (1) background of traditional ASR,\nend-to-end transformer ecosystem, and speech transformers (2) foundational\nmodels in a speech via lingualism paradigm, i.e., monolingual, bilingual,\nmultilingual, and cross-lingual (3) dataset and languages, acoustic features,\narchitecture, decoding, and evaluation metric from a specific topological\nlingualism perspective (4) popular speech transformer toolkit for building\nend-to-end ASR systems. Finally, highlight the discussion of open challenges\nand potential research directions for the community to conduct further research\nin this domain.", "published": "2024-08-27 12:15:43", "link": "http://arxiv.org/abs/2408.14991v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "How transformers learn structured data: insights from hierarchical\n  filtering", "abstract": "Understanding the learning process and the embedded computation in\ntransformers is becoming a central goal for the development of interpretable\nAI. In the present study, we introduce a hierarchical filtering procedure for\ngenerative models of sequences on trees, allowing us to hand-tune the range of\npositional correlations in the data. Leveraging this controlled setting, we\nprovide evidence that vanilla encoder-only transformers can approximate the\nexact inference algorithm when trained on root classification and masked\nlanguage modeling tasks, and study how this computation is discovered and\nimplemented. We find that correlations at larger distances, corresponding to\nincreasing layers of the hierarchy, are sequentially included by the network\nduring training. Moreover, by comparing attention maps from models trained with\nvarying degrees of filtering and by probing the different encoder levels, we\nfind clear evidence of a reconstruction of correlations on successive length\nscales corresponding to the various levels of the hierarchy, which we relate to\na plausible implementation of the exact inference algorithm within the same\narchitecture.", "published": "2024-08-27 15:23:09", "link": "http://arxiv.org/abs/2408.15138v2", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.CL"], "primary_category": "cs.LG"}
{"title": "X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation", "abstract": "Large Language Models (LLMs) and Large Multimodal Models (LMMs) have been\nshown to enhance the effectiveness of enriching item descriptions, thereby\nimproving the accuracy of recommendation systems. However, most existing\napproaches either rely on text-only prompting or employ basic multimodal\nstrategies that do not fully exploit the complementary information available\nfrom both textual and visual modalities. This paper introduces a novel\nframework, Cross-Reflection Prompting, termed X-Reflect, designed to address\nthese limitations by prompting LMMs to explicitly identify and reconcile\nsupportive and conflicting information between text and images. By capturing\nnuanced insights from both modalities, this approach generates more\ncomprehensive and contextually richer item representations. Extensive\nexperiments conducted on two widely used benchmarks demonstrate that our method\noutperforms existing prompting baselines in downstream recommendation accuracy.\nAdditionally, we evaluate the generalizability of our framework across\ndifferent LMM backbones and the robustness of the prompting strategies,\noffering insights for optimization. This work underscores the importance of\nintegrating multimodal information and presents a novel solution for improving\nitem understanding in multimodal recommendation systems.", "published": "2024-08-27 16:10:21", "link": "http://arxiv.org/abs/2408.15172v1", "categories": ["cs.IR", "cs.CL", "cs.CV"], "primary_category": "cs.IR"}
{"title": "Unifying Multitrack Music Arrangement via Reconstruction Fine-Tuning and\n  Efficient Tokenization", "abstract": "Automatic music arrangement streamlines the creation of musical variants for\ncomposers and arrangers, reducing reliance on extensive music expertise.\nHowever, existing methods suffer from inefficient tokenization,\nunderutilization of pre-trained music language models (LMs), and suboptimal\nfidelity and coherence in generated arrangements. This paper introduces an\nefficient multitrack music tokenizer for unconditional and conditional symbolic\nmusic generation, along with a unified sequence-to-sequence reconstruction\nfine-tuning objective for pre-trained music LMs that balances task-specific\nneeds with coherence constraints. Our approach achieves state-of-the-art\nresults on band arrangement, piano reduction, and drum arrangement, surpassing\ntask-specific models in both objective metrics and perceptual quality.\nAdditionally, we demonstrate that generative pretraining significantly\ncontributes to the performance across these arrangement tasks, especially when\nhandling long segments with complex alignment.", "published": "2024-08-27 16:18:51", "link": "http://arxiv.org/abs/2408.15176v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Infusing Acoustic Pause Context into Text-Based Dementia Assessment", "abstract": "Speech pauses, alongside content and structure, offer a valuable and\nnon-invasive biomarker for detecting dementia. This work investigates the use\nof pause-enriched transcripts in transformer-based language models to\ndifferentiate the cognitive states of subjects with no cognitive impairment,\nmild cognitive impairment, and Alzheimer's dementia based on their speech from\na clinical assessment. We address three binary classification tasks: Onset,\nmonitoring, and dementia exclusion. The performance is evaluated through\nexperiments on a German Verbal Fluency Test and a Picture Description Test,\ncomparing the model's effectiveness across different speech production\ncontexts. Starting from a textual baseline, we investigate the effect of\nincorporation of pause information and acoustic context. We show the test\nshould be chosen depending on the task, and similarly, lexical pause\ninformation and acoustic cross-attention contribute differently.", "published": "2024-08-27 16:44:41", "link": "http://arxiv.org/abs/2408.15188v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Can Unconfident LLM Annotations Be Used for Confident Conclusions?", "abstract": "Large language models (LLMs) have shown high agreement with human raters\nacross a variety of tasks, demonstrating potential to ease the challenges of\nhuman data collection. In computational social science (CSS), researchers are\nincreasingly leveraging LLM annotations to complement slow and expensive human\nannotations. Still, guidelines for collecting and using LLM annotations,\nwithout compromising the validity of downstream conclusions, remain limited. We\nintroduce Confidence-Driven Inference: a method that combines LLM annotations\nand LLM confidence indicators to strategically select which human annotations\nshould be collected, with the goal of producing accurate statistical estimates\nand provably valid confidence intervals while reducing the number of human\nannotations needed. Our approach comes with safeguards against LLM annotations\nof poor quality, guaranteeing that the conclusions will be both valid and no\nless accurate than if we only relied on human annotations. We demonstrate the\neffectiveness of Confidence-Driven Inference over baselines in statistical\nestimation tasks across three CSS settings--text politeness, stance, and\nbias--reducing the needed number of human annotations by over 25% in each.\nAlthough we use CSS settings for demonstration, Confidence-Driven Inference can\nbe used to estimate most standard quantities across a broad range of NLP\nproblems.", "published": "2024-08-27 17:03:18", "link": "http://arxiv.org/abs/2408.15204v2", "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "cs.CL"}
{"title": "LLM Defenses Are Not Robust to Multi-Turn Human Jailbreaks Yet", "abstract": "Recent large language model (LLM) defenses have greatly improved models'\nability to refuse harmful queries, even when adversarially attacked. However,\nLLM defenses are primarily evaluated against automated adversarial attacks in a\nsingle turn of conversation, an insufficient threat model for real-world\nmalicious use. We demonstrate that multi-turn human jailbreaks uncover\nsignificant vulnerabilities, exceeding 70% attack success rate (ASR) on\nHarmBench against defenses that report single-digit ASRs with automated\nsingle-turn attacks. Human jailbreaks also reveal vulnerabilities in machine\nunlearning defenses, successfully recovering dual-use biosecurity knowledge\nfrom unlearned models. We compile these results into Multi-Turn Human\nJailbreaks (MHJ), a dataset of 2,912 prompts across 537 multi-turn jailbreaks.\nWe publicly release MHJ alongside a compendium of jailbreak tactics developed\nacross dozens of commercial red teaming engagements, supporting research\ntowards stronger LLM defenses.", "published": "2024-08-27 17:33:30", "link": "http://arxiv.org/abs/2408.15221v2", "categories": ["cs.LG", "cs.CL", "cs.CR", "cs.CY"], "primary_category": "cs.LG"}
{"title": "Into the Unknown Unknowns: Engaged Human Learning through Participation\n  in Language Model Agent Conversations", "abstract": "While language model (LM)-powered chatbots and generative search engines\nexcel at answering concrete queries, discovering information in the terrain of\nunknown unknowns remains challenging for users. To emulate the common\neducational scenario where children/students learn by listening to and\nparticipating in conversations of their parents/teachers, we create\nCollaborative STORM (Co-STORM). Unlike QA systems that require users to ask all\nthe questions, Co-STORM lets users observe and occasionally steer the discourse\namong several LM agents. The agents ask questions on the user's behalf,\nallowing the user to discover unknown unknowns serendipitously. To facilitate\nuser interaction, Co-STORM assists users in tracking the discourse by\norganizing the uncovered information into a dynamic mind map, ultimately\ngenerating a comprehensive report as takeaways. For automatic evaluation, we\nconstruct the WildSeek dataset by collecting real information-seeking records\nwith user goals. Co-STORM outperforms baseline methods on both discourse trace\nand report quality. In a further human evaluation, 70% of participants prefer\nCo-STORM over a search engine, and 78% favor it over a RAG chatbot.", "published": "2024-08-27 17:50:03", "link": "http://arxiv.org/abs/2408.15232v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "I.2.7; H.5.2; H.3.3"], "primary_category": "cs.CL"}
{"title": "Learning Granularity Representation for Temporal Knowledge Graph\n  Completion", "abstract": "Temporal Knowledge Graphs (TKGs) incorporate temporal information to reflect\nthe dynamic structural knowledge and evolutionary patterns of real-world facts.\nNevertheless, TKGs are still limited in downstream applications due to the\nproblem of incompleteness. Consequently, TKG completion (also known as link\nprediction) has been widely studied, with recent research focusing on\nincorporating independent embeddings of time or combining them with entities\nand relations to form temporal representations. However, most existing methods\noverlook the impact of history from a multi-granularity aspect. The inherent\nsemantics of human-defined temporal granularities, such as ordinal dates,\nreveal general patterns to which facts typically adhere. To counter this\nlimitation, this paper proposes \\textbf{L}earning \\textbf{G}ranularity\n\\textbf{Re}presentation (termed $\\mathsf{LGRe}$) for TKG completion. It\ncomprises two main components: Granularity Representation Learning (GRL) and\nAdaptive Granularity Balancing (AGB). Specifically, GRL employs time-specific\nmulti-layer convolutional neural networks to capture interactions between\nentities and relations at different granularities. After that, AGB generates\nadaptive weights for these embeddings according to temporal semantics,\nresulting in expressive representations of predictions. Moreover, to reflect\nsimilar semantics of adjacent timestamps, a temporal loss function is\nintroduced. Extensive experimental results on four event benchmarks demonstrate\nthe effectiveness of $\\mathsf{LGRe}$ in learning time-related representations.\nTo ensure reproducibility, our code is available at\nhttps://github.com/KcAcoZhang/LGRe.", "published": "2024-08-27 08:19:34", "link": "http://arxiv.org/abs/2408.15293v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "YOLO-Stutter: End-to-end Region-Wise Speech Dysfluency Detection", "abstract": "Dysfluent speech detection is the bottleneck for disordered speech analysis\nand spoken language learning. Current state-of-the-art models are governed by\nrule-based systems which lack efficiency and robustness, and are sensitive to\ntemplate design. In this paper, we propose YOLO-Stutter: a first end-to-end\nmethod that detects dysfluencies in a time-accurate manner. YOLO-Stutter takes\nimperfect speech-text alignment as input, followed by a spatial feature\naggregator, and a temporal dependency extractor to perform region-wise boundary\nand class predictions. We also introduce two dysfluency corpus, VCTK-Stutter\nand VCTK-TTS, that simulate natural spoken dysfluencies including repetition,\nblock, missing, replacement, and prolongation. Our end-to-end method achieves\nstate-of-the-art performance with a minimum number of trainable parameters for\non both simulated data and real aphasia speech. Code and datasets are\nopen-sourced at https://github.com/rorizzz/YOLO-Stutter", "published": "2024-08-27 11:31:12", "link": "http://arxiv.org/abs/2408.15297v3", "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in\n  Language Models", "abstract": "Fine-tuning large language models (LLMs) on human preferences, typically\nthrough reinforcement learning from human feedback (RLHF), has proven\nsuccessful in enhancing their capabilities. However, ensuring the safety of\nLLMs during fine-tuning remains a critical concern, and mitigating the\npotential conflicts in safety and helpfulness is costly in RLHF. To address\nthis issue, we propose a supervised learning framework called Bi-Factorial\nPreference Optimization (BFPO), which re-parameterizes a joint RLHF objective\nof both safety and helpfulness into a single supervised learning objective. In\nsupervised optimization, a labeling function is used to capture the global\npreferences ranking to balance both safety and helpfulness. To evaluate BFPO,\nwe develop a benchmark that includes comprehensive discriminative and\ngenerative tasks for helpfulness and harmlessness. The results indicate that\nour method significantly outperforms existing approaches in both safety and\nhelpfulness. Moreover, BFPO achieves the same level of safety as methods that\nheavily rely on human labor with less than 10\\% of the computational resources\nand human prompting and annotation process. The training recipes can be found\nhere: https://github.com/wx-zhang/bfpo.", "published": "2024-08-27 17:31:21", "link": "http://arxiv.org/abs/2408.15313v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A Statistical Framework for Data-dependent Retrieval-Augmented Models", "abstract": "Modern ML systems increasingly augment input instances with additional\nrelevant information to enhance final prediction. Despite growing interest in\nsuch retrieval-augmented models, their fundamental properties and training are\nnot well understood. We propose a statistical framework to study such models\nwith two components: 1) a {\\em retriever} to identify the relevant information\nout of a large corpus via a data-dependent metric; and 2) a {\\em predictor}\nthat consumes the input instances along with the retrieved information to make\nthe final predictions. We present a principled method for end-to-end training\nof both components and draw connections with various training approaches in the\nliterature. Furthermore, we establish excess risk bounds for\nretrieval-augmented models while delineating the contributions of both\nretriever and predictor towards the model performance. We validate the utility\nof our proposed training methods along with the key takeaways from our\nstatistical analysis on open domain question answering task where retrieval\naugmentation is important.", "published": "2024-08-27 20:51:06", "link": "http://arxiv.org/abs/2408.15399v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Intertwined Biases Across Social Media Spheres: Unpacking Correlations\n  in Media Bias Dimensions", "abstract": "Media bias significantly shapes public perception by reinforcing stereotypes\nand exacerbating societal divisions. Prior research has often focused on\nisolated media bias dimensions such as \\textit{political bias} or\n\\textit{racial bias}, neglecting the complex interrelationships among various\nbias dimensions across different topic domains. Moreover, we observe that\nmodels trained on existing media bias benchmarks fail to generalize effectively\non recent social media posts, particularly in certain bias identification\ntasks. This shortfall primarily arises because these benchmarks do not\nadequately reflect the rapidly evolving nature of social media content, which\nis characterized by shifting user behaviors and emerging trends. In response to\nthese limitations, our research introduces a novel dataset collected from\nYouTube and Reddit over the past five years. Our dataset includes automated\nannotations for YouTube content across a broad spectrum of bias dimensions,\nsuch as gender, racial, and political biases, as well as hate speech, among\nothers. It spans diverse domains including politics, sports, healthcare,\neducation, and entertainment, reflecting the complex interplay of biases across\ndifferent societal sectors. Through comprehensive statistical analysis, we\nidentify significant differences in bias expression patterns and intra-domain\nbias correlations across these domains. By utilizing our understanding of the\ncorrelations among various bias dimensions, we lay the groundwork for creating\nadvanced systems capable of detecting multiple biases simultaneously. Overall,\nour dataset advances the field of media bias identification, contributing to\nthe development of tools that promote fairer media consumption. The\ncomprehensive awareness of existing media bias fosters more ethical journalism,\npromotes cultural sensitivity, and supports a more informed and equitable\npublic discourse.", "published": "2024-08-27 21:03:42", "link": "http://arxiv.org/abs/2408.15406v1", "categories": ["cs.SI", "cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.SI"}
{"title": "Non-instructional Fine-tuning: Enabling Instruction-Following\n  Capabilities in Pre-trained Language Models without Instruction-Following\n  Data", "abstract": "Instruction fine-tuning is crucial for today's large language models (LLMs)\nto learn to follow instructions and align with human preferences.\nConventionally, supervised data, including the instruction and the correct\nresponse, is required for instruction fine-tuning. To obtain such data, some\nresearchers prompted well-trained models like GPT-4 to generate instructions\nand correct responses. In this paper, we propose a novel approach that uses the\nfirst half of a random text from OpenWebText as the instruction and\nGPT-3.5-turbo or GPT-4-turbo to complete the text as the response. Despite the\ndata being \"non-instructional\", we found that pre-trained LLMs fine-tuned on\nthis data can gain instruction-following capabilities. This observation is\nverified by fine-tuning several well-known pre-trained LLMs (e.g., LLaMA-2-7B,\nLLaMA-3-8B, LLaMA-3-70B, Mistral-7B-v0.1). The \"non-instructional data\" also\nimproved some models that underwent supervised fine-tuning and human preference\nalignment. Our LLaMA-3-70B-Instruct fine-tuned through \"non-instructional data\"\nis comparable with LLaMA-3.1-70B-Instruct on the Arena Hard leaderboard. We\nanalyzed the \"non-instructional data\" and ensured it is devoid of content\nrelated to instruction fine-tuning. Our findings will inspire further\ninvestigation into how to develop instruction-following capabilities without\nexplicit instruction-related data.", "published": "2024-08-27 01:21:53", "link": "http://arxiv.org/abs/2409.00096v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Query-by-Example Keyword Spotting Using Spectral-Temporal Graph\n  Attentive Pooling and Multi-Task Learning", "abstract": "Existing keyword spotting (KWS) systems primarily rely on predefined keyword\nphrases. However, the ability to recognize customized keywords is crucial for\ntailoring interactions with intelligent devices. In this paper, we present a\nnovel Query-by-Example (QbyE) KWS system that employs spectral-temporal graph\nattentive pooling and multi-task learning. This framework aims to effectively\nlearn speaker-invariant and linguistic-informative embeddings for QbyE KWS\ntasks. Within this framework, we investigate three distinct network\narchitectures for encoder modeling: LiCoNet, Conformer and ECAPA_TDNN. The\nexperimental results on a substantial internal dataset of $629$ speakers have\ndemonstrated the effectiveness of the proposed QbyE framework in maximizing the\npotential of simpler models such as LiCoNet. Particularly, LiCoNet, which is\n13x more efficient, achieves comparable performance to the computationally\nintensive Conformer model (1.98% vs. 1.63\\% FRR at 0.3 FAs/Hr).", "published": "2024-08-27 03:44:57", "link": "http://arxiv.org/abs/2409.00099v2", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Negation Blindness in Large Language Models: Unveiling the NO Syndrome\n  in Image Generation", "abstract": "Foundational Large Language Models (LLMs) have changed the way we perceive\ntechnology. They have been shown to excel in tasks ranging from poem writing\nand coding to essay generation and puzzle solving. With the incorporation of\nimage generation capability, they have become more comprehensive and versatile\nAI tools. At the same time, researchers are striving to identify the\nlimitations of these tools to improve them further. Currently identified flaws\ninclude hallucination, biases, and bypassing restricted commands to generate\nharmful content. In the present work, we have identified a fundamental\nlimitation related to the image generation ability of LLMs, and termed it The\nNO Syndrome. This negation blindness refers to LLMs inability to correctly\ncomprehend NO related natural language prompts to generate the desired images.\nInterestingly, all tested LLMs including GPT-4, Gemini, and Copilot were found\nto be suffering from this syndrome. To demonstrate the generalization of this\nlimitation, we carried out simulation experiments and conducted entropy-based\nand benchmark statistical analysis tests on various LLMs in multiple languages,\nincluding English, Hindi, and French. We conclude that the NO syndrome is a\nsignificant flaw in current LLMs that needs to be addressed. A related finding\nof this study showed a consistent discrepancy between image and textual\nresponses as a result of this NO syndrome. We posit that the introduction of a\nnegation context-aware reinforcement learning based feedback loop between the\nLLMs textual response and generated image could help ensure the generated text\nis based on both the LLMs correct contextual understanding of the negation\nquery and the generated visual output.", "published": "2024-08-27 14:40:16", "link": "http://arxiv.org/abs/2409.00105v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Visual Reasoning by Vision-Language Models: Benchmarking and\n  Analysis", "abstract": "Vision-language models (VLMs) have shown impressive zero- and few-shot\nperformance on real-world visual question answering (VQA) benchmarks, alluding\nto their capabilities as visual reasoning engines. However, the benchmarks\nbeing used conflate \"pure\" visual reasoning with world knowledge, and also have\nquestions that involve a limited number of reasoning steps. Thus, it remains\nunclear whether a VLM's apparent visual reasoning performance is due to its\nworld knowledge, or due to actual visual reasoning capabilities.\n  To clarify this ambiguity, we systematically benchmark and dissect the\nzero-shot visual reasoning capabilities of VLMs through synthetic datasets that\nrequire minimal world knowledge, and allow for analysis over a broad range of\nreasoning steps. We focus on two novel aspects of zero-shot visual reasoning:\ni) evaluating the impact of conveying scene information as either visual\nembeddings or purely textual scene descriptions to the underlying large\nlanguage model (LLM) of the VLM, and ii) comparing the effectiveness of\nchain-of-thought prompting to standard prompting for zero-shot visual\nreasoning.\n  We find that the underlying LLMs, when provided textual scene descriptions,\nconsistently perform better compared to being provided visual embeddings. In\nparticular, 18% higher accuracy is achieved on the PTR dataset. We also find\nthat CoT prompting performs marginally better than standard prompting only for\nthe comparatively large GPT-3.5-Turbo (175B) model, and does worse for\nsmaller-scale models. This suggests the emergence of CoT abilities for visual\nreasoning in LLMs at larger scales even when world knowledge is limited.\nOverall, we find limitations in the abilities of VLMs and LLMs for more complex\nvisual reasoning, and highlight the important role that LLMs can play in visual\nreasoning.", "published": "2024-08-27 14:43:54", "link": "http://arxiv.org/abs/2409.00106v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Toward Large Language Models as a Therapeutic Tool: Comparing Prompting\n  Techniques to Improve GPT-Delivered Problem-Solving Therapy", "abstract": "While Large Language Models (LLMs) are being quickly adapted to many domains,\nincluding healthcare, their strengths and pitfalls remain under-explored. In\nour study, we examine the effects of prompt engineering to guide Large Language\nModels (LLMs) in delivering parts of a Problem-Solving Therapy (PST) session\nvia text, particularly during the symptom identification and assessment phase\nfor personalized goal setting. We present evaluation results of the models'\nperformances by automatic metrics and experienced medical professionals. We\ndemonstrate that the models' capability to deliver protocolized therapy can be\nimproved with the proper use of prompt engineering methods, albeit with\nlimitations. To our knowledge, this study is among the first to assess the\neffects of various prompting techniques in enhancing a generalist model's\nability to deliver psychotherapy, focusing on overall quality, consistency, and\nempathy. Exploring LLMs' potential in delivering psychotherapy holds promise\nwith the current shortage of mental health professionals amid significant\nneeds, enhancing the potential utility of AI-based and AI-enhanced care\nservices.", "published": "2024-08-27 17:25:16", "link": "http://arxiv.org/abs/2409.00112v1", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.HC", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Impact of Noisy Labels on Sound Event Detection: Deletion Errors Are\n  More Detrimental Than Insertion Errors", "abstract": "This study explores the critical but underexamined impact of label noise on\nSound Event Detection (SED), which requires both sound identification and\nprecise temporal localization. We categorize label noise into deletion,\ninsertion, substitution, and subjective types and systematically evaluate their\neffects on SED using synthetic and real-life datasets. Our analysis shows that\ndeletion noise significantly degrades performance, while insertion noise is\nrelatively benign. Moreover, loss functions effective against classification\nnoise do not perform well for SED due to intra-class imbalance between\nforeground sound events and background sounds. We demonstrate that loss\nfunctions designed to address data imbalance in SED can effectively reduce the\nimpact of noisy labels on system performance. For instance, halving the weight\nof background sounds in a synthetic dataset improved macro-F1 and micro-F1\nscores by approximately $9\\%$ with minimal Error Rate increase, with consistent\nresults in real-life datasets. This research highlights the nuanced effects of\nnoisy labels on SED systems and provides practical strategies to enhance model\nrobustness, which are pivotal for both constructing new SED datasets and\nimproving model performance, including efficient utilization of soft and\ncrowdsourced labels.", "published": "2024-08-27 04:18:39", "link": "http://arxiv.org/abs/2408.14771v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Similarity Metrics For Late Reverberation", "abstract": "Automatic tuning of reverberation algorithms relies on the optimization of a\ncost function. While general audio similarity metrics are useful, they are not\noptimized for the specific statistical properties of reverberation in rooms.\nThis paper presents two novel metrics for assessing the similarity of late\nreverberation in room impulse responses. These metrics are differentiable and\ncan be utilized within a machine-learning framework. We compare the performance\nof these metrics to two popular audio metrics using a large dataset of room\nimpulse responses encompassing various room configurations and microphone\npositions. The results indicate that the proposed functions based on averaged\npower and frequency-band energy decay outperform the baselines with the former\nexhibiting the most suitable profile towards the minimum. The proposed work\nholds promise as an improvement to the design and evaluation of reverberation\nsimilarity metrics.", "published": "2024-08-27 07:44:58", "link": "http://arxiv.org/abs/2408.14836v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Integrating Continuous and Binary Relevances in Audio-Text Relevance\n  Learning", "abstract": "Audio-text relevance learning refers to learning the shared semantic\nproperties of audio samples and textual descriptions. The standard approach\nuses binary relevances derived from pairs of audio samples and their\nhuman-provided captions, categorizing each pair as either positive or negative.\nThis may result in suboptimal systems due to varying levels of relevance\nbetween audio samples and captions. In contrast, a recent study used\nhuman-assigned relevance ratings, i.e., continuous relevances, for these pairs\nbut did not obtain performance gains in audio-text relevance learning. This\nwork introduces a relevance learning method that utilizes both human-assigned\ncontinuous relevance ratings and binary relevances using a combination of a\nlistwise ranking objective and a contrastive learning objective. Experimental\nresults demonstrate the effectiveness of the proposed method, showing\nimprovements in language-based audio retrieval, a downstream task in audio-text\nrelevance learning. In addition, we analyze how properties of the captions or\naudio clips contribute to the continuous audio-text relevances provided by\nhumans or learned by the machine.", "published": "2024-08-27 10:23:26", "link": "http://arxiv.org/abs/2408.14939v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Is Audio Spoof Detection Robust to Laundering Attacks?", "abstract": "Voice-cloning (VC) systems have seen an exceptional increase in the realism\nof synthesized speech in recent years. The high quality of synthesized speech\nand the availability of low-cost VC services have given rise to many potential\nabuses of this technology. Several detection methodologies have been proposed\nover the years that can detect voice spoofs with reasonably good accuracy.\nHowever, these methodologies are mostly evaluated on clean audio databases,\nsuch as ASVSpoof 2019. This paper evaluates SOTA Audio Spoof Detection\napproaches in the presence of laundering attacks. In that regard, a new\nlaundering attack database, called the ASVSpoof Laundering Database, is\ncreated. This database is based on the ASVSpoof 2019 (LA) eval database\ncomprising a total of 1388.22 hours of audio recordings. Seven SOTA audio spoof\ndetection approaches are evaluated on this laundered database. The results\nindicate that SOTA systems perform poorly in the presence of aggressive\nlaundering attacks, especially reverberation and additive noise attacks. This\nsuggests the need for robust audio spoof detection.", "published": "2024-08-27 00:35:29", "link": "http://arxiv.org/abs/2408.14712v1", "categories": ["eess.AS", "eess.SP"], "primary_category": "eess.AS"}
{"title": "Physics-Informed Machine Learning For Sound Field Estimation", "abstract": "The area of study concerning the estimation of spatial sound, i.e., the\ndistribution of a physical quantity of sound such as acoustic pressure, is\ncalled sound field estimation, which is the basis for various applied\ntechnologies related to spatial audio processing. The sound field estimation\nproblem is formulated as a function interpolation problem in machine learning\nin a simplified scenario. However, high estimation performance cannot be\nexpected by simply applying general interpolation techniques that rely only on\ndata. The physical properties of sound fields are useful a priori information,\nand it is considered extremely important to incorporate them into the\nestimation. In this article, we introduce the fundamentals of physics-informed\nmachine learning (PIML) for sound field estimation and overview current\nPIML-based sound field estimation methods.", "published": "2024-08-27 01:54:00", "link": "http://arxiv.org/abs/2408.14731v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "VoiceTailor: Lightweight Plug-In Adapter for Diffusion-Based\n  Personalized Text-to-Speech", "abstract": "We propose VoiceTailor, a parameter-efficient speaker-adaptive text-to-speech\n(TTS) system, by equipping a pre-trained diffusion-based TTS model with a\npersonalized adapter. VoiceTailor identifies pivotal modules that benefit from\nthe adapter based on a weight change ratio analysis. We utilize Low-Rank\nAdaptation (LoRA) as a parameter-efficient adaptation method and incorporate\nthe adapter into pivotal modules of the pre-trained diffusion decoder. To\nachieve powerful adaptation performance with few parameters, we explore various\nguidance techniques for speaker adaptation and investigate the best strategies\nto strengthen speaker information. VoiceTailor demonstrates comparable speaker\nadaptation performance to existing adaptive TTS models by fine-tuning only\n0.25\\% of the total parameters. VoiceTailor shows strong robustness when\nadapting to a wide range of real-world speakers, as shown in the demo.", "published": "2024-08-27 02:30:44", "link": "http://arxiv.org/abs/2408.14739v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "MaskCycleGAN-based Whisper to Normal Speech Conversion", "abstract": "Whisper to normal speech conversion is an active area of research. Various\narchitectures based on generative adversarial networks have been proposed in\nthe recent past. Especially, recent study shows that MaskCycleGAN, which is a\nmask guided, and cyclic consistency keeping, generative adversarial network,\nperforms really well for voice conversion from spectrogram representations. In\nthe current work we present a MaskCycleGAN approach for the conversion of\nwhispered speech to normal speech. We find that tuning the mask parameters, and\npre-processing the signal with a voice activity detector provides superior\nperformance when compared to the existing approach. The wTIMIT dataset is used\nfor evaluation. Objective metrics such as PESQ and G-Loss are used to evaluate\nthe converted speech, along with subjective evaluation using mean opinion\nscore. The results show that the proposed approach offers considerable\nbenefits.", "published": "2024-08-27 06:07:18", "link": "http://arxiv.org/abs/2408.14797v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Leveraging Self-supervised Audio Representations for Data-Efficient\n  Acoustic Scene Classification", "abstract": "Acoustic scene classification (ASC) predominantly relies on supervised\napproaches. However, acquiring labeled data for training ASC models is often\ncostly and time-consuming. Recently, self-supervised learning (SSL) has emerged\nas a powerful method for extracting features from unlabeled audio data,\nbenefiting many downstream audio tasks. This paper proposes a data-efficient\nand low-complexity ASC system by leveraging self-supervised audio\nrepresentations extracted from general-purpose audio datasets. We introduce\nBEATs, an audio SSL pre-trained model, to extract the general representations\nfrom AudioSet. Through extensive experiments, it has been demonstrated that the\nself-supervised audio representations can help to achieve high ASC accuracy\nwith limited labeled fine-tuning data. Furthermore, we find that ensembling the\nSSL models fine-tuned with different strategies contributes to a further\nperformance improvement. To meet low-complexity requirements, we use knowledge\ndistillation to transfer the self-supervised knowledge from large teacher\nmodels to an efficient student model. The experimental results suggest that the\nself-supervised teachers effectively improve the classification accuracy of the\nstudent model. Our best-performing system obtains an average accuracy of 56.7%.", "published": "2024-08-27 08:33:26", "link": "http://arxiv.org/abs/2408.14862v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Literary and Colloquial Dialect Identification for Tamil using Acoustic\n  Features", "abstract": "The evolution and diversity of a language is evident from it's various\ndialects. If the various dialects are not addressed in technological\nadvancements like automatic speech recognition and speech synthesis, there is a\nchance that these dialects may disappear. Speech technology plays a role in\npreserving various dialects of a language from going extinct. In order to build\na full fledged automatic speech recognition system that addresses various\ndialects, an Automatic Dialect Identification (ADI) system acting as the front\nend is required. This is similar to how language identification systems act as\nfront ends to automatic speech recognition systems that handle multiple\nlanguages. The current work proposes a way to identify two popular and broadly\nclassified Tamil dialects, namely literary and colloquial Tamil. Acoustical\ncharacteristics rather than phonetics and phonotactics are used, alleviating\nthe requirement of language-dependant linguistic tools. Hence one major\nadvantage of the proposed method is that it does not require an annotated\ncorpus, hence it can be easily adapted to other languages. Gaussian Mixture\nModels (GMM) using Mel Frequency Cepstral Coefficient (MFCC) features are used\nto perform the classification task. The experiments yielded an error rate of\n12%. Vowel nasalization, as being the reason for this good performance, is\ndiscussed. The number of mixture models for the GMM is varied and the\nperformance is analysed.", "published": "2024-08-27 09:00:27", "link": "http://arxiv.org/abs/2408.14887v1", "categories": ["eess.AS", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Examining the Interplay Between Privacy and Fairness for Speech\n  Processing: A Review and Perspective", "abstract": "Speech technology has been increasingly deployed in various areas of daily\nlife including sensitive domains such as healthcare and law enforcement. For\nthese technologies to be effective, they must work reliably for all users while\npreserving individual privacy. Although tradeoffs between privacy and utility,\nas well as fairness and utility, have been extensively researched, the specific\ninterplay between privacy and fairness in speech processing remains\nunderexplored. This review and position paper offers an overview of emerging\nprivacy-fairness tradeoffs throughout the entire machine learning lifecycle for\nspeech processing. By drawing on well-established frameworks on fairness and\nprivacy, we examine existing biases and sources of privacy harm that coexist\nduring the development of speech processing models. We then highlight how\ncorresponding privacy-enhancing technologies have the potential to\ninadvertently increase these biases and how bias mitigation strategies may\nconversely reduce privacy. By raising open questions, we advocate for a\ncomprehensive evaluation of privacy-fairness tradeoffs for speech technology\nand the development of privacy-enhancing and fairness-aware algorithms in this\ndomain.", "published": "2024-08-27 20:32:01", "link": "http://arxiv.org/abs/2408.15391v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "StyleSpeech: Parameter-efficient Fine Tuning for Pre-trained\n  Controllable Text-to-Speech", "abstract": "This paper introduces StyleSpeech, a novel Text-to-Speech~(TTS) system that\nenhances the naturalness and accuracy of synthesized speech. Building upon\nexisting TTS technologies, StyleSpeech incorporates a unique Style Decorator\nstructure that enables deep learning models to simultaneously learn style and\nphoneme features, improving adaptability and efficiency through the principles\nof Lower Rank Adaptation~(LoRA). LoRA allows efficient adaptation of style\nfeatures in pre-trained models. Additionally, we introduce a novel automatic\nevaluation metric, the LLM-Guided Mean Opinion Score (LLM-MOS), which employs\nlarge language models to offer an objective and robust protocol for\nautomatically assessing TTS system performance. Extensive testing on benchmark\ndatasets shows that our approach markedly outperforms existing state-of-the-art\nbaseline methods in producing natural, accurate, and high-quality speech. These\nadvancements not only pushes the boundaries of current TTS system capabilities,\nbut also facilitate the application of TTS system in more dynamic and\nspecialized, such as interactive virtual assistants, adaptive audiobooks, and\ncustomized voice for gaming. Speech samples can be found in\nhttps://style-speech.vercel.app", "published": "2024-08-27 00:37:07", "link": "http://arxiv.org/abs/2408.14713v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CoopASD: Cooperative Machine Anomalous Sound Detection with Privacy\n  Concerns", "abstract": "Machine anomalous sound detection (ASD) has emerged as one of the most\npromising applications in the Industrial Internet of Things (IIoT) due to its\nunprecedented efficacy in mitigating risks of malfunctions and promoting\nproduction efficiency. Previous works mainly investigated the machine ASD task\nunder centralized settings. However, developing the ASD system under\ndecentralized settings is crucial in practice, since the machine data are\ndispersed in various factories and the data should not be explicitly shared due\nto privacy concerns. To enable these factories to cooperatively develop a\nscalable ASD model while preserving their privacy, we propose a novel framework\nnamed CoopASD, where each factory trains an ASD model on its local dataset, and\na central server aggregates these local models periodically. We employ a\npre-trained model as the backbone of the ASD model to improve its robustness\nand develop specialized techniques to stabilize the model under a completely\nnon-iid and domain shift setting. Compared with previous state-of-the-art\n(SOTA) models trained in centralized settings, CoopASD showcases competitive\nresults with negligible degradation of 0.08%. We also conduct extensive\nablation studies to demonstrate the effectiveness of CoopASD.", "published": "2024-08-27 03:07:03", "link": "http://arxiv.org/abs/2408.14753v1", "categories": ["cs.SD", "cs.AI", "cs.DC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quartered Chirp Spectral Envelope for Whispered vs Normal Speech\n  Classification", "abstract": "Whispered speech as an acceptable form of human-computer interaction is\ngaining traction. Systems that address multiple modes of speech require a\nrobust front-end speech classifier. Performance of whispered vs normal speech\nclassification drops in the presence of additive white Gaussian noise, since\nnormal speech takes on some of the characteristics of whispered speech. In this\nwork, we propose a new feature named the quartered chirp spectral envelope, a\ncombination of the chirp spectrum and the quartered spectral envelope, to\nclassify whispered and normal speech. The chirp spectrum can be fine-tuned to\nobtain customized features for a given task, and the quartered spectral\nenvelope has been proven to work especially well for the current task. The\nfeature is trained on a one dimensional convolutional neural network, that\ncaptures the trends in the spectral envelope. The proposed system performs\nbetter than the state of the art, in the presence of white noise.", "published": "2024-08-27 04:56:22", "link": "http://arxiv.org/abs/2408.14777v1", "categories": ["eess.AS", "cs.LG", "eess.SP"], "primary_category": "eess.AS"}
{"title": "The VoxCeleb Speaker Recognition Challenge: A Retrospective", "abstract": "The VoxCeleb Speaker Recognition Challenges (VoxSRC) were a series of\nchallenges and workshops that ran annually from 2019 to 2023. The challenges\nprimarily evaluated the tasks of speaker recognition and diarisation under\nvarious settings including: closed and open training data; as well as\nsupervised, self-supervised, and semi-supervised training for domain\nadaptation. The challenges also provided publicly available training and\nevaluation datasets for each task and setting, with new test sets released each\nyear. In this paper, we provide a review of these challenges that covers: what\nthey explored; the methods developed by the challenge participants and how\nthese evolved; and also the current state of the field for speaker verification\nand diarisation. We chart the progress in performance over the five\ninstallments of the challenge on a common evaluation dataset and provide a\ndetailed analysis of how each year's special focus affected participants'\nperformance. This paper is aimed both at researchers who want an overview of\nthe speaker recognition and diarisation field, and also at challenge organisers\nwho want to benefit from the successes and avoid the mistakes of the VoxSRC\nchallenges. We end with a discussion of the current strengths of the field and\nopen challenges. Project page :\nhttps://mm.kaist.ac.kr/datasets/voxceleb/voxsrc/workshop.html", "published": "2024-08-27 08:57:31", "link": "http://arxiv.org/abs/2408.14886v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Development of Large Annotated Music Datasets using HMM-based Forced\n  Viterbi Alignment", "abstract": "Datasets are essential for any machine learning task. Automatic Music\nTranscription (AMT) is one such task, where considerable amount of data is\nrequired depending on the way the solution is achieved. Considering the fact\nthat a music dataset, complete with audio and its time-aligned transcriptions\nwould require the effort of people with musical experience, it could be stated\nthat the task becomes even more challenging. Musical experience is required in\nplaying the musical instrument(s), and in annotating and verifying the\ntranscriptions. We propose a method that would help in streamlining this\nprocess, making the task of obtaining a dataset from a particular instrument\neasy and efficient. We use predefined guitar exercises and hidden Markov\nmodel(HMM) based forced viterbi alignment to accomplish this. The guitar\nexercises are designed to be simple. Since the note sequence are already\ndefined, HMM based forced viterbi alignment provides time-aligned\ntranscriptions of these audio files. The onsets of the transcriptions are\nmanually verified and the labels are accurate up to 10ms, averaging at 5ms. The\ncontributions of the proposed work is two fold, i) a well streamlined and\nefficient method for generating datasets for any instrument, especially\nmonophonic and, ii) an acoustic plectrum guitar dataset containing wave files\nand transcriptions in the form of label files. This method will aid as a\npreliminary step towards building concrete datasets for building AMT systems\nfor different instruments.", "published": "2024-08-27 09:06:29", "link": "http://arxiv.org/abs/2408.14890v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Deep learning classification system for coconut maturity levels based on\n  acoustic signals", "abstract": "The advancement of computer image processing, pattern recognition, signal\nprocessing, and other technologies has gradually replaced the manual methods of\nclassifying fruit with computer and mechanical methods. In the field of\nagriculture, the intelligent classification of post-harvested fruit has enabled\nthe use of smart devices that creates a direct impact on farmers, especially on\nexport products. For coconut classification, it remains to be traditional in\nprocess. This study presents a classification of the coconut dataset based on\nacoustic signals. To address the imbalanced dataset, a data augmentation\ntechnique was conducted through audiomentation and procedural audio generation\nmethods. Audio signals under premature, mature, and overmature now have 4,050,\n4,050, and 5,850 audio signals, respectively. To address the updation of the\nclassification system and the classification accuracy performance, deep\nlearning models were utilized for classifying the generated audio signals from\ndata generation. Specifically, RNN and LSTM models were trained and tested, and\ntheir performances were compared with each other and the machine learning\nmethods used by Caladcad et al. (2020). The two DL models showed impressive\nperformance with both having an accuracy of 97.42% and neither of them\noutperformed the other since there are no significant differences in their\nclassification performance.", "published": "2024-08-27 09:37:19", "link": "http://arxiv.org/abs/2408.14910v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "Morphogenesis of sound creates acoustic rainbows", "abstract": "Sound is an essential sensing element for many organisms in nature, and\nmultiple species have evolved organic structures that create complex acoustic\nscattering and dispersion phenomena to emit and perceive sound unambiguously.\nTo date, it has not proven possible to design artificial scattering structures\nthat rival the performance of those found in organic structures. Contrarily,\nmost sound manipulation relies on active transduction in fluid media rather\nthan relying on passive scattering principles, as are often found in nature. In\nthis work, we utilize computational morphogenesis to synthesize complex\nenergy-efficient wavelength-sized single-material scattering structures that\npassively decompose radiated sound into its spatio-spectral components.\nSpecifically, we tailor an acoustic rainbow structure with \"above unity\"\nefficiency and an acoustic wavelength-splitter. Our work paves the way for a\nnew frontier in sound-field engineering, with potential applications in\ntransduction, bionics, energy harvesting, communications and sensing.", "published": "2024-08-27 10:57:01", "link": "http://arxiv.org/abs/2408.14953v1", "categories": ["cs.SD", "eess.AS", "math.OC", "physics.app-ph"], "primary_category": "cs.SD"}
{"title": "Feature Representations for Automatic Meerkat Vocalization\n  Classification", "abstract": "Understanding evolution of vocal communication in social animals is an\nimportant research problem. In that context, beyond humans, there is an\ninterest in analyzing vocalizations of other social animals such as, meerkats,\nmarmosets, apes. While existing approaches address vocalizations of certain\nspecies, a reliable method tailored for meerkat calls is lacking. To that\nextent, this paper investigates feature representations for automatic meerkat\nvocalization analysis. Both traditional signal processing-based representations\nand data-driven representations facilitated by advances in deep learning are\nexplored. Call type classification studies conducted on two data sets reveal\nthat feature extraction methods developed for human speech processing can be\neffectively employed for automatic meerkat call analysis.", "published": "2024-08-27 10:51:51", "link": "http://arxiv.org/abs/2408.15296v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
