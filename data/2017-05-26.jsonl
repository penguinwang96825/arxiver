{"title": "Biomedical Event Trigger Identification Using Bidirectional Recurrent\n  Neural Network Based Models", "abstract": "Biomedical events describe complex interactions between various biomedical\nentities. Event trigger is a word or a phrase which typically signifies the\noccurrence of an event. Event trigger identification is an important first step\nin all event extraction methods. However many of the current approaches either\nrely on complex hand-crafted features or consider features only within a\nwindow. In this paper we propose a method that takes the advantage of recurrent\nneural network (RNN) to extract higher level features present across the\nsentence. Thus hidden state representation of RNN along with word and entity\ntype embedding as features avoid relying on the complex hand-crafted features\ngenerated using various NLP toolkits. Our experiments have shown to achieve\nstate-of-art F1-score on Multi Level Event Extraction (MLEE) corpus. We have\nalso performed category-wise analysis of the result and discussed the\nimportance of various features in trigger identification task.", "published": "2017-05-26 10:36:12", "link": "http://arxiv.org/abs/1705.09516v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting and Explaining Crisis", "abstract": "Individuals on social media may reveal themselves to be in various states of\ncrisis (e.g. suicide, self-harm, abuse, or eating disorders). Detecting crisis\nfrom social media text automatically and accurately can have profound\nconsequences. However, detecting a general state of crisis without explaining\nwhy has limited applications. An explanation in this context is a coherent,\nconcise subset of the text that rationalizes the crisis detection. We explore\nseveral methods to detect and explain crisis using a combination of neural and\nnon-neural techniques. We evaluate these techniques on a unique data set\nobtained from Koko, an anonymous emotional support network available through\nvarious messaging applications. We annotate a small subset of the samples\nlabeled with crisis with corresponding explanations. Our best technique\nsignificantly outperforms the baseline for detection and explanation.", "published": "2017-05-26 13:44:54", "link": "http://arxiv.org/abs/1705.09585v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Semi-Supervised Model Training for Unbounded Conversational Speech\n  Recognition", "abstract": "For conversational large-vocabulary continuous speech recognition (LVCSR)\ntasks, up to about two thousand hours of audio is commonly used to train state\nof the art models. Collection of labeled conversational audio however, is\nprohibitively expensive, laborious and error-prone. Furthermore, academic\ncorpora like Fisher English (2004) or Switchboard (1992) are inadequate to\ntrain models with sufficient accuracy in the unbounded space of conversational\nspeech. These corpora are also timeworn due to dated acoustic telephony\nfeatures and the rapid advancement of colloquial vocabulary and idiomatic\nspeech over the last decades. Utilizing the colossal scale of our unlabeled\ntelephony dataset, we propose a technique to construct a modern, high quality\nconversational speech training corpus on the order of hundreds of millions of\nutterances (or tens of thousands of hours) for both acoustic and language model\ntraining. We describe the data collection, selection and training, evaluating\nthe results of our updated speech recognition system on a test corpus of 7K\nmanually transcribed utterances. We show relative word error rate (WER)\nreductions of {35%, 19%} on {agent, caller} utterances over our seed model and\n5% absolute WER improvements over IBM Watson STT on this conversational speech\ntask.", "published": "2017-05-26 21:10:15", "link": "http://arxiv.org/abs/1705.09724v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Style Transfer from Non-Parallel Text by Cross-Alignment", "abstract": "This paper focuses on style transfer on the basis of non-parallel text. This\nis an instance of a broad family of problems including machine translation,\ndecipherment, and sentiment modification. The key challenge is to separate the\ncontent from other aspects such as style. We assume a shared latent content\ndistribution across different text corpora, and propose a method that leverages\nrefined alignment of latent representations to perform style transfer. The\ntransferred sentences from one style should match example sentences from the\nother style as a population. We demonstrate the effectiveness of this\ncross-alignment method on three tasks: sentiment modification, decipherment of\nword substitution ciphers, and recovery of word order.", "published": "2017-05-26 17:40:12", "link": "http://arxiv.org/abs/1705.09655v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A WL-SPPIM Semantic Model for Document Classification", "abstract": "In this paper, we explore SPPIM-based text classification method, and the\nexperiment reveals that the SPPIM method is equal to or even superior than SGNS\nmethod in text classification task on three international and standard text\ndatasets, namely 20newsgroups, Reuters52 and WebKB. Comparing to SGNS, although\nSPPMI provides a better solution, it is not necessarily better than SGNS in\ntext classification tasks. Based on our analysis, SGNS takes into the\nconsideration of weight calculation during decomposition process, so it has\nbetter performance than SPPIM in some standard datasets. Inspired by this, we\npropose a WL-SPPIM semantic model based on SPPIM model, and experiment shows\nthat WL-SPPIM approach has better classification and higher scalability in the\ntext classification task compared with LDA, SGNS and SPPIM approaches.", "published": "2017-05-26 08:03:10", "link": "http://arxiv.org/abs/1706.01758v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ASR error management for improving spoken language understanding", "abstract": "This paper addresses the problem of automatic speech recognition (ASR) error\ndetection and their use for improving spoken language understanding (SLU)\nsystems. In this study, the SLU task consists in automatically extracting, from\nASR transcriptions , semantic concepts and concept/values pairs in a e.g\ntouristic information system. An approach is proposed for enriching the set of\nsemantic labels with error specific labels and by using a recently proposed\nneural approach based on word embeddings to compute well calibrated ASR\nconfidence measures. Experimental results are reported showing that it is\npossible to decrease significantly the Concept/Value Error Rate with a state of\nthe art system, outperforming previously published results performance on the\nsame experimental data. It also shown that combining an SLU approach based on\nconditional random fields with a neural encoder/decoder attention based\narchitecture , it is possible to effectively identifying confidence islands and\nuncertain semantic output segments useful for deciding appropriate error\nhandling actions by the dialogue manager strategy .", "published": "2017-05-26 10:34:24", "link": "http://arxiv.org/abs/1705.09515v1", "categories": ["cs.CL", "cs.AI", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Helping News Editors Write Better Headlines: A Recommender to Improve\n  the Keyword Contents & Shareability of News Headlines", "abstract": "We present a software tool that employs state-of-the-art natural language\nprocessing (NLP) and machine learning techniques to help newspaper editors\ncompose effective headlines for online publication. The system identifies the\nmost salient keywords in a news article and ranks them based on both their\noverall popularity and their direct relevance to the article. The system also\nuses a supervised regression model to identify headlines that are likely to be\nwidely shared on social media. The user interface is designed to simplify and\nspeed the editor's decision process on the composition of the headline. As\nsuch, the tool provides an efficient way to combine the benefits of automated\npredictors of engagement and search-engine optimization (SEO) with human\njudgments of overall headline quality.", "published": "2017-05-26 17:40:58", "link": "http://arxiv.org/abs/1705.09656v1", "categories": ["cs.CL", "cs.HC", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Community Identity and User Engagement in a Multi-Community Landscape", "abstract": "A community's identity defines and shapes its internal dynamics. Our current\nunderstanding of this interplay is mostly limited to glimpses gathered from\nisolated studies of individual communities. In this work we provide a\nsystematic exploration of the nature of this relation across a wide variety of\nonline communities. To this end we introduce a quantitative, language-based\ntypology reflecting two key aspects of a community's identity: how distinctive,\nand how temporally dynamic it is. By mapping almost 300 Reddit communities into\nthe landscape induced by this typology, we reveal regularities in how patterns\nof user engagement vary with the characteristics of a community.\n  Our results suggest that the way new and existing users engage with a\ncommunity depends strongly and systematically on the nature of the collective\nidentity it fosters, in ways that are highly consequential to community\nmaintainers. For example, communities with distinctive and highly dynamic\nidentities are more likely to retain their users. However, such niche\ncommunities also exhibit much larger acculturation gaps between existing users\nand newcomers, which potentially hinder the integration of the latter.\n  More generally, our methodology reveals differences in how various social\nphenomena manifest across communities, and shows that structuring the\nmulti-community landscape can lead to a better understanding of the systematic\nnature of this diversity.", "published": "2017-05-26 18:00:02", "link": "http://arxiv.org/abs/1705.09665v1", "categories": ["cs.SI", "cs.CL", "cs.CY", "physics.soc-ph"], "primary_category": "cs.SI"}
{"title": "Multiplex model of mental lexicon reveals explosive learning in humans", "abstract": "Word similarities affect language acquisition and use in a multi-relational\nway barely accounted for in the literature. We propose a multiplex network\nrepresentation of this mental lexicon of word similarities as a natural\nframework for investigating large-scale cognitive patterns. Our representation\naccounts for semantic, taxonomic, and phonological interactions and it\nidentifies a cluster of words which are used with greater frequency, are\nidentified, memorised, and learned more easily, and have more meanings than\nexpected at random. This cluster emerges around age 7 through an explosive\ntransition not reproduced by null models. We relate this explosive emergence to\npolysemy -- redundancy in word meanings. Results indicate that the word cluster\nacts as a core for the lexicon, increasing both lexical navigability and\nrobustness to linguistic degradation. Our findings provide quantitative\nconfirmation of existing conjectures about core structure in the mental lexicon\nand the importance of integrating multi-relational word-word interactions in\npsycholinguistic frameworks.", "published": "2017-05-26 22:18:39", "link": "http://arxiv.org/abs/1705.09731v3", "categories": ["physics.soc-ph", "cs.CL", "cs.SI", "nlin.AO"], "primary_category": "physics.soc-ph"}
