{"title": "Efficient Vector Representation for Documents through Corruption", "abstract": "We present an efficient document representation learning framework, Document\nVector through Corruption (Doc2VecC). Doc2VecC represents each document as a\nsimple average of word embeddings. It ensures a representation generated as\nsuch captures the semantic meanings of the document during learning. A\ncorruption model is included, which introduces a data-dependent regularization\nthat favors informative or rare words while forcing the embeddings of common\nand non-discriminative ones to be close to zero. Doc2VecC produces\nsignificantly better word embeddings than Word2Vec. We compare Doc2VecC with\nseveral state-of-the-art document representation learning algorithms. The\nsimple model architecture introduced by Doc2VecC matches or out-performs the\nstate-of-the-art in generating high-quality document representations for\nsentiment analysis, document classification as well as semantic relatedness\ntasks. The simplicity of the model enables training on billions of words per\nhour on a single machine. At the same time, the model is very efficient in\ngenerating representations of unseen documents at test time.", "published": "2017-07-08 00:57:01", "link": "http://arxiv.org/abs/1707.02377v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weakly Supervised Cross-Lingual Named Entity Recognition via Effective\n  Annotation and Representation Projection", "abstract": "The state-of-the-art named entity recognition (NER) systems are supervised\nmachine learning models that require large amounts of manually annotated data\nto achieve high accuracy. However, annotating NER data by human is expensive\nand time-consuming, and can be quite difficult for a new language. In this\npaper, we present two weakly supervised approaches for cross-lingual NER with\nno human annotation in a target language. The first approach is to create\nautomatically labeled NER data for a target language via annotation projection\non comparable corpora, where we develop a heuristic scheme that effectively\nselects good-quality projection-labeled data from noisy data. The second\napproach is to project distributed representations of words (word embeddings)\nfrom a target language to a source language, so that the source-language NER\nsystem can be applied to the target language without re-training. We also\ndesign two co-decoding schemes that effectively combine the outputs of the two\nprojection-based approaches. We evaluate the performance of the proposed\napproaches on both in-house and open NER data for several target languages. The\nresults show that the combined systems outperform three other weakly supervised\napproaches on the CoNLL data.", "published": "2017-07-08 19:45:47", "link": "http://arxiv.org/abs/1707.02483v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Predicting the Quality of Short Narratives from Social Media", "abstract": "An important and difficult challenge in building computational models for\nnarratives is the automatic evaluation of narrative quality. Quality evaluation\nconnects narrative understanding and generation as generation systems need to\nevaluate their own products. To circumvent difficulties in acquiring\nannotations, we employ upvotes in social media as an approximate measure for\nstory quality. We collected 54,484 answers from a crowd-powered\nquestion-and-answer website, Quora, and then used active learning to build a\nclassifier that labeled 28,320 answers as stories. To predict the number of\nupvotes without the use of social network features, we create neural networks\nthat model textual regions and the interdependence among regions, which serve\nas strong benchmarks for future research. To our best knowledge, this is the\nfirst large-scale study for automatic evaluation of narrative quality.", "published": "2017-07-08 21:30:40", "link": "http://arxiv.org/abs/1707.02499v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Improving Multilingual Named Entity Recognition with Wikipedia Entity\n  Type Mapping", "abstract": "The state-of-the-art named entity recognition (NER) systems are statistical\nmachine learning models that have strong generalization capability (i.e., can\nrecognize unseen entities that do not appear in training data) based on lexical\nand contextual information. However, such a model could still make mistakes if\nits features favor a wrong entity type. In this paper, we utilize Wikipedia as\nan open knowledge base to improve multilingual NER systems. Central to our\napproach is the construction of high-accuracy, high-coverage multilingual\nWikipedia entity type mappings. These mappings are built from weakly annotated\ndata and can be extended to new languages with no human annotation or\nlanguage-dependent knowledge involved. Based on these mappings, we develop\nseveral approaches to improve an NER system. We evaluate the performance of the\napproaches via experiments on NER systems trained for 6 languages. Experimental\nresults show that the proposed approaches are effective in improving the\naccuracy of such systems on unseen entities, especially when a system is\napplied to a new domain or it is trained with little training data (up to 18.3\nF1 score improvement).", "published": "2017-07-08 16:17:04", "link": "http://arxiv.org/abs/1707.02459v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
