{"title": "Examining European Press Coverage of the Covid-19 No-Vax Movement: An\n  NLP Framework", "abstract": "This paper examines how the European press dealt with the no-vax reactions\nagainst the Covid-19 vaccine and the dis- and misinformation associated with\nthis movement. Using a curated dataset of 1786 articles from 19 European\nnewspapers on the anti-vaccine movement over a period of 22 months in\n2020-2021, we used Natural Language Processing techniques including topic\nmodeling, sentiment analysis, semantic relationship with word embeddings,\npolitical analysis, named entity recognition, and semantic networks, to\nunderstand the specific role of the European traditional press in the\ndisinformation ecosystem. The results of this multi-angle analysis demonstrate\nthat the European well-established press actively opposed a variety of hoaxes\nmainly spread on social media, and was critical of the anti-vax trend,\nregardless of the political orientation of the newspaper. This confirms the\nrelevance of studying the role of high-quality press in the disinformation\necosystem.", "published": "2023-04-29 06:26:03", "link": "http://arxiv.org/abs/2305.00182v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Still no evidence for an effect of the proportion of non-native speakers\n  on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023)", "abstract": "In a recent paper published in the Journal of Language Evolution, Kauhanen,\nEinhaus & Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the\nresults presented in one of my papers (Koplenig, Royal Society Open Science, 6,\n181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show\nthrough a series of statistical analyses that large numbers of L2 (second\nlanguage) speakers do not seem to affect the (grammatical or statistical)\ncomplexity of a language. To this end, I focus on the way in which the\nEthnologue assesses language status: a language is characterised as vehicular\nif, in addition to being used by L1 (first language) speakers, it should also\nhave a significant number of L2 users. KEW criticise both the use of\nvehicularity as a (binary) indicator of whether a language has a significant\nnumber of L2 users and the idea of imputing a zero proportion of L2 speakers to\nnon-vehicular languages whenever a direct estimate of that proportion is\nunavailable. While I recognise the importance of post-publication commentary on\npublished research, I show in this rejoinder that both points of criticism are\nexplicitly mentioned and analysed in my paper. In addition, I also comment on\nother points raised by KEW and demonstrate that both alternative analyses\noffered by KEW do not stand up to closer scrutiny.", "published": "2023-04-29 09:58:32", "link": "http://arxiv.org/abs/2305.00217v6", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Hierarchical Dialogue Understanding with Special Tokens and Turn-level\n  Attention", "abstract": "Compared with standard text, understanding dialogue is more challenging for\nmachines as the dynamic and unexpected semantic changes in each turn. To model\nsuch inconsistent semantics, we propose a simple but effective Hierarchical\nDialogue Understanding model, HiDialog. Specifically, we first insert multiple\nspecial tokens into a dialogue and propose the turn-level attention to learn\nturn embeddings hierarchically. Then, a heterogeneous graph module is leveraged\nto polish the learned embeddings. We evaluate our model on various dialogue\nunderstanding tasks including dialogue relation extraction, dialogue emotion\nrecognition, and dialogue act classification. Results show that our simple\napproach achieves state-of-the-art performance on all three tasks above. All\nour source code is publicly available at https://github.com/ShawX825/HiDialog.", "published": "2023-04-29 13:53:48", "link": "http://arxiv.org/abs/2305.00262v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Cognitive Account of the Puzzle of Ideography", "abstract": "In this commentary article to 'The Puzzle of Ideography' by Morin, we put\nforth a new cognitive account of the puzzle of ideography, that complements the\nstandardization account of Morin. Efficient standardization of spoken language\nis phenomenologically attributed to a modality effect coupled with chunking of\ncognitive representations, further aided by multi-sensory integration and the\nserialized nature of attention. These cognitive mechanisms are crucial for\nexplaining why languages dominate graphic codes for general-purpose human\ncommunication.", "published": "2023-04-29 16:13:13", "link": "http://arxiv.org/abs/2305.00296v1", "categories": ["q-bio.NC", "cs.CL"], "primary_category": "q-bio.NC"}
{"title": "QICHWABASE: A Quechua Language and Knowledge Base for Quechua\n  Communities", "abstract": "Over the last decade, the Web has increasingly become a space of language and\nknowledge representation. However, it is only true for well-spread languages\nand well-established communities, while minority communities and their\nresources received less attention. In this paper, we propose QICHWABASE to\nsupport the harmonization process of the Quechua language and knowledge, and\nits community. For doing it, we adopt methods and tools that could become a\ngame changer in favour of Quechua communities around the world. We conclude\nthat the methodology and tools adopted on building QICHWABASE, which is a\nWikibase instance, could enhance the presence of minorities on the Web.", "published": "2023-04-29 09:14:55", "link": "http://arxiv.org/abs/2305.06173v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained\n  models", "abstract": "Through prompting, large-scale pre-trained models have become more expressive\nand powerful, gaining significant attention in recent years. Though these big\nmodels have zero-shot capabilities, in general, labeled data are still required\nto adapt them to downstream tasks. To overcome this critical limitation, we\npropose an unsupervised fine-tuning framework to directly fine-tune the model\nor prompt on the unlabeled target data. We demonstrate how to apply our method\nto both language-augmented vision and masked-language models by aligning the\ndiscrete distributions extracted from the prompts and target data. To verify\nour approach's applicability, we conduct extensive experiments on image\nclassification, sentiment analysis, and natural language inference tasks.\nAcross 13 image-related tasks and 15 language-related ones, the proposed\napproach achieves consistent improvements over the baselines.", "published": "2023-04-29 22:05:22", "link": "http://arxiv.org/abs/2305.00350v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Enhancing multilingual speech recognition in air traffic control by\n  sentence-level language identification", "abstract": "Automatic speech recognition (ASR) technique is becoming increasingly popular\nto improve the efficiency and safety of air traffic control (ATC) operations.\nHowever, the conversation between ATC controllers and pilots using multilingual\nspeech brings a great challenge to building high-accuracy ASR systems. In this\nwork, we present a two-stage multilingual ASR framework. The first stage is to\ntrain a language identifier (LID), that based on a recurrent neural network\n(RNN) to obtain sentence language identification in the form of one-hot\nencoding. The second stage aims to train an RNN-based end-to-end multilingual\nrecognition model that utilizes sentence language features generated by LID to\nenhance input features. In this work, We introduce Featurewise Linear\nModulation (FiLM) to improve the performance of multilingual ASR by utilizing\nsentence language identification. Furthermore, we introduce a new sentence\nlanguage identification learning module called SLIL, which consists of a FiLM\nlayer and a Squeeze-and-Excitation Networks layer. Extensive experiments on the\nATCSpeech dataset show that our proposed method outperforms the baseline model.\nCompared to the vanilla FiLMed backbone model, the proposed multilingual ASR\nmodel obtains about 7.50% character error rate relative performance\nimprovement.", "published": "2023-04-29 04:47:40", "link": "http://arxiv.org/abs/2305.00170v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Environmental sound synthesis from vocal imitations and sound event\n  labels", "abstract": "One way of expressing an environmental sound is using vocal imitations, which\ninvolve the process of replicating or mimicking the rhythm and pitch of sounds\nby voice. We can effectively express the features of environmental sounds, such\nas rhythm and pitch, using vocal imitations, which cannot be expressed by\nconventional input information, such as sound event labels, images, or texts,\nin an environmental sound synthesis model. In this paper, we propose a\nframework for environmental sound synthesis from vocal imitations and sound\nevent labels based on a framework of a vector quantized encoder and the\nTacotron2 decoder. Using vocal imitations is expected to control the pitch and\nrhythm of the synthesized sound, which only sound event labels cannot control.\nOur objective and subjective experimental results show that vocal imitations\neffectively control the pitch and rhythm of synthesized sounds.", "published": "2023-04-29 17:06:04", "link": "http://arxiv.org/abs/2305.00302v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Adversarial Representation Learning for Robust Privacy Preservation in\n  Audio", "abstract": "Sound event detection systems are widely used in various applications such as\nsurveillance and environmental monitoring where data is automatically\ncollected, processed, and sent to a cloud for sound recognition. However, this\nprocess may inadvertently reveal sensitive information about users or their\nsurroundings, hence raising privacy concerns. In this study, we propose a novel\nadversarial training method for learning representations of audio recordings\nthat effectively prevents the detection of speech activity from the latent\nfeatures of the recordings. The proposed method trains a model to generate\ninvariant latent representations of speech-containing audio recordings that\ncannot be distinguished from non-speech recordings by a speech classifier. The\nnovelty of our work is in the optimization algorithm, where the speech\nclassifier's weights are regularly replaced with the weights of classifiers\ntrained in a supervised manner. This increases the discrimination power of the\nspeech classifier constantly during the adversarial training, motivating the\nmodel to generate latent representations in which speech is not\ndistinguishable, even using new speech classifiers trained outside the\nadversarial training loop. The proposed method is evaluated against a baseline\napproach with no privacy measures and a prior adversarial training method,\ndemonstrating a significant reduction in privacy violations compared to the\nbaseline approach. Additionally, we show that the prior adversarial method is\npractically ineffective for this purpose.", "published": "2023-04-29 08:39:55", "link": "http://arxiv.org/abs/2305.00011v2", "categories": ["cs.SD", "cs.CR", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Analysis of vocal breath sounds before and after administering\n  Bronchodilator in Asthmatic patients", "abstract": "Asthma is one of the chronic inflammatory diseases of the airways, which\ncauses chest tightness, wheezing, breathlessness, and cough. Spirometry is an\neffort-dependent test used to monitor and diagnose lung conditions like Asthma.\nVocal breath sound (VBS) based analysis can be an alternative to spirometry as\nVBS characteristics change depending on the lung condition. VBS test consumes\nless time, and it also requires less effort, unlike spirometry. In this work,\nVBS characteristics are analyzed before and after administering bronchodilator\nin a subject-dependent manner using linear discriminant analysis (LDA). We find\nthat features learned through LDA show a significant difference between VBS\nrecorded before and after administering bronchodilator in all 30 subjects\nconsidered in this work, whereas the baseline features could achieve a\nsignificant difference between VBS only for 26 subjects. We also observe that\nall frequency ranges do not contribute equally to the discrimination between\npre and post bronchodilator conditions. From experiments, we find that two\nfrequency ranges, namely 400-500Hz and 1480-1900Hz, maximally contribute to the\ndiscrimination of all the subjects. The study presented in this paper analyzes\nthe pre and post-bronchodilator effect on the inhalation sound recorded at the\nmouth in a subject-dependent manner. The findings of this work suggest that,\ninhalation sound recorded at mouth can be a good stimulus to discriminate pre\nand post-bronchodilator conditions in asthmatic subjects. Inhale sound-based\npre and post-bronchodilator discrimination can be of potential use in clinical\nsettings.", "published": "2023-04-29 11:49:23", "link": "http://arxiv.org/abs/2305.00242v1", "categories": ["physics.med-ph", "eess.AS", "eess.SP"], "primary_category": "physics.med-ph"}
