{"title": "Symbolic Sets for Proving Bounds on Rado Numbers", "abstract": "Given a linear equation $\\cal E$ of the form $ax + by = cz$ where $a$, $b$,\n$c$ are positive integers, the $k$-colour Rado number $R_k({\\cal E})$ is the\nsmallest positive integer $n$, if it exists, such that every $k$-colouring of\nthe positive integers $\\{1, 2, \\dotsc, n\\}$ contains a monochromatic solution\nto $\\cal E$. In this paper, we consider $k = 3$ and the linear equations $ax +\nby = bz$ and $ax + ay = bz$. Using SAT solvers, we compute a number of\npreviously unknown Rado numbers corresponding to these equations. We prove new\ngeneral bounds on Rado numbers inspired by the satisfying assignments\ndiscovered by the SAT solver. Our proofs require extensive case-based analyses\nthat are difficult to check for correctness by hand, so we automate checking\nthe correctness of our proofs via an approach which makes use of a new tool we\ndeveloped with support for operations on symbolically-defined sets -- e.g.,\nunions or intersections of sets of the form $\\{f(1), f(2), \\dotsc, f(a)\\}$\nwhere $a$ is a symbolic variable and $f$ is a function possibly dependent on\n$a$. No computer algebra system that we are aware of currently has sufficiently\ncapable support for symbolic sets, leading us to develop a tool supporting\nsymbolic sets using the Python symbolic computation library SymPy coupled with\nthe Satisfiability Modulo Theories solver Z3.", "published": "2025-05-17 16:59:11", "link": "http://arxiv.org/abs/2505.12085v1", "categories": ["math.CO", "cs.DM", "cs.LO", "cs.SC"], "primary_category": "math.CO"}
{"title": "Which Phylogenetic Networks are Level-k Networks with Additional Arcs? Structure and Algorithms", "abstract": "Reticulate evolution gives rise to complex phylogenetic networks, making\ntheir interpretation challenging. A typical approach is to extract trees within\nsuch networks. Since Francis and Steel's seminal paper, \"Which Phylogenetic\nNetworks are Merely Trees with Additional Arcs?\" (2015), tree-based\nphylogenetic networks and their support trees (spanning trees with the same\nroot and leaf set as a given network) have been extensively studied. However,\nnot all phylogenetic networks are tree-based, and for the study of reticulate\nevolution, it is often more biologically relevant to identify support networks\nrather than trees. This study generalizes Hayamizu's structure theorem for\nrooted binary phylogenetic networks, which yielded optimal algorithms for\nvarious computational problems on support trees, to extend the theoretical\nframework for support trees to support networks. This allows us to obtain a\ndirect-product characterization of each of three sets: all, minimal, and\nminimum support networks, for a given network. Each characterization yields\noptimal algorithms for counting and generating the support networks of each\ntype. Applications include a linear-time algorithm for finding a support\nnetwork with the fewest reticulations (i.e., the minimum tier). We also provide\nexact and heuristic algorithms for finding a support network with the minimum\nlevel, both running in exponential time but practical across a reasonably wide\nrange of reticulation numbers.", "published": "2025-05-17 10:26:01", "link": "http://arxiv.org/abs/2505.11947v1", "categories": ["math.CO", "cs.DM", "q-bio.PE", "05C20 (Primary), 05C30, 05C70, 05C75, 05C85, 11B39, 92D15\n  (Secondary)"], "primary_category": "math.CO"}
{"title": "Scalable Time-Tagged Data Acquisition for Entanglement Distribution in Quantum Networks", "abstract": "In distributed quantum applications such as entanglement distribution,\nprecise time synchronization and efficient time-tagged data handling are\nessential. Traditional systems often suffer from overflow, synchronization\ndrift, and storage inefficiencies. We propose a modular Time Tagging (TT) agent\nthat uses a 1 pulse per second (PPS) signal from White Rabbit (WR) devices to\nachieve network-wide synchronization, while applying real-time calibration,\noverflow mitigation, and compression. A live two-lab entanglement distribution\nexperiment validated the system's performance, achieving synchronized\ncoincidence detection at 25,000 counts/sec.", "published": "2025-05-17 18:10:32", "link": "http://arxiv.org/abs/2505.12102v1", "categories": ["cs.SE", "cs.IR", "cs.NI"], "primary_category": "cs.SE"}
{"title": "Demystifying and Enhancing the Efficiency of Large Language Model Based Search Agents", "abstract": "Large Language Model (LLM)-based search agents have shown remarkable\ncapabilities in solving complex tasks by dynamically decomposing problems and\naddressing them through interleaved reasoning and retrieval. However, this\ninterleaved paradigm introduces substantial efficiency bottlenecks. First, we\nobserve that both highly accurate and overly approximate retrieval methods\ndegrade system efficiency: exact search incurs significant retrieval overhead,\nwhile coarse retrieval requires additional reasoning steps during generation.\nSecond, we identify inefficiencies in system design, including improper\nscheduling and frequent retrieval stalls, which lead to cascading latency --\nwhere even minor delays in retrieval amplify end-to-end inference time. To\naddress these challenges, we introduce SearchAgent-X, a high-efficiency\ninference framework for LLM-based search agents. SearchAgent-X leverages\nhigh-recall approximate retrieval and incorporates two key techniques:\npriority-aware scheduling and non-stall retrieval. Extensive experiments\ndemonstrate that SearchAgent-X consistently outperforms state-of-the-art\nsystems such as vLLM and HNSW-based retrieval across diverse tasks, achieving\nup to 3.4$\\times$ higher throughput and 5$\\times$ lower latency, without\ncompromising generation quality. SearchAgent-X is available at\nhttps://github.com/tiannuo-yang/SearchAgent-X.", "published": "2025-05-17 16:07:01", "link": "http://arxiv.org/abs/2505.12065v1", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Let's have a chat with the EU AI Act", "abstract": "As artificial intelligence (AI) regulations evolve and the regulatory\nlandscape develops and becomes more complex, ensuring compliance with ethical\nguidelines and legal frameworks remains a challenge for AI developers. This\npaper introduces an AI-driven self-assessment chatbot designed to assist users\nin navigating the European Union AI Act and related standards. Leveraging a\nRetrieval-Augmented Generation (RAG) framework, the chatbot enables real-time,\ncontext-aware compliance verification by retrieving relevant regulatory texts\nand providing tailored guidance. By integrating both public and proprietary\nstandards, it streamlines regulatory adherence, reduces complexity, and fosters\nresponsible AI development. The paper explores the chatbot's architecture,\ncomparing naive and graph-based RAG models, and discusses its potential impact\non AI governance.", "published": "2025-05-17 10:24:08", "link": "http://arxiv.org/abs/2505.11946v1", "categories": ["cs.IR", "cs.AI", "cs.CY", "cs.DL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Basic model for ranking microfinance institutions", "abstract": "This paper discusses the challenges encountered in building a ranking model\nfor aggregator site products, using the example of ranking microfinance\ninstitutions (MFIs) based on post-click conversion. We suggest which features\nof MFIs should be considered, and using an algorithm based on Markov chains, we\ndemonstrate the ``usefulness'' of these features on real data. The ideas\ndeveloped in this work can be applied to aggregator websites in microinsurance,\nespecially when personal data is unavailable. Since we did not find similar\ndatasets in the public domain, we are publishing our dataset with a detailed\ndescription of its attributes.", "published": "2025-05-17 10:15:05", "link": "http://arxiv.org/abs/2505.11944v1", "categories": ["cs.IR", "math.PR", "stat.OT"], "primary_category": "cs.IR"}
{"title": "Conversational Recommendation System using NLP and Sentiment Analysis", "abstract": "In today's digitally-driven world, the demand for personalized and\ncontext-aware recommendations has never been greater. Traditional recommender\nsystems have made significant strides in this direction, but they often lack\nthe ability to tap into the richness of conversational data. This paper\nrepresents a novel approach to recommendation systems by integrating\nconversational insights into the recommendation process. The Conversational\nRecommender System integrates cutting-edge technologies such as deep learning,\nleveraging machine learning algorithms like Apriori for Association Rule\nMining, Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN),\nand Long Short-Term Memory (LTSM). Furthermore, sophisticated voice recognition\ntechnologies, including Hidden Markov Models (HMMs) and Dynamic Time Warping\n(DTW) algorithms, play a crucial role in accurate speech-to-text conversion,\nensuring robust performance in diverse environments. The methodology\nincorporates a fusion of content-based and collaborative recommendation\napproaches, enhancing them with NLP techniques. This innovative integration\nensures a more personalized and context-aware recommendation experience,\nparticularly in marketing applications.", "published": "2025-05-17 09:36:05", "link": "http://arxiv.org/abs/2505.11933v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "Neuro-Symbolic Query Compiler", "abstract": "Precise recognition of search intent in Retrieval-Augmented Generation (RAG)\nsystems remains a challenging goal, especially under resource constraints and\nfor complex queries with nested structures and dependencies. This paper\npresents QCompiler, a neuro-symbolic framework inspired by linguistic grammar\nrules and compiler design, to bridge this gap. It theoretically designs a\nminimal yet sufficient Backus-Naur Form (BNF) grammar $G[q]$ to formalize\ncomplex queries. Unlike previous methods, this grammar maintains completeness\nwhile minimizing redundancy. Based on this, QCompiler includes a Query\nExpression Translator, a Lexical Syntax Parser, and a Recursive Descent\nProcessor to compile queries into Abstract Syntax Trees (ASTs) for execution.\nThe atomicity of the sub-queries in the leaf nodes ensures more precise\ndocument retrieval and response generation, significantly improving the RAG\nsystem's ability to address complex queries.", "published": "2025-05-17 09:36:03", "link": "http://arxiv.org/abs/2505.11932v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Recursive Question Understanding for Complex Question Answering over Heterogeneous Personal Data", "abstract": "Question answering over mixed sources, like text and tables, has been\nadvanced by verbalizing all contents and encoding it with a language model. A\nprominent case of such heterogeneous data is personal information: user devices\nlog vast amounts of data every day, such as calendar entries, workout\nstatistics, shopping records, streaming history, and more. Information needs\nrange from simple look-ups to queries of analytical nature. The challenge is to\nprovide humans with convenient access with small footprint, so that all\npersonal data stays on the user devices. We present ReQAP, a novel method that\ncreates an executable operator tree for a given question, via recursive\ndecomposition. Operators are designed to enable seamless integration of\nstructured and unstructured sources, and the execution of the operator tree\nyields a traceable answer. We further release the PerQA benchmark, with\npersona-based data and questions, covering a diverse spectrum of realistic user\nneeds.", "published": "2025-05-17 08:32:05", "link": "http://arxiv.org/abs/2505.11900v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Telco-oRAG: Optimizing Retrieval-augmented Generation for Telecom Queries via Hybrid Retrieval and Neural Routing", "abstract": "Artificial intelligence will be one of the key pillars of the next generation\nof mobile networks (6G), as it is expected to provide novel added-value\nservices and improve network performance. In this context, large language\nmodels have the potential to revolutionize the telecom landscape through intent\ncomprehension, intelligent knowledge retrieval, coding proficiency, and\ncross-domain orchestration capabilities. This paper presents Telco-oRAG, an\nopen-source Retrieval-Augmented Generation (RAG) framework optimized for\nanswering technical questions in the telecommunications domain, with a\nparticular focus on 3GPP standards. Telco-oRAG introduces a hybrid retrieval\nstrategy that combines 3GPP domain-specific retrieval with web search,\nsupported by glossary-enhanced query refinement and a neural router for\nmemory-efficient retrieval. Our results show that Telco-oRAG improves the\naccuracy in answering 3GPP-related questions by up to 17.6% and achieves a\n10.6% improvement in lexicon queries compared to baselines. Furthermore,\nTelco-oRAG reduces memory usage by 45% through targeted retrieval of relevant\n3GPP series compared to baseline RAG, and enables open-source LLMs to reach\nGPT-4-level accuracy on telecom benchmarks.", "published": "2025-05-17 05:46:30", "link": "http://arxiv.org/abs/2505.11856v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "The Effects of Demographic Instructions on LLM Personas", "abstract": "Social media platforms must filter sexist content in compliance with\ngovernmental regulations. Current machine learning approaches can reliably\ndetect sexism based on standardized definitions, but often neglect the\nsubjective nature of sexist language and fail to consider individual users'\nperspectives. To address this gap, we adopt a perspectivist approach, retaining\ndiverse annotations rather than enforcing gold-standard labels or their\naggregations, allowing models to account for personal or group-specific views\nof sexism. Using demographic data from Twitter, we employ large language models\n(LLMs) to personalize the identification of sexism.", "published": "2025-05-17 02:49:15", "link": "http://arxiv.org/abs/2505.11795v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Attribution Projection Calculus: A Novel Framework for Causal Inference in Bayesian Networks", "abstract": "This paper introduces Attribution Projection Calculus (AP-Calculus), a novel\nmathematical framework for determining causal relationships in structured\nBayesian networks. We investigate a specific network architecture with source\nnodes connected to destination nodes through intermediate nodes, where each\ninput maps to a single label with maximum marginal probability. We prove that\nfor each label, exactly one intermediate node acts as a deconfounder while\nothers serve as confounders, enabling optimal attribution of features to their\ncorresponding labels. The framework formalizes the dual nature of intermediate\nnodes as both confounders and deconfounders depending on the context, and\nestablishes separation functions that maximize distinctions between\nintermediate representations. We demonstrate that the proposed network\narchitecture is optimal for causal inference compared to alternative\nstructures, including those based on Pearl's causal framework. AP-Calculus\nprovides a comprehensive mathematical foundation for analyzing feature-label\nattributions, managing spurious correlations, quantifying information gain,\nensuring fairness, and evaluating uncertainty in prediction models, including\nlarge language models. Theoretical verification shows that AP-Calculus not only\nextends but can also subsume traditional do-calculus for many practical\napplications, offering a more direct approach to causal inference in supervised\nlearning contexts.", "published": "2025-05-17 17:29:13", "link": "http://arxiv.org/abs/2505.12094v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML", "60E10, 62R07, 68Q32, 68T07, 94A16", "F.2.2; G.3; I.1.2; I.2.6"], "primary_category": "cs.LG"}
{"title": "A general secondary construction of Boolean functions including the indirect sum and its generalizations", "abstract": "We study a secondary construction of Boolean functions, which generalizes the\ndirect sum and the indirect sum. We detail how these two classic secondary\nconstructions are particular cases of this more general one, as well as two\nknown generalizations of the indirect sum. This unifies the known secondary\nconstructions of Boolean functions. We study very precisely the Walsh transform\nof the constructed functions. This leads us to an interesting observation on\nthe Walsh transforms $W_g,W_{g'},W_{g''}$, and $W_{g\\oplus g'\\oplus g''}$ when\n$g,g',g''$ are Boolean functions such that $(g\\oplus g')(g\\oplus g'')$ equals\nthe zero function.", "published": "2025-05-17 13:12:43", "link": "http://arxiv.org/abs/2505.11994v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "XiSort: Deterministic Sorting via IEEE-754 Total Ordering and Entropy Minimization", "abstract": "We introduce XiSort, a deterministic and reproducible sorting algorithm for\nfloating-point sequences based on IEEE-754 total ordering and entropy\nminimization. XiSort guarantees bit-for-bit stability across runs and platforms\nby resolving tie-breaking via information-theoretic and symbolic methods. The\nalgorithm supports both in-memory and external (out-of-core) operation,\noffering consistent performance on large datasets. We formalize a curved\nvariant of the sorting metric that integrates into the Alpay Algebra framework,\ntreating XiSort as a recursive operator with provable convergence and symbolic\nidempotence. This model preserves state-space closure while minimizing local\ndisorder, interpretable as symbolic entropy. Empirical benchmarks demonstrate\nthat XiSort achieves competitive throughput (e.g., sorting 10^8 doubles in\napproximately 12 seconds in-memory, and 100 GB at around 100 MB/s on SSDs),\nwith applications in scientific computing, high-frequency finance, and\nreproducible numerical workflows. The results position XiSort as a principled\ntool for stable data alignment, symbolic preprocessing, and cross-platform\nfloat ordering.\n  Keywords: deterministic sorting, IEEE-754, entropy minimization, symbolic\nalgebra, reproducibility, external memory, Alpay Algebra, data pipelines", "published": "2025-05-17 09:25:10", "link": "http://arxiv.org/abs/2505.11927v1", "categories": ["cs.DS", "cs.IT", "cs.NA", "math.IT", "math.NA", "68P10, 68Q25, 94A17, 65Y20", "F.2.2; G.4; E.1; G.3"], "primary_category": "cs.DS"}
{"title": "K*-Means: A Parameter-free Clustering Algorithm", "abstract": "Clustering is a widely used and powerful machine learning technique, but its\neffectiveness is often limited by the need to specify the number of clusters,\nk, or by relying on thresholds that implicitly determine k. We introduce\nk*-means, a novel clustering algorithm that eliminates the need to set k or any\nother parameters. Instead, it uses the minimum description length principle to\nautomatically determine the optimal number of clusters, k*, by splitting and\nmerging clusters while also optimising the standard k-means objective. We prove\nthat k*-means is guaranteed to converge and demonstrate experimentally that it\nsignificantly outperforms existing methods in scenarios where k is unknown. We\nalso show that it is accurate in estimating k, and that empirically its runtime\nis competitive with existing methods, and scales well with dataset size.", "published": "2025-05-17 08:41:07", "link": "http://arxiv.org/abs/2505.11904v1", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "Communication-Efficient Hybrid Language Model via Uncertainty-Aware Opportunistic and Compressed Transmission", "abstract": "To support emerging language-based applications using dispersed and\nheterogeneous computing resources, the hybrid language model (HLM) offers a\npromising architecture, where an on-device small language model (SLM) generates\ndraft tokens that are validated and corrected by a remote large language model\n(LLM). However, the original HLM suffers from substantial communication\noverhead, as the LLM requires the SLM to upload the full vocabulary\ndistribution for each token. Moreover, both communication and computation\nresources are wasted when the LLM validates tokens that are highly likely to be\naccepted. To overcome these limitations, we propose communication-efficient and\nuncertainty-aware HLM (CU-HLM). In CU-HLM, the SLM transmits truncated\nvocabulary distributions only when its output uncertainty is high. We validate\nthe feasibility of this opportunistic transmission by discovering a strong\ncorrelation between SLM's uncertainty and LLM's rejection probability.\nFurthermore, we theoretically derive optimal uncertainty thresholds and optimal\nvocabulary truncation strategies. Simulation results show that, compared to\nstandard HLM, CU-HLM achieves up to 206$\\times$ higher token throughput by\nskipping 74.8% transmissions with 97.4% vocabulary compression, while\nmaintaining 97.4% accuracy.", "published": "2025-05-17 02:10:34", "link": "http://arxiv.org/abs/2505.11788v1", "categories": ["cs.DC", "cs.IT", "cs.LG", "cs.NI", "eess.SP", "math.IT"], "primary_category": "cs.DC"}
{"title": "Study of Robust Resource Allocation in Cell-Free Multiple-Antenna Networks", "abstract": "Cell-free networks outperform cellular networks in many aspects, yet their\nefficiency is affected by imperfect channel state information (CSI). In order\nto address this issue, this work presents a robust resource allocation\nframework designed for the downlink of user-centric cell-free massive\nmulti-input multi-output (CF-mMIMO) networks. This framework employs a\nsequential resource allocation strategy with a robust user scheduling algorithm\ndesigned to maximize the sum-rate of the network and two robust power\nallocation algorithms aimed at minimizing the mean square error, which are\ndeveloped to mitigate the effects of imperfect CSI. An analysis of the proposed\nrobust resource allocation problems is developed along with a study of their\ncomputational cost. Simulation results demonstrate the effectiveness of the\nproposed robust resource allocation algorithms, showing a performance\nimprovement of up to 30\\% compared to existing techniques.", "published": "2025-05-17 01:04:13", "link": "http://arxiv.org/abs/2505.11778v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "cs.IT"}
{"title": "Incentivize Contribution and Learn Parameters Too: Federated Learning with Strategic Data Owners", "abstract": "Classical federated learning (FL) assumes that the clients have a limited\namount of noisy data with which they voluntarily participate and contribute\ntowards learning a global, more accurate model in a principled manner. The\nlearning happens in a distributed fashion without sharing the data with the\ncenter. However, these methods do not consider the incentive of an agent for\nparticipating and contributing to the process, given that data collection and\nrunning a distributed algorithm is costly for the clients. The question of\nrationality of contribution has been asked recently in the literature and some\nresults exist that consider this problem. This paper addresses the question of\nsimultaneous parameter learning and incentivizing contribution, which\ndistinguishes it from the extant literature. Our first mechanism incentivizes\neach client to contribute to the FL process at a Nash equilibrium and\nsimultaneously learn the model parameters. However, this equilibrium outcome\ncan be away from the optimal, where clients contribute with their full data and\nthe algorithm learns the optimal parameters. We propose a second mechanism with\nmonetary transfers that is budget balanced and enables the full data\ncontribution along with optimal parameter learning. Large scale experiments\nwith real (federated) datasets (CIFAR-10, FeMNIST, and Twitter) show that these\nalgorithms converge quite fast in practice, yield good welfare guarantees, and\nbetter model performance for all agents.", "published": "2025-05-17 14:04:20", "link": "http://arxiv.org/abs/2505.12010v1", "categories": ["cs.GT", "cs.LG", "cs.MA"], "primary_category": "cs.GT"}
{"title": "Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework", "abstract": "As large language models (LLMs) are increasingly used in multi-agent systems,\nquestions of fairness should extend beyond resource distribution and procedural\ndesign to include the fairness of how agents communicate. Drawing from\norganizational psychology, we introduce a novel framework for evaluating\nInteractional fairness encompassing Interpersonal fairness (IF) and\nInformational fairness (InfF) in LLM-based multi-agent systems (LLM-MAS). We\nextend the theoretical grounding of Interactional Fairness to non-sentient\nagents, reframing fairness as a socially interpretable signal rather than a\nsubjective experience. We then adapt established tools from organizational\njustice research, including Colquitt's Organizational Justice Scale and the\nCritical Incident Technique, to measure fairness as a behavioral property of\nagent interaction. We validate our framework through a pilot study using\ncontrolled simulations of a resource negotiation task. We systematically\nmanipulate tone, explanation quality, outcome inequality, and task framing\n(collaborative vs. competitive) to assess how IF influences agent behavior.\nResults show that tone and justification quality significantly affect\nacceptance decisions even when objective outcomes are held constant. In\naddition, the influence of IF vs. InfF varies with context. This work lays the\nfoundation for fairness auditing and norm-sensitive alignment in LLM-MAS.", "published": "2025-05-17 13:24:13", "link": "http://arxiv.org/abs/2505.12001v1", "categories": ["cs.AI", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Mod\u00e8les de Substitution pour les Mod\u00e8les \u00e0 base d'Agents : Enjeux, M\u00e9thodes et Applications", "abstract": "Multi-agent simulations enables the modeling and analyses of the dynamic\nbehaviors and interactions of autonomous entities evolving in complex\nenvironments. Agent-based models (ABM) are widely used to study emergent\nphenomena arising from local interactions. However, their high computational\ncost poses a significant challenge, particularly for large-scale simulations\nrequiring extensive parameter exploration, optimization, or uncertainty\nquantification. The increasing complexity of ABM limits their feasibility for\nreal-time decision-making and large-scale scenario analysis. To address these\nlimitations, surrogate models offer an efficient alternative by learning\napproximations from sparse simulation data. These models provide\ncheap-to-evaluate predictions, significantly reducing computational costs while\nmaintaining accuracy. Various machine learning techniques, including regression\nmodels, neural networks, random forests and Gaussian processes, have been\napplied to construct robust surrogates. Moreover, uncertainty quantification\nand sensitivity analysis play a crucial role in enhancing model reliability and\ninterpretability.\n  This article explores the motivations, methods, and applications of surrogate\nmodeling for ABM, emphasizing the trade-offs between accuracy, computational\nefficiency, and interpretability. Through a case study on a segregation model,\nwe highlight the challenges associated with building and validating surrogate\nmodels, comparing different approaches and evaluating their performance.\nFinally, we discuss future perspectives on integrating surrogate models within\nABM to improve scalability, explainability, and real-time decision support\nacross various fields such as ecology, urban planning and economics.", "published": "2025-05-17 08:55:33", "link": "http://arxiv.org/abs/2505.11912v1", "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "cs.LG"}
{"title": "OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration", "abstract": "Agents powered by advanced large language models (LLMs) have demonstrated\nimpressive capabilities across diverse complex applications. Recently,\nMulti-Agent Systems (MAS), wherein multiple agents collaborate and communicate\nwith each other, have exhibited enhanced capabilities in complex tasks, such as\nhigh-quality code generation and arithmetic reasoning. However, the development\nof such systems often relies on handcrafted methods, and the literature on\nsystematic design and optimization of LLM-based MAS remains limited.\n  In this work, we introduce OMAC, a general framework designed for holistic\noptimization of LLM-based MAS. Specifically, we identify five key optimization\ndimensions for MAS, encompassing both agent functionality and collaboration\nstructure. Building upon these dimensions, we first propose a general\nalgorithm, utilizing two actors termed the Semantic Initializer and the\nContrastive Comparator, to optimize any single dimension. Then, we present an\nalgorithm for joint optimization across multiple dimensions. Extensive\nexperiments demonstrate the superior performance of OMAC on code generation,\narithmetic reasoning, and general reasoning tasks against state-of-the-art\napproaches.", "published": "2025-05-17 00:13:46", "link": "http://arxiv.org/abs/2505.11765v1", "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Propagation of chaos and approximation error of random batch particle system in the mean field regime", "abstract": "The random batch method [J. Comput. Phys. 400 (2020) 108877] is not only an\nefficient algorithm for simulation of classical $N$-particle systems and their\nmean-field limit, but also a new model for interacting particle system that\ncould be more physical in some applications. In this work, we establish the\npropagation of chaos for the random batch particle system and at the same time\nobtain its sharp approximation error to the classical mean field limit of\n$N$-particle systems. The proof leverages the BBGKY hierarchy and achieves a\nsharp bound both in the particle number $N$ and the time step $\\tau$. In\nparticular, by introducing a coupling of the division of the random batches to\nresolve the $N$-dependence, we derive an $\\mathcal{O}(k^2/N^2 + k\\tau^2)$ bound\non the $k$-particle relative entropy between the law of the system and the\ntensorized law of the mean-field limit. This result provides a useful\nunderstanding of the convergence properties of the random batch system in the\nmean field regime.", "published": "2025-05-17 23:42:08", "link": "http://arxiv.org/abs/2505.12172v1", "categories": ["math.NA", "cs.NA", "math.PR"], "primary_category": "math.NA"}
{"title": "Numerical Integrators for Mechanical Systems on Lie Groups", "abstract": "Retraction maps are known to be the seed for all numerical integrators. These\nretraction maps-based integrators can be further lifted to tangent and\ncotangent bundles, giving rise to structure-preserving integrators for\nmechanical systems. We explore the particular case where the configuration\nspace of our mechanical system is a Lie group with certain symmetries. Here,\nthe integrator simplifies based on the property that the tangent and cotangent\nbundles of Lie groups are trivializable. Finally, we present a framework for\ndesigning numerical integrators for Euler- Poincare and Lie-Poisson type\nequations.", "published": "2025-05-17 18:12:31", "link": "http://arxiv.org/abs/2505.12103v1", "categories": ["math.NA", "cs.NA", "math.DG"], "primary_category": "math.NA"}
{"title": "Approximation theory for 1-Lipschitz ResNets", "abstract": "1-Lipschitz neural networks are fundamental for generative modelling, inverse\nproblems, and robust classifiers. In this paper, we focus on 1-Lipschitz\nresidual networks (ResNets) based on explicit Euler steps of negative gradient\nflows and study their approximation capabilities. Leveraging the Restricted\nStone-Weierstrass Theorem, we first show that these 1-Lipschitz ResNets are\ndense in the set of scalar 1-Lipschitz functions on any compact domain when\nwidth and depth are allowed to grow. We also show that these networks can\nexactly represent scalar piecewise affine 1-Lipschitz functions. We then prove\na stronger statement: by inserting norm-constrained linear maps between the\nresidual blocks, the same density holds when the hidden width is fixed. Because\nevery layer obeys simple norm constraints, the resulting models can be trained\nwith off-the-shelf optimisers. This paper provides the first universal\napproximation guarantees for 1-Lipschitz ResNets, laying a rigorous foundation\nfor their practical use.", "published": "2025-05-17 13:36:55", "link": "http://arxiv.org/abs/2505.12003v1", "categories": ["cs.LG", "cs.NA", "math.NA", "68T07"], "primary_category": "cs.LG"}
{"title": "An Immersed Finite Element Method for Anisotropic Elliptic Interface Problems with Nonhomogeneous Jump Conditions", "abstract": "A new finite element method (FEM) using meshes that do not necessarily align\nwith the interface is developed for two- and three-dimensional anisotropic\nelliptic interface problems with nonhomogeneous jump conditions. The degrees of\nfreedom of the proposed method are the same as those of traditional\nnonconforming FEMs, while the function space is modified to account for the\njump conditions of the solution. The modified function space on an interface\nelement is shown to exist uniquely, independent of the element's shape and the\nmanner in which the interface intersects it. Optimal error estimates for the\nmethod, along with the usual bound on the condition number of the stiffness\nmatrix, are proven, with the error constant independent of the interface's\nlocation relative to the mesh. To solve the resulting linear system, a\npreconditioner is proposed in which a Gauss-Seidel smoother with the interface\ncorrection is employed to ensure robustness against large jumps in the\ndiffusion matrix. Numerical experiments are provided to demonstrate the optimal\nconvergence of the proposed method and the efficiency of the preconditioner.", "published": "2025-05-17 11:24:41", "link": "http://arxiv.org/abs/2505.11961v1", "categories": ["math.NA", "cs.NA", "65N15, 65N30, 35R05"], "primary_category": "math.NA"}
{"title": "Stable Nonlinear Dynamical Approximation with Dynamical Sampling", "abstract": "We present a nonlinear dynamical approximation method for time-dependent\nPartial Differential Equations (PDEs). The approach makes use of parametrized\ndecoder functions, and provides a general, and principled way of understanding\nand analyzing stability and accuracy of nonlinear dynamical approximations. The\nparameters of these functions are evolved in time by means of projections on\nfinite dimensional subspaces of an ambient Hilbert space related to the PDE\nevolution. For practical computations of these projections, one usually needs\nto sample. We propose a dynamical sampling strategy which comes with stability\nguarantees, while keeping a low numerical complexity. We show the effectiveness\nof the method on several examples in moderate spatial dimension.", "published": "2025-05-17 09:57:54", "link": "http://arxiv.org/abs/2505.11938v1", "categories": ["math.NA", "cs.NA", "35C99, 32W99, 65D40, 65D99, 65D30, 65D15"], "primary_category": "math.NA"}
{"title": "A preconditioned difference of convex functions algorithm with extrapolation and line search", "abstract": "This paper proposes a novel proximal difference-of-convex (DC) algorithm\nenhanced with extrapolation and aggressive non-monotone line search for solving\nnon-convex optimization problems. We introduce an adaptive conservative update\nstrategy of the extrapolation parameter determined by a computationally\nefficient non-monotone line search. The core of our algorithm is to unite the\nupdate of the extrapolation parameter with the step size of the non-monotone\nline search interactively. The global convergence of the two proposed\nalgorithms is established through the Kurdyka-{\\L}ojasiewicz properties,\nensuring convergence within a preconditioned framework for linear equations.\nNumerical experiments on two general non-convex problems: SCAD-penalized binary\nclassification and graph-based Ginzburg-Landau image segmentation models,\ndemonstrate the proposed method's high efficiency compared to existing DC\nalgorithms both in convergence rate and solution accuracy.", "published": "2025-05-17 08:56:51", "link": "http://arxiv.org/abs/2505.11914v1", "categories": ["math.OC", "cs.NA", "math.NA", "65K10, 65F08, 49K35, 90C25, 90C26"], "primary_category": "math.OC"}
{"title": "Numerical reconstructions of a source term in a mobile-immobile diffusion model from the partial interior observation", "abstract": "We consider an inverse source problem in the two-time-scale mobile-immobile\nfractional diffusion model from partial interior observation. Theoretically, we\ncombine the fractional Duhamel's principle with the weak vanishing property to\nestablish the uniqueness of this inverse problem. Numerically, we adopt an\noptimal control approach for determining the source term. A coupled\nforward-backward system of equations is derived using the first-order\noptimality condition. Finally, we construct a finite element conjugate gradient\nalgorithm for the numerical inversion of the source term. Several experiments\nare presented to show the utility of the method.", "published": "2025-05-17 06:31:52", "link": "http://arxiv.org/abs/2505.11869v1", "categories": ["math.NA", "cs.NA", "65M32, 35R11, 65K10, 65M60"], "primary_category": "math.NA"}
{"title": "Identifying convex obstacles from backscattering far field data", "abstract": "The recovery of anomalies from backscattering far field data is a\nlong-standing open problem in inverse scattering theory. We make a first step\nin this direction by establishing the unique identifiability of convex\nimpenetrable obstacles from backscattering far field measurements.\nSpecifically, we prove that both the boundary and the boundary conditions of\nthe convex obstacle are uniquely determined by the far field pattern measured\nin backscattering directions for all frequencies. The key tool is Majda's\nasymptotic estimate of the far field patterns in the high-frequency regime.\nFurthermore, we introduce a fast and stable numerical algorithm for\nreconstructing the boundary and computing the boundary condition. A key feature\nof the algorithm is that the boundary condition can be computed even if the\nboundary is not known, and vice versa. Numerical experiments demonstrate the\nvalidity and robustness of the proposed algorithm.", "published": "2025-05-17 05:26:58", "link": "http://arxiv.org/abs/2505.11850v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "math.NA"}
{"title": "A parameterized Wasserstein Hamiltonian flow approach for solving the Schr\u00f6dinger equation", "abstract": "In this paper, we propose a new method to compute the solution of\ntime-dependent Schr\\\"odinger equation (TDSE). Using push-forward maps and\nWasserstein Hamiltonian flow, we reformulate the TDSE as a Hamiltonian system\nin terms of push-forward maps. The new formulation can be viewed as a\ngenerative model in the Wasserstein space, which is a manifold of probability\ndensity functions. Then we parameterize the push-forward maps by reduce-order\nmodels such as neural networks. This induces a new metric in the parameter\nspace by pulling back the Wasserstein metric on density manifold, which further\nresults in a system of ordinary differential equations (ODEs) for the\nparameters of the reduce-order model. Leveraging the computational techniques\nfrom deep learning, such as Neural ODE, we design an algorithm to solve the\nTDSE in the parameterized push-forward map space, which provides an alternative\napproach with the potential to scale up to high-dimensional problems. Several\nnumerical examples are presented to demonstrate the performance of this\nalgorithm.", "published": "2025-05-17 00:08:55", "link": "http://arxiv.org/abs/2505.11762v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Learning to Dissipate Energy in Oscillatory State-Space Models", "abstract": "State-space models (SSMs) are a class of networks for sequence learning that\nbenefit from fixed state size and linear complexity with respect to sequence\nlength, contrasting the quadratic scaling of typical attention mechanisms.\nInspired from observations in neuroscience, Linear Oscillatory State-Space\nmodels (LinOSS) are a recently proposed class of SSMs constructed from layers\nof discretized forced harmonic oscillators. Although these models perform\ncompetitively, leveraging fast parallel scans over diagonal recurrent matrices\nand achieving state-of-the-art performance on tasks with sequence length up to\n50k, LinOSS models rely on rigid energy dissipation (\"forgetting\") mechanisms\nthat are inherently coupled to the timescale of state evolution. As forgetting\nis a crucial mechanism for long-range reasoning, we demonstrate the\nrepresentational limitations of these models and introduce Damped Linear\nOscillatory State-Space models (D-LinOSS), a more general class of oscillatory\nSSMs that learn to dissipate latent state energy on multiple timescales. We\nanalyze the spectral distribution of the model's recurrent matrices and prove\nthat the SSM layers exhibit stable dynamics under simple, flexible\nparameterizations. D-LinOSS consistently outperforms previous LinOSS methods on\nlong-range learning tasks, without introducing additional complexity, and\nsimultaneously reduces the hyperparameter search space by 50%.", "published": "2025-05-17 23:15:17", "link": "http://arxiv.org/abs/2505.12171v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Transformer learns the cross-task prior and regularization for in-context learning", "abstract": "Transformers have shown a remarkable ability for in-context learning (ICL),\nmaking predictions based on contextual examples. However, while theoretical\nanalyses have explored this prediction capability, the nature of the inferred\ncontext and its utility for downstream predictions remain open questions. This\npaper aims to address these questions by examining ICL for inverse linear\nregression (ILR), where context inference can be characterized by unsupervised\nlearning of underlying weight vectors. Focusing on the challenging scenario of\nrank-deficient inverse problems, where context length is smaller than the\nnumber of unknowns in the weight vectors and regularization is necessary, we\nintroduce a linear transformer to learn the inverse mapping from contextual\nexamples to the underlying weight vector. Our findings reveal that the\ntransformer implicitly learns both a prior distribution and an effective\nregularization strategy, outperforming traditional ridge regression and\nregularization methods. A key insight is the necessity of low task\ndimensionality relative to the context length for successful learning.\nFurthermore, we numerically verify that the error of the transformer estimator\nscales linearly with the noise level, the ratio of task dimension to context\nlength, and the condition number of the input data. These results not only\ndemonstrate the potential of transformers for solving ill-posed inverse\nproblems, but also provide a new perspective towards understanding the\nknowledge extraction mechanism within transformers.", "published": "2025-05-17 20:42:23", "link": "http://arxiv.org/abs/2505.12138v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Metric Graph Kernels via the Tropical Torelli Map", "abstract": "We propose new graph kernels grounded in the study of metric graphs via\ntropical algebraic geometry. In contrast to conventional graph kernels that are\nbased on graph combinatorics such as nodes, edges, and subgraphs, our graph\nkernels are purely based on the geometry and topology of the underlying metric\nspace. A key characterizing property of our construction is its invariance\nunder edge subdivision, making the kernels intrinsically well-suited for\ncomparing graphs that represent different underlying spaces. We develop\nefficient algorithms for computing these kernels and analyze their complexity,\nshowing that it depends primarily on the genus of the input graphs.\nEmpirically, our kernels outperform existing methods in label-free settings, as\ndemonstrated on both synthetic and real-world benchmark datasets. We further\nhighlight their practical utility through an urban road network classification\ntask.", "published": "2025-05-17 20:00:50", "link": "http://arxiv.org/abs/2505.12129v1", "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "cs.LG"}
{"title": "T-Rex: Fitting a Robust Factor Model via Expectation-Maximization", "abstract": "Over the past decades, there has been a surge of interest in studying\nlow-dimensional structures within high-dimensional data. Statistical factor\nmodels $-$ i.e., low-rank plus diagonal covariance structures $-$ offer a\npowerful framework for modeling such structures. However, traditional methods\nfor fitting statistical factor models, such as principal component analysis\n(PCA) or maximum likelihood estimation assuming the data is Gaussian, are\nhighly sensitive to heavy tails and outliers in the observed data. In this\npaper, we propose a novel expectation-maximization (EM) algorithm for robustly\nfitting statistical factor models. Our approach is based on Tyler's M-estimator\nof the scatter matrix for an elliptical distribution, and consists of solving\nTyler's maximum likelihood estimation problem while imposing a structural\nconstraint that enforces the low-rank plus diagonal covariance structure. We\npresent numerical experiments on both synthetic and real examples,\ndemonstrating the robustness of our method for direction-of-arrival estimation\nin nonuniform noise and subspace recovery.", "published": "2025-05-17 18:53:06", "link": "http://arxiv.org/abs/2505.12117v1", "categories": ["stat.ML", "cs.LG", "eess.SP", "math.OC", "90C26"], "primary_category": "stat.ML"}
{"title": "Proximal optimal transport divergences", "abstract": "We introduce proximal optimal transport divergence, a novel discrepancy\nmeasure that interpolates between information divergences and optimal transport\ndistances via an infimal convolution formulation. This divergence provides a\nprincipled foundation for optimal transport proximals and proximal optimization\nmethods frequently used in generative modeling. We explore its mathematical\nproperties, including smoothness, boundedness, and computational tractability,\nand establish connections to primal-dual formulation and adversarial learning.\nBuilding on the Benamou-Brenier dynamic formulation of optimal transport cost,\nwe also establish a dynamic formulation for proximal OT divergences. The\nresulting dynamic formulation is a first order mean-field game whose optimality\nconditions are governed by a pair of nonlinear partial differential equations,\na backward Hamilton-Jacobi and a forward continuity partial differential\nequations. Our framework generalizes existing approaches while offering new\ninsights and computational tools for generative modeling, distributional\noptimization, and gradient-based learning in probability spaces.", "published": "2025-05-17 17:48:11", "link": "http://arxiv.org/abs/2505.12097v1", "categories": ["math.OC", "math.PR", "stat.ME", "stat.ML"], "primary_category": "math.OC"}
{"title": "When the Left Foot Leads to the Right Path: Bridging Initial Prejudice and Trainability", "abstract": "Understanding the statistical properties of deep neural networks (DNNs) at\ninitialization is crucial for elucidating both their trainability and the\nintrinsic architectural biases they encode prior to data exposure. Mean-field\n(MF) analyses have demonstrated that the parameter distribution in randomly\ninitialized networks dictates whether gradients vanish or explode.\nConcurrently, untrained DNNs were found to exhibit an initial-guessing bias\n(IGB), in which large regions of the input space are assigned to a single\nclass. In this work, we derive a theoretical proof establishing the\ncorrespondence between IGB and previous MF theories, thereby connecting a\nnetwork prejudice toward specific classes with the conditions for fast and\naccurate learning. This connection yields the counter-intuitive conclusion: the\ninitialization that optimizes trainability is necessarily biased, rather than\nneutral. Furthermore, we extend the MF/IGB framework to multi-node activation\nfunctions, offering practical guidelines for designing initialization schemes\nthat ensure stable optimization in architectures employing max- and\naverage-pooling layers.", "published": "2025-05-17 17:31:56", "link": "http://arxiv.org/abs/2505.12096v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Thompson Sampling-like Algorithms for Stochastic Rising Bandits", "abstract": "Stochastic rising rested bandit (SRRB) is a setting where the arms' expected\nrewards increase as they are pulled. It models scenarios in which the\nperformances of the different options grow as an effect of an underlying\nlearning process (e.g., online model selection). Even if the bandit literature\nprovides specifically crafted algorithms based on upper-confidence bounds for\nsuch a setting, no study about Thompson sampling TS-like algorithms has been\nperformed so far. The strong regularity of the expected rewards in the SRRB\nsetting suggests that specific instances may be tackled effectively using\nadapted and sliding-window TS approaches. This work provides novel regret\nanalyses for such algorithms in SRRBs, highlighting the challenges and\nproviding new technical tools of independent interest. Our results allow us to\nidentify under which assumptions TS-like algorithms succeed in achieving\nsublinear regret and which properties of the environment govern the complexity\nof the regret minimization problem when approached with TS. Furthermore, we\nprovide a regret lower bound based on a complexity index we introduce. Finally,\nwe conduct numerical simulations comparing TS-like algorithms with\nstate-of-the-art approaches for SRRBs in synthetic and real-world settings.", "published": "2025-05-17 17:19:07", "link": "http://arxiv.org/abs/2505.12092v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Integrative Analysis and Imputation of Multiple Data Streams via Deep Gaussian Processes", "abstract": "Healthcare data, particularly in critical care settings, presents three key\nchallenges for analysis. First, physiological measurements come from different\nsources but are inherently related. Yet, traditional methods often treat each\nmeasurement type independently, losing valuable information about their\nrelationships. Second, clinical measurements are collected at irregular\nintervals, and these sampling times can carry clinical meaning. Finally, the\nprevalence of missing values. Whilst several imputation methods exist to tackle\nthis common problem, they often fail to address the temporal nature of the data\nor provide estimates of uncertainty in their predictions. We propose using deep\nGaussian process emulation with stochastic imputation, a methodology initially\nconceived to deal with computationally expensive models and uncertainty\nquantification, to solve the problem of handling missing values that naturally\noccur in critical care data. This method leverages longitudinal and\ncross-sectional information and provides uncertainty estimation for the imputed\nvalues. Our evaluation of a clinical dataset shows that the proposed method\nperforms better than conventional methods, such as multiple imputations with\nchained equations (MICE), last-known value imputation, and individually fitted\nGaussian Processes (GPs).", "published": "2025-05-17 16:32:52", "link": "http://arxiv.org/abs/2505.12076v1", "categories": ["stat.AP", "stat.ML", "60G15, 62D10", "G.3; I.2.1; J.3"], "primary_category": "stat.AP"}
{"title": "Variance-Optimal Arm Selection: Regret Minimization and Best Arm Identification", "abstract": "This paper focuses on selecting the arm with the highest variance from a set\nof $K$ independent arms. Specifically, we focus on two settings: (i) regret\nsetting, that penalizes the number of pulls of suboptimal arms in terms of\nvariance, and (ii) fixed-budget \\ac{BAI} setting, that evaluates the ability of\nan algorithm to determine the arm with the highest variance after a fixed\nnumber of pulls. We develop a novel online algorithm called \\texttt{UCB-VV} for\nthe regret setting and show that its upper bound on regret for bounded rewards\nevolves as $\\mathcal{O}\\left(\\log{n}\\right)$ where $n$ is the horizon. By\nderiving the lower bound on the regret, we show that \\texttt{UCB-VV} is order\noptimal. For the fixed budget \\ac{BAI} setting and propose the \\texttt{SHVV}\nalgorithm. We show that the upper bound of the error probability of\n\\texttt{SHVV} evolves as $\\exp\\left(-\\frac{n}{\\log(K) H}\\right)$, where $H$\nrepresents the complexity of the problem, and this rate matches the\ncorresponding lower bound. We extend the framework from bounded distributions\nto sub-Gaussian distributions using a novel concentration inequality on the\nsample variance. Leveraging the same, we derive a concentration inequality for\nthe empirical Sharpe ratio (SR) for sub-Gaussian distributions, which was\npreviously unknown in the literature. Empirical simulations show that\n\\texttt{UCB-VV} consistently outperforms \\texttt{$\\epsilon$-greedy} across\ndifferent sub-optimality gaps though it is surpassed by \\texttt{VTS}, which\nexhibits the lowest regret, albeit lacking in theoretical guarantees. We also\nillustrate the superior performance of \\texttt{SHVV}, for a fixed budget\nsetting under 6 different setups against uniform sampling. Finally, we conduct\na case study to empirically evaluate the performance of the \\texttt{UCB-VV} and\n\\texttt{SHVV} in call option trading on $100$ stocks generated using \\ac{GBM}.", "published": "2025-05-17 12:38:23", "link": "http://arxiv.org/abs/2505.11985v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Multi-Attribute Graph Estimation with Sparse-Group Non-Convex Penalties", "abstract": "We consider the problem of inferring the conditional independence graph (CIG)\nof high-dimensional Gaussian vectors from multi-attribute data. Most existing\nmethods for graph estimation are based on single-attribute models where one\nassociates a scalar random variable with each node. In multi-attribute\ngraphical models, each node represents a random vector. In this paper we\nprovide a unified theoretical analysis of multi-attribute graph learning using\na penalized log-likelihood objective function. We consider both convex\n(sparse-group lasso) and sparse-group non-convex (log-sum and smoothly clipped\nabsolute deviation (SCAD) penalties) penalty/regularization functions. An\nalternating direction method of multipliers (ADMM) approach coupled with local\nlinear approximation to non-convex penalties is presented for optimization of\nthe objective function. For non-convex penalties, theoretical analysis\nestablishing local consistency in support recovery, local convexity and\nprecision matrix estimation in high-dimensional settings is provided under two\nsets of sufficient conditions: with and without some irrepresentability\nconditions. We illustrate our approaches using both synthetic and real-data\nnumerical examples. In the synthetic data examples the sparse-group log-sum\npenalized objective function significantly outperformed the lasso penalized as\nwell as SCAD penalized objective functions with $F_1$-score and Hamming\ndistance as performance metrics.", "published": "2025-05-17 12:35:28", "link": "http://arxiv.org/abs/2505.11984v1", "categories": ["stat.ML", "cs.LG", "eess.SP"], "primary_category": "stat.ML"}
{"title": "Accelerating Neural Network Training Along Sharp and Flat Directions", "abstract": "Recent work has highlighted a surprising alignment between gradients and the\ntop eigenspace of the Hessian -- termed the Dominant subspace -- during neural\nnetwork training. Concurrently, there has been growing interest in the distinct\nroles of sharp and flat directions in the Hessian spectrum. In this work, we\nstudy Bulk-SGD, a variant of SGD that restricts updates to the orthogonal\ncomplement of the Dominant subspace. Through ablation studies, we characterize\nthe stability properties of Bulk-SGD and identify critical hyperparameters that\ngovern its behavior. We show that updates along the Bulk subspace,\ncorresponding to flatter directions in the loss landscape, can accelerate\nconvergence but may compromise stability. To balance these effects, we\nintroduce interpolated gradient methods that unify SGD, Dom-SGD, and Bulk-SGD.\nFinally, we empirically connect this subspace decomposition to the Generalized\nGauss-Newton and Functional Hessian terms, showing that curvature energy is\nlargely concentrated in the Dominant subspace. Our findings suggest a\nprincipled approach to designing curvature-aware optimizers.", "published": "2025-05-17 12:13:05", "link": "http://arxiv.org/abs/2505.11972v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Transformers as Unsupervised Learning Algorithms: A study on Gaussian Mixtures", "abstract": "The transformer architecture has demonstrated remarkable capabilities in\nmodern artificial intelligence, among which the capability of implicitly\nlearning an internal model during inference time is widely believed to play a\nkey role in the under standing of pre-trained large language models. However,\nmost recent works have been focusing on studying supervised learning topics\nsuch as in-context learning, leaving the field of unsupervised learning largely\nunexplored. This paper investigates the capabilities of transformers in solving\nGaussian Mixture Models (GMMs), a fundamental unsupervised learning problem\nthrough the lens of statistical estimation. We propose a transformer-based\nlearning framework called TGMM that simultaneously learns to solve multiple GMM\ntasks using a shared transformer backbone. The learned models are empirically\ndemonstrated to effectively mitigate the limitations of classical methods such\nas Expectation-Maximization (EM) or spectral algorithms, at the same time\nexhibit reasonable robustness to distribution shifts. Theoretically, we prove\nthat transformers can approximate both the EM algorithm and a core component of\nspectral methods (cubic tensor power iterations). These results bridge the gap\nbetween practical success and theoretical understanding, positioning\ntransformers as versatile tools for unsupervised learning.", "published": "2025-05-17 09:02:18", "link": "http://arxiv.org/abs/2505.11918v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Improving Coverage in Combined Prediction Sets with Weighted p-values", "abstract": "Conformal prediction quantifies the uncertainty of machine learning models by\naugmenting point predictions with valid prediction sets, assuming\nexchangeability. For complex scenarios involving multiple trials, models, or\ndata sources, conformal prediction sets can be aggregated to create a\nprediction set that captures the overall uncertainty, often improving\nprecision. However, aggregating multiple prediction sets with individual\n$1-\\alpha$ coverage inevitably weakens the overall guarantee, typically\nresulting in $1-2\\alpha$ worst-case coverage. In this work, we propose a\nframework for the weighted aggregation of prediction sets, where weights are\nassigned to each prediction set based on their contribution. Our framework\noffers flexible control over how the sets are aggregated, achieving tighter\ncoverage bounds that interpolate between the $1-2\\alpha$ guarantee of the\ncombined models and the $1-\\alpha$ guarantee of an individual model depending\non the distribution of weights. We extend our framework to data-dependent\nweights, and we derive a general procedure for data-dependent weight\naggregation that maintains finite-sample validity. We demonstrate the\neffectiveness of our methods through experiments on synthetic and real data in\nthe mixture-of-experts setting, and we show that aggregation with\ndata-dependent weights provides a form of adaptive coverage.", "published": "2025-05-17 01:51:28", "link": "http://arxiv.org/abs/2505.11785v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Residual Feature Integration is Sufficient to Prevent Negative Transfer", "abstract": "Transfer learning typically leverages representations learned from a source\ndomain to improve performance on a target task. A common approach is to extract\nfeatures from a pre-trained model and directly apply them for target\nprediction. However, this strategy is prone to negative transfer where the\nsource representation fails to align with the target distribution. In this\narticle, we propose Residual Feature Integration (REFINE), a simple yet\neffective method designed to mitigate negative transfer. Our approach combines\na fixed source-side representation with a trainable target-side encoder and\nfits a shallow neural network on the resulting joint representation, which\nadapts to the target domain while preserving transferable knowledge from the\nsource domain. Theoretically, we prove that REFINE is sufficient to prevent\nnegative transfer under mild conditions, and derive the generalization bound\ndemonstrating its theoretical benefit. Empirically, we show that REFINE\nconsistently enhances performance across diverse application and data\nmodalities including vision, text, and tabular data, and outperforms numerous\nalternative solutions. Our method is lightweight, architecture-agnostic, and\nrobust, making it a valuable addition to the existing transfer learning\ntoolbox.", "published": "2025-05-17 00:36:59", "link": "http://arxiv.org/abs/2505.11771v1", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors", "abstract": "Interpretability research now offers a variety of techniques for identifying\nabstract internal mechanisms in neural networks. Can such techniques be used to\npredict how models will behave on out-of-distribution examples? In this work,\nwe provide a positive answer to this question. Through a diverse set of\nlanguage modeling tasks--including symbol manipulation, knowledge retrieval,\nand instruction following--we show that the most robust features for\ncorrectness prediction are those that play a distinctive causal role in the\nmodel's behavior. Specifically, we propose two methods that leverage causal\nmechanisms to predict the correctness of model outputs: counterfactual\nsimulation (checking whether key causal variables are realized) and value\nprobing (using the values of those variables to make predictions). Both achieve\nhigh AUC-ROC in distribution and outperform methods that rely on\ncausal-agnostic features in out-of-distribution settings, where predicting\nmodel behaviors is more crucial. Our work thus highlights a novel and\nsignificant application for internal causal analysis of language models.", "published": "2025-05-17 00:31:39", "link": "http://arxiv.org/abs/2505.11770v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "WaLRUS: Wavelets for Long-range Representation Using SSMs", "abstract": "State-Space Models (SSMs) have proven to be powerful tools for modeling\nlong-range dependencies in sequential data. While the recent method known as\nHiPPO has demonstrated strong performance, and formed the basis for machine\nlearning models S4 and Mamba, it remains limited by its reliance on closed-form\nsolutions for a few specific, well-behaved bases. The SaFARi framework\ngeneralized this approach, enabling the construction of SSMs from arbitrary\nframes, including non-orthogonal and redundant ones, thus allowing an infinite\ndiversity of possible \"species\" within the SSM family. In this paper, we\nintroduce WaLRUS (Wavelets for Long-range Representation Using SSMs), a new\nimplementation of SaFARi built from Daubechies wavelets.", "published": "2025-05-17 22:41:24", "link": "http://arxiv.org/abs/2505.12161v1", "categories": ["eess.IV", "cs.LG", "cs.SY", "eess.AS", "eess.SP", "eess.SY"], "primary_category": "eess.IV"}
{"title": "Learning to Highlight Audio by Watching Movies", "abstract": "Recent years have seen a significant increase in video content creation and\nconsumption. Crafting engaging content requires the careful curation of both\nvisual and audio elements. While visual cue curation, through techniques like\noptimal viewpoint selection or post-editing, has been central to media\nproduction, its natural counterpart, audio, has not undergone equivalent\nadvancements. This often results in a disconnect between visual and acoustic\nsaliency. To bridge this gap, we introduce a novel task: visually-guided\nacoustic highlighting, which aims to transform audio to deliver appropriate\nhighlighting effects guided by the accompanying video, ultimately creating a\nmore harmonious audio-visual experience. We propose a flexible,\ntransformer-based multimodal framework to solve this task. To train our model,\nwe also introduce a new dataset -- the muddy mix dataset, leveraging the\nmeticulous audio and video crafting found in movies, which provides a form of\nfree supervision. We develop a pseudo-data generation process to simulate\npoorly mixed audio, mimicking real-world scenarios through a three-step process\n-- separation, adjustment, and remixing. Our approach consistently outperforms\nseveral baselines in both quantitative and subjective evaluation. We also\nsystematically study the impact of different types of contextual guidance and\ndifficulty levels of the dataset. Our project page is here:\nhttps://wikichao.github.io/VisAH/.", "published": "2025-05-17 22:03:57", "link": "http://arxiv.org/abs/2505.12154v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "SepPrune: Structured Pruning for Efficient Deep Speech Separation", "abstract": "Although deep learning has substantially advanced speech separation in recent\nyears, most existing studies continue to prioritize separation quality while\noverlooking computational efficiency, an essential factor for low-latency\nspeech processing in real-time applications. In this paper, we propose\nSepPrune, the first structured pruning framework specifically designed to\ncompress deep speech separation models and reduce their computational cost.\nSepPrune begins by analyzing the computational structure of a given model to\nidentify layers with the highest computational burden. It then introduces a\ndifferentiable masking strategy to enable gradient-driven channel selection.\nBased on the learned masks, SepPrune prunes redundant channels and fine-tunes\nthe remaining parameters to recover performance. Extensive experiments\ndemonstrate that this learnable pruning paradigm yields substantial advantages\nfor channel pruning in speech separation models, outperforming existing\nmethods. Notably, a model pruned with SepPrune can recover 85% of the\nperformance of a pre-trained model (trained over hundreds of epochs) with only\none epoch of fine-tuning, and achieves convergence 36$\\times$ faster than\ntraining from scratch. Code is available at\nhttps://github.com/itsnotacie/SepPrune.", "published": "2025-05-17 16:44:38", "link": "http://arxiv.org/abs/2505.12079v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BINAQUAL: A Full-Reference Objective Localization Similarity Metric for Binaural Audio", "abstract": "Spatial audio enhances immersion in applications such as virtual reality,\naugmented reality, gaming, and cinema by creating a three-dimensional auditory\nexperience. Ensuring the spatial fidelity of binaural audio is crucial, given\nthat processes such as compression, encoding, or transmission can alter\nlocalization cues. While subjective listening tests like MUSHRA remain the gold\nstandard for evaluating spatial localization quality, they are costly and\ntime-consuming. This paper introduces BINAQUAL, a full-reference objective\nmetric designed to assess localization similarity in binaural audio recordings.\nBINAQUAL adapts the AMBIQUAL metric, originally developed for localization\nquality assessment in ambisonics audio format to the binaural domain. We\nevaluate BINAQUAL across five key research questions, examining its sensitivity\nto variations in sound source locations, angle interpolations, surround speaker\nlayouts, audio degradations, and content diversity. Results demonstrate that\nBINAQUAL effectively differentiates between subtle spatial variations and\ncorrelates strongly with subjective listening tests, making it a reliable\nmetric for binaural localization quality assessment. The proposed metric\nprovides a robust benchmark for ensuring spatial accuracy in binaural audio\nprocessing, paving the way for improved objective evaluations in immersive\naudio applications.", "published": "2025-05-17 08:59:39", "link": "http://arxiv.org/abs/2505.11915v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Exploring the Potential of SSL Models for Sound Event Detection", "abstract": "Self-supervised learning (SSL) models offer powerful representations for\nsound event detection (SED), yet their synergistic potential remains\nunderexplored. This study systematically evaluates state-of-the-art SSL models\nto guide optimal model selection and integration for SED. We propose a\nframework that combines heterogeneous SSL representations (e.g., BEATs, HuBERT,\nWavLM) through three fusion strategies: individual SSL embedding integration,\ndual-modal fusion, and full aggregation. Experiments on the DCASE 2023 Task 4\nChallenge reveal that dual-modal fusion (e.g., CRNN+BEATs+WavLM) achieves\ncomplementary performance gains, while CRNN+BEATs alone delivers the best\nresults among individual SSL models. We further introduce normalized sound\nevent bounding boxes (nSEBBs), an adaptive post-processing method that\ndynamically adjusts event boundary predictions, improving PSDS1 by up to 4% for\nstandalone SSL models. These findings highlight the compatibility and\ncomplementarity of SSL architectures, providing guidance for task-specific\nfusion and robust SED system design.", "published": "2025-05-17 07:54:31", "link": "http://arxiv.org/abs/2505.11889v1", "categories": ["eess.AS", "cs.AI", "cs.SD", "I.5.4; I.2.10; H.5.5"], "primary_category": "eess.AS"}
{"title": "AnalyticKWS: Towards Exemplar-Free Analytic Class Incremental Learning for Small-footprint Keyword Spotting", "abstract": "Keyword spotting (KWS) offers a vital mechanism to identify spoken commands\nin voice-enabled systems, where user demands often shift, requiring models to\nlearn new keywords continually over time. However, a major problem is\ncatastrophic forgetting, where models lose their ability to recognize earlier\nkeywords. Although several continual learning methods have proven their\nusefulness for reducing forgetting, most existing approaches depend on storing\nand revisiting old data to combat catastrophic forgetting. Though effective,\nthese methods face two practical challenges: 1) privacy risks from keeping user\ndata and 2) large memory and time consumption that limit deployment on small\ndevices. To address these issues, we propose an exemplar-free Analytic\nContinual Learning (AnalyticKWS) method that updates model parameters without\nrevisiting earlier data. Inspired by efficient learning principles, AnalyticKWS\ncomputes a closed-form analytical solution for model updates and requires only\na single epoch of adaptation for incoming keywords. AnalyticKWS demands fewer\ncomputational resources by avoiding gradient-based updates and does not store\nold data. By eliminating the need for back-propagation during incremental\nlearning, the model remains lightweight and efficient. As a result, AnalyticKWS\nmeets the challenges mentioned earlier and suits resource-limited settings\nwell. Extensive experiments on various datasets and settings show that\nAnalyticKWS consistently outperforms existing continual learning methods.", "published": "2025-05-17 03:55:28", "link": "http://arxiv.org/abs/2505.11817v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "OFDM Based Bistatic Integrated Sensing and Communication: Sensing Beyond CP Limit", "abstract": "This work investigates a bistatic OFDM-based integrated sensing and\ncommunication (ISAC) system under a single-target scenario, considering both\nline-of-sight (LOS) presence and LOS blockage cases. A sliding window-based\nsensing receiver architecture is proposed to extend the intersymbol\ninterference (ISI)-free sensing range beyond the cyclic prefix (CP) duration by\nexploiting pilot symbols embedded in the time-frequency grid. The performance\nof the proposed receiver is evaluated in terms of range and velocity estimation\naccuracy and is compared against the Cramer-Rao bounds (CRBs) for the bi-static\nISAC setting. Numerical results confirm that the proposed method achieves\nestimation performance that closely approaches the CRBs in the high\nsignal-to-noise ratio (SNR) regime.", "published": "2025-05-17 22:49:58", "link": "http://arxiv.org/abs/2505.12166v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "LLM-guided DRL for Multi-tier LEO Satellite Networks with Hybrid FSO/RF Links", "abstract": "Despite significant advancements in terrestrial networks, inherent\nlimitations persist in providing reliable coverage to remote areas and\nmaintaining resilience during natural disasters. Multi-tier networks with low\nEarth orbit (LEO) satellites and high-altitude platforms (HAPs) offer promising\nsolutions, but face challenges from high mobility and dynamic channel\nconditions that cause unstable connections and frequent handovers. In this\npaper, we design a three-tier network architecture that integrates LEO\nsatellites, HAPs, and ground terminals with hybrid free-space optical (FSO) and\nradio frequency (RF) links to maximize coverage while maintaining connectivity\nreliability. This hybrid approach leverages the high bandwidth of FSO for\nsatellite-to-HAP links and the weather resilience of RF for HAP-to-ground\nlinks. We formulate a joint optimization problem to simultaneously balance\ndownlink transmission rate and handover frequency by optimizing network\nconfiguration and satellite handover decisions. The problem is highly dynamic\nand non-convex with time-coupled constraints. To address these challenges, we\npropose a novel large language model (LLM)-guided truncated quantile critics\nalgorithm with dynamic action masking (LTQC-DAM) that utilizes dynamic action\nmasking to eliminate unnecessary exploration and employs LLMs to adaptively\ntune hyperparameters. Simulation results demonstrate that the proposed LTQC-DAM\nalgorithm outperforms baseline algorithms in terms of convergence, downlink\ntransmission rate, and handover frequency. We also reveal that compared to\nother state-of-the-art LLMs, DeepSeek delivers the best performance through\ngradual, contextually-aware parameter adjustments.", "published": "2025-05-17 12:21:30", "link": "http://arxiv.org/abs/2505.11978v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Fine-Grained ECG-Text Contrastive Learning via Waveform Understanding Enhancement", "abstract": "Electrocardiograms (ECGs) are essential for diagnosing cardiovascular\ndiseases. While previous ECG-text contrastive learning methods have shown\npromising results, they often overlook the incompleteness of the reports. Given\nan ECG, the report is generated by first identifying key waveform features and\nthen inferring the final diagnosis through these features. Despite their\nimportance, these waveform features are often not recorded in the report as\nintermediate results. Aligning ECGs with such incomplete reports impedes the\nmodel's ability to capture the ECG's waveform features and limits its\nunderstanding of diagnostic reasoning based on those features. To address this,\nwe propose FG-CLEP (Fine-Grained Contrastive Language ECG Pre-training), which\naims to recover these waveform features from incomplete reports with the help\nof large language models (LLMs), under the challenges of hallucinations and the\nnon-bijective relationship between waveform features and diagnoses.\nAdditionally, considering the frequent false negatives due to the prevalence of\ncommon diagnoses in ECGs, we introduce a semantic similarity matrix to guide\ncontrastive learning. Furthermore, we adopt a sigmoid-based loss function to\naccommodate the multi-label nature of ECG-related tasks. Experiments on six\ndatasets demonstrate that FG-CLEP outperforms state-of-the-art methods in both\nzero-shot prediction and linear probing across these datasets.", "published": "2025-05-17 10:03:06", "link": "http://arxiv.org/abs/2505.11939v1", "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "eess.SP"}
{"title": "S-Crescendo: A Nested Transformer Weaving Framework for Scalable Nonlinear System in S-Domain Representation", "abstract": "Simulation of high-order nonlinear system requires extensive computational\nresources, especially in modern VLSI backend design where bifurcation-induced\ninstability and chaos-like transient behaviors pose challenges. We present\nS-Crescendo - a nested transformer weaving framework that synergizes S-domain\nwith neural operators for scalable time-domain prediction in high-order\nnonlinear networks, alleviating the computational bottlenecks of conventional\nsolvers via Newton-Raphson method. By leveraging the partial-fraction\ndecomposition of an n-th order transfer function into first-order modal terms\nwith repeated poles and residues, our method bypasses the conventional Jacobian\nmatrix-based iterations and efficiently reduces computational complexity from\ncubic $O(n^3)$ to linear $O(n)$.The proposed architecture seamlessly integrates\nan S-domain encoder with an attention-based correction operator to\nsimultaneously isolate dominant response and adaptively capture higher-order\nnon-linearities. Validated on order-1 to order-10 networks, our method achieves\nup to 0.99 test-set ($R^2$) accuracy against HSPICE golden waveforms and\naccelerates simulation by up to 18(X), providing a scalable, physics-aware\nframework for high-dimensional nonlinear modeling.", "published": "2025-05-17 05:06:58", "link": "http://arxiv.org/abs/2505.11843v1", "categories": ["eess.SP", "cs.LG"], "primary_category": "eess.SP"}
{"title": "Thompson Sampling-like Algorithms for Stochastic Rising Bandits", "abstract": "Stochastic rising rested bandit (SRRB) is a setting where the arms' expected\nrewards increase as they are pulled. It models scenarios in which the\nperformances of the different options grow as an effect of an underlying\nlearning process (e.g., online model selection). Even if the bandit literature\nprovides specifically crafted algorithms based on upper-confidence bounds for\nsuch a setting, no study about Thompson sampling TS-like algorithms has been\nperformed so far. The strong regularity of the expected rewards in the SRRB\nsetting suggests that specific instances may be tackled effectively using\nadapted and sliding-window TS approaches. This work provides novel regret\nanalyses for such algorithms in SRRBs, highlighting the challenges and\nproviding new technical tools of independent interest. Our results allow us to\nidentify under which assumptions TS-like algorithms succeed in achieving\nsublinear regret and which properties of the environment govern the complexity\nof the regret minimization problem when approached with TS. Furthermore, we\nprovide a regret lower bound based on a complexity index we introduce. Finally,\nwe conduct numerical simulations comparing TS-like algorithms with\nstate-of-the-art approaches for SRRBs in synthetic and real-world settings.", "published": "2025-05-17 17:19:07", "link": "http://arxiv.org/abs/2505.12092v2", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Variance-Optimal Arm Selection: Regret Minimization and Best Arm Identification", "abstract": "This paper focuses on selecting the arm with the highest variance from a set\nof $K$ independent arms. Specifically, we focus on two settings: (i) regret\nsetting, that penalizes the number of pulls of suboptimal arms in terms of\nvariance, and (ii) fixed-budget BAI setting, that evaluates the ability of an\nalgorithm to determine the arm with the highest variance after a fixed number\nof pulls. We develop a novel online algorithm called \\texttt{UCB-VV} for the\nregret setting and show that its upper bound on regret for bounded rewards\nevolves as $\\mathcal{O}\\left(\\log{n}\\right)$ where $n$ is the horizon. By\nderiving the lower bound on the regret, we show that \\texttt{UCB-VV} is order\noptimal. For the fixed budget BAI setting, we propose the \\texttt{SHVV}\nalgorithm. We show that the upper bound of the error probability of\n\\texttt{SHVV} evolves as $\\exp\\left(-\\frac{n}{\\log(K) H}\\right)$, where $H$\nrepresents the complexity of the problem, and this rate matches the\ncorresponding lower bound. We extend the framework from bounded distributions\nto sub-Gaussian distributions using a novel concentration inequality on the\nsample variance. Leveraging the same, we derive a concentration inequality for\nthe empirical Sharpe ratio (SR) for sub-Gaussian distributions, which was\npreviously unknown in the literature. Empirical simulations show that\n\\texttt{UCB-VV} consistently outperforms \\texttt{$\\epsilon$-greedy} across\ndifferent sub-optimality gaps, though it is surpassed by \\texttt{VTS}, which\nexhibits the lowest regret, albeit lacking in theoretical guarantees. We also\nillustrate the superior performance of \\texttt{SHVV}, for a fixed budget\nsetting under 6 different setups against uniform sampling. Finally, we conduct\na case study to empirically evaluate the performance of the \\texttt{UCB-VV} and\n\\texttt{SHVV} in call option trading on $100$ stocks generated using geometric\nBrownian motion (GBM).", "published": "2025-05-17 12:38:23", "link": "http://arxiv.org/abs/2505.11985v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Beyond Retrieval: Joint Supervision and Multimodal Document Ranking for Textbook Question Answering", "abstract": "Textbook question answering (TQA) is a complex task, requiring the\ninterpretation of complex multimodal context. Although recent advances have\nimproved overall performance, they often encounter difficulties in educational\nsettings where accurate semantic alignment and task-specific document retrieval\nare essential. In this paper, we propose a novel approach to multimodal\ntextbook question answering by introducing a mechanism for enhancing semantic\nrepresentations through multi-objective joint training. Our model, Joint\nEmbedding Training With Ranking Supervision for Textbook Question Answering\n(JETRTQA), is a multimodal learning framework built on a retriever--generator\narchitecture that uses a retrieval-augmented generation setup, in which a\nmultimodal large language model generates answers. JETRTQA is designed to\nimprove the relevance of retrieved documents in complex educational contexts.\nUnlike traditional direct scoring approaches, JETRTQA learns to refine the\nsemantic representations of questions and documents through a supervised signal\nthat combines pairwise ranking and implicit supervision derived from answers.\nWe evaluate our method on the CK12-QA dataset and demonstrate that it\nsignificantly improves the discrimination between informative and irrelevant\ndocuments, even when they are long, complex, and multimodal. JETRTQA\noutperforms the previous state of the art, achieving a 2.4\\% gain in accuracy\non the validation set and 11.1\\% on the test set.", "published": "2025-05-17 13:23:54", "link": "http://arxiv.org/abs/2505.13520v1", "categories": ["cs.IR", "cs.AI"], "primary_category": "cs.IR"}
{"title": "HALO: Hierarchical Autonomous Logic-Oriented Orchestration for Multi-Agent LLM Systems", "abstract": "Recent advancements in Multi-Agent Systems (MAS) powered by Large Language\nModels (LLMs) have demonstrated tremendous potential in diverse task scenarios.\nNonetheless, existing agentic systems typically rely on predefined agent-role\ndesign spaces and static communication structures, limiting their adaptability\nas well as flexibility in complex interaction environments and leading to\nsubpar performance on highly specialized and expert-level tasks. To address\nthese issues, we introduce HALO, a multi-agent collaboration framework based on\na hierarchical reasoning architecture. Specifically, we incorporate a\nhigh-level planning agent for task decomposition, mid-level role-design agents\nfor subtask-specific agent instantiation, and low-level inference agents for\nsubtask execution. Particularly, subtask execution is reformulated as a\nstructured workflow search problem, where Monte Carlo Tree Search (MCTS)\nsystematically explores the agentic action space to construct optimal reasoning\ntrajectories. Additionally, as the majority of users lack expertise in prompt\nengineering, we leverage an Adaptive Prompt Refinement module to transform raw\nqueries into task-specific prompts. Empirical evaluations on Code Generation\n(HumanEval), General Reasoning (MMLU), and Arithmetic Reasoning (MATH)\nbenchmark datasets highlight the effectiveness of HALO, yielding a 14.4%\naverage improvement over state-of-the-art baselines. Notably, HALO achieves up\nto 13.3% performance gain on the Moral Scenarios subject in the MMLU benchmark\nand up to 19.6% performance gain on the Algebra subarea in the MATH benchmark,\nindicating its advanced proficiency in tackling highly specialized and\nexpert-level tasks. The code repository is available at\nhttps://github.com/23japhone/HALO.", "published": "2025-05-17 04:14:03", "link": "http://arxiv.org/abs/2505.13516v1", "categories": ["cs.MA", "cs.AI"], "primary_category": "cs.MA"}
{"title": "Continuous Domain Generalization", "abstract": "Real-world data distributions often shift continuously across multiple latent\nfactors such as time, geography, and socioeconomic context. However, existing\ndomain generalization approaches typically treat domains as discrete or\nevolving along a single axis (e.g., time), which fails to capture the complex,\nmulti-dimensional nature of real-world variation. This paper introduces the\ntask of Continuous Domain Generalization (CDG), which aims to generalize\npredictive models to unseen domains defined by arbitrary combinations of\ncontinuous variation descriptors. We present a principled framework grounded in\ngeometric and algebraic theory, showing that optimal model parameters across\ndomains lie on a low-dimensional manifold. To model this structure, we propose\na Neural Lie Transport Operator (NeuralLTO), which enables structured parameter\ntransitions by enforcing geometric continuity and algebraic consistency. To\nhandle noisy or incomplete domain descriptors, we introduce a gating mechanism\nto suppress irrelevant dimensions and a local chart-based strategy for robust\ngeneralization. Extensive experiments on synthetic and real-world\ndatasets-including remote sensing, scientific documents, and traffic\nforecasting-demonstrate that our method significantly outperforms existing\nbaselines in generalization accuracy and robustness under descriptor\nimperfections.", "published": "2025-05-17 12:39:45", "link": "http://arxiv.org/abs/2505.13519v1", "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "stat.ML"}
