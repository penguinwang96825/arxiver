{"title": "Periodic portfolio selection with quasi-hyperbolic discounting", "abstract": "We introduce an infinite-horizon, continuous-time portfolio selection problem\nfaced by an agent with periodic S-shaped preference and present bias. The\ninclusion of a quasi-hyperbolic discount function leads to time-inconsistency\nand we characterize the optimal portfolio for a pre-committing, naive and\nsophisticated agent respectively. In the more theoretically challenging problem\nwith a sophisticated agent, the time-consistent planning strategy can be\nformulated as an equilibrium to a static mean field game. Interestingly,\npresent bias and naivety do not necessarily result in less desirable risk\ntaking behaviors, while agent's sophistication may lead to excessive leverage\n(underinvestement) in the bad (good) states of the world.", "published": "2024-10-23 19:34:45", "link": "http://arxiv.org/abs/2410.18240v1", "categories": ["q-fin.PM", "econ.GN", "q-fin.EC", "q-fin.GN", "q-fin.MF", "49L99, 49N90, 91A10, 91E99, 91G10, 93E20"], "primary_category": "q-fin.PM"}
{"title": "Enhancing literature review with LLM and NLP methods. Algorithmic trading case", "abstract": "This study utilizes machine learning algorithms to analyze and organize\nknowledge in the field of algorithmic trading. By filtering a dataset of 136\nmillion research papers, we identified 14,342 relevant articles published\nbetween 1956 and Q1 2020. We compare traditional practices-such as\nkeyword-based algorithms and embedding techniques-with state-of-the-art topic\nmodeling methods that employ dimensionality reduction and clustering. This\ncomparison allows us to assess the popularity and evolution of different\napproaches and themes within algorithmic trading. We demonstrate the usefulness\nof Natural Language Processing (NLP) in the automatic extraction of knowledge,\nhighlighting the new possibilities created by the latest iterations of Large\nLanguage Models (LLMs) like ChatGPT. The rationale for focusing on this topic\nstems from our analysis, which reveals that research articles on algorithmic\ntrading are increasing at a faster rate than the overall number of\npublications. While stocks and main indices comprise more than half of all\nassets considered, certain asset classes, such as cryptocurrencies, exhibit a\nmuch stronger growth trend. Machine learning models have become the most\npopular methods in recent years. The study demonstrates the efficacy of LLMs in\nrefining datasets and addressing intricate questions about the analyzed\narticles, such as comparing the efficiency of different models. Our research\nshows that by decomposing tasks into smaller components and incorporating\nreasoning steps, we can effectively tackle complex questions supported by case\nanalyses. This approach contributes to a deeper understanding of algorithmic\ntrading methodologies and underscores the potential of advanced NLP techniques\nin literature reviews.", "published": "2024-10-23 13:37:27", "link": "http://arxiv.org/abs/2411.05013v1", "categories": ["q-fin.ST", "cs.AI", "cs.LG", "q-fin.TR"], "primary_category": "q-fin.ST"}
{"title": "Is artificial intelligence still intelligence? LLMs generalize to novel\n  adjective-noun pairs, but don't mimic the full human distribution", "abstract": "Inferences from adjective-noun combinations like \"Is artificial intelligence\nstill intelligence?\" provide a good test bed for LLMs' understanding of meaning\nand compositional generalization capability, since there are many combinations\nwhich are novel to both humans and LLMs but nevertheless elicit convergent\nhuman judgments. We study a range of LLMs and find that the largest models we\ntested are able to draw human-like inferences when the inference is determined\nby context and can generalize to unseen adjective-noun combinations. We also\npropose three methods to evaluate LLMs on these inferences out of context,\nwhere there is a distribution of human-like answers rather than a single\ncorrect answer. We find that LLMs show a human-like distribution on at most\n75\\% of our dataset, which is promising but still leaves room for improvement.", "published": "2024-10-23 00:05:57", "link": "http://arxiv.org/abs/2410.17482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models Still Exhibit Bias in Long Text", "abstract": "Existing fairness benchmarks for large language models (LLMs) primarily focus\non simple tasks, such as multiple-choice questions, overlooking biases that may\narise in more complex scenarios like long-text generation. To address this gap,\nwe introduce the Long Text Fairness Test (LTF-TEST), a framework that evaluates\nbiases in LLMs through essay-style prompts. LTF-TEST covers 14 topics and 10\ndemographic axes, including gender and race, resulting in 11,948 samples. By\nassessing both model responses and the reasoning behind them, LTF-TEST uncovers\nsubtle biases that are difficult to detect in simple responses. In our\nevaluation of five recent LLMs, including GPT-4o and LLaMa3, we identify two\nkey patterns of bias. First, these models frequently favor certain demographic\ngroups in their responses. Second, they show excessive sensitivity toward\ntraditionally disadvantaged groups, often providing overly protective responses\nwhile neglecting others. To mitigate these biases, we propose FT-REGARD, a\nfinetuning approach that pairs biased prompts with neutral responses. FT-REGARD\nreduces gender bias by 34.6% and improves performance by 1.4 percentage points\non the BBQ benchmark, offering a promising approach to addressing biases in\nlong-text generation tasks.", "published": "2024-10-23 02:51:33", "link": "http://arxiv.org/abs/2410.17519v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Navigate Complex Physical Worlds via Geometrically Constrained LLM", "abstract": "This study investigates the potential of Large Language Models (LLMs) for\nreconstructing and constructing the physical world solely based on textual\nknowledge. It explores the impact of model performance on spatial understanding\nabilities. To enhance the comprehension of geometric and spatial relationships\nin the complex physical world, the study introduces a set of geometric\nconventions and develops a workflow based on multi-layer graphs and multi-agent\nsystem frameworks. It examines how LLMs achieve multi-step and multi-objective\ngeometric inference in a spatial environment using multi-layer graphs under\nunified geometric conventions. Additionally, the study employs a genetic\nalgorithm, inspired by large-scale model knowledge, to solve geometric\nconstraint problems. In summary, this work innovatively explores the\nfeasibility of using text-based LLMs as physical world builders and designs a\nworkflow to enhance their capabilities.", "published": "2024-10-23 03:14:07", "link": "http://arxiv.org/abs/2410.17529v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ESpeW: Robust Copyright Protection for LLM-based EaaS via\n  Embedding-Specific Watermark", "abstract": "Embeddings as a Service (EaaS) is emerging as a crucial role in AI\napplications. Unfortunately, EaaS is vulnerable to model extraction attacks,\nhighlighting the urgent need for copyright protection. Although some\npreliminary works propose applying embedding watermarks to protect EaaS, recent\nresearch reveals that these watermarks can be easily removed. Hence, it is\ncrucial to inject robust watermarks resistant to watermark removal attacks.\nExisting watermarking methods typically inject a target embedding into\nembeddings through linear interpolation when the text contains triggers.\nHowever, this mechanism results in each watermarked embedding having the same\ncomponent, which makes the watermark easy to identify and eliminate. Motivated\nby this, in this paper, we propose a novel embedding-specific watermarking\n(ESpeW) mechanism to offer robust copyright protection for EaaS. Our approach\ninvolves injecting unique, yet readily identifiable watermarks into each\nembedding. Watermarks inserted by ESpeW are designed to maintain a significant\ndistance from one another and to avoid sharing common components, thus making\nit significantly more challenging to remove the watermarks. Extensive\nexperiments on four popular datasets demonstrate that ESpeW can even watermark\nsuccessfully against a highly aggressive removal strategy without sacrificing\nthe quality of embeddings. Code is available at\nhttps://github.com/liudan193/ESpeW.", "published": "2024-10-23 04:34:49", "link": "http://arxiv.org/abs/2410.17552v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MM-Eval: A Multilingual Meta-Evaluation Benchmark for LLM-as-a-Judge and\n  Reward Models", "abstract": "As Large Language Models (LLMs) are now capable of producing fluent and\ncoherent content in languages other than English, it is not imperative to\nprecisely evaluate these non-English outputs. However, when assessing the\noutputs from mutlilingual LLMs, prior works often employed LLM based evaluators\nthat excel at assessing English outputs, without a thorough examination of\nwhether these evaluators could effectively assess non-English text as well.\nMoreover, existing benchmarks to test evaluator LLMs (referred to as\n\"meta-evaluation benchmarks\") are mostly English-centric. To bridge this gap\nand examine whether evaluator LLMs can reliably assess the outputs of\nmultilingual LLMs, we introduce MM-Eval, a multilingual meta-evaluation\nbenchmark comprising five core subsets covering 18 languages and a Language\nConsistency subset spanning 122 languages. A core attribute of MM-Eval is that,\ninstead of merely translating existing English meta-evaluation benchmarks, it\nis designed with multilingual-specific challenges in mind. Additionally, unlike\nexisting meta-evaluation benchmarks that focus solely on ranking accuracy over\npairwise data, MM-Eval also evaluates the consistency and fairness of absolute\nscore values across a wide range of languages. Our results show that existing\nevaluator LLMs that excel in English contexts have considerable room for\nimprovement when assessing non-English outputs. Furthermore, we find that\nevaluators are unfair and inconsistent when evaluating lower-resourced\nlanguages. Finally, we validate MM-Eval by measuring its correlation with\nBest-of-N rankings, finding a significantly stronger correlation compared to\nother meta-evaluation benchmarks. We publicly release our benchmark and code.", "published": "2024-10-23 06:04:55", "link": "http://arxiv.org/abs/2410.17578v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-model Control: Improving Multiple Large Language Models in\n  One-time Training", "abstract": "The number of large language models (LLMs) with varying parameter scales and\nvocabularies is increasing. While they deliver powerful performance, they also\nface a set of common optimization needs to meet specific requirements or\nstandards, such as instruction following or avoiding the output of sensitive\ninformation from the real world. However, how to reuse the fine-tuning outcomes\nof one model to other models to reduce training costs remains a challenge. To\nbridge this gap, we introduce Cross-model Control (CMC), a method that improves\nmultiple LLMs in one-time training with a portable tiny language model.\nSpecifically, we have observed that the logit shift before and after\nfine-tuning is remarkably similar across different models. Based on this\ninsight, we incorporate a tiny language model with a minimal number of\nparameters. By training alongside a frozen template LLM, the tiny model gains\nthe capability to alter the logits output by the LLMs. To make this tiny\nlanguage model applicable to models with different vocabularies, we propose a\nnovel token mapping strategy named PM-MinED. We have conducted extensive\nexperiments on instruction tuning and unlearning tasks, demonstrating the\neffectiveness of CMC. Our code is available at https://github.com/wujwyi/CMC.", "published": "2024-10-23 06:52:09", "link": "http://arxiv.org/abs/2410.17599v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents", "abstract": "Large Language Models (LLMs) have shown promising potential in the medical\ndomain, assisting with tasks like clinical note generation and patient\ncommunication. However, current LLMs are limited to text-based communication,\nhindering their ability to interact with diverse forms of information in\nclinical environments. Despite clinical agents succeeding in diverse signal\ninteraction, they are oriented to a single clinical scenario and hence fail for\nbroader applications. To evaluate clinical agents holistically, we propose\nClinicalAgent Bench~(CAB), a comprehensive medical agent benchmark consisting\nof 18 tasks across five key realistic clinical dimensions. Building on this, we\nintroduce ReflecTool, a novel framework that excels at utilizing\ndomain-specific tools within two stages. The first optimization stage\nprogressively enlarges a long-term memory by saving successful solving\nprocesses and tool-wise experience of agents in a tiny pre-defined training\nset. In the following inference stage, ReflecTool can search for supportive\nsuccessful demonstrations from already built long-term memory to guide the tool\nselection strategy, and a verifier improves the tool usage according to the\ntool-wise experience with two verification methods--iterative refinement and\ncandidate selection. Extensive experiments on ClinicalAgent Benchmark\ndemonstrate that ReflecTool surpasses the pure LLMs with more than 10 points\nand the well-established agent-based methods with 3 points, highlighting its\nadaptability and effectiveness in solving complex clinical tasks.", "published": "2024-10-23 08:19:18", "link": "http://arxiv.org/abs/2410.17657v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantifying the Risks of Tool-assisted Rephrasing to Linguistic\n  Diversity", "abstract": "Writing assistants and large language models see widespread use in the\ncreation of text content. While their effectiveness for individual users has\nbeen evaluated in the literature, little is known about their proclivity to\nchange language or reduce its richness when adopted by a large user base. In\nthis paper, we take a first step towards quantifying this risk by measuring the\nsemantic and vocabulary change enacted by the use of rephrasing tools on a\nmulti-domain corpus of human-generated text.", "published": "2024-10-23 08:42:36", "link": "http://arxiv.org/abs/2410.17670v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a Similarity-adjusted Surprisal Theory", "abstract": "Surprisal theory posits that the cognitive effort required to comprehend a\nword is determined by its contextual predictability, quantified as surprisal.\nTraditionally, surprisal theory treats words as distinct entities, overlooking\nany potential similarity between them. Giulianelli et al. (2023) address this\nlimitation by introducing information value, a measure of predictability\ndesigned to account for similarities between communicative units. Our work\nleverages Ricotta and Szeidl's (2006) diversity index to extend surprisal into\na metric that we term similarity-adjusted surprisal, exposing a mathematical\nrelationship between surprisal and information value. Similarity-adjusted\nsurprisal aligns with information value when considering graded similarities\nand reduces to standard surprisal when words are treated as distinct.\nExperimental results with reading time data indicate that similarity-adjusted\nsurprisal adds predictive power beyond standard surprisal for certain datasets,\nsuggesting it serves as a complementary measure of comprehension effort.", "published": "2024-10-23 08:49:51", "link": "http://arxiv.org/abs/2410.17676v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dialectal and Low-Resource Machine Translation for Aromanian", "abstract": "This paper presents the process of building a neural machine translation\nsystem with support for English, Romanian, and Aromanian - an endangered\nEastern Romance language. The primary contribution of this research is twofold:\n(1) the creation of the most extensive Aromanian-Romanian parallel corpus to\ndate, consisting of 79,000 sentence pairs, and (2) the development and\ncomparative analysis of several machine translation models optimized for\nAromanian. To accomplish this, we introduce a suite of auxiliary tools,\nincluding a language-agnostic sentence embedding model for text mining and\nautomated evaluation, complemented by a diacritics conversion system for\ndifferent writing standards. This research brings contributions to both\ncomputational linguistics and language preservation efforts by establishing\nessential resources for a historically under-resourced language. All datasets,\ntrained models, and associated tools are public: https://huggingface.co/aronlp\nand https://arotranslate.com", "published": "2024-10-23 10:00:23", "link": "http://arxiv.org/abs/2410.17728v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MojoBench: Language Modeling and Benchmarks for Mojo", "abstract": "The recently introduced Mojo programming language (PL) by Modular, has\nreceived significant attention in the scientific community due to its claimed\nsignificant speed boost over Python. Despite advancements in code Large\nLanguage Models (LLMs) across various PLs, Mojo remains unexplored in this\ncontext. To address this gap, we introduce MojoBench, the first framework for\nMojo code generation. MojoBench includes HumanEval-Mojo, a benchmark dataset\ndesigned for evaluating code LLMs on Mojo, and Mojo-Coder, the first LLM\npretrained and finetuned for Mojo code generation, which supports instructions\nin 5 natural languages (NLs). Our results show that Mojo-Coder achieves a\n30-35% performance improvement over leading models like GPT-4o and\nClaude-3.5-Sonnet. Furthermore, we provide insights into LLM behavior with\nunderrepresented and unseen PLs, offering potential strategies for enhancing\nmodel adaptability. MojoBench contributes to our understanding of LLM\ncapabilities and limitations in emerging programming paradigms fostering more\nrobust code generation systems.", "published": "2024-10-23 10:11:40", "link": "http://arxiv.org/abs/2410.17736v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Latent Structures of Intertextuality in French Fiction", "abstract": "Intertextuality is a key concept in literary theory that challenges\ntraditional notions of text, signification or authorship. It views texts as\npart of a vast intertextual network that is constantly evolving and being\nreconfigured. This paper argues that the field of computational literary\nstudies is the ideal place to conduct a study of intertextuality since we have\nnow the ability to systematically compare texts with each others. Specifically,\nwe present a work on a corpus of more than 12.000 French fictions from the\n18th, 19th and early 20th century. We focus on evaluating the underlying roles\nof two literary notions, sub-genres and the literary canon in the framing of\ntextuality. The article attempts to operationalize intertextuality using\nstate-of-the-art contextual language models to encode novels and capture\nfeatures that go beyond simple lexical or thematic approaches. Previous\nresearch (Hughes, 2012) supports the existence of a literary \"style of a time\",\nand our findings further reinforce this concept. Our findings also suggest that\nboth subgenres and canonicity play a significant role in shaping textual\nsimilarities within French fiction. These discoveries point to the importance\nof considering genre and canon as dynamic forces that influence the evolution\nand intertextual connections of literary works within specific historical\ncontexts.", "published": "2024-10-23 10:50:40", "link": "http://arxiv.org/abs/2410.17759v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Understanding When Tree of Thoughts Succeeds: Larger Models Excel in\n  Generation, Not Discrimination", "abstract": "Tree of Thoughts (ToT) is a reasoning strategy for Large Language Models\n(LLMs) that employs a generator to suggest reasoning steps and a discriminator\nto decide which steps to implement. ToT demonstrates strong performance on\nreasoning tasks, often surpassing simple methods such as Input-Output (IO)\nprompting and Chain-of-Thought (CoT) reasoning. However, ToT does not\nconsistently outperform such simpler methods across all models, leaving large\nknowledge gaps on the conditions under which ToT is most beneficial. In this\npaper, we analyze the roles of the generator and discriminator separately to\nbetter understand the conditions when ToT is beneficial. We find that the\ngenerator plays a more critical role than the discriminator in driving the\nsuccess of ToT. Scaling the generator leads to notable improvements in ToT\nperformance, even when using a smaller model as the discriminator, whereas\nscaling the discriminator with a fixed generator yields only marginal gains.\nOur results show that models across different scales exhibit comparable\ndiscrimination capabilities, yet differ significantly in their generative\nperformance for ToT.", "published": "2024-10-23 12:26:10", "link": "http://arxiv.org/abs/2410.17820v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SpeakGer: A meta-data enriched speech corpus of German state and federal\n  parliaments", "abstract": "The application of natural language processing on political texts as well as\nspeeches has become increasingly relevant in political sciences due to the\nability to analyze large text corpora which cannot be read by a single person.\nBut such text corpora often lack critical meta information, detailing for\ninstance the party, age or constituency of the speaker, that can be used to\nprovide an analysis tailored to more fine-grained research questions. To enable\nresearchers to answer such questions with quantitative approaches such as\nnatural language processing, we provide the SpeakGer data set, consisting of\nGerman parliament debates from all 16 federal states of Germany as well as the\nGerman Bundestag from 1947-2023, split into a total of 10,806,105 speeches.\nThis data set includes rich meta data in form of information on both reactions\nfrom the audience towards the speech as well as information about the speaker's\nparty, their age, their constituency and their party's political alignment,\nwhich enables a deeper analysis. We further provide three exploratory analyses,\ndetailing topic shares of different parties throughout time, a descriptive\nanalysis of the development of the age of an average speaker as well as a\nsentiment analysis of speeches of different parties with regards to the\nCOVID-19 pandemic.", "published": "2024-10-23 14:00:48", "link": "http://arxiv.org/abs/2410.17886v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scaling Diffusion Language Models via Adaptation from Autoregressive\n  Models", "abstract": "Diffusion Language Models (DLMs) have emerged as a promising new paradigm for\ntext generative modeling, potentially addressing limitations of autoregressive\n(AR) models. However, current DLMs have been studied at a smaller scale\ncompared to their AR counterparts and lack fair comparison on language modeling\nbenchmarks. Additionally, training diffusion models from scratch at scale\nremains challenging. Given the prevalence of open-source AR language models, we\npropose adapting these models to build text diffusion models. We demonstrate\nconnections between AR and diffusion modeling objectives and introduce a simple\ncontinual pre-training approach for training diffusion models. Through\nsystematic evaluation on language modeling, reasoning, and commonsense\nbenchmarks, we show that we can convert AR models ranging from 127M to 7B\nparameters (GPT2 and LLaMA) into diffusion models DiffuGPT and DiffuLLaMA,\nusing less than 200B tokens for training. Our experimental results reveal that\nthese models outperform earlier DLMs and are competitive with their AR\ncounterparts. We release a suite of DLMs (127M-355M-7B) capable of generating\nfluent text, performing in-context learning, filling in the middle without\nprompt re-ordering, and following instructions\nhttps://github.com/HKUNLP/DiffuLLaMA.", "published": "2024-10-23 14:04:22", "link": "http://arxiv.org/abs/2410.17891v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Value Residual Learning", "abstract": "While Transformer models have achieved remarkable success in various domains,\nthe effectiveness of information propagation through deep networks remains a\ncritical challenge. Standard hidden state residuals often fail to adequately\npreserve initial token-level information in deeper layers. This paper\nintroduces ResFormer, a novel architecture that enhances information flow by\nincorporating value residual connections in addition to hidden state residuals.\nAnd a variant is the SVFormer, where all layers share the first layer's value\nembedding. Comprehensive empirical evidence demonstrates ResFormer achieves\nequivalent validation loss with 13.3\\% fewer model parameters and 15.4\\% less\ntraining data compared to Transformer, while maintaining similar memory usage\nand computational cost. Besides, SVFormer reduces KV cache size by nearly half\nwith only a small performance penalty and can be integrated with other\nKV-efficient methods, yielding further reductions in KV cache, with performance\ninfluenced by sequence length and cumulative learning rate.", "published": "2024-10-23 14:15:07", "link": "http://arxiv.org/abs/2410.17897v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zeitenwenden: Detecting changes in the German political discourse", "abstract": "From a monarchy to a democracy, to a dictatorship and back to a democracy --\nthe German political landscape has been constantly changing ever since the\nfirst German national state was formed in 1871. After World War II, the Federal\nRepublic of Germany was formed in 1949. Since then every plenary session of the\nGerman Bundestag was logged and even has been digitized over the course of the\nlast few years. We analyze these texts using a time series variant of the topic\nmodel LDA to investigate which events had a lasting effect on the political\ndiscourse and how the political topics changed over time. This allows us to\ndetect changes in word frequency (and thus key discussion points) in political\ndiscourse.", "published": "2024-10-23 15:28:53", "link": "http://arxiv.org/abs/2410.17960v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dependency Graph Parsing as Sequence Labeling", "abstract": "Various linearizations have been proposed to cast syntactic dependency\nparsing as sequence labeling. However, these approaches do not support more\ncomplex graph-based representations, such as semantic dependencies or enhanced\nuniversal dependencies, as they cannot handle reentrancy or cycles. By\nextending them, we define a range of unbounded and bounded linearizations that\ncan be used to cast graph parsing as a tagging task, enlarging the toolbox of\nproblems that can be solved under this paradigm. Experimental results on\nsemantic dependency and enhanced UD parsing show that with a good choice of\nencoding, sequence-labeling dependency graph parsers combine high efficiency\nwith accuracies close to the state of the art, in spite of their simplicity.", "published": "2024-10-23 15:37:02", "link": "http://arxiv.org/abs/2410.17972v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Together We Can: Multilingual Automatic Post-Editing for Low-Resource\n  Languages", "abstract": "This exploratory study investigates the potential of multilingual Automatic\nPost-Editing (APE) systems to enhance the quality of machine translations for\nlow-resource Indo-Aryan languages. Focusing on two closely related language\npairs, English-Marathi and English-Hindi, we exploit the linguistic\nsimilarities to develop a robust multilingual APE model. To facilitate\ncross-linguistic transfer, we generate synthetic Hindi-Marathi and\nMarathi-Hindi APE triplets. Additionally, we incorporate a Quality Estimation\n(QE)-APE multi-task learning framework. While the experimental results\nunderline the complementary nature of APE and QE, we also observe that QE-APE\nmultitask learning facilitates effective domain adaptation. Our experiments\ndemonstrate that the multilingual APE models outperform their corresponding\nEnglish-Hindi and English-Marathi single-pair models by $2.5$ and $2.39$ TER\npoints, respectively, with further notable improvements over the multilingual\nAPE model observed through multi-task learning ($+1.29$ and $+1.44$ TER\npoints), data augmentation ($+0.53$ and $+0.45$ TER points) and domain\nadaptation ($+0.35$ and $+0.45$ TER points). We release the synthetic data,\ncode, and models accrued during this study publicly at\nhttps://github.com/cfiltnlp/Multilingual-APE.", "published": "2024-10-23 15:37:08", "link": "http://arxiv.org/abs/2410.17973v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language\n  Models Fine-tuning", "abstract": "Low-rank adaptation (LoRA) and its mixture-of-experts (MOE) variants are\nhighly effective parameter-efficient fine-tuning (PEFT) methods. However, they\nintroduce significant latency in multi-tenant settings due to the LoRA modules\nand MOE routers added to multiple linear modules in the Transformer layer. To\naddress this issue, we propose Mixture of Low-Rank Adaptation (MiLoRA), a novel\nand efficient LoRA variant. MiLoRA differs from previous MOE-style LoRA methods\nby considering each LoRA module as an expert and employing a prompt-aware\nrouting mechanism. This mechanism calculates expert routing results once before\ngenerating the first new token and reuses these results for subsequent tokens,\nreducing latency. Extensive experiments and analysis on commonsense reasoning\ntasks, math reasoning tasks, and widely used LLM evaluation benchmarks\ndemonstrate that MiLoRA consistently outperforms strong PEFT baselines with\ncomparable tunable parameter budgets. Additionally, MiLoRA significantly\nreduces latency in multi-tenant settings compared to previous LoRA-based\nmethods.", "published": "2024-10-23 17:04:40", "link": "http://arxiv.org/abs/2410.18035v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for\n  Long-Context Question Answering", "abstract": "Long-Context Question Answering (LCQA), a challenging task, aims to reason\nover long-context documents to yield accurate answers to questions. Existing\nlong-context Large Language Models (LLMs) for LCQA often struggle with the\n\"lost in the middle\" issue. Retrieval-Augmented Generation (RAG) mitigates this\nissue by providing external factual evidence. However, its chunking strategy\ndisrupts the global long-context information, and its low-quality retrieval in\nlong contexts hinders LLMs from identifying effective factual details due to\nsubstantial noise. To this end, we propose LongRAG, a general,\ndual-perspective, and robust LLM-based RAG system paradigm for LCQA to enhance\nRAG's understanding of complex long-context knowledge (i.e., global information\nand factual details). We design LongRAG as a plug-and-play paradigm,\nfacilitating adaptation to various domains and LLMs. Extensive experiments on\nthree multi-hop datasets demonstrate that LongRAG significantly outperforms\nlong-context LLMs (up by 6.94%), advanced RAG (up by 6.16%), and Vanilla RAG\n(up by 17.25%). Furthermore, we conduct quantitative ablation studies and\nmulti-dimensional analyses, highlighting the effectiveness of the system's\ncomponents and fine-tuning strategies. Data and code are available at\nhttps://github.com/QingFei1/LongRAG.", "published": "2024-10-23 17:24:58", "link": "http://arxiv.org/abs/2410.18050v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gazelle: An Instruction Dataset for Arabic Writing Assistance", "abstract": "Writing has long been considered a hallmark of human intelligence and remains\na pinnacle task for artificial intelligence (AI) due to the intricate cognitive\nprocesses involved. Recently, rapid advancements in generative AI, particularly\nthrough the development of Large Language Models (LLMs), have significantly\ntransformed the landscape of writing assistance. However, underrepresented\nlanguages like Arabic encounter significant challenges in the development of\nadvanced AI writing tools, largely due to the limited availability of data.\nThis scarcity constrains the training of effective models, impeding the\ncreation of sophisticated writing assistance technologies. To address these\nissues, we present Gazelle, a comprehensive dataset for Arabic writing\nassistance. In addition, we offer an evaluation framework designed to enhance\nArabic writing assistance tools. Our human evaluation of leading LLMs,\nincluding GPT-4, GPT-4o, Cohere Command R+, and Gemini 1.5 Pro, highlights\ntheir respective strengths and limitations in addressing the challenges of\nArabic writing. Our findings underscore the need for continuous model training\nand dataset enrichment to manage the complexities of Arabic language\nprocessing, paving the way for more effective AI-powered Arabic writing tools.", "published": "2024-10-23 17:51:58", "link": "http://arxiv.org/abs/2410.18163v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CorrectionLM: Self-Corrections with SLM for Dialogue State Tracking", "abstract": "Large language models (LLMs) have demonstrated self-improvement capabilities\nvia feedback and refinement, but current small language models (SLMs) have had\nlimited success in this area. Existing correction approaches often rely on\ndistilling knowledge from LLMs, which imposes significant computation demands.\nIn this work, we introduce CORRECTIONLM, a novel correction framework that\nenables SLMs to self-correct using in-context exemplars without LLM\ninvolvement. Applied to two dialogue state tracking (DST) tasks in low-resource\nsettings, CORRECTIONLM achieves results similar to a state-of-the-art LLM at a\nsmall fraction of the computation costs.", "published": "2024-10-23 18:27:16", "link": "http://arxiv.org/abs/2410.18209v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Generalizations across filler-gap dependencies in neural language models", "abstract": "Humans develop their grammars by making structural generalizations from\nfinite input. We ask how filler-gap dependencies, which share a structural\ngeneralization despite diverse surface forms, might arise from the input. We\nexplicitly control the input to a neural language model (NLM) to uncover\nwhether the model posits a shared representation for filler-gap dependencies.\nWe show that while NLMs do have success differentiating grammatical from\nungrammatical filler-gap dependencies, they rely on superficial properties of\nthe input, rather than on a shared generalization. Our work highlights the need\nfor specific linguistic inductive biases to model language acquisition.", "published": "2024-10-23 19:04:42", "link": "http://arxiv.org/abs/2410.18225v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilingual Hallucination Gaps in Large Language Models", "abstract": "Large language models (LLMs) are increasingly used as alternatives to\ntraditional search engines given their capacity to generate text that resembles\nhuman language. However, this shift is concerning, as LLMs often generate\nhallucinations, misleading or false information that appears highly credible.\nIn this study, we explore the phenomenon of hallucinations across multiple\nlanguages in freeform text generation, focusing on what we call multilingual\nhallucination gaps. These gaps reflect differences in the frequency of\nhallucinated answers depending on the prompt and language used. To quantify\nsuch hallucinations, we used the FactScore metric and extended its framework to\na multilingual setting. We conducted experiments using LLMs from the LLaMA,\nQwen, and Aya families, generating biographies in 19 languages and comparing\nthe results to Wikipedia pages. Our results reveal variations in hallucination\nrates, especially between high and low resource languages, raising important\nquestions about LLM multilingual performance and the challenges in evaluating\nhallucinations in multilingual freeform text generation.", "published": "2024-10-23 20:41:51", "link": "http://arxiv.org/abs/2410.18270v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Measuring individual semantic networks: A simulation study", "abstract": "Accurately capturing individual differences in semantic networks is\nfundamental to advancing our mechanistic understanding of semantic memory. Past\nempirical attempts to construct individual-level semantic networks from\nbehavioral paradigms may be limited by data constraints. To assess these\nlimitations and propose improved designs for the measurement of individual\nsemantic networks, we conducted a recovery simulation investigating the\npsychometric properties underlying estimates of individual semantic networks\nobtained from two different behavioral paradigms: free associations and\nrelatedness judgment tasks. Our results show that successful inference of\nsemantic networks is achievable, but they also highlight critical challenges.\nEstimates of absolute network characteristics are severely biased, such that\ncomparisons between behavioral paradigms and different design configurations\nare often not meaningful. However, comparisons within a given paradigm and\ndesign configuration can be accurate and generalizable when based on designs\nwith moderate numbers of cues, moderate numbers of responses, and cue sets\nincluding diverse words. Ultimately, our results provide insights that help\nevaluate past findings on the structure of semantic networks and design new\nstudies capable of more reliably revealing individual differences in semantic\nnetworks.", "published": "2024-10-23 23:40:44", "link": "http://arxiv.org/abs/2410.18326v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "VoiceTextBlender: Augmenting Large Language Models with Speech\n  Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning", "abstract": "Recent studies have augmented large language models (LLMs) with speech\ncapabilities, leading to the development of speech language models (SpeechLMs).\nEarlier SpeechLMs focused on single-turn speech-based question answering (QA),\nwhere user input comprised a speech context and a text question. More recent\nstudies have extended this to multi-turn conversations, though they often\nrequire complex, multi-stage supervised fine-tuning (SFT) with diverse data.\nAnother critical challenge with SpeechLMs is catastrophic forgetting, where\nmodels optimized for speech tasks suffer significant degradation in text-only\nperformance. To mitigate these issues, we propose a novel single-stage joint\nspeech-text SFT approach on the low-rank adaptation (LoRA) of the LLM backbone.\nOur joint SFT combines text-only SFT data with three types of speech-related\ndata: speech recognition and translation, speech-based QA, and mixed-modal SFT.\nCompared to previous SpeechLMs with 7B or 13B parameters, our 3B model\ndemonstrates superior performance across various speech benchmarks while\npreserving the original capabilities on text-only tasks. Furthermore, our model\nshows emergent abilities of effectively handling previously unseen prompts and\ntasks, including multi-turn, mixed-modal inputs.", "published": "2024-10-23 00:36:06", "link": "http://arxiv.org/abs/2410.17485v2", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile\n  Device Control", "abstract": "Autonomous agents powered by large language models (LLMs) show promising\npotential in assistive tasks across various domains, including mobile device\ncontrol. As these agents interact directly with personal information and device\nsettings, ensuring their safe and reliable behavior is crucial to prevent\nundesirable outcomes. However, no benchmark exists for standardized evaluation\nof the safety of mobile device-control agents. In this work, we introduce\nMobileSafetyBench, a benchmark designed to evaluate the safety of\ndevice-control agents within a realistic mobile environment based on Android\nemulators. We develop a diverse set of tasks involving interactions with\nvarious mobile applications, including messaging and banking applications,\nchallenging agents with managing risks encompassing misuse and negative side\neffects. These tasks include tests to evaluate the safety of agents in daily\nscenarios as well as their robustness against indirect prompt injection\nattacks. Our experiments demonstrate that baseline agents, based on\nstate-of-the-art LLMs, often fail to effectively prevent harm while performing\nthe tasks. To mitigate these safety concerns, we propose a prompting method\nthat encourages agents to prioritize safety considerations. While this method\nshows promise in promoting safer behaviors, there is still considerable room\nfor improvement to fully earn user trust. This highlights the urgent need for\ncontinued research to develop more robust safety mechanisms in mobile\nenvironments. We open-source our benchmark at:\nhttps://mobilesafetybench.github.io/.", "published": "2024-10-23 02:51:43", "link": "http://arxiv.org/abs/2410.17520v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Responsible Multilingual Large Language Models: A Survey of Development,\n  Applications, and Societal Impact", "abstract": "Multilingual Large Language Models (MLLMs) represent a pivotal advancement in\ndemocratizing artificial intelligence across linguistic boundaries. While\ntheoretical foundations are well-established, practical implementation\nguidelines remain scattered. This work bridges this gap by providing a\ncomprehensive end-to-end framework for developing and deploying MLLMs in\nproduction environments. We make three distinctive contributions: First, we\npresent an actionable pipeline from data pre-processing through deployment,\nintegrating insights from academic research and industrial applications.\nSecond, using Llama2 as a case study, we provide detailed optimization\nstrategies for enhancing multilingual capabilities, including curriculum\nlearning approaches for balancing high-resource and low-resource languages,\ntokenization strategies, and effective sampling methods. Third, we offer an\ninterdisciplinary analysis that considers technical, linguistic, and cultural\nperspectives in MLLM development. Our findings reveal critical challenges in\nsupporting linguistic diversity, with 88.38% of world languages categorized as\nlow-resource, affecting over a billion speakers. We examine practical solutions\nthrough real-world applications in customer service, search engines, and\nmachine translation. By synthesizing theoretical frameworks with\nproduction-ready implementation strategies, this survey provides essential\nguidance for practitioners and researchers working to develop more inclusive\nand effective multilingual AI systems.", "published": "2024-10-23 03:19:15", "link": "http://arxiv.org/abs/2410.17532v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Advancing Interpretability in Text Classification through Prototype\n  Learning", "abstract": "Deep neural networks have achieved remarkable performance in various\ntext-based tasks but often lack interpretability, making them less suitable for\napplications where transparency is critical. To address this, we propose\nProtoLens, a novel prototype-based model that provides fine-grained,\nsub-sentence level interpretability for text classification. ProtoLens uses a\nPrototype-aware Span Extraction module to identify relevant text spans\nassociated with learned prototypes and a Prototype Alignment mechanism to\nensure prototypes are semantically meaningful throughout training. By aligning\nthe prototype embeddings with human-understandable examples, ProtoLens provides\ninterpretable predictions while maintaining competitive accuracy. Extensive\nexperiments demonstrate that ProtoLens outperforms both prototype-based and\nnon-interpretable baselines on multiple text classification benchmarks. Code\nand data are available at\n\\url{https://anonymous.4open.science/r/ProtoLens-CE0B/}.", "published": "2024-10-23 03:53:46", "link": "http://arxiv.org/abs/2410.17546v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LMLPA: Language Model Linguistic Personality Assessment", "abstract": "Large Language Models (LLMs) are increasingly used in everyday life and\nresearch. One of the most common use cases is conversational interactions,\nenabled by the language generation capabilities of LLMs. Just as between two\nhumans, a conversation between an LLM-powered entity and a human depends on the\npersonality of the conversants. However, measuring the personality of a given\nLLM is currently a challenge. This paper introduces the Language Model\nLinguistic Personality Assessment (LMLPA), a system designed to evaluate the\nlinguistic personalities of LLMs. Our system helps to understand LLMs' language\ngeneration capabilities by quantitatively assessing the distinct personality\ntraits reflected in their linguistic outputs. Unlike traditional human-centric\npsychometrics, the LMLPA adapts a personality assessment questionnaire,\nspecifically the Big Five Inventory, to align with the operational capabilities\nof LLMs, and also incorporates the findings from previous language-based\npersonality measurement literature. To mitigate sensitivity to the order of\noptions, our questionnaire is designed to be open-ended, resulting in textual\nanswers. Thus, the AI rater is needed to transform ambiguous personality\ninformation from text responses into clear numerical indicators of personality\ntraits. Utilising Principal Component Analysis and reliability validations, our\nfindings demonstrate that LLMs possess distinct personality traits that can be\neffectively quantified by the LMLPA. This research contributes to\nHuman-Computer Interaction and Human-Centered AI, providing a robust framework\nfor future studies to refine AI personality assessments and expand their\napplications in multiple areas, including education and manufacturing.", "published": "2024-10-23 07:48:51", "link": "http://arxiv.org/abs/2410.17632v2", "categories": ["cs.CL", "cs.AI", "I.2"], "primary_category": "cs.CL"}
{"title": "Markov Chain of Thought for Efficient Mathematical Reasoning", "abstract": "Chain of Thought (CoT) of multi-step benefits from the logical structure of\nthe reasoning steps and task-specific actions, significantly enhancing the\nmathematical reasoning capabilities of large language models. As the prevalence\nof long CoT, the number of reasoning steps exceeds manageable token limits and\nleads to higher computational demands. Inspired by the fundamental logic of\nhuman cognition, \"derive, then reduce\", we conceptualize the standard\nmulti-step CoT as a novel Markov Chain of Thought (MCoT). In this study, we\nconsider the mathematical reasoning task, defining each reasoning step as text\naccompanied by a Python code snippet. To facilitate a longer reasoning path,\nself-correction is enabled through interactions with the code interpreter. Our\nMCoT aims to compress previous reasoning steps into a simplified question,\nenabling efficient next-step inference without relying on a lengthy KV cache.\nIn our experiments, we curate the $\\texttt{MCoTInstruct}$ dataset, and the\nempirical results indicate that MCoT not only significantly enhances efficiency\nbut also maintains comparable accuracy. While much remains to be explored, this\nwork paves the way for exploring the long CoT reasoning abilities of LLMs. The\ncode is available at https://github.com/james-yw/Markov-Chain-of-Thought", "published": "2024-10-23 07:53:29", "link": "http://arxiv.org/abs/2410.17635v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "An Adaptive Framework for Generating Systematic Explanatory Answer in\n  Online Q&A Platforms", "abstract": "Question Answering (QA) systems face challenges in handling complex questions\nthat require multi-domain knowledge synthesis. The naive RAG models, although\neffective in information retrieval, struggle with complex questions that\nrequire comprehensive and in-depth answers. The pioneering task is defined as\nexplanatory answer generation, which entails handling identified challenges\nsuch as the requirement for comprehensive information and logical coherence\nwithin the generated context. To address these issues, we refer to systematic\nthinking theory and propose SynthRAG, an innovative framework designed to\nenhance QA performance. SynthRAG improves on conventional models by employing\nadaptive outlines for dynamic content structuring, generating systematic\ninformation to ensure detailed coverage, and producing customized answers\ntailored to specific user inquiries. This structured approach guarantees\nlogical coherence and thorough integration of information, yielding responses\nthat are both insightful and methodically organized. Empirical evaluations\nunderscore SynthRAG's effectiveness, demonstrating its superiority in handling\ncomplex questions, overcoming the limitations of naive RAG models, and\nsignificantly improving answer quality and depth. Furthermore, an online\ndeployment on the Zhihu platform revealed that SynthRAG's answers achieved\nnotable user engagement, with each response averaging 5.73 upvotes and\nsurpassing the performance of 79.8% of human contributors, highlighting the\npractical relevance and impact of the proposed framework. Our code is available\nat https://github.com/czy1999/SynthRAG .", "published": "2024-10-23 09:14:57", "link": "http://arxiv.org/abs/2410.17694v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "CogSteer: Cognition-Inspired Selective Layer Intervention for\n  Efficiently Steering Large Language Models", "abstract": "Large Language Models (LLMs) achieve remarkable performance through\npretraining on extensive data. This enables efficient adaptation to diverse\ndownstream tasks. However, the lack of interpretability in their underlying\nmechanisms limits the ability to effectively steer LLMs for specific\napplications. In this work, we investigate the intrinsic mechanisms of LLMs\nfrom a cognitive perspective using eye movement measures. Specifically, we\nanalyze the layer-wise correlation between human cognitive indicators and LLM\nrepresentations. Building on these insights, we propose a heuristic approach\nfor selecting the optimal steering layer to modulate LLM semantics. To this\nend, we introduce an efficient selective layer intervention based on prominent\nparameter-efficient fine-tuning methods, which conventionally adjust either all\nlayers or only the final layer. Additionally, we present an implicit layer\ncontrastive intervention during inference to steer LLMs away from toxic\noutputs. Extensive experiments on natural language understanding, reasoning,\nand generation tasks, conducted on GPT-2, LLaMa2-7B, and Mixtral-7B,\ndemonstrate the effectiveness and efficiency of our approach. As a\nmodel-agnostic framework, it enhances the interpretability of LLMs while\nimproving efficiency for safe deployment.", "published": "2024-10-23 09:40:15", "link": "http://arxiv.org/abs/2410.17714v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Local Contrastive Editing of Gender Stereotypes", "abstract": "Stereotypical bias encoded in language models (LMs) poses a threat to safe\nlanguage technology, yet our understanding of how bias manifests in the\nparameters of LMs remains incomplete. We introduce local contrastive editing\nthat enables the localization and editing of a subset of weights in a target\nmodel in relation to a reference model. We deploy this approach to identify and\nmodify subsets of weights that are associated with gender stereotypes in LMs.\nThrough a series of experiments, we demonstrate that local contrastive editing\ncan precisely localize and control a small subset (< 0.5%) of weights that\nencode gender bias. Our work (i) advances our understanding of how\nstereotypical biases can manifest in the parameter space of LMs and (ii) opens\nup new avenues for developing parameter-efficient strategies for controlling\nmodel properties in a contrastive manner.", "published": "2024-10-23 10:12:35", "link": "http://arxiv.org/abs/2410.17739v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Leveraging the Domain Adaptation of Retrieval Augmented Generation\n  Models for Question Answering and Reducing Hallucination", "abstract": "While ongoing advancements in Large Language Models have demonstrated\nremarkable success across various NLP tasks, Retrieval Augmented Generation\nModel stands out to be highly effective on downstream applications like\nQuestion Answering. Recently, RAG-end2end model further optimized the\narchitecture and achieved notable performance improvements on domain\nadaptation. However, the effectiveness of these RAG-based architectures remains\nrelatively unexplored when fine-tuned on specialized domains such as customer\nservice for building a reliable conversational AI system. Furthermore, a\ncritical challenge persists in reducing the occurrence of hallucinations while\nmaintaining high domain-specific accuracy. In this paper, we investigated the\nperformance of diverse RAG and RAG-like architectures through domain adaptation\nand evaluated their ability to generate accurate and relevant response grounded\nin the contextual knowledge base. To facilitate the evaluation of the models,\nwe constructed a novel dataset HotelConvQA, sourced from wide range of\nhotel-related conversations and fine-tuned all the models on our domain\nspecific dataset. We also addressed a critical research gap on determining the\nimpact of domain adaptation on reducing hallucinations across different RAG\narchitectures, an aspect that was not properly measured in prior work. Our\nevaluation shows positive results in all metrics by employing domain\nadaptation, demonstrating strong performance on QA tasks and providing insights\ninto their efficacy in reducing hallucinations. Our findings clearly indicate\nthat domain adaptation not only enhances the models' performance on QA tasks\nbut also significantly reduces hallucination across all evaluated RAG\narchitectures.", "published": "2024-10-23 11:32:46", "link": "http://arxiv.org/abs/2410.17783v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Understanding Layer Significance in LLM Alignment", "abstract": "Aligning large language models (LLMs) through supervised fine-tuning is\nessential for tailoring them to specific applications. Recent studies suggest\nthat alignment primarily adjusts a model's presentation style rather than its\nfoundational knowledge, indicating that only certain components of the model\nare significantly impacted. To uncover how alignment affects model behavior at\na granular level, we propose identifying which layers within LLMs are most\ncritical to the alignment process. Our approach, named ILA, involves learning a\nbinary mask for the parameter changes in each layer during alignment, as an\nindicator of layer significance. Experimental results reveal that, despite\nsubstantial differences in alignment datasets, the important layers of a model\nidentified by ILA exhibit nearly 90\\% overlap, highlighting fundamental\npatterns in LLM alignment. The results also indicate that freezing\nnon-essential layers improves overall model performance, while selectively\ntuning the most critical layers significantly enhances fine-tuning efficiency\nwith minimal performance loss. Finally, we discuss how these findings extend\nfrom LLM alignment to reasoning.", "published": "2024-10-23 13:47:05", "link": "http://arxiv.org/abs/2410.17875v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and\n  Low-frequency Character Bigrams", "abstract": "Recent advancements in Text-to-Speech (TTS) technology have led to\nnatural-sounding speech for English, primarily due to the availability of\nlarge-scale, high-quality web data. However, many other languages lack access\nto such resources, relying instead on limited studio-quality data. This\nscarcity results in synthesized speech that often suffers from intelligibility\nissues, particularly with low-frequency character bigrams. In this paper, we\npropose three solutions to address this challenge. First, we leverage\nhigh-quality data from linguistically or geographically related languages to\nimprove TTS for the target language. Second, we utilize low-quality Automatic\nSpeech Recognition (ASR) data recorded in non-studio environments, which is\nrefined using denoising and speech enhancement models. Third, we apply\nknowledge distillation from large-scale models using synthetic data to generate\nmore robust outputs. Our experiments with Hindi demonstrate significant\nreductions in intelligibility issues, as validated by human evaluators. We\npropose this methodology as a viable alternative for languages with limited\naccess to high-quality data, enabling them to collectively benefit from shared\nresources.", "published": "2024-10-23 14:18:25", "link": "http://arxiv.org/abs/2410.17901v1", "categories": ["cs.CL", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ExpertFlow: Optimized Expert Activation and Token Allocation for\n  Efficient Mixture-of-Experts Inference", "abstract": "Sparse Mixture of Experts (MoE) models, while outperforming dense Large\nLanguage Models (LLMs) in terms of performance, face significant deployment\nchallenges during inference due to their high memory demands. Existing\noffloading techniques, which involve swapping activated and idle experts\nbetween the GPU and CPU, often suffer from rigid expert caching mechanisms.\nThese mechanisms fail to adapt to dynamic routing, leading to inefficient cache\nutilization, or incur prohibitive costs for prediction training. To tackle\nthese inference-specific challenges, we introduce ExpertFlow, a comprehensive\nsystem specifically designed to enhance inference efficiency by accommodating\nflexible routing and enabling efficient expert scheduling between CPU and GPU.\nThis reduces overhead and boosts system performance. Central to our approach is\na predictive routing path-based offloading mechanism that utilizes a\nlightweight predictor to accurately forecast routing paths before computation\nbegins. This proactive strategy allows for real-time error correction in expert\ncaching, significantly increasing cache hit ratios and reducing the frequency\nof expert transfers, thereby minimizing I/O overhead. Additionally, we\nimplement a dynamic token scheduling strategy that optimizes MoE inference by\nrearranging input tokens across different batches. This method not only reduces\nthe number of activated experts per batch but also improves computational\nefficiency. Our extensive experiments demonstrate that ExpertFlow achieves up\nto 93.72\\% GPU memory savings and enhances inference speed by 2 to 10 times\ncompared to baseline methods, highlighting its effectiveness and utility as a\nrobust solution for resource-constrained inference scenarios.", "published": "2024-10-23 15:24:54", "link": "http://arxiv.org/abs/2410.17954v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Cross-lingual Transfer of Reward Models in Multilingual Alignment", "abstract": "Reinforcement learning with human feedback (RLHF) is shown to largely benefit\nfrom precise reward models (RMs). However, recent studies in reward modeling\nschemes are skewed towards English, limiting the applicability of RLHF in\nmultilingual alignments. In this work, we investigate the cross-lingual\ntransfer of RMs trained in diverse languages, primarily from English. Our\nexperimental results demonstrate the strong cross-lingual transfer of English\nRMs, exceeding target language RMs by 3~4% average increase in Multilingual\nRewardBench. Furthermore, we analyze the cross-lingual transfer of RMs through\nthe representation shifts. Finally, we perform multilingual alignment to\nexemplify how cross-lingual transfer in RM propagates to enhanced multilingual\ninstruction-following capability, along with extensive analyses on\noff-the-shelf RMs. We release the code, model, and data.", "published": "2024-10-23 17:00:13", "link": "http://arxiv.org/abs/2410.18027v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for\n  Russian Scientific Keyphrases", "abstract": "Keyphrase selection is a challenging task in natural language processing that\nhas a wide range of applications. Adapting existing supervised and unsupervised\nsolutions for the Russian language faces several limitations due to the rich\nmorphology of Russian and the limited number of training datasets available.\nRecent studies conducted on English texts show that large language models\n(LLMs) successfully address the task of generating keyphrases. LLMs allow\nachieving impressive results without task-specific fine-tuning, using text\nprompts instead. In this work, we access the performance of prompt-based\nmethods for generating keyphrases for Russian scientific abstracts. First, we\ncompare the performance of zero-shot and few-shot prompt-based methods,\nfine-tuned models, and unsupervised methods. Then we assess strategies for\nselecting keyphrase examples in a few-shot setting. We present the outcomes of\nhuman evaluation of the generated keyphrases and analyze the strengths and\nweaknesses of the models through expert assessment. Our results suggest that\nprompt-based methods can outperform common baselines even using simple text\nprompts.", "published": "2024-10-23 17:07:32", "link": "http://arxiv.org/abs/2410.18040v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7; I.7.m; H.3.3"], "primary_category": "cs.CL"}
{"title": "CLEAR: Character Unlearning in Textual and Visual Modalities", "abstract": "Machine Unlearning (MU) is critical for removing private or hazardous\ninformation from deep learning models. While MU has advanced significantly in\nunimodal (text or vision) settings, multimodal unlearning (MMU) remains\nunderexplored due to the lack of open benchmarks for evaluating cross-modal\ndata removal. To address this gap, we introduce CLEAR, the first open-source\nbenchmark designed specifically for MMU. CLEAR contains 200 fictitious\nindividuals and 3,700 images linked with corresponding question-answer pairs,\nenabling a thorough evaluation across modalities. We conduct a comprehensive\nanalysis of 11 MU methods (e.g., SCRUB, gradient ascent, DPO) across four\nevaluation sets, demonstrating that jointly unlearning both modalities\noutperforms single-modality approaches. The dataset is available at\nhttps://huggingface.co/datasets/therem/CLEAR", "published": "2024-10-23 17:30:50", "link": "http://arxiv.org/abs/2410.18057v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Future Token Prediction -- Causal Language Modelling with Per-Token\n  Semantic State Vector for Multi-Token Prediction", "abstract": "Causal decoder-only transformer models used for generative language\nmodelling, such as Generative Pre-trained Transformers (GPT), are trained to\npredict the next token in a sequence based only on its previous tokens. Despite\nthis simple training objective, they have proved to be powerful AI tools.\nHowever, only predicting the next token results in top layer embedding vectors\nthat are highly token-focused. There may be benefits in generating embedding\nvectors at each token position that better capture the overall meaning of\nlonger sequences of future text. Recent studies matching brain scans with deep\nlanguage models suggest that humans also predict upcoming words when listening\nor reading but consider multiple future tokens rather than just one.\n  This research investigates a new pretraining method called Future Token\nPrediction (FTP). In FTP, a large transformer encoder generates top layer\nembedding vectors for each token position, which, instead of being passed to a\nlanguage head, are linearly and expansively projected to a pseudo-sequence,\nwhich is cross attended to by a small transformer decoder to predict the next N\ntokens forward from that position in the sequence.\n  The top layer embedding vectors from FTP models exhibit distinct properties\ncompared to those from standard GPT models, varying smoothly along a text\nsequence as measured by cosine similarity between adjacent tokens. Text\ngenerated by FTP models show improved topic coherence compared to standard\nGPT-like models trained with the same prediction perplexity for the next single\ntoken. The vectors are shown to better represent the topic of text based on the\nresults of text classification examples. On a toy, but complex, coding problem,\nFTP networks produce significantly better results than GPT networks.", "published": "2024-10-23 14:50:15", "link": "http://arxiv.org/abs/2410.18160v1", "categories": ["cs.CL", "cs.LG", "I.2.6; I.2.7"], "primary_category": "cs.CL"}
{"title": "Advancing NLP Security by Leveraging LLMs as Adversarial Engines", "abstract": "This position paper proposes a novel approach to advancing NLP security by\nleveraging Large Language Models (LLMs) as engines for generating diverse\nadversarial attacks. Building upon recent work demonstrating LLMs'\neffectiveness in creating word-level adversarial examples, we argue for\nexpanding this concept to encompass a broader range of attack types, including\nadversarial patches, universal perturbations, and targeted attacks. We posit\nthat LLMs' sophisticated language understanding and generation capabilities can\nproduce more effective, semantically coherent, and human-like adversarial\nexamples across various domains and classifier architectures. This paradigm\nshift in adversarial NLP has far-reaching implications, potentially enhancing\nmodel robustness, uncovering new vulnerabilities, and driving innovation in\ndefense mechanisms. By exploring this new frontier, we aim to contribute to the\ndevelopment of more secure, reliable, and trustworthy NLP systems for critical\napplications.", "published": "2024-10-23 18:32:03", "link": "http://arxiv.org/abs/2410.18215v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "LEGO: Language Model Building Blocks", "abstract": "Large language models (LLMs) are essential in natural language processing\n(NLP) but are costly in data collection, pre-training, fine-tuning, and\ninference. Task-specific small language models (SLMs) offer a cheaper\nalternative but lack robustness and generalization. This paper proposes LEGO, a\nnovel technique to extract SLMs from an LLM and recombine them. Using\nstate-of-the-art LLM pruning strategies, we can create task- and user-specific\nSLM building blocks that are efficient for fine-tuning and inference while also\npreserving user data privacy. LEGO utilizes Federated Learning and a novel\naggregation scheme for the LLM reconstruction, maintaining robustness without\nhigh costs and preserving user data privacy. We experimentally demonstrate the\nversatility of LEGO, showing its ability to enable model heterogeneity and\nmitigate the effects of data heterogeneity while maintaining LLM robustness.", "published": "2024-10-23 21:31:42", "link": "http://arxiv.org/abs/2410.18287v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Kenyan Sign Language (KSL) Dataset: Using Artificial Intelligence (AI)\n  in Bridging Communication Barrier among the Deaf Learners", "abstract": "Kenyan Sign Language (KSL) is the primary language used by the deaf community\nin Kenya. It is the medium of instruction from Pre-primary 1 to university\namong deaf learners, facilitating their education and academic achievement.\nKenyan Sign Language is used for social interaction, expression of needs,\nmaking requests and general communication among persons who are deaf in Kenya.\nHowever, there exists a language barrier between the deaf and the hearing\npeople in Kenya. Thus, the innovation on AI4KSL is key in eliminating the\ncommunication barrier. Artificial intelligence for KSL is a two-year research\nproject (2023-2024) that aims to create a digital open-access AI of spontaneous\nand elicited data from a representative sample of the Kenyan deaf community.\nThe purpose of this study is to develop AI assistive technology dataset that\ntranslates English to KSL as a way of fostering inclusion and bridging language\nbarriers among deaf learners in Kenya. Specific objectives are: Build KSL\ndataset for spoken English and video recorded Kenyan Sign Language and to build\ntranscriptions of the KSL signs to a phonetic-level interface of the sign\nlanguage. In this paper, the methodology for building the dataset is described.\nData was collected from 48 teachers and tutors of the deaf learners and 400\nlearners who are Deaf. Participants engaged mainly in sign language elicitation\ntasks through reading and singing. Findings of the dataset consisted of about\n14,000 English sentences with corresponding KSL Gloss derived from a pool of\nabout 4000 words and about 20,000 signed KSL videos that are either signed\nwords or sentences. The second level of data outcomes consisted of 10,000 split\nand segmented KSL videos. The third outcome of the dataset consists of 4,000\ntranscribed words into five articulatory parameters according to HamNoSys\nsystem.", "published": "2024-10-23 22:01:31", "link": "http://arxiv.org/abs/2410.18295v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "CoreInfer: Accelerating Large Language Model Inference with\n  Semantics-Inspired Adaptive Sparse Activation", "abstract": "Large language models (LLMs) with billions of parameters have sparked a new\nwave of exciting AI applications. However, their high computational costs and\nmemory demands during inference pose significant challenges. Adaptive sparse\nactivation inference, which activates only a small number of neurons for each\ntoken, offers a novel way to accelerate model inference without degrading\nperformance, showing great potential for resource-constrained hardware devices.\nNevertheless, existing methods predict activated neurons based on individual\ntokens with additional MLP, which involve frequent changes in activation maps\nand resource calls, limiting the acceleration benefits of sparse activation. In\nthis paper, we introduce CoreInfer, an MLP-free adaptive sparse activation\ninference method based on sentence-level prediction. Specifically, we propose\nthe concept of sentence-wise core neurons, which refers to the subset of\nneurons most critical for a given sentence, and empirically demonstrate its\neffectiveness. To determine the core neurons, we explore the correlation\nbetween core neurons and the sentence's semantics. Remarkably, we discovered\nthat core neurons exhibit both stability and similarity in relation to the\nsentence's semantics -- an insight overlooked by previous studies. Building on\nthis finding, we further design two semantic-based methods for predicting core\nneurons to fit different input scenarios. In CoreInfer, the core neurons are\ndetermined during the pre-filling stage and fixed during the encoding stage,\nenabling zero-cost sparse inference. We evaluated the model generalization and\ntask generalization of CoreInfer across various models and tasks. Notably, on\nan NVIDIA TITAN XP GPU, CoreInfer achieved a 10.33 times and 2.72 times speedup\ncompared to the Huggingface implementation and PowerInfer, respectively.", "published": "2024-10-23 22:45:23", "link": "http://arxiv.org/abs/2410.18311v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Which Client is Reliable?: A Reliable and Personalized Prompt-based\n  Federated Learning for Medical Image Question Answering", "abstract": "Conventional medical artificial intelligence (AI) models face barriers in\nclinical application and ethical issues owing to their inability to handle the\nprivacy-sensitive characteristics of medical data. We present a novel\npersonalized federated learning (pFL) method for medical visual question\nanswering (VQA) models, addressing privacy reliability challenges in the\nmedical domain. Our method introduces learnable prompts into a Transformer\narchitecture to efficiently train it on diverse medical datasets without\nmassive computational costs. Then we introduce a reliable client VQA model that\nincorporates Dempster-Shafer evidence theory to quantify uncertainty in\npredictions, enhancing the model's reliability. Furthermore, we propose a novel\ninter-client communication mechanism that uses maximum likelihood estimation to\nbalance accuracy and uncertainty, fostering efficient integration of insights\nacross clients.", "published": "2024-10-23 00:31:17", "link": "http://arxiv.org/abs/2410.17484v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers", "abstract": "Attacking fairness is crucial because compromised models can introduce biased\noutcomes, undermining trust and amplifying inequalities in sensitive\napplications like hiring, healthcare, and law enforcement. This highlights the\nurgent need to understand how fairness mechanisms can be exploited and to\ndevelop defenses that ensure both fairness and robustness. We introduce\nBadFair, a novel backdoored fairness attack methodology. BadFair stealthily\ncrafts a model that operates with accuracy and fairness under regular\nconditions but, when activated by certain triggers, discriminates and produces\nincorrect results for specific groups. This type of attack is particularly\nstealthy and dangerous, as it circumvents existing fairness detection methods,\nmaintaining an appearance of fairness in normal use. Our findings reveal that\nBadFair achieves a more than 85% attack success rate in attacks aimed at target\ngroups on average while only incurring a minimal accuracy loss. Moreover, it\nconsistently exhibits a significant discrimination score, distinguishing\nbetween pre-defined target and non-target attacked groups across various\ndatasets and models.", "published": "2024-10-23 01:14:54", "link": "http://arxiv.org/abs/2410.17492v1", "categories": ["cs.CR", "cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CR"}
{"title": "Mechanisms of Symbol Processing for In-Context Learning in Transformer\n  Networks", "abstract": "Large Language Models (LLMs) have demonstrated impressive abilities in symbol\nprocessing through in-context learning (ICL). This success flies in the face of\ndecades of predictions that artificial neural networks cannot master abstract\nsymbol manipulation. We seek to understand the mechanisms that can enable\nrobust symbol processing in transformer networks, illuminating both the\nunanticipated success, and the significant limitations, of transformers in\nsymbol processing. Borrowing insights from symbolic AI on the power of\nProduction System architectures, we develop a high-level language, PSL, that\nallows us to write symbolic programs to do complex, abstract symbol processing,\nand create compilers that precisely implement PSL programs in transformer\nnetworks which are, by construction, 100% mechanistically interpretable. We\ndemonstrate that PSL is Turing Universal, so the work can inform the\nunderstanding of transformer ICL in general. The type of transformer\narchitecture that we compile from PSL programs suggests a number of paths for\nenhancing transformers' capabilities at symbol processing. (Note: The first\nsection of the paper gives an extended synopsis of the entire paper.)", "published": "2024-10-23 01:38:10", "link": "http://arxiv.org/abs/2410.17498v1", "categories": ["cs.AI", "cs.CL", "cs.NE", "cs.SC", "F.1; I.2"], "primary_category": "cs.AI"}
{"title": "Differentially Private Learning Needs Better Model Initialization and\n  Self-Distillation", "abstract": "Differentially private SGD (DPSGD) enables privacy-preserving training of\nlanguage models, but often reduces utility, diversity, and linguistic quality.\nWe introduce DPRefine, a three-phase method that initializes a model using data\nsynthesis from a small pre-trained LM with rigorous filtering, applies DP\nfinetuning on private data, and performs self-distillation to refine outputs.\nThis approach significantly outperforms vanilla DPSGD, with AlpacaEval\npreferring DPRefine's generations in 78.4% of cases across all datasets. Our\nanalysis reveals that DPRefine reduces linguistic errors in generated text by\n84.0%, mitigating grammar and spelling errors, commonly associated with DPSGD.\nIt also reduces inconsistencies of non-private models, such as hallucinated\ndetails and misattributed quotes. We find that small models like GPT-2 can be\neffective for initialization and distillation, highlighting their potential in\nenabling scalable and efficient deployment of privacy-preserving language.", "published": "2024-10-23 05:19:51", "link": "http://arxiv.org/abs/2410.17566v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "primary_category": "cs.LG"}
{"title": "Graphusion: A RAG Framework for Knowledge Graph Construction with a\n  Global Perspective", "abstract": "Knowledge Graphs (KGs) are crucial in the field of artificial intelligence\nand are widely used in downstream tasks, such as question-answering (QA). The\nconstruction of KGs typically requires significant effort from domain experts.\nLarge Language Models (LLMs) have recently been used for Knowledge Graph\nConstruction (KGC). However, most existing approaches focus on a local\nperspective, extracting knowledge triplets from individual sentences or\ndocuments, missing a fusion process to combine the knowledge in a global KG.\nThis work introduces Graphusion, a zero-shot KGC framework from free text. It\ncontains three steps: in Step 1, we extract a list of seed entities using topic\nmodeling to guide the final KG includes the most relevant entities; in Step 2,\nwe conduct candidate triplet extraction using LLMs; in Step 3, we design the\nnovel fusion module that provides a global view of the extracted knowledge,\nincorporating entity merging, conflict resolution, and novel triplet discovery.\nResults show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for\nentity extraction and relation recognition, respectively. Moreover, we showcase\nhow Graphusion could be applied to the Natural Language Processing (NLP) domain\nand validate it in an educational scenario. Specifically, we introduce TutorQA,\na new expert-verified benchmark for QA, comprising six tasks and a total of\n1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant\nimprovement on the benchmark, for example, a 9.2% accuracy improvement on\nsub-graph completion.", "published": "2024-10-23 06:54:03", "link": "http://arxiv.org/abs/2410.17600v2", "categories": ["cs.CL", "cs.AI", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Beware of Calibration Data for Pruning Large Language Models", "abstract": "As large language models (LLMs) are widely applied across various fields,\nmodel compression has become increasingly crucial for reducing costs and\nimproving inference efficiency. Post-training pruning is a promising method\nthat does not require resource-intensive iterative training and only needs a\nsmall amount of calibration data to assess the importance of parameters.\nPrevious research has primarily focused on designing advanced pruning methods,\nwhile different calibration data's impact on pruning performance still lacks\nsystematical exploration. We fill this blank and surprisingly observe that the\neffects of calibration data even value more than designing advanced pruning\nstrategies, especially for high sparsity. Our preliminary exploration also\ndiscloses that using calibration data similar to the training data can yield\nbetter performance. As pre-training data is usually inaccessible for advanced\nLLMs, we further provide a self-generating calibration data synthesis strategy\nto construct feasible calibration data. We conduct experiments on the recent\nstrong open-source LLMs (e.g., DCLM, and LLaMA-3), and the results show that\nthe proposed method outperforms commonly used calibration data and can\neffectively enhance strong pruning methods (e.g., Wanda, OWL).", "published": "2024-10-23 09:36:21", "link": "http://arxiv.org/abs/2410.17711v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation", "abstract": "Full-duplex spoken dialogue systems significantly surpass traditional\nturn-based dialogue systems, as they allow simultaneous bidirectional\ncommunication, closely mirroring human-human interactions. However, achieving\nlow latency and natural interactions in full-duplex dialogue systems remains a\nsignificant challenge, especially considering human conversation dynamics such\nas interruptions, backchannels, and overlapping speech. In this paper, we\nintroduce a novel End-to-End GPT-based model OmniFlatten for full-duplex\nconversation, capable of effectively modeling the complex behaviors inherent to\nnatural conversations with low latency. To achieve full-duplex conversation\ncapabilities, we propose a multi-stage post-training scheme that progressively\nadapts a text large language model (LLM) backbone into a speech-text dialogue\nLLM, capable of generating text and speech in real time, without modifying the\narchitecture of the backbone LLM. The training process comprises three stages:\nmodality alignment, half-duplex dialogue learning, and full-duplex dialogue\nlearning. In all training stages, we standardize the data using a flattening\noperation, which enables unifying the training methods and the GPT backbone\nacross different modalities and tasks. Our approach offers a simple modeling\ntechnique and a promising research direction for developing efficient and\nnatural end-to-end full-duplex spoken dialogue systems. Audio samples of\ndialogues generated by OmniFlatten can be found at this web site\n(https://omniflatten.github.io/).", "published": "2024-10-23 11:58:58", "link": "http://arxiv.org/abs/2410.17799v2", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large\n  Language Models to Specialized Domains", "abstract": "Retrieval-augmented generation (RAG) enhances the question-answering (QA)\nabilities of large language models (LLMs) by integrating external knowledge.\nHowever, adapting general-purpose RAG systems to specialized fields such as\nscience and medicine poses unique challenges due to distribution shifts and\nlimited access to domain-specific data. To tackle this, we propose SimRAG, a\nself-training approach that equips the LLM with joint capabilities of question\nanswering and question generation for domain adaptation. Our method first\nfine-tunes the LLM on instruction-following, question-answering, and\nsearch-related data. Then, it prompts the same LLM to generate diverse\ndomain-relevant questions from unlabeled corpora, with an additional filtering\nstrategy to retain high-quality synthetic examples. By leveraging these\nself-generated synthetic examples, the LLM can improve their performance on\ndomain-specific RAG tasks. Experiments on 11 datasets, spanning two backbone\nsizes and three domains, demonstrate that SimRAG outperforms baselines by\n1.2\\%--8.6\\%.", "published": "2024-10-23 15:24:16", "link": "http://arxiv.org/abs/2410.17952v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024", "abstract": "The eRisk laboratory aims to address issues related to early risk detection\non the Web. In this year's edition, three tasks were proposed, where Task 2 was\nabout early detection of signs of anorexia. Early risk detection is a problem\nwhere precision and speed are two crucial objectives. Our research group solved\nTask 2 by defining a CPI+DMC approach, addressing both objectives\nindependently, and a time-aware approach, where precision and speed are\nconsidered a combined single-objective. We implemented the last approach by\nexplicitly integrating time during the learning process, considering the\nERDE{\\theta} metric as the training objective. It also allowed us to\nincorporate temporal metrics to validate and select the optimal models. We\nachieved outstanding results for the ERDE50 metric and ranking-based metrics,\ndemonstrating consistency in solving ERD problems.", "published": "2024-10-23 15:30:37", "link": "http://arxiv.org/abs/2410.17963v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Stick-breaking Attention", "abstract": "The self-attention mechanism traditionally relies on the softmax operator,\nnecessitating positional embeddings like RoPE, or position biases to account\nfor token order. But current methods using still face length generalisation\nchallenges. We propose an alternative attention mechanism based on the\nstick-breaking process: For each token before the current, we determine a break\npoint $\\beta_{i,j}$, which represents the proportion of the remaining stick to\nallocate to the current token. We repeat the process until the stick is fully\nallocated, resulting in a sequence of attention weights. This process naturally\nincorporates recency bias, which has linguistic motivations for grammar parsing\n(Shen et. al., 2017). We study the implications of replacing the conventional\nsoftmax-based attention mechanism with stick-breaking attention. We then\ndiscuss implementation of numerically stable stick-breaking attention and adapt\nFlash Attention to accommodate this mechanism. When used as a drop-in\nreplacement for current softmax+RoPE attention systems, we find that\nstick-breaking attention performs competitively with current methods on length\ngeneralisation and downstream tasks. Stick-breaking also performs well at\nlength generalisation, allowing a model trained with $2^{11}$ context window to\nperform well at $2^{14}$ with perplexity improvements.", "published": "2024-10-23 15:51:13", "link": "http://arxiv.org/abs/2410.17980v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "GraphTeam: Facilitating Large Language Model-based Graph Analysis via\n  Multi-Agent Collaboration", "abstract": "Graphs are widely used for modeling relational data in real-world scenarios,\nsuch as social networks and urban computing. Existing LLM-based graph analysis\napproaches either integrate graph neural networks (GNNs) for specific machine\nlearning tasks, limiting their transferability, or rely solely on LLMs'\ninternal reasoning ability, resulting in suboptimal performance. To address\nthese limitations, we take advantage of recent advances in LLM-based agents,\nwhich have shown capabilities of utilizing external knowledge or tools for\nproblem solving. By simulating human problem-solving strategies such as analogy\nand collaboration, we propose a multi-agent system based on LLMs named\nGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from\nthree modules, and the agents with different specialities can collaborate with\neach other to address complex problems. Specifically, (1) input-output\nnormalization module: the question agent extracts and refines four key\narguments from the original question, facilitating the problem understanding,\nand the answer agent organizes the results to meet the output requirement; (2)\nexternal knowledge retrieval module: we first build a knowledge base consisting\nof relevant documentation and experience information, and then the search agent\nretrieves the most relevant entries for each question. (3) problem-solving\nmodule: given the retrieved information from search agent, the coding agent\nuses established algorithms via programming to generate solutions, and in case\nthe coding agent does not work, the reasoning agent will directly compute the\nresults without programming. Extensive experiments on six graph analysis\nbenchmarks demonstrate that GraphTeam achieves state-of-the-art performance\nwith an average 25.85% improvement over the best baseline in terms of accuracy.\nThe code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.", "published": "2024-10-23 17:02:59", "link": "http://arxiv.org/abs/2410.18032v4", "categories": ["cs.AI", "cs.CL", "cs.MA"], "primary_category": "cs.AI"}
{"title": "TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing\n  Prompts", "abstract": "Recently, multimodal large language models (MLLMs) have received much\nattention for their impressive capabilities. The evaluation of MLLMs is\nbecoming critical to analyzing attributes of MLLMs and providing valuable\ninsights. However, current benchmarks overlook the problem of prompt\nsensitivity - minor prompt variations may lead to significant performance\nfluctuations. Thus, inappropriate prompts may obscure the models' capabilities,\nunderestimating the models' performance. Moreover, different models have\ndifferent preferences for different prompts, and thus, using the same prompt\nfor all models will cause evaluation bias. This paper analyzes this deficiency\nin existing benchmarks and further introduces a new evaluation framework named\nTP-Eval, which introduces a prompt customization method to reduce evaluation\nbiases and tap models' potential. TP-Eval will rewrite the original prompts to\ndifferent customized prompts for different models. In particular, we propose\nsome well-designed modules for prompt customization tailored to the scenario of\nMLLM evaluation. Extensive experiments demonstrate the effectiveness of our\napproach to uncovering models' capabilities, and TP-Eval should benefit the\ncommunity in developing more comprehensive and convincing MLLM evaluation\nbenchmarks.", "published": "2024-10-23 17:54:43", "link": "http://arxiv.org/abs/2410.18071v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "ALTA: Compiler-Based Analysis of Transformers", "abstract": "We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.", "published": "2024-10-23 17:58:49", "link": "http://arxiv.org/abs/2410.18077v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment", "abstract": "Data selection is crucial for optimizing language model (LM) performance on\nspecific tasks, yet most existing methods fail to effectively consider the\ntarget task distribution.\n  Current approaches either ignore task-specific requirements entirely or rely\non approximations that fail to capture the nuanced patterns needed for tasks\nlike Autoformalization or code generation.\n  Methods that do consider the target distribution often rely on simplistic,\nsometimes noisy, representations, like hashed n-gram features, which can lead\nto collisions and introduce noise.\n  We introduce ZIP-FIT, a data selection framework that uses gzip compression\nto directly measure alignment between potential training data and the target\ntask distribution.\n  In extensive evaluations on Autoformalization and Python code generation,\nZIP-FIT significantly outperforms leading baselines like DSIR and D4.\n  Models trained on ZIP-FIT-selected data achieve their lowest cross-entropy\nloss up to 85.1\\% faster than baselines, demonstrating that better task\nalignment leads to more efficient learning.\n  In addition, ZIP-FIT performs selection up to 65.8\\% faster than DSIR and two\norders of magnitude faster than D4.\n  Notably, ZIP-FIT shows that smaller, well-aligned datasets often outperform\nlarger but less targeted ones, demonstrating that a small amount of higher\nquality data is superior to a large amount of lower quality data.\n  Our results imply that task-aware data selection is crucial for efficient\ndomain adaptation, and that compression offers a principled way to measure task\nalignment.\n  By showing that targeted data selection can dramatically improve\ntask-specific performance, our work provides new insights into the relationship\nbetween data quality, task alignment, and model learning efficiency.", "published": "2024-10-23 18:01:06", "link": "http://arxiv.org/abs/2410.18194v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Towards Understanding the Fragility of Multilingual LLMs against\n  Fine-Tuning Attacks", "abstract": "Recent advancements in Large Language Models (LLMs) have sparked widespread\nconcerns about their safety. Recent work demonstrates that safety alignment of\nLLMs can be easily removed by fine-tuning with a few adversarially chosen\ninstruction-following examples, i.e., fine-tuning attacks. We take a further\nstep to understand fine-tuning attacks in multilingual LLMs. We first discover\ncross-lingual generalization of fine-tuning attacks: using a few adversarially\nchosen instruction-following examples in one language, multilingual LLMs can\nalso be easily compromised (e.g., multilingual LLMs fail to refuse harmful\nprompts in other languages). Motivated by this finding, we hypothesize that\nsafety-related information is language-agnostic and propose a new method termed\nSafety Information Localization (SIL) to identify the safety-related\ninformation in the model parameter space. Through SIL, we validate this\nhypothesis and find that only changing 20% of weight parameters in fine-tuning\nattacks can break safety alignment across all languages. Furthermore, we\nprovide evidence to the alternative pathways hypothesis for why freezing\nsafety-related parameters does not prevent fine-tuning attacks, and we\ndemonstrate that our attack vector can still jailbreak LLMs adapted to new\nlanguages.", "published": "2024-10-23 18:27:36", "link": "http://arxiv.org/abs/2410.18210v2", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Optimizing the role of human evaluation in LLM-based spoken document\n  summarization systems", "abstract": "The emergence of powerful LLMs has led to a paradigm shift in abstractive\nsummarization of spoken documents. The properties that make LLMs so valuable\nfor this task -- creativity, ability to produce fluent speech, and ability to\nabstract information from large corpora -- also present new challenges to\nevaluating their content. Quick, cost-effective automatic evaluations such as\nROUGE and BERTScore offer promise, but do not yet show competitive performance\nwhen compared to human evaluations. We draw on methodologies from the social\nsciences to propose an evaluation paradigm for spoken document summarization\nexplicitly tailored for generative AI content. We provide detailed evaluation\ncriteria and best practices guidelines to ensure robustness in the experimental\ndesign, replicability, and trustworthiness of human evaluation studies. We\nadditionally include two case studies that show how these human-in-the-loop\nevaluation methods have been implemented at a major U.S. technology company.", "published": "2024-10-23 18:37:14", "link": "http://arxiv.org/abs/2410.18218v1", "categories": ["cs.AI", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language\n  Models", "abstract": "The dominant paradigm for RLHF is online and on-policy RL: synchronously\ngenerating from the large language model (LLM) policy, labelling with a reward\nmodel, and learning using feedback on the LLM's own outputs. While performant,\nthis paradigm is computationally inefficient. Inspired by classical deep RL\nliterature, we propose separating generation and learning in RLHF. This enables\nasynchronous generation of new samples while simultaneously training on old\nsamples, leading to faster training and more compute-optimal scaling. However,\nasynchronous training relies on an underexplored regime, online but off-policy\nRLHF: learning on samples from previous iterations of our model which give a\nworse training signal. We tackle the fundamental challenge in this regime: how\nmuch off-policyness can we tolerate for asynchronous training to speed up\nlearning but maintain performance? Among several RLHF algorithms we test,\nonline DPO is found to be most robust to off-policy data, and robustness\nincreases with the scale of the policy model. We study further compute\noptimizations for asynchronous RLHF but find that they come at a performance\ncost, giving rise to a trade-off. We verify the scalability of asynchronous\nRLHF by training a general-purpose chatbot from LLaMA 3.1 8B on an\ninstruction-following task ~40% faster than a synchronous run while matching\nfinal performance. Finally, we extend our results to math and reasoning to\ndemonstrate asynchronous RL can finetune Rho 1B on GSM8k ~70% faster while\nmatching synchronous accuracy.", "published": "2024-10-23 19:59:50", "link": "http://arxiv.org/abs/2410.18252v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Robust and Explainable Depression Identification from Speech Using\n  Vowel-Based Ensemble Learning Approaches", "abstract": "This study investigates explainable machine learning algorithms for\nidentifying depression from speech. Grounded in evidence from speech production\nthat depression affects motor control and vowel generation, pre-trained\nvowel-based embeddings, that integrate semantically meaningful linguistic\nunits, are used. Following that, an ensemble learning approach decomposes the\nproblem into constituent parts characterized by specific depression symptoms\nand severity levels. Two methods are explored: a \"bottom-up\" approach with 8\nmodels predicting individual Patient Health Questionnaire-8 (PHQ-8) item\nscores, and a \"top-down\" approach using a Mixture of Experts (MoE) with a\nrouter module for assessing depression severity. Both methods depict\nperformance comparable to state-of-the-art baselines, demonstrating robustness\nand reduced susceptibility to dataset mean/median values. System explainability\nbenefits are discussed highlighting their potential to assist clinicians in\ndepression diagnosis and screening.", "published": "2024-10-23 22:03:09", "link": "http://arxiv.org/abs/2410.18298v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Adaptive Segment-level Reward: Bridging the Gap Between Action and\n  Reward Space in Alignment", "abstract": "Reinforcement Learning (RL) has proven highly effective in aligning Large\nLanguage Models (LLMs) with human preferences. Typical RL methods optimize\nunder an overall sequence reward, which can lead to a suboptimal learning\nprocess. This reflects a key credit assignment problem: identifying which\ntokens to reinforce or suppress. To rectify these shortcomings, step-wise and\ntoken-wise methods have been proposed. However, step-wise methods rely on\npunctuation segmentation and still cannot accurately identify the key tokens.\nThe token-level approach is too fine-grained, attending to many unimportant\ntokens and thus introducing a large amount of noise. To assign more accurate\nrewards to different tokens, improving credit assignment, we propose the\n\"Adaptive Segment-wise Reward\" method. We employ semantic meaning, rather than\npunctuation, to adaptively delineate segments. Experiments demonstrate that our\nmethod can be integrated into various training methods. Compared to training\nmethods \\textit{without} our approach, our method improves the success rate on\nadversarial samples by 10\\%, and achieves a 1.3\\% improvement on evaluation\nbenchmarks such as MMLU, GSM8K, HumanEval, etc.", "published": "2024-10-23 16:16:15", "link": "http://arxiv.org/abs/2411.00809v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Multi-Draft Speculative Sampling: Canonical Architectures and\n  Theoretical Limits", "abstract": "We consider multi-draft speculative sampling, where the proposal sequences\nare sampled independently from different draft models. At each step, a\ntoken-level draft selection scheme takes a list of valid tokens as input and\nproduces an output token whose distribution matches that of the target model.\nPrevious works have demonstrated that the optimal scheme (which maximizes the\nprobability of accepting one of the input tokens) can be cast as a solution to\na linear program. In this work we show that the optimal scheme can be\ndecomposed into a two-step solution: in the first step an importance sampling\n(IS) type scheme is used to select one intermediate token; in the second step\n(single-draft) speculative sampling is applied to generate the output token.\nFor the case of two identical draft models we further 1) establish a necessary\nand sufficient condition on the distributions of the target and draft models\nfor the acceptance probability to equal one and 2) provide an explicit\nexpression for the optimal acceptance probability. Our theoretical analysis\nalso motives a new class of token-level selection scheme based on weighted\nimportance sampling. Our experimental results demonstrate consistent\nimprovements in the achievable block efficiency and token rates over baseline\nschemes in a number of scenarios.", "published": "2024-10-23 19:28:34", "link": "http://arxiv.org/abs/2410.18234v1", "categories": ["cs.CL", "cs.DC", "cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.CL"}
{"title": "Regularized autoregressive modeling and its application to audio signal\n  declipping", "abstract": "Autoregressive (AR) modeling is invaluable in signal processing, in\nparticular in speech and audio fields. Attempts in the literature can be found\nthat regularize or constrain either the time-domain signal values or the AR\ncoefficients, which is done for various reasons, including the incorporation of\nprior information or numerical stabilization. Although these attempts are\nappealing, an encompassing and generic modeling framework is still missing. We\npropose such a framework and the related optimization problem and algorithm. We\ndiscuss the computational demands of the algorithm and explore the effects of\nvarious improvements on its convergence speed. In the experimental part, we\ndemonstrate the usefulness of our approach on the audio declipping problem. We\ncompare its performance against the state-of-the-art methods and demonstrate\nthe competitiveness of the proposed method, especially for mildly clipped\nsignals. The evaluation is extended by considering a heuristic algorithm of\ngeneralized linear prediction (GLP), a strong competitor which has only been\npresented as a patent and is new in the scientific community.", "published": "2024-10-23 11:45:31", "link": "http://arxiv.org/abs/2410.17790v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Adversarial Domain Adaptation for Metal Cutting Sound Detection:\n  Leveraging Abundant Lab Data for Scarce Industry Data", "abstract": "Cutting state monitoring in the milling process is crucial for improving\nmanufacturing efficiency and tool life. Cutting sound detection using machine\nlearning (ML) models, inspired by experienced machinists, can be employed as a\ncost-effective and non-intrusive monitoring method in a complex manufacturing\nenvironment. However, labeling industry data for training is costly and\ntime-consuming. Moreover, industry data is often scarce. In this study, we\npropose a novel adversarial domain adaptation (DA) approach to leverage\nabundant lab data to learn from scarce industry data, both labeled, for\ntraining a cutting-sound detection model. Rather than adapting the features\nfrom separate domains directly, we project them first into two separate latent\nspaces that jointly work as the feature space for learning domain-independent\nrepresentations. We also analyze two different mechanisms for adversarial\nlearning where the discriminator works as an adversary and a critic in separate\nsettings, enabling our model to learn expressive domain-invariant and\ndomain-ingrained features, respectively. We collected cutting sound data from\nmultiple sensors in different locations, prepared datasets from lab and\nindustry domain, and evaluated our learning models on them. Experiments showed\nthat our models outperformed the multi-layer perceptron based vanilla domain\nadaptation models in labeling tasks on the curated datasets, achieving near\n92%, 82% and 85% accuracy respectively for three different sensors installed in\nindustry settings.", "published": "2024-10-23 05:55:21", "link": "http://arxiv.org/abs/2410.17574v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Exploring Tokenization Methods for Multitrack Sheet Music Generation", "abstract": "This study explores the tokenization of multitrack sheet music in ABC\nnotation, introducing two methods--bar-stream and line-stream patching. We\ncompare these methods against existing techniques, including bar patching, byte\npatching, and Byte Pair Encoding (BPE). In terms of both computational\nefficiency and the musicality of the generated compositions, experimental\nresults show that bar-stream patching performs best overall compared to the\nothers, which makes it a promising tokenization strategy for sheet music\ngeneration.", "published": "2024-10-23 06:19:48", "link": "http://arxiv.org/abs/2410.17584v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Non-intrusive Speech Quality Assessment with Diffusion Models Trained on\n  Clean Speech", "abstract": "Diffusion models have found great success in generating high quality, natural\nsamples of speech, but their potential for density estimation for speech has so\nfar remained largely unexplored. In this work, we leverage an unconditional\ndiffusion model trained only on clean speech for the assessment of speech\nquality. We show that the quality of a speech utterance can be assessed by\nestimating the likelihood of a corresponding sample in the terminating Gaussian\ndistribution, obtained via a deterministic noising process. The resulting\nmethod is purely unsupervised, trained only on clean speech, and therefore does\nnot rely on annotations. Our diffusion-based approach leverages clean speech\npriors to assess quality based on how the input relates to the learned\ndistribution of clean data. Our proposed log-likelihoods show promising\nresults, correlating well with intrusive speech quality metrics such as POLQA\nand SI-SDR.", "published": "2024-10-23 12:53:58", "link": "http://arxiv.org/abs/2410.17834v1", "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Music102: An $D_{12}$-equivariant transformer for chord progression\n  accompaniment", "abstract": "We present Music102, an advanced model built upon the Music101 prototype,\naimed at enhancing chord progression accompaniment through a D12-equivariant\ntransformer. Inspired by group theory and symbolic music structures, Music102\nleverages musical symmetry--such as transposition and reflection\noperations--integrating these properties into the transformer architecture. By\nencoding prior music knowledge, the model maintains equivariance across both\nmelody and chord sequences. The POP909 dataset was employed to train and\nevaluate Music102, revealing significant improvements over Music101 in both\nweighted loss and exact accuracy metrics, despite using fewer parameters. This\nwork showcases the adaptability of self-attention mechanisms and layer\nnormalization to the discrete musical domain, addressing challenges in\ncomputational music analysis. With its stable and flexible neural framework,\nMusic102 sets the stage for further exploration in equivariant music generation\nand computational composition tools, bridging mathematical theory with\npractical music performance.", "published": "2024-10-23 03:11:01", "link": "http://arxiv.org/abs/2410.18151v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Vocal Melody Construction for Persian Lyrics Using LSTM Recurrent Neural\n  Networks", "abstract": "The present paper investigated automatic melody construction for Persian\nlyrics as an input. It was assumed that there is a phonological correlation\nbetween the lyric syllables and the melody in a song. A seq2seq neural network\nwas developed to investigate this assumption, trained on parallel syllable and\nnote sequences in Persian songs to suggest a pleasant melody for a new sequence\nof syllables. More than 100 pieces of Persian music were collected and\nconverted from the printed version to the digital format due to the lack of a\ndataset on Persian digital music. Finally, 14 new lyrics were given to the\nmodel as input, and the suggested melodies were performed and recorded by music\nexperts to evaluate the trained model. The evaluation was conducted using an\naudio questionnaire, which more than 170 persons answered. According to the\nanswers about the pleasantness of melody, the system outputs scored an average\nof 3.005 from 5, while the human-made melodies for the same lyrics obtained an\naverage score of 4.078.", "published": "2024-10-23 18:11:44", "link": "http://arxiv.org/abs/2410.18203v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Unified Microphone Conversion: Many-to-Many Device Mapping via\n  Feature-wise Linear Modulation", "abstract": "In this study, we introduce Unified Microphone Conversion, a unified\ngenerative framework to enhance the resilience of sound event classification\nsystems against device variability. Building on the limitations of previous\nworks, we condition the generator network with frequency response information\nto achieve many-to-many device mapping. This approach overcomes the inherent\nlimitation of CycleGAN, requiring separate models for each device pair. Our\nframework leverages the strengths of CycleGAN for unpaired training to simulate\ndevice characteristics in audio recordings and significantly extends its\nscalability by integrating frequency response related information via\nFeature-wise Linear Modulation. The experiment results show that our method\noutperforms the state-of-the-art method by 2.6% and reducing variability by\n0.8% in macro-average F1 score.", "published": "2024-10-23 23:10:09", "link": "http://arxiv.org/abs/2410.18322v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Challenge on Sound Scene Synthesis: Evaluating Text-to-Audio Generation", "abstract": "Despite significant advancements in neural text-to-audio generation,\nchallenges persist in controllability and evaluation. This paper addresses\nthese issues through the Sound Scene Synthesis challenge held as part of the\nDetection and Classification of Acoustic Scenes and Events 2024. We present an\nevaluation protocol combining objective metric, namely Fr\\'echet Audio\nDistance, with perceptual assessments, utilizing a structured prompt format to\nenable diverse captions and effective evaluation. Our analysis reveals varying\nperformance across sound categories and model architectures, with larger models\ngenerally excelling but innovative lightweight approaches also showing promise.\nThe strong correlation between objective metrics and human ratings validates\nour evaluation approach. We discuss outcomes in terms of audio quality,\ncontrollability, and architectural considerations for text-to-audio\nsynthesizers, providing direction for future research.", "published": "2024-10-23 06:35:41", "link": "http://arxiv.org/abs/2410.17589v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
