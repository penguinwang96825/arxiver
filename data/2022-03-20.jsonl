{"title": "How does the pre-training objective affect what large language models\n  learn about linguistic properties?", "abstract": "Several pre-training objectives, such as masked language modeling (MLM), have\nbeen proposed to pre-train language models (e.g. BERT) with the aim of learning\nbetter language representations. However, to the best of our knowledge, no\nprevious work so far has investigated how different pre-training objectives\naffect what BERT learns about linguistics properties. We hypothesize that\nlinguistically motivated objectives such as MLM should help BERT to acquire\nbetter linguistic knowledge compared to other non-linguistically motivated\nobjectives that are not intuitive or hard for humans to guess the association\nbetween the input and the label to be predicted. To this end, we pre-train BERT\nwith two linguistically motivated objectives and three non-linguistically\nmotivated ones. We then probe for linguistic characteristics encoded in the\nrepresentation of the resulting models. We find strong evidence that there are\nonly small differences in probing performance between the representations\nlearned by the two different types of objectives. These surprising results\nquestion the dominant narrative of linguistically informed pre-training.", "published": "2022-03-20 00:02:10", "link": "http://arxiv.org/abs/2203.10415v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DEIM: An effective deep encoding and interaction model for sentence\n  matching", "abstract": "Natural language sentence matching is the task of comparing two sentences and\nidentifying the relationship between them.It has a wide range of applications\nin natural language processing tasks such as reading comprehension, question\nand answer systems. The main approach is to compute the interaction between\ntext representations and sentence pairs through an attention mechanism, which\ncan extract the semantic information between sentence pairs well. However,this\nkind of method can not gain satisfactory results when dealing with complex\nsemantic features. To solve this problem, we propose a sentence matching method\nbased on deep encoding and interaction to extract deep semantic information. In\nthe encoder layer,we refer to the information of another sentence in the\nprocess of encoding a single sentence, and later use a heuristic algorithm to\nfuse the information. In the interaction layer, we use a bidirectional\nattention mechanism and a self-attention mechanism to obtain deep semantic\ninformation.Finally, we perform a pooling operation and input it to the MLP for\nclassification. we evaluate our model on three tasks: recognizing textual\nentailment, paraphrase recognition, and answer selection. We conducted\nexperiments on the SNLI and SciTail datasets for the recognizing textual\nentailment task, the Quora dataset for the paraphrase recognition task, and the\nWikiQA dataset for the answer selection task. The experimental results show\nthat the proposed algorithm can effectively extract deep semantic features that\nverify the effectiveness of the algorithm on sentence matching tasks.", "published": "2022-03-20 07:59:42", "link": "http://arxiv.org/abs/2203.10482v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Entailment Relation Aware Paraphrase Generation", "abstract": "We introduce a new task of entailment relation aware paraphrase generation\nwhich aims at generating a paraphrase conforming to a given entailment relation\n(e.g. equivalent, forward entailing, or reverse entailing) with respect to a\ngiven input. We propose a reinforcement learning-based weakly-supervised\nparaphrasing system, ERAP, that can be trained using existing paraphrase and\nnatural language inference (NLI) corpora without an explicit task-specific\ncorpus. A combination of automated and human evaluations show that ERAP\ngenerates paraphrases conforming to the specified entailment relation and are\nof good quality as compared to the baselines and uncontrolled paraphrasing\nsystems. Using ERAP for augmenting training data for downstream textual\nentailment task improves performance over an uncontrolled paraphrasing system,\nand introduces fewer training artifacts, indicating the benefit of explicit\ncontrol during paraphrasing.", "published": "2022-03-20 08:02:09", "link": "http://arxiv.org/abs/2203.10483v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Parallel Instance Query Network for Named Entity Recognition", "abstract": "Named entity recognition (NER) is a fundamental task in natural language\nprocessing. Recent works treat named entity recognition as a reading\ncomprehension task, constructing type-specific queries manually to extract\nentities. This paradigm suffers from three issues. First, type-specific queries\ncan only extract one type of entities per inference, which is inefficient.\nSecond, the extraction for different types of entities is isolated, ignoring\nthe dependencies between them. Third, query construction relies on external\nknowledge and is difficult to apply to realistic scenarios with hundreds of\nentity types. To deal with them, we propose Parallel Instance Query Network\n(PIQN), which sets up global and learnable instance queries to extract entities\nfrom a sentence in a parallel manner. Each instance query predicts one entity,\nand by feeding all instance queries simultaneously, we can query all entities\nin parallel. Instead of being constructed from external knowledge, instance\nqueries can learn their different query semantics during training. For training\nthe model, we treat label assignment as a one-to-many Linear Assignment Problem\n(LAP) and dynamically assign gold entities to instance queries with minimal\nassignment cost. Experiments on both nested and flat NER datasets demonstrate\nthat our proposed method outperforms previous state-of-the-art models.", "published": "2022-03-20 13:01:25", "link": "http://arxiv.org/abs/2203.10545v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Neural-Symbolic Approach to Natural Language Understanding", "abstract": "Deep neural networks, empowered by pre-trained language models, have achieved\nremarkable results in natural language understanding (NLU) tasks. However,\ntheir performances can drastically deteriorate when logical reasoning is\nneeded. This is because NLU in principle depends on not only analogical\nreasoning, which deep neural networks are good at, but also logical reasoning.\nAccording to the dual-process theory, analogical reasoning and logical\nreasoning are respectively carried out by System 1 and System 2 in the human\nbrain. Inspired by the theory, we present a novel framework for NLU called\nNeural-Symbolic Processor (NSP), which performs analogical reasoning based on\nneural processing and logical reasoning based on both neural and symbolic\nprocessing. As a case study, we conduct experiments on two NLU tasks, question\nanswering (QA) and natural language inference (NLI), when numerical reasoning\n(a type of logical reasoning) is necessary. The experimental results show that\nour method significantly outperforms state-of-the-art methods in both tasks.", "published": "2022-03-20 14:12:44", "link": "http://arxiv.org/abs/2203.10557v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "STEMM: Self-learning with Speech-text Manifold Mixup for Speech\n  Translation", "abstract": "How to learn a better speech representation for end-to-end speech-to-text\ntranslation (ST) with limited labeled data? Existing techniques often attempt\nto transfer powerful machine translation (MT) capabilities to ST, but neglect\nthe representation discrepancy across modalities. In this paper, we propose the\nSpeech-TExt Manifold Mixup (STEMM) method to calibrate such discrepancy.\nSpecifically, we mix up the representation sequences of different modalities,\nand take both unimodal speech sequences and multimodal mixed sequences as input\nto the translation model in parallel, and regularize their output predictions\nwith a self-learning framework. Experiments on MuST-C speech translation\nbenchmark and further analysis show that our method effectively alleviates the\ncross-modal representation discrepancy, and achieves significant improvements\nover a strong baseline on eight translation directions.", "published": "2022-03-20 01:49:53", "link": "http://arxiv.org/abs/2203.10426v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Interpretability of Fine-grained Classification of Sadness and\n  Depression", "abstract": "While sadness is a human emotion that people experience at certain times\nthroughout their lives, inflicting them with emotional disappointment and pain,\ndepression is a longer term mental illness which impairs social, occupational,\nand other vital regions of functioning making it a much more serious issue and\nneeds to be catered to at the earliest. NLP techniques can be utilized for the\ndetection and subsequent diagnosis of these emotions. Most of the open sourced\ndata on the web deal with sadness as a part of depression, as an emotion even\nthough the difference in severity of both is huge. Thus, we create our own\nnovel dataset illustrating the difference between the two. In this paper, we\naim to highlight the difference between the two and highlight how interpretable\nour models are to distinctly label sadness and depression. Due to the sensitive\nnature of such information, privacy measures need to be taken for handling and\ntraining of such data. Hence, we also explore the effect of Federated Learning\n(FL) on contextualised language models.", "published": "2022-03-20 02:34:51", "link": "http://arxiv.org/abs/2203.10432v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Structuring Real-World Data at Scale: Deep Learning for\n  Extracting Key Oncology Information from Clinical Text with Patient-Level\n  Supervision", "abstract": "Objective: The majority of detailed patient information in real-world data\n(RWD) is only consistently available in free-text clinical documents. Manual\ncuration is expensive and time-consuming. Developing natural language\nprocessing (NLP) methods for structuring RWD is thus essential for scaling\nreal-world evidence generation.\n  Materials and Methods: Traditional rule-based systems are vulnerable to the\nprevalent linguistic variations and ambiguities in clinical text, and prior\napplications of machine-learning methods typically require sentence-level or\nreport-level labeled examples that are hard to produce at scale. We propose\nleveraging patient-level supervision from medical registries, which are often\nreadily available and capture key patient information, for general RWD\napplications. To combat the lack of sentence-level or report-level annotations,\nwe explore advanced deep-learning methods by combining domain-specific\npretraining, recurrent neural networks, and hierarchical attention.\n  Results: We conduct an extensive study on 135,107 patients from the cancer\nregistry of a large integrated delivery network (IDN) comprising healthcare\nsystems in five western US states. Our deep learning methods attain test AUROC\nof 94-99% for key tumor attributes and comparable performance on held-out data\nfrom separate health systems and states.\n  Discussion and Conclusion: Ablation results demonstrate clear superiority of\nthese advanced deep-learning methods over prior approaches. Error analysis\nshows that our NLP system sometimes even corrects errors in registrar labels.\nWe also conduct a preliminary investigation in accelerating registry curation\nand general RWD structuring via assisted curation for over 1.2 million cancer\npatients in this healthcare network.", "published": "2022-03-20 03:42:03", "link": "http://arxiv.org/abs/2203.10442v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hierarchical Inductive Transfer for Continual Dialogue Learning", "abstract": "Pre-trained models have achieved excellent performance on the dialogue task.\nHowever, for the continual increase of online chit-chat scenarios, directly\nfine-tuning these models for each of the new tasks not only explodes the\ncapacity of the dialogue system on the embedded devices but also causes\nknowledge forgetting on pre-trained models and knowledge interference among\ndiverse dialogue tasks. In this work, we propose a hierarchical inductive\ntransfer framework to learn and deploy the dialogue skills continually and\nefficiently. First, we introduce the adapter module into pre-trained models for\nlearning new dialogue tasks. As the only trainable module, it is beneficial for\nthe dialogue system on the embedded devices to acquire new dialogue skills with\nnegligible additional parameters. Then, for alleviating knowledge interference\nbetween tasks yet benefiting the regularization between them, we further design\nhierarchical inductive transfer that enables new tasks to use general knowledge\nin the base adapter without being misled by diverse knowledge in task-specific\nadapters. Empirical evaluation and analysis indicate that our framework obtains\ncomparable performance under deployment-friendly model capacity.", "published": "2022-03-20 08:06:44", "link": "http://arxiv.org/abs/2203.10484v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cluster & Tune: Boost Cold Start Performance in Text Classification", "abstract": "In real-world scenarios, a text classification task often begins with a cold\nstart, when labeled data is scarce. In such cases, the common practice of\nfine-tuning pre-trained models, such as BERT, for a target classification task,\nis prone to produce poor performance. We suggest a method to boost the\nperformance of such models by adding an intermediate unsupervised\nclassification task, between the pre-training and fine-tuning phases. As such\nan intermediate task, we perform clustering and train the pre-trained model on\npredicting the cluster labels. We test this hypothesis on various data sets,\nand show that this additional classification phase can significantly improve\nperformance, mainly for topical classification tasks, when the number of\nlabeled instances available for fine-tuning is only a couple of dozen to a few\nhundred.", "published": "2022-03-20 15:29:34", "link": "http://arxiv.org/abs/2203.10581v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Large-Scale Interpretable Knowledge Graph Reasoning for Dialogue\n  Systems", "abstract": "Users interacting with voice assistants today need to phrase their requests\nin a very specific manner to elicit an appropriate response. This limits the\nuser experience, and is partly due to the lack of reasoning capabilities of\ndialogue platforms and the hand-crafted rules that require extensive labor. One\npossible way to improve user experience and relieve the manual efforts of\ndesigners is to build an end-to-end dialogue system that can do reasoning\nitself while perceiving user's utterances. In this work, we propose a novel\nmethod to incorporate the knowledge reasoning capability into dialogue systems\nin a more scalable and generalizable manner. Our proposed method allows a\nsingle transformer model to directly walk on a large-scale knowledge graph to\ngenerate responses. To the best of our knowledge, this is the first work to\nhave transformer models generate responses by reasoning over differentiable\nknowledge graphs. We investigate the reasoning abilities of the proposed method\non both task-oriented and domain-specific chit-chat dialogues. Empirical\nresults show that this method can effectively and efficiently incorporate a\nknowledge graph into a dialogue system with fully-interpretable reasoning\npaths.", "published": "2022-03-20 17:51:49", "link": "http://arxiv.org/abs/2203.10610v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Calibration of Machine Reading Systems at Scale", "abstract": "In typical machine learning systems, an estimate of the probability of the\nprediction is used to assess the system's confidence in the prediction. This\nconfidence measure is usually uncalibrated; i.e.\\ the system's confidence in\nthe prediction does not match the true probability of the predicted output. In\nthis paper, we present an investigation into calibrating open setting machine\nreading systems such as open-domain question answering and claim verification\nsystems. We show that calibrating such complex systems which contain discrete\nretrieval and deep reading components is challenging and current calibration\ntechniques fail to scale to these settings. We propose simple extensions to\nexisting calibration approaches that allows us to adapt them to these settings.\nOur experimental results reveal that the approach works well, and can be useful\nto selectively predict answers when question answering systems are posed with\nunanswerable or out-of-the-training distribution questions.", "published": "2022-03-20 18:41:42", "link": "http://arxiv.org/abs/2203.10623v2", "categories": ["cs.CL", "cs.LG", "68T50 (Primary) 68T07 (Secondary)"], "primary_category": "cs.CL"}
{"title": "Enriching Unsupervised User Embedding via Medical Concepts", "abstract": "Clinical notes in Electronic Health Records (EHR) present rich documented\ninformation of patients to inference phenotype for disease diagnosis and study\npatient characteristics for cohort selection. Unsupervised user embedding aims\nto encode patients into fixed-length vectors without human supervisions.\nMedical concepts extracted from the clinical notes contain rich connections\nbetween patients and their clinical categories. However, existing unsupervised\napproaches of user embeddings from clinical notes do not explicitly incorporate\nmedical concepts. In this study, we propose a concept-aware unsupervised user\nembedding that jointly leverages text documents and medical concepts from two\nclinical corpora, MIMIC-III and Diabetes. We evaluate user embeddings on both\nextrinsic and intrinsic tasks, including phenotype classification, in-hospital\nmortality prediction, patient retrieval, and patient relatedness. Experiments\non the two clinical corpora show our approach exceeds unsupervised baselines,\nand incorporating medical concepts can significantly improve the baseline\nperformance.", "published": "2022-03-20 18:54:05", "link": "http://arxiv.org/abs/2203.10627v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Continual Sequence Generation with Adaptive Compositional Modules", "abstract": "Continual learning is essential for real-world deployment when there is a\nneed to quickly adapt the model to new tasks without forgetting knowledge of\nold tasks. Existing work on continual sequence generation either always reuses\nexisting parameters to learn new tasks, which is vulnerable to catastrophic\nforgetting on dissimilar tasks, or blindly adds new parameters for every new\ntask, which could prevent knowledge sharing between similar tasks. To get the\nbest of both worlds, in this work, we propose continual sequence generation\nwith adaptive compositional modules to adaptively add modules in transformer\narchitectures and compose both old and new modules for new tasks. We also\nincorporate pseudo experience replay to facilitate knowledge transfer in those\nshared modules. Experiment results on various sequences of generation tasks\nshow that our framework can adaptively add modules or reuse modules based on\ntask similarity, outperforming state-of-the-art baselines in terms of both\nperformance and parameter efficiency. We make our code public at\nhttps://github.com/GT-SALT/Adaptive-Compositional-Modules.", "published": "2022-03-20 21:22:48", "link": "http://arxiv.org/abs/2203.10652v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "From Stance to Concern: Adaptation of Propositional Analysis to New\n  Tasks and Domains", "abstract": "We present a generalized paradigm for adaptation of propositional analysis\n(predicate-argument pairs) to new tasks and domains. We leverage an analogy\nbetween stances (belief-driven sentiment) and concerns (topical issues with\nmoral dimensions/endorsements) to produce an explanatory representation. A key\ncontribution is the combination of semi-automatic resource building for\nextraction of domain-dependent concern types (with 2-4 hours of human labor per\ndomain) and an entirely automatic procedure for extraction of\ndomain-independent moral dimensions and endorsement values. Prudent (automatic)\nselection of terms from propositional structures for lexical expansion (via\nsemantic similarity) produces new moral dimension lexicons at three levels of\ngranularity beyond a strong baseline lexicon. We develop a ground truth (GT)\nbased on expert annotators and compare our concern detection output to GT, to\nyield 231% improvement in recall over baseline, with only a 10% loss in\nprecision. F1 yields 66% improvement over baseline and 97.8% of human\nperformance. Our lexically based approach yields large savings over approaches\nthat employ costly human labor and model building. We provide to the community\na newly expanded moral dimension/value lexicon, annotation guidelines, and GT.", "published": "2022-03-20 21:50:35", "link": "http://arxiv.org/abs/2203.10659v1", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Mitigating Gender Bias in Machine Translation through Adversarial\n  Learning", "abstract": "Machine translation and other NLP systems often contain significant biases\nregarding sensitive attributes, such as gender or race, that worsen system\nperformance and perpetuate harmful stereotypes. Recent preliminary research\nsuggests that adversarial learning can be used as part of a model-agnostic bias\nmitigation method that requires no data modifications. However, adapting this\nstrategy for machine translation and other modern NLP domains requires (1)\nrestructuring training objectives in the context of fine-tuning pretrained\nlarge language models and (2) developing measures for gender or other protected\nvariables for tasks in which these attributes must be deduced from the data\nitself.\n  We present an adversarial learning framework that addresses these challenges\nto mitigate gender bias in seq2seq machine translation. Our framework improves\nthe disparity in translation quality for sentences with male vs. female\nentities by 86% for English-German translation and 91% for English-French\ntranslation, with minimal effect on translation quality. The results suggest\nthat adversarial learning is a promising technique for mitigating gender bias\nin machine translation.", "published": "2022-03-20 23:35:09", "link": "http://arxiv.org/abs/2203.10675v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Delta Keyword Transformer: Bringing Transformers to the Edge through\n  Dynamically Pruned Multi-Head Self-Attention", "abstract": "Multi-head self-attention forms the core of Transformer networks. However,\ntheir quadratically growing complexity with respect to the input sequence\nlength impedes their deployment on resource-constrained edge devices. We\naddress this challenge by proposing a dynamic pruning method, which exploits\nthe temporal stability of data across tokens to reduce inference cost. The\nthreshold-based method only retains significant differences between the\nsubsequent tokens, effectively reducing the number of multiply-accumulates, as\nwell as the internal tensor data sizes. The approach is evaluated on the Google\nSpeech Commands Dataset for keyword spotting, and the performance is compared\nagainst the baseline Keyword Transformer. Our experiments show that we can\nreduce ~80% of operations while maintaining the original 98.4% accuracy.\nMoreover, a reduction of ~87-94% operations can be achieved when only degrading\nthe accuracy by 1-4%, speeding up the multi-head self-attention inference by a\nfactor of ~7.5-16.", "published": "2022-03-20 20:59:13", "link": "http://arxiv.org/abs/2204.03479v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Perceiving the World: Question-guided Reinforcement Learning for\n  Text-based Games", "abstract": "Text-based games provide an interactive way to study natural language\nprocessing. While deep reinforcement learning has shown effectiveness in\ndeveloping the game playing agent, the low sample efficiency and the large\naction space remain to be the two major challenges that hinder the DRL from\nbeing applied in the real world. In this paper, we address the challenges by\nintroducing world-perceiving modules, which automatically decompose tasks and\nprune actions by answering questions about the environment. We then propose a\ntwo-phase training framework to decouple language learning from reinforcement\nlearning, which further improves the sample efficiency. The experimental\nresults show that the proposed method significantly improves the performance\nand sample efficiency. Besides, it shows robustness against compound error and\nlimited pre-training data.", "published": "2022-03-20 04:23:57", "link": "http://arxiv.org/abs/2204.09597v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Build a Robust QA System with Transformer-based Mixture of Experts", "abstract": "In this paper, we aim to build a robust question answering system that can\nadapt to out-of-domain datasets. A single network may overfit to the\nsuperficial correlation in the training distribution, but with a meaningful\nnumber of expert sub-networks, a gating network that selects a sparse\ncombination of experts for each input, and careful balance on the importance of\nexpert sub-networks, the Mixture-of-Experts (MoE) model allows us to train a\nmulti-task learner that can be generalized to out-of-domain datasets. We also\nexplore the possibility of bringing the MoE layers up to the middle of the\nDistilBERT and replacing the dense feed-forward network with a\nsparsely-activated switch FFN layers, similar to the Switch Transformer\narchitecture, which simplifies the MoE routing algorithm with reduced\ncommunication and computational costs. In addition to model architectures, we\nexplore techniques of data augmentation including Easy Data Augmentation (EDA)\nand back translation, to create more meaningful variance among the small\nout-of-domain training data, therefore boosting the performance and robustness\nof our models. In this paper, we show that our combination of best architecture\nand data augmentation techniques achieves a 53.477 F1 score in the\nout-of-domain evaluation, which is a 9.52% performance gain over the baseline.\nOn the final test set, we reported a higher 59.506 F1 and 41.651 EM. We\nsuccessfully demonstrate the effectiveness of Mixture-of-Expert architecture in\na Robust QA task.", "published": "2022-03-20 02:38:29", "link": "http://arxiv.org/abs/2204.09598v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "MetaOnce: A Metaverse Framework Based on Multi-scene Relations and\n  Entity-relation-event Game", "abstract": "Existing metaverse systems lack rich relation types between entities and\nevents. The challenge is that there is no portable framework to introduce rich\nconcepts, relations, events into the metaverse. This paper introduces a new\nmetaverse framework, MetaOnce. This framework proposes to build multi-scene\ngraphs. This framework not only describes rich relations in a single scene but\nalso combines multiple scene graphs into a complete graph for more\ncomprehensive analysis and inference. Prior social network systems mainly\ndescribe friend relations. They ignore the effect of entity-relation-event\ngames on the metaverse system and existing rule constraints. We propose a rule\ncontroller and impose constraints on the relations that allow the framework to\nbehave in a compliant manner. We build a metaverse system to test the features\nof the framework, and experimental results show that our framework can build a\nmulti-scene metaverse with memory and rule constraints.", "published": "2022-03-20 01:01:05", "link": "http://arxiv.org/abs/2203.10424v1", "categories": ["cs.CL", "cs.CY", "cs.GT"], "primary_category": "cs.CL"}
{"title": "g2pW: A Conditional Weighted Softmax BERT for Polyphone Disambiguation\n  in Mandarin", "abstract": "Polyphone disambiguation is the most crucial task in Mandarin\ngrapheme-to-phoneme (g2p) conversion. Previous studies have approached this\nproblem using pre-trained language models, restricted output, and extra\ninformation from Part-Of-Speech (POS) tagging. Inspired by these strategies, we\npropose a novel approach, called g2pW, which adapts learnable softmax-weights\nto condition the outputs of BERT with the polyphonic character of interest and\nits POS tagging. Rather than using the hard mask as in previous works, our\nexperiments show that learning a soft-weighting function for the candidate\nphonemes benefits performance. In addition, our proposed g2pW does not require\nextra pre-trained POS tagging models while using POS tags as auxiliary features\nsince we train the POS tagging model simultaneously with the unified encoder.\nExperimental results show that our g2pW outperforms existing methods on the\npublic CPP dataset. All codes, model weights, and a user-friendly package are\npublicly available.", "published": "2022-03-20 02:28:25", "link": "http://arxiv.org/abs/2203.10430v5", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Who Shares Fake News? Uncovering Insights from Social Media Users' Post\n  Histories", "abstract": "We propose that social-media users' own post histories are an underused yet\nvaluable resource for studying fake-news sharing. By extracting textual cues\nfrom their prior posts, and contrasting their prevalence against random\nsocial-media users and others (e.g., those with similar socio-demographics,\npolitical news-sharers, and fact-check sharers), researchers can identify cues\nthat distinguish fake-news sharers, predict those most likely to share fake\nnews, and identify promising constructs to build interventions. Our research\nincludes studies along these lines. In Study 1, we explore the distinctive\nlanguage patterns of fake-news sharers, highlighting elements such as their\nhigher use of anger and power-related words. In Study 2, we show that adding\ntextual cues into predictive models enhances their accuracy in predicting\nfake-news sharers. In Study 3, we explore the contrasting role of trait and\nsituational anger, and show trait anger is associated with a greater propensity\nto share both true and fake news. In Study 4, we introduce a way to\nauthenticate Twitter accounts in surveys, before using it to explore how\ncrafting an ad copy that resonates with users' sense of power encourages the\nadoption of fact-checking tools. We hope to encourage the use of novel research\nmethods for marketers and misinformation researchers.", "published": "2022-03-20 14:26:20", "link": "http://arxiv.org/abs/2203.10560v3", "categories": ["cs.CY", "cs.CL", "cs.SI"], "primary_category": "cs.CY"}
{"title": "Small Batch Sizes Improve Training of Low-Resource Neural MT", "abstract": "We study the role of an essential hyper-parameter that governs the training\nof Transformers for neural machine translation in a low-resource setting: the\nbatch size. Using theoretical insights and experimental evidence, we argue\nagainst the widespread belief that batch size should be set as large as allowed\nby the memory of the GPUs. We show that in a low-resource setting, a smaller\nbatch size leads to higher scores in a shorter training time, and argue that\nthis is due to better regularization of the gradients during training.", "published": "2022-03-20 15:14:39", "link": "http://arxiv.org/abs/2203.10579v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Differentiable Reasoning over Long Stories -- Assessing Systematic\n  Generalisation in Neural Models", "abstract": "Contemporary neural networks have achieved a series of developments and\nsuccesses in many aspects; however, when exposed to data outside the training\ndistribution, they may fail to predict correct answers. In this work, we were\nconcerned about this generalisation issue and thus analysed a broad set of\nmodels systematically and robustly over long stories. Related experiments were\nconducted based on the CLUTRR, which is a diagnostic benchmark suite that can\nanalyse generalisation of natural language understanding (NLU) systems by\ntraining over small story graphs and testing on larger ones. In order to handle\nthe multi-relational story graph, we consider two classes of neural models:\n\"E-GNN\", the graph-based models that can process graph-structured data and\nconsider the edge attributes simultaneously; and \"L-Graph\", the sequence-based\nmodels which can process linearized version of the graphs. We performed an\nextensive empirical evaluation, and we found that the modified recurrent neural\nnetwork yield surprisingly accurate results across every systematic\ngeneralisation tasks which outperform the modified graph neural network, while\nthe latter produced more robust models.", "published": "2022-03-20 18:34:42", "link": "http://arxiv.org/abs/2203.10620v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Immersive Text Game and Personality Classification", "abstract": "We designed and built a game called \\textit{Immersive Text Game}, which\nallows the player to choose a story and a character, and interact with other\ncharacters in the story in an immersive manner of dialogues. The game is based\non several latest models, including text generation language model, information\nextraction model, commonsense reasoning model, and psychology evaluation model.\nIn the past, similar text games usually let players choose from limited actions\ninstead of answering on their own, and not every time what characters said are\ndetermined by the player. Through the combination of these models and elaborate\ngame mechanics and modes, the player will find some novel experiences as driven\nthrough the storyline.", "published": "2022-03-20 18:37:03", "link": "http://arxiv.org/abs/2203.10621v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Vocal effort modeling in neural TTS for improving the intelligibility of\n  synthetic speech in noise", "abstract": "We present a neural text-to-speech (TTS) method that models natural vocal\neffort variation to improve the intelligibility of synthetic speech in the\npresence of noise. The method consists of first measuring the spectral tilt of\nunlabeled conventional speech data, and then conditioning a neural TTS model\nwith normalized spectral tilt among other prosodic factors. Changing the\nspectral tilt parameter and keeping other prosodic factors unchanged enables\neffective vocal effort control at synthesis time independent of other prosodic\nfactors. By extrapolation of the spectral tilt values beyond what has been seen\nin the original data, we can generate speech with high vocal effort levels,\nthus improving the intelligibility of speech in the presence of masking noise.\nWe evaluate the intelligibility and quality of normal speech and speech with\nincreased vocal effort in the presence of various masking noise conditions, and\ncompare these to well-known speech intelligibility-enhancing algorithms. The\nevaluations show that the proposed method can improve the intelligibility of\nsynthetic speech with little loss in speech quality.", "published": "2022-03-20 20:16:11", "link": "http://arxiv.org/abs/2203.10637v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Study on Robustness to Perturbations for Representations of\n  Environmental Sound", "abstract": "Audio applications involving environmental sound analysis increasingly use\ngeneral-purpose audio representations, also known as embeddings, for transfer\nlearning. Recently, Holistic Evaluation of Audio Representations (HEAR)\nevaluated twenty-nine embedding models on nineteen diverse tasks. However, the\nevaluation's effectiveness depends on the variation already captured within a\ngiven dataset. Therefore, for a given data domain, it is unclear how the\nrepresentations would be affected by the variations caused by myriad\nmicrophones' range and acoustic conditions -- commonly known as channel\neffects. We aim to extend HEAR to evaluate invariance to channel effects in\nthis work. To accomplish this, we imitate channel effects by injecting\nperturbations to the audio signal and measure the shift in the new (perturbed)\nembeddings with three distance measures, making the evaluation domain-dependent\nbut not task-dependent. Combined with the downstream performance, it helps us\nmake a more informed prediction of how robust the embeddings are to the channel\neffects. We evaluate two embeddings -- YAMNet, and OpenL3 on monophonic\n(UrbanSound8K) and polyphonic (SONYC-UST) urban datasets. We show that one\ndistance measure does not suffice in such task-independent evaluation. Although\nFr\\'echet Audio Distance (FAD) correlates with the trend of the performance\ndrop in the downstream task most accurately, we show that we need to study FAD\nin conjunction with the other distances to get a clear understanding of the\noverall effect of the perturbation. In terms of the embedding performance, we\nfind OpenL3 to be more robust than YAMNet, which aligns with the HEAR\nevaluation.", "published": "2022-03-20 01:04:38", "link": "http://arxiv.org/abs/2203.10425v3", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ECAPA-TDNN for Multi-speaker Text-to-speech Synthesis", "abstract": "In recent years, neural network based methods for multi-speaker\ntext-to-speech synthesis (TTS) have made significant progress. However, the\ncurrent speaker encoder models used in these methods still cannot capture\nenough speaker information. In this paper, we focus on accurate speaker encoder\nmodeling and propose an end-to-end method that can generate high-quality speech\nand better similarity for both seen and unseen speakers. The proposed\narchitecture consists of three separately trained components: a speaker encoder\nbased on the state-of-the-art ECAPA-TDNN model which is derived from speaker\nverification task, a FastSpeech2 based synthesizer, and a HiFi-GAN vocoder. The\ncomparison among different speaker encoder models shows our proposed method can\nachieve better naturalness and similarity. To efficiently evaluate our\nsynthesized speech, we are the first to adopt deep learning based automatic MOS\nevaluation methods to assess our results, and these methods show great\npotential in automatic speech quality assessment.", "published": "2022-03-20 07:04:26", "link": "http://arxiv.org/abs/2203.10473v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Deep Learning based Intelligent Coin-tap Test for Defect Recognition", "abstract": "The coin-tap test is a convenient and primary method for non-destructive\ntesting, while its manual on-site operation is tough and costly. With the help\nof the latest intelligent signal processing method, convolutional neural\nnetworks (CNN), we achieve an intelligent coin-tap test which exhibited\nsuperior performance in recognizing the defects. However, this success of CNNs\nrelies on plenty of well-labeled data from the identical scenario, which could\nbe difficult to get for many real industrial practices. This paper further\ndevelops transfer learning strategies for this issue, that is, to transfer the\nmodel trained on data of one scenario to another. In experiments, the result\npresents a notable improvement by using domain adaptation and pseudo label\nlearning strategies. Hence, it becomes possible to apply the model into\nscenarios with none or little (less than 10\\%) labeled data adopting the\ntransfer learning strategies proposed herein. In addition, we used a benchmark\ndataset constructed ourselves throughout this study. This benchmark dataset for\nthe coin-tap test containing around 100,000 sound signals is published at\nhttps://github.com/PPhub-hy/torch-tapnet.", "published": "2022-03-20 04:48:52", "link": "http://arxiv.org/abs/2203.12594v1", "categories": ["eess.SP", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "eess.SP"}
