{"title": "Improving negation detection with negation-focused pre-training", "abstract": "Negation is a common linguistic feature that is crucial in many language\nunderstanding tasks, yet it remains a hard problem due to diversity in its\nexpression in different types of text. Recent work has shown that\nstate-of-the-art NLP models underperform on samples containing negation in\nvarious tasks, and that negation detection models do not transfer well across\ndomains. We propose a new negation-focused pre-training strategy, involving\ntargeted data augmentation and negation masking, to better incorporate negation\ninformation into language models. Extensive experiments on common benchmarks\nshow that our proposed approach improves negation detection performance and\ngeneralizability over the strong baseline NegBERT (Khandewal and Sawant, 2020).", "published": "2022-05-09 02:41:11", "link": "http://arxiv.org/abs/2205.04012v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ProQA: Structural Prompt-based Pre-training for Unified Question\n  Answering", "abstract": "Question Answering (QA) is a longstanding challenge in natural language\nprocessing. Existing QA works mostly focus on specific question types,\nknowledge domains, or reasoning skills. The specialty in QA research hinders\nsystems from modeling commonalities between tasks and generalization for wider\napplications. To address this issue, we present ProQA, a unified QA paradigm\nthat solves various tasks through a single model. ProQA takes a unified\nstructural prompt as the bridge and improves the QA-centric ability by\nstructural prompt-based pre-training. Through a structurally designed\nprompt-based input schema, ProQA concurrently models the knowledge\ngeneralization for all QA tasks while keeping the knowledge customization for\nevery specific QA task. Furthermore, ProQA is pre-trained with structural\nprompt-formatted large-scale synthesized corpus, which empowers the model with\nthe commonly-required QA ability. Experimental results on 11 QA benchmarks\ndemonstrate that ProQA consistently boosts performance on both full data\nfine-tuning, few-shot learning, and zero-shot testing scenarios. Furthermore,\nProQA exhibits strong ability in both continual learning and transfer learning\nby taking the advantages of the structural prompt.", "published": "2022-05-09 04:59:26", "link": "http://arxiv.org/abs/2205.04040v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few-shot Mining of Naturally Occurring Inputs and Outputs", "abstract": "Creating labeled natural language training data is expensive and requires\nsignificant human effort. We mine input output examples from large corpora\nusing a supervised mining function trained using a small seed set of only 100\nexamples. The mining consists of two stages -- (1) a biencoder-based\nrecall-oriented dense search which pairs inputs with potential outputs, and (2)\na crossencoder-based filter which re-ranks the output of the biencoder stage\nfor better precision. Unlike model-generated data augmentation, our method\nmines naturally occurring high-quality input output pairs to mimic the style of\nthe seed set for multiple tasks. On SQuAD-style reading comprehension,\naugmenting the seed set with the mined data results in an improvement of 13 F1\nover a BART-large baseline fine-tuned only on the seed set. Likewise, we see\nimprovements of 1.46 ROUGE-L on Xsum abstractive summarization.", "published": "2022-05-09 05:40:52", "link": "http://arxiv.org/abs/2205.04050v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sub-Word Alignment Is Still Useful: A Vest-Pocket Method for Enhancing\n  Low-Resource Machine Translation", "abstract": "We leverage embedding duplication between aligned sub-words to extend the\nParent-Child transfer learning method, so as to improve low-resource machine\ntranslation. We conduct experiments on benchmark datasets of My-En, Id-En and\nTr-En translation scenarios. The test results show that our method produces\nsubstantial improvements, achieving the BLEU scores of 22.5, 28.0 and 18.1\nrespectively. In addition, the method is computationally efficient which\nreduces the consumption of training time by 63.8%, reaching the duration of 1.6\nhours when training on a Tesla 16GB P100 GPU. All the models and source codes\nin the experiments will be made publicly available to support reproducible\nresearch.", "published": "2022-05-09 06:44:24", "link": "http://arxiv.org/abs/2205.04067v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automated Evaluation for Student Argumentative Writing: A Survey", "abstract": "This paper surveys and organizes research works in an under-studied area,\nwhich we call automated evaluation for student argumentative writing. Unlike\ntraditional automated writing evaluation that focuses on holistic essay\nscoring, this field is more specific: it focuses on evaluating argumentative\nessays and offers specific feedback, including argumentation structures,\nargument strength trait score, etc. The focused and detailed evaluation is\nuseful for helping students acquire important argumentation skill. In this\npaper we organize existing works around tasks, data and methods. We further\nexperiment with BERT on representative datasets, aiming to provide up-to-date\nbaselines for this field.", "published": "2022-05-09 07:27:59", "link": "http://arxiv.org/abs/2205.04083v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "So Different Yet So Alike! Constrained Unsupervised Text Style Transfer", "abstract": "Automatic transfer of text between domains has become popular in recent\ntimes. One of its aims is to preserve the semantic content of text being\ntranslated from source to target domain. However, it does not explicitly\nmaintain other attributes between the source and translated text, for e.g.,\ntext length and descriptiveness. Maintaining constraints in transfer has\nseveral downstream applications, including data augmentation and de-biasing. We\nintroduce a method for such constrained unsupervised text style transfer by\nintroducing two complementary losses to the generative adversarial network\n(GAN) family of models. Unlike the competing losses used in GANs, we introduce\ncooperative losses where the discriminator and the generator cooperate and\nreduce the same loss. The first is a contrastive loss and the second is a\nclassification loss, aiming to regularize the latent space further and bring\nsimilar sentences across domains closer together. We demonstrate that such\ntraining retains lexical, syntactic, and domain-specific constraints between\ndomains for multiple benchmark datasets, including ones where more than one\nattribute change. We show that the complementary cooperative losses improve\ntext quality, according to both automated and human evaluation measures.", "published": "2022-05-09 07:46:40", "link": "http://arxiv.org/abs/2205.04093v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Counterfactually Augmented Data and Unintended Bias: The Case of Sexism\n  and Hate Speech Detection", "abstract": "Counterfactually Augmented Data (CAD) aims to improve out-of-domain\ngeneralizability, an indicator of model robustness. The improvement is credited\nwith promoting core features of the construct over spurious artifacts that\nhappen to correlate with it. Yet, over-relying on core features may lead to\nunintended model bias. Especially, construct-driven CAD -- perturbations of\ncore features -- may induce models to ignore the context in which core features\nare used. Here, we test models for sexism and hate speech detection on\nchallenging data: non-hateful and non-sexist usage of identity and gendered\nterms. In these hard cases, models trained on CAD, especially construct-driven\nCAD, show higher false-positive rates than models trained on the original,\nunperturbed data. Using a diverse set of CAD -- construct-driven and\nconstruct-agnostic -- reduces such unintended bias.", "published": "2022-05-09 12:39:26", "link": "http://arxiv.org/abs/2205.04238v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EASE: Entity-Aware Contrastive Learning of Sentence Embedding", "abstract": "We present EASE, a novel method for learning sentence embeddings via\ncontrastive learning between sentences and their related entities. The\nadvantage of using entity supervision is twofold: (1) entities have been shown\nto be a strong indicator of text semantics and thus should provide rich\ntraining signals for sentence embeddings; (2) entities are defined\nindependently of languages and thus offer useful cross-lingual alignment\nsupervision. We evaluate EASE against other unsupervised models both in\nmonolingual and multilingual settings. We show that EASE exhibits competitive\nor better performance in English semantic textual similarity (STS) and short\ntext clustering (STC) tasks and it significantly outperforms baseline methods\nin multilingual settings on a variety of tasks. Our source code, pre-trained\nmodels, and newly constructed multilingual STC dataset are available at\nhttps://github.com/studio-ousia/ease.", "published": "2022-05-09 13:22:44", "link": "http://arxiv.org/abs/2205.04260v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ISA-bEL: Intelligent Search Algorithm based on Entity Linking", "abstract": "Nowadays, the way in which the people interact with computers has changed.\nText- or voice-based interfaces are being widely applied in different\nindustries. Among the most used ways of processing the user input are those\nbased on intents or retrieval algorithms. In these solutions, important\ninformation of the user could be lost in the process. For the proposed natural\nlanguage processing pipeline the entities are going to take a principal role,\nunder the assumption that entities are where the purpose of the user resides.\nEntities fed with context will be projected to a specific domain supported by a\nknowledge graph, resulting in what has been named as linked entities. These\nlinked entities serve then as a key for searching a top level aggregation\nconcept within our knowledge graph.", "published": "2022-05-09 14:26:52", "link": "http://arxiv.org/abs/2205.04322v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "XSTEM: An exemplar-based stemming algorithm", "abstract": "Stemming is the process of reducing related words to a standard form by\nremoving affixes from them. Existing algorithms vary with respect to their\ncomplexity, configurability, handling of unknown words, and ability to avoid\nunder- and over-stemming. This paper presents a fast, simple, configurable,\nhigh-precision, high-recall stemming algorithm that combines the simplicity and\nperformance of word-based lookup tables with the strong generalizability of\nrule-based methods to avert problems with out-of-vocabulary words.", "published": "2022-05-09 14:58:34", "link": "http://arxiv.org/abs/2205.04355v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Behind the Mask: Demographic bias in name detection for PII masking", "abstract": "Many datasets contain personally identifiable information, or PII, which\nposes privacy risks to individuals. PII masking is commonly used to redact\npersonal information such as names, addresses, and phone numbers from text\ndata. Most modern PII masking pipelines involve machine learning algorithms.\nHowever, these systems may vary in performance, such that individuals from\nparticular demographic groups bear a higher risk for having their personal\ninformation exposed. In this paper, we evaluate the performance of three\noff-the-shelf PII masking systems on name detection and redaction. We generate\ndata using names and templates from the customer service domain. We find that\nan open-source RoBERTa-based system shows fewer disparities than the commercial\nmodels we test. However, all systems demonstrate significant differences in\nerror rate based on demographics. In particular, the highest error rates\noccurred for names associated with Black and Asian/Pacific Islander\nindividuals.", "published": "2022-05-09 18:21:41", "link": "http://arxiv.org/abs/2205.04505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Slot Schema Induction for Task-oriented Dialog", "abstract": "Carefully-designed schemas describing how to collect and annotate dialog\ncorpora are a prerequisite towards building task-oriented dialog systems. In\npractical applications, manually designing schemas can be error-prone,\nlaborious, iterative, and slow, especially when the schema is complicated. To\nalleviate this expensive and time consuming process, we propose an unsupervised\napproach for slot schema induction from unlabeled dialog corpora. Leveraging\nin-domain language models and unsupervised parsing structures, our data-driven\napproach extracts candidate slots without constraints, followed by\ncoarse-to-fine clustering to induce slot types. We compare our method against\nseveral strong supervised baselines, and show significant performance\nimprovement in slot schema induction on MultiWoz and SGD datasets. We also\ndemonstrate the effectiveness of induced schemas on downstream applications\nincluding dialog state tracking and response generation.", "published": "2022-05-09 18:36:25", "link": "http://arxiv.org/abs/2205.04515v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Frictional Authors", "abstract": "I present a method for text analysis based on an analogy with the dynamic\nfriction of sliding surfaces. One surface is an array of points with a\n'friction coefficient' derived from the distribution frequency of a text's\nalphabetic characters. The other surface is a test patch having points with\nthis friction coefficient equal to a median value. Examples are presented from\nan analysis of a broad range of public domain texts, and comparison is made to\nthe Flesch Reading Ease. Source code for the analysis program is provided.", "published": "2022-05-09 00:37:23", "link": "http://arxiv.org/abs/2206.05016v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Construction and Evaluation of the LEAFTOP Dataset of Automatically\n  Extracted Nouns in 1480 Languages", "abstract": "The LEAFTOP (language extracted automatically from thousands of passages)\ndataset consists of nouns that appear in multiple places in the four gospels of\nthe New Testament. We use a naive approach -- probabilistic inference -- to\nidentify likely translations in 1480 other languages. We evaluate this process\nand find that it provides lexiconaries with accuracy from 42% (Korafe) to 99%\n(Runyankole), averaging 72% correct across evaluated languages. The process\ntranslates up to 161 distinct lemmas from Koine Greek (average 159). We\nidentify nouns which appear to be easy and hard to translate, language families\nwhere this technique works, and future possible improvements and extensions.\nThe claims to novelty are: the use of a Koine Greek New Testament as the source\nlanguage; using a fully-annotated manually-created grammatically parse of the\nsource text; a custom scraper for texts in the target languages; a new metric\nfor language similarity; a novel strategy for evaluation on low-resource\nlanguages.", "published": "2022-05-09 01:09:41", "link": "http://arxiv.org/abs/2206.05034v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ACM -- Attribute Conditioning for Abstractive Multi Document\n  Summarization", "abstract": "Abstractive multi document summarization has evolved as a task through the\nbasic sequence to sequence approaches to transformer and graph based\ntechniques. Each of these approaches has primarily focused on the issues of\nmulti document information synthesis and attention based approaches to extract\nsalient information. A challenge that arises with multi document summarization\nwhich is not prevalent in single document summarization is the need to\neffectively summarize multiple documents that might have conflicting polarity,\nsentiment or subjective information about a given topic. In this paper we\npropose ACM, attribute conditioned multi document summarization,a model that\nincorporates attribute conditioning modules in order to decouple conflicting\ninformation by conditioning for a certain attribute in the output summary. This\napproach shows strong gains in ROUGE score over baseline multi document\nsummarization approaches and shows gains in fluency, informativeness and\nreduction in repetitiveness as shown through a human annotation analysis study.", "published": "2022-05-09 00:00:14", "link": "http://arxiv.org/abs/2205.03978v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Data Augmentation with Paraphrase Generation and Entity Extraction for\n  Multimodal Dialogue System", "abstract": "Contextually aware intelligent agents are often required to understand the\nusers and their surroundings in real-time. Our goal is to build Artificial\nIntelligence (AI) systems that can assist children in their learning process.\nWithin such complex frameworks, Spoken Dialogue Systems (SDS) are crucial\nbuilding blocks to handle efficient task-oriented communication with children\nin game-based learning settings. We are working towards a multimodal dialogue\nsystem for younger kids learning basic math concepts. Our focus is on improving\nthe Natural Language Understanding (NLU) module of the task-oriented SDS\npipeline with limited datasets. This work explores the potential benefits of\ndata augmentation with paraphrase generation for the NLU models trained on\nsmall task-specific datasets. We also investigate the effects of extracting\nentities for conceivably further data expansion. We have shown that\nparaphrasing with model-in-the-loop (MITL) strategies using small seed data is\na promising approach yielding improved performance results for the Intent\nRecognition task.", "published": "2022-05-09 02:21:20", "link": "http://arxiv.org/abs/2205.04006v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CoCoA-MT: A Dataset and Benchmark for Contrastive Controlled MT with\n  Application to Formality", "abstract": "The machine translation (MT) task is typically formulated as that of\nreturning a single translation for an input segment. However, in many cases,\nmultiple different translations are valid and the appropriate translation may\ndepend on the intended target audience, characteristics of the speaker, or even\nthe relationship between speakers. Specific problems arise when dealing with\nhonorifics, particularly translating from English into languages with formality\nmarkers. For example, the sentence \"Are you sure?\" can be translated in German\nas \"Sind Sie sich sicher?\" (formal register) or \"Bist du dir sicher?\"\n(informal). Using wrong or inconsistent tone may be perceived as inappropriate\nor jarring for users of certain cultures and demographics. This work addresses\nthe problem of learning to control target language attributes, in this case\nformality, from a small amount of labeled contrastive data. We introduce an\nannotated dataset (CoCoA-MT) and an associated evaluation metric for training\nand evaluating formality-controlled MT models for six diverse target languages.\nWe show that we can train formality-controlled models by fine-tuning on labeled\ncontrastive data, achieving high accuracy (82% in-domain and 73% out-of-domain)\nwhile maintaining overall quality.", "published": "2022-05-09 04:05:36", "link": "http://arxiv.org/abs/2205.04022v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Balanced Data Approach for Evaluating Cross-Lingual Transfer: Mapping\n  the Linguistic Blood Bank", "abstract": "We show that the choice of pretraining languages affects downstream\ncross-lingual transfer for BERT-based models. We inspect zero-shot performance\nin balanced data conditions to mitigate data size confounds, classifying\npretraining languages that improve downstream performance as donors, and\nlanguages that are improved in zero-shot performance as recipients. We develop\na method of quadratic time complexity in the number of languages to estimate\nthese relations, instead of an exponential exhaustive computation of all\npossible combinations. We find that our method is effective on a diverse set of\nlanguages spanning different linguistic features and two downstream tasks. Our\nfindings can inform developers of large-scale multilingual language models in\nchoosing better pretraining configurations.", "published": "2022-05-09 07:32:50", "link": "http://arxiv.org/abs/2205.04086v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Task-specific Compression for Multi-task Language Models using\n  Attribution-based Pruning", "abstract": "Multi-task language models show outstanding performance for various natural\nlanguage understanding tasks with only a single model. However, these language\nmodels utilize an unnecessarily large number of model parameters, even when\nused only for a specific task. This paper proposes a novel training-free\ncompression method for multi-task language models using a pruning method.\nSpecifically, we use an attribution method to determine which neurons are\nessential for performing a specific task. We task-specifically prune\nunimportant neurons and leave only task-specific parameters. Furthermore, we\nextend our method to be applicable in low-resource and unsupervised settings.\nSince our compression method is training-free, it uses few computing resources\nand does not destroy the pre-trained knowledge of language models. Experimental\nresults on the six widely-used datasets show that our proposed pruning method\nsignificantly outperforms baseline pruning methods. In addition, we demonstrate\nthat our method preserves performance even in an unseen domain setting.", "published": "2022-05-09 10:12:08", "link": "http://arxiv.org/abs/2205.04157v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing Cross-lingual Transfer by Manifold Mixup", "abstract": "Based on large-scale pre-trained multilingual representations, recent\ncross-lingual transfer methods have achieved impressive transfer performances.\nHowever, the performance of target languages still lags far behind the source\nlanguage. In this paper, our analyses indicate such a performance gap is\nstrongly associated with the cross-lingual representation discrepancy. To\nachieve better cross-lingual transfer performance, we propose the cross-lingual\nmanifold mixup (X-Mixup) method, which adaptively calibrates the representation\ndiscrepancy and gives a compromised representation for target languages.\nExperiments on the XTREME benchmark show X-Mixup achieves 1.8% performance\ngains on multiple text understanding tasks, compared with strong baselines, and\nsignificantly reduces the cross-lingual representation discrepancy.", "published": "2022-05-09 10:49:07", "link": "http://arxiv.org/abs/2205.04182v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Dataset and BERT-based Models for Targeted Sentiment Analysis on\n  Turkish Texts", "abstract": "Targeted Sentiment Analysis aims to extract sentiment towards a particular\ntarget from a given text. It is a field that is attracting attention due to the\nincreasing accessibility of the Internet, which leads people to generate an\nenormous amount of data. Sentiment analysis, which in general requires\nannotated data for training, is a well-researched area for widely studied\nlanguages such as English. For low-resource languages such as Turkish, there is\na lack of such annotated data. We present an annotated Turkish dataset suitable\nfor targeted sentiment analysis. We also propose BERT-based models with\ndifferent architectures to accomplish the task of targeted sentiment analysis.\nThe results demonstrate that the proposed models outperform the traditional\nsentiment analysis models for the targeted sentiment analysis task.", "published": "2022-05-09 10:57:39", "link": "http://arxiv.org/abs/2205.04185v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Long Document Re-ranking with Modular Re-ranker", "abstract": "Long document re-ranking has been a challenging problem for neural re-rankers\nbased on deep language models like BERT. Early work breaks the documents into\nshort passage-like chunks. These chunks are independently mapped to scalar\nscores or latent vectors, which are then pooled into a final relevance score.\nThese encode-and-pool methods however inevitably introduce an information\nbottleneck: the low dimension representations. In this paper, we propose\ninstead to model full query-to-document interaction, leveraging the attention\noperation and modular Transformer re-ranker framework. First, document chunks\nare encoded independently with an encoder module. An interaction module then\nencodes the query and performs joint attention from the query to all document\nchunk representations. We demonstrate that the model can use this new degree of\nfreedom to aggregate important information from the entire document. Our\nexperiments show that this design produces effective re-ranking on two\nclassical IR collections Robust04 and ClueWeb09, and a large-scale supervised\ncollection MS-MARCO document ranking.", "published": "2022-05-09 13:44:02", "link": "http://arxiv.org/abs/2205.04275v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "CounterGeDi: A controllable approach to generate polite, detoxified and\n  emotional counterspeech", "abstract": "Recently, many studies have tried to create generation models to assist\ncounter speakers by providing counterspeech suggestions for combating the\nexplosive proliferation of online hate. However, since these suggestions are\nfrom a vanilla generation model, they might not include the appropriate\nproperties required to counter a particular hate speech instance. In this\npaper, we propose CounterGeDi - an ensemble of generative discriminators (GeDi)\nto guide the generation of a DialoGPT model toward more polite, detoxified, and\nemotionally laden counterspeech. We generate counterspeech using three datasets\nand observe significant improvement across different attribute scores. The\npoliteness and detoxification scores increased by around 15% and 6%\nrespectively, while the emotion in the counterspeech increased by at least 10%\nacross all the datasets. We also experiment with triple-attribute control and\nobserve significant improvement over single attribute results when combining\ncomplementing attributes, e.g., politeness, joyfulness and detoxification. In\nall these experiments, the relevancy of the generated text does not deteriorate\ndue to the application of these controls", "published": "2022-05-09 14:10:57", "link": "http://arxiv.org/abs/2205.04304v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "A Song of (Dis)agreement: Evaluating the Evaluation of Explainable\n  Artificial Intelligence in Natural Language Processing", "abstract": "There has been significant debate in the NLP community about whether or not\nattention weights can be used as an explanation - a mechanism for interpreting\nhow important each input token is for a particular prediction. The validity of\n\"attention as explanation\" has so far been evaluated by computing the rank\ncorrelation between attention-based explanations and existing feature\nattribution explanations using LSTM-based models. In our work, we (i) compare\nthe rank correlation between five more recent feature attribution methods and\ntwo attention-based methods, on two types of NLP tasks, and (ii) extend this\nanalysis to also include transformer-based models. We find that attention-based\nexplanations do not correlate strongly with any recent feature attribution\nmethods, regardless of the model or task. Furthermore, we find that none of the\ntested explanations correlate strongly with one another for the\ntransformer-based model, leading us to question the underlying assumption that\nwe should measure the validity of attention-based explanations based on how\nwell they correlate with existing feature attribution explanation methods.\nAfter conducting experiments on five datasets using two different models, we\nargue that the community should stop using rank correlation as an evaluation\nmetric for attention-based explanations. We suggest that researchers and\npractitioners should instead test various explanation methods and employ a\nhuman-in-the-loop process to determine if the explanations align with human\nintuition for the particular use case at hand.", "published": "2022-05-09 21:07:39", "link": "http://arxiv.org/abs/2205.04559v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Unified Model for Reverse Dictionary and Definition Modelling", "abstract": "We build a dual-way neural dictionary to retrieve words given definitions,\nand produce definitions for queried words. The model learns the two tasks\nsimultaneously and handles unknown words via embeddings. It casts a word or a\ndefinition to the same representation space through a shared layer, then\ngenerates the other form in a multi-task fashion. Our method achieves promising\nautomatic scores on previous benchmarks without extra resources. Human\nannotators prefer the model's outputs in both reference-less and\nreference-based evaluation, indicating its practicality. Analysis suggests that\nmultiple objectives benefit learning.", "published": "2022-05-09 23:52:39", "link": "http://arxiv.org/abs/2205.04602v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database", "abstract": "The emotional state of a speaker can be influenced by many different factors\nin dialogues, such as dialogue scene, dialogue topic, and interlocutor\nstimulus. The currently available data resources to support such multimodal\naffective analysis in dialogues are however limited in scale and diversity. In\nthis work, we propose a Multi-modal Multi-scene Multi-label Emotional Dialogue\ndataset, M3ED, which contains 990 dyadic emotional dialogues from 56 different\nTV series, a total of 9,082 turns and 24,449 utterances. M3 ED is annotated\nwith 7 emotion categories (happy, surprise, sad, disgust, anger, fear, and\nneutral) at utterance level, and encompasses acoustic, visual, and textual\nmodalities. To the best of our knowledge, M3ED is the first multimodal\nemotional dialogue dataset in Chinese. It is valuable for cross-culture emotion\nanalysis and recognition. We apply several state-of-the-art methods on the M3ED\ndataset to verify the validity and quality of the dataset. We also propose a\ngeneral Multimodal Dialogue-aware Interaction framework, MDI, to model the\ndialogue context for emotion recognition, which achieves comparable performance\nto the state-of-the-art methods on the M3ED. The full dataset and codes are\navailable.", "published": "2022-05-09 06:52:51", "link": "http://arxiv.org/abs/2205.10237v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Empathetic Conversational Systems: A Review of Current Advances, Gaps,\n  and Opportunities", "abstract": "Empathy is a vital factor that contributes to mutual understanding, and joint\nproblem-solving. In recent years, a growing number of studies have recognized\nthe benefits of empathy and started to incorporate empathy in conversational\nsystems. We refer to this topic as empathetic conversational systems. To\nidentify the critical gaps and future opportunities in this topic, this paper\nexamines this rapidly growing field using five review dimensions: (i)\nconceptual empathy models and frameworks, (ii) adopted empathy-related\nconcepts, (iii) datasets and algorithmic techniques developed, (iv) evaluation\nstrategies, and (v) state-of-the-art approaches. The findings show that most\nstudies have centered on the use of the EMPATHETICDIALOGUES dataset, and the\ntext-based modality dominates research in this field. Studies mainly focused on\nextracting features from the messages of the users and the conversational\nsystems, with minimal emphasis on user modeling and profiling. Notably, studies\nthat have incorporated emotion causes, external knowledge, and affect matching\nin the response generation models, have obtained significantly better results.\nFor implementation in diverse real-world settings, we recommend that future\nstudies should address key gaps in areas of detecting and authenticating\nemotions at the entity level, handling multimodal inputs, displaying more\nnuanced empathetic behaviors, and encompassing additional dialogue system\nfeatures.", "published": "2022-05-09 05:19:48", "link": "http://arxiv.org/abs/2206.05017v2", "categories": ["cs.CL", "cs.AI", "I.2"], "primary_category": "cs.CL"}
{"title": "LayoutXLM vs. GNN: An Empirical Evaluation of Relation Extraction for\n  Documents", "abstract": "This paper investigates the Relation Extraction task in documents by\nbenchmarking two different neural network models: a multi-modal language model\n(LayoutXLM) and a Graph Neural Network: Edge Convolution Network (ECN). For\nthis benchmark, we use the XFUND dataset, released along with LayoutXLM. While\nboth models reach similar results, they both exhibit very different\ncharacteristics. This raises the question on how to integrate various\nmodalities in a neural network: by merging all modalities thanks to additional\npretraining (LayoutXLM), or in a cascaded way (ECN). We conclude by discussing\nsome methodological issues that must be considered for new datasets and task\ndefinition in the domain of Information Extraction with complex documents.", "published": "2022-05-09 13:36:09", "link": "http://arxiv.org/abs/2206.10304v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Building Machine Translation Systems for the Next Thousand Languages", "abstract": "In this paper we share findings from our effort to build practical machine\ntranslation (MT) systems capable of translating across over one thousand\nlanguages. We describe results in three research domains: (i) Building clean,\nweb-mined datasets for 1500+ languages by leveraging semi-supervised\npre-training for language identification and developing data-driven filtering\ntechniques; (ii) Developing practical MT models for under-served languages by\nleveraging massively multilingual models trained with supervised parallel data\nfor over 100 high-resource languages and monolingual datasets for an additional\n1000+ languages; and (iii) Studying the limitations of evaluation metrics for\nthese languages and conducting qualitative analysis of the outputs from our MT\nmodels, highlighting several frequent error modes of these types of models. We\nhope that our work provides useful insights to practitioners working towards\nbuilding MT systems for currently understudied languages, and highlights\nresearch directions that can complement the weaknesses of massively\nmultilingual models in data-sparse settings.", "published": "2022-05-09 00:24:13", "link": "http://arxiv.org/abs/2205.03983v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Approaches to the classification of complex systems: Words, texts, and\n  more", "abstract": "The Chapter starts with introductory information about quantitative\nlinguistics notions, like rank--frequency dependence, Zipf's law, frequency\nspectra, etc. Similarities in distributions of words in texts with level\noccupation in quantum ensembles hint at a superficial analogy with statistical\nphysics. This enables one to define various parameters for texts based on this\nphysical analogy, including \"temperature\", \"chemical potential\", entropy, and\nsome others. Such parameters provide a set of variables to classify texts\nserving as an example of complex systems. Moreover, texts are perhaps the\neasiest complex systems to collect and analyze.\n  Similar approaches can be developed to study, for instance, genomes due to\nwell-known linguistic analogies. We consider a couple of approaches to define\nnucleotide sequences in mitochondrial DNAs and viral RNAs and demonstrate their\npossible application as an auxiliary tool for comparative analysis of genomes.\n  Finally, we discuss entropy as one of the parameters, which can be easily\ncomputed from rank--frequency dependences. Being a discriminating parameter in\nsome problems of classification of complex systems, entropy can be given a\nproper interpretation only in a limited class of problems. Its overall role and\nsignificance remain an open issue so far.", "published": "2022-05-09 06:27:37", "link": "http://arxiv.org/abs/2205.04060v1", "categories": ["physics.data-an", "cond-mat.stat-mech", "cs.CL", "q-bio.OT"], "primary_category": "physics.data-an"}
{"title": "Re-thinking Knowledge Graph Completion Evaluation from an Information\n  Retrieval Perspective", "abstract": "Knowledge graph completion (KGC) aims to infer missing knowledge triples\nbased on known facts in a knowledge graph. Current KGC research mostly follows\nan entity ranking protocol, wherein the effectiveness is measured by the\npredicted rank of a masked entity in a test triple. The overall performance is\nthen given by a micro(-average) metric over all individual answer entities. Due\nto the incomplete nature of the large-scale knowledge bases, such an entity\nranking setting is likely affected by unlabelled top-ranked positive examples,\nraising questions on whether the current evaluation protocol is sufficient to\nguarantee a fair comparison of KGC systems. To this end, this paper presents a\nsystematic study on whether and how the label sparsity affects the current KGC\nevaluation with the popular micro metrics. Specifically, inspired by the TREC\nparadigm for large-scale information retrieval (IR) experimentation, we create\na relatively \"complete\" judgment set based on a sample from the popular\nFB15k-237 dataset following the TREC pooling method. According to our analysis,\nit comes as a surprise that switching from the original labels to our\n\"complete\" labels results in a drastic change of system ranking of a variety of\n13 popular KGC models in terms of micro metrics. Further investigation\nindicates that the IR-like macro(-average) metrics are more stable and\ndiscriminative under different settings, meanwhile, less affected by label\nsparsity. Thus, for KGC evaluation, we recommend conducting TREC-style pooling\nto balance between human efforts and label completeness, and reporting also the\nIR-like macro metrics to reflect the ranking nature of the KGC task.", "published": "2022-05-09 08:12:20", "link": "http://arxiv.org/abs/2205.04105v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Cross-Utterance Conditioned VAE for Non-Autoregressive Text-to-Speech", "abstract": "Modelling prosody variation is critical for synthesizing natural and\nexpressive speech in end-to-end text-to-speech (TTS) systems. In this paper, a\ncross-utterance conditional VAE (CUC-VAE) is proposed to estimate a posterior\nprobability distribution of the latent prosody features for each phoneme by\nconditioning on acoustic features, speaker information, and text features\nobtained from both past and future sentences. At inference time, instead of the\nstandard Gaussian distribution used by VAE, CUC-VAE allows sampling from an\nutterance-specific prior distribution conditioned on cross-utterance\ninformation, which allows the prosody features generated by the TTS system to\nbe related to the context and is more similar to how humans naturally produce\nprosody. The performance of CUC-VAE is evaluated via a qualitative listening\ntest for naturalness, intelligibility and quantitative measurements, including\nword error rates and the standard deviation of prosody attributes. Experimental\nresults on LJ-Speech and LibriTTS data show that the proposed CUC-VAE TTS\nsystem improves naturalness and prosody diversity with clear margins.", "published": "2022-05-09 08:39:53", "link": "http://arxiv.org/abs/2205.04120v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Detecting and Understanding Harmful Memes: A Survey", "abstract": "The automatic identification of harmful content online is of major concern\nfor social media platforms, policymakers, and society. Researchers have studied\ntextual, visual, and audio content, but typically in isolation. Yet, harmful\ncontent often combines multiple modalities, as in the case of memes, which are\nof particular interest due to their viral nature. With this in mind, here we\noffer a comprehensive survey with a focus on harmful memes. Based on a\nsystematic analysis of recent literature, we first propose a new typology of\nharmful memes, and then we highlight and summarize the relevant state of the\nart. One interesting finding is that many types of harmful memes are not really\nstudied, e.g., such featuring self-harm and extremism, partly due to the lack\nof suitable datasets. We further find that existing datasets mostly capture\nmulti-class scenarios, which are not inclusive of the affective spectrum that\nmemes can represent. Another observation is that memes can propagate globally\nthrough repackaging in different languages and that they can also be\nmultilingual, blending different cultures. We conclude by highlighting several\nchallenges related to multimodal semiotics, technological constraints, and\nnon-trivial social engagement, and we present several open-ended aspects such\nas delineating online harm and empirically examining related frameworks and\nassistive interventions, which we believe will motivate and drive future\nresearch.", "published": "2022-05-09 13:43:27", "link": "http://arxiv.org/abs/2205.04274v2", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Detecting the Role of an Entity in Harmful Memes: Techniques and Their\n  Limitations", "abstract": "Harmful or abusive online content has been increasing over time, raising\nconcerns for social media platforms, government agencies, and policymakers.\nSuch harmful or abusive content can have major negative impact on society,\ne.g., cyberbullying can lead to suicides, rumors about COVID-19 can cause\nvaccine hesitance, promotion of fake cures for COVID-19 can cause health harms\nand deaths. The content that is posted and shared online can be textual,\nvisual, or a combination of both, e.g., in a meme. Here, we describe our\nexperiments in detecting the roles of the entities (hero, villain, victim) in\nharmful memes, which is part of the CONSTRAINT-2022 shared task, as well as our\nsystem for the task. We further provide a comparative analysis of different\nexperimental settings (i.e., unimodal, multimodal, attention, and\naugmentation). For reproducibility, we make our experimental code publicly\navailable. \\url{https://github.com/robi56/harmful_memes_block_fusion}", "published": "2022-05-09 16:11:04", "link": "http://arxiv.org/abs/2205.04402v1", "categories": ["cs.CL", "cs.CV", "cs.MM", "cs.SI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "BLINK with Elasticsearch for Efficient Entity Linking in Business\n  Conversations", "abstract": "An Entity Linking system aligns the textual mentions of entities in a text to\ntheir corresponding entries in a knowledge base. However, deploying a neural\nentity linking system for efficient real-time inference in production\nenvironments is a challenging task. In this work, we present a neural entity\nlinking system that connects the product and organization type entities in\nbusiness conversations to their corresponding Wikipedia and Wikidata entries.\nThe proposed system leverages Elasticsearch to ensure inference efficiency when\ndeployed in a resource limited cloud machine, and obtains significant\nimprovements in terms of inference speed and memory consumption while retaining\nhigh accuracy.", "published": "2022-05-09 17:40:55", "link": "http://arxiv.org/abs/2205.04438v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "EigenNoise: A Contrastive Prior to Warm-Start Representations", "abstract": "In this work, we present a naive initialization scheme for word vectors based\non a dense, independent co-occurrence model and provide preliminary results\nthat suggest it is competitive and warrants further investigation.\nSpecifically, we demonstrate through information-theoretic minimum description\nlength (MDL) probing that our model, EigenNoise, can approach the performance\nof empirically trained GloVe despite the lack of any pre-training data (in the\ncase of EigenNoise). We present these preliminary results with interest to set\nthe stage for further investigations into how this competitive initialization\nworks without pre-training data, as well as to invite the exploration of more\nintelligent initialization schemes informed by the theory of harmonic\nlinguistic structure. Our application of this theory likewise contributes a\nnovel (and effective) interpretation of recent discoveries which have\nelucidated the underlying distributional information that linguistic\nrepresentations capture from data and contrast distributions.", "published": "2022-05-09 15:30:50", "link": "http://arxiv.org/abs/2205.04376v1", "categories": ["cs.CL", "cs.IT", "cs.LG", "math.IT", "stat.ML"], "primary_category": "cs.CL"}
{"title": "TeamX@DravidianLangTech-ACL2022: A Comparative Analysis for Troll-Based\n  Meme Classification", "abstract": "The spread of fake news, propaganda, misinformation, disinformation, and\nharmful content online raised concerns among social media platforms, government\nagencies, policymakers, and society as a whole. This is because such harmful or\nabusive content leads to several consequences to people such as physical,\nemotional, relational, and financial. Among different harmful content\n\\textit{trolling-based} online content is one of them, where the idea is to\npost a message that is provocative, offensive, or menacing with an intent to\nmislead the audience. The content can be textual, visual, a combination of\nboth, or a meme. In this study, we provide a comparative analysis of\ntroll-based memes classification using the textual, visual, and multimodal\ncontent. We report several interesting findings in terms of code-mixed text,\nmultimodal setting, and combining an additional dataset, which shows\nimprovements over the majority baseline.", "published": "2022-05-09 16:19:28", "link": "http://arxiv.org/abs/2205.04404v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.MM", "cs.SI", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level\n  Quality", "abstract": "Text to speech (TTS) has made rapid progress in both academia and industry in\nrecent years. Some questions naturally arise that whether a TTS system can\nachieve human-level quality, how to define/judge that quality and how to\nachieve it. In this paper, we answer these questions by first defining the\nhuman-level quality based on the statistical significance of subjective measure\nand introducing appropriate guidelines to judge it, and then developing a TTS\nsystem called NaturalSpeech that achieves human-level quality on a benchmark\ndataset. Specifically, we leverage a variational autoencoder (VAE) for\nend-to-end text to waveform generation, with several key modules to enhance the\ncapacity of the prior from text and reduce the complexity of the posterior from\nspeech, including phoneme pre-training, differentiable duration modeling,\nbidirectional prior/posterior modeling, and a memory mechanism in VAE.\nExperiment evaluations on popular LJSpeech dataset show that our proposed\nNaturalSpeech achieves -0.01 CMOS (comparative mean opinion score) to human\nrecordings at the sentence level, with Wilcoxon signed rank test at p-level p\n>> 0.05, which demonstrates no statistically significant difference from human\nrecordings for the first time on this dataset.", "published": "2022-05-09 16:57:35", "link": "http://arxiv.org/abs/2205.04421v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ReCAB-VAE: Gumbel-Softmax Variational Inference Based on Analytic\n  Divergence", "abstract": "The Gumbel-softmax distribution, or Concrete distribution, is often used to\nrelax the discrete characteristics of a categorical distribution and enable\nback-propagation through differentiable reparameterization. Although it\nreliably yields low variance gradients, it still relies on a stochastic\nsampling process for optimization. In this work, we present a relaxed\ncategorical analytic bound (ReCAB), a novel divergence-like metric which\ncorresponds to the upper bound of the Kullback-Leibler divergence (KLD) of a\nrelaxed categorical distribution. The proposed metric is easy to implement\nbecause it has a closed form solution, and empirical results show that it is\nclose to the actual KLD. Along with this new metric, we propose a relaxed\ncategorical analytic bound variational autoencoder (ReCAB-VAE) that\nsuccessfully models both continuous and relaxed discrete latent\nrepresentations. We implement an emotional text-to-speech synthesis system\nbased on the proposed framework, and show that the proposed system flexibly and\nstably controls emotion expressions with better speech quality compared to\nbaselines that use stochastic estimation or categorical distribution\napproximation.", "published": "2022-05-09 08:11:46", "link": "http://arxiv.org/abs/2205.04104v1", "categories": ["eess.AS", "cs.AI"], "primary_category": "eess.AS"}
{"title": "Bandwidth-Scalable Fully Mask-Based Deep FCRN Acoustic Echo Cancellation\n  and Postfiltering", "abstract": "Although today's speech communication systems support various bandwidths from\nnarrowband to super-wideband and beyond, state-of-the art DNN methods for\nacoustic echo cancellation (AEC) are lacking modularity and bandwidth\nscalability. Our proposed DNN model builds upon a fully convolutional recurrent\nnetwork (FCRN) and introduces scalability over various bandwidths up to a\nfullband (FB) system (48 kHz sampling rate). This modular approach allows joint\nwideband (WB) pre-training of mask-based AEC and postfilter stages with\ndedicated losses, followed by a separate training of them on FB data. A third\nlightweight blind bandwidth extension stage is separately trained on FB data,\nflexibly allowing to extend the WB postfilter output towards higher bandwidths\nuntil reaching FB. Thereby, higher frequency noise and echo are reliably\nsuppressed. On the ICASSP 2022 Acoustic Echo Cancellation Challenge blind test\nset we report a competitive performance, showing robustness even under highly\ndelayed echo and dynamic echo path changes.", "published": "2022-05-09 13:44:02", "link": "http://arxiv.org/abs/2205.04276v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Speaker Reinforcement Using Target Source Extraction for Robust\n  Automatic Speech Recognition", "abstract": "Improving the accuracy of single-channel automatic speech recognition (ASR)\nin noisy conditions is challenging. Strong speech enhancement front-ends are\navailable, however, they typically require that the ASR model is retrained to\ncope with the processing artifacts. In this paper we explore a speaker\nreinforcement strategy for improving recognition performance without retraining\nthe acoustic model (AM). This is achieved by remixing the enhanced signal with\nthe unprocessed input to alleviate the processing artifacts. We evaluate the\nproposed approach using a DNN speaker extraction based speech denoiser trained\nwith a perceptually motivated loss function. Results show that (without AM\nretraining) our method yields about 23% and 25% relative accuracy gains\ncompared with the unprocessed for the monoaural simulated and real CHiME-4\nevaluation sets, respectively, and outperforms a state-of-the-art reference\nmethod.", "published": "2022-05-09 17:34:41", "link": "http://arxiv.org/abs/2205.04433v1", "categories": ["eess.AS", "cs.SD", "68T10"], "primary_category": "eess.AS"}
{"title": "Deep Learning Enabled Semantic Communications with Speech Recognition\n  and Synthesis", "abstract": "In this paper, we develop a deep learning based semantic communication system\nfor speech transmission, named DeepSC-ST. We take the speech recognition and\nspeech synthesis as the transmission tasks of the communication system,\nrespectively. First, the speech recognition-related semantic features are\nextracted for transmission by a joint semantic-channel encoder and the text is\nrecovered at the receiver based on the received semantic features, which\nsignificantly reduces the required amount of data transmission without\nperformance degradation. Then, we perform speech synthesis at the receiver,\nwhich dedicates to re-generate the speech signals by feeding the recognized\ntext and the speaker information into a neural network module. To enable the\nDeepSC-ST adaptive to dynamic channel environments, we identify a robust model\nto cope with different channel conditions. According to the simulation results,\nthe proposed DeepSC-ST significantly outperforms conventional communication\nsystems and existing DL-enabled communication systems, especially in the low\nsignal-to-noise ratio (SNR) regime. A software demonstration is further\ndeveloped as a proof-of-concept of the DeepSC-ST.", "published": "2022-05-09 23:55:46", "link": "http://arxiv.org/abs/2205.04603v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Muskits: an End-to-End Music Processing Toolkit for Singing Voice\n  Synthesis", "abstract": "This paper introduces a new open-source platform named Muskits for end-to-end\nmusic processing, which mainly focuses on end-to-end singing voice synthesis\n(E2E-SVS). Muskits supports state-of-the-art SVS models, including RNN SVS,\ntransformer SVS, and XiaoiceSing. The design of Muskits follows the style of\nwidely-used speech processing toolkits, ESPnet and Kaldi, for data\nprepossessing, training, and recipe pipelines. To the best of our knowledge,\nthis toolkit is the first platform that allows a fair and highly-reproducible\ncomparison between several published works in SVS. In addition, we also\ndemonstrate several advanced usages based on the toolkit functionalities,\nincluding multilingual training and transfer learning. This paper describes the\nmajor framework of Muskits, its functionalities, and experimental results in\nsingle-singer, multi-singer, multilingual, and transfer learning scenarios. The\ntoolkit is publicly available at https://github.com/SJTMusicTeam/Muskits.", "published": "2022-05-09 04:25:47", "link": "http://arxiv.org/abs/2205.04029v2", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Insights on Modelling Physiological, Appraisal, and Affective Indicators\n  of Stress using Audio Features", "abstract": "Stress is a major threat to well-being that manifests in a variety of\nphysiological and mental symptoms. Utilising speech samples collected while the\nsubject is undergoing an induced stress episode has recently shown promising\nresults for the automatic characterisation of individual stress responses. In\nthis work, we introduce new findings that shed light onto whether speech\nsignals are suited to model physiological biomarkers, as obtained via cortisol\nmeasurements, or self-assessed appraisal and affect measurements. Our results\nshow that different indicators impact acoustic features in a diverse way, but\nthat their complimentary information can nevertheless be effectively harnessed\nby a multi-tasking architecture to improve prediction performance for all of\nthem.", "published": "2022-05-09 14:32:38", "link": "http://arxiv.org/abs/2205.04328v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Fatigue Prediction in Outdoor Running Conditions using Audio Data", "abstract": "Although running is a common leisure activity and a core training regiment\nfor several athletes, between $29\\%$ and $79\\%$ of runners sustain an overuse\ninjury each year. These injuries are linked to excessive fatigue, which alters\nhow someone runs. In this work, we explore the feasibility of modelling the\nBorg received perception of exertion (RPE) scale (range: $[6-20]$), a\nwell-validated subjective measure of fatigue, using audio data captured in\nrealistic outdoor environments via smartphones attached to the runners' arms.\nUsing convolutional neural networks (CNNs) on log-Mel spectrograms, we obtain a\nmean absolute error of $2.35$ in subject-dependent experiments, demonstrating\nthat audio can be effectively used to model fatigue, while being more easily\nand non-invasively acquired than by signals from other sensors.", "published": "2022-05-09 14:44:05", "link": "http://arxiv.org/abs/2205.04343v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
