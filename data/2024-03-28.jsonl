{"title": "Learning From Correctness Without Prompting Makes LLM Efficient Reasoner", "abstract": "Large language models (LLMs) have demonstrated outstanding performance across\nvarious tasks, yet they still exhibit limitations such as hallucination,\nunfaithful reasoning, and toxic content. One potential approach to mitigate\nthese issues is learning from human or external feedback (e.g. tools). In this\npaper, we introduce an intrinsic self-correct reasoning framework for LLMs that\neliminates the need for human feedback, external tools, and handcraft prompts.\nThe proposed framework, based on a multi-step reasoning paradigm\n\\textbf{Le}arning from \\textbf{Co}rrectness (\\textsc{LeCo}), improves reasoning\nperformance without needing to learn from errors. This paradigm prioritizes\nlearning from correct reasoning steps, and a unique method to measure\nconfidence for each reasoning step based on generation logits. Experimental\nresults across various multi-step reasoning tasks demonstrate the effectiveness\nof the framework in improving reasoning performance with reduced token\nconsumption.", "published": "2024-03-28 02:12:49", "link": "http://arxiv.org/abs/2403.19094v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code Comparison Tuning for Code Large Language Models", "abstract": "We present Code Comparison Tuning (CCT), a simple and effective tuning method\nfor code large language models (Code LLMs) to better handle subtle code errors.\nSpecifically, we integrate the concept of comparison into instruction tuning,\nboth at the token and sequence levels, enabling the model to discern even the\nslightest deviations in code. To compare the original code with an erroneous\nversion containing manually added code errors, we use token-level preference\nloss for detailed token-level comparisons. Additionally, we combine code\nsegments to create a new instruction tuning sample for sequence-level\ncomparisons, enhancing the model's bug-fixing capability. Experimental results\non the HumanEvalFix benchmark show that CCT surpasses instruction tuning in\npass@1 scores by up to 4 points across diverse code LLMs, and extensive\nanalysis demonstrates the effectiveness of our method.", "published": "2024-03-28 03:25:23", "link": "http://arxiv.org/abs/2403.19121v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Tulu Resource for Machine Translation", "abstract": "We present the first parallel dataset for English-Tulu translation. Tulu,\nclassified within the South Dravidian linguistic family branch, is\npredominantly spoken by approximately 2.5 million individuals in southwestern\nIndia. Our dataset is constructed by integrating human translations into the\nmultilingual machine translation resource FLORES-200. Furthermore, we use this\ndataset for evaluation purposes in developing our English-Tulu machine\ntranslation model. For the model's training, we leverage resources available\nfor related South Dravidian languages. We adopt a transfer learning approach\nthat exploits similarities between high-resource and low-resource languages.\nThis method enables the training of a machine translation system even in the\nabsence of parallel data between the source and target language, thereby\novercoming a significant obstacle in machine translation development for\nlow-resource languages. Our English-Tulu system, trained without using parallel\nEnglish-Tulu data, outperforms Google Translate by 19 BLEU points (in September\n2023). The dataset and code are available here:\nhttps://github.com/manunarayanan/Tulu-NMT.", "published": "2024-03-28 04:30:07", "link": "http://arxiv.org/abs/2403.19142v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Vietnamese-English Medical Machine Translation", "abstract": "Machine translation for Vietnamese-English in the medical domain is still an\nunder-explored research area. In this paper, we introduce MedEV -- a\nhigh-quality Vietnamese-English parallel dataset constructed specifically for\nthe medical domain, comprising approximately 360K sentence pairs. We conduct\nextensive experiments comparing Google Translate, ChatGPT (gpt-3.5-turbo),\nstate-of-the-art Vietnamese-English neural machine translation models and\npre-trained bilingual/multilingual sequence-to-sequence models on our new MedEV\ndataset. Experimental results show that the best performance is achieved by\nfine-tuning \"vinai-translate\" for each translation direction. We publicly\nrelease our dataset to promote further research.", "published": "2024-03-28 06:07:15", "link": "http://arxiv.org/abs/2403.19161v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Empirical Analysis for Unsupervised Universal Dependency Parse Tree\n  Aggregation", "abstract": "Dependency parsing is an essential task in NLP, and the quality of dependency\nparsers is crucial for many downstream tasks. Parsers' quality often varies\ndepending on the domain and the language involved. Therefore, it is essential\nto combat the issue of varying quality to achieve stable performance. In\nvarious NLP tasks, aggregation methods are used for post-processing aggregation\nand have been shown to combat the issue of varying quality. However,\naggregation methods for post-processing aggregation have not been sufficiently\nstudied in dependency parsing tasks. In an extensive empirical study, we\ncompare different unsupervised post-processing aggregation methods to identify\nthe most suitable dependency tree structure aggregation method.", "published": "2024-03-28 07:27:10", "link": "http://arxiv.org/abs/2403.19183v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Collaborative Knowledge Infusion for Low-resource Stance Detection", "abstract": "Stance detection is the view towards a specific target by a given context\n(\\textit{e.g.} tweets, commercial reviews). Target-related knowledge is often\nneeded to assist stance detection models in understanding the target well and\nmaking detection correctly. However, prevailing works for knowledge-infused\nstance detection predominantly incorporate target knowledge from a singular\nsource that lacks knowledge verification in limited domain knowledge. The\nlow-resource training data further increases the challenge for the data-driven\nlarge models in this task. To address those challenges, we propose a\ncollaborative knowledge infusion approach for low-resource stance detection\ntasks, employing a combination of aligned knowledge enhancement and efficient\nparameter learning techniques. Specifically, our stance detection approach\nleverages target background knowledge collaboratively from different knowledge\nsources with the help of knowledge alignment. Additionally, we also introduce\nthe parameter-efficient collaborative adaptor with a staged optimization\nalgorithm, which collaboratively addresses the challenges associated with\nlow-resource stance detection tasks from both network structure and learning\nperspectives. To assess the effectiveness of our method, we conduct extensive\nexperiments on three public stance detection datasets, including low-resource\nand cross-target settings. The results demonstrate significant performance\nimprovements compared to the existing stance detection approaches.", "published": "2024-03-28 08:32:14", "link": "http://arxiv.org/abs/2403.19219v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "J-CRe3: A Japanese Conversation Dataset for Real-world Reference\n  Resolution", "abstract": "Understanding expressions that refer to the physical world is crucial for\nsuch human-assisting systems in the real world, as robots that must perform\nactions that are expected by users. In real-world reference resolution, a\nsystem must ground the verbal information that appears in user interactions to\nthe visual information observed in egocentric views. To this end, we propose a\nmultimodal reference resolution task and construct a Japanese Conversation\ndataset for Real-world Reference Resolution (J-CRe3). Our dataset contains\negocentric video and dialogue audio of real-world conversations between two\npeople acting as a master and an assistant robot at home. The dataset is\nannotated with crossmodal tags between phrases in the utterances and the object\nbounding boxes in the video frames. These tags include indirect reference\nrelations, such as predicate-argument structures and bridging references as\nwell as direct reference relations. We also constructed an experimental model\nand clarified the challenges in multimodal reference resolution tasks.", "published": "2024-03-28 09:32:43", "link": "http://arxiv.org/abs/2403.19259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using\n  Representative Data", "abstract": "To address the global issue of online hate, hate speech detection (HSD)\nsystems are typically developed on datasets from the United States, thereby\nfailing to generalize to English dialects from the Majority World. Furthermore,\nHSD models are often evaluated on non-representative samples, raising concerns\nabout overestimating model performance in real-world settings. In this work, we\nintroduce NaijaHate, the first dataset annotated for HSD which contains a\nrepresentative sample of Nigerian tweets. We demonstrate that HSD evaluated on\nbiased datasets traditionally used in the literature consistently overestimates\nreal-world performance by at least two-fold. We then propose NaijaXLM-T, a\npretrained model tailored to the Nigerian Twitter context, and establish the\nkey role played by domain-adaptive pretraining and finetuning in maximizing HSD\nperformance. Finally, owing to the modest performance of HSD systems in\nreal-world conditions, we find that content moderators would need to review\nabout ten thousand Nigerian tweets flagged as hateful daily to moderate 60% of\nall hateful content, highlighting the challenges of moderating hate speech at\nscale as social media usage continues to grow globally. Taken together, these\nresults pave the way towards robust HSD systems and a better protection of\nsocial media users from hateful content in low-resource settings.", "published": "2024-03-28 09:34:31", "link": "http://arxiv.org/abs/2403.19260v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ungrammatical-syntax-based In-context Example Selection for Grammatical\n  Error Correction", "abstract": "In the era of large language models (LLMs), in-context learning (ICL) stands\nout as an effective prompting strategy that explores LLMs' potency across\nvarious tasks. However, applying LLMs to grammatical error correction (GEC) is\nstill a challenging task. In this paper, we propose a novel\nungrammatical-syntax-based in-context example selection strategy for GEC.\nSpecifically, we measure similarity of sentences based on their syntactic\nstructures with diverse algorithms, and identify optimal ICL examples sharing\nthe most similar ill-formed syntax to the test input. Additionally, we carry\nout a two-stage process to further improve the quality of selection results. On\nbenchmark English GEC datasets, empirical results show that our proposed\nungrammatical-syntax-based strategies outperform commonly-used word-matching or\nsemantics-based methods with multiple LLMs. This indicates that for a\nsyntax-oriented task like GEC, paying more attention to syntactic information\ncan effectively boost LLMs' performance. Our code will be publicly available\nafter the publication of this paper.", "published": "2024-03-28 10:05:57", "link": "http://arxiv.org/abs/2403.19283v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Going Beyond Word Matching: Syntax Improves In-context Example Selection\n  for Machine Translation", "abstract": "In-context learning (ICL) is the trending prompting strategy in the era of\nlarge language models (LLMs), where a few examples are demonstrated to evoke\nLLMs' power for a given task. How to select informative examples remains an\nopen issue. Previous works on in-context example selection for machine\ntranslation (MT) focus on superficial word-level features while ignoring deep\nsyntax-level knowledge. In this paper, we propose a syntax-based in-context\nexample selection method for MT, by computing the syntactic similarity between\ndependency trees using Polynomial Distance. In addition, we propose an ensemble\nstrategy combining examples selected by both word-level and syntax-level\ncriteria. Experimental results between English and 6 common languages indicate\nthat syntax can effectively enhancing ICL for MT, obtaining the highest COMET\nscores on 11 out of 12 translation directions.", "published": "2024-03-28 10:13:34", "link": "http://arxiv.org/abs/2403.19285v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond Borders: Investigating Cross-Jurisdiction Transfer in Legal Case\n  Summarization", "abstract": "Legal professionals face the challenge of managing an overwhelming volume of\nlengthy judgments, making automated legal case summarization crucial. However,\nprior approaches mainly focused on training and evaluating these models within\nthe same jurisdiction. In this study, we explore the cross-jurisdictional\ngeneralizability of legal case summarization models.Specifically, we explore\nhow to effectively summarize legal cases of a target jurisdiction where\nreference summaries are not available. In particular, we investigate whether\nsupplementing models with unlabeled target jurisdiction corpus and extractive\nsilver summaries obtained from unsupervised algorithms on target data enhances\ntransfer performance. Our comprehensive study on three datasets from different\njurisdictions highlights the role of pre-training in improving transfer\nperformance. We shed light on the pivotal influence of jurisdictional\nsimilarity in selecting optimal source datasets for effective transfer.\nFurthermore, our findings underscore that incorporating unlabeled target data\nyields improvements in general pre-trained models, with additional gains when\nsilver summaries are introduced. This augmentation is especially valuable when\ndealing with extractive datasets and scenarios featuring limited alignment\nbetween source and target jurisdictions. Our study provides key insights for\ndeveloping adaptable legal case summarization systems, transcending\njurisdictional boundaries.", "published": "2024-03-28 11:18:31", "link": "http://arxiv.org/abs/2403.19317v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office\n  Usage Scenarios", "abstract": "We introduce TableLLM, a robust large language model (LLM) with 8 billion\nparameters, purpose-built for proficiently handling tabular data manipulation\ntasks, whether they are embedded within documents or spreadsheets, catering to\nreal-world office scenarios. We propose a distant supervision method for\ntraining, which comprises a reasoning process extension strategy, aiding in\ntraining LLMs to understand reasoning patterns more effectively as well as a\ncross-way validation strategy, ensuring the quality of the automatically\ngenerated data. To evaluate the performance of TableLLM, we have crafted\nbenchmarks tailored to address both document and spreadsheet formats as well as\nconstructed a well-organized evaluation pipeline capable of handling both\nscenarios. Thorough evaluations underscore the advantages of TableLLM when\ncompared to various existing general-purpose and tabular data-focused LLMs. We\nhave publicly released the model checkpoint, source code, benchmarks, and a web\napplication for user interaction. Our codes and data are publicly available at\nhttps://github.com/TableLLM/TableLLM.", "published": "2024-03-28 11:21:12", "link": "http://arxiv.org/abs/2403.19318v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KazSAnDRA: Kazakh Sentiment Analysis Dataset of Reviews and Attitudes", "abstract": "This paper presents KazSAnDRA, a dataset developed for Kazakh sentiment\nanalysis that is the first and largest publicly available dataset of its kind.\nKazSAnDRA comprises an extensive collection of 180,064 reviews obtained from\nvarious sources and includes numerical ratings ranging from 1 to 5, providing a\nquantitative representation of customer attitudes. The study also pursued the\nautomation of Kazakh sentiment classification through the development and\nevaluation of four machine learning models trained for both polarity\nclassification and score classification. Experimental analysis included\nevaluation of the results considering both balanced and imbalanced scenarios.\nThe most successful model attained an F1-score of 0.81 for polarity\nclassification and 0.39 for score classification on the test sets. The dataset\nand fine-tuned models are open access and available for download under the\nCreative Commons Attribution 4.0 International License (CC BY 4.0) through our\nGitHub repository.", "published": "2024-03-28 11:51:11", "link": "http://arxiv.org/abs/2403.19335v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large Language Models Are Unconscious of Unreasonability in Math\n  Problems", "abstract": "Large language models (LLMs) demonstrate substantial capabilities in solving\nmath problems. However, they tend to produce hallucinations when given\nquestions containing unreasonable errors. In this paper, we study the behavior\nof LLMs when faced with unreasonable math problems and further explore their\npotential to address these problems. We construct the Unreasonable Math Problem\n(UMP) benchmark to examine the error detection ability of LLMs. Experiments\nshow that LLMs are able to detect unreasonable errors, but still fail in\ngenerating non-hallucinatory content. In order to improve their ability of\nerror detection and correction, we further design a strategic prompt template\ncalled Critical Calculation and Conclusion(CCC). With CCC, LLMs can better\nself-evaluate and detect unreasonable errors in math questions, making them\nmore reliable and safe in practical application scenarios.", "published": "2024-03-28 12:04:28", "link": "http://arxiv.org/abs/2403.19346v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A diverse Multilingual News Headlines Dataset from around the World", "abstract": "Babel Briefings is a novel dataset featuring 4.7 million news headlines from\nAugust 2020 to November 2021, across 30 languages and 54 locations worldwide\nwith English translations of all articles included. Designed for natural\nlanguage processing and media studies, it serves as a high-quality dataset for\ntraining or evaluating language models as well as offering a simple, accessible\ncollection of articles, for example, to analyze global news coverage and\ncultural narratives. As a simple demonstration of the analyses facilitated by\nthis dataset, we use a basic procedure using a TF-IDF weighted similarity\nmetric to group articles into clusters about the same event. We then visualize\nthe \\emph{event signatures} of the event showing articles of which languages\nappear over time, revealing intuitive features based on the proximity of the\nevent and unexpectedness of the event. The dataset is available on\n\\href{https://www.kaggle.com/datasets/felixludos/babel-briefings}{Kaggle} and\n\\href{https://huggingface.co/datasets/felixludos/babel-briefings}{HuggingFace}\nwith accompanying \\href{https://github.com/felixludos/babel-briefings}{GitHub}\ncode.", "published": "2024-03-28 12:08:39", "link": "http://arxiv.org/abs/2403.19352v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AIpom at SemEval-2024 Task 8: Detecting AI-produced Outputs in M4", "abstract": "This paper describes AIpom, a system designed to detect a boundary between\nhuman-written and machine-generated text (SemEval-2024 Task 8, Subtask C:\nHuman-Machine Mixed Text Detection). We propose a two-stage pipeline combining\npredictions from an instruction-tuned decoder-only model and encoder-only\nsequence taggers. AIpom is ranked second on the leaderboard while achieving a\nMean Absolute Error of 15.94. Ablation studies confirm the benefits of\npipelining encoder and decoder models, particularly in terms of improved\nperformance.", "published": "2024-03-28 12:10:30", "link": "http://arxiv.org/abs/2403.19354v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Risk prediction of pathological gambling on social media", "abstract": "This paper addresses the problem of risk prediction on social media data,\nspecifically focusing on the classification of Reddit users as having a\npathological gambling disorder. To tackle this problem, this paper focuses on\nincorporating temporal and emotional features into the model. The preprocessing\nphase involves dealing with the time irregularity of posts by padding\nsequences. Two baseline architectures are used for preliminary evaluation: BERT\nclassifier on concatenated posts per user and GRU with LSTM on sequential data.\nExperimental results demonstrate that the sequential models outperform the\nconcatenation-based model. The results of the experiments conclude that the\nincorporation of a time decay layer (TD) and passing the emotion classification\nlayer (EmoBERTa) through LSTM improves the performance significantly.\nExperiments concluded that the addition of a self-attention layer didn't\nsignificantly improve the performance of the model, however provided easily\ninterpretable attention scores. The developed architecture with the inclusion\nof EmoBERTa and TD layers achieved a high F1 score, beating existing benchmarks\non pathological gambling dataset. Future work may involve the early prediction\nof risk factors associated with pathological gambling disorder and testing\nmodels on other datasets. Overall, this research highlights the significance of\nthe sequential processing of posts including temporal and emotional features to\nboost the predictive power, as well as adding an attention layer for\ninterpretability.", "published": "2024-03-28 12:17:36", "link": "http://arxiv.org/abs/2403.19358v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EthioMT: Parallel Corpus for Low-resource Ethiopian Languages", "abstract": "Recent research in natural language processing (NLP) has achieved impressive\nperformance in tasks such as machine translation (MT), news classification, and\nquestion-answering in high-resource languages. However, the performance of MT\nleaves much to be desired for low-resource languages. This is due to the\nsmaller size of available parallel corpora in these languages, if such corpora\nare available at all. NLP in Ethiopian languages suffers from the same issues\ndue to the unavailability of publicly accessible datasets for NLP tasks,\nincluding MT. To help the research community and foster research for Ethiopian\nlanguages, we introduce EthioMT -- a new parallel corpus for 15 languages. We\nalso create a new benchmark by collecting a dataset for better-researched\nlanguages in Ethiopia. We evaluate the newly collected corpus and the benchmark\ndataset for 23 Ethiopian languages using transformer and fine-tuning\napproaches.", "published": "2024-03-28 12:26:45", "link": "http://arxiv.org/abs/2403.19365v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Checkpoint Merging via Bayesian Optimization in LLM Pretraining", "abstract": "The rapid proliferation of large language models (LLMs) such as GPT-4 and\nGemini underscores the intense demand for resources during their training\nprocesses, posing significant challenges due to substantial computational and\nenvironmental costs. To alleviate this issue, we propose checkpoint merging in\npretraining LLM. This method utilizes LLM checkpoints with shared training\ntrajectories, and is rooted in an extensive search space exploration for the\nbest merging weight via Bayesian optimization. Through various experiments, we\ndemonstrate that: (1) Our proposed methodology exhibits the capacity to augment\npretraining, presenting an opportunity akin to obtaining substantial benefits\nat minimal cost; (2) Our proposed methodology, despite requiring a given\nheld-out dataset, still demonstrates robust generalization capabilities across\ndiverse domains, a pivotal aspect in pretraining.", "published": "2024-03-28 13:01:18", "link": "http://arxiv.org/abs/2403.19390v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KazParC: Kazakh Parallel Corpus for Machine Translation", "abstract": "We introduce KazParC, a parallel corpus designed for machine translation\nacross Kazakh, English, Russian, and Turkish. The first and largest publicly\navailable corpus of its kind, KazParC contains a collection of 371,902 parallel\nsentences covering different domains and developed with the assistance of human\ntranslators. Our research efforts also extend to the development of a neural\nmachine translation model nicknamed Tilmash. Remarkably, the performance of\nTilmash is on par with, and in certain instances, surpasses that of industry\ngiants, such as Google Translate and Yandex Translate, as measured by standard\nevaluation metrics, such as BLEU and chrF. Both KazParC and Tilmash are openly\navailable for download under the Creative Commons Attribution 4.0 International\nLicense (CC BY 4.0) through our GitHub repository.", "published": "2024-03-28 13:19:16", "link": "http://arxiv.org/abs/2403.19399v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BP4ER: Bootstrap Prompting for Explicit Reasoning in Medical Dialogue\n  Generation", "abstract": "Medical dialogue generation (MDG) has gained increasing attention due to its\nsubstantial practical value. Previous works typically employ a\nsequence-to-sequence framework to generate medical responses by modeling\ndialogue context as sequential text with annotated medical entities. While\nthese methods have been successful in generating fluent responses, they fail to\nprovide process explanations of reasoning and require extensive entity\nannotation. To address these limitations, we propose the method Bootstrap\nPrompting for Explicit Reasoning in MDG (BP4ER), which explicitly model MDG's\nmulti-step reasoning process and iteratively enhance this reasoning process. We\nemploy a least-to-most prompting strategy to guide a large language model (LLM)\nin explicit reasoning, breaking down MDG into simpler sub-questions. These\nsub-questions build on answers from previous ones. Additionally, we also\nintroduce two distinct bootstrapping techniques for prompting, which\nautonomously correct errors and facilitate the LLM's explicit reasoning. This\napproach eliminates the need for entity annotation and increases the\ntransparency of the MDG process by explicitly generating the intermediate\nreasoning chain. The experimental findings on the two public datasets indicate\nthat BP4ER outperforms state-of-the-art methods in terms of both objective and\nsubjective evaluation metrics.", "published": "2024-03-28 13:38:13", "link": "http://arxiv.org/abs/2403.19414v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Mixed Preference Optimization: Reinforcement Learning with Data\n  Selection and Better Reference Model", "abstract": "Large Language Models (LLMs) have become increasingly popular due to their\nability to process and generate natural language. However, as they are trained\non massive datasets of text, LLMs can inherit harmful biases and produce\noutputs that are not aligned with human values. This paper studies two main\napproaches to LLM alignment: Reinforcement Learning with Human Feedback (RLHF)\nand contrastive learning-based methods like Direct Preference Optimization\n(DPO). By analyzing the stability and robustness of RLHF and DPO, we propose\nMPO (Mixed Preference Optimization), a novel method that mitigates the\nweaknesses of both approaches. Specifically, we propose a two-stage training\nprocedure: first train DPO on an easy dataset, and then perform RLHF on a\ndifficult set with DPO model being the reference model. Here, the easy and\ndifficult sets are constructed by a well-trained reward model that splits\nresponse pairs into those with large gaps of reward (easy), and those with\nsmall gaps (difficult). The first stage allows us to obtain a relatively\noptimal policy (LLM) model quickly, whereas the second stage refines LLM with\nonline RLHF, thus mitigating the distribution shift issue associated with DPO.\nExperiments are conducted on two public alignment datasets, namely HH-RLHF and\nTLDR, demonstrating the effectiveness of MPO, both in terms of GPT4 and human\nevaluation.", "published": "2024-03-28 14:15:10", "link": "http://arxiv.org/abs/2403.19443v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "JDocQA: Japanese Document Question Answering Dataset for Generative\n  Language Models", "abstract": "Document question answering is a task of question answering on given\ndocuments such as reports, slides, pamphlets, and websites, and it is a truly\ndemanding task as paper and electronic forms of documents are so common in our\nsociety. This is known as a quite challenging task because it requires not only\ntext understanding but also understanding of figures and tables, and hence\nvisual question answering (VQA) methods are often examined in addition to\ntextual approaches. We introduce Japanese Document Question Answering (JDocQA),\na large-scale document-based QA dataset, essentially requiring both visual and\ntextual information to answer questions, which comprises 5,504 documents in PDF\nformat and annotated 11,600 question-and-answer instances in Japanese. Each QA\ninstance includes references to the document pages and bounding boxes for the\nanswer clues. We incorporate multiple categories of questions and unanswerable\nquestions from the document for realistic question-answering applications. We\nempirically evaluate the effectiveness of our dataset with text-based large\nlanguage models (LLMs) and multimodal models. Incorporating unanswerable\nquestions in finetuning may contribute to harnessing the so-called\nhallucination generation.", "published": "2024-03-28 14:22:54", "link": "http://arxiv.org/abs/2403.19454v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Clinical NLP Performance through Language Model-Generated\n  Synthetic Clinical Data", "abstract": "Generative models have been showing potential for producing data in mass.\nThis study explores the enhancement of clinical natural language processing\nperformance by utilizing synthetic data generated from advanced language\nmodels. Promising results show feasible applications in such a high-stakes\ndomain.", "published": "2024-03-28 15:44:18", "link": "http://arxiv.org/abs/2403.19511v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "WaterJudge: Quality-Detection Trade-off when Watermarking Large Language\n  Models", "abstract": "Watermarking generative-AI systems, such as LLMs, has gained considerable\ninterest, driven by their enhanced capabilities across a wide range of tasks.\nAlthough current approaches have demonstrated that small, context-dependent\nshifts in the word distributions can be used to apply and detect watermarks,\nthere has been little work in analyzing the impact that these perturbations\nhave on the quality of generated texts. Balancing high detectability with\nminimal performance degradation is crucial in terms of selecting the\nappropriate watermarking setting; therefore this paper proposes a simple\nanalysis framework where comparative assessment, a flexible NLG evaluation\nframework, is used to assess the quality degradation caused by a particular\nwatermark setting. We demonstrate that our framework provides easy\nvisualization of the quality-detection trade-off of watermark settings,\nenabling a simple solution to find an LLM watermark operating point that\nprovides a well-balanced performance. This approach is applied to two different\nsummarization systems and a translation system, enabling cross-model analysis\nfor a task, and cross-task analysis.", "published": "2024-03-28 16:28:38", "link": "http://arxiv.org/abs/2403.19548v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Adversarial Data Collection by Supporting Annotators: Lessons\n  from GAHD, a German Hate Speech Dataset", "abstract": "Hate speech detection models are only as good as the data they are trained\non. Datasets sourced from social media suffer from systematic gaps and biases,\nleading to unreliable models with simplistic decision boundaries. Adversarial\ndatasets, collected by exploiting model weaknesses, promise to fix this\nproblem. However, adversarial data collection can be slow and costly, and\nindividual annotators have limited creativity. In this paper, we introduce\nGAHD, a new German Adversarial Hate speech Dataset comprising ca.\\ 11k\nexamples. During data collection, we explore new strategies for supporting\nannotators, to create more diverse adversarial examples more efficiently and\nprovide a manual analysis of annotator disagreements for each strategy. Our\nexperiments show that the resulting dataset is challenging even for\nstate-of-the-art hate speech detection models, and that training on GAHD\nclearly improves model robustness. Further, we find that mixing multiple\nsupport strategies is most advantageous. We make GAHD publicly available at\nhttps://github.com/jagol/gahd.", "published": "2024-03-28 16:44:14", "link": "http://arxiv.org/abs/2403.19559v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GOLD: Generalized Knowledge Distillation via Out-of-Distribution-Guided\n  Language Data Generation", "abstract": "Knowledge distillation from LLMs is essential for the efficient deployment of\nlanguage models. Prior works have proposed data generation using LLMs for\npreparing distilled models. We argue that generating data with LLMs is prone to\nsampling mainly from the center of original content distribution. This\nlimitation hinders the distilled model from learning the true underlying data\ndistribution and to forget the tails of the distributions (samples with lower\nprobability). To this end, we propose GOLD, a task-agnostic data generation and\nknowledge distillation framework, which employs an iterative\nout-of-distribution-guided feedback mechanism for the LLM. As a result, the\ngenerated data improves the generalizability of distilled models. An\nenergy-based OOD evaluation approach is also introduced to deal with noisy\ngenerated data. Our extensive experiments on 10 different classification and\nsequence-to-sequence tasks in NLP show that GOLD respectively outperforms prior\narts and the LLM with an average improvement of 5% and 14%. We will also show\nthat the proposed method is applicable to less explored and novel tasks. The\ncode is available.", "published": "2024-03-28 18:08:22", "link": "http://arxiv.org/abs/2403.19754v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case\n  of the Missing AANNs", "abstract": "Language models learn rare syntactic phenomena, but the extent to which this\nis attributable to generalization vs. memorization is a major open question. To\nthat end, we iteratively trained transformer language models on systematically\nmanipulated corpora which were human-scale in size, and then evaluated their\nlearning of a rare grammatical phenomenon: the English\nArticle+Adjective+Numeral+Noun (AANN) construction (``a beautiful five days'').\nWe compared how well this construction was learned on the default corpus\nrelative to a counterfactual corpus in which AANN sentences were removed. We\nfound that AANNs were still learned better than systematically perturbed\nvariants of the construction. Using additional counterfactual corpora, we\nsuggest that this learning occurs through generalization from related\nconstructions (e.g., ``a few days''). An additional experiment showed that this\nlearning is enhanced when there is more variability in the input. Taken\ntogether, our results provide an existence proof that LMs can learn rare\ngrammatical phenomena by generalization from less rare phenomena. Data and\ncode: https://github.com/kanishkamisra/aannalysis.", "published": "2024-03-28 20:35:10", "link": "http://arxiv.org/abs/2403.19827v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Target Span Detection for Implicit Harmful Content", "abstract": "Identifying the targets of hate speech is a crucial step in grasping the\nnature of such speech and, ultimately, in improving the detection of offensive\nposts on online forums. Much harmful content on online platforms uses implicit\nlanguage especially when targeting vulnerable and protected groups such as\nusing stereotypical characteristics instead of explicit target names, making it\nharder to detect and mitigate the language. In this study, we focus on\nidentifying implied targets of hate speech, essential for recognizing subtler\nhate speech and enhancing the detection of harmful content on digital\nplatforms. We define a new task aimed at identifying the targets even when they\nare not explicitly stated. To address that task, we collect and annotate target\nspans in three prominent implicit hate speech datasets: SBIC, DynaHate, and\nIHC. We call the resulting merged collection Implicit-Target-Span. The\ncollection is achieved using an innovative pooling method with matching scores\nbased on human annotations and Large Language Models (LLMs). Our experiments\nindicate that Implicit-Target-Span provides a challenging test bed for target\nspan detection methods.", "published": "2024-03-28 21:15:15", "link": "http://arxiv.org/abs/2403.19836v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "FACTOID: FACtual enTailment fOr hallucInation Detection", "abstract": "The widespread adoption of Large Language Models (LLMs) has facilitated\nnumerous benefits. However, hallucination is a significant concern. In\nresponse, Retrieval Augmented Generation (RAG) has emerged as a highly\npromising paradigm to improve LLM outputs by grounding them in factual\ninformation. RAG relies on textual entailment (TE) or similar methods to check\nif the text produced by LLMs is supported or contradicted, compared to\nretrieved documents. This paper argues that conventional TE methods are\ninadequate for spotting hallucinations in content generated by LLMs. For\ninstance, consider a prompt about the 'USA's stance on the Ukraine war''. The\nAI-generated text states, ...U.S. President Barack Obama says the U.S. will not\nput troops in Ukraine...'' However, during the war the U.S. president is Joe\nBiden which contradicts factual reality. Moreover, current TE systems are\nunable to accurately annotate the given text and identify the exact portion\nthat is contradicted. To address this, we introduces a new type of TE called\n``Factual Entailment (FE).'', aims to detect factual inaccuracies in content\ngenerated by LLMs while also highlighting the specific text segment that\ncontradicts reality. We present FACTOID (FACTual enTAILment for hallucInation\nDetection), a benchmark dataset for FE. We propose a multi-task learning (MTL)\nframework for FE, incorporating state-of-the-art (SoTA) long text embeddings\nsuch as e5-mistral-7b-instruct, along with GPT-3, SpanBERT, and RoFormer. The\nproposed MTL architecture for FE achieves an avg. 40\\% improvement in accuracy\non the FACTOID benchmark compared to SoTA TE methods. As FE automatically\ndetects hallucinations, we assessed 15 modern LLMs and ranked them using our\nproposed Auto Hallucination Vulnerability Index (HVI_auto). This index\nquantifies and offers a comparative scale to evaluate and rank LLMs according\nto their hallucinations.", "published": "2024-03-28 03:09:42", "link": "http://arxiv.org/abs/2403.19113v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering", "abstract": "In today's fast-paced industry, professionals face the challenge of\nsummarizing a large number of documents and extracting vital information from\nthem on a daily basis. These metrics are frequently hidden away in tables\nand/or their nested hyperlinks. To address this challenge, the approach of\nTable Question Answering (QA) has been developed to extract the relevant\ninformation. However, traditional Table QA training tasks that provide a table\nand an answer(s) from a gold cell coordinate(s) for a question may not always\nensure extracting the accurate answer(s). Recent advancements in Large Language\nModels (LLMs) have opened up new possibilities for extracting information from\ntabular data using prompts. In this paper, we introduce the Multi-hop Few-shot\nOpen Rich Table QA (MFORT-QA) approach, which consists of two major steps. The\nfirst step involves Few-Shot Learning (FSL), where relevant tables and\nassociated contexts of hyperlinks are retrieved based on a given question. The\nretrieved content is then used to construct few-shot prompts as inputs to an\nLLM, such as ChatGPT. To tackle the challenge of answering complex questions,\nthe second step leverages Chain-of-thought (CoT) prompting to decompose the\ncomplex question into a sequential chain of questions and reasoning thoughts in\na multi-hop manner. Retrieval-Augmented Generation (RAG) enhances this process\nby retrieving relevant tables and contexts of hyperlinks that are relevant to\nthe resulting reasoning thoughts and questions. These additional contexts are\nthen used to supplement the prompt used in the first step, resulting in more\naccurate answers from an LLM. Empirical results from OTT-QA demonstrate that\nour abstractive QA approach significantly improves the accuracy of extractive\nTable QA methods.", "published": "2024-03-28 03:14:18", "link": "http://arxiv.org/abs/2403.19116v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Streamlining Redundant Layers to Compress Large Language Models", "abstract": "This paper introduces LLM-Streamline, a pioneer work on layer pruning for\nlarge language models (LLMs). It is based on the observation that different\nlayers have varying impacts on hidden states, enabling the identification of\nless important layers to be pruned.LLM-Streamline comprises two parts: layer\npruning, which removes consecutive layers with the lowest importance based on\ntarget sparsity, and layer replacement, a novel module that trains a\nlightweight network to replace the pruned layers to mitigate performance loss.\nAdditionally, a new metric called stability is proposed to address the\nlimitations of the widely used accuracy metric in evaluating model compression.\nExperiments show that LLM-Streamline outperforms both previous and concurrent\nstate-of-the-art pruning methods in terms of both performance and training\nefficiency.Our code is available at\nhttps://github.com/RUCKBReasoning/LLM-Streamline", "published": "2024-03-28 04:12:13", "link": "http://arxiv.org/abs/2403.19135v5", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "STaR-GATE: Teaching Language Models to Ask Clarifying Questions", "abstract": "When prompting language models to complete a task, users often leave\nimportant aspects unsaid. While asking questions could resolve this ambiguity\n(GATE; Li et al., 2023), models often struggle to ask good questions. We\nexplore a language model's ability to self-improve (STaR; Zelikman et al.,\n2022) by rewarding the model for generating useful questions-a simple method we\ndub STaR-GATE. We generate a synthetic dataset of 25,500 unique persona-task\nprompts to simulate conversations between a pretrained language model-the\nQuestioner-and a Roleplayer whose preferences are unknown to the Questioner. By\nasking questions, the Questioner elicits preferences from the Roleplayer. The\nQuestioner is iteratively finetuned on questions that increase the probability\nof high-quality responses to the task, which are generated by an Oracle with\naccess to the Roleplayer's latent preferences. After two iterations of\nself-improvement, the Questioner asks better questions, allowing it to generate\nresponses that are preferred over responses from the initial model on 72% of\ntasks. Our results indicate that teaching a language model to ask better\nquestions leads to better personalized responses.", "published": "2024-03-28 05:35:22", "link": "http://arxiv.org/abs/2403.19154v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Disentangling Length from Quality in Direct Preference Optimization", "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been a crucial\ncomponent in the recent success of Large Language Models. However, RLHF is know\nto exploit biases in human preferences, such as verbosity. A well-formatted and\neloquent answer is often more highly rated by users, even when it is less\nhelpful and objective. A number of approaches have been developed to control\nthose biases in the classical RLHF literature, but the problem remains\nrelatively under-explored for Direct Alignment Algorithms such as Direct\nPreference Optimization (DPO). Unlike classical RLHF, DPO does not train a\nseparate reward model or use reinforcement learning directly, so previous\napproaches developed to control verbosity cannot be directly applied to this\nsetting. Our work makes several contributions. For the first time, we study the\nlength problem in the DPO setting, showing significant exploitation in DPO and\nlinking it to out-of-distribution bootstrapping. We then develop a principled\nbut simple regularization strategy that prevents length exploitation, while\nstill maintaining improvements in model quality. We demonstrate these effects\nacross datasets on summarization and dialogue, where we achieve up to 20\\%\nimprovement in win rates when controlling for length, despite the GPT4 judge's\nwell-known verbosity bias.", "published": "2024-03-28 06:03:47", "link": "http://arxiv.org/abs/2403.19159v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Mitigating Misleading Chain-of-Thought Reasoning with Selective\n  Filtering", "abstract": "Large language models have manifested remarkable capabilities by leveraging\nchain-of-thought (CoT) reasoning techniques to solve intricate questions\nthrough step-by-step reasoning chains. Despite its success, the efficacy of\nsuch reasoning is inherently contingent upon the quality of CoT. However,\nflawless CoT reasoning cannot be guaranteed due to the presence of\nindecomposable questions and the potential for erroneous reasoning chains,\nparticularly in the case of small-scale language models. To tackle this\nchallenge, we propose a novel approach called the selective filtering reasoner\n(SelF-Reasoner) that assesses the entailment relationship between the question\nand the candidate reasoning chain. Then, we proceed with CoT reasoning when the\nreasoning chain demonstrates confidence; otherwise, we opt to predict the\nanswer directly. SelF-Reasoner improves the fine-tuned T5 baseline consistently\nover the ScienceQA, ECQA, and LastLetter tasks. Code is available at\n\\texttt{https://github.com/LibroWu/SelF-Reasoner}.", "published": "2024-03-28 06:28:35", "link": "http://arxiv.org/abs/2403.19167v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Understanding Archives: Towards New Research Interfaces Relying on the\n  Semantic Annotation of Documents", "abstract": "The digitisation campaigns carried out by libraries and archives in recent\nyears have facilitated access to documents in their collections. However,\nexploring and exploiting these documents remain difficult tasks due to the\nsheer quantity of documents available for consultation. In this article, we\nshow how the semantic annotation of the textual content of study corpora of\narchival documents allow to facilitate their exploitation and valorisation.\nFirst, we present a methodological framework for the construction of new\ninterfaces based on textual semantics, then address the current technological\nobstacles and their potential solutions. We conclude by presenting a practical\ncase of the application of this framework.", "published": "2024-03-28 07:55:29", "link": "http://arxiv.org/abs/2403.19201v1", "categories": ["cs.DL", "cs.CL"], "primary_category": "cs.DL"}
{"title": "MineLand: Simulating Large-Scale Multi-Agent Interactions with Limited\n  Multimodal Senses and Physical Needs", "abstract": "While Vision-Language Models (VLMs) hold promise for tasks requiring\nextensive collaboration, traditional multi-agent simulators have facilitated\nrich explorations of an interactive artificial society that reflects collective\nbehavior. However, these existing simulators face significant limitations.\nFirstly, they struggle with handling large numbers of agents due to high\nresource demands. Secondly, they often assume agents possess perfect\ninformation and limitless capabilities, hindering the ecological validity of\nsimulated social interactions. To bridge this gap, we propose a multi-agent\nMinecraft simulator, MineLand, that bridges this gap by introducing three key\nfeatures: large-scale scalability, limited multimodal senses, and physical\nneeds. Our simulator supports 64 or more agents. Agents have limited visual,\nauditory, and environmental awareness, forcing them to actively communicate and\ncollaborate to fulfill physical needs like food and resources. Additionally, we\nfurther introduce an AI agent framework, Alex, inspired by multitasking theory,\nenabling agents to handle intricate coordination and scheduling. Our\nexperiments demonstrate that the simulator, the corresponding benchmark, and\nthe AI agent framework contribute to more ecological and nuanced collective\nbehavior.The source code of MineLand and Alex is openly available at\nhttps://github.com/cocacola-lab/MineLand.", "published": "2024-03-28 09:53:41", "link": "http://arxiv.org/abs/2403.19267v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "sDPO: Don't Use Your Data All at Once", "abstract": "As development of large language models (LLM) progresses, aligning them with\nhuman preferences has become increasingly important. We propose stepwise DPO\n(sDPO), an extension of the recently popularized direct preference optimization\n(DPO) for alignment tuning. This approach involves dividing the available\npreference datasets and utilizing them in a stepwise manner, rather than\nemploying it all at once. We demonstrate that this method facilitates the use\nof more precisely aligned reference models within the DPO training framework.\nFurthermore, sDPO trains the final model to be more performant, even\noutperforming other popular LLMs with more parameters.", "published": "2024-03-28 09:56:04", "link": "http://arxiv.org/abs/2403.19270v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Knowledge Boundary and Persona Dynamic Shape A Better Social Media Agent", "abstract": "Constructing personalized and anthropomorphic agents holds significant\nimportance in the simulation of social networks. However, there are still two\nkey problems in existing works: the agent possesses world knowledge that does\nnot belong to its personas, and it cannot eliminate the interference of diverse\npersona information on current actions, which reduces the personalization and\nanthropomorphism of the agent. To solve the above problems, we construct the\nsocial media agent based on personalized knowledge and dynamic persona\ninformation. For personalized knowledge, we add external knowledge sources and\nmatch them with the persona information of agents, thereby giving the agent\npersonalized world knowledge. For dynamic persona information, we use current\naction information to internally retrieve the persona information of the agent,\nthereby reducing the interference of diverse persona information on the current\naction. To make the agent suitable for social media, we design five basic\nmodules for it: persona, planning, action, memory and reflection. To provide an\ninteraction and verification environment for the agent, we build a social media\nsimulation sandbox. In the experimental verification, automatic and human\nevaluations demonstrated the effectiveness of the agent we constructed.", "published": "2024-03-28 10:01:23", "link": "http://arxiv.org/abs/2403.19275v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended\n  Text Evaluation", "abstract": "Recent advancements in generative Large Language Models(LLMs) have been\nremarkable, however, the quality of the text generated by these models often\nreveals persistent issues. Evaluating the quality of text generated by these\nmodels, especially in open-ended text, has consistently presented a significant\nchallenge. Addressing this, recent work has explored the possibility of using\nLLMs as evaluators. While using a single LLM as an evaluation agent shows\npotential, it is filled with significant uncertainty and instability. To\naddress these issues, we propose the MATEval: A \"Multi-Agent Text Evaluation\nframework\" where all agents are played by LLMs like GPT-4. The MATEval\nframework emulates human collaborative discussion methods, integrating multiple\nagents' interactions to evaluate open-ended text. Our framework incorporates\nself-reflection and Chain-of-Thought (CoT) strategies, along with feedback\nmechanisms, enhancing the depth and breadth of the evaluation process and\nguiding discussions towards consensus, while the framework generates\ncomprehensive evaluation reports, including error localization, error types and\nscoring. Experimental results show that our framework outperforms existing\nopen-ended text evaluation methods and achieves the highest correlation with\nhuman evaluation, which confirms the effectiveness and advancement of our\nframework in addressing the uncertainties and instabilities in evaluating\nLLMs-generated text. Furthermore, our framework significantly improves the\nefficiency of text evaluation and model iteration in industrial scenarios.", "published": "2024-03-28 10:41:47", "link": "http://arxiv.org/abs/2403.19305v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Plug-and-Play Grounding of Reasoning in Multimodal Large Language Models", "abstract": "The rise of Multimodal Large Language Models (MLLMs), renowned for their\nadvanced instruction-following and reasoning capabilities, has significantly\npropelled the field of visual reasoning. However, due to limitations in their\nimage tokenization processes, most MLLMs struggle to capture fine details of\ntext and objects in images, especially in high-resolution samples. To overcome\nthis limitation, we introduce P2G, a novel framework for plug-and-play\ngrounding in MLLMs. P2G utilizes the tool-usage potential of MLLMs to employ\nexpert agents for on-the-fly grounding of reasoning into critical visual and\ntextual elements in images, thereby enabling deliberate reasoning through\nmultimodal prompting. Additionally, we develop P2GB, a benchmark designed to\nevaluate MLLMs' proficiency in understanding inter-object relationships and\ntextual content in challenging high-resolution images. Extensive experiments on\nvisual reasoning tasks demonstrate the superiority of P2G, achieving\nperformance comparable to GPT-4V on P2GB with a 7B backbone. Our work\nunderscores the potential of grounding reasoning with external agents in MLLMs,\npresenting a promising alternative to mere model scaling.", "published": "2024-03-28 11:26:30", "link": "http://arxiv.org/abs/2403.19322v2", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large\n  Language Models", "abstract": "To address the challenges associated with data processing at scale, we\npropose Dataverse, a unified open-source Extract-Transform-Load (ETL) pipeline\nfor large language models (LLMs) with a user-friendly design at its core. Easy\naddition of custom processors with block-based interface in Dataverse allows\nusers to readily and efficiently use Dataverse to build their own ETL pipeline.\nWe hope that Dataverse will serve as a vital tool for LLM development and open\nsource the entire library to welcome community contribution. Additionally, we\nprovide a concise, two-minute video demonstration of our system, illustrating\nits capabilities and implementation.", "published": "2024-03-28 11:57:08", "link": "http://arxiv.org/abs/2403.19340v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Echo-chambers and Idea Labs: Communication Styles on Twitter", "abstract": "This paper investigates the communication styles and structures of Twitter\n(X) communities within the vaccination context. While mainstream research\nprimarily focuses on the echo-chamber phenomenon, wherein certain ideas are\nreinforced and participants are isolated from opposing opinions, this study\nreveals the presence of diverse communication styles across various\ncommunities. In addition to the communities exhibiting echo-chamber behavior,\nthis research uncovers communities with distinct communication patterns. By\nshedding light on the nuanced nature of communication within social networks,\nthis study emphasizes the significance of understanding the diversity of\nperspectives within online communities.", "published": "2024-03-28 13:55:51", "link": "http://arxiv.org/abs/2403.19423v1", "categories": ["cs.SI", "cs.CL", "J.4; K.4.1; K.4.2"], "primary_category": "cs.SI"}
{"title": "The Role of Syntactic Span Preferences in Post-Hoc Explanation\n  Disagreement", "abstract": "Post-hoc explanation methods are an important tool for increasing model\ntransparency for users. Unfortunately, the currently used methods for\nattributing token importance often yield diverging patterns. In this work, we\nstudy potential sources of disagreement across methods from a linguistic\nperspective. We find that different methods systematically select different\nclasses of words and that methods that agree most with other methods and with\nhumans display similar linguistic preferences. Token-level differences between\nmethods are smoothed out if we compare them on the syntactic span level. We\nalso find higher agreement across methods by estimating the most important\nspans dynamically instead of relying on a fixed subset of size $k$. We\nsystematically investigate the interaction between $k$ and spans and propose an\nimproved configuration for selecting important tokens.", "published": "2024-03-28 13:56:23", "link": "http://arxiv.org/abs/2403.19424v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Uncovering Misattributed Suicide Causes through Annotation Inconsistency\n  Detection in Death Investigation Notes", "abstract": "Data accuracy is essential for scientific research and policy development.\nThe National Violent Death Reporting System (NVDRS) data is widely used for\ndiscovering the patterns and causes of death. Recent studies suggested the\nannotation inconsistencies within the NVDRS and the potential impact on\nerroneous suicide-cause attributions. We present an empirical Natural Language\nProcessing (NLP) approach to detect annotation inconsistencies and adopt a\ncross-validation-like paradigm to identify problematic instances. We analyzed\n267,804 suicide death incidents between 2003 and 2020 from the NVDRS. Our\nresults showed that incorporating the target state's data into training the\nsuicide-crisis classifier brought an increase of 5.4% to the F-1 score on the\ntarget state's test set and a decrease of 1.1% on other states' test set. To\nconclude, we demonstrated the annotation inconsistencies in NVDRS's death\ninvestigation notes, identified problematic instances, evaluated the\neffectiveness of correcting problematic instances, and eventually proposed an\nNLP improvement solution.", "published": "2024-03-28 14:03:12", "link": "http://arxiv.org/abs/2403.19432v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "New Semantic Task for the French Spoken Language Understanding MEDIA\n  Benchmark", "abstract": "Intent classification and slot-filling are essential tasks of Spoken Language\nUnderstanding (SLU). In most SLUsystems, those tasks are realized by\nindependent modules. For about fifteen years, models achieving both of\nthemjointly and exploiting their mutual enhancement have been proposed. A\nmultilingual module using a joint modelwas envisioned to create a touristic\ndialogue system for a European project, HumanE-AI-Net. A combination ofmultiple\ndatasets, including the MEDIA dataset, was suggested for training this joint\nmodel. The MEDIA SLU datasetis a French dataset distributed since 2005 by ELRA,\nmainly used by the French research community and free foracademic research\nsince 2020. Unfortunately, it is annotated only in slots but not intents. An\nenhanced version ofMEDIA annotated with intents has been built to extend its\nuse to more tasks and use cases. This paper presents thesemi-automatic\nmethodology used to obtain this enhanced version. In addition, we present the\nfirst results of SLUexperiments on this enhanced dataset using joint models for\nintent classification and slot-filling.", "published": "2024-03-28 08:40:02", "link": "http://arxiv.org/abs/2403.19727v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Developing Healthcare Language Model Embedding Spaces", "abstract": "Pre-trained Large Language Models (LLMs) often struggle on out-of-domain\ndatasets like healthcare focused text. We explore specialized pre-training to\nadapt smaller LLMs to different healthcare datasets. Three methods are\nassessed: traditional masked language modeling, Deep Contrastive Learning for\nUnsupervised Textual Representations (DeCLUTR), and a novel pre-training\nobjective utilizing metadata categories from the healthcare settings. These\nschemes are evaluated on downstream document classification tasks for each\ndataset, with additional analysis of the resultant embedding spaces.\nContrastively trained models outperform other approaches on the classification\ntasks, delivering strong performance from limited labeled data and with fewer\nmodel parameter updates required. While metadata-based pre-training does not\nfurther improve classifications across the datasets, it yields interesting\nembedding cluster separability. All domain adapted LLMs outperform their\npublicly available general base LLM, validating the importance of\ndomain-specialization. This research illustrates efficient approaches to\ninstill healthcare competency in compact LLMs even under tight computational\nbudgets, an essential capability for responsible and sustainable deployment in\nlocal healthcare settings. We provide pre-training guidelines for specialized\nhealthcare LLMs, motivate continued inquiry into contrastive objectives, and\ndemonstrates adaptation techniques to align small LLMs with privacy-sensitive\nmedical tasks.", "published": "2024-03-28 19:31:32", "link": "http://arxiv.org/abs/2403.19802v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multi-Stage Multi-Modal Pre-Training for Automatic Speech Recognition", "abstract": "Recent advances in machine learning have demonstrated that multi-modal\npre-training can improve automatic speech recognition (ASR) performance\ncompared to randomly initialized models, even when models are fine-tuned on\nuni-modal tasks. Existing multi-modal pre-training methods for the ASR task\nhave primarily focused on single-stage pre-training where a single unsupervised\ntask is used for pre-training followed by fine-tuning on the downstream task.\nIn this work, we introduce a novel method combining multi-modal and multi-task\nunsupervised pre-training with a translation-based supervised mid-training\napproach. We empirically demonstrate that such a multi-stage approach leads to\nrelative word error rate (WER) improvements of up to 38.45% over baselines on\nboth Librispeech and SUPERB. Additionally, we share several important findings\nfor choosing pre-training methods and datasets.", "published": "2024-03-28 20:23:39", "link": "http://arxiv.org/abs/2403.19822v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Jamba: A Hybrid Transformer-Mamba Language Model", "abstract": "We present Jamba, a new base large language model based on a novel hybrid\nTransformer-Mamba mixture-of-experts (MoE) architecture. Specifically, Jamba\ninterleaves blocks of Transformer and Mamba layers, enjoying the benefits of\nboth model families. MoE is added in some of these layers to increase model\ncapacity while keeping active parameter usage manageable. This flexible\narchitecture allows resource- and objective-specific configurations. In the\nparticular configuration we have implemented, we end up with a powerful model\nthat fits in a single 80GB GPU. Built at large scale, Jamba provides high\nthroughput and small memory footprint compared to vanilla Transformers, and at\nthe same time state-of-the-art performance on standard language model\nbenchmarks and long-context evaluations. Remarkably, the model presents strong\nresults for up to 256K tokens context length. We study various architectural\ndecisions, such as how to combine Transformer and Mamba layers, and how to mix\nexperts, and show that some of them are crucial in large scale modeling. We\nalso describe several interesting properties of these architectures which the\ntraining and evaluation of Jamba have revealed, and plan to release checkpoints\nfrom various ablation runs, to encourage further exploration of this novel\narchitecture. We make the weights of our implementation of Jamba publicly\navailable under a permissive license.", "published": "2024-03-28 23:55:06", "link": "http://arxiv.org/abs/2403.19887v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Review of Multi-Modal Large Language and Vision Models", "abstract": "Large Language Models (LLMs) have recently emerged as a focal point of\nresearch and application, driven by their unprecedented ability to understand\nand generate text with human-like quality. Even more recently, LLMs have been\nextended into multi-modal large language models (MM-LLMs) which extends their\ncapabilities to deal with image, video and audio information, in addition to\ntext. This opens up applications like text-to-video generation, image\ncaptioning, text-to-speech, and more and is achieved either by retro-fitting an\nLLM with multi-modal capabilities, or building a MM-LLM from scratch. This\npaper provides an extensive review of the current state of those LLMs with\nmulti-modal capabilities as well as the very recent MM-LLMs. It covers the\nhistorical development of LLMs especially the advances enabled by\ntransformer-based architectures like OpenAI's GPT series and Google's BERT, as\nwell as the role of attention mechanisms in enhancing model performance. The\npaper includes coverage of the major and most important of the LLMs and MM-LLMs\nand also covers the techniques of model tuning, including fine-tuning and\nprompt engineering, which tailor pre-trained models to specific tasks or\ndomains. Ethical considerations and challenges, such as data bias and model\nmisuse, are also analysed to underscore the importance of responsible AI\ndevelopment and deployment. Finally, we discuss the implications of open-source\nversus proprietary models in AI research. Through this review, we provide\ninsights into the transformative potential of MM-LLMs in various applications.", "published": "2024-03-28 15:53:45", "link": "http://arxiv.org/abs/2404.01322v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Model Of Information System Towards Harmonized Industry And Computer\n  Science", "abstract": "The aim of attending an educational institution is learning, which in turn is\nsought after for the reason of independence of thoughts, ideologies as well as\nphysical and material independence. This physical and material independence is\ngotten from working in the industry, that is, being a part of the independent\nworking population of the country. There needs to be a way by which students\nupon graduation can easily adapt to the real world with necessary skills and\nknowledge required. This problem has been a challenge in some computer science\ndepartments, which after effects known after the student begins to work in an\nindustry. The objectives of this project include: Designing a web based chat\napplication for the industry and computer science department, Develop a web\nbased chat application for the industry and computer science and Evaluate the\nweb based chat application for the industry and computer science department.\nWaterfall system development lifecycle is used in establishing a system project\nplan, because it gives an overall list of processes and sub-processes required\nin developing a system. The descriptive research method applied in this project\nis documentary analysis of previous articles. The result of the project is the\ndesign, software a web-based chat application that aids communication between\nthe industry and the computer science department and the evaluation of the\nsystem. The application is able to store this information which can be decided\nto be used later. Awareness of the software to companies and universities,\nimplementation of the suggestions made by the industry in the computer science\ncurriculum, use of this software in universities across Nigeria and use of this\nnot just in the computer science field but in other field of study", "published": "2024-03-28 16:53:08", "link": "http://arxiv.org/abs/2406.11848v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Automated Black-box Prompt Engineering for Personalized Text-to-Image\n  Generation", "abstract": "Prompt engineering is effective for controlling the output of text-to-image\n(T2I) generative models, but it is also laborious due to the need for manually\ncrafted prompts. This challenge has spurred the development of algorithms for\nautomated prompt generation. However, these methods often struggle with\ntransferability across T2I models, require white-box access to the underlying\nmodel, and produce non-intuitive prompts. In this work, we introduce PRISM, an\nalgorithm that automatically identifies human-interpretable and transferable\nprompts that can effectively generate desired concepts given only black-box\naccess to T2I models. Inspired by large language model (LLM) jailbreaking,\nPRISM leverages the in-context learning ability of LLMs to iteratively refine\nthe candidate prompts distribution for given reference images. Our experiments\ndemonstrate the versatility and effectiveness of PRISM in generating accurate\nprompts for objects, styles and images across multiple T2I models, including\nStable Diffusion, DALL-E, and Midjourney.", "published": "2024-03-28 02:35:53", "link": "http://arxiv.org/abs/2403.19103v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Top Leaderboard Ranking = Top Coding Proficiency, Always? EvoEval:\n  Evolving Coding Benchmarks via LLM", "abstract": "LLMs have become the go-to choice for code generation tasks, with an\nexponential increase in the training, development, and usage of LLMs\nspecifically for code generation. To evaluate the ability of LLMs on code, both\nacademic and industry practitioners rely on popular handcrafted benchmarks.\nHowever, prior benchmarks contain only a very limited set of problems, both in\nquantity and variety. Further, due to popularity and age, many benchmarks are\nprone to data leakage where example solutions can be readily found on the web\nand thus potentially in training data. Such limitations inevitably lead us to\ninquire: Is the leaderboard performance on existing benchmarks reliable and\ncomprehensive enough to measure the program synthesis ability of LLMs? To\naddress this, we introduce EvoEval -- a program synthesis benchmark suite\ncreated by evolving existing benchmarks into different targeted domains for a\ncomprehensive evaluation of LLM coding abilities. Our study on 51 LLMs shows\nthat compared to the high performance obtained on standard benchmarks like\nHumanEval, there is a significant drop in performance (on average 39.4%) when\nusing EvoEval. Additionally, the decrease in performance can range from 19.6%\nto 47.7%, leading to drastic ranking changes amongst LLMs and showing potential\noverfitting of existing benchmarks. Furthermore, we showcase various insights,\nincluding the brittleness of instruction-following models when encountering\nrewording or subtle changes as well as the importance of learning problem\ncomposition and decomposition. EvoEval not only provides comprehensive\nbenchmarks, but can be used to further evolve arbitrary problems to keep up\nwith advances and the ever-changing landscape of LLMs for code. We have\nopen-sourced our benchmarks, tools, and complete LLM generations at\nhttps://github.com/evo-eval/evoeval", "published": "2024-03-28 03:10:39", "link": "http://arxiv.org/abs/2403.19114v1", "categories": ["cs.SE", "cs.CL", "cs.LG", "cs.PL"], "primary_category": "cs.SE"}
{"title": "Make Large Language Model a Better Ranker", "abstract": "Large Language Models (LLMs) demonstrate robust capabilities across various\nfields, leading to a paradigm shift in LLM-enhanced Recommender System (RS).\nResearch to date focuses on point-wise and pair-wise recommendation paradigms,\nwhich are inefficient for LLM-based recommenders due to high computational\ncosts. However, existing list-wise approaches also fall short in ranking tasks\ndue to misalignment between ranking objectives and next-token prediction.\nMoreover, these LLM-based methods struggle to effectively address the order\nrelation among candidates, particularly given the scale of ratings. To address\nthese challenges, this paper introduces the large language model framework with\nAligned Listwise Ranking Objectives (ALRO). ALRO is designed to bridge the gap\nbetween the capabilities of LLMs and the nuanced requirements of ranking tasks.\nSpecifically, ALRO employs explicit feedback in a listwise manner by\nintroducing soft lambda loss, a customized adaptation of lambda loss designed\nfor optimizing order relations. This mechanism provides more accurate\noptimization goals, enhancing the ranking process. Additionally, ALRO\nincorporates a permutation-sensitive learning mechanism that addresses position\nbias, a prevalent issue in generative models, without imposing additional\ncomputational burdens during inference. Our evaluative studies reveal that ALRO\noutperforms both existing embedding-based recommendation methods and LLM-based\nrecommendation baselines.", "published": "2024-03-28 07:22:16", "link": "http://arxiv.org/abs/2403.19181v3", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Dual-Personalizing Adapter for Federated Foundation Models", "abstract": "Recently, foundation models, particularly large language models (LLMs), have\ndemonstrated an impressive ability to adapt to various tasks by fine-tuning\ndiverse instruction data. Notably, federated foundation models (FedFM) emerge\nas a privacy preservation method to fine-tune models collaboratively under\nfederated learning (FL) settings by leveraging many distributed datasets with\nnon-IID data. To alleviate communication and computation overhead,\nparameter-efficient methods are introduced for efficiency, and some research\nadapted personalization methods to FedFM for better user preferences alignment.\nHowever, a critical gap in existing research is the neglect of test-time\ndistribution shifts in real-world applications, and conventional methods for\ntest-time distribution shifts in personalized FL are less effective for FedFM\ndue to their failure to adapt to complex distribution shift scenarios and the\nrequirement to train all parameters. To bridge this gap, we refine the setting\nin FedFM, termed test-time personalization, which aims to learn personalized\nfederated foundation models on clients while effectively handling test-time\ndistribution shifts simultaneously. To address challenges in this setting, we\nexplore a simple yet effective solution, a Federated Dual-Personalizing Adapter\n(FedDPA) architecture. By co-working with a foundation model, a global adapter\nand a local adapter jointly tackle the test-time distribution shifts and\nclient-specific personalization. Additionally, we introduce an instance-wise\ndynamic weighting mechanism that dynamically integrates the global and local\nadapters for each test instance during inference, facilitating effective\ntest-time personalization. The effectiveness of the proposed method has been\nevaluated on benchmark datasets across different NLP tasks.", "published": "2024-03-28 08:19:33", "link": "http://arxiv.org/abs/2403.19211v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Fine-Tuning Language Models with Reward Learning on Policy", "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as an effective\napproach to aligning large language models (LLMs) to human preferences. RLHF\ncontains three steps, i.e., human preference collecting, reward learning, and\npolicy optimization, which are usually performed serially. Despite its\npopularity, however, (fixed) reward models may suffer from inaccurate\noff-distribution, since policy optimization continuously shifts LLMs' data\ndistribution. Repeatedly collecting new preference data from the latest LLMs\nmay alleviate this issue, which unfortunately makes the resulting system more\ncomplicated and difficult to optimize. In this paper, we propose reward\nlearning on policy (RLP), an unsupervised framework that refines a reward model\nusing policy samples to keep it on-distribution. Specifically, an unsupervised\nmulti-view learning method is introduced to learn robust representations of\npolicy samples. Meanwhile, a synthetic preference generation approach is\ndeveloped to simulate high-quality preference data with policy outputs.\nExtensive experiments on three benchmark datasets show that RLP consistently\noutperforms the state-of-the-art. Our code is available at\n\\url{https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/rlp}.", "published": "2024-03-28 10:02:10", "link": "http://arxiv.org/abs/2403.19279v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Phonetic Segmentation of the UCLA Phonetics Lab Archive", "abstract": "Research in speech technologies and comparative linguistics depends on access\nto diverse and accessible speech data. The UCLA Phonetics Lab Archive is one of\nthe earliest multilingual speech corpora, with long-form audio recordings and\nphonetic transcriptions for 314 languages (Ladefoged et al., 2009). Recently,\n95 of these languages were time-aligned with word-level phonetic transcriptions\n(Li et al., 2021). Here we present VoxAngeles, a corpus of audited phonetic\ntranscriptions and phone-level alignments of the UCLA Phonetics Lab Archive,\nwhich uses the 95-language CMU re-release as our starting point. VoxAngeles\nalso includes word- and phone-level segmentations from the original UCLA\ncorpus, as well as phonetic measurements of word and phone durations, vowel\nformants, and vowel f0. This corpus enhances the usability of the original\ndata, particularly for quantitative phonetic typology, as demonstrated through\na case study of vowel intrinsic f0. We also discuss the utility of the\nVoxAngeles corpus for general research and pedagogy in crosslinguistic\nphonetics, as well as for low-resource and multilingual speech technologies.\nVoxAngeles is free to download and use under a CC-BY-NC 4.0 license.", "published": "2024-03-28 15:42:07", "link": "http://arxiv.org/abs/2403.19509v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Interpreting Key Mechanisms of Factual Recall in Transformer-Based\n  Language Models", "abstract": "In this paper, we delve into several mechanisms employed by Transformer-based\nlanguage models (LLMs) for factual recall tasks. We outline a pipeline\nconsisting of three major steps: (1) Given a prompt ``The capital of France\nis,'' task-specific attention heads extract the topic token, such as\n``France,'' from the context and pass it to subsequent MLPs. (2) As attention\nheads' outputs are aggregated with equal weight and added to the residual\nstream, the subsequent MLP acts as an ``activation,'' which either erases or\namplifies the information originating from individual heads. As a result, the\ntopic token ``France'' stands out in the residual stream. (3) A deep MLP takes\n``France'' and generates a component that redirects the residual stream towards\nthe direction of the correct answer, i.e., ``Paris.'' This procedure is akin to\napplying an implicit function such as ``get\\_capital($X$),'' and the argument\n$X$ is the topic token information passed by attention heads. To achieve the\nabove quantitative and qualitative analysis for MLPs, we proposed a novel\nanalytic method aimed at decomposing the outputs of the MLP into components\nunderstandable by humans. Additionally, we observed a universal\nanti-overconfidence mechanism in the final layer of models, which suppresses\ncorrect predictions. We mitigate this suppression by leveraging our\ninterpretation to improve factual recall confidence. The above interpretations\nare evaluated across diverse tasks spanning various domains of factual\nknowledge, using various language models from the GPT-2 families, 1.3B OPT, up\nto 7B Llama-2, and in both zero- and few-shot setups.", "published": "2024-03-28 15:54:59", "link": "http://arxiv.org/abs/2403.19521v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Semantic Map-based Generation of Navigation Instructions", "abstract": "We are interested in the generation of navigation instructions, either in\ntheir own right or as training material for robotic navigation task. In this\npaper, we propose a new approach to navigation instruction generation by\nframing the problem as an image captioning task using semantic maps as visual\ninput. Conventional approaches employ a sequence of panorama images to generate\nnavigation instructions. Semantic maps abstract away from visual details and\nfuse the information in multiple panorama images into a single top-down\nrepresentation, thereby reducing computational complexity to process the input.\nWe present a benchmark dataset for instruction generation using semantic maps,\npropose an initial model and ask human subjects to manually assess the quality\nof generated instructions. Our initial investigations show promise in using\nsemantic maps for instruction generation instead of a sequence of panorama\nimages, but there is vast scope for improvement. We release the code for data\npreparation and model training at https://github.com/chengzu-li/VLGen.", "published": "2024-03-28 17:27:44", "link": "http://arxiv.org/abs/2403.19603v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop\n  Question Answering", "abstract": "Large Language Models (LLMs) have shown proficiency in question-answering\ntasks but often struggle to integrate real-time knowledge, leading to\npotentially outdated or inaccurate responses. This problem becomes even more\nchallenging when dealing with multi-hop questions, since they require LLMs to\nupdate and integrate multiple knowledge pieces relevant to the questions. To\ntackle the problem, we propose the Retrieval-Augmented model Editing (RAE)\nframework for multi-hop question answering. RAE first retrieves edited facts\nand then refines the language model through in-context learning. Specifically,\nour retrieval approach, based on mutual information maximization, leverages the\nreasoning abilities of LLMs to identify chain facts that traditional\nsimilarity-based searches might miss. In addition, our framework includes a\npruning strategy to eliminate redundant information from the retrieved facts,\nwhich enhances the editing accuracy and mitigates the hallucination problem.\nOur framework is supported by theoretical justification for its fact retrieval\nefficacy. Finally, comprehensive evaluation across various LLMs validates RAE's\nability in providing accurate answers with updated knowledge. Our code is\navailable at: https://github.com/sycny/RAE.", "published": "2024-03-28 17:47:19", "link": "http://arxiv.org/abs/2403.19631v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Asymmetric and trial-dependent modeling: the contribution of LIA to SdSV\n  Challenge Task 2", "abstract": "The SdSv challenge Task 2 provided an opportunity to assess efficiency and\nrobustness of modern text-independent speaker verification systems. But it also\nmade it possible to test new approaches, capable of taking into account the\nmain issues of this challenge (duration, language, ...). This paper describes\nthe contributions of our laboratory to the speaker recognition field. These\ncontributions highlight two other challenges in addition to short-duration and\nlanguage: the mismatch between enrollment and test data and the one between\nsubsets of the evaluation trial dataset. The proposed approaches experimentally\nshow their relevance and efficiency on the SdSv evaluation, and could be of\ninterest in many real-life applications.", "published": "2024-03-28 17:49:31", "link": "http://arxiv.org/abs/2403.19634v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Sparse Feature Circuits: Discovering and Editing Interpretable Causal\n  Graphs in Language Models", "abstract": "We introduce methods for discovering and applying sparse feature circuits.\nThese are causally implicated subnetworks of human-interpretable features for\nexplaining language model behaviors. Circuits identified in prior work consist\nof polysemantic and difficult-to-interpret units like attention heads or\nneurons, rendering them unsuitable for many downstream applications. In\ncontrast, sparse feature circuits enable detailed understanding of\nunanticipated mechanisms. Because they are based on fine-grained units, sparse\nfeature circuits are useful for downstream tasks: We introduce SHIFT, where we\nimprove the generalization of a classifier by ablating features that a human\njudges to be task-irrelevant. Finally, we demonstrate an entirely unsupervised\nand scalable interpretability pipeline by discovering thousands of sparse\nfeature circuits for automatically discovered model behaviors.", "published": "2024-03-28 17:56:07", "link": "http://arxiv.org/abs/2403.19647v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "HeGTa: Leveraging Heterogeneous Graph-enhanced Large Language Models for\n  Few-shot Complex Table Understanding", "abstract": "Table understanding (TU) has achieved promising advancements, but it faces\nthe challenges of the scarcity of manually labeled tables and the presence of\ncomplex table structures.To address these challenges, we propose HGT, a\nframework with a heterogeneous graph (HG)-enhanced large language model (LLM)\nto tackle few-shot TU tasks.It leverages the LLM by aligning the table\nsemantics with the LLM's parametric knowledge through soft prompts and\ninstruction turning and deals with complex tables by a multi-task pre-training\nscheme involving three novel multi-granularity self-supervised HG pre-training\nobjectives.We empirically demonstrate the effectiveness of HGT, showing that it\noutperforms the SOTA for few-shot complex TU on several benchmarks.", "published": "2024-03-28 03:20:54", "link": "http://arxiv.org/abs/2403.19723v2", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.MM"], "primary_category": "cs.CL"}
{"title": "MUGC: Machine Generated versus User Generated Content Detection", "abstract": "As advanced modern systems like deep neural networks (DNNs) and generative AI\ncontinue to enhance their capabilities in producing convincing and realistic\ncontent, the need to distinguish between user-generated and machine generated\ncontent is becoming increasingly evident. In this research, we undertake a\ncomparative evaluation of eight traditional machine-learning algorithms to\ndistinguish between machine-generated and human-generated data across three\ndiverse datasets: Poems, Abstracts, and Essays. Our results indicate that\ntraditional methods demonstrate a high level of accuracy in identifying\nmachine-generated data, reflecting the documented effectiveness of popular\npre-trained models like RoBERT. We note that machine-generated texts tend to be\nshorter and exhibit less word variety compared to human-generated content.\nWhile specific domain-related keywords commonly utilized by humans, albeit\ndisregarded by current LLMs (Large Language Models), may contribute to this\nhigh detection accuracy, we show that deeper word representations like word2vec\ncan capture subtle semantic variances. Furthermore, readability, bias, moral,\nand affect comparisons reveal a discernible contrast between machine-generated\nand human generated content. There are variations in expression styles and\npotentially underlying biases in the data sources (human and\nmachine-generated). This study provides valuable insights into the advancing\ncapacities and challenges associated with machine-generated content across\nvarious domains.", "published": "2024-03-28 07:33:53", "link": "http://arxiv.org/abs/2403.19725v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Benchmark Evaluation of Clinical Named Entity Recognition in French", "abstract": "Background: Transformer-based language models have shown strong performance\non many Natural LanguageProcessing (NLP) tasks. Masked Language Models (MLMs)\nattract sustained interest because they can be adaptedto different languages\nand sub-domains through training or fine-tuning on specific corpora while\nremaining lighterthan modern Large Language Models (LLMs). Recently, several\nMLMs have been released for the biomedicaldomain in French, and experiments\nsuggest that they outperform standard French counterparts. However,\nnosystematic evaluation comparing all models on the same corpora is available.\nObjective: This paper presentsan evaluation of masked language models for\nbiomedical French on the task of clinical named entity recognition.Material and\nmethods: We evaluate biomedical models CamemBERT-bio and DrBERT and compare\nthem tostandard French models CamemBERT, FlauBERT and FrALBERT as well as\nmultilingual mBERT using three publicallyavailable corpora for clinical named\nentity recognition in French. The evaluation set-up relies on\ngold-standardcorpora as released by the corpus developers. Results: Results\nsuggest that CamemBERT-bio outperformsDrBERT consistently while FlauBERT offers\ncompetitive performance and FrAlBERT achieves the lowest carbonfootprint.\nConclusion: This is the first benchmark evaluation of biomedical masked\nlanguage models for Frenchclinical entity recognition that compares model\nperformance consistently on nested entity recognition using metricscovering\nperformance and environmental impact.", "published": "2024-03-28 07:59:58", "link": "http://arxiv.org/abs/2403.19726v1", "categories": ["cs.CL", "cs.AI", "q-bio.QM"], "primary_category": "cs.CL"}
{"title": "EmoScan: Automatic Screening of Depression Symptoms in Romanized Sinhala\n  Tweets", "abstract": "This work explores the utilization of Romanized Sinhala social media data to\nidentify individuals at risk of depression. A machine learning-based framework\nis presented for the automatic screening of depression symptoms by analyzing\nlanguage patterns, sentiment, and behavioural cues within a comprehensive\ndataset of social media posts. The research has been carried out to compare the\nsuitability of Neural Networks over the classical machine learning techniques.\nThe proposed Neural Network with an attention layer which is capable of\nhandling long sequence data, attains a remarkable accuracy of 93.25% in\ndetecting depression symptoms, surpassing current state-of-the-art methods.\nThese findings underscore the efficacy of this approach in pinpointing\nindividuals in need of proactive interventions and support. Mental health\nprofessionals, policymakers, and social media companies can gain valuable\ninsights through the proposed model. Leveraging natural language processing\ntechniques and machine learning algorithms, this work offers a promising\npathway for mental health screening in the digital era. By harnessing the\npotential of social media data, the framework introduces a proactive method for\nrecognizing and assisting individuals at risk of depression. In conclusion,\nthis research contributes to the advancement of proactive interventions and\nsupport systems for mental health, thereby influencing both research and\npractical applications in the field.", "published": "2024-03-28 10:31:09", "link": "http://arxiv.org/abs/2403.19728v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Quantum Natural Language Processing", "abstract": "Language processing is at the heart of current developments in artificial\nintelligence, and quantum computers are becoming available at the same time.\nThis has led to great interest in quantum natural language processing, and\nseveral early proposals and experiments.\n  This paper surveys the state of this area, showing how NLP-related techniques\nhave been used in quantum language processing. We examine the art of word\nembeddings and sequential models, proposing some avenues for future\ninvestigation and discussing the tradeoffs present in these directions. We also\nhighlight some recent methods to compute attention in transformer models, and\nperform grammatical parsing. We also introduce a new quantum design for the\nbasic task of text encoding (representing a string of characters in memory),\nwhich has not been addressed in detail before.\n  Quantum theory has contributed toward quantifying uncertainty and explaining\n\"What is intelligence?\" In this context, we argue that \"hallucinations\" in\nmodern artificial intelligence systems are a misunderstanding of the way facts\nare conceptualized: language can express many plausible hypotheses, of which\nonly a few become actual.", "published": "2024-03-28 18:15:07", "link": "http://arxiv.org/abs/2403.19758v2", "categories": ["quant-ph", "cs.AI", "cs.CL"], "primary_category": "quant-ph"}
{"title": "The New Agronomists: Language Models are Experts in Crop Management", "abstract": "Crop management plays a crucial role in determining crop yield, economic\nprofitability, and environmental sustainability. Despite the availability of\nmanagement guidelines, optimizing these practices remains a complex and\nmultifaceted challenge. In response, previous studies have explored using\nreinforcement learning with crop simulators, typically employing simple\nneural-network-based reinforcement learning (RL) agents. Building on this\nfoundation, this paper introduces a more advanced intelligent crop management\nsystem. This system uniquely combines RL, a language model (LM), and crop\nsimulations facilitated by the Decision Support System for Agrotechnology\nTransfer (DSSAT). We utilize deep RL, specifically a deep Q-network, to train\nmanagement policies that process numerous state variables from the simulator as\nobservations. A novel aspect of our approach is the conversion of these state\nvariables into more informative language, facilitating the language model's\ncapacity to understand states and explore optimal management practices. The\nempirical results reveal that the LM exhibits superior learning capabilities.\nThrough simulation experiments with maize crops in Florida (US) and Zaragoza\n(Spain), the LM not only achieves state-of-the-art performance under various\nevaluation metrics but also demonstrates a remarkable improvement of over 49\\%\nin economic profit, coupled with reduced environmental impact when compared to\nbaseline methods. Our code is available at\n\\url{https://github.com/jingwu6/LM_AG}.", "published": "2024-03-28 21:20:27", "link": "http://arxiv.org/abs/2403.19839v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Localizing Paragraph Memorization in Language Models", "abstract": "Can we localize the weights and mechanisms used by a language model to\nmemorize and recite entire paragraphs of its training data? In this paper, we\nshow that while memorization is spread across multiple layers and model\ncomponents, gradients of memorized paragraphs have a distinguishable spatial\npattern, being larger in lower model layers than gradients of non-memorized\nexamples. Moreover, the memorized examples can be unlearned by fine-tuning only\nthe high-gradient weights. We localize a low-layer attention head that appears\nto be especially involved in paragraph memorization. This head is predominantly\nfocusing its attention on distinctive, rare tokens that are least frequent in a\ncorpus-level unigram distribution. Next, we study how localized memorization is\nacross the tokens in the prefix by perturbing tokens and measuring the caused\nchange in the decoding. A few distinctive tokens early in a prefix can often\ncorrupt the entire continuation. Overall, memorized continuations are not only\nharder to unlearn, but also to corrupt than non-memorized ones.", "published": "2024-03-28 21:53:24", "link": "http://arxiv.org/abs/2403.19851v1", "categories": ["cs.CL", "cs.CR", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions", "abstract": "Image retrieval, i.e., finding desired images given a reference image,\ninherently encompasses rich, multi-faceted search intents that are difficult to\ncapture solely using image-based measures. Recent works leverage text\ninstructions to allow users to more freely express their search intents.\nHowever, they primarily focus on image pairs that are visually similar and/or\ncan be characterized by a small set of pre-defined relations. The core thesis\nof this paper is that text instructions can enable retrieving images with\nricher relations beyond visual similarity. To show this, we introduce\nMagicLens, a series of self-supervised image retrieval models that support\nopen-ended instructions. MagicLens is built on a key novel insight: image pairs\nthat naturally occur on the same web pages contain a wide range of implicit\nrelations (e.g., inside view of), and we can bring those implicit relations\nexplicit by synthesizing instructions via foundation models. Trained on 36.7M\n(query image, instruction, target image) triplets with rich semantic relations\nmined from the web, MagicLens achieves results comparable with or better than\nprior best on eight benchmarks of various image retrieval tasks, while\nmaintaining high parameter efficiency with a significantly smaller model size.\nAdditional human analyses on a 1.4M-image unseen corpus further demonstrate the\ndiversity of search intents supported by MagicLens. Code and models are\npublicly available at https://open-vision-language.github.io/MagicLens/.", "published": "2024-03-28 17:59:20", "link": "http://arxiv.org/abs/2403.19651v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.IR", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Concept-based Analysis of Neural Networks via Vision-Language Models", "abstract": "The analysis of vision-based deep neural networks (DNNs) is highly desirable\nbut it is very challenging due to the difficulty of expressing formal\nspecifications for vision tasks and the lack of efficient verification\nprocedures. In this paper, we propose to leverage emerging multimodal,\nvision-language, foundation models (VLMs) as a lens through which we can reason\nabout vision models. VLMs have been trained on a large body of images\naccompanied by their textual description, and are thus implicitly aware of\nhigh-level, human-understandable concepts describing the images. We describe a\nlogical specification language $\\texttt{Con}_{\\texttt{spec}}$ designed to\nfacilitate writing specifications in terms of these concepts. To define and\nformally check $\\texttt{Con}_{\\texttt{spec}}$ specifications, we build a map\nbetween the internal representations of a given vision model and a VLM, leading\nto an efficient verification procedure of natural-language properties for\nvision models. We demonstrate our techniques on a ResNet-based classifier\ntrained on the RIVAL-10 dataset using CLIP as the multimodal model.", "published": "2024-03-28 21:15:38", "link": "http://arxiv.org/abs/2403.19837v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.LO"], "primary_category": "cs.LG"}
{"title": "NativE: Multi-modal Knowledge Graph Completion in the Wild", "abstract": "Multi-modal knowledge graph completion (MMKGC) aims to automatically discover\nthe unobserved factual knowledge from a given multi-modal knowledge graph by\ncollaboratively modeling the triple structure and multi-modal information from\nentities. However, real-world MMKGs present challenges due to their diverse and\nimbalanced nature, which means that the modality information can span various\ntypes (e.g., image, text, numeric, audio, video) but its distribution among\nentities is uneven, leading to missing modalities for certain entities.\nExisting works usually focus on common modalities like image and text while\nneglecting the imbalanced distribution phenomenon of modal information. To\naddress these issues, we propose a comprehensive framework NativE to achieve\nMMKGC in the wild. NativE proposes a relation-guided dual adaptive fusion\nmodule that enables adaptive fusion for any modalities and employs a\ncollaborative modality adversarial training framework to augment the imbalanced\nmodality information. We construct a new benchmark called WildKGC with five\ndatasets to evaluate our method. The empirical results compared with 21 recent\nbaselines confirm the superiority of our method, consistently achieving\nstate-of-the-art performance across different datasets and various scenarios\nwhile keeping efficient and generalizable. Our code and data are released at\nhttps://github.com/zjukg/NATIVE", "published": "2024-03-28 03:04:00", "link": "http://arxiv.org/abs/2406.17605v1", "categories": ["cs.MM", "cs.AI", "cs.CL", "cs.CV", "cs.IR"], "primary_category": "cs.MM"}
{"title": "LV-CTC: Non-autoregressive ASR with CTC and latent variable models", "abstract": "Non-autoregressive (NAR) models for automatic speech recognition (ASR) aim to\nachieve high accuracy and fast inference by simplifying the autoregressive (AR)\ngeneration process of conventional models. Connectionist temporal\nclassification (CTC) is one of the key techniques used in NAR ASR models. In\nthis paper, we propose a new model combining CTC and a latent variable model,\nwhich is one of the state-of-the-art models in the neural machine translation\nresearch field. A new neural network architecture and formulation specialized\nfor ASR application are introduced. In the proposed model, CTC alignment is\nassumed to be dependent on the latent variables that are expected to capture\ndependencies between tokens. Experimental results on a 100 hours subset of\nLibrispeech corpus showed the best recognition accuracy among CTC-based NAR\nmodels. On the TED-LIUM2 corpus, the best recognition accuracy is achieved\nincluding AR E2E models with faster inference speed.", "published": "2024-03-28 08:08:53", "link": "http://arxiv.org/abs/2403.19207v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Blind Identification of Binaural Room Impulse Responses from Smart\n  Glasses", "abstract": "Smart glasses are increasingly recognized as a key medium for augmented\nreality, offering a hands-free platform with integrated microphones and\nnon-ear-occluding loudspeakers to seamlessly mix virtual sound sources into the\nreal-world acoustic scene. To convincingly integrate virtual sound sources, the\nroom acoustic rendering of the virtual sources must match the real-world\nacoustics. Information about a user's acoustic environment however is typically\nnot available. This work uses a microphone array in a pair of smart glasses to\nblindly identify binaural room impulse responses (BRIRs) from a few seconds of\nspeech in the real-world environment. The proposed method uses dereverberation\nand beamforming to generate a pseudo reference signal that is used by a\nmultichannel Wiener filter to estimate room impulse responses which are then\nconverted to BRIRs. The multichannel room impulse responses can be used to\nestimate room acoustic parameters which is shown to outperform baseline\nalgorithms in the estimation of reverberation time and direct-to-reverberant\nenergy ratio. Results from a listening experiment further indicate that the\nestimated BRIRs often reproduce the real-world room acoustics perceptually more\nconvincingly than measured BRIRs from other rooms of similar size.", "published": "2024-03-28 08:30:14", "link": "http://arxiv.org/abs/2403.19217v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Emotion Neural Transducer for Fine-Grained Speech Emotion Recognition", "abstract": "The mainstream paradigm of speech emotion recognition (SER) is identifying\nthe single emotion label of the entire utterance. This line of works neglect\nthe emotion dynamics at fine temporal granularity and mostly fail to leverage\nlinguistic information of speech signal explicitly. In this paper, we propose\nEmotion Neural Transducer for fine-grained speech emotion recognition with\nautomatic speech recognition (ASR) joint training. We first extend typical\nneural transducer with emotion joint network to construct emotion lattice for\nfine-grained SER. Then we propose lattice max pooling on the alignment lattice\nto facilitate distinguishing emotional and non-emotional frames. To adapt\nfine-grained SER to transducer inference manner, we further make blank, the\nspecial symbol of ASR, serve as underlying emotion indicator as well, yielding\nFactorized Emotion Neural Transducer. For typical utterance-level SER, our ENT\nmodels outperform state-of-the-art methods on IEMOCAP in low word error rate.\nExperiments on IEMOCAP and the latest speech emotion diarization dataset ZED\nalso demonstrate the superiority of fine-grained emotion modeling. Our code is\navailable at https://github.com/ECNU-Cross-Innovation-Lab/ENT.", "published": "2024-03-28 08:38:43", "link": "http://arxiv.org/abs/2403.19224v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Novel Stochastic Transformer-based Approach for Post-Traumatic Stress\n  Disorder Detection using Audio Recording of Clinical Interviews", "abstract": "Post-traumatic stress disorder (PTSD) is a mental disorder that can be\ndeveloped after witnessing or experiencing extremely traumatic events. PTSD can\naffect anyone, regardless of ethnicity, or culture. An estimated one in every\neleven people will experience PTSD during their lifetime. The\nClinician-Administered PTSD Scale (CAPS) and the PTSD Check List for Civilians\n(PCL-C) interviews are gold standards in the diagnosis of PTSD. These\nquestionnaires can be fooled by the subject's responses. This work proposes a\ndeep learning-based approach that achieves state-of-the-art performances for\nPTSD detection using audio recordings during clinical interviews. Our approach\nis based on MFCC low-level features extracted from audio recordings of clinical\ninterviews, followed by deep high-level learning using a Stochastic\nTransformer. Our proposed approach achieves state-of-the-art performances with\nan RMSE of 2.92 on the eDAIC dataset thanks to the stochastic depth, stochastic\ndeep learning layers, and stochastic activation function.", "published": "2024-03-28 14:11:40", "link": "http://arxiv.org/abs/2403.19441v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Siamese Vision Transformers are Scalable Audio-visual Learners", "abstract": "Traditional audio-visual methods rely on independent audio and visual\nbackbones, which is costly and not scalable. In this work, we investigate using\nan audio-visual siamese network (AVSiam) for efficient and scalable\naudio-visual pretraining. Our framework uses a single shared vision transformer\nbackbone to process audio and visual inputs, improving its parameter\nefficiency, reducing the GPU memory footprint, and allowing us to scale our\nmethod to larger datasets and model sizes. We pretrain our model using a\ncontrastive audio-visual matching objective with a multi-ratio random masking\nscheme, which enables our model to process larger audio-visual instance\nbatches, helpful for contrastive learning. Unlike prior audio-visual methods,\nour method can robustly handle audio, visual, and audio-visual inputs with a\nsingle shared ViT backbone. Furthermore, despite using the shared backbone for\nboth modalities, AVSiam achieves competitive or even better results than prior\nmethods on AudioSet and VGGSound for audio-visual classification and retrieval.\nOur code is available at https://github.com/GenjiB/AVSiam", "published": "2024-03-28 17:52:24", "link": "http://arxiv.org/abs/2403.19638v1", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Creating Aesthetic Sonifications on the Web with SIREN", "abstract": "SIREN is a flexible, extensible, and customizable web-based general-purpose\ninterface for auditory data display (sonification). Designed as a digital audio\nworkstation for sonification, synthesizers written in JavaScript using the Web\nAudio API facilitate intuitive mapping of data to auditory parameters for a\nwide range of purposes.\n  This paper explores the breadth of sound synthesis techniques supported by\nSIREN, and details the structure and definition of a SIREN synthesizer module.\nThe paper proposes further development that will increase SIREN's utility.", "published": "2024-03-28 18:24:09", "link": "http://arxiv.org/abs/2403.19763v1", "categories": ["cs.SD", "cs.HC", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
