{"title": "Sparse Named Entity Classification using Factorization Machines", "abstract": "Named entity classification is the task of classifying text-based elements\ninto various categories, including places, names, dates, times, and monetary\nvalues. A bottleneck in named entity classification, however, is the data\nproblem of sparseness, because new named entities continually emerge, making it\nrather difficult to maintain a dictionary for named entity classification.\nThus, in this paper, we address the problem of named entity classification\nusing matrix factorization to overcome the problem of feature sparsity.\nExperimental results show that our proposed model, with fewer features and a\nsmaller size, achieves competitive accuracy to state-of-the-art models.", "published": "2017-03-15 01:54:52", "link": "http://arxiv.org/abs/1703.04879v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Neural Machine Translation with Conditional Sequence\n  Generative Adversarial Nets", "abstract": "This paper proposes an approach for applying GANs to NMT. We build a\nconditional sequence generative adversarial net which comprises of two\nadversarial sub models, a generator and a discriminator. The generator aims to\ngenerate sentences which are hard to be discriminated from human-translated\nsentences (i.e., the golden target sentences), And the discriminator makes\nefforts to discriminate the machine-generated sentences from human-translated\nones. The two sub models play a mini-max game and achieve the win-win situation\nwhen they reach a Nash Equilibrium. Additionally, the static sentence-level\nBLEU is utilized as the reinforced objective for the generator, which biases\nthe generation towards high BLEU points. During training, both the dynamic\ndiscriminator and the static BLEU objective are employed to evaluate the\ngenerated sentences and feedback the evaluations to guide the learning of the\ngenerator. Experimental results show that the proposed model consistently\noutperforms the traditional RNNSearch and the newly emerged state-of-the-art\nTransformer on English-German and Chinese-English translation tasks.", "published": "2017-03-15 02:26:25", "link": "http://arxiv.org/abs/1703.04887v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SyntaxNet Models for the CoNLL 2017 Shared Task", "abstract": "We describe a baseline dependency parsing system for the CoNLL2017 Shared\nTask. This system, which we call \"ParseySaurus,\" uses the DRAGNN framework\n[Kong et al, 2017] to combine transition-based recurrent parsing and tagging\nwith character-based word representations. On the v1.3 Universal Dependencies\nTreebanks, the new system outpeforms the publicly available, state-of-the-art\n\"Parsey's Cousins\" models by 3.47% absolute Labeled Accuracy Score (LAS) across\n52 treebanks.", "published": "2017-03-15 04:57:17", "link": "http://arxiv.org/abs/1703.04929v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Is this word borrowed? An automatic approach to quantify the likeliness\n  of borrowing in social media", "abstract": "Code-mixing or code-switching are the effortless phenomena of natural\nswitching between two or more languages in a single conversation. Use of a\nforeign word in a language; however, does not necessarily mean that the speaker\nis code-switching because often languages borrow lexical items from other\nlanguages. If a word is borrowed, it becomes a part of the lexicon of a\nlanguage; whereas, during code-switching, the speaker is aware that the\nconversation involves foreign words or phrases. Identifying whether a foreign\nword used by a bilingual speaker is due to borrowing or code-switching is a\nfundamental importance to theories of multilingualism, and an essential\nprerequisite towards the development of language and speech technologies for\nmultilingual communities. In this paper, we present a series of novel\ncomputational methods to identify the borrowed likeliness of a word, based on\nthe social media signals. We first propose context based clustering method to\nsample a set of candidate words from the social media data.Next, we propose\nthree novel and similar metrics based on the usage of these words by the users\nin different tweets; these metrics were used to score and rank the candidate\nwords indicating their borrowed likeliness. We compare these rankings with a\nground truth ranking constructed through a human judgment experiment. The\nSpearman's rank correlation between the two rankings (nearly 0.62 for all the\nthree metric variants) is more than double the value (0.26) of the most\ncompetitive existing baseline reported in the literature. Some other striking\nobservations are, (i) the correlation is higher for the ground truth data\nelicited from the younger participants (age less than 30) than that from the\nolder participants, and (ii )those participants who use mixed-language for\ntweeting the least, provide the best signals of borrowing.", "published": "2017-03-15 12:32:34", "link": "http://arxiv.org/abs/1703.05122v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "End-to-end optimization of goal-driven and visually grounded dialogue\n  systems", "abstract": "End-to-end design of dialogue systems has recently become a popular research\ntopic thanks to powerful tools such as encoder-decoder architectures for\nsequence-to-sequence learning. Yet, most current approaches cast human-machine\ndialogue management as a supervised learning problem, aiming at predicting the\nnext utterance of a participant given the full history of the dialogue. This\nvision is too simplistic to render the intrinsic planning problem inherent to\ndialogue as well as its grounded nature, making the context of a dialogue\nlarger than the sole history. This is why only chit-chat and question answering\ntasks have been addressed so far using end-to-end architectures. In this paper,\nwe introduce a Deep Reinforcement Learning method to optimize visually grounded\ntask-oriented dialogues, based on the policy gradient algorithm. This approach\nis tested on a dataset of 120k dialogues collected through Mechanical Turk and\nprovides encouraging results at solving both the problem of generating natural\ndialogues and the task of discovering a specific object in a complex picture.", "published": "2017-03-15 23:34:20", "link": "http://arxiv.org/abs/1703.05423v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Distributed-Representation Based Hybrid Recommender System with Short\n  Item Descriptions", "abstract": "Collaborative filtering (CF) aims to build a model from users' past behaviors\nand/or similar decisions made by other users, and use the model to recommend\nitems for users. Despite of the success of previous collaborative filtering\napproaches, they are all based on the assumption that there are sufficient\nrating scores available for building high-quality recommendation models. In\nreal world applications, however, it is often difficult to collect sufficient\nrating scores, especially when new items are introduced into the system, which\nmakes the recommendation task challenging. We find that there are often \"short\"\ntexts describing features of items, based on which we can approximate the\nsimilarity of items and make recommendation together with rating scores. In\nthis paper we \"borrow\" the idea of vector representation of words to capture\nthe information of short texts and embed it into a matrix factorization\nframework. We empirically show that our approach is effective by comparing it\nwith state-of-the-art approaches.", "published": "2017-03-15 00:47:28", "link": "http://arxiv.org/abs/1703.04854v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Emergence of Grounded Compositional Language in Multi-Agent Populations", "abstract": "By capturing statistical patterns in large corpora, machine learning has\nenabled significant advances in natural language processing, including in\nmachine translation, question answering, and sentiment analysis. However, for\nagents to intelligently interact with humans, simply capturing the statistical\npatterns is insufficient. In this paper we investigate if, and how, grounded\ncompositional language can emerge as a means to achieve goals in multi-agent\npopulations. Towards this end, we propose a multi-agent learning environment\nand learning methods that bring about emergence of a basic compositional\nlanguage. This language is represented as streams of abstract discrete symbols\nuttered by agents over time, but nonetheless has a coherent structure that\npossesses a defined vocabulary and syntax. We also observe emergence of\nnon-verbal communication such as pointing and guiding when language\ncommunication is unavailable.", "published": "2017-03-15 03:30:13", "link": "http://arxiv.org/abs/1703.04908v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Ensemble of Neural Classifiers for Scoring Knowledge Base Triples", "abstract": "This paper describes our approach for the triple scoring task at the WSDM Cup\n2017. The task required participants to assign a relevance score for each pair\nof entities and their types in a knowledge base in order to enhance the ranking\nresults in entity retrieval tasks. We propose an approach wherein the outputs\nof multiple neural network classifiers are combined using a supervised machine\nlearning model. The experimental results showed that our proposed method\nachieved the best performance in one out of three measures (i.e., Kendall's\ntau), and performed competitively in the other two measures (i.e., accuracy and\naverage score difference).", "published": "2017-03-15 04:00:27", "link": "http://arxiv.org/abs/1703.04914v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Character-based Neural Embeddings for Tweet Clustering", "abstract": "In this paper we show how the performance of tweet clustering can be improved\nby leveraging character-based neural networks. The proposed approach overcomes\nthe limitations related to the vocabulary explosion in the word-based models\nand allows for the seamless processing of the multilingual content. Our\nevaluation results and code are available on-line at\nhttps://github.com/vendi12/tweet2vec_clustering", "published": "2017-03-15 12:37:22", "link": "http://arxiv.org/abs/1703.05123v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "InScript: Narrative texts annotated with script information", "abstract": "This paper presents the InScript corpus (Narrative Texts Instantiating Script\nstructure). InScript is a corpus of 1,000 stories centered around 10 different\nscenarios. Verbs and noun phrases are annotated with event and participant\ntypes, respectively. Additionally, the text is annotated with coreference\ninformation. The corpus shows rich lexical variation and will serve as a unique\nresource for the study of the role of script knowledge in natural language\nprocessing.", "published": "2017-03-15 17:01:20", "link": "http://arxiv.org/abs/1703.05260v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Convolutional Recurrent Neural Networks for Small-Footprint Keyword\n  Spotting", "abstract": "Keyword spotting (KWS) constitutes a major component of human-technology\ninterfaces. Maximizing the detection accuracy at a low false alarm (FA) rate,\nwhile minimizing the footprint size, latency and complexity are the goals for\nKWS. Towards achieving them, we study Convolutional Recurrent Neural Networks\n(CRNNs). Inspired by large-scale state-of-the-art speech recognition systems,\nwe combine the strengths of convolutional layers and recurrent layers to\nexploit local structure and long-range context. We analyze the effect of\narchitecture parameters, and propose training strategies to improve\nperformance. With only ~230k parameters, our CRNN model yields acceptably low\nlatency, and achieves 97.71% accuracy at 0.5 FA/hour for 5 dB signal-to-noise\nratio.", "published": "2017-03-15 21:20:44", "link": "http://arxiv.org/abs/1703.05390v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
