{"title": "Let's Negotiate! A Survey of Negotiation Dialogue Systems", "abstract": "Negotiation is a crucial ability in human communication. Recently, there has\nbeen a resurgent research interest in negotiation dialogue systems, whose goal\nis to create intelligent agents that can assist people in resolving conflicts\nor reaching agreements. Although there have been many explorations into\nnegotiation dialogue systems, a systematic review of this task has not been\nperformed to date. We aim to fill this gap by investigating recent studies in\nthe field of negotiation dialogue systems, and covering benchmarks, evaluations\nand methodologies within the literature. We also discuss potential future\ndirections, including multi-modal, multi-party and cross-cultural negotiation\nscenarios. Our goal is to provide the community with a systematic overview of\nnegotiation dialogue systems and to inspire future research.", "published": "2024-02-02 02:12:46", "link": "http://arxiv.org/abs/2402.01097v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CABINET: Content Relevance based Noise Reduction for Table Question\n  Answering", "abstract": "Table understanding capability of Large Language Models (LLMs) has been\nextensively studied through the task of question-answering (QA) over tables.\nTypically, only a small part of the whole table is relevant to derive the\nanswer for a given question. The irrelevant parts act as noise and are\ndistracting information, resulting in sub-optimal performance due to the\nvulnerability of LLMs to noise. To mitigate this, we propose CABINET (Content\nRelevAnce-Based NoIse ReductioN for TablE QuesTion-Answering) - a framework to\nenable LLMs to focus on relevant tabular data by suppressing extraneous\ninformation. CABINET comprises an Unsupervised Relevance Scorer (URS), trained\ndifferentially with the QA LLM, that weighs the table content based on its\nrelevance to the input question before feeding it to the question-answering LLM\n(QA LLM). To further aid the relevance scorer, CABINET employs a weakly\nsupervised module that generates a parsing statement describing the criteria of\nrows and columns relevant to the question and highlights the content of\ncorresponding table cells. CABINET significantly outperforms various tabular\nLLM baselines, as well as GPT3-based in-context learning methods, is more\nrobust to noise, maintains outperformance on tables of varying sizes, and\nestablishes new SoTA performance on WikiTQ, FeTaQA, and WikiSQL datasets. We\nrelease our code and datasets at https://github.com/Sohanpatnaik106/CABINET_QA.", "published": "2024-02-02 05:48:39", "link": "http://arxiv.org/abs/2402.01155v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-Detector: Improving AI-Generated Chinese Text Detection with\n  Open-Source LLM Instruction Tuning", "abstract": "ChatGPT and other general large language models (LLMs) have achieved\nremarkable success, but they have also raised concerns about the misuse of\nAI-generated texts. Existing AI-generated text detection models, such as based\non BERT and RoBERTa, are prone to in-domain over-fitting, leading to poor\nout-of-domain (OOD) detection performance. In this paper, we first collected\nChinese text responses generated by human experts and 9 types of LLMs, for\nwhich to multiple domains questions, and further created a dataset that mixed\nhuman-written sentences and sentences polished by LLMs. We then proposed\nLLM-Detector, a novel method for both document-level and sentence-level text\ndetection through Instruction Tuning of LLMs. Our method leverages the wealth\nof knowledge LLMs acquire during pre-training, enabling them to detect the text\nthey generate. Instruction tuning aligns the model's responses with the user's\nexpected text detection tasks. Experimental results show that previous methods\nstruggle with sentence-level AI-generated text detection and OOD detection. In\ncontrast, our proposed method not only significantly outperforms baseline\nmethods in both sentence-level and document-level text detection but also\ndemonstrates strong generalization capabilities. Furthermore, since\nLLM-Detector is trained based on open-source LLMs, it is easy to customize for\ndeployment.", "published": "2024-02-02 05:54:12", "link": "http://arxiv.org/abs/2402.01158v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "In-Context Learning for Few-Shot Nested Named Entity Recognition", "abstract": "In nested Named entity recognition (NER), entities are nested with each\nother, and thus requiring more data annotations to address. This leads to the\ndevelopment of few-shot nested NER, where the prevalence of pretrained language\nmodels with in-context learning (ICL) offers promising solutions. In this work,\nwe introduce an effective and innovative ICL framework for the setting of\nfew-shot nested NER. We improve the ICL prompt by devising a novel example\ndemonstration selection mechanism, EnDe retriever. In EnDe retriever, we employ\ncontrastive learning to perform three types of representation learning, in\nterms of semantic similarity, boundary similarity, and label similarity, to\ngenerate high-quality demonstration examples. Extensive experiments over three\nnested NER and four flat NER datasets demonstrate the efficacy of our system.", "published": "2024-02-02 06:57:53", "link": "http://arxiv.org/abs/2402.01182v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Two Approaches to Diachronic Normalization of Polish Texts", "abstract": "This paper discusses two approaches to the diachronic normalization of Polish\ntexts: a rule-based solution that relies on a set of handcrafted patterns, and\na neural normalization model based on the text-to-text transfer transformer\narchitecture. The training and evaluation data prepared for the task are\ndiscussed in detail, along with experiments conducted to compare the proposed\nnormalization solutions. A quantitative and qualitative analysis is made. It is\nshown that at the current stage of inquiry into the problem, the rule-based\nsolution outperforms the neural one on 3 out of 4 variants of the prepared\ndataset, although in practice both approaches have distinct advantages and\ndisadvantages.", "published": "2024-02-02 10:42:06", "link": "http://arxiv.org/abs/2402.01300v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "What Makes Medical Claims (Un)Verifiable? Analyzing Entity and Relation\n  Properties for Fact Verification", "abstract": "Biomedical claim verification fails if no evidence can be discovered. In\nthese cases, the fact-checking verdict remains unknown and the claim is\nunverifiable. To improve upon this, we have to understand if there are any\nclaim properties that impact its verifiability. In this work we assume that\nentities and relations define the core variables in a biomedical claim's\nanatomy and analyze if their properties help us to differentiate verifiable\nfrom unverifiable claims. In a study with trained annotation experts we prompt\nthem to find evidence for biomedical claims, and observe how they refine search\nqueries for their evidence search. This leads to the first corpus for\nscientific fact verification annotated with subject-relation-object triplets,\nevidence documents, and fact-checking verdicts (the BEAR-Fact corpus). We find\n(1) that discovering evidence for negated claims (e.g., X-does-not-cause-Y) is\nparticularly challenging. Further, we see that annotators process queries\nmostly by adding constraints to the search and by normalizing entities to\ncanonical names. (2) We compare our in-house annotations with a small\ncrowdsourcing setting where we employ medical experts and laypeople. We find\nthat domain expertise does not have a substantial effect on the reliability of\nannotations. Finally, (3), we demonstrate that it is possible to reliably\nestimate the success of evidence retrieval purely from the claim text~(.82\\F),\nwhereas identifying unverifiable claims proves more challenging (.27\\F). The\ndataset is available at http://www.ims.uni-stuttgart.de/data/bioclaim.", "published": "2024-02-02 12:27:58", "link": "http://arxiv.org/abs/2402.01360v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Dive into the Chasm: Probing the Gap between In- and Cross-Topic\n  Generalization", "abstract": "Pre-trained language models (LMs) perform well in In-Topic setups, where\ntraining and testing data come from the same topics. However, they face\nchallenges in Cross-Topic scenarios where testing data is derived from distinct\ntopics -- such as Gun Control. This study analyzes various LMs with three\nprobing-based experiments to shed light on the reasons behind the In- vs.\nCross-Topic generalization gap. Thereby, we demonstrate, for the first time,\nthat generalization gaps and the robustness of the embedding space vary\nsignificantly across LMs. Additionally, we assess larger LMs and underscore the\nrelevance of our analysis for recent models. Overall, diverse pre-training\nobjectives, architectural regularization, or data deduplication contribute to\nmore robust LMs and diminish generalization gaps. Our research contributes to a\ndeeper understanding and comparison of language models across different\ngeneralization scenarios.", "published": "2024-02-02 12:59:27", "link": "http://arxiv.org/abs/2402.01375v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-based NLG Evaluation: Current Status and Challenges", "abstract": "Evaluating natural language generation (NLG) is a vital but challenging\nproblem in artificial intelligence. Traditional evaluation metrics mainly\ncapturing content (e.g. n-gram) overlap between system outputs and references\nare far from satisfactory, and large language models (LLMs) such as ChatGPT\nhave demonstrated great potential in NLG evaluation in recent years. Various\nautomatic evaluation methods based on LLMs have been proposed, including\nmetrics derived from LLMs, prompting LLMs, and fine-tuning LLMs with labeled\nevaluation data. In this survey, we first give a taxonomy of LLM-based NLG\nevaluation methods, and discuss their pros and cons, respectively. We also\ndiscuss human-LLM collaboration for NLG evaluation. Lastly, we discuss several\nopen problems in this area and point out future research directions.", "published": "2024-02-02 13:06:35", "link": "http://arxiv.org/abs/2402.01383v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Measuring Context Utilization in Document-Level MT Systems", "abstract": "Document-level translation models are usually evaluated using general metrics\nsuch as BLEU, which are not informative about the benefits of context. Current\nwork on context-aware evaluation, such as contrastive methods, only measure\ntranslation accuracy on words that need context for disambiguation. Such\nmeasures cannot reveal whether the translation model uses the correct\nsupporting context. We propose to complement accuracy-based evaluation with\nmeasures of context utilization. We find that perturbation-based analysis\n(comparing models' performance when provided with correct versus random\ncontext) is an effective measure of overall context utilization. For a\nfiner-grained phenomenon-specific evaluation, we propose to measure how much\nthe supporting context contributes to handling context-dependent discourse\nphenomena. We show that automatically-annotated supporting context gives\nsimilar conclusions to human-annotated context and can be used as alternative\nfor cases where human annotations are not available. Finally, we highlight the\nimportance of using discourse-rich datasets when assessing context utilization.", "published": "2024-02-02 13:37:07", "link": "http://arxiv.org/abs/2402.01404v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Different Tastes of Entities: Investigating Human Label Variation in\n  Named Entity Annotations", "abstract": "Named Entity Recognition (NER) is a key information extraction task with a\nlong-standing tradition. While recent studies address and aim to correct\nannotation errors via re-labeling efforts, little is known about the sources of\nhuman label variation, such as text ambiguity, annotation error, or guideline\ndivergence. This is especially the case for high-quality datasets and beyond\nEnglish CoNLL03. This paper studies disagreements in expert-annotated named\nentity datasets for three languages: English, Danish, and Bavarian. We show\nthat text ambiguity and artificial guideline changes are dominant factors for\ndiverse annotations among high-quality revisions. We survey student annotations\non a subset of difficult entities and substantiate the feasibility and\nnecessity of manifold annotations for understanding named entity ambiguities\nfrom a distributional perspective.", "published": "2024-02-02 14:08:34", "link": "http://arxiv.org/abs/2402.01423v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The effect of diversity on group decision-making", "abstract": "We explore different aspects of cognitive diversity and its effect on the\nsuccess of group deliberation. To evaluate this, we use 500 dialogues from\nsmall, online groups discussing the Wason Card Selection task - the DeliData\ncorpus. Leveraging the corpus, we perform quantitative analysis evaluating\nthree different measures of cognitive diversity. First, we analyse the effect\nof group size as a proxy measure for diversity. Second, we evaluate the effect\nof the size of the initial idea pool. Finally, we look into the content of the\ndiscussion by analysing discussed solutions, discussion patterns, and how\nconversational probing can improve those characteristics. Despite the\nreputation of groups for compounding bias, we show that small groups can,\nthrough dialogue, overcome intuitive biases and improve individual\ndecision-making. Across a large sample and different operationalisations, we\nconsistently find that greater cognitive diversity is associated with more\nsuccessful group deliberation. Code and data used for the analysis are\navailable in the repository:\nhttps://github.com/gkaradzhov/cognitive-diversity-groups-cogsci24.", "published": "2024-02-02 14:15:01", "link": "http://arxiv.org/abs/2402.01427v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Queen of England is not England's Queen: On the Lack of Factual\n  Coherency in PLMs", "abstract": "Factual knowledge encoded in Pre-trained Language Models (PLMs) enriches\ntheir representations and justifies their use as knowledge bases. Previous work\nhas focused on probing PLMs for factual knowledge by measuring how often they\ncan correctly predict an object entity given a subject and a relation, and\nimproving fact retrieval by optimizing the prompts used for querying PLMs. In\nthis work, we consider a complementary aspect, namely the coherency of factual\nknowledge in PLMs, i.e., how often can PLMs predict the subject entity given\nits initial prediction of the object entity. This goes beyond evaluating how\nmuch PLMs know, and focuses on the internal state of knowledge inside them. Our\nresults indicate that PLMs have low coherency using manually written, optimized\nand paraphrased prompts, but including an evidence paragraph leads to\nsubstantial improvement. This shows that PLMs fail to model inverse relations\nand need further enhancements to be able to handle retrieving facts from their\nparameters in a coherent manner, and to be considered as knowledge bases.", "published": "2024-02-02 14:42:09", "link": "http://arxiv.org/abs/2402.01453v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through\n  Process Feedback", "abstract": "The notable success of large language models (LLMs) has sparked an upsurge in\nbuilding language agents to complete various complex tasks. We present AMOR, an\nagent framework based on open-source LLMs, which reasons with external\nknowledge bases and adapts to specific domains through human supervision to the\nreasoning process. AMOR builds reasoning logic over a finite state machine\n(FSM) that solves problems through autonomous executions and transitions over\ndisentangled modules. This allows humans to provide direct feedback to the\nindividual modules, and thus naturally forms process supervision. Based on this\nreasoning and feedback framework, we develop AMOR through two-stage\nfine-tuning: warm-up and adaptation. The former fine-tunes the LLM with\nexamples automatically constructed from various public datasets, enabling AMOR\nto generalize across different knowledge environments, while the latter tailors\nAMOR to specific domains using process feedback. Extensive experiments across\nmultiple domains demonstrate the advantage of AMOR to strong baselines, thanks\nto its FSM-based reasoning and process feedback mechanism. The code and data\nare publicly available at \\url{https://github.com/JianGuanTHU/AMOR}.", "published": "2024-02-02 14:56:48", "link": "http://arxiv.org/abs/2402.01469v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparative Analysis of Conversational Large Language Models in\n  Knowledge-Based Text Generation", "abstract": "Generating natural language text from graph-structured data is essential for\nconversational information seeking. Semantic triples derived from knowledge\ngraphs can serve as a valuable source for grounding responses from\nconversational agents by providing a factual basis for the information they\ncommunicate. This is especially relevant in the context of large language\nmodels, which offer great potential for conversational interaction but are\nprone to hallucinating, omitting, or producing conflicting information. In this\nstudy, we conduct an empirical analysis of conversational large language models\nin generating natural language text from semantic triples. We compare four\nlarge language models of varying sizes with different prompting techniques.\nThrough a series of benchmark experiments on the WebNLG dataset, we analyze the\nmodels' performance and identify the most common issues in the generated\npredictions. Our findings show that the capabilities of large language models\nin triple verbalization can be significantly improved through few-shot\nprompting, post-processing, and efficient fine-tuning techniques, particularly\nfor smaller models that exhibit lower zero-shot performance.", "published": "2024-02-02 15:26:39", "link": "http://arxiv.org/abs/2402.01495v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code-Switched Language Identification is Harder Than You Think", "abstract": "Code switching (CS) is a very common phenomenon in written and spoken\ncommunication but one that is handled poorly by many natural language\nprocessing applications. Looking to the application of building CS corpora, we\nexplore CS language identification (LID) for corpus building. We make the task\nmore realistic by scaling it to more languages and considering models with\nsimpler architectures for faster inference. We also reformulate the task as a\nsentence-level multi-label tagging problem to make it more tractable. Having\ndefined the task, we investigate three reasonable models for this task and\ndefine metrics which better reflect desired performance. We present empirical\nevidence that no current approach is adequate and finally provide\nrecommendations for future work in this area.", "published": "2024-02-02 15:38:47", "link": "http://arxiv.org/abs/2402.01505v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Hybrid Strategy for Chat Transcript Summarization", "abstract": "Text summarization is the process of condensing a piece of text to fewer\nsentences, while still preserving its content. Chat transcript, in this\ncontext, is a textual copy of a digital or online conversation between a\ncustomer (caller) and agent(s). This paper presents an indigenously (locally)\ndeveloped hybrid method that first combines extractive and abstractive\nsummarization techniques in compressing ill-punctuated or un-punctuated chat\ntranscripts to produce more readable punctuated summaries and then optimizes\nthe overall quality of summarization through reinforcement learning. Extensive\ntesting, evaluations, comparisons, and validation have demonstrated the\nefficacy of this approach for large-scale deployment of chat transcript\nsummarization, in the absence of manually generated reference (annotated)\nsummaries.", "published": "2024-02-02 15:44:28", "link": "http://arxiv.org/abs/2402.01510v2", "categories": ["cs.CL", "68", "I.7"], "primary_category": "cs.CL"}
{"title": "Distractor Generation in Multiple-Choice Tasks: A Survey of Methods,\n  Datasets, and Evaluation", "abstract": "The distractor generation task focuses on generating incorrect but plausible\noptions for objective questions such as fill-in-the-blank and multiple-choice\nquestions. This task is widely utilized in educational settings across various\ndomains and subjects. The effectiveness of these questions in assessments\nrelies on the quality of the distractors, as they challenge examinees to select\nthe correct answer from a set of misleading options. The evolution of\nartificial intelligence (AI) has transitioned the task from traditional methods\nto the use of neural networks and pre-trained language models. This shift has\nestablished new benchmarks and expanded the use of advanced deep learning\nmethods in generating distractors. This survey explores distractor generation\ntasks, datasets, methods, and current evaluation metrics for English objective\nquestions, covering both text-based and multi-modal domains. It also evaluates\nexisting AI models and benchmarks and discusses potential future research\ndirections.", "published": "2024-02-02 15:53:31", "link": "http://arxiv.org/abs/2402.01512v2", "categories": ["cs.CL", "Computation and Language (cs.CL)"], "primary_category": "cs.CL"}
{"title": "Multilingual Gradient Word-Order Typology from Universal Dependencies", "abstract": "While information from the field of linguistic typology has the potential to\nimprove performance on NLP tasks, reliable typological data is a prerequisite.\nExisting typological databases, including WALS and Grambank, suffer from\ninconsistencies primarily caused by their categorical format. Furthermore,\ntypological categorisations by definition differ significantly from the\ncontinuous nature of phenomena, as found in natural language corpora. In this\npaper, we introduce a new seed dataset made up of continuous-valued data,\nrather than categorical data, that can better reflect the variability of\nlanguage. While this initial dataset focuses on word-order typology, we also\npresent the methodology used to create the dataset, which can be easily adapted\nto generate data for a broader set of features and languages.", "published": "2024-02-02 15:54:19", "link": "http://arxiv.org/abs/2402.01513v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automating Sound Change Prediction for Phylogenetic Inference: A\n  Tukanoan Case Study", "abstract": "We describe a set of new methods to partially automate linguistic\nphylogenetic inference given (1) cognate sets with their respective protoforms\nand sound laws, (2) a mapping from phones to their articulatory features and\n(3) a typological database of sound changes. We train a neural network on these\nsound change data to weight articulatory distances between phones and predict\nintermediate sound change steps between historical protoforms and their modern\ndescendants, replacing a linguistic expert in part of a parsimony-based\nphylogenetic inference algorithm. In our best experiments on Tukanoan\nlanguages, this method produces trees with a Generalized Quartet Distance of\n0.12 from a tree that used expert annotations, a significant improvement over\nother semi-automated baselines. We discuss potential benefits and drawbacks to\nour neural approach and parsimony-based tree prediction. We also experiment\nwith a minimal generalization learner for automatic sound law induction,\nfinding it comparably effective to sound laws from expert annotation. Our code\nis publicly available at https://github.com/cmu-llab/aiscp.", "published": "2024-02-02 17:20:16", "link": "http://arxiv.org/abs/2402.01582v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Sustainable Workplace Mental Health: A Novel Approach to Early\n  Intervention and Support", "abstract": "Employee well-being is a critical concern in the contemporary workplace, as\nhighlighted by the American Psychological Association's 2021 report, indicating\nthat 71% of employees experience stress or tension. This stress contributes\nsignificantly to workplace attrition and absenteeism, with 61% of attrition and\n16% of sick days attributed to poor mental health. A major challenge for\nemployers is that employees often remain unaware of their mental health issues\nuntil they reach a crisis point, resulting in limited utilization of corporate\nwell-being benefits. This research addresses this challenge by presenting a\ngroundbreaking stress detection algorithm that provides real-time support\npreemptively. Leveraging automated chatbot technology, the algorithm\nobjectively measures mental health levels by analyzing chat conversations,\noffering personalized treatment suggestions in real-time based on linguistic\nbiomarkers. The study explores the feasibility of integrating these innovations\ninto practical learning applications within real-world contexts and introduces\na chatbot-style system integrated into the broader employee experience\nplatform. This platform, encompassing various features, aims to enhance overall\nemployee well-being, detect stress in real time, and proactively engage with\nindividuals to improve support effectiveness, demonstrating a 22% increase when\nassistance is provided early. Overall, the study emphasizes the importance of\nfostering a supportive workplace environment for employees' mental health.", "published": "2024-02-02 17:35:49", "link": "http://arxiv.org/abs/2402.01592v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Style Vectors for Steering Generative Large Language Model", "abstract": "This research explores strategies for steering the output of large language\nmodels (LLMs) towards specific styles, such as sentiment, emotion, or writing\nstyle, by adding style vectors to the activations of hidden layers during text\ngeneration. We show that style vectors can be simply computed from recorded\nlayer activations for input texts in a specific style in contrast to more\ncomplex training-based approaches. Through a series of experiments, we\ndemonstrate the effectiveness of activation engineering using such style\nvectors to influence the style of generated text in a nuanced and\nparameterisable way, distinguishing it from prompt engineering. The presented\nresearch constitutes a significant step towards developing more adaptive and\neffective AI-empowered interactive systems.", "published": "2024-02-02 18:31:15", "link": "http://arxiv.org/abs/2402.01618v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce\n  Programs over Low-resourced Knowledge Bases", "abstract": "Program induction (PI) has become a promising paradigm for using knowledge\nbases (KBs) to help large language models (LLMs) answer complex\nknowledge-intensive questions. Nonetheless, PI typically relies on a large\nnumber of parallel question-program pairs to make the LLM aware of the schema\nof the given KB, and is thus challenging for many low-resourced KBs that lack\nannotated data. To this end, we propose KB-Plugin, a plug-and-play framework\nthat enables LLMs to induce programs over any low-resourced KB. Firstly,\nKB-Plugin adopts self-supervised learning to encode the detailed schema\ninformation of a given KB into a pluggable module, namely schema plugin.\nSecondly, KB-Plugin utilizes abundant annotated data from a rich-resourced KB\nto train another pluggable module, namely PI plugin, which can help the LLM\nextract question-relevant schema information from the schema plugin of any KB\nand utilize this information to induce programs over this KB. Experiments on\nfive heterogeneous KBQA datasets show that KB-Plugin achieves better or\ncomparable performance with 25$\\times$ smaller backbone LLM compared to SoTA PI\nmethods for low-resourced KBs, and even approaches the performance of\nsupervised methods. Our code and data are available at\nhttps://github.com/THU-KEG/KB-Plugin.", "published": "2024-02-02 18:32:24", "link": "http://arxiv.org/abs/2402.01619v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MAGDi: Structured Distillation of Multi-Agent Interaction Graphs\n  Improves Reasoning in Smaller Language Models", "abstract": "Multi-agent interactions between Large Language Model (LLM) agents have shown\nmajor improvements on diverse reasoning tasks. However, these involve long\ngenerations from multiple models across several rounds, making them expensive.\nMoreover, these multi-agent approaches fail to provide a final, single model\nfor efficient inference. To address this, we introduce MAGDi, a new method for\nstructured distillation of the reasoning interactions between multiple LLMs\ninto smaller LMs. MAGDi teaches smaller models by representing multi-agent\ninteractions as graphs, augmenting a base student model with a graph encoder,\nand distilling knowledge using three objective functions: next-token\nprediction, a contrastive loss between correct and incorrect reasoning, and a\ngraph-based objective to model the interaction structure. Experiments on seven\nwidely used commonsense and math reasoning benchmarks show that MAGDi improves\nthe reasoning capabilities of smaller models, outperforming several methods\nthat distill from a single teacher and multiple teachers. Moreover, MAGDi also\ndemonstrates an order of magnitude higher efficiency over its teachers. We\nconduct extensive analyses to show that MAGDi (1) enhances the generalizability\nto out-of-domain tasks, (2) scales positively with the size and strength of the\nbase student model, and (3) obtains larger improvements (via our multi-teacher\ntraining) when applying self-consistency -- an inference technique that relies\non model diversity.", "published": "2024-02-02 18:35:14", "link": "http://arxiv.org/abs/2402.01620v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TravelPlanner: A Benchmark for Real-World Planning with Language Agents", "abstract": "Planning has been part of the core pursuit for artificial intelligence since\nits conception, but earlier AI agents mostly focused on constrained settings\nbecause many of the cognitive substrates necessary for human-level planning\nhave been lacking. Recently, language agents powered by large language models\n(LLMs) have shown interesting capabilities such as tool use and reasoning. Are\nthese language agents capable of planning in more complex settings that are out\nof the reach of prior AI agents? To advance this investigation, we propose\nTravelPlanner, a new planning benchmark that focuses on travel planning, a\ncommon real-world planning scenario. It provides a rich sandbox environment,\nvarious tools for accessing nearly four million data records, and 1,225\nmeticulously curated planning intents and reference plans. Comprehensive\nevaluations show that the current language agents are not yet capable of\nhandling such complex planning tasks-even GPT-4 only achieves a success rate of\n0.6%. Language agents struggle to stay on task, use the right tools to collect\ninformation, or keep track of multiple constraints. However, we note that the\nmere possibility for language agents to tackle such a complex problem is in\nitself non-trivial progress. TravelPlanner provides a challenging yet\nmeaningful testbed for future language agents.", "published": "2024-02-02 18:39:51", "link": "http://arxiv.org/abs/2402.01622v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Whispering in Norwegian: Navigating Orthographic and Dialectic\n  Challenges", "abstract": "This article introduces NB-Whisper, an adaptation of OpenAI's Whisper,\nspecifically fine-tuned for Norwegian language Automatic Speech Recognition\n(ASR). We highlight its key contributions and summarise the results achieved in\nconverting spoken Norwegian into written forms and translating other languages\ninto Norwegian. We show that we are able to improve the Norwegian Bokm{\\aa}l\ntranscription by OpenAI Whisper Large-v3 from a WER of 10.4 to 6.6 on the\nFleurs Dataset and from 6.8 to 2.2 on the NST dataset.", "published": "2024-02-02 21:38:12", "link": "http://arxiv.org/abs/2402.01917v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code Representation Learning At Scale", "abstract": "Recent studies have shown that code language models at scale demonstrate\nsignificant performance gains on downstream tasks, i.e., code generation.\nHowever, most of the existing works on code representation learning train\nmodels at a hundred million parameter scale using very limited pretraining\ncorpora. In this work, we fuel code representation learning with a vast amount\nof code data via a two-stage pretraining scheme. We first train the encoders\nvia a mix that leverages both randomness in masking language modeling and the\nstructure aspect of programming language. We then enhance the representations\nvia contrastive learning with hard negative and hard positive constructed in an\nunsupervised manner. We establish an off-the-shelf encoder model that\npersistently outperforms the existing models on a wide variety of downstream\ntasks by large margins. To comprehend the factors contributing to successful\ncode representation learning, we conduct detailed ablations and share our\nfindings on (i) a customized and effective token-level denoising scheme for\nsource code; (ii) the importance of hard negatives and hard positives; (iii)\nhow the proposed bimodal contrastive learning boost the cross-lingual semantic\nsearch performance; and (iv) how the pretraining schemes decide the downstream\ntask performance scales with the model size.", "published": "2024-02-02 22:19:15", "link": "http://arxiv.org/abs/2402.01935v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Morphologically-Aware Dictionary-based Data Augmentation Technique for\n  Machine Translation of Under-Represented Languages", "abstract": "The availability of parallel texts is crucial to the performance of machine\ntranslation models. However, most of the world's languages face the predominant\nchallenge of data scarcity. In this paper, we propose strategies to synthesize\nparallel data relying on morpho-syntactic information and using bilingual\nlexicons along with a small amount of seed parallel data. Our methodology\nadheres to a realistic scenario backed by the small parallel seed data. It is\nlinguistically informed, as it aims to create augmented data that is more\nlikely to be grammatically correct. We analyze how our synthetic data can be\ncombined with raw parallel data and demonstrate a consistent improvement in\nperformance in our experiments on 14 languages (28 English <-> X pairs) ranging\nfrom well- to very low-resource ones. Our method leads to improvements even\nwhen using only five seed sentences and a bilingual lexicon.", "published": "2024-02-02 22:25:44", "link": "http://arxiv.org/abs/2402.01939v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Case Study on Filtering for End-to-End Speech Translation", "abstract": "It is relatively easy to mine a large parallel corpus for any machine\nlearning task, such as speech-to-text or speech-to-speech translation. Although\nthese mined corpora are large in volume, their quality is questionable. This\nwork shows that the simplest filtering technique can trim down these big, noisy\ndatasets to a more manageable, clean dataset. We also show that using this\nclean dataset can improve the model's performance, as in the case of the\nmultilingual-to-English Speech Translation (ST) model, where, on average, we\nobtain a 4.65 BLEU score improvement.", "published": "2024-02-02 22:42:33", "link": "http://arxiv.org/abs/2402.01945v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Need a Small Specialized Language Model? Plan Early!", "abstract": "Large language models are versatile tools but are not suitable for small\ninference budgets. Small models have more efficient inference, but their lower\ncapacity means that their performance can be good only if one limits their\nscope to a specialized domain. This paper explores how to get good specialized\nsmall language models using a large, generic, pretraining set and a limited\namount of specialized data. We consider two scenarios, depending on whether (i)\none can afford pretraining a model for each specialization task, or (ii) one\nwants to cheaply adapt a single pretrained model for each task. In the first\nscenario, we propose an effective solution based on importance sampling: we\nresample the pretraining set to imitate the specialization data and train a\nsmall model on it. In the second scenario, we propose a novel architecture,\nprojected networks (PN). PN is a large network whose parameters can be linearly\nprojected into a small network for specialization. For both scenarios, we\ndemonstrate the empirical effectiveness of our solutions across various\ndomains, training set sizes, and training budgets.", "published": "2024-02-02 01:45:18", "link": "http://arxiv.org/abs/2402.01093v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and\n  Human-Centered Solutions", "abstract": "Remarkable performance of large language models (LLMs) in a variety of tasks\nbrings forth many opportunities as well as challenges of utilizing them in\nproduction settings. Towards practical adoption of LLMs, multi-agent systems\nhold great promise to augment, integrate, and orchestrate LLMs in the larger\ncontext of enterprise platforms that use existing proprietary data and models\nto tackle complex real-world tasks. Despite the tremendous success of these\nsystems, current approaches rely on narrow, single-focus objectives for\noptimization and evaluation, often overlooking potential constraints in\nreal-world scenarios, including restricted budgets, resources and time.\nFurthermore, interpreting, analyzing, and debugging these systems requires\ndifferent components to be evaluated in relation to one another. This demand is\ncurrently not feasible with existing methodologies. In this postion paper, we\nintroduce the concept of reasoning capacity as a unifying criterion to enable\nintegration of constraints during optimization and establish connections among\ndifferent components within the system, which also enable a more holistic and\ncomprehensive approach to evaluation. We present a formal definition of\nreasoning capacity and illustrate its utility in identifying limitations within\neach component of the system. We then argue how these limitations can be\naddressed with a self-reflective process wherein human-feedback is used to\nalleviate shortcomings in reasoning and enhance overall consistency of the\nsystem.", "published": "2024-02-02 02:53:11", "link": "http://arxiv.org/abs/2402.01108v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Vaccine: Perturbation-aware Alignment for Large Language Models against\n  Harmful Fine-tuning Attack", "abstract": "The new paradigm of finetuning-as-a-service introduces a new attack surface\nfor Large Language Models (LLMs): a few harmful data uploaded by users can\neasily trick the finetuning to produce an alignment-broken model. We conduct an\nempirical analysis and uncover a \\textit{harmful embedding drift} phenomenon,\nshowing a probable cause of the alignment-broken effect. Inspired by our\nfindings, we propose Vaccine, a perturbation-aware alignment technique to\nmitigate the security risk of users finetuning. The core idea of Vaccine is to\nproduce invariant hidden embeddings by progressively adding crafted\nperturbation to them in the alignment phase. This enables the embeddings to\nwithstand harmful perturbation from un-sanitized user data in the finetuning\nphase. Our results on open source mainstream LLMs (e.g., Llama2, Opt, Vicuna)\ndemonstrate that Vaccine can boost the robustness of alignment against harmful\nprompts induced embedding drift while reserving reasoning ability towards\nbenign prompts. Our code is available at\n\\url{https://github.com/git-disl/Vaccine}.", "published": "2024-02-02 02:56:50", "link": "http://arxiv.org/abs/2402.01109v6", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Interpretation of Intracardiac Electrograms Through Textual\n  Representations", "abstract": "Understanding the irregular electrical activity of atrial fibrillation (AFib)\nhas been a key challenge in electrocardiography. For serious cases of AFib,\ncatheter ablations are performed to collect intracardiac electrograms (EGMs).\nEGMs offer intricately detailed and localized electrical activity of the heart\nand are an ideal modality for interpretable cardiac studies. Recent\nadvancements in artificial intelligence (AI) has allowed some works to utilize\ndeep learning frameworks to interpret EGMs during AFib. Additionally, language\nmodels (LMs) have shown exceptional performance in being able to generalize to\nunseen domains, especially in healthcare. In this study, we are the first to\nleverage pretrained LMs for finetuning of EGM interpolation and AFib\nclassification via masked language modeling. We formulate the EGM as a textual\nsequence and present competitive performances on AFib classification compared\nagainst other representations. Lastly, we provide a comprehensive\ninterpretability study to provide a multi-perspective intuition of the model's\nbehavior, which could greatly benefit the clinical use.", "published": "2024-02-02 03:15:13", "link": "http://arxiv.org/abs/2402.01115v5", "categories": ["cs.CL", "eess.SP", "I.2.7; J.3"], "primary_category": "cs.CL"}
{"title": "PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language\n  Models", "abstract": "We introduce PokeLLMon, the first LLM-embodied agent that achieves\nhuman-parity performance in tactical battle games, as demonstrated in Pokemon\nbattles. The design of PokeLLMon incorporates three key strategies: (i)\nIn-context reinforcement learning that instantly consumes text-based feedback\nderived from battles to iteratively refine the policy; (ii) Knowledge-augmented\ngeneration that retrieves external knowledge to counteract hallucination and\nenables the agent to act timely and properly; (iii) Consistent action\ngeneration to mitigate the panic switching phenomenon when the agent faces a\npowerful opponent and wants to elude the battle. We show that online battles\nagainst human demonstrates PokeLLMon's human-like battle strategies and\njust-in-time decision making, achieving 49% of win rate in the Ladder\ncompetitions and 56% of win rate in the invited battles. Our implementation and\nplayable battle logs are available at: https://github.com/git-disl/PokeLLMon.", "published": "2024-02-02 03:22:12", "link": "http://arxiv.org/abs/2402.01118v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Multi-Agent Conversational Recommender System", "abstract": "Due to strong capabilities in conducting fluent, multi-turn conversations\nwith users, Large Language Models (LLMs) have the potential to further improve\nthe performance of Conversational Recommender System (CRS). Unlike the aimless\nchit-chat that LLM excels at, CRS has a clear target. So it is imperative to\ncontrol the dialogue flow in the LLM to successfully recommend appropriate\nitems to the users. Furthermore, user feedback in CRS can assist the system in\nbetter modeling user preferences, which has been ignored by existing studies.\nHowever, simply prompting LLM to conduct conversational recommendation cannot\naddress the above two key challenges.\n  In this paper, we propose Multi-Agent Conversational Recommender System\n(MACRS) which contains two essential modules. First, we design a multi-agent\nact planning framework, which can control the dialogue flow based on four\nLLM-based agents. This cooperative multi-agent framework will generate various\ncandidate responses based on different dialogue acts and then choose the most\nappropriate response as the system response, which can help MACRS plan suitable\ndialogue acts. Second, we propose a user feedback-aware reflection mechanism\nwhich leverages user feedback to reason errors made in previous turns to adjust\nthe dialogue act planning, and higher-level user information from implicit\nsemantics. We conduct extensive experiments based on user simulator to\ndemonstrate the effectiveness of MACRS in recommendation and user preferences\ncollection. Experimental results illustrate that MACRS demonstrates an\nimprovement in user interaction experience compared to directly using LLMs.", "published": "2024-02-02 04:20:13", "link": "http://arxiv.org/abs/2402.01135v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Efficient Prompt Caching via Embedding Similarity", "abstract": "Large language models (LLMs) have achieved huge success in numerous natural\nlanguage process (NLP) tasks. However, it faces the challenge of significant\nresource consumption during inference. In this paper, we aim to improve the\ninference efficiency of LLMs by prompt caching, i.e., if the current prompt can\nbe answered by the same response of a previous prompt, one can directly utilize\nthat previous response without calling the LLM. Specifically, we focus on the\nprediction accuracy of prompt caching for single-round question-answering tasks\nvia embedding similarity. The existing embeddings of prompts mostly focus on\nwhether two prompts are semantically similar, which is not necessarily\nequivalent to whether the same response can answer them. Therefore, we propose\na distillation-based method to fine-tune the existing embeddings for better\ncaching prediction. Theoretically, we provide finite-sample guarantees for the\nconvergence of our method under different types of loss functions. Empirically,\nwe carefully construct a hard dataset based on Kwiatkowski et al. (2019) where\nthe existing embedding model (Wang et al., 2022) only achieves an AUC of 0.51.\nWe then fine-tune the above embedding model, which significantly improves the\nAUC of caching prediction from 0.51 to 0.81. We also conduct simulations\ndemonstrating that our trained models achieve better caching efficiency than\nthe previous embedding model.", "published": "2024-02-02 06:34:11", "link": "http://arxiv.org/abs/2402.01173v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CorpusLM: Towards a Unified Language Model on Corpus for\n  Knowledge-Intensive Tasks", "abstract": "Large language models (LLMs) have gained significant attention in various\nfields but prone to hallucination, especially in knowledge-intensive (KI)\ntasks. To address this, retrieval-augmented generation (RAG) has emerged as a\npopular solution to enhance factual accuracy. However, traditional retrieval\nmodules often rely on large document index and disconnect with generative\ntasks. With the advent of generative retrieval (GR), language models can\nretrieve by directly generating document identifiers (DocIDs), offering\nsuperior performance in retrieval tasks. However, the potential relationship\nbetween GR and downstream tasks remains unexplored. In this paper, we propose\n\\textbf{CorpusLM}, a unified language model that leverages external corpus to\ntackle various knowledge-intensive tasks by integrating generative retrieval,\nclosed-book generation, and RAG through a unified greedy decoding process. We\ndesign the following mechanisms to facilitate effective retrieval and\ngeneration, and improve the end-to-end effectiveness of KI tasks: (1) We\ndevelop a ranking-oriented DocID list generation strategy, which refines GR by\ndirectly learning from a DocID ranking list, to improve retrieval quality. (2)\nWe design a continuous DocIDs-References-Answer generation strategy, which\nfacilitates effective and efficient RAG. (3) We employ well-designed\nunsupervised DocID understanding tasks, to comprehend DocID semantics and their\nrelevance to downstream tasks. We evaluate our approach on the widely used KILT\nbenchmark with two variants of backbone models, i.e., T5 and Llama2.\nExperimental results demonstrate the superior performance of our models in both\nretrieval and downstream tasks.", "published": "2024-02-02 06:44:22", "link": "http://arxiv.org/abs/2402.01176v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The Human and the Mechanical: logos, truthfulness, and ChatGPT", "abstract": "The paper addresses the question of whether it is appropriate to talk about\n`mechanical minds' at all, and whether ChatGPT models can indeed be thought of\nas realizations of that. Our paper adds a semantic argument to the current\ndebate. The act of human assertion requires the formation of a veridicality\njudgment. Modification of assertions with modals (John must be at home) and the\nuse of subjective elements (John is obviously at home) indicate that the\nspeaker is manipulating her judgments and, in a cooperative context, intends\nher epistemic state to be transparent to the addressee. Veridicality judgments\nare formed on the basis of two components: (i) evidence that relates to reality\n(exogenous evidence) and (ii) endogenous evidence, such as preferences and\nprivate beliefs. `Mechanical minds' lack these two components: (i) they do not\nrelate to reality and (ii) do not have endogenous evidence. Therefore they lack\nthe ability to form a belief about the world and a veridicality judgments\naltogether. They can only mimic that judgment, but the output is not ground in\nthe very foundations for it.", "published": "2024-02-02 09:41:51", "link": "http://arxiv.org/abs/2402.01267v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can MLLMs Perform Text-to-Image In-Context Learning?", "abstract": "The evolution from Large Language Models (LLMs) to Multimodal Large Language\nModels (MLLMs) has spurred research into extending In-Context Learning (ICL) to\nits multimodal counterpart. Existing such studies have primarily concentrated\non image-to-text ICL. However, the Text-to-Image ICL (T2I-ICL), with its unique\ncharacteristics and potential applications, remains underexplored. To address\nthis gap, we formally define the task of T2I-ICL and present CoBSAT, the first\nT2I-ICL benchmark dataset, encompassing ten tasks. Utilizing our dataset to\nbenchmark six state-of-the-art MLLMs, we uncover considerable difficulties\nMLLMs encounter in solving T2I-ICL. We identify the primary challenges as the\ninherent complexity of multimodality and image generation, and show that\nstrategies such as fine-tuning and Chain-of-Thought prompting help to mitigate\nthese difficulties, leading to notable improvements in performance. Our code\nand dataset are available at https://github.com/UW-Madison-Lee-Lab/CoBSAT.", "published": "2024-02-02 10:30:05", "link": "http://arxiv.org/abs/2402.01293v3", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLMs May Perform MCQA by Selecting the Least Incorrect Option", "abstract": "In the field of NLP, Large Language Models (LLMs) have markedly enhanced\nperformance across a variety of tasks. However, the comprehensive evaluation of\nLLMs remains an inevitable challenge for the community. Recently, the adoption\nof Multiple Choice Question Answering (MCQA) as a benchmark for assessing LLMs\nhas gained considerable traction. However, concerns regarding the robustness of\nthis evaluative method persist. Building upon previous discussions on the issue\nof \\textit{variability}, we reveal an additional dimension of concern: LLMs may\nperform MCQA by selecting the least incorrect option rather than distinctly\ncorrect. This observation suggests that LLMs might regard multiple options as\ncorrect, which could undermine the reliability of MCQA as a metric for\nevaluating LLMs. To address this challenge, we introduce an enhanced dataset\naugmentation method for MCQA, termed MCQA+, to provide a more accurate\nreflection of the model performance, thereby highlighting the necessity for\nmore sophisticated evaluation mechanisms in the assessment of LLM capabilities.", "published": "2024-02-02 12:07:00", "link": "http://arxiv.org/abs/2402.01349v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Continual Learning for Large Language Models: A Survey", "abstract": "Large language models (LLMs) are not amenable to frequent re-training, due to\nhigh training costs arising from their massive scale. However, updates are\nnecessary to endow LLMs with new skills and keep them up-to-date with rapidly\nevolving human knowledge. This paper surveys recent works on continual learning\nfor LLMs. Due to the unique nature of LLMs, we catalog continue learning\ntechniques in a novel multi-staged categorization scheme, involving continual\npretraining, instruction tuning, and alignment. We contrast continual learning\nfor LLMs with simpler adaptation methods used in smaller models, as well as\nwith other enhancement strategies like retrieval-augmented generation and model\nediting. Moreover, informed by a discussion of benchmarks and evaluation, we\nidentify several challenges and future work directions for this crucial task.", "published": "2024-02-02 12:34:09", "link": "http://arxiv.org/abs/2402.01364v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "StepCoder: Improve Code Generation with Reinforcement Learning from\n  Compiler Feedback", "abstract": "The advancement of large language models (LLMs) has significantly propelled\nthe field of code generation. Previous work integrated reinforcement learning\n(RL) with compiler feedback for exploring the output space of LLMs to enhance\ncode generation quality. However, the lengthy code generated by LLMs in\nresponse to complex human requirements makes RL exploration a challenge. Also,\nsince the unit tests may not cover the complicated code, optimizing LLMs by\nusing these unexecuted code snippets is ineffective. To tackle these\nchallenges, we introduce StepCoder, a novel RL framework for code generation,\nconsisting of two main components: CCCS addresses the exploration challenge by\nbreaking the long sequences code generation task into a Curriculum of Code\nCompletion Subtasks, while FGO only optimizes the model by masking the\nunexecuted code segments to provide Fine-Grained Optimization. In addition, we\nfurthermore construct the APPS+ dataset for RL training, which is manually\nverified to ensure the correctness of unit tests. Experimental results show\nthat our method improves the ability to explore the output space and\noutperforms state-of-the-art approaches in corresponding benchmarks. Our\ndataset APPS+ and StepCoder are available online.", "published": "2024-02-02 13:14:31", "link": "http://arxiv.org/abs/2402.01391v2", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "K-Level Reasoning: Establishing Higher Order Beliefs in Large Language\n  Models for Strategic Reasoning", "abstract": "Strategic reasoning is a complex yet essential capability for intelligent\nagents. It requires Large Language Model (LLM) agents to adapt their strategies\ndynamically in multi-agent environments. Unlike static reasoning tasks, success\nin these contexts depends on anticipating other agents' beliefs and actions\nwhile continuously adjusting strategies to achieve individual goals. LLMs and\nLLM agents often struggle with strategic reasoning due to the absence of a\nreasoning framework that enables them to dynamically infer others' perspectives\nand adapt to changing environments. Inspired by the Level-K framework from game\ntheory and behavioral economics, which extends reasoning from simple reactions\nto structured strategic depth, we propose a novel framework: \"K-Level Reasoning\nwith Large Language Models (K-R).\" This framework employs recursive mechanisms\nto enable LLMs to achieve varying levels of strategic depth, allowing agents to\nform higher order beliefs - beliefs about others' beliefs. We validate this\nframework through rigorous testing on four testbeds: two classical game theory\nproblems and two social intelligence tasks. The results demonstrate the\nadvantages of K-R in strategic reasoning. Our work presents the first recursive\nimplementation of strategic depth in large language models (LLMs). It\nestablishes a foundation for future research into theory of mind and strategic\nreasoning in LLMs.", "published": "2024-02-02 16:07:05", "link": "http://arxiv.org/abs/2402.01521v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Decoding Speculative Decoding", "abstract": "Speculative Decoding is a widely used technique to speed up inference for\nLarge Language Models (LLMs) without sacrificing quality. When performing\ninference, speculative decoding uses a smaller draft model to generate\nspeculative tokens and then uses the target LLM to verify those draft tokens.\nThe speedup provided by speculative decoding heavily depends on the choice of\nthe draft model. In this work, we perform a detailed study comprising over 350\nexperiments with LLaMA-65B and OPT-66B using speculative decoding and delineate\nthe factors that affect the performance gain provided by speculative decoding.\nOur experiments indicate that the performance of speculative decoding depends\nheavily on the latency of the draft model, and the draft model's capability in\nlanguage modeling does not correlate strongly with its performance in\nspeculative decoding. Based on these insights we explore a new design space for\ndraft models and design hardware-efficient draft models for speculative\ndecoding. Our newly designed draft model can provide 111% higher throughput\nthan existing draft models and our approach generalizes further to all LLaMA\nmodels (1/2/3.1) and supervised fine-tuned models.", "published": "2024-02-02 16:15:24", "link": "http://arxiv.org/abs/2402.01528v4", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "An Empirical Analysis of Diversity in Argument Summarization", "abstract": "Presenting high-level arguments is a crucial task for fostering participation\nin online societal discussions. Current argument summarization approaches miss\nan important facet of this task -- capturing diversity -- which is important\nfor accommodating multiple perspectives. We introduce three aspects of\ndiversity: those of opinions, annotators, and sources. We evaluate approaches\nto a popular argument summarization task called Key Point Analysis, which shows\nhow these approaches struggle to (1) represent arguments shared by few people,\n(2) deal with data from various sources, and (3) align with subjectivity in\nhuman-provided annotations. We find that both general-purpose LLMs and\ndedicated KPA models exhibit this behavior, but have complementary strengths.\nFurther, we observe that diversification of training data may ameliorate\ngeneralization. Addressing diversity in argument summarization requires a mix\nof strategies to deal with subjectivity.", "published": "2024-02-02 16:26:52", "link": "http://arxiv.org/abs/2402.01535v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Nomic Embed: Training a Reproducible Long Context Text Embedder", "abstract": "This technical report describes the training of nomic-embed-text-v1, the\nfirst fully reproducible, open-source, open-weights, open-data, 8192 context\nlength English text embedding model that outperforms both OpenAI Ada-002 and\nOpenAI text-embedding-3-small on the short-context MTEB benchmark and the long\ncontext LoCo benchmark. We release the training code and model weights under an\nApache 2.0 license. In contrast with other open-source models, we release the\nfull curated training data and code that allows for full replication of\nnomic-embed-text-v1. You can find code and data to replicate the model at\nhttps://github.com/nomic-ai/contrastors.", "published": "2024-02-02 18:23:18", "link": "http://arxiv.org/abs/2402.01613v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Can LLMs perform structured graph reasoning?", "abstract": "Pretrained Large Language Models (LLMs) have demonstrated various reasoning\ncapabilities through language-based prompts alone, particularly in unstructured\ntask settings (tasks purely based on language semantics). However, LLMs often\nstruggle with structured tasks, because of the inherent incompatibility of\ninput representation. Reducing structured tasks to uni-dimensional language\nsemantics often renders the problem trivial. Keeping the trade-off between LLM\ncompatibility and structure complexity in mind, we design various graph\nreasoning tasks as a proxy to semi-structured tasks in this paper, in order to\ntest the ability to navigate through representations beyond plain text in\nvarious LLMs. Particularly, we design 10 distinct problems of graph traversal,\neach representing increasing levels of complexity, and benchmark 5 different\ninstruct-finetuned LLMs (GPT-4, GPT-3.5, Claude-2, Llama-2 and Palm-2) on the\naforementioned tasks. Further, we analyse the performance of models across\nvarious settings such as varying sizes of graphs as well as different forms of\nk-shot prompting. We highlight various limitations, biases and properties of\nLLMs through this benchmarking process, such as an inverse relation to the\naverage degrees of freedom of traversal per node in graphs, the overall\nnegative impact of k-shot prompting on graph reasoning tasks, and a positive\nresponse bias which prevents LLMs from identifying the absence of a valid\nsolution. Finally, we introduce a new prompting technique specially designed\nfor graph traversal tasks (PathCompare), which demonstrates a notable increase\nin the performance of LLMs in comparison to standard prompting techniques such\nas Chain-of-Thought (CoT).", "published": "2024-02-02 09:45:33", "link": "http://arxiv.org/abs/2402.01805v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack\n  on Text", "abstract": "Black-box hard-label adversarial attack on text is a practical and\nchallenging task, as the text data space is inherently discrete and\nnon-differentiable, and only the predicted label is accessible. Research on\nthis problem is still in the embryonic stage and only a few methods are\navailable. Nevertheless, existing methods rely on the complex heuristic\nalgorithm or unreliable gradient estimation strategy, which probably fall into\nthe local optimum and inevitably consume numerous queries, thus are difficult\nto craft satisfactory adversarial examples with high semantic similarity and\nlow perturbation rate in a limited query budget. To alleviate above issues, we\npropose a simple yet effective framework to generate high quality textual\nadversarial examples under the black-box hard-label attack scenarios, named\nHQA-Attack. Specifically, after initializing an adversarial example randomly,\nHQA-attack first constantly substitutes original words back as many as\npossible, thus shrinking the perturbation rate. Then it leverages the synonym\nset of the remaining changed words to further optimize the adversarial example\nwith the direction which can improve the semantic similarity and satisfy the\nadversarial condition simultaneously. In addition, during the optimizing\nprocedure, it searches a transition synonym word for each changed word, thus\navoiding traversing the whole synonym set and reducing the query number to some\nextent. Extensive experimental results on five text classification datasets,\nthree natural language inference datasets and two real-world APIs have shown\nthat the proposed HQA-Attack method outperforms other strong baselines\nsignificantly.", "published": "2024-02-02 10:06:43", "link": "http://arxiv.org/abs/2402.01806v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Building Guardrails for Large Language Models", "abstract": "As Large Language Models (LLMs) become more integrated into our daily lives,\nit is crucial to identify and mitigate their risks, especially when the risks\ncan have profound impacts on human users and societies. Guardrails, which\nfilter the inputs or outputs of LLMs, have emerged as a core safeguarding\ntechnology. This position paper takes a deep look at current open-source\nsolutions (Llama Guard, Nvidia NeMo, Guardrails AI), and discusses the\nchallenges and the road towards building more complete solutions. Drawing on\nrobust evidence from previous research, we advocate for a systematic approach\nto construct guardrails for LLMs, based on comprehensive consideration of\ndiverse contexts across various LLMs applications. We propose employing\nsocio-technical methods through collaboration with a multi-disciplinary team to\npinpoint precise technical requirements, exploring advanced neural-symbolic\nimplementations to embrace the complexity of the requirements, and developing\nverification and testing to ensure the utmost quality of the final product.", "published": "2024-02-02 16:35:00", "link": "http://arxiv.org/abs/2402.01822v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Fractal Patterns May Illuminate the Success of Next-Token Prediction", "abstract": "We study the fractal structure of language, aiming to provide a precise\nformalism for quantifying properties that may have been previously suspected\nbut not formally shown. We establish that language is: (1) self-similar,\nexhibiting complexities at all levels of granularity, with no particular\ncharacteristic context length, and (2) long-range dependent (LRD), with a Hurst\nparameter of approximately H=0.7. Based on these findings, we argue that\nshort-term patterns/dependencies in language, such as in paragraphs, mirror the\npatterns/dependencies over larger scopes, like entire documents. This may shed\nsome light on how next-token prediction can capture the structure of text\nacross multiple levels of granularity, from words and clauses to broader\ncontexts and intents. In addition, we carry out an extensive analysis across\ndifferent domains and architectures, showing that fractal parameters are\nrobust. Finally, we demonstrate that the tiny variations in fractal parameters\nseen across LLMs improve upon perplexity-based bits-per-byte (BPB) in\npredicting their downstream performance. We hope these findings offer a fresh\nperspective on language and the mechanisms underlying the success of LLMs.", "published": "2024-02-02 17:09:33", "link": "http://arxiv.org/abs/2402.01825v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Analyzing Blood Pressure Variations\n  Across Biological Sex from Scientific Literature", "abstract": "Hypertension, defined as blood pressure (BP) that is above normal, holds\nparamount significance in the realm of public health, as it serves as a\ncritical precursor to various cardiovascular diseases (CVDs) and significantly\ncontributes to elevated mortality rates worldwide. However, many existing BP\nmeasurement technologies and standards might be biased because they do not\nconsider clinical outcomes, comorbidities, or demographic factors, making them\ninconclusive for diagnostic purposes. There is limited data-driven research\nfocused on studying the variance in BP measurements across these variables. In\nthis work, we employed GPT-35-turbo, a large language model (LLM), to\nautomatically extract the mean and standard deviation values of BP for both\nmales and females from a dataset comprising 25 million abstracts sourced from\nPubMed. 993 article abstracts met our predefined inclusion criteria (i.e.,\npresence of references to blood pressure, units of blood pressure such as mmHg,\nand mention of biological sex). Based on the automatically-extracted\ninformation from these articles, we conducted an analysis of the variations of\nBP values across biological sex. Our results showed the viability of utilizing\nLLMs to study the BP variations across different demographic factors.", "published": "2024-02-02 18:15:51", "link": "http://arxiv.org/abs/2402.01826v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Leveraging Large Language Models for Structure Learning in Prompted Weak\n  Supervision", "abstract": "Prompted weak supervision (PromptedWS) applies pre-trained large language\nmodels (LLMs) as the basis for labeling functions (LFs) in a weak supervision\nframework to obtain large labeled datasets. We further extend the use of LLMs\nin the loop to address one of the key challenges in weak supervision: learning\nthe statistical dependency structure among supervision sources. In this work,\nwe ask the LLM how similar are these prompted LFs. We propose a Structure\nRefining Module, a simple yet effective first approach based on the\nsimilarities of the prompts by taking advantage of the intrinsic structure in\nthe embedding space. At the core of Structure Refining Module are Labeling\nFunction Removal (LaRe) and Correlation Structure Generation (CosGen). Compared\nto previous methods that learn the dependencies from weak labels, our method\nfinds the dependencies which are intrinsic to the LFs and less dependent on the\ndata. We show that our Structure Refining Module improves the PromptedWS\npipeline by up to 12.7 points on the benchmark tasks. We also explore the\ntrade-offs between efficiency and performance with comprehensive ablation\nexperiments and analysis. Code for this project can be found in\nhttps://github.com/BatsResearch/su-bigdata23-code.", "published": "2024-02-02 19:45:39", "link": "http://arxiv.org/abs/2402.01867v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LiPO: Listwise Preference Optimization through Learning-to-Rank", "abstract": "Aligning language models (LMs) with curated human feedback is critical to\ncontrol their behaviors in real-world applications. Several recent policy\noptimization methods, such as DPO and SLiC, serve as promising alternatives to\nthe traditional Reinforcement Learning from Human Feedback (RLHF) approach. In\npractice, human feedback often comes in a format of a ranked list over multiple\nresponses to amortize the cost of reading prompt. Multiple responses can also\nbe ranked by reward models or AI feedback. There lacks such a thorough study on\ndirectly fitting upon a list of responses. In this work, we formulate the LM\nalignment as a \\textit{listwise} ranking problem and describe the LiPO\nframework, where the policy can potentially learn more effectively from a\nranked list of plausible responses given the prompt. This view draws an\nexplicit connection to Learning-to-Rank (LTR), where most existing preference\noptimization work can be mapped to existing ranking objectives. Following this\nconnection, we provide an examination of ranking objectives that are not well\nstudied for LM alignment with DPO and SLiC as special cases when list size is\ntwo. In particular, we highlight a specific method, LiPO-$\\lambda$, which\nleverages a state-of-the-art \\textit{listwise} ranking objective and weights\neach preference pair in a more advanced manner. We show that LiPO-$\\lambda$ can\noutperform DPO variants and SLiC by a clear margin on several preference\nalignment tasks with both curated and real rankwise preference data.", "published": "2024-02-02 20:08:10", "link": "http://arxiv.org/abs/2402.01878v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Reading Between the Tweets: Deciphering Ideological Stances of\n  Interconnected Mixed-Ideology Communities", "abstract": "Recent advances in NLP have improved our ability to understand the nuanced\nworldviews of online communities. Existing research focused on probing\nideological stances treats liberals and conservatives as separate groups.\nHowever, this fails to account for the nuanced views of the organically formed\nonline communities and the connections between them. In this paper, we study\ndiscussions of the 2020 U.S. election on Twitter to identify complex\ninteracting communities. Capitalizing on this interconnectedness, we introduce\na novel approach that harnesses message passing when finetuning language models\n(LMs) to probe the nuanced ideologies of these communities. By comparing the\nresponses generated by LMs and real-world survey results, our method shows\nhigher alignment than existing baselines, highlighting the potential of using\nLMs in revealing complex ideologies within and across interconnected\nmixed-ideology communities.", "published": "2024-02-02 01:39:00", "link": "http://arxiv.org/abs/2402.01091v1", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models", "abstract": "Leading models for the text-to-SQL task heavily rely on proprietary Large\nLanguage Models (LLMs), posing concerns over data privacy. Closing the\nperformance gap between small open-source models and large proprietary models\nis crucial to mitigate this reliance. To this end, we introduce a novel\ntwo-stage fine-tuning approach that decomposes the task into two simpler tasks.\nThrough comprehensive evaluation on two large cross-domain datasets and two\nsmall LLMs, we show that this approach improves execution accuracy by 3 to 7\npercent, effectively aligning the performance of open-source models with their\nproprietary counterparts.", "published": "2024-02-02 03:21:00", "link": "http://arxiv.org/abs/2402.01117v1", "categories": ["cs.CL", "cs.DB", "cs.HC"], "primary_category": "cs.CL"}
{"title": "AccentFold: A Journey through African Accents for Zero-Shot ASR\n  Adaptation to Target Accents", "abstract": "Despite advancements in speech recognition, accented speech remains\nchallenging. While previous approaches have focused on modeling techniques or\ncreating accented speech datasets, gathering sufficient data for the multitude\nof accents, particularly in the African context, remains impractical due to\ntheir sheer diversity and associated budget constraints. To address these\nchallenges, we propose AccentFold, a method that exploits spatial relationships\nbetween learned accent embeddings to improve downstream Automatic Speech\nRecognition (ASR). Our exploratory analysis of speech embeddings representing\n100+ African accents reveals interesting spatial accent relationships\nhighlighting geographic and genealogical similarities, capturing consistent\nphonological, and morphological regularities, all learned empirically from\nspeech. Furthermore, we discover accent relationships previously\nuncharacterized by the Ethnologue. Through empirical evaluation, we demonstrate\nthe effectiveness of AccentFold by showing that, for out-of-distribution (OOD)\naccents, sampling accent subsets for training based on AccentFold information\noutperforms strong baselines a relative WER improvement of 4.6%. AccentFold\npresents a promising approach for improving ASR performance on accented speech,\nparticularly in the context of African accents, where data scarcity and budget\nconstraints pose significant challenges. Our findings emphasize the potential\nof leveraging linguistic relationships to improve zero-shot ASR adaptation to\ntarget accents.", "published": "2024-02-02 05:38:59", "link": "http://arxiv.org/abs/2402.01152v2", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Streaming Sequence Transduction through Dynamic Compression", "abstract": "We introduce STAR (Stream Transduction with Anchor Representations), a novel\nTransformer-based model designed for efficient sequence-to-sequence\ntransduction over streams. STAR dynamically segments input streams to create\ncompressed anchor representations, achieving nearly lossless compression (12x)\nin Automatic Speech Recognition (ASR) and outperforming existing methods.\nMoreover, STAR demonstrates superior segmentation and latency-quality\ntrade-offs in simultaneous speech-to-text tasks, optimizing latency, memory\nfootprint, and quality.", "published": "2024-02-02 06:31:50", "link": "http://arxiv.org/abs/2402.01172v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "LINGO-Space: Language-Conditioned Incremental Grounding for Space", "abstract": "We aim to solve the problem of spatially localizing composite instructions\nreferring to space: space grounding. Compared to current instance grounding,\nspace grounding is challenging due to the ill-posedness of identifying\nlocations referred to by discrete expressions and the compositional ambiguity\nof referring expressions. Therefore, we propose a novel probabilistic\nspace-grounding methodology (LINGO-Space) that accurately identifies a\nprobabilistic distribution of space being referred to and incrementally updates\nit, given subsequent referring expressions leveraging configurable polar\ndistributions. Our evaluations show that the estimation using polar\ndistributions enables a robot to ground locations successfully through $20$\ntable-top manipulation benchmark tests. We also show that updating the\ndistribution helps the grounding method accurately narrow the referring space.\nWe finally demonstrate the robustness of the space grounding with simulated\nmanipulation and real quadruped robot navigation tasks. Code and videos are\navailable at https://lingo-space.github.io.", "published": "2024-02-02 06:58:39", "link": "http://arxiv.org/abs/2402.01183v1", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.RO"}
{"title": "Skip \\n: A Simple Method to Reduce Hallucination in Large\n  Vision-Language Models", "abstract": "Recent advancements in large vision-language models (LVLMs) have demonstrated\nimpressive capability in visual information understanding with human language.\nDespite these advances, LVLMs still face challenges with multimodal\nhallucination, such as generating text descriptions of objects that are not\npresent in the visual information. However, the underlying fundamental reasons\nof multimodal hallucinations remain poorly explored. In this paper, we propose\na new perspective, suggesting that the inherent biases in LVLMs might be a key\nfactor in hallucinations. Specifically, we systematically identify a semantic\nshift bias related to paragraph breaks (\\n\\n), where the content before and\nafter '\\n\\n' in the training data frequently exhibit significant semantic\nchanges. This pattern leads the model to infer that the contents following\n'\\n\\n' should be obviously different from the preceding contents with less\nhallucinatory descriptions, thereby increasing the probability of hallucinatory\ndescriptions subsequent to the '\\n\\n'. We have validated this hypothesis on\nmultiple publicly available LVLMs. Besides, we find that deliberately inserting\n'\\n\\n' at the generated description can induce more hallucinations. A simple\nmethod is proposed to effectively mitigate the hallucination of LVLMs by\nskipping the output of '\\n'.", "published": "2024-02-02 12:02:46", "link": "http://arxiv.org/abs/2402.01345v6", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Describing Images $\\textit{Fast and Slow}$: Quantifying and Predicting\n  the Variation in Human Signals during Visuo-Linguistic Processes", "abstract": "There is an intricate relation between the properties of an image and how\nhumans behave while describing the image. This behavior shows ample variation,\nas manifested in human signals such as eye movements and when humans start to\ndescribe the image. Despite the value of such signals of visuo-linguistic\nvariation, they are virtually disregarded in the training of current pretrained\nmodels, which motivates further investigation. Using a corpus of Dutch image\ndescriptions with concurrently collected eye-tracking data, we explore the\nnature of the variation in visuo-linguistic signals, and find that they\ncorrelate with each other. Given this result, we hypothesize that variation\nstems partly from the properties of the images, and explore whether image\nrepresentations encoded by pretrained vision encoders can capture such\nvariation. Our results indicate that pretrained models do so to a\nweak-to-moderate degree, suggesting that the models lack biases about what\nmakes a stimulus complex for humans and what leads to variations in human\noutputs.", "published": "2024-02-02 12:11:16", "link": "http://arxiv.org/abs/2402.01352v1", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "LoTR: Low Tensor Rank Weight Adaptation", "abstract": "In this paper we generalize and extend an idea of low-rank adaptation (LoRA)\nof large language models (LLMs) based on Transformer architecture. Widely used\nLoRA-like methods of fine-tuning LLMs are based on matrix factorization of\ngradient update. We introduce LoTR, a novel approach for parameter-efficient\nfine-tuning of LLMs which represents a gradient update to parameters in a form\nof tensor decomposition. Low-rank adapter for each layer is constructed as a\nproduct of three matrices, and tensor structure arises from sharing left and\nright multipliers of this product among layers. Simultaneous compression of a\nsequence of layers with low-rank tensor representation allows LoTR to archive\neven better parameter efficiency then LoRA especially for deep models.\nMoreover, the core tensor does not depend on original weight dimension and can\nbe made arbitrary small, which allows for extremely cheap and fast downstream\nfine-tuning.", "published": "2024-02-02 13:00:38", "link": "http://arxiv.org/abs/2402.01376v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Sequence Shortening for Context-Aware Machine Translation", "abstract": "Context-aware Machine Translation aims to improve translations of sentences\nby incorporating surrounding sentences as context. Towards this task, two main\narchitectures have been applied, namely single-encoder (based on concatenation)\nand multi-encoder models. In this study, we show that a special case of\nmulti-encoder architecture, where the latent representation of the source\nsentence is cached and reused as the context in the next step, achieves higher\naccuracy on the contrastive datasets (where the models have to rank the correct\ntranslation among the provided sentences) and comparable BLEU and COMET scores\nas the single- and multi-encoder approaches. Furthermore, we investigate the\napplication of Sequence Shortening to the cached representations. We test three\npooling-based shortening techniques and introduce two novel methods - Latent\nGrouping and Latent Selecting, where the network learns to group tokens or\nselects the tokens to be cached as context. Our experiments show that the two\nmethods achieve competitive BLEU and COMET scores and accuracies on the\ncontrastive datasets to the other tested methods while potentially allowing for\nhigher interpretability and reducing the growth of memory requirements with\nincreased context size.", "published": "2024-02-02 13:55:37", "link": "http://arxiv.org/abs/2402.01416v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Deep Active Learning for Data Mining from Conflict Text Corpora", "abstract": "High-resolution event data on armed conflict and related processes have\nrevolutionized the study of political contention with datasets like UCDP GED,\nACLED etc. However, most of these datasets limit themselves to collecting\nspatio-temporal (high-resolution) and intensity data. Information on dynamics,\nsuch as targets, tactics, purposes etc. are rarely collected owing to the\nextreme workload of collecting data. However, most datasets rely on a rich\ncorpus of textual data allowing further mining of further information connected\nto each event. This paper proposes one such approach that is inexpensive and\nhigh performance, leveraging active learning - an iterative process of\nimproving a machine learning model based on sequential (guided) human input.\nActive learning is employed to then step-wise train (fine-tuning) of a large,\nencoder-only language model adapted for extracting sub-classes of events\nrelating to conflict dynamics. The approach shows performance similar to human\n(gold-standard) coding while reducing the amount of required human annotation\nby as much as 99%.", "published": "2024-02-02 17:16:23", "link": "http://arxiv.org/abs/2402.01577v1", "categories": ["cs.CY", "cs.CL", "stat.ML"], "primary_category": "cs.CY"}
{"title": "Are Paralinguistic Representations all that is needed for Speech Emotion\n  Recognition?", "abstract": "Availability of representations from pre-trained models (PTMs) have\nfacilitated substantial progress in speech emotion recognition (SER).\nParticularly, representations from PTM trained for paralinguistic speech\nprocessing have shown state-of-the-art (SOTA) performance for SER. However,\nsuch paralinguistic PTM representations haven't been evaluated for SER in\nlinguistic environments other than English. Also, paralinguistic PTM\nrepresentations haven't been investigated in benchmarks such as SUPERB,\nEMO-SUPERB, ML-SUPERB for SER. This makes it difficult to access the efficacy\nof paralinguistic PTM representations for SER in multiple languages. To fill\nthis gap, we perform a comprehensive comparative study of five SOTA PTM\nrepresentations. Our results shows that paralinguistic PTM (TRILLsson)\nrepresentations performs the best and this performance can be attributed to its\neffectiveness in capturing pitch, tone and other speech characteristics more\neffectively than other PTM representations.", "published": "2024-02-02 17:17:42", "link": "http://arxiv.org/abs/2402.01579v2", "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "TrustAgent: Towards Safe and Trustworthy LLM-based Agents", "abstract": "The rise of LLM-based agents shows great potential to revolutionize task\nplanning, capturing significant attention. Given that these agents will be\nintegrated into high-stake domains, ensuring their reliability and safety is\ncrucial. This paper presents an Agent-Constitution-based agent framework,\nTrustAgent, with a particular focus on improving the LLM-based agent safety.\nThe proposed framework ensures strict adherence to the Agent Constitution\nthrough three strategic components: pre-planning strategy which injects safety\nknowledge to the model before plan generation, in-planning strategy which\nenhances safety during plan generation, and post-planning strategy which\nensures safety by post-planning inspection. Our experimental results\ndemonstrate that the proposed framework can effectively enhance an LLM agent's\nsafety across multiple domains by identifying and mitigating potential dangers\nduring the planning. Further analysis reveals that the framework not only\nimproves safety but also enhances the helpfulness of the agent. Additionally,\nwe highlight the importance of the LLM reasoning ability in adhering to the\nConstitution. This paper sheds light on how to ensure the safe integration of\nLLM-based agents into human-centric environments. Data and code are available\nat https://github.com/agiresearch/TrustAgent.", "published": "2024-02-02 17:26:23", "link": "http://arxiv.org/abs/2402.01586v4", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "cs.CL"}
{"title": "BAT: Learning to Reason about Spatial Sounds with Large Language Models", "abstract": "Spatial sound reasoning is a fundamental human skill, enabling us to navigate\nand interpret our surroundings based on sound. In this paper we present BAT,\nwhich combines the spatial sound perception ability of a binaural acoustic\nscene analysis model with the natural language reasoning capabilities of a\nlarge language model (LLM) to replicate this innate ability. To address the\nlack of existing datasets of in-the-wild spatial sounds, we synthesized a\nbinaural audio dataset using AudioSet and SoundSpaces 2.0. Next, we developed\nSpatialSoundQA, a spatial sound-based question-answering dataset, offering a\nrange of QA tasks that train BAT in various aspects of spatial sound perception\nand reasoning. The acoustic front end encoder of BAT is a novel spatial audio\nencoder named Spatial Audio Spectrogram Transformer, or Spatial-AST, which by\nitself achieves strong performance across sound event detection, spatial\nlocalization, and distance estimation. By integrating Spatial-AST with LLaMA-2\n7B model, BAT transcends standard Sound Event Localization and Detection (SELD)\ntasks, enabling the model to reason about the relationships between the sounds\nin its environment. Our experiments demonstrate BAT's superior performance on\nboth spatial sound perception and reasoning, showcasing the immense potential\nof LLMs in navigating and interpreting complex spatial audio environments.", "published": "2024-02-02 17:34:53", "link": "http://arxiv.org/abs/2402.01591v2", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Position Paper: Generalized grammar rules and structure-based\n  generalization beyond classical equivariance for lexical tasks and\n  transduction", "abstract": "Compositional generalization is one of the main properties which\ndifferentiates lexical learning in humans from state-of-art neural networks. We\npropose a general framework for building models that can generalize\ncompositionally using the concept of Generalized Grammar Rules (GGRs), a class\nof symmetry-based compositional constraints for transduction tasks, which we\nview as a transduction analogue of equivariance constraints in physics-inspired\ntasks. Besides formalizing generalized notions of symmetry for language\ntransduction, our framework is general enough to contain many existing works as\nspecial cases. We present ideas on how GGRs might be implemented, and in the\nprocess draw connections to reinforcement learning and other areas of research.", "published": "2024-02-02 18:44:37", "link": "http://arxiv.org/abs/2402.01629v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "LitLLM: A Toolkit for Scientific Literature Review", "abstract": "Conducting literature reviews for scientific papers is essential for\nunderstanding research, its limitations, and building on existing work. It is a\ntedious task which makes an automatic literature review generator appealing.\nUnfortunately, many existing works that generate such reviews using Large\nLanguage Models (LLMs) have significant limitations. They tend to\nhallucinate-generate non-factual information-and ignore the latest research\nthey have not been trained on. To address these limitations, we propose a\ntoolkit that operates on Retrieval Augmented Generation (RAG) principles,\nspecialized prompting and instructing techniques with the help of LLMs. Our\nsystem first initiates a web search to retrieve relevant papers by summarizing\nuser-provided abstracts into keywords using an off-the-shelf LLM. Authors can\nenhance the search by supplementing it with relevant papers or keywords,\ncontributing to a tailored retrieval process. Second, the system re-ranks the\nretrieved papers based on the user-provided abstract. Finally, the related work\nsection is generated based on the re-ranked results and the abstract. There is\na substantial reduction in time and effort for literature review compared to\ntraditional methods, establishing our toolkit as an efficient alternative. Our\nproject page including the demo and toolkit can be accessed here:\nhttps://litllm.github.io", "published": "2024-02-02 02:41:28", "link": "http://arxiv.org/abs/2402.01788v2", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "The Political Preferences of LLMs", "abstract": "I report here a comprehensive analysis about the political preferences\nembedded in Large Language Models (LLMs). Namely, I administer 11 political\norientation tests, designed to identify the political preferences of the test\ntaker, to 24 state-of-the-art conversational LLMs, both closed and open source.\nWhen probed with questions/statements with political connotations, most\nconversational LLMs tend to generate responses that are diagnosed by most\npolitical test instruments as manifesting preferences for left-of-center\nviewpoints. This does not appear to be the case for five additional base (i.e.\nfoundation) models upon which LLMs optimized for conversation with humans are\nbuilt. However, the weak performance of the base models at coherently answering\nthe tests' questions makes this subset of results inconclusive. Finally, I\ndemonstrate that LLMs can be steered towards specific locations in the\npolitical spectrum through Supervised Fine-Tuning (SFT) with only modest\namounts of politically aligned data, suggesting SFT's potential to embed\npolitical orientation in LLMs. With LLMs beginning to partially displace\ntraditional information sources like search engines and Wikipedia, the societal\nimplications of political biases embedded in LLMs are substantial.", "published": "2024-02-02 02:43:10", "link": "http://arxiv.org/abs/2402.01789v2", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Speech foundation models in healthcare: Effect of layer selection on\n  pathological speech feature prediction", "abstract": "Accurately extracting clinical information from speech is critical to the\ndiagnosis and treatment of many neurological conditions. As such, there is\ninterest in leveraging AI for automatic, objective assessments of clinical\nspeech to facilitate diagnosis and treatment of speech disorders. We explore\ntransfer learning using foundation models, focusing on the impact of layer\nselection for the downstream task of predicting pathological speech features.\nWe find that selecting an optimal layer can greatly improve performance (~15.8%\nincrease in balanced accuracy per feature as compared to worst layer, ~13.6%\nincrease as compared to final layer), though the best layer varies by predicted\nfeature and does not always generalize well to unseen data. A learned weighted\nsum offers comparable performance to the average best layer in-distribution\n(only ~1.2% lower) and had strong generalization for out-of-distribution data\n(only 1.5% lower than the average best layer).", "published": "2024-02-02 05:09:42", "link": "http://arxiv.org/abs/2402.01796v2", "categories": ["eess.AS", "cs.CL", "cs.LG"], "primary_category": "eess.AS"}
{"title": "Faster and Lighter LLMs: A Survey on Current Challenges and Way Forward", "abstract": "Despite the impressive performance of LLMs, their widespread adoption faces\nchallenges due to substantial computational and memory requirements during\ninference. Recent advancements in model compression and system-level\noptimization methods aim to enhance LLM inference. This survey offers an\noverview of these methods, emphasizing recent developments. Through experiments\non LLaMA(/2)-7B, we evaluate various compression techniques, providing\npractical insights for efficient LLM deployment in a unified setting. The\nempirical analysis on LLaMA(/2)-7B highlights the effectiveness of these\nmethods. Drawing from survey insights, we identify current limitations and\ndiscuss potential future directions to improve LLM inference efficiency. We\nrelease the codebase to reproduce the results presented in this paper at\nhttps://github.com/nyunAI/Faster-LLM-Survey", "published": "2024-02-02 06:29:34", "link": "http://arxiv.org/abs/2402.01799v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Large Language Models for Time Series: A Survey", "abstract": "Large Language Models (LLMs) have seen significant use in domains such as\nnatural language processing and computer vision. Going beyond text, image and\ngraphics, LLMs present a significant potential for analysis of time series\ndata, benefiting domains such as climate, IoT, healthcare, traffic, audio and\nfinance. This survey paper provides an in-depth exploration and a detailed\ntaxonomy of the various methodologies employed to harness the power of LLMs for\ntime series analysis. We address the inherent challenge of bridging the gap\nbetween LLMs' original text data training and the numerical nature of time\nseries data, and explore strategies for transferring and distilling knowledge\nfrom LLMs to numerical time series analysis. We detail various methodologies,\nincluding (1) direct prompting of LLMs, (2) time series quantization, (3)\naligning techniques, (4) utilization of the vision modality as a bridging\nmechanism, and (5) the combination of LLMs with tools. Additionally, this\nsurvey offers a comprehensive overview of the existing multimodal time series\nand text datasets and delves into the challenges and future opportunities of\nthis emerging field. We maintain an up-to-date Github repository which includes\nall the papers and datasets discussed in the survey.", "published": "2024-02-02 07:24:35", "link": "http://arxiv.org/abs/2402.01801v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Distilling LLMs' Decomposition Abilities into Compact Language Models", "abstract": "Large Language Models (LLMs) have demonstrated proficiency in their reasoning\nabilities, yet their large size presents scalability challenges and limits any\nfurther customization. In contrast, compact models offer customized training\nbut often fall short in solving complex reasoning tasks. This study focuses on\ndistilling the LLMs' decomposition skills into compact models using offline\nreinforcement learning. We leverage the advancements in the LLM`s capabilities\nto provide feedback and generate a specialized task-specific dataset for\ntraining compact models. The development of an AI-generated dataset and the\nestablishment of baselines constitute the primary contributions of our work,\nunderscoring the potential of compact models in replicating complex\nproblem-solving skills.", "published": "2024-02-02 13:23:15", "link": "http://arxiv.org/abs/2402.01812v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Retrieval Augmented End-to-End Spoken Dialog Models", "abstract": "We recently developed SLM, a joint speech and language model, which fuses a\npretrained foundational speech model and a large language model (LLM), while\npreserving the in-context learning capability intrinsic to the pretrained LLM.\nIn this paper, we apply SLM to speech dialog applications where the dialog\nstates are inferred directly from the audio signal.\n  Task-oriented dialogs often contain domain-specific entities, i.e.,\nrestaurants, hotels, train stations, and city names, which are difficult to\nrecognize, however, critical for the downstream applications. Inspired by the\nRAG (retrieval-augmented generation) paradigm, we propose a retrieval augmented\nSLM (ReSLM) that overcomes this weakness. We first train a speech retriever to\nretrieve text entities mentioned in the audio. The retrieved entities are then\nadded as text inputs to the underlying SLM to bias model predictions. We\nevaluated ReSLM on speech MultiWoz task (DSTC-11 challenge), and found that\nthis retrieval augmentation boosts model performance, achieving joint goal\naccuracy (38.6% vs 32.7%), slot error rate (20.6% vs 24.8%) and ASR word error\nrate (5.5% vs 6.7%). While demonstrated on dialog state tracking, our approach\nis broadly applicable to other speech tasks requiring contextual information or\ndomain-specific entities, such as contextual ASR with biasing capability.", "published": "2024-02-02 18:23:09", "link": "http://arxiv.org/abs/2402.01828v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Predicting ATP binding sites in protein sequences using Deep Learning\n  and Natural Language Processing", "abstract": "Predicting ATP-Protein Binding sites in genes is of great significance in the\nfield of Biology and Medicine. The majority of research in this field has been\nconducted through time- and resource-intensive 'wet experiments' in\nlaboratories. Over the years, researchers have been investigating computational\nmethods computational methods to accomplish the same goals, utilising the\nstrength of advanced Deep Learning and NLP algorithms. In this paper, we\npropose to develop methods to classify ATP-Protein binding sites. We conducted\nvarious experiments mainly using PSSMs and several word embeddings as features.\nWe used 2D CNNs and LightGBM classifiers as our chief Deep Learning Algorithms.\nThe MP3Vec and BERT models have also been subjected to testing in our study.\nThe outcomes of our experiments demonstrated improvement over the\nstate-of-the-art benchmarks.", "published": "2024-02-02 18:42:39", "link": "http://arxiv.org/abs/2402.01829v1", "categories": ["q-bio.BM", "cs.CL", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "PiCO: Peer Review in LLMs based on the Consistency Optimization", "abstract": "Existing large language models (LLMs) evaluation methods typically focus on\ntesting the performance on some closed-environment and domain-specific\nbenchmarks with human annotations. In this paper, we explore a novel\nunsupervised evaluation direction, utilizing peer-review mechanisms to measure\nLLMs automatically. In this setting, both open-source and closed-source LLMs\nlie in the same environment, capable of answering unlabeled questions and\nevaluating each other, where each LLM's response score is jointly determined by\nother anonymous ones. To obtain the ability hierarchy among these models, we\nassign each LLM a learnable capability parameter to adjust the final ranking.\nWe formalize it as a constrained optimization problem, intending to maximize\nthe consistency of each LLM's capabilities and scores. The key assumption\nbehind is that high-level LLM can evaluate others' answers more accurately than\nlow-level ones, while higher-level LLM can also achieve higher response scores.\nMoreover, we propose three metrics called PEN, CIN, and LIS to evaluate the gap\nin aligning human rankings. We perform experiments on multiple datasets with\nthese metrics, validating the effectiveness of the proposed approach.", "published": "2024-02-02 18:49:26", "link": "http://arxiv.org/abs/2402.01830v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "COMET: Generating Commit Messages using Delta Graph Context\n  Representation", "abstract": "Commit messages explain code changes in a commit and facilitate collaboration\namong developers. Several commit message generation approaches have been\nproposed; however, they exhibit limited success in capturing the context of\ncode changes. We propose Comet (Context-Aware Commit Message Generation), a\nnovel approach that captures context of code changes using a graph-based\nrepresentation and leverages a transformer-based model to generate high-quality\ncommit messages. Our proposed method utilizes delta graph that we developed to\neffectively represent code differences. We also introduce a customizable\nquality assurance module to identify optimal messages, mitigating subjectivity\nin commit messages. Experiments show that Comet outperforms state-of-the-art\ntechniques in terms of bleu-norm and meteor metrics while being comparable in\nterms of rogue-l. Additionally, we compare the proposed approach with the\npopular gpt-3.5-turbo model, along with gpt-4-turbo; the most capable GPT\nmodel, over zero-shot, one-shot, and multi-shot settings. We found Comet\noutperforming the GPT models, on five and four metrics respectively and provide\ncompetitive results with the two other metrics. The study has implications for\nresearchers, tool developers, and software developers. Software developers may\nutilize Comet to generate context-aware commit messages. Researchers and tool\ndevelopers can apply the proposed delta graph technique in similar contexts,\nlike code review summarization.", "published": "2024-02-02 19:01:52", "link": "http://arxiv.org/abs/2402.01841v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Explaining latent representations of generative models with large\n  multimodal models", "abstract": "Learning interpretable representations of data generative latent factors is\nan important topic for the development of artificial intelligence. With the\nrise of the large multimodal model, it can align images with text to generate\nanswers. In this work, we propose a framework to comprehensively explain each\nlatent variable in the generative models using a large multimodal model. We\nfurther measure the uncertainty of our generated explanations, quantitatively\nevaluate the performance of explanation generation among multiple large\nmultimodal models, and qualitatively visualize the variations of each latent\nvariable to learn the disentanglement effects of different generative models on\nexplanations. Finally, we discuss the explanatory capabilities and limitations\nof state-of-the-art large multimodal models.", "published": "2024-02-02 19:28:33", "link": "http://arxiv.org/abs/2402.01858v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "What Will My Model Forget? Forecasting Forgotten Examples in Language\n  Model Refinement", "abstract": "Language models deployed in the wild make errors. However, simply updating\nthe model with the corrected error instances causes catastrophic forgetting --\nthe updated model makes errors on instances learned during the instruction\ntuning or upstream training phase. Randomly replaying upstream data yields\nunsatisfactory performance and often comes with high variance and poor\ncontrollability. To this end, we try to forecast upstream examples that will be\nforgotten due to a model update for improved controllability of the replay\nprocess and interpretability. We train forecasting models given a collection of\nonline learned examples and corresponding forgotten upstream pre-training\nexamples. We propose a partially interpretable forecasting model based on the\nobservation that changes in pre-softmax logit scores of pretraining examples\nresemble that of online learned examples, which performs decently on BART but\nfails on T5 models. We further show a black-box classifier based on inner\nproducts of example representations achieves better forecasting performance\nover a series of setups. Finally, we show that we reduce forgetting of upstream\npretraining examples by replaying examples that are forecasted to be forgotten,\ndemonstrating the practical utility of forecasting example forgetting.", "published": "2024-02-02 19:43:15", "link": "http://arxiv.org/abs/2402.01865v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "InferCept: Efficient Intercept Support for Augmented Large Language\n  Model Inference", "abstract": "Large language models are increasingly integrated with external environments,\ntools, and agents like ChatGPT plugins to extend their capability beyond\nlanguage-centric tasks. However, today's LLM inference systems are designed for\nstandalone LLMs. They treat each external interaction as the end of LLM\ngeneration and form a new request when the interaction finishes, causing\nunnecessary recomputation of already computed contexts, which accounts for\n37-40% of total model forwarding time. This paper presents InferCept, the first\nLLM inference framework targeting augmented LLMs and supporting the efficient\ninterception of LLM generation. InferCept minimizes the GPU resource waste\ncaused by LLM interceptions and dedicates saved memory for serving more\nrequests. InferCept improves the overall serving throughput by 1.6x-2x and\ncompletes 2x more requests per second compared to the state-of-the-art LLM\ninference systems.", "published": "2024-02-02 19:47:57", "link": "http://arxiv.org/abs/2402.01869v2", "categories": ["cs.LG", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
{"title": "The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement\n  Learning and Large Language Models", "abstract": "In this work, we review research studies that combine Reinforcement Learning\n(RL) and Large Language Models (LLMs), two areas that owe their momentum to the\ndevelopment of deep neural networks. We propose a novel taxonomy of three main\nclasses based on the way that the two model types interact with each other. The\nfirst class, RL4LLM, includes studies where RL is leveraged to improve the\nperformance of LLMs on tasks related to Natural Language Processing. L4LLM is\ndivided into two sub-categories depending on whether RL is used to directly\nfine-tune an existing LLM or to improve the prompt of the LLM. In the second\nclass, LLM4RL, an LLM assists the training of an RL model that performs a task\nthat is not inherently related to natural language. We further break down\nLLM4RL based on the component of the RL training framework that the LLM assists\nor replaces, namely reward shaping, goal generation, and policy function.\nFinally, in the third class, RL+LLM, an LLM and an RL agent are embedded in a\ncommon planning framework without either of them contributing to training or\nfine-tuning of the other. We further branch this class to distinguish between\nstudies with and without natural language feedback. We use this taxonomy to\nexplore the motivations behind the synergy of LLMs and RL and explain the\nreasons for its success, while pinpointing potential shortcomings and areas\nwhere further research is needed, as well as alternative methodologies that\nserve the same goal.", "published": "2024-02-02 20:01:15", "link": "http://arxiv.org/abs/2402.01874v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "cs.CL"}
{"title": "Natural language guidance of high-fidelity text-to-speech with synthetic\n  annotations", "abstract": "Text-to-speech models trained on large-scale datasets have demonstrated\nimpressive in-context learning capabilities and naturalness. However, control\nof speaker identity and style in these models typically requires conditioning\non reference speech recordings, limiting creative applications. Alternatively,\nnatural language prompting of speaker identity and style has demonstrated\npromising results and provides an intuitive method of control. However,\nreliance on human-labeled descriptions prevents scaling to large datasets. Our\nwork bridges the gap between these two approaches. We propose a scalable method\nfor labeling various aspects of speaker identity, style, and recording\nconditions. We then apply this method to a 45k hour dataset, which we use to\ntrain a speech language model. Furthermore, we propose simple methods for\nincreasing audio fidelity, significantly outperforming recent work despite\nrelying entirely on found data. Our results demonstrate high-fidelity speech\ngeneration in a diverse range of accents, prosodic styles, channel conditions,\nand acoustic conditions, all accomplished with a single model and intuitive\nnatural language conditioning. Audio samples can be heard at\nhttps://text-description-to-speech.com/.", "published": "2024-02-02 21:29:34", "link": "http://arxiv.org/abs/2402.01912v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "CoLe and LYS at BioASQ MESINESP8 Task: similarity based descriptor\n  assignment in Spanish", "abstract": "In this paper, we describe our participation in the MESINESP Task of the\nBioASQ biomedical semantic indexing challenge. The participating system follows\nan approach based solely on conventional information retrieval tools. We have\nevaluated various alternatives for extracting index terms from IBECS/LILACS\ndocuments in order to be stored in an Apache Lucene index. Those indexed\nrepresentations are queried using the contents of the article to be annotated\nand a ranked list of candidate labels is created from the retrieved documents.\nWe also have evaluated a sort of limited Label Powerset approach which creates\nmeta-labels joining pairs of DeCS labels with high co-occurrence scores, and an\nalternative method based on label profile matching. Results obtained in\nofficial runs seem to confirm the suitability of this approach for languages\nlike Spanish.", "published": "2024-02-02 21:36:03", "link": "http://arxiv.org/abs/2402.01916v1", "categories": ["cs.IR", "cs.CL", "cs.LG", "68P20, 68T50", "H.3.3; I.2.7"], "primary_category": "cs.IR"}
{"title": "Preference Poisoning Attacks on Reward Model Learning", "abstract": "Learning reward models from pairwise comparisons is a fundamental component\nin a number of domains, including autonomous control, conversational agents,\nand recommendation systems, as part of a broad goal of aligning automated\ndecisions with user preferences. These approaches entail collecting preference\ninformation from people, with feedback often provided anonymously. Since\npreferences are subjective, there is no gold standard to compare against; yet,\nreliance of high-impact systems on preference learning creates a strong\nmotivation for malicious actors to skew data collected in this fashion to their\nends. We investigate the nature and extent of this vulnerability by considering\nan attacker who can flip a small subset of preference comparisons to either\npromote or demote a target outcome. We propose two classes of algorithmic\napproaches for these attacks: a gradient-based framework, and several variants\nof rank-by-distance methods. Next, we evaluate the efficacy of best attacks in\nboth these classes in successfully achieving malicious goals on datasets from\nthree domains: autonomous control, recommendation system, and textual\nprompt-response preference learning. We find that the best attacks are often\nhighly successful, achieving in the most extreme case 100\\% success rate with\nonly 0.3\\% of the data poisoned. However, \\emph{which} attack is best can vary\nsignificantly across domains. In addition, we observe that the simpler and more\nscalable rank-by-distance approaches are often competitive with, and on\noccasion significantly outperform, gradient-based methods. Finally, we show\nthat state-of-the-art defenses against other classes of poisoning attacks\nexhibit limited efficacy in our setting.", "published": "2024-02-02 21:45:24", "link": "http://arxiv.org/abs/2402.01920v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Digits micro-model for accurate and secure transactions", "abstract": "Automatic Speech Recognition (ASR) systems are used in the financial domain\nto enhance the caller experience by enabling natural language understanding and\nfacilitating efficient and intuitive interactions. Increasing use of ASR\nsystems requires that such systems exhibit very low error rates. The\npredominant ASR models to collect numeric data are large, general-purpose\ncommercial models -- Google Speech-to-text (STT), or Amazon Transcribe -- or\nopen source (OpenAI's Whisper). Such ASR models are trained on hundreds of\nthousands of hours of audio data and require considerable resources to run.\nDespite recent progress large speech recognition models, we highlight the\npotential of smaller, specialized \"micro\" models. Such light models can be\ntrained perform well on number recognition specific tasks, competing with\ngeneral models like Whisper or Google STT while using less than 80 minutes of\ntraining time and occupying at least an order of less memory resources. Also,\nunlike larger speech recognition models, micro-models are trained on carefully\nselected and curated datasets, which makes them highly accurate, agile, and\neasy to retrain, while using low compute resources. We present our work on\ncreating micro models for multi-digit number recognition that handle diverse\nspeaking styles reflecting real-world pronunciation patterns. Our work\ncontributes to domain-specific ASR models, improving digit recognition\naccuracy, and privacy of data. An added advantage, their low resource\nconsumption allows them to be hosted on-premise, keeping private data local\ninstead uploading to an external cloud. Our results indicate that our\nmicro-model makes less errors than the best-of-breed commercial or open-source\nASRs in recognizing digits (1.8% error rate of our best micro-model versus 5.8%\nerror rate of Whisper), and has a low memory footprint (0.66 GB VRAM for our\nmodel versus 11 GB VRAM for Whisper).", "published": "2024-02-02 22:01:27", "link": "http://arxiv.org/abs/2402.01931v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Evaluation of Google's Voice Recognition and Sentence Classification for\n  Health Care Applications", "abstract": "This study examined the use of voice recognition technology in perioperative\nservices (Periop) to enable Periop staff to record workflow milestones using\nmobile technology. The use of mobile technology to improve patient flow and\nquality of care could be facilitated if such voice recognition technology could\nbe made robust. The goal of this experiment was to allow the Periop staff to\nprovide care without being interrupted with data entry and querying tasks.\nHowever, the results are generalizable to other situations where an engineering\nmanager attempts to improve communication performance using mobile technology.\nThis study enhanced Google's voice recognition capability by using\npost-processing classifiers (i.e., bag-of-sentences, support vector machine,\nand maximum entropy). The experiments investigated three factors (original\nphrasing, reduced phrasing, and personalized phrasing) at three levels (zero\ntraining repetition, 5 training repetitions, and 10 training repetitions).\nResults indicated that personal phrasing yielded the highest correctness and\nthat training the device to recognize an individual's voice improved\ncorrectness as well. Although simplistic, the bag-of-sentences classifier\nsignificantly improved voice recognition correctness. The classification\nefficiency of the maximum entropy and support vector machine algorithms was\nfound to be nearly identical. These results suggest that engineering managers\ncould significantly enhance Google's voice recognition technology by using\npost-processing techniques, which would facilitate its use in health care and\nother applications.", "published": "2024-02-02 03:13:09", "link": "http://arxiv.org/abs/2402.03369v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Detection of tortured phrases in scientific literature", "abstract": "This paper presents various automatic detection methods to extract so called\ntortured phrases from scientific papers. These tortured phrases, e.g. flag to\nclamor instead of signal to noise, are the results of paraphrasing tools used\nto escape plagiarism detection. We built a dataset and evaluated several\nstrategies to flag previously undocumented tortured phrases. The proposed and\ntested methods are based on language models and either on embeddings\nsimilarities or on predictions of masked token. We found that an approach using\ntoken prediction and that propagates the scores to the chunk level gives the\nbest results. With a recall value of .87 and a precision value of .61, it could\nretrieve new tortured phrases to be submitted to domain experts for validation.", "published": "2024-02-02 08:15:43", "link": "http://arxiv.org/abs/2402.03370v1", "categories": ["cs.IR", "cs.AI", "cs.CL", "cs.DL"], "primary_category": "cs.IR"}
{"title": "Rethinking the Role of Proxy Rewards in Language Model Alignment", "abstract": "Learning from human feedback via proxy reward modeling has been studied to\nalign Large Language Models (LLMs) with human values. However, achieving\nreliable training through that proxy reward model (RM) is not a trivial\nproblem, and its behavior remained as a black-box. In this paper, we study the\nrole of proxy rewards in the LLM alignment via `reverse reward engineering' by\ncomposing interpretable features as a white-box reward function. We aim to\nreplicate the ground truth (gold) reward signal by achieving a monotonic\nrelationship between the proxy and gold reward signals after training the model\nusing the proxy reward in reinforcement learning (RL). Our findings indicate\nthat successfully emulating the gold reward requires generating responses that\nare relevant with enough length to open-ended questions, while also ensuring\nresponse consistency in closed-ended questions. Furthermore, resulting models\noptimizing our devised white-box reward show competitive performances with\nstrong open-source RMs in alignment benchmarks. We highlight its potential\nusage as a simple but strong reward baseline for the LLM alignment, not\nrequiring explicit human feedback dataset and RM training. Our code is\navailable at https://github.com/naver-ai/rethinking-proxy-reward.", "published": "2024-02-02 11:58:08", "link": "http://arxiv.org/abs/2402.03469v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "An Intra-BRNN and GB-RVQ Based END-TO-END Neural Audio Codec", "abstract": "Recently, neural networks have proven to be effective in performing speech\ncoding task at low bitrates. However, under-utilization of intra-frame\ncorrelations and the error of quantizer specifically degrade the reconstructed\naudio quality. To improve the coding quality, we present an end-to-end neural\nspeech codec, namely CBRC (Convolutional and Bidirectional Recurrent neural\nCodec). An interleaved structure using 1D-CNN and Intra-BRNN is designed to\nexploit the intra-frame correlations more efficiently. Furthermore, Group-wise\nand Beam-search Residual Vector Quantizer (GB-RVQ) is used to reduce the\nquantization noise. CBRC encodes audio every 20ms with no additional latency,\nwhich is suitable for real-time communication. Experimental results demonstrate\nthe superiority of the proposed codec when comparing CBRC at 3kbps with Opus at\n12kbps.", "published": "2024-02-02 09:55:15", "link": "http://arxiv.org/abs/2402.01271v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Del Visual al Auditivo: Sonorizaci\u00f3n de Escenas Guiada por Imagen", "abstract": "Recent advances in image, video, text and audio generative techniques, and\ntheir use by the general public, are leading to new forms of content\ngeneration. Usually, each modality was approached separately, which poses\nlimitations. The automatic sound recording of visual sequences is one of the\ngreatest challenges for the automatic generation of multimodal content. We\npresent a processing flow that, starting from images extracted from videos, is\nable to sound them. We work with pre-trained models that employ complex\nencoders, contrastive learning, and multiple modalities, allowing complex\nrepresentations of the sequences for their sonorization. The proposed scheme\nproposes different possibilities for audio mapping and text guidance. We\nevaluated the scheme on a dataset of frames extracted from a commercial video\ngame and sounds extracted from the Freesound platform. Subjective tests have\nevidenced that the proposed scheme is able to generate and assign audios\nautomatically and conveniently to images. Moreover, it adapts well to user\npreferences, and the proposed objective metrics show a high correlation with\nthe subjective ratings.", "published": "2024-02-02 13:09:49", "link": "http://arxiv.org/abs/2402.01385v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "KS-Net: Multi-band joint speech restoration and enhancement network for\n  2024 ICASSP SSI Challenge", "abstract": "This paper presents the speech restoration and enhancement system created by\nthe 1024K team for the ICASSP 2024 Speech Signal Improvement (SSI) Challenge.\nOur system consists of a generative adversarial network (GAN) in complex-domain\nfor speech restoration and a fine-grained multi-band fusion module for speech\nenhancement. In the blind test set of SSI, the proposed system achieves an\noverall mean opinion score (MOS) of 3.49 based on ITU-T P.804 and a Word\nAccuracy Rate (WAcc) of 0.78 for the real-time track, as well as an overall\nP.804 MOS of 3.43 and a WAcc of 0.78 for the non-real-time track, ranking 1st\nin both tracks.", "published": "2024-02-02 11:28:18", "link": "http://arxiv.org/abs/2402.01808v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ToMoBrush: Exploring Dental Health Sensing using a Sonic Toothbrush", "abstract": "Early detection of dental disease is crucial to prevent adverse outcomes.\nToday, dental X-rays are currently the most accurate gold standard for dental\ndisease detection. Unfortunately, regular X-ray exam is still a privilege for\nbillions of people around the world. In this paper, we ask: \"Can we develop a\nlow-cost sensing system that enables dental self-examination in the comfort of\none's home?\"\n  This paper presents ToMoBrush, a dental health sensing system that explores\nusing off-the-shelf sonic toothbrushes for dental condition detection. Our\nsolution leverages the fact that a sonic toothbrush produces rich acoustic\nsignals when in contact with teeth, which contain important information about\neach tooth's status. ToMoBrush extracts tooth resonance signatures from the\nacoustic signals to characterize varied dental health conditions of the teeth.\nWe evaluate ToMoBrush on 19 participants and dental-standard models for\ndetecting common dental problems including caries, calculus, and food\nimpaction, achieving a detection ROC-AUC of 0.90, 0.83, and 0.88 respectively.\nInterviews with dental experts validate ToMoBrush's potential in enhancing\nat-home dental healthcare.", "published": "2024-02-02 22:05:57", "link": "http://arxiv.org/abs/2402.01933v1", "categories": ["eess.AS", "cs.SD", "J.3; C.3; H.5.2"], "primary_category": "eess.AS"}
{"title": "STAA-Net: A Sparse and Transferable Adversarial Attack for Speech\n  Emotion Recognition", "abstract": "Speech contains rich information on the emotions of humans, and Speech\nEmotion Recognition (SER) has been an important topic in the area of\nhuman-computer interaction. The robustness of SER models is crucial,\nparticularly in privacy-sensitive and reliability-demanding domains like\nprivate healthcare. Recently, the vulnerability of deep neural networks in the\naudio domain to adversarial attacks has become a popular area of research.\nHowever, prior works on adversarial attacks in the audio domain primarily rely\non iterative gradient-based techniques, which are time-consuming and prone to\noverfitting the specific threat model. Furthermore, the exploration of sparse\nperturbations, which have the potential for better stealthiness, remains\nlimited in the audio domain. To address these challenges, we propose a\ngenerator-based attack method to generate sparse and transferable adversarial\nexamples to deceive SER models in an end-to-end and efficient manner. We\nevaluate our method on two widely-used SER datasets, Database of Elicited Mood\nin Speech (DEMoS) and Interactive Emotional dyadic MOtion CAPture (IEMOCAP),\nand demonstrate its ability to generate successful sparse adversarial examples\nin an efficient manner. Moreover, our generated adversarial examples exhibit\nmodel-agnostic transferability, enabling effective adversarial attacks on\nadvanced victim models.", "published": "2024-02-02 08:46:57", "link": "http://arxiv.org/abs/2402.01227v1", "categories": ["cs.SD", "cs.AI", "cs.HC", "eess.AS"], "primary_category": "cs.SD"}
{"title": "On the Transferability of Large-Scale Self-Supervision to Few-Shot Audio\n  Classification", "abstract": "In recent years, self-supervised learning has excelled for its capacity to\nlearn robust feature representations from unlabelled data. Networks pretrained\nthrough self-supervision serve as effective feature extractors for downstream\ntasks, including Few-Shot Learning. While the evaluation of unsupervised\napproaches for few-shot learning is well-established in imagery, it is notably\nabsent in acoustics. This study addresses this gap by assessing large-scale\nself-supervised models' performance in few-shot audio classification.\nAdditionally, we explore the relationship between a model's few-shot learning\ncapability and other downstream task benchmarks. Our findings reveal\nstate-of-the-art performance in some few-shot problems such as\nSpeechCommandsv2, as well as strong correlations between speech-based few-shot\nproblems and various downstream audio tasks.", "published": "2024-02-02 10:00:51", "link": "http://arxiv.org/abs/2402.01274v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning Semantic Information from Raw Audio Signal Using Both\n  Contextual and Phonetic Representations", "abstract": "We propose a framework to learn semantics from raw audio signals using two\ntypes of representations, encoding contextual and phonetic information\nrespectively. Specifically, we introduce a speech-to-unit processing pipeline\nthat captures two types of representations with different time resolutions. For\nthe language model, we adopt a dual-channel architecture to incorporate both\ntypes of representation. We also present new training objectives, masked\ncontext reconstruction and masked context prediction, that push models to learn\nsemantics effectively. Experiments on the sSIMI metric of Zero Resource Speech\nBenchmark 2021 and Fluent Speech Command dataset show our framework learns\nsemantics better than models trained with only one type of representation.", "published": "2024-02-02 10:39:58", "link": "http://arxiv.org/abs/2402.01298v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Bass Accompaniment Generation via Latent Diffusion", "abstract": "The ability to automatically generate music that appropriately matches an\narbitrary input track is a challenging task. We present a novel controllable\nsystem for generating single stems to accompany musical mixes of arbitrary\nlength. At the core of our method are audio autoencoders that efficiently\ncompress audio waveform samples into invertible latent representations, and a\nconditional latent diffusion model that takes as input the latent encoding of a\nmix and generates the latent encoding of a corresponding stem. To provide\ncontrol over the timbre of generated samples, we introduce a technique to\nground the latent space to a user-provided reference style during diffusion\nsampling. For further improving audio quality, we adapt classifier-free\nguidance to avoid distortions at high guidance strengths when generating an\nunbounded latent space. We train our model on a dataset of pairs of mixes and\nmatching bass stems. Quantitative experiments demonstrate that, given an input\nmix, the proposed system can generate basslines with user-specified timbres.\nOur controllable conditional audio generation framework represents a\nsignificant step forward in creating generative AI tools to assist musicians in\nmusic production.", "published": "2024-02-02 13:44:47", "link": "http://arxiv.org/abs/2402.01412v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Objective and subjective evaluation of speech enhancement methods in the\n  UDASE task of the 7th CHiME challenge", "abstract": "Supervised models for speech enhancement are trained using artificially\ngenerated mixtures of clean speech and noise signals. However, the synthetic\ntraining conditions may not accurately reflect real-world conditions\nencountered during testing. This discrepancy can result in poor performance\nwhen the test domain significantly differs from the synthetic training domain.\nTo tackle this issue, the UDASE task of the 7th CHiME challenge aimed to\nleverage real-world noisy speech recordings from the test domain for\nunsupervised domain adaptation of speech enhancement models. Specifically, this\ntest domain corresponds to the CHiME-5 dataset, characterized by real\nmulti-speaker and conversational speech recordings made in noisy and\nreverberant domestic environments, for which ground-truth clean speech signals\nare not available. In this paper, we present the objective and subjective\nevaluations of the systems that were submitted to the CHiME-7 UDASE task, and\nwe provide an analysis of the results. This analysis reveals a limited\ncorrelation between subjective ratings and several supervised nonintrusive\nperformance metrics recently proposed for speech enhancement. Conversely, the\nresults suggest that more traditional intrusive objective metrics can be used\nfor in-domain performance evaluation using the reverberant LibriCHiME-5 dataset\ndeveloped for the challenge. The subjective evaluation indicates that all\nsystems successfully reduced the background noise, but always at the expense of\nincreased distortion. Out of the four speech enhancement methods evaluated\nsubjectively, only one demonstrated an improvement in overall quality compared\nto the unprocessed noisy speech, highlighting the difficulty of the task. The\ntools and audio material created for the CHiME-7 UDASE task are shared with the\ncommunity.", "published": "2024-02-02 13:45:42", "link": "http://arxiv.org/abs/2402.01413v2", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Data-Driven Analysis of Robust Automatic Piano Transcription", "abstract": "Algorithms for automatic piano transcription have improved dramatically in\nrecent years due to new datasets and modeling techniques. Recent developments\nhave focused primarily on adapting new neural network architectures, such as\nthe Transformer and Perceiver, in order to yield more accurate systems. In this\nwork, we study transcription systems from the perspective of their training\ndata. By measuring their performance on out-of-distribution annotated piano\ndata, we show how these models can severely overfit to acoustic properties of\nthe training data. We create a new set of audio for the MAESTRO dataset,\ncaptured automatically in a professional studio recording environment via\nYamaha Disklavier playback. Using various data augmentation techniques when\ntraining with the original and re-performed versions of the MAESTRO dataset, we\nachieve state-of-the-art note-onset accuracy of 88.4 F1-score on the MAPS\ndataset, without seeing any of its training data. We subsequently analyze these\ndata augmentation techniques in a series of ablation studies to better\nunderstand their influence on the resulting models.", "published": "2024-02-02 14:11:23", "link": "http://arxiv.org/abs/2402.01424v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Low-Resource Cross-Domain Singing Voice Synthesis via Reduced\n  Self-Supervised Speech Representations", "abstract": "In this paper, we propose a singing voice synthesis model, Karaoker-SSL, that\nis trained only on text and speech data as a typical multi-speaker acoustic\nmodel. It is a low-resource pipeline that does not utilize any singing data\nend-to-end, since its vocoder is also trained on speech data. Karaoker-SSL is\nconditioned by self-supervised speech representations in an unsupervised\nmanner. We preprocess these representations by selecting only a subset of their\ntask-correlated dimensions. The conditioning module is indirectly guided to\ncapture style information during training by multi-tasking. This is achieved\nwith a Conformer-based module, which predicts the pitch from the acoustic\nmodel's output. Thus, Karaoker-SSL allows singing voice synthesis without\nreliance on hand-crafted and domain-specific features. There are also no\nrequirements for text alignments or lyrics timestamps. To refine the voice\nquality, we employ a U-Net discriminator that is conditioned on the target\nspeaker and follows a Diffusion GAN training scheme.", "published": "2024-02-02 16:06:24", "link": "http://arxiv.org/abs/2402.01520v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Spiking Music: Audio Compression with Event Based Auto-encoders", "abstract": "Neurons in the brain communicate information via punctual events called\nspikes. The timing of spikes is thought to carry rich information, but it is\nnot clear how to leverage this in digital systems. We demonstrate that\nevent-based encoding is efficient for audio compression. To build this\nevent-based representation we use a deep binary auto-encoder, and under high\nsparsity pressure, the model enters a regime where the binary event matrix is\nstored more efficiently with sparse matrix storage algorithms. We test this on\nthe large MAESTRO dataset of piano recordings against vector quantized\nauto-encoders. Not only does our \"Spiking Music compression\" algorithm achieve\na competitive compression/reconstruction trade-off, but selectivity and\nsynchrony between encoded events and piano key strikes emerge without\nsupervision in the sparse regime.", "published": "2024-02-02 17:07:39", "link": "http://arxiv.org/abs/2402.01571v1", "categories": ["cs.SD", "cs.LG", "cs.NE", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Identification of Cognitive Decline from Spoken Language through Feature\n  Selection and the Bag of Acoustic Words Model", "abstract": "Memory disorders are a central factor in the decline of functioning and daily\nactivities in elderly individuals. The confirmation of the illness, initiation\nof medication to slow its progression, and the commencement of occupational\ntherapy aimed at maintaining and rehabilitating cognitive abilities require a\nmedical diagnosis. The early identification of symptoms of memory disorders,\nespecially the decline in cognitive abilities, plays a significant role in\nensuring the well-being of populations. Features related to speech production\nare known to connect with the speaker's cognitive ability and changes. The lack\nof standardized speech tests in clinical settings has led to a growing emphasis\non developing automatic machine learning techniques for analyzing naturally\nspoken language. Non-lexical but acoustic properties of spoken language have\nproven useful when fast, cost-effective, and scalable solutions are needed for\nthe rapid diagnosis of a disease. The work presents an approach related to\nfeature selection, allowing for the automatic selection of the essential\nfeatures required for diagnosis from the Geneva minimalistic acoustic parameter\nset and relative speech pauses, intended for automatic paralinguistic and\nclinical speech analysis. These features are refined into word histogram\nfeatures, in which machine learning classifiers are trained to classify control\nsubjects and dementia patients from the Dementia Bank's Pitt audio database.\nThe results show that achieving a 75% average classification accuracy with only\ntwenty-five features with the separate ADReSS 2020 competition test data and\nthe Leave-One-Subject-Out cross-validation of the entire competition data is\npossible. The results rank at the top compared to international research, where\nthe same dataset and only acoustic features have been used to diagnose\npatients.", "published": "2024-02-02 17:06:03", "link": "http://arxiv.org/abs/2402.01824v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and\n  Dialogue Abilities", "abstract": "Augmenting large language models (LLMs) to understand audio -- including\nnon-speech sounds and non-verbal speech -- is critically important for diverse\nreal-world applications of LLMs. In this paper, we propose Audio Flamingo, a\nnovel audio language model with 1) strong audio understanding abilities, 2) the\nability to quickly adapt to unseen tasks via in-context learning and retrieval,\nand 3) strong multi-turn dialogue abilities. We introduce a series of training\ntechniques, architecture design, and data strategies to enhance our model with\nthese abilities. Extensive evaluations across various audio understanding tasks\nconfirm the efficacy of our method, setting new state-of-the-art benchmarks.\nOur demo website is https://audioflamingo.github.io/ and the code is\nopen-sourced at https://github.com/NVIDIA/audio-flamingo.", "published": "2024-02-02 18:58:34", "link": "http://arxiv.org/abs/2402.01831v3", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
