{"title": "Semantic Journeys: Quantifying Change in Emoji Meaning from 2012-2018", "abstract": "The semantics of emoji has, to date, been considered from a static\nperspective. We offer the first longitudinal study of how emoji semantics\nchanges over time, applying techniques from computational linguistics to six\nyears of Twitter data. We identify five patterns in emoji semantic development\nand find evidence that the less abstract an emoji is, the more likely it is to\nundergo semantic change. In addition, we analyse select emoji in more detail,\nexamining the effect of seasonality and world events on emoji semantics. To aid\nfuture work on emoji and semantics, we make our data publicly available along\nwith a web-based interface that anyone can use to explore semantic change in\nemoji.", "published": "2021-05-03 13:35:10", "link": "http://arxiv.org/abs/2105.00846v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Teaching NLP outside Linguistics and Computer Science classrooms: Some\n  challenges and some opportunities", "abstract": "NLP's sphere of influence went much beyond computer science research and the\ndevelopment of software applications in the past decade. We see people using\nNLP methods in a range of academic disciplines from Asian Studies to Clinical\nOncology. We also notice the presence of NLP as a module in most of the data\nscience curricula within and outside of regular university setups. These\ncourses are taken by students from very diverse backgrounds. This paper takes a\ncloser look at some issues related to teaching NLP to these diverse audiences\nbased on my classroom experiences, and identifies some challenges the\ninstructors face, particularly when there is no ecosystem of related courses\nfor the students. In this process, it also identifies a few challenge areas for\nboth NLP researchers and tool developers.", "published": "2021-05-03 14:30:32", "link": "http://arxiv.org/abs/2105.00895v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pseudo Siamese Network for Few-shot Intent Generation", "abstract": "Few-shot intent detection is a challenging task due to the scare annotation\nproblem. In this paper, we propose a Pseudo Siamese Network (PSN) to generate\nlabeled data for few-shot intents and alleviate this problem. PSN consists of\ntwo identical subnetworks with the same structure but different weights: an\naction network and an object network. Each subnetwork is a transformer-based\nvariational autoencoder that tries to model the latent distribution of\ndifferent components in the sentence. The action network is learned to\nunderstand action tokens and the object network focuses on object-related\nexpressions. It provides an interpretable framework for generating an utterance\nwith an action and an object existing in a given intent. Experiments on two\nreal-world datasets show that PSN achieves state-of-the-art performance for the\ngeneralized few shot intent detection task.", "published": "2021-05-03 14:30:47", "link": "http://arxiv.org/abs/2105.00896v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Impact of Gender Debiased Word Embeddings in Language Modeling", "abstract": "Gender, race and social biases have recently been detected as evident\nexamples of unfairness in applications of Natural Language Processing. A key\npath towards fairness is to understand, analyse and interpret our data and\nalgorithms. Recent studies have shown that the human-generated data used in\ntraining is an apparent factor of getting biases. In addition, current\nalgorithms have also been proven to amplify biases from data.\n  To further address these concerns, in this paper, we study how an\nstate-of-the-art recurrent neural language model behaves when trained on data,\nwhich under-represents females, using pre-trained standard and debiased word\nembeddings. Results show that language models inherit higher bias when trained\non unbalanced data when using pre-trained embeddings, in comparison with using\nembeddings trained within the task. Moreover, results show that, on the same\ndata, language models inherit lower bias when using debiased pre-trained\nemdeddings, compared to using standard pre-trained embeddings.", "published": "2021-05-03 14:45:10", "link": "http://arxiv.org/abs/2105.00908v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Trends, Limitations and Open Challenges in Automatic Readability\n  Assessment Research", "abstract": "Readability assessment is the task of evaluating the reading difficulty of a\ngiven piece of text. Although research on computational approaches to\nreadability assessment is now two decades old, there is not much work on\nsynthesizing this research. This article is a brief survey of contemporary\nresearch on developing computational models for readability assessment. We\nidentify the common approaches, discuss their shortcomings, and identify some\nchallenges for the future. Where possible, we also connect computational\nresearch with insights from related work in other disciplines such as education\nand psychology.", "published": "2021-05-03 16:18:42", "link": "http://arxiv.org/abs/2105.00973v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Russian News Clustering and Headline Selection Shared Task", "abstract": "This paper presents the results of the Russian News Clustering and Headline\nSelection shared task. As a part of it, we propose the tasks of Russian news\nevent detection, headline selection, and headline generation. These tasks are\naccompanied by datasets and baselines. The presented datasets for event\ndetection and headline selection are the first public Russian datasets for\ntheir tasks. The headline generation dataset is based on clustering and\nprovides multiple reference headlines for every cluster, unlike the previous\ndatasets. Finally, the approaches proposed by the shared task participants are\nreported and analyzed.", "published": "2021-05-03 16:32:33", "link": "http://arxiv.org/abs/2105.00981v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Deep Representations of Radiology Reports in Survival\n  Analysis for Predicting Heart Failure Patient Mortality", "abstract": "Utilizing clinical texts in survival analysis is difficult because they are\nlargely unstructured. Current automatic extraction models fail to capture\ntextual information comprehensively since their labels are limited in scope.\nFurthermore, they typically require a large amount of data and high-quality\nexpert annotations for training. In this work, we present a novel method of\nusing BERT-based hidden layer representations of clinical texts as covariates\nfor proportional hazards models to predict patient survival outcomes. We show\nthat hidden layers yield notably more accurate predictions than predefined\nfeatures, outperforming the previous baseline model by 5.7% on average across\nC-index and time-dependent AUC. We make our work publicly available at\nhttps://github.com/bionlplab/heart_failure_mortality.", "published": "2021-05-03 16:54:52", "link": "http://arxiv.org/abs/2105.01009v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Applied Language Technology: NLP for the Humanities", "abstract": "This contribution describes a two-course module that seeks to provide\nhumanities majors with a basic understanding of language technology and its\napplications using Python. The learning materials consist of interactive\nJupyter Notebooks and accompanying YouTube videos, which are openly available\nwith a Creative Commons licence.", "published": "2021-05-03 17:51:17", "link": "http://arxiv.org/abs/2105.01052v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scalar Adjective Identification and Multilingual Ranking", "abstract": "The intensity relationship that holds between scalar adjectives (e.g., nice <\ngreat < wonderful) is highly relevant for natural language inference and\ncommon-sense reasoning. Previous research on scalar adjective ranking has\nfocused on English, mainly due to the availability of datasets for evaluation.\nWe introduce a new multilingual dataset in order to promote research on scalar\nadjectives in new languages. We perform a series of experiments and set\nperformance baselines on this dataset, using monolingual and multilingual\ncontextual language models. Additionally, we introduce a new binary\nclassification task for English scalar adjective identification which examines\nthe models' ability to distinguish scalar from relational adjectives. We probe\ncontextualised representations and report baseline results for future\ncomparison on this task.", "published": "2021-05-03 21:32:41", "link": "http://arxiv.org/abs/2105.01180v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unreasonable Effectiveness of Rule-Based Heuristics in Solving Russian\n  SuperGLUE Tasks", "abstract": "Leader-boards like SuperGLUE are seen as important incentives for active\ndevelopment of NLP, since they provide standard benchmarks for fair comparison\nof modern language models. They have driven the world's best engineering teams\nas well as their resources to collaborate and solve a set of tasks for general\nlanguage understanding. Their performance scores are often claimed to be close\nto or even higher than the human performance. These results encouraged more\nthorough analysis of whether the benchmark datasets featured any statistical\ncues that machine learning based language models can exploit. For English\ndatasets, it was shown that they often contain annotation artifacts. This\nallows solving certain tasks with very simple rules and achieving competitive\nrankings.\n  In this paper, a similar analysis was done for the Russian SuperGLUE (RSG), a\nrecently published benchmark set and leader-board for Russian natural language\nunderstanding. We show that its test datasets are vulnerable to shallow\nheuristics. Often approaches based on simple rules outperform or come close to\nthe results of the notorious pre-trained language models like GPT-3 or BERT. It\nis likely (as the simplest explanation) that a significant part of the SOTA\nmodels performance in the RSG leader-board is due to exploiting these shallow\nheuristics and that has nothing in common with real language understanding. We\nprovide a set of recommendations on how to improve these datasets, making the\nRSG leader-board even more representative of the real progress in Russian NLU.", "published": "2021-05-03 22:19:22", "link": "http://arxiv.org/abs/2105.01192v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Goldilocks: Just-Right Tuning of BERT for Technology-Assisted Review", "abstract": "Technology-assisted review (TAR) refers to iterative active learning\nworkflows for document review in high recall retrieval (HRR) tasks. TAR\nresearch and most commercial TAR software have applied linear models such as\nlogistic regression to lexical features. Transformer-based models with\nsupervised tuning are known to improve effectiveness on many text\nclassification tasks, suggesting their use in TAR. We indeed find that the\npre-trained BERT model reduces review cost by 10% to 15% in TAR workflows\nsimulated on the RCV1-v2 newswire collection. In contrast, we likewise\ndetermined that linear models outperform BERT for simulated legal discovery\ntopics on the Jeb Bush e-mail collection. This suggests the match between\ntransformer pre-training corpora and the task domain is of greater significance\nthan generally appreciated. Additionally, we show that just-right language\nmodel fine-tuning on the task collection before starting active learning is\ncritical. Too little or too much fine-tuning hinders performance, worse than\nthat of linear models, even for a favorable corpus such as RCV1-v2.", "published": "2021-05-03 17:41:18", "link": "http://arxiv.org/abs/2105.01044v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Modeling Social Readers: Novel Tools for Addressing Reception from\n  Online Book Reviews", "abstract": "Readers' responses to literature have received scant attention in\ncomputational literary studies. The rise of social media offers an opportunity\nto capture a segment of these responses while data-driven analysis of these\nresponses can provide new critical insight into how people \"read\". Posts\ndiscussing an individual book on Goodreads, a social media platform that hosts\nuser discussions of popular literature, are referred to as \"reviews\", and\nconsist of plot summaries, opinions, quotes, or some mixture of these. Since\nthese reviews are written by readers, computationally modeling them allows one\nto discover the overall non-professional discussion space about a work,\nincluding an aggregated summary of the work's plot, an implicit ranking of the\nimportance of events, and the readers' impressions of main characters. We\ndevelop a pipeline of interlocking computational tools to extract a\nrepresentation of this reader generated shared narrative model. Using a corpus\nof reviews of five popular novels, we discover the readers' distillation of the\nmain storylines in a novel, their understanding of the relative importance of\ncharacters, as well as the readers' varying impressions of these characters. In\nso doing, we make three important contributions to the study of infinite\nvocabulary networks: (i) an automatically derived narrative network that\nincludes meta-actants; (ii) a new sequencing algorithm, REV2SEQ, that generates\na consensus sequence of events based on partial trajectories aggregated from\nthe reviews; and (iii) a new \"impressions\" algorithm, SENT2IMP, that provides\nfiner, non-trivial and multi-modal insight into readers' opinions of\ncharacters.", "published": "2021-05-03 20:10:14", "link": "http://arxiv.org/abs/2105.01150v2", "categories": ["cs.CL", "stat.AP"], "primary_category": "cs.CL"}
{"title": "Textual Analysis of Communications in COVID-19 Infected Community on\n  Social Media", "abstract": "During the COVID-19 pandemic, people started to discuss about\npandemic-related topics on social media. On subreddit\n\\textit{r/COVID19positive}, a number of topics are discussed or being shared,\nincluding experience of those who got a positive test result, stories of those\nwho presumably got infected, and questions asked regarding the pandemic and the\ndisease. In this study, we try to understand, from a linguistic perspective,\nthe nature of discussions on the subreddit. We found differences in linguistic\ncharacteristics (e.g. psychological, emotional and reasoning) across three\ndifferent categories of topics. We also classified posts into the different\ncategories using SOTA pre-trained language models. Such classification model\ncan be used for pandemic-related research on social media.", "published": "2021-05-03 22:09:35", "link": "http://arxiv.org/abs/2105.01189v1", "categories": ["cs.SI", "cs.CL"], "primary_category": "cs.SI"}
{"title": "Looking for COVID-19 misinformation in multilingual social media texts", "abstract": "This paper presents the Multilingual COVID-19 Analysis Method (CMTA) for\ndetecting and observing the spread of misinformation about this disease within\ntexts. CMTA proposes a data science (DS) pipeline that applies machine learning\nmodels for processing, classifying (Dense-CNN) and analyzing (MBERT)\nmultilingual (micro)-texts. DS pipeline data preparation tasks extract features\nfrom multilingual textual data and categorize it into specific information\nclasses (i.e., 'false', 'partly false', 'misleading'). The CMTA pipeline has\nbeen experimented with multilingual micro-texts (tweets), showing\nmisinformation spread across different languages. To assess the performance of\nCMTA and put it in perspective, we performed a comparative analysis of CMTA\nwith eight monolingual models used for detecting misinformation. The comparison\nshows that CMTA has surpassed various monolingual models and suggests that it\ncan be used as a general method for detecting misinformation in multilingual\nmicro-texts. CMTA experimental results show misinformation trends about\nCOVID-19 in different languages during the first pandemic months.", "published": "2021-05-03 14:30:49", "link": "http://arxiv.org/abs/2105.03313v1", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "The Online Pivot: Lessons Learned from Teaching a Text and Data Mining\n  Course in Lockdown, Enhancing online Teaching with Pair Programming and\n  Digital Badges", "abstract": "In this paper we provide an account of how we ported a text and data mining\ncourse online in summer 2020 as a result of the COVID-19 pandemic and how we\nimproved it in a second pilot run. We describe the course, how we adapted it\nover the two pilot runs and what teaching techniques we used to improve\nstudents' learning and community building online. We also provide information\non the relentless feedback collected during the course which helped us to adapt\nour teaching from one session to the next and one pilot to the next. We discuss\nthe lessons learned and promote the use of innovative teaching techniques\napplied to the digital such as digital badges and pair programming in break-out\nrooms for teaching Natural Language Processing courses to beginners and\nstudents with different backgrounds.", "published": "2021-05-03 09:38:26", "link": "http://arxiv.org/abs/2105.07847v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Switching Contexts: Transportability Measures for NLP", "abstract": "This paper explores the topic of transportability, as a sub-area of\ngeneralisability. By proposing the utilisation of metrics based on\nwell-established statistics, we are able to estimate the change in performance\nof NLP models in new contexts. Defining a new measure for transportability may\nallow for better estimation of NLP system performance in new domains, and is\ncrucial when assessing the performance of NLP systems in new tasks and domains.\nThrough several instances of increasing complexity, we demonstrate how\nlightweight domain similarity measures can be used as estimators for the\ntransportability in NLP applications. The proposed transportability measures\nare evaluated in the context of Named Entity Recognition and Natural Language\nInference tasks.", "published": "2021-05-03 13:15:24", "link": "http://arxiv.org/abs/2105.00823v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Explaining Outcomes of Multi-Party Dialogues using Causal Learning", "abstract": "Multi-party dialogues are common in enterprise social media on technical as\nwell as non-technical topics. The outcome of a conversation may be positive or\nnegative. It is important to analyze why a dialogue ends with a particular\nsentiment from the point of view of conflict analysis as well as future\ncollaboration design. We propose an explainable time series mining algorithm\nfor such analysis. A dialogue is represented as an attributed time series of\noccurrences of keywords, EMPATH categories, and inferred sentiments at various\npoints in its progress. A special decision tree, with decision metrics that\ntake into account temporal relationships between dialogue events, is used for\npredicting the cause of the outcome sentiment. Interpretable rules mined from\nthe classifier are used to explain the prediction. Experimental results are\npresented for the enterprise social media posts in a large company.", "published": "2021-05-03 15:18:53", "link": "http://arxiv.org/abs/2105.00944v1", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "On the limit of English conversational speech recognition", "abstract": "In our previous work we demonstrated that a single headed attention\nencoder-decoder model is able to reach state-of-the-art results in\nconversational speech recognition. In this paper, we further improve the\nresults for both Switchboard 300 and 2000. Through use of an improved\noptimizer, speaker vector embeddings, and alternative speech representations we\nreduce the recognition errors of our LSTM system on Switchboard-300 by 4%\nrelative. Compensation of the decoder model with the probability ratio approach\nallows more efficient integration of an external language model, and we report\n5.9% and 11.5% WER on the SWB and CHM parts of Hub5'00 with very simple LSTM\nmodels. Our study also considers the recently proposed conformer, and more\nadvanced self-attention based language models. Overall, the conformer shows\nsimilar performance to the LSTM; nevertheless, their combination and decoding\nwith an improved LM reaches a new record on Switchboard-300, 5.0% and 10.0% WER\non SWB and CHM. Our findings are also confirmed on Switchboard-2000, and a new\nstate of the art is reported, practically reaching the limit of the benchmark.", "published": "2021-05-03 16:32:38", "link": "http://arxiv.org/abs/2105.00982v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Context-aware Ensemble of Multifaceted Factorization Models for\n  Recommendation Prediction in Social Networks", "abstract": "This paper describes the solution of Shanda Innovations team to Task 1 of\nKDD-Cup 2012. A novel approach called Multifaceted Factorization Models is\nproposed to incorporate a great variety of features in social networks. Social\nrelationships and actions between users are integrated as implicit feedbacks to\nimprove the recommendation accuracy. Keywords, tags, profiles, time and some\nother features are also utilized for modeling user interests. In addition, user\nbehaviors are modeled from the durations of recommendation records. A\ncontext-aware ensemble framework is then applied to combine multiple predictors\nand produce final recommendation results. The proposed approach obtained\n0.43959 (public score) / 0.41874 (private score) on the testing dataset, which\nachieved the 2nd place in the KDD-Cup competition.", "published": "2021-05-03 16:42:50", "link": "http://arxiv.org/abs/2105.00991v1", "categories": ["cs.IR", "cs.CL", "stat.CO"], "primary_category": "cs.IR"}
{"title": "SUPERB: Speech processing Universal PERformance Benchmark", "abstract": "Self-supervised learning (SSL) has proven vital for advancing research in\nnatural language processing (NLP) and computer vision (CV). The paradigm\npretrains a shared model on large volumes of unlabeled data and achieves\nstate-of-the-art (SOTA) for various tasks with minimal adaptation. However, the\nspeech processing community lacks a similar setup to systematically explore the\nparadigm. To bridge this gap, we introduce Speech processing Universal\nPERformance Benchmark (SUPERB). SUPERB is a leaderboard to benchmark the\nperformance of a shared model across a wide range of speech processing tasks\nwith minimal architecture changes and labeled data. Among multiple usages of\nthe shared model, we especially focus on extracting the representation learned\nfrom SSL due to its preferable re-usability. We present a simple framework to\nsolve SUPERB tasks by learning task-specialized lightweight prediction heads on\ntop of the frozen shared model. Our results demonstrate that the framework is\npromising as SSL representations show competitive generalizability and\naccessibility across SUPERB tasks. We release SUPERB as a challenge with a\nleaderboard and a benchmark toolkit to fuel the research in representation\nlearning and general speech processing.", "published": "2021-05-03 17:51:09", "link": "http://arxiv.org/abs/2105.01051v4", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards A Multi-agent System for Online Hate Speech Detection", "abstract": "This paper envisions a multi-agent system for detecting the presence of hate\nspeech in online social media platforms such as Twitter and Facebook. We\nintroduce a novel framework employing deep learning techniques to coordinate\nthe channels of textual and im-age processing. Our experimental results aim to\ndemonstrate the effectiveness of our methods for classifying online content,\ntraining the proposed neural network model to effectively detect hateful\ninstances in the input. We conclude with a discussion of how our system may be\nof use to provide recommendations to users who are managing online social\nnetworks, showcasing the immense potential of intelligent multi-agent systems\ntowards delivering social good.", "published": "2021-05-03 19:06:42", "link": "http://arxiv.org/abs/2105.01129v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.MA"], "primary_category": "cs.AI"}
{"title": "Initialization and Regularization of Factorized Neural Layers", "abstract": "Factorized layers--operations parameterized by products of two or more\nmatrices--occur in a variety of deep learning contexts, including compressed\nmodel training, certain types of knowledge distillation, and multi-head\nself-attention architectures. We study how to initialize and regularize deep\nnets containing such layers, examining two simple, understudied schemes,\nspectral initialization and Frobenius decay, for improving their performance.\nThe guiding insight is to design optimization routines for these networks that\nare as close as possible to that of their well-tuned, non-decomposed\ncounterparts; we back this intuition with an analysis of how the initialization\nand regularization schemes impact training with gradient descent, drawing on\nmodern attempts to understand the interplay of weight-decay and\nbatch-normalization. Empirically, we highlight the benefits of spectral\ninitialization and Frobenius decay across a variety of settings. In model\ncompression, we show that they enable low-rank methods to significantly\noutperform both unstructured sparsity and tensor methods on the task of\ntraining low-memory residual networks; analogs of the schemes also improve the\nperformance of tensor decomposition techniques. For knowledge distillation,\nFrobenius decay enables a simple, overcomplete baseline that yields a compact\nmodel from over-parameterized training without requiring retraining with or\npruning a teacher network. Finally, we show how both schemes applied to\nmulti-head attention lead to improved performance on both translation and\nunsupervised pre-training.", "published": "2021-05-03 17:28:07", "link": "http://arxiv.org/abs/2105.01029v2", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "stat.ML"}
{"title": "AvaTr: One-Shot Speaker Extraction with Transformers", "abstract": "To extract the voice of a target speaker when mixed with a variety of other\nsounds, such as white and ambient noises or the voices of interfering speakers,\nwe extend the Transformer network to attend the most relevant information with\nrespect to the target speaker given the characteristics of his or her voices as\na form of contextual information. The idea has a natural interpretation in\nterms of the selective attention theory. Specifically, we propose two models to\nincorporate the voice characteristics in Transformer based on different\ninsights of where the feature selection should take place. Both models yield\nexcellent performance, on par or better than published state-of-the-art models\non the speaker extraction task, including separating speech of novel speakers\nnot seen during training.", "published": "2021-05-03 02:43:16", "link": "http://arxiv.org/abs/2105.00609v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Quantifying and Maximizing the Benefits of Back-End Noise Adaption on\n  Attention-Based Speech Recognition Models", "abstract": "This work analyzes how attention-based Bidirectional Long Short-Term Memory\n(BLSTM) models adapt to noise-augmented speech. We identify crucial components\nfor noise adaptation in BLSTM models by freezing model components during\nfine-tuning. We first freeze larger model subnetworks and then pursue a\nfine-grained freezing approach in the encoder after identifying its importance\nfor noise adaptation. The first encoder layer is shown to be crucial for noise\nadaptation, and the weights are shown to be more important than the other\nlayers. Appreciable accuracy benefits are identified when fine-tuning on a\ntarget noisy environment from a model pretrained with noisy speech relative to\nfine-tuning from a model pretrained with only clean speech when tested on the\ntarget noisy environment. For this analysis, we produce our own dataset\naugmentation tool and it is open-sourced to encourage future efforts in\nexploring noise adaptation in ASR.", "published": "2021-05-03 19:23:58", "link": "http://arxiv.org/abs/2105.01134v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Naturalistic audio-visual volumetric sequences dataset of sounding\n  actions for six degree-of-freedom interaction", "abstract": "As audio-visual systems increasingly bring immersive and interactive\ncapabilities into our work and leisure activities, so the need for naturalistic\ntest material grows. New volumetric datasets have captured high-quality 3D\nvideo, but accompanying audio is often neglected, making it hard to test an\nintegrated bimodal experience. Designed to cover diverse sound types and\nfeatures, the presented volumetric dataset was constructed from audio and video\nstudio recordings of scenes to yield forty short action sequences. Potential\nuses in technical and scientific tests are discussed.", "published": "2021-05-03 06:16:33", "link": "http://arxiv.org/abs/2105.00641v1", "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Exploiting Audio-Visual Consistency with Partial Supervision for Spatial\n  Audio Generation", "abstract": "Human perceives rich auditory experience with distinct sound heard by ears.\nVideos recorded with binaural audio particular simulate how human receives\nambient sound. However, a large number of videos are with monaural audio only,\nwhich would degrade the user experience due to the lack of ambient information.\nTo address this issue, we propose an audio spatialization framework to convert\na monaural video into a binaural one exploiting the relationship across audio\nand visual components. By preserving the left-right consistency in both audio\nand visual modalities, our learning strategy can be viewed as a self-supervised\nlearning technique, and alleviates the dependency on a large amount of video\ndata with ground truth binaural audio data during training. Experiments on\nbenchmark datasets confirm the effectiveness of our proposed framework in both\nsemi-supervised and fully supervised scenarios, with ablation studies and\nvisualization further support the use of our model for audio spatialization.", "published": "2021-05-03 09:34:11", "link": "http://arxiv.org/abs/2105.00708v1", "categories": ["cs.SD", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Full-Reference Speech Quality Estimation with Attentional Siamese Neural\n  Networks", "abstract": "In this paper, we present a full-reference speech quality prediction model\nwith a deep learning approach. The model determines a feature representation of\nthe reference and the degraded signal through a siamese recurrent convolutional\nnetwork that shares the weights for both signals as input. The resulting\nfeatures are then used to align the signals with an attention mechanism and are\nfinally combined to estimate the overall speech quality. The proposed network\narchitecture represents a simple solution for the time-alignment problem that\noccurs for speech signals transmitted through Voice-Over-IP networks and shows\nhow the clean reference signal can be incorporated into speech quality models\nthat are based on end-to-end trained neural networks.", "published": "2021-05-03 12:38:25", "link": "http://arxiv.org/abs/2105.00783v1", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Fully Learnable Deep Wavelet Transform for Unsupervised Monitoring of\n  High-Frequency Time Series", "abstract": "High-Frequency (HF) signals are ubiquitous in the industrial world and are of\ngreat use for monitoring of industrial assets. Most deep learning tools are\ndesigned for inputs of fixed and/or very limited size and many successful\napplications of deep learning to the industrial context use as inputs extracted\nfeatures, which is a manually and often arduously obtained compact\nrepresentation of the original signal. In this paper, we propose a fully\nunsupervised deep learning framework that is able to extract a meaningful and\nsparse representation of raw HF signals. We embed in our architecture important\nproperties of the fast discrete wavelet transformation (FDWT) such as (1) the\ncascade algorithm, (2) the conjugate quadrature filter property that links\ntogether the wavelet, the scaling and transposed filter functions, and (3) the\ncoefficient denoising. Using deep learning, we make this architecture fully\nlearnable: both the wavelet bases and the wavelet coefficient denoising are\nlearnable. To achieve this objective, we propose a new activation function that\nperforms a learnable hard-thresholding of the wavelet coefficients. With our\nframework, the denoising FDWT becomes a fully learnable unsupervised tool that\ndoes neither require any type of pre- nor post-processing, nor any prior\nknowledge on wavelet transform. We demonstrate the benefits of embedding all\nthese properties on three machine-learning tasks performed on open source sound\ndatasets. We perform an ablation study of the impact of each property on the\nperformance of the architecture, achieve results well above baseline and\noutperform other state-of-the-art methods.", "published": "2021-05-03 14:35:06", "link": "http://arxiv.org/abs/2105.00899v2", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Deep Neural Network for Musical Instrument Recognition using MFCCs", "abstract": "The task of efficient automatic music classification is of vital importance\nand forms the basis for various advanced applications of AI in the musical\ndomain. Musical instrument recognition is the task of instrument identification\nby virtue of its audio. This audio, also termed as the sound vibrations are\nleveraged by the model to match with the instrument classes. In this paper, we\nuse an artificial neural network (ANN) model that was trained to perform\nclassification on twenty different classes of musical instruments. Here we use\nuse only the mel-frequency cepstral coefficients (MFCCs) of the audio data. Our\nproposed model trains on the full London philharmonic orchestra dataset which\ncontains twenty classes of instruments belonging to the four families viz.\nwoodwinds, brass, percussion, and strings. Based on experimental results our\nmodel achieves state-of-the-art accuracy on the same.", "published": "2021-05-03 15:10:34", "link": "http://arxiv.org/abs/2105.00933v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
