{"title": "ner and pos when nothing is capitalized", "abstract": "For those languages which use it, capitalization is an important signal for\nthe fundamental NLP tasks of Named Entity Recognition (NER) and Part of Speech\n(POS) tagging. In fact, it is such a strong signal that model performance on\nthese tasks drops sharply in common lowercased scenarios, such as noisy web\ntext or machine translation outputs. In this work, we perform a systematic\nanalysis of solutions to this problem, modifying only the casing of the train\nor test data using lowercasing and truecasing methods. While prior work and\nfirst impressions might suggest training a caseless model, or using a truecaser\nat test time, we show that the most effective strategy is a concatenation of\ncased and lowercased training data, producing a single model with high\nperformance on both cased and uncased text. As shown in our experiments, this\nresult holds across tasks and input representations. Finally, we show that our\nproposed solution gives an 8% F1 improvement in mention detection on noisy\nout-of-domain Twitter data.", "published": "2019-03-27 01:57:18", "link": "http://arxiv.org/abs/1903.11222v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CSS10: A Collection of Single Speaker Speech Datasets for 10 Languages", "abstract": "We describe our development of CSS10, a collection of single speaker speech\ndatasets for ten languages. It is composed of short audio clips from LibriVox\naudiobooks and their aligned texts. To validate its quality we train two neural\ntext-to-speech models on each dataset. Subsequently, we conduct Mean Opinion\nScore tests on the synthesized speech samples. We make our datasets,\npre-trained models, and test resources publicly available. We hope they will be\nused for future speech tasks.", "published": "2019-03-27 07:15:21", "link": "http://arxiv.org/abs/1903.11269v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Grammatical Error Correction and Style Transfer via Zero-shot\n  Monolingual Translation", "abstract": "Both grammatical error correction and text style transfer can be viewed as\nmonolingual sequence-to-sequence transformation tasks, but the scarcity of\ndirectly annotated data for either task makes them unfeasible for most\nlanguages. We present an approach that does both tasks within the same trained\nmodel, and only uses regular language parallel data, without requiring\nerror-corrected or style-adapted texts. We apply our model to three languages\nand present a thorough evaluation on both tasks, showing that the model is\nreliable for a number of error types and style transfer aspects.", "published": "2019-03-27 08:16:10", "link": "http://arxiv.org/abs/1903.11283v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multilevel Text Normalization with Sequence-to-Sequence Networks and\n  Multisource Learning", "abstract": "We define multilevel text normalization as sequence-to-sequence processing\nthat transforms naturally noisy text into a sequence of normalized units of\nmeaning (morphemes) in three steps: 1) writing normalization, 2) lemmatization,\n3) canonical segmentation. These steps are traditionally considered separate\nNLP tasks, with diverse solutions, evaluation schemes and data sources. We\nexploit the fact that all these tasks involve sub-word sequence-to-sequence\ntransformation to propose a systematic solution for all of them using neural\nencoder-decoder technology. The specific challenge that we tackle in this paper\nis integrating the traditional know-how on separate tasks into the neural\nsequence-to-sequence framework to improve the state of the art. We address this\nchallenge by enriching the general framework with mechanisms that allow\nprocessing the information on multiple levels of text organization (characters,\nmorphemes, words, sentences) in combination with structural information\n(multilevel language model, part-of-speech) and heterogeneous sources (text,\ndictionaries). We show that our solution consistently improves on the current\nmethods in all three steps. In addition, we analyze the performance of our\nsystem to show the specific contribution of the integrating components to the\noverall improvement.", "published": "2019-03-27 10:50:23", "link": "http://arxiv.org/abs/1903.11340v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning semantic sentence representations from visually grounded\n  language without lexical knowledge", "abstract": "Current approaches to learning semantic representations of sentences often\nuse prior word-level knowledge. The current study aims to leverage visual\ninformation in order to capture sentence level semantics without the need for\nword embeddings. We use a multimodal sentence encoder trained on a corpus of\nimages with matching text captions to produce visually grounded sentence\nembeddings. Deep Neural Networks are trained to map the two modalities to a\ncommon embedding space such that for an image the corresponding caption can be\nretrieved and vice versa. We show that our model achieves results comparable to\nthe current state-of-the-art on two popular image-caption retrieval benchmark\ndata sets: MSCOCO and Flickr8k. We evaluate the semantic content of the\nresulting sentence embeddings using the data from the Semantic Textual\nSimilarity benchmark task and show that the multimodal embeddings correlate\nwell with human semantic similarity judgements. The system achieves\nstate-of-the-art results on several of these benchmarks, which shows that a\nsystem trained solely on multimodal data, without assuming any word\nrepresentations, is able to capture sentence level semantics. Importantly, this\nresult shows that we do not need prior knowledge of lexical level semantics in\norder to model sentence level semantics. These findings demonstrate the\nimportance of visual information in semantics.", "published": "2019-03-27 12:56:37", "link": "http://arxiv.org/abs/1903.11393v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structural Neural Encoders for AMR-to-text Generation", "abstract": "AMR-to-text generation is a problem recently introduced to the NLP community,\nin which the goal is to generate sentences from Abstract Meaning Representation\n(AMR) graphs. Sequence-to-sequence models can be used to this end by converting\nthe AMR graphs to strings. Approaching the problem while working directly with\ngraphs requires the use of graph-to-sequence models that encode the AMR graph\ninto a vector representation. Such encoding has been shown to be beneficial in\nthe past, and unlike sequential encoding, it allows us to explicitly capture\nreentrant structures in the AMR graphs. We investigate the extent to which\nreentrancies (nodes with multiple parents) have an impact on AMR-to-text\ngeneration by comparing graph encoders to tree encoders, where reentrancies are\nnot preserved. We show that improvements in the treatment of reentrancies and\nlong-range dependencies contribute to higher overall scores for graph encoders.\nOur best model achieves 24.40 BLEU on LDC2015E86, outperforming the state of\nthe art by 1.1 points and 24.54 BLEU on LDC2017T10, outperforming the state of\nthe art by 1.24 points.", "published": "2019-03-27 13:21:51", "link": "http://arxiv.org/abs/1903.11410v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using Monolingual Data in Neural Machine Translation: a Systematic Study", "abstract": "Neural Machine Translation (MT) has radically changed the way systems are\ndeveloped. A major difference with the previous generation (Phrase-Based MT) is\nthe way monolingual target data, which often abounds, is used in these two\nparadigms. While Phrase-Based MT can seamlessly integrate very large language\nmodels trained on billions of sentences, the best option for Neural MT\ndevelopers seems to be the generation of artificial parallel data through\n\\textsl{back-translation} - a technique that fails to fully take advantage of\nexisting datasets. In this paper, we conduct a systematic study of\nback-translation, comparing alternative uses of monolingual data, as well as\nmultiple data generation procedures. Our findings confirm that back-translation\nis very effective and give new explanations as to why this is the case. We also\nintroduce new data simulation techniques that are almost as effective, yet much\ncheaper to implement.", "published": "2019-03-27 14:11:18", "link": "http://arxiv.org/abs/1903.11437v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On Attribution of Recurrent Neural Network Predictions via Additive\n  Decomposition", "abstract": "RNN models have achieved the state-of-the-art performance in a wide range of\ntext mining tasks. However, these models are often regarded as black-boxes and\nare criticized due to the lack of interpretability. In this paper, we enhance\nthe interpretability of RNNs by providing interpretable rationales for RNN\npredictions. Nevertheless, interpreting RNNs is a challenging problem. Firstly,\nunlike existing methods that rely on local approximation, we aim to provide\nrationales that are more faithful to the decision making process of RNN models.\nSecondly, a flexible interpretation method should be able to assign\ncontribution scores to text segments of varying lengths, instead of only to\nindividual words. To tackle these challenges, we propose a novel attribution\nmethod, called REAT, to provide interpretations to RNN predictions. REAT\ndecomposes the final prediction of a RNN into additive contribution of each\nword in the input text. This additive decomposition enables REAT to further\nobtain phrase-level attribution scores. In addition, REAT is generally\napplicable to various RNN architectures, including GRU, LSTM and their\nbidirectional versions. Experimental results demonstrate the faithfulness and\ninterpretability of the proposed attribution method. Comprehensive analysis\nshows that our attribution method could unveil the useful linguistic knowledge\ncaptured by RNNs. Some analysis further demonstrates our method could be\nutilized as a debugging tool to examine the vulnerability and failure reasons\nof RNNs, which may lead to several promising future directions to promote\ngeneralization ability of RNNs.", "published": "2019-03-27 04:25:57", "link": "http://arxiv.org/abs/1903.11245v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Image search using multilingual texts: a cross-modal learning approach\n  between image and text", "abstract": "Multilingual (or cross-lingual) embeddings represent several languages in a\nunique vector space. Using a common embedding space enables for a shared\nsemantic between words from different languages. In this paper, we propose to\nembed images and texts into a unique distributional vector space, enabling to\nsearch images by using text queries expressing information needs related to the\n(visual) content of images, as well as using image similarity. Our framework\nforces the representation of an image to be similar to the representation of\nthe text that describes it. Moreover, by using multilingual embeddings we\nensure that words from two different languages have close descriptors and thus\nare attached to similar images. We provide experimental evidence of the\nefficiency of our approach by experimenting it on two datasets: Common Objects\nin COntext (COCO) [19] and Multi30K [7].", "published": "2019-03-27 09:02:41", "link": "http://arxiv.org/abs/1903.11299v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Does My Rebuttal Matter? Insights from a Major NLP Conference", "abstract": "Peer review is a core element of the scientific process, particularly in\nconference-centered fields such as ML and NLP. However, only few studies have\nevaluated its properties empirically. Aiming to fill this gap, we present a\ncorpus that contains over 4k reviews and 1.2k author responses from ACL-2018.\nWe quantitatively and qualitatively assess the corpus. This includes a pilot\nstudy on paper weaknesses given by reviewers and on quality of author\nresponses. We then focus on the role of the rebuttal phase, and propose a novel\ntask to predict after-rebuttal (i.e., final) scores from initial reviews and\nauthor responses. Although author responses do have a marginal (and\nstatistically significant) influence on the final scores, especially for\nborderline papers, our results suggest that a reviewer's final score is largely\ndetermined by her initial score and the distance to the other reviewers'\ninitial scores. In this context, we discuss the conformity bias inherent to\npeer reviewing, a bias that has largely been overlooked in previous research.\nWe hope our analyses will help better assess the usefulness of the rebuttal\nphase in NLP conferences.", "published": "2019-03-27 12:00:20", "link": "http://arxiv.org/abs/1903.11367v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Polysemy and brevity versus frequency in language", "abstract": "The pioneering research of G. K. Zipf on the relationship between word\nfrequency and other word features led to the formulation of various linguistic\nlaws. The most popular is Zipf's law for word frequencies. Here we focus on two\nlaws that have been studied less intensively: the meaning-frequency law, i.e.\nthe tendency of more frequent words to be more polysemous, and the law of\nabbreviation, i.e. the tendency of more frequent words to be shorter. In a\nprevious work, we tested the robustness of these Zipfian laws for English,\nroughly measuring word length in number of characters and distinguishing adult\nfrom child speech. In the present article, we extend our study to other\nlanguages (Dutch and Spanish) and introduce two additional measures of length:\nsyllabic length and phonemic length. Our correlation analysis indicates that\nboth the meaning-frequency law and the law of abbreviation hold overall in all\nthe analyzed languages.", "published": "2019-03-27 14:21:57", "link": "http://arxiv.org/abs/1904.00812v1", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "Text Processing Like Humans Do: Visually Attacking and Shielding NLP\n  Systems", "abstract": "Visual modifications to text are often used to obfuscate offensive comments\nin social media (e.g., \"!d10t\") or as a writing style (\"1337\" in \"leet speak\"),\namong other scenarios. We consider this as a new type of adversarial attack in\nNLP, a setting to which humans are very robust, as our experiments with both\nsimple and more difficult visual input perturbations demonstrate. We then\ninvestigate the impact of visual adversarial attacks on current NLP systems on\ncharacter-, word-, and sentence-level tasks, showing that both neural and\nnon-neural models are, in contrast to humans, extremely sensitive to such\nattacks, suffering performance decreases of up to 82\\%. We then explore three\nshielding methods---visual character embeddings, adversarial training, and\nrule-based recovery---which substantially improve the robustness of the models.\nHowever, the shielding methods still fall behind performances achieved in\nnon-attack scenarios, which demonstrates the difficulty of dealing with visual\nattacks.", "published": "2019-03-27 16:01:18", "link": "http://arxiv.org/abs/1903.11508v2", "categories": ["cs.CL", "cs.CR", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Visualization and Interpretation of Latent Spaces for Controlling\n  Expressive Speech Synthesis through Audio Analysis", "abstract": "The field of Text-to-Speech has experienced huge improvements last years\nbenefiting from deep learning techniques. Producing realistic speech becomes\npossible now. As a consequence, the research on the control of the\nexpressiveness, allowing to generate speech in different styles or manners, has\nattracted increasing attention lately. Systems able to control style have been\ndeveloped and show impressive results. However the control parameters often\nconsist of latent variables and remain complex to interpret. In this paper, we\nanalyze and compare different latent spaces and obtain an interpretation of\ntheir influence on expressive speech. This will enable the possibility to build\ncontrollable speech synthesis systems with an understandable behaviour.", "published": "2019-03-27 17:33:33", "link": "http://arxiv.org/abs/1903.11570v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "MuSE-ing on the Impact of Utterance Ordering On Crowdsourced Emotion\n  Annotations", "abstract": "Emotion recognition algorithms rely on data annotated with high quality\nlabels. However, emotion expression and perception are inherently subjective.\nThere is generally not a single annotation that can be unambiguously declared\n\"correct\". As a result, annotations are colored by the manner in which they\nwere collected. In this paper, we conduct crowdsourcing experiments to\ninvestigate this impact on both the annotations themselves and on the\nperformance of these algorithms. We focus on one critical question: the effect\nof context. We present a new emotion dataset, Multimodal Stressed Emotion\n(MuSE), and annotate the dataset using two conditions: randomized, in which\nannotators are presented with clips in random order, and contextualized, in\nwhich annotators are presented with clips in order. We find that contextual\nlabeling schemes result in annotations that are more similar to a speaker's own\nself-reported labels and that labels generated from randomized schemes are most\neasily predictable by automated systems.", "published": "2019-03-27 19:49:00", "link": "http://arxiv.org/abs/1903.11672v1", "categories": ["cs.SD", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Automatic Spelling Correction with Transformer for CTC-based End-to-End\n  Speech Recognition", "abstract": "Connectionist Temporal Classification (CTC) based end-to-end speech\nrecognition system usually need to incorporate an external language model by\nusing WFST-based decoding in order to achieve promising results. This is more\nessential to Mandarin speech recognition since it owns a special phenomenon,\nnamely homophone, which causes a lot of substitution errors. The linguistic\ninformation introduced by language model will help to distinguish these\nsubstitution errors. In this work, we propose a transformer based spelling\ncorrection model to automatically correct errors especially the substitution\nerrors made by CTC-based Mandarin speech recognition system. Specifically, we\ninvestigate using the recognition results generated by CTC-based systems as\ninput and the ground-truth transcriptions as output to train a transformer with\nencoder-decoder architecture, which is much similar to machine translation.\nResults in a 20,000 hours Mandarin speech recognition task show that the\nproposed spelling correction model can achieve a CER of 3.41%, which results in\n22.9% and 53.2% relative improvement compared to the baseline CTC-based systems\ndecoded with and without language model respectively.", "published": "2019-03-27 07:16:48", "link": "http://arxiv.org/abs/1904.10045v1", "categories": ["eess.AS", "cs.NE", "cs.SD"], "primary_category": "eess.AS"}
