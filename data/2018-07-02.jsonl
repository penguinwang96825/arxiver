{"title": "A Simple but Effective Classification Model for Grammatical Error\n  Correction", "abstract": "We treat grammatical error correction (GEC) as a classification problem in\nthis study, where for different types of errors, a target word is identified,\nand the classifier predicts the correct word form from a set of possible\nchoices. We propose a novel neural network based feature representation and\nclassification model, trained using large text corpora without human\nannotations. Specifically we use RNNs with attention to represent both the left\nand right context of a target word. All feature embeddings are learned jointly\nin an end-to-end fashion. Experimental results show that our novel approach\noutperforms other classifier methods on the CoNLL-2014 test set (F0.5 45.05%).\nOur model is simple but effective, and is suitable for industrial production.", "published": "2018-07-02 06:48:46", "link": "http://arxiv.org/abs/1807.00488v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Punctuation Prediction Model for Conversational Speech", "abstract": "An ASR system usually does not predict any punctuation or capitalization.\nLack of punctuation causes problems in result presentation and confuses both\nthe human reader andoff-the-shelf natural language processing algorithms. To\novercome these limitations, we train two variants of Deep Neural Network (DNN)\nsequence labelling models - a Bidirectional Long Short-Term Memory (BLSTM) and\na Convolutional Neural Network (CNN), to predict the punctuation. The models\nare trained on the Fisher corpus which includes punctuation annotation. In our\nexperiments, we combine time-aligned and punctuated Fisher corpus transcripts\nusing a sequence alignment algorithm. The neural networks are trained on Common\nWeb Crawl GloVe embedding of the words in Fisher transcripts aligned with\nconversation side indicators and word time infomation. The CNNs yield a better\nprecision and BLSTMs tend to have better recall. While BLSTMs make fewer\nmistakes overall, the punctuation predicted by the CNN is more accurate -\nespecially in the case of question marks. Our results constitute significant\nevidence that the distribution of words in time, as well as pre-trained\nembeddings, can be useful in the punctuation prediction task.", "published": "2018-07-02 09:06:27", "link": "http://arxiv.org/abs/1807.00543v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Interplay between Lexical Resources and Natural Language Processing", "abstract": "Incorporating linguistic, world and common sense knowledge into AI/NLP\nsystems is currently an important research area, with several open problems and\nchallenges. At the same time, processing and storing this knowledge in lexical\nresources is not a straightforward task. This tutorial proposes to address\nthese complementary goals from two methodological perspectives: the use of NLP\nmethods to help the process of constructing and enriching lexical resources and\nthe use of lexical resources for improving NLP applications. Two main types of\naudience can benefit from this tutorial: those working on language resources\nwho are interested in becoming acquainted with automatic NLP techniques, with\nthe end goal of speeding and/or easing up the process of resource curation; and\non the other hand, researchers in NLP who would like to benefit from the\nknowledge of lexical resources to improve their systems and models. The slides\nof the tutorial are available at https://bitbucket.org/luisespinosa/lr-nlp/", "published": "2018-07-02 09:53:50", "link": "http://arxiv.org/abs/1807.00571v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Neural Approach to Language Variety Translation", "abstract": "In this paper we present the first neural-based machine translation system\ntrained to translate between standard national varieties of the same language.\nWe take the pair Brazilian - European Portuguese as an example and compare the\nperformance of this method to a phrase-based statistical machine translation\nsystem. We report a performance improvement of 0.9 BLEU points in translating\nfrom European to Brazilian Portuguese and 0.2 BLEU points when translating in\nthe opposite direction. We also carried out a human evaluation experiment with\nnative speakers of Brazilian Portuguese which indicates that humans prefer the\noutput produced by the neural-based system in comparison to the statistical\nsystem.", "published": "2018-07-02 13:29:46", "link": "http://arxiv.org/abs/1807.00651v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Transparent, Efficient, and Robust Word Embedding Access with WOMBAT", "abstract": "We present WOMBAT, a Python tool which supports NLP practitioners in\naccessing word embeddings from code. WOMBAT addresses common research problems,\nincluding unified access, scaling, and robust and reproducible preprocessing.\nCode that uses WOMBAT for accessing word embeddings is not only cleaner, more\nreadable, and easier to reuse, but also much more efficient than code using\nstandard in-memory methods: a Python script using WOMBAT for evaluating seven\nlarge word embedding collections (8.7M embedding vectors in total) on a simple\nSemEval sentence similarity task involving 250 raw sentence pairs completes in\nunder ten seconds end-to-end on a standard notebook computer.", "published": "2018-07-02 14:47:30", "link": "http://arxiv.org/abs/1807.00717v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Representation Mapping: A Novel Approach to Generate High-Quality\n  Multi-Lingual Emotion Lexicons", "abstract": "In the past years, sentiment analysis has increasingly shifted attention to\nrepresentational frameworks more expressive than semantic polarity (being\npositive, negative or neutral). However, these richer formats (like Basic\nEmotions or Valence-Arousal-Dominance, and variants therefrom), rooted in\npsychological research, tend to proliferate the number of representation\nschemes for emotion encoding. Thus, a large amount of representationally\nincompatible emotion lexicons has been developed by various research groups\nadopting one or the other emotion representation format. As a consequence, the\nreusability of these resources decreases as does the comparability of systems\nusing them. In this paper, we propose to solve this dilemma by methods and\ntools which map different representation formats onto each other for the sake\nof mutual compatibility and interoperability of language resources. We present\nthe first large-scale investigation of such representation mappings for four\ntypologically diverse languages and find evidence that our approach produces\n(near-)gold quality emotion lexicons, even in cross-lingual settings. Finally,\nwe use our models to create new lexicons for eight typologically diverse\nlanguages.", "published": "2018-07-02 16:29:34", "link": "http://arxiv.org/abs/1807.00775v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pragmatic approach to structured data querying via natural language\n  interface", "abstract": "As the use of technology increases and data analysis becomes integral in many\nbusinesses, the ability to quickly access and interpret data has become more\nimportant than ever. Information retrieval technologies are being utilized by\norganizations and companies to manage their information systems and processes.\nDespite information retrieval of a large amount of data being efficient\norganized in relational databases, a user still needs to master the DB\nlanguage/schema to completely formulate the queries. This puts a burden on\norganizations and companies to hire employees that are proficient in DB\nlanguages/schemas to formulate queries. To reduce some of the burden on already\noverstretched data teams, many organizations are looking for tools that allow\nnon-developers to query their databases. Unfortunately, writing a valid SQL\nquery that answers the question a user is trying to ask isn't always easy. Even\nseemingly simple questions, like \"Which start-up companies received more than\n$200M in funding?\" can actually be very hard to answer, let alone convert into\na SQL query. How do you define start-up companies? By size, location, duration\nof time they have been incorporated? This may be fine if a user is working with\na database they're already familiar with, but what if users are not familiar\nwith the database. What is needed is a centralized system that can effectively\ntranslate natural language queries into specific database queries for different\ncustomer database types. There is a number of factors that can dramatically\naffect the system architecture and the set of algorithms used to translate NL\nqueries into a structured query representation.", "published": "2018-07-02 17:24:22", "link": "http://arxiv.org/abs/1807.00791v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modeling Language Variation and Universals: A Survey on Typological\n  Linguistics for Natural Language Processing", "abstract": "Linguistic typology aims to capture structural and semantic variation across\nthe world's languages. A large-scale typology could provide excellent guidance\nfor multilingual Natural Language Processing (NLP), particularly for languages\nthat suffer from the lack of human labeled resources. We present an extensive\nliterature survey on the use of typological information in the development of\nNLP techniques. Our survey demonstrates that to date, the use of information in\nexisting typological databases has resulted in consistent but modest\nimprovements in system performance. We show that this is due to both intrinsic\nlimitations of databases (in terms of coverage and feature granularity) and\nunder-employment of the typological features included in them. We advocate for\na new approach that adapts the broad and discrete nature of typological\ncategories to the contextual and continuous nature of machine learning\nalgorithms used in contemporary NLP. In particular, we suggest that such\napproach could be facilitated by recent developments in data-driven induction\nof typological knowledge.", "published": "2018-07-02 22:09:59", "link": "http://arxiv.org/abs/1807.00914v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Random Projections for Language Modelling", "abstract": "Neural network-based language models deal with data sparsity problems by\nmapping the large discrete space of words into a smaller continuous space of\nreal-valued vectors. By learning distributed vector representations for words,\neach training sample informs the neural network model about a combinatorial\nnumber of other patterns. In this paper, we exploit the sparsity in natural\nlanguage even further by encoding each unique input word using a fixed sparse\nrandom representation. These sparse codes are then projected onto a smaller\nembedding space which allows for the encoding of word occurrences from a\npossibly unknown vocabulary, along with the creation of more compact language\nmodels using a reduced number of parameters. We investigate the properties of\nour encoding mechanism empirically, by evaluating its performance on the widely\nused Penn Treebank corpus. We show that guaranteeing approximately equidistant\n(nearly orthogonal) vector representations for unique discrete inputs is enough\nto provide the neural network model with enough information to learn --and make\nuse-- of distributed representations for these inputs.", "published": "2018-07-02 23:54:48", "link": "http://arxiv.org/abs/1807.00930v4", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Weight-importance sparse training in keyword spotting", "abstract": "Large size models are implemented in recently ASR system to deal with complex\nspeech recognition problems. The num- ber of parameters in these models makes\nthem hard to deploy, especially on some resource-short devices such as car\ntablet. Besides this, at most of time, ASR system is used to deal with\nreal-time problem such as keyword spotting (KWS). It is contradictory to the\nfact that large model requires long com- putation time. To deal with this\nproblem, we apply some sparse algo- rithms to reduces number of parameters in\nsome widely used models, Deep Neural Network (DNN) KWS, which requires real\nshort computation time. We can prune more than 90 % even 95% of parameters in\nthe model with tiny effect decline. And the sparse model performs better than\nbaseline models which has same order number of parameters. Besides this, sparse\nalgorithm can lead us to find rational model size au- tomatically for certain\nproblem without concerning choosing an original model size.", "published": "2018-07-02 09:34:34", "link": "http://arxiv.org/abs/1807.00560v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Training a Neural Network in a Low-Resource Setting on Automatically\n  Annotated Noisy Data", "abstract": "Manually labeled corpora are expensive to create and often not available for\nlow-resource languages or domains. Automatic labeling approaches are an\nalternative way to obtain labeled data in a quicker and cheaper way. However,\nthese labels often contain more errors which can deteriorate a classifier's\nperformance when trained on this data. We propose a noise layer that is added\nto a neural network architecture. This allows modeling the noise and train on a\ncombination of clean and noisy data. We show that in a low-resource NER task we\ncan improve performance by up to 35% by using additional, noisy data and\nhandling the noise.", "published": "2018-07-02 15:35:02", "link": "http://arxiv.org/abs/1807.00745v2", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Waveform to Single Sinusoid Regression to Estimate the F0 Contour from\n  Noisy Speech Using Recurrent Deep Neural Networks", "abstract": "The fundamental frequency (F0) represents pitch in speech that determines\nprosodic characteristics of speech and is needed in various tasks for speech\nanalysis and synthesis. Despite decades of research on this topic, F0\nestimation at low signal-to-noise ratios (SNRs) in unexpected noise conditions\nremains difficult. This work proposes a new approach to noise robust F0\nestimation using a recurrent neural network (RNN) trained in a supervised\nmanner. Recent studies employ deep neural networks (DNNs) for F0 tracking as a\nframe-by-frame classification task into quantised frequency states but we\npropose waveform-to-sinusoid regression instead to achieve both noise\nrobustness and accurate estimation with increased frequency resolution.\n  Experimental results with PTDB-TUG corpus contaminated by additive noise\n(NOISEX-92) demonstrate that the proposed method improves gross pitch error\n(GPE) rate and fine pitch error (FPE) by more than 35 % at SNRs between -10 dB\nand +10 dB compared with well-known noise robust F0 tracker, PEFAC.\nFurthermore, the proposed method also outperforms state-of-the-art DNN-based\napproaches by more than 15 % in terms of both FPE and GPE rate over the\npreceding SNR range.", "published": "2018-07-02 15:42:00", "link": "http://arxiv.org/abs/1807.00752v1", "categories": ["eess.AS", "cs.CL", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
{"title": "Improving part-of-speech tagging via multi-task learning and\n  character-level word representations", "abstract": "In this paper, we explore the ways to improve POS-tagging using various types\nof auxiliary losses and different word representations. As a baseline, we\nutilized a BiLSTM tagger, which is able to achieve state-of-the-art results on\nthe sequence labelling tasks. We developed a new method for character-level\nword representation using feedforward neural network. Such representation gave\nus better results in terms of speed and performance of the model. We also\napplied a novel technique of pretraining such word representations with\nexisting word vectors. Finally, we designed a new variant of auxiliary loss for\nsequence labelling tasks: an additional prediction of the neighbour labels.\nSuch loss forces a model to learn the dependencies in-side a sequence of labels\nand accelerates the process of training. We test these methods on English and\nRussian languages.", "published": "2018-07-02 13:04:52", "link": "http://arxiv.org/abs/1807.00818v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Exploring End-to-End Techniques for Low-Resource Speech Recognition", "abstract": "In this work we present simple grapheme-based system for low-resource speech\nrecognition using Babel data for Turkish spontaneous speech (80 hours). We have\ninvestigated different neural network architectures performance, including\nfully-convolutional, recurrent and ResNet with GRU. Different features and\nnormalization techniques are compared as well. We also proposed CTC-loss\nmodification using segmentation during training, which leads to improvement\nwhile decoding with small beam size. Our best model achieved word error rate of\n45.8%, which is the best reported result for end-to-end systems using in-domain\ndata for this task, according to our knowledge.", "published": "2018-07-02 19:47:22", "link": "http://arxiv.org/abs/1807.00868v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Harnessing AI for Speech Reconstruction using Multi-view Silent Video\n  Feed", "abstract": "Speechreading or lipreading is the technique of understanding and getting\nphonetic features from a speaker's visual features such as movement of lips,\nface, teeth and tongue. It has a wide range of multimedia applications such as\nin surveillance, Internet telephony, and as an aid to a person with hearing\nimpairments. However, most of the work in speechreading has been limited to\ntext generation from silent videos. Recently, research has started venturing\ninto generating (audio) speech from silent video sequences but there have been\nno developments thus far in dealing with divergent views and poses of a\nspeaker. Thus although, we have multiple camera feeds for the speech of a user,\nbut we have failed in using these multiple video feeds for dealing with the\ndifferent poses. To this end, this paper presents the world's first ever\nmulti-view speech reading and reconstruction system. This work encompasses the\nboundaries of multimedia research by putting forth a model which leverages\nsilent video feeds from multiple cameras recording the same subject to generate\nintelligent speech for a speaker. Initial results confirm the usefulness of\nexploiting multiple camera views in building an efficient speech reading and\nreconstruction system. It further shows the optimal placement of cameras which\nwould lead to the maximum intelligibility of speech. Next, it lays out various\ninnovative applications for the proposed system focusing on its potential\nprodigious impact in not just security arena but in many other multimedia\nanalytics problems.", "published": "2018-07-02 12:16:55", "link": "http://arxiv.org/abs/1807.00619v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "An energy-based generative sequence model for testing sensory theories\n  of Western harmony", "abstract": "The relationship between sensory consonance and Western harmony is an\nimportant topic in music theory and psychology. We introduce new methods for\nanalysing this relationship, and apply them to large corpora representing three\nprominent genres of Western music: classical, popular, and jazz music. These\nmethods centre on a generative sequence model with an exponential-family\nenergy-based form that predicts chord sequences from continuous features. We\nuse this model to investigate one aspect of instantaneous consonance\n(harmonicity) and two aspects of sequential consonance (spectral distance and\nvoice-leading distance). Applied to our three musical genres, the results\ngenerally support the relationship between sensory consonance and harmony, but\nlead us to question the high importance attributed to spectral distance in the\npsychological literature. We anticipate that our methods will provide a useful\nplatform for future work linking music psychology to music theory.", "published": "2018-07-02 17:23:06", "link": "http://arxiv.org/abs/1807.00790v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
