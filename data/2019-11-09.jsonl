{"title": "How Decoding Strategies Affect the Verifiability of Generated Text", "abstract": "Recent progress in pre-trained language models led to systems that are able\nto generate text of an increasingly high quality. While several works have\ninvestigated the fluency and grammatical correctness of such models, it is\nstill unclear to which extent the generated text is consistent with factual\nworld knowledge. Here, we go beyond fluency and also investigate the\nverifiability of text generated by state-of-the-art pre-trained language\nmodels. A generated sentence is verifiable if it can be corroborated or\ndisproved by Wikipedia, and we find that the verifiability of generated text\nstrongly depends on the decoding strategy. In particular, we discover a\ntradeoff between factuality (i.e., the ability of generating Wikipedia\ncorroborated text) and repetitiveness. While decoding strategies such as top-k\nand nucleus sampling lead to less repetitive generations, they also produce\nless verifiable text. Based on these finding, we introduce a simple and\neffective decoding strategy which, in comparison to previously used decoding\nstrategies, produces less repetitive and more verifiable text.", "published": "2019-11-09 00:16:03", "link": "http://arxiv.org/abs/1911.03587v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Zero-Shot Paraphrase Generation with Multilingual Language Models", "abstract": "Leveraging multilingual parallel texts to automatically generate paraphrases\nhas drawn much attention as size of high-quality paraphrase corpus is limited.\nRound-trip translation, also known as the pivoting method, is a typical\napproach to this end. However, we notice that the pivoting process involves\nmultiple machine translation models and is likely to incur semantic drift\nduring the two-step translations. In this paper, inspired by the\nTransformer-based language models, we propose a simple and unified paraphrasing\nmodel, which is purely trained on multilingual parallel data and can conduct\nzero-shot paraphrase generation in one step. Compared with the pivoting\napproach, paraphrases generated by our model is more semantically similar to\nthe input sentence. Moreover, since our model shares the same architecture as\nGPT (Radford et al., 2018), we are able to pre-train the model on large-scale\nunparallel corpus, which further improves the fluency of the output sentences.\nIn addition, we introduce the mechanism of denoising auto-encoder (DAE) to\nimprove diversity and robustness of the model. Experimental results show that\nour model surpasses the pivoting method in terms of relevance, diversity,\nfluency and efficiency.", "published": "2019-11-09 02:49:31", "link": "http://arxiv.org/abs/1911.03597v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Table-to-Text Natural Language Generation with Unseen Schemas", "abstract": "Traditional table-to-text natural language generation (NLG) tasks focus on\ngenerating text from schemas that are already seen in the training set. This\nlimitation curbs their generalizabilities towards real-world scenarios, where\nthe schemas of input tables are potentially infinite. In this paper, we propose\nthe new task of table-to-text NLG with unseen schemas, which specifically aims\nto test the generalization of NLG for input tables with attribute types that\nnever appear during training. To do this, we construct a new benchmark dataset\nfor this task. To deal with the problem of unseen attribute types, we propose a\nnew model that first aligns unseen table schemas to seen ones, and then\ngenerates text with updated table representations. Experimental evaluation on\nthe new benchmark demonstrates that our model outperforms baseline methods by a\nlarge margin. In addition, comparison with standard data-to-text settings shows\nthe challenges and uniqueness of our proposed task.", "published": "2019-11-09 03:18:02", "link": "http://arxiv.org/abs/1911.03601v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Copy for Automatic Post-Editing", "abstract": "Automatic post-editing (APE), which aims to correct errors in the output of\nmachine translation systems in a post-processing step, is an important task in\nnatural language processing. While recent work has achieved considerable\nperformance gains by using neural networks, how to model the copying mechanism\nfor APE remains a challenge. In this work, we propose a new method for modeling\ncopying for APE. To better identify translation errors, our method learns the\nrepresentations of source sentences and system outputs in an interactive way.\nThese representations are used to explicitly indicate which words in the system\noutputs should be copied, which is useful to help CopyNet (Gu et al., 2016)\nbetter generate post-edited translations. Experiments on the datasets of the\nWMT 2016-2017 APE shared tasks show that our approach outperforms all best\npublished results.", "published": "2019-11-09 06:58:29", "link": "http://arxiv.org/abs/1911.03627v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Graph Network for Multi-hop Question Answering", "abstract": "In this paper, we present Hierarchical Graph Network (HGN) for multi-hop\nquestion answering. To aggregate clues from scattered texts across multiple\nparagraphs, a hierarchical graph is created by constructing nodes on different\nlevels of granularity (questions, paragraphs, sentences, entities), the\nrepresentations of which are initialized with pre-trained contextual encoders.\nGiven this hierarchical graph, the initial node representations are updated\nthrough graph propagation, and multi-hop reasoning is performed via traversing\nthrough the graph edges for each subsequent sub-task (e.g., paragraph\nselection, supporting facts extraction, answer prediction). By weaving\nheterogeneous nodes into an integral unified graph, this hierarchical\ndifferentiation of node granularity enables HGN to support different question\nanswering sub-tasks simultaneously. Experiments on the HotpotQA benchmark\ndemonstrate that the proposed model achieves new state of the art,\noutperforming existing multi-hop QA approaches.", "published": "2019-11-09 07:18:47", "link": "http://arxiv.org/abs/1911.03631v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hate Speech Detection on Vietnamese Social Media Text using the\n  Bi-GRU-LSTM-CNN Model", "abstract": "In recent years, Hate Speech Detection has become one of the interesting\nfields in natural language processing or computational linguistics. In this\npaper, we present the description of our system to solve this problem at the\nVLSP shared task 2019: Hate Speech Detection on Social Networks with the corpus\nwhich contains 20,345 human-labeled comments/posts for training and 5,086 for\npublic-testing. We implement a deep learning method based on the\nBi-GRU-LSTM-CNN classifier into this task. Our result in this task is 70.576%\nof F1-score, ranking the 5th of performance on public-test set.", "published": "2019-11-09 09:12:58", "link": "http://arxiv.org/abs/1911.03644v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Perspective Inferrer: Reasoning Sentences Relationship from\n  Holistic Perspective", "abstract": "Natural Language Inference (NLI) aims to determine the logic relationships\n(i.e., entailment, neutral and contradiction) between a pair of premise and\nhypothesis. Recently, the alignment mechanism effectively helps NLI by\ncapturing the aligned parts (i.e., the similar segments) in the sentence pairs,\nwhich imply the perspective of entailment and contradiction. However, these\naligned parts will sometimes mislead the judgment of neutral relations.\nIntuitively, NLI should rely more on multiple perspectives to form a holistic\nview to eliminate bias. In this paper, we propose the Multi-Perspective\nInferrer (MPI), a novel NLI model that reasons relationships from multiple\nperspectives associated with the three relationships. The MPI determines the\nperspectives of different parts of the sentences via a routing-by-agreement\npolicy and makes the final decision from a holistic view. Additionally, we\nintroduce an auxiliary supervised signal to ensure the MPI to learn the\nexpected perspectives. Experiments on SNLI and MultiNLI show that 1) the MPI\nachieves substantial improvements on the base model, which verifies the\nmotivation of multi-perspective inference; 2) visualized evidence verifies that\nthe MPI learns highly interpretable perspectives as expected; 3) more\nimportantly, the MPI is architecture-free and compatible with the powerful\nBERT.", "published": "2019-11-09 11:21:48", "link": "http://arxiv.org/abs/1911.03668v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "E-BERT: Efficient-Yet-Effective Entity Embeddings for BERT", "abstract": "We present a novel way of injecting factual knowledge about entities into the\npretrained BERT model (Devlin et al., 2019): We align Wikipedia2Vec entity\nvectors (Yamada et al., 2016) with BERT's native wordpiece vector space and use\nthe aligned entity vectors as if they were wordpiece vectors. The resulting\nentity-enhanced version of BERT (called E-BERT) is similar in spirit to ERNIE\n(Zhang et al., 2019) and KnowBert (Peters et al., 2019), but it requires no\nexpensive further pretraining of the BERT encoder. We evaluate E-BERT on\nunsupervised question answering (QA), supervised relation classification (RC)\nand entity linking (EL). On all three tasks, E-BERT outperforms BERT and other\nbaselines. We also show quantitatively that the original BERT model is overly\nreliant on the surface form of entity names (e.g., guessing that someone with\nan Italian-sounding name speaks Italian), and that E-BERT mitigates this\nproblem.", "published": "2019-11-09 13:08:25", "link": "http://arxiv.org/abs/1911.03681v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ConveRT: Efficient and Accurate Conversational Representations from\n  Transformers", "abstract": "General-purpose pretrained sentence encoders such as BERT are not ideal for\nreal-world conversational AI applications; they are computationally heavy,\nslow, and expensive to train. We propose ConveRT (Conversational\nRepresentations from Transformers), a pretraining framework for conversational\ntasks satisfying all the following requirements: it is effective, affordable,\nand quick to train. We pretrain using a retrieval-based response selection\ntask, effectively leveraging quantization and subword-level parameterization in\nthe dual encoder to build a lightweight memory- and energy-efficient model. We\nshow that ConveRT achieves state-of-the-art performance across widely\nestablished response selection tasks. We also demonstrate that the use of\nextended dialog history as context yields further performance gains. Finally,\nwe show that pretrained representations from the proposed encoder can be\ntransferred to the intent classification task, yielding strong results across\nthree diverse data sets. ConveRT trains substantially faster than standard\nsentence encoders or previous state-of-the-art dual encoders. With its reduced\nsize and superior performance, we believe this model promises wider portability\nand scalability for Conversational AI applications.", "published": "2019-11-09 13:35:18", "link": "http://arxiv.org/abs/1911.03688v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentence Meta-Embeddings for Unsupervised Semantic Textual Similarity", "abstract": "We address the task of unsupervised Semantic Textual Similarity (STS) by\nensembling diverse pre-trained sentence encoders into sentence meta-embeddings.\nWe apply, extend and evaluate different meta-embedding methods from the word\nembedding literature at the sentence level, including dimensionality reduction\n(Yin and Sch\\\"utze, 2016), generalized Canonical Correlation Analysis (Rastogi\net al., 2015) and cross-view auto-encoders (Bollegala and Bao, 2018). Our\nsentence meta-embeddings set a new unsupervised State of The Art (SoTA) on the\nSTS Benchmark and on the STS12-STS16 datasets, with gains of between 3.7% and\n6.4% Pearson's r over single-source systems.", "published": "2019-11-09 14:31:03", "link": "http://arxiv.org/abs/1911.03700v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Error Analysis for Vietnamese Dependency Parsing", "abstract": "Dependency parsing is needed in different applications of natural language\nprocessing. In this paper, we present a thorough error analysis for dependency\nparsing for the Vietnamese language, using two state-of-the-art parsers:\nMSTParser and MaltParser. The error analysis results provide us insights in\norder to improve the performance of dependency parsing for the Vietnamese\nlanguage.", "published": "2019-11-09 16:00:26", "link": "http://arxiv.org/abs/1911.03724v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Vietnamese transition-based dependency parsing with supertag features", "abstract": "In recent years, dependency parsing is a fascinating research topic and has a\nlot of applications in natural language processing. In this paper, we present\nan effective approach to improve dependency parsing by utilizing supertag\nfeatures. We performed experiments with the transition-based dependency parsing\napproach because it can take advantage of rich features. Empirical evaluation\non Vietnamese Dependency Treebank showed that, we achieved an improvement of\n18.92% in labeled attachment score with gold supertags and an improvement of\n3.57% with automatic supertags.", "published": "2019-11-09 16:07:38", "link": "http://arxiv.org/abs/1911.03726v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Multi-Sentence Argument Linking", "abstract": "We present a novel document-level model for finding argument spans that fill\nan event's roles, connecting related ideas in sentence-level semantic role\nlabeling and coreference resolution. Because existing datasets for\ncross-sentence linking are small, development of our neural model is supported\nthrough the creation of a new resource, Roles Across Multiple Sentences (RAMS),\nwhich contains 9,124 annotated events across 139 types. We demonstrate strong\nperformance of our model on RAMS and other event-related datasets.", "published": "2019-11-09 20:00:03", "link": "http://arxiv.org/abs/1911.03766v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code-Mixed to Monolingual Translation Framework", "abstract": "The use of multilingualism in the new generation is widespread in the form of\ncode-mixed data on social media, and therefore a robust translation system is\nrequired for catering to the monolingual users, as well as for easier\ncomprehension by language processing models. In this work, we present a\ntranslation framework that uses a translation-transliteration strategy for\ntranslating code-mixed data into their equivalent monolingual instances. For\nconverting the output to a more fluent form, it is reordered using a target\nlanguage model. The most important advantage of the proposed framework is that\nit does not require a code-mixed to monolingual parallel corpus at any point.\nOn testing the framework, it achieved BLEU and TER scores of 16.47 and 55.45,\nrespectively. Since the proposed framework deals with various sub-modules, we\ndive deeper into the importance of each of them, analyze the errors and\nfinally, discuss some improvement strategies.", "published": "2019-11-09 20:41:54", "link": "http://arxiv.org/abs/1911.03772v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Subjective Sentiment Analysis for Arabic Newswire Comments", "abstract": "This paper presents an approach based on supervised machine learning methods\nto discriminate between positive, negative and neutral Arabic reviews in online\nnewswire. The corpus is labeled for subjectivity and sentiment analysis (SSA)\nat the sentence-level. The model uses both count and TF-IDF representations and\napply six machine learning algorithms; Multinomial Naive Bayes, Support Vector\nMachines (SVM), Random Forest, Logistic Regression, Multi-layer perceptron and\nk-nearest neighbors using uni-grams, bi-grams features. With the goal of\nextracting users sentiment from written text. Experimental results showed that\nn-gram features could substantially improve performance; and showed that the\nMultinomial Naive Bayes approach is the most accurate in predicting topic\npolarity. Best results were achieved using count vectors trained by combination\nof word-based uni-grams and bi-grams with an overall accuracy of 85.57% over\ntwo classes and 65.64% over three classes.", "published": "2019-11-09 20:59:40", "link": "http://arxiv.org/abs/1911.03776v1", "categories": ["cs.CL", "H.3.1; I.2.7; I.7"], "primary_category": "cs.CL"}
{"title": "PoD: Positional Dependency-Based Word Embedding for Aspect Term\n  Extraction", "abstract": "Dependency context-based word embedding jointly learns the representations of\nword and dependency context, and has been proved effective in aspect term\nextraction. In this paper, we design the positional dependency-based word\nembedding (PoD) which considers both dependency context and positional context\nfor aspect term extraction. Specifically, the positional context is modeled via\nrelative position encoding. Besides, we enhance the dependency context by\nintegrating more lexical information (e.g., POS tags) along dependency paths.\nExperiments on SemEval 2014/2015/2016 datasets show that our approach\noutperforms other embedding methods in aspect term extraction.", "published": "2019-11-09 22:06:39", "link": "http://arxiv.org/abs/1911.03785v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MKD: a Multi-Task Knowledge Distillation Approach for Pretrained\n  Language Models", "abstract": "Pretrained language models have led to significant performance gains in many\nNLP tasks. However, the intensive computing resources to train such models\nremain an issue. Knowledge distillation alleviates this problem by learning a\nlight-weight student model. So far the distillation approaches are all\ntask-specific. In this paper, we explore knowledge distillation under the\nmulti-task learning setting. The student is jointly distilled across different\ntasks. It acquires more general representation capacity through multi-tasking\ndistillation and can be further fine-tuned to improve the model in the target\ndomain. Unlike other BERT distillation methods which specifically designed for\nTransformer-based architectures, we provide a general learning framework. Our\napproach is model agnostic and can be easily applied on different future\nteacher model architectures. We evaluate our approach on a Transformer-based\nand LSTM based student model. Compared to a strong, similarly LSTM-based\napproach, we achieve better quality under the same computational constraints.\nCompared to the present state of the art, we reach comparable results with much\nfaster inference speed.", "published": "2019-11-09 00:22:05", "link": "http://arxiv.org/abs/1911.03588v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Hate Speech Detection on Vietnamese Social Media Text using the\n  Bidirectional-LSTM Model", "abstract": "In this paper, we describe our system which participates in the shared task\nof Hate Speech Detection on Social Networks of VLSP 2019 evaluation campaign.\nWe are provided with the pre-labeled dataset and an unlabeled dataset for\nsocial media comments or posts. Our mission is to pre-process and build machine\nlearning models to classify comments/posts. In this report, we use\nBidirectional Long Short-Term Memory to build the model that can predict labels\nfor social media text according to Clean, Offensive, Hate. With this system, we\nachieve comparative results with 71.43% on the public standard test set of VLSP\n2019.", "published": "2019-11-09 09:33:42", "link": "http://arxiv.org/abs/1911.03648v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Reinforced Generation of Adversarial Examples for Neural Machine\n  Translation", "abstract": "Neural machine translation systems tend to fail on less decent inputs despite\nits significant efficacy, which may significantly harm the credibility of this\nsystems-fathoming how and when neural-based systems fail in such cases is\ncritical for industrial maintenance. Instead of collecting and analyzing bad\ncases using limited handcrafted error features, here we investigate this issue\nby generating adversarial examples via a new paradigm based on reinforcement\nlearning. Our paradigm could expose pitfalls for a given performance metric,\ne.g., BLEU, and could target any given neural machine translation architecture.\nWe conduct experiments of adversarial attacks on two mainstream neural machine\ntranslation architectures, RNN-search, and Transformer. The results show that\nour method efficiently produces stable attacks with meaning-preserving\nadversarial examples. We also present a qualitative and quantitative analysis\nfor the preference pattern of the attack, demonstrating its capability of\npitfall exposure.", "published": "2019-11-09 12:33:47", "link": "http://arxiv.org/abs/1911.03677v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Bootstrapping Disjoint Datasets for Multilingual Multimodal\n  Representation Learning", "abstract": "Recent work has highlighted the advantage of jointly learning grounded\nsentence representations from multiple languages. However, the data used in\nthese studies has been limited to an aligned scenario: the same images\nannotated with sentences in multiple languages. We focus on the more realistic\ndisjoint scenario in which there is no overlap between the images in\nmultilingual image--caption datasets. We confirm that training with aligned\ndata results in better grounded sentence representations than training with\ndisjoint data, as measured by image--sentence retrieval performance. In order\nto close this gap in performance, we propose a pseudopairing method to generate\nsynthetically aligned English--German--image triplets from the disjoint sets.\nThe method works by first training a model on the disjoint data, and then\ncreating new triples across datasets using sentence similarity under the\nlearned model. Experiments show that pseudopairs improve image--sentence\nretrieval performance compared to disjoint training, despite requiring no\nexternal data or models. However, we do find that using an external machine\ntranslation model to generate the synthetic data sets results in better\nperformance.", "published": "2019-11-09 12:34:01", "link": "http://arxiv.org/abs/1911.03678v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "On Architectures for Including Visual Information in Neural Language\n  Models for Image Description", "abstract": "A neural language model can be conditioned into generating descriptions for\nimages by providing visual information apart from the sentence prefix. This\nvisual information can be included into the language model through different\npoints of entry resulting in different neural architectures. We identify four\nmain architectures which we call init-inject, pre-inject, par-inject, and\nmerge.\n  We analyse these four architectures and conclude that the best performing one\nis init-inject, which is when the visual information is injected into the\ninitial state of the recurrent neural network. We confirm this using both\nautomatic evaluation measures and human annotation.\n  We then analyse how much influence the images have on each architecture. This\nis done by measuring how different the output probabilities of a model are when\na partial sentence is combined with a completely different image from the one\nit is meant to be combined with. We find that init-inject tends to quickly\nbecome less influenced by the image as more words are generated. A different\narchitecture called merge, which is when the visual information is merged with\nthe recurrent neural network's hidden state vector prior to output, loses\nvisual influence much more slowly, suggesting that it would work better for\ngenerating longer sentences.\n  We also observe that the merge architecture can have its recurrent neural\nnetwork pre-trained in a text-only language model (transfer learning) rather\nthan be initialised randomly as usual. This results in even better performance\nthan the other architectures, provided that the source language model is not\ntoo good at language modelling or it will overspecialise and be less effective\nat image description generation.\n  Our work opens up new avenues of research in neural architectures,\nexplainable AI, and transfer learning.", "published": "2019-11-09 17:07:23", "link": "http://arxiv.org/abs/1911.03738v1", "categories": ["cs.NE", "cs.CL"], "primary_category": "cs.NE"}
{"title": "The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded\n  Conversational Agents", "abstract": "We introduce dodecaDialogue: a set of 12 tasks that measures if a\nconversational agent can communicate engagingly with personality and empathy,\nask questions, answer questions by utilizing knowledge resources, discuss\ntopics and situations, and perceive and converse about images. By multi-tasking\non such a broad large-scale set of data, we hope to both move towards and\nmeasure progress in producing a single unified agent that can perceive, reason\nand converse with humans in an open-domain setting. We show that such\nmulti-tasking improves over a BERT pre-trained baseline, largely due to\nmulti-tasking with very large dialogue datasets in a similar domain, and that\nthe multi-tasking in general provides gains to both text and image-based tasks\nusing several metrics in both the fine-tune and task transfer settings. We\nobtain state-of-the-art results on many of the tasks, providing a strong\nbaseline for this challenge.", "published": "2019-11-09 20:05:06", "link": "http://arxiv.org/abs/1911.03768v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enforcing Encoder-Decoder Modularity in Sequence-to-Sequence Models", "abstract": "Inspired by modular software design principles of independence,\ninterchangeability, and clarity of interface, we introduce a method for\nenforcing encoder-decoder modularity in seq2seq models without sacrificing the\noverall model quality or its full differentiability. We discretize the encoder\noutput units into a predefined interpretable vocabulary space using the\nConnectionist Temporal Classification (CTC) loss. Our modular systems achieve\nnear SOTA performance on the 300h Switchboard benchmark, with WER of 8.3% and\n17.6% on the SWB and CH subsets, using seq2seq models with encoder and decoder\nmodules which are independent and interchangeable.", "published": "2019-11-09 21:36:28", "link": "http://arxiv.org/abs/1911.03782v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Interactive Classification by Asking Informative Questions", "abstract": "We study the potential for interaction in natural language classification. We\nadd a limited form of interaction for intent classification, where users\nprovide an initial query using natural language, and the system asks for\nadditional information using binary or multi-choice questions. At each turn,\nour system decides between asking the most informative question or making the\nfinal classification prediction.The simplicity of the model allows for\nbootstrapping of the system without interaction data, instead relying on simple\ncrowdsourcing tasks. We evaluate our approach on two domains, showing the\nbenefit of interaction and the advantage of learning to balance between asking\nadditional questions and making the final prediction.", "published": "2019-11-09 03:05:50", "link": "http://arxiv.org/abs/1911.03598v2", "categories": ["cs.CL", "cs.HC", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Simplified Fully Quantized Transformer for End-to-end Speech\n  Recognition", "abstract": "While significant improvements have been made in recent years in terms of\nend-to-end automatic speech recognition (ASR) performance, such improvements\nwere obtained through the use of very large neural networks, unfit for embedded\nuse on edge devices. That being said, in this paper, we work on simplifying and\ncompressing Transformer-based encoder-decoder architectures for the end-to-end\nASR task. We empirically introduce a more compact Speech-Transformer by\ninvestigating the impact of discarding particular modules on the performance of\nthe model. Moreover, we evaluate reducing the numerical precision of our\nnetwork's weights and activations while maintaining the performance of the\nfull-precision model. Our experiments show that we can reduce the number of\nparameters of the full-precision model and then further compress the model 4x\nby fully quantizing to 8-bit fixed point precision.", "published": "2019-11-09 03:29:06", "link": "http://arxiv.org/abs/1911.03604v4", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Improving Machine Reading Comprehension via Adversarial Training", "abstract": "Adversarial training (AT) as a regularization method has proved its\neffectiveness in various tasks, such as image classification and text\nclassification. Though there are successful applications of AT in many tasks of\nnatural language processing (NLP), the mechanism behind it is still unclear. In\nthis paper, we aim to apply AT on machine reading comprehension (MRC) and study\nits effects from multiple perspectives. We experiment with three different\nkinds of RC tasks: span-based RC, span-based RC with unanswerable questions and\nmulti-choice RC. The experimental results show that the proposed method can\nimprove the performance significantly and universally on SQuAD1.1, SQuAD2.0 and\nRACE. With virtual adversarial training (VAT), we explore the possibility of\nimproving the RC models with semi-supervised learning and prove that examples\nfrom a different task are also beneficial. We also find that AT helps little in\ndefending against artificial adversarial examples, but AT helps the model to\nlearn better on examples that contain more low-frequency words.", "published": "2019-11-09 05:31:40", "link": "http://arxiv.org/abs/1911.03614v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Beyond Statistical Relations: Integrating Knowledge Relations into Style\n  Correlations for Multi-Label Music Style Classification", "abstract": "Automatically labeling multiple styles for every song is a comprehensive\napplication in all kinds of music websites. Recently, some researches explore\nreview-driven multi-label music style classification and exploit style\ncorrelations for this task. However, their methods focus on mining the\nstatistical relations between different music styles and only consider shallow\nstyle relations. Moreover, these statistical relations suffer from the\nunderfitting problem because some music styles have little training data.\n  To tackle these problems, we propose a novel knowledge relations integrated\nframework (KRF) to capture the complete style correlations, which jointly\nexploits the inherent relations between music styles according to external\nknowledge and their statistical relations. Based on the two types of relations,\nwe use a graph convolutional network to learn the deep correlations between\nstyles automatically. Experimental results show that our framework\nsignificantly outperforms state-of-the-art methods. Further studies demonstrate\nthat our framework can effectively alleviate the underfitting problem and learn\nmeaningful style correlations. The source code can be available at\nhttps://github.com/Makwen1995/MusicGenre.", "published": "2019-11-09 06:55:39", "link": "http://arxiv.org/abs/1911.03626v2", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Towards Understanding Gender Bias in Relation Extraction", "abstract": "Recent developments in Neural Relation Extraction (NRE) have made significant\nstrides towards Automated Knowledge Base Construction (AKBC). While much\nattention has been dedicated towards improvements in accuracy, there have been\nno attempts in the literature to our knowledge to evaluate social biases in NRE\nsystems. We create WikiGenderBias, a distantly supervised dataset with a human\nannotated test set. WikiGenderBias has sentences specifically curated to\nanalyze gender bias in relation extraction systems. We use WikiGenderBias to\nevaluate systems for bias and find that NRE systems exhibit gender biased\npredictions and lay groundwork for future evaluation of bias in NRE. We also\nanalyze how name anonymization, hard debiasing for word embeddings, and\ncounterfactual data augmentation affect gender bias in predictions and\nperformance.", "published": "2019-11-09 08:43:02", "link": "http://arxiv.org/abs/1911.03642v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Style is NOT a single variable: Case Studies for Cross-Style Language\n  Understanding", "abstract": "Every natural text is written in some style. Style is formed by a complex\ncombination of different stylistic factors, including formality markers,\nemotions, metaphors, etc. One cannot form a complete understanding of a text\nwithout considering these factors. The factors combine and co-vary in complex\nways to form styles. Studying the nature of the co-varying combinations sheds\nlight on stylistic language in general, sometimes called cross-style language\nunderstanding. This paper provides the benchmark corpus (xSLUE) that combines\nexisting datasets and collects a new one for sentence-level cross-style\nlanguage understanding and evaluation. The benchmark contains text in 15\ndifferent styles under the proposed four theoretical groupings: figurative,\npersonal, affective, and interpersonal groups. For valid evaluation, we collect\nan additional diagnostic set by annotating all 15 styles on the same text.\nUsing xSLUE, we propose three interesting cross-style applications in\nclassification, correlation, and generation. First, our proposed cross-style\nclassifier trained with multiple styles together helps improve overall\nclassification performance against individually-trained style classifiers.\nSecond, our study shows that some styles are highly dependent on each other in\nhuman-written text. Finally, we find that combinations of some contradictive\nstyles likely generate stylistically less appropriate text. We believe our\nbenchmark and case studies help explore interesting future directions for\ncross-style research. The preprocessed datasets and code are publicly\navailable.", "published": "2019-11-09 10:55:34", "link": "http://arxiv.org/abs/1911.03663v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Conditioned Query Generation for Task-Oriented Dialogue Systems", "abstract": "Scarcity of training data for task-oriented dialogue systems is a well known\nproblem that is usually tackled with costly and time-consuming manual data\nannotation. An alternative solution is to rely on automatic text generation\nwhich, although less accurate than human supervision, has the advantage of\nbeing cheap and fast. In this paper we propose a novel controlled data\ngeneration method that could be used as a training augmentation framework for\nclosed-domain dialogue. Our contribution is twofold. First we show how to\noptimally train and control the generation of intent-specific sentences using a\nconditional variational autoencoder. Then we introduce a novel protocol called\nquery transfer that allows to leverage a broad, unlabelled dataset to extract\nrelevant information. Comparison with two different baselines shows that our\nmethod, in the appropriate regime, consistently improves the diversity of the\ngenerated queries without compromising their quality.", "published": "2019-11-09 14:22:57", "link": "http://arxiv.org/abs/1911.03698v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "CommonGen: A Constrained Text Generation Challenge for Generative\n  Commonsense Reasoning", "abstract": "Recently, large-scale pre-trained language models have demonstrated\nimpressive performance on several commonsense-reasoning benchmark datasets.\nHowever, building machines with commonsense to compose realistically plausible\nsentences remains challenging. In this paper, we present a constrained text\ngeneration task, CommonGen associated with a benchmark dataset, to explicitly\ntest machines for the ability of generative commonsense reasoning. Given a set\nof common concepts (e.g., {dog, frisbee, catch, throw}); the task is to\ngenerate a coherent sentence describing an everyday scenario using these\nconcepts (e.g., \"a man throws a frisbee and his dog catches it\").\n  The CommonGen task is challenging because it inherently requires 1)\nrelational reasoning with background commonsense knowledge, and 2)\ncompositional generalization ability to work on unseen concept combinations.\nOur dataset, constructed through a combination of crowdsourced and existing\ncaption corpora, consists of 79k commonsense descriptions over 35k unique\nconcept-sets. Experiments show that there is a large gap between\nstate-of-the-art text generation models (e.g., T5) and human performance.\nFurthermore, we demonstrate that the learned generative commonsense reasoning\ncapability can be transferred to improve downstream tasks such as CommonsenseQA\nby generating additional context.", "published": "2019-11-09 14:53:59", "link": "http://arxiv.org/abs/1911.03705v4", "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "cs.CL"}
{"title": "A perspective on multi-agent communication for information fusion", "abstract": "Collaborative decision making in multi-agent systems typically requires a\npredefined communication protocol among agents. Usually, agent-level\nobservations are locally processed and information is exchanged using the\npredefined protocol, enabling the team to perform more efficiently than each\nagent operating in isolation. In this work, we consider the situation where\nagents, with complementary sensing modalities must co-operate to achieve a\ncommon goal/task by learning an efficient communication protocol. We frame the\nproblem within an actor-critic scheme, where the agents learn optimal policies\nin a centralized fashion, while taking action in a distributed manner. We\nprovide an interpretation of the emergent communication between the agents. We\nobserve that the information exchanged is not just an encoding of the raw\nsensor data but is, rather, a specific set of directive actions that depend on\nthe overall task. Simulation results demonstrate the interpretability of the\nlearnt communication in a variety of tasks.", "published": "2019-11-09 17:56:47", "link": "http://arxiv.org/abs/1911.03743v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.MA"}
{"title": "Speaker Adaptation for Attention-Based End-to-End Speech Recognition", "abstract": "We propose three regularization-based speaker adaptation approaches to adapt\nthe attention-based encoder-decoder (AED) model with very limited adaptation\ndata from target speakers for end-to-end automatic speech recognition. The\nfirst method is Kullback-Leibler divergence (KLD) regularization, in which the\noutput distribution of a speaker-dependent (SD) AED is forced to be close to\nthat of the speaker-independent (SI) model by adding a KLD regularization to\nthe adaptation criterion. To compensate for the asymmetric deficiency in KLD\nregularization, an adversarial speaker adaptation (ASA) method is proposed to\nregularize the deep-feature distribution of the SD AED through the adversarial\nlearning of an auxiliary discriminator and the SD AED. The third approach is\nthe multi-task learning, in which an SD AED is trained to jointly perform the\nprimary task of predicting a large number of output units and an auxiliary task\nof predicting a small number of output units to alleviate the target sparsity\nissue. Evaluated on a Microsoft short message dictation task, all three methods\nare highly effective in adapting the AED model, achieving up to 12.2% and 3.0%\nword error rate improvement over an SI AED trained from 3400 hours data for\nsupervised and unsupervised adaptation, respectively.", "published": "2019-11-09 19:41:50", "link": "http://arxiv.org/abs/1911.03762v1", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Orthogonal Relation Transforms with Graph Context Modeling for Knowledge\n  Graph Embedding", "abstract": "Translational distance-based knowledge graph embedding has shown progressive\nimprovements on the link prediction task, from TransE to the latest\nstate-of-the-art RotatE. However, N-1, 1-N and N-N predictions still remain\nchallenging. In this work, we propose a novel translational distance-based\napproach for knowledge graph link prediction. The proposed method includes\ntwo-folds, first we extend the RotatE from 2D complex domain to high dimension\nspace with orthogonal transforms to model relations for better modeling\ncapacity. Second, the graph context is explicitly modeled via two directed\ncontext representations. These context representations are used as part of the\ndistance scoring function to measure the plausibility of the triples during\ntraining and inference. The proposed approach effectively improves prediction\naccuracy on the difficult N-1, 1-N and N-N cases for knowledge graph link\nprediction task. The experimental results show that it achieves better\nperformance on two benchmark data sets compared to the baseline RotatE,\nespecially on data set (FB15k-237) with many high in-degree connection nodes.", "published": "2019-11-09 07:02:33", "link": "http://arxiv.org/abs/1911.04910v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "M3ER: Multiplicative Multimodal Emotion Recognition Using Facial,\n  Textual, and Speech Cues", "abstract": "We present M3ER, a learning-based method for emotion recognition from\nmultiple input modalities. Our approach combines cues from multiple\nco-occurring modalities (such as face, text, and speech) and also is more\nrobust than other methods to sensor noise in any of the individual modalities.\nM3ER models a novel, data-driven multiplicative fusion method to combine the\nmodalities, which learn to emphasize the more reliable cues and suppress others\non a per-sample basis. By introducing a check step which uses Canonical\nCorrelational Analysis to differentiate between ineffective and effective\nmodalities, M3ER is robust to sensor noise. M3ER also generates proxy features\nin place of the ineffectual modalities. We demonstrate the efficiency of our\nnetwork through experimentation on two benchmark datasets, IEMOCAP and\nCMU-MOSEI. We report a mean accuracy of 82.7% on IEMOCAP and 89.0% on\nCMU-MOSEI, which, collectively, is an improvement of about 5% over prior work.", "published": "2019-11-09 01:58:03", "link": "http://arxiv.org/abs/1911.05659v2", "categories": ["eess.SP", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "eess.SP"}
{"title": "Predictive Biases in Natural Language Processing Models: A Conceptual\n  Framework and Overview", "abstract": "An increasing number of works in natural language processing have addressed\nthe effect of bias on the predicted outcomes, introducing mitigation techniques\nthat act on different parts of the standard NLP pipeline (data and models).\nHowever, these works have been conducted in isolation, without a unifying\nframework to organize efforts within the field. This leads to repetitive\napproaches, and puts an undue focus on the effects of bias, rather than on\ntheir origins. Research focused on bias symptoms rather than the underlying\norigins could limit the development of effective countermeasures. In this\npaper, we propose a unifying conceptualization: the predictive bias framework\nfor NLP. We summarize the NLP literature and propose a general mathematical\ndefinition of predictive bias in NLP along with a conceptual framework,\ndifferentiating four main origins of biases: label bias, selection bias, model\noveramplification, and semantic bias. We discuss how past work has countered\neach bias origin. Our framework serves to guide an introductory overview of\npredictive bias in NLP, integrating existing work into a single structure and\nopening avenues for future research.", "published": "2019-11-09 23:53:19", "link": "http://arxiv.org/abs/1912.11078v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Speech Dereverberation and Noise Reduction for both diffusive noise\n  field and point noise source in Binaural Hearing Aids: Preliminary Version", "abstract": "The multichannel Wiener filter (MWF) and its variations have been extensively\napplied to binaural hearing aids. However, its major drawback is the distortion\nof the binaural cues of the residual noise, changing the original acoustic\nscenario, which is of paramount importance for hearing impaired people. The\nMWF-IC method was previously proposed for joint speech dereverberation and\nnoise reduction, preserving the interaural coherence (IC) of diffuse noise\nfields. In this work, we propose a new variation of the MWF-IC for both speech\ndereverberation and noise reduction, which preserves the original spatial\ncharacteristics of the residual noise for either diffuse fields or point\nsources. Objective measures and preliminary psychoacoustic experiments indicate\nthe proposed method is capable of perceptually preserving the original\nspatialization of both types of noise, without significant performance loss in\nboth speech dereverberation and noise reduction.", "published": "2019-11-09 18:28:05", "link": "http://arxiv.org/abs/1911.03750v1", "categories": ["eess.AS", "cs.SD", "14J60 (dereverberation, noise reduction, spacial preservation)\n  14F05, 14J26 (wiener filter, binaural hearing aids)"], "primary_category": "eess.AS"}
