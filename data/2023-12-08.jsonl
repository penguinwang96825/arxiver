{"title": "First Attempt at Building Parallel Corpora for Machine Translation of\n  Northeast India's Very Low-Resource Languages", "abstract": "This paper presents the creation of initial bilingual corpora for thirteen\nvery low-resource languages of India, all from Northeast India. It also\npresents the results of initial translation efforts in these languages. It\ncreates the first-ever parallel corpora for these languages and provides\ninitial benchmark neural machine translation results for these languages. We\nintend to extend these corpora to include a large number of low-resource Indian\nlanguages and integrate the effort with our prior work with African and\nAmerican-Indian languages to create corpora covering a large number of\nlanguages from across the world.", "published": "2023-12-08 00:28:41", "link": "http://arxiv.org/abs/2312.04764v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Determine the Most Powerful Pre-trained Language Model without\n  Brute Force Fine-tuning? An Empirical Survey", "abstract": "Transferability estimation has been attached to great attention in the\ncomputer vision fields. Researchers try to estimate with low computational cost\nthe performance of a model when transferred from a source task to a given\ntarget task. Considering the effectiveness of such estimations, the communities\nof natural language processing also began to study similar problems for the\nselection of pre-trained language models. However, there is a lack of a\ncomprehensive comparison between these estimation methods yet. Also, the\ndifferences between vision and language scenarios make it doubtful whether\nprevious conclusions can be established across fields. In this paper, we first\nconduct a thorough survey of existing transferability estimation methods being\nable to find the most suitable model, then we conduct a detailed empirical\nstudy for the surveyed methods based on the GLUE benchmark. From qualitative\nand quantitative analyses, we demonstrate the strengths and weaknesses of\nexisting methods and show that H-Score generally performs well with\nsuperiorities in effectiveness and efficiency. We also outline the difficulties\nof consideration of training details, applicability to text generation, and\nconsistency to certain metrics which shed light on future directions.", "published": "2023-12-08 01:17:28", "link": "http://arxiv.org/abs/2312.04775v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Neural Machine Translation by Multi-Knowledge Integration with\n  Prompting", "abstract": "Improving neural machine translation (NMT) systems with prompting has\nachieved significant progress in recent years. In this work, we focus on how to\nintegrate multi-knowledge, multiple types of knowledge, into NMT models to\nenhance the performance with prompting. We propose a unified framework, which\ncan integrate effectively multiple types of knowledge including sentences,\nterminologies/phrases and translation templates into NMT models. We utilize\nmultiple types of knowledge as prefix-prompts of input for the encoder and\ndecoder of NMT models to guide the translation process. The approach requires\nno changes to the model architecture and effectively adapts to domain-specific\ntranslation without retraining. The experiments on English-Chinese and\nEnglish-German translation demonstrate that our approach significantly\noutperform strong baselines, achieving high translation quality and terminology\nmatch accuracy.", "published": "2023-12-08 02:55:00", "link": "http://arxiv.org/abs/2312.04807v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ophtha-LLaMA2: A Large Language Model for Ophthalmology", "abstract": "In recent years, pre-trained large language models (LLMs) have achieved\ntremendous success in the field of Natural Language Processing (NLP). Prior\nstudies have primarily focused on general and generic domains, with relatively\nless research on specialized LLMs in the medical field. The specialization and\nhigh accuracy requirements for diagnosis in the medical field, as well as the\nchallenges in collecting large-scale data, have constrained the application and\ndevelopment of LLMs in medical scenarios. In the field of ophthalmology,\nclinical diagnosis mainly relies on doctors' interpretation of reports and\nmaking diagnostic decisions. In order to take advantage of LLMs to provide\ndecision support for doctors, we collected three modalities of ophthalmic\nreport data and fine-tuned the LLaMA2 model, successfully constructing an LLM\ntermed the \"Ophtha-LLaMA2\" specifically tailored for ophthalmic disease\ndiagnosis. Inference test results show that even with a smaller fine-tuning\ndataset, Ophtha-LLaMA2 performs significantly better in ophthalmic diagnosis\ncompared to other LLMs. It demonstrates that the Ophtha-LLaMA2 exhibits\nsatisfying accuracy and efficiency in ophthalmic disease diagnosis, making it a\nvaluable tool for ophthalmologists to provide improved diagnostic support for\npatients. This research provides a useful reference for the application of LLMs\nin the field of ophthalmology, while showcasing the immense potential and\nprospects in this domain.", "published": "2023-12-08 08:43:46", "link": "http://arxiv.org/abs/2312.04906v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Boosting Prompt-Based Self-Training With Mapping-Free Automatic\n  Verbalizer for Multi-Class Classification", "abstract": "Recently, prompt-based fine-tuning has garnered considerable interest as a\ncore technique for few-shot text classification task. This approach\nreformulates the fine-tuning objective to align with the Masked Language\nModeling (MLM) objective. Leveraging unlabeled data, prompt-based self-training\nhas shown greater effectiveness in binary and three-class classification.\nHowever, prompt-based self-training for multi-class classification has not been\nadequately investigated, despite its significant applicability to real-world\nscenarios. Moreover, extending current methods to multi-class classification\nsuffers from the verbalizer that extracts the predicted value of manually\npre-defined single label word for each class from MLM predictions.\nConsequently, we introduce a novel, efficient verbalizer structure, named\nMapping-free Automatic Verbalizer (MAV). Comprising two fully connected layers,\nMAV serves as a trainable verbalizer that automatically extracts the requisite\nword features for classification by capitalizing on all available information\nfrom MLM predictions. Experimental results on five multi-class classification\ndatasets indicate MAV's superior self-training efficacy.", "published": "2023-12-08 11:43:00", "link": "http://arxiv.org/abs/2312.04982v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Converting Epics/Stories into Pseudocode using Transformers", "abstract": "The conversion of user epics or stories into their appropriate representation\nin pseudocode or code is a time-consuming task, which can take up a large\nportion of the time in an industrial project. With this research paper, we aim\nto present a methodology to generate pseudocode from a given agile user story\nof small functionalities so as to reduce the overall time spent on the\nindustrial project. Pseudocode is a programming language agnostic\nrepresentation of the steps involved in a computer program, which can be easily\nconverted into any programming language. Leveraging the potential of Natural\nLanguage Processing, we want to simplify the development process in\norganizations that use the Agile Model of Software Development. We present a\nmethodology to convert a problem described in the English language into\npseudocode. This methodology divides the Text to Pseudocode conversion task\ninto two stages or subtasks, each of which is treated like an individual\nmachine translation task. Stage 1 is Text to Code Conversion and Stage 2 is\nCode to Pseudocode Conversion. We find that the CodeT5 model gives the best\nresults in terms of BLEU score when trained separately on the two subtasks\nmentioned above. BLEU score is a metric that is used to measure the similarity\nbetween a machine-translated text and a set of reference translations.", "published": "2023-12-08 14:01:09", "link": "http://arxiv.org/abs/2312.05047v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LaCour!: Enabling Research on Argumentation in Hearings of the European\n  Court of Human Rights", "abstract": "Why does an argument end up in the final court decision? Was it deliberated\nor questioned during the oral hearings? Was there something in the hearings\nthat triggered a particular judge to write a dissenting opinion? Despite the\navailability of the final judgments of the European Court of Human Rights\n(ECHR), none of these legal research questions can currently be answered as the\nECHR's multilingual oral hearings are not transcribed, structured, or\nspeaker-attributed. We address this fundamental gap by presenting LaCour!, the\nfirst corpus of textual oral arguments of the ECHR, consisting of 154 full\nhearings (2.1 million tokens from over 267 hours of video footage) in English,\nFrench, and other court languages, each linked to the corresponding final\njudgment documents. In addition to the transcribed and partially manually\ncorrected text from the video, we provide sentence-level timestamps and\nmanually annotated role and language labels. We also showcase LaCour! in a set\nof preliminary experiments that explore the interplay between questions and\ndissenting opinions. Apart from the use cases in legal NLP, we hope that law\nstudents or other interested parties will also use LaCour! as a learning\nresource, as it is freely available in various formats at\nhttps://huggingface.co/datasets/TrustHLT/LaCour.", "published": "2023-12-08 14:30:08", "link": "http://arxiv.org/abs/2312.05061v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Lengthy to Lucid: A Systematic Literature Review on NLP Techniques\n  for Taming Long Sentences", "abstract": "Long sentences have been a persistent issue in written communication for many\nyears since they make it challenging for readers to grasp the main points or\nfollow the initial intention of the writer. This survey, conducted using the\nPRISMA guidelines, systematically reviews two main strategies for addressing\nthe issue of long sentences: a) sentence compression and b) sentence splitting.\nAn increased trend of interest in this area has been observed since 2005, with\nsignificant growth after 2017. Current research is dominated by supervised\napproaches for both sentence compression and splitting. Yet, there is a\nconsiderable gap in weakly and self-supervised techniques, suggesting an\nopportunity for further research, especially in domains with limited data. In\nthis survey, we categorize and group the most representative methods into a\ncomprehensive taxonomy. We also conduct a comparative evaluation analysis of\nthese methods on common sentence compression and splitting datasets. Finally,\nwe discuss the challenges and limitations of current methods, providing\nvaluable insights for future research directions. This survey is meant to serve\nas a comprehensive resource for addressing the complexities of long sentences.\nWe aim to enable researchers to make further advancements in the field until\nlong sentences are no longer a barrier to effective communication.", "published": "2023-12-08 16:51:29", "link": "http://arxiv.org/abs/2312.05172v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "PathFinder: Guided Search over Multi-Step Reasoning Paths", "abstract": "With recent advancements in large language models, methods like\nchain-of-thought prompting to elicit reasoning chains have been shown to\nimprove results on reasoning tasks. However, tasks that require multiple steps\nof reasoning still pose significant challenges to state-of-the-art models.\nDrawing inspiration from the beam search algorithm, we propose PathFinder, a\ntree-search-based reasoning path generation approach. It enhances diverse\nbranching and multi-hop reasoning through the integration of dynamic decoding,\nenabled by varying sampling methods and parameters. Using constrained\nreasoning, PathFinder integrates novel quality constraints, pruning, and\nexploration methods to enhance the efficiency and the quality of generation.\nMoreover, it includes scoring and ranking features to improve candidate\nselection. Our approach outperforms competitive baselines on three complex\narithmetic and commonsense reasoning tasks by 6% on average. Our model\ngeneralizes well to longer, unseen reasoning chains, reflecting similar\ncomplexities to beam search with large branching factors.", "published": "2023-12-08 17:05:47", "link": "http://arxiv.org/abs/2312.05180v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "DelucionQA: Detecting Hallucinations in Domain-specific Question\n  Answering", "abstract": "Hallucination is a well-known phenomenon in text generated by large language\nmodels (LLMs). The existence of hallucinatory responses is found in almost all\napplication scenarios e.g., summarization, question-answering (QA) etc. For\napplications requiring high reliability (e.g., customer-facing assistants), the\npotential existence of hallucination in LLM-generated text is a critical\nproblem. The amount of hallucination can be reduced by leveraging information\nretrieval to provide relevant background information to the LLM. However, LLMs\ncan still generate hallucinatory content for various reasons (e.g.,\nprioritizing its parametric knowledge over the context, failure to capture the\nrelevant information from the context, etc.). Detecting hallucinations through\nautomated methods is thus paramount. To facilitate research in this direction,\nwe introduce a sophisticated dataset, DelucionQA, that captures hallucinations\nmade by retrieval-augmented LLMs for a domain-specific QA task. Furthermore, we\npropose a set of hallucination detection methods to serve as baselines for\nfuture works from the research community. Analysis and case study are also\nprovided to share valuable insights on hallucination phenomena in the target\nscenario.", "published": "2023-12-08 17:41:06", "link": "http://arxiv.org/abs/2312.05200v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lyrics: Boosting Fine-grained Language-Vision Alignment and\n  Comprehension via Semantic-aware Visual Objects", "abstract": "Large Vision Language Models (LVLMs) have demonstrated impressive zero-shot\ncapabilities in various vision-language dialogue scenarios. However, the\nabsence of fine-grained visual object detection hinders the model from\nunderstanding the details of images, leading to irreparable visual\nhallucinations and factual errors. In this paper, we propose Lyrics, a novel\nmulti-modal pre-training and instruction fine-tuning paradigm that bootstraps\nvision-language alignment from fine-grained cross-modal collaboration. Building\non the foundation of BLIP-2, Lyrics infuses local visual features extracted\nfrom a visual refiner that includes image tagging, object detection and\nsemantic segmentation modules into the Querying Transformer, while on the text\nside, the language inputs equip the boundary boxes and tags derived from the\nvisual refiner. We further introduce a two-stage training scheme, in which the\npre-training stage bridges the modality gap through explicit and comprehensive\nvision-language alignment targets. During the instruction fine-tuning stage, we\nintroduce semantic-aware visual feature extraction, a crucial method that\nenables the model to extract informative features from concrete visual objects.\nOur approach achieves robust performance on 13 datasets across various\nvision-language tasks, and demonstrates promising multi-modal understanding,\nperception and conversation capabilities in 11 scenario-based benchmark\ntoolkits.", "published": "2023-12-08 09:02:45", "link": "http://arxiv.org/abs/2312.05278v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Controlled Table-to-Text Generation with Scientific Reasoning", "abstract": "The sheer volume of scientific experimental results and complex technical\nstatements, often presented in tabular formats, presents a formidable barrier\nto individuals acquiring preferred information. The realms of scientific\nreasoning and content generation that adhere to user preferences encounter\ndistinct challenges. In this work, we present a new task for generating fluent\nand logical descriptions that match user preferences over scientific tabular\ndata, aiming to automate scientific document analysis. To facilitate research\nin this direction, we construct a new challenging dataset CTRLSciTab consisting\nof table-description pairs extracted from the scientific literature, with\nhighlighted cells and corresponding domain-specific knowledge base. We\nevaluated popular pre-trained language models to establish a baseline and\nproposed a novel architecture outperforming competing approaches. The results\nshowed that large models struggle to produce accurate content that aligns with\nuser preferences. As the first of its kind, our work should motivate further\nresearch in scientific domains.", "published": "2023-12-08 22:57:35", "link": "http://arxiv.org/abs/2312.05402v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Partial Rewriting for Multi-Stage ASR", "abstract": "For many streaming automatic speech recognition tasks, it is important to\nprovide timely intermediate streaming results, while refining a high quality\nfinal result. This can be done using a multi-stage architecture, where a small\nleft-context only model creates streaming results and a larger left- and\nright-context model produces a final result at the end. While this\nsignificantly improves the quality of the final results without compromising\nthe streaming emission latency of the system, streaming results do not benefit\nfrom the quality improvements. Here, we propose using a text manipulation\nalgorithm that merges the streaming outputs of both models. We improve the\nquality of streaming results by around 10%, without altering the final results.\nOur approach introduces no additional latency and reduces flickering. It is\nalso lightweight, does not require retraining the model, and it can be applied\nto a wide variety of multi-stage architectures.", "published": "2023-12-08 00:31:43", "link": "http://arxiv.org/abs/2312.09463v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hate Cannot Drive out Hate: Forecasting Conversation Incivility\n  following Replies to Hate Speech", "abstract": "User-generated replies to hate speech are promising means to combat hatred,\nbut questions about whether they can stop incivility in follow-up conversations\nlinger. We argue that effective replies stop incivility from emerging in\nfollow-up conversations - replies that elicit more incivility are\ncounterproductive. This study introduces the task of predicting the incivility\nof conversations following replies to hate speech. We first propose a metric to\nmeasure conversation incivility based on the number of civil and uncivil\ncomments as well as the unique authors involved in the discourse. Our metric\napproximates human judgments more accurately than previous metrics. We then use\nthe metric to evaluate the outcomes of replies to hate speech. A linguistic\nanalysis uncovers the differences in the language of replies that elicit\nfollow-up conversations with high and low incivility. Experimental results show\nthat forecasting incivility is challenging. We close with a qualitative\nanalysis shedding light into the most common errors made by the best model.", "published": "2023-12-08 02:39:17", "link": "http://arxiv.org/abs/2312.04804v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "HuRef: HUman-REadable Fingerprint for Large Language Models", "abstract": "Protecting the copyright of large language models (LLMs) has become crucial\ndue to their resource-intensive training and accompanying carefully designed\nlicenses. However, identifying the original base model of an LLM is challenging\ndue to potential parameter alterations. In this study, we introduce HuRef, a\nhuman-readable fingerprint for LLMs that uniquely identifies the base model\nwithout interfering with training or exposing model parameters to the public.\nWe first observe that the vector direction of LLM parameters remains stable\nafter the model has converged during pretraining, with negligible perturbations\nthrough subsequent training steps, including continued pretraining, supervised\nfine-tuning, and RLHF, which makes it a sufficient condition to identify the\nbase model. The necessity is validated by continuing to train an LLM with an\nextra term to drive away the model parameters' direction and the model becomes\ndamaged. However, this direction is vulnerable to simple attacks like dimension\npermutation or matrix rotation, which significantly change it without affecting\nperformance. To address this, leveraging the Transformer structure, we\nsystematically analyze potential attacks and define three invariant terms that\nidentify an LLM's base model. Due to the potential risk of information leakage,\nwe cannot publish invariant terms directly. Instead, we map them to a Gaussian\nvector using an encoder, then convert it into a natural image using StyleGAN2,\nand finally publish the image. In our black-box setting, all fingerprinting\nsteps are internally conducted by the LLMs owners. To ensure the published\nfingerprints are honestly generated, we introduced Zero-Knowledge Proof (ZKP).\nExperimental results across various LLMs demonstrate the effectiveness of our\nmethod. The code is available at https://github.com/LUMIA-Group/HuRef.", "published": "2023-12-08 05:01:47", "link": "http://arxiv.org/abs/2312.04828v5", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FREDSum: A Dialogue Summarization Corpus for French Political Debates", "abstract": "Recent advances in deep learning, and especially the invention of\nencoder-decoder architectures, has significantly improved the performance of\nabstractive summarization systems. The majority of research has focused on\nwritten documents, however, neglecting the problem of multi-party dialogue\nsummarization. In this paper, we present a dataset of French political debates\nfor the purpose of enhancing resources for multi-lingual dialogue\nsummarization. Our dataset consists of manually transcribed and annotated\npolitical debates, covering a range of topics and perspectives. We highlight\nthe importance of high quality transcription and annotations for training\naccurate and effective dialogue summarization models, and emphasize the need\nfor multilingual resources to support dialogue summarization in non-English\nlanguages. We also provide baseline experiments using state-of-the-art methods,\nand encourage further research in this area to advance the field of dialogue\nsummarization. Our dataset will be made publicly available for use by the\nresearch community.", "published": "2023-12-08 05:42:04", "link": "http://arxiv.org/abs/2312.04843v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning to Break: Knowledge-Enhanced Reasoning in Multi-Agent Debate\n  System", "abstract": "Multi-agent debate system (MAD) imitating the process of human discussion in\npursuit of truth, aims to align the correct cognition of different agents for\nthe optimal solution. It is challenging to make various agents perform right\nand highly consistent cognition due to their limited and different knowledge\nbackgrounds (i.e., cognitive islands), which hinders the search for the optimal\nsolution. To address the challenge, we propose a novel\n\\underline{M}ulti-\\underline{A}gent \\underline{D}ebate with\n\\underline{K}nowledge-\\underline{E}nhanced framework (\\textbf{MADKE}) to\npromote the system to find the solution. First, we involve a shared retrieval\nknowledge pool in the debate process to solve the problem of limited and\ndifferent knowledge backgrounds. Then, we propose an adaptive knowledge\nselection method to guarantee the accuracy and personalization of knowledge.\nThis method allows agents to choose whether to use external knowledge in each\nconversation round according to their own needs. Our experimental results on\nsix datasets show that our method achieves state-of-the-art results compared to\nexisting single-agent and multi-agent methods. Further analysis reveals that\nthe introduction of retrieval knowledge can help the agent to break cognitive\nislands in the debate process and effectively improve the consistency and\ncorrectness of the model. Moreover, MADKE using Qwen1.5-72B-Chat surpasses\nGPT-4 by +1.26\\% on average in six datasets, which validates that our method\ncan help open-source LLMs achieve or even surpass the performance of GPT-4. Our\ncode is available at \\url{https://github.com/FutureForMe/MADKE}.", "published": "2023-12-08 06:22:12", "link": "http://arxiv.org/abs/2312.04854v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Generating Explanations to Understand and Repair Embedding-based Entity\n  Alignment", "abstract": "Entity alignment (EA) seeks identical entities in different knowledge graphs,\nwhich is a long-standing task in the database research. Recent work leverages\ndeep learning to embed entities in vector space and align them via nearest\nneighbor search. Although embedding-based EA has gained marked success in\nrecent years, it lacks explanations for alignment decisions. In this paper, we\npresent the first framework that can generate explanations for understanding\nand repairing embedding-based EA results. Given an EA pair produced by an\nembedding model, we first compare its neighbor entities and relations to build\na matching subgraph as a local explanation. We then construct an alignment\ndependency graph to understand the pair from an abstract perspective. Finally,\nwe repair the pair by resolving three types of alignment conflicts based on\ndependency graphs. Experiments on a variety of EA datasets demonstrate the\neffectiveness, generalization, and robustness of our framework in explaining\nand repairing embedding-based EA results.", "published": "2023-12-08 07:27:26", "link": "http://arxiv.org/abs/2312.04877v3", "categories": ["cs.CL", "cs.DB"], "primary_category": "cs.CL"}
{"title": "Classification of Human- and AI-Generated Texts for English, French,\n  German, and Spanish", "abstract": "In this paper we analyze features to classify human- and AI-generated text\nfor English, French, German and Spanish and compare them across languages. We\ninvestigate two scenarios: (1) The detection of text generated by AI from\nscratch, and (2) the detection of text rephrased by AI. For training and\ntesting the classifiers in this multilingual setting, we created a new text\ncorpus covering 10 topics for each language. For the detection of AI-generated\ntext, the combination of all proposed features performs best, indicating that\nour features are portable to other related languages: The F1-scores are close\nwith 99% for Spanish, 98% for English, 97% for German and 95% for French. For\nthe detection of AI-rephrased text, the systems with all features outperform\nsystems with other features in many cases, but using only document features\nperforms best for German (72%) and Spanish (86%) and only text vector features\nleads to best results for English (78%).", "published": "2023-12-08 07:42:06", "link": "http://arxiv.org/abs/2312.04882v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zoology: Measuring and Improving Recall in Efficient Language Models", "abstract": "Attention-free language models that combine gating and convolutions are\ngrowing in popularity due to their efficiency and increasingly competitive\nperformance. To better understand these architectures, we pretrain a suite of\n17 attention and \"gated-convolution\" language models, finding that SoTA\ngated-convolution architectures still underperform attention by up to 2.1\nperplexity points on the Pile. In fine-grained analysis, we find 82% of the gap\nis explained by each model's ability to recall information that is previously\nmentioned in-context, e.g. \"Hakuna Matata means no worries Hakuna Matata it\nmeans no\" $\\rightarrow$ \"??\". On this task, termed \"associative recall\", we\nfind that attention outperforms gated-convolutions by a large margin: a 70M\nparameter attention model outperforms a 1.4 billion parameter gated-convolution\nmodel on associative recall. This is surprising because prior work shows gated\nconvolutions can perfectly solve synthetic tests for AR capability. To close\nthe gap between synthetics and real language, we develop a new formalization of\nthe task called multi-query associative recall (MQAR) that better reflects\nactual language. We perform an empirical and theoretical study of MQAR that\nelucidates differences in the parameter-efficiency of attention and\ngated-convolution recall. Informed by our analysis, we evaluate simple\nconvolution-attention hybrids and show that hybrids with input-dependent sparse\nattention patterns can close 97.4% of the gap to attention, while maintaining\nsub-quadratic scaling. Our code is accessible at:\nhttps://github.com/HazyResearch/zoology.", "published": "2023-12-08 09:44:25", "link": "http://arxiv.org/abs/2312.04927v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "HALO: An Ontology for Representing and Categorizing Hallucinations in\n  Large Language Models", "abstract": "Recent progress in generative AI, including large language models (LLMs) like\nChatGPT, has opened up significant opportunities in fields ranging from natural\nlanguage processing to knowledge discovery and data mining. However, there is\nalso a growing awareness that the models can be prone to problems such as\nmaking information up or `hallucinations', and faulty reasoning on seemingly\nsimple problems. Because of the popularity of models like ChatGPT, both\nacademic scholars and citizen scientists have documented hallucinations of\nseveral different types and severity. Despite this body of work, a formal model\nfor describing and representing these hallucinations (with relevant meta-data)\nat a fine-grained level, is still lacking. In this paper, we address this gap\nby presenting the Hallucination Ontology or HALO, a formal, extensible ontology\nwritten in OWL that currently offers support for six different types of\nhallucinations known to arise in LLMs, along with support for provenance and\nexperimental metadata. We also collect and publish a dataset containing\nhallucinations that we inductively gathered across multiple independent Web\nsources, and show that HALO can be successfully used to model this dataset and\nanswer competency questions.", "published": "2023-12-08 17:57:20", "link": "http://arxiv.org/abs/2312.05209v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Generative AI in Higher Education: Seeing ChatGPT Through Universities'\n  Policies, Resources, and Guidelines", "abstract": "The advancements in Generative Artificial Intelligence (GenAI) provide\nopportunities to enrich educational experiences, but also raise concerns about\nacademic integrity. Many educators have expressed anxiety and hesitation in\nintegrating GenAI in their teaching practices, and are in needs of\nrecommendations and guidance from their institutions that can support them to\nincorporate GenAI in their classrooms effectively. In order to respond to\nhigher educators' needs, this study aims to explore how universities and\neducators respond and adapt to the development of GenAI in their academic\ncontexts by analyzing academic policies and guidelines established by\ntop-ranked U.S. universities regarding the use of GenAI, especially ChatGPT.\nData sources include academic policies, statements, guidelines, and relevant\nresources provided by the top 100 universities in the U.S. Results show that\nthe majority of these universities adopt an open but cautious approach towards\nGenAI. Primary concerns lie in ethical usage, accuracy, and data privacy. Most\nuniversities actively respond and provide diverse types of resources, such as\nsyllabus templates, workshops, shared articles, and one-on-one consultations\nfocusing on a range of topics: general technical introduction, ethical\nconcerns, pedagogical applications, preventive strategies, data privacy,\nlimitations, and detective tools. The findings provide four practical\npedagogical implications for educators in teaching practices: accept its\npresence, align its use with learning objectives, evolve curriculum to prevent\nmisuse, and adopt multifaceted evaluation strategies rather than relying on AI\ndetectors. Two recommendations are suggested for educators in policy making:\nestablish discipline-specific policies and guidelines, and manage sensitive\ninformation carefully.", "published": "2023-12-08 18:33:11", "link": "http://arxiv.org/abs/2312.05235v3", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Assessing LLMs for Moral Value Pluralism", "abstract": "The fields of AI current lacks methods to quantitatively assess and\npotentially alter the moral values inherent in the output of large language\nmodels (LLMs). However, decades of social science research has developed and\nrefined widely-accepted moral value surveys, such as the World Values Survey\n(WVS), eliciting value judgments from direct questions in various geographies.\nWe have turned those questions into value statements and use NLP to compute to\nhow well popular LLMs are aligned with moral values for various demographics\nand cultures. While the WVS is accepted as an explicit assessment of values, we\nlack methods for assessing implicit moral and cultural values in media, e.g.,\nencountered in social media, political rhetoric, narratives, and generated by\nAI systems such as LLMs that are increasingly present in our daily lives. As we\nconsume online content and utilize LLM outputs, we might ask, which moral\nvalues are being implicitly promoted or undercut, or -- in the case of LLMs --\nif they are intending to represent a cultural identity, are they doing so\nconsistently? In this paper we utilize a Recognizing Value Resonance (RVR) NLP\nmodel to identify WVS values that resonate and conflict with a given passage of\noutput text. We apply RVR to the text generated by LLMs to characterize\nimplicit moral values, allowing us to quantify the moral/cultural distance\nbetween LLMs and various demographics that have been surveyed using the WVS. In\nline with other work we find that LLMs exhibit several Western-centric value\nbiases; they overestimate how conservative people in non-Western countries are,\nthey are less accurate in representing gender for non-Western countries, and\nportray older populations as having more traditional values. Our results\nhighlight value misalignment and age groups, and a need for social science\ninformed technological solutions addressing value plurality in LLMs.", "published": "2023-12-08 16:18:15", "link": "http://arxiv.org/abs/2312.10075v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Localized Symbolic Knowledge Distillation for Visual Commonsense Models", "abstract": "Instruction following vision-language (VL) models offer a flexible interface\nthat supports a broad range of multimodal tasks in a zero-shot fashion.\nHowever, interfaces that operate on full images do not directly enable the user\nto \"point to\" and access specific regions within images. This capability is\nimportant not only to support reference-grounded VL benchmarks, but also, for\npractical applications that require precise within-image reasoning. We build\nLocalized Visual Commonsense models, which allow users to specify (multiple)\nregions as input. We train our model by sampling localized commonsense\nknowledge from a large language model (LLM): specifically, we prompt an LLM to\ncollect commonsense knowledge given a global literal image description and a\nlocal literal region description automatically generated by a set of VL models.\nWith a separately trained critic model that selects high-quality examples, we\nfind that training on the localized commonsense corpus can successfully distill\nexisting VL models to support a reference-as-input interface. Empirical results\nand human evaluations in a zero-shot setup demonstrate that our distillation\nmethod results in more precise VL models of reasoning compared to a baseline of\npassing a generated referring expression to an LLM.", "published": "2023-12-08 05:23:50", "link": "http://arxiv.org/abs/2312.04837v2", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "Predictive Chemistry Augmented with Text Retrieval", "abstract": "This paper focuses on using natural language descriptions to enhance\npredictive models in the chemistry field. Conventionally, chemoinformatics\nmodels are trained with extensive structured data manually extracted from the\nliterature. In this paper, we introduce TextReact, a novel method that directly\naugments predictive chemistry with texts retrieved from the literature.\nTextReact retrieves text descriptions relevant for a given chemical reaction,\nand then aligns them with the molecular representation of the reaction. This\nalignment is enhanced via an auxiliary masked LM objective incorporated in the\npredictor training. We empirically validate the framework on two chemistry\ntasks: reaction condition recommendation and one-step retrosynthesis. By\nleveraging text retrieval, TextReact significantly outperforms state-of-the-art\nchemoinformatics models trained solely on molecular data.", "published": "2023-12-08 07:40:59", "link": "http://arxiv.org/abs/2312.04881v1", "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "cs.CL"}
{"title": "KwaiAgents: Generalized Information-seeking Agent System with Large\n  Language Models", "abstract": "Driven by curiosity, humans have continually sought to explore and understand\nthe world around them, leading to the invention of various tools to satiate\nthis inquisitiveness. Despite not having the capacity to process and memorize\nvast amounts of information in their brains, humans excel in critical thinking,\nplanning, reflection, and harnessing available tools to interact with and\ninterpret the world, enabling them to find answers efficiently. The recent\nadvancements in large language models (LLMs) suggest that machines might also\npossess the aforementioned human-like capabilities, allowing them to exhibit\npowerful abilities even with a constrained parameter count. In this paper, we\nintroduce KwaiAgents, a generalized information-seeking agent system based on\nLLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its\ncognitive core, which is capable of understanding a user's query, behavior\nguidelines, and referencing external documents. The agent can also update and\nretrieve information from its internal memory, plan and execute actions using a\ntime-aware search-browse toolkit, and ultimately provide a comprehensive\nresponse. We further investigate the system's performance when powered by LLMs\nless advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework,\ndesigned to ensure even an open-sourced 7B or 13B model performs well among\nmany agent systems. We exploit both benchmark and human evaluations to\nsystematically validate these capabilities. Extensive experiments show the\nsuperiority of our agent system compared to other autonomous agents and\nhighlight the enhanced generalized agent-abilities of our fine-tuned LLMs.", "published": "2023-12-08 08:11:11", "link": "http://arxiv.org/abs/2312.04889v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "The ICL Consistency Test", "abstract": "Just like the previous generation of task-tuned models, large language models\n(LLMs) that are adapted to tasks via prompt-based methods like\nin-context-learning (ICL) perform well in some setups but not in others. This\nlack of consistency in prompt-based learning hints at a lack of robust\ngeneralisation. We here introduce the ICL consistency test -- a contribution to\nthe GenBench collaborative benchmark task (CBT) -- which evaluates how\nconsistent a model makes predictions across many different setups while using\nthe same data. The test is based on different established natural language\ninference tasks. We provide preprocessed data constituting 96 different\n'setups' and a metric that estimates model consistency across these setups. The\nmetric is provided on a fine-grained level to understand what properties of a\nsetup render predictions unstable and on an aggregated level to compare overall\nmodel consistency. We conduct an empirical analysis of eight state-of-the-art\nmodels, and our consistency metric reveals how all tested LLMs lack robust\ngeneralisation.", "published": "2023-12-08 10:22:43", "link": "http://arxiv.org/abs/2312.04945v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "TMID: A Comprehensive Real-world Dataset for Trademark Infringement\n  Detection in E-Commerce", "abstract": "Annually, e-commerce platforms incur substantial financial losses due to\ntrademark infringements, making it crucial to identify and mitigate potential\nlegal risks tied to merchant information registered to the platforms. However,\nthe absence of high-quality datasets hampers research in this area. To address\nthis gap, our study introduces TMID, a novel dataset to detect trademark\ninfringement in merchant registrations. This is a real-world dataset sourced\ndirectly from Alipay, one of the world's largest e-commerce and digital payment\nplatforms. As infringement detection is a legal reasoning task requiring an\nunderstanding of the contexts and legal rules, we offer a thorough collection\nof legal rules and merchant and trademark-related contextual information with\nannotations from legal experts. We ensure the data quality by performing an\nextensive statistical analysis. Furthermore, we conduct an empirical study on\nthis dataset to highlight its value and the key challenges. Through this study,\nwe aim to contribute valuable resources to advance research into legal\ncompliance related to trademark infringement within the e-commerce sphere. The\ndataset is available at https://github.com/emnlpTMID/emnlpTMID.github.io .", "published": "2023-12-08 15:31:39", "link": "http://arxiv.org/abs/2312.05103v1", "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Seamless: Multilingual Expressive and Streaming Speech Translation", "abstract": "Large-scale automatic speech translation systems today lack key features that\nhelp machine-mediated communication feel seamless when compared to\nhuman-to-human dialogue. In this work, we introduce a family of models that\nenable end-to-end expressive and multilingual translations in a streaming\nfashion. First, we contribute an improved version of the massively multilingual\nand multimodal SeamlessM4T model-SeamlessM4T v2. This newer model,\nincorporating an updated UnitY2 framework, was trained on more low-resource\nlanguage data. SeamlessM4T v2 provides the foundation on which our next two\nmodels are initiated. SeamlessExpressive enables translation that preserves\nvocal styles and prosody. Compared to previous efforts in expressive speech\nresearch, our work addresses certain underexplored aspects of prosody, such as\nspeech rate and pauses, while also preserving the style of one's voice. As for\nSeamlessStreaming, our model leverages the Efficient Monotonic Multihead\nAttention mechanism to generate low-latency target translations without waiting\nfor complete source utterances. As the first of its kind, SeamlessStreaming\nenables simultaneous speech-to-speech/text translation for multiple source and\ntarget languages. To ensure that our models can be used safely and responsibly,\nwe implemented the first known red-teaming effort for multimodal machine\ntranslation, a system for the detection and mitigation of added toxicity, a\nsystematic evaluation of gender bias, and an inaudible localized watermarking\nmechanism designed to dampen the impact of deepfakes. Consequently, we bring\nmajor components from SeamlessExpressive and SeamlessStreaming together to form\nSeamless, the first publicly available system that unlocks expressive\ncross-lingual communication in real-time. The contributions to this work are\npublicly released and accessible at\nhttps://github.com/facebookresearch/seamless_communication", "published": "2023-12-08 17:18:42", "link": "http://arxiv.org/abs/2312.05187v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "GlitchBench: Can large multimodal models detect video game glitches?", "abstract": "Large multimodal models (LMMs) have evolved from large language models (LLMs)\nto integrate multiple input modalities, such as visual inputs. This integration\naugments the capacity of LLMs for tasks requiring visual comprehension and\nreasoning. However, the extent and limitations of their enhanced abilities are\nnot fully understood, especially when it comes to real-world tasks. To address\nthis gap, we introduce GlitchBench, a novel benchmark derived from video game\nquality assurance tasks, to test and evaluate the reasoning capabilities of\nLMMs. Our benchmark is curated from a variety of unusual and glitched scenarios\nfrom video games and aims to challenge both the visual and linguistic reasoning\npowers of LMMs in detecting and interpreting out-of-the-ordinary events. We\nevaluate multiple state-of-the-art LMMs, and we show that GlitchBench presents\na new challenge for these models. Code and data are available at:\nhttps://glitchbench.github.io/", "published": "2023-12-08 18:14:21", "link": "http://arxiv.org/abs/2312.05291v2", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Neuron Patching: Semantic-based Neuron-level Language Model Repair for\n  Code Generation", "abstract": "Language Models (LMs) have become widely used in software engineering,\nespecially for tasks such as code generation, where they are referred to as\ncode LMs. These models have proven effective in generating code, making it\neasier for developers to automate coding activities. However, research has\nhighlighted a significant limitation: despite their effectiveness, LMs often\nproduce code that is incorrect, buggy, or not fully functional. Updating these\nmodels with limited data can be prohibitively challenging, yet it is essential\nto maximize their utility. This may require hot-fix techniques (updating models\nwith limited data) to resolve. In this paper, we propose \\ul{M}odel\n\\ul{I}mprovement via \\ul{N}euron \\ul{T}argeting (\\textsc{MINT}), a novel\napproach for repairing code LMs. MINT leverages the semantic property of\nlanguage models to perform neuron-level repairs in a novel way. Further, by\nanalyzing the relationships between the model's latent representations, the\nincorrect outputs, and the desired outputs, \\textsc{MINT} determines which\nneurons are worth updating. This approach ensures that only the neurons crucial\nto the model's failure are targeted, avoiding unnecessary changes and allowing\nfor a more efficient and precise repair process. \\textsc{MINT} is effective,\nefficient, and reliable, capable of correcting a neural model by patching a\nminimum number of neurons (usually one or two neurons). Our approach is\nevaluated on three coding tasks: line-level code generation, shellcode\ngeneration, and intent-to-bash translation. The experimental results\ndemonstrate that the proposed approach significantly outperforms the\nstate-of-the-art in both effectiveness and efficiency measures. In addition, we\nanalyze and discuss the side effects of model repair techniques, including the\nbalance between generalization and specificity, and the performance after\nmultiple repairs in succession.", "published": "2023-12-08 20:28:08", "link": "http://arxiv.org/abs/2312.05356v5", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "An Experimental Study: Assessing the Combined Framework of WavLM and\n  BEST-RQ for Text-to-Speech Synthesis", "abstract": "We propose a new model architecture specifically suited for text-to-speech\n(TTS) models. We combine WavLM, a pre-trained self-supervised learning (SSL)\nspeech model, and the BEST-RQ vector quantization framework. We assess the\nextent to which the more task-agnostic WavLM, coupled with the superior\nsuitability of the simplistic BEST-RQ framework for a wider array of downstream\ntasks, yields favorable outcomes. Experiments on the LibriSpeech dataset with\nSUPERB benchmarking assert that the proposed model significantly underperforms.\nWe speculate the underlying reason for this performance is related to the\ndifference between featurizing raw audio waveforms and spectrograms with a\nquantizer. We discuss the limitations of this approach to better guide future\nadvancements in TTS.", "published": "2023-12-08 23:59:25", "link": "http://arxiv.org/abs/2312.05415v1", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research", "abstract": "Large Language Models (LLMs) generalize well across language tasks, but\nsuffer from hallucinations and uninterpretability, making it difficult to\nassess their accuracy without ground-truth. Retrieval-Augmented Generation\n(RAG) models have been proposed to reduce hallucinations and provide provenance\nfor how an answer was generated. Applying such models to the scientific\nliterature may enable large-scale, systematic processing of scientific\nknowledge. We present PaperQA, a RAG agent for answering questions over the\nscientific literature. PaperQA is an agent that performs information retrieval\nacross full-text scientific articles, assesses the relevance of sources and\npassages, and uses RAG to provide answers. Viewing this agent as a question\nanswering model, we find it exceeds performance of existing LLMs and LLM agents\non current science QA benchmarks. To push the field closer to how humans\nperform research on scientific literature, we also introduce LitQA, a more\ncomplex benchmark that requires retrieval and synthesis of information from\nfull-text scientific papers across the literature. Finally, we demonstrate\nPaperQA's matches expert human researchers on LitQA.", "published": "2023-12-08 18:50:20", "link": "http://arxiv.org/abs/2312.07559v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Language Models, Agent Models, and World Models: The LAW for Machine\n  Reasoning and Planning", "abstract": "Despite their tremendous success in many applications, large language models\noften fall short of consistent reasoning and planning in various (language,\nembodied, and social) scenarios, due to inherent limitations in their\ninference, learning, and modeling capabilities. In this position paper, we\npresent a new perspective of machine reasoning, LAW, that connects the concepts\nof Language models, Agent models, and World models, for more robust and\nversatile reasoning capabilities. In particular, we propose that world and\nagent models are a better abstraction of reasoning, that introduces the crucial\nelements of deliberate human-like reasoning, including beliefs about the world\nand other agents, anticipation of consequences, goals/rewards, and strategic\nplanning. Crucially, language models in LAW serve as a backend to implement the\nsystem or its elements and hence provide the computational power and\nadaptability. We review the recent studies that have made relevant progress and\ndiscuss future research directions towards operationalizing the LAW framework.", "published": "2023-12-08 18:25:22", "link": "http://arxiv.org/abs/2312.05230v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.RO"], "primary_category": "cs.AI"}
{"title": "Sound Source Localization for a Source inside a Structure using\n  Ac-CycleGAN", "abstract": "We propose a method for sound source localization (SSL) for a source inside a\nstructure using Ac-CycleGAN under unpaired data conditions. The proposed method\nutilizes a large amount of simulated data and a small amount of actual\nexperimental data to locate a sound source inside a structure in a real\nenvironment. An Ac-CycleGAN generator contributes to the transformation of\nsimulated data into real data, or vice versa, using unpaired data from both\ndomains. The discriminator of an Ac-CycleGAN model is designed to differentiate\nbetween the transformed data generated by the generator and real data, while\nalso predicting the location of the sound source. Vectors representing the\nfrequency spectrum of the accelerometers (FSAs) measured at three points\noutside the structure are used as input data and the source areas inside the\nstructure are used as labels. The input data vectors are concatenated\nvertically to form an image. Labels are defined by dividing the interior of the\nstructure into eight areas with one-hot encoding for each area. Thus, the SSL\nproblem is redefined as an image-classification problem to stochastically\nestimate the location of the sound source. We show that it is possible to\nestimate the sound source location using the Ac-CycleGAN discriminator for\nunpaired data across domains. Furthermore, we analyze the discriminative\nfactors for distinguishing the data. The proposed model exhibited an accuracy\nexceeding 90\\% when trained on 80\\% of actual data (12.5\\% of simulated data).\nDespite potential imperfections in the domain transformation process carried\nout by the Ac-CycleGAN generator, the discriminator can effectively distinguish\nbetween transferred and real data by selectively utilizing only those features\nthat generate a relatively small transformation error.", "published": "2023-12-08 05:50:07", "link": "http://arxiv.org/abs/2312.04846v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Neural Concatenative Singing Voice Conversion: Rethinking\n  Concatenation-Based Approach for One-Shot Singing Voice Conversion", "abstract": "Any-to-any singing voice conversion (SVC) is confronted with the challenge of\n``timbre leakage'' issue caused by inadequate disentanglement between the\ncontent and the speaker timbre. To address this issue, this study introduces\nNeuCoSVC, a novel neural concatenative SVC framework. It consists of a\nself-supervised learning (SSL) representation extractor, a neural harmonic\nsignal generator, and a waveform synthesizer. The SSL extractor condenses audio\ninto fixed-dimensional SSL features, while the harmonic signal generator\nleverages linear time-varying filters to produce both raw and filtered harmonic\nsignals for pitch information. The synthesizer reconstructs waveforms using SSL\nfeatures, harmonic signals, and loudness information. During inference, voice\nconversion is performed by substituting source SSL features with their nearest\ncounterparts from a matching pool which comprises SSL features extracted from\nthe reference audio, while preserving raw harmonic signals and loudness from\nthe source audio. By directly utilizing SSL features from the reference audio,\nthe proposed framework effectively resolves the ``timbre leakage\" issue caused\nby previous disentanglement-based approaches. Experimental results demonstrate\nthat the proposed NeuCoSVC system outperforms the disentanglement-based speaker\nembedding approach in one-shot SVC across intra-language, cross-language, and\ncross-domain evaluations.", "published": "2023-12-08 09:35:08", "link": "http://arxiv.org/abs/2312.04919v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Binaural multichannel blind speaker separation with a causal low-latency\n  and low-complexity approach", "abstract": "In this paper, we introduce a causal low-latency low-complexity approach for\nbinaural multichannel blind speaker separation in noisy reverberant conditions.\n  The model, referred to as Group Communication Binaural Filter and Sum Network\n(GCBFSnet) predicts complex filters for filter-and-sum beamforming in the\ntime-frequency domain.\n  We apply Group Communication (GC),\n  i.e., latent model variables are split into groups and processed with a\nshared sequence model with the aim of reducing the complexity of a simple model\nonly containing one convolutional and one recurrent module.\n  With GC we are able to reduce the size of the model by up to 83 % and the\ncomplexity up to 73 % compared to the model without GC, while mostly retaining\nperformance.\n  Even for the smallest model configuration, GCBFSnet matches the performance\nof a low-complexity TasNet baseline in most metrics despite the larger size and\nhigher number of required operations of the baseline.", "published": "2023-12-08 16:53:04", "link": "http://arxiv.org/abs/2312.05173v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "CMMD: Contrastive Multi-Modal Diffusion for Video-Audio Conditional\n  Modeling", "abstract": "We introduce a multi-modal diffusion model tailored for the bi-directional\nconditional generation of video and audio. We propose a joint contrastive\ntraining loss to improve the synchronization between visual and auditory\noccurrences. We present experiments on two datasets to evaluate the efficacy of\nour proposed model. The assessment of generation quality and alignment\nperformance is carried out from various angles, encompassing both objective and\nsubjective metrics. Our findings demonstrate that the proposed model\noutperforms the baseline in terms of quality and generation speed through\nintroduction of our novel cross-modal easy fusion architectural block.\nFurthermore, the incorporation of the contrastive loss results in improvements\nin audio-visual alignment, particularly in the high-correlation video-to-audio\ngeneration task.", "published": "2023-12-08 23:55:19", "link": "http://arxiv.org/abs/2312.05412v2", "categories": ["cs.LG", "cs.CV", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
