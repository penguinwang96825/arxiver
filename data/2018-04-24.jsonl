{"title": "End-Task Oriented Textual Entailment via Deep Explorations of\n  Inter-Sentence Interactions", "abstract": "This work deals with SciTail, a natural entailment challenge derived from a\nmulti-choice question answering problem. The premises and hypotheses in SciTail\nwere generated with no awareness of each other, and did not specifically aim at\nthe entailment task. This makes it more challenging than other entailment data\nsets and more directly useful to the end-task -- question answering. We propose\nDEISTE (deep explorations of inter-sentence interactions for textual\nentailment) for this entailment task. Given word-to-word interactions between\nthe premise-hypothesis pair ($P$, $H$), DEISTE consists of: (i) a\nparameter-dynamic convolution to make important words in $P$ and $H$ play a\ndominant role in learnt representations; and (ii) a position-aware attentive\nconvolution to encode the representation and position information of the\naligned word pairs. Experiments show that DEISTE gets $\\approx$5\\% improvement\nover prior state of the art and that the pretrained DEISTE on SciTail\ngeneralizes well on RTE-5.", "published": "2018-04-24 02:29:14", "link": "http://arxiv.org/abs/1804.08813v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Integrating Multiplicative Features into Supervised Distributional\n  Methods for Lexical Entailment", "abstract": "Supervised distributional methods are applied successfully in lexical\nentailment, but recent work questioned whether these methods actually learn a\nrelation between two words. Specifically, Levy et al. (2015) claimed that\nlinear classifiers learn only separate properties of each word. We suggest a\ncheap and easy way to boost the performance of these methods by integrating\nmultiplicative features into commonly used representations. We provide an\nextensive evaluation with different classifiers and evaluation setups, and\nsuggest a suitable evaluation setup for the task, eliminating biases existing\nin previous ones.", "published": "2018-04-24 05:34:59", "link": "http://arxiv.org/abs/1804.08845v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Data-driven Summarization of Scientific Articles", "abstract": "Data-driven approaches to sequence-to-sequence modelling have been\nsuccessfully applied to short text summarization of news articles. Such models\nare typically trained on input-summary pairs consisting of only a single or a\nfew sentences, partially due to limited availability of multi-sentence training\ndata. Here, we propose to use scientific articles as a new milestone for text\nsummarization: large-scale training data come almost for free with two types of\nhigh-quality summaries at different levels - the title and the abstract. We\ngenerate two novel multi-sentence summarization datasets from scientific\narticles and test the suitability of a wide range of existing extractive and\nabstractive neural network-based summarization approaches. Our analysis\ndemonstrates that scientific papers are suitable for data-driven text\nsummarization. Our results could serve as valuable benchmarks for scaling\nsequence-to-sequence models to very long sequences.", "published": "2018-04-24 07:40:31", "link": "http://arxiv.org/abs/1804.08875v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Assessing Language Models with Scaling Properties", "abstract": "Language models have primarily been evaluated with perplexity. While\nperplexity quantifies the most comprehensible prediction performance, it does\nnot provide qualitative information on the success or failure of models.\nAnother approach for evaluating language models is thus proposed, using the\nscaling properties of natural language. Five such tests are considered, with\nthe first two accounting for the vocabulary population and the other three for\nthe long memory of natural language. The following models were evaluated with\nthese tests: n-grams, probabilistic context-free grammar (PCFG), Simon and\nPitman-Yor (PY) processes, hierarchical PY, and neural language models. Only\nthe neural language models exhibit the long memory properties of natural\nlanguage, but to a limited degree. The effectiveness of every test of these\nmodels is also discussed.", "published": "2018-04-24 07:58:20", "link": "http://arxiv.org/abs/1804.08881v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SIRIUS-LTG-UiO at SemEval-2018 Task 7: Convolutional Neural Networks\n  with Shortest Dependency Paths for Semantic Relation Extraction and\n  Classification in Scientific Papers", "abstract": "This article presents the SIRIUS-LTG-UiO system for the SemEval 2018 Task 7\non Semantic Relation Extraction and Classification in Scientific Papers. First\nwe extract the shortest dependency path (sdp) between two entities, then we\nintroduce a convolutional neural network (CNN) which takes the shortest\ndependency path embeddings as input and performs relation classification with\ndiffering objectives for each subtask of the shared task. This approach\nachieved overall F1 scores of 76.7 and 83.2 for relation classification on\nclean and noisy data, respectively. Furthermore, for combined relation\nextraction and classification on clean data, it obtained F1 scores of 37.4 and\n33.6 for each phase. Our system ranks 3rd in all three sub-tasks of the shared\ntask.", "published": "2018-04-24 08:10:07", "link": "http://arxiv.org/abs/1804.08887v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Scheduled Multi-Task Learning: From Syntax to Translation", "abstract": "Neural encoder-decoder models of machine translation have achieved impressive\nresults, while learning linguistic knowledge of both the source and target\nlanguages in an implicit end-to-end manner. We propose a framework in which our\nmodel begins learning syntax and translation interleaved, gradually putting\nmore focus on translation. Using this approach, we achieve considerable\nimprovements in terms of BLEU score on relatively large parallel corpus (WMT14\nEnglish to German) and a low-resource (WIT German to English) setup.", "published": "2018-04-24 09:18:13", "link": "http://arxiv.org/abs/1804.08915v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Style Transfer Through Back-Translation", "abstract": "Style transfer is the task of rephrasing the text to contain specific\nstylistic properties without changing the intent or affect within the context.\nThis paper introduces a new method for automatic style transfer. We first learn\na latent representation of the input sentence which is grounded in a language\ntranslation model in order to better preserve the meaning of the sentence while\nreducing stylistic properties. Then adversarial generation techniques are used\nto make the output match the desired style. We evaluate this technique on three\ndifferent style transformations: sentiment, gender and political slant.\nCompared to two state-of-the-art style transfer modeling techniques we show\nimprovements both in automatic evaluation of style transfer and in manual\nevaluation of meaning preservation and fluency.", "published": "2018-04-24 12:58:45", "link": "http://arxiv.org/abs/1804.09000v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards a Neural Network Approach to Abstractive Multi-Document\n  Summarization", "abstract": "Till now, neural abstractive summarization methods have achieved great\nsuccess for single document summarization (SDS). However, due to the lack of\nlarge scale multi-document summaries, such methods can be hardly applied to\nmulti-document summarization (MDS). In this paper, we investigate neural\nabstractive methods for MDS by adapting a state-of-the-art neural abstractive\nsummarization model for SDS. We propose an approach to extend the neural\nabstractive model trained on large scale SDS data to the MDS task. Our approach\nonly makes use of a small number of multi-document summaries for fine tuning.\nExperimental results on two benchmark DUC datasets demonstrate that our\napproach can outperform a variety of baseline neural models.", "published": "2018-04-24 13:24:08", "link": "http://arxiv.org/abs/1804.09010v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Unsupervised Neural Machine Translation with Weight Sharing", "abstract": "Unsupervised neural machine translation (NMT) is a recently proposed approach\nfor machine translation which aims to train the model without using any labeled\ndata. The models proposed for unsupervised NMT often use only one shared\nencoder to map the pairs of sentences from different languages to a\nshared-latent space, which is weak in keeping the unique and internal\ncharacteristics of each language, such as the style, terminology, and sentence\nstructure. To address this issue, we introduce an extension by utilizing two\nindependent encoders but sharing some partial weights which are responsible for\nextracting high-level representations of the input sentences. Besides, two\ndifferent generative adversarial networks (GANs), namely the local GAN and\nglobal GAN, are proposed to enhance the cross-language translation. With this\nnew approach, we achieve significant improvements on English-German,\nEnglish-French and Chinese-to-English translation tasks.", "published": "2018-04-24 14:11:28", "link": "http://arxiv.org/abs/1804.09057v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Report on the Complex Word Identification Shared Task 2018", "abstract": "We report the findings of the second Complex Word Identification (CWI) shared\ntask organized as part of the BEA workshop co-located with NAACL-HLT'2018. The\nsecond CWI shared task featured multilingual and multi-genre datasets divided\ninto four tracks: English monolingual, German monolingual, Spanish monolingual,\nand a multilingual track with a French test set, and two tasks: binary\nclassification and probabilistic classification. A total of 12 teams submitted\ntheir results in different task/track combinations and 11 of them wrote system\ndescription papers that are referred to in this report and appear in the BEA\nworkshop proceedings.", "published": "2018-04-24 16:49:30", "link": "http://arxiv.org/abs/1804.09132v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Commonsense mining as knowledge base completion? A study on the impact\n  of novelty", "abstract": "Commonsense knowledge bases such as ConceptNet represent knowledge in the\nform of relational triples. Inspired by the recent work by Li et al., we\nanalyse if knowledge base completion models can be used to mine commonsense\nknowledge from raw text. We propose novelty of predicted triples with respect\nto the training set as an important factor in interpreting results. We\ncritically analyse the difficulty of mining novel commonsense knowledge, and\nshow that a simple baseline method outperforms the previous state of the art on\npredicting more novel.", "published": "2018-04-24 21:07:04", "link": "http://arxiv.org/abs/1804.09259v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SimpleQuestions Nearly Solved: A New Upperbound and Baseline Approach", "abstract": "The SimpleQuestions dataset is one of the most commonly used benchmarks for\nstudying single-relation factoid questions. In this paper, we present new\nevidence that this benchmark can be nearly solved by standard methods. First we\nshow that ambiguity in the data bounds performance on this benchmark at 83.4%;\nthere are often multiple answers that cannot be disambiguated from the\nlinguistic signal alone. Second we introduce a baseline that sets a new\nstate-of-the-art performance level at 78.1% accuracy, despite using standard\nmethods. Finally, we report an empirical analysis showing that the upperbound\nis loose; roughly a third of the remaining errors are also not resolvable from\nthe linguistic signal. Together, these results suggest that the SimpleQuestions\ndataset is nearly solved.", "published": "2018-04-24 01:24:35", "link": "http://arxiv.org/abs/1804.08798v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "DeepEmo: Learning and Enriching Pattern-Based Emotion Representations", "abstract": "We propose a graph-based mechanism to extract rich-emotion bearing patterns,\nwhich fosters a deeper analysis of online emotional expressions, from a corpus.\nThe patterns are then enriched with word embeddings and evaluated through\nseveral emotion recognition tasks. Moreover, we conduct analysis on the\nemotion-oriented patterns to demonstrate its applicability and to explore its\nproperties. Our experimental results demonstrate that the proposed techniques\noutperform most state-of-the-art emotion recognition techniques.", "published": "2018-04-24 06:00:28", "link": "http://arxiv.org/abs/1804.08847v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Label-aware Double Transfer Learning for Cross-Specialty Medical Named\n  Entity Recognition", "abstract": "We study the problem of named entity recognition (NER) from electronic\nmedical records, which is one of the most fundamental and critical problems for\nmedical text mining. Medical records which are written by clinicians from\ndifferent specialties usually contain quite different terminologies and writing\nstyles. The difference of specialties and the cost of human annotation makes it\nparticularly difficult to train a universal medical NER system. In this paper,\nwe propose a label-aware double transfer learning framework (La-DTL) for\ncross-specialty NER, so that a medical NER system designed for one specialty\ncould be conveniently applied to another one with minimal annotation efforts.\nThe transferability is guaranteed by two components: (i) we propose label-aware\nMMD for feature representation transfer, and (ii) we perform parameter transfer\nwith a theoretical upper bound which is also label aware. We conduct extensive\nexperiments on 12 cross-specialty NER tasks. The experimental results\ndemonstrate that La-DTL provides consistent accuracy improvement over strong\nbaselines. Besides, the promising experimental results on non-medical NER\nscenarios indicate that La-DTL is potential to be seamlessly adapted to a wide\nrange of NER tasks.", "published": "2018-04-24 13:35:11", "link": "http://arxiv.org/abs/1804.09021v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Automatic speech recognition for launch control center communication\n  using recurrent neural networks with data augmentation and custom language\n  model", "abstract": "Transcribing voice communications in NASA's launch control center is\nimportant for information utilization. However, automatic speech recognition in\nthis environment is particularly challenging due to the lack of training data,\nunfamiliar words in acronyms, multiple different speakers and accents, and\nconversational characteristics of speaking. We used bidirectional deep\nrecurrent neural networks to train and test speech recognition performance. We\nshowed that data augmentation and custom language models can improve speech\nrecognition accuracy. Transcribing communications from the launch control\ncenter will help the machine analyze information and accelerate knowledge\ngeneration.", "published": "2018-04-24 10:28:57", "link": "http://arxiv.org/abs/1804.09552v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Estimate and Replace: A Novel Approach to Integrating Deep Neural\n  Networks with Existing Applications", "abstract": "Existing applications include a huge amount of knowledge that is out of reach\nfor deep neural networks. This paper presents a novel approach for integrating\ncalls to existing applications into deep learning architectures. Using this\napproach, we estimate each application's functionality with an estimator, which\nis implemented as a deep neural network (DNN). The estimator is then embedded\ninto a base network that we direct into complying with the application's\ninterface during an end-to-end optimization process. At inference time, we\nreplace each estimator with its existing application counterpart and let the\nbase network solve the task by interacting with the existing application. Using\nthis 'Estimate and Replace' method, we were able to train a DNN end-to-end with\nless data and outperformed a matching DNN that did not interact with the\nexternal application.", "published": "2018-04-24 13:40:09", "link": "http://arxiv.org/abs/1804.09028v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Automated Detection of Adverse Drug Reactions in the Biomedical\n  Literature Using Convolutional Neural Networks and Biomedical Word Embeddings", "abstract": "Monitoring the biomedical literature for cases of Adverse Drug Reactions\n(ADRs) is a critically important and time consuming task in pharmacovigilance.\nThe development of computer assisted approaches to aid this process in\ndifferent forms has been the subject of many recent works. One particular area\nthat has shown promise is the use of Deep Neural Networks, in particular,\nConvolutional Neural Networks (CNNs), for the detection of ADR relevant\nsentences. Using token-level convolutions and general purpose word embeddings,\nthis architecture has shown good performance relative to more traditional\nmodels as well as Long Short Term Memory (LSTM) models. In this work, we\nevaluate and compare two different CNN architectures using the ADE corpus. In\naddition, we show that by de-duplicating the ADR relevant sentences, we can\ngreatly reduce overoptimism in the classification results. Finally, we evaluate\nthe use of word embeddings specifically developed for biomedical text and show\nthat they lead to a better performance in this task.", "published": "2018-04-24 17:18:01", "link": "http://arxiv.org/abs/1804.09148v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "No Metrics Are Perfect: Adversarial Reward Learning for Visual\n  Storytelling", "abstract": "Though impressive results have been achieved in visual captioning, the task\nof generating abstract stories from photo streams is still a little-tapped\nproblem. Different from captions, stories have more expressive language styles\nand contain many imaginary concepts that do not appear in the images. Thus it\nposes challenges to behavioral cloning algorithms. Furthermore, due to the\nlimitations of automatic metrics on evaluating story quality, reinforcement\nlearning methods with hand-crafted rewards also face difficulties in gaining an\noverall performance boost. Therefore, we propose an Adversarial REward Learning\n(AREL) framework to learn an implicit reward function from human\ndemonstrations, and then optimize policy search with the learned reward\nfunction. Though automatic eval- uation indicates slight performance boost over\nstate-of-the-art (SOTA) methods in cloning expert behaviors, human evaluation\nshows that our approach achieves significant improvement in generating more\nhuman-like stories than SOTA systems.", "published": "2018-04-24 17:41:24", "link": "http://arxiv.org/abs/1804.09160v2", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Visual Distance for WordNet", "abstract": "Measuring the distance between concepts is an important field of study of\nNatural Language Processing, as it can be used to improve tasks related to the\ninterpretation of those same concepts. WordNet, which includes a wide variety\nof concepts associated with words (i.e., synsets), is often used as a source\nfor computing those distances. In this paper, we explore a distance for WordNet\nsynsets based on visual features, instead of lexical ones. For this purpose, we\nextract the graphic features generated within a deep convolutional neural\nnetworks trained with ImageNet and use those features to generate a\nrepresentative of each synset. Based on those representatives, we define a\ndistance measure of synsets, which complements the traditional lexical\ndistances. Finally, we propose some experiments to evaluate its performance and\ncompare it with the current state-of-the-art.", "published": "2018-04-24 15:34:33", "link": "http://arxiv.org/abs/1804.09558v2", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Vocal melody extraction using patch-based CNN", "abstract": "A patch-based convolutional neural network (CNN) model presented in this\npaper for vocal melody extraction in polyphonic music is inspired from object\ndetection in image processing. The input of the model is a novel time-frequency\nrepresentation which enhances the pitch contours and suppresses the harmonic\ncomponents of a signal. This succinct data representation and the patch-based\nCNN model enable an efficient training process with limited labeled data.\nExperiments on various datasets show excellent speed and competitive accuracy\ncomparing to other deep learning approaches.", "published": "2018-04-24 18:28:48", "link": "http://arxiv.org/abs/1804.09202v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Perceptual Evaluation of the Effectiveness of Voice Disguise by Age\n  Modification", "abstract": "Voice disguise, purposeful modification of one's speaker identity with the\naim of avoiding being identified as oneself, is a low-effort way to fool\nspeaker recognition, whether performed by a human or an automatic speaker\nverification (ASV) system. We present an evaluation of the effectiveness of age\nstereotypes as a voice disguise strategy, as a follow up to our recent work\nwhere 60 native Finnish speakers attempted to sound like an elderly and like a\nchild. In that study, we presented evidence that both ASV and human observers\ncould easily miss the target speaker but we did not address how believable the\npresented vocal age stereotypes were; this study serves to fill that gap. The\ninteresting cases would be speakers who succeed in being missed by the ASV\nsystem, and which a typical listener cannot detect as being a disguise. We\ncarry out a perceptual test to study the quality of the disguised speech\nsamples. The listening test was carried out both locally and with the help of\nAmazon's Mechanical Turk (MT) crowd-workers. A total of 91 listeners\nparticipated in the test and were instructed to estimate both the speaker's\nchronological and intended age. The results indicate that age estimations for\nthe intended old and child voices for female speakers were towards the target\nage groups, while for male speakers, the age estimations corresponded to the\ndirection of the target voice only for elderly voices. In the case of intended\nchild's voice, listeners estimated the age of male speakers to be older than\ntheir chronological age for most of the speakers and not the intended target\nage.", "published": "2018-04-24 09:07:05", "link": "http://arxiv.org/abs/1804.08910v2", "categories": ["cs.SD", "cs.CY", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A Closer Look at Weak Label Learning for Audio Events", "abstract": "Audio content analysis in terms of sound events is an important research\nproblem for a variety of applications. Recently, the development of weak\nlabeling approaches for audio or sound event detection (AED) and availability\nof large scale weakly labeled dataset have finally opened up the possibility of\nlarge scale AED. However, a deeper understanding of how weak labels affect the\nlearning for sound events is still missing from literature. In this work, we\nfirst describe a CNN based approach for weakly supervised training of audio\nevents. The approach follows some basic design principle desirable in a\nlearning method relying on weakly labeled audio. We then describe important\ncharacteristics, which naturally arise in weakly supervised learning of sound\nevents. We show how these aspects of weak labels affect the generalization of\nmodels. More specifically, we study how characteristics such as label density\nand corruption of labels affects weakly supervised training for audio events.\nWe also study the feasibility of directly obtaining weak labeled data from the\nweb without any manual label and compare it with a dataset which has been\nmanually labeled. The analysis and understanding of these factors should be\ntaken into picture in the development of future weak label learning methods.\nAudioset, a large scale weakly labeled dataset for sound events is used in our\nexperiments.", "published": "2018-04-24 23:04:35", "link": "http://arxiv.org/abs/1804.09288v1", "categories": ["cs.SD", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
