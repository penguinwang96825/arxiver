{"title": "In-Context Operator Learning for Linear Propagator Models", "abstract": "We study operator learning in the context of linear propagator models for\noptimal order execution problems with transient price impact \\`a la Bouchaud et\nal. (2004) and Gatheral (2010). Transient price impact persists and decays over\ntime according to some propagator kernel. Specifically, we propose to use\nIn-Context Operator Networks (ICON), a novel transformer-based neural network\narchitecture introduced by Yang et al. (2023), which facilitates data-driven\nlearning of operators by merging offline pre-training with an online few-shot\nprompting inference. First, we train ICON to learn the operator from various\npropagator models that maps the trading rate to the induced transient price\nimpact. The inference step is then based on in-context prediction, where ICON\nis presented only with a few examples. We illustrate that ICON is capable of\naccurately inferring the underlying price impact model from the data prompts,\neven with propagator kernels not seen in the training data. In a second step,\nwe employ the pre-trained ICON model provided with context as a surrogate\noperator in solving an optimal order execution problem via a neural network\ncontrol policy, and demonstrate that the exact optimal execution strategies\nfrom Abi Jaber and Neuman (2022) for the models generating the context are\ncorrectly retrieved. Our introduced methodology is very general, offering a new\napproach to solving optimal stochastic control problems with unknown state\ndynamics, inferred data-efficiently from a limited number of examples by\nleveraging the few-shot and transfer learning capabilities of transformer\nnetworks.", "published": "2025-01-25 07:15:47", "link": "http://arxiv.org/abs/2501.15106v1", "categories": ["q-fin.TR", "cs.LG", "math.OC", "q-fin.CP", "93E20, 91G60, 68T07"], "primary_category": "q-fin.TR"}
{"title": "Federated Retrieval Augmented Generation for Multi-Product Question\n  Answering", "abstract": "Recent advancements in Large Language Models and Retrieval-Augmented\nGeneration have boosted interest in domain-specific question-answering for\nenterprise products. However, AI Assistants often face challenges in\nmulti-product QA settings, requiring accurate responses across diverse domains.\nExisting multi-domain RAG-QA approaches either query all domains\nindiscriminately, increasing computational costs and LLM hallucinations, or\nrely on rigid resource selection, which can limit search results. We introduce\nMKP-QA, a novel multi-product knowledge-augmented QA framework with\nprobabilistic federated search across domains and relevant knowledge. This\nmethod enhances multi-domain search quality by aggregating query-domain and\nquery-passage probabilistic relevance. To address the lack of suitable\nbenchmarks for multi-product QAs, we also present new datasets focused on three\nAdobe products: Adobe Experience Platform, Target, and Customer Journey\nAnalytics. Our experiments show that MKP-QA significantly boosts multi-product\nRAG-QA performance in terms of both retrieval accuracy and response quality.", "published": "2025-01-25 00:22:27", "link": "http://arxiv.org/abs/2501.14998v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AKVQ-VL: Attention-Aware KV Cache Adaptive 2-Bit Quantization for\n  Vision-Language Models", "abstract": "Vision-language models (VLMs) show remarkable performance in multimodal\ntasks. However, excessively long multimodal inputs lead to oversized Key-Value\n(KV) caches, resulting in significant memory consumption and I/O bottlenecks.\nPrevious KV quantization methods for Large Language Models (LLMs) may alleviate\nthese issues but overlook the attention saliency differences of multimodal\ntokens, resulting in suboptimal performance. In this paper, we investigate the\nattention-aware token saliency patterns in VLM and propose AKVQ-VL. AKVQ-VL\nleverages the proposed Text-Salient Attention (TSA) and Pivot-Token-Salient\nAttention (PSA) patterns to adaptively allocate bit budgets. Moreover,\nachieving extremely low-bit quantization requires effectively addressing\noutliers in KV tensors. AKVQ-VL utilizes the Walsh-Hadamard transform (WHT) to\nconstruct outlier-free KV caches, thereby reducing quantization difficulty.\nEvaluations of 2-bit quantization on 12 long-context and multimodal tasks\ndemonstrate that AKVQ-VL maintains or even improves accuracy, outperforming\nLLM-oriented methods. AKVQ-VL can reduce peak memory usage by 2.13x, support up\nto 3.25x larger batch sizes and 2.46x throughput.", "published": "2025-01-25 02:01:56", "link": "http://arxiv.org/abs/2501.15021v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SCCD: A Session-based Dataset for Chinese Cyberbullying Detection", "abstract": "The rampant spread of cyberbullying content poses a growing threat to\nsocietal well-being. However, research on cyberbullying detection in Chinese\nremains underdeveloped, primarily due to the lack of comprehensive and reliable\ndatasets. Notably, no existing Chinese dataset is specifically tailored for\ncyberbullying detection. Moreover, while comments play a crucial role within\nsessions, current session-based datasets often lack detailed, fine-grained\nannotations at the comment level. To address these limitations, we present a\nnovel Chinese cyber-bullying dataset, termed SCCD, which consists of 677\nsession-level samples sourced from a major social media platform Weibo.\nMoreover, each comment within the sessions is annotated with fine-grained\nlabels rather than conventional binary class labels. Empirically, we evaluate\nthe performance of various baseline methods on SCCD, highlighting the\nchallenges for effective Chinese cyberbullying detection.", "published": "2025-01-25 02:56:40", "link": "http://arxiv.org/abs/2501.15042v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Abstractive Text Summarization for Bangla Language Using NLP and Machine\n  Learning Approaches", "abstract": "Text summarization involves reducing extensive documents to short sentences\nthat encapsulate the essential ideas. The goal is to create a summary that\neffectively conveys the main points of the original text. We spend a\nsignificant amount of time each day reading the newspaper to stay informed\nabout current events both domestically and internationally. While reading\nnewspapers enriches our knowledge, we sometimes come across unnecessary content\nthat isn't particularly relevant to our lives. In this paper, we introduce a\nneural network model designed to summarize Bangla text into concise and\nstraightforward paragraphs, aiming for greater stability and efficiency.", "published": "2025-01-25 03:19:38", "link": "http://arxiv.org/abs/2501.15051v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Cross-modal Context Fusion and Adaptive Graph Convolutional Network for\n  Multimodal Conversational Emotion Recognition", "abstract": "Emotion recognition has a wide range of applications in human-computer\ninteraction, marketing, healthcare, and other fields. In recent years, the\ndevelopment of deep learning technology has provided new methods for emotion\nrecognition. Prior to this, many emotion recognition methods have been\nproposed, including multimodal emotion recognition methods, but these methods\nignore the mutual interference between different input modalities and pay\nlittle attention to the directional dialogue between speakers. Therefore, this\narticle proposes a new multimodal emotion recognition method, including a cross\nmodal context fusion module, an adaptive graph convolutional encoding module,\nand an emotion classification module. The cross modal context module includes a\ncross modal alignment module and a context fusion module, which are used to\nreduce the noise introduced by mutual interference between different input\nmodalities. The adaptive graph convolution module constructs a dialogue\nrelationship graph for extracting dependencies and self dependencies between\nspeakers. Our model has surpassed some state-of-the-art methods on publicly\navailable benchmark datasets and achieved high recognition accuracy.", "published": "2025-01-25 03:53:53", "link": "http://arxiv.org/abs/2501.15063v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LongReason: A Synthetic Long-Context Reasoning Benchmark via Context\n  Expansion", "abstract": "Large language models (LLMs) have demonstrated remarkable progress in\nunderstanding long-context inputs. However, benchmarks for evaluating the\nlong-context reasoning abilities of LLMs fall behind the pace. Existing\nbenchmarks often focus on a narrow range of tasks or those that do not demand\ncomplex reasoning. To address this gap and enable a more comprehensive\nevaluation of the long-context reasoning capabilities of current LLMs, we\npropose a new synthetic benchmark, LongReason, which is constructed by\nsynthesizing long-context reasoning questions from a varied set of\nshort-context reasoning questions through context expansion. LongReason\nconsists of 794 multiple-choice reasoning questions with diverse reasoning\npatterns across three task categories: reading comprehension, logical\ninference, and mathematical word problems. We evaluate 21 LLMs on LongReason,\nrevealing that most models experience significant performance drops as context\nlength increases. Our further analysis shows that even state-of-the-art LLMs\nstill have significant room for improvement in providing robust reasoning\nacross different tasks. We have open-sourced LongReason under\nhttps://huggingface.co/datasets/lz1bytedance/LongReason to support the\ncomprehensive evaluation of LLMs' long-context reasoning capabilities.", "published": "2025-01-25 05:32:14", "link": "http://arxiv.org/abs/2501.15089v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speech Translation Refinement using Large Language Models", "abstract": "Recent advancements in large language models (LLMs) have demonstrated their\nremarkable capabilities across various language tasks. Inspired by the success\nof text-to-text translation refinement, this paper investigates how LLMs can\nimprove the performance of speech translation by introducing a joint refinement\nprocess. Through the joint refinement of speech translation (ST) and automatic\nspeech recognition (ASR) transcription via LLMs, the performance of the ST\nmodel is significantly improved in both training-free in-context learning and\nparameter-efficient fine-tuning scenarios. Additionally, we explore the effect\nof document-level context on refinement under the context-aware fine-tuning\nscenario. Experimental results on the MuST-C and CoVoST 2 datasets, which\ninclude seven translation tasks, demonstrate the effectiveness of the proposed\napproach using several popular LLMs including GPT-3.5-turbo, LLaMA3-8B, and\nMistral-12B. Further analysis further suggests that jointly refining both\ntranscription and translation yields better performance compared to refining\ntranslation alone. Meanwhile, incorporating document-level context\nsignificantly enhances refinement performance. We release our code and datasets\non GitHub.", "published": "2025-01-25 05:32:42", "link": "http://arxiv.org/abs/2501.15090v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Knowledge Hierarchy Guided Biological-Medical Dataset Distillation for\n  Domain LLM Training", "abstract": "The rapid advancement of large language models (LLMs) in biological-medical\napplications has highlighted a gap between their potential and the limited\nscale and often low quality of available open-source annotated textual\ndatasets. In addition, the inherent complexity of the biomedical knowledge\nhierarchy significantly hampers efforts to bridge this gap.Can LLMs themselves\nplay a pivotal role in overcoming this limitation? Motivated by this question,\nwe investigate this challenge in the present study.We propose a framework that\nautomates the distillation of high-quality textual training data from the\nextensive scientific literature. Our approach self-evaluates and generates\nquestions that are more closely aligned with the biomedical domain, guided by\nthe biomedical knowledge hierarchy through medical subject headings (MeSH).\nThis comprehensive framework establishes an automated workflow, thereby\neliminating the need for manual intervention. Furthermore, we conducted\ncomprehensive experiments to evaluate the impact of our framework-generated\ndata on downstream language models of varying sizes. Our approach substantially\nimproves question-answering tasks compared to pre-trained models from the life\nsciences domain and powerful close-source models represented by GPT-4. Notably,\nthe generated AI-Ready dataset enabled the Llama3-70B base model to outperform\nGPT-4 using MedPrompt with multiple times the number of parameters. Detailed\ncase studies and ablation experiments underscore the significance of each\ncomponent within our framework", "published": "2025-01-25 07:20:44", "link": "http://arxiv.org/abs/2501.15108v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Task-KV: Task-aware KV Cache Optimization via Semantic Differentiation\n  of Attention Heads", "abstract": "KV cache is a widely used acceleration technique for large language models\n(LLMs) inference. However, its memory requirement grows rapidly with input\nlength. Previous studies have reduced the size of KV cache by either removing\nthe same number of unimportant tokens for all attention heads or by allocating\ndifferentiated KV cache budgets for pre-identified attention heads. However,\ndue to the importance of attention heads varies across different tasks, the\npre-identified attention heads fail to adapt effectively to various downstream\ntasks. To address this issue, we propose Task-KV, a method that leverages the\nsemantic differentiation of attention heads to allocate differentiated KV cache\nbudgets across various tasks. We demonstrate that attention heads far from the\nsemantic center (called heterogeneous heads) make an significant contribution\nto task outputs and semantic understanding. In contrast, other attention heads\nplay the role of aggregating important information and focusing reasoning.\nTask-KV allocates full KV cache budget to heterogeneous heads to preserve\ncomprehensive semantic information, while reserving a small number of recent\ntokens and attention sinks for non-heterogeneous heads. Furthermore, we\ninnovatively introduce middle activations to preserve key contextual\ninformation aggregated from non-heterogeneous heads. To dynamically perceive\nsemantic differences among attention heads, we design a semantic separator to\ndistinguish heterogeneous heads from non-heterogeneous ones based on their\ndistances from the semantic center. Experimental results on multiple benchmarks\nand different model architectures demonstrate that Task-KV significantly\noutperforms existing baseline methods.", "published": "2025-01-25 07:28:13", "link": "http://arxiv.org/abs/2501.15113v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Faster Machine Translation Ensembling with Reinforcement Learning and\n  Competitive Correction", "abstract": "Ensembling neural machine translation (NMT) models to produce higher-quality\ntranslations than the $L$ individual models has been extensively studied.\nRecent methods typically employ a candidate selection block (CSB) and an\nencoder-decoder fusion block (FB), requiring inference across \\textit{all}\ncandidate models, leading to significant computational overhead, generally\n$\\Omega(L)$. This paper introduces \\textbf{SmartGen}, a reinforcement learning\n(RL)-based strategy that improves the CSB by selecting a small, fixed number of\ncandidates and identifying optimal groups to pass to the fusion block for each\ninput sentence. Furthermore, previously, the CSB and FB were trained\nindependently, leading to suboptimal NMT performance. Our DQN-based\n\\textbf{SmartGen} addresses this by using feedback from the FB block as a\nreward during training. We also resolve a key issue in earlier methods, where\ncandidates were passed to the FB without modification, by introducing a\nCompetitive Correction Block (CCB). Finally, we validate our approach with\nextensive experiments on English-Hindi translation tasks in both directions.", "published": "2025-01-25 13:50:18", "link": "http://arxiv.org/abs/2501.15219v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ASRank: Zero-Shot Re-Ranking with Answer Scent for Document Retrieval", "abstract": "Retrieval-Augmented Generation (RAG) models have drawn considerable attention\nin modern open-domain question answering. The effectiveness of RAG depends on\nthe quality of the top retrieved documents. However, conventional retrieval\nmethods sometimes fail to rank the most relevant documents at the top. In this\npaper, we introduce ASRank, a new re-ranking method based on scoring retrieved\ndocuments using zero-shot answer scent which relies on a pre-trained large\nlanguage model to compute the likelihood of the document-derived answers\naligning with the answer scent. Our approach demonstrates marked improvements\nacross several datasets, including NQ, TriviaQA, WebQA, ArchivalQA, HotpotQA,\nand Entity Questions. Notably, ASRank increases Top-1 retrieval accuracy on NQ\nfrom $19.2\\%$ to $46.5\\%$ for MSS and $22.1\\%$ to $47.3\\%$ for BM25. It also\nshows strong retrieval performance on several datasets compared to\nstate-of-the-art methods (47.3 Top-1 by ASRank vs 35.4 by UPR by BM25).", "published": "2025-01-25 15:27:40", "link": "http://arxiv.org/abs/2501.15245v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "New Evaluation Paradigm for Lexical Simplification", "abstract": "Lexical Simplification (LS) methods use a three-step pipeline: complex word\nidentification, substitute generation, and substitute ranking, each with\nseparate evaluation datasets. We found large language models (LLMs) can\nsimplify sentences directly with a single prompt, bypassing the traditional\npipeline. However, existing LS datasets are not suitable for evaluating these\nLLM-generated simplified sentences, as they focus on providing substitutes for\nsingle complex words without identifying all complex words in a sentence.\n  To address this gap, we propose a new annotation method for constructing an\nall-in-one LS dataset through human-machine collaboration. Automated methods\ngenerate a pool of potential substitutes, which human annotators then assess,\nsuggesting additional alternatives as needed. Additionally, we explore\nLLM-based methods with single prompts, in-context learning, and\nchain-of-thought techniques. We introduce a multi-LLMs collaboration approach\nto simulate each step of the LS task. Experimental results demonstrate that LS\nbased on multi-LLMs approaches significantly outperforms existing baselines.", "published": "2025-01-25 16:31:37", "link": "http://arxiv.org/abs/2501.15268v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Human Interactions Replicable by Generative Agents? A Case Study on\n  Pronoun Usage in Hierarchical Interactions", "abstract": "As Large Language Models (LLMs) advance in their capabilities, researchers\nhave increasingly employed them for social simulation. In this paper, we\ninvestigate whether interactions among LLM agents resemble those of humans.\nSpecifically, we focus on the pronoun usage difference between leaders and\nnon-leaders, examining whether the simulation would lead to human-like pronoun\nusage patterns during the LLMs' interactions. Our evaluation reveals the\nsignificant discrepancies between LLM-based simulations and human pronoun\nusage, with prompt-based or specialized agents failing to demonstrate\nhuman-like pronoun usage patterns. In addition, we reveal that even if LLMs\nunderstand the human pronoun usage patterns, they fail to demonstrate them in\nthe actual interaction process. Our study highlights the limitations of social\nsimulations based on LLM agents, urging caution in using such social simulation\nin practitioners' decision-making process.", "published": "2025-01-25 17:42:47", "link": "http://arxiv.org/abs/2501.15283v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "You Only Prune Once: Designing Calibration-Free Model Compression With\n  Policy Learning", "abstract": "The ever-increasing size of large language models (LLMs) presents significant\nchallenges for deployment due to their heavy computational and memory\nrequirements. Current model pruning techniques attempt to alleviate these\nissues by relying heavily on external calibration datasets to determine which\nparameters to prune or compress, thus limiting their flexibility and\nscalability across different compression ratios. Moreover, these methods often\ncause severe performance degradation, particularly in downstream tasks, when\nsubjected to higher compression rates. In this paper, we propose PruneNet, a\nnovel model compression method that addresses these limitations by\nreformulating model pruning as a policy learning process. PruneNet decouples\nthe pruning process from the model architecture, eliminating the need for\ncalibration datasets. It learns a stochastic pruning policy to assess parameter\nimportance solely based on intrinsic model properties while preserving the\nspectral structure to minimize information loss. PruneNet can compress the\nLLaMA-2-7B model in just 15 minutes, achieving over 80% retention of its\nzero-shot performance with a 30% compression ratio, outperforming existing\nmethods that retain only 75% performance. Furthermore, on complex multitask\nlanguage understanding tasks, PruneNet demonstrates its robustness by\npreserving up to 80% performance of the original model, proving itself a\nsuperior alternative to conventional structured compression techniques.", "published": "2025-01-25 18:26:39", "link": "http://arxiv.org/abs/2501.15296v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MDEval: Evaluating and Enhancing Markdown Awareness in Large Language\n  Models", "abstract": "Large language models (LLMs) are expected to offer structured Markdown\nresponses for the sake of readability in web chatbots (e.g., ChatGPT). Although\nthere are a myriad of metrics to evaluate LLMs, they fail to evaluate the\nreadability from the view of output content structure. To this end, we focus on\nan overlooked yet important metric -- Markdown Awareness, which directly\nimpacts the readability and structure of the content generated by these\nlanguage models. In this paper, we introduce MDEval, a comprehensive benchmark\nto assess Markdown Awareness for LLMs, by constructing a dataset with 20K\ninstances covering 10 subjects in English and Chinese. Unlike traditional\nmodel-based evaluations, MDEval provides excellent interpretability by\ncombining model-based generation tasks and statistical methods. Our results\ndemonstrate that MDEval achieves a Spearman correlation of 0.791 and an\naccuracy of 84.1% with human, outperforming existing methods by a large margin.\nExtensive experimental results also show that through fine-tuning over our\nproposed dataset, less performant open-source models are able to achieve\ncomparable performance to GPT-4o in terms of Markdown Awareness. To ensure\nreproducibility and transparency, MDEval is open sourced at\nhttps://github.com/SWUFE-DB-Group/MDEval-Benchmark.", "published": "2025-01-25 00:26:01", "link": "http://arxiv.org/abs/2501.15000v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Using Large Language Models for education managements in Vietnamese with\n  low resources", "abstract": "Large language models (LLMs), such as GPT-4, Gemini 1.5, Claude 3.5 Sonnet,\nand Llama3, have demonstrated significant advancements in various NLP tasks\nsince the release of ChatGPT in 2022. Despite their success, fine-tuning and\ndeploying LLMs remain computationally expensive, especially in\nresource-constrained environments. In this paper, we proposed VietEduFrame, a\nframework specifically designed to apply LLMs to educational management tasks\nin Vietnamese institutions. Our key contribution includes the development of a\ntailored dataset, derived from student education documents at Hanoi VNU, which\naddresses the unique challenges faced by educational systems with limited\nresources. Through extensive experiments, we show that our approach outperforms\nexisting methods in terms of accuracy and efficiency, offering a promising\nsolution for improving educational management in under-resourced environments.\nWhile our framework leverages synthetic data to supplement real-world examples,\nwe discuss potential limitations regarding broader applicability and robustness\nin future implementations.", "published": "2025-01-25 02:09:51", "link": "http://arxiv.org/abs/2501.15022v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Improving Retrieval-Augmented Generation through Multi-Agent\n  Reinforcement Learning", "abstract": "Retrieval-augmented generation (RAG) is extensively utilized to incorporate\nexternal, current knowledge into large language models, thereby minimizing\nhallucinations. A standard RAG pipeline may comprise several components, such\nas query rewriting, document retrieval, document filtering, and answer\ngeneration. However, these components are typically optimized separately\nthrough supervised fine-tuning, which can lead to misalignments between the\nobjectives of individual modules and the overarching aim of generating accurate\nanswers in question-answering (QA) tasks. Although recent efforts have explored\nreinforcement learning (RL) to optimize specific RAG components, these\napproaches often focus on overly simplistic pipelines with only two components\nor do not adequately address the complex interdependencies and collaborative\ninteractions among the modules. To overcome these challenges, we propose\ntreating the RAG pipeline as a multi-agent cooperative task, with each\ncomponent regarded as an RL agent. Specifically, we present MMOA-RAG, a\nMulti-Module joint Optimization Algorithm for RAG, which employs multi-agent\nreinforcement learning to harmonize all agents' goals towards a unified reward,\nsuch as the F1 score of the final answer. Experiments conducted on various QA\ndatasets demonstrate that MMOA-RAG improves the overall pipeline performance\nand outperforms existing baselines. Furthermore, comprehensive ablation studies\nvalidate the contributions of individual components and the adaptability of\nMMOA-RAG across different RAG components and datasets. The code of MMOA-RAG is\non https://github.com/chenyiqun/MMOA-RAG.", "published": "2025-01-25 14:24:50", "link": "http://arxiv.org/abs/2501.15228v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Prompting ChatGPT for Chinese Learning as L2: A CEFR and EBCL Level\n  Study", "abstract": "The use of chatbots in language learning has evolved significantly since the\n1960s, becoming more sophisticated platforms as generative AI emerged. These\ntools now simulate natural conversations, adapting to individual learners'\nneeds, including those studying Chinese. Our study explores how learners can\nuse specific prompts to engage Large Language Models (LLM) as personalized\nchatbots, aiming to target their language level based on the Common European\nFramework of Reference for Languages (CEFR) and the European Benchmarking\nChinese Language (EBCL) project. Focusing on A1, A1+ and A2 levels, we examine\nthe teaching of Chinese, which presents unique challenges due to its\nlogographic writing system. Our goal is to develop prompts that integrate oral\nand written skills, using high-frequency character lists and controlling oral\nlexical productions. These tools, powered by generative AI, aim to enhance\nlanguage practice by crossing lexical and sinographic recurrence. While\ngenerative AI shows potential as a personalized tutor, further evaluation is\nneeded to assess its effectiveness. We conducted a systematic series of\nexperiments using ChatGPT models to evaluate their adherence to constraints\nspecified in the prompts. The results indicate that incorporating level A1 and\nA1+ characters, along with the associated reference list, significantly\nenhances compliance with the EBCL character set. Properly prompted, LLMs can\nincrease exposure to the target language and offer interactive exchanges to\ndevelop language skills.", "published": "2025-01-25 15:30:13", "link": "http://arxiv.org/abs/2501.15247v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Breaking the Stigma! Unobtrusively Probe Symptoms in Depression Disorder\n  Diagnosis Dialogue", "abstract": "Stigma has emerged as one of the major obstacles to effectively diagnosing\ndepression, as it prevents users from open conversations about their struggles.\nThis requires advanced questioning skills to carefully probe the presence of\nspecific symptoms in an unobtrusive manner. While recent efforts have been made\non depression-diagnosis-oriented dialogue systems, they largely ignore this\nproblem, ultimately hampering their practical utility. To this end, we propose\na novel and effective method, UPSD$^{4}$, developing a series of strategies to\npromote a sense of unobtrusiveness within the dialogue system and assessing\ndepression disorder by probing symptoms. We experimentally show that UPSD$^{4}$\ndemonstrates a significant improvement over current baselines, including\nunobtrusiveness evaluation of dialogue content and diagnostic accuracy. We\nbelieve our work contributes to developing more accessible and user-friendly\ntools for addressing the widespread need for depression diagnosis.", "published": "2025-01-25 16:09:07", "link": "http://arxiv.org/abs/2501.15260v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "PIP: Perturbation-based Iterative Pruning for Large Language Models", "abstract": "The rapid increase in the parameter counts of Large Language Models (LLMs),\nreaching billions or even trillions, presents significant challenges for their\npractical deployment, particularly in resource-constrained environments. To\nease this issue, we propose PIP (Perturbation-based Iterative Pruning), a novel\ndouble-view structured pruning method to optimize LLMs, which combines\ninformation from two different views: the unperturbed view and the perturbed\nview. With the calculation of gradient differences, PIP iteratively prunes\nthose that struggle to distinguish between these two views. Our experiments\nshow that PIP reduces the parameter count by approximately 20% while retaining\nover 85% of the original model's accuracy across varied benchmarks. In some\ncases, the performance of the pruned model is within 5% of the unpruned\nversion, demonstrating PIP's ability to preserve key aspects of model\neffectiveness. Moreover, PIP consistently outperforms existing state-of-the-art\n(SOTA) structured pruning methods, establishing it as a leading technique for\noptimizing LLMs in environments with constrained resources. Our code is\navailable at: https://github.com/caoyiiiiii/PIP.", "published": "2025-01-25 17:10:50", "link": "http://arxiv.org/abs/2501.15278v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ToMoE: Converting Dense Large Language Models to Mixture-of-Experts\n  through Dynamic Structural Pruning", "abstract": "Large Language Models (LLMs) have demonstrated remarkable abilities in\ntackling a wide range of complex tasks. However, their huge computational and\nmemory costs raise significant challenges in deploying these models on\nresource-constrained devices or efficiently serving them. Prior approaches have\nattempted to alleviate these problems by permanently removing less important\nmodel structures, yet these methods often result in substantial performance\ndegradation due to the permanent deletion of model parameters. In this work, we\ntried to mitigate this issue by reducing the number of active parameters\nwithout permanently removing them. Specifically, we introduce a differentiable\ndynamic pruning method that pushes dense models to maintain a fixed number of\nactive parameters by converting their MLP layers into a Mixture of Experts\n(MoE) architecture. Our method, even without fine-tuning, consistently\noutperforms previous structural pruning techniques across diverse model\nfamilies, including Phi-2, LLaMA-2, LLaMA-3, and Qwen-2.5.", "published": "2025-01-25 20:01:42", "link": "http://arxiv.org/abs/2501.15316v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Figurative-cum-Commonsense Knowledge Infusion for Multimodal Mental\n  Health Meme Classification", "abstract": "The expression of mental health symptoms through non-traditional means, such\nas memes, has gained remarkable attention over the past few years, with users\noften highlighting their mental health struggles through figurative intricacies\nwithin memes. While humans rely on commonsense knowledge to interpret these\ncomplex expressions, current Multimodal Language Models (MLMs) struggle to\ncapture these figurative aspects inherent in memes. To address this gap, we\nintroduce a novel dataset, AxiOM, derived from the GAD anxiety questionnaire,\nwhich categorizes memes into six fine-grained anxiety symptoms. Next, we\npropose a commonsense and domain-enriched framework, M3H, to enhance MLMs'\nability to interpret figurative language and commonsense knowledge. The\noverarching goal remains to first understand and then classify the mental\nhealth symptoms expressed in memes. We benchmark M3H against 6 competitive\nbaselines (with 20 variations), demonstrating improvements in both quantitative\nand qualitative metrics, including a detailed human evaluation. We observe a\nclear improvement of 4.20% and 4.66% on weighted-F1 metric. To assess the\ngeneralizability, we perform extensive experiments on a public dataset,\nRESTORE, for depressive symptom identification, presenting an extensive\nablation study that highlights the contribution of each module in both\ndatasets. Our findings reveal limitations in existing models and the advantage\nof employing commonsense to enhance figurative understanding.", "published": "2025-01-25 20:36:21", "link": "http://arxiv.org/abs/2501.15321v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "FBQuant: FeedBack Quantization for Large Language Models", "abstract": "Deploying Large Language Models (LLMs) on edge devices is increasingly\nimportant, as it eliminates reliance on network connections, reduces expensive\nAPI calls, and enhances user privacy. However, on-device deployment is\nchallenging due to the limited computational resources of edge devices. In\nparticular, the key bottleneck stems from memory bandwidth constraints related\nto weight loading. Weight-only quantization effectively reduces memory access,\nyet often induces significant accuracy degradation. Recent efforts to\nincorporate sub-branches have shown promise for mitigating quantization errors,\nbut these methods either lack robust optimization strategies or rely on\nsuboptimal objectives. To address these gaps, we propose FeedBack Quantization\n(FBQuant), a novel approach inspired by negative feedback mechanisms in\nautomatic control. FBQuant inherently ensures that the reconstructed weights\nremain bounded by the quantization process, thereby reducing the risk of\noverfitting. To further offset the additional latency introduced by\nsub-branches, we develop an efficient CUDA kernel that decreases 60\\% of extra\ninference time. Comprehensive experiments demonstrate the efficiency and\neffectiveness of FBQuant across various LLMs. Notably, for 3-bit Llama2-7B,\nFBQuant improves zero-shot accuracy by 1.2\\%.", "published": "2025-01-25 06:04:07", "link": "http://arxiv.org/abs/2501.16385v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "LLM Evaluation Based on Aerospace Manufacturing Expertise: Automated\n  Generation and Multi-Model Question Answering", "abstract": "Aerospace manufacturing demands exceptionally high precision in technical\nparameters. The remarkable performance of Large Language Models (LLMs), such as\nGPT-4 and QWen, in Natural Language Processing has sparked industry interest in\ntheir application to tasks including process design, material selection, and\ntool information retrieval. However, LLMs are prone to generating\n\"hallucinations\" in specialized domains, producing inaccurate or false\ninformation that poses significant risks to the quality of aerospace products\nand flight safety. This paper introduces a set of evaluation metrics tailored\nfor LLMs in aerospace manufacturing, aiming to assess their accuracy by\nanalyzing their performance in answering questions grounded in professional\nknowledge. Firstly, key information is extracted through in-depth textual\nanalysis of classic aerospace manufacturing textbooks and guidelines.\nSubsequently, utilizing LLM generation techniques, we meticulously construct\nmultiple-choice questions with multiple correct answers of varying difficulty.\nFollowing this, different LLM models are employed to answer these questions,\nand their accuracy is recorded. Experimental results demonstrate that the\ncapabilities of LLMs in aerospace professional knowledge are in urgent need of\nimprovement. This study provides a theoretical foundation and practical\nguidance for the application of LLMs in aerospace manufacturing, addressing a\ncritical gap in the field.", "published": "2025-01-25 12:26:44", "link": "http://arxiv.org/abs/2501.17183v2", "categories": ["cs.CL", "cs.AI", "68T50, 90B30", "I.2.7; J.2"], "primary_category": "cs.CL"}
{"title": "OptiSeq: Ordering Examples On-The-Fly for In-Context Learning", "abstract": "Developers using LLMs and LLM-based agents in their applications have\nprovided plenty of anecdotal evidence that in-context-learning (ICL) is\nfragile. In this paper, we show that in addition to the quantity and quality of\nexamples, the order in which the in-context examples are listed in the prompt\naffects the output of the LLM and, consequently, their performance. While prior\nwork has explored improving ICL through dataset-dependent techniques, we\nintroduce OptiSeq, a purely inference-time, dataset-free optimization method\nthat efficiently determines the best example order. OptiSeq leverages log\nprobabilities of LLM-generated outputs to systematically prune the search space\nof possible orderings and recommend the best order(s) by distinguishing\norderings that yield high levels of accuracy and those that underperform.\nExtensive empirical evaluation on multiple LLMs, datasets, and prompts\ndemonstrate that OptiSeq improves accuracy by 5.5 - 10.5 percentage points\nacross multiple tasks.", "published": "2025-01-25 02:24:00", "link": "http://arxiv.org/abs/2501.15030v2", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.PF"], "primary_category": "cs.LG"}
{"title": "An Attempt to Unraveling Token Prediction Refinement and Identifying\n  Essential Layers of Large Language Models", "abstract": "This research aims to unravel how large language models (LLMs) iteratively\nrefine token predictions (or, in a general sense, vector predictions). We\nutilized a logit lens technique to analyze the model's token predictions\nderived from intermediate representations. Specifically, we focused on how LLMs\naccess and use information from input contexts, and how positioning of relevant\ninformation affects the model's token prediction refinement process. Our\nfindings for multi-document question answering task, by varying input context\nlengths (the number of documents), using GPT-2, revealed that the number of\nlayers between the first layer that the model predicted next tokens correctly\nand the later layers that the model finalized its correct predictions, as a\nfunction of the position of relevant information (i.e., placing the relevant\none at the beginning, middle, or end of the input context), has a nearly\ninverted U shape. We found that the gap between these two layers, on average,\ndiminishes when relevant information is positioned at the beginning or end of\nthe input context, suggesting that the model requires more refinements when\nprocessing longer contexts with relevant information situated in the middle,\nand highlighting which layers are essential for determining the correct output.\nOur analysis provides insights about how token predictions are distributed\nacross different conditions, and establishes important connections to existing\nhypotheses and previous findings in AI safety research and development.", "published": "2025-01-25 03:34:15", "link": "http://arxiv.org/abs/2501.15054v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Feedback-Aware Monte Carlo Tree Search for Efficient Information Seeking\n  in Goal-Oriented Conversations", "abstract": "The ability to identify and acquire missing information is a critical\ncomponent of effective decision making and problem solving. With the rise of\nconversational artificial intelligence (AI) systems, strategically formulating\ninformation-seeking questions becomes crucial and demands efficient methods to\nguide the search process. We introduce a novel approach to adaptive\nquestion-asking through a combination of Large Language Models (LLM) for\ngenerating questions that maximize information gain, Monte Carlo Tree Search\n(MCTS) for constructing and leveraging a decision tree across multiple samples,\nand a hierarchical feedback mechanism to learn from past interactions. We\npresent two key innovations: (1) an adaptive MCTS algorithm that balances\nexploration and exploitation for efficient search over potential questions; and\n(2) a clustering-based feedback algorithm that leverages prior experience to\nguide future interactions. Each incoming sample is assigned to a cluster based\non its semantic similarity with previously observed samples. Our UCT (Upper\nConfidence bound for Trees) formulation selects optimal questions by combining\nexpected rewards, a function of information gain, with a cluster-specific bonus\nthat decays with depth, to emphasize the importance of early-stage questions\nthat have proven effective for narrowing the solution space in similar samples.\nExperiments across three domains, including medical diagnosis and\ntroubleshooting, demonstrate that our method leads to an average of 12%\nimprovement in success rates and a 10x reduction in the average number of LLM\ncalls made per conversation for the search process, in comparison to the state\nof the art.", "published": "2025-01-25 03:42:22", "link": "http://arxiv.org/abs/2501.15056v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Analyzing and Boosting the Power of Fine-Grained Visual Recognition for\n  Multi-modal Large Language Models", "abstract": "Multi-modal large language models (MLLMs) have shown remarkable abilities in\nvarious visual understanding tasks. However, MLLMs still struggle with\nfine-grained visual recognition (FGVR), which aims to identify\nsubordinate-level categories from images. This can negatively impact more\nadvanced capabilities of MLLMs, such as object-centric visual question\nanswering and reasoning. In our study, we revisit three quintessential\ncapabilities of MLLMs for FGVR, including object information extraction,\ncategory knowledge reserve, object-category alignment, and position of the root\ncause as a misalignment problem. To address this issue, we present Finedefics,\nan MLLM that enhances the model's FGVR capability by incorporating informative\nattribute descriptions of objects into the training phase. We employ\ncontrastive learning on object-attribute pairs and attribute-category pairs\nsimultaneously and use examples from similar but incorrect categories as hard\nnegatives, naturally bringing representations of visual objects and category\nnames closer. Extensive evaluations across multiple popular FGVR datasets\ndemonstrate that Finedefics outperforms existing MLLMs of comparable parameter\nsizes, showcasing its remarkable efficacy. The code is available at\nhttps://github.com/PKU-ICST-MIPL/Finedefics_ICLR2025.", "published": "2025-01-25 08:52:43", "link": "http://arxiv.org/abs/2501.15140v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Option-ID Based Elimination For Multiple Choice Questions", "abstract": "Multiple choice questions (MCQs) are a popular and important task for\nevaluating large language models (LLMs). Based on common strategies people use\nwhen answering MCQs, the process of elimination (PoE) has been proposed as an\neffective problem-solving method. Existing methods to the PoE generally fall\ninto two categories: one involves having the LLM directly select the incorrect\noptions, while the other involves scoring the options. However, both methods\nincur high computational costs and often perform worse than methods that\ndirectly answer the MCQs with the option IDs. To address this issue, this paper\nproposes a PoE based on option ID. Specifically, our method eliminates option\nby selecting the option ID with the lowest probability. We conduct experiments\nwith 10 different LLMs in zero-shot settings on 7 publicly available datasets.\nThe experimental results demonstrate that our method significantly improves the\nLLM's performance. Further analysis reveals that the sequential elimination\nstrategy can effectively enhance the LLM's reasoning ability. Additionally, we\nfind that sequential elimination is also applicable to few-shot settings and\ncan be combined with debias methods to further improve LLM's performance.", "published": "2025-01-25 11:06:37", "link": "http://arxiv.org/abs/2501.15175v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Who is the root in a syntactic dependency structure?", "abstract": "The syntactic structure of a sentence can be described as a tree that\nindicates the syntactic relationships between words. In spite of significant\nprogress in unsupervised methods that retrieve the syntactic structure of\nsentences, guessing the right direction of edges is still a challenge. As in a\nsyntactic dependency structure edges are oriented away from the root, the\nchallenge of guessing the right direction can be reduced to finding an\nundirected tree and the root. The limited performance of current unsupervised\nmethods demonstrates the lack of a proper understanding of what a root vertex\nis from first principles. We consider an ensemble of centrality scores, some\nthat only take into account the free tree (non-spatial scores) and others that\ntake into account the position of vertices (spatial scores). We test the\nhypothesis that the root vertex is an important or central vertex of the\nsyntactic dependency structure. We confirm that hypothesis and find that the\nbest performance in guessing the root is achieved by novel scores that only\ntake into account the position of a vertex and that of its neighbours. We\nprovide theoretical and empirical foundations towards a universal notion of\nrootness from a network science perspective.", "published": "2025-01-25 11:52:15", "link": "http://arxiv.org/abs/2501.15188v2", "categories": ["cs.CL", "cs.SI", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "SEAL: Scaling to Emphasize Attention for Long-Context Retrieval", "abstract": "In this work, we introduce a novel approach called Scaling to Emphasize\nAttention for Long-context retrieval (SEAL), which enhances the retrieval\nperformance of large language models (LLMs) over extended contexts. Previous\nstudies have shown that each attention head in LLMs has a unique functionality\nand collectively contributes to the overall behavior of the model. Similarly,\nwe observe that specific heads are closely tied to long-context retrieval,\nshowing positive or negative correlation with retrieval scores. Built on this\ninsight, we propose a learning-based mechanism using zero-shot generated data\nto emphasize these heads, improving the model's performance in long-context\nretrieval tasks. By applying SEAL, we can achieve significant improvements in\nin-domain retrieval performance, including document QA tasks from LongBench,\nand considerable improvements in out-of-domain cases. Additionally, when\ncombined with existing training-free context extension techniques, SEAL extends\nthe context limits of LLMs while maintaining highly reliable outputs, opening\nnew avenues for research in this field.", "published": "2025-01-25 14:09:39", "link": "http://arxiv.org/abs/2501.15225v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Inductive Biases for Zero-shot Systematic Generalization in\n  Language-informed Reinforcement Learning", "abstract": "Sample efficiency and systematic generalization are two long-standing\nchallenges in reinforcement learning. Previous studies have shown that\ninvolving natural language along with other observation modalities can improve\ngeneralization and sample efficiency due to its compositional and open-ended\nnature. However, to transfer these properties of language to the\ndecision-making process, it is necessary to establish a proper language\ngrounding mechanism. One approach to this problem is applying inductive biases\nto extract fine-grained and informative representations from the observations,\nwhich makes them more connectable to the language units. We provide\narchitecture-level inductive biases for modularity and sparsity mainly based on\nNeural Production Systems (NPS). Alongside NPS, we assign a central role to\nmemory in our architecture. It can be seen as a high-level information\naggregator which feeds policy/value heads with comprehensive information and\nsimultaneously guides selective attention in NPS through attentional feedback.\nOur results in the BabyAI environment suggest that the proposed model's\nsystematic generalization and sample efficiency are improved significantly\ncompared to previous models. An extensive ablation study on variants of the\nproposed method is conducted, and the effectiveness of each employed technique\non generalization, sample efficiency, and training stability is specified.", "published": "2025-01-25 16:36:59", "link": "http://arxiv.org/abs/2501.15270v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Pre-training a Transformer-Based Generative Model Using a Small Sepedi\n  Dataset", "abstract": "Due to the scarcity of data in low-resourced languages, the development of\nlanguage models for these languages has been very slow. Currently, pre-trained\nlanguage models have gained popularity in natural language processing,\nespecially, in developing domain-specific models for low-resourced languages.\nIn this study, we experiment with the impact of using occlusion-based\ntechniques when training a language model for a text generation task. We curate\n2 new datasets, the Sepedi monolingual (SepMono) dataset from several South\nAfrican resources and the Sepedi radio news (SepNews) dataset from the radio\nnews domain. We use the SepMono dataset to pre-train transformer-based models\nusing the occlusion and non-occlusion pre-training techniques and compare\nperformance. The SepNews dataset is specifically used for fine-tuning. Our\nresults show that the non-occlusion models perform better compared to the\nocclusion-based models when measuring validation loss and perplexity. However,\nanalysis of the generated text using the BLEU score metric, which measures the\nquality of the generated text, shows a slightly higher BLEU score for the\nocclusion-based models compared to the non-occlusion models.", "published": "2025-01-25 17:25:06", "link": "http://arxiv.org/abs/2501.15281v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "The Multicultural Medical Assistant: Can LLMs Improve Medical ASR Errors\n  Across Borders?", "abstract": "The global adoption of Large Language Models (LLMs) in healthcare shows\npromise to enhance clinical workflows and improve patient outcomes. However,\nAutomatic Speech Recognition (ASR) errors in critical medical terms remain a\nsignificant challenge. These errors can compromise patient care and safety if\nnot detected. This study investigates the prevalence and impact of ASR errors\nin medical transcription in Nigeria, the United Kingdom, and the United States.\nBy evaluating raw and LLM-corrected transcriptions of accented English in these\nregions, we assess the potential and limitations of LLMs to address challenges\nrelated to accents and medical terminology in ASR. Our findings highlight\nsignificant disparities in ASR accuracy across regions and identify specific\nconditions under which LLM corrections are most effective.", "published": "2025-01-25 19:40:26", "link": "http://arxiv.org/abs/2501.15310v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "RotateKV: Accurate and Robust 2-Bit KV Cache Quantization for LLMs via\n  Outlier-Aware Adaptive Rotations", "abstract": "Key-Value (KV) cache facilitates efficient large language models (LLMs)\ninference by avoiding recomputation of past KVs. As the batch size and context\nlength increase, the oversized KV caches become a significant memory\nbottleneck, highlighting the need for efficient compression. Existing KV\nquantization rely on fine-grained quantization or the retention of a\nsignificant portion of high bit-widths caches, both of which compromise\ncompression ratio and often fail to maintain robustness at extremely low\naverage bit-widths. In this work, we explore the potential of rotation\ntechnique for 2-bit KV quantization and propose RotateKV, which achieves\naccurate and robust performance through the following innovations: (i)\nOutlier-Aware Rotation, which utilizes channel-reordering to adapt the\nrotations to varying channel-wise outlier distributions without sacrificing the\ncomputational efficiency of the fast Walsh-Hadamard transform (FWHT); (ii)\nPre-RoPE Grouped-Head Rotation, which mitigates the impact of rotary position\nembedding (RoPE) on proposed outlier-aware rotation and further smooths\noutliers across heads; (iii) Attention-Sink-Aware Quantization, which leverages\nthe massive activations to precisely identify and protect attention sinks.\nRotateKV achieves less than 0.3 perplexity (PPL) degradation with 2-bit\nquantization on WikiText-2 using LLaMA-2-13B, maintains strong CoT reasoning\nand long-context capabilities, with less than 1.7\\% degradation on GSM8K,\noutperforming existing methods even at lower average bit-widths. RotateKV also\nshowcases a 3.97x reduction in peak memory usage, supports 5.75x larger batch\nsizes, and achieves a 2.32x speedup in decoding stage.", "published": "2025-01-25 01:45:29", "link": "http://arxiv.org/abs/2501.16383v2", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "An AI-Driven Live Systematic Reviews in the Brain-Heart Interconnectome:\n  Minimizing Research Waste and Advancing Evidence Synthesis", "abstract": "The Brain-Heart Interconnectome (BHI) combines neurology and cardiology but\nis hindered by inefficiencies in evidence synthesis, poor adherence to quality\nstandards, and research waste. To address these challenges, we developed an\nAI-driven system to enhance systematic reviews in the BHI domain. The system\nintegrates automated detection of Population, Intervention, Comparator,\nOutcome, and Study design (PICOS), semantic search using vector embeddings,\ngraph-based querying, and topic modeling to identify redundancies and\nunderexplored areas. Core components include a Bi-LSTM model achieving 87%\naccuracy for PICOS compliance, a study design classifier with 95.7% accuracy,\nand Retrieval-Augmented Generation (RAG) with GPT-3.5, which outperformed GPT-4\nfor graph-based and topic-driven queries. The system provides real-time\nupdates, reducing research waste through a living database and offering an\ninteractive interface with dashboards and conversational AI. While initially\ndeveloped for BHI, the system's adaptable architecture enables its application\nacross various biomedical fields, supporting rigorous evidence synthesis,\nefficient resource allocation, and informed clinical decision-making.", "published": "2025-01-25 03:51:07", "link": "http://arxiv.org/abs/2501.17181v1", "categories": ["cs.AI", "cs.CL", "cs.DL", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Dialogue Systems for Emotional Support via Value Reinforcement", "abstract": "Emotional support dialogue systems aim to reduce help-seekers' distress and\nhelp them overcome challenges. While human values$\\unicode{x2013}$core beliefs\nthat shape an individual's priorities$\\unicode{x2013}$are increasingly\nemphasized in contemporary psychological therapy for their role in fostering\ninternal transformation and long-term emotional well-being, their integration\ninto emotional support systems remains underexplored. To bridge this gap, we\npresent a value-driven method for training emotional support dialogue systems\ndesigned to reinforce positive values in seekers. Notably, our model identifies\nwhich values to reinforce at each turn and how to do so, by leveraging online\nsupport conversations from Reddit. We evaluate the method across support\nskills, seekers' emotional intensity, and value reinforcement. Our method\nconsistently outperforms various baselines, effectively exploring and eliciting\nvalues from seekers. Additionally, leveraging crowd knowledge from Reddit\nsignificantly enhances its effectiveness. Therapists highlighted its ability to\nvalidate seekers' challenges and emphasize positive aspects of their\nsituations$\\unicode{x2013}$both crucial elements of value reinforcement. Our\nwork, being the first to integrate value reinforcement into emotional support\nsystems, demonstrates its promise and establishes a foundation for future\nresearch.", "published": "2025-01-25 11:51:31", "link": "http://arxiv.org/abs/2501.17182v2", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "I.2.7"], "primary_category": "cs.CL"}
{"title": "TrustDataFilter:Leveraging Trusted Knowledge Base Data for More\n  Effective Filtering of Unknown Information", "abstract": "With the advancement of technology and changes in the market, the demand for\nthe construction of domain-specific knowledge bases has been increasing, either\nto improve model performance or to promote enterprise innovation and\ncompetitiveness. The construction of domain-specific knowledge bases typically\nrelies on web crawlers or existing industry databases, leading to problems with\naccuracy and consistency of the data. To address these challenges, we\nconsidered the characteristics of domain data, where internal knowledge is\ninterconnected, and proposed the Self-Natural Language Inference Data Filtering\n(self-nli-TDF) framework. This framework compares trusted filtered knowledge\nwith the data to be filtered, deducing the reasoning relationship between them,\nthus improving filtering performance. The framework uses plug-and-play large\nlanguage models for trustworthiness assessment and employs the RoBERTa-MNLI\nmodel from the NLI domain for reasoning. We constructed three datasets in the\ndomains of biology, radiation, and science, and conducted experiments using\nRoBERTa, GPT3.5, and the local Qwen2 model. The experimental results show that\nthis framework improves filter quality, producing more consistent and reliable\nfiltering results.", "published": "2025-01-25 04:18:35", "link": "http://arxiv.org/abs/2502.15714v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "The ICME 2025 Audio Encoder Capability Challenge", "abstract": "This challenge aims to evaluate the capabilities of audio encoders,\nespecially in the context of multi-task learning and real-world applications.\nParticipants are invited to submit pre-trained audio encoders that map raw\nwaveforms to continuous embeddings. These encoders will be tested across\ndiverse tasks including speech, environmental sounds, and music, with a focus\non real-world usability. The challenge features two tracks: Track A for\nparameterized evaluation, and Track B for parameter-free evaluation. This\nchallenge provides a platform for evaluating and advancing the state-of-the-art\nin audio encoder design.", "published": "2025-01-25 18:56:40", "link": "http://arxiv.org/abs/2501.15302v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Robust Cross-Etiology and Speaker-Independent Dysarthric Speech\n  Recognition", "abstract": "In this paper, we present a speaker-independent dysarthric speech recognition\nsystem, with a focus on evaluating the recently released Speech Accessibility\nProject (SAP-1005) dataset, which includes speech data from individuals with\nParkinson's disease (PD). Despite the growing body of research in dysarthric\nspeech recognition, many existing systems are speaker-dependent and adaptive,\nlimiting their generalizability across different speakers and etiologies. Our\nprimary objective is to develop a robust speaker-independent model capable of\naccurately recognizing dysarthric speech, irrespective of the speaker.\nAdditionally, as a secondary objective, we aim to test the cross-etiology\nperformance of our model by evaluating it on the TORGO dataset, which contains\nspeech samples from individuals with cerebral palsy (CP) and amyotrophic\nlateral sclerosis (ALS). By leveraging the Whisper model, our\nspeaker-independent system achieved a CER of 6.99% and a WER of 10.71% on the\nSAP-1005 dataset. Further, in cross-etiology settings, we achieved a CER of\n25.08% and a WER of 39.56% on the TORGO dataset. These results highlight the\npotential of our approach to generalize across unseen speakers and different\netiologies of dysarthria.", "published": "2025-01-25 00:02:58", "link": "http://arxiv.org/abs/2501.14994v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Stealthy Voice Eavesdropping with Acoustic Metamaterials: Unraveling a\n  New Privacy Threat", "abstract": "We present SuperEar, a novel privacy threat based on acoustic metamaterials.\nUnlike previous research, SuperEar can surreptitiously track and eavesdrop on\nthe phone calls of a moving outdoor target from a safe distance. To design this\nattack, SuperEar overcomes the challenges faced by traditional acoustic\nmetamaterials, including low low-frequency gain and audio distortion during\nreconstruction. It successfully magnifies the speech signal by approximately 20\ntimes, allowing the sound to be captured from the earpiece of the target phone.\nIn addition, SuperEar optimizes the trade-off between the number and size of\nacoustic metamaterials, improving the portability and concealability of the\ninterceptor while ensuring effective interception performance. This makes it\nhighly suitable for outdoor tracking and eavesdropping scenarios. Through\nextensive experimentation, we have evaluated SuperEar and our results show that\nit can achieve an eavesdropping accuracy of over 80% within a range of 4.5\nmeters in the aforementioned scenario, thus validating its great potential in\nreal-world applications.", "published": "2025-01-25 02:30:03", "link": "http://arxiv.org/abs/2501.15032v1", "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio-Language Models for Audio-Centric Tasks: A survey", "abstract": "Audio-Language Models (ALMs), which are trained on audio-text data, focus on\nthe processing, understanding, and reasoning of sounds. Unlike traditional\nsupervised learning approaches learning from predefined labels, ALMs utilize\nnatural language as a supervision signal, which is more suitable for describing\ncomplex real-world audio recordings. ALMs demonstrate strong zero-shot\ncapabilities and can be flexibly adapted to diverse downstream tasks. These\nstrengths not only enhance the accuracy and generalization of audio processing\ntasks but also promote the development of models that more closely resemble\nhuman auditory perception and comprehension. Recent advances in ALMs have\npositioned them at the forefront of computer audition research, inspiring a\nsurge of efforts to advance ALM technologies. Despite rapid progress in the\nfield of ALMs, there is still a notable lack of systematic surveys that\ncomprehensively organize and analyze developments. In this paper, we present a\ncomprehensive review of ALMs with a focus on general audio tasks, aiming to\nfill this gap by providing a structured and holistic overview of ALMs.\nSpecifically, we cover: (1) the background of computer audition and\naudio-language models; (2) the foundational aspects of ALMs, including\nprevalent network architectures, training objectives, and evaluation methods;\n(3) foundational pre-training and audio-language pre-training approaches; (4)\ntask-specific fine-tuning, multi-task tuning and agent systems for downstream\napplications; (5) datasets and benchmarks; and (6) current challenges and\nfuture directions. Our review provides a clear technical roadmap for\nresearchers to understand the development and future trends of existing\ntechnologies, offering valuable references for implementation in real-world\nscenarios.", "published": "2025-01-25 11:15:06", "link": "http://arxiv.org/abs/2501.15177v1", "categories": ["cs.SD", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Music Generation using Human-In-The-Loop Reinforcement Learning", "abstract": "This paper presents an approach that combines Human-In-The-Loop Reinforcement\nLearning (HITL RL) with principles derived from music theory to facilitate\nreal-time generation of musical compositions. HITL RL, previously employed in\ndiverse applications such as modelling humanoid robot mechanics and enhancing\nlanguage models, harnesses human feedback to refine the training process. In\nthis study, we develop a HILT RL framework that can leverage the constraints\nand principles in music theory. In particular, we propose an episodic tabular\nQ-learning algorithm with an epsilon-greedy exploration policy. The system\ngenerates musical tracks (compositions), continuously enhancing its quality\nthrough iterative human-in-the-loop feedback. The reward function for this\nprocess is the subjective musical taste of the user.", "published": "2025-01-25 19:01:51", "link": "http://arxiv.org/abs/2501.15304v1", "categories": ["cs.SD", "cs.AI", "cs.HC", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
