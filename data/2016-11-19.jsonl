{"title": "Tracking Words in Chinese Poetry of Tang and Song Dynasties with the\n  China Biographical Database", "abstract": "Large-scale comparisons between the poetry of Tang and Song dynasties shed\nlight on how words, collocations, and expressions were used and shared among\nthe poets. That some words were used only in the Tang poetry and some only in\nthe Song poetry could lead to interesting research in linguistics. That the\nmost frequent colors are different in the Tang and Song poetry provides a trace\nof the changing social circumstances in the dynasties. Results of the current\nwork link to research topics of lexicography, semantics, and social\ntransitions. We discuss our findings and present our algorithms for efficient\ncomparisons among the poems, which are crucial for completing billion times of\ncomparisons within acceptable time.", "published": "2016-11-19 07:14:59", "link": "http://arxiv.org/abs/1611.06320v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Incorporating Pass-Phrase Dependent Background Models for Text-Dependent\n  Speaker Verification", "abstract": "In this paper, we propose pass-phrase dependent background models (PBMs) for\ntext-dependent (TD) speaker verification (SV) to integrate the pass-phrase\nidentification process into the conventional TD-SV system, where a PBM is\nderived from a text-independent background model through adaptation using the\nutterances of a particular pass-phrase. During training, pass-phrase specific\ntarget speaker models are derived from the particular PBM using the training\ndata for the respective target model. While testing, the best PBM is first\nselected for the test utterance in the maximum likelihood (ML) sense and the\nselected PBM is then used for the log likelihood ratio (LLR) calculation with\nrespect to the claimant model. The proposed method incorporates the pass-phrase\nidentification step in the LLR calculation, which is not considered in\nconventional standalone TD-SV systems. The performance of the proposed method\nis compared to conventional text-independent background model based TD-SV\nsystems using either Gaussian mixture model (GMM)-universal background model\n(UBM) or Hidden Markov model (HMM)-UBM or i-vector paradigms. In addition, we\nconsider two approaches to build PBMs: speaker-independent and\nspeaker-dependent. We show that the proposed method significantly reduces the\nerror rates of text-dependent speaker verification for the non-target types:\ntarget-wrong and imposter-wrong while it maintains comparable TD-SV performance\nwhen imposters speak a correct utterance with respect to the conventional\nsystem. Experiments are conducted on the RedDots challenge and the RSR2015\ndatabases that consist of short utterances.", "published": "2016-11-19 20:12:19", "link": "http://arxiv.org/abs/1611.06423v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Spotting Rumors via Novelty Detection", "abstract": "Rumour detection is hard because the most accurate systems operate\nretrospectively, only recognizing rumours once they have collected repeated\nsignals. By then the rumours might have already spread and caused harm. We\nintroduce a new category of features based on novelty, tailored to detect\nrumours early on. To compensate for the absence of repeated signals, we make\nuse of news wire as an additional data source. Unconfirmed (novel) information\nwith respect to the news articles is considered as an indication of rumours.\nAdditionally we introduce pseudo feedback, which assumes that documents that\nare similar to previous rumours, are more likely to also be a rumour.\nComparison with other real-time approaches shows that novelty based features in\nconjunction with pseudo feedback perform significantly better, when detecting\nrumours instantly after their publication.", "published": "2016-11-19 07:23:10", "link": "http://arxiv.org/abs/1611.06322v1", "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "cs.SI"}
