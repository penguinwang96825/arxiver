{"title": "Automatically Segmenting Oral History Transcripts", "abstract": "Dividing oral histories into topically coherent segments can make them more\naccessible online. People regularly make judgments about where coherent\nsegments can be extracted from oral histories. But making these judgments can\nbe taxing, so automated assistance is potentially attractive to speed the task\nof extracting segments from open-ended interviews. When different people are\nasked to extract coherent segments from the same oral histories, they often do\nnot agree about precisely where such segments begin and end. This low agreement\nmakes the evaluation of algorithmic segmenters challenging, but there is reason\nto believe that for segmenting oral history transcripts, some approaches are\nmore promising than others. The BayesSeg algorithm performs slightly better\nthan TextTiling, while TextTiling does not perform significantly better than a\nuniform segmentation. BayesSeg might be used to suggest boundaries to someone\nsegmenting oral histories, but this segmentation task needs to be better\ndefined.", "published": "2015-09-29 16:46:52", "link": "http://arxiv.org/abs/1509.08842v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Polish - English Speech Statistical Machine Translation Systems for the\n  IWSLT 2014", "abstract": "This research explores effects of various training settings between Polish\nand English Statistical Machine Translation systems for spoken language.\nVarious elements of the TED parallel text corpora for the IWSLT 2014 evaluation\ncampaign were used as the basis for training of language models, and for\ndevelopment, tuning and testing of the translation system as well as Wikipedia\nbased comparable corpora prepared by us. The BLEU, NIST, METEOR and TER metrics\nwere used to evaluate the effects of data preparations on translation results.\nOur experiments included systems, which use lemma and morphological information\non Polish words. We also conducted a deep analysis of provided Polish data as\npreparatory work for the automatic data correction and cleaning phase.", "published": "2015-09-29 18:17:22", "link": "http://arxiv.org/abs/1509.08874v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Very Deep Multilingual Convolutional Neural Networks for LVCSR", "abstract": "Convolutional neural networks (CNNs) are a standard component of many current\nstate-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR)\nsystems. However, CNNs in LVCSR have not kept pace with recent advances in\nother domains where deeper neural networks provide superior performance. In\nthis paper we propose a number of architectural advances in CNNs for LVCSR.\nFirst, we introduce a very deep convolutional network architecture with up to\n14 weight layers. There are multiple convolutional layers before each pooling\nlayer, with small 3x3 kernels, inspired by the VGG Imagenet 2014 architecture.\nThen, we introduce multilingual CNNs with multiple untied layers. Finally, we\nintroduce multi-scale input features aimed at exploiting more context at\nnegligible computational cost. We evaluate the improvements first on a Babel\ntask for low resource speech recognition, obtaining an absolute 5.77% WER\nimprovement over the baseline PLP DNN by training our CNN on the combined data\nof six different languages. We then evaluate the very deep CNNs on the Hub5'00\nbenchmark (using the 262 hours of SWB-1 training data) achieving a word error\nrate of 11.8% after cross-entropy training, a 1.4% WER improvement (10.6%\nrelative) over the best published CNN result so far.", "published": "2015-09-29 22:28:11", "link": "http://arxiv.org/abs/1509.08967v2", "categories": ["cs.CL", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Tuned and GPU-accelerated parallel data mining from comparable corpora", "abstract": "The multilingual nature of the world makes translation a crucial requirement\ntoday. Parallel dictionaries constructed by humans are a widely-available\nresource, but they are limited and do not provide enough coverage for good\nquality translation purposes, due to out-of-vocabulary words and neologisms.\nThis motivates the use of statistical translation systems, which are\nunfortunately dependent on the quantity and quality of training data. Such has\na very limited availability especially for some languages and very narrow text\ndomains. Is this research we present our improvements to Yalign mining\nmethodology by reimplementing the comparison algorithm, introducing a tuning\nscripts and by improving performance using GPU computing acceleration. The\nexperiments are conducted on various text domains and bi-data is extracted from\nthe Wikipedia dumps.", "published": "2015-09-29 08:44:14", "link": "http://arxiv.org/abs/1509.08639v1", "categories": ["cs.CL", "cs.AI", "cs.DS"], "primary_category": "cs.CL"}
{"title": "Neural-based machine translation for medical text domain. Based on\n  European Medicines Agency leaflet texts", "abstract": "The quality of machine translation is rapidly evolving. Today one can find\nseveral machine translation systems on the web that provide reasonable\ntranslations, although the systems are not perfect. In some specific domains,\nthe quality may decrease. A recently proposed approach to this domain is neural\nmachine translation. It aims at building a jointly-tuned single neural network\nthat maximizes translation performance, a very different approach from\ntraditional statistical machine translation. Recently proposed neural machine\ntranslation models often belong to the encoder-decoder family in which a source\nsentence is encoded into a fixed length vector that is, in turn, decoded to\ngenerate a translation. The present research examines the effects of different\ntraining methods on a Polish-English Machine Translation system used for\nmedical data. The European Medicines Agency parallel text corpus was used as\nthe basis for training of neural and statistical network-based translation\nsystems. The main machine translation evaluation metrics have also been used in\nanalysis of the systems. A comparison and implementation of a real-time medical\ntranslator is the main focus of our experiments.", "published": "2015-09-29 08:54:48", "link": "http://arxiv.org/abs/1509.08644v1", "categories": ["cs.CL", "cs.CY", "cs.NE", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Building Subject-aligned Comparable Corpora and Mining it for Truly\n  Parallel Sentence Pairs", "abstract": "Parallel sentences are a relatively scarce but extremely useful resource for\nmany applications including cross-lingual retrieval and statistical machine\ntranslation. This research explores our methodology for mining such data from\npreviously obtained comparable corpora. The task is highly practical since\nnon-parallel multilingual data exist in far greater quantities than parallel\ncorpora, but parallel sentences are a much more useful resource. Here we\npropose a web crawling method for building subject-aligned comparable corpora\nfrom Wikipedia articles. We also introduce a method for extracting truly\nparallel sentences that are filtered out from noisy or just comparable sentence\npairs. We describe our implementation of a specialized tool for this task as\nwell as training and adaption of a machine translation system that supplies our\nfilter with additional information about the similarity of comparable sentence\npairs.", "published": "2015-09-29 18:35:49", "link": "http://arxiv.org/abs/1509.08881v1", "categories": ["cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Polish -English Statistical Machine Translation of Medical Texts", "abstract": "This new research explores the effects of various training methods on a\nPolish to English Statistical Machine Translation system for medical texts.\nVarious elements of the EMEA parallel text corpora from the OPUS project were\nused as the basis for training of phrase tables and language models and for\ndevelopment, tuning and testing of the translation system. The BLEU, NIST,\nMETEOR, RIBES and TER metrics have been used to evaluate the effects of various\nsystem and data preparations on translation results. Our experiments included\nsystems that used POS tagging, factored phrase models, hierarchical models,\nsyntactic taggers, and many different alignment methods. We also conducted a\ndeep analysis of Polish data as preparatory work for automatic data correction\nsuch as true casing and punctuation normalization phase.", "published": "2015-09-29 19:57:24", "link": "http://arxiv.org/abs/1509.08909v1", "categories": ["cs.CL", "cs.IR", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Symbol Emergence in Robotics: A Survey", "abstract": "Humans can learn the use of language through physical interaction with their\nenvironment and semiotic communication with other people. It is very important\nto obtain a computational understanding of how humans can form a symbol system\nand obtain semiotic skills through their autonomous mental development.\nRecently, many studies have been conducted on the construction of robotic\nsystems and machine-learning methods that can learn the use of language through\nembodied multimodal interaction with their environment and other systems.\nUnderstanding human social interactions and developing a robot that can\nsmoothly communicate with human users in the long term, requires an\nunderstanding of the dynamics of symbol systems and is crucially important. The\nembodied cognition and social interaction of participants gradually change a\nsymbol system in a constructive manner. In this paper, we introduce a field of\nresearch called symbol emergence in robotics (SER). SER is a constructive\napproach towards an emergent symbol system. The emergent symbol system is\nsocially self-organized through both semiotic communications and physical\ninteractions with autonomous cognitive developmental agents, i.e., humans and\ndevelopmental robots. Specifically, we describe some state-of-art research\ntopics concerning SER, e.g., multimodal categorization, word discovery, and a\ndouble articulation analysis, that enable a robot to obtain words and their\nembodied meanings from raw sensory--motor information, including visual\ninformation, haptic information, auditory information, and acoustic speech\nsignals, in a totally unsupervised manner. Finally, we suggest future\ndirections of research in SER.", "published": "2015-09-29 23:16:48", "link": "http://arxiv.org/abs/1509.08973v1", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO"], "primary_category": "cs.AI"}
