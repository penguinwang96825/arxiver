{"title": "ReCOGS: How Incidental Details of a Logical Form Overshadow an\n  Evaluation of Semantic Interpretation", "abstract": "Compositional generalization benchmarks for semantic parsing seek to assess\nwhether models can accurately compute meanings for novel sentences, but\noperationalize this in terms of logical form (LF) prediction. This raises the\nconcern that semantically irrelevant details of the chosen LFs could shape\nmodel performance. We argue that this concern is realized for the COGS\nbenchmark. COGS poses generalization splits that appear impossible for\npresent-day models, which could be taken as an indictment of those models.\nHowever, we show that the negative results trace to incidental features of COGS\nLFs. Converting these LFs to semantically equivalent ones and factoring out\ncapabilities unrelated to semantic interpretation, we find that even baseline\nmodels get traction. A recent variable-free translation of COGS LFs suggests\nsimilar conclusions, but we observe this format is not semantically equivalent;\nit is incapable of accurately representing some COGS meanings. These findings\ninform our proposal for ReCOGS, a modified version of COGS that comes closer to\nassessing the target semantic capabilities while remaining very challenging.\nOverall, our results reaffirm the importance of compositional generalization\nand careful benchmark task design.", "published": "2023-03-24 00:01:24", "link": "http://arxiv.org/abs/2303.13716v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Natural language processing to automatically extract the presence and\n  severity of esophagitis in notes of patients undergoing radiotherapy", "abstract": "Radiotherapy (RT) toxicities can impair survival and quality-of-life, yet\nremain under-studied. Real-world evidence holds potential to improve our\nunderstanding of toxicities, but toxicity information is often only in clinical\nnotes. We developed natural language processing (NLP) models to identify the\npresence and severity of esophagitis from notes of patients treated with\nthoracic RT. We fine-tuned statistical and pre-trained BERT-based models for\nthree esophagitis classification tasks: Task 1) presence of esophagitis, Task\n2) severe esophagitis or not, and Task 3) no esophagitis vs. grade 1 vs. grade\n2-3. Transferability was tested on 345 notes from patients with esophageal\ncancer undergoing RT.\n  Fine-tuning PubmedBERT yielded the best performance. The best macro-F1 was\n0.92, 0.82, and 0.74 for Task 1, 2, and 3, respectively. Selecting the most\ninformative note sections during fine-tuning improved macro-F1 by over 2% for\nall tasks. Silver-labeled data improved the macro-F1 by over 3% across all\ntasks. For the esophageal cancer notes, the best macro-F1 was 0.73, 0.74, and\n0.65 for Task 1, 2, and 3, respectively, without additional fine-tuning.\n  To our knowledge, this is the first effort to automatically extract\nesophagitis toxicity severity according to CTCAE guidelines from clinic notes.\nThe promising performance provides proof-of-concept for NLP-based automated\ndetailed toxicity monitoring in expanded domains.", "published": "2023-03-24 00:26:07", "link": "http://arxiv.org/abs/2303.13722v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Towards Making the Most of ChatGPT for Machine Translation", "abstract": "ChatGPT shows remarkable capabilities for machine translation (MT). Several\nprior studies have shown that it achieves comparable results to commercial\nsystems for high-resource languages, but lags behind in complex tasks, e.g.,\nlow-resource and distant-language-pairs translation. However, they usually\nadopt simple prompts which can not fully elicit the capability of ChatGPT. In\nthis paper, we aim to further mine ChatGPT's translation ability by revisiting\nseveral aspects: temperature, task information, and domain information, and\ncorrespondingly propose an optimal temperature setting and two (simple but\neffective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts\n(DSP). We show that: 1) The performance of ChatGPT depends largely on\ntemperature, and a lower temperature usually can achieve better performance; 2)\nEmphasizing the task information can further improve ChatGPT's performance,\nparticularly in complex MT tasks; 3) Introducing domain information can elicit\nChatGPT's generalization ability and improve its performance in the specific\ndomain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT\ntasks, which can be partially addressed by our proposed prompts but still need\nto be highlighted for the MT/NLP community. We also explore the effects of\nadvanced in-context learning strategies and find a (negative but interesting)\nobservation: the powerful chain-of-thought prompt leads to word-by-word\ntranslation behavior, thus bringing significant translation degradation.", "published": "2023-03-24 03:35:21", "link": "http://arxiv.org/abs/2303.13780v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Error Analysis Prompting Enables Human-Like Translation Evaluation in\n  Large Language Models", "abstract": "Generative large language models (LLMs), e.g., ChatGPT, have demonstrated\nremarkable proficiency across several NLP tasks, such as machine translation,\ntext summarization. Recent research (Kocmi and Federmann, 2023) has shown that\nutilizing LLMs for assessing the quality of machine translation (MT) achieves\nstate-of-the-art performance at the system level but \\textit{performs poorly at\nthe segment level}. To further improve the performance of LLMs on MT quality\nassessment, we investigate several prompting designs, and propose a new\nprompting method called \\textbf{\\texttt{Error Analysis Prompting}} (EAPrompt)\nby combining Chain-of-Thoughts (Wei et al., 2022) and Error Analysis (Lu et\nal., 2023). This technique emulates the commonly accepted human evaluation\nframework - Multidimensional Quality Metrics (MQM, Freitag et al. (2021)) and\n\\textit{produces explainable and reliable MT evaluations at both the system and\nsegment level}. Experimental Results from the WMT22 metrics shared task\nvalidate the effectiveness of EAPrompt on various LLMs, with different\nstructures. Further analysis confirms that EAPrompt effectively distinguishes\nmajor errors from minor ones, while also sharing a similar distribution of the\nnumber of errors with MQM. These findings highlight the potential of EAPrompt\nas a human-like evaluator prompting technique for MT evaluation.", "published": "2023-03-24 05:05:03", "link": "http://arxiv.org/abs/2303.13809v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MUG: A General Meeting Understanding and Generation Benchmark", "abstract": "Listening to long video/audio recordings from video conferencing and online\ncourses for acquiring information is extremely inefficient. Even after ASR\nsystems transcribe recordings into long-form spoken language documents, reading\nASR transcripts only partly speeds up seeking information. It has been observed\nthat a range of NLP applications, such as keyphrase extraction, topic\nsegmentation, and summarization, significantly improve users' efficiency in\ngrasping important information. The meeting scenario is among the most valuable\nscenarios for deploying these spoken language processing (SLP) capabilities.\nHowever, the lack of large-scale public meeting datasets annotated for these\nSLP tasks severely hinders their advancement. To prompt SLP advancement, we\nestablish a large-scale general Meeting Understanding and Generation Benchmark\n(MUG) to benchmark the performance of a wide range of SLP tasks, including\ntopic segmentation, topic-level and session-level extractive summarization and\ntopic title generation, keyphrase extraction, and action item detection. To\nfacilitate the MUG benchmark, we construct and release a large-scale meeting\ndataset for comprehensive long-form SLP development, the AliMeeting4MUG Corpus,\nwhich consists of 654 recorded Mandarin meeting sessions with diverse topic\ncoverage, with manual annotations for SLP tasks on manual transcripts of\nmeeting recordings. To the best of our knowledge, the AliMeeting4MUG Corpus is\nso far the largest meeting corpus in scale and facilitates most SLP tasks. In\nthis paper, we provide a detailed introduction of this corpus, SLP tasks and\nevaluation methods, baseline systems and their performance.", "published": "2023-03-24 11:52:25", "link": "http://arxiv.org/abs/2303.13939v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model\n  Meta-AI (LLaMA) Using Medical Domain Knowledge", "abstract": "The primary aim of this research was to address the limitations observed in\nthe medical knowledge of prevalent large language models (LLMs) such as\nChatGPT, by creating a specialized language model with enhanced accuracy in\nmedical advice. We achieved this by adapting and refining the large language\nmodel meta-AI (LLaMA) using a large dataset of 100,000 patient-doctor dialogues\nsourced from a widely used online medical consultation platform. These\nconversations were cleaned and anonymized to respect privacy concerns. In\naddition to the model refinement, we incorporated a self-directed information\nretrieval mechanism, allowing the model to access and utilize real-time\ninformation from online sources like Wikipedia and data from curated offline\nmedical databases. The fine-tuning of the model with real-world patient-doctor\ninteractions significantly improved the model's ability to understand patient\nneeds and provide informed advice. By equipping the model with self-directed\ninformation retrieval from reliable online and offline sources, we observed\nsubstantial improvements in the accuracy of its responses. Our proposed\nChatDoctor, represents a significant advancement in medical LLMs, demonstrating\na significant improvement in understanding patient inquiries and providing\naccurate advice. Given the high stakes and low error tolerance in the medical\nfield, such enhancements in providing accurate and reliable information are not\nonly beneficial but essential.", "published": "2023-03-24 15:29:16", "link": "http://arxiv.org/abs/2303.14070v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The crime of being poor", "abstract": "The criminalization of poverty has been widely denounced as a collective bias\nagainst the most vulnerable. NGOs and international organizations claim that\nthe poor are blamed for their situation, are more often associated with\ncriminal offenses than the wealthy strata of society and even incur criminal\noffenses simply as a result of being poor. While no evidence has been found in\nthe literature that correlates poverty and overall criminality rates, this\npaper offers evidence of a collective belief that associates both concepts.\nThis brief report measures the societal bias that correlates criminality with\nthe poor, as compared to the rich, by using Natural Language Processing (NLP)\ntechniques in Twitter. The paper quantifies the level of crime-poverty bias in\na panel of eight different English-speaking countries. The regional differences\nin the association between crime and poverty cannot be justified based on\ndifferent levels of inequality or unemployment, which the literature correlates\nto property crimes. The variation in the observed rates of crime-poverty bias\nfor different geographic locations could be influenced by cultural factors and\nthe tendency to overestimate the equality of opportunities and social mobility\nin specific countries. These results have consequences for policy-making and\nopen a new path of research for poverty mitigation with the focus not only on\nthe poor but on society as a whole. Acting on the collective bias against the\npoor would facilitate the approval of poverty reduction policies, as well as\nthe restoration of the dignity of the persons affected.", "published": "2023-03-24 16:35:42", "link": "http://arxiv.org/abs/2303.14128v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Lay Text Summarisation Using Natural Language Processing: A Narrative\n  Literature Review", "abstract": "Summarisation of research results in plain language is crucial for promoting\npublic understanding of research findings. The use of Natural Language\nProcessing to generate lay summaries has the potential to relieve researchers'\nworkload and bridge the gap between science and society. The aim of this\nnarrative literature review is to describe and compare the different text\nsummarisation approaches used to generate lay summaries. We searched the\ndatabases Web of Science, Google Scholar, IEEE Xplore, Association for\nComputing Machinery Digital Library and arXiv for articles published until 6\nMay 2022. We included original studies on automatic text summarisation methods\nto generate lay summaries. We screened 82 articles and included eight relevant\npapers published between 2020 and 2021, all using the same dataset. The results\nshow that transformer-based methods such as Bidirectional Encoder\nRepresentations from Transformers (BERT) and Pre-training with Extracted\nGap-sentences for Abstractive Summarization (PEGASUS) dominate the landscape of\nlay text summarisation, with all but one study using these methods. A\ncombination of extractive and abstractive summarisation methods in a hybrid\napproach was found to be most effective. Furthermore, pre-processing approaches\nto input text (e.g. applying extractive summarisation) or determining which\nsections of a text to include, appear critical. Evaluation metrics such as\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE) were used, which do\nnot consider readability. To conclude, automatic lay text summarisation is\nunder-explored. Future research should consider long document lay text\nsummarisation, including clinical trial reports, and the development of\nevaluation metrics that consider readability of the lay summary.", "published": "2023-03-24 18:30:50", "link": "http://arxiv.org/abs/2303.14222v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SIGMORPHON 2023 Shared Task of Interlinear Glossing: Baseline Model", "abstract": "Language documentation is a critical aspect of language preservation, often\nincluding the creation of Interlinear Glossed Text (IGT). Creating IGT is\ntime-consuming and tedious, and automating the process can save valuable\nannotator effort.\n  This paper describes the baseline system for the SIGMORPHON 2023 Shared Task\nof Interlinear Glossing. In our system, we utilize a transformer architecture\nand treat gloss generation as a sequence labelling task.", "published": "2023-03-24 18:59:06", "link": "http://arxiv.org/abs/2303.14234v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Depression detection in social media posts using affective and social\n  norm features", "abstract": "We propose a deep architecture for depression detection from social media\nposts. The proposed architecture builds upon BERT to extract language\nrepresentations from social media posts and combines these representations\nusing an attentive bidirectional GRU network. We incorporate affective\ninformation, by augmenting the text representations with features extracted\nfrom a pretrained emotion classifier. Motivated by psychological literature we\npropose to incorporate profanity and morality features of posts and words in\nour architecture using a late fusion scheme. Our analysis indicates that\nmorality and profanity can be important features for depression detection. We\napply our model for depression detection on Reddit posts on the Pirina dataset,\nand further consider the setting of detecting depressed users, given multiple\nposts per user, proposed in the Reddit RSDD dataset. The inclusion of the\nproposed features yields state-of-the-art results in both settings, namely\n2.65% and 6.73% absolute improvement in F1 score respectively. Index Terms:\nDepression detection, BERT, Feature fusion, Emotion recognition, profanity,\nmorality", "published": "2023-03-24 21:26:27", "link": "http://arxiv.org/abs/2303.14279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Voice-Based Conversational Agents and Knowledge Graphs for Improving\n  News Search in Assisted Living", "abstract": "As the healthcare sector is facing major challenges, such as aging\npopulations, staff shortages, and common chronic diseases, delivering\nhigh-quality care to individuals has become very difficult. Conversational\nagents have shown to be a promising technology to alleviate some of these\nissues. In the form of digital health assistants, they have the potential to\nimprove the everyday life of the elderly and chronically ill people. This\nincludes, for example, medication reminders, routine checks, or social\nchit-chat. In addition, conversational agents can satisfy the fundamental need\nof having access to information about daily news or local events, which enables\nindividuals to stay informed and connected with the world around them. However,\nfinding relevant news sources and navigating the plethora of news articles\navailable online can be overwhelming, particularly for those who may have\nlimited technological literacy or health-related impairments. To address this\nchallenge, we propose an innovative solution that combines knowledge graphs and\nconversational agents for news search in assisted living. By leveraging graph\ndatabases to semantically structure news data and implementing an intuitive\nvoice-based interface, our system can help care-dependent people to easily\ndiscover relevant news articles and give personalized recommendations. We\nexplain our design choices, provide a system architecture, share insights of an\ninitial user test, and give an outlook on planned future work.", "published": "2023-03-24 21:49:27", "link": "http://arxiv.org/abs/2303.14286v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Personalizing Task-oriented Dialog Systems via Zero-shot Generalizable\n  Reward Function", "abstract": "Task-oriented dialog systems enable users to accomplish tasks using natural\nlanguage. State-of-the-art systems respond to users in the same way regardless\nof their personalities, although personalizing dialogues can lead to higher\nlevels of adoption and better user experiences. Building personalized dialog\nsystems is an important, yet challenging endeavor and only a handful of works\ntook on the challenge. Most existing works rely on supervised learning\napproaches and require laborious and expensive labeled training data for each\nuser profile. Additionally, collecting and labeling data for each user profile\nis virtually impossible. In this work, we propose a novel framework, P-ToD, to\npersonalize task-oriented dialog systems capable of adapting to a wide range of\nuser profiles in an unsupervised fashion using a zero-shot generalizable reward\nfunction. P-ToD uses a pre-trained GPT-2 as a backbone model and works in three\nphases. Phase one performs task-specific training. Phase two kicks off\nunsupervised personalization by leveraging the proximal policy optimization\nalgorithm that performs policy gradients guided by the zero-shot generalizable\nreward function. Our novel reward function can quantify the quality of the\ngenerated responses even for unseen profiles. The optional final phase\nfine-tunes the personalized model using a few labeled training examples. We\nconduct extensive experimental analysis using the personalized bAbI dialogue\nbenchmark for five tasks and up to 180 diverse user profiles. The experimental\nresults demonstrate that P-ToD, even when it had access to zero labeled\nexamples, outperforms state-of-the-art supervised personalization models and\nachieves competitive performance on BLEU and ROUGE metrics when compared to a\nstrong fully-supervised GPT-2 baseline", "published": "2023-03-24 04:33:40", "link": "http://arxiv.org/abs/2303.13797v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Toward Open-domain Slot Filling via Self-supervised Co-training", "abstract": "Slot filling is one of the critical tasks in modern conversational systems.\nThe majority of existing literature employs supervised learning methods, which\nrequire labeled training data for each new domain. Zero-shot learning and weak\nsupervision approaches, among others, have shown promise as alternatives to\nmanual labeling. Nonetheless, these learning paradigms are significantly\ninferior to supervised learning approaches in terms of performance. To minimize\nthis performance gap and demonstrate the possibility of open-domain slot\nfilling, we propose a Self-supervised Co-training framework, called SCot, that\nrequires zero in-domain manually labeled training examples and works in three\nphases. Phase one acquires two sets of complementary pseudo labels\nautomatically. Phase two leverages the power of the pre-trained language model\nBERT, by adapting it for the slot filling task using these sets of pseudo\nlabels. In phase three, we introduce a self-supervised cotraining mechanism,\nwhere both models automatically select highconfidence soft labels to further\nimprove the performance of the other in an iterative fashion. Our thorough\nevaluations show that SCot outperforms state-of-the-art models by 45.57% and\n37.56% on SGD and MultiWoZ datasets, respectively. Moreover, our proposed\nframework SCot achieves comparable performance when compared to\nstate-of-the-art fully supervised models.", "published": "2023-03-24 04:51:22", "link": "http://arxiv.org/abs/2303.13801v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest\n  Neighbor Inference", "abstract": "In-Context Learning (ICL), which formulates target tasks as prompt completion\nconditioned on in-context demonstrations, has become the prevailing utilization\nof LLMs. In this paper, we first disclose an actual predicament for this\ntypical usage that it can not scale up with training data due to context length\nrestriction. Besides, existing works have shown that ICL also suffers from\nvarious biases and requires delicate calibration treatment. To address both\nchallenges, we advocate a simple and effective solution, $k$NN Prompting, which\nfirst queries LLM with training data for distributed representations, then\npredicts test instances by simply referring to nearest neighbors. We conduct\ncomprehensive experiments to demonstrate its two-fold superiority: 1)\nCalibration-Free: $k$NN Prompting does not directly align LLM output\ndistribution with task-specific label space, instead leverages such\ndistribution to align test and training instances. It significantly outperforms\nstate-of-the-art calibration-based methods under comparable few-shot scenario.\n2) Beyond-Context: $k$NN Prompting can further scale up effectively with as\nmany training data as are available, continually bringing substantial\nimprovements. The scaling trend holds across 10 orders of magnitude ranging\nfrom 2 shots to 1024 shots as well as different LLMs scales ranging from 0.8B\nto 30B. It successfully bridges data scaling into model scaling, and brings new\npotentials for the gradient-free paradigm of LLM deployment. Code is publicly\navailable.", "published": "2023-03-24 06:16:29", "link": "http://arxiv.org/abs/2303.13824v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "HRDoc: Dataset and Baseline Method Toward Hierarchical Reconstruction of\n  Document Structures", "abstract": "The problem of document structure reconstruction refers to converting digital\nor scanned documents into corresponding semantic structures. Most existing\nworks mainly focus on splitting the boundary of each element in a single\ndocument page, neglecting the reconstruction of semantic structure in\nmulti-page documents. This paper introduces hierarchical reconstruction of\ndocument structures as a novel task suitable for NLP and CV fields. To better\nevaluate the system performance on the new task, we built a large-scale dataset\nnamed HRDoc, which consists of 2,500 multi-page documents with nearly 2 million\nsemantic units. Every document in HRDoc has line-level annotations including\ncategories and relations obtained from rule-based extractors and human\nannotators. Moreover, we proposed an encoder-decoder-based hierarchical\ndocument structure parsing system (DSPS) to tackle this problem. By adopting a\nmulti-modal bidirectional encoder and a structure-aware GRU decoder with\nsoft-mask operation, the DSPS model surpass the baseline method by a large\nmargin. All scripts and datasets will be made publicly available at\nhttps://github.com/jfma-USTC/HRDoc.", "published": "2023-03-24 07:23:56", "link": "http://arxiv.org/abs/2303.13839v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Machine Psychology", "abstract": "Large language models (LLMs) show increasingly advanced emergent capabilities\nand are being incorporated across various societal domains. Understanding their\nbehavior and reasoning abilities therefore holds significant importance. We\nargue that a fruitful direction for research is engaging LLMs in behavioral\nexperiments inspired by psychology that have traditionally been aimed at\nunderstanding human cognition and behavior. In this article, we highlight and\nsummarize theoretical perspectives, experimental paradigms, and computational\nanalysis techniques that this approach brings to the table. It paves the way\nfor a \"machine psychology\" for generative artificial intelligence (AI) that\ngoes beyond performance benchmarks and focuses instead on computational\ninsights that move us toward a better understanding and discovery of emergent\nabilities and behavioral patterns in LLMs. We review existing work taking this\napproach, synthesize best practices, and highlight promising future directions.\nWe also highlight the important caveats of applying methodologies designed for\nunderstanding humans to machines. We posit that leveraging tools from\nexperimental psychology to study AI will become increasingly valuable as models\nevolve to be more powerful, opaque, multi-modal, and integrated into complex\nreal-world settings.", "published": "2023-03-24 13:24:41", "link": "http://arxiv.org/abs/2303.13988v6", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Paraphrase Detection: Human vs. Machine Content", "abstract": "The growing prominence of large language models, such as GPT-4 and ChatGPT,\nhas led to increased concerns over academic integrity due to the potential for\nmachine-generated content and paraphrasing. Although studies have explored the\ndetection of human- and machine-paraphrased content, the comparison between\nthese types of content remains underexplored. In this paper, we conduct a\ncomprehensive analysis of various datasets commonly employed for paraphrase\ndetection tasks and evaluate an array of detection methods. Our findings\nhighlight the strengths and limitations of different detection methods in terms\nof performance on individual datasets, revealing a lack of suitable\nmachine-generated datasets that can be aligned with human expectations. Our\nmain finding is that human-authored paraphrases exceed machine-generated ones\nin terms of difficulty, diversity, and similarity implying that automatically\ngenerated texts are not yet on par with human-level performance. Transformers\nemerged as the most effective method across datasets with TF-IDF excelling on\nsemantically diverse corpora. Additionally, we identify four datasets as the\nmost diverse and challenging for paraphrase detection.", "published": "2023-03-24 13:25:46", "link": "http://arxiv.org/abs/2303.13989v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SPEC: Summary Preference Decomposition for Low-Resource Abstractive\n  Summarization", "abstract": "Neural abstractive summarization has been widely studied and achieved great\nsuccess with large-scale corpora. However, the considerable cost of annotating\ndata motivates the need for learning strategies under low-resource settings. In\nthis paper, we investigate the problems of learning summarizers with only few\nexamples and propose corresponding methods for improvements. First, typical\ntransfer learning methods are prone to be affected by data properties and\nlearning objectives in the pretext tasks. Therefore, based on pretrained\nlanguage models, we further present a meta learning framework to transfer\nfew-shot learning processes from source corpora to the target corpus. Second,\nprevious methods learn from training examples without decomposing the content\nand preference. The generated summaries could therefore be constrained by the\npreference bias in the training set, especially under low-resource settings. As\nsuch, we propose decomposing the contents and preferences during learning\nthrough the parameter modulation, which enables control over preferences during\ninference. Third, given a target application, specifying required preferences\ncould be non-trivial because the preferences may be difficult to derive through\nobservations. Therefore, we propose a novel decoding method to automatically\nestimate suitable preferences and generate corresponding summary candidates\nfrom the few training examples. Extensive experiments demonstrate that our\nmethods achieve state-of-the-art performance on six diverse corpora with\n30.11%/33.95%/27.51% and 26.74%/31.14%/24.48% average improvements on\nROUGE-1/2/L under 10- and 100-example settings.", "published": "2023-03-24 14:07:03", "link": "http://arxiv.org/abs/2303.14011v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Scaling Expert Language Models with Unsupervised Domain Discovery", "abstract": "Large language models are typically trained densely: all parameters are\nupdated with respect to all inputs. This requires synchronization of billions\nof parameters across thousands of GPUs. We introduce a simple but effective\nmethod to asynchronously train large, sparse language models on arbitrary text\ncorpora. Our method clusters a corpus into sets of related documents, trains a\nseparate expert language model on each cluster, and combines them in a sparse\nensemble for inference. This approach generalizes embarrassingly parallel\ntraining by automatically discovering the domains for each expert, and\neliminates nearly all the communication overhead of existing sparse language\nmodels. Our technique outperforms dense baselines on multiple corpora and\nfew-shot tasks, and our analysis shows that specializing experts to meaningful\nclusters is key to these gains. Performance also improves with the number of\nexperts and size of training data, suggesting this is a highly efficient and\naccessible approach to training large language models.", "published": "2023-03-24 17:38:58", "link": "http://arxiv.org/abs/2303.14177v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models for Healthcare Data Augmentation: An Example on\n  Patient-Trial Matching", "abstract": "The process of matching patients with suitable clinical trials is essential\nfor advancing medical research and providing optimal care. However, current\napproaches face challenges such as data standardization, ethical\nconsiderations, and a lack of interoperability between Electronic Health\nRecords (EHRs) and clinical trial criteria. In this paper, we explore the\npotential of large language models (LLMs) to address these challenges by\nleveraging their advanced natural language generation capabilities to improve\ncompatibility between EHRs and clinical trial descriptions. We propose an\ninnovative privacy-aware data augmentation approach for LLM-based patient-trial\nmatching (LLM-PTM), which balances the benefits of LLMs while ensuring the\nsecurity and confidentiality of sensitive patient data. Our experiments\ndemonstrate a 7.32% average improvement in performance using the proposed\nLLM-PTM method, and the generalizability to new data is improved by 12.12%.\nAdditionally, we present case studies to further illustrate the effectiveness\nof our approach and provide a deeper understanding of its underlying\nprinciples.", "published": "2023-03-24 03:14:00", "link": "http://arxiv.org/abs/2303.16756v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Overview of the ICASSP 2023 General Meeting Understanding and Generation\n  Challenge (MUG)", "abstract": "ICASSP2023 General Meeting Understanding and Generation Challenge (MUG)\nfocuses on prompting a wide range of spoken language processing (SLP) research\non meeting transcripts, as SLP applications are critical to improve users'\nefficiency in grasping important information in meetings. MUG includes five\ntracks, including topic segmentation, topic-level and session-level extractive\nsummarization, topic title generation, keyphrase extraction, and action item\ndetection. To facilitate MUG, we construct and release a large-scale meeting\ndataset, the AliMeeting4MUG Corpus.", "published": "2023-03-24 11:42:19", "link": "http://arxiv.org/abs/2303.13932v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "PromptORE -- A Novel Approach Towards Fully Unsupervised Relation\n  Extraction", "abstract": "Unsupervised Relation Extraction (RE) aims to identify relations between\nentities in text, without having access to labeled data during training. This\nsetting is particularly relevant for domain specific RE where no annotated\ndataset is available and for open-domain RE where the types of relations are a\npriori unknown. Although recent approaches achieve promising results, they\nheavily depend on hyperparameters whose tuning would most often require labeled\ndata. To mitigate the reliance on hyperparameters, we propose PromptORE, a\n''Prompt-based Open Relation Extraction'' model. We adapt the novel\nprompt-tuning paradigm to work in an unsupervised setting, and use it to embed\nsentences expressing a relation. We then cluster these embeddings to discover\ncandidate relations, and we experiment different strategies to automatically\nestimate an adequate number of clusters. To the best of our knowledge,\nPromptORE is the first unsupervised RE model that does not need hyperparameter\ntuning. Results on three general and specific domain datasets show that\nPromptORE consistently outperforms state-of-the-art models with a relative gain\nof more than 40% in B 3 , V-measure and ARI. Qualitative analysis also\nindicates PromptORE's ability to identify semantically coherent clusters that\nare very close to true relations.", "published": "2023-03-24 12:55:35", "link": "http://arxiv.org/abs/2304.01209v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Improving Prediction Performance and Model Interpretability through\n  Attention Mechanisms from Basic and Applied Research Perspectives", "abstract": "With the dramatic advances in deep learning technology, machine learning\nresearch is focusing on improving the interpretability of model predictions as\nwell as prediction performance in both basic and applied research. While deep\nlearning models have much higher prediction performance than traditional\nmachine learning models, the specific prediction process is still difficult to\ninterpret and/or explain. This is known as the black-boxing of machine learning\nmodels and is recognized as a particularly important problem in a wide range of\nresearch fields, including manufacturing, commerce, robotics, and other\nindustries where the use of such technology has become commonplace, as well as\nthe medical field, where mistakes are not tolerated. This bulletin is based on\nthe summary of the author's dissertation. The research summarized in the\ndissertation focuses on the attention mechanism, which has been the focus of\nmuch attention in recent years, and discusses its potential for both basic\nresearch in terms of improving prediction performance and interpretability, and\napplied research in terms of evaluating it for real-world applications using\nlarge data sets beyond the laboratory environment. The dissertation also\nconcludes with a summary of the implications of these findings for subsequent\nresearch and future prospects in the field.", "published": "2023-03-24 16:24:08", "link": "http://arxiv.org/abs/2303.14116v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.LG"}
{"title": "Symbolic Music Structure Analysis with Graph Representations and\n  Changepoint Detection Methods", "abstract": "Music Structure Analysis is an open research task in Music Information\nRetrieval (MIR). In the past, there have been several works that attempt to\nsegment music into the audio and symbolic domains, however, the identification\nand segmentation of the music structure at different levels is still an open\nresearch problem in this area. In this work we propose three methods, two of\nwhich are novel graph-based algorithms that aim to segment symbolic music by\nits form or structure: Norm, G-PELT and G-Window. We performed an ablation\nstudy with two public datasets that have different forms or structures in order\nto compare such methods varying their parameter values and comparing the\nperformance against different music styles. We have found that encoding\nsymbolic music with graph representations and computing the novelty of\nAdjacency Matrices obtained from graphs represent the structure of symbolic\nmusic pieces well without the need to extract features from it. We are able to\ndetect the boundaries with an online unsupervised changepoint detection method\nwith a F_1 of 0.5640 for a 1 bar tolerance in one of the public datasets that\nwe used for testing our methods. We also provide the performance results of the\nalgorithms at different levels of structure, high, medium and low, to show how\nthe parameters of the proposed methods have to be adjusted depending on the\nlevel. We added the best performing method with its parameters for each\nstructure level to musicaiz, an open source python package, to facilitate the\nreproducibility and usability of this work. We hope that this methods could be\nused to improve other MIR tasks such as music generation with structure, music\nclassification or key changes detection.", "published": "2023-03-24 09:45:11", "link": "http://arxiv.org/abs/2303.13881v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Wave-U-Net Discriminator: Fast and Lightweight Discriminator for\n  Generative Adversarial Network-Based Speech Synthesis", "abstract": "In speech synthesis, a generative adversarial network (GAN), training a\ngenerator (speech synthesizer) and a discriminator in a min-max game, is widely\nused to improve speech quality. An ensemble of discriminators is commonly used\nin recent neural vocoders (e.g., HiFi-GAN) and end-to-end text-to-speech (TTS)\nsystems (e.g., VITS) to scrutinize waveforms from multiple perspectives. Such\ndiscriminators allow synthesized speech to adequately approach real speech;\nhowever, they require an increase in the model size and computation time\naccording to the increase in the number of discriminators. Alternatively, this\nstudy proposes a Wave-U-Net discriminator, which is a single but expressive\ndiscriminator with Wave-U-Net architecture. This discriminator is unique; it\ncan assess a waveform in a sample-wise manner with the same resolution as the\ninput signal, while extracting multilevel features via an encoder and decoder\nwith skip connections. This architecture provides a generator with sufficiently\nrich information for the synthesized speech to be closely matched to the real\nspeech. During the experiments, the proposed ideas were applied to a\nrepresentative neural vocoder (HiFi-GAN) and an end-to-end TTS system (VITS).\nThe results demonstrate that the proposed models can achieve comparable speech\nquality with a 2.31 times faster and 14.5 times more lightweight discriminator\nwhen used in HiFi-GAN and a 1.90 times faster and 9.62 times more lightweight\ndiscriminator when used in VITS. Audio samples are available at\nhttps://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/waveunetd/.", "published": "2023-03-24 10:46:40", "link": "http://arxiv.org/abs/2303.13909v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "MusicFace: Music-driven Expressive Singing Face Synthesis", "abstract": "It is still an interesting and challenging problem to synthesize a vivid and\nrealistic singing face driven by music signal. In this paper, we present a\nmethod for this task with natural motions of the lip, facial expression, head\npose, and eye states. Due to the coupling of the mixed information of human\nvoice and background music in common signals of music audio, we design a\ndecouple-and-fuse strategy to tackle the challenge. We first decompose the\ninput music audio into human voice stream and background music stream. Due to\nthe implicit and complicated correlation between the two-stream input signals\nand the dynamics of the facial expressions, head motions and eye states, we\nmodel their relationship with an attention scheme, where the effects of the two\nstreams are fused seamlessly. Furthermore, to improve the expressiveness of the\ngenerated results, we propose to decompose head movements generation into speed\ngeneration and direction generation, and decompose eye states generation into\nthe short-time eye blinking generation and the long-time eye closing generation\nto model them separately. We also build a novel SingingFace Dataset to support\nthe training and evaluation of this task, and to facilitate future works on\nthis topic. Extensive experiments and user study show that our proposed method\nis capable of synthesizing vivid singing face, which is better than\nstate-of-the-art methods qualitatively and quantitatively.", "published": "2023-03-24 14:51:46", "link": "http://arxiv.org/abs/2303.14044v1", "categories": ["cs.GR", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
{"title": "Pitchclass2vec: Symbolic Music Structure Segmentation with Chord\n  Embeddings", "abstract": "Structure perception is a fundamental aspect of music cognition in humans.\nHistorically, the hierarchical organization of music into structures served as\na narrative device for conveying meaning, creating expectancy, and evoking\nemotions in the listener. Thereby, musical structures play an essential role in\nmusic composition, as they shape the musical discourse through which the\ncomposer organises his ideas. In this paper, we present a novel music\nsegmentation method, pitchclass2vec, based on symbolic chord annotations, which\nare embedded into continuous vector representations using both natural language\nprocessing techniques and custom-made encodings. Our algorithm is based on\nlong-short term memory (LSTM) neural network and outperforms the\nstate-of-the-art techniques based on symbolic chord annotations in the field.", "published": "2023-03-24 10:23:15", "link": "http://arxiv.org/abs/2303.15306v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
