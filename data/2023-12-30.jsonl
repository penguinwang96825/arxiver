{"title": "Mitigating the Impact of False Negatives in Dense Retrieval with\n  Contrastive Confidence Regularization", "abstract": "In open-domain Question Answering (QA), dense retrieval is crucial for\nfinding relevant passages for answer generation. Typically, contrastive\nlearning is used to train a retrieval model that maps passages and queries to\nthe same semantic space. The objective is to make similar ones closer and\ndissimilar ones further apart. However, training such a system is challenging\ndue to the false negative issue, where relevant passages may be missed during\ndata annotation. Hard negative sampling, which is commonly used to improve\ncontrastive learning, can introduce more noise in training. This is because\nhard negatives are those closer to a given query, and thus more likely to be\nfalse negatives. To address this issue, we propose a novel contrastive\nconfidence regularizer for Noise Contrastive Estimation (NCE) loss, a commonly\nused loss for dense retrieval. Our analysis shows that the regularizer helps\ndense retrieval models be more robust against false negatives with a\ntheoretical guarantee. Additionally, we propose a model-agnostic method to\nfilter out noisy negative passages in the dataset, improving any downstream\ndense retrieval models. Through experiments on three datasets, we demonstrate\nthat our method achieves better retrieval performance in comparison to existing\nstate-of-the-art dense retrieval systems.", "published": "2023-12-30 08:01:57", "link": "http://arxiv.org/abs/2401.00165v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluation is all you need. Prompting Generative Large Language Models\n  for Annotation Tasks in the Social Sciences. A Primer using Open Models", "abstract": "This paper explores the use of open generative Large Language Models (LLMs)\nfor annotation tasks in the social sciences. The study highlights the\nchallenges associated with proprietary models, such as limited reproducibility\nand privacy concerns, and advocates for the adoption of open (source) models\nthat can be operated on independent devices. Two examples of annotation tasks,\nsentiment analysis in tweets and identification of leisure activities in\nchildhood aspirational essays are provided. The study evaluates the performance\nof different prompting strategies and models (neural-chat-7b-v3-2,\nStarling-LM-7B-alpha, openchat_3.5, zephyr-7b-alpha and zephyr-7b-beta). The\nresults indicate the need for careful validation and tailored prompt\nengineering. The study highlights the advantages of open models for data\nprivacy and reproducibility.", "published": "2023-12-30 17:22:01", "link": "http://arxiv.org/abs/2401.00284v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Art of Defending: A Systematic Evaluation and Analysis of LLM\n  Defense Strategies on Safety and Over-Defensiveness", "abstract": "As Large Language Models (LLMs) play an increasingly pivotal role in natural\nlanguage processing applications, their safety concerns become critical areas\nof NLP research. This paper presents Safety and Over-Defensiveness Evaluation\n(SODE) benchmark: a collection of diverse safe and unsafe prompts with\ncarefully designed evaluation methods that facilitate systematic evaluation,\ncomparison, and analysis over 'safety' and 'over-defensiveness.' With SODE, we\nstudy a variety of LLM defense strategies over multiple state-of-the-art LLMs,\nwhich reveals several interesting and important findings, such as (a) the\nwidely popular 'self-checking' techniques indeed improve the safety against\nunsafe inputs, but this comes at the cost of extreme over-defensiveness on the\nsafe inputs, (b) providing a safety instruction along with in-context exemplars\n(of both safe and unsafe inputs) consistently improves safety and also\nmitigates undue over-defensiveness of the models, (c) providing contextual\nknowledge easily breaks the safety guardrails and makes the models more\nvulnerable to generating unsafe responses. Overall, our work reveals numerous\nsuch critical findings that we believe will pave the way and facilitate further\nresearch in improving the safety of LLMs.", "published": "2023-12-30 17:37:06", "link": "http://arxiv.org/abs/2401.00287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained\n  Language Models for Question Answering over Knowledge Graph", "abstract": "Question Answering over Knowledge Graph (KGQA) aims to seek answer entities\nfor the natural language question from a large-scale Knowledge Graph~(KG). To\nbetter perform reasoning on KG, recent work typically adopts a pre-trained\nlanguage model~(PLM) to model the question, and a graph neural network~(GNN)\nbased module to perform multi-hop reasoning on the KG. Despite the\neffectiveness, due to the divergence in model architecture, the PLM and GNN are\nnot closely integrated, limiting the knowledge sharing and fine-grained feature\ninteractions. To solve it, we aim to simplify the above two-module approach,\nand develop a more capable PLM that can directly support subgraph reasoning for\nKGQA, namely ReasoningLM. In our approach, we propose a subgraph-aware\nself-attention mechanism to imitate the GNN for performing structured\nreasoning, and also adopt an adaptation tuning strategy to adapt the model\nparameters with 20,000 subgraphs with synthesized questions. After adaptation,\nthe PLM can be parameter-efficient fine-tuned on downstream tasks. Experiments\nshow that ReasoningLM surpasses state-of-the-art models by a large margin, even\nwith fewer updated parameters and less training data. Our codes and data are\npublicly available at~\\url{https://github.com/RUCAIBox/ReasoningLM}.", "published": "2023-12-30 07:18:54", "link": "http://arxiv.org/abs/2401.00158v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "L3Cube-MahaSocialNER: A Social Media based Marathi NER Dataset and BERT\n  models", "abstract": "This work introduces the L3Cube-MahaSocialNER dataset, the first and largest\nsocial media dataset specifically designed for Named Entity Recognition (NER)\nin the Marathi language. The dataset comprises 18,000 manually labeled\nsentences covering eight entity classes, addressing challenges posed by social\nmedia data, including non-standard language and informal idioms. Deep learning\nmodels, including CNN, LSTM, BiLSTM, and Transformer models, are evaluated on\nthe individual dataset with IOB and non-IOB notations. The results demonstrate\nthe effectiveness of these models in accurately recognizing named entities in\nMarathi informal text. The L3Cube-MahaSocialNER dataset offers user-centric\ninformation extraction and supports real-time applications, providing a\nvaluable resource for public opinion analysis, news, and marketing on social\nmedia platforms. We also show that the zero-shot results of the regular NER\nmodel are poor on the social NER test set thus highlighting the need for more\nsocial NER datasets. The datasets and models are publicly available at\nhttps://github.com/l3cube-pune/MarathiNLP", "published": "2023-12-30 08:30:24", "link": "http://arxiv.org/abs/2401.00170v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Principle Interference in Technical and Scientific Translation", "abstract": "In this article, I will explore the nature of interference in translation,\nespecially in technical and scientific texts, using a descriptivist approach. I\nwill have a brief overview of the historical excursion of interference in\ntechnical and scientific translation. My aim is to explain this phenomenon and\nits causes with all its paradoxes, instead of simply condemning it as an\nexample of supposedly bad translation. Thus, I will focus on its status in the\nbibliography of translation, on the motives for and consequences of\ninterference in specialized translation, as well as on the nature of the\narguments given for and against this phenomenon. Therefore the relationship\nbetween different societies has always been possible with the act of\ntranslation. When civilizations are examined throughout history, it is seen\nthat the dissemination of knowledge among different societies has been achieved\nby translation. These societies have often become aware of the advancements in\ntechnology and science by means of translation. Therefore; translation becomes\nvery significant in technical contact between societies and humans. Since the\ntranslation of technical texts is the preliminary scope of this thesis, it will\nbe beneficial to have a brief look at the history of technical translation in\nthe world.", "published": "2023-12-30 09:04:30", "link": "http://arxiv.org/abs/2401.00177v1", "categories": ["cs.CL", "physics.hist-ph"], "primary_category": "cs.CL"}
{"title": "The Problem of Alignment", "abstract": "Large Language Models produce sequences learned as statistical patterns from\nlarge corpora. In order not to reproduce corpus biases, after initial training\nmodels must be aligned with human values, preferencing certain continuations\nover others. Alignment, which can be viewed as the superimposition of normative\nstructure onto a statistical model, reveals a conflicted and complex\ninterrelationship between language and technology. This relationship shapes\ntheories of language, linguistic practice and subjectivity, which are\nespecially relevant to the current sophistication in artificially produced\ntext. We examine this practice of structuration as a two-way interaction\nbetween users and models by analysing how ChatGPT4 redacts perceived\n`anomalous' language in fragments of Joyce's Ulysses and the new linguistic\npractice of prompt engineering. We then situate this alignment problem\nhistorically, revisiting earlier postwar linguistic debates which counterposed\ntwo views of meaning: as discrete structures, and as continuous probability\ndistributions. We discuss the largely occluded work of the Moscow Linguistic\nSchool, which sought to reconcile this opposition. Our attention to the Moscow\nSchool and later related arguments by Searle and Kristeva casts the problem of\nalignment in a new light: as one involving attention to the social\nstructuration of linguistic practice, including structuration of anomalies\nthat, like the Joycean text, exist in defiance of expressive conventions. These\ndebates around the communicative orientation toward language can help explain\nsome of the contemporary behaviours and interdependencies that take place\nbetween users and LLMs.", "published": "2023-12-30 11:44:59", "link": "http://arxiv.org/abs/2401.00210v1", "categories": ["cs.CL", "cs.CY", "K.4.2"], "primary_category": "cs.CL"}
{"title": "How to Evaluate Coreference in Literary Texts?", "abstract": "In this short paper, we examine the main metrics used to evaluate textual\ncoreference and we detail some of their limitations. We show that a unique\nscore cannot represent the full complexity of the problem at stake, and is thus\nuninformative, or even misleading. We propose a new way of evaluating\ncoreference, taking into account the context (in our case, the analysis of\nfictions, esp. novels). More specifically, we propose to distinguish long\ncoreference chains (corresponding to main characters), from short ones\n(corresponding to secondary characters), and singletons (isolated elements).\nThis way, we hope to get more interpretable and thus more informative results\nthrough evaluation.", "published": "2023-12-30 14:02:36", "link": "http://arxiv.org/abs/2401.00238v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigating Zero-Shot Generalizability on Mandarin-English\n  Code-Switched ASR and Speech-to-text Translation of Recent Foundation Models\n  with Self-Supervision and Weak Supervision", "abstract": "This work evaluated several cutting-edge large-scale foundation models based\non self-supervision or weak supervision, including SeamlessM4T, SeamlessM4T v2,\nand Whisper-large-v3, on three code-switched corpora. We found that\nself-supervised models can achieve performances close to the supervised model,\nindicating the effectiveness of multilingual self-supervised pre-training. We\nalso observed that these models still have room for improvement as they kept\nmaking similar mistakes and had unsatisfactory performances on modeling\nintra-sentential code-switching. In addition, the validity of several variants\nof Whisper was explored, and we concluded that they remained effective in a\ncode-switching scenario, and similar techniques for self-supervised models are\nworth studying to boost the performance of code-switched tasks.", "published": "2023-12-30 16:15:02", "link": "http://arxiv.org/abs/2401.00273v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Red Teaming for Large Language Models At Scale: Tackling Hallucinations\n  on Mathematics Tasks", "abstract": "We consider the problem of red teaming LLMs on elementary calculations and\nalgebraic tasks to evaluate how various prompting techniques affect the quality\nof outputs. We present a framework to procedurally generate numerical questions\nand puzzles, and compare the results with and without the application of\nseveral red teaming techniques. Our findings suggest that even though\nstructured reasoning and providing worked-out examples slow down the\ndeterioration of the quality of answers, the gpt-3.5-turbo and gpt-4 models are\nnot well suited for elementary calculations and reasoning tasks, also when\nbeing red teamed.", "published": "2023-12-30 17:59:12", "link": "http://arxiv.org/abs/2401.00290v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Uncovering Regulatory Affairs Complexity in Medical Products: A\n  Qualitative Assessment Utilizing Open Coding and Natural Language Processing\n  (NLP)", "abstract": "This study investigates the complexity of regulatory affairs in the medical\ndevice industry, a critical factor influencing market access and patient care.\nThrough qualitative research, we sought expert insights to understand the\nfactors contributing to this complexity. The study involved semi-structured\ninterviews with 28 professionals from medical device companies, specializing in\nvarious aspects of regulatory affairs. These interviews were analyzed using\nopen coding and Natural Language Processing (NLP) techniques. The findings\nreveal key sources of complexity within the regulatory landscape, divided into\nfive domains: (A) Regulatory language complexity, (B) Intricacies within the\nregulatory process, (C) Global-level complexities, (D) Database-related\nconsiderations, and (E) Product-level issues. The participants highlighted the\nneed for strategies to streamline regulatory compliance, enhance interactions\nbetween regulatory bodies and industry players, and develop adaptable\nframeworks for rapid technological advancements. Emphasizing interdisciplinary\ncollaboration and increased transparency, the study concludes that these\nelements are vital for establishing coherent and effective regulatory\nprocedures in the medical device sector.", "published": "2023-12-30 03:39:57", "link": "http://arxiv.org/abs/2401.02975v1", "categories": ["cs.CY", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Trace and Edit Relation Associations in GPT", "abstract": "This study introduces a novel approach for analyzing and modifying entity\nrelationships in GPT models, diverging from ROME's entity-focused methods. We\ndevelop a relation tracing technique to understand the influence of language\nmodel computations on relationship judgments. Using the FewRel dataset, we\nidentify key roles of MLP modules and attention mechanisms in processing\nrelationship information. Our method, tested against ROME on a new dataset,\nshows improved balance in specificity and generalization, underscoring the\npotential of manipulating early-layer modules for enhanced model understanding\nand accuracy.", "published": "2023-12-30 21:04:41", "link": "http://arxiv.org/abs/2401.02976v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Is Knowledge All Large Language Models Needed for Causal Reasoning?", "abstract": "This paper explores the causal reasoning of large language models (LLMs) to\nenhance their interpretability and reliability in advancing artificial\nintelligence. Despite the proficiency of LLMs in a range of tasks, their\npotential for understanding causality requires further exploration. We propose\na novel causal attribution model that utilizes ``do-operators\" for constructing\ncounterfactual scenarios, allowing us to systematically quantify the influence\nof input numerical data and LLMs' pre-existing knowledge on their causal\nreasoning processes. Our newly developed experimental setup assesses LLMs'\nreliance on contextual information and inherent knowledge across various\ndomains. Our evaluation reveals that LLMs' causal reasoning ability mainly\ndepends on the context and domain-specific knowledge provided. In the absence\nof such knowledge, LLMs can still maintain a degree of causal reasoning using\nthe available numerical data, albeit with limitations in the calculations. This\nmotivates the proposed fine-tuned LLM for pairwise causal discovery,\neffectively leveraging both knowledge and numerical information.", "published": "2023-12-30 04:51:46", "link": "http://arxiv.org/abs/2401.00139v2", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ME"], "primary_category": "cs.AI"}
{"title": "Boosting Large Language Model for Speech Synthesis: An Empirical Study", "abstract": "Large language models (LLMs) have made significant advancements in natural\nlanguage processing and are concurrently extending the language ability to\nother modalities, such as speech and vision. Nevertheless, most of the previous\nwork focuses on prompting LLMs with perception abilities like auditory\ncomprehension, and the effective approach for augmenting LLMs with speech\nsynthesis capabilities remains ambiguous. In this paper, we conduct a\ncomprehensive empirical exploration of boosting LLMs with the ability to\ngenerate speech, by combining pre-trained LLM LLaMA/OPT and text-to-speech\nsynthesis model VALL-E. We compare three integration methods between LLMs and\nspeech synthesis models, including directly fine-tuned LLMs, superposed layers\nof LLMs and VALL-E, and coupled LLMs and VALL-E using LLMs as a powerful text\nencoder. Experimental results show that, using LoRA method to fine-tune LLMs\ndirectly to boost the speech synthesis capability does not work well, and\nsuperposed LLMs and VALL-E can improve the quality of generated speech both in\nspeaker similarity and word error rate (WER). Among these three methods,\ncoupled methods leveraging LLMs as the text encoder can achieve the best\nperformance, making it outperform original speech synthesis models with a\nconsistently better speaker similarity and a significant (10.9%) WER reduction.", "published": "2023-12-30 14:20:04", "link": "http://arxiv.org/abs/2401.00246v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "ODAQ: Open Dataset of Audio Quality", "abstract": "Research into the prediction and analysis of perceived audio quality is\nhampered by the scarcity of openly available datasets of audio signals\naccompanied by corresponding subjective quality scores. To address this\nproblem, we present the Open Dataset of Audio Quality (ODAQ), a new dataset\ncontaining the results of a MUSHRA listening test conducted with expert\nlisteners from 2 international laboratories. ODAQ contains 240 audio samples\nand corresponding quality scores. Each audio sample is rated by 26 listeners.\nThe audio samples are stereo audio signals sampled at 44.1 or 48 kHz and are\nprocessed by a total of 6 method classes, each operating at different quality\nlevels. The processing method classes are designed to generate quality\ndegradations possibly encountered during audio coding and source separation,\nand the quality levels for each method class span the entire quality range. The\ndiversity of the processing methods, the large span of quality levels, the high\nsampling frequency, and the pool of international listeners make ODAQ\nparticularly suited for further research into subjective and objective audio\nquality. The dataset is released with permissive licenses, and the software\nused to conduct the listening test is also made publicly available.", "published": "2023-12-30 10:32:53", "link": "http://arxiv.org/abs/2401.00197v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "AI and Tempo Estimation: A Review", "abstract": "The author's goal in this paper is to explore how artificial intelligence\n(AI) has been utilised to inform our understanding of and ability to estimate\nat scale a critical aspect of musical creativity - musical tempo. The central\nimportance of tempo to musical creativity can be seen in how it is used to\nexpress specific emotions (Eerola and Vuoskoski 2013), suggest particular\nmusical styles (Li and Chan 2011), influence perception of expression (Webster\nand Weir 2005) and mediate the urge to move one's body in time to the music\n(Burger et al. 2014). Traditional tempo estimation methods typically detect\nsignal periodicities that reflect the underlying rhythmic structure of the\nmusic, often using some form of autocorrelation of the amplitude envelope\n(Lartillot and Toiviainen 2007). Recently, AI-based methods utilising\nconvolutional or recurrent neural networks (CNNs, RNNs) on spectral\nrepresentations of the audio signal have enjoyed significant improvements in\naccuracy (Aarabi and Peeters 2022). Common AI-based techniques include those\nbased on probability (e.g., Bayesian approaches, hidden Markov models (HMM)),\nclassification and statistical learning (e.g., support vector machines (SVM)),\nand artificial neural networks (ANNs) (e.g., self-organising maps (SOMs), CNNs,\nRNNs, deep learning (DL)). The aim here is to provide an overview of some of\nthe more common AI-based tempo estimation algorithms and to shine a light on\nnotable benefits and potential drawbacks of each. Limitations of AI in this\nfield in general are also considered, as is the capacity for such methods to\naccount for idiosyncrasies inherent in tempo perception, i.e., how well\nAI-based approaches are able to think and act like humans.", "published": "2023-12-30 11:42:44", "link": "http://arxiv.org/abs/2401.00209v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Enhancing dysarthria speech feature representation with empirical mode\n  decomposition and Walsh-Hadamard transform", "abstract": "Dysarthria speech contains the pathological characteristics of vocal tract\nand vocal fold, but so far, they have not yet been included in traditional\nacoustic feature sets. Moreover, the nonlinearity and non-stationarity of\nspeech have been ignored. In this paper, we propose a feature enhancement\nalgorithm for dysarthria speech called WHFEMD. It combines empirical mode\ndecomposition (EMD) and fast Walsh-Hadamard transform (FWHT) to enhance\nfeatures. With the proposed algorithm, the fast Fourier transform of the\ndysarthria speech is first performed and then followed by EMD to get intrinsic\nmode functions (IMFs). After that, FWHT is used to output new coefficients and\nto extract statistical features based on IMFs, power spectral density, and\nenhanced gammatone frequency cepstral coefficients. To evaluate the proposed\napproach, we conducted experiments on two public pathological speech databases\nincluding UA Speech and TORGO. The results show that our algorithm performed\nbetter than traditional features in classification. We achieved improvements of\n13.8% (UA Speech) and 3.84% (TORGO), respectively. Furthermore, the\nincorporation of an imbalanced classification algorithm to address data\nimbalance has resulted in a 12.18% increase in recognition accuracy. This\nalgorithm effectively addresses the challenges of the imbalanced dataset and\nnon-linearity in dysarthric speech and simultaneously provides a robust\nrepresentation of the local pathological features of the vocal folds and\ntracts.", "published": "2023-12-30 13:25:26", "link": "http://arxiv.org/abs/2401.00225v1", "categories": ["eess.AS", "cs.AI", "eess.SP"], "primary_category": "eess.AS"}
