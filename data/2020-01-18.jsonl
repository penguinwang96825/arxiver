{"title": "Capturing Evolution in Word Usage: Just Add More Clusters?", "abstract": "The way the words are used evolves through time, mirroring cultural or\ntechnological evolution of society. Semantic change detection is the task of\ndetecting and analysing word evolution in textual data, even in short periods\nof time. In this paper we focus on a new set of methods relying on\ncontextualised embeddings, a type of semantic modelling that revolutionised the\nNLP field recently. We leverage the ability of the transformer-based BERT model\nto generate contextualised embeddings capable of detecting semantic change of\nwords across time. Several approaches are compared in a common setting in order\nto establish strengths and weaknesses for each of them. We also propose several\nideas for improvements, managing to drastically improve the performance of\nexisting approaches.", "published": "2020-01-18 09:04:42", "link": "http://arxiv.org/abs/2001.06629v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Ranking Significant Discrepancies in Clinical Reports", "abstract": "Medical errors are a major public health concern and a leading cause of death\nworldwide. Many healthcare centers and hospitals use reporting systems where\nmedical practitioners write a preliminary medical report and the report is\nlater reviewed, revised, and finalized by a more experienced physician. The\nrevisions range from stylistic to corrections of critical errors or\nmisinterpretations of the case. Due to the large quantity of reports written\ndaily, it is often difficult to manually and thoroughly review all the\nfinalized reports to find such errors and learn from them. To address this\nchallenge, we propose a novel ranking approach, consisting of textual and\nontological overlaps between the preliminary and final versions of reports. The\napproach learns to rank the reports based on the degree of discrepancy between\nthe versions. This allows medical practitioners to easily identify and learn\nfrom the reports in which their interpretation most substantially differed from\nthat of the attending physician (who finalized the report). This is a crucial\nstep towards uncovering potential errors and helping medical practitioners to\nlearn from such errors, thus improving patient-care in the long run. We\nevaluate our model on a dataset of radiology reports and show that our approach\noutperforms both previously-proposed approaches and more recent language models\nby 4.5% to 15.4%.", "published": "2020-01-18 14:47:10", "link": "http://arxiv.org/abs/2001.06674v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Adaptive Parameterization for Neural Dialogue Generation", "abstract": "Neural conversation systems generate responses based on the\nsequence-to-sequence (SEQ2SEQ) paradigm. Typically, the model is equipped with\na single set of learned parameters to generate responses for given input\ncontexts. When confronting diverse conversations, its adaptability is rather\nlimited and the model is hence prone to generate generic responses. In this\nwork, we propose an {\\bf Ada}ptive {\\bf N}eural {\\bf D}ialogue generation\nmodel, \\textsc{AdaND}, which manages various conversations with\nconversation-specific parameterization. For each conversation, the model\ngenerates parameters of the encoder-decoder by referring to the input context.\nIn particular, we propose two adaptive parameterization mechanisms: a\ncontext-aware and a topic-aware parameterization mechanism. The context-aware\nparameterization directly generates the parameters by capturing local semantics\nof the given context. The topic-aware parameterization enables parameter\nsharing among conversations with similar topics by first inferring the latent\ntopics of the given context and then generating the parameters with respect to\nthe distributional topics. Extensive experiments conducted on a large-scale\nreal-world conversational dataset show that our model achieves superior\nperformance in terms of both quantitative metrics and human evaluations.", "published": "2020-01-18 08:18:19", "link": "http://arxiv.org/abs/2001.06626v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Fair Transfer of Multiple Style Attributes in Text", "abstract": "To preserve anonymity and obfuscate their identity on online platforms users\nmay morph their text and portray themselves as a different gender or\ndemographic. Similarly, a chatbot may need to customize its communication style\nto improve engagement with its audience. This manner of changing the style of\nwritten text has gained significant attention in recent years. Yet these past\nresearch works largely cater to the transfer of single style attributes. The\ndisadvantage of focusing on a single style alone is that this often results in\ntarget text where other existing style attributes behave unpredictably or are\nunfairly dominated by the new style. To counteract this behavior, it would be\nnice to have a style transfer mechanism that can transfer or control multiple\nstyles simultaneously and fairly. Through such an approach, one could obtain\nobfuscated or written text incorporated with a desired degree of multiple soft\nstyles such as female-quality, politeness, or formalness.\n  In this work, we demonstrate that the transfer of multiple styles cannot be\nachieved by sequentially performing multiple single-style transfers. This is\nbecause each single style-transfer step often reverses or dominates over the\nstyle incorporated by a previous transfer step. We then propose a neural\nnetwork architecture for fairly transferring multiple style attributes in a\ngiven text. We test our architecture on the Yelp data set to demonstrate our\nsuperior performance as compared to existing one-style transfer steps performed\nin a sequence.", "published": "2020-01-18 15:38:04", "link": "http://arxiv.org/abs/2001.06693v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
