{"title": "Forward-backward Contention Resolution Schemes for Fair Rationing", "abstract": "We use contention resolution schemes (CRS) to derive algorithms for the fair\nrationing of a single resource when agents have stochastic demands. We aim to\nprovide ex-ante guarantees on the level of service provided to each agent, who\nmay measure service in different ways (Type-I, II, or III), calling for CRS\nunder different feasibility constraints (rank-1 matroid or knapsack). We are\nparticularly interested in two-order CRS where the agents are equally likely to\narrive in a known forward order or its reverse, which is motivated by online\nrationing at food banks.\n  In particular, we derive a two-order CRS for rank-1 matroids with guarantee\n$1/(1+e^{-1/2})\\approx 0.622$, which we prove is tight. This improves upon the\n$1/2$ guarantee that is best-possible under a single order (Alaei, SIAM J.\nComput. 2014), while achieving separation with the $1-1/e\\approx 0.632$\nguarantee that is possible for random-order CRS (Lee and Singla, ESA 2018).\nBecause CRS guarantees imply prophet inequalities, this also beats the\ntwo-order prophet inequality with ratio $(\\sqrt{5}-1)/2\\approx 0.618$ from\n(Arsenis, SODA 2021), which was tight for single-threshold policies. Rank-1\nmatroids suffice to provide guarantees under Type-II or III service, but Type-I\nservice requires knapsack. Accordingly, we derive a two-order CRS for knapsack\nwith guarantee $1/3$, improving upon the $1/(3+e^{-2})\\approx 0.319$ guarantee\nthat is best-possible under a single order (Jiang et al., SODA 2022). To our\nknowledge, $1/3$ provides the best-known guarantee for knapsack CRS even in the\noffline setting. Finally, we provide an upper bound of $1/(2+e^{-1})\\approx\n0.422$ for two-order knapsack CRS, strictly smaller than the upper bound of\n$(1-e^{-2})/2\\approx0.432$ for random-order knapsack CRS.", "published": "2025-02-13 17:36:12", "link": "http://arxiv.org/abs/2502.09521v1", "categories": ["cs.DS", "cs.DM", "F.2.2; G.2.2"], "primary_category": "cs.DS"}
{"title": "RTD-Conjecture and Concept Classes Induced by Graphs", "abstract": "It is conjectured that the recursive teaching dimension of any finite concept\nclass is upper-bounded by the VC-dimension of this class times a universal\nconstant. In this paper, we confirm this conjecture for two rich families of\nconcept classes where each class is induced by some graph $G$. For each $G$, we\nconsider the class whose concepts represent stars in $G$ as well as the class\nwhose concepts represent connected sets in $G$. We show that, for concept\nclasses of this kind, the recursive teaching dimension either equals the\nVC-dimension or is less by $1$.", "published": "2025-02-13 16:19:58", "link": "http://arxiv.org/abs/2502.09453v1", "categories": ["cs.DM", "68R05 (primary) 05C99 (secondary)", "F.1.3; G.2.1; I.2.6"], "primary_category": "cs.DM"}
{"title": "Depth-Bounds for Neural Networks via the Braid Arrangement", "abstract": "We contribute towards resolving the open question of how many hidden layers\nare required in ReLU networks for exactly representing all continuous and\npiecewise linear functions on $\\mathbb{R}^d$. While the question has been\nresolved in special cases, the best known lower bound in general is still 2. We\nfocus on neural networks that are compatible with certain polyhedral complexes,\nmore precisely with the braid fan. For such neural networks, we prove a\nnon-constant lower bound of $\\Omega(\\log\\log d)$ hidden layers required to\nexactly represent the maximum of $d$ numbers. Additionally, under our\nassumption, we provide a combinatorial proof that 3 hidden layers are necessary\nto compute the maximum of 5 numbers; this had only been verified with an\nexcessive computation so far. Finally, we show that a natural generalization of\nthe best known upper bound to maxout networks is not tight, by demonstrating\nthat a rank-3 maxout layer followed by a rank-2 maxout layer is sufficient to\nrepresent the maximum of 7 numbers.", "published": "2025-02-13 13:37:52", "link": "http://arxiv.org/abs/2502.09324v1", "categories": ["cs.LG", "cs.DM", "cs.NE", "math.CO"], "primary_category": "cs.LG"}
{"title": "Graphical Conditions for the Existence, Unicity and Number of Regular Models", "abstract": "The regular models of a normal logic program are a particular type of partial\n(i.e. 3-valued) models which correspond to stable partial models with minimal\nundefinedness. In this paper, we explore graphical conditions on the dependency\ngraph of a finite ground normal logic program to analyze the existence, unicity\nand number of regular models for the program. We show three main results: 1) a\nnecessary condition for the existence of non-trivial (i.e. non-2-valued)\nregular models, 2) a sufficient condition for the unicity of regular models,\nand 3) two upper bounds for the number of regular models based on positive\nfeedback vertex sets. The first two conditions generalize the finite cases of\nthe two existing results obtained by You and Yuan (1994) for normal logic\nprograms with well-founded stratification. The third result is also new to the\nbest of our knowledge. Key to our proofs is a connection that we establish\nbetween finite ground normal logic programs and Boolean network theory.", "published": "2025-02-13 11:50:20", "link": "http://arxiv.org/abs/2502.09220v1", "categories": ["cs.LO", "cs.AI", "cs.DM"], "primary_category": "cs.LO"}
{"title": "Robust Graph-Based Semi-Supervised Learning via $p$-Conductances", "abstract": "We study the problem of semi-supervised learning on graphs in the regime\nwhere data labels are scarce or possibly corrupted. We propose an approach\ncalled $p$-conductance learning that generalizes the $p$-Laplace and Poisson\nlearning methods by introducing an objective reminiscent of $p$-Laplacian\nregularization and an affine relaxation of the label constraints. This leads to\na family of probability measure mincut programs that balance sparse edge\nremoval with accurate distribution separation. Our theoretical analysis\nconnects these programs to well-known variational and probabilistic problems on\ngraphs (including randomized cuts, effective resistance, and Wasserstein\ndistance) and provides motivation for robustness when labels are diffused via\nthe heat kernel. Computationally, we develop a semismooth Newton-conjugate\ngradient algorithm and extend it to incorporate class-size estimates when\nconverting the continuous solutions into label assignments. Empirical results\non computer vision and citation datasets demonstrate that our approach achieves\nstate-of-the-art accuracy in low label-rate, corrupted-label, and partial-label\nregimes.", "published": "2025-02-13 01:11:25", "link": "http://arxiv.org/abs/2502.08873v1", "categories": ["cs.LG", "cs.DM", "math.OC", "68Q87, 90C35, 05C90, 90C53"], "primary_category": "cs.LG"}
{"title": "LOB-Bench: Benchmarking Generative AI for Finance -- an Application to Limit Order Book Data", "abstract": "While financial data presents one of the most challenging and interesting\nsequence modelling tasks due to high noise, heavy tails, and strategic\ninteractions, progress in this area has been hindered by the lack of consensus\non quantitative evaluation paradigms. To address this, we present LOB-Bench, a\nbenchmark, implemented in python, designed to evaluate the quality and realism\nof generative message-by-order data for limit order books (LOB) in the LOBSTER\nformat. Our framework measures distributional differences in conditional and\nunconditional statistics between generated and real LOB data, supporting\nflexible multivariate statistical evaluation. The benchmark also includes\nfeatures commonly used LOB statistics such as spread, order book volumes, order\nimbalance, and message inter-arrival times, along with scores from a trained\ndiscriminator network. Lastly, LOB-Bench contains \"market impact metrics\", i.e.\nthe cross-correlations and price response functions for specific events in the\ndata. We benchmark generative autoregressive state-space models, a (C)GAN, as\nwell as a parametric LOB model and find that the autoregressive GenAI approach\nbeats traditional model classes.", "published": "2025-02-13 10:56:58", "link": "http://arxiv.org/abs/2502.09172v1", "categories": ["cs.LG", "cs.CE", "q-fin.CP", "q-fin.TR"], "primary_category": "cs.LG"}
{"title": "Quantifying Cryptocurrency Unpredictability: A Comprehensive Study of Complexity and Forecasting", "abstract": "This paper offers a thorough examination of the univariate predictability in\ncryptocurrency time-series. By exploiting a combination of complexity measure\nand model predictions we explore the cryptocurrencies time-series forecasting\ntask focusing on the exchange rate in USD of Litecoin, Binance Coin, Bitcoin,\nEthereum, and XRP. On one hand, to assess the complexity and the randomness of\nthese time-series, a comparative analysis has been performed using Brownian and\ncolored noises as a benchmark. The results obtained from the Complexity-Entropy\ncausality plane and power density spectrum analysis reveal that cryptocurrency\ntime-series exhibit characteristics closely resembling those of Brownian noise\nwhen analyzed in a univariate context. On the other hand, the application of a\nwide range of statistical, machine and deep learning models for time-series\nforecasting demonstrates the low predictability of cryptocurrencies. Notably,\nour analysis reveals that simpler models such as Naive models consistently\noutperform the more complex machine and deep learning ones in terms of\nforecasting accuracy across different forecast horizons and time windows. The\ncombined study of complexity and forecasting accuracies highlights the\ndifficulty of predicting the cryptocurrency market. These findings provide\nvaluable insights into the inherent characteristics of the cryptocurrency data\nand highlight the need to reassess the challenges associated with predicting\ncryptocurrency's price movements.", "published": "2025-02-13 08:53:13", "link": "http://arxiv.org/abs/2502.09079v1", "categories": ["q-fin.ST", "cs.LG", "q-fin.CP"], "primary_category": "q-fin.ST"}
{"title": "A class of locally state-dependent models for forward curves", "abstract": "We present a dynamic model for forward curves within the Heath-Jarrow-Morton\nframework under the Musiela parametrization. The forward curves take values in\na function space H, and their dynamics follows a stochastic partial\ndifferential equation with state-dependent coefficients. In particular, the\ncoefficients are defined through point-wise operating maps on H, resulting in a\nlocally state-dependent structure. We first explore conditions under which\nthese point-wise operators are well defined on H. Next, we determine conditions\nto ensure that the resulting coefficient functions satisfy local growth and\nLipschitz properties, so to guarantee the existence and uniqueness of mild\nsolutions. The proposed model captures the behavior of the entire forward curve\nthrough a single equation, yet retains remarkable simplicity. Notably, we\ndemonstrate that certain one-dimensional projections of the model are Markovian\nand satisfy a one-dimensional stochastic differential equation. This connects\nour Hilbert-space approach to well established models for forward contracts\nwith fixed delivery times, for which existing formulas and numerical techniques\ncan be applied. This link allows us to examine also conditions for maintaining\npositivity of the solutions. As concrete examples, we analyze Hilbert-space\nvalued variants of an exponential model and of a constant elasticity of\nvariance model.", "published": "2025-02-13 16:47:25", "link": "http://arxiv.org/abs/2502.09486v2", "categories": ["math.PR", "q-fin.MF", "60H15, 60G07, 60J25"], "primary_category": "math.PR"}
{"title": "BrainWavLM: Fine-tuning Speech Representations with Brain Responses to\n  Language", "abstract": "Speech encoding models use auditory representations to predict how the human\nbrain responds to spoken language stimuli. Most performant encoding models\nlinearly map the hidden states of artificial neural networks to brain data, but\nthis linear restriction may limit their effectiveness. In this work, we use\nlow-rank adaptation (LoRA) to fine-tune a WavLM-based encoding model end-to-end\non a brain encoding objective, producing a model we name BrainWavLM. We show\nthat fine-tuning across all of cortex improves average encoding performance\nwith greater stability than without LoRA. This improvement comes at the expense\nof low-level regions like auditory cortex (AC), but selectively fine-tuning on\nthese areas improves performance in AC, while largely retaining gains made in\nthe rest of cortex. Fine-tuned models generalized across subjects, indicating\nthat they learned robust brain-like representations of the speech stimuli.\nFinally, by training linear probes, we showed that the brain data strengthened\nsemantic representations in the speech model without any explicit annotations.\nOur results demonstrate that brain fine-tuning produces best-in-class speech\nencoding models, and that non-linear methods have the potential to bridge the\ngap between artificial and biological representations of semantics.", "published": "2025-02-13 00:37:27", "link": "http://arxiv.org/abs/2502.08866v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-Enhanced Multiple Instance Learning for Joint Rumor and Stance\n  Detection with Social Context Information", "abstract": "The proliferation of misinformation, such as rumors on social media, has\ndrawn significant attention, prompting various expressions of stance among\nusers. Although rumor detection and stance detection are distinct tasks, they\ncan complement each other. Rumors can be identified by cross-referencing\nstances in related posts, and stances are influenced by the nature of the\nrumor. However, existing stance detection methods often require post-level\nstance annotations, which are costly to obtain. We propose a novel LLM-enhanced\nMIL approach to jointly predict post stance and claim class labels, supervised\nsolely by claim labels, using an undirected microblog propagation model. Our\nweakly supervised approach relies only on bag-level labels of claim veracity,\naligning with multi-instance learning (MIL) principles. To achieve this, we\ntransform the multi-class problem into multiple MIL-based binary classification\nproblems. We then employ a discriminative attention layer to aggregate the\noutputs from these classifiers into finer-grained classes. Experiments\nconducted on three rumor datasets and two stance datasets demonstrate the\neffectiveness of our approach, highlighting strong connections between rumor\nveracity and expressed stances in responding posts. Our method shows promising\nperformance in joint rumor and stance detection compared to the\nstate-of-the-art methods.", "published": "2025-02-13 02:03:30", "link": "http://arxiv.org/abs/2502.08888v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Uniform Meaning Representation Help GPT-4 Translate from Indigenous\n  Languages?", "abstract": "While ChatGPT and GPT-based models are able to effectively perform many tasks\nwithout additional fine-tuning, they struggle with related to extremely\nlow-resource languages and indigenous languages. Uniform Meaning Representation\n(UMR), a semantic representation designed to capture the meaning of texts in\nmany languages, is well-poised to be leveraged in the development of\nlow-resource language technologies. In this work, we explore the downstream\ntechnical utility of UMR for low-resource languages by incorporating it into\nGPT-4 prompts. Specifically, we examine the ability of GPT-4 to perform\ntranslation from three indigenous languages (Navajo, Ar\\'apaho, and Kukama),\nwith and without demonstrations, as well as with and without UMR annotations.\nUltimately we find that in the majority of our test cases, integrating UMR into\nthe prompt results in a statistically significant increase in performance,\nwhich is a promising indication of future applications of the UMR formalism.", "published": "2025-02-13 02:27:30", "link": "http://arxiv.org/abs/2502.08900v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Structured Convergence in Large Language Model Representations via\n  Hierarchical Latent Space Folding", "abstract": "Token representations in high-dimensional latent spaces often exhibit\nredundancy, limiting computational efficiency and reducing structural coherence\nacross model layers. Hierarchical latent space folding introduces a structured\ntransformation mechanism that enforces a multi-scale organization within\nlearned embeddings, refining representational compactness while preserving\nessential contextual distinctions. The proposed approach incorporates dynamic\nfolding operations that iteratively adjust token embeddings through structured\ntransformations, influencing both short-range and long-range dependencies in\nsequential processing tasks. Empirical evaluation demonstrates a reduction in\nrepresentational variance across layers, contributing to more stable perplexity\ndistributions and enhancing predictive confidence in text generation. The\nstructured redistribution of attention head utilization leads to more efficient\nallocation of computational resources, particularly in deeper layers, where\nhierarchical refinements improve contextual abstraction. Comparative analysis\nof activation sparsity patterns suggests that hierarchical adjustments\nselectively reinforce critical pathways while reducing computational overhead\nin non-essential regions of the model. Statistical assessments of token\nreordering frequencies reveal that hierarchical modifications introduce subtle\nshifts in sequential dependencies, improving contextual alignment while\nmaintaining syntactic correctness. Computational trade-offs associated with\nhierarchical folding introduce marginal increases in training time per epoch,\nyet empirical findings indicate that inference efficiency benefits from the\nstructured representation adjustments. The results highlight the impact of\nhierarchical latent space folding on optimizing model performance through\nimproved representation structuring and computational efficiency.", "published": "2025-02-13 04:01:54", "link": "http://arxiv.org/abs/2502.08947v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Medicine on the Edge: Comparative Performance Analysis of On-Device LLMs\n  for Clinical Reasoning", "abstract": "The deployment of Large Language Models (LLM) on mobile devices offers\nsignificant potential for medical applications, enhancing privacy, security,\nand cost-efficiency by eliminating reliance on cloud-based services and keeping\nsensitive health data local. However, the performance and accuracy of on-device\nLLMs in real-world medical contexts remain underexplored. In this study, we\nbenchmark publicly available on-device LLMs using the AMEGA dataset, evaluating\naccuracy, computational efficiency, and thermal limitation across various\nmobile devices. Our results indicate that compact general-purpose models like\nPhi-3 Mini achieve a strong balance between speed and accuracy, while medically\nfine-tuned models such as Med42 and Aloe attain the highest accuracy. Notably,\ndeploying LLMs on older devices remains feasible, with memory constraints\nposing a greater challenge than raw processing power. Our study underscores the\npotential of on-device LLMs for healthcare while emphasizing the need for more\nefficient inference and models tailored to real-world clinical reasoning.", "published": "2025-02-13 04:35:55", "link": "http://arxiv.org/abs/2502.08954v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing RAG with Active Learning on Conversation Records: Reject\n  Incapables and Answer Capables", "abstract": "Retrieval-augmented generation (RAG) is a key technique for leveraging\nexternal knowledge and reducing hallucinations in large language models (LLMs).\nHowever, RAG still struggles to fully prevent hallucinated responses. To\naddress this, it is essential to identify samples prone to hallucination or\nguide LLMs toward correct responses, which experts then annotate to develop\nhigh-quality datasets for refining LLMs. However, the growing scarcity of such\ndatasets makes their creation challenging. This paper proposes using the vast\namount of conversations from widespread LLM usage to build these datasets,\ntraining LLMs to avoid hallucination-prone questions while accurately\nresponding to manageable ones. Given the impracticality of expert-annotating\nall conversation records, the paper introduces AL4RAG, which uses active\nlearning to select the most suitable conversation samples for annotation,\noptimizing performance within an annotation budget. Additionally, recognizing\nthat traditional active learning methods are not fully compatible with RAG due\nto unsuitable distance metrics, we develop a novel sample distance measurement\nfor RAG active learning. Extensive experiments show that our method\nconsistently outperforms baselines across multiple metrics.", "published": "2025-02-13 08:42:29", "link": "http://arxiv.org/abs/2502.09073v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Hybrid Model for Few-Shot Text Classification Using Transfer and\n  Meta-Learning", "abstract": "With the continuous development of natural language processing (NLP)\ntechnology, text classification tasks have been widely used in multiple\napplication fields. However, obtaining labeled data is often expensive and\ndifficult, especially in few-shot learning scenarios. To solve this problem,\nthis paper proposes a few-shot text classification model based on transfer\nlearning and meta-learning. The model uses the knowledge of the pre-trained\nmodel for transfer and optimizes the model's rapid adaptability in few-sample\ntasks through a meta-learning mechanism. Through a series of comparative\nexperiments and ablation experiments, we verified the effectiveness of the\nproposed method. The experimental results show that under the conditions of few\nsamples and medium samples, the model based on transfer learning and\nmeta-learning significantly outperforms traditional machine learning and deep\nlearning methods. In addition, ablation experiments further analyzed the\ncontribution of each component to the model performance and confirmed the key\nrole of transfer learning and meta-learning in improving model accuracy.\nFinally, this paper discusses future research directions and looks forward to\nthe potential of this method in practical applications.", "published": "2025-02-13 09:00:32", "link": "http://arxiv.org/abs/2502.09086v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian\n  Optimization and Bidirectional Recurrent Unit", "abstract": "In this paper, we propose an optimized Transformer model that integrates\nBayesian algorithms with a Bidirectional Gated Recurrent Unit (BiGRU), and\napply it to fake news classification for the first time. First, we employ the\nTF-IDF method to extract features from news texts and transform them into\nnumeric representations to facilitate subsequent machine learning tasks. Two\nsets of experiments are then conducted for fake news detection and\nclassification: one using a Transformer model optimized only with BiGRU, and\nthe other incorporating Bayesian algorithms into the BiGRU-based Transformer.\nExperimental results show that the BiGRU-optimized Transformer achieves 100%\naccuracy on the training set and 99.67% on the test set, while the addition of\nthe Bayesian algorithm maintains 100% accuracy on the training set and slightly\nimproves test-set accuracy to 99.73%. This indicates that the Bayesian\nalgorithm boosts model accuracy by 0.06%, further enhancing the detection\ncapability for fake news. Moreover, the proposed algorithm converges rapidly at\naround the 10th training epoch with accuracy nearing 100%, demonstrating both\nits effectiveness and its fast classification ability. Overall, the optimized\nTransformer model, enhanced by the Bayesian algorithm and BiGRU, exhibits\nexcellent continuous learning and detection performance, offering a robust\ntechnical means to combat the spread of fake news in the current era of\ninformation overload.", "published": "2025-02-13 09:13:23", "link": "http://arxiv.org/abs/2502.09097v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The influence of visual and linguistic cues on ignorance inference in\n  Vision-Language Models", "abstract": "This study explored how Vision-Language Models (VLMs) process ignorance\nimplicatures with visual and linguistic cues. Particularly, we focused on the\neffects of contexts (precise and approximate contexts) and modifier types (bare\nnumerals, superlative, and comparative modifiers), which were considered\npragmatic and semantic factors respectively. Methodologically, we conducted a\ntruth-value judgment task in visually grounded settings using GPT-4o and Gemini\n1.5 Pro. The results indicate that while both models exhibited sensitivity to\nlinguistic cues (modifier), they failed to process ignorance implicatures with\nvisual cues (context) as humans do. Specifically, the influence of context was\nweaker and inconsistent across models, indicating challenges in pragmatic\nreasoning for VLMs. On the other hand, superlative modifiers were more strongly\nassociated with ignorance implicatures as compared to comparative modifiers,\nsupporting the semantic view. These findings highlight the need for further\nadvancements in VLMs to process language-vision information in a\ncontext-dependent way to achieve human-like pragmatic inference.", "published": "2025-02-13 09:55:48", "link": "http://arxiv.org/abs/2502.09120v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving TCM Question Answering through Tree-Organized Self-Reflective\n  Retrieval with LLMs", "abstract": "Objectives: Large language models (LLMs) can harness medical knowledge for\nintelligent question answering (Q&A), promising support for auxiliary diagnosis\nand medical talent cultivation. However, there is a deficiency of highly\nefficient retrieval-augmented generation (RAG) frameworks within the domain of\nTraditional Chinese Medicine (TCM). Our purpose is to observe the effect of the\nTree-Organized Self-Reflective Retrieval (TOSRR) framework on LLMs in TCM Q&A\ntasks.\n  Materials and Methods: We introduce the novel approach of knowledge\norganization, constructing a tree structure knowledge base with hierarchy. At\ninference time, our self-reflection framework retrieves from this knowledge\nbase, integrating information across chapters. Questions from the TCM Medical\nLicensing Examination (MLE) and the college Classics Course Exam (CCE) were\nrandomly selected as benchmark datasets.\n  Results: By coupling with GPT-4, the framework can improve the best\nperformance on the TCM MLE benchmark by 19.85% in absolute accuracy, and\nimprove recall accuracy from 27% to 38% on CCE datasets. In manual evaluation,\nthe framework improves a total of 18.52 points across dimensions of safety,\nconsistency, explainability, compliance, and coherence.\n  Conclusion: The TOSRR framework can effectively improve LLM's capability in\nQ&A tasks of TCM.", "published": "2025-02-13 10:36:18", "link": "http://arxiv.org/abs/2502.09156v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Musical Heritage Historical Entity Linking", "abstract": "Linking named entities occurring in text to their corresponding entity in a\nKnowledge Base (KB) is challenging, especially when dealing with historical\ntexts. In this work, we introduce Musical Heritage named Entities Recognition,\nClassification and Linking (MHERCL), a novel benchmark consisting of manually\nannotated sentences extrapolated from historical periodicals of the music\ndomain. MHERCL contains named entities under-represented or absent in the most\nfamous KBs. We experiment with several State-of-the-Art models on the Entity\nLinking (EL) task and show that MHERCL is a challenging dataset for all of\nthem. We propose a novel unsupervised EL model and a method to extend\nsupervised entity linkers by using Knowledge Graphs (KGs) to tackle the main\ndifficulties posed by historical documents. Our experiments reveal that relying\non unsupervised techniques and improving models with logical constraints based\non KGs and heuristics to predict NIL entities (entities not represented in the\nKB of reference) results in better EL performance on historical documents.", "published": "2025-02-13 10:51:40", "link": "http://arxiv.org/abs/2502.09168v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Thinking beyond the anthropomorphic paradigm benefits LLM research", "abstract": "Anthropomorphism, or the attribution of human traits to technology, is an\nautomatic and unconscious response that occurs even in those with advanced\ntechnical expertise. In this position paper, we analyze hundreds of thousands\nof computer science research articles from the past decade and present\nempirical evidence of the prevalence and growth of anthropomorphic terminology\nin research on large language models (LLMs). This terminology reflects deeper\nanthropomorphic conceptualizations which shape how we think about and conduct\nLLM research. We argue these conceptualizations may be limiting, and that\nchallenging them opens up new pathways for understanding and improving LLMs\nbeyond human analogies. To illustrate this, we identify and analyze five core\nanthropomorphic assumptions shaping prominent methodologies across the LLM\ndevelopment lifecycle, from the assumption that models must use natural\nlanguage for reasoning tasks to the assumption that model capabilities should\nbe evaluated through human-centric benchmarks. For each assumption, we\ndemonstrate how non-anthropomorphic alternatives can open new directions for\nresearch and development.", "published": "2025-02-13 11:32:09", "link": "http://arxiv.org/abs/2502.09192v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Judge-free LLM Open-ended Generation Benchmark Based on the\n  Distributional Hypothesis", "abstract": "Evaluating the open-ended text generation of large language models (LLMs) is\nchallenging because of the lack of a clear ground truth and the high cost of\nhuman or LLM-based assessments. We propose a novel benchmark that evaluates\nLLMs using n-gram statistics and rules, without relying on human judgement or\nLLM-as-a-judge approaches. Using 50 question and reference answer sets, we\nintroduce three new metrics based on n-grams and rules: Fluency, Truthfulness,\nand Helpfulness. Our benchmark strongly correlates with GPT-4o-based\nevaluations while requiring significantly fewer computational resources,\ndemonstrating its effectiveness as a scalable alternative for assessing LLMs'\nopen-ended generation capabilities.", "published": "2025-02-13 13:30:54", "link": "http://arxiv.org/abs/2502.09316v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Beyond English: The Impact of Prompt Translation Strategies across\n  Languages and Tasks in Multilingual LLMs", "abstract": "Despite advances in the multilingual capabilities of Large Language Models\n(LLMs) across diverse tasks, English remains the dominant language for LLM\nresearch and development. So, when working with a different language, this has\nled to the widespread practice of pre-translation, i.e., translating the task\nprompt into English before inference. Selective pre-translation, a more\nsurgical approach, focuses on translating specific prompt components. However,\nits current use is sporagic and lacks a systematic research foundation.\nConsequently, the optimal pre-translation strategy for various multilingual\nsettings and tasks remains unclear. In this work, we aim to uncover the optimal\nsetup for pre-translation by systematically assessing its use. Specifically, we\nview the prompt as a modular entity, composed of four functional parts:\ninstruction, context, examples, and output, either of which could be translated\nor not. We evaluate pre-translation strategies across 35 languages covering\nboth low and high-resource languages, on various tasks including Question\nAnswering (QA), Natural Language Inference (NLI), Named Entity Recognition\n(NER), and Abstractive Summarization. Our experiments show the impact of\nfactors as similarity to English, translation quality and the size of\npre-trained data, on the model performance with pre-translation. We suggest\npractical guidelines for choosing optimal strategies in various multilingual\nsettings.", "published": "2025-02-13 13:49:30", "link": "http://arxiv.org/abs/2502.09331v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use\n  a Different Evaluation Process than Human?", "abstract": "One of the goals of automatic evaluation metrics in grammatical error\ncorrection (GEC) is to rank GEC systems such that it matches human preferences.\nHowever, current automatic evaluations are based on procedures that diverge\nfrom human evaluation. Specifically, human evaluation derives rankings by\naggregating sentence-level relative evaluation results, e.g., pairwise\ncomparisons, using a rating algorithm, whereas automatic evaluation averages\nsentence-level absolute scores to obtain corpus-level scores, which are then\nsorted to determine rankings. In this study, we propose an aggregation method\nfor existing automatic evaluation metrics which aligns with human evaluation\nmethods to bridge this gap. We conducted experiments using various metrics,\nincluding edit-based metrics, $n$-gram based metrics, and sentence-level\nmetrics, and show that resolving the gap improves results for the most of\nmetrics on the SEEDA benchmark. We also found that even BERT-based metrics\nsometimes outperform the metrics of GPT-4. We publish our unified\nimplementation of the metrics and meta-evaluations.", "published": "2025-02-13 15:39:07", "link": "http://arxiv.org/abs/2502.09416v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "The Multilingual Mind : A Survey of Multilingual Reasoning in Language\n  Models", "abstract": "While reasoning and multilingual capabilities in Language Models (LMs) have\nachieved remarkable progress in recent years, their integration into a unified\nparadigm, multilingual reasoning, is at a nascent stage. Multilingual reasoning\nrequires language models to handle logical reasoning across languages while\naddressing misalignment, biases, and challenges in low-resource settings. This\nsurvey provides the first in-depth review of multilingual reasoning in LMs. In\nthis survey, we provide a systematic overview of existing methods that leverage\nLMs for multilingual reasoning, specifically outlining the challenges,\nmotivations, and foundational aspects of applying language models to reason\nacross diverse languages. We provide an overview of the standard data resources\nused for training multilingual reasoning in LMs and the evaluation benchmarks\nemployed to assess their multilingual capabilities. Next, we analyze various\nstate-of-the-art methods and their performance on these benchmarks. Finally, we\nexplore future research opportunities to improve multilingual reasoning in LMs,\nfocusing on enhancing their ability to handle diverse languages and complex\nreasoning tasks.", "published": "2025-02-13 16:25:16", "link": "http://arxiv.org/abs/2502.09457v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Partial Colexifications Improve Concept Embeddings", "abstract": "While the embedding of words has revolutionized the field of Natural Language\nProcessing, the embedding of concepts has received much less attention so far.\nA dense and meaningful representation of concepts, however, could prove useful\nfor several tasks in computational linguistics, especially those involving\ncross-linguistic data or sparse data from low resource languages. First methods\nthat have been proposed so far embed concepts from automatically constructed\ncolexification networks. While these approaches depart from automatically\ninferred polysemies, attested across a larger number of languages, they are\nrestricted to the word level, ignoring lexical relations that would only hold\nfor parts of the words in a given language. Building on recently introduced\nmethods for the inference of partial colexifications, we show how they can be\nused to improve concept embeddings in meaningful ways. The learned embeddings\nare evaluated against lexical similarity ratings, recorded instances of\nsemantic shift, and word association data. We show that in all evaluation\ntasks, the inclusion of partial colexifications lead to improved concept\nrepresentations and better results. Our results further show that the learned\nembeddings are able to capture and represent different semantic relationships\nbetween concepts.", "published": "2025-02-13 19:58:00", "link": "http://arxiv.org/abs/2502.09743v1", "categories": ["cs.CL", "J.5"], "primary_category": "cs.CL"}
{"title": "The Widespread Adoption of Large Language Model-Assisted Writing Across\n  Society", "abstract": "The recent advances in large language models (LLMs) attracted significant\npublic and policymaker interest in its adoption patterns. In this paper, we\nsystematically analyze LLM-assisted writing across four domains-consumer\ncomplaints, corporate communications, job postings, and international\norganization press releases-from January 2022 to September 2024. Our dataset\nincludes 687,241 consumer complaints, 537,413 corporate press releases, 304.3\nmillion job postings, and 15,919 United Nations (UN) press releases. Using a\nrobust population-level statistical framework, we find that LLM usage surged\nfollowing the release of ChatGPT in November 2022. By late 2024, roughly 18% of\nfinancial consumer complaint text appears to be LLM-assisted, with adoption\npatterns spread broadly across regions and slightly higher in urban areas. For\ncorporate press releases, up to 24% of the text is attributable to LLMs. In job\npostings, LLM-assisted writing accounts for just below 10% in small firms, and\nis even more common among younger firms. UN press releases also reflect this\ntrend, with nearly 14% of content being generated or modified by LLMs. Although\nadoption climbed rapidly post-ChatGPT, growth appears to have stabilized by\n2024, reflecting either saturation in LLM adoption or increasing subtlety of\nmore advanced models. Our study shows the emergence of a new reality in which\nfirms, consumers and even international organizations substantially rely on\ngenerative AI for communications.", "published": "2025-02-13 20:07:03", "link": "http://arxiv.org/abs/2502.09747v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Prompt and circumstance: A word-by-word LLM prompting approach to\n  interlinear glossing for low-resource languages", "abstract": "Partly automated creation of interlinear glossed text (IGT) has the potential\nto assist in linguistic documentation. We argue that LLMs can make this process\nmore accessible to linguists because of their capacity to follow\nnatural-language instructions. We investigate the effectiveness of a\nretrieval-based LLM prompting approach to glossing, applied to the seven\nlanguages from the SIGMORPHON 2023 shared task. Our system beats the BERT-based\nshared task baseline for every language in the morpheme-level score category,\nand we show that a simple 3-best oracle has higher word-level scores than the\nchallenge winner (a tuned sequence model) in five languages. In a case study on\nTsez, we ask the LLM to automatically create and follow linguistic\ninstructions, reducing errors on a confusing grammatical feature. Our results\nthus demonstrate the potential contributions which LLMs can make in interactive\nsystems for glossing, both in making suggestions to human annotators and\nfollowing directions.", "published": "2025-02-13 21:23:16", "link": "http://arxiv.org/abs/2502.09778v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for\n  16 African Languages", "abstract": "Slot-filling and intent detection are well-established tasks in\nConversational AI. However, current large-scale benchmarks for these tasks\noften exclude evaluations of low-resource languages and rely on translations\nfrom English benchmarks, thereby predominantly reflecting Western-centric\nconcepts. In this paper, we introduce Injongo -- a multicultural, open-source\nbenchmark dataset for 16 African languages with utterances generated by native\nspeakers across diverse domains, including banking, travel, home, and dining.\nThrough extensive experiments, we benchmark the fine-tuning multilingual\ntransformer models and the prompting large language models (LLMs), and show the\nadvantage of leveraging African-cultural utterances over Western-centric\nutterances for improving cross-lingual transfer from the English language.\nExperimental results reveal that current LLMs struggle with the slot-filling\ntask, with GPT-4o achieving an average performance of 26 F1-score. In contrast,\nintent detection performance is notably better, with an average accuracy of\n70.6%, though it still falls behind the fine-tuning baselines. Compared to the\nEnglish language, GPT-4o and fine-tuning baselines perform similarly on intent\ndetection, achieving an accuracy of approximately 81%. Our findings suggest\nthat the performance of LLMs is still behind for many low-resource African\nlanguages, and more work is needed to further improve their downstream\nperformance.", "published": "2025-02-13 23:17:10", "link": "http://arxiv.org/abs/2502.09814v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Statistical Coherence Alignment for Large Language Model Representation\n  Learning Through Tensor Field Convergence", "abstract": "Representation learning plays a central role in structuring internal\nembeddings to capture the statistical properties of language, influencing the\ncoherence and contextual consistency of generated text. Statistical Coherence\nAlignment is introduced as a method to enforce structured token representations\nthrough tensor field convergence, guiding embeddings to reflect statistical\ndependencies inherent in linguistic data. A mathematical framework is\nestablished to quantify coherence alignment, integrating a loss function that\noptimizes representational consistency across training iterations. Empirical\nevaluations demonstrate that applying coherence constraints improves\nperplexity, enhances classification accuracy, and refines rare word embeddings,\ncontributing to a more stable representation space. Comparative analyses with\nbaseline models reveal that the proposed method fosters a more interpretable\ninternal structure, ensuring that embeddings retain contextual dependencies\nwhile mitigating representation collapse. The impact on coherence score\ndistributions suggests that the alignment mechanism strengthens semantic\nintegrity across diverse linguistic constructs, leading to a more balanced\norganization of learned embeddings. Computational assessments indicate that\nwhile the method introduces additional memory and training costs, the\nstructured optimization process justifies the trade-offs in applications\nrequiring heightened contextual fidelity. Experimental results validate the\neffectiveness of coherence alignment in optimizing token representations,\nproviding insights into how statistical dependencies can be leveraged to\nimprove language model training.", "published": "2025-02-13 23:24:25", "link": "http://arxiv.org/abs/2502.09815v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of QUD Models for Discourse Processing", "abstract": "Question Under Discussion (QUD), which is originally a linguistic analytic\nframework, gains increasing attention in the community of natural language\nprocessing over the years. Various models have been proposed for implementing\nQUD for discourse processing. This survey summarizes these models, with a focus\non application to written texts, and examines studies that explore the\nrelationship between QUD and mainstream discourse frameworks, including RST,\nPDTB and SDRT. Some questions that may require further study are suggested.", "published": "2025-02-13 07:04:08", "link": "http://arxiv.org/abs/2502.15573v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "EnigmaEval: A Benchmark of Long Multimodal Reasoning Challenges", "abstract": "As language models master existing reasoning benchmarks, we need new\nchallenges to evaluate their cognitive frontiers. Puzzle-solving events are\nrich repositories of challenging multimodal problems that test a wide range of\nadvanced reasoning and knowledge capabilities, making them a unique testbed for\nevaluating frontier language models. We introduce EnigmaEval, a dataset of\nproblems and solutions derived from puzzle competitions and events that probes\nmodels' ability to perform implicit knowledge synthesis and multi-step\ndeductive reasoning. Unlike existing reasoning and knowledge benchmarks, puzzle\nsolving challenges models to discover hidden connections between seemingly\nunrelated pieces of information to uncover solution paths. The benchmark\ncomprises 1184 puzzles of varying complexity -- each typically requiring teams\nof skilled solvers hours to days to complete -- with unambiguous, verifiable\nsolutions that enable efficient evaluation. State-of-the-art language models\nachieve extremely low accuracy on these puzzles, even lower than other\ndifficult benchmarks such as Humanity's Last Exam, unveiling models'\nshortcomings when challenged with problems requiring unstructured and lateral\nreasoning.", "published": "2025-02-13 00:18:34", "link": "http://arxiv.org/abs/2502.08859v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Communication is All You Need: Persuasion Dataset Construction via\n  Multi-LLM Communication", "abstract": "Large Language Models (LLMs) have shown proficiency in generating persuasive\ndialogue, yet concerns about the fluency and sophistication of their outputs\npersist. This paper presents a multi-LLM communication framework designed to\nenhance the generation of persuasive data automatically. This framework\nfacilitates the efficient production of high-quality, diverse linguistic\ncontent with minimal human oversight. Through extensive evaluations, we\ndemonstrate that the generated data excels in naturalness, linguistic\ndiversity, and the strategic use of persuasion, even in complex scenarios\ninvolving social taboos. The framework also proves adept at generalizing across\nnovel contexts. Our results highlight the framework's potential to\nsignificantly advance research in both computational and social science domains\nconcerning persuasive communication.", "published": "2025-02-13 02:22:48", "link": "http://arxiv.org/abs/2502.08896v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Automated Fact-Checking of Real-World Claims: Exploring Task\n  Formulation and Assessment with LLMs", "abstract": "Fact-checking is necessary to address the increasing volume of\nmisinformation. Traditional fact-checking relies on manual analysis to verify\nclaims, but it is slow and resource-intensive. This study establishes baseline\ncomparisons for Automated Fact-Checking (AFC) using Large Language Models\n(LLMs) across multiple labeling schemes (binary, three-class, five-class) and\nextends traditional claim verification by incorporating analysis, verdict\nclassification, and explanation in a structured setup to provide comprehensive\njustifications for real-world claims. We evaluate Llama-3 models of varying\nsizes (3B, 8B, 70B) on 17,856 claims collected from PolitiFact (2007-2024)\nusing evidence retrieved via restricted web searches. We utilize TIGERScore as\na reference-free evaluation metric to score the justifications. Our results\nshow that larger LLMs consistently outperform smaller LLMs in classification\naccuracy and justification quality without fine-tuning. We find that smaller\nLLMs in a one-shot scenario provide comparable task performance to fine-tuned\nSmall Language Models (SLMs) with large context sizes, while larger LLMs\nconsistently surpass them. Evidence integration improves performance across all\nmodels, with larger LLMs benefiting most. Distinguishing between nuanced labels\nremains challenging, emphasizing the need for further exploration of labeling\nschemes and alignment with evidences. Our findings demonstrate the potential of\nretrieval-augmented AFC with LLMs.", "published": "2025-02-13 02:51:17", "link": "http://arxiv.org/abs/2502.08909v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on\n  a Single GPU", "abstract": "In modern large language models (LLMs), handling very long context lengths\npresents significant challenges as it causes slower inference speeds and\nincreased memory costs. Additionally, most existing pre-trained LLMs fail to\ngeneralize beyond their original training sequence lengths. To enable efficient\nand practical long-context utilization, we introduce InfiniteHiP, a novel, and\npractical LLM inference framework that accelerates processing by dynamically\neliminating irrelevant context tokens through a modular hierarchical token\npruning algorithm. Our method also allows generalization to longer sequences by\nselectively applying various RoPE adjustment methods according to the internal\nattention patterns within LLMs. Furthermore, we offload the key-value cache to\nhost memory during inference, significantly reducing GPU memory pressure. As a\nresult, InfiniteHiP enables the processing of up to 3 million tokens on a\nsingle L40s 48GB GPU -- 3x larger -- without any permanent loss of context\ninformation. Our framework achieves an 18.95x speedup in attention decoding for\na 1 million token context without requiring additional training. We implement\nour method in the SGLang framework and demonstrate its effectiveness and\npracticality through extensive evaluations.", "published": "2025-02-13 02:52:01", "link": "http://arxiv.org/abs/2502.08910v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Tuning-Free Personalized Alignment via Trial-Error-Explain In-Context\n  Learning", "abstract": "Language models are aligned to the collective voice of many, resulting in\ngeneric outputs that do not align with specific users' styles. In this work, we\npresent Trial-Error-Explain In-Context Learning (TICL), a tuning-free method\nthat personalizes language models for text generation tasks with fewer than 10\nexamples per user. TICL iteratively expands an in-context learning prompt via a\ntrial-error-explain process, adding model-generated negative samples and\nexplanations that provide fine-grained guidance towards a specific user's\nstyle. TICL achieves favorable win rates on pairwise comparisons with\nLLM-as-a-judge up to 91.5% against the previous state-of-the-art and\noutperforms competitive tuning-free baselines for personalized alignment tasks\nof writing emails, essays and news articles. Both lexical and qualitative\nanalyses show that the negative samples and explanations enable language models\nto learn stylistic context more effectively and overcome the bias towards\nstructural and formal phrases observed in their zero-shot outputs. By\nfront-loading inference compute to create a user-specific in-context learning\nprompt that does not require extra generation steps at test time, TICL presents\na novel yet simple approach for personalized alignment.", "published": "2025-02-13 05:20:21", "link": "http://arxiv.org/abs/2502.08972v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Diversity Enhances an LLM's Performance in RAG and Long-context Task", "abstract": "The rapid advancements in large language models (LLMs) have highlighted the\nchallenge of context window limitations, primarily due to the quadratic time\ncomplexity of the self-attention mechanism (\\(O(N^2)\\), where \\(N\\) denotes the\ncontext window length). This constraint impacts tasks such as\nretrieval-augmented generation (RAG) in question answering (Q\\&A) and long\ncontext summarization. A common approach involves selecting content with the\nhighest similarity to the query; however, this often leads to redundancy and\nthe exclusion of diverse yet relevant information. Building on principles from\nMaximal Marginal Relevance (MMR) and Farthest Point Sampling (FPS), we\nintegrate diversity into the content selection process. Our findings reveal\nthat incorporating diversity substantially increases the recall of selecting\nrelevant sentences or chunks before LLM-based Q\\&A and summarization. These\nresults highlight the importance of maintaining diversity in future LLM\napplications to further improve summarization and Q\\&A outcomes.", "published": "2025-02-13 07:11:01", "link": "http://arxiv.org/abs/2502.09017v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Typhoon T1: An Open Thai Reasoning Model", "abstract": "This paper introduces Typhoon T1, an open effort to develop an open Thai\nreasoning model. A reasoning model is a relatively new type of generative model\nbuilt on top of large language models (LLMs). A reasoning model generates a\nlong chain of thought before arriving at a final answer, an approach found to\nimprove performance on complex tasks. However, details on developing such a\nmodel are limited, especially for reasoning models that can generate traces in\na low-resource language. Typhoon T1 presents an open effort that dives into the\ndetails of developing a reasoning model in a more cost-effective way by\nleveraging supervised fine-tuning using open datasets, instead of reinforcement\nlearning. This paper shares the details about synthetic data generation and\ntraining, as well as our dataset and model weights. Additionally, we provide\ninsights gained from developing a reasoning model that generalizes across\ndomains and is capable of generating reasoning traces in a low-resource\nlanguage, using Thai as an example. We hope this open effort provides a\nfoundation for further research in this field.", "published": "2025-02-13 07:55:54", "link": "http://arxiv.org/abs/2502.09042v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Adapting Language-Specific LLMs to a Reasoning Model in One Day via\n  Model Merging -- An Open Recipe", "abstract": "This paper investigates data selection and model merging methodologies aimed\nat incorporating advanced reasoning capabilities such as those of DeepSeek R1\ninto language-specific large language models (LLMs), with a particular focus on\nthe Thai LLM. Our goal is to enhance the reasoning capabilities of\nlanguage-specific LLMs while maintaining their target language abilities.\nDeepSeek R1 excels in reasoning but primarily benefits high-resource languages\nsuch as English and Chinese. However, low-resource languages remain underserved\ndue to the dominance of English-centric training data and model optimizations,\nwhich limit performance in these languages. This limitation results in\nunreliable code-switching and diminished effectiveness on tasks in low-resource\nlanguages. Meanwhile, local and regional LLM initiatives have attempted to\nbridge this gap by developing language-specific LLMs that focus on improving\nlocal linguistic fidelity. We demonstrate that, with only publicly available\ndatasets and a computational budget of $120, it is possible to enhance the\nreasoning capabilities of language-specific LLMs to match the level of DeepSeek\nR1, without compromising their performance on target language tasks.", "published": "2025-02-13 08:10:45", "link": "http://arxiv.org/abs/2502.09056v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "CoSER: Coordinating LLM-Based Persona Simulation of Established Roles", "abstract": "Role-playing language agents (RPLAs) have emerged as promising applications\nof large language models (LLMs). However, simulating established characters\npresents a challenging task for RPLAs, due to the lack of authentic character\ndatasets and nuanced evaluation methods using such data. In this paper, we\npresent CoSER, a collection of a high-quality dataset, open models, and an\nevaluation protocol towards effective RPLAs of established characters. The\nCoSER dataset covers 17,966 characters from 771 renowned books. It provides\nauthentic dialogues with real-world intricacies, as well as diverse data types\nsuch as conversation setups, character experiences and internal thoughts.\nDrawing from acting methodology, we introduce given-circumstance acting for\ntraining and evaluating role-playing LLMs, where LLMs sequentially portray\nmultiple characters in book scenes. Using our dataset, we develop CoSER 8B and\nCoSER 70B, i.e., advanced open role-playing LLMs built on LLaMA-3.1 models.\nExtensive experiments demonstrate the value of the CoSER dataset for RPLA\ntraining, evaluation and retrieval. Moreover, CoSER 70B exhibits\nstate-of-the-art performance surpassing or matching GPT-4o on our evaluation\nand three existing benchmarks, i.e., achieving 75.80% and 93.47% accuracy on\nthe InCharacter and LifeChoice benchmarks respectively.", "published": "2025-02-13 08:55:24", "link": "http://arxiv.org/abs/2502.09082v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Logical Reasoning in Large Language Models: A Survey", "abstract": "With the emergence of advanced reasoning models like OpenAI o3 and\nDeepSeek-R1, large language models (LLMs) have demonstrated remarkable\nreasoning capabilities. However, their ability to perform rigorous logical\nreasoning remains an open question. This survey synthesizes recent advancements\nin logical reasoning within LLMs, a critical area of AI research. It outlines\nthe scope of logical reasoning in LLMs, its theoretical foundations, and the\nbenchmarks used to evaluate reasoning proficiency. We analyze existing\ncapabilities across different reasoning paradigms - deductive, inductive,\nabductive, and analogical - and assess strategies to enhance reasoning\nperformance, including data-centric tuning, reinforcement learning, decoding\nstrategies, and neuro-symbolic approaches. The review concludes with future\ndirections, emphasizing the need for further exploration to strengthen logical\nreasoning in AI systems.", "published": "2025-02-13 09:19:14", "link": "http://arxiv.org/abs/2502.09100v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "A Novel Dialect-Aware Framework for the Classification of Arabic\n  Dialects and Emotions", "abstract": "Arabic is one of the oldest languages still in use today. As a result,\nseveral Arabic-speaking regions have developed dialects that are unique to\nthem. Dialect and emotion recognition have various uses in Arabic text\nanalysis, such as determining an online customer's origin based on their\ncomments. Furthermore, intelligent chatbots that are aware of a user's emotions\ncan respond appropriately to the user. Current research in emotion detection in\nthe Arabic language lacks awareness of how emotions are exhibited in different\ndialects, which motivates the work found in this study. This research addresses\nthe problems of dialect and emotion classification in Arabic. Specifically,\nthis is achieved by building a novel framework that can identify and predict\nArabic dialects and emotions from a given text. The framework consists of three\nmodules: A text-preprocessing module, a classification module, and a clustering\nmodule with the novel capability of building new dialect-aware emotion\nlexicons. The proposed framework generated a new emotional lexicon for\ndifferent dialects. It achieved an accuracy of 88.9% in classifying Arabic\ndialects, which outperforms the state-of-the-art results by 6.45 percentage\npoints. Furthermore, the framework achieved 89.1-79% accuracy in detecting\nemotions in the Egyptian and Gulf dialects, respectively.", "published": "2025-02-13 10:05:44", "link": "http://arxiv.org/abs/2502.09128v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "RefineCoder: Iterative Improving of Large Language Models via Adaptive\n  Critique Refinement for Code Generation", "abstract": "Code generation has attracted increasing attention with the rise of Large\nLanguage Models (LLMs). Many studies have developed powerful code LLMs by\nsynthesizing code-related instruction data and applying supervised fine-tuning.\nHowever, these methods are limited by teacher model distillation and ignore the\npotential of iterative refinement by self-generated code. In this paper, we\npropose Adaptive Critique Refinement (ACR), which enables the model to refine\nitself by self-generated code and external critique, rather than directly\nimitating the code responses of the teacher model. Concretely, ACR includes a\ncomposite scoring system with LLM-as-a-Judge to evaluate the quality of code\nresponses and a selective critique strategy with LLM-as-a-Critic to critique\nself-generated low-quality code responses. We develop the RefineCoder series by\niteratively applying ACR, achieving continuous performance improvement on\nmultiple code generation benchmarks. Compared to the baselines of the same\nsize, our proposed RefineCoder series can achieve comparable or even superior\nperformance using less data.", "published": "2025-02-13 11:17:53", "link": "http://arxiv.org/abs/2502.09183v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Matina: A Large-Scale 73B Token Persian Text Corpus", "abstract": "Text corpora are essential for training models used in tasks like\nsummarization, translation, and large language models (LLMs). While various\nefforts have been made to collect monolingual and multilingual datasets in many\nlanguages, Persian has often been underrepresented due to limited resources for\ndata collection and preprocessing. Existing Persian datasets are typically\nsmall and lack content diversity, consisting mainly of weblogs and news\narticles. This shortage of high-quality, varied data has slowed the development\nof NLP models and open-source LLMs for Persian. Since model performance depends\nheavily on the quality of training data, we address this gap by introducing the\nMatina corpus, a new Persian dataset of 72.9B tokens, carefully preprocessed\nand deduplicated to ensure high data quality. We further assess its\neffectiveness by training and evaluating transformer-based models on key NLP\ntasks. Both the dataset and preprocessing codes are publicly available,\nenabling researchers to build on and improve this resource for future Persian\nNLP advancements.", "published": "2025-02-13 11:22:19", "link": "http://arxiv.org/abs/2502.09188v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LP-LM: No Hallucinations in Question Answering with Logic Programming", "abstract": "Large language models (LLMs) are able to generate human-like responses to\nuser queries. However, LLMs exhibit inherent limitations, especially because\nthey hallucinate. This paper introduces LP-LM, a system that grounds answers to\nquestions in known facts contained in a knowledge base (KB), facilitated\nthrough semantic parsing in Prolog, and always produces answers that are\nreliable.\n  LP-LM generates a most probable constituency parse tree along with a\ncorresponding Prolog term for an input question via Prolog definite clause\ngrammar (DCG) parsing. The term is then executed against a KB of natural\nlanguage sentences also represented as Prolog terms for question answering. By\nleveraging DCG and tabling, LP-LM runs in linear time in the size of input\nsentences for sufficiently many grammar rules. Performing experiments comparing\nLP-LM with current well-known LLMs in accuracy, we show that LLMs hallucinate\non even simple questions, unlike LP-LM.", "published": "2025-02-13 11:48:31", "link": "http://arxiv.org/abs/2502.09212v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Neuro-Symbolic Contrastive Learning for Cross-domain Inference", "abstract": "Pre-trained language models (PLMs) have made significant advances in natural\nlanguage inference (NLI) tasks, however their sensitivity to textual\nperturbations and dependence on large datasets indicate an over-reliance on\nshallow heuristics. In contrast, inductive logic programming (ILP) excels at\ninferring logical relationships across diverse, sparse and limited datasets,\nbut its discrete nature requires the inputs to be precisely specified, which\nlimits their application. This paper proposes a bridge between the two\napproaches: neuro-symbolic contrastive learning. This allows for smooth and\ndifferentiable optimisation that improves logical accuracy across an otherwise\ndiscrete, noisy, and sparse topological space of logical functions. We show\nthat abstract logical relationships can be effectively embedded within a\nneuro-symbolic paradigm, by representing data as logic programs and sets of\nlogic rules. The embedding space captures highly varied textual information\nwith similar semantic logical relations, but can also separate similar textual\nrelations that have dissimilar logical relations. Experimental results\ndemonstrate that our approach significantly improves the inference capabilities\nof the models in terms of generalisation and reasoning.", "published": "2025-02-13 11:48:46", "link": "http://arxiv.org/abs/2502.09213v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Answer Set Counting and its Applications", "abstract": "We have focused on Answer Set Programming (ASP), more specifically, answer\nset counting, exploring both exact and approximate methodologies. We developed\nan exact ASP counter, sharpASP, which utilizes a compact encoding for\npropositional formulas, significantly enhancing efficiency compared to existing\nmethods that often struggle with inefficient encodings. Our evaluations\nindicate that sharpASP outperforms current ASP counters on several benchmarks.\nIn addition, we proposed an approximate ASP counter, named ApproxASP, a\nhashing-based counter integrating Gauss-Jordan elimination within the ASP\nsolver, clingo. As a practical application, we employed ApproxASP for network\nreliability estimation, demonstrating superior performance over both\ntraditional reliability estimators and #SAT-based methods.", "published": "2025-02-13 11:52:55", "link": "http://arxiv.org/abs/2502.09231v1", "categories": ["cs.CL", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Reliable Conversational Agents under ASP Control that Understand Natural\n  Language", "abstract": "Efforts have been made to make machines converse like humans in the past few\ndecades. The recent techniques of Large Language Models (LLMs) make it possible\nto have human-like conversations with machines, but LLM's flaws of lacking\nunderstanding and reliability are well documented. We believe that the best way\nto eliminate this problem is to use LLMs only as parsers to translate text to\nknowledge and vice versa and carry out the conversation by reasoning over this\nknowledge using the answer set programming. I have been developing a framework\nbased on LLMs and ASP to realize reliable chatbots that \"understand\" human\nconversation. This framework has been used to develop task-specific chatbots as\nwell as socialbots. My future research is focused on making these chatbots\nscalable and trainable.", "published": "2025-02-13 11:54:28", "link": "http://arxiv.org/abs/2502.09237v1", "categories": ["cs.LO", "cs.CL"], "primary_category": "cs.LO"}
{"title": "You Do Not Fully Utilize Transformer's Representation Capacity", "abstract": "In contrast to RNNs, which compress previous tokens into a single hidden\nstate, Transformers can attend to all previous tokens directly. However,\nstandard Transformers only use representations from the immediately preceding\nlayer. In this paper, we show that this design choice causes representation\ncollapse and leads to suboptimal performance. To address this issue, we\nintroduce Layer-Integrated Memory (LIMe), a simple yet powerful approach that\npreserves the model's overall memory footprint while expanding its\nrepresentational capacity by allowing access to hidden states from earlier\nlayers. Through extensive experiments across various architectures and\ndifferent lookup mechanisms, we demonstrate consistent performance improvements\non a wide range of tasks. Moreover, our analysis of the learned representation\ndynamics and our exploration of depthwise circuits reveal how LIMe integrates\ninformation across layers, pointing to promising directions for future\nresearch.", "published": "2025-02-13 12:00:50", "link": "http://arxiv.org/abs/2502.09245v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "The Joint Entity-Relation Extraction Model Based on Span and Interactive\n  Fusion Representation for Chinese Medical Texts with Complex Semantics", "abstract": "Joint entity-relation extraction is a critical task in transforming\nunstructured or semi-structured text into triplets, facilitating the\nconstruction of large-scale knowledge graphs, and supporting various downstream\napplications. Despite its importance, research on Chinese text, particularly\nwith complex semantics in specialized domains like medicine, remains limited.\nTo address this gap, we introduce the CH-DDI, a Chinese drug-drug interactions\ndataset designed to capture the intricacies of medical text. Leveraging the\nstrengths of attention mechanisms in capturing long-range dependencies, we\npropose the SEA module, which enhances the extraction of complex contextual\nsemantic information, thereby improving entity recognition and relation\nextraction. Additionally, to address the inefficiencies of existing methods in\nfacilitating information exchange between entity recognition and relation\nextraction, we present an interactive fusion representation module. This module\nemploys Cross Attention for bidirectional information exchange between the\ntasks and further refines feature extraction through BiLSTM. Experimental\nresults on both our CH-DDI dataset and public CoNLL04 dataset demonstrate that\nour model exhibits strong generalization capabilities. On the CH-DDI dataset,\nour model achieves an F1-score of 96.73% for entity recognition and 78.43% for\nrelation extraction. On the CoNLL04 dataset, it attains an entity recognition\nprecision of 89.54% and a relation extraction accuracy of 71.64%.", "published": "2025-02-13 12:03:36", "link": "http://arxiv.org/abs/2502.09247v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SparQLe: Speech Queries to Text Translation Through LLMs", "abstract": "With the growing influence of Large Language Models (LLMs), there is\nincreasing interest in integrating speech representations with them to enable\nmore seamless multi-modal processing and speech understanding. This study\nintroduces a novel approach that leverages self-supervised speech\nrepresentations in combination with instruction-tuned LLMs for speech-to-text\ntranslation. The proposed approach leverages a modality adapter to align\nextracted speech features with instruction-tuned LLMs using English-language\ndata. Our experiments demonstrate that this method effectively preserves the\nsemantic content of the input speech and serves as an effective bridge between\nself-supervised speech models and instruction-tuned LLMs, offering a promising\nsolution for various speech understanding applications.", "published": "2025-02-13 12:57:15", "link": "http://arxiv.org/abs/2502.09284v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "When the LM misunderstood the human chuckled: Analyzing garden path\n  effects in humans and language models", "abstract": "Modern Large Language Models (LLMs) have shown human-like abilities in many\nlanguage tasks, sparking interest in comparing LLMs' and humans' language\nprocessing. In this paper, we conduct a detailed comparison of the two on a\nsentence comprehension task using garden-path constructions, which are\nnotoriously challenging for humans. Based on psycholinguistic research, we\nformulate hypotheses on why garden-path sentences are hard, and test these\nhypotheses on human participants and a large suite of LLMs using comprehension\nquestions. Our findings reveal that both LLMs and humans struggle with specific\nsyntactic complexities, with some models showing high correlation with human\ncomprehension. To complement our findings, we test LLM comprehension of\ngarden-path constructions with paraphrasing and text-to-image generation tasks,\nand find that the results mirror the sentence comprehension question results,\nfurther validating our findings on LLM understanding of these constructions.", "published": "2025-02-13 13:19:33", "link": "http://arxiv.org/abs/2502.09307v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On multi-token prediction for efficient LLM inference", "abstract": "We systematically investigate multi-token prediction (MTP) capabilities\nwithin LLMs pre-trained for next-token prediction (NTP). We first show that\nsuch models inherently possess MTP capabilities via numerical marginalization\nover intermediate token probabilities, though performance is data-dependent and\nimproves with model scale. Furthermore, we explore the challenges of\nintegrating MTP heads into frozen LLMs and find that their hidden layers are\nstrongly specialized for NTP, making adaptation non-trivial. Finally, we show\nthat while joint training of MTP heads with the backbone improves performance,\nit cannot fully overcome this barrier, prompting further research in this\ndirection. Our findings provide a deeper understanding of MTP applied to\npretrained LLMs, informing strategies for accelerating inference through\nparallel token prediction.", "published": "2025-02-13 15:42:44", "link": "http://arxiv.org/abs/2502.09419v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pixel-Level Reasoning Segmentation via Multi-turn Conversations", "abstract": "Existing visual perception systems focus on region-level segmentation in\nsingle-turn dialogues, relying on complex and explicit query instructions. Such\nsystems cannot reason at the pixel level and comprehend dynamic user intent\nthat changes over interaction. Our work tackles this issue by introducing a\nnovel task, Pixel-level Reasoning Segmentation (Pixel-level RS) based on\nmulti-turn conversations, tracking evolving user intent via multi-turn\ninteractions for fine-grained segmentation. To establish a benchmark for this\nnovel task, we build a Pixel-level ReasonIng Segmentation Dataset Based on\nMulti-Turn Conversations (PRIST), comprising 24k utterances from 8.3k\nmulti-turn conversational scenarios with segmentation targets. Building on\nPRIST, we further propose MIRAS, a Multi-turn Interactive ReAsoning\nSegmentation framework, integrates pixel-level segmentation with robust\nmulti-turn conversation understanding, generating pixel-grounded explanations\naligned with user intent. The PRIST dataset and MIRSA framework fill the gap in\npixel-level reasoning segmentation. Experimental results on the PRIST dataset\ndemonstrate that our method outperforms current segmentation-specific baselines\nin terms of segmentation and LLM-based reasoning metrics. The code and data are\navailable at: https://github.com/ccccai239/PixelRIST.", "published": "2025-02-13 16:16:54", "link": "http://arxiv.org/abs/2502.09447v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Improve LLM-based Automatic Essay Scoring with Linguistic Features", "abstract": "Automatic Essay Scoring (AES) assigns scores to student essays, reducing the\ngrading workload for instructors. Developing a scoring system capable of\nhandling essays across diverse prompts is challenging due to the flexibility\nand diverse nature of the writing task. Existing methods typically fall into\ntwo categories: supervised feature-based approaches and large language model\n(LLM)-based methods. Supervised feature-based approaches often achieve higher\nperformance but require resource-intensive training. In contrast, LLM-based\nmethods are computationally efficient during inference but tend to suffer from\nlower performance. This paper combines these approaches by incorporating\nlinguistic features into LLM-based scoring. Experimental results show that this\nhybrid method outperforms baseline models for both in-domain and out-of-domain\nwriting prompts.", "published": "2025-02-13 17:09:52", "link": "http://arxiv.org/abs/2502.09497v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Zero-shot generation of synthetic neurosurgical data with large language\n  models", "abstract": "Clinical data is fundamental to advance neurosurgical research, but access is\noften constrained by data availability, small sample sizes, privacy\nregulations, and resource-intensive preprocessing and de-identification\nprocedures. Synthetic data offers a potential solution to challenges associated\nwith accessing and using real-world data (RWD). This study aims to evaluate the\ncapability of zero-shot generation of synthetic neurosurgical data with a large\nlanguage model (LLM), GPT-4o, by benchmarking with the conditional tabular\ngenerative adversarial network (CTGAN). Synthetic datasets were compared to\nreal-world neurosurgical data to assess fidelity (means, proportions,\ndistributions, and bivariate correlations), utility (ML classifier performance\non RWD), and privacy (duplication of records from RWD). The GPT-4o-generated\ndatasets matched or exceeded CTGAN performance, despite no fine-tuning or\naccess to RWD for pre-training. Datasets demonstrated high univariate and\nbivariate fidelity to RWD without directly exposing any real patient records,\neven at amplified sample size. Training an ML classifier on GPT-4o-generated\ndata and testing on RWD for a binary prediction task showed an F1 score (0.706)\nwith comparable performance to training on the CTGAN data (0.705) for\npredicting postoperative functional status deterioration. GPT-4o demonstrated a\npromising ability to generate high-fidelity synthetic neurosurgical data. These\nfindings also indicate that data synthesized with GPT-4o can effectively\naugment clinical data with small sample sizes, and train ML models for\nprediction of neurosurgical outcomes. Further investigation is necessary to\nimprove the preservation of distributional characteristics and boost classifier\nperformance.", "published": "2025-02-13 18:21:15", "link": "http://arxiv.org/abs/2502.09566v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "MorphNLI: A Stepwise Approach to Natural Language Inference Using Text\n  Morphing", "abstract": "We introduce MorphNLI, a modular step-by-step approach to natural language\ninference (NLI). When classifying the premise-hypothesis pairs into\n{entailment, contradiction, neutral}, we use a language model to generate the\nnecessary edits to incrementally transform (i.e., morph) the premise into the\nhypothesis. Then, using an off-the-shelf NLI model we track how the entailment\nprogresses with these atomic changes, aggregating these intermediate labels\ninto a final output. We demonstrate the advantages of our proposed method\nparticularly in realistic cross-domain settings, where our method always\noutperforms strong baselines with improvements up to 12.6% (relative). Further,\nour proposed approach is explainable as the atomic edits can be used to\nunderstand the overall NLI label.", "published": "2025-02-13 18:22:31", "link": "http://arxiv.org/abs/2502.09567v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Logical forms complement probability in understanding language model\n  (and human) performance", "abstract": "With the increasing interest in using large language models (LLMs) for\nplanning in natural language, understanding their behaviors becomes an\nimportant research question. This work conducts a systematic investigation of\nLLMs' ability to perform logical reasoning in natural language. We introduce a\ncontrolled dataset of hypothetical and disjunctive syllogisms in propositional\nand modal logic and use it as the testbed for understanding LLM performance.\nOur results lead to novel insights in predicting LLM behaviors: in addition to\nthe probability of input (Gonen et al., 2023; McCoy et al., 2024), logical\nforms should be considered as important factors. In addition, we show\nsimilarities and discrepancies between the logical reasoning performances of\nhumans and LLMs by collecting and comparing behavioral data from both.", "published": "2025-02-13 18:46:44", "link": "http://arxiv.org/abs/2502.09589v2", "categories": ["cs.CL", "cs.LO"], "primary_category": "cs.CL"}
{"title": "Do LLMs Recognize Your Preferences? Evaluating Personalized Preference\n  Following in LLMs", "abstract": "Large Language Models (LLMs) are increasingly used as chatbots, yet their\nability to personalize responses to user preferences remains limited. We\nintroduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize\nand adhere to user preferences in a long-context conversational setting.\nPrefEval comprises 3,000 manually curated user preference and query pairs\nspanning 20 topics. PrefEval contains user personalization or preference\ninformation in both explicit and implicit forms, and evaluates LLM performance\nusing a generation and a classification task. With PrefEval, we evaluated the\naforementioned preference following capabilities of 10 open-source and\nproprietary LLMs in multi-session conversations with varying context lengths up\nto 100k tokens. We benchmark with various prompting, iterative feedback, and\nretrieval-augmented generation methods. Our benchmarking effort reveals that\nstate-of-the-art LLMs face significant challenges in proactively following\nusers' preferences during conversations. In particular, in zero-shot settings,\npreference following accuracy falls below 10% at merely 10 turns (~3k tokens)\nacross most evaluated models. Even with advanced prompting and retrieval\nmethods, preference following still deteriorates in long-context conversations.\nFurthermore, we show that fine-tuning on PrefEval significantly improves\nperformance. We believe PrefEval serves as a valuable resource for measuring,\nunderstanding, and enhancing LLMs' preference following abilities, paving the\nway for personalized conversational agents. Our code and dataset are available\nat https://prefeval.github.io/.", "published": "2025-02-13 18:52:03", "link": "http://arxiv.org/abs/2502.09597v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "ASVspoof 5: Design, Collection and Validation of Resources for Spoofing,\n  Deepfake, and Adversarial Attack Detection Using Crowdsourced Speech", "abstract": "ASVspoof 5 is the fifth edition in a series of challenges which promote the\nstudy of speech spoofing and deepfake attacks as well as the design of\ndetection solutions. We introduce the ASVspoof 5 database which is generated in\ncrowdsourced fashion from data collected in diverse acoustic conditions (cf.\nstudio-quality data for earlier ASVspoof databases) and from ~2,000 speakers\n(cf. ~100 earlier). The database contains attacks generated with 32 different\nalgorithms, also crowdsourced, and optimised to varying degrees using new\nsurrogate detection models. Among them are attacks generated with a mix of\nlegacy and contemporary text-to-speech synthesis and voice conversion models,\nin addition to adversarial attacks which are incorporated for the first time.\nASVspoof 5 protocols comprise seven speaker-disjoint partitions. They include\ntwo distinct partitions for the training of different sets of attack models,\ntwo more for the development and evaluation of surrogate detection models, and\nthen three additional partitions which comprise the ASVspoof 5 training,\ndevelopment and evaluation sets. An auxiliary set of data collected from an\nadditional 30k speakers can also be used to train speaker encoders for the\nimplementation of attack algorithms. Also described herein is an experimental\nvalidation of the new ASVspoof 5 database using a set of automatic speaker\nverification and spoof/deepfake baseline detectors. With the exception of\nprotocols and tools for the generation of spoofed/deepfake speech, the\nresources described in this paper, already used by participants of the ASVspoof\n5 challenge in 2024, are now all freely available to the community.", "published": "2025-02-13 00:15:54", "link": "http://arxiv.org/abs/2502.08857v3", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Predicting Cognitive Decline: A Multimodal AI Approach to Dementia\n  Screening from Speech", "abstract": "Recent progress has been made in detecting early stage dementia entirely\nthrough recordings of patient speech. Multimodal speech analysis methods were\napplied to the PROCESS challenge, which requires participants to use audio\nrecordings of clinical interviews to predict patients as healthy control, mild\ncognitive impairment (MCI), or dementia and regress the patient's Mini-Mental\nState Exam (MMSE) scores. The approach implemented in this work combines\nacoustic features (eGeMAPS and Prosody) with embeddings from Whisper and\nRoBERTa models, achieving competitive results in both regression (RMSE: 2.7666)\nand classification (Macro-F1 score: 0.5774) tasks. Additionally, a novel\ntwo-tiered classification setup is utilized to better differentiate between MCI\nand dementia. Our approach achieved strong results on the test set, ranking\nseventh on regression and eleventh on classification out of thirty-seven teams,\nexceeding the baseline results.", "published": "2025-02-13 00:24:51", "link": "http://arxiv.org/abs/2502.08862v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Advances in Microphone Array Processing and Multichannel Speech\n  Enhancement", "abstract": "This paper reviews pioneering works in microphone array processing and\nmultichannel speech enhancement, highlighting historical achievements,\ntechnological evolution, commercialization aspects, and key challenges. It\nprovides valuable insights into the progression and future direction of these\nareas. The paper examines foundational developments in microphone array design\nand optimization, showcasing innovations that improved sound acquisition and\nenhanced speech intelligibility in noisy and reverberant environments. It then\nintroduces recent advancements and cutting-edge research in the field,\nparticularly the integration of deep learning techniques such as all-neural\nbeamformers. The paper also explores critical applications, discussing their\nevolution and current state-of-the-art technologies that significantly impact\nuser experience. Finally, the paper outlines future research directions,\nidentifying challenges and potential solutions that could drive further\ninnovation in these fields. By providing a comprehensive overview and\nforward-looking perspective, this paper aims to inspire ongoing research and\ncontribute to the sustained growth and development of microphone arrays and\nmultichannel speech enhancement.", "published": "2025-02-13 07:43:23", "link": "http://arxiv.org/abs/2502.09037v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers\n  and Large Language Models", "abstract": "The increasing prevalence of microphones in everyday devices and the growing\nreliance on online services have amplified the risk of acoustic side-channel\nattacks (ASCAs) targeting keyboards. This study explores deep learning\ntechniques, specifically vision transformers (VTs) and large language models\n(LLMs), to enhance the effectiveness and applicability of such attacks. We\npresent substantial improvements over prior research, with the CoAtNet model\nachieving state-of-the-art performance. Our CoAtNet shows a 5.0% improvement\nfor keystrokes recorded via smartphone (Phone) and 5.9% for those recorded via\nZoom compared to previous benchmarks. We also evaluate transformer\narchitectures and language models, with the best VT model matching CoAtNet's\nperformance. A key advancement is the introduction of a noise mitigation method\nfor real-world scenarios. By using LLMs for contextual understanding, we detect\nand correct erroneous keystrokes in noisy environments, enhancing ASCA\nperformance. Additionally, fine-tuned lightweight language models with Low-Rank\nAdaptation (LoRA) deliver comparable performance to heavyweight models with 67X\nmore parameters. This integration of VTs and LLMs improves the practical\napplicability of ASCA mitigation, marking the first use of these technologies\nto address ASCAs and error correction in real-world scenarios.", "published": "2025-02-13 21:33:57", "link": "http://arxiv.org/abs/2502.09782v3", "categories": ["cs.LG", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "cs.LG"}
