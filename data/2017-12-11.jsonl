{"title": "Scale Up Event Extraction Learning via Automatic Training Data\n  Generation", "abstract": "The task of event extraction has long been investigated in a supervised\nlearning paradigm, which is bound by the number and the quality of the training\ninstances. Existing training data must be manually generated through a\ncombination of expert domain knowledge and extensive human involvement.\nHowever, due to drastic efforts required in annotating text, the resultant\ndatasets are usually small, which severally affects the quality of the learned\nmodel, making it hard to generalize. Our work develops an automatic approach\nfor generating training data for event extraction. Our approach allows us to\nscale up event extraction training instances from thousands to hundreds of\nthousands, and it does this at a much lower cost than a manual approach. We\nachieve this by employing distant supervision to automatically create event\nannotations from unlabelled text using existing structured knowledge bases or\ntables.We then develop a neural network model with post inference to transfer\nthe knowledge extracted from structured knowledge bases to automatically\nannotate typed events with corresponding arguments in text.We evaluate our\napproach by using the knowledge extracted from Freebase to label texts from\nWikipedia articles. Experimental results show that our approach can generate a\nlarge number of high quality training instances. We show that this large volume\nof training data not only leads to a better event extractor, but also allows us\nto detect multiple typed events.", "published": "2017-12-11 07:41:28", "link": "http://arxiv.org/abs/1712.03665v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "On the Benefit of Combining Neural, Statistical and External Features\n  for Fake News Identification", "abstract": "Identifying the veracity of a news article is an interesting problem while\nautomating this process can be a challenging task. Detection of a news article\nas fake is still an open question as it is contingent on many factors which the\ncurrent state-of-the-art models fail to incorporate. In this paper, we explore\na subtask to fake news identification, and that is stance detection. Given a\nnews article, the task is to determine the relevance of the body and its claim.\nWe present a novel idea that combines the neural, statistical and external\nfeatures to provide an efficient solution to this problem. We compute the\nneural embedding from the deep recurrent model, statistical features from the\nweighted n-gram bag-of-words model and handcrafted external features with the\nhelp of feature engineering heuristics. Finally, using deep neural layer all\nthe features are combined, thereby classifying the headline-body news pair as\nagree, disagree, discuss, or unrelated. We compare our proposed technique with\nthe current state-of-the-art models on the fake news challenge dataset. Through\nextensive experiments, we find that the proposed model outperforms all the\nstate-of-the-art techniques including the submissions to the fake news\nchallenge.", "published": "2017-12-11 18:32:11", "link": "http://arxiv.org/abs/1712.03935v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Social Media Writing Style Fingerprint", "abstract": "We present our approach for computer-aided social media text authorship\nattribution based on recent advances in short text authorship verification. We\nuse various natural language techniques to create word-level and\ncharacter-level models that act as hidden layers to simulate a simple neural\nnetwork. The choice of word-level and character-level models in each layer was\ninformed through validation performance. The output layer of our system uses an\nunweighted majority vote vector to arrive at a conclusion. We also considered\nwriting bias in social media posts while collecting our training dataset to\nincrease system robustness. Our system achieved a precision, recall, and\nF-measure of 0.82, 0.926 and 0.869 respectively.", "published": "2017-12-11 20:03:22", "link": "http://arxiv.org/abs/1712.04762v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Long-Range Correlation Underlying Childhood Language and Generative\n  Models", "abstract": "Long-range correlation, a property of time series exhibiting long-term\nmemory, is mainly studied in the statistical physics domain and has been\nreported to exist in natural language. Using a state-of-the-art method for such\nanalysis, long-range correlation is first shown to occur in long CHILDES data\nsets. To understand why, Bayesian generative models of language, originally\nproposed in the cognitive scientific domain, are investigated. Among\nrepresentative models, the Simon model was found to exhibit surprisingly good\nlong-range correlation, but not the Pitman-Yor model. Since the Simon model is\nknown not to correctly reflect the vocabulary growth of natural language, a\nsimple new model is devised as a conjunct of the Simon and Pitman-Yor models,\nsuch that long-range correlation holds with a correct vocabulary growth rate.\nThe investigation overall suggests that uniform sampling is one cause of\nlong-range correlation and could thus have a relation with actual linguistic\nprocesses.", "published": "2017-12-11 04:48:43", "link": "http://arxiv.org/abs/1712.03645v1", "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "cs.CL"}
{"title": "A Novel Way of Identifying Cyber Predators", "abstract": "Recurrent Neural Networks with Long Short-Term Memory cell (LSTM-RNN) have\nimpressive ability in sequence data processing, particularly for language model\nbuilding and text classification. This research proposes the combination of\nsentiment analysis, new approach of sentence vectors and LSTM-RNN as a novel\nway for Sexual Predator Identification (SPI). LSTM-RNN language model is\napplied to generate sentence vectors which are the last hidden states in the\nlanguage model. Sentence vectors are fed into another LSTM-RNN classifier, so\nas to capture suspicious conversations. Hidden state enables to generate\nvectors for sentences never seen before. Fasttext is used to filter the\ncontents of conversations and generate a sentiment score so as to identify\npotential predators. The experiment achieves a record-breaking accuracy and\nprecision of 100% with recall of 81.10%, exceeding the top-ranked result in the\nSPI competition.", "published": "2017-12-11 17:24:13", "link": "http://arxiv.org/abs/1712.03903v1", "categories": ["cs.CL", "cs.CY"], "primary_category": "cs.CL"}
{"title": "Learning Robust Dialog Policies in Noisy Environments", "abstract": "Modern virtual personal assistants provide a convenient interface for\ncompleting daily tasks via voice commands. An important consideration for these\nassistants is the ability to recover from automatic speech recognition (ASR)\nand natural language understanding (NLU) errors. In this paper, we focus on\nlearning robust dialog policies to recover from these errors. To this end, we\ndevelop a user simulator which interacts with the assistant through voice\ncommands in realistic scenarios with noisy audio, and use it to learn dialog\npolicies through deep reinforcement learning. We show that dialogs generated by\nour simulator are indistinguishable from human generated dialogs, as determined\nby human evaluators. Furthermore, preliminary experimental results show that\nthe learned policies in noisy environments achieve the same execution success\nrate with fewer dialog turns compared to fixed rule-based policies.", "published": "2017-12-11 21:22:01", "link": "http://arxiv.org/abs/1712.04034v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Learning Modality-Invariant Representations for Speech and Images", "abstract": "In this paper, we explore the unsupervised learning of a semantic embedding\nspace for co-occurring sensory inputs. Specifically, we focus on the task of\nlearning a semantic vector space for both spoken and handwritten digits using\nthe TIDIGITs and MNIST datasets. Current techniques encode image and\naudio/textual inputs directly to semantic embeddings. In contrast, our\ntechnique maps an input to the mean and log variance vectors of a diagonal\nGaussian from which sample semantic embeddings are drawn. In addition to\nencouraging semantic similarity between co-occurring inputs,our loss function\nincludes a regularization term borrowed from variational autoencoders (VAEs)\nwhich drives the posterior distributions over embeddings to be unit Gaussian.\nWe can use this regularization term to filter out modality information while\npreserving semantic information. We speculate this technique may be more\nbroadly applicable to other areas of cross-modality/domain information\nretrieval and transfer learning.", "published": "2017-12-11 17:18:34", "link": "http://arxiv.org/abs/1712.03897v1", "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "cs.LG"}
{"title": "Character-Based Handwritten Text Transcription with Attention Networks", "abstract": "The paper approaches the task of handwritten text recognition (HTR) with\nattentional encoder-decoder networks trained on sequences of characters, rather\nthan words. We experiment on lines of text from popular handwriting datasets\nand compare different activation functions for the attention mechanism used for\naligning image pixels and target characters. We find that softmax attention\nfocuses heavily on individual characters, while sigmoid attention focuses on\nmultiple characters at each step of the decoding. When the sequence alignment\nis one-to-one, softmax attention is able to learn a more precise alignment at\neach step of the decoding, whereas the alignment generated by sigmoid attention\nis much less precise. When a linear function is used to obtain attention\nweights, the model predicts a character by looking at the entire sequence of\ncharacters and performs poorly because it lacks a precise alignment between the\nsource and target. Future research may explore HTR in natural scene images,\nsince the model is capable of transcribing handwritten text without the need\nfor producing segmentations or bounding boxes of text in images.", "published": "2017-12-11 21:57:03", "link": "http://arxiv.org/abs/1712.04046v3", "categories": ["cs.CV", "cs.CL", "stat.ML"], "primary_category": "cs.CV"}
{"title": "Cavs: A Vertex-centric Programming Interface for Dynamic Neural Networks", "abstract": "Recent deep learning (DL) models have moved beyond static network\narchitectures to dynamic ones, handling data where the network structure\nchanges every example, such as sequences of variable lengths, trees, and\ngraphs. Existing dataflow-based programming models for DL---both static and\ndynamic declaration---either cannot readily express these dynamic models, or\nare inefficient due to repeated dataflow graph construction and processing, and\ndifficulties in batched execution. We present Cavs, a vertex-centric\nprogramming interface and optimized system implementation for dynamic DL\nmodels. Cavs represents dynamic network structure as a static vertex function\n$\\mathcal{F}$ and a dynamic instance-specific graph $\\mathcal{G}$, and performs\nbackpropagation by scheduling the execution of $\\mathcal{F}$ following the\ndependencies in $\\mathcal{G}$. Cavs bypasses expensive graph construction and\npreprocessing overhead, allows for the use of static graph optimization\ntechniques on pre-defined operations in $\\mathcal{F}$, and naturally exposes\nbatched execution opportunities over different graphs. Experiments comparing\nCavs to two state-of-the-art frameworks for dynamic NNs (TensorFlow Fold and\nDyNet) demonstrate the efficacy of this approach: Cavs achieves a near one\norder of magnitude speedup on training of various dynamic NN architectures, and\nablations demonstrate the contribution of our proposed batching and memory\nmanagement strategies.", "published": "2017-12-11 22:04:39", "link": "http://arxiv.org/abs/1712.04048v1", "categories": ["cs.LG", "cs.CL", "cs.DC"], "primary_category": "cs.LG"}
