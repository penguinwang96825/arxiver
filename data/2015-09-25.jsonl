{"title": "Sentiment Uncertainty and Spam in Twitter Streams and Its Implications\n  for General Purpose Realtime Sentiment Analysis", "abstract": "State of the art benchmarks for Twitter Sentiment Analysis do not consider\nthe fact that for more than half of the tweets from the public stream a\ndistinct sentiment cannot be chosen. This paper provides a new perspective on\nTwitter Sentiment Analysis by highlighting the necessity of explicitly\nincorporating uncertainty. Moreover, a dataset of high quality to evaluate\nsolutions for this new problem is introduced and made publicly available.", "published": "2015-09-25 07:55:26", "link": "http://arxiv.org/abs/1509.07612v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Sentiment of Emojis", "abstract": "There is a new generation of emoticons, called emojis, that is increasingly\nbeing used in mobile communications and social media. In the past two years,\nover ten billion emojis were used on Twitter. Emojis are Unicode graphic\nsymbols, used as a shorthand to express concepts and ideas. In contrast to the\nsmall number of well-known emoticons that carry clear emotional contents, there\nare hundreds of emojis. But what are their emotional contents? We provide the\nfirst emoji sentiment lexicon, called the Emoji Sentiment Ranking, and draw a\nsentiment map of the 751 most frequently used emojis. The sentiment of the\nemojis is computed from the sentiment of the tweets in which they occur. We\nengaged 83 human annotators to label over 1.6 million tweets in 13 European\nlanguages by the sentiment polarity (negative, neutral, or positive). About 4%\nof the annotated tweets contain emojis. The sentiment analysis of the emojis\nallows us to draw several interesting conclusions. It turns out that most of\nthe emojis are positive, especially the most popular ones. The sentiment\ndistribution of the tweets with and without emojis is significantly different.\nThe inter-annotator agreement on the tweets with emojis is higher. Emojis tend\nto occur at the end of the tweets, and their sentiment polarity increases with\nthe distance. We observe no significant differences in the emoji rankings\nbetween the 13 languages and the Emoji Sentiment Ranking. Consequently, we\npropose our Emoji Sentiment Ranking as a European language-independent resource\nfor automated sentiment analysis. Finally, the paper provides a formalization\nof sentiment and a novel visualization in the form of a sentiment bar.", "published": "2015-09-25 15:41:13", "link": "http://arxiv.org/abs/1509.07761v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Selecting Relevant Web Trained Concepts for Automated Event Retrieval", "abstract": "Complex event retrieval is a challenging research problem, especially when no\ntraining videos are available. An alternative to collecting training videos is\nto train a large semantic concept bank a priori. Given a text description of an\nevent, event retrieval is performed by selecting concepts linguistically\nrelated to the event description and fusing the concept responses on unseen\nvideos. However, defining an exhaustive concept lexicon and pre-training it\nrequires vast computational resources. Therefore, recent approaches automate\nconcept discovery and training by leveraging large amounts of weakly annotated\nweb data. Compact visually salient concepts are automatically obtained by the\nuse of concept pairs or, more generally, n-grams. However, not all visually\nsalient n-grams are necessarily useful for an event query--some combinations of\nconcepts may be visually compact but irrelevant--and this drastically affects\nperformance. We propose an event retrieval algorithm that constructs pairs of\nautomatically discovered concepts and then prunes those concepts that are\nunlikely to be helpful for retrieval. Pruning depends both on the query and on\nthe specific video instance being evaluated. Our approach also addresses\ncalibration and domain adaptation issues that arise when applying concept\ndetectors to unseen videos. We demonstrate large improvements over other vision\nbased systems on the TRECVID MED 13 dataset.", "published": "2015-09-25 19:27:54", "link": "http://arxiv.org/abs/1509.07845v1", "categories": ["cs.CV", "cs.CL", "cs.IR"], "primary_category": "cs.CV"}
