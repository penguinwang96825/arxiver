{"title": "Exploring Lexical Irregularities in Hypothesis-Only Models of Natural\n  Language Inference", "abstract": "Natural Language Inference (NLI) or Recognizing Textual Entailment (RTE) is\nthe task of predicting the entailment relation between a pair of sentences\n(premise and hypothesis). This task has been described as a valuable testing\nground for the development of semantic representations, and is a key component\nin natural language understanding evaluation benchmarks. Models that understand\nentailment should encode both, the premise and the hypothesis. However,\nexperiments by Poliak et al. revealed a strong preference of these models\ntowards patterns observed only in the hypothesis, based on a 10 dataset\ncomparison. Their results indicated the existence of statistical irregularities\npresent in the hypothesis that bias the model into performing competitively\nwith the state of the art. While recast datasets provide large scale generation\nof NLI instances due to minimal human intervention, the papers that generate\nthem do not provide fine-grained analysis of the potential statistical patterns\nthat can bias NLI models. In this work, we analyze hypothesis-only models\ntrained on one of the recast datasets provided in Poliak et al. for word-level\npatterns. Our results indicate the existence of potential lexical biases that\ncould contribute to inflating the model performance.", "published": "2021-01-19 01:08:06", "link": "http://arxiv.org/abs/2101.07397v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Single versus Multiple Annotation for Named Entity Recognition of\n  Mutations", "abstract": "The focus of this paper is to address the knowledge acquisition bottleneck\nfor Named Entity Recognition (NER) of mutations, by analysing different\napproaches to build manually-annotated data. We address first the impact of\nusing a single annotator vs two annotators, in order to measure whether\nmultiple annotators are required. Once we evaluate the performance loss when\nusing a single annotator, we apply different methods to sample the training\ndata for second annotation, aiming at improving the quality of the dataset\nwithout requiring a full pass. We use held-out double-annotated data to build\ntwo scenarios with different types of rankings: similarity-based and confidence\nbased. We evaluate both approaches on: (i) their ability to identify training\ninstances that are erroneous (cases where single-annotator labels differ from\ndouble-annotation after discussion), and (ii) on Mutation NER performance for\nstate-of-the-art classifiers after integrating the fixes at different\nthresholds.", "published": "2021-01-19 03:54:17", "link": "http://arxiv.org/abs/2101.07450v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Challenges for Computational Lexical Semantic Change", "abstract": "The computational study of lexical semantic change (LSC) has taken off in the\npast few years and we are seeing increasing interest in the field, from both\ncomputational sciences and linguistics. Most of the research so far has focused\non methods for modelling and detecting semantic change using large diachronic\ntextual data, with the majority of the approaches employing neural embeddings.\nWhile methods that offer easy modelling of diachronic text are one of the main\nreasons for the spiking interest in LSC, neural models leave many aspects of\nthe problem unsolved. The field has several open and complex challenges. In\nthis chapter, we aim to describe the most important of these challenges and\noutline future directions.", "published": "2021-01-19 15:01:30", "link": "http://arxiv.org/abs/2101.07668v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Comparison of Question Rewriting Methods for Conversational Passage\n  Retrieval", "abstract": "Conversational passage retrieval relies on question rewriting to modify the\noriginal question so that it no longer depends on the conversation history.\nSeveral methods for question rewriting have recently been proposed, but they\nwere compared under different retrieval pipelines. We bridge this gap by\nthoroughly evaluating those question rewriting methods on the TREC CAsT 2019\nand 2020 datasets under the same retrieval pipeline. We analyze the effect of\ndifferent types of question rewriting methods on retrieval performance and show\nthat by combining question rewriting methods of different types we can achieve\nstate-of-the-art performance on both datasets.", "published": "2021-01-19 00:17:52", "link": "http://arxiv.org/abs/2101.07382v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "ArtEmis: Affective Language for Visual Art", "abstract": "We present a novel large-scale dataset and accompanying machine learning\nmodels aimed at providing a detailed understanding of the interplay between\nvisual content, its emotional effect, and explanations for the latter in\nlanguage. In contrast to most existing annotation datasets in computer vision,\nwe focus on the affective experience triggered by visual artworks and ask the\nannotators to indicate the dominant emotion they feel for a given image and,\ncrucially, to also provide a grounded verbal explanation for their emotion\nchoice. As we demonstrate below, this leads to a rich set of signals for both\nthe objective content and the affective impact of an image, creating\nassociations with abstract concepts (e.g., \"freedom\" or \"love\"), or references\nthat go beyond what is directly visible, including visual similes and\nmetaphors, or subjective references to personal experiences. We focus on visual\nart (e.g., paintings, artistic photographs) as it is a prime example of imagery\ncreated to elicit emotional responses from its viewers. Our dataset, termed\nArtEmis, contains 439K emotion attributions and explanations from humans, on\n81K artworks from WikiArt. Building on this data, we train and demonstrate a\nseries of captioning systems capable of expressing and explaining emotions from\nvisual stimuli. Remarkably, the captions produced by these systems often\nsucceed in reflecting the semantic and abstract content of the image, going\nwell beyond systems trained on existing datasets. The collected dataset and\ndeveloped methods are available at https://artemisdataset.org.", "published": "2021-01-19 01:03:40", "link": "http://arxiv.org/abs/2101.07396v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Inferring COVID-19 Biological Pathways from Clinical Phenotypes via\n  Topological Analysis", "abstract": "COVID-19 has caused thousands of deaths around the world and also resulted in\na large international economic disruption. Identifying the pathways associated\nwith this illness can help medical researchers to better understand the\nproperties of the condition. This process can be carried out by analyzing the\nmedical records. It is crucial to develop tools and models that can aid\nresearchers with this process in a timely manner. However, medical records are\noften unstructured clinical notes, and this poses significant challenges to\ndeveloping the automated systems. In this article, we propose a pipeline to aid\npractitioners in analyzing clinical notes and revealing the pathways associated\nwith this disease. Our pipeline relies on topological properties and consists\nof three steps: 1) pre-processing the clinical notes to extract the salient\nconcepts, 2) constructing a feature space of the patients to characterize the\nextracted concepts, and finally, 3) leveraging the topological properties to\ndistill the available knowledge and visualize the result. Our experiments on a\npublicly available dataset of COVID-19 clinical notes testify that our pipeline\ncan indeed extract meaningful pathways.", "published": "2021-01-19 02:27:03", "link": "http://arxiv.org/abs/2101.07417v3", "categories": ["cs.CL", "math.AT"], "primary_category": "cs.CL"}
{"title": "Chronological Citation Recommendation with Time Preference", "abstract": "Citation recommendation is an important task to assist scholars in finding\ncandidate literature to cite. Traditional studies focus on static models of\nrecommending citations, which do not explicitly distinguish differences between\npapers that are caused by temporal variations. Although, some researchers have\ninvestigated chronological citation recommendation by adding time related\nfunction or modeling textual topics dynamically. These solutions can hardly\ncope with function generalization or cold-start problems when there is no\ninformation for user profiling or there are isolated papers never being cited.\nWith the rise and fall of science paradigms, scientific topics tend to change\nand evolve over time. People would have the time preference when citing papers,\nsince most of the theoretical basis exist in classical readings that published\nin old time, while new techniques are proposed in more recent papers. To\nexplore chronological citation recommendation, this paper wants to predict the\ntime preference based on user queries, which is a probability distribution of\nciting papers published in different time slices. Then, we use this time\npreference to re-rank the initial citation list obtained by content-based\nfiltering. Experimental results demonstrate that task performance can be\nfurther enhanced by time preference and it's flexible to be added in other\ncitation recommendation frameworks.", "published": "2021-01-19 13:18:05", "link": "http://arxiv.org/abs/2101.07609v1", "categories": ["cs.IR", "cs.CL", "H.3.3"], "primary_category": "cs.IR"}
{"title": "Characterizing References from Different Disciplines: A Perspective of\n  Citation Content Analysis", "abstract": "Multidisciplinary cooperation is now common in research since social issues\ninevitably involve multiple disciplines. In research articles, reference\ninformation, especially citation content, is an important representation of\ncommunication among different disciplines. Analyzing the distribution\ncharacteristics of references from different disciplines in research articles\nis basic to detecting the sources of referred information and identifying\ncontributions of different disciplines. This work takes articles in PLoS as the\ndata and characterizes the references from different disciplines based on\nCitation Content Analysis (CCA). First, we download 210,334 full-text articles\nfrom PLoS and collect the information of the in-text citations. Then, we\nidentify the discipline of each reference in these academic articles. To\ncharacterize the distribution of these references, we analyze three\ncharacteristics, namely, the number of citations, the average cited intensity\nand the average citation length. Finally, we conclude that the distributions of\nreferences from different disciplines are significantly different. Although\nmost references come from Natural Science, Humanities and Social Sciences play\nimportant roles in the Introduction and Background sections of the articles.\nBasic disciplines, such as Mathematics, mainly provide research methods in the\narticles in PLoS. Citations mentioned in the Results and Discussion sections of\narticles are mainly in-discipline citations, such as citations from Nursing and\nMedicine in PLoS.", "published": "2021-01-19 13:30:00", "link": "http://arxiv.org/abs/2101.07614v1", "categories": ["cs.DL", "cs.CL", "H.3.7"], "primary_category": "cs.DL"}
{"title": "Situation and Behavior Understanding by Trope Detection on Films", "abstract": "The human ability of deep cognitive skills are crucial for the development of\nvarious real-world applications that process diverse and abundant user\ngenerated input. While recent progress of deep learning and natural language\nprocessing have enabled learning system to reach human performance on some\nbenchmarks requiring shallow semantics, such human ability still remains\nchallenging for even modern contextual embedding models, as pointed out by many\nrecent studies. Existing machine comprehension datasets assume sentence-level\ninput, lack of casual or motivational inferences, or could be answered with\nquestion-answer bias. Here, we present a challenging novel task, trope\ndetection on films, in an effort to create a situation and behavior\nunderstanding for machines. Tropes are storytelling devices that are frequently\nused as ingredients in recipes for creative works. Comparing to existing movie\ntag prediction tasks, tropes are more sophisticated as they can vary widely,\nfrom a moral concept to a series of circumstances, and embedded with\nmotivations and cause-and-effects. We introduce a new dataset, Tropes in Movie\nSynopses (TiMoS), with 5623 movie synopses and 95 different tropes collecting\nfrom a Wikipedia-style database, TVTropes. We present a multi-stream\ncomprehension network (MulCom) leveraging multi-level attention of words,\nsentences, and role relations. Experimental result demonstrates that modern\nmodels including BERT contextual embedding, movie tag prediction systems, and\nrelational networks, perform at most 37% of human performance (23.97/64.87) in\nterms of F1 score. Our MulCom outperforms all modern baselines, by 1.5 to 5.0\nF1 score and 1.5 to 3.0 mean of average precision (mAP) score. We also provide\na detailed analysis and human evaluation to pave ways for future research.", "published": "2021-01-19 14:09:54", "link": "http://arxiv.org/abs/2101.07632v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Towards Facilitating Empathic Conversations in Online Mental Health\n  Support: A Reinforcement Learning Approach", "abstract": "Online peer-to-peer support platforms enable conversations between millions\nof people who seek and provide mental health support. If successful, web-based\nmental health conversations could improve access to treatment and reduce the\nglobal disease burden. Psychologists have repeatedly demonstrated that empathy,\nthe ability to understand and feel the emotions and experiences of others, is a\nkey component leading to positive outcomes in supportive conversations.\nHowever, recent studies have shown that highly empathic conversations are rare\nin online mental health platforms.\n  In this paper, we work towards improving empathy in online mental health\nsupport conversations. We introduce a new task of empathic rewriting which aims\nto transform low-empathy conversational posts to higher empathy. Learning such\ntransformations is challenging and requires a deep understanding of empathy\nwhile maintaining conversation quality through text fluency and specificity to\nthe conversational context. Here we propose PARTNER, a deep reinforcement\nlearning agent that learns to make sentence-level edits to posts in order to\nincrease the expressed level of empathy while maintaining conversation quality.\nOur RL agent leverages a policy network, based on a transformer language model\nadapted from GPT-2, which performs the dual task of generating candidate\nempathic sentences and adding those sentences at appropriate positions. During\ntraining, we reward transformations that increase empathy in posts while\nmaintaining text fluency, context specificity and diversity. Through a\ncombination of automatic and human evaluation, we demonstrate that PARTNER\nsuccessfully generates more empathic, specific, and diverse responses and\noutperforms NLP methods from related tasks like style transfer and empathic\ndialogue generation. Our work has direct implications for facilitating empathic\nconversations on web-based platforms.", "published": "2021-01-19 16:37:58", "link": "http://arxiv.org/abs/2101.07714v3", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Grounding Language to Entities and Dynamics for Generalization in\n  Reinforcement Learning", "abstract": "We investigate the use of natural language to drive the generalization of\ncontrol policies and introduce the new multi-task environment Messenger with\nfree-form text manuals describing the environment dynamics. Unlike previous\nwork, Messenger does not assume prior knowledge connecting text and state\nobservations $-$ the control policy must simultaneously ground the game manual\nto entity symbols and dynamics in the environment. We develop a new model, EMMA\n(Entity Mapper with Multi-modal Attention) which uses an entity-conditioned\nattention module that allows for selective focus over relevant descriptions in\nthe manual for each entity in the environment. EMMA is end-to-end\ndifferentiable and learns a latent grounding of entities and dynamics from text\nto observations using only environment rewards. EMMA achieves successful\nzero-shot generalization to unseen games with new dynamics, obtaining a 40%\nhigher win rate compared to multiple baselines. However, win rate on the\nhardest stage of Messenger remains low (10%), demonstrating the need for\nadditional work in this direction.", "published": "2021-01-19 00:59:16", "link": "http://arxiv.org/abs/2101.07393v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "UniSpeech: Unified Speech Representation Learning with Labeled and\n  Unlabeled Data", "abstract": "In this paper, we propose a unified pre-training approach called UniSpeech to\nlearn speech representations with both unlabeled and labeled data, in which\nsupervised phonetic CTC learning and phonetically-aware contrastive\nself-supervised learning are conducted in a multi-task learning manner. The\nresultant representations can capture information more correlated with phonetic\nstructures and improve the generalization across languages and domains. We\nevaluate the effectiveness of UniSpeech for cross-lingual representation\nlearning on public CommonVoice corpus. The results show that UniSpeech\noutperforms self-supervised pretraining and supervised transfer learning for\nspeech recognition by a maximum of 13.4% and 17.8% relative phone error rate\nreductions respectively (averaged over all testing languages). The\ntransferability of UniSpeech is also demonstrated on a domain-shift speech\nrecognition task, i.e., a relative word error rate reduction of 6% against the\nprevious approach.", "published": "2021-01-19 12:53:43", "link": "http://arxiv.org/abs/2101.07597v2", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Twitter Subjective Well-Being Indicator During COVID-19 Pandemic: A\n  Cross-Country Comparative Study", "abstract": "This study analyzes the impact of the COVID-19 pandemic on the subjective\nwell-being as measured through Twitter data indicators for Japan and Italy. It\nturns out that, overall, the subjective well-being dropped by 11.7% for Italy\nand 8.3% for Japan in the first nine months of 2020 compared to the last two\nmonths of 2019 and even more compared to the historical mean of the indexes.\nThrough a data science approach we try to identify the possible causes of this\ndrop down by considering several explanatory variables including, climate and\nair quality data, number of COVID-19 cases and deaths, Facebook Covid and flu\nsymptoms global survey, Google Trends data and coronavirus-related searches,\nGoogle mobility data, policy intervention measures, economic variables and\ntheir Google Trends proxies, as well as health and stress proxy variables based\non big data. We show that a simple static regression model is not able to\ncapture the complexity of well-being and therefore we propose a dynamic elastic\nnet approach to show how different group of factors may impact the well-being\nin different periods, even over a short time length, and showing further\ncountry-specific aspects. Finally, a structural equation modeling analysis\ntries to address the causal relationships among the COVID-19 factors and\nsubjective well-being showing that, overall, prolonged mobility\nrestrictions,flu and Covid-like symptoms, economic uncertainty, social\ndistancing and news about the pandemic have negative effects on the subjective\nwell-being.", "published": "2021-01-19 15:51:53", "link": "http://arxiv.org/abs/2101.07695v1", "categories": ["econ.GN", "cs.CL", "q-fin.EC", "stat.AP"], "primary_category": "econ.GN"}
{"title": "A System for Automated Open-Source Threat Intelligence Gathering and\n  Management", "abstract": "To remain aware of the fast-evolving cyber threat landscape, open-source\nCyber Threat Intelligence (OSCTI) has received growing attention from the\ncommunity. Commonly, knowledge about threats is presented in a vast number of\nOSCTI reports. Despite the pressing need for high-quality OSCTI, existing OSCTI\ngathering and management platforms, however, have primarily focused on\nisolated, low-level Indicators of Compromise. On the other hand, higher-level\nconcepts (e.g., adversary tactics, techniques, and procedures) and their\nrelationships have been overlooked, which contain essential knowledge about\nthreat behaviors that is critical to uncovering the complete threat scenario.\nTo bridge the gap, we propose SecurityKG, a system for automated OSCTI\ngathering and management. SecurityKG collects OSCTI reports from various\nsources, uses a combination of AI and NLP techniques to extract high-fidelity\nknowledge about threat behaviors, and constructs a security knowledge graph.\nSecurityKG also provides a UI that supports various types of interactivity to\nfacilitate knowledge graph exploration.", "published": "2021-01-19 18:31:35", "link": "http://arxiv.org/abs/2101.07769v2", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.DB"], "primary_category": "cs.CR"}
{"title": "Improved parallel WaveGAN vocoder with perceptually weighted spectrogram\n  loss", "abstract": "This paper proposes a spectral-domain perceptual weighting technique for\nParallel WaveGAN-based text-to-speech (TTS) systems. The recently proposed\nParallel WaveGAN vocoder successfully generates waveform sequences using a fast\nnon-autoregressive WaveNet model. By employing multi-resolution short-time\nFourier transform (MR-STFT) criteria with a generative adversarial network, the\nlight-weight convolutional networks can be effectively trained without any\ndistillation process. To further improve the vocoding performance, we propose\nthe application of frequency-dependent weighting to the MR-STFT loss function.\nThe proposed method penalizes perceptually-sensitive errors in the frequency\ndomain; thus, the model is optimized toward reducing auditory noise in the\nsynthesized speech. Subjective listening test results demonstrate that our\nproposed method achieves 4.21 and 4.26 TTS mean opinion scores for female and\nmale Korean speakers, respectively.", "published": "2021-01-19 01:59:52", "link": "http://arxiv.org/abs/2101.07412v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Towards duration robust weakly supervised sound event detection", "abstract": "Sound event detection (SED) is the task of tagging the absence or presence of\naudio events and their corresponding interval within a given audio clip. While\nSED can be done using supervised machine learning, where training data is fully\nlabeled with access to per event timestamps and duration, our work focuses on\nweakly-supervised sound event detection (WSSED), where prior knowledge about an\nevent's duration is unavailable. Recent research within the field focuses on\nimproving segment- and event-level localization performance for specific\ndatasets regarding specific evaluation metrics. Specifically, well-performing\nevent-level localization requires fully labeled development subsets to obtain\nevent duration estimates, which significantly benefits localization\nperformance. Moreover, well-performing segment-level localization models output\npredictions at a coarse-scale (e.g., 1 second), hindering their deployment on\ndatasets containing very short events (< 1 second). This work proposes a\nduration robust CRNN (CDur) framework, which aims to achieve competitive\nperformance in terms of segment- and event-level localization. This paper\nproposes a new post-processing strategy named \"Triple Threshold\" and\ninvestigates two data augmentation methods along with a label smoothing method\nwithin the scope of WSSED. Evaluation of our model is done on the DCASE2017 and\n2018 Task 4 datasets, and URBAN-SED. Our model outperforms other approaches on\nthe DCASE2018 and URBAN-SED datasets without requiring prior duration\nknowledge. In particular, our model is capable of similar performance to\nstrongly-labeled supervised models on the URBAN-SED dataset. Lastly, ablation\nexperiments to reveal that without post-processing, our model's localization\nperformance drop is significantly lower compared with other approaches.", "published": "2021-01-19 15:28:54", "link": "http://arxiv.org/abs/2101.07687v2", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "A framework to compare music generative models using automatic\n  evaluation metrics extended to rhythm", "abstract": "To train a machine learning model is necessary to take numerous decisions\nabout many options for each process involved, in the field of sequence\ngeneration and more specifically of music composition, the nature of the\nproblem helps to narrow the options but at the same time, some other options\nappear for specific challenges. This paper takes the framework proposed in a\nprevious research that did not consider rhythm to make a series of design\ndecisions, then, rhythm support is added to evaluate the performance of two RNN\nmemory cells in the creation of monophonic music. The model considers the\nhandling of music transposition and the framework evaluates the quality of the\ngenerated pieces using automatic quantitative metrics based on geometry which\nhave rhythm support added as well.", "published": "2021-01-19 15:04:46", "link": "http://arxiv.org/abs/2101.07669v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
