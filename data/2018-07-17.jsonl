{"title": "Low-Resource Contextual Topic Identification on Speech", "abstract": "In topic identification (topic ID) on real-world unstructured audio, an audio\ninstance of variable topic shifts is first broken into sequential segments, and\neach segment is independently classified. We first present a general purpose\nmethod for topic ID on spoken segments in low-resource languages, using a\ncascade of universal acoustic modeling, translation lexicons to English, and\nEnglish-language topic classification. Next, instead of classifying each\nsegment independently, we demonstrate that exploring the contextual\ndependencies across sequential segments can provide large improvements. In\nparticular, we propose an attention-based contextual model which is able to\nleverage the contexts in a selective manner. We test both our contextual and\nnon-contextual models on four LORELEI languages, and on all but one our\nattention-based contextual model significantly outperforms the\ncontext-independent models.", "published": "2018-07-17 04:01:06", "link": "http://arxiv.org/abs/1807.06204v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Hierarchical Multitask Learning for CTC-based Speech Recognition", "abstract": "Previous work has shown that neural encoder-decoder speech recognition can be\nimproved with hierarchical multitask learning, where auxiliary tasks are added\nat intermediate layers of a deep encoder. We explore the effect of hierarchical\nmultitask learning in the context of connectionist temporal classification\n(CTC)-based speech recognition, and investigate several aspects of this\napproach. Consistent with previous work, we observe performance improvements on\ntelephone conversational speech recognition (specifically the Eval2000 test\nsets) when training a subword-level CTC model with an auxiliary phone loss at\nan intermediate layer. We analyze the effects of a number of experimental\nvariables (like interpolation constant and position of the auxiliary loss\nfunction), performance in lower-resource settings, and the relationship between\npretraining and multitask learning. We observe that the hierarchical multitask\napproach improves over standard multitask training in our higher-data\nexperiments, while in the low-resource settings standard multitask training\nworks well. The best results are obtained by combining hierarchical multitask\nlearning and pretraining, which improves word error rates by 3.4% absolute on\nthe Eval2000 test sets.", "published": "2018-07-17 06:05:00", "link": "http://arxiv.org/abs/1807.06234v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chinese Poetry Generation with Flexible Styles", "abstract": "Research has shown that sequence-to-sequence neural models, particularly\nthose with the attention mechanism, can successfully generate classical Chinese\npoems. However, neural models are not capable of generating poems that match\nspecific styles, such as the impulsive style of Li Bai, a famous poet in the\nTang Dynasty. This work proposes a memory-augmented neural model to enable the\ngeneration of style-specific poetry. The key idea is a memory structure that\nstores how poems with a desired style were generated by humans, and uses\nsimilar fragments to adjust the generation. We demonstrate that the proposed\nalgorithm generates poems with flexible styles, including styles of a\nparticular era and an individual poet.", "published": "2018-07-17 15:26:04", "link": "http://arxiv.org/abs/1807.06500v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing", "abstract": "Robust dialogue belief tracking is a key component in maintaining good\nquality dialogue systems. The tasks that dialogue systems are trying to solve\nare becoming increasingly complex, requiring scalability to multi domain,\nsemantically rich dialogues. However, most current approaches have difficulty\nscaling up with domains because of the dependency of the model parameters on\nthe dialogue ontology. In this paper, a novel approach is introduced that fully\nutilizes semantic similarity between dialogue utterances and the ontology\nterms, allowing the information to be shared across domains. The evaluation is\nperformed on a recently collected multi-domain dialogues dataset, one order of\nmagnitude larger than currently available corpora. Our model demonstrates great\ncapability in handling multi-domain dialogues, simultaneously outperforming\nexisting state-of-the-art models in single-domain dialogue tracking tasks.", "published": "2018-07-17 16:00:35", "link": "http://arxiv.org/abs/1807.06517v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Power Networks: A Novel Neural Architecture to Predict Power Relations", "abstract": "Can language analysis reveal the underlying social power relations that exist\nbetween participants of an interaction? Prior work within NLP has shown promise\nin this area, but the performance of automatically predicting power relations\nusing NLP analysis of social interactions remains wanting. In this paper, we\npresent a novel neural architecture that captures manifestations of power\nwithin individual emails which are then aggregated in an order-preserving way\nin order to infer the direction of power between pairs of participants in an\nemail thread. We obtain an accuracy of 80.4%, a 10.1% improvement over\nstate-of-the-art methods, in this task. We further apply our model to the task\nof predicting power relations between individuals based on the entire set of\nmessages exchanged between them; here also, our model significantly outperforms\nthe70.0% accuracy using prior state-of-the-art techniques, obtaining an\naccuracy of 83.0%.", "published": "2018-07-17 17:04:52", "link": "http://arxiv.org/abs/1807.06557v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using semantic clustering to support situation awareness on Twitter: The\n  case of World Views", "abstract": "In recent years, situation awareness has been recognised as a critical part\nof effective decision making, in particular for crisis management. One way to\nextract value and allow for better situation awareness is to develop a system\ncapable of analysing a dataset of multiple posts, and clustering consistent\nposts into different views or stories (or, world views). However, this can be\nchallenging as it requires an understanding of the data, including determining\nwhat is consistent data, and what data corroborates other data. Attempting to\naddress these problems, this article proposes Subject-Verb-Object Semantic\nSuffix Tree Clustering (SVOSSTC) and a system to support it, with a special\nfocus on Twitter content. The novelty and value of SVOSSTC is its emphasis on\nutilising the Subject-Verb-Object (SVO) typology in order to construct\nsemantically consistent world views, in which individuals---particularly those\ninvolved in crisis response---might achieve an enhanced picture of a situation\nfrom social media data. To evaluate our system and its ability to provide\nenhanced situation awareness, we tested it against existing approaches,\nincluding human data analysis, using a variety of real-world scenarios. The\nresults indicated a noteworthy degree of evidence (e.g., in cluster granularity\nand meaningfulness) to affirm the suitability and rigour of our approach.\nMoreover, these results highlight this article's proposals as innovative and\npractical system contributions to the research field.", "published": "2018-07-17 17:59:39", "link": "http://arxiv.org/abs/1807.06588v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Named Entity Recognition by Jointly Learning to Disambiguate\n  Morphological Tags", "abstract": "Previous studies have shown that linguistic features of a word such as\npossession, genitive or other grammatical cases can be employed in word\nrepresentations of a named entity recognition (NER) tagger to improve the\nperformance for morphologically rich languages. However, these taggers require\nexternal morphological disambiguation (MD) tools to function which are hard to\nobtain or non-existent for many languages. In this work, we propose a model\nwhich alleviates the need for such disambiguators by jointly learning NER and\nMD taggers in languages for which one can provide a list of candidate\nmorphological analyses. We show that this can be done independent of the\nmorphological annotation schemes, which differ among languages. Our experiments\nemploying three different model architectures that join these two tasks show\nthat joint learning improves NER performance. Furthermore, the morphological\ndisambiguator's performance is shown to be competitive.", "published": "2018-07-17 21:46:02", "link": "http://arxiv.org/abs/1807.06683v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Clinical Text Classification with Rule-based Features and\n  Knowledge-guided Convolutional Neural Networks", "abstract": "Clinical text classification is an important problem in medical natural\nlanguage processing. Existing studies have conventionally focused on rules or\nknowledge sources-based feature engineering, but only a few have exploited\neffective feature learning capability of deep learning methods. In this study,\nwe propose a novel approach which combines rule-based features and\nknowledge-guided deep learning techniques for effective disease classification.\nCritical Steps of our method include identifying trigger phrases, predicting\nclasses with very few examples using trigger phrases and training a\nconvolutional neural network with word embeddings and Unified Medical Language\nSystem (UMLS) entity embeddings. We evaluated our method on the 2008\nIntegrating Informatics with Biology and the Bedside (i2b2) obesity challenge.\nThe results show that our method outperforms the state of the art methods.", "published": "2018-07-17 20:00:41", "link": "http://arxiv.org/abs/1807.07425v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bench-Marking Information Extraction in Semi-Structured Historical\n  Handwritten Records", "abstract": "In this report, we present our findings from benchmarking experiments for\ninformation extraction on historical handwritten marriage records Esposalles\nfrom IEHHR - ICDAR 2017 robust reading competition. The information extraction\nis modeled as semantic labeling of the sequence across 2 set of labels. This\ncan be achieved by sequentially or jointly applying handwritten text\nrecognition (HTR) and named entity recognition (NER). We deploy a pipeline\napproach where first we use state-of-the-art HTR and use its output as input\nfor NER. We show that given low resource setup and simple structure of the\nrecords, high performance of HTR ensures overall high performance. We explore\nthe various configurations of conditional random fields and neural networks to\nbenchmark NER on given certain noisy input. The best model on 10-fold\ncross-validation as well as blind test data uses n-gram features with\nbidirectional long short-term memory.", "published": "2018-07-17 08:13:19", "link": "http://arxiv.org/abs/1807.06270v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Developing a Portable Natural Language Processing Based Phenotyping\n  System", "abstract": "This paper presents a portable phenotyping system that is capable of\nintegrating both rule-based and statistical machine learning based approaches.\nOur system utilizes UMLS to extract clinically relevant features from the\nunstructured text and then facilitates portability across different\ninstitutions and data systems by incorporating OHDSI's OMOP Common Data Model\n(CDM) to standardize necessary data elements. Our system can also store the key\ncomponents of rule-based systems (e.g., regular expression matches) in the\nformat of OMOP CDM, thus enabling the reuse, adaptation and extension of many\nexisting rule-based clinical NLP systems. We experimented with our system on\nthe corpus from i2b2's Obesity Challenge as a pilot study. Our system\nfacilitates portable phenotyping of obesity and its 15 comorbidities based on\nthe unstructured patient discharge summaries, while achieving a performance\nthat often ranked among the top 10 of the challenge participants. This\nstandardization enables a consistent application of numerous rule-based and\nmachine learning based classification techniques downstream.", "published": "2018-07-17 19:40:28", "link": "http://arxiv.org/abs/1807.06638v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Learning Noise-Invariant Representations for Robust Speech Recognition", "abstract": "Despite rapid advances in speech recognition, current models remain brittle\nto superficial perturbations to their inputs. Small amounts of noise can\ndestroy the performance of an otherwise state-of-the-art model. To harden\nmodels against background noise, practitioners often perform data augmentation,\nadding artificially-noised examples to the training set, carrying over the\noriginal label. In this paper, we hypothesize that a clean example and its\nsuperficially perturbed counterparts shouldn't merely map to the same class ---\nthey should map to the same representation. We propose\ninvariant-representation-learning (IRL): At each training iteration, for each\ntraining example,we sample a noisy counterpart. We then apply a penalty term to\ncoerce matched representations at each layer (above some chosen layer). Our key\nresults, demonstrated on the Librispeech dataset are the following: (i) IRL\nsignificantly reduces character error rates (CER) on both 'clean' (3.3% vs\n6.5%) and 'other' (11.0% vs 18.1%) test sets; (ii) on several out-of-domain\nnoise settings (different from those seen during training), IRL's benefits are\neven more pronounced. Careful ablations confirm that our results are not simply\ndue to shrinking activations at the chosen layers.", "published": "2018-07-17 18:15:14", "link": "http://arxiv.org/abs/1807.06610v1", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Guess who? Multilingual approach for the automated generation of\n  author-stylized poetry", "abstract": "This paper addresses the problem of stylized text generation in a\nmultilingual setup. A version of a language model based on a long short-term\nmemory (LSTM) artificial neural network with extended phonetic and semantic\nembeddings is used for stylized poetry generation. The quality of the resulting\npoems generated by the network is estimated through bilingual evaluation\nunderstudy (BLEU), a survey and a new cross-entropy based metric that is\nsuggested for the problems of such type. The experiments show that the proposed\nmodel consistently outperforms random sample and vanilla-LSTM baselines, humans\nalso tend to associate machine generated texts with the target author.", "published": "2018-07-17 15:13:20", "link": "http://arxiv.org/abs/1807.07147v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Hand-Held Multimedia Translation and Interpretation System with\n  Application to Diet Management", "abstract": "We propose a network independent, hand-held system to translate and\ndisambiguate foreign restaurant menu items in real-time. The system is based on\nthe use of a portable multimedia device, such as a smartphones or a PDA. An\naccurate and fast translation is obtained using a Machine Translation engine\nand a context-specific corpora to which we apply two pre-processing steps,\ncalled translation standardization and $n$-gram consolidation. The phrase-table\ngenerated is orders of magnitude lighter than the ones commonly used in market\napplications, thus making translations computationally less expensive, and\ndecreasing the battery usage. Translation ambiguities are mitigated using\nmultimedia information including images of dishes and ingredients, along with\ningredient lists. We implemented a prototype of our system on an iPod Touch\nSecond Generation for English speakers traveling in Spain. Our tests indicate\nthat our translation method yields higher accuracy than translation engines\nsuch as Google Translate, and does so almost instantaneously. The memory\nrequirements of the application, including the database of images, are also\nwell within the limits of the device. By combining it with a database of\nnutritional information, our proposed system can be used to help individuals\nwho follow a medical diet maintain this diet while traveling.", "published": "2018-07-17 03:52:26", "link": "http://arxiv.org/abs/1807.07149v1", "categories": ["cs.CL", "cs.MM", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Cavity Filling: Pseudo-Feature Generation for Multi-Class Imbalanced\n  Data Problems in Deep Learning", "abstract": "Herein, we generate pseudo-features based on the multivariate probability\ndistributions obtained from the feature maps in layers of trained deep neural\nnetworks. Further, we augment the minor-class data based on these generated\npseudo-features to overcome the imbalanced data problems. The proposed method,\ni.e., cavity filling, improves the deep learning capabilities in several\nproblems because all the real-world data are observed to be imbalanced.", "published": "2018-07-17 16:34:47", "link": "http://arxiv.org/abs/1807.06538v6", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "stat.ML"], "primary_category": "cs.LG"}
{"title": "MCE 2018: The 1st Multi-target Speaker Detection and Identification\n  Challenge Evaluation (MCE) Plan, Dataset and Baseline System", "abstract": "The Multitarget Challenge aims to assess how well current speech technology\nis able to determine whether or not a recorded utterance was spoken by one of a\nlarge number of 'blacklisted' speakers. It is a form of multi-target speaker\ndetection based on real-world telephone conversations. Data recordings are\ngenerated from call center customer-agent conversations. Each conversation is\nrepresented by a single i-vector. Given a pool of training and development data\nfrom non-Blacklist and Blacklist speakers, the task is to measure how\naccurately one can detect 1) whether a test recording is spoken by a Blacklist\nspeaker, and 2) which specific Blacklist speaker was talking.", "published": "2018-07-17 20:37:18", "link": "http://arxiv.org/abs/1807.06663v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Psychological constraints on string-based methods for pattern discovery\n  in polyphonic corpora", "abstract": "Researchers often divide symbolic music corpora into contiguous sequences of\nn events (called n-grams) for the purposes of pattern discovery, key finding,\nclassification, and prediction. What is more, several studies have reported\nimproved task performance when using psychologically motivated weighting\nfunctions, which adjust the count to privilege n-grams featuring more salient\nor memorable events (e.g., Krumhansl, 1990). However, these functions have yet\nto appear in harmonic pattern discovery algorithms, which attempt to discover\nthe most recurrent chord progressions in complex polyphonic corpora. This study\nexamines whether psychologically-motivated weighting functions can improve\nharmonic pattern discovery algorithms. Models using various n-gram selection\nmethods, weighting functions, and ranking algorithms attempt to discover the\nmost conventional closing harmonic progression in the common-practice period,\nii6-\"I64\"-V7-I, with the progression's mean reciprocal rank serving as an\nevaluation metric for model comparison.", "published": "2018-07-17 23:04:17", "link": "http://arxiv.org/abs/1807.06700v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Learning to Listen, Read, and Follow: Score Following as a Reinforcement\n  Learning Game", "abstract": "Score following is the process of tracking a musical performance (audio) with\nrespect to a known symbolic representation (a score). We start this paper by\nformulating score following as a multimodal Markov Decision Process, the\nmathematical foundation for sequential decision making. Given this formal\ndefinition, we address the score following task with state-of-the-art deep\nreinforcement learning (RL) algorithms such as synchronous advantage actor\ncritic (A2C). In particular, we design multimodal RL agents that simultaneously\nlearn to listen to music, read the scores from images of sheet music, and\nfollow the audio along in the sheet, in an end-to-end fashion. All this\nbehavior is learned entirely from scratch, based on a weak and potentially\ndelayed reward signal that indicates to the agent how close it is to the\ncorrect position in the score. Besides discussing the theoretical advantages of\nthis learning paradigm, we show in experiments that it is in fact superior\ncompared to previously proposed methods for score following in raw sheet music\nimages.", "published": "2018-07-17 12:49:18", "link": "http://arxiv.org/abs/1807.06391v1", "categories": ["cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.AI"}
{"title": "Sonification in security operations centres: what do security\n  practitioners think?", "abstract": "In Security Operations Centres (SOCs) security practitioners work using a\nrange of tools to detect and mitigate malicious computer-network activity.\nSonification, in which data is represented as sound, is said to have potential\nas an approach to addressing some of the unique challenges faced by SOCs. For\nexample, sonification has been shown to enable peripheral monitoring of\nprocesses, which could aid practitioners multitasking in busy SOCs. The\nperspectives of security practitioners on incorporating sonification into their\nactual working environments have not yet been examined, however. The aim of\nthis paper therefore is to address this gap by exploring attitudes to using\nsonification in SOCs. We report on the results of a study consisting of an\nonline survey (N=20) and interviews (N=21) with security practitioners working\nin a range of different SOCs. Our contribution is a refined appreciation of the\ncontexts in which sonification could aid in SOC working practice, and an\nunderstanding of the areas in which sonification may not be beneficial or may\neven be problematic.We also analyse the critical requirements for the design of\nsonification systems and their integration into the SOC setting. Our findings\nclarify insights into the potential benefits and challenges of introducing\nsonification to support work in this vital security-monitoring environment.", "published": "2018-07-17 23:26:14", "link": "http://arxiv.org/abs/1807.06706v1", "categories": ["cs.HC", "cs.CR", "cs.SD", "eess.AS", "K.6.5; H.5.5"], "primary_category": "cs.HC"}
{"title": "Data-Efficient Weakly Supervised Learning for Low-Resource Audio Event\n  Detection Using Deep Learning", "abstract": "We propose a method to perform audio event detection under the common\nconstraint that only limited training data are available. In training a deep\nlearning system to perform audio event detection, two practical problems arise.\nFirstly, most datasets are \"weakly labelled\" having only a list of events\npresent in each recording without any temporal information for training.\nSecondly, deep neural networks need a very large amount of labelled training\ndata to achieve good quality performance, yet in practice it is difficult to\ncollect enough samples for most classes of interest. In this paper, we propose\na data-efficient training of a stacked convolutional and recurrent neural\nnetwork. This neural network is trained in a multi instance learning setting\nfor which we introduce a new loss function that leads to improved training\ncompared to the usual approaches for weakly supervised learning. We\nsuccessfully test our approach on two low-resource datasets that lack temporal\nlabels.", "published": "2018-07-17 14:03:55", "link": "http://arxiv.org/abs/1807.06972v2", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
