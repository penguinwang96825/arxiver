{"title": "Can an unsupervised clustering algorithm reproduce a categorization system?", "abstract": "Peer analysis is a critical component of investment management, often relying\non expert-provided categorization systems. These systems' consistency is\nquestioned when they do not align with cohorts from unsupervised clustering\nalgorithms optimized for various metrics. We investigate whether unsupervised\nclustering can reproduce ground truth classes in a labeled dataset, showing\nthat success depends on feature selection and the chosen distance metric. Using\ntoy datasets and fund categorization as real-world examples we demonstrate that\naccurately reproducing ground truth classes is challenging. We also highlight\nthe limitations of standard clustering evaluation metrics in identifying the\noptimal number of clusters relative to the ground truth classes. We then show\nthat if appropriate features are available in the dataset, and a proper\ndistance metric is known (e.g., using a supervised Random Forest-based distance\nmetric learning method), then an unsupervised clustering can indeed reproduce\nthe ground truth classes as distinct clusters.", "published": "2024-08-19 18:27:14", "link": "http://arxiv.org/abs/2408.10340v1", "categories": ["stat.ML", "cs.LG", "q-fin.ST", "stat.AP"], "primary_category": "stat.ML"}
{"title": "Combining supervised and unsupervised learning methods to predict financial market movements", "abstract": "The decisions traders make to buy or sell an asset depend on various\nanalyses, with expertise required to identify patterns that can be exploited\nfor profit. In this paper we identify novel features extracted from emergent\nand well-established financial markets using linear models and Gaussian Mixture\nModels (GMM) with the aim of finding profitable opportunities. We used\napproximately six months of data consisting of minute candles from the Bitcoin,\nPepecoin, and Nasdaq markets to derive and compare the proposed novel features\nwith commonly used ones. These features were extracted based on the previous 59\nminutes for each market and used to identify predictions for the hour ahead. We\nexplored the performance of various machine learning strategies, such as Random\nForests (RF) and K-Nearest Neighbours (KNN) to classify market movements. A\nnaive random approach to selecting trading decisions was used as a benchmark,\nwith outcomes assumed to be equally likely. We used a temporal cross-validation\napproach using test sets of 40%, 30% and 20% of total hours to evaluate the\nlearning algorithms' performances. Our results showed that filtering the time\nseries facilitates algorithms' generalisation. The GMM filtering approach\nrevealed that the KNN and RF algorithms produced higher average returns than\nthe random algorithm.", "published": "2024-08-19 13:17:36", "link": "http://arxiv.org/abs/2409.03762v1", "categories": ["q-fin.ST", "cs.LG"], "primary_category": "q-fin.ST"}
{"title": "High-Frequency Trading Liquidity Analysis | Application of Machine Learning Classification", "abstract": "This research presents a comprehensive framework for analyzing liquidity in\nfinancial markets, particularly in the context of high-frequency trading. By\nleveraging advanced machine learning classification techniques, including\nLogistic Regression, Support Vector Machine, and Random Forest, the study aims\nto predict minute-level price movements using an extensive set of liquidity\nmetrics derived from the Trade and Quote (TAQ) data. The findings reveal that\nemploying a broad spectrum of liquidity measures yields higher predictive\naccuracy compared to models utilizing a reduced subset of features. Key\nliquidity metrics, such as Liquidity Ratio, Flow Ratio, and Turnover,\nconsistently emerged as significant predictors across all models, with the\nRandom Forest algorithm demonstrating superior accuracy. This study not only\nunderscores the critical role of liquidity in market stability and transaction\ncosts but also highlights the complexities involved in short-interval market\npredictions. The research suggests that a comprehensive set of liquidity\nmeasures is essential for accurate prediction, and proposes future work to\nvalidate these findings across different stock datasets to assess their\ngeneralizability.", "published": "2024-08-19 14:11:46", "link": "http://arxiv.org/abs/2408.10016v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Refining Packing and Shuffling Strategies for Enhanced Performance in\n  Generative Language Models", "abstract": "Packing and shuffling tokens is a common practice in training auto-regressive\nlanguage models (LMs) to prevent overfitting and improve efficiency. Typically\ndocuments are concatenated to chunks of maximum sequence length (MSL) and then\nshuffled. However setting the atom size, the length for each data chunk\naccompanied by random shuffling, to MSL may lead to contextual incoherence due\nto tokens from different documents being packed into the same chunk. An\nalternative approach is to utilize padding, another common data packing\nstrategy, to avoid contextual incoherence by only including one document in\neach shuffled chunk. To optimize both packing strategies (concatenation vs\npadding), we investigated the optimal atom size for shuffling and compared\ntheir performance and efficiency. We found that matching atom size to MSL\noptimizes performance for both packing methods (concatenation and padding), and\npadding yields lower final perplexity (higher performance) than concatenation\nat the cost of more training steps and lower compute efficiency. This trade-off\ninforms the choice of packing methods in training language models.", "published": "2024-08-19 00:26:53", "link": "http://arxiv.org/abs/2408.09621v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "A Strategy to Combine 1stGen Transformers and Open LLMs for Automatic\n  Text Classification", "abstract": "Transformer models have achieved state-of-the-art results, with Large\nLanguage Models (LLMs), an evolution of first-generation transformers (1stTR),\nbeing considered the cutting edge in several NLP tasks. However, the literature\nhas yet to conclusively demonstrate that LLMs consistently outperform 1stTRs\nacross all NLP tasks. This study compares three 1stTRs (BERT, RoBERTa, and\nBART) with two open LLMs (Llama 2 and Bloom) across 11 sentiment analysis\ndatasets. The results indicate that open LLMs may moderately outperform or\nmatch 1stTRs in 8 out of 11 datasets but only when fine-tuned. Given this\nsubstantial cost for only moderate gains, the practical applicability of these\nmodels in cost-sensitive scenarios is questionable. In this context, a\nconfidence-based strategy that seamlessly integrates 1stTRs with open LLMs\nbased on prediction certainty is proposed. High-confidence documents are\nclassified by the more cost-effective 1stTRs, while uncertain cases are handled\nby LLMs in zero-shot or few-shot modes, at a much lower cost than fine-tuned\nversions. Experiments in sentiment analysis demonstrate that our solution not\nonly outperforms 1stTRs, zero-shot, and few-shot LLMs but also competes closely\nwith fine-tuned LLMs at a fraction of the cost.", "published": "2024-08-19 01:22:21", "link": "http://arxiv.org/abs/2408.09629v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Acquiring Bidirectionality via Large and Small Language Models", "abstract": "Using token representation from bidirectional language models (LMs) such as\nBERT is still a widely used approach for token-classification tasks. Even\nthough there exist much larger unidirectional LMs such as Llama-2, they are\nrarely used to replace the token representation of bidirectional LMs. In this\nwork, we hypothesize that their lack of bidirectionality is keeping them\nbehind. To that end, we propose to newly train a small backward LM and\nconcatenate its representations to those of existing LM for downstream tasks.\nThrough experiments in named entity recognition, we demonstrate that\nintroducing backward model improves the benchmark performance more than 10\npoints. Furthermore, we show that the proposed method is especially effective\nfor rare domains and in few-shot learning settings.", "published": "2024-08-19 01:54:37", "link": "http://arxiv.org/abs/2408.09640v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BLADE: Benchmarking Language Model Agents for Data-Driven Science", "abstract": "Data-driven scientific discovery requires the iterative integration of\nscientific domain knowledge, statistical expertise, and an understanding of\ndata semantics to make nuanced analytical decisions, e.g., about which\nvariables, transformations, and statistical models to consider. LM-based agents\nequipped with planning, memory, and code execution capabilities have the\npotential to support data-driven science. However, evaluating agents on such\nopen-ended tasks is challenging due to multiple valid approaches, partially\ncorrect steps, and different ways to express the same decisions. To address\nthese challenges, we present BLADE, a benchmark to automatically evaluate\nagents' multifaceted approaches to open-ended research questions. BLADE\nconsists of 12 datasets and research questions drawn from existing scientific\nliterature, with ground truth collected from independent analyses by expert\ndata scientists and researchers. To automatically evaluate agent responses, we\ndeveloped corresponding computational methods to match different\nrepresentations of analyses to this ground truth. Though language models\npossess considerable world knowledge, our evaluation shows that they are often\nlimited to basic analyses. However, agents capable of interacting with the\nunderlying data demonstrate improved, but still non-optimal, diversity in their\nanalytical decision making. Our work enables the evaluation of agents for\ndata-driven science and provides researchers deeper insights into agents'\nanalysis approaches.", "published": "2024-08-19 02:59:35", "link": "http://arxiv.org/abs/2408.09667v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Recording for Eyes, Not Echoing to Ears: Contextualized\n  Spoken-to-Written Conversion of ASR Transcripts", "abstract": "Automatic Speech Recognition (ASR) transcripts exhibit recognition errors and\nvarious spoken language phenomena such as disfluencies, ungrammatical\nsentences, and incomplete sentences, hence suffering from poor readability. To\nimprove readability, we propose a Contextualized Spoken-to-Written conversion\n(CoS2W) task to address ASR and grammar errors and also transfer the informal\ntext into the formal style with content preserved, utilizing contexts and\nauxiliary information. This task naturally matches the in-context learning\ncapabilities of Large Language Models (LLMs). To facilitate comprehensive\ncomparisons of various LLMs, we construct a document-level Spoken-to-Written\nconversion of ASR Transcripts Benchmark (SWAB) dataset. Using SWAB, we study\nthe impact of different granularity levels on the CoS2W performance, and\npropose methods to exploit contexts and auxiliary information to enhance the\noutputs. Experimental results reveal that LLMs have the potential to excel in\nthe CoS2W task, particularly in grammaticality and formality, our methods\nachieve effective understanding of contexts and auxiliary information by LLMs.\nWe further investigate the effectiveness of using LLMs as evaluators and find\nthat LLM evaluators show strong correlations with human evaluations on rankings\nof faithfulness and formality, which validates the reliability of LLM\nevaluators for the CoS2W task.", "published": "2024-08-19 03:53:48", "link": "http://arxiv.org/abs/2408.09688v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code\n  Generation in LLMs via Zero-Shot Cross-Lingual Transfer", "abstract": "The use of Large Language Models (LLMs) for program code generation has\ngained substantial attention, but their biases and limitations with non-English\nprompts challenge global inclusivity. This paper investigates the complexities\nof multilingual prompt-based code generation. Our evaluations of LLMs,\nincluding CodeLLaMa and CodeGemma, reveal significant disparities in code\nquality for non-English prompts; we also demonstrate the inadequacy of simple\napproaches like prompt translation, bootstrapped data augmentation, and\nfine-tuning. To address this, we propose a zero-shot cross-lingual approach\nusing a neural projection technique, integrating a cross-lingual encoder like\nLASER artetxe2019massively to map multilingual embeddings from it into the\nLLM's token space. This method requires training only on English data and\nscales effectively to other languages. Results on a translated and\nquality-checked MBPP dataset show substantial improvements in code quality.\nThis research promotes a more inclusive code generation landscape by empowering\nLLMs with multilingual capabilities to support the diverse linguistic spectrum\nin programming.", "published": "2024-08-19 05:11:46", "link": "http://arxiv.org/abs/2408.09701v1", "categories": ["cs.CL", "68T50 (Primary) 68T07 (Secondary)"], "primary_category": "cs.CL"}
{"title": "SEMDR: A Semantic-Aware Dual Encoder Model for Legal Judgment Prediction\n  with Legal Clue Tracing", "abstract": "Legal Judgment Prediction (LJP) aims to form legal judgments based on the\ncriminal fact description. However, researchers struggle to classify confusing\ncriminal cases, such as robbery and theft, which requires LJP models to\ndistinguish the nuances between similar crimes. Existing methods usually design\nhandcrafted features to pick up necessary semantic legal clues to make more\naccurate legal judgment predictions. In this paper, we propose a Semantic-Aware\nDual Encoder Model (SEMDR), which designs a novel legal clue tracing mechanism\nto conduct fine-grained semantic reasoning between criminal facts and\ninstruments. Our legal clue tracing mechanism is built from three reasoning\nlevels: 1) Lexicon-Tracing, which aims to extract criminal facts from criminal\ndescriptions; 2) Sentence Representation Learning, which contrastively trains\nlanguage models to better represent confusing criminal facts; 3) Multi-Fact\nReasoning, which builds a reasons graph to propagate semantic clues among fact\nnodes to capture the subtle difference among criminal facts. Our legal clue\ntracing mechanism helps SEMDR achieve state-of-the-art on the CAIL2018 dataset\nand shows its advance in few-shot scenarios. Our experiments show that SEMDR\nhas a strong ability to learn more uniform and distinguished representations\nfor criminal facts, which helps to make more accurate predictions on confusing\ncriminal cases and reduces the model uncertainty during making judgments. All\ncodes will be released via GitHub.", "published": "2024-08-19 06:13:19", "link": "http://arxiv.org/abs/2408.09717v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Are Large Language Models More Honest in Their Probabilistic or\n  Verbalized Confidence?", "abstract": "Large language models (LLMs) have been found to produce hallucinations when\nthe question exceeds their internal knowledge boundaries. A reliable model\nshould have a clear perception of its knowledge boundaries, providing correct\nanswers within its scope and refusing to answer when it lacks knowledge.\nExisting research on LLMs' perception of their knowledge boundaries typically\nuses either the probability of the generated tokens or the verbalized\nconfidence as the model's confidence in its response. However, these studies\noverlook the differences and connections between the two. In this paper, we\nconduct a comprehensive analysis and comparison of LLMs' probabilistic\nperception and verbalized perception of their factual knowledge boundaries.\nFirst, we investigate the pros and cons of these two perceptions. Then, we\nstudy how they change under questions of varying frequencies. Finally, we\nmeasure the correlation between LLMs' probabilistic confidence and verbalized\nconfidence. Experimental results show that 1) LLMs' probabilistic perception is\ngenerally more accurate than verbalized perception but requires an in-domain\nvalidation set to adjust the confidence threshold. 2) Both perceptions perform\nbetter on less frequent questions. 3) It is challenging for LLMs to accurately\nexpress their internal confidence in natural language.", "published": "2024-08-19 08:01:11", "link": "http://arxiv.org/abs/2408.09773v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Summarizing long regulatory documents with a multi-step pipeline", "abstract": "Due to their length and complexity, long regulatory texts are challenging to\nsummarize. To address this, a multi-step extractive-abstractive architecture is\nproposed to handle lengthy regulatory documents more effectively. In this\npaper, we show that the effectiveness of a two-step architecture for\nsummarizing long regulatory texts varies significantly depending on the model\nused. Specifically, the two-step architecture improves the performance of\ndecoder-only models. For abstractive encoder-decoder models with short context\nlengths, the effectiveness of an extractive step varies, whereas for\nlong-context encoder-decoder models, the extractive step worsens their\nperformance. This research also highlights the challenges of evaluating\ngenerated texts, as evidenced by the differing results from human and automated\nevaluations. Most notably, human evaluations favoured language models\npretrained on legal text, while automated metrics rank general-purpose language\nmodels higher. The results underscore the importance of selecting the\nappropriate summarization strategy based on model architecture and context\nlength.", "published": "2024-08-19 08:07:25", "link": "http://arxiv.org/abs/2408.09777v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Continual Dialogue State Tracking via Reason-of-Select Distillation", "abstract": "An ideal dialogue system requires continuous skill acquisition and adaptation\nto new tasks while retaining prior knowledge. Dialogue State Tracking (DST),\nvital in these systems, often involves learning new services and confronting\ncatastrophic forgetting, along with a critical capability loss termed the\n\"Value Selection Quandary.\" To address these challenges, we introduce the\nReason-of-Select (RoS) distillation method by enhancing smaller models with a\nnovel 'meta-reasoning' capability. Meta-reasoning employs an enhanced\nmulti-domain perspective, combining fragments of meta-knowledge from\ndomain-specific dialogues during continual learning. This transcends\ntraditional single-perspective reasoning. The domain bootstrapping process\nenhances the model's ability to dissect intricate dialogues from multiple\npossible values. Its domain-agnostic property aligns data distribution across\ndifferent domains, effectively mitigating forgetting. Additionally, two novel\nimprovements, \"multi-value resolution\" strategy and Semantic Contrastive\nReasoning Selection method, significantly enhance RoS by generating\nDST-specific selection chains and mitigating hallucinations in teachers'\nreasoning, ensuring effective and reliable knowledge transfer. Extensive\nexperiments validate the exceptional performance and robust generalization\ncapabilities of our method. The source code is provided for reproducibility.", "published": "2024-08-19 09:48:50", "link": "http://arxiv.org/abs/2408.09846v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TaSL: Continual Dialog State Tracking via Task Skill Localization and\n  Consolidation", "abstract": "A practical dialogue system requires the capacity for ongoing skill\nacquisition and adaptability to new tasks while preserving prior knowledge.\nHowever, current methods for Continual Dialogue State Tracking (DST), a crucial\nfunction of dialogue systems, struggle with the catastrophic forgetting issue\nand knowledge transfer between tasks. We present TaSL, a novel framework for\ntask skill localization and consolidation that enables effective knowledge\ntransfer without relying on memory replay. TaSL uses a novel group-wise\ntechnique to pinpoint task-specific and task-shared areas. Additionally, a\nfine-grained skill consolidation strategy protects task-specific knowledge from\nbeing forgotten while updating shared knowledge for bi-directional knowledge\ntransfer. As a result, TaSL strikes a balance between preserving previous\nknowledge and excelling at new tasks. Comprehensive experiments on various\nbackbones highlight the significant performance improvements of TaSL over\nexisting state-of-the-art methods. The source code is provided for\nreproducibility.", "published": "2024-08-19 10:01:28", "link": "http://arxiv.org/abs/2408.09857v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "\"Image, Tell me your story!\" Predicting the original meta-context of\n  visual misinformation", "abstract": "To assist human fact-checkers, researchers have developed automated\napproaches for visual misinformation detection. These methods assign veracity\nscores by identifying inconsistencies between the image and its caption, or by\ndetecting forgeries in the image. However, they neglect a crucial point of the\nhuman fact-checking process: identifying the original meta-context of the\nimage. By explaining what is actually true about the image, fact-checkers can\nbetter detect misinformation, focus their efforts on check-worthy visual\ncontent, engage in counter-messaging before misinformation spreads widely, and\nmake their explanation more convincing. Here, we fill this gap by introducing\nthe task of automated image contextualization. We create 5Pils, a dataset of\n1,676 fact-checked images with question-answer pairs about their original\nmeta-context. Annotations are based on the 5 Pillars fact-checking framework.\nWe implement a first baseline that grounds the image in its original\nmeta-context using the content of the image and textual evidence retrieved from\nthe open web. Our experiments show promising results while highlighting several\nopen challenges in retrieval and reasoning. We make our code and data publicly\navailable.", "published": "2024-08-19 12:21:34", "link": "http://arxiv.org/abs/2408.09939v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "GLIMMER: Incorporating Graph and Lexical Features in Unsupervised\n  Multi-Document Summarization", "abstract": "Pre-trained language models are increasingly being used in multi-document\nsummarization tasks. However, these models need large-scale corpora for\npre-training and are domain-dependent. Other non-neural unsupervised\nsummarization approaches mostly rely on key sentence extraction, which can lead\nto information loss. To address these challenges, we propose a lightweight yet\neffective unsupervised approach called GLIMMER: a Graph and LexIcal features\nbased unsupervised Multi-docuMEnt summaRization approach. It first constructs a\nsentence graph from the source documents, then automatically identifies\nsemantic clusters by mining low-level features from raw texts, thereby\nimproving intra-cluster correlation and the fluency of generated sentences.\nFinally, it summarizes clusters into natural sentences. Experiments conducted\non Multi-News, Multi-XScience and DUC-2004 demonstrate that our approach\noutperforms existing unsupervised approaches. Furthermore, it surpasses\nstate-of-the-art pre-trained multi-document summarization models (e.g. PEGASUS\nand PRIMERA) under zero-shot settings in terms of ROUGE scores. Additionally,\nhuman evaluations indicate that summaries generated by GLIMMER achieve high\nreadability and informativeness scores. Our code is available at\nhttps://github.com/Oswald1997/GLIMMER.", "published": "2024-08-19 16:01:48", "link": "http://arxiv.org/abs/2408.10115v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Instruction Finetuning for Leaderboard Generation from Empirical AI\n  Research", "abstract": "This study demonstrates the application of instruction finetuning of\npretrained Large Language Models (LLMs) to automate the generation of AI\nresearch leaderboards, extracting (Task, Dataset, Metric, Score) quadruples\nfrom articles. It aims to streamline the dissemination of advancements in AI\nresearch by transitioning from traditional, manual community curation, or\notherwise taxonomy-constrained natural language inference (NLI) models, to an\nautomated, generative LLM-based approach. Utilizing the FLAN-T5 model, this\nresearch enhances LLMs' adaptability and reliability in information extraction,\noffering a novel method for structured knowledge representation.", "published": "2024-08-19 16:41:07", "link": "http://arxiv.org/abs/2408.10141v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Resolving Lexical Bias in Edit Scoping with Projector Editor Networks", "abstract": "Weight-preserving model editing techniques heavily rely on the scoping\nmechanism that decides when to apply an edit to the base model. These scoping\nmechanisms utilize distance functions in the representation space to ascertain\nthe scope of the edit. In this work, we show that distance-based scoping\nfunctions grapple with lexical biases leading to issues such as misfires with\nirrelevant prompts that share similar lexical characteristics. To address this\nproblem, we introduce, Projector Editor Networks for Model Editing (PENME),is a\nmodel editing approach that employs a compact adapter with a projection network\ntrained via a contrastive learning objective. We demonstrate the efficacy of\nPENME in achieving superior results while being compute efficient and flexible\nto adapt across model architectures.", "published": "2024-08-19 20:50:41", "link": "http://arxiv.org/abs/2408.10411v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Goldfish: Monolingual Language Models for 350 Languages", "abstract": "For many low-resource languages, the only available language models are large\nmultilingual models trained on many languages simultaneously. However, using\nFLORES perplexity as a metric, we find that these models perform worse than\nbigrams for many languages (e.g. 24% of languages in XGLM 4.5B; 43% in BLOOM\n7.1B). To facilitate research that focuses on low-resource languages, we\npre-train and release Goldfish, a suite of monolingual autoregressive\nTransformer language models up to 125M parameters for 350 languages. The\nGoldfish reach lower FLORES perplexities than BLOOM, XGLM, and MaLA-500 on 98\nof 204 FLORES languages, despite each Goldfish model being over 10x smaller.\nHowever, the Goldfish significantly underperform larger multilingual models on\nreasoning benchmarks, suggesting that for low-resource languages,\nmultilinguality primarily improves general reasoning abilities rather than\nbasic text generation. We release models trained on 5MB (350 languages), 10MB\n(288 languages), 100MB (166 languages), and 1GB (83 languages) of text data\nwhere available. The Goldfish models are available as baselines, fine-tuning\nsources, or augmentations to existing models in low-resource NLP research, and\nthey are further useful for crosslinguistic studies requiring maximally\ncomparable models across languages.", "published": "2024-08-19 22:31:21", "link": "http://arxiv.org/abs/2408.10441v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "How to Make the Most of LLMs' Grammatical Knowledge for Acceptability\n  Judgments", "abstract": "The grammatical knowledge of language models (LMs) is often measured using a\nbenchmark of linguistic minimal pairs, where the LMs are presented with a pair\nof acceptable and unacceptable sentences and required to judge which is more\nacceptable. Conventional approaches directly compare sentence probabilities\nassigned by LMs, but recent large language models (LLMs) are trained to perform\ntasks via prompting, and thus, the raw probabilities they assign may not fully\nreflect their grammatical knowledge. In this study, we attempt to derive more\naccurate acceptability judgments from LLMs using prompts and templates. Through\nextensive experiments in English and Chinese, we compare nine judgment methods\nand find two of them, a probability readout method -- in-template LP and a\nprompt-based method -- Yes/No probability computing, achieve higher accuracy\nthan the conventional ones. Our analysis reveals that these methods excel in\ndifferent linguistic phenomena, suggesting they access different aspects of\nLLMs' knowledge. We also find that ensembling the two methods outperforms\nsingle methods. Consequently, we recommend these techniques, either\nindividually or ensembled, as more effective alternatives to conventional\napproaches for assessing grammatical knowledge in LLMs.", "published": "2024-08-19 01:53:47", "link": "http://arxiv.org/abs/2408.09639v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "AutoML-guided Fusion of Entity and LLM-based Representations for\n  Document Classification", "abstract": "Large semantic knowledge bases are grounded in factual knowledge. However,\nrecent approaches to dense text representations (i.e. embeddings) do not\nefficiently exploit these resources. Dense and robust representations of\ndocuments are essential for effectively solving downstream classification and\nretrieval tasks. This work demonstrates that injecting embedded information\nfrom knowledge bases can augment the performance of contemporary Large Language\nModel (LLM)-based representations for the task of text classification. Further,\nby considering automated machine learning (AutoML) with the fused\nrepresentation space, we demonstrate it is possible to improve classification\naccuracy even if we use low-dimensional projections of the original\nrepresentation space obtained via efficient matrix factorization. This result\nshows that significantly faster classifiers can be achieved with minimal or no\nloss in predictive performance, as demonstrated using five strong LLM baselines\non six diverse real-life datasets. The code is freely available at\n\\url{https://github.com/bkolosk1/bablfusion.git}.", "published": "2024-08-19 08:41:40", "link": "http://arxiv.org/abs/2408.09794v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "CMoralEval: A Moral Evaluation Benchmark for Chinese Large Language\n  Models", "abstract": "What a large language model (LLM) would respond in ethically relevant\ncontext? In this paper, we curate a large benchmark CMoralEval for morality\nevaluation of Chinese LLMs. The data sources of CMoralEval are two-fold: 1) a\nChinese TV program discussing Chinese moral norms with stories from the society\nand 2) a collection of Chinese moral anomies from various newspapers and\nacademic papers on morality. With these sources, we aim to create a moral\nevaluation dataset characterized by diversity and authenticity. We develop a\nmorality taxonomy and a set of fundamental moral principles that are not only\nrooted in traditional Chinese culture but also consistent with contemporary\nsocietal norms. To facilitate efficient construction and annotation of\ninstances in CMoralEval, we establish a platform with AI-assisted instance\ngeneration to streamline the annotation process. These help us curate\nCMoralEval that encompasses both explicit moral scenarios (14,964 instances)\nand moral dilemma scenarios (15,424 instances), each with instances from\ndifferent data sources. We conduct extensive experiments with CMoralEval to\nexamine a variety of Chinese LLMs. Experiment results demonstrate that\nCMoralEval is a challenging benchmark for Chinese LLMs. The dataset is publicly\navailable at \\url{https://github.com/tjunlp-lab/CMoralEval}.", "published": "2024-08-19 09:15:35", "link": "http://arxiv.org/abs/2408.09819v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Importance Weighting Can Help Large Language Models Self-Improve", "abstract": "Large language models (LLMs) have shown remarkable capability in numerous\ntasks and applications. However, fine-tuning LLMs using high-quality datasets\nunder external supervision remains prohibitively expensive. In response, LLM\nself-improvement approaches have been vibrantly developed recently. The typical\nparadigm of LLM self-improvement involves training LLM on self-generated data,\npart of which may be detrimental and should be filtered out due to the unstable\ndata quality. While current works primarily employs filtering strategies based\non answer correctness, in this paper, we demonstrate that filtering out correct\nbut with high distribution shift extent (DSE) samples could also benefit the\nresults of self-improvement. Given that the actual sample distribution is\nusually inaccessible, we propose a new metric called DS weight to approximate\nDSE, inspired by the Importance Weighting methods. Consequently, we integrate\nDS weight with self-consistency to comprehensively filter the self-generated\nsamples and fine-tune the language model. Experiments show that with only a\ntiny valid set (up to 5\\% size of the training set) to compute DS weight, our\napproach can notably promote the reasoning ability of current LLM\nself-improvement methods. The resulting performance is on par with methods that\nrely on external supervision from pre-trained reward models.", "published": "2024-08-19 09:51:02", "link": "http://arxiv.org/abs/2408.09849v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Self-Directed Turing Test for Large Language Models", "abstract": "The Turing test examines whether AIs can exhibit human-like behaviour in\nnatural language conversations. Traditional Turing tests adopt a rigid dialogue\nformat where each participant sends only one message each time and require\ncontinuous human involvement to direct the entire interaction with the test\nsubject. This fails to reflect a natural conversational style and hinders the\nevaluation of Large Language Models (LLMs) in complex and prolonged dialogues.\nThis paper proposes the Self-Directed Turing Test, which extends the original\ntest with a burst dialogue format, allowing more dynamic exchanges by multiple\nconsecutive messages. It further efficiently reduces human workload by having\nthe LLM self-direct the majority of the test process, iteratively generating\ndialogues that simulate its interaction with humans. With the pseudo-dialogue\nhistory, the model then engages in a shorter dialogue with a human, which is\npaired with a human-human conversation on the same topic to be judged using\nquestionnaires. We introduce the X-Turn Pass-Rate metric to assess the human\nlikeness of LLMs across varying durations. While LLMs like GPT-4 initially\nperform well, achieving pass rates of 51.9% and 38.9% during 3 turns and 10\nturns of dialogues respectively, their performance drops as the dialogue\nprogresses, which underscores the difficulty in maintaining consistency in the\nlong term.", "published": "2024-08-19 09:57:28", "link": "http://arxiv.org/abs/2408.09853v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and\n  Competition", "abstract": "While Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have\neffectively addressed GPU memory constraints during fine-tuning, their\nperformance often falls short, especially in multidimensional task scenarios.\nTo address this issue, one straightforward solution is to introduce\ntask-specific LoRA modules as domain experts, leveraging the modeling of\nmultiple experts' capabilities and thus enhancing the general capability of\nmulti-task learning. Despite promising, these additional components often add\ncomplexity to the training and inference process, contravening the efficient\ncharacterization of PEFT designed for. Considering this, we introduce an\ninnovative PEFT method, TeamLoRA, consisting of a collaboration and competition\nmodule for experts, and thus achieving the right balance of effectiveness and\nefficiency: (i) For collaboration, a novel knowledge-sharing and -organizing\nmechanism is devised to appropriately reduce the scale of matrix operations,\nthereby boosting the training and inference speed. (ii) For competition, we\npropose leveraging a game-theoretic interaction mechanism for experts,\nencouraging experts to transfer their domain-specific knowledge while facing\ndiverse downstream tasks, and thus enhancing the performance. By doing so,\nTeamLoRA elegantly connects the experts as a \"Team\" with internal collaboration\nand competition, enabling a faster and more accurate PEFT paradigm for\nmulti-task learning. To validate the superiority of TeamLoRA, we curate a\ncomprehensive multi-task evaluation(CME) benchmark to thoroughly assess the\ncapability of multi-task learning. Experiments conducted on our CME and other\nbenchmarks indicate the effectiveness and efficiency of TeamLoRA. Our project\nis available at https://github.com/Lin-Tianwei/TeamLoRA.", "published": "2024-08-19 09:58:53", "link": "http://arxiv.org/abs/2408.09856v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Performance Law of Large Language Models", "abstract": "Guided by the belief of the scaling law, large language models (LLMs) have\nachieved impressive performance in recent years. However, scaling law only\ngives a qualitative estimation of loss, which is influenced by various factors\nsuch as model architectures, data distributions, tokenizers, and computation\nprecision. Thus, estimating the real performance of LLMs with different\ntraining settings rather than loss may be quite useful in practical\ndevelopment. In this article, we present an empirical equation named\n\"Performance Law\" to directly predict the MMLU score of an LLM, which is a\nwidely used metric to indicate the general capability of LLMs in real-world\nconversations and applications. Based on only a few key hyperparameters of the\nLLM architecture and the size of training data, we obtain a quite accurate MMLU\nprediction of various LLMs with diverse sizes and architectures developed by\ndifferent organizations in different years. Performance law can be used to\nguide the choice of LLM architecture and the effective allocation of\ncomputational resources without extensive experiments.", "published": "2024-08-19 11:09:12", "link": "http://arxiv.org/abs/2408.09895v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Active Learning for Identifying Disaster-Related Tweets: A Comparison\n  with Keyword Filtering and Generic Fine-Tuning", "abstract": "Information from social media can provide essential information for emergency\nresponse during natural disasters in near real-time. However, it is difficult\nto identify the disaster-related posts among the large amounts of unstructured\ndata available. Previous methods often use keyword filtering, topic modelling\nor classification-based techniques to identify such posts. Active Learning (AL)\npresents a promising sub-field of Machine Learning (ML) that has not been used\nmuch in the field of text classification of social media content. This study\ntherefore investigates the potential of AL for identifying disaster-related\nTweets. We compare a keyword filtering approach, a RoBERTa model fine-tuned\nwith generic data from CrisisLex, a base RoBERTa model trained with AL and a\nfine-tuned RoBERTa model trained with AL regarding classification performance.\nFor testing, data from CrisisLex and manually labelled data from the 2021 flood\nin Germany and the 2023 Chile forest fires were considered. The results show\nthat generic fine-tuning combined with 10 rounds of AL outperformed all other\napproaches. Consequently, a broadly applicable model for the identification of\ndisaster-related Tweets could be trained with very little labelling effort. The\nmodel can be applied to use cases beyond this study and provides a useful tool\nfor further research in social media analysis.", "published": "2024-08-19 11:40:20", "link": "http://arxiv.org/abs/2408.09914v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Attribution Analysis Meets Model Editing: Advancing Knowledge Correction\n  in Vision Language Models with VisEdit", "abstract": "Model editing aims to correct outdated or erroneous knowledge in large models\nwithout costly retraining. Recent research discovered that the mid-layer\nrepresentation of the subject's final token in a prompt has a strong influence\non factual predictions, and developed Large Language Model (LLM) editing\ntechniques based on this observation. However, for Vision-LLMs (VLLMs), how\nvisual representations impact the predictions from a decoder-only language\nmodel remains largely unexplored. To the best of our knowledge, model editing\nfor VLLMs has not been extensively studied in the literature. In this work, we\nemploy the contribution allocation and noise perturbation methods to measure\nthe contributions of visual representations for token predictions. Our\nattribution analysis shows that visual representations in mid-to-later layers\nthat are highly relevant to the prompt contribute significantly to predictions.\nBased on these insights, we propose VisEdit, a novel model editor for VLLMs\nthat effectively corrects knowledge by editing intermediate visual\nrepresentations in regions important to the edit prompt. We evaluated VisEdit\nusing multiple VLLM backbones and public VLLM editing benchmark datasets. The\nresults show the superiority of VisEdit over the strong baselines adapted from\nexisting state-of-the-art editors for LLMs.", "published": "2024-08-19 11:44:40", "link": "http://arxiv.org/abs/2408.09916v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Large Language Models for Classical Chinese Poetry Translation:\n  Benchmarking, Evaluating, and Improving", "abstract": "Different from the traditional translation tasks, classical Chinese poetry\ntranslation requires both adequacy and fluency in translating culturally and\nhistorically significant content and linguistic poetic elegance. Large language\nmodels (LLMs) with impressive multilingual capabilities may bring a ray of hope\nto achieve this extreme translation demand. This paper first introduces a\nsuitable benchmark (PoetMT) where each Chinese poetry has a recognized elegant\ntranslation. Meanwhile, we propose a new metric based on GPT-4 to evaluate the\nextent to which current LLMs can meet these demands. Our empirical evaluation\nreveals that the existing LLMs fall short in the challenging task. Hence, we\npropose a Retrieval-Augmented Machine Translation (RAT) method which\nincorporates knowledge related to classical poetry for advancing the\ntranslation of Chinese Poetry in LLMs. Experimental results show that RAT\nconsistently outperforms all comparison methods regarding wildly used BLEU,\nCOMET, BLEURT, our proposed metric, and human evaluation.", "published": "2024-08-19 12:34:31", "link": "http://arxiv.org/abs/2408.09945v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Microscopic Analysis on LLM players via Social Deduction Game", "abstract": "Recent studies have begun developing autonomous game players for social\ndeduction games using large language models (LLMs). When building LLM players,\nfine-grained evaluations are crucial for addressing weaknesses in game-playing\nabilities. However, existing studies have often overlooked such assessments.\nSpecifically, we point out two issues with the evaluation methods employed.\nFirst, game-playing abilities have typically been assessed through game-level\noutcomes rather than specific event-level skills; Second, error analyses have\nlacked structured methodologies. To address these issues, we propose an\napproach utilizing a variant of the SpyFall game, named SpyGame. We conducted\nan experiment with four LLMs, analyzing their gameplay behavior in SpyGame both\nquantitatively and qualitatively. For the quantitative analysis, we introduced\neight metrics to resolve the first issue, revealing that these metrics are more\neffective than existing ones for evaluating the two critical skills: intent\nidentification and camouflage. In the qualitative analysis, we performed\nthematic analysis to resolve the second issue. This analysis identifies four\nmajor categories that affect gameplay of LLMs. Additionally, we demonstrate how\nthese categories complement and support the findings from the quantitative\nanalysis.", "published": "2024-08-19 12:35:23", "link": "http://arxiv.org/abs/2408.09946v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "C${^2}$RL: Content and Context Representation Learning for Gloss-free\n  Sign Language Translation and Retrieval", "abstract": "Sign Language Representation Learning (SLRL) is crucial for a range of sign\nlanguage-related downstream tasks such as Sign Language Translation (SLT) and\nSign Language Retrieval (SLRet). Recently, many gloss-based and gloss-free SLRL\nmethods have been proposed, showing promising performance. Among them, the\ngloss-free approach shows promise for strong scalability without relying on\ngloss annotations. However, it currently faces suboptimal solutions due to\nchallenges in encoding the intricate, context-sensitive characteristics of sign\nlanguage videos, mainly struggling to discern essential sign features using a\nnon-monotonic video-text alignment strategy. Therefore, we introduce an\ninnovative pretraining paradigm for gloss-free SLRL, called C${^2}$RL, in this\npaper. Specifically, rather than merely incorporating a non-monotonic semantic\nalignment of video and text to learn language-oriented sign features, we\nemphasize two pivotal aspects of SLRL: Implicit Content Learning (ICL) and\nExplicit Context Learning (ECL). ICL delves into the content of communication,\ncapturing the nuances, emphasis, timing, and rhythm of the signs. In contrast,\nECL focuses on understanding the contextual meaning of signs and converting\nthem into equivalent sentences. Despite its simplicity, extensive experiments\nconfirm that the joint optimization of ICL and ECL results in robust sign\nlanguage representation and significant performance gains in gloss-free SLT and\nSLRet tasks. Notably, C${^2}$RL improves the BLEU-4 score by +5.3 on P14T,\n+10.6 on CSL-daily, +6.2 on OpenASL, and +1.3 on How2Sign. It also boosts the\nR@1 score by +8.3 on P14T, +14.4 on CSL-daily, and +5.9 on How2Sign.\nAdditionally, we set a new baseline for the OpenASL dataset in the SLRet task.", "published": "2024-08-19 12:42:10", "link": "http://arxiv.org/abs/2408.09949v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Privacy Checklist: Privacy Violation Detection Grounding on Contextual\n  Integrity Theory", "abstract": "Privacy research has attracted wide attention as individuals worry that their\nprivate data can be easily leaked during interactions with smart devices,\nsocial platforms, and AI applications. Computer science researchers, on the\nother hand, commonly study privacy issues through privacy attacks and defenses\non segmented fields. Privacy research is conducted on various sub-fields,\nincluding Computer Vision (CV), Natural Language Processing (NLP), and Computer\nNetworks. Within each field, privacy has its own formulation. Though pioneering\nworks on attacks and defenses reveal sensitive privacy issues, they are\nnarrowly trapped and cannot fully cover people's actual privacy concerns.\nConsequently, the research on general and human-centric privacy research\nremains rather unexplored. In this paper, we formulate the privacy issue as a\nreasoning problem rather than simple pattern matching. We ground on the\nContextual Integrity (CI) theory which posits that people's perceptions of\nprivacy are highly correlated with the corresponding social context. Based on\nsuch an assumption, we develop the first comprehensive checklist that covers\nsocial identities, private attributes, and existing privacy regulations. Unlike\nprior works on CI that either cover limited expert annotated norms or model\nincomplete social context, our proposed privacy checklist uses the whole Health\nInsurance Portability and Accountability Act of 1996 (HIPAA) as an example, to\nshow that we can resort to large language models (LLMs) to completely cover the\nHIPAA's regulations. Additionally, our checklist also gathers expert\nannotations across multiple ontologies to determine private information\nincluding but not limited to personally identifiable information (PII). We use\nour preliminary results on the HIPAA to shed light on future context-centric\nprivacy research to cover more privacy regulations, social norms and standards.", "published": "2024-08-19 14:48:04", "link": "http://arxiv.org/abs/2408.10053v2", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Rhyme-aware Chinese lyric generator based on GPT", "abstract": "Neural language representation models such as GPT, pre-trained on large-scale\ncorpora, can effectively capture rich semantic patterns from plain text and be\nfine-tuned to consistently improve natural language generation performance.\nHowever, existing pre-trained language models used to generate lyrics rarely\nconsider rhyme information, which is crucial in lyrics. Using a pre-trained\nmodel directly results in poor performance. To enhance the rhyming quality of\ngenerated lyrics, we incorporate integrated rhyme information into our model,\nthereby improving lyric generation performance.", "published": "2024-08-19 16:17:20", "link": "http://arxiv.org/abs/2408.10130v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Multilingual Needle in a Haystack: Investigating Long-Context Behavior\n  of Multilingual Large Language Models", "abstract": "While recent large language models (LLMs) demonstrate remarkable abilities in\nresponding to queries in diverse languages, their ability to handle long\nmultilingual contexts is unexplored. As such, a systematic evaluation of the\nlong-context capabilities of LLMs in multilingual settings is crucial,\nspecifically in the context of information retrieval. To address this gap, we\nintroduce the MultiLingual Needle-in-a-Haystack (MLNeedle) test, designed to\nassess a model's ability to retrieve relevant information (the needle) from a\ncollection of multilingual distractor texts (the haystack). This test serves as\nan extension of the multilingual question-answering task, encompassing both\nmonolingual and cross-lingual retrieval. We evaluate four state-of-the-art LLMs\non MLNeedle. Our findings reveal that model performance can vary significantly\nwith language and needle position. Specifically, we observe that model\nperformance is the lowest when the needle is (i) in a language outside the\nEnglish language family and (ii) located in the middle of the input context.\nFurthermore, although some models claim a context size of $8k$ tokens or\ngreater, none demonstrate satisfactory cross-lingual retrieval performance as\nthe context length increases. Our analysis provides key insights into the\nlong-context behavior of LLMs in multilingual settings to guide future\nevaluation protocols. To our knowledge, this is the first study to investigate\nthe multilingual long-context behavior of LLMs.", "published": "2024-08-19 17:02:06", "link": "http://arxiv.org/abs/2408.10151v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "LongVILA: Scaling Long-Context Visual Language Models for Long Videos", "abstract": "Long-context capability is critical for multi-modal foundation models,\nespecially for long video understanding. We introduce LongVILA, a full-stack\nsolution for long-context visual-language models by co-designing the algorithm\nand system. For model training, we upgrade existing VLMs to support long video\nunderstanding by incorporating two additional stages, i.e., long context\nextension and long video supervised fine-tuning. However, training on long\nvideo is computationally and memory intensive. We introduce the long-context\nMulti-Modal Sequence Parallelism (MM-SP) system that efficiently parallelizes\nlong video training and inference, enabling 2M context length training on 256\nGPUs without any gradient checkpointing. LongVILA efficiently extends the\nnumber of video frames of VILA from 8 to 2048, achieving 99.8% accuracy in\n6,000-frame (more than 1 million tokens) video needle-in-a-haystack.\nLongVILA-7B demonstrates strong accuracy on 9 popular video benchmarks, e.g.\n65.1% VideoMME with subtitle. Besides, MM-SP is 2.1x - 5.7x faster than ring\nstyle sequence parallelism and 1.1x - 1.4x faster than Megatron with a hybrid\ncontext and tensor parallelism. Moreover, it seamlessly integrates with Hugging\nFace Transformers.", "published": "2024-08-19 17:48:08", "link": "http://arxiv.org/abs/2408.10188v6", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Beyond Relevant Documents: A Knowledge-Intensive Approach for\n  Query-Focused Summarization using Large Language Models", "abstract": "Query-focused summarization (QFS) is a fundamental task in natural language\nprocessing with broad applications, including search engines and report\ngeneration. However, traditional approaches assume the availability of relevant\ndocuments, which may not always hold in practical scenarios, especially in\nhighly specialized topics. To address this limitation, we propose a novel\nknowledge-intensive approach that reframes QFS as a knowledge-intensive task\nsetup. This approach comprises two main components: a retrieval module and a\nsummarization controller. The retrieval module efficiently retrieves\npotentially relevant documents from a large-scale knowledge corpus based on the\ngiven textual query, eliminating the dependence on pre-existing document sets.\nThe summarization controller seamlessly integrates a powerful large language\nmodel (LLM)-based summarizer with a carefully tailored prompt, ensuring the\ngenerated summary is comprehensive and relevant to the query. To assess the\neffectiveness of our approach, we create a new dataset, along with\nhuman-annotated relevance labels, to facilitate comprehensive evaluation\ncovering both retrieval and summarization performance. Extensive experiments\ndemonstrate the superior performance of our approach, particularly its ability\nto generate accurate summaries without relying on the availability of relevant\ndocuments initially. This underscores our method's versatility and practical\napplicability across diverse query scenarios.", "published": "2024-08-19 18:54:20", "link": "http://arxiv.org/abs/2408.10357v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Narrowing the Gap between Vision and Action in Navigation", "abstract": "The existing methods for Vision and Language Navigation in the Continuous\nEnvironment (VLN-CE) commonly incorporate a waypoint predictor to discretize\nthe environment. This simplifies the navigation actions into a view selection\ntask and improves navigation performance significantly compared to direct\ntraining using low-level actions. However, the VLN-CE agents are still far from\nthe real robots since there are gaps between their visual perception and\nexecuted actions. First, VLN-CE agents that discretize the visual environment\nare primarily trained with high-level view selection, which causes them to\nignore crucial spatial reasoning within the low-level action movements. Second,\nin these models, the existing waypoint predictors neglect object semantics and\ntheir attributes related to passibility, which can be informative in indicating\nthe feasibility of actions. To address these two issues, we introduce a\nlow-level action decoder jointly trained with high-level action prediction,\nenabling the current VLN agent to learn and ground the selected visual view to\nthe low-level controls. Moreover, we enhance the current waypoint predictor by\nutilizing visual representations containing rich semantic information and\nexplicitly masking obstacles based on humans' prior knowledge about the\nfeasibility of actions. Empirically, our agent can improve navigation\nperformance metrics compared to the strong baselines on both high-level and\nlow-level actions.", "published": "2024-08-19 20:09:56", "link": "http://arxiv.org/abs/2408.10388v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Value Alignment from Unstructured Text", "abstract": "Aligning large language models (LLMs) to value systems has emerged as a\nsignificant area of research within the fields of AI and NLP. Currently, this\nalignment process relies on the availability of high-quality supervised and\npreference data, which can be both time-consuming and expensive to curate or\nannotate. In this paper, we introduce a systematic end-to-end methodology for\naligning LLMs to the implicit and explicit values represented in unstructured\ntext data. Our proposed approach leverages the use of scalable synthetic data\ngeneration techniques to effectively align the model to the values present in\nthe unstructured data. Through two distinct use-cases, we demonstrate the\nefficiency of our methodology on the Mistral-7B-Instruct model. Our approach\ncredibly aligns LLMs to the values embedded within documents, and shows\nimproved performance against other approaches, as quantified through the use of\nautomatic metrics and win rates.", "published": "2024-08-19 20:22:08", "link": "http://arxiv.org/abs/2408.10392v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Development of an AI Anti-Bullying System Using Large Language Model Key\n  Topic Detection", "abstract": "This paper presents and evaluates work on the development of an artificial\nintelligence (AI) anti-bullying system. The system is designed to identify\ncoordinated bullying attacks via social media and other mechanisms,\ncharacterize them and propose remediation and response activities to them. In\nparticular, a large language model (LLM) is used to populate an enhanced expert\nsystem-based network model of a bullying attack. This facilitates analysis and\nremediation activity - such as generating report messages to social media\ncompanies - determination. The system is described and the efficacy of the LLM\nfor populating the model is analyzed herein.", "published": "2024-08-19 21:09:31", "link": "http://arxiv.org/abs/2408.10417v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "DELIA: Diversity-Enhanced Learning for Instruction Adaptation in Large\n  Language Models", "abstract": "Although instruction tuning is widely used to adjust behavior in Large\nLanguage Models (LLMs), extensive empirical evidence and research indicates\nthat it is primarily a process where the model fits to specific task formats,\nrather than acquiring new knowledge or capabilities. We propose that this\nlimitation stems from biased features learned during instruction tuning, which\ndiffer from ideal task-specfic features, leading to learn less underlying\nsemantics in downstream tasks. However, ideal features are unknown and\nincalculable, constraining past work to rely on prior knowledge to assist\nreasoning or training, which limits LLMs' capabilities to the developers'\nabilities, rather than data-driven scalable learning. In our paper, through our\nnovel data synthesis method, DELIA (Diversity-Enhanced Learning for Instruction\nAdaptation), we leverage the buffering effect of extensive diverse data in LLMs\ntraining to transform biased features in instruction tuning into approximations\nof ideal features, without explicit prior ideal features. Experiments show\nDELIA's better performance compared to common instruction tuning and other\nbaselines. It outperforms common instruction tuning by 17.07%-33.41% on\nIcelandic-English translation bleurt score (WMT-21 dataset, gemma-7b-it) and\nimproves accuracy by 36.1% on formatted text generation (Llama2-7b-chat).\nNotably, among knowledge injection methods we've known, DELIA uniquely align\nthe internal representations of new special tokens with their prior semantics.", "published": "2024-08-19 17:56:06", "link": "http://arxiv.org/abs/2408.10841v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "MegaFake: A Theory-Driven Dataset of Fake News Generated by Large\n  Language Models", "abstract": "The advent of large language models (LLMs) has revolutionized online content\ncreation, making it much easier to generate high-quality fake news. This misuse\nthreatens the integrity of our digital environment and ethical standards.\nTherefore, understanding the motivations and mechanisms behind LLM-generated\nfake news is crucial. In this study, we analyze the creation of fake news from\na social psychology perspective and develop a comprehensive LLM-based\ntheoretical framework, LLM-Fake Theory. We introduce a novel pipeline that\nautomates the generation of fake news using LLMs, thereby eliminating the need\nfor manual annotation. Utilizing this pipeline, we create a theoretically\ninformed Machine-generated Fake news dataset, MegaFake, derived from the\nGossipCop dataset. We conduct comprehensive analyses to evaluate our MegaFake\ndataset. We believe that our dataset and insights will provide valuable\ncontributions to future research focused on the detection and governance of\nfake news in the era of LLMs.", "published": "2024-08-19 13:27:07", "link": "http://arxiv.org/abs/2408.11871v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MoDeGPT: Modular Decomposition for Large Language Model Compression", "abstract": "Large Language Models (LLMs) have reshaped the landscape of artificial\nintelligence by demonstrating exceptional performance across various tasks.\nHowever, substantial computational requirements make their deployment\nchallenging on devices with limited resources. Recently, compression methods\nusing low-rank matrix techniques have shown promise, yet these often lead to\ndegraded accuracy or introduce significant overhead in parameters and inference\nlatency. This paper introduces \\textbf{Mo}dular \\textbf{De}composition\n(MoDeGPT), a novel structured compression framework that does not need recovery\nfine-tuning while resolving the above drawbacks. MoDeGPT partitions the\nTransformer block into modules comprised of matrix pairs and reduces the hidden\ndimensions via reconstructing the module-level outputs. MoDeGPT is developed\nbased on a theoretical framework that utilizes three well-established matrix\ndecomposition algorithms -- Nystr\\\"om approximation, CR decomposition, and SVD\n-- and applies them to our redefined transformer modules. Our comprehensive\nexperiments show MoDeGPT, without backward propagation, matches or surpasses\nprevious structured compression methods that rely on gradient information, and\nsaves 98% of compute costs on compressing a 13B model. On \\textsc{Llama}-2/3\nand OPT models, MoDeGPT maintains 90-95% zero-shot performance with 25-30%\ncompression rates. Moreover, the compression can be done on a single GPU within\na few hours and increases the inference throughput by up to 46%.", "published": "2024-08-19 01:30:14", "link": "http://arxiv.org/abs/2408.09632v4", "categories": ["cs.LG", "cs.CL", "stat.ML", "15A23 (Primary)", "I.2.7"], "primary_category": "cs.LG"}
{"title": "A Comparison of Large Language Model and Human Performance on Random\n  Number Generation Tasks", "abstract": "Random Number Generation Tasks (RNGTs) are used in psychology for examining\nhow humans generate sequences devoid of predictable patterns. By adapting an\nexisting human RNGT for an LLM-compatible environment, this preliminary study\ntests whether ChatGPT-3.5, a large language model (LLM) trained on\nhuman-generated text, exhibits human-like cognitive biases when generating\nrandom number sequences. Initial findings indicate that ChatGPT-3.5 more\neffectively avoids repetitive and sequential patterns compared to humans, with\nnotably lower repeat frequencies and adjacent number frequencies. Continued\nresearch into different models, parameters, and prompting methodologies will\ndeepen our understanding of how LLMs can more closely mimic human random\ngeneration behaviors, while also broadening their applications in cognitive and\nbehavioral science research.", "published": "2024-08-19 02:34:15", "link": "http://arxiv.org/abs/2408.09656v2", "categories": ["cs.AI", "cs.CL", "q-bio.NC"], "primary_category": "cs.AI"}
{"title": "Pedestrian Attribute Recognition: A New Benchmark Dataset and A Large\n  Language Model Augmented Framework", "abstract": "Pedestrian Attribute Recognition (PAR) is one of the indispensable tasks in\nhuman-centered research. However, existing datasets neglect different domains\n(e.g., environments, times, populations, and data sources), only conducting\nsimple random splits, and the performance of these datasets has already\napproached saturation. In the past five years, no large-scale dataset has been\nopened to the public. To address this issue, this paper proposes a new\nlarge-scale, cross-domain pedestrian attribute recognition dataset to fill the\ndata gap, termed MSP60K. It consists of 60,122 images and 57 attribute\nannotations across eight scenarios. Synthetic degradation is also conducted to\nfurther narrow the gap between the dataset and real-world challenging\nscenarios. To establish a more rigorous benchmark, we evaluate 17\nrepresentative PAR models under both random and cross-domain split protocols on\nour dataset. Additionally, we propose an innovative Large Language Model (LLM)\naugmented PAR framework, named LLM-PAR. This framework processes pedestrian\nimages through a Vision Transformer (ViT) backbone to extract features and\nintroduces a multi-embedding query Transformer to learn partial-aware features\nfor attribute classification. Significantly, we enhance this framework with LLM\nfor ensemble learning and visual feature augmentation. Comprehensive\nexperiments across multiple PAR benchmark datasets have thoroughly validated\nthe efficacy of our proposed framework. The dataset and source code\naccompanying this paper will be made publicly available at\n\\url{https://github.com/Event-AHU/OpenPAR}.", "published": "2024-08-19 06:19:31", "link": "http://arxiv.org/abs/2408.09720v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Paired Completion: Flexible Quantification of Issue-framing at Scale\n  with LLMs", "abstract": "Detecting and quantifying issue framing in textual discourse - the\nperspective one takes to a given topic (e.g. climate science vs. denialism,\nmisogyny vs. gender equality) - is highly valuable to a range of end-users from\nsocial and political scientists to program evaluators and policy analysts.\nHowever, conceptual framing is notoriously challenging for automated natural\nlanguage processing (NLP) methods since the words and phrases used by either\n`side' of an issue are often held in common, with only subtle stylistic\nflourishes separating their use. Here we develop and rigorously evaluate new\ndetection methods for issue framing and narrative analysis within large text\ndatasets. By introducing a novel application of next-token log probabilities\nderived from generative large language models (LLMs) we show that issue framing\ncan be reliably and efficiently detected in large corpora with only a few\nexamples of either perspective on a given issue, a method we call `paired\ncompletion'. Through 192 independent experiments over three novel, synthetic\ndatasets, we evaluate paired completion against prompt-based LLM methods and\nlabelled methods using traditional NLP and recent LLM contextual embeddings. We\nadditionally conduct a cost-based analysis to mark out the feasible set of\nperformant methods at production-level scales, and a model bias analysis.\nTogether, our work demonstrates a feasible path to scalable, accurate and\nlow-bias issue-framing in large corpora.", "published": "2024-08-19 07:14:15", "link": "http://arxiv.org/abs/2408.09742v1", "categories": ["cs.CL", "cs.AI", "econ.GN", "q-fin.EC", "I.2.7"], "primary_category": "cs.CL"}
{"title": "R2GenCSR: Retrieving Context Samples for Large Language Model based\n  X-ray Medical Report Generation", "abstract": "Inspired by the tremendous success of Large Language Models (LLMs), existing\nX-ray medical report generation methods attempt to leverage large models to\nachieve better performance. They usually adopt a Transformer to extract the\nvisual features of a given X-ray image, and then, feed them into the LLM for\ntext generation. How to extract more effective information for the LLMs to help\nthem improve final results is an urgent problem that needs to be solved.\nAdditionally, the use of visual Transformer models also brings high\ncomputational complexity. To address these issues, this paper proposes a novel\ncontext-guided efficient X-ray medical report generation framework.\nSpecifically, we introduce the Mamba as the vision backbone with linear\ncomplexity, and the performance obtained is comparable to that of the strong\nTransformer model. More importantly, we perform context retrieval from the\ntraining set for samples within each mini-batch during the training phase,\nutilizing both positively and negatively related samples to enhance feature\nrepresentation and discriminative learning. Subsequently, we feed the vision\ntokens, context information, and prompt statements to invoke the LLM for\ngenerating high-quality medical reports. Extensive experiments on three X-ray\nreport generation datasets (i.e., IU-Xray, MIMIC-CXR, CheXpert Plus) fully\nvalidated the effectiveness of our proposed model. The source code of this work\nwill be released on \\url{https://github.com/Event-AHU/Medical_Image_Analysis}.", "published": "2024-08-19 07:15:11", "link": "http://arxiv.org/abs/2408.09743v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Strategic Demonstration Selection for Improved Fairness in LLM\n  In-Context Learning", "abstract": "Recent studies highlight the effectiveness of using in-context learning (ICL)\nto steer large language models (LLMs) in processing tabular data, a challenging\ntask given the structured nature of such data. Despite advancements in\nperformance, the fairness implications of these methods are less understood.\nThis study investigates how varying demonstrations within ICL prompts influence\nthe fairness outcomes of LLMs. Our findings reveal that deliberately including\nminority group samples in prompts significantly boosts fairness without\nsacrificing predictive accuracy. Further experiments demonstrate that the\nproportion of minority to majority samples in demonstrations affects the\ntrade-off between fairness and prediction accuracy. Based on these insights, we\nintroduce a mitigation technique that employs clustering and evolutionary\nstrategies to curate a diverse and representative sample set from the training\ndata. This approach aims to enhance both predictive performance and fairness in\nICL applications. Experimental results validate that our proposed method\ndramatically improves fairness across various metrics, showing its efficacy in\nreal-world scenarios.", "published": "2024-08-19 07:34:43", "link": "http://arxiv.org/abs/2408.09757v1", "categories": ["cs.LG", "cs.CL", "cs.CY"], "primary_category": "cs.LG"}
{"title": "GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining\n  Automotive Software Release Decision-Making", "abstract": "Traditional methods for making software deployment decisions in the\nautomotive industry typically rely on manual analysis of tabular software test\ndata. These methods often lead to higher costs and delays in the software\nrelease cycle due to their labor-intensive nature. Large Language Models (LLMs)\npresent a promising solution to these challenges. However, their application\ngenerally demands multiple rounds of human-driven prompt engineering, which\nlimits their practical deployment, particularly for industrial end-users who\nneed reliable and efficient results. In this paper, we propose GoNoGo, an LLM\nagent system designed to streamline automotive software deployment while\nmeeting both functional requirements and practical industrial constraints.\nUnlike previous systems, GoNoGo is specifically tailored to address\ndomain-specific and risk-sensitive systems. We evaluate GoNoGo's performance\nacross different task difficulties using zero-shot and few-shot examples taken\nfrom industrial practice. Our results show that GoNoGo achieves a 100% success\nrate for tasks up to Level 2 difficulty with 3-shot examples, and maintains\nhigh performance even for more complex tasks. We find that GoNoGo effectively\nautomates decision-making for simpler tasks, significantly reducing the need\nfor manual intervention. In summary, GoNoGo represents an efficient and\nuser-friendly LLM-based solution currently employed in our industrial partner's\ncompany to assist with software release decision-making, supporting more\ninformed and timely decisions in the release process for risk-sensitive vehicle\nsystems.", "published": "2024-08-19 08:22:20", "link": "http://arxiv.org/abs/2408.09785v2", "categories": ["cs.AI", "cs.CL", "cs.SE"], "primary_category": "cs.AI"}
{"title": "Anim-Director: A Large Multimodal Model Powered Agent for Controllable\n  Animation Video Generation", "abstract": "Traditional animation generation methods depend on training generative models\nwith human-labelled data, entailing a sophisticated multi-stage pipeline that\ndemands substantial human effort and incurs high training costs. Due to limited\nprompting plans, these methods typically produce brief, information-poor, and\ncontext-incoherent animations. To overcome these limitations and automate the\nanimation process, we pioneer the introduction of large multimodal models\n(LMMs) as the core processor to build an autonomous animation-making agent,\nnamed Anim-Director. This agent mainly harnesses the advanced understanding and\nreasoning capabilities of LMMs and generative AI tools to create animated\nvideos from concise narratives or simple instructions. Specifically, it\noperates in three main stages: Firstly, the Anim-Director generates a coherent\nstoryline from user inputs, followed by a detailed director's script that\nencompasses settings of character profiles and interior/exterior descriptions,\nand context-coherent scene descriptions that include appearing characters,\ninteriors or exteriors, and scene events. Secondly, we employ LMMs with the\nimage generation tool to produce visual images of settings and scenes. These\nimages are designed to maintain visual consistency across different scenes\nusing a visual-language prompting method that combines scene descriptions and\nimages of the appearing character and setting. Thirdly, scene images serve as\nthe foundation for producing animated videos, with LMMs generating prompts to\nguide this process. The whole process is notably autonomous without manual\nintervention, as the LMMs interact seamlessly with generative tools to generate\nprompts, evaluate visual quality, and select the best one to optimize the final\noutput.", "published": "2024-08-19 08:27:31", "link": "http://arxiv.org/abs/2408.09787v1", "categories": ["cs.CL", "cs.CV", "cs.MM"], "primary_category": "cs.CL"}
{"title": "MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in\n  Explainable Recommendation", "abstract": "Explainable Recommendation task is designed to receive a pair of user and\nitem and output explanations to justify why an item is recommended to a user.\nMany models treat review-generation as a proxy of explainable recommendation.\nAlthough they are able to generate fluent and grammatical sentences, they\nsuffer from generality and hallucination issues. We propose a personalized,\naspect-controlled model called Multi-Aspect Prompt LEarner (MAPLE), in which it\nintegrates aspect category as another input dimension to facilitate the\nmemorization of fine-grained aspect terms. Experiments on two real-world review\ndatasets in restaurant domain show that MAPLE outperforms the baseline\nreview-generation models in terms of text and feature diversity while\nmaintaining excellent coherence and factual relevance. We further treat MAPLE\nas a retriever component in the retriever-reader framework and employ a\nLarge-Language Model (LLM) as the reader, showing that MAPLE's explanation\nalong with the LLM's comprehension ability leads to enriched and personalized\nexplanation as a result. We will release the code and data in this http upon\nacceptance.", "published": "2024-08-19 10:12:52", "link": "http://arxiv.org/abs/2408.09865v1", "categories": ["cs.LG", "cs.CL", "cs.IR"], "primary_category": "cs.LG"}
{"title": "Docling Technical Report", "abstract": "This technical report introduces Docling, an easy to use, self-contained,\nMIT-licensed open-source package for PDF document conversion. It is powered by\nstate-of-the-art specialized AI models for layout analysis (DocLayNet) and\ntable structure recognition (TableFormer), and runs efficiently on commodity\nhardware in a small resource budget. The code interface allows for easy\nextensibility and addition of new features and models.", "published": "2024-08-19 10:20:06", "link": "http://arxiv.org/abs/2408.09869v5", "categories": ["cs.CL", "cs.CV", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Personalizing Reinforcement Learning from Human Feedback with\n  Variational Preference Learning", "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for\naligning foundation models to human values and preferences. However, current\nRLHF techniques cannot account for the naturally occurring differences in\nindividual human preferences across a diverse population. When these\ndifferences arise, traditional RLHF frameworks simply average over them,\nleading to inaccurate rewards and poor performance for individual subgroups. To\naddress the need for pluralistic alignment, we develop a class of multimodal\nRLHF methods. Our proposed techniques are based on a latent variable\nformulation - inferring a novel user-specific latent and learning reward models\nand policies conditioned on this latent without additional user-specific data.\nWhile conceptually simple, we show that in practice, this reward modeling\nrequires careful algorithmic considerations around model architecture and\nreward scaling. To empirically validate our proposed technique, we first show\nthat it can provide a way to combat underspecification in simulated control\nproblems, inferring and optimizing user-specific reward functions. Next, we\nconduct experiments on pluralistic language datasets representing diverse user\npreferences and demonstrate improved reward function accuracy. We additionally\nshow the benefits of this probabilistic framework in terms of measuring\nuncertainty, and actively learning user preferences. This work enables learning\nfrom diverse populations of users with divergent preferences, an important\nchallenge that naturally occurs in problems from robot learning to foundation\nmodel alignment.", "published": "2024-08-19 15:18:30", "link": "http://arxiv.org/abs/2408.10075v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.RO"], "primary_category": "cs.LG"}
{"title": "Federated Learning of Large ASR Models in the Real World", "abstract": "Federated learning (FL) has shown promising results on training machine\nlearning models with privacy preservation. However, for large models with over\n100 million parameters, the training resource requirement becomes an obstacle\nfor FL because common devices do not have enough memory and computation power\nto finish the FL tasks. Although efficient training methods have been proposed,\nit is still a challenge to train the large models like Conformer based ASR.\nThis paper presents a systematic solution to train the full-size ASR models of\n130M parameters with FL. To our knowledge, this is the first real-world FL\napplication of the Conformer model, which is also the largest model ever\ntrained with FL so far. And this is the first paper showing FL can improve the\nASR model quality with a set of proposed methods to refine the quality of data\nand labels of clients. We demonstrate both the training efficiency and the\nmodel quality improvement in real-world experiments.", "published": "2024-08-19 22:44:10", "link": "http://arxiv.org/abs/2408.10443v1", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Improving embedding with contrastive fine-tuning on small datasets with\n  expert-augmented scores", "abstract": "This paper presents an approach to improve text embedding models through\ncontrastive fine-tuning on small datasets augmented with expert scores. It\nfocuses on enhancing semantic textual similarity tasks and addressing text\nretrieval problems. The proposed method uses soft labels derived from\nexpert-augmented scores to fine-tune embedding models, preserving their\nversatility and ensuring retrieval capability is improved. The paper evaluates\nthe method using a Q\\&A dataset from an online shopping website and eight\nexpert models. Results show improved performance over a benchmark model across\nmultiple metrics on various retrieval tasks from the massive text embedding\nbenchmark (MTEB). The method is cost-effective and practical for real-world\napplications, especially when labeled data is scarce.", "published": "2024-08-19 01:59:25", "link": "http://arxiv.org/abs/2408.11868v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ELDER: Enhancing Lifelong Model Editing with Mixture-of-LoRA", "abstract": "Large language models (LLMs) require model editing to efficiently update\nspecific knowledge within them and avoid factual errors. Most model editing\nmethods are solely designed for single-time use and result in a significant\nforgetting effect in lifelong editing scenarios, where sequential edits are\nconducted over time. Previous approaches manage sequential edits by freezing\noriginal parameters and discretely allocating new parameters for each knowledge\nupdate. However, these methods lack robustness to minor input variations due to\nthe discrete mapping between data and parameters. To overcome this challenge,\nwe propose ELDER, a novel approach to create a continuous association between\ndata and adapters. ELDER integrates multiple LoRAs through a router network and\nis trained to establish a smooth data-adapter association, thereby enhancing\nthe edit robustness and generalization of semantically equivalent inputs. To\nensure inputs containing the same knowledge will be processed by the same\nLoRAs, we design a novel loss to guide the model link LoRA allocations with\nedit knowledge. Furthermore, we propose a deferral mechanism to retain the\noriginal LLM capabilities post-edit. Extensive experiments on GPT-2 XL and\nLLaMA2-7B demonstrate that ELDER effectively edits models in the lifelong\nsetting, outperforming eight baselines while exhibiting strong scalability and\npreserving LLMs' general abilities on downstream tasks. Our code is available\nat https://github.com/JiaangL/ELDER.", "published": "2024-08-19 02:27:00", "link": "http://arxiv.org/abs/2408.11869v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "In-Context Learning with Representations: Contextual Generalization of\n  Trained Transformers", "abstract": "In-context learning (ICL) refers to a remarkable capability of pretrained\nlarge language models, which can learn a new task given a few examples during\ninference. However, theoretical understanding of ICL is largely under-explored,\nparticularly whether transformers can be trained to generalize to unseen\nexamples in a prompt, which will require the model to acquire contextual\nknowledge of the prompt for generalization. This paper investigates the\ntraining dynamics of transformers by gradient descent through the lens of\nnon-linear regression tasks. The contextual generalization here can be attained\nvia learning the template function for each task in-context, where all template\nfunctions lie in a linear space with $m$ basis functions. We analyze the\ntraining dynamics of one-layer multi-head transformers to in-contextly predict\nunlabeled inputs given partially labeled prompts, where the labels contain\nGaussian noise and the number of examples in each prompt are not sufficient to\ndetermine the template. Under mild assumptions, we show that the training loss\nfor a one-layer multi-head transformer converges linearly to a global minimum.\nMoreover, the transformer effectively learns to perform ridge regression over\nthe basis functions. To our knowledge, this study is the first provable\ndemonstration that transformers can learn contextual (i.e., template)\ninformation to generalize to both unseen examples and tasks when prompts\ncontain only a small number of query-answer pairs.", "published": "2024-08-19 16:47:46", "link": "http://arxiv.org/abs/2408.10147v2", "categories": ["cs.LG", "cs.CL", "cs.IT", "math.IT", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Efficient Area-based and Speaker-Agnostic Source Separation", "abstract": "This paper introduces an area-based source separation method designed for\nvirtual meeting scenarios. The aim is to preserve speech signals from an\nunspecified number of sources within a defined spatial area in front of a\nlinear microphone array, while suppressing all other sounds. Therefore, we\nemploy an efficient neural network architecture adapted for multi-channel input\nto encompass the predefined target area. To evaluate the approach, training\ndata and specific test scenarios including multiple target and interfering\nspeakers, as well as background noise are simulated. All models are rated\naccording to DNSMOS and scale-invariant signal-to-distortion ratio. Our\nexperiments show that the proposed method separates speech from multiple\nspeakers within the target area well, besides being of very low complexity,\nintended for real-time processing. In addition, a power reduction heatmap is\nused to demonstrate the networks' ability to identify sources located within\nthe target area. We put our approach in context with a well-established\nbaseline for speaker-speaker separation and discuss its strengths and\nchallenges.", "published": "2024-08-19 09:02:41", "link": "http://arxiv.org/abs/2408.09810v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "ASASVIcomtech: The Vicomtech-UGR Speech Deepfake Detection and SASV\n  Systems for the ASVspoof5 Challenge", "abstract": "This paper presents the work carried out by the ASASVIcomtech team, made up\nof researchers from Vicomtech and University of Granada, for the ASVspoof5\nChallenge. The team has participated in both Track 1 (speech deepfake\ndetection) and Track 2 (spoofing-aware speaker verification). This work started\nwith an analysis of the challenge available data, which was regarded as an\nessential step to avoid later potential biases of the trained models, and whose\nmain conclusions are presented here. With respect to the proposed approaches, a\nclosed-condition system employing a deep complex convolutional recurrent\narchitecture was developed for Track 1, although, unfortunately, no noteworthy\nresults were achieved. On the other hand, different possibilities of\nopen-condition systems, based on leveraging self-supervised models, augmented\ntraining data from previous challenges, and novel vocoders, were explored for\nboth tracks, finally achieving very competitive results with an ensemble\nsystem.", "published": "2024-08-19 18:57:34", "link": "http://arxiv.org/abs/2408.10361v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Unsupervised Composable Representations for Audio", "abstract": "Current generative models are able to generate high-quality artefacts but\nhave been shown to struggle with compositional reasoning, which can be defined\nas the ability to generate complex structures from simpler elements. In this\npaper, we focus on the problem of compositional representation learning for\nmusic data, specifically targeting the fully-unsupervised setting. We propose a\nsimple and extensible framework that leverages an explicit compositional\ninductive bias, defined by a flexible auto-encoding objective that can leverage\nany of the current state-of-art generative models. We demonstrate that our\nframework, used with diffusion models, naturally addresses the task of\nunsupervised audio source separation, showing that our model is able to perform\nhigh-quality separation. Our findings reveal that our proposal achieves\ncomparable or superior performance with respect to other blind source\nseparation methods and, furthermore, it even surpasses current state-of-art\nsupervised baselines on signal-to-interference ratio metrics. Additionally, by\nlearning an a-posteriori masking diffusion model in the space of composable\nrepresentations, we achieve a system capable of seamlessly performing\nunsupervised source separation, unconditional generation, and variation\ngeneration. Finally, as our proposal works in the latent space of pre-trained\nneural audio codecs, it also provides a lower computational cost with respect\nto other neural baselines.", "published": "2024-08-19 08:41:09", "link": "http://arxiv.org/abs/2408.09792v1", "categories": ["cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.LG"}
{"title": "Hear Your Face: Face-based voice conversion with F0 estimation", "abstract": "This paper delves into the emerging field of face-based voice conversion,\nleveraging the unique relationship between an individual's facial features and\ntheir vocal characteristics. We present a novel face-based voice conversion\nframework that particularly utilizes the average fundamental frequency of the\ntarget speaker, derived solely from their facial images. Through extensive\nanalysis, our framework demonstrates superior speech generation quality and the\nability to align facial features with voice characteristics, including tracking\nof the target speaker's fundamental frequency.", "published": "2024-08-19 08:47:03", "link": "http://arxiv.org/abs/2408.09802v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
{"title": "SZU-AFS Antispoofing System for the ASVspoof 5 Challenge", "abstract": "This paper presents the SZU-AFS anti-spoofing system, designed for Track 1 of\nthe ASVspoof 5 Challenge under open conditions. The system is built with four\nstages: selecting a baseline model, exploring effective data augmentation (DA)\nmethods for fine-tuning, applying a co-enhancement strategy based on gradient\nnorm aware minimization (GAM) for secondary fine-tuning, and fusing logits\nscores from the two best-performing fine-tuned models. The system utilizes the\nWav2Vec2 front-end feature extractor and the AASIST back-end classifier as the\nbaseline model. During model fine-tuning, three distinct DA policies have been\ninvestigated: single-DA, random-DA, and cascade-DA. Moreover, the employed\nGAM-based co-enhancement strategy, designed to fine-tune the augmented model at\nboth data and optimizer levels, helps the Adam optimizer find flatter minima,\nthereby boosting model generalization. Overall, the final fusion system\nachieves a minDCF of 0.115 and an EER of 4.04% on the evaluation set.", "published": "2024-08-19 12:12:29", "link": "http://arxiv.org/abs/2408.09933v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Convert and Speak: Zero-shot Accent Conversion with Minimum Supervision", "abstract": "Low resource of parallel data is the key challenge of accent conversion(AC)\nproblem in which both the pronunciation units and prosody pattern need to be\nconverted. We propose a two-stage generative framework \"convert-and-speak\" in\nwhich the conversion is only operated on the semantic token level and the\nspeech is synthesized conditioned on the converted semantic token with a speech\ngenerative model in target accent domain. The decoupling design enables the\n\"speaking\" module to use massive amount of target accent speech and relieves\nthe parallel data required for the \"conversion\" module. Conversion with the\nbridge of semantic token also relieves the requirement for the data with text\ntranscriptions and unlocks the usage of language pre-training technology to\nfurther efficiently reduce the need of parallel accent speech data. To reduce\nthe complexity and latency of \"speaking\", a single-stage AR generative model is\ndesigned to achieve good quality as well as lower computation cost. Experiments\non Indian-English to general American-English conversion show that the proposed\nframework achieves state-of-the-art performance in accent similarity, speech\nquality, and speaker maintenance with only 15 minutes of weakly parallel data\nwhich is not constrained to the same speaker. Extensive experimentation with\ndiverse accent types suggests that this framework possesses a high degree of\nadaptability, making it readily scalable to accommodate other accents with\nlow-resource data. Audio samples are available at\nhttps://www.microsoft.com/en-us/research/project/convert-and-speak-zero-shot-accent-conversion-with-minimumsupervision/.", "published": "2024-08-19 15:33:59", "link": "http://arxiv.org/abs/2408.10096v2", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Advancing Voice Cloning for Nepali: Leveraging Transfer Learning in a\n  Low-Resource Language", "abstract": "Voice cloning is a prominent feature in personalized speech interfaces. A\nneural vocal cloning system can mimic someone's voice using just a few audio\nsamples. Both speaker encoding and speaker adaptation are topics of research in\nthe field of voice cloning. Speaker adaptation relies on fine-tuning a\nmulti-speaker generative model, which involves training a separate model to\ninfer a new speaker embedding used for speaker encoding. Both methods can\nachieve excellent performance, even with a small number of cloning audios, in\nterms of the speech's naturalness and similarity to the original speaker.\nSpeaker encoding approaches are more appropriate for low-resource deployment\nsince they require significantly less memory and have a faster cloning time\nthan speaker adaption, which can offer slightly greater naturalness and\nsimilarity. The main goal is to create a vocal cloning system that produces\naudio output with a Nepali accent or that sounds like Nepali. For the further\nadvancement of TTS, the idea of transfer learning was effectively used to\naddress several issues that were encountered in the development of this system,\nincluding the poor audio quality and the lack of available data.", "published": "2024-08-19 16:15:09", "link": "http://arxiv.org/abs/2408.10128v2", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "91F20", "I.2.7"], "primary_category": "cs.SD"}
{"title": "Meta-Learning in Audio and Speech Processing: An End to End\n  Comprehensive Review", "abstract": "This survey overviews various meta-learning approaches used in audio and\nspeech processing scenarios. Meta-learning is used where model performance\nneeds to be maximized with minimum annotated samples, making it suitable for\nlow-sample audio processing. Although the field has made some significant\ncontributions, audio meta-learning still lacks the presence of comprehensive\nsurvey papers. We present a systematic review of meta-learning methodologies in\naudio processing. This includes audio-specific discussions on data\naugmentation, feature extraction, preprocessing techniques, meta-learners, task\nselection strategies and also presents important datasets in audio, together\nwith crucial real-world use cases. Through this extensive review, we aim to\nprovide valuable insights and identify future research directions in the\nintersection of meta-learning and audio processing.", "published": "2024-08-19 18:11:59", "link": "http://arxiv.org/abs/2408.10330v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "BrewCLIP: A Bifurcated Representation Learning Framework for\n  Audio-Visual Retrieval", "abstract": "Previous methods for audio-image matching generally fall into one of two\ncategories: pipeline models or End-to-End models. Pipeline models first\ntranscribe speech and then encode the resulting text; End-to-End models encode\nspeech directly. Generally, pipeline models outperform end-to-end models, but\nthe intermediate transcription necessarily discards some potentially useful\nnon-textual information. In addition to textual information, speech can convey\ndetails such as accent, mood, and and emphasis, which should be effectively\ncaptured in the encoded representation. In this paper, we investigate whether\nnon-textual information, which is overlooked by pipeline-based models, can be\nleveraged to improve speech-image matching performance. We thoroughly analyze\nand compare End-to-End models, pipeline models, and our proposed dual-channel\nmodel for robust audio-image retrieval on a variety of datasets. Our approach\nachieves a substantial performance gain over the previous state-of-the-art by\nleveraging strong pretrained models, a prompting mechanism and a bifurcated\ndesign.", "published": "2024-08-19 19:56:10", "link": "http://arxiv.org/abs/2408.10383v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Parameter-Efficient Transfer Learning under Federated Learning for\n  Automatic Speech Recognition", "abstract": "This work explores the challenge of enhancing Automatic Speech Recognition\n(ASR) model performance across various user-specific domains while preserving\nuser data privacy. We employ federated learning and parameter-efficient domain\nadaptation methods to solve the (1) massive data requirement of ASR models from\nuser-specific scenarios and (2) the substantial communication cost between\nservers and clients during federated learning. We demonstrate that when\nequipped with proper adapters, ASR models under federated tuning can achieve\nsimilar performance compared with centralized tuning ones, thus providing a\npotential direction for future privacy-preserved ASR services. Besides, we\ninvestigate the efficiency of different adapters and adapter incorporation\nstrategies under the federated learning setting.", "published": "2024-08-19 22:28:20", "link": "http://arxiv.org/abs/2408.11873v1", "categories": ["eess.AS", "cs.CR", "cs.LG"], "primary_category": "eess.AS"}
