{"title": "Are You Looking? Grounding to Multiple Modalities in Vision-and-Language\n  Navigation", "abstract": "Vision-and-Language Navigation (VLN) requires grounding instructions, such as\n\"turn right and stop at the door\", to routes in a visual environment. The\nactual grounding can connect language to the environment through multiple\nmodalities, e.g. \"stop at the door\" might ground into visual objects, while\n\"turn right\" might rely only on the geometric structure of a route. We\ninvestigate where the natural language empirically grounds under two recent\nstate-of-the-art VLN models. Surprisingly, we discover that visual features may\nactually hurt these models: models which only use route structure, ablating\nvisual features, outperform their visual counterparts in unseen new\nenvironments on the benchmark Room-to-Room dataset. To better use all the\navailable modalities, we propose to decompose the grounding procedure into a\nset of expert models with access to different modalities (including object\ndetections) and ensemble them at prediction time, improving the performance of\nstate-of-the-art models on the VLN task.", "published": "2019-06-02 05:16:06", "link": "http://arxiv.org/abs/1906.00347v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Adaptation of Neural Machine Translation by Lexicon Induction", "abstract": "It has been previously noted that neural machine translation (NMT) is very\nsensitive to domain shift. In this paper, we argue that this is a dual effect\nof the highly lexicalized nature of NMT, resulting in failure for sentences\nwith large numbers of unknown words, and lack of supervision for\ndomain-specific words. To remedy this problem, we propose an unsupervised\nadaptation method which fine-tunes a pre-trained out-of-domain NMT model using\na pseudo-in-domain corpus. Specifically, we perform lexicon induction to\nextract an in-domain lexicon, and construct a pseudo-parallel in-domain corpus\nby performing word-for-word back-translation of monolingual in-domain target\nsentences. In five domains over twenty pairwise adaptation settings and two\nmodel architectures, our method achieves consistent improvements without using\nany in-domain parallel sentences, improving up to 14 BLEU over unadapted\nmodels, and up to 2 BLEU over strong back-translation baselines.", "published": "2019-06-02 09:50:12", "link": "http://arxiv.org/abs/1906.00376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Domain Adaptive Inference for Neural Machine Translation", "abstract": "We investigate adaptive ensemble weighting for Neural Machine Translation,\naddressing the case of improving performance on a new and potentially unknown\ndomain without sacrificing performance on the original domain. We adapt\nsequentially across two Spanish-English and three English-German tasks,\ncomparing unregularized fine-tuning, L2 and Elastic Weight Consolidation. We\nthen report a novel scheme for adaptive NMT ensemble decoding by extending\nBayesian Interpolation with source information, and show strong improvements\nacross test domains without access to the domain label.", "published": "2019-06-02 14:00:05", "link": "http://arxiv.org/abs/1906.00408v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Plain English Summarization of Contracts", "abstract": "Unilateral contracts, such as terms of service, play a substantial role in\nmodern digital life. However, few users read these documents before accepting\nthe terms within, as they are too long and the language too complicated. We\npropose the task of summarizing such legal documents in plain English, which\nwould enable users to have a better understanding of the terms they are\naccepting.\n  We propose an initial dataset of legal text snippets paired with summaries\nwritten in plain English. We verify the quality of these summaries manually and\nshow that they involve heavy abstraction, compression, and simplification.\nInitial experiments show that unsupervised extractive summarization methods do\nnot perform well on this task due to the level of abstraction and style\ndifferences. We conclude with a call for resource and technique development for\nsimplification and style transfer for legal language.", "published": "2019-06-02 15:27:51", "link": "http://arxiv.org/abs/1906.00424v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A Survey of Natural Language Generation Techniques with a Focus on\n  Dialogue Systems - Past, Present and Future Directions", "abstract": "One of the hardest problems in the area of Natural Language Processing and\nArtificial Intelligence is automatically generating language that is coherent\nand understandable to humans. Teaching machines how to converse as humans do\nfalls under the broad umbrella of Natural Language Generation. Recent years\nhave seen unprecedented growth in the number of research articles published on\nthis subject in conferences and journals both by academic and industry\nresearchers. There have also been several workshops organized alongside\ntop-tier NLP conferences dedicated specifically to this problem. All this\nactivity makes it hard to clearly define the state of the field and reason\nabout its future directions. In this work, we provide an overview of this\nimportant and thriving area, covering traditional approaches, statistical\napproaches and also approaches that use deep neural networks. We provide a\ncomprehensive review towards building open domain dialogue systems, an\nimportant application of natural language generation. We find that,\npredominantly, the approaches for building dialogue systems use seq2seq or\nlanguage models architecture. Notably, we identify three important areas of\nfurther research towards building more effective dialogue systems: 1)\nincorporating larger context, including conversation context and world\nknowledge; 2) adding personae or personality in the NLG system; and 3)\novercoming dull and generic responses that affect the quality of\nsystem-produced responses. We provide pointers on how to tackle these open\nproblems through the use of cognitive architectures that mimic human language\nunderstanding and generation capabilities.", "published": "2019-06-02 22:55:14", "link": "http://arxiv.org/abs/1906.00500v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Question Answering as an Automatic Evaluation Metric for News Article\n  Summarization", "abstract": "Recent work in the field of automatic summarization and headline generation\nfocuses on maximizing ROUGE scores for various news datasets. We present an\nalternative, extrinsic, evaluation metric for this task, Answering Performance\nfor Evaluation of Summaries. APES utilizes recent progress in the field of\nreading-comprehension to quantify the ability of a summary to answer a set of\nmanually created questions regarding central entities in the source article. We\nfirst analyze the strength of this metric by comparing it to known manual\nevaluation metrics. We then present an end-to-end neural abstractive model that\nmaximizes APES, while increasing ROUGE scores to competitive results.", "published": "2019-06-02 00:29:05", "link": "http://arxiv.org/abs/1906.00318v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Does It Make Sense? And Why? A Pilot Study for Sense Making and\n  Explanation", "abstract": "Introducing common sense to natural language understanding systems has\nreceived increasing research attention. It remains a fundamental question on\nhow to evaluate whether a system has a sense making capability. Existing\nbenchmarks measures commonsense knowledge indirectly and without explanation.\nIn this paper, we release a benchmark to directly test whether a system can\ndifferentiate natural language statements that make sense from those that do\nnot make sense. In addition, a system is asked to identify the most crucial\nreason why a statement does not make sense. We evaluate models trained over\nlarge-scale language modeling tasks as well as human performance, showing that\nthere are different challenges for system sense making.", "published": "2019-06-02 08:03:21", "link": "http://arxiv.org/abs/1906.00363v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Unsupervised Bilingual Lexicon Induction from Mono-lingual Multimodal\n  Data", "abstract": "Bilingual lexicon induction, translating words from the source language to\nthe target language, is a long-standing natural language processing task.\nRecent endeavors prove that it is promising to employ images as pivot to learn\nthe lexicon induction without reliance on parallel corpora. However, these\nvision-based approaches simply associate words with entire images, which are\nconstrained to translate concrete words and require object-centered images. We\nhumans can understand words better when they are within a sentence with\ncontext. Therefore, in this paper, we propose to utilize images and their\nassociated captions to address the limitations of previous approaches. We\npropose a multi-lingual caption model trained with different mono-lingual\nmultimodal data to map words in different languages into joint spaces. Two\ntypes of word representation are induced from the multi-lingual caption model:\nlinguistic features and localized visual features. The linguistic feature is\nlearned from the sentence contexts with visual semantic constraints, which is\nbeneficial to learn translation for words that are less visual-relevant. The\nlocalized visual feature is attended to the region in the image that correlates\nto the word, so that it alleviates the image restriction for salient visual\nrepresentation. The two types of features are complementary for word\ntranslation. Experimental results on multiple language pairs demonstrate the\neffectiveness of our proposed method, which substantially outperforms previous\nvision-based approaches without using any parallel sentences or supervision of\nseed word pairs.", "published": "2019-06-02 10:05:26", "link": "http://arxiv.org/abs/1906.00378v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "TechNet: Technology Semantic Network Based on Patent Data", "abstract": "The growing developments in general semantic networks, knowledge graphs and\nontology databases have motivated us to build a large-scale comprehensive\nsemantic network of technology-related data for engineering knowledge\ndiscovery, technology search and retrieval, and artificial intelligence for\nengineering design and innovation. Specially, we constructed a technology\nsemantic network (TechNet) that covers the elemental concepts in all domains of\ntechnology and their semantic associations by mining the complete U.S. patent\ndatabase from 1976. To derive the TechNet, natural language processing\ntechniques were utilized to extract terms from massive patent texts and recent\nword embedding algorithms were employed to vectorize such terms and establish\ntheir semantic relationships. We report and evaluate the TechNet for retrieving\nterms and their pairwise relevance that is meaningful from a technology and\nengineering design perspective. The TechNet may serve as an infrastructure to\nsupport a wide range of applications, e.g., technical text summaries, search\nquery predictions, relational knowledge discovery, and design ideation support,\nin the context of engineering and technology, and complement or enrich existing\nsemantic databases. To enable such applications, the TechNet is made public via\nan online interface and APIs for public users to retrieve technology-related\nterms and their relevancies.", "published": "2019-06-02 14:11:37", "link": "http://arxiv.org/abs/1906.00411v4", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Pretraining Methods for Dialog Context Representation Learning", "abstract": "This paper examines various unsupervised pretraining objectives for learning\ndialog context representations. Two novel methods of pretraining dialog context\nencoders are proposed, and a total of four methods are examined. Each\npretraining objective is fine-tuned and evaluated on a set of downstream dialog\ntasks using the MultiWoz dataset and strong performance improvement is\nobserved. Further evaluation shows that our pretraining objectives result in\nnot only better performance, but also better convergence, models that are less\ndata hungry and have better domain generalizability.", "published": "2019-06-02 14:57:25", "link": "http://arxiv.org/abs/1906.00414v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Deep Unknown Intent Detection with Margin Loss", "abstract": "Identifying the unknown (novel) user intents that have never appeared in the\ntraining set is a challenging task in the dialogue system. In this paper, we\npresent a two-stage method for detecting unknown intents. We use bidirectional\nlong short-term memory (BiLSTM) network with the margin loss as the feature\nextractor. With margin loss, we can learn discriminative deep features by\nforcing the network to maximize inter-class variance and to minimize\nintra-class variance. Then, we feed the feature vectors to the density-based\nnovelty detection algorithm, local outlier factor (LOF), to detect unknown\nintents. Experiments on two benchmark datasets show that our method can yield\nconsistent improvements compared with the baseline methods.", "published": "2019-06-02 16:14:46", "link": "http://arxiv.org/abs/1906.00434v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Pre-training of Graph Augmented Transformers for Medication\n  Recommendation", "abstract": "Medication recommendation is an important healthcare application. It is\ncommonly formulated as a temporal prediction task. Hence, most existing works\nonly utilize longitudinal electronic health records (EHRs) from a small number\nof patients with multiple visits ignoring a large number of patients with a\nsingle visit (selection bias). Moreover, important hierarchical knowledge such\nas diagnosis hierarchy is not leveraged in the representation learning process.\nTo address these challenges, we propose G-BERT, a new model to combine the\npower of Graph Neural Networks (GNNs) and BERT (Bidirectional Encoder\nRepresentations from Transformers) for medical code representation and\nmedication recommendation. We use GNNs to represent the internal hierarchical\nstructures of medical codes. Then we integrate the GNN representation into a\ntransformer-based visit encoder and pre-train it on EHR data from patients only\nwith a single visit. The pre-trained visit encoder and representation are then\nfine-tuned for downstream predictive tasks on longitudinal EHRs from patients\nwith multiple visits. G-BERT is the first to bring the language model\npre-training schema into the healthcare domain and it achieved state-of-the-art\nperformance on the medication recommendation task.", "published": "2019-06-02 05:11:38", "link": "http://arxiv.org/abs/1906.00346v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Budgeted Policy Learning for Task-Oriented Dialogue Systems", "abstract": "This paper presents a new approach that extends Deep Dyna-Q (DDQ) by\nincorporating a Budget-Conscious Scheduling (BCS) to best utilize a fixed,\nsmall amount of user interactions (budget) for learning task-oriented dialogue\nagents. BCS consists of (1) a Poisson-based global scheduler to allocate budget\nover different stages of training; (2) a controller to decide at each training\nstep whether the agent is trained using real or simulated experiences; (3) a\nuser goal sampling module to generate the experiences that are most effective\nfor policy learning. Experiments on a movie-ticket booking task with simulated\nand real users show that our approach leads to significant improvements in\nsuccess rate over the state-of-the-art baselines given the fixed budget.", "published": "2019-06-02 22:53:33", "link": "http://arxiv.org/abs/1906.00499v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
{"title": "An acoustic model of a Helmholtz resonator under a grazing turbulent\n  boundary layer", "abstract": "Acoustic models of resonant duct systems with turbulent flow depend on fitted\nconstants based on expensive experimental test series. We introduce a new model\nof a resonant cavity, flush mounted in a duct or flat plate, under grazing\nturbulent flow. Based on previous work by Goody, Howe and Golliard, we present\na more universal model where the constants are replaced by physically\nsignificant parameters. This enables the user to understand and to trace back\nhow a modification of design parameters (geometry, fluid condition) will affect\nacoustic properties. The derivation of the model is supported by a detailed\nthree-dimensional direct numerical simulation as well as an experimental test\nseries. We show that the model is valid for low Mach number flows (M =\n0.01-0.14) and for low frequencies (below higher transverse cavity modes).\nHence, within this range, no expensive simulation or experiment is needed any\nlonger to predict the sound spectrum. In principle, the model is applicable to\narbitrary geometries: Just the provided definitions need to be applied to\nupdate the significant parameters. Utilizing the lumped-element method, the\nmodel consists of exchangeable elements and guarantees a flexible use. Even\nthough the model is linear, resonance conditions between acoustic cavity modes\nand fluid dynamic unstable modes are correctly predicted.", "published": "2019-06-02 00:41:01", "link": "http://arxiv.org/abs/1906.00319v1", "categories": ["physics.flu-dyn", "cs.SD", "eess.AS", "physics.comp-ph", "76F65, 76F10, 76F40, 76G25"], "primary_category": "physics.flu-dyn"}
