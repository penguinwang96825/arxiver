{"title": "What Does the Indian Parliament Discuss? An Exploratory Analysis of the\n  Question Hour in the Lok Sabha", "abstract": "The TCPD-IPD dataset is a collection of questions and answers discussed in\nthe Lower House of the Parliament of India during the Question Hour between\n1999 and 2019. Although it is difficult to analyze such a huge collection\nmanually, modern text analysis tools can provide a powerful means to navigate\nit. In this paper, we perform an exploratory analysis of the dataset. In\nparticular, we present insightful corpus-level statistics and a detailed\nanalysis of three subsets of the dataset. In the latter analysis, the focus is\non understanding the temporal evolution of topics using a dynamic topic model.\nWe observe that the parliamentary conversation indeed mirrors the political and\nsocio-economic tensions of each period.", "published": "2023-04-01 05:43:22", "link": "http://arxiv.org/abs/2304.00235v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Crowd Meets Persona: Creating a Large-Scale Open-Domain Persona\n  Dialogue Corpus", "abstract": "Building a natural language dataset requires caution since word semantics is\nvulnerable to subtle text change or the definition of the annotated concept.\nSuch a tendency can be seen in generative tasks like question-answering and\ndialogue generation and also in tasks that create a categorization-based\ncorpus, like topic classification or sentiment analysis. Open-domain\nconversations involve two or more crowdworkers freely conversing about any\ntopic, and collecting such data is particularly difficult for two reasons: 1)\nthe dataset should be ``crafted\" rather than ``obtained\" due to privacy\nconcerns, and 2) paid creation of such dialogues may differ from how\ncrowdworkers behave in real-world settings. In this study, we tackle these\nissues when creating a large-scale open-domain persona dialogue corpus, where\npersona implies that the conversation is performed by several actors with a\nfixed persona and user-side workers from an unspecified crowd.", "published": "2023-04-01 16:10:36", "link": "http://arxiv.org/abs/2304.00350v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Automatic Authorship Attribution in the Work of Tirso de Molina", "abstract": "Automatic Authorship Attribution (AAA) is the result of applying tools and\ntechniques from Digital Humanities to authorship attribution studies. Through a\nquantitative and statistical approach this discipline can draw further\nconclusions about renowned authorship issues which traditional critics have\nbeen dealing with for centuries, opening a new door to style comparison. The\naim of this paper is to prove the potential of these tools and techniques by\ntesting the authorship of five comedies traditionally attributed to Spanish\nplaywright Tirso de Molina (1579-1648): La ninfa del cielo, El burlador de\nSevilla, Tan largo me lo fiais, La mujer por fuerza and El condenado por\ndesconfiado. To accomplish this purpose some experiments concerning clustering\nanalysis by Stylo package from R and four distance measures are carried out on\na corpus built with plays by Tirso, Andres de Claramonte (c. 1560-1626),\nAntonio Mira de Amescua (1577-1644) and Luis Velez de Guevara (1579-1644). The\nresults obtained point to the denial of all the attributions to Tirso except\nfor the case of La mujer por fuerza.", "published": "2023-04-01 18:05:14", "link": "http://arxiv.org/abs/2304.00363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Inductive Relation Prediction from Relational Paths and Context with\n  Hierarchical Transformers", "abstract": "Relation prediction on knowledge graphs (KGs) is a key research topic.\nDominant embedding-based methods mainly focus on the transductive setting and\nlack the inductive ability to generalize to new entities for inference.\nExisting methods for inductive reasoning mostly mine the connections between\nentities, i.e., relational paths, without considering the nature of head and\ntail entities contained in the relational context. This paper proposes a novel\nmethod that captures both connections between entities and the intrinsic nature\nof entities, by simultaneously aggregating RElational Paths and cOntext with a\nunified hieRarchical Transformer framework, namely REPORT. REPORT relies solely\non relation semantics and can naturally generalize to the fully-inductive\nsetting, where KGs for training and inference have no common entities. In the\nexperiments, REPORT performs consistently better than all baselines on almost\nall the eight version subsets of two fully-inductive datasets. Moreover. REPORT\nis interpretable by providing each element's contribution to the prediction\nresults.", "published": "2023-04-01 03:49:47", "link": "http://arxiv.org/abs/2304.00215v3", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Accuracy and Political Bias of News Source Credibility Ratings by Large\n  Language Models", "abstract": "Search engines increasingly leverage large language models (LLMs) to generate\ndirect answers, and AI chatbots now access the Internet for fresh data. As\ninformation curators for billions of users, LLMs must assess the accuracy and\nreliability of different sources. This paper audits nine widely used LLMs from\nthree leading providers -- OpenAI, Google, and Meta -- to evaluate their\nability to discern credible and high-quality information sources from\nlow-credibility ones. We find that while LLMs can rate most tested news\noutlets, larger models more frequently refuse to provide ratings due to\ninsufficient information, whereas smaller models are more prone to making\nerrors in their ratings. For sources where ratings are provided, LLMs exhibit a\nhigh level of agreement among themselves (average Spearman's $\\rho = 0.79$),\nbut their ratings align only moderately with human expert evaluations (average\n$\\rho = 0.50$). Analyzing news sources with different political leanings in the\nUS, we observe a liberal bias in credibility ratings yielded by all LLMs in\ndefault configurations. Additionally, assigning partisan roles to LLMs\nconsistently induces strong politically congruent bias in their ratings. These\nfindings have important implications for the use of LLMs in curating news and\npolitical information.", "published": "2023-04-01 05:04:06", "link": "http://arxiv.org/abs/2304.00228v3", "categories": ["cs.CL", "cs.CY", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Evaluating Large Language Models on a Highly-specialized Topic,\n  Radiation Oncology Physics", "abstract": "We present the first study to investigate Large Language Models (LLMs) in\nanswering radiation oncology physics questions. Because popular exams like AP\nPhysics, LSAT, and GRE have large test-taker populations and ample test\npreparation resources in circulation, they may not allow for accurately\nassessing the true potential of LLMs. This paper proposes evaluating LLMs on a\nhighly-specialized topic, radiation oncology physics, which may be more\npertinent to scientific and medical communities in addition to being a valuable\nbenchmark of LLMs. We developed an exam consisting of 100 radiation oncology\nphysics questions based on our expertise at Mayo Clinic. Four LLMs, ChatGPT\n(GPT-3.5), ChatGPT (GPT-4), Bard (LaMDA), and BLOOMZ, were evaluated against\nmedical physicists and non-experts. ChatGPT (GPT-4) outperformed all other LLMs\nas well as medical physicists, on average. The performance of ChatGPT (GPT-4)\nwas further improved when prompted to explain first, then answer. ChatGPT\n(GPT-3.5 and GPT-4) showed a high level of consistency in its answer choices\nacross a number of trials, whether correct or incorrect, a characteristic that\nwas not observed in the human test groups. In evaluating ChatGPTs (GPT-4)\ndeductive reasoning ability using a novel approach (substituting the correct\nanswer with \"None of the above choices is the correct answer.\"), ChatGPT\n(GPT-4) demonstrated surprising accuracy, suggesting the potential presence of\nan emergent ability. Finally, although ChatGPT (GPT-4) performed well overall,\nits intrinsic properties did not allow for further improvement when scoring\nbased on a majority vote across trials. In contrast, a team of medical\nphysicists were able to greatly outperform ChatGPT (GPT-4) using a majority\nvote. This study suggests a great potential for LLMs to work alongside\nradiation oncology experts as highly knowledgeable assistants.", "published": "2023-04-01 06:04:58", "link": "http://arxiv.org/abs/2304.01938v1", "categories": ["physics.med-ph", "cs.CL", "physics.ed-ph"], "primary_category": "physics.med-ph"}
{"title": "From Smart to Intelligent Utility Meters in Natural Gas Distribution\n  Networks", "abstract": "We propose a novel method for monitoring gas distribution networks (GDNs)\nusing intelligent sensor nodes that can be integrated with existing smart gas\nmeters (intelligent meters). The method aims at detecting and locating gas\nleaks in GDNs in real time. The intelligent meters leverage wireless\nconnectivity in existing smart meters to collaborate in implementing this\nmethod, which comprises an active acoustic probing phase and a passive linear\nimaging phase. In the active acoustic phase, the intelligent meters\ncollaboratively discover the topology of the monitored pipeline network using a\nnovel acoustic pulse reflectometry technique. In the passive linear imaging\nphase, the intelligent meters use their knowledge of the pipeline network\ntopology to create a linear image of the pipeline using the Time-Exposure\nAcoustic (TEA) algorithm. The resulting image reveals the presence and\nlocations of active gas leaks in the network. We present the theoretical basis\nof the method and show results of implementing it on experimental data\ncollected in the lab.", "published": "2023-04-01 07:59:12", "link": "http://arxiv.org/abs/2304.00251v1", "categories": ["eess.SP", "eess.AS"], "primary_category": "eess.SP"}
