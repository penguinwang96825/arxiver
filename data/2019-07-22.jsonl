{"title": "ELI5: Long Form Question Answering", "abstract": "We introduce the first large-scale corpus for long-form question answering, a\ntask requiring elaborate and in-depth answers to open-ended questions. The\ndataset comprises 270K threads from the Reddit forum ``Explain Like I'm Five''\n(ELI5) where an online community provides answers to questions which are\ncomprehensible by five year olds. Compared to existing datasets, ELI5 comprises\ndiverse questions requiring multi-sentence answers. We provide a large set of\nweb documents to help answer the question. Automatic and human evaluations show\nthat an abstractive model trained with a multi-task objective outperforms\nconventional Seq2Seq, language modeling, as well as a strong extractive\nbaseline. However, our best model is still far from human performance since\nraters prefer gold responses in over 86% of cases, leaving ample opportunity\nfor future improvement.", "published": "2019-07-22 09:01:35", "link": "http://arxiv.org/abs/1907.09190v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Syntax-aware Neural Semantic Role Labeling", "abstract": "Semantic role labeling (SRL), also known as shallow semantic parsing, is an\nimportant yet challenging task in NLP. Motivated by the close correlation\nbetween syntactic and semantic structures, traditional discrete-feature-based\nSRL approaches make heavy use of syntactic features. In contrast,\ndeep-neural-network-based approaches usually encode the input sentence as a\nword sequence without considering the syntactic structures. In this work, we\ninvestigate several previous approaches for encoding syntactic trees, and make\na thorough study on whether extra syntax-aware representations are beneficial\nfor neural SRL models. Experiments on the benchmark CoNLL-2005 dataset show\nthat syntax-aware SRL approaches can effectively improve performance over a\nstrong baseline with external word representations from ELMo. With the extra\nsyntax-aware representations, our approaches achieve new state-of-the-art 85.6\nF1 (single model) and 86.6 F1 (ensemble) on the test data, outperforming the\ncorresponding strong baselines with ELMo by 0.8 and 1.0, respectively. Detailed\nerror analysis are conducted to gain more insights on the investigated\napproaches.", "published": "2019-07-22 13:25:27", "link": "http://arxiv.org/abs/1907.09312v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning dynamic word embeddings with drift regularisation", "abstract": "Word usage, meaning and connotation change throughout time. Diachronic word\nembeddings are used to grasp these changes in an unsupervised way. In this\npaper, we use variants of the Dynamic Bernoulli Embeddings model to learn\ndynamic word embeddings, in order to identify notable properties of the model.\nThe comparison is made on the New York Times Annotated Corpus in English and a\nset of articles from the French newspaper Le Monde covering the same period.\nThis allows us to define a pipeline to analyse the evolution of words use\nacross two languages.", "published": "2019-07-22 07:44:09", "link": "http://arxiv.org/abs/1907.09169v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Why Build an Assistant in Minecraft?", "abstract": "In this document we describe a rationale for a research program aimed at\nbuilding an open \"assistant\" in the game Minecraft, in order to make progress\non the problems of natural language understanding and learning from dialogue.", "published": "2019-07-22 12:32:15", "link": "http://arxiv.org/abs/1907.09273v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "SlugBot: Developing a Computational Model andFramework of a Novel\n  Dialogue Genre", "abstract": "One of the most interesting aspects of the Amazon Alexa Prize competition is\nthat the framing of the competition requires the development of new\ncomputational models of dialogue and its structure. Traditional computational\nmodels of dialogue are of two types: (1) task-oriented dialogue, supported by\nAI planning models,or simplified planning models consisting of frames with\nslots to be filled; or (2)search-oriented dialogue where every user turn is\ntreated as a search query that may elaborate and extend current search results.\nAlexa Prize dialogue systems such as SlugBot must support conversational\ncapabilities that go beyond what these traditional models can do. Moreover,\nwhile traditional dialogue systems rely on theoretical computational models,\nthere are no existing computational theories that circumscribe the expected\nsystem and user behaviors in the intended conversational genre of the Alexa\nPrize Bots. This paper describes how UCSC's SlugBot team has combined the\ndevelopment of a novel computational theoretical model, Discourse Relation\nDialogue Model, with its implementation in a modular system in order to test\nand refine it. We highlight how our novel dialogue model has led us to create a\nnovel ontological resource, UniSlug, and how the structure of UniSlug determine\nshow we curate and structure content so that our dialogue manager implements\nand tests our novel computational dialogue model.", "published": "2019-07-22 21:16:58", "link": "http://arxiv.org/abs/1907.10658v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "Sparsity Emerges Naturally in Neural Language Models", "abstract": "Concerns about interpretability, computational resources, and principled\ninductive priors have motivated efforts to engineer sparse neural models for\nNLP tasks. If sparsity is important for NLP, might well-trained neural models\nnaturally become roughly sparse? Using the Taxi-Euclidean norm to measure\nsparsity, we find that frequent input words are associated with concentrated or\nsparse activations, while frequent target words are associated with dispersed\nactivations but concentrated gradients. We find that gradients associated with\nfunction words are more concentrated than the gradients of content words, even\ncontrolling for word frequency.", "published": "2019-07-22 14:06:15", "link": "http://arxiv.org/abs/1908.01817v1", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "GEAR: Graph-based Evidence Aggregating and Reasoning for Fact\n  Verification", "abstract": "Fact verification (FV) is a challenging task which requires to retrieve\nrelevant evidence from plain text and use the evidence to verify given claims.\nMany claims require to simultaneously integrate and reason over several pieces\nof evidence for verification. However, previous work employs simple models to\nextract information from evidence without letting evidence communicate with\neach other, e.g., merely concatenate the evidence for processing. Therefore,\nthese methods are unable to grasp sufficient relational and logical information\namong the evidence. To alleviate this issue, we propose a graph-based evidence\naggregating and reasoning (GEAR) framework which enables information to\ntransfer on a fully-connected evidence graph and then utilizes different\naggregators to collect multi-evidence information. We further employ BERT, an\neffective pre-trained language representation model, to improve the\nperformance. Experimental results on a large-scale benchmark dataset FEVER have\ndemonstrated that GEAR could leverage multi-evidence information for FV and\nthus achieves the promising result with a test FEVER score of 67.10%. Our code\nis available at https://github.com/thunlp/GEAR.", "published": "2019-07-22 08:25:16", "link": "http://arxiv.org/abs/1908.01843v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Generating Sentiment-Preserving Fake Online Reviews Using Neural\n  Language Models and Their Human- and Machine-based Detection", "abstract": "Advanced neural language models (NLMs) are widely used in sequence generation\ntasks because they are able to produce fluent and meaningful sentences. They\ncan also be used to generate fake reviews, which can then be used to attack\nonline review systems and influence the buying decisions of online shoppers. To\nperform such attacks, it is necessary for experts to train a tailored LM for a\nspecific topic. In this work, we show that a low-skilled threat model can be\nbuilt just by combining publicly available LMs and show that the produced fake\nreviews can fool both humans and machines. In particular, we use the GPT-2 NLM\nto generate a large number of high-quality reviews based on a review with the\ndesired sentiment and then using a BERT based text classifier (with accuracy of\n96%) to filter out reviews with undesired sentiments. Because none of the words\nin the review are modified, fluent samples like the training data can be\ngenerated from the learned distribution. A subjective evaluation with 80\nparticipants demonstrated that this simple method can produce reviews that are\nas fluent as those written by people. It also showed that the participants\ntended to distinguish fake reviews randomly. Three countermeasures, Grover,\nGLTR, and OpenAI GPT-2 detector, were found to be difficult to accurately\ndetect fake review.", "published": "2019-07-22 08:22:08", "link": "http://arxiv.org/abs/1907.09177v2", "categories": ["cs.CL", "cs.CR", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "VIFIDEL: Evaluating the Visual Fidelity of Image Descriptions", "abstract": "We address the task of evaluating image description generation systems. We\npropose a novel image-aware metric for this task: VIFIDEL. It estimates the\nfaithfulness of a generated caption with respect to the content of the actual\nimage, based on the semantic similarity between labels of objects depicted in\nimages and words in the description. The metric is also able to take into\naccount the relative importance of objects mentioned in human reference\ndescriptions during evaluation. Even if these human reference descriptions are\nnot available, VIFIDEL can still reliably evaluate system descriptions. The\nmetric achieves high correlation with human judgments on two well-known\ndatasets and is competitive with metrics that depend on human references", "published": "2019-07-22 14:33:43", "link": "http://arxiv.org/abs/1907.09340v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Trends in Integration of Vision and Language Research: A Survey of\n  Tasks, Datasets, and Methods", "abstract": "Interest in Artificial Intelligence (AI) and its applications has seen\nunprecedented growth in the last few years. This success can be partly\nattributed to the advancements made in the sub-fields of AI such as machine\nlearning, computer vision, and natural language processing. Much of the growth\nin these fields has been made possible with deep learning, a sub-area of\nmachine learning that uses artificial neural networks. This has created\nsignificant interest in the integration of vision and language. In this survey,\nwe focus on ten prominent tasks that integrate language and vision by\ndiscussing their problem formulation, methods, existing datasets, evaluation\nmeasures, and compare the results obtained with corresponding state-of-the-art\nmethods. Our efforts go beyond earlier surveys which are either task-specific\nor concentrate only on one type of visual content, i.e., image or video.\nFurthermore, we also provide some potential future directions in this field of\nresearch with an anticipation that this survey stimulates innovative thoughts\nand ideas to address the existing challenges and build new applications.", "published": "2019-07-22 14:53:48", "link": "http://arxiv.org/abs/1907.09358v3", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Introduction to Neural Network based Approaches for Question Answering\n  over Knowledge Graphs", "abstract": "Question answering has emerged as an intuitive way of querying structured\ndata sources, and has attracted significant advancements over the years. In\nthis article, we provide an overview over these recent advancements, focusing\non neural network based question answering systems over knowledge graphs. We\nintroduce readers to the challenges in the tasks, current paradigms of\napproaches, discuss notable advancements, and outline the emerging trends in\nthe field. Through this article, we aim to provide newcomers to the field with\na suitable entry point, and ease their process of making informed decisions\nwhile creating their own QA system.", "published": "2019-07-22 14:57:13", "link": "http://arxiv.org/abs/1907.09361v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Emotion Detection in Text: Focusing on Latent Representation", "abstract": "In recent years, emotion detection in text has become more popular due to its\nvast potential applications in marketing, political science, psychology,\nhuman-computer interaction, artificial intelligence, etc. In this work, we\nargue that current methods which are based on conventional machine learning\nmodels cannot grasp the intricacy of emotional language by ignoring the\nsequential nature of the text, and the context. These methods, therefore, are\nnot sufficient to create an applicable and generalizable emotion detection\nmethodology. Understanding these limitations, we present a new network based on\na bidirectional GRU model to show that capturing more meaningful information\nfrom text can significantly improve the performance of these models. The\nresults show significant improvement with an average of 26.8 point increase in\nF-measure on our test data and 38.6 increase on the totally new dataset.", "published": "2019-07-22 15:33:53", "link": "http://arxiv.org/abs/1907.09369v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Maximizing Stylistic Control and Semantic Accuracy in NLG: Personality\n  Variation and Discourse Contrast", "abstract": "Neural generation methods for task-oriented dialogue typically generate from\na meaning representation that is populated using a database of domain\ninformation, such as a table of data describing a restaurant. While earlier\nwork focused solely on the semantic fidelity of outputs, recent work has\nstarted to explore methods for controlling the style of the generated text\nwhile simultaneously achieving semantic accuracy. Here we experiment with two\nstylistic benchmark tasks, generating language that exhibits variation in\npersonality, and generating discourse contrast. We report a huge performance\nimprovement in both stylistic control and semantic accuracy over the state of\nthe art on both of these benchmarks. We test several different models and show\nthat putting stylistic conditioning in the decoder and eliminating the semantic\nre-ranker used in earlier models results in more than 15 points higher BLEU for\nPersonality, with a reduction of semantic error to near zero. We also report an\nimprovement from .75 to .81 in controlling contrast and a reduction in semantic\nerror from 16% to 2%.", "published": "2019-07-22 18:57:14", "link": "http://arxiv.org/abs/1907.09527v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluation of Embeddings of Laboratory Test Codes for Patients at a\n  Cancer Center", "abstract": "Laboratory test results are an important and generally high dimensional\ncomponent of a patient's Electronic Health Record (EHR). We train embedding\nrepresentations (via Word2Vec and GloVe) for LOINC codes of laboratory tests\nfrom the EHRs of about 80,000 patients at a cancer center. To include\ninformation about lab test outcomes, we also train embeddings on the\nconcatenation of a LOINC code with a symbol indicating normality or abnormality\nof the result. We observe several clinically meaningful similarities among\nLOINC embeddings trained over our data. For the embeddings of the concatenation\nof LOINCs with abnormality codes, we evaluate the performance for mortality\nprediction tasks and the ability to preserve ordinality properties: i.e. a lab\ntest with normal outcome should be more similar to an abnormal one than to the\na very abnormal one.", "published": "2019-07-22 21:58:40", "link": "http://arxiv.org/abs/1907.09600v2", "categories": ["cs.LG", "cs.CL", "cs.CY", "stat.ML"], "primary_category": "cs.LG"}
{"title": "On Modeling ASR Word Confidence", "abstract": "We present a new method for computing ASR word confidences that effectively\nmitigates the effect of ASR errors for diverse downstream applications,\nimproves the word error rate of the 1-best result, and allows better comparison\nof scores across different models. We propose 1) a new method for modeling word\nconfidence using a Heterogeneous Word Confusion Network (HWCN) that addresses\nsome key flaws in conventional Word Confusion Networks, and 2) a new score\ncalibration method for facilitating direct comparison of scores from different\nmodels. Using a bidirectional lattice recurrent neural network to compute the\nconfidence scores of each word in the HWCN, we show that the word sequence with\nthe best overall confidence is more accurate than the default 1-best result of\nthe recognizer, and that the calibration method can substantially improve the\nreliability of recognizer combination.", "published": "2019-07-22 23:53:41", "link": "http://arxiv.org/abs/1907.09636v4", "categories": ["cs.CL", "cs.SD", "eess.AS", "stat.ML"], "primary_category": "cs.CL"}
{"title": "Green AI", "abstract": "The computations required for deep learning research have been doubling every\nfew months, resulting in an estimated 300,000x increase from 2012 to 2018 [2].\nThese computations have a surprisingly large carbon footprint [38]. Ironically,\ndeep learning was inspired by the human brain, which is remarkably energy\nefficient. Moreover, the financial cost of the computations can make it\ndifficult for academics, students, and researchers, in particular those from\nemerging economies, to engage in deep learning research.\n  This position paper advocates a practical solution by making efficiency an\nevaluation criterion for research alongside accuracy and related measures. In\naddition, we propose reporting the financial cost or \"price tag\" of developing,\ntraining, and running models to provide baselines for the investigation of\nincreasingly efficient methods. Our goal is to make AI both greener and more\ninclusive---enabling any inspired undergraduate with a laptop to write\nhigh-quality research papers. Green AI is an emerging focus at the Allen\nInstitute for AI.", "published": "2019-07-22 19:36:18", "link": "http://arxiv.org/abs/1907.10597v3", "categories": ["cs.CY", "cs.CL", "cs.CV", "cs.LG", "stat.ME"], "primary_category": "cs.CY"}
{"title": "Crowdsourcing a Dataset of Audio Captions", "abstract": "Audio captioning is a novel field of multi-modal translation and it is the\ntask of creating a textual description of the content of an audio signal (e.g.\n\"people talking in a big room\"). The creation of a dataset for this task\nrequires a considerable amount of work, rendering the crowdsourcing a very\nattractive option. In this paper we present a three steps based framework for\ncrowdsourcing an audio captioning dataset, based on concepts and practises\nfollowed for the creation of widely used image captioning and machine\ntranslations datasets. During the first step initial captions are gathered. A\ngrammatically corrected and/or rephrased version of each initial caption is\nobtained in second step. Finally, the initial and edited captions are rated,\nkeeping the top ones for the produced dataset. We objectively evaluate the\nimpact of our framework during the process of creating an audio captioning\ndataset, in terms of diversity and amount of typographical errors in the\nobtained captions. The obtained results show that the resulting dataset has\nless typographical errors than the initial captions, and on average each sound\nin the produced dataset has captions with a Jaccard similarity of 0.24, roughly\nequivalent to two ten-word captions having in common four words with the same\nroot, indicating that the captions are dissimilar while they still contain some\nof the same information.", "published": "2019-07-22 11:21:08", "link": "http://arxiv.org/abs/1907.09238v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "ML Estimation and CRBs for Reverberation, Speech and Noise PSDs in\n  Rank-Deficient Noise-Field", "abstract": "Speech communication systems are prone to performance degradation in\nreverberant and noisy acoustic environments. Dereverberation and noise\nreduction algorithms typically require several model parameters, e.g. the\nspeech, reverberation and noise power spectral densities (PSDs). A commonly\nused assumption is that the noise PSD matrix is known. However, in practical\nacoustic scenarios, the noise PSD matrix is unknown and should be estimated\nalong with the speech and reverberation PSDs. In this paper, we consider the\ncase of rank-deficient noise PSD matrix, which arises when the noise signal\nconsists of multiple directional interference sources, whose number is less\nthan the number of microphones. We derive two closed-form maximum likelihood\nestimators (MLEs). The first is a non-blocking-based estimator which jointly\nestimates the speech, reverberation and noise PSDs, and the second is a\nblocking-based estimator, which first blocks the speech signal and then jointly\nestimates the reverberation and noise PSDs. Both estimators are analytically\ncompared and analyzed, and mean square errors (MSEs) expressions are derived.\nFurthermore, Cramer-Rao Bounds (CRBs) on the estimated PSDs are derived. The\nproposed estimators are examined using both simulation and real reverberant and\nnoisy signals, demonstrating the advantage of the proposed method compared to\ncompeting estimators.", "published": "2019-07-22 12:00:44", "link": "http://arxiv.org/abs/1907.09250v2", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Deep Neural Network for Short-Segment Speaker Recognition", "abstract": "Todays interactive devices such as smart-phone assistants and smart speakers\noften deal with short-duration speech segments. As a result, speaker\nrecognition systems integrated into such devices will be much better suited\nwith models capable of performing the recognition task with short-duration\nutterances. In this paper, a new deep neural network, UtterIdNet, capable of\nperforming speaker recognition with short speech segments is proposed. Our\nproposed model utilizes a novel architecture that makes it suitable for\nshort-segment speaker recognition through an efficiently increased use of\ninformation in short speech segments. UtterIdNet has been trained and tested on\nthe VoxCeleb datasets, the latest benchmarks in speaker recognition.\nEvaluations for different segment durations show consistent and stable\nperformance for short segments, with significant improvement over the previous\nmodels for segments of 2 seconds, 1 second, and especially sub-second durations\n(250 ms and 500 ms).", "published": "2019-07-22 23:43:20", "link": "http://arxiv.org/abs/1907.10420v1", "categories": ["eess.AS", "cs.LG", "cs.SD", "stat.ML"], "primary_category": "eess.AS"}
