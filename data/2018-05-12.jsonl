{"title": "Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context", "abstract": "We know very little about how neural language models (LM) use prior\nlinguistic context. In this paper, we investigate the role of context in an\nLSTM LM, through ablation studies. Specifically, we analyze the increase in\nperplexity when prior context words are shuffled, replaced, or dropped. On two\nstandard datasets, Penn Treebank and WikiText-2, we find that the model is\ncapable of using about 200 tokens of context on average, but sharply\ndistinguishes nearby context (recent 50 tokens) from the distant history. The\nmodel is highly sensitive to the order of words within the most recent\nsentence, but ignores word order in the long-range context (beyond 50 tokens),\nsuggesting the distant past is modeled only as a rough semantic field or topic.\nWe further find that the neural caching model (Grave et al., 2017b) especially\nhelps the LSTM to copy words from within this distant context. Overall, our\nanalysis not only provides a better understanding of how neural LMs use their\ncontext, but also sheds light on recent success from cache-based models.", "published": "2018-05-12 00:26:29", "link": "http://arxiv.org/abs/1805.04623v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Ask Good Questions: Ranking Clarification Questions using\n  Neural Expected Value of Perfect Information", "abstract": "Inquiry is fundamental to communication, and machines cannot effectively\ncollaborate with humans unless they can ask questions. In this work, we build a\nneural network model for the task of ranking clarification questions. Our model\nis inspired by the idea of expected value of perfect information: a good\nquestion is one whose expected answer will be useful. We study this problem\nusing data from StackExchange, a plentiful online resource in which people\nroutinely ask clarifying questions to posts so that they can better offer\nassistance to the original poster. We create a dataset of clarification\nquestions consisting of ~77K posts paired with a clarification question (and\nanswer) from three domains of StackExchange: askubuntu, unix and superuser. We\nevaluate our model on 500 samples of this dataset against expert human\njudgments and demonstrate significant improvements over controlled baselines.", "published": "2018-05-12 05:11:07", "link": "http://arxiv.org/abs/1805.04655v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Backpropagating through Structured Argmax using a SPIGOT", "abstract": "We introduce the structured projection of intermediate gradients optimization\ntechnique (SPIGOT), a new method for backpropagating through neural networks\nthat include hard-decision structured predictions (e.g., parsing) in\nintermediate layers. SPIGOT requires no marginal inference, unlike structured\nattention networks (Kim et al., 2017) and some reinforcement learning-inspired\nsolutions (Yogatama et al., 2017). Like so-called straight-through estimators\n(Hinton, 2012), SPIGOT defines gradient-like quantities associated with\nintermediate nondifferentiable operations, allowing backpropagation before and\nafter them; SPIGOT's proxy aims to ensure that, after a parameter update, the\nintermediate structure will remain well-formed.\n  We experiment on two structured NLP pipelines: syntactic-then-semantic\ndependency parsing, and semantic parsing followed by sentiment classification.\nWe show that training with SPIGOT leads to a larger improvement on the\ndownstream task than a modularly-trained pipeline, the straight-through\nestimator, and structured attention, reaching a new state of the art on\nsemantic dependency parsing.", "published": "2018-05-12 05:27:45", "link": "http://arxiv.org/abs/1805.04658v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Huge Automatically Extracted Training Sets for Multilingual Word Sense\n  Disambiguation", "abstract": "We release to the community six large-scale sense-annotated datasets in\nmultiple language to pave the way for supervised multilingual Word Sense\nDisambiguation. Our datasets cover all the nouns in the English WordNet and\ntheir translations in other languages for a total of millions of sense-tagged\nsentences. Experiments prove that these corpora can be effectively used as\ntraining sets for supervised WSD systems, surpassing the state of the art for\nlow-resourced languages and providing competitive results for English, where\nmanually annotated training sets are accessible. The data is available at\ntrainomatic.org.", "published": "2018-05-12 08:25:33", "link": "http://arxiv.org/abs/1805.04685v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TED-LIUM 3: twice as much data and corpus repartition for experiments on\n  speaker adaptation", "abstract": "In this paper, we present TED-LIUM release 3 corpus dedicated to speech\nrecognition in English, that multiplies by more than two the available data to\ntrain acoustic models in comparison with TED-LIUM 2. We present the recent\ndevelopment on Automatic Speech Recognition (ASR) systems in comparison with\nthe two previous releases of the TED-LIUM Corpus from 2012 and 2014. We\ndemonstrate that, passing from 207 to 452 hours of transcribed speech training\ndata is really more useful for end-to-end ASR systems than for HMM-based\nstate-of-the-art ones, even if the HMM-based ASR system still outperforms\nend-to-end ASR system when the size of audio training data is 452 hours, with\nrespectively a Word Error Rate (WER) of 6.6% and 13.7%. Last, we propose two\nrepartitions of the TED-LIUM release 3 corpus: the legacy one that is the same\nas the one existing in release 2, and a new one, calibrated and designed to\nmake experiments on speaker adaptation. Like the two first releases, TED-LIUM 3\ncorpus will be freely available for the research community.", "published": "2018-05-12 11:06:47", "link": "http://arxiv.org/abs/1805.04699v4", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Unsupervised Semantic Frame Induction using Triclustering", "abstract": "We use dependency triples automatically extracted from a Web-scale corpus to\nperform unsupervised semantic frame induction. We cast the frame induction\nproblem as a triclustering problem that is a generalization of clustering for\ntriadic data. Our replicable benchmarks demonstrate that the proposed\ngraph-based approach, Triframes, shows state-of-the art results on this task on\na FrameNet-derived dataset and performing on par with competitive methods on a\nverb class clustering task.", "published": "2018-05-12 12:55:31", "link": "http://arxiv.org/abs/1805.04715v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Jointly Predicting Predicates and Arguments in Neural Semantic Role\n  Labeling", "abstract": "Recent BIO-tagging-based neural semantic role labeling models are very high\nperforming, but assume gold predicates as part of the input and cannot\nincorporate span-level features. We propose an end-to-end approach for jointly\npredicting all predicates, arguments spans, and the relations between them. The\nmodel makes independent decisions about what relationship, if any, holds\nbetween every possible word-span pair, and learns contextualized span\nrepresentations that provide rich, shared input features for each decision.\nExperiments demonstrate that this approach sets a new state of the art on\nPropBank SRL without gold predicates.", "published": "2018-05-12 21:32:50", "link": "http://arxiv.org/abs/1805.04787v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Coarse-to-Fine Decoding for Neural Semantic Parsing", "abstract": "Semantic parsing aims at mapping natural language utterances into structured\nmeaning representations. In this work, we propose a structure-aware neural\narchitecture which decomposes the semantic parsing process into two stages.\nGiven an input utterance, we first generate a rough sketch of its meaning,\nwhere low-level information (such as variable names and arguments) is glossed\nover. Then, we fill in missing details by taking into account the natural\nlanguage input and the sketch itself. Experimental results on four datasets\ncharacteristic of different domains and meaning representations show that our\napproach consistently improves performance, achieving competitive results\ndespite the use of relatively simple decoders.", "published": "2018-05-12 22:06:17", "link": "http://arxiv.org/abs/1805.04793v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Gaussian Mixture Latent Vector Grammars", "abstract": "We introduce Latent Vector Grammars (LVeGs), a new framework that extends\nlatent variable grammars such that each nonterminal symbol is associated with a\ncontinuous vector space representing the set of (infinitely many) subtypes of\nthe nonterminal. We show that previous models such as latent variable grammars\nand compositional vector grammars can be interpreted as special cases of LVeGs.\nWe then present Gaussian Mixture LVeGs (GM-LVeGs), a new special case of LVeGs\nthat uses Gaussian mixtures to formulate the weights of production rules over\nsubtypes of nonterminals. A major advantage of using Gaussian mixtures is that\nthe partition function and the expectations of subtype rules can be computed\nusing an extension of the inside-outside algorithm, which enables efficient\ninference and learning. We apply GM-LVeGs to part-of-speech tagging and\nconstituency parsing and show that GM-LVeGs can achieve competitive accuracies.\nOur code is available at https://github.com/zhaoyanpeng/lveg.", "published": "2018-05-12 09:27:53", "link": "http://arxiv.org/abs/1805.04688v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Weight Initialization in Neural Language Models", "abstract": "Semantic Similarity is an important application which finds its use in many\ndownstream NLP applications. Though the task is mathematically defined,\nsemantic similarity's essence is to capture the notions of similarity\nimpregnated in humans. Machines use some heuristics to calculate the similarity\nbetween words, but these are typically corpus dependent or are useful for\nspecific domains. The difference between Semantic Similarity and Semantic\nRelatedness motivates the development of new algorithms. For a human, the word\ncar and road are probably as related as car and bus. But this may not be the\ncase for computational methods. Ontological methods are good at encoding\nSemantic Similarity and Vector Space models are better at encoding Semantic\nRelatedness. There is a dearth of methods which leverage ontologies to create\nbetter vector representations. The aim of this proposal is to explore in the\ndirection of a hybrid method which combines statistical/vector space methods\nlike Word2Vec and Ontological methods like WordNet to leverage the advantages\nprovided by both.", "published": "2018-05-12 03:08:58", "link": "http://arxiv.org/abs/1805.06503v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Analogical Reasoning on Chinese Morphological and Semantic Relations", "abstract": "Analogical reasoning is effective in capturing linguistic regularities. This\npaper proposes an analogical reasoning task on Chinese. After delving into\nChinese lexical knowledge, we sketch 68 implicit morphological relations and 28\nexplicit semantic relations. A big and balanced dataset CA8 is then built for\nthis task, including 17813 questions. Furthermore, we systematically explore\nthe influences of vector representations, context features, and corpora on\nanalogical reasoning. With the experiments, CA8 is proved to be a reliable\nbenchmark for evaluating Chinese word embeddings.", "published": "2018-05-12 15:24:32", "link": "http://arxiv.org/abs/1805.06504v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Examining a hate speech corpus for hate speech detection and popularity\n  prediction", "abstract": "As research on hate speech becomes more and more relevant every day, most of\nit is still focused on hate speech detection. By attempting to replicate a hate\nspeech detection experiment performed on an existing Twitter corpus annotated\nfor hate speech, we highlight some issues that arise from doing research in the\nfield of hate speech, which is essentially still in its infancy. We take a\ncritical look at the training corpus in order to understand its biases, while\nalso using it to venture beyond hate speech detection and investigate whether\nit can be used to shed light on other facets of research, such as popularity of\nhate tweets.", "published": "2018-05-12 06:00:47", "link": "http://arxiv.org/abs/1805.04661v1", "categories": ["cs.CL", "cs.AI", "cs.CY", "68T50"], "primary_category": "cs.CL"}
{"title": "AdvEntuRe: Adversarial Training for Textual Entailment with\n  Knowledge-Guided Examples", "abstract": "We consider the problem of learning textual entailment models with limited\nsupervision (5K-10K training examples), and present two complementary\napproaches for it. First, we propose knowledge-guided adversarial example\ngenerators for incorporating large lexical resources in entailment models via\nonly a handful of rule templates. Second, to make the entailment model - a\ndiscriminator - more robust, we propose the first GAN-style approach for\ntraining it using a natural language example generator that iteratively adjusts\nbased on the discriminator's performance. We demonstrate effectiveness using\ntwo entailment datasets, where the proposed methods increase accuracy by 4.7%\non SciTail and by 2.8% on a 1% training sub-sample of SNLI. Notably, even a\nsingle hand-written rule, negate, improves the accuracy on the negation\nexamples in SNLI by 6.1%.", "published": "2018-05-12 07:52:59", "link": "http://arxiv.org/abs/1805.04680v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Extended pipeline for content-based feature engineering in music genre\n  recognition", "abstract": "We present a feature engineering pipeline for the construction of musical\nsignal characteristics, to be used for the design of a supervised model for\nmusical genre identification. The key idea is to extend the traditional\ntwo-step process of extraction and classification with additive stand-alone\nphases which are no longer organized in a waterfall scheme. The whole system is\nrealized by traversing backtrack arrows and cycles between various stages. In\norder to give a compact and effective representation of the features, the\nstandard early temporal integration is combined with other selection and\nextraction phases: on the one hand, the selection of the most meaningful\ncharacteristics based on information gain, and on the other hand, the inclusion\nof the nonlinear correlation between this subset of features, determined by an\nautoencoder. The results of the experiments conducted on GTZAN dataset reveal a\nnoticeable contribution of this methodology towards the model's performance in\nclassification task.", "published": "2018-05-12 16:47:01", "link": "http://arxiv.org/abs/1805.05324v1", "categories": ["cs.SD", "cs.LG", "eess.AS", "stat.ML"], "primary_category": "cs.SD"}
{"title": "Scene-Aware Audio for 360\\textdegree{} Videos", "abstract": "Although 360\\textdegree{} cameras ease the capture of panoramic footage, it\nremains challenging to add realistic 360\\textdegree{} audio that blends into\nthe captured scene and is synchronized with the camera motion. We present a\nmethod for adding scene-aware spatial audio to 360\\textdegree{} videos in\ntypical indoor scenes, using only a conventional mono-channel microphone and a\nspeaker. We observe that the late reverberation of a room's impulse response is\nusually diffuse spatially and directionally. Exploiting this fact, we propose a\nmethod that synthesizes the directional impulse response between any source and\nlistening locations by combining a synthesized early reverberation part and a\nmeasured late reverberation tail. The early reverberation is simulated using a\ngeometric acoustic simulation and then enhanced using a frequency modulation\nmethod to capture room resonances. The late reverberation is extracted from a\nrecorded impulse response, with a carefully chosen time duration that separates\nout the late reverberation from the early reverberation. In our validations, we\nshow that our synthesized spatial audio matches closely with recordings using\nambisonic microphones. Lastly, we demonstrate the strength of our method in\nseveral applications.", "published": "2018-05-12 22:06:04", "link": "http://arxiv.org/abs/1805.04792v1", "categories": ["cs.GR", "cs.CV", "cs.ET", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
