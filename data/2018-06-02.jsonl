{"title": "Does the brain represent words? An evaluation of brain decoding studies\n  of language understanding", "abstract": "Language decoding studies have identified word representations which can be\nused to predict brain activity in response to novel words and sentences\n(Anderson et al., 2016; Pereira et al., 2018). The unspoken assumption of these\nstudies is that, during processing, linguistic information is transformed into\nsome shared semantic space, and those semantic representations are then used\nfor a variety of linguistic and non-linguistic tasks. We claim that current\nstudies vastly underdetermine the content of these representations, the\nalgorithms which the brain deploys to produce and consume them, and the\ncomputational tasks which they are designed to solve. We illustrate this\nindeterminacy with an extension of the sentence-decoding experiment of Pereira\net al. (2018), showing how standard evaluations fail to distinguish between\nlanguage processing models which deploy different mechanisms and which are\noptimized to solve very different tasks. We conclude by suggesting changes to\nthe brain decoding paradigm which can support stronger claims of neural\nrepresentation.", "published": "2018-06-02 06:33:47", "link": "http://arxiv.org/abs/1806.00591v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "AP18-OLR Challenge: Three Tasks and Their Baselines", "abstract": "The third oriental language recognition (OLR) challenge AP18-OLR is\nintroduced in this paper, including the data profile, the tasks and the\nevaluation principles. Following the events in the last two years, namely\nAP16-OLR and AP17-OLR, the challenge this year focuses on more challenging\ntasks, including (1) short-duration utterances, (2) confusing languages, and\n(3) open-set recognition. The same as the previous events, the data of AP18-OLR\nis also provided by SpeechOcean and the NSFC M2ASR project. Baselines based on\nboth the i-vector model and neural networks are constructed for the\nparticipants' reference. We report the baseline results on the three tasks and\ndemonstrate that the three tasks are truly challenging. All the data is free\nfor participants, and the Kaldi recipes for the baselines have been published\nonline.", "published": "2018-06-02 10:07:10", "link": "http://arxiv.org/abs/1806.00616v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Emotion Detection in Text: a Review", "abstract": "In recent years, emotion detection in text has become more popular due to its\nvast potential applications in marketing, political science, psychology,\nhuman-computer interaction, artificial intelligence, etc. Access to a huge\namount of textual data, especially opinionated and self-expression text also\nplayed a special role to bring attention to this field. In this paper, we\nreview the work that has been done in identifying emotion expressions in text\nand argue that although many techniques, methodologies, and models have been\ncreated to detect emotion in text, there are various reasons that make these\nmethods insufficient. Although, there is an essential need to improve the\ndesign and architecture of current systems, factors such as the complexity of\nhuman emotions, and the use of implicit and metaphorical language in expressing\nit, lead us to think that just re-purposing standard methodologies will not be\nenough to capture these complexities, and it is important to pay attention to\nthe linguistic intricacies of emotion expression.", "published": "2018-06-02 17:18:06", "link": "http://arxiv.org/abs/1806.00674v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Stress Test Evaluation for Natural Language Inference", "abstract": "Natural language inference (NLI) is the task of determining if a natural\nlanguage hypothesis can be inferred from a given premise in a justifiable\nmanner. NLI was proposed as a benchmark task for natural language\nunderstanding. Existing models perform well at standard datasets for NLI,\nachieving impressive results across different genres of text. However, the\nextent to which these models understand the semantic content of sentences is\nunclear. In this work, we propose an evaluation methodology consisting of\nautomatically constructed \"stress tests\" that allow us to examine whether\nsystems have the ability to make real inferential decisions. Our evaluation of\nsix sentence-encoder models on these stress tests reveals strengths and\nweaknesses of these models with respect to challenging linguistic phenomena,\nand suggests important directions for future work in this area.", "published": "2018-06-02 19:14:39", "link": "http://arxiv.org/abs/1806.00692v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Quantifying the dynamics of topical fluctuations in language", "abstract": "The availability of large diachronic corpora has provided the impetus for a\ngrowing body of quantitative research on language evolution and meaning change.\nThe central quantities in this research are token frequencies of linguistic\nelements in texts, with changes in frequency taken to reflect the popularity or\nselective fitness of an element. However, corpus frequencies may change for a\nwide variety of reasons, including purely random sampling effects, or because\ncorpora are composed of contemporary media and fiction texts within which the\nunderlying topics ebb and flow with cultural and socio-political trends. In\nthis work, we introduce a simple model for controlling for topical fluctuations\nin corpora - the topical-cultural advection model - and demonstrate how it\nprovides a robust baseline of variability in word frequency changes over time.\nWe validate the model on a diachronic corpus spanning two centuries, and a\ncarefully-controlled artificial language change scenario, and then use it to\ncorrect for topical fluctuations in historical time series. Finally, we use the\nmodel to show that the emergence of new words typically corresponds with the\nrise of a trending topic. This suggests that some lexical innovations occur due\nto growing communicative need in a subspace of the lexicon, and that the\ntopical-cultural advection model can be used to quantify this.", "published": "2018-06-02 20:14:17", "link": "http://arxiv.org/abs/1806.00699v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NLP-assisted software testing: A systematic mapping of the literature", "abstract": "Context: To reduce manual effort of extracting test cases from\nnatural-language requirements, many approaches based on Natural Language\nProcessing (NLP) have been proposed in the literature. Given the large amount\nof approaches in this area, and since many practitioners are eager to utilize\nsuch techniques, it is important to synthesize and provide an overview of the\nstate-of-the-art in this area. Objective: Our objective is to summarize the\nstate-of-the-art in NLP-assisted software testing which could benefit\npractitioners to potentially utilize those NLP-based techniques. Moreover, this\ncan benefit researchers in providing an overview of the research landscape.\nMethod: To address the above need, we conducted a survey in the form of a\nsystematic literature mapping (classification). After compiling an initial pool\nof 95 papers, we conducted a systematic voting, and our final pool included 67\ntechnical papers. Results: This review paper provides an overview of the\ncontribution types presented in the papers, types of NLP approaches used to\nassist software testing, types of required input requirements, and a review of\ntool support in this area. Some key results we have detected are: (1) only four\nof the 38 tools (11%) presented in the papers are available for download; (2) a\nlarger ratio of the papers (30 of 67) provided a shallow exposure to the NLP\naspects (almost no details). Conclusion: This paper would benefit both\npractitioners and researchers by serving as an \"index\" to the body of knowledge\nin this area. The results could help practitioners utilizing the existing\nNLP-based techniques; this in turn reduces the cost of test-case design and\ndecreases the amount of human resources spent on test activities. After sharing\nthis review with some of our industrial collaborators, initial insights show\nthat this review can indeed be useful and beneficial to practitioners.", "published": "2018-06-02 20:00:44", "link": "http://arxiv.org/abs/1806.00696v3", "categories": ["cs.SE", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Fast Locality Sensitive Hashing for Beam Search on GPU", "abstract": "We present a GPU-based Locality Sensitive Hashing (LSH) algorithm to speed up\nbeam search for sequence models. We utilize the winner-take-all (WTA) hash,\nwhich is based on relative ranking order of hidden dimensions and thus\nresilient to perturbations in numerical values. Our algorithm is designed by\nfully considering the underling architecture of CUDA-enabled GPUs\n(Algorithm/Architecture Co-design): 1) A parallel Cuckoo hash table is applied\nfor LSH code lookup (guaranteed O(1) lookup time); 2) Candidate lists are\nshared across beams to maximize the parallelism; 3) Top frequent words are\nmerged into candidate lists to improve performance. Experiments on 4\nlarge-scale neural machine translation models demonstrate that our algorithm\ncan achieve up to 4x speedup on softmax module, and 2x overall speedup without\nhurting BLEU on GPU.", "published": "2018-06-02 06:18:15", "link": "http://arxiv.org/abs/1806.00588v1", "categories": ["cs.CL", "cs.AI", "cs.DC", "cs.DS"], "primary_category": "cs.CL"}
{"title": "Multiplex Communities and the Emergence of International Conflict", "abstract": "Advances in community detection reveal new insights into multiplex and\nmultilayer networks. Less work, however, investigates the relationship between\nthese communities and outcomes in social systems. We leverage these advances to\nshed light on the relationship between the cooperative mesostructure of the\ninternational system and the onset of interstate conflict. We detect\ncommunities based upon weaker signals of affinity expressed in United Nations\nvotes and speeches, as well as stronger signals observed across multiple layers\nof bilateral cooperation. Communities of diplomatic affinity display an\nexpected negative relationship with conflict onset. Ties in communities based\nupon observed cooperation, however, display no effect under a standard model\nspecification and a positive relationship with conflict under an alternative\nspecification. These results align with some extant hypotheses but also point\nto a paucity in our understanding of the relationship between community\nstructure and behavioral outcomes in networks.", "published": "2018-06-02 09:58:50", "link": "http://arxiv.org/abs/1806.00615v2", "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A Novel Framework for Recurrent Neural Networks with Enhancing\n  Information Processing and Transmission between Units", "abstract": "This paper proposes a novel framework for recurrent neural networks (RNNs)\ninspired by the human memory models in the field of cognitive neuroscience to\nenhance information processing and transmission between adjacent RNNs' units.\nThe proposed framework for RNNs consists of three stages that is working\nmemory, forget, and long-term store. The first stage includes taking input data\ninto sensory memory and transferring it to working memory for preliminary\ntreatment. And the second stage mainly focuses on proactively forgetting the\nsecondary information rather than the primary in the working memory. And\nfinally, we get the long-term store normally using some kind of RNN's unit. Our\nframework, which is generalized and simple, is evaluated on 6 datasets which\nfall into 3 different tasks, corresponding to text classification, image\nclassification and language modelling. Experiments reveal that our framework\ncan obviously improve the performance of traditional recurrent neural networks.\nAnd exploratory task shows the ability of our framework of correctly forgetting\nthe secondary information.", "published": "2018-06-02 12:59:18", "link": "http://arxiv.org/abs/1806.00628v1", "categories": ["cs.NE", "cs.CL", "cs.LG"], "primary_category": "cs.NE"}
