{"title": "Ultradense Word Embeddings by Orthogonal Transformation", "abstract": "Embeddings are generic representations that are useful for many NLP tasks. In\nthis paper, we introduce DENSIFIER, a method that learns an orthogonal\ntransformation of the embedding space that focuses the information relevant for\na task in an ultradense subspace of a dimensionality that is smaller by a\nfactor of 100 than the original space. We show that ultradense embeddings\ngenerated by DENSIFIER reach state of the art on a lexicon creation task in\nwhich words are annotated with three types of lexical information - sentiment,\nconcreteness and frequency. On the SemEval2015 10B sentiment analysis task we\nshow that no information is lost when the ultradense subspace is used, but\ntraining is an order of magnitude more efficient due to the compactness of the\nultradense space.", "published": "2016-02-24 16:06:25", "link": "http://arxiv.org/abs/1602.07572v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Toward Mention Detection Robustness with Recurrent Neural Networks", "abstract": "One of the key challenges in natural language processing (NLP) is to yield\ngood performance across application domains and languages. In this work, we\ninvestigate the robustness of the mention detection systems, one of the\nfundamental tasks in information extraction, via recurrent neural networks\n(RNNs). The advantage of RNNs over the traditional approaches is their capacity\nto capture long ranges of context and implicitly adapt the word embeddings,\ntrained on a large corpus, into a task-specific word representation, but still\npreserve the original semantic generalization to be helpful across domains. Our\nsystematic evaluation for RNN architectures demonstrates that RNNs not only\noutperform the best reported systems (up to 9\\% relative error reduction) in\nthe general setting but also achieve the state-of-the-art performance in the\ncross-domain setting for English. Regarding other languages, RNNs are\nsignificantly better than the traditional methods on the similar task of named\nentity recognition for Dutch (up to 22\\% relative error reduction).", "published": "2016-02-24 23:14:01", "link": "http://arxiv.org/abs/1602.07749v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improved Accent Classification Combining Phonetic Vowels with Acoustic\n  Features", "abstract": "Researches have shown accent classification can be improved by integrating\nsemantic information into pure acoustic approach. In this work, we combine\nphonetic knowledge, such as vowels, with enhanced acoustic features to build an\nimproved accent classification system. The classifier is based on Gaussian\nMixture Model-Universal Background Model (GMM-UBM), with normalized Perceptual\nLinear Predictive (PLP) features. The features are further optimized by\nPrinciple Component Analysis (PCA) and Hetroscedastic Linear Discriminant\nAnalysis (HLDA). Using 7 major types of accented speech from the Foreign\nAccented English (FAE) corpus, the system achieves classification accuracy 54%\nwith input test data as short as 20 seconds, which is competitive to the state\nof the art in this field.", "published": "2016-02-24 04:33:49", "link": "http://arxiv.org/abs/1602.07394v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Multilingual Twitter Sentiment Classification: The Role of Human\n  Annotators", "abstract": "What are the limits of automated Twitter sentiment classification? We analyze\na large set of manually labeled tweets in different languages, use them as\ntraining data, and construct automated classification models. It turns out that\nthe quality of classification models depends much more on the quality and size\nof training data than on the type of the model trained. Experimental results\nindicate that there is no statistically significant difference between the\nperformance of the top classification models. We quantify the quality of\ntraining data by applying various annotator agreement measures, and identify\nthe weakest points of different datasets. We show that the model performance\napproaches the inter-annotator agreement when the size of the training set is\nsufficiently large. However, it is crucial to regularly monitor the self- and\ninter-annotator agreements since this improves the training datasets and\nconsequently the model performance. Finally, we show that there is strong\nevidence that humans perceive the sentiment classes (negative, neutral, and\npositive) as ordered.", "published": "2016-02-24 15:34:22", "link": "http://arxiv.org/abs/1602.07563v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Accent Classification with Phonetic Vowel Representation", "abstract": "Previous accent classification research focused mainly on detecting accents\nwith pure acoustic information without recognizing accented speech. This work\ncombines phonetic knowledge such as vowels with acoustic information to build\nGuassian Mixture Model (GMM) classifier with Perceptual Linear Predictive (PLP)\nfeatures, optimized by Hetroscedastic Linear Discriminant Analysis (HLDA). With\ninput about 20-second accented speech, this system achieves classification rate\nof 51% on a 7-way classification system focusing on the major types of accents\nin English, which is competitive to the state-of-the-art results in this field.", "published": "2016-02-24 02:50:44", "link": "http://arxiv.org/abs/1604.08095v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Domain Specific Author Attribution Based on Feedforward Neural Network\n  Language Models", "abstract": "Authorship attribution refers to the task of automatically determining the\nauthor based on a given sample of text. It is a problem with a long history and\nhas a wide range of application. Building author profiles using language models\nis one of the most successful methods to automate this task. New language\nmodeling methods based on neural networks alleviate the curse of dimensionality\nand usually outperform conventional N-gram methods. However, there have not\nbeen much research applying them to authorship attribution. In this paper, we\npresent a novel setup of a Neural Network Language Model (NNLM) and apply it to\na database of text samples from different authors. We investigate how the NNLM\nperforms on a task with moderate author set size and relatively limited\ntraining and test data, and how the topics of the text samples affect the\naccuracy. NNLM achieves nearly 2.5% reduction in perplexity, a measurement of\nfitness of a trained language model to the test data. Given 5 random test\nsentences, it also increases the author classification accuracy by 3.43% on\naverage, compared with the N-gram methods using SRILM tools. An open source\nimplementation of our methodology is freely available at\nhttps://github.com/zge/authorship-attribution/.", "published": "2016-02-24 04:32:34", "link": "http://arxiv.org/abs/1602.07393v1", "categories": ["cs.CL", "cs.LG", "cs.NE"], "primary_category": "cs.CL"}
