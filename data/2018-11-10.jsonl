{"title": "Dual Latent Variable Model for Low-Resource Natural Language Generation\n  in Dialogue Systems", "abstract": "Recent deep learning models have shown improving results to natural language\ngeneration (NLG) irrespective of providing sufficient annotated data. However,\na modest training data may harm such models performance. Thus, how to build a\ngenerator that can utilize as much of knowledge from a low-resource setting\ndata is a crucial issue in NLG. This paper presents a variational neural-based\ngeneration model to tackle the NLG problem of having limited labeled dataset,\nin which we integrate a variational inference into an encoder-decoder generator\nand introduce a novel auxiliary autoencoding with an effective training\nprocedure. Experiments showed that the proposed methods not only outperform the\nprevious models when having sufficient training dataset but also show strong\nability to work acceptably well when the training data is scarce.", "published": "2018-11-10 00:12:56", "link": "http://arxiv.org/abs/1811.04164v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Speech Intention Understanding in a Head-final Language: A\n  Disambiguation Utilizing Intonation-dependency", "abstract": "For a large portion of real-life utterances, the intention cannot be solely\ndecided by either their semantic or syntactic characteristics. Although not all\nthe sociolinguistic and pragmatic information can be digitized, at least\nphonetic features are indispensable in understanding the spoken language.\nEspecially in head-final languages such as Korean, sentence-final prosody has\ngreat importance in identifying the speaker's intention. This paper suggests a\nsystem which identifies the inherent intention of a spoken utterance given its\ntranscript, in some cases using auxiliary acoustic features. The main point\nhere is a separate distinction for cases where discrimination of intention\nrequires an acoustic cue. Thus, the proposed classification system decides\nwhether the given utterance is a fragment, statement, question, command, or a\nrhetorical question/command, utilizing the intonation-dependency coming from\nthe head-finality. Based on an intuitive understanding of the Korean language\nthat is engaged in the data annotation, we construct a network which identifies\nthe intention of a speech, and validate its utility with the test sentences.\nThe system, if combined with up-to-date speech recognizers, is expected to be\nflexibly inserted into various language understanding modules.", "published": "2018-11-10 10:41:27", "link": "http://arxiv.org/abs/1811.04231v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving End-to-end Speech Recognition with Pronunciation-assisted\n  Sub-word Modeling", "abstract": "Most end-to-end speech recognition systems model text directly as a sequence\nof characters or sub-words. Current approaches to sub-word extraction only\nconsider character sequence frequencies, which at times produce inferior\nsub-word segmentation that might lead to erroneous speech recognition output.\nWe propose pronunciation-assisted sub-word modeling (PASM), a sub-word\nextraction method that leverages the pronunciation information of a word.\nExperiments show that the proposed method can greatly improve upon the\ncharacter-based baseline, and also outperform commonly used byte-pair encoding\nmethods.", "published": "2018-11-10 17:07:44", "link": "http://arxiv.org/abs/1811.04284v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarially-Trained Normalized Noisy-Feature Auto-Encoder for Text\n  Generation", "abstract": "This article proposes Adversarially-Trained Normalized Noisy-Feature\nAuto-Encoder (ATNNFAE) for byte-level text generation. An ATNNFAE consists of\nan auto-encoder where the internal code is normalized on the unit sphere and\ncorrupted by additive noise. Simultaneously, a replica of the decoder (sharing\nthe same parameters as the AE decoder) is used as the generator and fed with\nrandom latent vectors. An adversarial discriminator is trained to distinguish\ntraining samples reconstructed from the AE from samples produced through the\nrandom-input generator, making the entire generator-discriminator path\ndifferentiable for discrete data like text. The combined effect of noise\ninjection in the code and shared weights between the decoder and the generator\ncan prevent the mode collapsing phenomenon commonly observed in GANs. Since\nperplexity cannot be applied to non-sequential text generation, we propose a\nnew evaluation method using the total variance distance between frequencies of\nhash-coded byte-level n-grams (NGTVD). NGTVD is a single benchmark that can\ncharacterize both the quality and the diversity of the generated texts.\nExperiments are offered in 6 large-scale datasets in Arabic, Chinese and\nEnglish, with comparisons against n-gram baselines and recurrent neural\nnetworks (RNNs). Ablation study on both the noise level and the discriminator\nis performed. We find that RNNs have trouble competing with the n-gram\nbaselines, and the ATNNFAE results are generally competitive.", "published": "2018-11-10 06:05:53", "link": "http://arxiv.org/abs/1811.04201v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Densely Connected Attention Propagation for Reading Comprehension", "abstract": "We propose DecaProp (Densely Connected Attention Propagation), a new densely\nconnected neural architecture for reading comprehension (RC). There are two\ndistinct characteristics of our model. Firstly, our model densely connects all\npairwise layers of the network, modeling relationships between passage and\nquery across all hierarchical levels. Secondly, the dense connectors in our\nnetwork are learned via attention instead of standard residual skip-connectors.\nTo this end, we propose novel Bidirectional Attention Connectors (BAC) for\nefficiently forging connections throughout the network. We conduct extensive\nexperiments on four challenging RC benchmarks. Our proposed approach achieves\nstate-of-the-art results on all four, outperforming existing baselines by up to\n$2.6\\%-14.2\\%$ in absolute F1 score.", "published": "2018-11-10 07:54:13", "link": "http://arxiv.org/abs/1811.04210v2", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.NE"], "primary_category": "cs.CL"}
{"title": "Playing by the Book: An Interactive Game Approach for Action Graph\n  Extraction from Text", "abstract": "Understanding procedural text requires tracking entities, actions and effects\nas the narrative unfolds. We focus on the challenging real-world problem of\naction-graph extraction from material science papers, where language is highly\nspecialized and data annotation is expensive and scarce. We propose a novel\napproach, Text2Quest, where procedural text is interpreted as instructions for\nan interactive game. A learning agent completes the game by executing the\nprocedure correctly in a text-based simulated lab environment. The framework\ncan complement existing approaches and enables richer forms of learning\ncompared to static texts. We discuss potential limitations and advantages of\nthe approach, and release a prototype proof-of-concept, hoping to encourage\nresearch in this direction.", "published": "2018-11-10 21:45:07", "link": "http://arxiv.org/abs/1811.04319v3", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Mapping Navigation Instructions to Continuous Control Actions with\n  Position-Visitation Prediction", "abstract": "We propose an approach for mapping natural language instructions and raw\nobservations to continuous control of a quadcopter drone. Our model predicts\ninterpretable position-visitation distributions indicating where the agent\nshould go during execution and where it should stop, and uses the predicted\ndistributions to select the actions to execute. This two-step model\ndecomposition allows for simple and efficient training using a combination of\nsupervised learning and imitation learning. We evaluate our approach with a\nrealistic drone simulator, and demonstrate absolute task-completion accuracy\nimprovements of 16.85% over two state-of-the-art instruction-following methods.", "published": "2018-11-10 02:57:38", "link": "http://arxiv.org/abs/1811.04179v2", "categories": ["cs.RO", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Reinforcement Learning Based Speech Enhancement for Robust Speech\n  Recognition", "abstract": "Conventional deep neural network (DNN)-based speech enhancement (SE)\napproaches aim to minimize the mean square error (MSE) between enhanced speech\nand clean reference. The MSE-optimized model may not directly improve the\nperformance of an automatic speech recognition (ASR) system. If the target is\nto minimize the recognition error, the recognition results should be used to\ndesign the objective function for optimizing the SE model. However, the\nstructure of an ASR system, which consists of multiple units, such as acoustic\nand language models, is usually complex and not differentiable. In this study,\nwe proposed to adopt the reinforcement learning algorithm to optimize the SE\nmodel based on the recognition results. We evaluated the propsoed SE system on\nthe Mandarin Chinese broadcast news corpus (MATBN). Experimental results\ndemonstrate that the proposed method can effectively improve the ASR results\nwith a notable 12.40% and 19.23% error rate reductions for signal to noise\nratio at 0 dB and 5 dB conditions, respectively.", "published": "2018-11-10 09:38:36", "link": "http://arxiv.org/abs/1811.04224v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
