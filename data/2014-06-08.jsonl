{"title": "Automatic Extraction of Protein Interaction in Literature", "abstract": "Protein-protein interaction extraction is the key precondition of the\nconstruction of protein knowledge network, and it is very important for the\nresearch in the biomedicine. This paper extracted directional protein-protein\ninteraction from the biological text, using the SVM-based method. Experiments\nwere evaluated on the LLL05 corpus with good results. The results show that\ndependency features are import for the protein-protein interaction extraction\nand features related to the interaction word are effective for the interaction\ndirection judgment. At last, we analyzed the effects of different features and\nplaned for the next step.", "published": "2014-06-08 07:41:07", "link": "http://arxiv.org/abs/1406.1953v2", "categories": ["cs.CL", "cs.CE", "H.2.8; H.3.5"], "primary_category": "cs.CL"}
{"title": "Two-dimensional Sentiment Analysis of text", "abstract": "Sentiment Analysis aims to get the underlying viewpoint of the text, which\ncould be anything that holds a subjective opinion, such as an online review,\nMovie rating, Comments on Blog posts etc. This paper presents a novel approach\nthat classify text in two-dimensional Emotional space, based on the sentiments\nof the author. The approach uses existing lexical resources to extract feature\nset, which is trained using Supervised Learning techniques.", "published": "2014-06-08 20:05:36", "link": "http://arxiv.org/abs/1406.2022v1", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Learning Word Representations with Hierarchical Sparse Coding", "abstract": "We propose a new method for learning word representations using hierarchical\nregularization in sparse coding inspired by the linguistic study of word\nmeanings. We show an efficient learning algorithm based on stochastic proximal\nmethods that is significantly faster than previous approaches, making it\npossible to perform hierarchical sparse coding on a corpus of billions of word\ntokens. Experiments on various benchmark tasks---word similarity ranking,\nanalogies, sentence completion, and sentiment analysis---demonstrate that the\nmethod outperforms or is competitive with state-of-the-art methods. Our word\nrepresentations are available at\n\\url{http://www.ark.cs.cmu.edu/dyogatam/wordvecs/}.", "published": "2014-06-08 22:35:09", "link": "http://arxiv.org/abs/1406.2035v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
