{"title": "Effective Approaches to Attention-based Neural Machine Translation", "abstract": "An attentional mechanism has lately been used to improve neural machine\ntranslation (NMT) by selectively focusing on parts of the source sentence\nduring translation. However, there has been little work exploring useful\narchitectures for attention-based NMT. This paper examines two simple and\neffective classes of attentional mechanism: a global approach which always\nattends to all source words and a local one that only looks at a subset of\nsource words at a time. We demonstrate the effectiveness of both approaches\nover the WMT translation tasks between English and German in both directions.\nWith local attention, we achieve a significant gain of 5.0 BLEU points over\nnon-attentional systems which already incorporate known techniques such as\ndropout. Our ensemble model using different attention architectures has\nestablished a new state-of-the-art result in the WMT'15 English to German\ntranslation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over\nthe existing best system backed by NMT and an n-gram reranker.", "published": "2015-08-17 13:43:19", "link": "http://arxiv.org/abs/1508.04025v5", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Molding CNNs for text: non-linear, non-consecutive convolutions", "abstract": "The success of deep learning often derives from well-chosen operational\nbuilding blocks. In this work, we revise the temporal convolution operation in\nCNNs to better adapt it to text processing. Instead of concatenating word\nrepresentations, we appeal to tensor algebra and use low-rank n-gram tensors to\ndirectly exploit interactions between words already at the convolution stage.\nMoreover, we extend the n-gram convolution to non-consecutive words to\nrecognize patterns with intervening words. Through a combination of low-rank\ntensors, and pattern weighting, we can efficiently evaluate the resulting\nconvolution operation via dynamic programming. We test the resulting\narchitecture on standard sentiment classification and news categorization\ntasks. Our model achieves state-of-the-art performance both in terms of\naccuracy and training speed. For instance, we obtain 51.2% accuracy on the\nfine-grained sentiment classification task.", "published": "2015-08-17 19:02:45", "link": "http://arxiv.org/abs/1508.04112v2", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
