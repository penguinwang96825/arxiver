{"title": "Relation Extraction Model Based on Semantic Enhancement Mechanism", "abstract": "Relational extraction is one of the basic tasks related to information\nextraction in the field of natural language processing, and is an important\nlink and core task in the fields of information extraction, natural language\nunderstanding, and information retrieval. None of the existing relation\nextraction methods can effectively solve the problem of triple overlap. The\nCasAug model proposed in this paper based on the CasRel framework combined with\nthe semantic enhancement mechanism can solve this problem to a certain extent.\nThe CasAug model enhances the semantics of the identified possible subjects by\nadding a semantic enhancement mechanism, First, based on the semantic coding of\npossible subjects, pre-classify the possible subjects, and then combine the\nsubject lexicon to calculate the semantic similarity to obtain the similar\nvocabulary of possible subjects. According to the similar vocabulary obtained,\neach word in different relations is calculated through the attention mechanism.\nFor the contribution of the possible subject, finally combine the relationship\npre-classification results to weight the enhanced semantics of each\nrelationship to find the enhanced semantics of the possible subject, and send\nthe enhanced semantics combined with the possible subject to the object and\nrelationship extraction module. Complete the final relation triplet extraction.\nThe experimental results show that, compared with the baseline model, the\nCasAug model proposed in this paper has improved the effect of relation\nextraction, and CasAug's ability to deal with overlapping problems and extract\nmultiple relations is also better than the baseline model, indicating that the\nsemantic enhancement mechanism proposed in this paper It can further reduce the\njudgment of redundant relations and alleviate the problem of triple overlap.", "published": "2023-11-05 04:40:39", "link": "http://arxiv.org/abs/2311.02564v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Topic model based on co-occurrence word networks for unbalanced short\n  text datasets", "abstract": "We propose a straightforward solution for detecting scarce topics in\nunbalanced short-text datasets. Our approach, named CWUTM (Topic model based on\nco-occurrence word networks for unbalanced short text datasets), Our approach\naddresses the challenge of sparse and unbalanced short text topics by\nmitigating the effects of incidental word co-occurrence. This allows our model\nto prioritize the identification of scarce topics (Low-frequency topics).\nUnlike previous methods, CWUTM leverages co-occurrence word networks to capture\nthe topic distribution of each word, and we enhanced the sensitivity in\nidentifying scarce topics by redefining the calculation of node activity and\nnormalizing the representation of both scarce and abundant topics to some\nextent. Moreover, CWUTM adopts Gibbs sampling, similar to LDA, making it easily\nadaptable to various application scenarios. Our extensive experimental\nvalidation on unbalanced short-text datasets demonstrates the superiority of\nCWUTM compared to baseline approaches in discovering scarce topics. According\nto the experimental results the proposed model is effective in early and\naccurate detection of emerging topics or unexpected events on social platforms.", "published": "2023-11-05 04:44:23", "link": "http://arxiv.org/abs/2311.02566v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "BanMANI: A Dataset to Identify Manipulated Social Media News in Bangla", "abstract": "Initial work has been done to address fake news detection and\nmisrepresentation of news in the Bengali language. However, no work in Bengali\nyet addresses the identification of specific claims in social media news that\nfalsely manipulates a related news article. At this point, this problem has\nbeen tackled in English and a few other languages, but not in the Bengali\nlanguage. In this paper, we curate a dataset of social media content labeled\nwith information manipulation relative to reference articles, called BanMANI.\nThe dataset collection method we describe works around the limitations of the\navailable NLP tools in Bangla. We expect these techniques will carry over to\nbuilding similar datasets in other low-resource languages. BanMANI forms the\nbasis both for evaluating the capabilities of existing NLP systems and for\ntraining or fine-tuning new models specifically on this task. In our analysis,\nwe find that this task challenges current LLMs both under zero-shot and\nfine-tuned settings.", "published": "2023-11-05 05:49:57", "link": "http://arxiv.org/abs/2311.02570v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Temporal Sequencing of Documents", "abstract": "We outline an unsupervised method for temporal rank ordering of sets of\nhistorical documents, namely American State of the Union Addresses and DEEDS, a\ncorpus of medieval English property transfer documents. Our method relies upon\neffectively capturing the gradual change in word usage via a bandwidth estimate\nfor the non-parametric Generalized Linear Models (Fan, Heckman, and Wand,\n1995). The number of possible rank orders needed to search through for cost\nfunctions related to the bandwidth can be quite large, even for a small set of\ndocuments. We tackle this problem of combinatorial optimization using the\nSimulated Annealing algorithm, which allows us to obtain the optimal document\ntemporal orders. Our rank ordering method significantly improved the temporal\nsequencing of both corpora compared to a randomly sequenced baseline. This\nunsupervised approach should enable the temporal ordering of undated document\nsets.", "published": "2023-11-05 06:51:04", "link": "http://arxiv.org/abs/2311.02578v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "LLM-enhanced Self-training for Cross-domain Constituency Parsing", "abstract": "Self-training has proven to be an effective approach for cross-domain tasks,\nand in this study, we explore its application to cross-domain constituency\nparsing. Traditional self-training methods rely on limited and potentially\nlow-quality raw corpora. To overcome this limitation, we propose enhancing\nself-training with the large language model (LLM) to generate domain-specific\nraw corpora iteratively. For the constituency parsing, we introduce grammar\nrules that guide the LLM in generating raw corpora and establish criteria for\nselecting pseudo instances. Our experimental results demonstrate that\nself-training for constituency parsing, equipped with an LLM, outperforms\ntraditional methods regardless of the LLM's performance. Moreover, the\ncombination of grammar rules and confidence criteria for pseudo-data selection\nyields the highest performance in the cross-domain constituency parsing.", "published": "2023-11-05 14:13:29", "link": "http://arxiv.org/abs/2311.02660v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pyclipse, a library for deidentification of free-text clinical notes", "abstract": "Automated deidentification of clinical text data is crucial due to the high\ncost of manual deidentification, which has been a barrier to sharing clinical\ntext and the advancement of clinical natural language processing. However,\ncreating effective automated deidentification tools faces several challenges,\nincluding issues in reproducibility due to differences in text processing,\nevaluation methods, and a lack of consistency across clinical domains and\ninstitutions. To address these challenges, we propose the pyclipse framework, a\nunified and configurable evaluation procedure to streamline the comparison of\ndeidentification algorithms. Pyclipse serves as a single interface for running\nopen-source deidentification algorithms on local clinical data, allowing for\ncontext-specific evaluation. To demonstrate the utility of pyclipse, we compare\nsix deidentification algorithms across four public and two private clinical\ntext datasets. We find that algorithm performance consistently falls short of\nthe results reported in the original papers, even when evaluated on the same\nbenchmark dataset. These discrepancies highlight the complexity of accurately\nassessing and comparing deidentification algorithms, emphasizing the need for a\nreproducible, adjustable, and extensible framework like pyclipse. Our framework\nlays the foundation for a unified approach to evaluate and improve\ndeidentification tools, ultimately enhancing patient protection in clinical\nnatural language processing.", "published": "2023-11-05 19:56:58", "link": "http://arxiv.org/abs/2311.02748v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "mahaNLP: A Marathi Natural Language Processing Library", "abstract": "We present mahaNLP, an open-source natural language processing (NLP) library\nspecifically built for the Marathi language. It aims to enhance the support for\nthe low-resource Indian language Marathi in the field of NLP. It is an\neasy-to-use, extensible, and modular toolkit for Marathi text analysis built on\nstate-of-the-art MahaBERT-based transformer models. Our work holds significant\nimportance as other existing Indic NLP libraries provide basic Marathi\nprocessing support and rely on older models with restricted performance. Our\ntoolkit stands out by offering a comprehensive array of NLP tasks, encompassing\nboth fundamental preprocessing tasks and advanced NLP tasks like sentiment\nanalysis, NER, hate speech detection, and sentence completion. This paper\nfocuses on an overview of the mahaNLP framework, its features, and its usage.\nThis work is a part of the L3Cube MahaNLP initiative, more information about it\ncan be found at https://github.com/l3cube-pune/MarathiNLP .", "published": "2023-11-05 06:59:59", "link": "http://arxiv.org/abs/2311.02579v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented\n  Generation with an LLM", "abstract": "Fast disaster impact reporting is crucial in planning humanitarian\nassistance. Large Language Models (LLMs) are well known for their ability to\nwrite coherent text and fulfill a variety of tasks relevant to impact\nreporting, such as question answering or text summarization. However, LLMs are\nconstrained by the knowledge within their training data and are prone to\ngenerating inaccurate, or \"hallucinated\", information. To address this, we\nintroduce a sophisticated pipeline embodied in our tool FloodBrain\n(floodbrain.com), specialized in generating flood disaster impact reports by\nextracting and curating information from the web. Our pipeline assimilates\ninformation from web search results to produce detailed and accurate reports on\nflood events. We test different LLMs as backbones in our tool and compare their\ngenerated reports to human-written reports on different metrics. Similar to\nother studies, we find a notable correlation between the scores assigned by\nGPT-4 and the scores given by human evaluators when comparing our generated\nreports to human-authored ones. Additionally, we conduct an ablation study to\ntest our single pipeline components and their relevancy for the final reports.\nWith our tool, we aim to advance the use of LLMs for disaster impact reporting\nand reduce the time for coordination of humanitarian efforts in the wake of\nflood disasters.", "published": "2023-11-05 08:34:26", "link": "http://arxiv.org/abs/2311.02597v1", "categories": ["cs.AI", "cs.CL", "I.2.7"], "primary_category": "cs.AI"}
{"title": "Divide & Conquer for Entailment-aware Multi-hop Evidence Retrieval", "abstract": "Lexical and semantic matches are commonly used as relevance measurements for\ninformation retrieval. Together they estimate the semantic equivalence between\nthe query and the candidates. However, semantic equivalence is not the only\nrelevance signal that needs to be considered when retrieving evidences for\nmulti-hop questions. In this work, we demonstrate that textual entailment\nrelation is another important relevance dimension that should be considered. To\nretrieve evidences that are either semantically equivalent to or entailed by\nthe question simultaneously, we divide the task of evidence retrieval for\nmulti-hop question answering (QA) into two sub-tasks, i.e., semantic textual\nsimilarity and inference similarity retrieval. We propose two ensemble models,\nEAR and EARnest, which tackle each of the sub-tasks separately and then jointly\nre-rank sentences with the consideration of the diverse relevance signals.\nExperimental results on HotpotQA verify that our models not only significantly\noutperform all the single retrieval models it is based on, but is also more\neffective than two intuitive ensemble baseline models.", "published": "2023-11-05 10:31:40", "link": "http://arxiv.org/abs/2311.02616v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE", "abstract": "Recent studies have demonstrated Large Language Models (LLMs) can extend\ntheir zero-shot generalization capabilities to multimodal learning through\ninstruction tuning. As more modalities and downstream tasks are introduced,\nnegative conflicts and interference may have a worse impact on performance.\nWhile this phenomenon has been overlooked in previous work, we propose a novel\nand extensible framework, called Octavius, for comprehensive studies and\nexperimentation on multimodal learning with Multimodal Large Language Models\n(MLLMs). Specifically, we combine the well-known Mixture-of-Experts (MoE) and\none of the representative PEFT techniques, i.e., LoRA, designing a novel\nLLM-based decoder, called LoRA-MoE, for multimodal learning. To the best of our\nknowledge, we are one of the pioneering efforts to introduce MoE into MLLMs to\naddress this problem. The experimental results (about 20% improvement) have\nshown the effectiveness and versatility of our design in various 2D and 3D\ndownstream tasks. Code and datasets are available at\nhttps://openlamm.github.io/tutorial/.", "published": "2023-11-05 15:48:29", "link": "http://arxiv.org/abs/2311.02684v3", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Extraction of Atypical Aspects from Customer Reviews: Datasets and\n  Experiments with Language Models", "abstract": "A restaurant dinner may become a memorable experience due to an unexpected\naspect enjoyed by the customer, such as an origami-making station in the\nwaiting area. If aspects that are atypical for a restaurant experience were\nknown in advance, they could be leveraged to make recommendations that have the\npotential to engender serendipitous experiences, further increasing user\nsatisfaction. Although relatively rare, whenever encountered, atypical aspects\noften end up being mentioned in reviews due to their memorable quality.\nCorrespondingly, in this paper we introduce the task of detecting atypical\naspects in customer reviews. To facilitate the development of extraction\nmodels, we manually annotate benchmark datasets of reviews in three domains -\nrestaurants, hotels, and hair salons, which we use to evaluate a number of\nlanguage models, ranging from fine-tuning the instruction-based text-to-text\ntransformer Flan-T5 to zero-shot and few-shot prompting of GPT-3.5.", "published": "2023-11-05 16:15:50", "link": "http://arxiv.org/abs/2311.02702v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Rule Learning as Machine Translation using the Atomic Knowledge Bank", "abstract": "Machine learning models, and in particular language models, are being applied\nto various tasks that require reasoning. While such models are good at\ncapturing patterns their ability to reason in a trustable and controlled manner\nis frequently questioned. On the other hand, logic-based rule systems allow for\ncontrolled inspection and already established verification methods. However it\nis well-known that creating such systems manually is time-consuming and prone\nto errors. We explore the capability of transformers to translate sentences\nexpressing rules in natural language into logical rules. We see reasoners as\nthe most reliable tools for performing logical reasoning and focus on\ntranslating language into the format expected by such tools. We perform\nexperiments using the DKET dataset from the literature and create a dataset for\nlanguage to logic translation based on the Atomic knowledge bank.", "published": "2023-11-05 20:48:54", "link": "http://arxiv.org/abs/2311.02765v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Robust Generalization Strategies for Morpheme Glossing in an Endangered\n  Language Documentation Context", "abstract": "Generalization is of particular importance in resource-constrained settings,\nwhere the available training data may represent only a small fraction of the\ndistribution of possible texts. We investigate the ability of morpheme labeling\nmodels to generalize by evaluating their performance on unseen genres of text,\nand we experiment with strategies for closing the gap between performance on\nin-distribution and out-of-distribution data. Specifically, we use weight decay\noptimization, output denoising, and iterative pseudo-labeling, and achieve a 2%\nimprovement on a test set containing texts from unseen genres. All experiments\nare performed using texts written in the Mayan language Uspanteko.", "published": "2023-11-05 21:45:57", "link": "http://arxiv.org/abs/2311.02777v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Large language models implicitly learn to straighten neural sentence\n  trajectories to construct a predictive representation of natural language", "abstract": "Predicting upcoming events is critical to our ability to interact with our\nenvironment. Transformer models, trained on next-word prediction, appear to\nconstruct representations of linguistic input that can support diverse\ndownstream tasks. But how does a predictive objective shape such\nrepresentations? Inspired by recent work in vision (Henaff et al., 2019), we\ntest a hypothesis about predictive representations of autoregressive\ntransformers. In particular, we test whether the neural trajectory of a\nsentence becomes progressively straighter as it passes through the network\nlayers. The key insight is that straighter trajectories should facilitate\nprediction via linear extrapolation. We quantify straightness using a\n1-dimensional curvature metric, and present four findings in support of the\ntrajectory straightening hypothesis: i) In trained models, the curvature\ndecreases from the early to the deeper layers of the network. ii) Models that\nperform better on the next-word prediction objective exhibit greater decreases\nin curvature, suggesting that this improved ability to straighten sentence\ntrajectories may be the driver of better language modeling performance. iii)\nGiven the same linguistic context, the sequences that are generated by the\nmodel have lower curvature than the actual continuations observed in a language\ncorpus, suggesting that the model favors straighter trajectories for making\npredictions. iv) A consistent relationship holds between the average curvature\nand the average surprisal of sentences in the deep model layers, such that\nsentences with straighter trajectories also have lower surprisal. Importantly,\nuntrained models do not exhibit these behaviors. In tandem, these results\nsupport the trajectory straightening hypothesis and provide a possible\nmechanism for how the geometry of the internal representations of\nautoregressive models supports next word prediction.", "published": "2023-11-05 22:16:21", "link": "http://arxiv.org/abs/2311.04930v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Evaluating the Potential of Leading Large Language Models in Reasoning\n  Biology Questions", "abstract": "Recent advances in Large Language Models (LLMs) have presented new\nopportunities for integrating Artificial General Intelligence (AGI) into\nbiological research and education. This study evaluated the capabilities of\nleading LLMs, including GPT-4, GPT-3.5, PaLM2, Claude2, and SenseNova, in\nanswering conceptual biology questions. The models were tested on a\n108-question multiple-choice exam covering biology topics in molecular biology,\nbiological techniques, metabolic engineering, and synthetic biology. Among the\nmodels, GPT-4 achieved the highest average score of 90 and demonstrated the\ngreatest consistency across trials with different prompts. The results\nindicated GPT-4's proficiency in logical reasoning and its potential to aid\nbiology research through capabilities like data analysis, hypothesis\ngeneration, and knowledge integration. However, further development and\nvalidation are still required before the promise of LLMs in accelerating\nbiological discovery can be realized.", "published": "2023-11-05 03:34:17", "link": "http://arxiv.org/abs/2311.07582v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Cross-Dialect Sentence Transformation: A Comparative Analysis of\n  Language Models for Adapting Sentences to British English", "abstract": "This study explores linguistic distinctions among American, Indian, and Irish\nEnglish dialects and assesses various Language Models (LLMs) in their ability\nto generate British English translations from these dialects. Using cosine\nsimilarity analysis, the study measures the linguistic proximity between\noriginal British English translations and those produced by LLMs for each\ndialect. The findings reveal that Indian and Irish English translations\nmaintain notably high similarity scores, suggesting strong linguistic alignment\nwith British English. In contrast, American English exhibits slightly lower\nsimilarity, reflecting its distinct linguistic traits. Additionally, the choice\nof LLM significantly impacts translation quality, with Llama-2-70b consistently\ndemonstrating superior performance. The study underscores the importance of\nselecting the right model for dialect translation, emphasizing the role of\nlinguistic expertise and contextual understanding in achieving accurate\ntranslations.", "published": "2023-11-05 12:56:28", "link": "http://arxiv.org/abs/2311.07583v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "UID as a Guiding Metric for Automated Authorship Obfuscation", "abstract": "Protecting the anonymity of authors has become a difficult task given the\nrise of automated authorship attributors. These attributors are capable of\nattributing the author of a text amongst a pool of authors with great accuracy.\nIn order to counter the rise of these automated attributors, there has also\nbeen a rise of automated obfuscators. These obfuscators are capable of taking\nsome text, perturbing the text in some manner, and, if successful, deceive an\nautomated attributor in misattributing the wrong author. We devised three novel\nauthorship obfuscation methods that utilized a Psycho-linguistic theory known\nas Uniform Information Density (UID) theory. This theory states that humans\nevenly distribute information amongst speech or text so as to maximize\nefficiency. Utilizing this theory in our three obfuscation methods, we\nattempted to see how successfully we could deceive two separate attributors.\nObfuscating 50 human and 50 GPT-3 generated articles from the TuringBench\ndataset, we observed how well each method did on deceiving the attributors.\nWhile the quality of the obfuscation in terms of semantic preservation and\nsensical changes was high, we were not able to find any evidence to indicate\nUID was a viable guiding metric for obfuscation. However, due to restrictions\nin time we were unable to test a large enough sample of article or tune the\nparameters for our attributors to comment conclusively on UID in obfuscation.", "published": "2023-11-05 22:16:37", "link": "http://arxiv.org/abs/2312.03709v1", "categories": ["cs.CL", "cs.CR"], "primary_category": "cs.CL"}
{"title": "Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close\n  the Healthcare Loop", "abstract": "To facilitate the advancement of research in healthcare robots without human\nintervention or commands, we introduce the Autonomous Helping Challenge, along\nwith a crowd-sourcing large-scale dataset. The goal is to create healthcare\nrobots that possess the ability to determine when assistance is necessary,\ngenerate useful sub-tasks to aid in planning, carry out these plans through a\nphysical robot, and receive feedback from the environment in order to generate\nnew tasks and continue the process. Besides the general challenge in open-ended\nscenarios, Autonomous Helping focuses on three specific challenges: autonomous\ntask generation, the gap between the current scene and static commonsense, and\nthe gap between language instruction and the real world. Additionally, we\npropose Helpy, a potential approach to close the healthcare loop in the\nlearning-free setting.", "published": "2023-11-05 08:57:59", "link": "http://arxiv.org/abs/2311.02602v1", "categories": ["cs.RO", "cs.AI", "cs.CL"], "primary_category": "cs.RO"}
{"title": "Nepali Video Captioning using CNN-RNN Architecture", "abstract": "This article presents a study on Nepali video captioning using deep neural\nnetworks. Through the integration of pre-trained CNNs and RNNs, the research\nfocuses on generating precise and contextually relevant captions for Nepali\nvideos. The approach involves dataset collection, data preprocessing, model\nimplementation, and evaluation. By enriching the MSVD dataset with Nepali\ncaptions via Google Translate, the study trains various CNN-RNN architectures.\nThe research explores the effectiveness of CNNs (e.g., EfficientNetB0,\nResNet101, VGG16) paired with different RNN decoders like LSTM, GRU, and\nBiLSTM. Evaluation involves BLEU and METEOR metrics, with the best model being\nEfficientNetB0 + BiLSTM with 1024 hidden dimensions, achieving a BLEU-4 score\nof 17 and METEOR score of 46. The article also outlines challenges and future\ndirections for advancing Nepali video captioning, offering a crucial resource\nfor further research in this area.", "published": "2023-11-05 16:09:40", "link": "http://arxiv.org/abs/2311.02699v1", "categories": ["cs.CV", "cs.CL", "cs.LG", "I.2.7; I.2.10"], "primary_category": "cs.CV"}
{"title": "Attention or Convolution: Transformer Encoders in Audio Language Models\n  for Inference Efficiency", "abstract": "In this paper, we show that a simple self-supervised pre-trained audio model\ncan achieve comparable inference efficiency to more complicated pre-trained\nmodels with speech transformer encoders. These speech transformers rely on\nmixing convolutional modules with self-attention modules. They achieve\nstate-of-the-art performance on ASR with top efficiency. We first show that\nemploying these speech transformers as an encoder significantly improves the\nefficiency of pre-trained audio models as well. However, our study shows that\nwe can achieve comparable efficiency with advanced self-attention solely. We\ndemonstrate that this simpler approach is particularly beneficial with a\nlow-bit weight quantization technique of a neural network to improve\nefficiency. We hypothesize that it prevents propagating the errors between\ndifferent quantized modules compared to recent speech transformers mixing\nquantized convolution and the quantized self-attention modules.", "published": "2023-11-05 21:30:10", "link": "http://arxiv.org/abs/2311.02772v2", "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AI-TA: Towards an Intelligent Question-Answer Teaching Assistant using\n  Open-Source LLMs", "abstract": "Responding to the thousands of student questions on online QA platforms each\nsemester has a considerable human cost, particularly in computing courses with\nrapidly growing enrollments. To address the challenges of scalable and\nintelligent question-answering (QA), we introduce an innovative solution that\nleverages open-source Large Language Models (LLMs) from the LLaMA-2 family to\nensure data privacy. Our approach combines augmentation techniques such as\nretrieval augmented generation (RAG), supervised fine-tuning (SFT), and\nlearning from human preferences data using Direct Preference Optimization\n(DPO). Through extensive experimentation on a Piazza dataset from an\nintroductory CS course, comprising 10,000 QA pairs and 1,500 pairs of\npreference data, we demonstrate a significant 30% improvement in the quality of\nanswers, with RAG being a particularly impactful addition. Our contributions\ninclude the development of a novel architecture for educational QA, extensive\nevaluations of LLM performance utilizing both human assessments and LLM-based\nmetrics, and insights into the challenges and future directions of educational\ndata processing. This work paves the way for the development of AI-TA, an\nintelligent QA assistant customizable for courses with an online QA platform", "published": "2023-11-05 21:43:02", "link": "http://arxiv.org/abs/2311.02775v3", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "CausalCite: A Causal Formulation of Paper Citations", "abstract": "Citation count of a paper is a commonly used proxy for evaluating the\nsignificance of a paper in the scientific community. Yet citation measures are\nwidely criticized for failing to accurately reflect the true impact of a paper.\nThus, we propose CausalCite, a new way to measure the significance of a paper\nby assessing the causal impact of the paper on its follow-up papers. CausalCite\nis based on a novel causal inference method, TextMatch, which adapts the\ntraditional matching framework to high-dimensional text embeddings. TextMatch\nencodes each paper using text embeddings from large language models (LLMs),\nextracts similar samples by cosine similarity, and synthesizes a counterfactual\nsample as the weighted average of similar papers according to their similarity\nvalues. We demonstrate the effectiveness of CausalCite on various criteria,\nsuch as high correlation with paper impact as reported by scientific experts on\na previous dataset of 1K papers, (test-of-time) awards for past papers, and its\nstability across various subfields of AI. We also provide a set of findings\nthat can serve as suggested ways for future researchers to use our metric for a\nbetter understanding of the quality of a paper. Our code is available at\nhttps://github.com/causalNLP/causal-cite.", "published": "2023-11-05 23:09:39", "link": "http://arxiv.org/abs/2311.02790v3", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Yet Another Generative Model For Room Impulse Response Estimation", "abstract": "Recent neural room impulse response (RIR) estimators typically comprise an\nencoder for reference audio analysis and a generator for RIR synthesis.\nEspecially, it is the performance of the generator that directly influences the\noverall estimation quality. In this context, we explore an alternate generator\narchitecture for improved performance. We first train an autoencoder with\nresidual quantization to learn a discrete latent token space, where each token\nrepresents a small time-frequency patch of the RIR. Then, we cast the RIR\nestimation problem as a reference-conditioned autoregressive token generation\ntask, employing transformer variants that operate across frequency, time, and\nquantization depth axes. This way, we address the standard blind estimation\ntask and additional acoustic matching problem, which aims to find an RIR that\nmatches the source signal to the target signal's reverberation characteristics.\nExperimental results show that our system is preferable to other baselines\nacross various evaluation metrics.", "published": "2023-11-05 07:25:39", "link": "http://arxiv.org/abs/2311.02581v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency\n  for Video Deepfake Detection", "abstract": "Multimodal manipulations (also known as audio-visual deepfakes) make it\ndifficult for unimodal deepfake detectors to detect forgeries in multimedia\ncontent. To avoid the spread of false propaganda and fake news, timely\ndetection is crucial. The damage to either modality (i.e., visual or audio) can\nonly be discovered through multi-modal models that can exploit both pieces of\ninformation simultaneously. Previous methods mainly adopt uni-modal video\nforensics and use supervised pre-training for forgery detection. This study\nproposes a new method based on a multi-modal self-supervised-learning (SSL)\nfeature extractor to exploit inconsistency between audio and visual modalities\nfor multi-modal video forgery detection. We use the transformer-based SSL\npre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic\nfeature extractor and a multi-scale temporal convolutional neural network to\ncapture the temporal correlation between the audio and visual modalities. Since\nAV-HuBERT only extracts visual features from the lip region, we also adopt\nanother transformer-based video model to exploit facial features and capture\nspatial and temporal artifacts caused during the deepfake generation process.\nExperimental results show that our model outperforms all existing models and\nachieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT\ndatasets.", "published": "2023-11-05 18:35:03", "link": "http://arxiv.org/abs/2311.02733v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
