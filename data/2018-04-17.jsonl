{"title": "Learning Joint Semantic Parsers from Disjoint Data", "abstract": "We present a new approach to learning semantic parsers from multiple\ndatasets, even when the target semantic formalisms are drastically different,\nand the underlying corpora do not overlap. We handle such \"disjoint\" data by\ntreating annotations for unobserved formalisms as latent structured variables.\nBuilding on state-of-the-art baselines, we show improvements both in\nframe-semantic parsing and semantic dependency parsing by modeling them\njointly.", "published": "2018-04-17 00:14:32", "link": "http://arxiv.org/abs/1804.05990v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Monte Carlo Syntax Marginals for Exploring and Using Dependency Parses", "abstract": "Dependency parsing research, which has made significant gains in recent\nyears, typically focuses on improving the accuracy of single-tree predictions.\nHowever, ambiguity is inherent to natural language syntax, and communicating\nsuch ambiguity is important for error analysis and better-informed downstream\napplications. In this work, we propose a transition sampling algorithm to\nsample from the full joint distribution of parse trees defined by a\ntransition-based parsing model, and demonstrate the use of the samples in\nprobabilistic dependency analysis. First, we define the new task of dependency\npath prediction, inferring syntactic substructures over part of a sentence, and\nprovide the first analysis of performance on this task. Second, we demonstrate\nthe usefulness of our Monte Carlo syntax marginal method for parser error\nanalysis and calibration. Finally, we use this method to propagate parse\nuncertainty to two downstream information extraction applications: identifying\npersons killed by police and semantic role assignment.", "published": "2018-04-17 01:22:41", "link": "http://arxiv.org/abs/1804.06004v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fortification of Neural Morphological Segmentation Models for\n  Polysynthetic Minimal-Resource Languages", "abstract": "Morphological segmentation for polysynthetic languages is challenging,\nbecause a word may consist of many individual morphemes and training data can\nbe extremely scarce. Since neural sequence-to-sequence (seq2seq) models define\nthe state of the art for morphological segmentation in high-resource settings\nand for (mostly) European languages, we first show that they also obtain\ncompetitive performance for Mexican polysynthetic languages in minimal-resource\nsettings. We then propose two novel multi-task training approaches -one with,\none without need for external unlabeled resources-, and two corresponding data\naugmentation methods, improving over the neural baseline for all languages.\nFinally, we explore cross-lingual transfer as a third way to fortify our neural\nmodel and show that we can train one single multi-lingual model for related\nlanguages while maintaining comparable or even improved performance, thus\nreducing the amount of parameters by close to 75%. We provide our morphological\nsegmentation datasets for Mexicanero, Nahuatl, Wixarika and Yorem Nokki for\nfuture research.", "published": "2018-04-17 03:10:51", "link": "http://arxiv.org/abs/1804.06024v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "ListOps: A Diagnostic Dataset for Latent Tree Learning", "abstract": "Latent tree learning models learn to parse a sentence without syntactic\nsupervision, and use that parse to build the sentence representation. Existing\nwork on such models has shown that, while they perform well on tasks like\nsentence classification, they do not learn grammars that conform to any\nplausible semantic or syntactic formalism (Williams et al., 2018a). Studying\nthe parsing ability of such models in natural language can be challenging due\nto the inherent complexities of natural language, like having several valid\nparses for a single sentence. In this paper we introduce ListOps, a toy dataset\ncreated to study the parsing ability of latent tree models. ListOps sequences\nare in the style of prefix arithmetic. The dataset is designed to have a single\ncorrect parsing strategy that a system needs to learn to succeed at the task.\nWe show that the current leading latent tree models are unable to learn to\nparse and succeed at ListOps. These models achieve accuracies worse than purely\nsequential RNNs.", "published": "2018-04-17 03:26:28", "link": "http://arxiv.org/abs/1804.06028v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Reinforced Co-Training", "abstract": "Co-training is a popular semi-supervised learning framework to utilize a\nlarge amount of unlabeled data in addition to a small labeled set. Co-training\nmethods exploit predicted labels on the unlabeled data and select samples based\non prediction confidence to augment the training. However, the selection of\nsamples in existing co-training methods is based on a predetermined policy,\nwhich ignores the sampling bias between the unlabeled and the labeled subsets,\nand fails to explore the data space. In this paper, we propose a novel method,\nReinforced Co-Training, to select high-quality unlabeled samples to better\nco-train on. More specifically, our approach uses Q-learning to learn a data\nselection policy with a small labeled dataset, and then exploits this policy to\ntrain the co-training classifiers automatically. Experimental results on\nclickbait detection and generic text classification tasks demonstrate that our\nproposed method can obtain more accurate text classification results.", "published": "2018-04-17 03:41:55", "link": "http://arxiv.org/abs/1804.06035v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Adversarial Example Generation with Syntactically Controlled Paraphrase\n  Networks", "abstract": "We propose syntactically controlled paraphrase networks (SCPNs) and use them\nto generate adversarial examples. Given a sentence and a target syntactic form\n(e.g., a constituency parse), SCPNs are trained to produce a paraphrase of the\nsentence with the desired syntax. We show it is possible to create training\ndata for this task by first doing backtranslation at a very large scale, and\nthen using a parser to label the syntactic transformations that naturally occur\nduring this process. Such data allows us to train a neural encoder-decoder\nmodel with extra inputs to specify the target syntax. A combination of\nautomated and human evaluations show that SCPNs generate paraphrases that\nfollow their target specifications without decreasing paraphrase quality when\ncompared to baseline (uncontrolled) paraphrase systems. Furthermore, they are\nmore capable of generating syntactically adversarial examples that both (1)\n\"fool\" pretrained models and (2) improve the robustness of these models to\nsyntactic variation when used to augment their training data.", "published": "2018-04-17 06:12:36", "link": "http://arxiv.org/abs/1804.06059v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "SeerNet at SemEval-2018 Task 1: Domain Adaptation for Affect in Tweets", "abstract": "The paper describes the best performing system for the SemEval-2018 Affect in\nTweets (English) sub-tasks. The system focuses on the ordinal classification\nand regression sub-tasks for valence and emotion. For ordinal classification\nvalence is classified into 7 different classes ranging from -3 to 3 whereas\nemotion is classified into 4 different classes 0 to 3 separately for each\nemotion namely anger, fear, joy and sadness. The regression sub-tasks estimate\nthe intensity of valence and each emotion. The system performs domain\nadaptation of 4 different models and creates an ensemble to give the final\nprediction. The proposed system achieved 1st position out of 75 teams which\nparticipated in the fore-mentioned sub-tasks. We outperform the baseline model\nby margins ranging from 49.2% to 76.4%, thus, pushing the state-of-the-art\nsignificantly.", "published": "2018-04-17 09:50:01", "link": "http://arxiv.org/abs/1804.06137v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Investigating Backtranslation in Neural Machine Translation", "abstract": "A prerequisite for training corpus-based machine translation (MT) systems --\neither Statistical MT (SMT) or Neural MT (NMT) -- is the availability of\nhigh-quality parallel data. This is arguably more important today than ever\nbefore, as NMT has been shown in many studies to outperform SMT, but mostly\nwhen large parallel corpora are available; in cases where data is limited, SMT\ncan still outperform NMT.\n  Recently researchers have shown that back-translating monolingual data can be\nused to create synthetic parallel corpora, which in turn can be used in\ncombination with authentic parallel data to train a high-quality NMT system.\nGiven that large collections of new parallel text become available only quite\nrarely, backtranslation has become the norm when building state-of-the-art NMT\nsystems, especially in resource-poor scenarios.\n  However, we assert that there are many unknown factors regarding the actual\neffects of back-translated data on the translation capabilities of an NMT\nmodel. Accordingly, in this work we investigate how using back-translated data\nas a training corpus -- both as a separate standalone dataset as well as\ncombined with human-generated parallel data -- affects the performance of an\nNMT model. We use incrementally larger amounts of back-translated data to train\na range of NMT systems for German-to-English, and analyse the resulting\ntranslation performance.", "published": "2018-04-17 12:16:25", "link": "http://arxiv.org/abs/1804.06189v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When and Why are Pre-trained Word Embeddings Useful for Neural Machine\n  Translation?", "abstract": "The performance of Neural Machine Translation (NMT) systems often suffers in\nlow-resource scenarios where sufficiently large-scale parallel corpora cannot\nbe obtained. Pre-trained word embeddings have proven to be invaluable for\nimproving performance in natural language analysis tasks, which often suffer\nfrom paucity of data. However, their utility for NMT has not been extensively\nexplored. In this work, we perform five sets of experiments that analyze when\nwe can expect pre-trained word embeddings to help in NMT tasks. We show that\nsuch embeddings can be surprisingly effective in some cases -- providing gains\nof up to 20 BLEU points in the most favorable setting.", "published": "2018-04-17 15:34:07", "link": "http://arxiv.org/abs/1804.06323v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Similarity between Learning Outcomes from Course Objectives using\n  Semantic Analysis, Blooms taxonomy and Corpus statistics", "abstract": "The course description provided by instructors is an essential piece of\ninformation as it defines what is expected from the instructor and what he/she\nis going to deliver during a particular course. One of the key components of a\ncourse description is the Learning Objectives section. The contents of this\nsection are used by program managers who are tasked to compare and match two\ndifferent courses during the development of Transfer Agreements between various\ninstitutions. This research introduces the development of semantic similarity\nalgorithms to calculate the similarity between two learning objectives of the\nsame domain. We present a novel methodology which deals with the semantic\nsimilarity by using a previously established algorithm and integrating it with\nthe domain corpus utilizing domain statistics. The disambiguated domain serves\nas a supervised learning data for the algorithm. We also introduce Bloom Index\nto calculate the similarity between action verbs in the Learning Objectives\nreferring to the Blooms taxonomy.", "published": "2018-04-17 15:54:25", "link": "http://arxiv.org/abs/1804.06333v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bootstrapping Generators from Noisy Data", "abstract": "A core step in statistical data-to-text generation concerns learning\ncorrespondences between structured data representations (e.g., facts in a\ndatabase) and associated texts. In this paper we aim to bootstrap generators\nfrom large scale datasets where the data (e.g., DBPedia facts) and related\ntexts (e.g., Wikipedia abstracts) are loosely aligned. We tackle this\nchallenging task by introducing a special-purpose content selection mechanism.\nWe use multi-instance learning to automatically discover correspondences\nbetween data and text pairs and show how these can be used to enhance the\ncontent signal while training an encoder-decoder architecture. Experimental\nresults demonstrate that models trained with content-specific objectives\nimprove upon a vanilla encoder-decoder which solely relies on soft attention.", "published": "2018-04-17 17:30:02", "link": "http://arxiv.org/abs/1804.06385v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style\n  Transfer", "abstract": "We consider the task of text attribute transfer: transforming a sentence to\nalter a specific attribute (e.g., sentiment) while preserving its\nattribute-independent content (e.g., changing \"screen is just the right size\"\nto \"screen is too small\"). Our training data includes only sentences labeled\nwith their attribute (e.g., positive or negative), but not pairs of sentences\nthat differ only in their attributes, so we must learn to disentangle\nattributes from attribute-independent content in an unsupervised way. Previous\nwork using adversarial methods has struggled to produce high-quality outputs.\nIn this paper, we propose simpler methods motivated by the observation that\ntext attributes are often marked by distinctive phrases (e.g., \"too small\").\nOur strongest method extracts content words by deleting phrases associated with\nthe sentence's original attribute value, retrieves new phrases associated with\nthe target attribute, and uses a neural model to fluently combine these into a\nfinal output. On human evaluation, our best method generates grammatical and\nappropriate responses on 22% more inputs than the best previous system,\naveraged over three attribute transfer datasets: altering sentiment of reviews\non Yelp, altering sentiment of reviews on Amazon, and altering image captions\nto be more romantic or humorous.", "published": "2018-04-17 18:59:51", "link": "http://arxiv.org/abs/1804.06437v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Detecting Linguistic Characteristics of Alzheimer's Dementia by\n  Interpreting Neural Models", "abstract": "Alzheimer's disease (AD) is an irreversible and progressive brain disease\nthat can be stopped or slowed down with medical treatment. Language changes\nserve as a sign that a patient's cognitive functions have been impacted,\npotentially leading to early diagnosis. In this work, we use NLP techniques to\nclassify and analyze the linguistic characteristics of AD patients using the\nDementiaBank dataset. We apply three neural models based on CNNs, LSTM-RNNs,\nand their combination, to distinguish between language samples from AD and\ncontrol patients. We achieve a new independent benchmark accuracy for the AD\nclassification task. More importantly, we next interpret what these neural\nmodels have learned about the linguistic characteristics of AD patients, via\nanalysis based on activation clustering and first-derivative saliency\ntechniques. We then perform novel automatic pattern discovery inside activation\nclusters, and consolidate AD patients' distinctive grammar patterns.\nAdditionally, we show that first derivative saliency can not only rediscover\nprevious language patterns of AD patients, but also shed light on the\nlimitations of neural models. Lastly, we also include analysis of\ngender-separated AD data.", "published": "2018-04-17 19:17:05", "link": "http://arxiv.org/abs/1804.06440v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Robust Machine Comprehension Models via Adversarial Training", "abstract": "It is shown that many published models for the Stanford Question Answering\nDataset (Rajpurkar et al., 2016) lack robustness, suffering an over 50%\ndecrease in F1 score during adversarial evaluation based on the AddSent (Jia\nand Liang, 2017) algorithm. It has also been shown that retraining models on\ndata generated by AddSent has limited effect on their robustness. We propose a\nnovel alternative adversary-generation algorithm, AddSentDiverse, that\nsignificantly increases the variance within the adversarial training data by\nproviding effective examples that punish the model for making certain\nsuperficial assumptions. Further, in order to improve robustness to AddSent's\nsemantic perturbations (e.g., antonyms), we jointly improve the model's\nsemantic-relationship learning capabilities in addition to our\nAddSentDiverse-based adversarial training data augmentation. With these\nadditions, we show that we can make a state-of-the-art model significantly more\nrobust, achieving a 36.5% increase in F1 score under many different types of\nadversarial evaluation while maintaining performance on the regular SQuAD task.", "published": "2018-04-17 21:24:20", "link": "http://arxiv.org/abs/1804.06473v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Improving Character-based Decoding Using Target-Side Morphological\n  Information for Neural Machine Translation", "abstract": "Recently, neural machine translation (NMT) has emerged as a powerful\nalternative to conventional statistical approaches. However, its performance\ndrops considerably in the presence of morphologically rich languages (MRLs).\nNeural engines usually fail to tackle the large vocabulary and high\nout-of-vocabulary (OOV) word rate of MRLs. Therefore, it is not suitable to\nexploit existing word-based models to translate this set of languages. In this\npaper, we propose an extension to the state-of-the-art model of Chung et al.\n(2016), which works at the character level and boosts the decoder with\ntarget-side morphological information. In our architecture, an additional\nmorphology table is plugged into the model. Each time the decoder samples from\na target vocabulary, the table sends auxiliary signals from the most relevant\naffixes in order to enrich the decoder's current state and constrain it to\nprovide better predictions. We evaluated our model to translate English into\nGerman, Russian, and Turkish as three MRLs and observed significant\nimprovements.", "published": "2018-04-17 23:54:26", "link": "http://arxiv.org/abs/1804.06506v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Learning to Color from Language", "abstract": "Automatic colorization is the process of adding color to greyscale images. We\ncondition this process on language, allowing end users to manipulate a\ncolorized image by feeding in different captions. We present two different\narchitectures for language-conditioned colorization, both of which produce more\naccurate and plausible colorizations than a language-agnostic version. Through\nthis language-based framework, we can dramatically alter colorizations by\nmanipulating descriptive color words in captions.", "published": "2018-04-17 03:22:00", "link": "http://arxiv.org/abs/1804.06026v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Personalized neural language models for real-world query auto completion", "abstract": "Query auto completion (QAC) systems are a standard part of search engines in\nindustry, helping users formulate their query. Such systems update their\nsuggestions after the user types each character, predicting the user's intent\nusing various signals - one of the most common being popularity. Recently, deep\nlearning approaches have been proposed for the QAC task, to specifically\naddress the main limitation of previous popularity-based methods: the inability\nto predict unseen queries. In this work we improve previous methods based on\nneural language modeling, with the goal of building an end-to-end system. We\nparticularly focus on using real-world data by integrating user information for\npersonalized suggestions when possible. We also make use of time information\nand study how to increase diversity in the suggestions while studying the\nimpact on scalability. Our empirical results demonstrate a marked improvement\non two separate datasets over previous best methods in both accuracy and\nscalability, making a step towards neural query auto-completion in production\nsearch engines.", "published": "2018-04-17 19:11:14", "link": "http://arxiv.org/abs/1804.06439v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "LCMR: Local and Centralized Memories for Collaborative Filtering with\n  Unstructured Text", "abstract": "Collaborative filtering (CF) is the key technique for recommender systems.\nPure CF approaches exploit the user-item interaction data (e.g., clicks, likes,\nand views) only and suffer from the sparsity issue. Items are usually\nassociated with content information such as unstructured text (e.g., abstracts\nof articles and reviews of products). CF can be extended to leverage text. In\nthis paper, we develop a unified neural framework to exploit interaction data\nand content information seamlessly. The proposed framework, called LCMR, is\nbased on memory networks and consists of local and centralized memories for\nexploiting content information and interaction data, respectively. By modeling\ncontent information as local memories, LCMR attentively learns what to exploit\nwith the guidance of user-item interaction. On real-world datasets, LCMR shows\nbetter performance by comparing with various baselines in terms of the hit\nratio and NDCG metrics. We further conduct analyses to understand how local and\ncentralized memories work for the proposed framework.", "published": "2018-04-17 12:32:23", "link": "http://arxiv.org/abs/1804.06201v2", "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Multi-Reward Reinforced Summarization with Saliency and Entailment", "abstract": "Abstractive text summarization is the task of compressing and rewriting a\nlong document into a short summary while maintaining saliency, directed logical\nentailment, and non-redundancy. In this work, we address these three important\naspects of a good summary via a reinforcement learning approach with two novel\nreward functions: ROUGESal and Entail, on top of a coverage-based baseline. The\nROUGESal reward modifies the ROUGE metric by up-weighting the salient\nphrases/words detected via a keyphrase classifier. The Entail reward gives high\n(length-normalized) scores to logically-entailed summaries using an entailment\nclassifier. Further, we show superior performance improvement when these\nrewards are combined with traditional metric (ROUGE) based rewards, via our\nnovel and effective multi-reward approach of optimizing multiple rewards\nsimultaneously in alternate mini-batches. Our method achieves the new\nstate-of-the-art results (including human evaluation) on the CNN/Daily Mail\ndataset as well as strong improvements in a test-only transfer setup on\nDUC-2002.", "published": "2018-04-17 19:39:26", "link": "http://arxiv.org/abs/1804.06451v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Precise Detection of Speech Endpoints Dynamically: A Wavelet Convolution\n  based approach", "abstract": "Precise detection of speech endpoints is an important factor which affects\nthe performance of the systems where speech utterances need to be extracted\nfrom the speech signal such as Automatic Speech Recognition (ASR) system.\nExisting endpoint detection (EPD) methods mostly uses Short-Term Energy (STE),\nZero-Crossing Rate (ZCR) based approaches and their variants. But STE and ZCR\nbased EPD algorithms often fail in the presence of Non-speech Sound Artifacts\n(NSAs) produced by the speakers. Algorithms based on pattern recognition and\nclassification techniques are also proposed but require labeled data for\ntraining. A new algorithm termed as Wavelet Convolution based Speech Endpoint\nDetection (WCSEPD) is proposed in this article to extract speech endpoints.\nWCSEPD decomposes the speech signal into high-frequency and low-frequency\ncomponents using wavelet convolution and computes entropy based thresholds for\nthe two frequency components. The low-frequency thresholds are used to extract\nvoiced speech segments, whereas the high-frequency thresholds are used to\nextract the unvoiced speech segments by filtering out the NSAs. WCSEPD does not\nrequire any labeled data for training and can automatically extract speech\nsegments. Experiment results show that the proposed algorithm precisely\nextracts speech endpoints in the presence of NSAs.", "published": "2018-04-17 10:53:30", "link": "http://arxiv.org/abs/1804.06159v1", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "The 2018 Signal Separation Evaluation Campaign", "abstract": "This paper reports the organization and results for the 2018 community-based\nSignal Separation Evaluation Campaign (SiSEC 2018). This year's edition was\nfocused on audio and pursued the effort towards scaling up and making it easier\nto prototype audio separation software in an era of machine-learning based\nsystems. For this purpose, we prepared a new music separation database:\nMUSDB18, featuring close to 10h of audio. Additionally, open-source software\nwas released to automatically load, process and report performance on MUSDB18.\nFurthermore, a new official Python version for the BSSEval toolbox was\nreleased, along with reference implementations for three oracle separation\nmethods: ideal binary mask, ideal ratio mask, and multichannel Wiener filter.\nWe finally report the results obtained by the participants.", "published": "2018-04-17 14:04:21", "link": "http://arxiv.org/abs/1804.06267v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
