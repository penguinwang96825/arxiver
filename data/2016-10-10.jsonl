{"title": "A Dynamic Window Neural Network for CCG Supertagging", "abstract": "Combinatory Category Grammar (CCG) supertagging is a task to assign lexical\ncategories to each word in a sentence. Almost all previous methods use fixed\ncontext window sizes as input features. However, it is obvious that different\ntags usually rely on different context window sizes. These motivate us to build\na supertagger with a dynamic window approach, which can be treated as an\nattention mechanism on the local contexts. Applying dropout on the dynamic\nfilters can be seen as drop on words directly, which is superior to the regular\ndropout on word embeddings. We use this approach to demonstrate the\nstate-of-the-art CCG supertagging performance on the standard test set.", "published": "2016-10-10 01:47:50", "link": "http://arxiv.org/abs/1610.02749v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modelling Sentence Pairs with Tree-structured Attentive Encoder", "abstract": "We describe an attentive encoder that combines tree-structured recursive\nneural networks and sequential recurrent neural networks for modelling sentence\npairs. Since existing attentive models exert attention on the sequential\nstructure, we propose a way to incorporate attention into the tree topology.\nSpecially, given a pair of sentences, our attentive encoder uses the\nrepresentation of one sentence, which generated via an RNN, to guide the\nstructural encoding of the other sentence on the dependency parse tree. We\nevaluate the proposed attentive encoder on three tasks: semantic similarity,\nparaphrase identification and true-false question selection. Experimental\nresults show that our encoder outperforms all baselines and achieves\nstate-of-the-art results on two tasks.", "published": "2016-10-10 08:52:36", "link": "http://arxiv.org/abs/1610.02806v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Very Deep Convolutional Networks for End-to-End Speech Recognition", "abstract": "Sequence-to-sequence models have shown success in end-to-end speech\nrecognition. However these models have only used shallow acoustic encoder\nnetworks. In our work, we successively train very deep convolutional networks\nto add more expressive power and better generalization for end-to-end ASR\nmodels. We apply network-in-network principles, batch normalization, residual\nconnections and convolutional LSTMs to build very deep recurrent and\nconvolutional structures. Our models exploit the spectral structure in the\nfeature space and add computational depth without overfitting issues. We\nexperiment with the WSJ ASR task and achieve 10.5\\% word error rate without any\ndictionary or language using a 15 layer deep network.", "published": "2016-10-10 18:43:58", "link": "http://arxiv.org/abs/1610.03022v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Neural Paraphrase Generation with Stacked Residual LSTM Networks", "abstract": "In this paper, we propose a novel neural approach for paraphrase generation.\nConventional para- phrase generation methods either leverage hand-written rules\nand thesauri-based alignments, or use statistical machine learning principles.\nTo the best of our knowledge, this work is the first to explore deep learning\nmodels for paraphrase generation. Our primary contribution is a stacked\nresidual LSTM network, where we add residual connections between LSTM layers.\nThis allows for efficient training of deep LSTMs. We evaluate our model and\nother state-of-the-art deep learning models on three different datasets: PPDB,\nWikiAnswers and MSCOCO. Evaluation results demonstrate that our model\noutperforms sequence to sequence, attention-based and bi- directional LSTM\nmodels on BLEU, METEOR, TER and an embedding-based sentence similarity metric.", "published": "2016-10-10 21:01:00", "link": "http://arxiv.org/abs/1610.03098v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Leveraging Recurrent Neural Networks for Multimodal Recognition of\n  Social Norm Violation in Dialog", "abstract": "Social norms are shared rules that govern and facilitate social interaction.\nViolating such social norms via teasing and insults may serve to upend power\nimbalances or, on the contrary reinforce solidarity and rapport in\nconversation, rapport which is highly situated and context-dependent. In this\nwork, we investigate the task of automatically identifying the phenomena of\nsocial norm violation in discourse. Towards this goal, we leverage the power of\nrecurrent neural networks and multimodal information present in the\ninteraction, and propose a predictive model to recognize social norm violation.\nUsing long-term temporal and contextual information, our model achieves an F1\nscore of 0.705. Implications of our work regarding developing a social-aware\nagent are discussed.", "published": "2016-10-10 22:08:13", "link": "http://arxiv.org/abs/1610.03112v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "A New Theoretical and Technological System of Imprecise-Information\n  Processing", "abstract": "Imprecise-information processing will play an indispensable role in\nintelligent systems, especially in the anthropomorphic intelligent systems (as\nintelligent robots). A new theoretical and technological system of\nimprecise-information processing has been founded in Principles of\nImprecise-Information Processing: A New Theoretical and Technological System[1]\nwhich is different from fuzzy technology. The system has clear hierarchy and\nrigorous structure, which results from the formation principle of imprecise\ninformation and has solid mathematical and logical bases, and which has many\nadvantages beyond fuzzy technology. The system provides a technological\nplatform for relevant applications and lays a theoretical foundation for\nfurther research.", "published": "2016-10-10 02:14:16", "link": "http://arxiv.org/abs/1610.02751v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Investigation of Synthetic Speech Detection Using Frame- and\n  Segment-Specific Importance Weighting", "abstract": "Speaker verification systems are vulnerable to spoofing attacks which\npresents a major problem in their real-life deployment. To date, most of the\nproposed synthetic speech detectors (SSDs) have weighted the importance of\ndifferent segments of speech equally. However, different attack methods have\ndifferent strengths and weaknesses and the traces that they leave may be short\nor long term acoustic artifacts. Moreover, those may occur for only particular\nphonemes or sounds. Here, we propose three algorithms that weigh\nlikelihood-ratio scores of individual frames, phonemes, and sound-classes\ndepending on their importance for the SSD. Significant improvement over the\nbaseline system has been obtained for known attack methods that were used in\ntraining the SSDs. However, improvement with unknown attack types was not\nsubstantial. Thus, the type of distortions that were caused by the unknown\nsystems were different and could not be captured better with the proposed SSD\ncompared to the baseline SSD.", "published": "2016-10-10 18:03:29", "link": "http://arxiv.org/abs/1610.03009v1", "categories": ["cs.SD", "cs.CL"], "primary_category": "cs.SD"}
{"title": "Fully Character-Level Neural Machine Translation without Explicit\n  Segmentation", "abstract": "Most existing machine translation systems operate at the level of words,\nrelying on explicit segmentation to extract tokens. We introduce a neural\nmachine translation (NMT) model that maps a source character sequence to a\ntarget character sequence without any segmentation. We employ a character-level\nconvolutional network with max-pooling at the encoder to reduce the length of\nsource representation, allowing the model to be trained at a speed comparable\nto subword-level models while capturing local regularities. Our\ncharacter-to-character model outperforms a recently proposed baseline with a\nsubword-level encoder on WMT'15 DE-EN and CS-EN, and gives comparable\nperformance on FI-EN and RU-EN. We then demonstrate that it is possible to\nshare a single character-level encoder across multiple languages by training a\nmodel on a many-to-one translation task. In this multilingual setting, the\ncharacter-level encoder significantly outperforms the subword-level encoder on\nall the language pairs. We observe that on CS-EN, FI-EN and RU-EN, the quality\nof the multilingual character-level translation even surpasses the models\nspecifically trained on that language pair alone, both in terms of BLEU score\nand human judgment.", "published": "2016-10-10 18:19:34", "link": "http://arxiv.org/abs/1610.03017v3", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Correlation-Based Method for Sentiment Classification", "abstract": "The classic supervised classification algorithms are efficient, but\ntime-consuming, complicated and not interpretable, which makes it difficult to\nanalyze their results that limits the possibility to improve them based on real\nobservations. In this paper, we propose a new and a simple classifier to\npredict a sentiment label of a short text. This model keeps the capacity of\nhuman interpret-ability and can be extended to integrate NLP techniques in a\nmore interpretable way. Our model is based on a correlation metric which\nmeasures the degree of association between a sentiment label and a word. Ten\ncorrelation metrics are proposed and evaluated intrinsically. And then a\nclassifier based on each metric is proposed, evaluated and compared to the\nclassic classification algorithms which have proved their performance in many\nstudies. Our model outperforms these algorithms with several correlation\nmetrics.", "published": "2016-10-10 22:35:21", "link": "http://arxiv.org/abs/1610.03120v2", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Personalizing a Dialogue System with Transfer Reinforcement Learning", "abstract": "It is difficult to train a personalized task-oriented dialogue system because\nthe data collected from each individual is often insufficient. Personalized\ndialogue systems trained on a small dataset can overfit and make it difficult\nto adapt to different user needs. One way to solve this problem is to consider\na collection of multiple users' data as a source domain and an individual\nuser's data as a target domain, and to perform a transfer learning from the\nsource to the target domain. By following this idea, we propose\n\"PETAL\"(PErsonalized Task-oriented diALogue), a transfer-learning framework\nbased on POMDP to learn a personalized dialogue system. The system first learns\ncommon dialogue knowledge from the source domain and then adapts this knowledge\nto the target user. This framework can avoid the negative transfer problem by\nconsidering differences between source and target users. The policy in the\npersonalized POMDP can learn to choose different actions appropriately for\ndifferent users. Experimental results on a real-world coffee-shopping data and\nsimulation data show that our personalized dialogue system can choose different\noptimal actions for different users, and thus effectively improve the dialogue\nquality under the personalized setting.", "published": "2016-10-10 12:51:05", "link": "http://arxiv.org/abs/1610.02891v3", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "A General Framework for Content-enhanced Network Representation Learning", "abstract": "This paper investigates the problem of network embedding, which aims at\nlearning low-dimensional vector representation of nodes in networks. Most\nexisting network embedding methods rely solely on the network structure, i.e.,\nthe linkage relationships between nodes, but ignore the rich content\ninformation associated with it, which is common in real world networks and\nbeneficial to describing the characteristics of a node. In this paper, we\npropose content-enhanced network embedding (CENE), which is capable of jointly\nleveraging the network structure and the content information. Our approach\nintegrates text modeling and structure modeling in a general framework by\ntreating the content information as a special kind of node. Experiments on\nseveral real world net- works with application to node classification show that\nour models outperform all existing network embedding methods, demonstrating the\nmerits of content information and joint learning.", "published": "2016-10-10 13:27:01", "link": "http://arxiv.org/abs/1610.02906v3", "categories": ["cs.SI", "cs.CL", "cs.LG"], "primary_category": "cs.SI"}
{"title": "Latent Sequence Decompositions", "abstract": "We present the Latent Sequence Decompositions (LSD) framework. LSD decomposes\nsequences with variable lengthed output units as a function of both the input\nsequence and the output sequence. We present a training algorithm which samples\nvalid extensions and an approximate decoding algorithm. We experiment with the\nWall Street Journal speech recognition task. Our LSD model achieves 12.9% WER\ncompared to a character baseline of 14.8% WER. When combined with a\nconvolutional network on the encoder, we achieve 9.6% WER.", "published": "2016-10-10 19:16:08", "link": "http://arxiv.org/abs/1610.03035v6", "categories": ["stat.ML", "cs.CL", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Supervised Term Weighting Metrics for Sentiment Analysis in Short Text", "abstract": "Term weighting metrics assign weights to terms in order to discriminate the\nimportant terms from the less crucial ones. Due to this characteristic, these\nmetrics have attracted growing attention in text classification and recently in\nsentiment analysis. Using the weights given by such metrics could lead to more\naccurate document representation which may improve the performance of the\nclassification. While previous studies have focused on proposing or comparing\ndifferent weighting metrics at two-classes document level sentiment analysis,\nthis study propose to analyse the results given by each metric in order to find\nout the characteristics of good and bad weighting metrics. Therefore we present\nan empirical study of fifteen global supervised weighting metrics with four\nlocal weighting metrics adopted from information retrieval, we also give an\nanalysis to understand the behavior of each metric by observing and analysing\nhow each metric distributes the terms and deduce some characteristics which may\ndistinguish the good and bad metrics. The evaluation has been done using\nSupport Vector Machine on three different datasets: Twitter, restaurant and\nlaptop reviews.", "published": "2016-10-10 21:52:47", "link": "http://arxiv.org/abs/1610.03106v1", "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
