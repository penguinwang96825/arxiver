{"title": "Leveraging Human Production-Interpretation Asymmetries to Test LLM Cognitive Plausibility", "abstract": "Whether large language models (LLMs) process language similarly to humans has\nbeen the subject of much theoretical and practical debate. We examine this\nquestion through the lens of the production-interpretation distinction found in\nhuman sentence processing and evaluate the extent to which instruction-tuned\nLLMs replicate this distinction. Using an empirically documented asymmetry\nbetween production and interpretation in humans for implicit causality verbs as\na testbed, we find that some LLMs do quantitatively and qualitatively reflect\nhuman-like asymmetries between production and interpretation. We demonstrate\nthat whether this behavior holds depends upon both model size - with larger\nmodels more likely to reflect human-like patterns and the choice of\nmeta-linguistic prompts used to elicit the behavior.", "published": "2025-03-21 23:25:42", "link": "http://arxiv.org/abs/2503.17579v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Autonomous Radiotherapy Treatment Planning Using DOLA: A Privacy-Preserving, LLM-Based Optimization Agent", "abstract": "Radiotherapy treatment planning is a complex and time-intensive process,\noften impacted by inter-planner variability and subjective decision-making. To\naddress these challenges, we introduce Dose Optimization Language Agent (DOLA),\nan autonomous large language model (LLM)-based agent designed for optimizing\nradiotherapy treatment plans while rigorously protecting patient privacy. DOLA\nintegrates the LLaMa3.1 LLM directly with a commercial treatment planning\nsystem, utilizing chain-of-thought prompting, retrieval-augmented generation\n(RAG), and reinforcement learning (RL). Operating entirely within secure local\ninfrastructure, this agent eliminates external data sharing. We evaluated DOLA\nusing a retrospective cohort of 18 prostate cancer patients prescribed 60 Gy in\n20 fractions, comparing model sizes (8 billion vs. 70 billion parameters) and\noptimization strategies (No-RAG, RAG, and RAG+RL) over 10 planning iterations.\nThe 70B model demonstrated significantly improved performance, achieving\napproximately 16.4% higher final scores than the 8B model. The RAG approach\noutperformed the No-RAG baseline by 19.8%, and incorporating RL accelerated\nconvergence, highlighting the synergy of retrieval-based memory and\nreinforcement learning. Optimal temperature hyperparameter analysis identified\n0.4 as providing the best balance between exploration and exploitation. This\nproof of concept study represents the first successful deployment of locally\nhosted LLM agents for autonomous optimization of treatment plans within a\ncommercial radiotherapy planning system. By extending human-machine interaction\nthrough interpretable natural language reasoning, DOLA offers a scalable and\nprivacy-conscious framework, with significant potential for clinical\nimplementation and workflow improvement.", "published": "2025-03-21 22:01:19", "link": "http://arxiv.org/abs/2503.17553v1", "categories": ["physics.med-ph", "cs.AI", "cs.CL", "cs.ET", "cs.HC"], "primary_category": "physics.med-ph"}
{"title": "Bayesian Teaching Enables Probabilistic Reasoning in Large Language Models", "abstract": "Artificial intelligence systems based on large language models (LLMs) are\nincreasingly used as agents that interact with users and with the world. To do\nso successfully, LLMs need to construct internal representations of the world\nand form probabilistic beliefs about those representations. To provide a user\nwith personalized recommendations, for example, the LLM needs to gradually\ninfer the user's preferences, over the course of multiple interactions. To\nevaluate whether contemporary LLMs are able to do so, we use the Bayesian\ninference framework from probability theory, which lays out the optimal way to\nupdate an agent's beliefs as it receives new information. We first show that\nthe LLMs do not update their beliefs as expected from the Bayesian framework,\nand that consequently their predictions do not improve as expected as more\ninformation becomes available, even less so than we find is the case for\nhumans. To address this issue, we teach the LLMs to reason in a Bayesian manner\nby training them to mimic the predictions of an optimal Bayesian model. We find\nthat this approach not only significantly improves the LLM's performance on the\nparticular recommendation task it is trained on, but also enables\ngeneralization to other tasks. This suggests that this method endows the LLM\nwith broader Bayesian reasoning skills. More generally, our results indicate\nthat LLMs can learn about reasoning strategies effectively and generalize those\nskills to new domains, which in part explains LLMs' empirical success.", "published": "2025-03-21 20:13:04", "link": "http://arxiv.org/abs/2503.17523v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Language Models May Verbatim Complete Text They Were Not Explicitly Trained On", "abstract": "An important question today is whether a given text was used to train a large\nlanguage model (LLM). A \\emph{completion} test is often employed: check if the\nLLM completes a sufficiently complex text. This, however, requires a\nground-truth definition of membership; most commonly, it is defined as a member\nbased on the $n$-gram overlap between the target text and any text in the\ndataset. In this work, we demonstrate that this $n$-gram based membership\ndefinition can be effectively gamed. We study scenarios where sequences are\n\\emph{non-members} for a given $n$ and we find that completion tests still\nsucceed. We find many natural cases of this phenomenon by retraining LLMs from\nscratch after removing all training samples that were completed; these cases\ninclude exact duplicates, near-duplicates, and even short overlaps. They\nshowcase that it is difficult to find a single viable choice of $n$ for\nmembership definitions. Using these insights, we design adversarial datasets\nthat can cause a given target sequence to be completed without containing it,\nfor any reasonable choice of $n$. Our findings highlight the inadequacy of\n$n$-gram membership, suggesting membership definitions fail to account for\nauxiliary information available to the training algorithm.", "published": "2025-03-21 19:57:04", "link": "http://arxiv.org/abs/2503.17514v2", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Follow-up Question Generation For Enhanced Patient-Provider Conversations", "abstract": "Follow-up question generation is an essential feature of dialogue systems as\nit can reduce conversational ambiguity and enhance modeling complex\ninteractions. Conversational contexts often pose core NLP challenges such as\n(i) extracting relevant information buried in fragmented data sources, and (ii)\nmodeling parallel thought processes. These two challenges occur frequently in\nmedical dialogue as a doctor asks questions based not only on patient\nutterances but also their prior EHR data and current diagnostic hypotheses.\nAsking medical questions in asynchronous conversations compounds these issues\nas doctors can only rely on static EHR information to motivate follow-up\nquestions.\n  To address these challenges, we introduce FollowupQ, a novel framework for\nenhancing asynchronous medical conversation. FollowupQ is a multi-agent\nframework that processes patient messages and EHR data to generate personalized\nfollow-up questions, clarifying patient-reported medical conditions. FollowupQ\nreduces requisite provider follow-up communications by 34%. It also improves\nperformance by 17% and 5% on real and synthetic data, respectively. We also\nrelease the first public dataset of asynchronous medical messages with linked\nEHR data alongside 2,300 follow-up questions written by clinical experts for\nthe wider NLP research community.", "published": "2025-03-21 19:40:53", "link": "http://arxiv.org/abs/2503.17509v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models (LLMs) for Source Code Analysis: applications, models and datasets", "abstract": "Large language models (LLMs) and transformer-based architectures are\nincreasingly utilized for source code analysis. As software systems grow in\ncomplexity, integrating LLMs into code analysis workflows becomes essential for\nenhancing efficiency, accuracy, and automation. This paper explores the role of\nLLMs for different code analysis tasks, focusing on three key aspects: 1) what\nthey can analyze and their applications, 2) what models are used and 3) what\ndatasets are used, and the challenges they face. Regarding the goal of this\nresearch, we investigate scholarly articles that explore the use of LLMs for\nsource code analysis to uncover research developments, current trends, and the\nintellectual structure of this emerging field. Additionally, we summarize\nlimitations and highlight essential tools, datasets, and key challenges, which\ncould be valuable for future work.", "published": "2025-03-21 19:29:50", "link": "http://arxiv.org/abs/2503.17502v1", "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "cs.SE"}
{"title": "Variance Control via Weight Rescaling in LLM Pre-training", "abstract": "The outcome of Large Language Model (LLM) pre-training strongly depends on\nweight initialization and variance control strategies. Although the importance\nof initial variance control has been well documented in neural networks in\ngeneral, the literature on initialization and management of its growth during\nLLM pre-training, specifically, is somewhat sparse. In this paper, we introduce\nthe Layer Index Rescaling (LIR) weight initialization scheme, and the Target\nVariance Rescaling (TVR) variance control strategy. Experiments on a 1B\nparameter LLaMA model demonstrate that better variance management using these\ntechniques yields substantial improvements in downstream task performance (up\nto 4.6% on common pre-training benchmarks) and reduces extreme activation\nvalues, thus mitigating challenges associated with quantization and\nlow-precision training. Our code is available at:\nhttps://github.com/bluorion-com/weight_rescaling.", "published": "2025-03-21 19:23:08", "link": "http://arxiv.org/abs/2503.17500v1", "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Judge Anything: MLLM as a Judge Across Any Modality", "abstract": "Evaluating generative foundation models on open-ended multimodal\nunderstanding (MMU) and generation (MMG) tasks across diverse modalities (e.g.,\nimages, audio, video) poses significant challenges due to the complexity of\ncross-modal interactions. To this end, the idea of utilizing Multimodal LLMs\n(MLLMs) as automated judges has emerged, with encouraging results in assessing\nvision-language understanding tasks. Moving further, this paper extends\nMLLM-as-a-Judge across modalities to a unified manner by introducing two\nbenchmarks, TaskAnything and JudgeAnything, to respectively evaluate the\noverall performance and judging capabilities of MLLMs across any-to-any\nmodality tasks. Specifically, TaskAnything evaluates the MMU and MMG\ncapabilities across 15 any-to-any modality categories, employing 1,500 queries\ncurated from well-established benchmarks. Furthermore, JudgeAnything evaluates\nthe judging capabilities of 5 advanced (e.g., GPT-4o and Gemini-2.0-Flash) from\nthe perspectives of Pair Comparison and Score Evaluation, providing a\nstandardized testbed that incorporates human judgments and detailed rubrics.\nOur extensive experiments reveal that while these MLLMs show promise in\nassessing MMU (i.e., achieving an average of 66.55% in Pair Comparison setting\nand 42.79% in Score Evaluation setting), they encounter significant challenges\nwith MMG tasks (i.e., averaging only 53.37% in Pair Comparison setting and\n30.05% in Score Evaluation setting), exposing cross-modality biases and\nhallucination issues. To address this, we present OmniArena, an automated\nplatform for evaluating omni-models and multimodal reward models. Our work\nhighlights the need for fairer evaluation protocols and stronger alignment with\nhuman preferences. The source code and dataset are publicly available at:\nhttps://urrealhero.github.io/judgeanythingweb/.", "published": "2025-03-21 18:59:20", "link": "http://arxiv.org/abs/2503.17489v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "SaudiCulture: A Benchmark for Evaluating Large Language Models Cultural Competence within Saudi Arabia", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language processing; however, they often struggle to accurately capture\nand reflect cultural nuances. This research addresses this challenge by\nfocusing on Saudi Arabia, a country characterized by diverse dialects and rich\ncultural traditions. We introduce SaudiCulture, a novel benchmark designed to\nevaluate the cultural competence of LLMs within the distinct geographical and\ncultural contexts of Saudi Arabia. SaudiCulture is a comprehensive dataset of\nquestions covering five major geographical regions, such as West, East, South,\nNorth, and Center, along with general questions applicable across all regions.\nThe dataset encompasses a broad spectrum of cultural domains, including food,\nclothing, entertainment, celebrations, and crafts. To ensure a rigorous\nevaluation, SaudiCulture includes questions of varying complexity, such as\nopen-ended, single-choice, and multiple-choice formats, with some requiring\nmultiple correct answers. Additionally, the dataset distinguishes between\ncommon cultural knowledge and specialized regional aspects. We conduct\nextensive evaluations on five LLMs, such as GPT-4, Llama 3.3, FANAR, Jais, and\nAceGPT, analyzing their performance across different question types and\ncultural contexts. Our findings reveal that all models experience significant\nperformance declines when faced with highly specialized or region-specific\nquestions, particularly those requiring multiple correct responses.\nAdditionally, certain cultural categories are more easily identifiable than\nothers, further highlighting inconsistencies in LLMs cultural understanding.\nThese results emphasize the importance of incorporating region-specific\nknowledge into LLMs training to enhance their cultural competence.", "published": "2025-03-21 18:55:10", "link": "http://arxiv.org/abs/2503.17485v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach", "abstract": "In this paper, we present ConvoGen: an innovative framework for generating\nsynthetic conversational data using multi-agent systems. Our method leverages\nfew-shot learning and introduces iterative sampling from a dynamically updated\nfew-shot hub to create diverse and realistic conversational scenarios. The\ngenerated data has numerous applications, including training and evaluating\nconversational AI models, and augmenting existing datasets for tasks like\nconversational intent classification or conversation summarization. Our\nexperiments demonstrate the effectiveness of this method in producing\nhigh-quality diverse synthetic conversational data, highlighting its potential\nto enhance the development and evaluation of conversational AI systems.", "published": "2025-03-21 18:14:12", "link": "http://arxiv.org/abs/2503.17460v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Language-specific Neurons Do Not Facilitate Cross-Lingual Transfer", "abstract": "Multilingual large language models (LLMs) aim towards robust natural language\nunderstanding across diverse languages, yet their performance significantly\ndegrades on low-resource languages. This work explores whether existing\ntechniques to identify language-specific neurons can be leveraged to enhance\ncross-lingual task performance of lowresource languages. We conduct detailed\nexperiments covering existing language-specific neuron identification\ntechniques (such as Language Activation Probability Entropy and activation\nprobability-based thresholding) and neuron-specific LoRA fine-tuning with\nmodels like Llama 3.1 and Mistral Nemo. We find that such neuron-specific\ninterventions are insufficient to yield cross-lingual improvements on\ndownstream tasks (XNLI, XQuAD) in lowresource languages. This study highlights\nthe challenges in achieving cross-lingual generalization and provides critical\ninsights for multilingual LLMs.", "published": "2025-03-21 18:08:11", "link": "http://arxiv.org/abs/2503.17456v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dancing with Critiques: Enhancing LLM Reasoning with Stepwise Natural Language Self-Critique", "abstract": "Enhancing the reasoning capabilities of large language models (LLMs),\nparticularly for complex tasks requiring multi-step logical deductions, remains\na significant challenge. Traditional inference time scaling methods utilize\nscalar reward signals from process reward models to evaluate candidate\nreasoning steps, but these scalar rewards lack the nuanced qualitative\ninformation essential for understanding and justifying each step. In this\npaper, we propose a novel inference-time scaling approach -- stepwise natural\nlanguage self-critique (PANEL), which employs self-generated natural language\ncritiques as feedback to guide the step-level search process. By generating\nrich, human-readable critiques for each candidate reasoning step, PANEL retains\nessential qualitative information, facilitating better-informed decision-making\nduring inference. This approach bypasses the need for task-specific verifiers\nand the associated training overhead, making it broadly applicable across\ndiverse tasks. Experimental results on challenging reasoning benchmarks,\nincluding AIME and GPQA, demonstrate that PANEL significantly enhances\nreasoning performance, outperforming traditional scalar reward-based methods.\nOur code is available at https://github.com/puddingyeah/PANEL to support and\nencourage future research in this promising field.", "published": "2025-03-21 17:59:55", "link": "http://arxiv.org/abs/2503.17363v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "OpenVLThinker: An Early Exploration to Complex Vision-Language Reasoning via Iterative Self-Improvement", "abstract": "Recent advancements demonstrated by DeepSeek-R1 have shown that complex\nreasoning abilities in large language models (LLMs), including sophisticated\nbehaviors such as self-verification and self-correction, can be achieved by RL\nwith verifiable rewards and significantly improves model performance on\nchallenging tasks such as AIME. Motivated by these findings, our study\ninvestigates whether similar reasoning capabilities can be successfully\nintegrated into large vision-language models (LVLMs) and assesses their impact\non challenging multimodal reasoning tasks. We consider an approach that\niteratively leverages supervised fine-tuning (SFT) on lightweight training data\nand Reinforcement Learning (RL) to further improve model generalization.\nInitially, reasoning capabilities were distilled from pure-text R1 models by\ngenerating reasoning steps using high-quality captions of the images sourced\nfrom diverse visual datasets. Subsequently, iterative RL training further\nenhance reasoning skills, with each iteration's RL-improved model generating\nrefined SFT datasets for the next round. This iterative process yielded\nOpenVLThinker, a LVLM exhibiting consistently improved reasoning performance on\nchallenging benchmarks such as MathVista, MathVerse, and MathVision,\ndemonstrating the potential of our strategy for robust vision-language\nreasoning. The code, model and data are held at\nhttps://github.com/yihedeng9/OpenVLThinker.", "published": "2025-03-21 17:52:43", "link": "http://arxiv.org/abs/2503.17352v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "Efficient Intent-Based Filtering for Multi-Party Conversations Using Knowledge Distillation from LLMs", "abstract": "Large language models (LLMs) have showcased remarkable capabilities in\nconversational AI, enabling open-domain responses in chat-bots, as well as\nadvanced processing of conversations like summarization, intent classification,\nand insights generation. However, these models are resource-intensive,\ndemanding substantial memory and computational power. To address this, we\npropose a cost-effective solution that filters conversational snippets of\ninterest for LLM processing, tailored to the target downstream application,\nrather than processing every snippet. In this work, we introduce an innovative\napproach that leverages knowledge distillation from LLMs to develop an\nintent-based filter for multi-party conversations, optimized for compute power\nconstrained environments. Our method combines different strategies to create a\ndiverse multi-party conversational dataset, that is annotated with the target\nintents and is then used to fine-tune the MobileBERT model for multi-label\nintent classification. This model achieves a balance between efficiency and\nperformance, effectively filtering conversation snippets based on their\nintents. By passing only the relevant snippets to the LLM for further\nprocessing, our approach significantly reduces overall operational costs\ndepending on the intents and the data distribution as demonstrated in our\nexperiments.", "published": "2025-03-21 17:34:37", "link": "http://arxiv.org/abs/2503.17336v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FastCuRL: Curriculum Reinforcement Learning with Progressive Context Extension for Efficient Training R1-like Reasoning Models", "abstract": "In this paper, we propose \\textbf{\\textsc{FastCuRL}}, a simple yet efficient\n\\textbf{Cu}rriculum \\textbf{R}einforcement \\textbf{L}earning approach with\ncontext window extending strategy to accelerate the reinforcement learning\ntraining efficiency for R1-like reasoning models while enhancing their\nperformance in tackling complex reasoning tasks with long chain-of-thought\nrationales, particularly with a 1.5B parameter language model.\n\\textbf{\\textsc{FastCuRL}} consists of two main procedures: length-aware\ntraining data segmentation and context window extension training. Specifically,\nthe former first splits the original training data into three different levels\nby the input prompt length, and then the latter leverages segmented training\ndatasets with a progressively increasing context window length to train the\nreasoning model. Experimental results demonstrate that\n\\textbf{\\textsc{FastCuRL}}-1.5B-Preview surpasses DeepScaleR-1.5B-Preview\nacross all five datasets (including MATH 500, AIME 2024, AMC 2023, Minerva\nMath, and OlympiadBench) while only utilizing 50\\% of training steps.\nFurthermore, all training stages for FastCuRL-1.5B-Preview are completed using\njust a single node with 8 GPUs.", "published": "2025-03-21 16:35:31", "link": "http://arxiv.org/abs/2503.17287v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "An Iterative Feedback Mechanism for Improving Natural Language Class Descriptions in Open-Vocabulary Object Detection", "abstract": "Recent advances in open-vocabulary object detection models will enable\nAutomatic Target Recognition systems to be sustainable and repurposed by\nnon-technical end-users for a variety of applications or missions. New, and\npotentially nuanced, classes can be defined with natural language text\ndescriptions in the field, immediately before runtime, without needing to\nretrain the model. We present an approach for improving non-technical users'\nnatural language text descriptions of their desired targets of interest, using\na combination of analysis techniques on the text embeddings, and proper\ncombinations of embeddings for contrastive examples. We quantify the\nimprovement that our feedback mechanism provides by demonstrating performance\nwith multiple publicly-available open-vocabulary object detection models.", "published": "2025-03-21 16:34:04", "link": "http://arxiv.org/abs/2503.17285v1", "categories": ["cs.CV", "cs.CL"], "primary_category": "cs.CV"}
{"title": "CASE -- Condition-Aware Sentence Embeddings for Conditional Semantic Textual Similarity Measurement", "abstract": "The meaning conveyed by a sentence often depends on the context in which it\nappears. Despite the progress of sentence embedding methods, it remains unclear\nhow to best modify a sentence embedding conditioned on its context. To address\nthis problem, we propose Condition-Aware Sentence Embeddings (CASE), an\nefficient and accurate method to create an embedding for a sentence under a\ngiven condition. First, CASE creates an embedding for the condition using a\nLarge Language Model (LLM), where the sentence influences the attention scores\ncomputed for the tokens in the condition during pooling. Next, a supervised\nnonlinear projection is learned to reduce the dimensionality of the LLM-based\ntext embeddings. We show that CASE significantly outperforms previously\nproposed Conditional Semantic Textual Similarity (C-STS) methods on an existing\nstandard benchmark dataset. We find that subtracting the condition embedding\nconsistently improves the C-STS performance of LLM-based text embeddings.\nMoreover, we propose a supervised dimensionality reduction method that not only\nreduces the dimensionality of LLM-based embeddings but also significantly\nimproves their performance.", "published": "2025-03-21 16:27:12", "link": "http://arxiv.org/abs/2503.17279v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Text to Talent: A Pipeline for Extracting Insights from Candidate Profiles", "abstract": "The recruitment process is undergoing a significant transformation with the\nincreasing use of machine learning and natural language processing techniques.\nWhile previous studies have focused on automating candidate selection, the role\nof multiple vacancies in this process remains understudied. This paper\naddresses this gap by proposing a novel pipeline that leverages Large Language\nModels and graph similarity measures to suggest ideal candidates for specific\njob openings. Our approach represents candidate profiles as multimodal\nembeddings, enabling the capture of nuanced relationships between job\nrequirements and candidate attributes. The proposed approach has significant\nimplications for the recruitment industry, enabling companies to streamline\ntheir hiring processes and identify top talent more efficiently. Our work\ncontributes to the growing body of research on the application of machine\nlearning in human resources, highlighting the potential of LLMs and graph-based\nmethods in revolutionizing the recruitment landscape.", "published": "2025-03-21 16:18:44", "link": "http://arxiv.org/abs/2503.17438v1", "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "cs.CY"}
{"title": "KL3M Tokenizers: A Family of Domain-Specific and Character-Level Tokenizers for Legal, Financial, and Preprocessing Applications", "abstract": "We present the KL3M tokenizers, a family of specialized tokenizers for legal,\nfinancial, and governmental text. Despite established work on tokenization,\nspecialized tokenizers for professional domains remain understudied. Our paper\noffers two main contributions to this area.\n  First, we introduce domain-specific BPE tokenizers for legal, financial, and\ngovernmental text. Our kl3m-004-128k-cased tokenizer uses 9-17% fewer tokens\nthan GPT-4o and Llama3 for domain-specific documents, despite having a smaller\nvocabulary. For specialized terminology, our cased tokenizer is even more\nefficient, using up to 83% fewer tokens for legal terms and 39% fewer tokens\nfor financial terms.\n  Second, we develop character-level BPE tokenizers (4K, 8K, and 16K vocabulary\nsizes) for text correction tasks like OCR post-processing. These tokenizers\nkeep consistent token boundaries between error-containing and correct text,\nmaking it easier for models to learn correction patterns.\n  These tokenizers help professional applications by fitting more text in\ncontext windows, reducing computational needs, and preserving the meaning of\ndomain-specific terms. Our analysis shows these efficiency gains directly\nbenefit the processing of long legal and financial documents. We release all\ntokenizers and code through GitHub and Hugging Face to support further research\nin specialized tokenization.", "published": "2025-03-21 15:51:43", "link": "http://arxiv.org/abs/2503.17247v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SafeMERGE: Preserving Safety Alignment in Fine-Tuned Large Language Models via Selective Layer-Wise Model Merging", "abstract": "Fine-tuning large language models (LLMs) on downstream tasks can\ninadvertently erode their safety alignment, even for benign fine-tuning\ndatasets. We address this challenge by proposing SafeMERGE, a post-fine-tuning\nframework that preserves safety while maintaining task utility. It achieves\nthis by selectively merging fine-tuned and safety-aligned model layers only\nwhen those deviate from safe behavior, measured by a cosine similarity\ncriterion. We evaluate SafeMERGE against other fine-tuning- and\npost-fine-tuning-stage approaches for Llama-2-7B-Chat and Qwen-2-7B-Instruct\nmodels on GSM8K and PubMedQA tasks while exploring different merging\nstrategies. We find that SafeMERGE consistently reduces harmful outputs\ncompared to other baselines without significantly sacrificing performance,\nsometimes even enhancing it. The results suggest that our selective,\nsubspace-guided, and per-layer merging method provides an effective safeguard\nagainst the inadvertent loss of safety in fine-tuned LLMs while outperforming\nsimpler post-fine-tuning-stage defenses.", "published": "2025-03-21 15:44:09", "link": "http://arxiv.org/abs/2503.17239v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "FactSelfCheck: Fact-Level Black-Box Hallucination Detection for LLMs", "abstract": "Large Language Models (LLMs) frequently generate hallucinated content, posing\nsignificant challenges for applications where factuality is crucial. While\nexisting hallucination detection methods typically operate at the sentence\nlevel or passage level, we propose FactSelfCheck, a novel black-box\nsampling-based method that enables fine-grained fact-level detection. Our\napproach represents text as knowledge graphs consisting of facts in the form of\ntriples. Through analyzing factual consistency across multiple LLM responses,\nwe compute fine-grained hallucination scores without requiring external\nresources or training data. Our evaluation demonstrates that FactSelfCheck\nperforms competitively with leading sampling-based methods while providing more\ndetailed insights. Most notably, our fact-level approach significantly improves\nhallucination correction, achieving a 35% increase in factual content compared\nto the baseline, while sentence-level SelfCheckGPT yields only an 8%\nimprovement. The granular nature of our detection enables more precise\nidentification and correction of hallucinated content.", "published": "2025-03-21 15:32:24", "link": "http://arxiv.org/abs/2503.17229v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Automating Adjudication of Cardiovascular Events Using Large Language Models", "abstract": "Cardiovascular events, such as heart attacks and strokes, remain a leading\ncause of mortality globally, necessitating meticulous monitoring and\nadjudication in clinical trials. This process, traditionally performed manually\nby clinical experts, is time-consuming, resource-intensive, and prone to\ninter-reviewer variability, potentially introducing bias and hindering trial\nprogress. This study addresses these critical limitations by presenting a novel\nframework for automating the adjudication of cardiovascular events in clinical\ntrials using Large Language Models (LLMs). We developed a two-stage approach:\nfirst, employing an LLM-based pipeline for event information extraction from\nunstructured clinical data and second, using an LLM-based adjudication process\nguided by a Tree of Thoughts approach and clinical endpoint committee (CEC)\nguidelines. Using cardiovascular event-specific clinical trial data, the\nframework achieved an F1-score of 0.82 for event extraction and an accuracy of\n0.68 for adjudication. Furthermore, we introduce the CLEART score, a novel,\nautomated metric specifically designed for evaluating the quality of\nAI-generated clinical reasoning in adjudicating cardiovascular events. This\napproach demonstrates significant potential for substantially reducing\nadjudication time and costs while maintaining high-quality, consistent, and\nauditable outcomes in clinical trials. The reduced variability and enhanced\nstandardization also allow for faster identification and mitigation of risks\nassociated with cardiovascular therapies.", "published": "2025-03-21 15:25:53", "link": "http://arxiv.org/abs/2503.17222v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A Language Anchor-Guided Method for Robust Noisy Domain Generalization", "abstract": "Real-world machine learning applications often struggle with two major\nchallenges: distribution shift and label noise. Models tend to overfit by\nfocusing on redundant and uninformative features in the training data, which\nmakes it hard for them to generalize to the target domain. Noisy data worsens\nthis problem by causing further overfitting to the noise, meaning that existing\nmethods often fail to tell the difference between true, invariant features and\nmisleading, spurious ones. To tackle these issues, we introduce Anchor\nAlignment and Adaptive Weighting (A3W). This new algorithm uses sample\nreweighting guided by natural language processing (NLP) anchors to extract more\nrepresentative features. In simple terms, A3W leverages semantic\nrepresentations from natural language models as a source of domain-invariant\nprior knowledge. Additionally, it employs a weighted loss function that adjusts\neach sample's contribution based on its similarity to the corresponding NLP\nanchor. This adjustment makes the model more robust to noisy labels. Extensive\nexperiments on standard benchmark datasets show that A3W consistently\noutperforms state-of-the-art domain generalization methods, offering\nsignificant improvements in both accuracy and robustness across different\ndatasets and noise levels.", "published": "2025-03-21 15:20:28", "link": "http://arxiv.org/abs/2503.17211v1", "categories": ["cs.CL", "cs.CV", "cs.LG"], "primary_category": "cs.CL"}
{"title": "CoKe: Customizable Fine-Grained Story Evaluation via Chain-of-Keyword Rationalization", "abstract": "Evaluating creative text such as human-written stories using language models\nhas always been a challenging task -- owing to the subjectivity of\nmulti-annotator ratings. To mimic the thinking process of humans, chain of\nthought (CoT) generates free-text explanations that help guide a model's\npredictions and Self-Consistency (SC) marginalizes predictions over multiple\ngenerated explanations. In this study, we discover that the widely-used\nself-consistency reasoning methods cause suboptimal results due to an objective\nmismatch between generating 'fluent-looking' explanations vs. actually leading\nto a good rating prediction for an aspect of a story. To overcome this\nchallenge, we propose $\\textbf{C}$hain-$\\textbf{o}$f-$\\textbf{Ke}$ywords\n(CoKe), that generates a sequence of keywords $\\textit{before}$ generating a\nfree-text rationale, that guide the rating prediction of our evaluation\nlanguage model. Then, we generate a diverse set of such keywords, and aggregate\nthe scores corresponding to these generations. On the StoryER dataset, CoKe\nbased on our small fine-tuned evaluation models not only reach human-level\nperformance and significantly outperform GPT-4 with a 2x boost in correlation\nwith human annotators, but also requires drastically less number of parameters.", "published": "2025-03-21 13:37:46", "link": "http://arxiv.org/abs/2503.17136v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Modifying Large Language Model Post-Training for Diverse Creative Writing", "abstract": "As creative writing tasks do not have singular correct answers, large\nlanguage models (LLMs) trained to perform these tasks should be able to\ngenerate diverse valid outputs. However, LLM post-training often focuses on\nimproving generation quality but neglects to facilitate output diversity.\nHence, in creative writing generation, we investigate post-training approaches\nto promote both output diversity and quality. Our core idea is to include\ndeviation -- the degree of difference between a training sample and all other\nsamples with the same prompt -- in the training objective to facilitate\nlearning from rare high-quality instances. By adopting our approach to direct\npreference optimization (DPO) and odds ratio preference optimization (ORPO), we\ndemonstrate that we can promote the output diversity of trained models while\nminimally decreasing quality. Our best model with 8B parameters could achieve\non-par diversity as a human-created dataset while having output quality similar\nto the best instruction-tuned models we examined, GPT-4o and DeepSeek-R1. We\nfurther validate our approaches with a human evaluation, an ablation, and a\ncomparison to an existing diversification approach, DivPO.", "published": "2025-03-21 13:21:45", "link": "http://arxiv.org/abs/2503.17126v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "A Study into Investigating Temporal Robustness of LLMs", "abstract": "Large Language Models (LLMs) encapsulate a surprising amount of factual world\nknowledge. However, their performance on temporal questions and historical\nknowledge is limited because they often cannot understand temporal scope and\norientation or neglect the temporal aspect altogether. In this study, we aim to\nmeasure precisely how robust LLMs are for question answering based on their\nability to process temporal information and perform tasks requiring temporal\nreasoning and temporal factual knowledge. Specifically, we design eight\ntime-sensitive robustness tests for factual information to check the\nsensitivity of six popular LLMs in the zero-shot setting. Overall, we find LLMs\nlacking temporal robustness, especially to temporal reformulations and the use\nof different granularities of temporal references. We show how a selection of\nthese eight tests can be used automatically to judge a model's temporal\nrobustness for user questions on the fly. Finally, we apply the findings of\nthis study to improve the temporal QA performance by up to 55 percent.", "published": "2025-03-21 11:56:17", "link": "http://arxiv.org/abs/2503.17073v1", "categories": ["cs.CL", "cs.IR", "68T50", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Summarization Metrics for Spanish and Basque: Do Automatic Scores and LLM-Judges Correlate with Humans?", "abstract": "Studies on evaluation metrics and LLM-as-a-Judge models for automatic text\nsummarization have largely been focused on English, limiting our understanding\nof their effectiveness in other languages. Through our new dataset BASSE\n(BAsque and Spanish Summarization Evaluation), we address this situation by\ncollecting human judgments on 2,040 abstractive summaries in Basque and\nSpanish, generated either manually or by five LLMs with four different prompts.\nFor each summary, annotators evaluated five criteria on a 5-point Likert scale:\ncoherence, consistency, fluency, relevance, and 5W1H. We use these data to\nreevaluate traditional automatic metrics used for evaluating summaries, as well\nas several LLM-as-a-Judge models that show strong performance on this task in\nEnglish. Our results show that currently proprietary judge LLMs have the\nhighest correlation with human judgments, followed by criteria-specific\nautomatic metrics, while open-sourced judge LLMs perform poorly. We release\nBASSE and our code publicly, along with the first large-scale Basque\nsummarization dataset containing 22,525 news articles with their subheads.", "published": "2025-03-21 10:52:20", "link": "http://arxiv.org/abs/2503.17039v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Beyond Negation Detection: Comprehensive Assertion Detection Models for Clinical NLP", "abstract": "Assertion status detection is a critical yet often overlooked component of\nclinical NLP, essential for accurately attributing extracted medical facts.\nPast studies have narrowly focused on negation detection, leading to\nunderperforming commercial solutions such as AWS Medical Comprehend, Azure AI\nText Analytics, and GPT-4o due to their limited domain adaptation. To address\nthis gap, we developed state-of-the-art assertion detection models, including\nfine-tuned LLMs, transformer-based classifiers, few-shot classifiers, and deep\nlearning (DL) approaches. We evaluated these models against cloud-based\ncommercial API solutions, the legacy rule-based NegEx approach, and GPT-4o. Our\nfine-tuned LLM achieves the highest overall accuracy (0.962), outperforming\nGPT-4o (0.901) and commercial APIs by a notable margin, particularly excelling\nin Present (+4.2%), Absent (+8.4%), and Hypothetical (+23.4%) assertions. Our\nDL-based models surpass commercial solutions in Conditional (+5.3%) and\nAssociated-with-Someone-Else (+10.1%) categories, while the few-shot classifier\noffers a lightweight yet highly competitive alternative (0.929), making it\nideal for resource-constrained environments. Integrated within Spark NLP, our\nmodels consistently outperform black-box commercial solutions while enabling\nscalable inference and seamless integration with medical NER, Relation\nExtraction, and Terminology Resolution. These results reinforce the importance\nof domain-adapted, transparent, and customizable clinical NLP solutions over\ngeneral-purpose LLMs and proprietary APIs.", "published": "2025-03-21 10:18:47", "link": "http://arxiv.org/abs/2503.17425v1", "categories": ["cs.CL", "cs.IR", "cs.LG", "H.3"], "primary_category": "cs.CL"}
{"title": "Text2Model: Generating dynamic chemical reactor models using large language models (LLMs)", "abstract": "As large language models have shown remarkable capabilities in conversing via\nnatural language, the question arises as to how LLMs could potentially assist\nchemical engineers in research and industry with domain-specific tasks. We\ngenerate dynamic chemical reactor models in Modelica code format from textual\ndescriptions as user input. We fine-tune Llama 3.1 8B Instruct on synthetically\ngenerated Modelica code for different reactor scenarios. We compare the\nperformance of our fine-tuned model to the baseline Llama 3.1 8B Instruct model\nand GPT4o. We manually assess the models' predictions regarding the syntactic\nand semantic accuracy of the generated dynamic models. We find that\nconsiderable improvements are achieved by the fine-tuned model with respect to\nboth the semantic and the syntactic accuracy of the Modelica models. However,\nthe fine-tuned model lacks a satisfactory ability to generalize to unseen\nscenarios compared to GPT4o.", "published": "2025-03-21 10:09:34", "link": "http://arxiv.org/abs/2503.17004v1", "categories": ["cs.PL", "cs.CL"], "primary_category": "cs.PL"}
{"title": "A Survey on Personalized Alignment -- The Missing Piece for Large Language Models in Real-World Applications", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities, yet\ntheir transition to real-world applications reveals a critical limitation: the\ninability to adapt to individual preferences while maintaining alignment with\nuniversal human values. Current alignment techniques adopt a one-size-fits-all\napproach that fails to accommodate users' diverse backgrounds and needs. This\npaper presents the first comprehensive survey of personalized alignment-a\nparadigm that enables LLMs to adapt their behavior within ethical boundaries\nbased on individual preferences. We propose a unified framework comprising\npreference memory management, personalized generation, and feedback-based\nalignment, systematically analyzing implementation approaches and evaluating\ntheir effectiveness across various scenarios. By examining current techniques,\npotential risks, and future challenges, this survey provides a structured\nfoundation for developing more adaptable and ethically-aligned LLMs.", "published": "2025-03-21 10:09:16", "link": "http://arxiv.org/abs/2503.17003v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Zero-Shot Commercial APIs Deliver Regulatory-Grade Clinical Text DeIdentification?", "abstract": "We evaluate the performance of four leading solutions for de-identification\nof unstructured medical text - Azure Health Data Services, AWS Comprehend\nMedical, OpenAI GPT-4o, and John Snow Labs - on a ground truth dataset of 48\nclinical documents annotated by medical experts. The analysis, conducted at\nboth entity-level and token-level, suggests that John Snow Labs' Medical\nLanguage Models solution achieves the highest accuracy, with a 96% F1-score in\nprotected health information (PHI) detection, outperforming Azure (91%), AWS\n(83%), and GPT-4o (79%). John Snow Labs is not only the only solution which\nachieves regulatory-grade accuracy (surpassing that of human experts) but is\nalso the most cost-effective solution: It is over 80% cheaper compared to Azure\nand GPT-4o, and is the only solution not priced by token. Its fixed-cost local\ndeployment model avoids the escalating per-request fees of cloud-based\nservices, making it a scalable and economical choice.", "published": "2025-03-21 10:05:04", "link": "http://arxiv.org/abs/2503.20794v2", "categories": ["cs.CL", "cs.CR", "cs.IR", "cs.LG", "H.3; F.2.2; I.2.7"], "primary_category": "cs.CL"}
{"title": "Token Dynamics: Towards Efficient and Dynamic Video Token Representation for Video Large Language Models", "abstract": "Token-based video representation has emerged as a promising approach for\nenabling LLMs to interpret video content. However, existing token reduction,\nsuch as token pruning and token merging, often disrupt essential\nspatial-temporal positional embeddings, failing to adequately balance\ncomputational efficiency with fewer tokens. Consequently, these methods result\nin lengthy token sequences, limiting their applicability in scenarios requiring\nextreme token compression, such as video large language models. In this paper,\nwe introduce the novel task of extreme short token reduction, aiming to\nrepresent extensive video sequences with a minimal number of tokens. To address\nthis challenge, we propose Token Dynamics, a new video representation framework\nthat dynamically reduces token count while preserving spatial-temporal\ncoherence. Specifically, we disentangle video representations by separating\nvisual embeddings from grid-level motion information, structuring them into: 1.\na concise token hash table, created by clustering tokens that describe\nobject-level content; 2. a token indices key map, capturing detailed\nspatial-temporal motion patterns across grids; 3. a token hash function, which\nvector-quantizes the token hash table to reconstruct the token sequence from\nthe key map. Furthermore, we introduce a cross-dynamics attention mechanism\nthat integrates motion features into the token base without increasing token\nlength, thereby maintaining compactness and spatial-temporal integrity. The\nexperiments demonstrate a reduction of token count to merely 0.07% of the\noriginal tokens, with only a minor performance drop of 1.13%. Additionally, we\npropose two novel subtasks within extreme token reduction (fixed-length and\nadaptive-length compression). Our method offers significantly lower theoretical\ncomplexity, fewer tokens, and enhanced throughput, thus providing an efficient\nsolution for video LLMs.", "published": "2025-03-21 09:46:31", "link": "http://arxiv.org/abs/2503.16980v3", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Assessing Consistency and Reproducibility in the Outputs of Large Language Models: Evidence Across Diverse Finance and Accounting Tasks", "abstract": "This study provides the first comprehensive assessment of consistency and\nreproducibility in Large Language Model (LLM) outputs in finance and accounting\nresearch. We evaluate how consistently LLMs produce outputs given identical\ninputs through extensive experimentation with 50 independent runs across five\ncommon tasks: classification, sentiment analysis, summarization, text\ngeneration, and prediction. Using three OpenAI models (GPT-3.5-turbo,\nGPT-4o-mini, and GPT-4o), we generate over 3.4 million outputs from diverse\nfinancial source texts and data, covering MD&As, FOMC statements, finance news\narticles, earnings call transcripts, and financial statements. Our findings\nreveal substantial but task-dependent consistency, with binary classification\nand sentiment analysis achieving near-perfect reproducibility, while complex\ntasks show greater variability. More advanced models do not consistently\ndemonstrate better consistency and reproducibility, with task-specific patterns\nemerging. LLMs significantly outperform expert human annotators in consistency\nand maintain high agreement even where human experts significantly disagree. We\nfurther find that simple aggregation strategies across 3-5 runs dramatically\nimprove consistency. We also find that aggregation may come with an additional\nbenefit of improved accuracy for sentiment analysis when using newer models.\nSimulation analysis reveals that despite measurable inconsistency in LLM\noutputs, downstream statistical inferences remain remarkably robust. These\nfindings address concerns about what we term \"G-hacking,\" the selective\nreporting of favorable outcomes from multiple Generative AI runs, by\ndemonstrating that such risks are relatively low for finance and accounting\ntasks.", "published": "2025-03-21 09:43:37", "link": "http://arxiv.org/abs/2503.16974v2", "categories": ["q-fin.GN", "cs.AI", "cs.CE", "cs.CL", "cs.LG"], "primary_category": "q-fin.GN"}
{"title": "When Words Outperform Vision: VLMs Can Self-Improve Via Text-Only Training For Human-Centered Decision Making", "abstract": "Embodied decision-making is fundamental for AI agents operating in real-world\nenvironments. While Visual Language Models (VLMs) have advanced this\ncapability, they still struggle with complex decisions, particularly in\nhuman-centered situations that require deep reasoning about human needs and\nvalues. In this study, we systematically evaluate open-sourced VLMs on\nmultimodal human-centered decision-making tasks. We find that LLMs receiving\nonly textual descriptions unexpectedly outperform their VLM counterparts of\nsimilar scale that process actual images, suggesting that visual alignment may\nhinder VLM abilities. To address this challenge, we propose a novel text-only\ntraining approach with synthesized textual data. This method strengthens VLMs'\nlanguage components and transfers the learned abilities to multimodal\ninference, eliminating the need for expensive image-text paired data.\nFurthermore, we show that VLMs can achieve substantial performance gains\nthrough self-improvement, using training data generated by their LLM\ncounterparts rather than relying on larger teacher models like GPT-4. Our\nfindings establish a more efficient and scalable approach to enhancing VLMs'\nhuman-centered decision-making capabilities, opening new avenues for optimizing\nVLMs through self-improvement mechanisms.", "published": "2025-03-21 09:25:23", "link": "http://arxiv.org/abs/2503.16965v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Understanding Social Support Needs in Questions: A Hybrid Approach Integrating Semi-Supervised Learning and LLM-based Data Augmentation", "abstract": "Patients are increasingly turning to online health Q&A communities for social\nsupport to improve their well-being. However, when this support received does\nnot align with their specific needs, it may prove ineffective or even\ndetrimental. This necessitates a model capable of identifying the social\nsupport needs in questions. However, training such a model is challenging due\nto the scarcity and class imbalance issues of labeled data. To overcome these\nchallenges, we follow the computational design science paradigm to develop a\nnovel framework, Hybrid Approach for SOcial Support need classification\n(HA-SOS). HA-SOS integrates an answer-enhanced semi-supervised learning\napproach, a text data augmentation technique leveraging large language models\n(LLMs) with reliability- and diversity-aware sample selection mechanism, and a\nunified training process to automatically label social support needs in\nquestions. Extensive empirical evaluations demonstrate that HA-SOS\nsignificantly outperforms existing question classification models and\nalternative semi-supervised learning approaches. This research contributes to\nthe literature on social support, question classification, semi-supervised\nlearning, and text data augmentation. In practice, our HA-SOS framework\nfacilitates online Q&A platform managers and answerers to better understand\nusers' social support needs, enabling them to provide timely, personalized\nanswers and interventions.", "published": "2025-03-21 07:25:16", "link": "http://arxiv.org/abs/2503.17421v1", "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "cs.CY"}
{"title": "Assessing the Reliability and Validity of GPT-4 in Annotating Emotion Appraisal Ratings", "abstract": "Appraisal theories suggest that emotions arise from subjective evaluations of\nevents, referred to as appraisals. The taxonomy of appraisals is quite diverse,\nand they are usually given ratings on a Likert scale to be annotated in an\nexperiencer-annotator or reader-annotator paradigm. This paper studies GPT-4 as\na reader-annotator of 21 specific appraisal ratings in different prompt\nsettings, aiming to evaluate and improve its performance compared to human\nannotators. We found that GPT-4 is an effective reader-annotator that performs\nclose to or even slightly better than human annotators, and its results can be\nsignificantly improved by using a majority voting of five completions. GPT-4\nalso effectively predicts appraisal ratings and emotion labels using a single\nprompt, but adding instruction complexity results in poorer performance. We\nalso found that longer event descriptions lead to more accurate annotations for\nboth model and human annotator ratings. This work contributes to the growing\nusage of LLMs in psychology and the strategies for improving GPT-4 performance\nin annotating appraisals.", "published": "2025-03-21 06:35:49", "link": "http://arxiv.org/abs/2503.16883v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Federated Cross-Domain Click-Through Rate Prediction With Large Language Model Augmentation", "abstract": "Accurately predicting click-through rates (CTR) under stringent privacy\nconstraints poses profound challenges, particularly when user-item interactions\nare sparse and fragmented across domains. Conventional cross-domain CTR (CCTR)\nmethods frequently assume homogeneous feature spaces and rely on centralized\ndata sharing, neglecting complex inter-domain discrepancies and the subtle\ntrade-offs imposed by privacy-preserving protocols. Here, we present Federated\nCross-Domain CTR Prediction with Large Language Model Augmentation\n(FedCCTR-LM), a federated framework engineered to address these limitations by\nsynchronizing data augmentation, representation disentanglement, and adaptive\nprivacy protection. Our approach integrates three core innovations. First, the\nPrivacy-Preserving Augmentation Network (PrivAugNet) employs large language\nmodels to enrich user and item representations and expand interaction\nsequences, mitigating data sparsity and feature incompleteness. Second, the\nIndependent Domain-Specific Transformer with Contrastive Learning (IDST-CL)\nmodule disentangles domain-specific and shared user preferences, employing\nintra-domain representation alignment (IDRA) and crossdomain representation\ndisentanglement (CDRD) to refine the learned embeddings and enhance knowledge\ntransfer across domains. Finally, the Adaptive Local Differential Privacy\n(AdaLDP) mechanism dynamically calibrates noise injection to achieve an optimal\nbalance between rigorous privacy guarantees and predictive accuracy. Empirical\nevaluations on four real-world datasets demonstrate that FedCCTR-LM\nsubstantially outperforms existing baselines, offering robust,\nprivacy-preserving, and generalizable cross-domain CTR prediction in\nheterogeneous, federated environments.", "published": "2025-03-21 06:22:42", "link": "http://arxiv.org/abs/2503.16875v1", "categories": ["cs.IR", "cs.CL", "cs.DC"], "primary_category": "cs.IR"}
{"title": "MARS: A Multi-Agent Framework Incorporating Socratic Guidance for Automated Prompt Optimization", "abstract": "The basic question-answering format of large language models involves\ninputting a prompt and receiving a response, and the quality of the prompt\ndirectly impacts the effectiveness of the response. Automated Prompt\nOptimization (APO) aims to break free from the cognitive biases of manually\ndesigned prompts and explores a broader design space for prompts. However,\nexisting APO methods suffer from limited flexibility of fixed templates and\ninefficient search in prompt spaces as key issues. To this end, we propose a\nMulti-Agent framework Incorporating Socratic guidance (MARS), which utilizes\nmulti-agent fusion technology for automatic planning, with gradual continuous\noptimization and evaluation. Specifically, MARS comprises seven agents, each\nwith distinct functionalities, which autonomously use the Planner to devise an\noptimization path that ensures flexibility. Additionally, it employs a\nTeacher-Critic-Student Socratic dialogue pattern to iteratively optimize the\nprompts while conducting effective search. We conduct extensive experiments on\nvarious datasets to validate the effectiveness of our method, and perform\nadditional analytical experiments to assess the model's advancement as well as\nthe interpretability.", "published": "2025-03-21 06:19:55", "link": "http://arxiv.org/abs/2503.16874v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs", "abstract": "Knowledge distillation can be a cost-effective technique to distill knowledge\nin Large Language Models, if the teacher output logits can be pre-computed and\ncached. However, successfully applying this to pre-training remains largely\nunexplored. In this work, we prove that naive approaches for sparse knowledge\ndistillation such as caching Top-K probabilities, while intuitive, provide\nbiased estimates of teacher probability distribution to the student, resulting\nin suboptimal performance and calibration. We propose an\nimportance-sampling-based method `Random Sampling Knowledge Distillation',\nwhich provides unbiased estimates, preserves the gradient in expectation, and\nrequires storing significantly sparser logits. Our method enables faster\ntraining of student models with marginal overhead (<10%) compared to\ncross-entropy based training, while maintaining competitive performance\ncompared to full distillation, across a range of model sizes from 300M to 3B.", "published": "2025-03-21 05:58:18", "link": "http://arxiv.org/abs/2503.16870v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T50", "I.2.7"], "primary_category": "cs.LG"}
{"title": "Joint Extraction Matters: Prompt-Based Visual Question Answering for Multi-Field Document Information Extraction", "abstract": "Visual question answering (VQA) has emerged as a flexible approach for\nextracting specific pieces of information from document images. However,\nexisting work typically queries each field in isolation, overlooking potential\ndependencies across multiple items. This paper investigates the merits of\nextracting multiple fields jointly versus separately. Through experiments on\nmultiple large vision language models and datasets, we show that jointly\nextracting fields often improves accuracy, especially when the fields share\nstrong numeric or contextual dependencies. We further analyze how performance\nscales with the number of requested items and use a regression based metric to\nquantify inter field relationships. Our results suggest that multi field\nprompts can mitigate confusion arising from similar surface forms and related\nnumeric values, providing practical methods for designing robust VQA systems in\ndocument information extraction tasks.", "published": "2025-03-21 05:54:42", "link": "http://arxiv.org/abs/2503.16868v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "MTBench: A Multimodal Time Series Benchmark for Temporal Reasoning and Question Answering", "abstract": "Understanding the relationship between textual news and time-series evolution\nis a critical yet under-explored challenge in applied data science. While\nmultimodal learning has gained traction, existing multimodal time-series\ndatasets fall short in evaluating cross-modal reasoning and complex question\nanswering, which are essential for capturing complex interactions between\nnarrative information and temporal patterns. To bridge this gap, we introduce\nMultimodal Time Series Benchmark (MTBench), a large-scale benchmark designed to\nevaluate large language models (LLMs) on time series and text understanding\nacross financial and weather domains. MTbench comprises paired time series and\ntextual data, including financial news with corresponding stock price movements\nand weather reports aligned with historical temperature records. Unlike\nexisting benchmarks that focus on isolated modalities, MTbench provides a\ncomprehensive testbed for models to jointly reason over structured numerical\ntrends and unstructured textual narratives. The richness of MTbench enables\nformulation of diverse tasks that require a deep understanding of both text and\ntime-series data, including time-series forecasting, semantic and technical\ntrend analysis, and news-driven question answering (QA). These tasks target the\nmodel's ability to capture temporal dependencies, extract key insights from\ntextual context, and integrate cross-modal information. We evaluate\nstate-of-the-art LLMs on MTbench, analyzing their effectiveness in modeling the\ncomplex relationships between news narratives and temporal patterns. Our\nfindings reveal significant challenges in current models, including\ndifficulties in capturing long-term dependencies, interpreting causality in\nfinancial and weather trends, and effectively fusing multimodal information.", "published": "2025-03-21 05:04:53", "link": "http://arxiv.org/abs/2503.16858v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "MMCR: Benchmarking Cross-Source Reasoning in Scientific Papers", "abstract": "Fully comprehending scientific papers by machines reflects a high level of\nArtificial General Intelligence, requiring the ability to reason across\nfragmented and heterogeneous sources of information, presenting a complex and\npractically significant challenge. While Vision-Language Models (VLMs) have\nmade remarkable strides in various tasks, particularly those involving\nreasoning with evidence source from single image or text page, their ability to\nuse cross-source information for reasoning remains an open problem. This work\npresents MMCR, a high-difficulty benchmark designed to evaluate VLMs' capacity\nfor reasoning with cross-source information from scientific papers. The\nbenchmark comprises 276 high-quality questions, meticulously annotated by\nhumans across 7 subjects and 10 task types. Experiments with 18 VLMs\ndemonstrate that cross-source reasoning presents a substantial challenge for\nexisting models. Notably, even the top-performing model, GPT-4o, achieved only\n48.55% overall accuracy, with only 20% accuracy in multi-table comprehension\ntasks, while the second-best model, Qwen2.5-VL-72B, reached 39.86% overall\naccuracy. Furthermore, we investigated the impact of the Chain-of-Thought (CoT)\ntechnique on cross-source reasoning and observed a detrimental effect on small\nmodels, whereas larger models demonstrated substantially enhanced performance.\nThese results highlight the pressing need to develop VLMs capable of\neffectively utilizing cross-source information for reasoning.", "published": "2025-03-21 05:02:20", "link": "http://arxiv.org/abs/2503.16856v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Imagine to Hear: Auditory Knowledge Generation can be an Effective Assistant for Language Models", "abstract": "Language models pretrained on text-only corpora often struggle with tasks\nthat require auditory commonsense knowledge. Previous work addresses this\nproblem by augmenting the language model to retrieve knowledge from external\naudio databases. This approach has several limitations, such as the potential\nlack of relevant audio in databases and the high costs associated with\nconstructing and querying the databases. To address these issues, we propose\nImagine to Hear, a novel approach that dynamically generates auditory knowledge\nusing generative models. Our framework detects multiple audio-related textual\nspans from the given prompt and generates corresponding auditory knowledge. We\ndevelop several mechanisms to efficiently process multiple auditory knowledge,\nincluding a CLAP-based rejection sampler and a language-audio fusion module.\nOur experiments show that our method achieves state-of-the-art performance on\nAuditoryBench without relying on external databases, highlighting the\neffectiveness of our generation-based approach.", "published": "2025-03-21 04:56:22", "link": "http://arxiv.org/abs/2503.16853v1", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Towards LLM Guardrails via Sparse Representation Steering", "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in\nnatural language generation tasks, yet their uncontrolled outputs pose\nsignificant ethical and safety risks. Recently, representation engineering\nmethods have shown promising results in steering model behavior by modifying\nthe rich semantic information encoded in activation vectors. However, due to\nthe difficulty of precisely disentangling semantic directions within\nhigh-dimensional representation space, existing approaches suffer from three\nmajor limitations: lack of fine-grained control, quality degradation of\ngenerated content, and poor interpretability. To address these challenges, we\npropose a sparse encoding-based representation engineering method, named SRE,\nwhich decomposes polysemantic activations into a structured, monosemantic\nfeature space. By leveraging sparse autoencoding, our approach isolates and\nadjusts only task-specific sparse feature dimensions, enabling precise and\ninterpretable steering of model behavior while preserving content quality. We\nvalidate our method on three critical domains, i.e., safety, fairness, and\ntruthfulness using the open-source LLM Gemma-2-2B-it. Experimental results show\nthat SRE achieves superior controllability while maintaining the overall\nquality of generated content (i.e., controllability and quality), demonstrating\nits effectiveness as a fine-grained and interpretable activation steering\nframework.", "published": "2025-03-21 04:50:25", "link": "http://arxiv.org/abs/2503.16851v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "The Deployment of End-to-End Audio Language Models Should Take into Account the Principle of Least Privilege", "abstract": "We are at a turning point for language models that accept audio input. The\nlatest end-to-end audio language models (Audio LMs) process speech directly\ninstead of relying on a separate transcription step. This shift preserves\ndetailed information, such as intonation or the presence of multiple speakers,\nthat would otherwise be lost in transcription. However, it also introduces new\nsafety risks, including the potential misuse of speaker identity cues and other\nsensitive vocal attributes, which could have legal implications. In this\nposition paper, we urge a closer examination of how these models are built and\ndeployed. We argue that the principle of least privilege should guide decisions\non whether to deploy cascaded or end-to-end models. Specifically, evaluations\nshould assess (1) whether end-to-end modeling is necessary for a given\napplication; and (2), the appropriate scope of information access. Finally, We\nhighlight related gaps in current audio LM benchmarks and identify key open\nresearch questions, both technical and policy-related, that must be addressed\nto enable the responsible deployment of end-to-end Audio LMs.", "published": "2025-03-21 04:03:59", "link": "http://arxiv.org/abs/2503.16833v1", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.CY", "eess.AS"], "primary_category": "cs.SD"}
{"title": "When Tom Eats Kimchi: Evaluating Cultural Bias of Multimodal Large Language Models in Cultural Mixture Contexts", "abstract": "In a highly globalized world, it is important for multi-modal large language\nmodels (MLLMs) to recognize and respond correctly to mixed-cultural inputs. For\nexample, a model should correctly identify kimchi (Korean food) in an image\nboth when an Asian woman is eating it, as well as an African man is eating it.\nHowever, current MLLMs show an over-reliance on the visual features of the\nperson, leading to misclassification of the entities. To examine the robustness\nof MLLMs to different ethnicity, we introduce MixCuBe, a cross-cultural bias\nbenchmark, and study elements from five countries and four ethnicities. Our\nfindings reveal that MLLMs achieve both higher accuracy and lower sensitivity\nto such perturbation for high-resource cultures, but not for low-resource\ncultures. GPT-4o, the best-performing model overall, shows up to 58% difference\nin accuracy between the original and perturbed cultural settings in\nlow-resource cultures. Our dataset is publicly available at:\nhttps://huggingface.co/datasets/kyawyethu/MixCuBe.", "published": "2025-03-21 03:50:05", "link": "http://arxiv.org/abs/2503.16826v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "When Debate Fails: Bias Reinforcement in Large Language Models", "abstract": "Large Language Models $($LLMs$)$ solve complex problems using training-free\nmethods like prompt engineering and in-context learning, yet ensuring reasoning\ncorrectness remains challenging. While self-correction methods such as\nself-consistency and self-refinement aim to improve reliability, they often\nreinforce biases due to the lack of effective feedback mechanisms. Multi-Agent\nDebate $($MAD$)$ has emerged as an alternative, but we identify two key\nlimitations: bias reinforcement, where debate amplifies model biases instead of\ncorrecting them, and lack of perspective diversity, as all agents share the\nsame model and reasoning patterns, limiting true debate effectiveness. To\nsystematically evaluate these issues, we introduce $\\textit{MetaNIM Arena}$, a\nbenchmark designed to assess LLMs in adversarial strategic decision-making,\nwhere dynamic interactions influence optimal decisions. To overcome MAD's\nlimitations, we propose $\\textbf{DReaMAD}$ $($$\\textbf{D}$iverse\n$\\textbf{Rea}$soning via $\\textbf{M}$ulti-$\\textbf{A}$gent $\\textbf{D}$ebate\nwith Refined Prompt$)$, a novel framework that $(1)$ refines LLM's strategic\nprior knowledge to improve reasoning quality and $(2)$ promotes diverse\nviewpoints within a single model by systematically modifying prompts, reducing\nbias. Empirical results show that $\\textbf{DReaMAD}$ significantly improves\ndecision accuracy, reasoning diversity, and bias mitigation across multiple\nstrategic tasks, establishing it as a more effective approach for LLM-based\ndecision-making.", "published": "2025-03-21 02:51:30", "link": "http://arxiv.org/abs/2503.16814v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Conversational User-AI Intervention: A Study on Prompt Rewriting for Improved LLM Response Generation", "abstract": "Human-LLM conversations are increasingly becoming more pervasive in peoples'\nprofessional and personal lives, yet many users still struggle to elicit\nhelpful responses from LLM Chatbots. One of the reasons for this issue is\nusers' lack of understanding in crafting effective prompts that accurately\nconvey their information needs. Meanwhile, the existence of real-world\nconversational datasets on the one hand, and the text understanding faculties\nof LLMs on the other, present a unique opportunity to study this problem, and\nits potential solutions at scale. Thus, in this paper we present the first\nLLM-centric study of real human-AI chatbot conversations, focused on\ninvestigating aspects in which user queries fall short of expressing\ninformation needs, and the potential of using LLMs to rewrite suboptimal user\nprompts. Our findings demonstrate that rephrasing ineffective prompts can\nelicit better responses from a conversational system, while preserving the\nuser's original intent. Notably, the performance of rewrites improves in longer\nconversations, where contextual inferences about user needs can be made more\naccurately. Additionally, we observe that LLMs often need to -- and inherently\ndo -- make \\emph{plausible} assumptions about a user's intentions and goals\nwhen interpreting prompts. Our findings largely hold true across conversational\ndomains, user intents, and LLMs of varying sizes and families, indicating the\npromise of using prompt rewriting as a solution for better human-AI\ninteractions.", "published": "2025-03-21 02:01:02", "link": "http://arxiv.org/abs/2503.16789v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain-of-Tools: Utilizing Massive Unseen Tools in the CoT Reasoning of Frozen Language Models", "abstract": "Tool learning can further broaden the usage scenarios of large language\nmodels (LLMs). However most of the existing methods either need to finetune\nthat the model can only use tools seen in the training data, or add tool\ndemonstrations into the prompt with lower efficiency. In this paper, we present\na new Tool Learning method Chain-of-Tools. It makes full use of the powerful\nsemantic representation capability of frozen LLMs to finish tool calling in CoT\nreasoning with a huge and flexible tool pool which may contain unseen tools.\nEspecially, to validate the effectiveness of our approach in the massive unseen\ntool scenario, we construct a new dataset SimpleToolQuestions. We conduct\nexperiments on two numerical reasoning benchmarks (GSM8K-XL and FuncQA) and two\nknowledge-based question answering benchmarks (KAMEL and SimpleToolQuestions).\nExperimental results show that our approach performs better than the baseline.\nWe also identify dimensions of the model output that are critical in tool\nselection, enhancing the model interpretability. Our code and data are\navailable at: https://github.com/fairyshine/Chain-of-Tools .", "published": "2025-03-21 01:26:12", "link": "http://arxiv.org/abs/2503.16779v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Measuring the Robustness of Audio Deepfake Detectors", "abstract": "Deepfakes have become a universal and rapidly intensifying concern of\ngenerative AI across various media types such as images, audio, and videos.\nAmong these, audio deepfakes have been of particular concern due to the ease of\nhigh-quality voice synthesis and distribution via platforms such as social\nmedia and robocalls. Consequently, detecting audio deepfakes plays a critical\nrole in combating the growing misuse of AI-synthesized speech. However,\nreal-world scenarios often introduce various audio corruptions, such as noise,\nmodification, and compression, that may significantly impact detection\nperformance. This work systematically evaluates the robustness of 10 audio\ndeepfake detection models against 16 common corruptions, categorized into noise\nperturbation, audio modification, and compression. Using both traditional deep\nlearning models and state-of-the-art foundation models, we make four unique\nobservations. First, our findings show that while most models demonstrate\nstrong robustness to noise, they are notably more vulnerable to modifications\nand compression, especially when neural codecs are applied. Second, speech\nfoundation models generally outperform traditional models across most\nscenarios, likely due to their self-supervised learning paradigm and\nlarge-scale pre-training. Third, our results show that increasing model size\nimproves robustness, albeit with diminishing returns. Fourth, we demonstrate\nhow targeted data augmentation during training can enhance model resilience to\nunseen perturbations. A case study on political speech deepfakes highlights the\neffectiveness of foundation models in achieving high accuracy under real-world\nconditions. These findings emphasize the importance of developing more robust\ndetection frameworks to ensure reliability in practical deployment settings.", "published": "2025-03-21 23:21:17", "link": "http://arxiv.org/abs/2503.17577v1", "categories": ["cs.CR", "cs.AI", "cs.SD"], "primary_category": "cs.CR"}
{"title": "Intelligent Resource Allocation Optimization for Cloud Computing via Machine Learning", "abstract": "With the rapid expansion of cloud computing applications, optimizing resource\nallocation has become crucial for improving system performance and cost\nefficiency. This paper proposes an intelligent resource allocation algorithm\nthat leverages deep learning (LSTM) for demand prediction and reinforcement\nlearning (DQN) for dynamic scheduling. By accurately forecasting computing\nresource demands and enabling real-time adjustments, the proposed system\nenhances resource utilization by 32.5%, reduces average response time by 43.3%,\nand lowers operational costs by 26.6%. Experimental results in a production\ncloud environment confirm that the method significantly improves efficiency\nwhile maintaining high service quality. This study provides a scalable and\neffective solution for intelligent cloud resource management, offering valuable\ninsights for future cloud optimization strategies.", "published": "2025-03-21 23:06:43", "link": "http://arxiv.org/abs/2504.03682v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "cs.DC"}
{"title": "Fairness-Driven LLM-based Causal Discovery with Active Learning and Dynamic Scoring", "abstract": "Causal discovery (CD) plays a pivotal role in numerous scientific fields by\nclarifying the causal relationships that underlie phenomena observed in diverse\ndisciplines. Despite significant advancements in CD algorithms that enhance\nbias and fairness analyses in machine learning, their application faces\nchallenges due to the high computational demands and complexities of\nlarge-scale data. This paper introduces a framework that leverages Large\nLanguage Models (LLMs) for CD, utilizing a metadata-based approach akin to the\nreasoning processes of human experts. By shifting from pairwise queries to a\nmore scalable breadth-first search (BFS) strategy, the number of required\nqueries is reduced from quadratic to linear in terms of variable count, thereby\naddressing scalability concerns inherent in previous approaches. This method\nutilizes an Active Learning (AL) and a Dynamic Scoring Mechanism that\nprioritizes queries based on their potential information gain, combining mutual\ninformation, partial correlation, and LLM confidence scores to refine the\ncausal graph more efficiently and accurately. This BFS query strategy reduces\nthe required number of queries significantly, thereby addressing scalability\nconcerns inherent in previous approaches. This study provides a more scalable\nand efficient solution for leveraging LLMs in fairness-driven CD, highlighting\nthe effects of the different parameters on performance. We perform fairness\nanalyses on the inferred causal graphs, identifying direct and indirect effects\nof sensitive attributes on outcomes. A comparison of these analyses against\nthose from graphs produced by baseline methods highlights the importance of\naccurate causal graph construction in understanding bias and ensuring fairness\nin machine learning systems.", "published": "2025-03-21 22:58:26", "link": "http://arxiv.org/abs/2503.17569v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Audio-Enhanced Vision-Language Modeling with Latent Space Broadening for High Quality Data Expansion", "abstract": "Transformer-based multimodal models are widely used in industrial-scale\nrecommendation, search, and advertising systems for content understanding and\nrelevance ranking. Enhancing labeled training data quality and cross-modal\nfusion significantly improves model performance, influencing key metrics such\nas quality view rates and ad revenue. High-quality annotations are crucial for\nadvancing content modeling, yet traditional statistical-based active learning\n(AL) methods face limitations: they struggle to detect overconfident\nmisclassifications and are less effective in distinguishing semantically\nsimilar items in deep neural networks. Additionally, audio information plays an\nincreasing role, especially in short-video platforms, yet most pre-trained\nmultimodal architectures primarily focus on text and images. While training\nfrom scratch across all three modalities is possible, it sacrifices the\nbenefits of leveraging existing pre-trained visual-language (VL) and audio\nmodels. To address these challenges, we propose kNN-based Latent Space\nBroadening (LSB) to enhance AL efficiency and Vision-Language Modeling with\nAudio Enhancement (VLMAE), a mid-fusion approach integrating audio into VL\nmodels. This system deployed in production systems, leading to significant\nbusiness gains.", "published": "2025-03-21 21:55:05", "link": "http://arxiv.org/abs/2503.17551v1", "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Learning Multi-Level Features with Matryoshka Sparse Autoencoders", "abstract": "Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting\nneural networks by extracting the concepts represented in their activations.\nHowever, choosing the size of the SAE dictionary (i.e. number of learned\nconcepts) creates a tension: as dictionary size increases to capture more\nrelevant concepts, sparsity incentivizes features to be split or absorbed into\nmore specific features, leaving high-level features missing or warped. We\nintroduce Matryoshka SAEs, a novel variant that addresses these issues by\nsimultaneously training multiple nested dictionaries of increasing size,\nforcing the smaller dictionaries to independently reconstruct the inputs\nwithout using the larger dictionaries. This organizes features hierarchically -\nthe smaller dictionaries learn general concepts, while the larger dictionaries\nlearn more specific concepts, without incentive to absorb the high-level\nfeatures. We train Matryoshka SAEs on Gemma-2-2B and TinyStories and find\nsuperior performance on sparse probing and targeted concept erasure tasks, more\ndisentangled concept representations, and reduced feature absorption. While\nthere is a minor tradeoff with reconstruction performance, we believe\nMatryoshka SAEs are a superior alternative for practical tasks, as they enable\ntraining arbitrarily large SAEs while retaining interpretable features at\ndifferent levels of abstraction.", "published": "2025-03-21 21:43:28", "link": "http://arxiv.org/abs/2503.17547v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "PRIMAL: Physically Reactive and Interactive Motor Model for Avatar Learning", "abstract": "To build a motor system of the interactive avatar, it is essential to develop\na generative motion model drives the body to move through 3D space in a\nperpetual, realistic, controllable, and responsive manner. Although motion\ngeneration has been extensively studied, most methods do not support ``embodied\nintelligence'' due to their offline setting, slow speed, limited motion\nlengths, or unnatural movements. To overcome these limitations, we propose\nPRIMAL, an autoregressive diffusion model that is learned with a two-stage\nparadigm, inspired by recent advances in foundation models. In the pretraining\nstage, the model learns motion dynamics from a large number of sub-second\nmotion segments, providing ``motor primitives'' from which more complex motions\nare built. In the adaptation phase, we employ a ControlNet-like adaptor to\nfine-tune the motor control for semantic action generation and spatial target\nreaching. Experiments show that physics effects emerge from our training. Given\na single-frame initial state, our model not only generates unbounded,\nrealistic, and controllable motion, but also enables the avatar to be\nresponsive to induced impulses in real time. In addition, we can effectively\nand efficiently adapt our base model to few-shot personalized actions and the\ntask of spatial control. Evaluations show that our proposed method outperforms\nstate-of-the-art baselines. We leverage the model to create a real-time\ncharacter animation system in Unreal Engine that is highly responsive and\nnatural. Code, models, and more results are available at:\nhttps://yz-cnsdqz.github.io/eigenmotion/PRIMAL", "published": "2025-03-21 21:27:57", "link": "http://arxiv.org/abs/2503.17544v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A Predictive Services Architecture for Efficient Airspace Operations", "abstract": "Predicting air traffic congestion and flow management is essential for\nairlines and Air Navigation Service Providers (ANSP) to enhance operational\nefficiency. Accurate estimates of future airport capacity and airspace density\nare vital for better airspace management, reducing air traffic controller\nworkload and fuel consumption, ultimately promoting sustainable aviation. While\nexisting literature has addressed these challenges, data management and query\nprocessing remain complex due to the vast volume of high-rate air traffic data.\nMany analytics use cases require a common pre-processing infrastructure, as\nad-hoc approaches are insufficient. Additionally, linear prediction models\noften fall short, necessitating more advanced techniques.\n  This paper presents a data processing and predictive services architecture\nthat ingests large, uncorrelated, and noisy streaming data to forecast future\nairspace system states. The system continuously collects raw data, periodically\ncompresses it, and stores it in NoSQL databases for efficient query processing.\nFor prediction, the system learns from historical traffic by extracting key\nfeatures such as airport arrival and departure events, sector boundary\ncrossings, weather parameters, and other air traffic data. These features are\ninput into various regression models, including linear, non-linear, and\nensemble models, with the best-performing model selected for predictions. We\nevaluate this infrastructure across three prediction use cases in the US\nNational Airspace System (NAS) and a segment of European airspace, using\nextensive real operations data, confirming that our system can predict future\nsystem states efficiently and accurately.", "published": "2025-03-21 19:57:38", "link": "http://arxiv.org/abs/2503.17515v1", "categories": ["cs.LG", "cs.AI", "cs.DB", "cs.SY", "eess.SY"], "primary_category": "cs.LG"}
{"title": "Improving Quantization with Post-Training Model Expansion", "abstract": "The size of a model has been a strong predictor of its quality, as well as\nits cost. As such, the trade-off between model cost and quality has been\nwell-studied. Post-training optimizations like quantization and pruning have\ntypically focused on reducing the overall volume of pre-trained models to\nreduce inference costs while maintaining model quality. However, recent\nadvancements have introduced optimization techniques that, interestingly,\nexpand models post-training, increasing model size to improve quality when\nreducing volume. For instance, to enable 4-bit weight and activation\nquantization, incoherence processing often necessitates inserting online\nHadamard rotations in the compute graph, and preserving highly sensitive\nweights often calls for additional higher precision computations. However, if\napplication requirements cannot be met, the prevailing solution is to relax\nquantization constraints. In contrast, we demonstrate post-training model\nexpansion is a viable strategy to improve model quality within a quantization\nco-design space, and provide theoretical justification. We show it is possible\nto progressively and selectively expand the size of a pre-trained large\nlanguage model (LLM) to improve model quality without end-to-end retraining. In\nparticular, when quantizing the weights and activations to 4 bits for Llama3\n1B, we reduce the zero-shot accuracy gap to full precision by an average of 3%\nrelative to both QuaRot and SpinQuant with only 5% more parameters, which is\nstill a 3.8% reduction in volume relative to a BF16 reference model.", "published": "2025-03-21 19:56:59", "link": "http://arxiv.org/abs/2503.17513v1", "categories": ["cs.LG", "cs.AI", "cs.AR"], "primary_category": "cs.LG"}
{"title": "Efficient Knowledge Distillation via Curriculum Extraction", "abstract": "Knowledge distillation is a technique used to train a small student network\nusing the output generated by a large teacher network, and has many empirical\nadvantages~\\citep{Hinton2015DistillingTK}. While the standard one-shot approach\nto distillation only uses the output of the final teacher network, recent\nwork~\\citep{panigrahi2024progressive} has shown that using intermediate\ncheckpoints from the teacher's training process as an implicit ``curriculum''\nfor progressive distillation can significantly speed up training. However, such\nschemes require storing these checkpoints, and often require careful selection\nof the intermediate checkpoints to train on, which can be impractical for\nlarge-scale training.\n  In this paper, we show that a curriculum can be \\emph{extracted} from just\nthe fully trained teacher network, and that this extracted curriculum can give\nsimilar efficiency benefits to those of progressive distillation. Our\nextraction scheme is natural; we use a random projection of the hidden\nrepresentations of the teacher network to progressively train the student\nnetwork, before training using the output of the full network. We show that our\nscheme significantly outperforms one-shot distillation and achieves a\nperformance similar to that of progressive distillation for learning sparse\nparities with two-layer networks, and provide theoretical guarantees for this\nsetting. Additionally, we show that our method outperforms one-shot\ndistillation even when using transformer-based architectures, both for\nsparse-parity learning, and language modeling tasks.", "published": "2025-03-21 19:09:41", "link": "http://arxiv.org/abs/2503.17494v1", "categories": ["cs.LG", "cs.AI", "math.ST", "stat.ML", "stat.TH"], "primary_category": "cs.LG"}
{"title": "ProtoGS: Efficient and High-Quality Rendering with 3D Gaussian Prototypes", "abstract": "3D Gaussian Splatting (3DGS) has made significant strides in novel view\nsynthesis but is limited by the substantial number of Gaussian primitives\nrequired, posing challenges for deployment on lightweight devices. Recent\nmethods address this issue by compressing the storage size of densified\nGaussians, yet fail to preserve rendering quality and efficiency. To overcome\nthese limitations, we propose ProtoGS to learn Gaussian prototypes to represent\nGaussian primitives, significantly reducing the total Gaussian amount without\nsacrificing visual quality. Our method directly uses Gaussian prototypes to\nenable efficient rendering and leverage the resulting reconstruction loss to\nguide prototype learning. To further optimize memory efficiency during\ntraining, we incorporate structure-from-motion (SfM) points as anchor points to\ngroup Gaussian primitives. Gaussian prototypes are derived within each group by\nclustering of K-means, and both the anchor points and the prototypes are\noptimized jointly. Our experiments on real-world and synthetic datasets prove\nthat we outperform existing methods, achieving a substantial reduction in the\nnumber of Gaussians, and enabling high rendering speed while maintaining or\neven enhancing rendering fidelity.", "published": "2025-03-21 18:55:14", "link": "http://arxiv.org/abs/2503.17486v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "What's Producible May Not Be Reachable: Measuring the Steerability of Generative Models", "abstract": "How should we evaluate the quality of generative models? Many existing\nmetrics focus on a model's producibility, i.e. the quality and breadth of\noutputs it can generate. However, the actual value from using a generative\nmodel stems not just from what it can produce but whether a user with a\nspecific goal can produce an output that satisfies that goal. We refer to this\nproperty as steerability. In this paper, we first introduce a mathematical\nframework for evaluating steerability independently from producibility.\nSteerability is more challenging to evaluate than producibility because it\nrequires knowing a user's goals. We address this issue by creating a benchmark\ntask that relies on one key idea: sample an output from a generative model and\nask users to reproduce it. We implement this benchmark in a large-scale user\nstudy of text-to-image models and large language models. Despite the ability of\nthese models to produce high-quality outputs, they all perform poorly on\nsteerabilty. This suggests that we need to focus on improving the steerability\nof generative models. We show such improvements are indeed possible: through\nreinforcement learning techniques, we create an alternative steering mechanism\nfor image models that achieves more than 2x improvement on this benchmark.", "published": "2025-03-21 18:51:56", "link": "http://arxiv.org/abs/2503.17482v1", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "primary_category": "cs.LG"}
{"title": "Your voice is your voice: Supporting Self-expression through Speech Generation and LLMs in Augmented and Alternative Communication", "abstract": "In this paper, we present Speak Ease: an augmentative and alternative\ncommunication (AAC) system to support users' expressivity by integrating\nmultimodal input, including text, voice, and contextual cues (conversational\npartner and emotional tone), with large language models (LLMs). Speak Ease\ncombines automatic speech recognition (ASR), context-aware LLM-based outputs,\nand personalized text-to-speech technologies to enable more personalized,\nnatural-sounding, and expressive communication. Through an exploratory\nfeasibility study and focus group evaluation with speech and language\npathologists (SLPs), we assessed Speak Ease's potential to enable expressivity\nin AAC. The findings highlight the priorities and needs of AAC users and the\nsystem's ability to enhance user expressivity by supporting more personalized\nand contextually relevant communication. This work provides insights into the\nuse of multimodal inputs and LLM-driven features to improve AAC systems and\nsupport expressivity.", "published": "2025-03-21 18:50:05", "link": "http://arxiv.org/abs/2503.17479v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Spatiotemporal Learning with Context-aware Video Tubelets for Ultrasound Video Analysis", "abstract": "Computer-aided pathology detection algorithms for video-based imaging\nmodalities must accurately interpret complex spatiotemporal information by\nintegrating findings across multiple frames. Current state-of-the-art methods\noperate by classifying on video sub-volumes (tubelets), but they often lose\nglobal spatial context by focusing only on local regions within detection ROIs.\nHere we propose a lightweight framework for tubelet-based object detection and\nvideo classification that preserves both global spatial context and fine\nspatiotemporal features. To address the loss of global context, we embed\ntubelet location, size, and confidence as inputs to the classifier.\nAdditionally, we use ROI-aligned feature maps from a pre-trained detection\nmodel, leveraging learned feature representations to increase the receptive\nfield and reduce computational complexity. Our method is efficient, with the\nspatiotemporal tubelet classifier comprising only 0.4M parameters. We apply our\napproach to detect and classify lung consolidation and pleural effusion in\nultrasound videos. Five-fold cross-validation on 14,804 videos from 828\npatients shows our method outperforms previous tubelet-based approaches and is\nsuited for real-time workflows.", "published": "2025-03-21 18:39:42", "link": "http://arxiv.org/abs/2503.17475v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "CausalRivers -- Scaling up benchmarking of causal discovery for real-world time-series", "abstract": "Causal discovery, or identifying causal relationships from observational\ndata, is a notoriously challenging task, with numerous methods proposed to\ntackle it. Despite this, in-the-wild evaluation of these methods is still\nlacking, as works frequently rely on synthetic data evaluation and sparse\nreal-world examples under critical theoretical assumptions. Real-world causal\nstructures, however, are often complex, making it hard to decide on a proper\ncausal discovery strategy. To bridge this gap, we introduce CausalRivers, the\nlargest in-the-wild causal discovery benchmarking kit for time-series data to\ndate. CausalRivers features an extensive dataset on river discharge that covers\nthe eastern German territory (666 measurement stations) and the state of\nBavaria (494 measurement stations). It spans the years 2019 to 2023 with a\n15-minute temporal resolution. Further, we provide additional data from a flood\naround the Elbe River, as an event with a pronounced distributional shift.\nLeveraging multiple sources of information and time-series meta-data, we\nconstructed two distinct causal ground truth graphs (Bavaria and eastern\nGermany). These graphs can be sampled to generate thousands of subgraphs to\nbenchmark causal discovery across diverse and challenging settings. To\ndemonstrate the utility of CausalRivers, we evaluate several causal discovery\napproaches through a set of experiments to identify areas for improvement.\nCausalRivers has the potential to facilitate robust evaluations and comparisons\nof causal discovery methods. Besides this primary purpose, we also expect that\nthis dataset will be relevant for connected areas of research, such as\ntime-series forecasting and anomaly detection. Based on this, we hope to push\nbenchmark-driven method development that fosters advanced techniques for causal\ndiscovery, as is the case for many other areas of machine learning.", "published": "2025-03-21 18:02:35", "link": "http://arxiv.org/abs/2503.17452v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "LEMMA: Learning from Errors for MatheMatical Advancement in LLMs", "abstract": "Large language models (LLMs) have demonstrated remarkable reasoning\ncapability in solving mathematical problems. However, existing approaches\nprimarily focus on improving the quality of correct training data, e.g.,\ndistilling high-quality correct solutions from advanced models, neglecting the\nvalue contained in error data, potentially hindering the model's reflective\nability. Though some studies attempt to leverage error data, they often involve\ncomplex mechanisms, such as Monte Carlo Tree Search (MCTS) to explore error\nnodes. In this work, we propose to enhance LLMs' reasoning ability by Learning\nfrom Errors for Mathematical Advancement (LEMMA). LEMMA constructs data\nconsisting of an incorrect solution with an erroneous step and a reflection\nconnection to a correct solution for fine-tuning. Specifically, we\nsystematically analyze the model-generated error types and introduce an\nerror-type grounded mistake augmentation method to collect diverse and\nrepresentative errors. Correct solutions are either from fixing the errors or\ngenerating a fresh start. Through a model-aware smooth reflection connection,\nthe erroneous solution is transferred to the correct one. By fine-tuning on the\nconstructed dataset, the model is able to self-correct errors autonomously\nwithin the generation process without relying on external critique models.\nExperimental results demonstrate that LEMMA achieves significant performance\nimprovements over other strong baselines.", "published": "2025-03-21 17:59:10", "link": "http://arxiv.org/abs/2503.17439v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "HCAST: Human-Calibrated Autonomy Software Tasks", "abstract": "To understand and predict the societal impacts of highly autonomous AI\nsystems, we need benchmarks with grounding, i.e., metrics that directly connect\nAI performance to real-world effects we care about. We present HCAST\n(Human-Calibrated Autonomy Software Tasks), a benchmark of 189 machine learning\nengineering, cybersecurity, software engineering, and general reasoning tasks.\nWe collect 563 human baselines (totaling over 1500 hours) from people skilled\nin these domains, working under identical conditions as AI agents, which lets\nus estimate that HCAST tasks take humans between one minute and 8+ hours.\nMeasuring the time tasks take for humans provides an intuitive metric for\nevaluating AI capabilities, helping answer the question \"can an agent be\ntrusted to complete a task that would take a human X hours?\" We evaluate the\nsuccess rates of AI agents built on frontier foundation models, and we find\nthat current agents succeed 70-80% of the time on tasks that take humans less\nthan one hour, and less than 20% of the time on tasks that take humans more\nthan 4 hours.", "published": "2025-03-21 17:54:01", "link": "http://arxiv.org/abs/2503.17354v1", "categories": ["cs.AI", "I.2.0"], "primary_category": "cs.AI"}
{"title": "NdLinear Is All You Need for Representation Learning", "abstract": "Many high-impact machine learning tasks involve multi-dimensional data (e.g.,\nimages, volumetric medical scans, multivariate time-series). Yet, most neural\narchitectures flatten inputs, discarding critical cross-dimension information.\nWe introduce NdLinear, a novel linear transformation that preserves these\nstructures without extra overhead. By operating separately along each\ndimension, NdLinear captures dependencies that standard fully connected layers\noverlook. Extensive experiments across convolutional, recurrent, and\ntransformer-based networks show significant improvements in representational\npower and parameter efficiency. Crucially, NdLinear serves as a foundational\nbuilding block for large-scale foundation models by operating on any unimodal\nor multimodal data in its native form. This removes the need for flattening or\nmodality-specific preprocessing. Ndlinear rethinks core architectural\npriorities beyond attention, enabling more expressive, context-aware models at\nscale. We propose NdLinear as a drop-in replacement for standard linear layers\n-- marking an important step toward next-generation neural architectures.", "published": "2025-03-21 17:52:44", "link": "http://arxiv.org/abs/2503.17353v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Align Your Rhythm: Generating Highly Aligned Dance Poses with Gating-Enhanced Rhythm-Aware Feature Representation", "abstract": "Automatically generating natural, diverse and rhythmic human dance movements\ndriven by music is vital for virtual reality and film industries. However,\ngenerating dance that naturally follows music remains a challenge, as existing\nmethods lack proper beat alignment and exhibit unnatural motion dynamics. In\nthis paper, we propose Danceba, a novel framework that leverages gating\nmechanism to enhance rhythm-aware feature representation for music-driven dance\ngeneration, which achieves highly aligned dance poses with enhanced rhythmic\nsensitivity. Specifically, we introduce Phase-Based Rhythm Extraction (PRE) to\nprecisely extract rhythmic information from musical phase data, capitalizing on\nthe intrinsic periodicity and temporal structures of music. Additionally, we\npropose Temporal-Gated Causal Attention (TGCA) to focus on global rhythmic\nfeatures, ensuring that dance movements closely follow the musical rhythm. We\nalso introduce Parallel Mamba Motion Modeling (PMMM) architecture to separately\nmodel upper and lower body motions along with musical features, thereby\nimproving the naturalness and diversity of generated dance movements. Extensive\nexperiments confirm that Danceba outperforms state-of-the-art methods,\nachieving significantly better rhythmic alignment and motion diversity. Project\npage: https://danceba.github.io/ .", "published": "2025-03-21 17:42:50", "link": "http://arxiv.org/abs/2503.17340v1", "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.MM"}
{"title": "Can AI expose tax loopholes? Towards a new generation of legal policy assistants", "abstract": "The legislative process is the backbone of a state built on solid\ninstitutions. Yet, due to the complexity of laws -- particularly tax law --\npolicies may lead to inequality and social tensions. In this study, we\nintroduce a novel prototype system designed to address the issues of tax\nloopholes and tax avoidance. Our hybrid solution integrates a natural language\ninterface with a domain-specific language tailored for planning. We demonstrate\non a case study how tax loopholes and avoidance schemes can be exposed. We\nconclude that our prototype can help enhance social welfare by systematically\nidentifying and addressing tax gaps stemming from loopholes.", "published": "2025-03-21 17:40:06", "link": "http://arxiv.org/abs/2503.17339v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Capturing Individual Human Preferences with Reward Features", "abstract": "Reinforcement learning from human feedback usually models preferences using a\nreward model that does not distinguish between people. We argue that this is\nunlikely to be a good design choice in contexts with high potential for\ndisagreement, like in the training of large language models. We propose a\nmethod to specialise a reward model to a person or group of people. Our\napproach builds on the observation that individual preferences can be captured\nas a linear combination of a set of general reward features. We show how to\nlearn such features and subsequently use them to quickly adapt the reward model\nto a specific individual, even if their preferences are not reflected in the\ntraining data. We present experiments with large language models comparing the\nproposed architecture with a non-adaptive reward model and also adaptive\ncounterparts, including models that do in-context personalisation. Depending on\nhow much disagreement there is in the training data, our model either\nsignificantly outperforms the baselines or matches their performance with a\nsimpler architecture and more stable training.", "published": "2025-03-21 17:39:33", "link": "http://arxiv.org/abs/2503.17338v1", "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real-World Web Application Vulnerabilities", "abstract": "Large language model (LLM) agents are increasingly capable of autonomously\nconducting cyberattacks, posing significant threats to existing applications.\nThis growing risk highlights the urgent need for a real-world benchmark to\nevaluate the ability of LLM agents to exploit web application vulnerabilities.\nHowever, existing benchmarks fall short as they are limited to abstracted\nCapture the Flag competitions or lack comprehensive coverage. Building a\nbenchmark for real-world vulnerabilities involves both specialized expertise to\nreproduce exploits and a systematic approach to evaluating unpredictable\nthreats. To address this challenge, we introduce CVE-Bench, a real-world\ncybersecurity benchmark based on critical-severity Common Vulnerabilities and\nExposures. In CVE-Bench, we design a sandbox framework that enables LLM agents\nto exploit vulnerable web applications in scenarios that mimic real-world\nconditions, while also providing effective evaluation of their exploits. Our\nevaluation shows that the state-of-the-art agent framework can resolve up to\n13% of vulnerabilities.", "published": "2025-03-21 17:32:32", "link": "http://arxiv.org/abs/2503.17332v2", "categories": ["cs.CR", "cs.AI", "I.2.1; I.2.7"], "primary_category": "cs.CR"}
{"title": "LLM+MAP: Bimanual Robot Task Planning using Large Language Models and Planning Domain Definition Language", "abstract": "Bimanual robotic manipulation provides significant versatility, but also\npresents an inherent challenge due to the complexity involved in the spatial\nand temporal coordination between two hands. Existing works predominantly focus\non attaining human-level manipulation skills for robotic hands, yet little\nattention has been paid to task planning on long-horizon timescales. With their\noutstanding in-context learning and zero-shot generation abilities, Large\nLanguage Models (LLMs) have been applied and grounded in diverse robotic\nembodiments to facilitate task planning. However, LLMs still suffer from errors\nin long-horizon reasoning and from hallucinations in complex robotic tasks,\nlacking a guarantee of logical correctness when generating the plan. Previous\nworks, such as LLM+P, extended LLMs with symbolic planners. However, none have\nbeen successfully applied to bimanual robots. New challenges inevitably arise\nin bimanual manipulation, necessitating not only effective task decomposition\nbut also efficient task allocation. To address these challenges, this paper\nintroduces LLM+MAP, a bimanual planning framework that integrates LLM reasoning\nand multi-agent planning, automating effective and efficient bimanual task\nplanning. We conduct simulated experiments on various long-horizon manipulation\ntasks of differing complexity. Our method is built using GPT-4o as the backend,\nand we compare its performance against plans generated directly by LLMs,\nincluding GPT-4o, V3 and also recent strong reasoning models o1 and R1. By\nanalyzing metrics such as planning time, success rate, group debits, and\nplanning-step reduction rate, we demonstrate the superior performance of\nLLM+MAP, while also providing insights into robotic reasoning. Code is\navailable at https://github.com/Kchu/LLM-MAP.", "published": "2025-03-21 17:04:01", "link": "http://arxiv.org/abs/2503.17309v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Preference-Guided Diffusion for Multi-Objective Offline Optimization", "abstract": "Offline multi-objective optimization aims to identify Pareto-optimal\nsolutions given a dataset of designs and their objective values. In this work,\nwe propose a preference-guided diffusion model that generates Pareto-optimal\ndesigns by leveraging a classifier-based guidance mechanism. Our guidance\nclassifier is a preference model trained to predict the probability that one\ndesign dominates another, directing the diffusion model toward optimal regions\nof the design space. Crucially, this preference model generalizes beyond the\ntraining distribution, enabling the discovery of Pareto-optimal solutions\noutside the observed dataset. We introduce a novel diversity-aware preference\nguidance, augmenting Pareto dominance preference with diversity criteria. This\nensures that generated solutions are optimal and well-distributed across the\nobjective space, a capability absent in prior generative methods for offline\nmulti-objective optimization. We evaluate our approach on various continuous\noffline multi-objective optimization tasks and find that it consistently\noutperforms other inverse/generative approaches while remaining competitive\nwith forward/surrogate-based optimization methods. Our results highlight the\neffectiveness of classifier-guided diffusion models in generating diverse and\nhigh-quality solutions that approximate the Pareto front well.", "published": "2025-03-21 16:49:38", "link": "http://arxiv.org/abs/2503.17299v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Breaking the Symmetries of Indistinguishable Objects", "abstract": "Indistinguishable objects often occur when modelling problems in constraint\nprogramming, as well as in other related paradigms. They occur when objects can\nbe viewed as being drawn from a set of unlabelled objects, and the only\noperation allowed on them is equality testing. For example, the golfers in the\nsocial golfer problem are indistinguishable. If we do label the golfers, then\nany relabelling of the golfers in one solution gives another valid solution.\nTherefore, we can regard the symmetric group of size $n$ as acting on a set of\n$n$ indistinguishable objects. In this paper, we show how we can break the\nsymmetries resulting from indistinguishable objects. We show how symmetries on\nindistinguishable objects can be defined properly in complex types, for example\nin a matrix indexed by indistinguishable objects. We then show how the\nresulting symmetries can be broken correctly. In Essence, a high-level\nmodelling language, indistinguishable objects are encapsulated in \"unnamed\ntypes\". We provide an implementation of complete symmetry breaking for unnamed\ntypes in Essence.", "published": "2025-03-21 15:56:52", "link": "http://arxiv.org/abs/2503.17251v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Strong Baseline: Multi-UAV Tracking via YOLOv12 with BoT-SORT-ReID", "abstract": "Detecting and tracking multiple unmanned aerial vehicles (UAVs) in thermal\ninfrared video is inherently challenging due to low contrast, environmental\nnoise, and small target sizes. This paper provides a straightforward approach\nto address multi-UAV tracking in thermal infrared video, leveraging recent\nadvances in detection and tracking. Instead of relying on the well-established\nYOLOv5 with DeepSORT combination, we present a tracking framework built on\nYOLOv12 and BoT-SORT, enhanced with tailored training and inference strategies.\nWe evaluate our approach following the 4th Anti-UAV Challenge metrics and reach\ncompetitive performance. Notably, we achieved strong results without using\ncontrast enhancement or temporal information fusion to enrich UAV features,\nhighlighting our approach as a \"Strong Baseline\" for multi-UAV tracking tasks.\nWe provide implementation details, in-depth experimental analysis, and a\ndiscussion of potential improvements. The code is available at\nhttps://github.com/wish44165/YOLOv12-BoT-SORT-ReID .", "published": "2025-03-21 15:40:18", "link": "http://arxiv.org/abs/2503.17237v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Neuro-Symbolic Scene Graph Conditioning for Synthetic Image Dataset Generation", "abstract": "As machine learning models increase in scale and complexity, obtaining\nsufficient training data has become a critical bottleneck due to acquisition\ncosts, privacy constraints, and data scarcity in specialised domains. While\nsynthetic data generation has emerged as a promising alternative, a notable\nperformance gap remains compared to models trained on real data, particularly\nas task complexity grows. Concurrently, Neuro-Symbolic methods, which combine\nneural networks' learning strengths with symbolic reasoning's structured\nrepresentations, have demonstrated significant potential across various\ncognitive tasks. This paper explores the utility of Neuro-Symbolic conditioning\nfor synthetic image dataset generation, focusing specifically on improving the\nperformance of Scene Graph Generation models. The research investigates whether\nstructured symbolic representations in the form of scene graphs can enhance\nsynthetic data quality through explicit encoding of relational constraints. The\nresults demonstrate that Neuro-Symbolic conditioning yields significant\nimprovements of up to +2.59% in standard Recall metrics and +2.83% in No Graph\nConstraint Recall metrics when used for dataset augmentation. These findings\nestablish that merging Neuro-Symbolic and generative approaches produces\nsynthetic data with complementary structural information that enhances model\nperformance when combined with real data, providing a novel approach to\novercome data scarcity limitations even for complex visual reasoning tasks.", "published": "2025-03-21 15:26:16", "link": "http://arxiv.org/abs/2503.17224v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "PP-DocLayout: A Unified Document Layout Detection Model to Accelerate Large-Scale Data Construction", "abstract": "Document layout analysis is a critical preprocessing step in document\nintelligence, enabling the detection and localization of structural elements\nsuch as titles, text blocks, tables, and formulas. Despite its importance,\nexisting layout detection models face significant challenges in generalizing\nacross diverse document types, handling complex layouts, and achieving\nreal-time performance for large-scale data processing. To address these\nlimitations, we present PP-DocLayout, which achieves high precision and\nefficiency in recognizing 23 types of layout regions across diverse document\nformats. To meet different needs, we offer three models of varying scales.\nPP-DocLayout-L is a high-precision model based on the RT-DETR-L detector,\nachieving 90.4% mAP@0.5 and an end-to-end inference time of 13.4 ms per page on\na T4 GPU. PP-DocLayout-M is a balanced model, offering 75.2% mAP@0.5 with an\ninference time of 12.7 ms per page on a T4 GPU. PP-DocLayout-S is a\nhigh-efficiency model designed for resource-constrained environments and\nreal-time applications, with an inference time of 8.1 ms per page on a T4 GPU\nand 14.5 ms on a CPU. This work not only advances the state of the art in\ndocument layout analysis but also provides a robust solution for constructing\nhigh-quality training data, enabling advancements in document intelligence and\nmultimodal AI systems. Code and models are available at\nhttps://github.com/PaddlePaddle/PaddleX .", "published": "2025-03-21 15:20:47", "link": "http://arxiv.org/abs/2503.17213v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Architecture of Information", "abstract": "The paper explores an approach to constructing energy landscapes of a formal\nneuron and multilayer artificial neural networks (ANNs). Their analysis makes\nit possible to determine the conceptual limitations of both classification ANNs\n(e.g., MLP or CNN) and generative ANN models. The study of informational and\nthermodynamic entropy in formal neuron and ANN models leads to the conclusion\nabout the energetic nature of informational entropy. The application of the\nGibbs free energy concept allows representing the output information of ANNs as\nthe structured part of enthalpy. Modeling ANNs as energy systems makes it\npossible to interpret the structure of their internal energy as an internal\nmodel of the external world, which self-organizes based on the interaction of\nthe system's internal energy components. The control of the self-organization\nand evolution process of this model is carried out through an energy function\n(analogous to the Lyapunov function) based on reduction operators. This makes\nit possible to introduce a new approach to constructing self-organizing and\nevolutionary ANNs with direct learning, which does not require additional\nexternal algorithms. The presented research makes it possible to formulate a\nformal definition of information in terms of the interaction processes between\nthe internal and external energy of the system.", "published": "2025-03-21 14:48:41", "link": "http://arxiv.org/abs/2503.21794v1", "categories": ["cs.NE", "cs.AI", "cs.IT", "cs.LG", "math.IT", "H.1.1; I.2.0"], "primary_category": "cs.NE"}
{"title": "TreeSynth: Synthesizing Diverse Data from Scratch via Tree-Guided Subspace Partitioning", "abstract": "Model customization requires high-quality and diverse datasets, but acquiring\nsuch data remains challenging and costly. Although large language models (LLMs)\ncan synthesize training data, current approaches are constrained by limited\nseed data, model bias and insufficient control over the generation process,\nresulting in limited diversity and biased distribution with the increase of\ndata scales. To tackle this challenge, we present TreeSynth, a tree-guided\nsubspace-based data synthesis framework that recursively partitions the entire\ndata space into hierar-chical subspaces, enabling comprehensive and diverse\nscaling of data synthesis. Briefly, given a task-specific description, we\nconstruct a data space partitioning tree by iteratively executing criteria\ndetermination and subspace coverage steps. This hierarchically divides the\nwhole space (i.e., root node) into mutually exclusive and complementary atomic\nsubspaces (i.e., leaf nodes). By collecting synthesized data according to the\nattributes of each leaf node, we obtain a diverse dataset that fully covers the\ndata space. Empirically, our extensive experiments demonstrate that TreeSynth\nsurpasses both human-designed datasets and the state-of-the-art data synthesis\nbaselines, achieving maximum improvements of 45.2% in data diversity and 17.6%\nin downstream task performance across various models and tasks. Hopefully,\nTreeSynth provides a scalable solution to synthesize diverse and comprehensive\ndatasets from scratch without human intervention.", "published": "2025-03-21 14:43:23", "link": "http://arxiv.org/abs/2503.17195v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "D2Fusion: Dual-domain Fusion with Feature Superposition for Deepfake Detection", "abstract": "Deepfake detection is crucial for curbing the harm it causes to society.\nHowever, current Deepfake detection methods fail to thoroughly explore artifact\ninformation across different domains due to insufficient intrinsic\ninteractions. These interactions refer to the fusion and coordination after\nfeature extraction processes across different domains, which are crucial for\nrecognizing complex forgery clues. Focusing on more generalized Deepfake\ndetection, in this work, we introduce a novel bi-directional attention module\nto capture the local positional information of artifact clues from the spatial\ndomain. This enables accurate artifact localization, thus addressing the coarse\nprocessing with artifact features. To further address the limitation that the\nproposed bi-directional attention module may not well capture global subtle\nforgery information in the artifact feature (e.g., textures or edges), we\nemploy a fine-grained frequency attention module in the frequency domain. By\ndoing so, we can obtain high-frequency information in the fine-grained\nfeatures, which contains the global and subtle forgery information. Although\nthese features from the diverse domains can be effectively and independently\nimproved, fusing them directly does not effectively improve the detection\nperformance. Therefore, we propose a feature superposition strategy that\ncomplements information from spatial and frequency domains. This strategy turns\nthe feature components into the form of wave-like tokens, which are updated\nbased on their phase, such that the distinctions between authentic and artifact\nfeatures can be amplified. Our method demonstrates significant improvements\nover state-of-the-art (SOTA) methods on five public Deepfake datasets in\ncapturing abnormalities across different manipulated operations and real-life.", "published": "2025-03-21 14:31:33", "link": "http://arxiv.org/abs/2503.17184v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "LLMs Love Python: A Study of LLMs' Bias for Programming Languages and Libraries", "abstract": "Programming language and library choices are crucial to software reliability\nand security. Poor or inconsistent choices can lead to increased technical\ndebt, security vulnerabilities, and even catastrophic failures in\nsafety-critical systems. As Large Language Models (LLMs) play an increasing\nrole in code generation, it is essential to understand how they make these\ndecisions. However, little is known about their preferences when selecting\nprogramming languages and libraries for different coding tasks. To fill this\ngap, this study provides the first in-depth investigation into LLM preferences\nfor programming languages and libraries used when generating code. We assess\nthe preferences of eight diverse LLMs by prompting them to complete various\ncoding tasks, including widely-studied benchmarks and the more practical task\nof generating the initial structural code for new projects (a crucial step that\noften determines a project's language or library choices).\n  Our findings reveal that LLMs heavily favour Python when solving\nlanguage-agnostic problems, using it in 90%-97% of cases for benchmark tasks.\nEven when generating initial project code where Python is not a suitable\nlanguage, it remains the most-used language in 58% of instances. Moreover, LLMs\ncontradict their own language recommendations in 83% of project initialisation\ntasks, raising concerns about their reliability in guiding language selection.\nSimilar biases toward well-established libraries further create serious\ndiscoverability challenges for newer open-source projects. These results\nhighlight the need to improve LLMs' adaptability to diverse programming\ncontexts and to develop mechanisms for mitigating programming language and\nlibrary bias.", "published": "2025-03-21 14:29:35", "link": "http://arxiv.org/abs/2503.17181v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "DiTEC-WDN: A Large-Scale Dataset of Hydraulic Scenarios across Multiple Water Distribution Networks", "abstract": "Privacy restrictions hinder the sharing of real-world Water Distribution\nNetwork (WDN) models, limiting the application of emerging data-driven machine\nlearning, which typically requires extensive observations. To address this\nchallenge, we propose the dataset DiTEC-WDN that comprises 36,000 unique\nscenarios simulated over either short-term (24 hours) or long-term (1 year)\nperiods. We constructed this dataset using an automated pipeline that optimizes\ncrucial parameters (e.g., pressure, flow rate, and demand patterns),\nfacilitates large-scale simulations, and records discrete, synthetic but\nhydraulically realistic states under standard conditions via rule validation\nand post-hoc analysis. With a total of 228 million generated graph-based\nstates, DiTEC-WDN can support a variety of machine-learning tasks, including\ngraph-level, node-level, and link-level regression, as well as time-series\nforecasting. This contribution, released under a public license, encourages\nopen scientific research in the critical water sector, eliminates the risk of\nexposing sensitive data, and fulfills the need for a large-scale water\ndistribution network benchmark for study comparisons and scenario analysis.", "published": "2025-03-21 14:14:03", "link": "http://arxiv.org/abs/2503.17167v2", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "MedAgent-Pro: Towards Multi-modal Evidence-based Medical Diagnosis via Reasoning Agentic Workflow", "abstract": "Developing reliable AI systems to assist human clinicians in multi-modal\nmedical diagnosis has long been a key objective for researchers. Recently,\nMulti-modal Large Language Models (MLLMs) have gained significant attention and\nachieved success across various domains. With strong reasoning capabilities and\nthe ability to perform diverse tasks based on user instructions, they hold\ngreat potential for enhancing medical diagnosis. However, directly applying\nMLLMs to the medical domain still presents challenges. They lack detailed\nperception of visual inputs, limiting their ability to perform quantitative\nimage analysis, which is crucial for medical diagnostics. Additionally, MLLMs\noften exhibit hallucinations and inconsistencies in reasoning, whereas clinical\ndiagnoses must adhere strictly to established criteria. To address these\nchallenges, we propose MedAgent-Pro, an evidence-based reasoning agentic system\ndesigned to achieve reliable, explainable, and precise medical diagnoses. This\nis accomplished through a hierarchical workflow: at the task level,\nknowledge-based reasoning generate reliable diagnostic plans for specific\ndiseases following retrieved clinical criteria. While at the case level,\nmultiple tool agents process multi-modal inputs, analyze different indicators\naccording to the plan, and provide a final diagnosis based on both quantitative\nand qualitative evidence. Comprehensive experiments on both 2D and 3D medical\ndiagnosis tasks demonstrate the superiority and effectiveness of MedAgent-Pro,\nwhile case studies further highlight its reliability and interpretability. The\ncode is available at https://github.com/jinlab-imvr/MedAgent-Pro.", "published": "2025-03-21 14:04:18", "link": "http://arxiv.org/abs/2503.18968v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Temporal-Guided Spiking Neural Networks for Event-Based Human Action Recognition", "abstract": "This paper explores the promising interplay between spiking neural networks\n(SNNs) and event-based cameras for privacy-preserving human action recognition\n(HAR). The unique feature of event cameras in capturing only the outlines of\nmotion, combined with SNNs' proficiency in processing spatiotemporal data\nthrough spikes, establishes a highly synergistic compatibility for event-based\nHAR. Previous studies, however, have been limited by SNNs' ability to process\nlong-term temporal information, essential for precise HAR. In this paper, we\nintroduce two novel frameworks to address this: temporal segment-based SNN\n(\\textit{TS-SNN}) and 3D convolutional SNN (\\textit{3D-SNN}). The\n\\textit{TS-SNN} extracts long-term temporal information by dividing actions\ninto shorter segments, while the \\textit{3D-SNN} replaces 2D spatial elements\nwith 3D components to facilitate the transmission of temporal information. To\npromote further research in event-based HAR, we create a dataset,\n\\textit{FallingDetection-CeleX}, collected using the high-resolution CeleX-V\nevent camera $(1280 \\times 800)$, comprising 7 distinct actions. Extensive\nexperimental results show that our proposed frameworks surpass state-of-the-art\nSNN methods on our newly collected dataset and three other neuromorphic\ndatasets, showcasing their effectiveness in handling long-range temporal\ninformation for event-based HAR.", "published": "2025-03-21 13:31:16", "link": "http://arxiv.org/abs/2503.17132v2", "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.NE"], "primary_category": "cs.CV"}
{"title": "LaMOuR: Leveraging Language Models for Out-of-Distribution Recovery in Reinforcement Learning", "abstract": "Deep Reinforcement Learning (DRL) has demonstrated strong performance in\nrobotic control but remains susceptible to out-of-distribution (OOD) states,\noften resulting in unreliable actions and task failure. While previous methods\nhave focused on minimizing or preventing OOD occurrences, they largely neglect\nrecovery once an agent encounters such states. Although the latest research has\nattempted to address this by guiding agents back to in-distribution states,\ntheir reliance on uncertainty estimation hinders scalability in complex\nenvironments. To overcome this limitation, we introduce Language Models for\nOut-of-Distribution Recovery (LaMOuR), which enables recovery learning without\nrelying on uncertainty estimation. LaMOuR generates dense reward codes that\nguide the agent back to a state where it can successfully perform its original\ntask, leveraging the capabilities of LVLMs in image description, logical\nreasoning, and code generation. Experimental results show that LaMOuR\nsubstantially enhances recovery efficiency across diverse locomotion tasks and\neven generalizes effectively to complex environments, including humanoid\nlocomotion and mobile manipulation, where existing methods struggle. The code\nand supplementary materials are available at https://lamour-rl.github.io/.", "published": "2025-03-21 13:20:39", "link": "http://arxiv.org/abs/2503.17125v5", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "The CASTLE 2024 Dataset: Advancing the Art of Multimodal Understanding", "abstract": "Egocentric video has seen increased interest in recent years, as it is used\nin a range of areas. However, most existing datasets are limited to a single\nperspective. In this paper, we present the CASTLE 2024 dataset, a multimodal\ncollection containing ego- and exo-centric (i.e., first- and third-person\nperspective) video and audio from 15 time-aligned sources, as well as other\nsensor streams and auxiliary data. The dataset was recorded by volunteer\nparticipants over four days in a fixed location and includes the point of view\nof 10 participants, with an additional 5 fixed cameras providing an exocentric\nperspective. The entire dataset contains over 600 hours of UHD video recorded\nat 50 frames per second. In contrast to other datasets, CASTLE 2024 does not\ncontain any partial censoring, such as blurred faces or distorted audio. The\ndataset is available via https://castle-dataset.github.io/.", "published": "2025-03-21 13:01:07", "link": "http://arxiv.org/abs/2503.17116v1", "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.IR"], "primary_category": "cs.MM"}
{"title": "FFaceNeRF: Few-shot Face Editing in Neural Radiance Fields", "abstract": "Recent 3D face editing methods using masks have produced high-quality edited\nimages by leveraging Neural Radiance Fields (NeRF). Despite their impressive\nperformance, existing methods often provide limited user control due to the use\nof pre-trained segmentation masks. To utilize masks with a desired layout, an\nextensive training dataset is required, which is challenging to gather. We\npresent FFaceNeRF, a NeRF-based face editing technique that can overcome the\nchallenge of limited user control due to the use of fixed mask layouts. Our\nmethod employs a geometry adapter with feature injection, allowing for\neffective manipulation of geometry attributes. Additionally, we adopt latent\nmixing for tri-plane augmentation, which enables training with a few samples.\nThis facilitates rapid model adaptation to desired mask layouts, crucial for\napplications in fields like personalized medical imaging or creative face\nediting. Our comparative evaluations demonstrate that FFaceNeRF surpasses\nexisting mask based face editing methods in terms of flexibility, control, and\ngenerated image quality, paving the way for future advancements in customized\nand high-fidelity 3D face editing. The code is available on the\n{\\href{https://kwanyun.github.io/FFaceNeRF_page/}{project-page}}.", "published": "2025-03-21 12:24:58", "link": "http://arxiv.org/abs/2503.17095v1", "categories": ["cs.GR", "cs.AI", "cs.CV", "68T45, 68U05", "I.3.3; I.3.8"], "primary_category": "cs.GR"}
{"title": "Does a Rising Tide Lift All Boats? Bias Mitigation for AI-based CMR Segmentation", "abstract": "Artificial intelligence (AI) is increasingly being used for medical imaging\ntasks. However, there can be biases in the resulting models, particularly when\nthey were trained using imbalanced training datasets. One such example has been\nthe strong race bias effect in cardiac magnetic resonance (CMR) image\nsegmentation models. Although this phenomenon has been reported in a number of\npublications, little is known about the effectiveness of bias mitigation\nalgorithms in this domain. We aim to investigate the impact of common bias\nmitigation methods to address bias between Black and White subjects in AI-based\nCMR segmentation models. Specifically, we use oversampling, importance\nreweighing and Group DRO as well as combinations of these techniques to\nmitigate the race bias. Furthermore, motivated by recent findings on the root\ncauses of AI-based CMR segmentation bias, we evaluate the same methods using\nmodels trained and evaluated on cropped CMR images. We find that bias can be\nmitigated using oversampling, significantly improving performance for the\nunderrepresented Black subjects whilst not significantly reducing the majority\nWhite subjects' performance. Group DRO also improves performance for Black\nsubjects but not significantly, while reweighing decreases performance for\nBlack subjects. Using a combination of oversampling and Group DRO also improves\nperformance for Black subjects but not significantly. Using cropped images\nincreases performance for both races and reduces the bias, whilst adding\noversampling as a bias mitigation technique with cropped images reduces the\nbias further.", "published": "2025-03-21 12:17:43", "link": "http://arxiv.org/abs/2503.17089v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "Deterministic AI Agent Personality Expression through Standard Psychological Diagnostics", "abstract": "Artificial intelligence (AI) systems powered by large language models have\nbecome increasingly prevalent in modern society, enabling a wide range of\napplications through natural language interaction. As AI agents proliferate in\nour daily lives, their generic and uniform expressiveness presents a\nsignificant limitation to their appeal and adoption. Personality expression\nrepresents a key prerequisite for creating more human-like and distinctive AI\nsystems. We show that AI models can express deterministic and consistent\npersonalities when instructed using established psychological frameworks, with\nvarying degrees of accuracy depending on model capabilities. We find that more\nadvanced models like GPT-4o and o1 demonstrate the highest accuracy in\nexpressing specified personalities across both Big Five and Myers-Briggs\nassessments, and further analysis suggests that personality expression emerges\nfrom a combination of intelligence and reasoning capabilities. Our results\nreveal that personality expression operates through holistic reasoning rather\nthan question-by-question optimization, with response-scale metrics showing\nhigher variance than test-scale metrics. Furthermore, we find that model\nfine-tuning affects communication style independently of personality expression\naccuracy. These findings establish a foundation for creating AI agents with\ndiverse and consistent personalities, which could significantly enhance\nhuman-AI interaction across applications from education to healthcare, while\nadditionally enabling a broader range of more unique AI agents. The ability to\nquantitatively assess and implement personality expression in AI systems opens\nnew avenues for research into more relatable, trustworthy, and ethically\ndesigned AI.", "published": "2025-03-21 12:12:05", "link": "http://arxiv.org/abs/2503.17085v1", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "cs.LG"}
{"title": "A Thorough Assessment of the Non-IID Data Impact in Federated Learning", "abstract": "Federated learning (FL) allows collaborative machine learning (ML) model\ntraining among decentralized clients' information, ensuring data privacy. The\ndecentralized nature of FL deals with non-independent and identically\ndistributed (non-IID) data. This open problem has notable consequences, such as\ndecreased model performance and more significant convergence times. Despite its\nimportance, experimental studies systematically addressing all types of data\nheterogeneity (a.k.a. non-IIDness) remain scarce. We aim to fill this gap by\nassessing and quantifying the non-IID effect through a thorough empirical\nanalysis. We use the Hellinger Distance (HD) to measure differences in\ndistribution among clients. Our study benchmarks four state-of-the-art\nstrategies for handling non-IID data, including label, feature, quantity, and\nspatiotemporal skewness, under realistic and controlled conditions. This is the\nfirst comprehensive analysis of the spatiotemporal skew effect in FL. Our\nfindings highlight the significant impact of label and spatiotemporal skew\nnon-IID types on FL model performance, with notable performance drops occurring\nat specific HD thresholds. Additionally, the FL performance is heavily affected\nmainly when the non-IIDness is extreme. Thus, we provide recommendations for FL\nresearch to tackle data heterogeneity effectively. Our work represents the most\nextensive examination of non-IIDness in FL, offering a robust foundation for\nfuture research.", "published": "2025-03-21 11:53:36", "link": "http://arxiv.org/abs/2503.17070v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "PVChat: Personalized Video Chat with One-Shot Learning", "abstract": "Video large language models (ViLLMs) excel in general video understanding,\ne.g., recognizing activities like talking and eating, but struggle with\nidentity-aware comprehension, such as \"Wilson is receiving chemotherapy\" or\n\"Tom is discussing with Sarah\", limiting their applicability in smart\nhealthcare and smart home environments. To address this limitation, we propose\na one-shot learning framework PVChat, the first personalized ViLLM that enables\nsubject-aware question answering (QA) from a single video for each subject. Our\napproach optimizes a Mixture-of-Heads (MoH) enhanced ViLLM on a synthetically\naugmented video-QA dataset, leveraging a progressive image-to-video learning\nstrategy. Specifically, we introduce an automated augmentation pipeline that\nsynthesizes identity-preserving positive samples and retrieves hard negatives\nfrom existing video corpora, generating a diverse training dataset with four QA\ntypes: existence, appearance, action, and location inquiries. To enhance\nsubject-specific learning, we propose a ReLU Routing MoH attention mechanism,\nalongside two novel objectives: (1) Smooth Proximity Regularization for\nprogressive learning through exponential distance scaling and (2) Head\nActivation Enhancement for balanced attention routing. Finally, we adopt a\ntwo-stage training strategy, transitioning from image pre-training to video\nfine-tuning, enabling a gradual learning process from static attributes to\ndynamic representations. We evaluate PVChat on diverse datasets covering\nmedical scenarios, TV series, anime, and real-world footage, demonstrating its\nsuperiority in personalized feature understanding after learning from a single\nvideo, compared to state-of-the-art ViLLMs.", "published": "2025-03-21 11:50:06", "link": "http://arxiv.org/abs/2503.17069v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Replay4NCL: An Efficient Memory Replay-based Methodology for Neuromorphic Continual Learning in Embedded AI Systems", "abstract": "Neuromorphic Continual Learning (NCL) paradigm leverages Spiking Neural\nNetworks (SNNs) to enable continual learning (CL) capabilities for AI systems\nto adapt to dynamically changing environments. Currently, the state-of-the-art\nemploy a memory replay-based method to maintain the old knowledge. However,\nthis technique relies on long timesteps and compression-decompression steps,\nthereby incurring significant latency and energy overheads, which are not\nsuitable for tightly-constrained embedded AI systems (e.g., mobile\nagents/robotics). To address this, we propose Replay4NCL, a novel efficient\nmemory replay-based methodology for enabling NCL in embedded AI systems.\nSpecifically, Replay4NCL compresses the latent data (old knowledge), then\nreplays them during the NCL training phase with small timesteps, to minimize\nthe processing latency and energy consumption. To compensate the information\nloss from reduced spikes, we adjust the neuron threshold potential and learning\nrate settings. Experimental results on the class-incremental scenario with the\nSpiking Heidelberg Digits (SHD) dataset show that Replay4NCL can preserve old\nknowledge with Top-1 accuracy of 90.43% compared to 86.22% from the\nstate-of-the-art, while effectively learning new tasks, achieving 4.88x latency\nspeed-up, 20% latent memory saving, and 36.43% energy saving. These results\nhighlight the potential of our Replay4NCL methodology to further advances NCL\ncapabilities for embedded AI systems.", "published": "2025-03-21 11:33:22", "link": "http://arxiv.org/abs/2503.17061v1", "categories": ["cs.NE", "cs.AI", "cs.LG"], "primary_category": "cs.NE"}
{"title": "Data-Driven Optimization of EV Charging Station Placement Using Causal Discovery", "abstract": "This paper addresses the critical challenge of optimizing electric vehicle\ncharging station placement through a novel data-driven methodology employing\ncausal discovery techniques. While traditional approaches prioritize economic\nfactors or power grid constraints, they often neglect empirical charging\npatterns that ultimately determine station utilization. We analyze extensive\ncharging data from Palo Alto and Boulder (337,344 events across 100 stations)\nto uncover latent relationships between station characteristics and\nutilization. Applying structural learning algorithms (NOTEARS and DAGMA) to\nthis data reveals that charging demand is primarily determined by three\nfactors: proximity to amenities, EV registration density, and adjacency to\nhigh-traffic routes. These findings, consistent across multiple algorithms and\nurban contexts, challenge conventional infrastructure distribution strategies.\nWe develop an optimization framework that translates these insights into\nactionable placement recommendations, identifying locations likely to\nexperience high utilization based on the discovered dependency structures. The\nresulting site selection model prioritizes strategic clustering in high-amenity\nareas with substantial EV populations rather than uniform spatial distribution.\nOur approach contributes a framework that integrates empirical charging\nbehavior into infrastructure planning, potentially enhancing both station\nutilization and user convenience. By focusing on data-driven insights instead\nof theoretical distribution models, we provide a more effective strategy for\nexpanding charging networks that can adjust to various stages of EV market\ndevelopment.", "published": "2025-03-21 11:15:02", "link": "http://arxiv.org/abs/2503.17055v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "HAPI: A Model for Learning Robot Facial Expressions from Human Preferences", "abstract": "Automatic robotic facial expression generation is crucial for human-robot\ninteraction, as handcrafted methods based on fixed joint configurations often\nyield rigid and unnatural behaviors. Although recent automated techniques\nreduce the need for manual tuning, they tend to fall short by not adequately\nbridging the gap between human preferences and model predictions-resulting in a\ndeficiency of nuanced and realistic expressions due to limited degrees of\nfreedom and insufficient perceptual integration. In this work, we propose a\nnovel learning-to-rank framework that leverages human feedback to address this\ndiscrepancy and enhanced the expressiveness of robotic faces. Specifically, we\nconduct pairwise comparison annotations to collect human preference data and\ndevelop the Human Affective Pairwise Impressions (HAPI) model, a Siamese\nRankNet-based approach that refines expression evaluation. Results obtained via\nBayesian Optimization and online expression survey on a 35-DOF android platform\ndemonstrate that our approach produces significantly more realistic and\nsocially resonant expressions of Anger, Happiness, and Surprise than those\ngenerated by baseline and expert-designed methods. This confirms that our\nframework effectively bridges the gap between human preferences and model\npredictions while robustly aligning robotic expression generation with human\naffective responses.", "published": "2025-03-21 11:04:01", "link": "http://arxiv.org/abs/2503.17046v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.HC", "cs.LG"], "primary_category": "cs.RO"}
{"title": "Enhanced Smart Contract Reputability Analysis using Multimodal Data Fusion on Ethereum", "abstract": "The evaluation of smart contract reputability is essential to foster trust in\ndecentralized ecosystems. However, existing methods that rely solely on code\nanalysis or transactional data, offer limited insight into evolving\ntrustworthiness. We propose a multimodal data fusion framework that integrates\ncode features with transactional data to enhance reputability prediction. Our\nframework initially focuses on AI-based code analysis, utilizing GAN-augmented\nopcode embeddings to address class imbalance, achieving 97.67% accuracy and a\nrecall of 0.942 in detecting illicit contracts, surpassing traditional\noversampling methods. This forms the crux of a reputability-centric fusion\nstrategy, where combining code and transactional data improves recall by 7.25%\nover single-source models, demonstrating robust performance across validation\nsets. By providing a holistic view of smart contract behaviour, our approach\nenhances the model's ability to assess reputability, identify fraudulent\nactivities, and predict anomalous patterns. These capabilities contribute to\nmore accurate reputability assessments, proactive risk mitigation, and enhanced\nblockchain security.", "published": "2025-03-21 10:45:17", "link": "http://arxiv.org/abs/2503.17426v2", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.ET"], "primary_category": "cs.LG"}
{"title": "An Attentive Representative Sample Selection Strategy Combined with Balanced Batch Training for Skin Lesion Segmentation", "abstract": "An often overlooked problem in medical image segmentation research is the\neffective selection of training subsets to annotate from a complete set of\nunlabelled data. Many studies select their training sets at random, which may\nlead to suboptimal model performance, especially in the minimal supervision\nsetting where each training image has a profound effect on performance\noutcomes. This work aims to address this issue. We use prototypical contrasting\nlearning and clustering to extract representative and diverse samples for\nannotation. We improve upon prior works with a bespoke cluster-based image\nselection process. Additionally, we introduce the concept of unsupervised\nbalanced batch dataloading to medical image segmentation, which aims to improve\nmodel learning with minimally annotated data. We evaluated our method on a\npublic skin lesion dataset (ISIC 2018) and compared it to another\nstate-of-the-art data sampling method. Our method achieved superior performance\nin a low annotation budget scenario.", "published": "2025-03-21 10:42:22", "link": "http://arxiv.org/abs/2503.17034v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Exploring the Efficacy of Partial Denoising Using Bit Plane Slicing for Enhanced Fracture Identification: A Comparative Study of Deep Learning-Based Approaches and Handcrafted Feature Extraction Techniques", "abstract": "Computer vision has transformed medical diagnosis, treatment, and research\nthrough advanced image processing and machine learning techniques. Fracture\nclassification, a critical area in healthcare, has greatly benefited from these\nadvancements, yet accurate detection is challenged by complex patterns and\nimage noise. Bit plane slicing enhances medical images by reducing noise\ninterference and extracting informative features. This research explores\npartial denoising techniques to provide practical solutions for improved\nfracture analysis, ultimately enhancing patient care. The study explores deep\nlearning model DenseNet and handcrafted feature extraction. Decision Tree and\nRandom Forest, were employed to train and evaluate distinct image\nrepresentations. These include the original image, the concatenation of the\nfour bit planes from the LSB as well as MSB, the fully denoised image, and an\nimage consisting of 6 bit planes from MSB and 2 denoised bit planes from LSB.\nThe purpose of forming these diverse image representations is to analyze SNR as\nwell as classification accuracy and identify the bit planes that contain the\nmost informative features. Moreover, the study delves into the significance of\npartial denoising techniques in preserving crucial features, leading to\nimprovements in classification results. Notably, this study shows that\nemploying the Random Forest classifier, the partially denoised image\nrepresentation exhibited a testing accuracy of 95.61% surpassing the\nperformance of other image representations. The outcomes of this research\nprovide valuable insights into the development of efficient preprocessing,\nfeature extraction and classification approaches for fracture identification.\nBy enhancing diagnostic accuracy, these advancements hold the potential to\npositively impact patient care and overall medical outcomes.", "published": "2025-03-21 10:39:21", "link": "http://arxiv.org/abs/2503.17030v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "eess.IV"}
{"title": "A Guide to Bayesian Networks Software Packages for Structure and Parameter Learning -- 2025 Edition", "abstract": "A representation of the cause-effect mechanism is needed to enable artificial\nintelligence to represent how the world works. Bayesian Networks (BNs) have\nproven to be an effective and versatile tool for this task. BNs require\nconstructing a structure of dependencies among variables and learning the\nparameters that govern these relationships. These tasks, referred to as\nstructural learning and parameter learning, are actively investigated by the\nresearch community, with several algorithms proposed and no single method\nhaving established itself as standard. A wide range of software, tools, and\npackages have been developed for BNs analysis and made available to academic\nresearchers and industry practitioners. As a consequence of having no\none-size-fits-all solution, moving the first practical steps and getting\noriented into this field is proving to be challenging to outsiders and\nbeginners. In this paper, we review the most relevant tools and software for\nBNs structural and parameter learning to date, providing our subjective\nrecommendations directed to an audience of beginners. In addition, we provide\nan extensive easy-to-consult overview table summarizing all software packages\nand their main features. By improving the reader understanding of which\navailable software might best suit their needs, we improve accessibility to the\nfield and make it easier for beginners to take their first step into it.", "published": "2025-03-21 10:36:11", "link": "http://arxiv.org/abs/2503.17025v1", "categories": ["cs.AI", "I.2"], "primary_category": "cs.AI"}
{"title": "Symbolic Audio Classification via Modal Decision Tree Learning", "abstract": "The range of potential applications of acoustic analysis is wide.\nClassification of sounds, in particular, is a typical machine learning task\nthat received a lot of attention in recent years. The most common approaches to\nsound classification are sub-symbolic, typically based on neural networks, and\nresult in black-box models with high performances but very low transparency. In\nthis work, we consider several audio tasks, namely, age and gender recognition,\nemotion classification, and respiratory disease diagnosis, and we approach them\nwith a symbolic technique, that is, (modal) decision tree learning. We prove\nthat such tasks can be solved using the same symbolic pipeline, that allows to\nextract simple rules with very high accuracy and low complexity. In principle,\nall such tasks could be associated to an autonomous conversation system, which\ncould be useful in different contexts, such as an automatic reservation agent\nfor an hospital or a clinic.", "published": "2025-03-21 10:27:16", "link": "http://arxiv.org/abs/2503.17018v1", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "68T05", "I.2.6"], "primary_category": "cs.SD"}
{"title": "Developing Critical Thinking in Second Language Learners: Exploring Generative AI like ChatGPT as a Tool for Argumentative Essay Writing", "abstract": "This study employs the Paul-Elder Critical Thinking Model and Tan's\nargumentative writing framework to create a structured methodology. This\nmethodology, ChatGPT Guideline for Critical Argumentative Writing (CGCAW)\nframework, integrates the models with ChatGPT's capabilities to guide L2\nlearners in utilizing ChatGPT to enhance their critical thinking skills. A\nquantitative experiment was conducted with 10 participants from a state\nuniversity, divided into experimental and control groups. The experimental\ngroup utilized the CGCAW framework, while the control group used ChatGPT\nwithout specific guidelines. Participants wrote an argumentative essay within a\n40-minute timeframe, and essays were evaluated by three assessors: ChatGPT,\nGrammarly, and a course instructor. Results indicated that the experimental\ngroup showed improvements in clarity, logical coherence, and use of evidence,\ndemonstrating ChatGPT's potential to enhance specific aspects of argumentative\nwriting. However, the control group performed better in overall language\nmechanics and articulation of main arguments, indicating areas where the CGCAW\nframework could be further refined. This study highlights the need for further\nresearch to optimize the use of AI tools like ChatGPT in L2 learning\nenvironments to enhance critical thinking and writing skills.", "published": "2025-03-21 10:22:58", "link": "http://arxiv.org/abs/2503.17013v1", "categories": ["cs.HC", "cs.AI", "I.2.7; K.3.1"], "primary_category": "cs.HC"}
{"title": "Targetless 6DoF Calibration of LiDAR and 2D Scanning Radar Based on Cylindrical Occupancy", "abstract": "Owing to the capability for reliable and all-weather long-range sensing, the\nfusion of LiDAR and Radar has been widely applied to autonomous vehicles for\nrobust perception. In practical operation, well manually calibrated extrinsic\nparameters, which are crucial for the fusion of multi-modal sensors, may drift\ndue to the vibration. To address this issue, we present a novel targetless\ncalibration approach, termed LiRaCo, for the extrinsic 6DoF calibration of\nLiDAR and Radar sensors. Although both types of sensors can obtain geometric\ninformation, bridging the geometric correspondences between multi-modal data\nwithout any clues of explicit artificial markers is nontrivial, mainly due to\nthe low vertical resolution of scanning Radar. To achieve the targetless\ncalibration, LiRaCo leverages a spatial occupancy consistency between LiDAR\npoint clouds and Radar scans in a common cylindrical representation,\nconsidering the increasing data sparsity with distance for both sensors.\nSpecifically, LiRaCo expands the valid Radar scanned pixels into 3D occupancy\ngrids to constrain LiDAR point clouds based on spatial consistency.\nConsequently, a cost function involving extrinsic calibration parameters is\nformulated based on the spatial overlap of 3D grids and LiDAR points. Extrinsic\nparameters are finally estimated by optimizing the cost function. Comprehensive\nquantitative and qualitative experiments on two real outdoor datasets with\ndifferent LiDAR sensors demonstrate the feasibility and accuracy of the\nproposed method. The source code will be publicly available.", "published": "2025-03-21 10:09:04", "link": "http://arxiv.org/abs/2503.17002v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Data to Decisions: A Computational Framework to Identify skill requirements from Advertorial Data", "abstract": "Among the factors of production, human capital or skilled manpower is the one\nthat keeps evolving and adapts to changing conditions and resources. This\nadaptability makes human capital the most crucial factor in ensuring a\nsustainable growth of industry/sector. As new technologies are developed and\nadopted, the new generations are required to acquire skills in newer\ntechnologies in order to be employable. At the same time professionals are\nrequired to upskill and reskill themselves to remain relevant in the industry.\nThere is however no straightforward method to identify the skill needs of the\nindustry at a given point of time. Therefore, this paper proposes a data to\ndecision framework that can successfully identify the desired skill set in a\ngiven area by analysing the advertorial data collected from popular online job\nportals and supplied as input to the framework. The proposed framework uses\ntechniques of statistical analysis, data mining and natural language processing\nfor the purpose. The applicability of the framework is demonstrated on CS&IT\njob advertisement data from India. The analytical results not only provide\nuseful insights about current state of skill needs in CS&IT industry but also\nprovide practical implications to prospective job applicants, training\nagencies, and institutions of higher education & professional training.", "published": "2025-03-21 09:49:31", "link": "http://arxiv.org/abs/2503.17424v1", "categories": ["cs.CY", "cs.AI"], "primary_category": "cs.CY"}
{"title": "Enabling Versatile Controls for Video Diffusion Models", "abstract": "Despite substantial progress in text-to-video generation, achieving precise\nand flexible control over fine-grained spatiotemporal attributes remains a\nsignificant unresolved challenge in video generation research. To address these\nlimitations, we introduce VCtrl (also termed PP-VCtrl), a novel framework\ndesigned to enable fine-grained control over pre-trained video diffusion models\nin a unified manner. VCtrl integrates diverse user-specified control\nsignals-such as Canny edges, segmentation masks, and human keypoints-into\npretrained video diffusion models via a generalizable conditional module\ncapable of uniformly encoding multiple types of auxiliary signals without\nmodifying the underlying generator. Additionally, we design a unified control\nsignal encoding pipeline and a sparse residual connection mechanism to\nefficiently incorporate control representations. Comprehensive experiments and\nhuman evaluations demonstrate that VCtrl effectively enhances controllability\nand generation quality. The source code and pre-trained models are publicly\navailable and implemented using the PaddlePaddle framework at\nhttp://github.com/PaddlePaddle/PaddleMIX/tree/develop/ppdiffusers/examples/ppvctrl.", "published": "2025-03-21 09:48:00", "link": "http://arxiv.org/abs/2503.16983v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Real-Time Diffusion Policies for Games: Enhancing Consistency Policies with Q-Ensembles", "abstract": "Diffusion models have shown impressive performance in capturing complex and\nmulti-modal action distributions for game agents, but their slow inference\nspeed prevents practical deployment in real-time game environments. While\nconsistency models offer a promising approach for one-step generation, they\noften suffer from training instability and performance degradation when applied\nto policy learning. In this paper, we present CPQE (Consistency Policy with\nQ-Ensembles), which combines consistency models with Q-ensembles to address\nthese challenges.CPQE leverages uncertainty estimation through Q-ensembles to\nprovide more reliable value function approximations, resulting in better\ntraining stability and improved performance compared to classic double\nQ-network methods. Our extensive experiments across multiple game scenarios\ndemonstrate that CPQE achieves inference speeds of up to 60 Hz -- a significant\nimprovement over state-of-the-art diffusion policies that operate at only 20 Hz\n-- while maintaining comparable performance to multi-step diffusion approaches.\nCPQE consistently outperforms state-of-the-art consistency model approaches,\nshowing both higher rewards and enhanced training stability throughout the\nlearning process. These results indicate that CPQE offers a practical solution\nfor deploying diffusion-based policies in games and other real-time\napplications where both multi-modal behavior modeling and rapid inference are\ncritical requirements.", "published": "2025-03-21 09:45:59", "link": "http://arxiv.org/abs/2503.16978v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "GeoT: Geometry-guided Instance-dependent Transition Matrix for Semi-supervised Tooth Point Cloud Segmentation", "abstract": "Achieving meticulous segmentation of tooth point clouds from intra-oral scans\nstands as an indispensable prerequisite for various orthodontic applications.\nGiven the labor-intensive nature of dental annotation, a significant amount of\ndata remains unlabeled, driving increasing interest in semi-supervised\napproaches. One primary challenge of existing semi-supervised medical\nsegmentation methods lies in noisy pseudo labels generated for unlabeled data.\nTo address this challenge, we propose GeoT, the first framework that employs\ninstance-dependent transition matrix (IDTM) to explicitly model noise in pseudo\nlabels for semi-supervised dental segmentation. Specifically, to handle the\nextensive solution space of IDTM arising from tens of thousands of dental\npoints, we introduce tooth geometric priors through two key components:\npoint-level geometric regularization (PLGR) to enhance consistency between\npoint adjacency relationships in 3D and IDTM spaces, and class-level geometric\nsmoothing (CLGS) to leverage the fixed spatial distribution of tooth categories\nfor optimal IDTM estimation. Extensive experiments performed on the public\nTeeth3DS dataset and private dataset demonstrate that our method can make full\nutilization of unlabeled data to facilitate segmentation, achieving performance\ncomparable to fully supervised methods with only $20\\%$ of the labeled data.", "published": "2025-03-21 09:43:57", "link": "http://arxiv.org/abs/2503.16976v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "ARFlow: Human Action-Reaction Flow Matching with Physical Guidance", "abstract": "Human action-reaction synthesis, a fundamental challenge in modeling causal\nhuman interactions, plays a critical role in applications ranging from virtual\nreality to social robotics. While diffusion-based models have demonstrated\npromising performance, they exhibit two key limitations for interaction\nsynthesis: reliance on complex noise-to-reaction generators with intricate\nconditional mechanisms, and frequent physical violations in generated motions.\nTo address these issues, we propose Action-Reaction Flow Matching (ARFlow), a\nnovel framework that establishes direct action-to-reaction mappings,\neliminating the need for complex conditional mechanisms. Our approach\nintroduces two key innovations: an x1-prediction method that directly outputs\nhuman motions instead of velocity fields, enabling explicit constraint\nenforcement; and a training-free, gradient-based physical guidance mechanism\nthat effectively prevents body penetration artifacts during sampling. Extensive\nexperiments on NTU120 and Chi3D datasets demonstrate that ARFlow not only\noutperforms existing methods in terms of Fr\\'echet Inception Distance and\nmotion diversity but also significantly reduces body collisions, as measured by\nour new Intersection Volume and Intersection Frequency metrics.", "published": "2025-03-21 09:41:24", "link": "http://arxiv.org/abs/2503.16973v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "From Faces to Voices: Learning Hierarchical Representations for High-quality Video-to-Speech", "abstract": "The objective of this study is to generate high-quality speech from silent\ntalking face videos, a task also known as video-to-speech synthesis. A\nsignificant challenge in video-to-speech synthesis lies in the substantial\nmodality gap between silent video and multi-faceted speech. In this paper, we\npropose a novel video-to-speech system that effectively bridges this modality\ngap, significantly enhancing the quality of synthesized speech. This is\nachieved by learning of hierarchical representations from video to speech.\nSpecifically, we gradually transform silent video into acoustic feature spaces\nthrough three sequential stages -- content, timbre, and prosody modeling. In\neach stage, we align visual factors -- lip movements, face identity, and facial\nexpressions -- with corresponding acoustic counterparts to ensure the seamless\ntransformation. Additionally, to generate realistic and coherent speech from\nthe visual representations, we employ a flow matching model that estimates\ndirect trajectories from a simple prior distribution to the target speech\ndistribution. Extensive experiments demonstrate that our method achieves\nexceptional generation quality comparable to real utterances, outperforming\nexisting methods by a significant margin.", "published": "2025-03-21 09:02:38", "link": "http://arxiv.org/abs/2503.16956v1", "categories": ["eess.AS", "cs.AI", "cs.CV", "cs.SD"], "primary_category": "eess.AS"}
{"title": "Neural-Guided Equation Discovery", "abstract": "Deep learning approaches are becoming increasingly attractive for equation\ndiscovery. We show the advantages and disadvantages of using neural-guided\nequation discovery by giving an overview of recent papers and the results of\nexperiments using our modular equation discovery system MGMT\n($\\textbf{M}$ulti-Task $\\textbf{G}$rammar-Guided $\\textbf{M}$onte-Carlo\n$\\textbf{T}$ree Search for Equation Discovery). The system uses neural-guided\nMonte-Carlo Tree Search (MCTS) and supports both supervised and reinforcement\nlearning, with a search space defined by a context-free grammar. We summarize\nseven desirable properties of equation discovery systems, emphasizing the\nimportance of embedding tabular data sets for such learning approaches. Using\nthe modular structure of MGMT, we compare seven architectures (among them,\nRNNs, CNNs, and Transformers) for embedding tabular datasets on the auxiliary\ntask of contrastive learning for tabular data sets on an equation discovery\ntask. For almost all combinations of modules, supervised learning outperforms\nreinforcement learning. Moreover, our experiments indicate an advantage of\nusing grammar rules as action space instead of tokens. Two adaptations of MCTS\n-- risk-seeking MCTS and AmEx-MCTS -- can improve equation discovery with that\nkind of search.", "published": "2025-03-21 08:55:51", "link": "http://arxiv.org/abs/2503.16953v1", "categories": ["cs.AI", "I.2.6; I.1.1; G.3"], "primary_category": "cs.AI"}
{"title": "On-Sensor Convolutional Neural Networks with Early-Exits", "abstract": "Tiny Machine Learning (TinyML) is a novel research field aiming at\nintegrating Machine Learning (ML) within embedded devices with limited memory,\ncomputation, and energy. Recently, a new branch of TinyML has emerged, focusing\non integrating ML directly into the sensors to further reduce the power\nconsumption of embedded devices. Interestingly, despite their state-of-the-art\nperformance in many tasks, none of the current solutions in the literature aims\nto optimize the implementation of Convolutional Neural Networks (CNNs)\noperating directly into sensors. In this paper, we introduce for the first time\nin the literature the optimized design and implementation of Depth-First CNNs\noperating on the Intelligent Sensor Processing Unit (ISPU) within an Inertial\nMeasurement Unit (IMU) by STMicroelectronics. Our approach partitions the CNN\nbetween the ISPU and the microcontroller (MCU) and employs an Early-Exit\nmechanism to stop the computations on the IMU when enough confidence about the\nresults is achieved, hence significantly reducing power consumption. When using\na NUCLEO-F411RE board, this solution achieved an average current consumption of\n4.8 mA, marking an 11% reduction compared to the regular inference pipeline on\nthe MCU, while having equal accuracy.", "published": "2025-03-21 08:31:07", "link": "http://arxiv.org/abs/2503.16939v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Interpretable Machine Learning for Oral Lesion Diagnosis through Prototypical Instances Identification", "abstract": "Decision-making processes in healthcare can be highly complex and\nchallenging. Machine Learning tools offer significant potential to assist in\nthese processes. However, many current methodologies rely on complex models\nthat are not easily interpretable by experts. This underscores the need to\ndevelop interpretable models that can provide meaningful support in clinical\ndecision-making. When approaching such tasks, humans typically compare the\nsituation at hand to a few key examples and representative cases imprinted in\ntheir memory. Using an approach which selects such exemplary cases and grounds\nits predictions on them could contribute to obtaining high-performing\ninterpretable solutions to such problems. To this end, we evaluate PivotTree,\nan interpretable prototype selection model, on an oral lesion detection\nproblem, specifically trying to detect the presence of neoplastic, aphthous and\ntraumatic ulcerated lesions from oral cavity images. We demonstrate the\nefficacy of using such method in terms of performance and offer a qualitative\nand quantitative comparison between exemplary cases and ground-truth prototypes\nselected by experts.", "published": "2025-03-21 08:25:32", "link": "http://arxiv.org/abs/2503.16938v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Rude Humans and Vengeful Robots: Examining Human Perceptions of Robot Retaliatory Intentions in Professional Settings", "abstract": "Humans and robots are increasingly working in personal and professional\nsettings. In workplace settings, humans and robots may work together as\ncolleagues, potentially leading to social expectations, or violation thereof.\nExtant research has primarily sought to understand social interactions and\nexpectations in personal rather than professional settings, and none of these\nstudies have examined negative outcomes arising from violations of social\nexpectations. This paper reports the results of a 2x3 online experiment that\nused a unique first-person perspective video to immerse participants in a\ncollaborative workplace setting. The results are nuanced and reveal that while\nrobots are expected to act in accordance with social expectations despite human\nbehavior, there are benefits for robots perceived as being the bigger person in\nthe face of human rudeness. Theoretical and practical implications are provided\nwhich discuss the import of these findings for the design of social robots.", "published": "2025-03-21 08:12:40", "link": "http://arxiv.org/abs/2503.16932v1", "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "cs.RO"}
{"title": "TEMPLE:Temporal Preference Learning of Video LLMs via Difficulty Scheduling and Pre-SFT Alignment", "abstract": "Video Large Language Models (Video LLMs) have achieved significant success by\nleveraging a two-stage paradigm: pretraining on large-scale video-text data for\nvision-language alignment, followed by supervised fine-tuning (SFT) for\ntask-specific capabilities. However, existing approaches struggle with temporal\nreasoning due to weak temporal correspondence in the data and reliance on the\nnext-token prediction paradigm during training. To address these limitations,\nwe propose TEMPLE (TEMporal Preference Learning), a systematic framework that\nenhances Video LLMs' temporal reasoning capabilities through Direct Preference\nOptimization (DPO). To facilitate this, we introduce an automated preference\ndata generation pipeline that systematically constructs preference pairs by\nselecting videos that are rich in temporal information, designing\nvideo-specific perturbation strategies, and finally evaluating model responses\non clean and perturbed video inputs. Our temporal alignment features two key\ninnovations: curriculum learning which that progressively increases\nperturbation difficulty to improve model robustness and adaptability; and\n\"Pre-SFT Alignment'', applying preference optimization before instruction\ntuning to prioritize fine-grained temporal comprehension. Extensive experiments\ndemonstrate that our approach consistently improves Video LLM performance\nacross multiple benchmarks with a relatively small set of self-generated DPO\ndata. We further analyze the transferability of DPO data across architectures\nand the role of difficulty scheduling in optimization. Our findings highlight\nour TEMPLE as a scalable and efficient complement to SFT-based methods, paving\nthe way for developing reliable Video LLMs. Code is available at\nhttps://github.com/lscpku/TEMPLE.", "published": "2025-03-21 08:00:29", "link": "http://arxiv.org/abs/2503.16929v2", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "RustEvo^2: An Evolving Benchmark for API Evolution in LLM-based Rust Code Generation", "abstract": "Large Language Models (LLMs) have become pivotal tools for automating code\ngeneration in software development. However, these models face significant\nchallenges in producing version-aware code for rapidly evolving languages like\nRust, where frequent Application Programming Interfaces (API) changes across\nversions lead to compatibility issues and correctness errors. Existing\nbenchmarks lack systematic evaluation of how models navigate API transitions,\nrelying on labor-intensive manual curation and offering limited\nversion-specific insights. To address this gap, we present RustEvo, a novel\nframework for constructing dynamic benchmarks that evaluate the ability of LLMs\nto adapt to evolving Rust APIs. RustEvo automates dataset creation by\nsynthesizing 588 API changes (380 from Rust standard libraries, 208 from 15\nthird-party crates) into programming tasks mirroring real-world challenges.\nThese tasks cover four API evolution categories: Stabilizations, Signature\nChanges, Behavioral Changes, and Deprecations, reflecting their actual\ndistribution in the Rust ecosystem.\n  Experiments on state-of-the-art (SOTA) LLMs reveal significant performance\nvariations: models achieve a 65.8% average success rate on stabilized APIs but\nonly 38.0% on behavioral changes, highlighting difficulties in detecting\nsemantic shifts without signature alterations. Knowledge cutoff dates strongly\ninfluence performance, with models scoring 56.1% on before-cutoff APIs versus\n32.5% on after-cutoff tasks. Retrieval-Augmented Generation (RAG) mitigates\nthis gap, improving success rates by 13.5% on average for APIs released after\nmodel training. Our findings underscore the necessity of our evolution-aware\nbenchmarks to advance the adaptability of LLMs in fast-paced software\necosystems. The framework and the benchmarks are publicly released at\nhttps://github.com/SYSUSELab/RustEvo.", "published": "2025-03-21 07:33:59", "link": "http://arxiv.org/abs/2503.16922v1", "categories": ["cs.SE", "cs.AI"], "primary_category": "cs.SE"}
{"title": "When Preferences Diverge: Aligning Diffusion Models with Minority-Aware Adaptive DPO", "abstract": "In recent years, the field of image generation has witnessed significant\nadvancements, particularly in fine-tuning methods that align models with\nuniversal human preferences. This paper explores the critical role of\npreference data in the training process of diffusion models, particularly in\nthe context of Diffusion-DPO and its subsequent adaptations. We investigate the\ncomplexities surrounding universal human preferences in image generation,\nhighlighting the subjective nature of these preferences and the challenges\nposed by minority samples in preference datasets. Through pilot experiments, we\ndemonstrate the existence of minority samples and their detrimental effects on\nmodel performance. We propose Adaptive-DPO -- a novel approach that\nincorporates a minority-instance-aware metric into the DPO objective. This\nmetric, which includes intra-annotator confidence and inter-annotator\nstability, distinguishes between majority and minority samples. We introduce an\nAdaptive-DPO loss function which improves the DPO loss in two ways: enhancing\nthe model's learning of majority labels while mitigating the negative impact of\nminority samples. Our experiments demonstrate that this method effectively\nhandles both synthetic minority data and real-world preference data, paving the\nway for more effective training methodologies in image generation tasks.", "published": "2025-03-21 07:33:44", "link": "http://arxiv.org/abs/2503.16921v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "A New Segment Routing method with Swap Node Selection Strategy Based on Deep Reinforcement Learning for Software Defined Network", "abstract": "The existing segment routing (SR) methods need to determine the routing first\nand then use path segmentation approaches to select swap nodes to form a\nsegment routing path (SRP). They require re-segmentation of the path when the\nrouting changes. Furthermore, they do not consider the flow table issuance\ntime, which cannot maximize the speed of issuance flow table. To address these\nissues, this paper establishes an optimization model that can simultaneously\nform routing strategies and path segmentation strategies for selecting the\nappropriate swap nodes to reduce flow table issuance time. It also designs an\nintelligent segment routing algorithm based on deep reinforcement learning\n(DRL-SR) to solve the proposed model. First, a traffic matrix is designed as\nthe state space for the deep reinforcement learning agent; this matrix includes\nmultiple QoS performance indicators, flow table issuance time overhead and SR\nlabel stack depth. Second, the action selection strategy and corresponding\nreward function are designed, where the agent selects the next node considering\nthe routing; in addition, the action selection strategy whether the newly added\nnode is selected as the swap node and the corresponding reward function are\ndesigned considering the time cost factor for the controller to issue the flow\ntable to the swap node. Finally, a series of experiments and their results show\nthat, compared with the existing methods, the designed segmented route\noptimization model and the intelligent solution algorithm (DRL-SR) can reduce\nthe time overhead required to complete the segmented route establishment task\nwhile optimizing performance metrics such as throughput, delays and packet\nlosses.", "published": "2025-03-21 07:24:09", "link": "http://arxiv.org/abs/2503.16914v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "MAPS: A Multi-Agent Framework Based on Big Seven Personality and Socratic Guidance for Multimodal Scientific Problem Solving", "abstract": "Multimodal scientific problems (MSPs) involve complex issues that require the\nintegration of multiple modalities, such as text and diagrams, presenting a\nsignificant challenge in artificial intelligence. While progress has been made\nin addressing traditional scientific problems, MSPs still face two primary\nissues: the challenge of multi-modal comprehensive reasoning in scientific\nproblem-solving and the lack of reflective and rethinking capabilities. To\naddress these issues, we introduce a Multi-Agent framework based on the Big\nSeven Personality and Socratic guidance (MAPS). This framework employs seven\ndistinct agents that leverage feedback mechanisms and the Socratic method to\nguide the resolution of MSPs. To tackle the first issue, we propose a\nprogressive four-agent solving strategy, where each agent focuses on a specific\nstage of the problem-solving process. For the second issue, we introduce a\nCritic agent, inspired by Socratic questioning, which prompts critical thinking\nand stimulates autonomous learning. We conduct extensive experiments on the\nEMMA, Olympiad, and MathVista datasets, achieving promising results that\noutperform the current SOTA model by 15.84% across all tasks. Meanwhile, the\nadditional analytical experiments also verify the model's progress as well as\ngeneralization ability.", "published": "2025-03-21 07:13:45", "link": "http://arxiv.org/abs/2503.16905v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Deep Learning for Human Locomotion Analysis in Lower-Limb Exoskeletons: A Comparative Study", "abstract": "Wearable robotics for lower-limb assistance have become a pivotal area of\nresearch, aiming to enhance mobility for individuals with physical impairments\nor augment the performance of able-bodied users. Accurate and adaptive control\nsystems are essential to ensure seamless interaction between the wearer and the\nrobotic device, particularly when navigating diverse and dynamic terrains.\nDespite the recent advances in neural networks for time series analysis, no\nattempts have been directed towards the classification of ground conditions,\ncategorized into five classes and subsequently determining the ramp's slope and\nstair's height. In this respect, this paper presents an experimental comparison\nbetween eight deep neural network backbones to predict high-level locomotion\nparameters across diverse terrains.\n  All the models are trained on the publicly available CAMARGO 2021 dataset.\nIMU-only data equally or outperformed IMU+EMG inputs, promoting a\ncost-effective and efficient design. Indeeds, using three IMU sensors, the LSTM\nachieved high terrain classification accuracy (0.94 +- 0.04) and precise ramp\nslope (1.95 +- 0.58{\\deg}) and the CNN-LSTM a stair height (15.65 +- 7.40 mm)\nestimations. As a further contribution, SHAP analysis justified sensor\nreduction without performance loss, ensuring a lightweight setup. The system\noperates with ~2 ms inference time, supporting real-time applications. The code\nis code available at\nhttps://github.com/cosbidev/Human-Locomotion-Identification.", "published": "2025-03-21 07:12:44", "link": "http://arxiv.org/abs/2503.16904v1", "categories": ["cs.RO", "cs.AI", "F.2.2, I.2.7"], "primary_category": "cs.RO"}
{"title": "Classifier-guided CLIP Distillation for Unsupervised Multi-label Classification", "abstract": "Multi-label classification is crucial for comprehensive image understanding,\nyet acquiring accurate annotations is challenging and costly. To address this,\na recent study suggests exploiting unsupervised multi-label classification\nleveraging CLIP, a powerful vision-language model. Despite CLIP's proficiency,\nit suffers from view-dependent predictions and inherent bias, limiting its\neffectiveness. We propose a novel method that addresses these issues by\nleveraging multiple views near target objects, guided by Class Activation\nMapping (CAM) of the classifier, and debiasing pseudo-labels derived from CLIP\npredictions. Our Classifier-guided CLIP Distillation (CCD) enables selecting\nmultiple local views without extra labels and debiasing predictions to enhance\nclassification performance. Experimental results validate our method's\nsuperiority over existing techniques across diverse datasets. The code is\navailable at https://github.com/k0u-id/CCD.", "published": "2025-03-21 06:12:14", "link": "http://arxiv.org/abs/2503.16873v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "In-House Evaluation Is Not Enough: Towards Robust Third-Party Flaw Disclosure for General-Purpose AI", "abstract": "The widespread deployment of general-purpose AI (GPAI) systems introduces\nsignificant new risks. Yet the infrastructure, practices, and norms for\nreporting flaws in GPAI systems remain seriously underdeveloped, lagging far\nbehind more established fields like software security. Based on a collaboration\nbetween experts from the fields of software security, machine learning, law,\nsocial science, and policy, we identify key gaps in the evaluation and\nreporting of flaws in GPAI systems. We call for three interventions to advance\nsystem safety. First, we propose using standardized AI flaw reports and rules\nof engagement for researchers in order to ease the process of submitting,\nreproducing, and triaging flaws in GPAI systems. Second, we propose GPAI system\nproviders adopt broadly-scoped flaw disclosure programs, borrowing from bug\nbounties, with legal safe harbors to protect researchers. Third, we advocate\nfor the development of improved infrastructure to coordinate distribution of\nflaw reports across the many stakeholders who may be impacted. These\ninterventions are increasingly urgent, as evidenced by the prevalence of\njailbreaks and other flaws that can transfer across different providers' GPAI\nsystems. By promoting robust reporting and coordination in the AI ecosystem,\nthese proposals could significantly improve the safety, security, and\naccountability of GPAI systems.", "published": "2025-03-21 05:09:46", "link": "http://arxiv.org/abs/2503.16861v2", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Casual Inference via Style Bias Deconfounding for Domain Generalization", "abstract": "Deep neural networks (DNNs) often struggle with out-of-distribution data,\nlimiting their reliability in diverse realworld applications. To address this\nissue, domain generalization methods have been developed to learn\ndomain-invariant features from single or multiple training domains, enabling\ngeneralization to unseen testing domains. However, existing approaches usually\noverlook the impact of style frequency within the training set. This oversight\npredisposes models to capture spurious visual correlations caused by style\nconfounding factors, rather than learning truly causal representations, thereby\nundermining inference reliability. In this work, we introduce Style\nDeconfounding Causal Learning (SDCL), a novel causal inference-based framework\ndesigned to explicitly address style as a confounding factor. Our approaches\nbegins with constructing a structural causal model (SCM) tailored to the domain\ngeneralization problem and applies a backdoor adjustment strategy to account\nfor style influence. Building on this foundation, we design a style-guided\nexpert module (SGEM) to adaptively clusters style distributions during\ntraining, capturing the global confounding style. Additionally, a back-door\ncausal learning module (BDCL) performs causal interventions during feature\nextraction, ensuring fair integration of global confounding styles into sample\npredictions, effectively reducing style bias. The SDCL framework is highly\nversatile and can be seamlessly integrated with state-of-the-art data\naugmentation techniques. Extensive experiments across diverse natural and\nmedical image recognition tasks validate its efficacy, demonstrating superior\nperformance in both multi-domain and the more challenging single-domain\ngeneralization scenarios.", "published": "2025-03-21 04:52:31", "link": "http://arxiv.org/abs/2503.16852v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Physics-Informed Neural Network Surrogate Models for River Stage Prediction", "abstract": "This work investigates the feasibility of using Physics-Informed Neural\nNetworks (PINNs) as surrogate models for river stage prediction, aiming to\nreduce computational cost while maintaining predictive accuracy. Our primary\ncontribution demonstrates that PINNs can successfully approximate HEC-RAS\nnumerical solutions when trained on a single river, achieving strong predictive\naccuracy with generally low relative errors, though some river segments exhibit\nhigher deviations.\n  By integrating the governing Saint-Venant equations into the learning\nprocess, the proposed PINN-based surrogate model enforces physical consistency\nand significantly improves computational efficiency compared to HEC-RAS. We\nevaluate the model's performance in terms of accuracy and computational speed,\ndemonstrating that it closely approximates HEC-RAS predictions while enabling\nreal-time inference.\n  These results highlight the potential of PINNs as effective surrogate models\nfor single-river hydrodynamics, offering a promising alternative for\ncomputationally efficient river stage forecasting. Future work will explore\ntechniques to enhance PINN training stability and robustness across a more\ngeneralized multi-river model.", "published": "2025-03-21 04:48:22", "link": "http://arxiv.org/abs/2503.16850v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "DyWA: Dynamics-adaptive World Action Model for Generalizable Non-prehensile Manipulation", "abstract": "Nonprehensile manipulation is crucial for handling objects that are too thin,\nlarge, or otherwise ungraspable in unstructured environments. While\nconventional planning-based approaches struggle with complex contact modeling,\nlearning-based methods have recently emerged as a promising alternative.\nHowever, existing learning-based approaches face two major limitations: they\nheavily rely on multi-view cameras and precise pose tracking, and they fail to\ngeneralize across varying physical conditions, such as changes in object mass\nand table friction. To address these challenges, we propose the\nDynamics-Adaptive World Action Model (DyWA), a novel framework that enhances\naction learning by jointly predicting future states while adapting to dynamics\nvariations based on historical trajectories. By unifying the modeling of\ngeometry, state, physics, and robot actions, DyWA enables more robust policy\nlearning under partial observability. Compared to baselines, our method\nimproves the success rate by 31.5% using only single-view point cloud\nobservations in the simulation. Furthermore, DyWA achieves an average success\nrate of 68% in real-world experiments, demonstrating its ability to generalize\nacross diverse object geometries, adapt to varying table friction, and\nrobustness in challenging scenarios such as half-filled water bottles and\nslippery surfaces.", "published": "2025-03-21 02:29:52", "link": "http://arxiv.org/abs/2503.16806v1", "categories": ["cs.RO", "cs.AI"], "primary_category": "cs.RO"}
{"title": "Auto-Regressive Diffusion for Generating 3D Human-Object Interactions", "abstract": "Text-driven Human-Object Interaction (Text-to-HOI) generation is an emerging\nfield with applications in animation, video games, virtual reality, and\nrobotics. A key challenge in HOI generation is maintaining interaction\nconsistency in long sequences. Existing Text-to-Motion-based approaches, such\nas discrete motion tokenization, cannot be directly applied to HOI generation\ndue to limited data in this domain and the complexity of the modality. To\naddress the problem of interaction consistency in long sequences, we propose an\nautoregressive diffusion model (ARDHOI) that predicts the next continuous\ntoken. Specifically, we introduce a Contrastive Variational Autoencoder (cVAE)\nto learn a physically plausible space of continuous HOI tokens, thereby\nensuring that generated human-object motions are realistic and natural. For\ngenerating sequences autoregressively, we develop a Mamba-based context encoder\nto capture and maintain consistent sequential actions. Additionally, we\nimplement an MLP-based denoiser to generate the subsequent token conditioned on\nthe encoded context. Our model has been evaluated on the OMOMO and BEHAVE\ndatasets, where it outperforms existing state-of-the-art methods in terms of\nboth performance and inference speed. This makes ARDHOI a robust and efficient\nsolution for text-driven HOI tasks", "published": "2025-03-21 02:25:59", "link": "http://arxiv.org/abs/2503.16801v1", "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "cs.GR"}
{"title": "Causally Aligned Curriculum Learning", "abstract": "A pervasive challenge in Reinforcement Learning (RL) is the \"curse of\ndimensionality\" which is the exponential growth in the state-action space when\noptimizing a high-dimensional target task. The framework of curriculum learning\ntrains the agent in a curriculum composed of a sequence of related and more\nmanageable source tasks. The expectation is that when some optimal decision\nrules are shared across source tasks and the target task, the agent could more\nquickly pick up the necessary skills to behave optimally in the environment,\nthus accelerating the learning process. However, this critical assumption of\ninvariant optimal decision rules does not necessarily hold in many practical\napplications, specifically when the underlying environment contains unobserved\nconfounders. This paper studies the problem of curriculum RL through causal\nlenses. We derive a sufficient graphical condition characterizing causally\naligned source tasks, i.e., the invariance of optimal decision rules holds. We\nfurther develop an efficient algorithm to generate a causally aligned\ncurriculum, provided with qualitative causal knowledge of the target task.\nFinally, we validate our proposed methodology through experiments in discrete\nand continuous confounded tasks with pixel observations.", "published": "2025-03-21 02:20:38", "link": "http://arxiv.org/abs/2503.16799v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "A Learnability Analysis on Neuro-Symbolic Learning", "abstract": "This paper analyzes the learnability of neuro-symbolic (NeSy) tasks within\nhybrid systems. We show that the learnability of NeSy tasks can be\ncharacterized by their derived constraint satisfaction problems (DCSPs).\nSpecifically, a task is learnable if the corresponding DCSP has a unique\nsolution; otherwise, it is unlearnable. For learnable tasks, we establish error\nbounds by exploiting the clustering property of the hypothesis space.\nAdditionally, we analyze the asymptotic error for general NeSy tasks, showing\nthat the expected error scales with the disagreement among solutions. Our\nresults offer a principled approach to determining learnability and provide\ninsights into the design of new algorithms.", "published": "2025-03-21 02:16:11", "link": "http://arxiv.org/abs/2503.16797v1", "categories": ["cs.AI", "cs.LG"], "primary_category": "cs.AI"}
{"title": "\"The Diagram is like Guardrails\": Structuring GenAI-assisted Hypotheses Exploration with an Interactive Shared Representation", "abstract": "Data analysis encompasses a spectrum of tasks, from high-level conceptual\nreasoning to lower-level execution. While AI-powered tools increasingly support\nexecution tasks, there remains a need for intelligent assistance in conceptual\ntasks. This paper investigates the design of an ordered node-link tree\ninterface augmented with AI-generated information hints and visualizations, as\na potential shared representation for hypothesis exploration. Through a design\nprobe (n=22), participants generated diagrams averaging 21.82 hypotheses. Our\nfindings showed that the node-link diagram acts as \"guardrails\" for hypothesis\nexploration, facilitating structured workflows, providing comprehensive\noverviews, and enabling efficient backtracking. The AI-generated information\nhints, particularly visualizations, aided users in transforming abstract ideas\ninto data-backed concepts while reducing cognitive load. We further discuss how\nnode-link diagrams can support both parallel exploration and iterative\nrefinement in hypothesis formulation, potentially enhancing the breadth and\ndepth of human-AI collaborative data analysis.", "published": "2025-03-21 02:01:37", "link": "http://arxiv.org/abs/2503.16791v1", "categories": ["cs.HC", "cs.AI"], "primary_category": "cs.HC"}
{"title": "Does Chain-of-Thought Reasoning Help Mobile GUI Agent? An Empirical Study", "abstract": "Reasoning capabilities have significantly improved the performance of\nvision-language models (VLMs) in domains such as mathematical problem-solving,\ncoding, and visual question-answering. However, their impact on real-world\napplications remains unclear. This paper presents the first empirical study on\nthe effectiveness of reasoning-enabled VLMs in mobile GUI agents, a domain that\nrequires interpreting complex screen layouts, understanding user instructions,\nand executing multi-turn interactions. We evaluate two pairs of commercial\nmodels--Gemini 2.0 Flash and Claude 3.7 Sonnet--comparing their base and\nreasoning-enhanced versions across two static benchmarks (ScreenSpot and\nAndroidControl) and one interactive environment (AndroidWorld). We surprisingly\nfind the Claude 3.7 Sonnet reasoning model achieves state-of-the-art\nperformance on AndroidWorld. However, reasoning VLMs generally offer marginal\nimprovements over non-reasoning models on static benchmarks and even degrade\nperformance in some agent setups. Notably, reasoning and non-reasoning VLMs\nfail on different sets of tasks, suggesting that reasoning does have an impact,\nbut its benefits and drawbacks counterbalance each other. We attribute these\ninconsistencies to the limitations of benchmarks and VLMs. Based on the\nfindings, we provide insights for further enhancing mobile GUI agents in terms\nof benchmarks, VLMs, and their adaptability in dynamically invoking reasoning\nVLMs. The experimental data are publicly available at\nhttps://github.com/LlamaTouch/VLM-Reasoning-Traces.", "published": "2025-03-21 01:52:43", "link": "http://arxiv.org/abs/2503.16788v1", "categories": ["cs.AI"], "primary_category": "cs.AI"}
{"title": "Learning Part Knowledge to Facilitate Category Understanding for Fine-Grained Generalized Category Discovery", "abstract": "Generalized Category Discovery (GCD) aims to classify unlabeled data\ncontaining both seen and novel categories. Although existing methods perform\nwell on generic datasets, they struggle in fine-grained scenarios. We attribute\nthis difficulty to their reliance on contrastive learning over global image\nfeatures to automatically capture discriminative cues, which fails to capture\nthe subtle local differences essential for distinguishing fine-grained\ncategories. Therefore, in this paper, we propose incorporating part knowledge\nto address fine-grained GCD, which introduces two key challenges: the absence\nof annotations for novel classes complicates the extraction of the part\nfeatures, and global contrastive learning prioritizes holistic feature\ninvariance, inadvertently suppressing discriminative local part patterns. To\naddress these challenges, we propose PartGCD, including 1) Adaptive Part\nDecomposition, which automatically extracts class-specific semantic parts via\nGaussian Mixture Models, and 2) Part Discrepancy Regularization, enforcing\nexplicit separation between part features to amplify fine-grained local part\ndistinctions.\n  Experiments demonstrate state-of-the-art performance across multiple\nfine-grained benchmarks while maintaining competitiveness on generic datasets,\nvalidating the effectiveness and robustness of our approach.", "published": "2025-03-21 01:37:51", "link": "http://arxiv.org/abs/2503.16782v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "cs.CV"}
{"title": "Generative Modeling of Class Probability for Multi-Modal Representation Learning", "abstract": "Multi-modal understanding plays a crucial role in artificial intelligence by\nenabling models to jointly interpret inputs from different modalities. However,\nconventional approaches such as contrastive learning often struggle with\nmodality discrepancies, leading to potential misalignments. In this paper, we\npropose a novel class anchor alignment approach that leverages class\nprobability distributions for multi-modal representation learning. Our method,\nClass-anchor-ALigned generative Modeling (CALM), encodes class anchors as\nprompts to generate and align class probability distributions for each\nmodality, enabling more effective alignment. Furthermore, we introduce a\ncross-modal probabilistic variational autoencoder to model uncertainty in the\nalignment, enhancing the ability to capture deeper relationships between\nmodalities and data variations. Extensive experiments on four benchmark\ndatasets demonstrate that our approach significantly outperforms\nstate-of-the-art methods, especially in out-of-domain evaluations. This\nhighlights its superior generalization capabilities in multi-modal\nrepresentation learning.", "published": "2025-03-21 01:17:44", "link": "http://arxiv.org/abs/2503.17417v1", "categories": ["cs.LG", "cs.AI"], "primary_category": "cs.LG"}
{"title": "Debugging and Runtime Analysis of Neural Networks with VLMs (A Case Study)", "abstract": "Debugging of Deep Neural Networks (DNNs), particularly vision models, is very\nchallenging due to the complex and opaque decision-making processes in these\nnetworks. In this paper, we explore multi-modal Vision-Language Models (VLMs),\nsuch as CLIP, to automatically interpret the opaque representation space of\nvision models using natural language. This in turn, enables a semantic analysis\nof model behavior using human-understandable concepts, without requiring costly\nhuman annotations. Key to our approach is the notion of semantic heatmap, that\nsuccinctly captures the statistical properties of DNNs in terms of the concepts\ndiscovered with the VLM and that are computed off-line using a held-out data\nset. We show the utility of semantic heatmaps for fault localization -- an\nessential step in debugging -- in vision models. Our proposed technique helps\nlocalize the fault in the network (encoder vs head) and also highlights the\nresponsible high-level concepts, by leveraging novel differential heatmaps,\nwhich summarize the semantic differences between the correct and incorrect\nbehaviour of the analyzed DNN. We further propose a lightweight runtime\nanalysis to detect and filter-out defects at runtime, thus improving the\nreliability of the analyzed DNNs. The runtime analysis works by measuring and\ncomparing the similarity between the heatmap computed for a new (unseen) input\nand the heatmaps computed a-priori for correct vs incorrect DNN behavior. We\nconsider two types of defects: misclassifications and vulnerabilities to\nadversarial attacks. We demonstrate the debugging and runtime analysis on a\ncase study involving a complex ResNet-based classifier trained on the RIVAL10\ndataset.", "published": "2025-03-21 01:12:57", "link": "http://arxiv.org/abs/2503.17416v1", "categories": ["cs.SE", "cs.AI", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Enhancing Subsequent Video Retrieval via Vision-Language Models (VLMs)", "abstract": "The rapid growth of video content demands efficient and precise retrieval\nsystems. While vision-language models (VLMs) excel in representation learning,\nthey often struggle with adaptive, time-sensitive video retrieval. This paper\nintroduces a novel framework that combines vector similarity search with\ngraph-based data structures. By leveraging VLM embeddings for initial retrieval\nand modeling contextual relationships among video segments, our approach\nenables adaptive query refinement and improves retrieval accuracy. Experiments\ndemonstrate its precision, scalability, and robustness, offering an effective\nsolution for interactive video retrieval in dynamic environments.", "published": "2025-03-21 01:11:14", "link": "http://arxiv.org/abs/2503.17415v1", "categories": ["cs.CV", "cs.AI", "cs.IR"], "primary_category": "cs.CV"}
{"title": "Dynamic Attention Mechanism in Spatiotemporal Memory Networks for Object Tracking", "abstract": "Mainstream visual object tracking frameworks predominantly rely on template\nmatching paradigms. Their performance heavily depends on the quality of\ntemplate features, which becomes increasingly challenging to maintain in\ncomplex scenarios involving target deformation, occlusion, and background\nclutter. While existing spatiotemporal memory-based trackers emphasize memory\ncapacity expansion, they lack effective mechanisms for dynamic feature\nselection and adaptive fusion. To address this gap, we propose a Dynamic\nAttention Mechanism in Spatiotemporal Memory Network (DASTM) with two key\ninnovations: 1) A differentiable dynamic attention mechanism that adaptively\nadjusts channel-spatial attention weights by analyzing spatiotemporal\ncorrelations between the templates and memory features; 2) A lightweight gating\nnetwork that autonomously allocates computational resources based on target\nmotion states, prioritizing high-discriminability features in challenging\nscenarios. Extensive evaluations on OTB-2015, VOT 2018, LaSOT, and GOT-10K\nbenchmarks demonstrate our DASTM's superiority, achieving state-of-the-art\nperformance in success rate, robustness, and real-time efficiency, thereby\noffering a novel solution for real-time tracking in complex environments.", "published": "2025-03-21 00:48:31", "link": "http://arxiv.org/abs/2503.16768v1", "categories": ["cs.CV", "cs.AI"], "primary_category": "cs.CV"}
{"title": "Opportunities and Challenges of Frontier Data Governance With Synthetic Data", "abstract": "Synthetic data, or data generated by machine learning models, is increasingly\nemerging as a solution to the data access problem. However, its use introduces\nsignificant governance and accountability challenges, and potentially debases\nexisting governance paradigms, such as compute and data governance. In this\npaper, we identify 3 key governance and accountability challenges that\nsynthetic data poses - it can enable the increased emergence of malicious\nactors, spontaneous biases and value drift. We thus craft 3 technical\nmechanisms to address these specific challenges, finding applications for\nsynthetic data towards adversarial training, bias mitigation and value\nreinforcement. These could not only counteract the risks of synthetic data, but\nserve as critical levers for governance of the frontier in the future.", "published": "2025-03-21 00:30:17", "link": "http://arxiv.org/abs/2503.17414v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "cs.CY"}
{"title": "Separation Number and Treewidth, Revisited", "abstract": "We give a constructive proof of the fact that the treewidth of a graph $G$ is\nbounded by a linear function of the separation number of $G$.", "published": "2025-03-21 12:56:13", "link": "http://arxiv.org/abs/2503.17112v1", "categories": ["math.CO", "cs.DM"], "primary_category": "math.CO"}
{"title": "Local Ratio based Real-time Job Offloading and Resource Allocation in Mobile Edge Computing", "abstract": "Mobile Edge Computing (MEC) has emerged as a promising paradigm enabling\nvehicles to handle computation-intensive and time-sensitive applications for\nintelligent transportation. Due to the limited resources in MEC, effective\nresource management is crucial for improving system performance. While existing\nstudies mostly focus on the job offloading problem and assume that job resource\ndemands are fixed and given apriori, the joint consideration of job offloading\n(selecting the edge server for each job) and resource allocation (determining\nthe bandwidth and computation resources for offloading and processing) remains\nunderexplored. This paper addresses the joint problem for deadline-constrained\njobs in MEC with both communication and computation resource constraints,\naiming to maximize the total utility gained from jobs. To tackle this problem,\nwe propose an approximation algorithm, $\\mathtt{IDAssign}$, with an\napproximation bound of $\\frac{1}{6}$, and experimentally evaluate the\nperformance of $\\mathtt{IDAssign}$ by comparing it to state-of-the-art\nheuristics using a real-world taxi trace and object detection applications.", "published": "2025-03-21 02:06:25", "link": "http://arxiv.org/abs/2503.16794v1", "categories": ["cs.DC", "cs.DM", "cs.DS"], "primary_category": "cs.DC"}
{"title": "Dense Passage Retrieval in Conversational Search", "abstract": "Information retrieval systems have traditionally relied on exact term match\nmethods such as BM25 for first-stage retrieval. However, recent advancements in\nneural network-based techniques have introduced a new method called dense\nretrieval. This approach uses a dual-encoder to create contextual embeddings\nthat can be indexed and clustered efficiently at run-time, resulting in\nimproved retrieval performance in Open-domain Question Answering systems. In\nthis paper, we apply the dense retrieval technique to conversational search by\nconducting experiments on the CAsT benchmark dataset. We also propose an\nend-to-end conversational search system called GPT2QR+DPR, which incorporates\nvarious query reformulation strategies to improve retrieval accuracy. Our\nfindings indicate that dense retrieval outperforms BM25 even without extensive\nfine-tuning. Our work contributes to the growing body of research on\nneural-based retrieval methods in conversational search, and highlights the\npotential of dense retrieval in improving retrieval accuracy in conversational\nsearch systems.", "published": "2025-03-21 19:39:31", "link": "http://arxiv.org/abs/2503.17507v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Towards Carbon Footprint-Aware Recommender Systems for Greener Item Recommendation", "abstract": "The commodity and widespread use of online shopping are having an\nunprecedented impact on climate, with emission figures from key actors that are\neasily comparable to those of a large-scale metropolis. Despite online shopping\nbeing fueled by recommender systems (RecSys) algorithms, the role and potential\nof the latter in promoting more sustainable choices is little studied. One of\nthe main reasons for this could be attributed to the lack of a dataset\ncontaining carbon footprint emissions for the items. While building such a\ndataset is a rather challenging task, its presence is pivotal for opening the\ndoors to novel perspectives, evaluations, and methods for RecSys research. In\nthis paper, we target this bottleneck and study the environmental role of\nRecSys algorithms. First, we mine a dataset that includes carbon footprint\nemissions for its items. Then, we benchmark conventional RecSys algorithms in\nterms of accuracy and sustainability as two faces of the same coin. We find\nthat RecSys algorithms optimized for accuracy overlook greenness and that\nlonger recommendation lists are greener but less accurate. Then, we show that a\nsimple reranking approach that accounts for the item's carbon footprint can\nestablish a better trade-off between accuracy and greenness. This reranking\napproach is modular, ready to use, and can be applied to any RecSys algorithm\nwithout the need to alter the underlying mechanisms or retrain models. Our\nresults show that a small sacrifice of accuracy can lead to significant\nimprovements of recommendation greenness across all algorithms and list\nlengths. Arguably, this accuracy-greenness trade-off could even be seen as an\nenhancement of user satisfaction, particularly for purpose-driven users who\nprioritize the environmental impact of their choices. We anticipate this work\nwill serve as the starting point for studying RecSys for more sustainable\nrecommendations.", "published": "2025-03-21 14:58:47", "link": "http://arxiv.org/abs/2503.17201v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Rankformer: A Graph Transformer for Recommendation based on Ranking Objective", "abstract": "Recommender Systems (RS) aim to generate personalized ranked lists for each\nuser and are evaluated using ranking metrics. Although personalized ranking is\na fundamental aspect of RS, this critical property is often overlooked in the\ndesign of model architectures. To address this issue, we propose Rankformer, a\nranking-inspired recommendation model. The architecture of Rankformer is\ninspired by the gradient of the ranking objective, embodying a unique (graph)\ntransformer architecture -- it leverages global information from all users and\nitems to produce more informative representations and employs specific\nattention weights to guide the evolution of embeddings towards improved ranking\nperformance. We further develop an acceleration algorithm for Rankformer,\nreducing its complexity to a linear level with respect to the number of\npositive instances. Extensive experimental results demonstrate that Rankformer\noutperforms state-of-the-art methods. The code is available at\nhttps://github.com/StupidThree/Rankformer.", "published": "2025-03-21 07:53:06", "link": "http://arxiv.org/abs/2503.16927v1", "categories": ["cs.IR"], "primary_category": "cs.IR"}
{"title": "Optimal Neural Compressors for the Rate-Distortion-Perception Tradeoff", "abstract": "Recent efforts in neural compression have focused on the\nrate-distortion-perception (RDP) tradeoff, where the perception constraint\nensures the source and reconstruction distributions are close in terms of a\nstatistical divergence. Theoretical work on RDP describes interesting\nproperties of RDP-optimal compressors without providing constructive and low\ncomplexity solutions. While classical rate distortion theory shows that optimal\ncompressors should efficiently pack the space, RDP theory additionally shows\nthat infinite randomness shared between the encoder and decoder may be\nnecessary for RDP optimality. In this paper, we propose neural compressors that\nare low complexity and benefit from high packing efficiency through lattice\ncoding and shared randomness through shared dithering over the lattice cells.\nFor two important settings, namely infinite shared and zero shared randomness,\nwe analyze the rate, distortion, and perception achieved by our proposed neural\ncompressors and further show optimality in the presence of infinite shared\nrandomness. Experimentally, we investigate the roles these two components of\nour design, lattice coding and randomness, play in the performance of neural\ncompressors on synthetic and real-world data. We observe that performance\nimproves with more shared randomness and better lattice packing.", "published": "2025-03-21 22:18:52", "link": "http://arxiv.org/abs/2503.17558v1", "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "cs.IT"}
{"title": "Infinite-fold Quantum Advantage in Classical Correlation Sensing", "abstract": "We study the hypothesis testing problem of detecting the presence of a\nthermal source emitting coherent quantum states towards an arbitrary but fixed\nnumber $K$ of detectors versus the situation where the detectors are presented\nuncorrelated thermal noise of the same average energy in the setting of\nasymmetric hypothesis testing. We compare two variations of this theme: In the\nfirst one the detectors perform heterodyne or homodyne detection and then\ntransmit their measured results to a central processing unit with unlimited\ncomputational resources. In the second one the detectors are able to teleport\nthe quantum states to the central unit, which acts on the received quantum\nstates with unlimited quantum computational resources. We find that when the\naverage received energy per detector goes to zero, the ratio of the error\nexponents goes to infinity, indicating an infinite-fold quantum advantage.", "published": "2025-03-21 15:36:51", "link": "http://arxiv.org/abs/2503.17235v1", "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "quant-ph"}
{"title": "Unsourced Random Access in MIMO Quasi-Static Rayleigh Fading Channels: Finite Blocklength and Scaling Law Analyses", "abstract": "This paper considers the unsourced random access (URA) problem with a random\nand unknown number of active users in multiple-input multiple-output (MIMO)\nquasi-static Rayleigh fading channels. We derive non-asymptotic achievability\nbounds on the probability of incorrectly estimating the number of active users,\nand provide scaling laws on the gap between the estimated and true numbers of\nactive users. We prove that the error probability reaches a plateau as the\npower $P$ and blocklength $n$ increase, whereas it decays exponentially with\nthe number $L$ of receive antennas and eventually vanishes. Then, we explore\nthe fundamental limits of URA by deriving non-asymptotic achievability bounds\nand converse bounds (including two single-user converse bounds and one\nmulti-user ensemble converse bound) on the minimum energy-per-bit required by\neach active user to transmit $J$ bits with blocklength $n$ under misdetection\nand false-alarm constraints. Numerical results show that the extra required\nenergy-per-bit due to the uncertainty in the number ${\\rm{K}}_a$ of active\nusers decreases as $L$ and $\\mathbb{E}[{\\rm{K}}_a]$ increase and the error\nrequirement becomes milder. In the non-asymptotic regime, using codewords\ndistributed on a sphere outperforms Gaussian random coding. Existing schemes\nare shown to exhibit a large gap to our bounds when the number of active users\nis large, calling for more advanced schemes that perform energy-efficiently in\nthis case. In the asymptotic regime with $n\\to\\infty$, we establish scaling\nlaws on the minimum required $P$ and $L$ to reliably support ${\\rm{K}}_a$\nactive users as functions of $n$, which highlight the potential of MIMO in\nenabling low-cost communication and indicate that it is possible for the\nminimum required $P$ and $L$ to remain on the same order when the number of\nactive users increases but stays below a threshold.", "published": "2025-03-21 12:17:18", "link": "http://arxiv.org/abs/2503.17088v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "Gaussian Blahut-Arimoto Algorithm for Capacity Region Calculation of Gaussian Vector Broadcast Channels", "abstract": "This paper is concerned with the computation of the capacity region of a\ncontinuous, Gaussian vector broadcast channel (BC) with covariance matrix\nconstraints. Since the decision variables of the corresponding optimization\nproblem are Gaussian distributed, they can be characterized by a finite number\nof parameters. Consequently, we develop new Blahut-Arimoto (BA)-type algorithms\nthat can compute the capacity without discretizing the channel. First, by\nexploiting projection and an approximation of the Lagrange multiplier, which\nare introduced to handle certain positive semidefinite constraints in the\noptimization formulation, we develop the Gaussian BA algorithm with projection\n(GBA-P). Then, we demonstrate that one of the subproblems arising from the\nalternating updates admits a closed-form solution. Based on this result, we\npropose the Gaussian BA algorithm with alternating updates (GBA-A) and\nestablish its convergence guarantee. Furthermore, we extend the GBA-P algorithm\nto compute the capacity region of the Gaussian vector BC with both private and\ncommon messages. All the proposed algorithms are parameter-free. Lastly, we\npresent numerical results to demonstrate the effectiveness of the proposed\nalgorithms.", "published": "2025-03-21 07:32:21", "link": "http://arxiv.org/abs/2503.16919v1", "categories": ["cs.IT", "math.IT"], "primary_category": "cs.IT"}
{"title": "On-Device Federated Continual Learning on RISC-V-based Ultra-Low-Power SoC for Intelligent Nano-Drone Swarms", "abstract": "RISC-V-based architectures are paving the way for efficient On-Device\nLearning (ODL) in smart edge devices. When applied across multiple nodes, ODL\nenables the creation of intelligent sensor networks that preserve data privacy.\nHowever, developing ODL-capable, battery-operated embedded platforms presents\nsignificant challenges due to constrained computational resources and limited\ndevice lifetime, besides intrinsic learning issues such as catastrophic\nforgetting. We face these challenges by proposing a regularization-based\nOn-Device Federated Continual Learning algorithm tailored for multiple\nnano-drones performing face recognition tasks. We demonstrate our approach on a\nRISC-V-based 10-core ultra-low-power SoC, optimizing the ODL computational\nrequirements. We improve the classification accuracy by 24% over naive\nfine-tuning, requiring 178 ms per local epoch and 10.5 s per global epoch,\ndemonstrating the effectiveness of the architecture for this task.", "published": "2025-03-21 15:53:57", "link": "http://arxiv.org/abs/2503.17436v1", "categories": ["cs.LG", "cs.CV", "cs.MA", "I.2.11; I.2.6; C.5.3; I.4.9"], "primary_category": "cs.LG"}
{"title": "Distributed Stochastic Zeroth-Order Optimization with Compressed Communication", "abstract": "The dual challenges of prohibitive communication overhead and the\nimpracticality of gradient computation due to data privacy or black-box\nconstraints in distributed systems motivate this work on\ncommunication-constrained gradient-free optimization. We propose a stochastic\ndistributed zeroth-order algorithm (Com-DSZO) requiring only two function\nevaluations per iteration, integrated with general compression operators.\nRigorous analysis establishes its sublinear convergence rate for both smooth\nand nonsmooth objectives, while explicitly elucidating the\ncompression-convergence trade-off. Furthermore, we develop a variance-reduced\nvariant (VR-Com-DSZO) under stochastic mini-batch feedback. The empirical\nalgorithm performance are illustrated with numerical examples.", "published": "2025-03-21 12:06:54", "link": "http://arxiv.org/abs/2503.17429v2", "categories": ["math.OC", "cs.MA"], "primary_category": "math.OC"}
{"title": "Equilibrium with non-convex preferences: some insights", "abstract": "We study the existence of equilibrium when agents' preferences may not\nbeconvex. For some specific utility functions, we provide a necessary and\nsufficientcondition under which there exists an equilibrium. The standard\napproach cannot be directly applied to our examples because the demand\ncorrespondence of some agents is neither single-valued nor convex-valued.", "published": "2025-03-21 06:46:24", "link": "http://arxiv.org/abs/2503.16890v1", "categories": ["q-fin.CP"], "primary_category": "q-fin.CP"}
{"title": "Martingale property and moment explosions in signature volatility models", "abstract": "We study the martingale property and moment explosions of a signature\nvolatility model, where the volatility process of the log-price is given by a\nlinear form of the signature of a time-extended Brownian motion. Excluding\ntrivial cases, we demonstrate that the price process is a true martingale if\nand only if the order of the linear form is odd and a correlation parameter is\nnegative. The proof involves a fine analysis of the explosion time of a\nsignature stochastic differential equation. This result is of key practical\nrelevance, as it highlights that, when used for approximation purposes, the\nlinear combination of signature elements must be taken of odd order to preserve\nthe martingale property. Once martingality is established, we also characterize\nthe existence of higher moments of the price process in terms of a condition on\na correlation parameter.", "published": "2025-03-21 12:42:41", "link": "http://arxiv.org/abs/2503.17103v1", "categories": ["q-fin.MF", "math.PR"], "primary_category": "q-fin.MF"}
{"title": "China and G7 in the Current Context of the World Trading", "abstract": "The paper analyses trade between the most developed economies of the world.\nThe analysis is based on the previously proposed model of international trade.\nThis model of international trade is based on the theory of general economic\nequilibrium. The demand for goods in this model is built on the import of goods\nby each of the countries participating in the trade. The structure of supply of\ngoods in this model is determined by the structure of exports of each country.\nIt is proved that in such a model, given a certain structure of supply and\ndemand, there exists a so-called ideal equilibrium state in which the trade\nbalance of each country is zero. Under certain conditions on the structure of\nsupply and demand, there is an equilibrium state in which each country have a\nstrictly positive trade balance. Among the equilibrium states under a certain\nstructure of supply and demand, there are some that differ from the ones\ndescribed above. Such states are characterized by the fact that there is an\ninequitable distribution of income between the participants in the trade. Such\nstates are called degenerate. In this paper, based on the previously proposed\nmodel of international trade, an analysis of the dynamics of international\ntrade of 8 of the world's most developed economies is made. It is shown that\ntrade between these countries was not in a state of economic equilibrium. The\nfound relative equilibrium price vector turned out to be very degenerate, which\nindicates the unequal exchange of goods on the market of the 8 studied\ncountries. An analysis of the dynamics of supply to the market of the world's\nmost developed economies showed an increase in China's share. The same applies\nto the share of demand.", "published": "2025-03-21 15:26:42", "link": "http://arxiv.org/abs/2503.17225v1", "categories": ["q-fin.TR"], "primary_category": "q-fin.TR"}
{"title": "Learning disentangled representations for instrument-based music similarity", "abstract": "A flexible recommendation and retrieval system requires music similarity in\nterms of multiple partial elements of musical pieces to allow users to select\nthe element they want to focus on. A method for music similarity learning using\nmultiple networks with individual instrumental signals is effective but faces\nthe problem that using each clean instrumental signal as a query is impractical\nfor retrieval systems and using separated instrumental sounds reduces accuracy\nowing to artifacts. In this paper, we present instrumental-part-based music\nsimilarity learning with a single network that takes mixed sounds as input\ninstead of individual instrumental sounds. Specifically, we designed a single\nsimilarity embedding space with disentangled dimensions for each instrument,\nextracted by Conditional Similarity Networks, which are trained using the\ntriplet loss with masks. Experimental results showed that (1) the proposed\nmethod can obtain more accurate feature representation than using individual\nnetworks using separated sounds as input in the evaluation of an instrument\nthat had low accuracy, (2) each sub-embedding space can hold the\ncharacteristics of the corresponding instrument, and (3) the selection of\nsimilar musical pieces focusing on each instrumental sound by the proposed\nmethod can obtain human acceptance, especially when focusing on timbre.", "published": "2025-03-21 16:29:28", "link": "http://arxiv.org/abs/2503.17281v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Continuous Boostlet Transform and Associated Uncertainty Principles", "abstract": "The Continuous Boostlet Transform (CBT) is introduced as a powerful tool for\nanalyzing spatiotemporal signals, particularly acoustic wavefields. Overcoming\nthe limitations of classical wavelets, the CBT leverages the Poincar\\'e group\nand isotropic dilations to capture sparse features of natural acoustic fields.\nThis paper presents the mathematical framework of the CBT, including its\ndefinition, fundamental properties, and associated uncertainty principles, such\nas Heisenberg's, logarithmic, Pitt's, and Nazarov's inequalities. These results\nilluminate the trade-offs between time and frequency localization in the\nboostlet domain. Practical examples with constant and exponential functions\nhighlight the CBT's adaptability. With applications in radar, communications,\naudio processing, and seismic analysis, the CBT offers flexible time-frequency\nresolution, making it ideal for non-stationary and transient signals, and a\nvaluable tool for modern signal processing.", "published": "2025-03-21 14:58:16", "link": "http://arxiv.org/abs/2504.03679v1", "categories": ["eess.SP", "cs.SD", "eess.AS", "math.FA", "42C40. 42C15. 81R30. 42A38"], "primary_category": "eess.SP"}
{"title": "HiFi-Stream: Streaming Speech Enhancement with Generative Adversarial Networks", "abstract": "Speech Enhancement techniques have become core technologies in mobile devices\nand voice software simplifying downstream speech tasks. Still, modern Deep\nLearning (DL) solutions often require high amount of computational resources\nwhat makes their usage on low-resource devices challenging. We present\nHiFi-Stream, an optimized version of recently published HiFi++ model. Our\nexperiments demonstrate that HiFiStream saves most of the qualities of the\noriginal model despite its size and computational complexity: the lightest\nversion has only around 490k parameters which is 3.5x reduction in comparison\nto the original HiFi++ making it one of the smallest and fastest models\navailable. The model is evaluated in streaming setting where it demonstrates\nits superior performance in comparison to modern baselines.", "published": "2025-03-21 13:44:12", "link": "http://arxiv.org/abs/2503.17141v1", "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "cs.SD"}
{"title": "DIDiffGes: Decoupled Semi-Implicit Diffusion Models for Real-time Gesture Generation from Speech", "abstract": "Diffusion models have demonstrated remarkable synthesis quality and diversity\nin generating co-speech gestures. However, the computationally intensive\nsampling steps associated with diffusion models hinder their practicality in\nreal-world applications. Hence, we present DIDiffGes, for a Decoupled\nSemi-Implicit Diffusion model-based framework, that can synthesize\nhigh-quality, expressive gestures from speech using only a few sampling steps.\nOur approach leverages Generative Adversarial Networks (GANs) to enable\nlarge-step sampling for diffusion model. We decouple gesture data into body and\nhands distributions and further decompose them into marginal and conditional\ndistributions. GANs model the marginal distribution implicitly, while L2\nreconstruction loss learns the conditional distributions exciplictly. This\nstrategy enhances GAN training stability and ensures expressiveness of\ngenerated full-body gestures. Our framework also learns to denoise root noise\nconditioned on local body representation, guaranteeing stability and realism.\nDIDiffGes can generate gestures from speech with just 10 sampling steps,\nwithout compromising quality and expressiveness, reducing the number of\nsampling steps by a factor of 100 compared to existing methods. Our user study\nreveals that our method outperforms state-of-the-art approaches in human\nlikeness, appropriateness, and style correctness. Project is\nhttps://cyk990422.github.io/DIDiffGes.", "published": "2025-03-21 11:23:39", "link": "http://arxiv.org/abs/2503.17059v1", "categories": ["cs.GR", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.GR"}
{"title": "STFTCodec: High-Fidelity Audio Compression through Time-Frequency Domain Representation", "abstract": "We present STFTCodec, a novel spectral-based neural audio codec that\nefficiently compresses audio using Short-Time Fourier Transform (STFT). Unlike\nwaveform-based approaches that require large model capacity and substantial\nmemory consumption, this method leverages STFT for compact spectral\nrepresentation and introduces unwrapped phase derivatives as auxiliary\nfeatures. Our architecture employs parallel magnitude and phase processing\nbranches enhanced by advanced feature extraction mechanisms. By relaxing strict\nphase reconstruction constraints while maintaining phase-aware processing, we\nachieve superior perceptual quality. Experimental results demonstrate that\nSTFTCodec outperforms both waveform-based and spectral-based approaches across\nmultiple bitrates, while offering unique flexibility in compression ratio\nadjustment through STFT parameter modification without architectural changes.", "published": "2025-03-21 09:55:31", "link": "http://arxiv.org/abs/2503.16989v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "City2Scene: Improving Acoustic Scene Classification with City Features", "abstract": "Acoustic scene recordings are often collected from a diverse range of cities.\nMost existing acoustic scene classification (ASC) approaches focus on\nidentifying common acoustic scene patterns across cities to enhance\ngeneralization. In contrast, we hypothesize that city-specific environmental\nand cultural differences in acoustic features are beneficial for the ASC task.\nIn this paper, we introduce City2Scene, a novel framework that leverages city\nfeatures to improve ASC. City2Scene transfers the city-specific knowledge from\ncity classification models to a scene classification model using knowledge\ndistillation. We evaluated City2Scene on the DCASE Challenge Task 1 datasets,\nwhere each audio clip is annotated with both scene and city labels.\nExperimental results demonstrate that city features provide valuable\ninformation for classifying scenes. By distilling the city-specific knowledge,\nCity2Scene effectively improves accuracy for various state-of-the-art ASC\nbackbone models, including both CNNs and Transformers.", "published": "2025-03-21 05:24:48", "link": "http://arxiv.org/abs/2503.16862v1", "categories": ["cs.SD", "cs.CV", "eess.AS"], "primary_category": "cs.SD"}
