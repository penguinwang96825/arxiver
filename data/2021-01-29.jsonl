{"title": "Few-Shot Domain Adaptation for Grammatical Error Correction via\n  Meta-Learning", "abstract": "Most existing Grammatical Error Correction (GEC) methods based on\nsequence-to-sequence mainly focus on how to generate more pseudo data to obtain\nbetter performance. Few work addresses few-shot GEC domain adaptation. In this\npaper, we treat different GEC domains as different GEC tasks and propose to\nextend meta-learning to few-shot GEC domain adaptation without using any pseudo\ndata. We exploit a set of data-rich source domains to learn the initialization\nof model parameters that facilitates fast adaptation on new resource-poor\ntarget domains. We adapt GEC model to the first language (L1) of the second\nlanguage learner. To evaluate the proposed method, we use nine L1s as source\ndomains and five L1s as target domains. Experiment results on the L1 GEC domain\nadaptation dataset demonstrate that the proposed approach outperforms the\nmulti-task transfer learning baseline by 0.50 $F_{0.5}$ score on average and\nenables us to effectively adapt to a new L1 domain with only 200 parallel\nsentences.", "published": "2021-01-29 05:28:55", "link": "http://arxiv.org/abs/2101.12409v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Synthesizing Monolingual Data for Neural Machine Translation", "abstract": "In neural machine translation (NMT), monolingual data in the target language\nare usually exploited through a method so-called \"back-translation\" to\nsynthesize additional training parallel data. The synthetic data have been\nshown helpful to train better NMT, especially for low-resource language pairs\nand domains. Nonetheless, large monolingual data in the target domains or\nlanguages are not always available to generate large synthetic parallel data.\nIn this work, we propose a new method to generate large synthetic parallel data\nleveraging very small monolingual data in a specific domain. We fine-tune a\npre-trained GPT-2 model on such small in-domain monolingual data and use the\nresulting model to generate a large amount of synthetic in-domain monolingual\ndata. Then, we perform back-translation, or forward translation, to generate\nsynthetic in-domain parallel data. Our preliminary experiments on three\nlanguage pairs and five domains show the effectiveness of our method to\ngenerate fully synthetic but useful in-domain parallel data for improving NMT\nin all configurations. We also show promising results in extreme adaptation for\npersonalized NMT.", "published": "2021-01-29 08:17:40", "link": "http://arxiv.org/abs/2101.12462v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "CD2CR: Co-reference Resolution Across Documents and Domains", "abstract": "Cross-document co-reference resolution (CDCR) is the task of identifying and\nlinking mentions to entities and concepts across many text documents. Current\nstate-of-the-art models for this task assume that all documents are of the same\ntype (e.g. news articles) or fall under the same theme. However, it is also\ndesirable to perform CDCR across different domains (type or theme). A\nparticular use case we focus on in this paper is the resolution of entities\nmentioned across scientific work and newspaper articles that discuss them.\nIdentifying the same entities and corresponding concepts in both scientific\narticles and news can help scientists understand how their work is represented\nin mainstream media. We propose a new task and English language dataset for\ncross-document cross-domain co-reference resolution (CD$^2$CR). The task aims\nto identify links between entities across heterogeneous document types. We show\nthat in this cross-domain, cross-document setting, existing CDCR models do not\nperform well and we provide a baseline model that outperforms current\nstate-of-the-art CDCR models on CD$^2$CR. Our data set, annotation tool and\nguidelines as well as our model for cross-document cross-domain co-reference\nare all supplied as open access open source resources.", "published": "2021-01-29 15:18:30", "link": "http://arxiv.org/abs/2101.12637v1", "categories": ["cs.CL", "I.2.7"], "primary_category": "cs.CL"}
{"title": "Challenges in Automated Debiasing for Toxic Language Detection", "abstract": "Biased associations have been a challenge in the development of classifiers\nfor detecting toxic language, hindering both fairness and accuracy. As\npotential solutions, we investigate recently introduced debiasing methods for\ntext classification datasets and models, as applied to toxic language\ndetection. Our focus is on lexical (e.g., swear words, slurs, identity\nmentions) and dialectal markers (specifically African American English). Our\ncomprehensive experiments establish that existing methods are limited in their\nability to prevent biased behavior in current toxicity detectors. We then\npropose an automatic, dialect-aware data correction method, as a\nproof-of-concept. Despite the use of synthetic labels, this method reduces\ndialectal associations with toxicity. Overall, our findings show that debiasing\na model trained on biased toxic language data is not as effective as simply\nrelabeling the data to remove existing biases.", "published": "2021-01-29 22:03:17", "link": "http://arxiv.org/abs/2102.00086v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fine-tuning BERT-based models for Plant Health Bulletin Classification", "abstract": "In the era of digitization, different actors in agriculture produce numerous\ndata. Such data contains already latent historical knowledge in the domain.\nThis knowledge enables us to precisely study natural hazards within global or\nlocal aspects, and then improve the risk prevention tasks and augment the\nyield, which helps to tackle the challenge of growing population and changing\nalimentary habits. In particular, French Plants Health Bulletins (BSV, for its\nname in French Bulletin de Sant{\\'e} du V{\\'e}g{\\'e}tal) give information about\nthe development stages of phytosanitary risks in agricultural production.\nHowever, they are written in natural language, thus, machines and human cannot\nexploit them as efficiently as it could be. Natural language processing (NLP)\ntechnologies aim to automatically process and analyze large amounts of natural\nlanguage data. Since the 2010s, with the increases in computational power and\nparallelization, representation learning and deep learning methods became\nwidespread in NLP. Recent advancements Bidirectional Encoder Representations\nfrom Transformers (BERT) inspire us to rethink of knowledge representation and\nnatural language understanding in plant health management domain. The goal in\nthis work is to propose a BERT-based approach to automatically classify the BSV\nto make their data easily indexable. We sampled 200 BSV to finetune the\npretrained BERT language models and classify them as pest or/and disease and we\nshow preliminary results.", "published": "2021-01-29 08:14:35", "link": "http://arxiv.org/abs/2102.00838v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fairness for Whom? Understanding the Reader's Perception of Fairness in\n  Text Summarization", "abstract": "With the surge in user-generated textual information, there has been a recent\nincrease in the use of summarization algorithms for providing an overview of\nthe extensive content. Traditional metrics for evaluation of these algorithms\n(e.g. ROUGE scores) rely on matching algorithmic summaries to human-generated\nones. However, it has been shown that when the textual contents are\nheterogeneous, e.g., when they come from different socially salient groups,\nmost existing summarization algorithms represent the social groups very\ndifferently compared to their distribution in the original data. To mitigate\nsuch adverse impacts, some fairness-preserving summarization algorithms have\nalso been proposed. All of these studies have considered normative notions of\nfairness from the perspective of writers of the contents, neglecting the\nreaders' perceptions of the underlying fairness notions. To bridge this gap, in\nthis work, we study the interplay between the fairness notions and how readers\nperceive them in textual summaries. Through our experiments, we show that\nreader's perception of fairness is often context-sensitive. Moreover, standard\nROUGE evaluation metrics are unable to quantify the perceived (un)fairness of\nthe summaries. To this end, we propose a human-in-the-loop metric and an\nautomated graph-based methodology to quantify the perceived bias in textual\nsummaries. We demonstrate their utility by quantifying the (un)fairness of\nseveral summaries of heterogeneous socio-political microblog datasets.", "published": "2021-01-29 05:14:34", "link": "http://arxiv.org/abs/2101.12406v2", "categories": ["cs.IR", "cs.CL"], "primary_category": "cs.IR"}
{"title": "Does injecting linguistic structure into language models lead to better\n  alignment with brain recordings?", "abstract": "Neuroscientists evaluate deep neural networks for natural language processing\nas possible candidate models for how language is processed in the brain. These\nmodels are often trained without explicit linguistic supervision, but have been\nshown to learn some linguistic structure in the absence of such supervision\n(Manning et al., 2020), potentially questioning the relevance of symbolic\nlinguistic theories in modeling such cognitive processes (Warstadt and Bowman,\n2020). We evaluate across two fMRI datasets whether language models align\nbetter with brain recordings, if their attention is biased by annotations from\nsyntactic or semantic formalisms. Using structure from dependency or minimal\nrecursion semantic annotations, we find alignments improve significantly for\none of the datasets. For another dataset, we see more mixed results. We present\nan extensive analysis of these results. Our proposed approach enables the\nevaluation of more targeted hypotheses about the composition of meaning in the\nbrain, expanding the range of possible scientific inferences a neuroscientist\ncould make, and opens up new opportunities for cross-pollination between\ncomputational neuroscience and linguistics.", "published": "2021-01-29 14:42:02", "link": "http://arxiv.org/abs/2101.12608v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Enhancing the Transformer Decoder with Transition-based Syntax", "abstract": "Notwithstanding recent advances, syntactic generalization remains a challenge\nfor text decoders. While some studies showed gains from incorporating\nsource-side symbolic syntactic and semantic structure into text generation\nTransformers, very little work addressed the decoding of such structure. We\npropose a general approach for tree decoding using a transition-based approach.\nExamining the challenging test case of incorporating Universal Dependencies\nsyntax into machine translation, we present substantial improvements on test\nsets that focus on syntactic generalization, while presenting improved or\ncomparable performance on standard MT benchmarks. Further qualitative analysis\naddresses cases where syntactic generalization in the vanilla Transformer\ndecoder is inadequate and demonstrates the advantages afforded by integrating\nsyntactic information.", "published": "2021-01-29 15:20:45", "link": "http://arxiv.org/abs/2101.12640v4", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "NLPBK at VLSP-2020 shared task: Compose transformer pretrained models\n  for Reliable Intelligence Identification on Social network", "abstract": "This paper describes our method for tuning a transformer-based pretrained\nmodel, to adaptation with Reliable Intelligence Identification on Vietnamese\nSNSs problem. We also proposed a model that combines bert-base pretrained\nmodels with some metadata features, such as the number of comments, number of\nlikes, images of SNS documents,... to improved results for VLSP shared task:\nReliable Intelligence Identification on Vietnamese SNSs. With appropriate\ntraining techniques, our model is able to achieve 0.9392 ROC-AUC on public test\nset and the final version settles at top 2 ROC-AUC (0.9513) on private test\nset.", "published": "2021-01-29 16:19:28", "link": "http://arxiv.org/abs/2101.12672v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "BCN2BRNO: ASR System Fusion for Albayzin 2020 Speech to Text Challenge", "abstract": "This paper describes joint effort of BUT and Telef\\'onica Research on\ndevelopment of Automatic Speech Recognition systems for Albayzin 2020\nChallenge. We compare approaches based on either hybrid or end-to-end models.\nIn hybrid modelling, we explore the impact of SpecAugment layer on performance.\nFor end-to-end modelling, we used a convolutional neural network with gated\nlinear units (GLUs). The performance of such model is also evaluated with an\nadditional n-gram language model to improve word error rates. We further\ninspect source separation methods to extract speech from noisy environment\n(i.e. TV shows). More precisely, we assess the effect of using a neural-based\nmusic separator named Demucs. A fusion of our best systems achieved 23.33% WER\nin official Albayzin 2020 evaluations. Aside from techniques used in our final\nsubmitted systems, we also describe our efforts in retrieving high quality\ntranscripts for training.", "published": "2021-01-29 18:40:54", "link": "http://arxiv.org/abs/2101.12729v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "Speech Enhancement for Wake-Up-Word detection in Voice Assistants", "abstract": "Keyword spotting and in particular Wake-Up-Word (WUW) detection is a very\nimportant task for voice assistants. A very common issue of voice assistants is\nthat they get easily activated by background noise like music, TV or background\nspeech that accidentally triggers the device. In this paper, we propose a\nSpeech Enhancement (SE) model adapted to the task of WUW detection that aims at\nincreasing the recognition rate and reducing the false alarms in the presence\nof these types of noises. The SE model is a fully-convolutional denoising\nauto-encoder at waveform level and is trained using a log-Mel Spectrogram and\nwaveform reconstruction losses together with the BCE loss of a simple WUW\nclassification network. A new database has been purposely prepared for the task\nof recognizing the WUW in challenging conditions containing negative samples\nthat are very phonetically similar to the keyword. The database is extended\nwith public databases and an exhaustive data augmentation to simulate different\nnoises and environments. The results obtained by concatenating the SE with a\nsimple and state-of-the-art WUW detectors show that the SE does not have a\nnegative impact on the recognition rate in quiet environments while increasing\nthe performance in the presence of noise, especially when the SE and WUW\ndetector are trained jointly end-to-end.", "published": "2021-01-29 18:44:05", "link": "http://arxiv.org/abs/2101.12732v1", "categories": ["eess.AS", "cs.CL"], "primary_category": "eess.AS"}
{"title": "N-grams Bayesian Differential Privacy", "abstract": "Differential privacy has gained popularity in machine learning as a strong\nprivacy guarantee, in contrast to privacy mitigation techniques such as\nk-anonymity. However, applying differential privacy to n-gram counts\nsignificantly degrades the utility of derived language models due to their\nlarge vocabularies. We propose a differential privacy mechanism that uses\npublic data as a prior in a Bayesian setup to provide tighter bounds on the\nprivacy loss metric epsilon, and thus better privacy-utility trade-offs. It\nfirst transforms the counts to log space, approximating the distribution of the\npublic and private data as Gaussian. The posterior distribution is then\nevaluated and softmax is applied to produce a probability distribution. This\ntechnique achieves up to 85% reduction in KL divergence compared to previously\nknown mechanisms at epsilon equals 0.1. We compare our mechanism to k-anonymity\nin a n-gram language modelling task and show that it offers competitive\nperformance at large vocabulary sizes, while also providing superior privacy\nprotection.", "published": "2021-01-29 18:48:49", "link": "http://arxiv.org/abs/2101.12736v1", "categories": ["cs.CR", "cs.CL"], "primary_category": "cs.CR"}
{"title": "ADePT: Auto-encoder based Differentially Private Text Transformation", "abstract": "Privacy is an important concern when building statistical models on data\ncontaining personal information. Differential privacy offers a strong\ndefinition of privacy and can be used to solve several privacy concerns (Dwork\net al., 2014). Multiple solutions have been proposed for the\ndifferentially-private transformation of datasets containing sensitive\ninformation. However, such transformation algorithms offer poor utility in\nNatural Language Processing (NLP) tasks due to noise added in the process. In\nthis paper, we address this issue by providing a utility-preserving\ndifferentially private text transformation algorithm using auto-encoders. Our\nalgorithm transforms text to offer robustness against attacks and produces\ntransformations with high semantic quality that perform well on downstream NLP\ntasks. We prove the theoretical privacy guarantee of our algorithm and assess\nits privacy leakage under Membership Inference Attacks(MIA) (Shokri et al.,\n2017) on models trained with transformed data. Our results show that the\nproposed model performs better against MIA attacks while offering lower to no\ndegradation in the utility of the underlying transformation process compared to\nexisting baselines.", "published": "2021-01-29 23:15:24", "link": "http://arxiv.org/abs/2102.01502v1", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
