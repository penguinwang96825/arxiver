{"title": "Massively Multilingual Word Embeddings", "abstract": "We introduce new methods for estimating and evaluating embeddings of words in\nmore than fifty languages in a single shared embedding space. Our estimation\nmethods, multiCluster and multiCCA, use dictionaries and monolingual data; they\ndo not require parallel data. Our new evaluation method, multiQVEC-CCA, is\nshown to correlate better than previous ones with two downstream tasks (text\ncategorization and parsing). We also describe a web portal for evaluation that\nwill facilitate further research in this area, along with open-source releases\nof all our methods.", "published": "2016-02-05 04:26:38", "link": "http://arxiv.org/abs/1602.01925v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Fantastic 4 system for NIST 2015 Language Recognition Evaluation", "abstract": "This article describes the systems jointly submitted by Institute for\nInfocomm (I$^2$R), the Laboratoire d'Informatique de l'Universit\\'e du Maine\n(LIUM), Nanyang Technology University (NTU) and the University of Eastern\nFinland (UEF) for 2015 NIST Language Recognition Evaluation (LRE). The\nsubmitted system is a fusion of nine sub-systems based on i-vectors extracted\nfrom different types of features. Given the i-vectors, several classifiers are\nadopted for the language detection task including support vector machines\n(SVM), multi-class logistic regression (MCLR), Probabilistic Linear\nDiscriminant Analysis (PLDA) and Deep Neural Networks (DNN).", "published": "2016-02-05 06:02:51", "link": "http://arxiv.org/abs/1602.01929v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Utiliza\u00e7\u00e3o de Grafos e Matriz de Similaridade na Sumariza\u00e7\u00e3o\n  Autom\u00e1tica de Documentos Baseada em Extra\u00e7\u00e3o de Frases", "abstract": "The internet increased the amount of information available. However, the\nreading and understanding of this information are costly tasks. In this\nscenario, the Natural Language Processing (NLP) applications enable very\nimportant solutions, highlighting the Automatic Text Summarization (ATS), which\nproduce a summary from one or more source texts. Automatically summarizing one\nor more texts, however, is a complex task because of the difficulties inherent\nto the analysis and generation of this summary. This master's thesis describes\nthe main techniques and methodologies (NLP and heuristics) to generate\nsummaries. We have also addressed and proposed some heuristics based on graphs\nand similarity matrix to measure the relevance of judgments and to generate\nsummaries by extracting sentences. We used the multiple languages (English,\nFrench and Spanish), CSTNews (Brazilian Portuguese), RPM (French) and DECODA\n(French) corpus to evaluate the developped systems. The results obtained were\nquite interesting.", "published": "2016-02-05 14:54:57", "link": "http://arxiv.org/abs/1602.02047v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "Harmonic Grammar in a DisCo Model of Meaning", "abstract": "The model of cognition developed in (Smolensky and Legendre, 2006) seeks to\nunify two levels of description of the cognitive process: the connectionist and\nthe symbolic. The theory developed brings together these two levels into the\nIntegrated Connectionist/Symbolic Cognitive architecture (ICS). Clark and\nPulman (2007) draw a parallel with semantics where meaning may be modelled on\nboth distributional and symbolic levels, developed by Coecke et al, 2010 into\nthe Distributional Compositional (DisCo) model of meaning. In the current work,\nwe revisit Smolensky and Legendre (S&L)'s model. We describe the DisCo\nframework, summarise the key ideas in S&L's architecture, and describe how\ntheir description of harmony as a graded measure of grammaticality may be\napplied in the DisCo model.", "published": "2016-02-05 16:40:44", "link": "http://arxiv.org/abs/1602.02089v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Mining Software Quality from Software Reviews: Research Trends and Open\n  Issues", "abstract": "Software review text fragments have considerably valuable information about\nusers experience. It includes a huge set of properties including the software\nquality. Opinion mining or sentiment analysis is concerned with analyzing\ntextual user judgments. The application of sentiment analysis on software\nreviews can find a quantitative value that represents software quality.\nAlthough many software quality methods are proposed they are considered\ndifficult to customize and many of them are limited. This article investigates\nthe application of opinion mining as an approach to extract software quality\nproperties. We found that the major issues of software reviews mining using\nsentiment analysis are due to software lifecycle and the diverse users and\nteams.", "published": "2016-02-05 19:42:24", "link": "http://arxiv.org/abs/1602.02133v1", "categories": ["cs.CL", "cs.IR"], "primary_category": "cs.CL"}
{"title": "How scientific literature has been evolving over the time? A novel\n  statistical approach using tracking verbal-based methods", "abstract": "This paper provides a global vision of the scientific publications related\nwith the Systemic Lupus Erythematosus (SLE), taking as starting point abstracts\nof articles. Through the time, abstracts have been evolving towards higher\ncomplexity on used terminology, which makes necessary the use of sophisticated\nstatistical methods and answering questions including: how vocabulary is\nevolving through the time? Which ones are most influential articles? And which\none are the articles that introduced new terms and vocabulary? To answer these,\nwe analyze a dataset composed by 506 abstracts and downloaded from 115\ndifferent journals and cover a 18 year-period.", "published": "2016-02-05 17:59:55", "link": "http://arxiv.org/abs/1607.07788v1", "categories": ["cs.CL", "cs.DL"], "primary_category": "cs.CL"}
{"title": "Generate Image Descriptions based on Deep RNN and Memory Cells for\n  Images Features", "abstract": "Generating natural language descriptions for images is a challenging task.\nThe traditional way is to use the convolutional neural network (CNN) to extract\nimage features, followed by recurrent neural network (RNN) to generate\nsentences. In this paper, we present a new model that added memory cells to\ngate the feeding of image features to the deep neural network. The intuition is\nenabling our model to memorize how much information from images should be fed\nat each stage of the RNN. Experiments on Flickr8K and Flickr30K datasets showed\nthat our model outperforms other state-of-the-art models with higher BLEU\nscores.", "published": "2016-02-05 00:17:18", "link": "http://arxiv.org/abs/1602.01895v1", "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "cs.CV"}
{"title": "From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label\n  Classification", "abstract": "We propose sparsemax, a new activation function similar to the traditional\nsoftmax, but able to output sparse probabilities. After deriving its\nproperties, we show how its Jacobian can be efficiently computed, enabling its\nuse in a network trained with backpropagation. Then, we propose a new smooth\nand convex loss function which is the sparsemax analogue of the logistic loss.\nWe reveal an unexpected connection between this new loss and the Huber\nclassification loss. We obtain promising empirical results in multi-label\nclassification problems and in attention-based neural networks for natural\nlanguage inference. For the latter, we achieve a similar performance as the\ntraditional softmax, but with a selective, more compact, attention focus.", "published": "2016-02-05 15:49:02", "link": "http://arxiv.org/abs/1602.02068v2", "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "cs.CL"}
