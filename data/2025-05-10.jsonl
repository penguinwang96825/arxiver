{"title": "Utilizing LLMs to Investigate the Disputed Role of Evidence in Electronic Cigarette Health Policy Formation in Australia and the UK", "abstract": "Australia and the UK have developed contrasting approaches to the regulation\nof electronic cigarettes, with - broadly speaking - Australia adopting a\nrelatively restrictive approach and the UK adopting a more permissive approach.\nNotably, these divergent policies were developed from the same broad evidence\nbase. In this paper, to investigate differences in how the two jurisdictions\nmanage and present evidence, we developed and evaluated a Large Language\nModel-based sentence classifier to perform automated analyses of electronic\ncigarette-related policy documents drawn from official Australian and UK\nlegislative processes (109 documents in total). Specifically, we utilized GPT-4\nto automatically classify sentences based on whether they contained claims that\ne-cigarettes were broadly helpful or harmful for public health. Our LLM-based\nclassifier achieved an F-score of 0.9. Further, when applying the classifier to\nour entire sentence-level corpus, we found that Australian legislative\ndocuments show a much higher proportion of harmful statements, and a lower\nproportion of helpful statements compared to the expected values, with the\nopposite holding for the UK. In conclusion, this work utilized an LLM-based\napproach to provide evidence to support the contention that - drawing on the\nsame evidence base - Australian ENDS-related policy documents emphasize the\nharms associated with ENDS products and UK policy documents emphasize the\nbenefits. Further, our approach provides a starting point for using LLM-based\nmethods to investigate the complex relationship between evidence and health\npolicy formation.", "published": "2025-05-10 23:40:28", "link": "http://arxiv.org/abs/2505.06782v1", "categories": ["cs.CL", "cs.SI"], "primary_category": "cs.CL"}
{"title": "Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free", "abstract": "Gating mechanisms have been widely utilized, from early models like LSTMs and\nHighway Networks to recent state space models, linear attention, and also\nsoftmax attention. Yet, existing literature rarely examines the specific\neffects of gating. In this work, we conduct comprehensive experiments to\nsystematically investigate gating-augmented softmax attention variants.\nSpecifically, we perform a comprehensive comparison over 30 variants of 15B\nMixture-of-Experts (MoE) models and 1.7B dense models trained on a 3.5 trillion\ntoken dataset. Our central finding is that a simple modification-applying a\nhead-specific sigmoid gate after the Scaled Dot-Product Attention\n(SDPA)-consistently improves performance. This modification also enhances\ntraining stability, tolerates larger learning rates, and improves scaling\nproperties. By comparing various gating positions and computational variants,\nwe attribute this effectiveness to two key factors: (1) introducing\nnon-linearity upon the low-rank mapping in the softmax attention, and (2)\napplying query-dependent sparse gating scores to modulate the SDPA output.\nNotably, we find this sparse gating mechanism mitigates 'attention sink' and\nenhances long-context extrapolation performance, and we also release related\n$\\href{https://github.com/qiuzh20/gated_attention}{codes}$ and\n$\\href{https://huggingface.co/QwQZh/gated_attention}{models}$ to facilitate\nfuture research.", "published": "2025-05-10 17:15:49", "link": "http://arxiv.org/abs/2505.06708v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "From Rankings to Insights: Evaluation Should Shift Focus from Leaderboard to Feedback", "abstract": "Automatic evaluation benchmarks such as MT-Bench, Arena-Hard, and Auto-Arena\nare seeing growing adoption for the evaluation of Large Language Models (LLMs).\nExisting research has primarily focused on approximating human-based model\nrankings using limited data and LLM-as-a-Judge. However, the fundamental\npremise of these studies, which attempts to replicate human rankings, is\nflawed. Specifically, these benchmarks typically offer only overall scores,\nlimiting their utility to leaderboard rankings, rather than providing feedback\nthat can guide model optimization and support model profiling. Therefore, we\nadvocate for an evaluation paradigm shift from approximating human-based model\nrankings to providing feedback with analytical value. To this end, we introduce\nFeedbacker, an evaluation framework that provides comprehensive and\nfine-grained results, thereby enabling thorough identification of a model's\nspecific strengths and weaknesses. Such feedback not only supports the targeted\noptimization of the model but also enhances the understanding of its behavior.\nFeedbacker comprises three key components: an extensible tree-based query\ntaxonomy builder, an automated query synthesis scheme, and a suite of\nvisualization and analysis tools. Furthermore, we propose a novel\nLLM-as-a-Judge method: PC2 (Pre-Comparison-derived Criteria) pointwise\nevaluation. This method derives evaluation criteria by pre-comparing the\ndifferences between several auxiliary responses, achieving the accuracy of\npairwise evaluation while maintaining the time complexity of pointwise\nevaluation. Finally, leveraging the evaluation results of 17 mainstream LLMs,\nwe demonstrate the usage of Feedbacker and highlight its effectiveness and\npotential. Our homepage project is available at\nhttps://liudan193.github.io/Feedbacker.", "published": "2025-05-10 16:52:40", "link": "http://arxiv.org/abs/2505.06698v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Enhancing BERTopic with Intermediate Layer Representations", "abstract": "BERTopic is a topic modeling algorithm that leverages transformer-based\nembeddings to create dense clusters, enabling the estimation of topic\nstructures and the extraction of valuable insights from a corpus of documents.\nThis approach allows users to efficiently process large-scale text data and\ngain meaningful insights into its structure. While BERTopic is a powerful tool,\nembedding preparation can vary, including extracting representations from\nintermediate model layers and applying transformations to these embeddings. In\nthis study, we evaluate 18 different embedding representations and present\nfindings based on experiments conducted on three diverse datasets. To assess\nthe algorithm's performance, we report topic coherence and topic diversity\nmetrics across all experiments. Our results demonstrate that, for each dataset,\nit is possible to find an embedding configuration that performs better than the\ndefault setting of BERTopic. Additionally, we investigate the influence of stop\nwords on different embedding configurations.", "published": "2025-05-10 16:47:08", "link": "http://arxiv.org/abs/2505.06696v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "TS-SUPERB: A Target Speech Processing Benchmark for Speech Self-Supervised Learning Models", "abstract": "Self-supervised learning (SSL) models have significantly advanced speech\nprocessing tasks, and several benchmarks have been proposed to validate their\neffectiveness. However, previous benchmarks have primarily focused on\nsingle-speaker scenarios, with less exploration of target-speaker tasks in\nnoisy, multi-talker conditions -- a more challenging yet practical case. In\nthis paper, we introduce the Target-Speaker Speech Processing Universal\nPerformance Benchmark (TS-SUPERB), which includes four widely recognized\ntarget-speaker processing tasks that require identifying the target speaker and\nextracting information from the speech mixture. In our benchmark, the speaker\nembedding extracted from enrollment speech is used as a clue to condition\ndownstream models. The benchmark result reveals the importance of evaluating\nSSL models in target speaker scenarios, demonstrating that performance cannot\nbe easily inferred from related single-speaker tasks. Moreover, by using a\nunified SSL-based target speech encoder, consisting of a speaker encoder and an\nextractor module, we also investigate joint optimization across TS tasks to\nleverage mutual information and demonstrate its effectiveness.", "published": "2025-05-10 14:23:37", "link": "http://arxiv.org/abs/2505.06660v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Improving Block-Wise LLM Quantization by 4-bit Block-Wise Optimal Float (BOF4): Analysis and Variations", "abstract": "Large language models (LLMs) demand extensive memory capacity during both\nfine-tuning and inference. To enable memory-efficient fine-tuning, existing\nmethods apply block-wise quantization techniques, such as NF4 and AF4, to the\nnetwork weights. We show that these quantization techniques incur suboptimal\nquantization errors. Therefore, as a first novelty, we propose an optimization\napproach for block-wise quantization. Using this method, we design a family of\nquantizers named 4-bit block-wise optimal float (BOF4), which consistently\nreduces the quantization error compared to both baseline methods. We provide\nboth a theoretical and a data-driven solution for the optimization process and\nprove their practical equivalence. Secondly, we propose a modification to the\nemployed normalization method based on the signed absolute block maximum\n(BOF4-S), enabling further reduction of the quantization error and empirically\nachieving less degradation in language modeling performance. Thirdly, we\nexplore additional variations of block-wise quantization methods applied to\nLLMs through an experimental study on the importance of accurately representing\nzero and large-amplitude weights on the one hand, and optimization towards\nvarious error metrics on the other hand. Lastly, we introduce a mixed-precision\nquantization strategy dubbed outlier-preserving quantization (OPQ) to address\nthe distributional mismatch induced by outlier weights in block-wise\nquantization. By storing outlier weights in 16-bit precision (OPQ) while\napplying BOF4-S, we achieve top performance among 4-bit block-wise quantization\ntechniques w.r.t. perplexity.", "published": "2025-05-10 14:00:15", "link": "http://arxiv.org/abs/2505.06653v1", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Attention Is Not All You Need: The Importance of Feedforward Networks in Transformer Models", "abstract": "Decoder-only transformer networks have become incredibly popular for language\nmodeling tasks. State-of-the-art models can have over a hundred transformer\nblocks, containing billions of trainable parameters, and are trained on\ntrillions of tokens of text. Each transformer block typically consists of a\nmulti-head attention (MHA) mechanism and a two-layer fully connected\nfeedforward network (FFN). In this paper, we examine the importance of the FFN\nduring the model pre-training process through a series of experiments,\nconfirming that the FFN is important to model performance. Furthermore, we show\nthat models using a transformer block configuration with three-layer FFNs with\nfewer such blocks outperform the standard two-layer configuration delivering\nlower training loss with fewer total parameters in less time.", "published": "2025-05-10 12:54:21", "link": "http://arxiv.org/abs/2505.06633v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Dynamic Domain Information Modulation Algorithm for Multi-domain Sentiment Analysis", "abstract": "Multi-domain sentiment classification aims to mitigate poor performance\nmodels due to the scarcity of labeled data in a single domain, by utilizing\ndata labeled from various domains. A series of models that jointly train domain\nclassifiers and sentiment classifiers have demonstrated their advantages,\nbecause domain classification helps generate necessary information for\nsentiment classification. Intuitively, the importance of sentiment\nclassification tasks is the same in all domains for multi-domain sentiment\nclassification; but domain classification tasks are different because the\nimpact of domain information on sentiment classification varies across\ndifferent fields; this can be controlled through adjustable weights or hyper\nparameters. However, as the number of domains increases, existing\nhyperparameter optimization algorithms may face the following challenges: (1)\ntremendous demand for computing resources, (2) convergence problems, and (3)\nhigh algorithm complexity. To efficiently generate the domain information\nrequired for sentiment classification in each domain, we propose a dynamic\ninformation modulation algorithm. Specifically, the model training process is\ndivided into two stages. In the first stage, a shared hyperparameter, which\nwould control the proportion of domain classification tasks across all fields,\nis determined. In the second stage, we introduce a novel domain-aware\nmodulation algorithm to adjust the domain information contained in the input\ntext, which is then calculated based on a gradient-based and loss-based method.\nIn summary, experimental results on a public sentiment analysis dataset\ncontaining 16 domains prove the superiority of the proposed method.", "published": "2025-05-10 12:36:00", "link": "http://arxiv.org/abs/2505.06630v1", "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "cs.CL"}
{"title": "The Efficiency of Pre-training with Objective Masking in Pseudo Labeling for Semi-Supervised Text Classification", "abstract": "We extend and study a semi-supervised model for text classification proposed\nearlier by Hatefi et al. for classification tasks in which document classes are\ndescribed by a small number of gold-labeled examples, while the majority of\ntraining examples is unlabeled. The model leverages the teacher-student\narchitecture of Meta Pseudo Labels in which a ''teacher'' generates labels for\noriginally unlabeled training data to train the ''student'' and updates its own\nmodel iteratively based on the performance of the student on the gold-labeled\nportion of the data. We extend the original model of Hatefi et al. by an\nunsupervised pre-training phase based on objective masking, and conduct\nin-depth performance evaluations of the original model, our extension, and\nvarious independent baselines. Experiments are performed using three different\ndatasets in two different languages (English and Swedish).", "published": "2025-05-10 12:16:03", "link": "http://arxiv.org/abs/2505.06624v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Boosting Neural Language Inference via Cascaded Interactive Reasoning", "abstract": "Natural Language Inference (NLI) focuses on ascertaining the logical\nrelationship (entailment, contradiction, or neutral) between a given premise\nand hypothesis. This task presents significant challenges due to inherent\nlinguistic features such as diverse phrasing, semantic complexity, and\ncontextual nuances. While Pre-trained Language Models (PLMs) built upon the\nTransformer architecture have yielded substantial advancements in NLI,\nprevailing methods predominantly utilize representations from the terminal\nlayer. This reliance on final-layer outputs may overlook valuable information\nencoded in intermediate layers, potentially limiting the capacity to model\nintricate semantic interactions effectively. Addressing this gap, we introduce\nthe Cascaded Interactive Reasoning Network (CIRN), a novel architecture\ndesigned for deeper semantic comprehension in NLI. CIRN implements a\nhierarchical feature extraction strategy across multiple network depths,\noperating within an interactive space where cross-sentence information is\ncontinuously integrated. This mechanism aims to mimic a process of progressive\nreasoning, transitioning from surface-level feature matching to uncovering more\nprofound logical and semantic connections between the premise and hypothesis.\nBy systematically mining latent semantic relationships at various\nrepresentational levels, CIRN facilitates a more thorough understanding of the\ninput pair. Comprehensive evaluations conducted on several standard NLI\nbenchmark datasets reveal consistent performance gains achieved by CIRN over\ncompetitive baseline approaches, demonstrating the efficacy of leveraging\nmulti-level interactive features for complex relational reasoning.", "published": "2025-05-10 11:37:15", "link": "http://arxiv.org/abs/2505.06607v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Using External knowledge to Enhanced PLM for Semantic Matching", "abstract": "Modeling semantic relevance has always been a challenging and critical task\nin natural language processing. In recent years, with the emergence of massive\namounts of annotated data, it has become feasible to train complex models, such\nas neural network-based reasoning models. These models have shown excellent\nperformance in practical applications and have achieved the current\nstate-ofthe-art performance. However, even with such large-scale annotated\ndata, we still need to think: Can machines learn all the knowledge necessary to\nperform semantic relevance detection tasks based on this data alone? If not,\nhow can neural network-based models incorporate external knowledge into\nthemselves, and how can relevance detection models be constructed to make full\nuse of external knowledge? In this paper, we use external knowledge to enhance\nthe pre-trained semantic relevance discrimination model. Experimental results\non 10 public datasets show that our method achieves consistent improvements in\nperformance compared to the baseline model.", "published": "2025-05-10 11:33:48", "link": "http://arxiv.org/abs/2505.06605v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Bridging the Gap: An Intermediate Language for Enhanced and Cost-Effective Grapheme-to-Phoneme Conversion with Homographs with Multiple Pronunciations Disambiguation", "abstract": "Grapheme-to-phoneme (G2P) conversion for Persian presents unique challenges\ndue to its complex phonological features, particularly homographs and Ezafe,\nwhich exist in formal and informal language contexts. This paper introduces an\nintermediate language specifically designed for Persian language processing\nthat addresses these challenges through a multi-faceted approach. Our\nmethodology combines two key components: Large Language Model (LLM) prompting\ntechniques and a specialized sequence-to-sequence machine transliteration\narchitecture. We developed and implemented a systematic approach for\nconstructing a comprehensive lexical database for homographs with multiple\npronunciations disambiguation often termed polyphones, utilizing formal concept\nanalysis for semantic differentiation. We train our model using two distinct\ndatasets: the LLM-generated dataset for formal and informal Persian and the\nB-Plus podcasts for informal language variants. The experimental results\ndemonstrate superior performance compared to existing state-of-the-art\napproaches, particularly in handling the complexities of Persian phoneme\nconversion. Our model significantly improves Phoneme Error Rate (PER) metrics,\nestablishing a new benchmark for Persian G2P conversion accuracy. This work\ncontributes to the growing research in low-resource language processing and\nprovides a robust solution for Persian text-to-speech systems and demonstrating\nits applicability beyond Persian. Specifically, the approach can extend to\nlanguages with rich homographic phenomena such as Chinese and Arabic", "published": "2025-05-10 11:10:48", "link": "http://arxiv.org/abs/2505.06599v1", "categories": ["cs.CL", "I.2.7; I.2.6"], "primary_category": "cs.CL"}
{"title": "Integrating Video and Text: A Balanced Approach to Multimodal Summary Generation and Evaluation", "abstract": "Vision-Language Models (VLMs) often struggle to balance visual and textual\ninformation when summarizing complex multimodal inputs, such as entire TV show\nepisodes. In this paper, we propose a zero-shot video-to-text summarization\napproach that builds its own screenplay representation of an episode,\neffectively integrating key video moments, dialogue, and character information\ninto a unified document. Unlike previous approaches, we simultaneously generate\nscreenplays and name the characters in zero-shot, using only the audio, video,\nand transcripts as input. Additionally, we highlight that existing\nsummarization metrics can fail to assess the multimodal content in summaries.\nTo address this, we introduce MFactSum, a multimodal metric that evaluates\nsummaries with respect to both vision and text modalities. Using MFactSum, we\nevaluate our screenplay summaries on the SummScreen3D dataset, demonstrating\nsuperiority against state-of-the-art VLMs such as Gemini 1.5 by generating\nsummaries containing 20% more relevant visual information while requiring 75%\nless of the video as input.", "published": "2025-05-10 10:52:23", "link": "http://arxiv.org/abs/2505.06594v1", "categories": ["cs.CL", "cs.CV"], "primary_category": "cs.CL"}
{"title": "Evaluating LLM-Generated Q&A Test: a Student-Centered Study", "abstract": "This research prepares an automatic pipeline for generating reliable\nquestion-answer (Q&A) tests using AI chatbots. We automatically generated a\nGPT-4o-mini-based Q&A test for a Natural Language Processing course and\nevaluated its psychometric and perceived-quality metrics with students and\nexperts. A mixed-format IRT analysis showed that the generated items exhibit\nstrong discrimination and appropriate difficulty, while student and expert star\nratings reflect high overall quality. A uniform DIF check identified two items\nfor review. These findings demonstrate that LLM-generated assessments can match\nhuman-authored tests in psychometric performance and user satisfaction,\nillustrating a scalable approach to AI-assisted assessment development.", "published": "2025-05-10 10:47:23", "link": "http://arxiv.org/abs/2505.06591v1", "categories": ["cs.CL", "cs.HC"], "primary_category": "cs.CL"}
{"title": "MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG", "abstract": "Long-context (LC) Large Language Models (LLMs) combined with\nRetrieval-Augmented Generation (RAG) hold strong potential for complex\nmulti-hop and large-document tasks. However, existing RAG systems often suffer\nfrom imprecise retrieval, incomplete context coverage under constrained context\nwindows, and fragmented information caused by suboptimal context construction.\nWe introduce Multi-scale Adaptive Context RAG (MacRAG), a hierarchical\nretrieval framework that compresses and partitions documents into\ncoarse-to-fine granularities, then adaptively merges relevant contexts through\nchunk- and document-level expansions in real time. By starting from the\nfinest-level retrieval and progressively incorporating higher-level and broader\ncontext, MacRAG constructs effective query-specific long contexts, optimizing\nboth precision and coverage. Evaluations on the challenging LongBench\nexpansions of HotpotQA, 2WikiMultihopQA, and Musique confirm that MacRAG\nconsistently surpasses baseline RAG pipelines on single- and multi-step\ngeneration with Llama-3.1-8B, Gemini-1.5-pro, and GPT-4o. Our results establish\nMacRAG as an efficient, scalable solution for real-world long-context,\nmulti-hop reasoning. Our code is available at\nhttps://github.com/Leezekun/MacRAG.", "published": "2025-05-10 08:50:44", "link": "http://arxiv.org/abs/2505.06569v1", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "References Indeed Matter? Reference-Free Preference Optimization for Conversational Query Reformulation", "abstract": "Conversational query reformulation (CQR) has become indispensable for\nimproving retrieval in dialogue-based applications. However, existing\napproaches typically rely on reference passages for optimization, which are\nimpractical to acquire in real-world scenarios. To address this limitation, we\nintroduce a novel reference-free preference optimization framework DualReform\nthat generates pseudo reference passages from commonly-encountered\nconversational datasets containing only queries and responses. DualReform\nattains this goal through two key innovations: (1) response-based inference,\nwhere responses serve as proxies to infer pseudo reference passages, and (2)\nresponse refinement via the dual-role of CQR, where a CQR model refines\nresponses based on the shared objectives between response refinement and CQR.\nDespite not relying on reference passages, DualReform achieves 96.9--99.1% of\nthe retrieval accuracy attainable only with reference passages and surpasses\nthe state-of-the-art method by up to 31.6%.", "published": "2025-05-10 07:43:23", "link": "http://arxiv.org/abs/2505.06552v1", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "REFINE-AF: A Task-Agnostic Framework to Align Language Models via Self-Generated Instructions using Reinforcement Learning from Automated Feedback", "abstract": "Instruction-based Large Language Models (LLMs) have proven effective in\nnumerous few-shot or zero-shot Natural Language Processing (NLP) tasks.\nHowever, creating human-annotated instruction data is time-consuming,\nexpensive, and often limited in quantity and task diversity. Previous research\nendeavors have attempted to address this challenge by proposing frameworks\ncapable of generating instructions in a semi-automated and task-agnostic manner\ndirectly from the model itself. Many of these efforts have relied on large\nAPI-only parameter-based models such as GPT-3.5 (175B), which are expensive,\nand subject to limits on a number of queries. This paper explores the\nperformance of three open-source small LLMs such as LLaMA 2-7B, LLama 2-13B,\nand Mistral 7B, using a semi-automated framework, thereby reducing human\nintervention, effort, and cost required to generate an instruction dataset for\nfine-tuning LLMs. Furthermore, we demonstrate that incorporating a\nReinforcement Learning (RL) based training algorithm into this LLMs-based\nframework leads to further enhancements. Our evaluation of the dataset reveals\nthat these RL-based frameworks achieve a substantial improvements in 63-66% of\nthe tasks compared to previous approaches.", "published": "2025-05-10 07:23:19", "link": "http://arxiv.org/abs/2505.06548v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Think in Safety: Unveiling and Mitigating Safety Alignment Collapse in Multimodal Large Reasoning Model", "abstract": "The rapid development of multimodal large reasoning models (MLRMs) has\ndemonstrated broad application potential, yet their safety and reliability\nremain critical concerns that require systematic exploration. To address this\ngap, we conduct a comprehensive and systematic safety evaluation of 11 MLRMs\nacross 5 benchmarks and unveil prevalent safety degradation phenomena in most\nadvanced models. Moreover, our analysis reveals distinct safety patterns across\ndifferent benchmarks: significant safety degradation is observed across\njailbreak robustness benchmarks, whereas safety-awareness benchmarks\ndemonstrate less pronounced degradation. In particular, a long thought process\nin some scenarios even enhances safety performance. Therefore, it is a\npotential approach to addressing safety issues in MLRMs by leveraging the\nintrinsic reasoning capabilities of the model to detect unsafe intent. To\noperationalize this insight, we construct a multimodal tuning dataset that\nincorporates a safety-oriented thought process. Experimental results from\nfine-tuning existing MLRMs with this dataset effectively enhances the safety on\nboth jailbreak robustness and safety-awareness benchmarks. This study provides\na new perspective for developing safe MLRMs. Our dataset is available at\nhttps://github.com/xinyuelou/Think-in-Safety.", "published": "2025-05-10 06:59:36", "link": "http://arxiv.org/abs/2505.06538v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "xGen-small Technical Report", "abstract": "We introduce xGen-small, a family of 4B and 9B Transformer decoder models\noptimized for long-context applications. Our vertically integrated pipeline\nunites domain-balanced, frequency-aware data curation; multi-stage pre-training\nwith quality annealing and length extension to 128k tokens; and targeted\npost-training via supervised fine-tuning, preference learning, and online\nreinforcement learning. xGen-small delivers strong performance across various\ntasks, especially in math and coding domains, while excelling at long context\nbenchmarks.", "published": "2025-05-10 02:54:16", "link": "http://arxiv.org/abs/2505.06496v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On Finding Randomly Planted Cliques in Arbitrary Graphs", "abstract": "We study a planted clique model introduced by Feige where a complete graph of\nsize $c\\cdot n$ is planted uniformly at random in an arbitrary $n$-vertex\ngraph. We give a simple deterministic algorithm that, in almost linear time,\nrecovers a clique of size $(c/3)^{O(1/c)} \\cdot n$ as long as the original\ngraph has maximum degree at most $(1-p)n$ for some fixed $p>0$. The proof\nhinges on showing that the degrees of the final graph are correlated with the\nplanted clique, in a way similar to (but more intricate than) the classical\n$G(n,\\frac{1}{2})+K_{\\sqrt{n}}$ planted clique model. Our algorithm suggests a\nseparation from the worst-case model, where, assuming the Unique Games\nConjecture, no polynomial algorithm can find cliques of size $\\Omega(n)$ for\nevery fixed $c>0$, even if the input graph has maximum degree $(1-p)n$. Our\ntechniques extend beyond the planted clique model. For example, when the\nplanted graph is a balanced biclique, we recover a balanced biclique of size\nlarger than the best guarantees known for the worst case.", "published": "2025-05-10 18:26:00", "link": "http://arxiv.org/abs/2505.06725v1", "categories": ["cs.CC", "cs.DM", "68W25", "F.2.2"], "primary_category": "cs.CC"}
{"title": "Burger: Robust Graph Denoising-augmentation Fusion and Multi-semantic Modeling in Social Recommendation", "abstract": "In the era of rapid development of social media, social recommendation\nsystems as hybrid recommendation systems have been widely applied. Existing\nmethods capture interest similarity between users to filter out\ninterest-irrelevant relations in social networks that inevitably decrease\nrecommendation accuracy, however, limited research has a focus on the mutual\ninfluence of semantic information between the social network and the user-item\ninteraction network for further improving social recommendation. To address\nthese issues, we introduce a social \\underline{r}ecommendation model with\nro\\underline{bu}st g\\underline{r}aph denoisin\\underline{g}-augmentation fusion\nand multi-s\\underline{e}mantic Modeling(Burger). Specifically, we firstly\npropose to construct a social tensor in order to smooth the training process of\nthe model. Then, a graph convolutional network and a tensor convolutional\nnetwork are employed to capture user's item preference and social preference,\nrespectively. Considering the different semantic information in the user-item\ninteraction network and the social network, a bi-semantic coordination loss is\nproposed to model the mutual influence of semantic information. To alleviate\nthe interference of interest-irrelevant relations on multi-semantic modeling,\nwe further use Bayesian posterior probability to mine potential social\nrelations to replace social noise. Finally, the sliding window mechanism is\nutilized to update the social tensor as the input for the next iteration.\nExtensive experiments on three real datasets show Burger has a superior\nperformance compared with the state-of-the-art models.", "published": "2025-05-10 11:51:22", "link": "http://arxiv.org/abs/2505.06612v1", "categories": ["cs.SI", "cs.AI", "cs.IR", "F.2.2; I.2.7"], "primary_category": "cs.SI"}
{"title": "Privacy-aware Berrut Approximated Coded Computing applied to general distributed learning", "abstract": "Coded computing is one of the techniques that can be used for privacy\nprotection in Federated Learning. However, most of the constructions used for\ncoded computing work only under the assumption that the computations involved\nare exact, generally restricted to special classes of functions, and require\nquantized inputs. This paper considers the use of Private Berrut Approximate\nCoded Computing (PBACC) as a general solution to add strong but non-perfect\nprivacy to federated learning. We derive new adapted PBACC algorithms for\ncentralized aggregation, secure distributed training with centralized data, and\nsecure decentralized training with decentralized data, thus enlarging\nsignificantly the applications of the method and the existing privacy\nprotection tools available for these paradigms. Particularly, PBACC can be used\nrobustly to attain privacy guarantees in decentralized federated learning for a\nvariety of models. Our numerical results show that the achievable quality of\ndifferent learning models (convolutional neural networks, variational\nautoencoders, and Cox regression) is minimally altered by using these new\ncomputing schemes, and that the privacy leakage can be bounded strictly to less\nthan a fraction of one bit per participant. Additionally, the computational\ncost of the encoding and decoding processes depends only of the degree of\ndecentralization of the data.", "published": "2025-05-10 21:27:40", "link": "http://arxiv.org/abs/2505.06759v1", "categories": ["cs.LG", "cs.CR", "cs.DC", "cs.IT", "math.IT"], "primary_category": "cs.LG"}
{"title": "JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes", "abstract": "Multi-agent reinforcement learning (MARL) has emerged as a promising solution\nfor learning complex and scalable coordination behaviors in multi-robot\nsystems. However, established MARL platforms (e.g., SMAC and MPE) lack robotics\nrelevance and hardware deployment, leaving multi-robot learning researchers to\ndevelop bespoke environments and hardware testbeds dedicated to the development\nand evaluation of their individual contributions. The Multi-Agent RL Benchmark\nand Learning Environment for the Robotarium (MARBLER) is an exciting recent\nstep in providing a standardized robotics-relevant platform for MARL, by\nbridging the Robotarium testbed with existing MARL software infrastructure.\nHowever, MARBLER lacks support for parallelization and GPU/TPU execution,\nmaking the platform prohibitively slow compared to modern MARL environments and\nhindering adoption. We contribute JaxRobotarium, a Jax-powered end-to-end\nsimulation, learning, deployment, and benchmarking platform for the Robotarium.\nJaxRobotarium enables rapid training and deployment of multi-robot\nreinforcement learning (MRRL) policies with realistic robot dynamics and safety\nconstraints, supporting both parallelization and hardware acceleration. Our\ngeneralizable learning interface provides an easy-to-use integration with SOTA\nMARL libraries (e.g., JaxMARL). In addition, JaxRobotarium includes eight\nstandardized coordination scenarios, including four novel scenarios that bring\nestablished MARL benchmark tasks (e.g., RWARE and Level-Based Foraging) to a\nrealistic robotics setting. We demonstrate that JaxRobotarium retains high\nsimulation fidelity while achieving dramatic speedups over baseline (20x in\ntraining and 150x in simulation), and provides an open-access sim-to-real\nevaluation pipeline through the Robotarium testbed, accelerating and\ndemocratizing access to multi-robot learning research and evaluation.", "published": "2025-05-10 22:38:39", "link": "http://arxiv.org/abs/2505.06771v1", "categories": ["cs.RO", "cs.LG", "cs.MA"], "primary_category": "cs.RO"}
{"title": "Learning Graph Representation of Agent Diffuser", "abstract": "Diffusion-based generative models have significantly advanced text-to-image\nsynthesis, demonstrating impressive text comprehension and zero-shot\ngeneralization. These models refine images from random noise based on textual\nprompts, with initial reliance on text input shifting towards enhanced visual\nfidelity over time. This transition suggests that static model parameters might\nnot optimally address the distinct phases of generation. We introduce LGR-AD\n(Learning Graph Representation of Agent Diffusers), a novel multi-agent system\ndesigned to improve adaptability in dynamic computer vision tasks. LGR-AD\nmodels the generation process as a distributed system of interacting agents,\neach representing an expert sub-model. These agents dynamically adapt to\nvarying conditions and collaborate through a graph neural network that encodes\ntheir relationships and performance metrics. Our approach employs a\ncoordination mechanism based on top-$k$ maximum spanning trees, optimizing the\ngeneration process. Each agent's decision-making is guided by a meta-model that\nminimizes a novel loss function, balancing accuracy and diversity. Theoretical\nanalysis and extensive empirical evaluations show that LGR-AD outperforms\ntraditional diffusion models across various benchmarks, highlighting its\npotential for scalable and flexible solutions in complex image generation\ntasks. Code is available at: https://github.com/YousIA/LGR_AD", "published": "2025-05-10 21:42:24", "link": "http://arxiv.org/abs/2505.06761v1", "categories": ["cs.LG", "cs.MA"], "primary_category": "cs.LG"}
{"title": "Emergent Multi-View Fidelity in Autonomous UAV Swarm Sport Injury Detection", "abstract": "Accurate, real-time collision detection is essential for ensuring player\nsafety and effective refereeing in high-contact sports such as rugby,\nparticularly given the severe risks associated with traumatic brain injuries\n(TBI). Traditional collision-monitoring methods employing fixed cameras or\nwearable sensors face limitations in visibility, coverage, and responsiveness.\nPreviously, we introduced a framework using unmanned aerial vehicles (UAVs) for\nmonitoring and real time kinematics extraction from videos of collision events.\nIn this paper, we show that the strategies operating on the objective of\nensuring at least one UAV captures every incident on the pitch have an emergent\nproperty of fulfilling a stronger key condition for successful kinematics\nextraction. Namely, they ensure that almost all collisions are captured by\nmultiple drones, establishing multi-view fidelity and redundancy, while not\nrequiring any drone-to-drone communication.", "published": "2025-05-10 10:31:24", "link": "http://arxiv.org/abs/2505.06588v1", "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY", "nlin.AO"], "primary_category": "cs.RO"}
{"title": "Regular mixed-radix DFT matrix factorization for in-place FFT accelerators", "abstract": "The generic vector memory based accelerator is considered which supports DIT\nand DIF FFT with fixed datapath. The regular mixed-radix factorization of the\nDFT matrix coherent with the accelerator architecture is proposed and the\ncorrection proof is presented. It allows better understanding of architecture\nrequirements and simplifies the developing and proving correctness of more\ncomplicated algorithms and conflict-free addressing schemes.", "published": "2025-05-10 18:35:18", "link": "http://arxiv.org/abs/2505.06728v1", "categories": ["cs.AR", "cs.DC", "cs.DS", "cs.NA", "math.NA", "B.2.4"], "primary_category": "cs.AR"}
{"title": "Tuning Butterworth filter's parameters in SPECT reconstructions via kernel-based Bayesian optimization with a no-reference image evaluation metric", "abstract": "In Single Photon Emission Computed Tomography (SPECT), the image\nreconstruction process involves many tunable parameters that have a significant\nimpact on the quality of the resulting clinical images. Traditional image\nquality evaluation often relies on expert judgment and full-reference metrics\nsuch as MSE and SSIM. However, these approaches are limited by their\nsubjectivity or the need for a ground-truth image. In this paper, we\ninvestigate the usage of a no-reference image quality assessment method\ntailored for SPECT imaging, employing the Perception-based Image QUality\nEvaluator (PIQUE) score. Precisely, we propose a novel application of PIQUE in\nevaluating SPECT images reconstructed via filtered backprojection using a\nparameter-dependent Butterworth filter. For the optimization of filter's\nparameters, we adopt a kernel-based Bayesian optimization framework grounded in\nreproducing kernel Hilbert space theory, highlighting the connections to recent\ngreedy approximation techniques. Experimental results in a concrete clinical\nsetting for SPECT imaging show the potential of this optimization approach for\nan objective and quantitative assessment of image quality, without requiring a\nreference image.", "published": "2025-05-10 16:35:28", "link": "http://arxiv.org/abs/2505.06692v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "A novel class of arbitrary high-order numerical schemes for fractional differential equations", "abstract": "A novel efficient and high accuracy numerical method for the time-fractional\ndifferential equations (TFDEs) is proposed in this work. We show the\nequivalence between TFDEs and the integer-order extended parametric\ndifferential equations (EPDE) by dimensional expanding, and establish the\nstability of EPDE. We apply BDF-$k$ formula for the temporal discretization,\nwhile we use the Jacobi spectral collocation method for the discretization of\nthe extended direction. We analyze the stability of the proposed method and\ngive rigorous error estimates with order $O(\\Delta t^{k} + M^{-m})$, where\n$\\Delta t$ and $M$ are time step size and number of collocation nodes in\nextended direction, respectively. Also, we point out that the computational\ncost and the storage requirement is essentially the same as the integer\nproblems, namely, the computational cost and the storage of the present\nalgorithm are $O(N)$ and $O(1)$, respectively, where $N$ is the total number of\ntime step. We present several numerical examples, including both linear and\nnonlinear problems, to demonstrate the effectiveness of the proposed method and\nto validate the theoretical results", "published": "2025-05-10 08:33:25", "link": "http://arxiv.org/abs/2505.06565v1", "categories": ["math.NA", "cs.NA"], "primary_category": "math.NA"}
{"title": "Out-of-Sample Embedding with Proximity Data: Projection versus Restricted Reconstruction", "abstract": "The problem of using proximity (similarity or dissimilarity) data for the\npurpose of \"adding a point to a vector diagram\" was first studied by J.C. Gower\nin 1968. Since then, a number of methods -- mostly kernel methods -- have been\nproposed for solving what has come to be called the problem of *out-of-sample\nembedding*. We survey the various kernel methods that we have encountered and\nshow that each can be derived from one or the other of two competing\nstrategies: *projection* or *restricted reconstruction*. Projection can be\nanalogized to a well-known formula for adding a point to a principal component\nanalysis. Restricted reconstruction poses a different challenge: how to best\napproximate redoing the entire multivariate analysis while holding fixed the\nvector diagram that was previously obtained. This strategy results in a\nnonlinear optimization problem that can be simplified to a unidimensional\nsearch. Various circumstances may warrant either projection or restricted\nreconstruction.", "published": "2025-05-10 21:11:30", "link": "http://arxiv.org/abs/2505.06756v1", "categories": ["stat.ML", "cs.LG", "stat.CO"], "primary_category": "stat.ML"}
{"title": "LineFlow: A Framework to Learn Active Control of Production Lines", "abstract": "Many production lines require active control mechanisms, such as adaptive\nrouting, worker reallocation, and rescheduling, to maintain optimal\nperformance. However, designing these control systems is challenging for\nvarious reasons, and while reinforcement learning (RL) has shown promise in\naddressing these challenges, a standardized and general framework is still\nlacking. In this work, we introduce LineFlow, an extensible, open-source Python\nframework for simulating production lines of arbitrary complexity and training\nRL agents to control them. To demonstrate the capabilities and to validate the\nunderlying theoretical assumptions of LineFlow, we formulate core subproblems\nof active line control in ways that facilitate mathematical analysis. For each\nproblem, we provide optimal solutions for comparison. We benchmark\nstate-of-the-art RL algorithms and show that the learned policies approach\noptimal performance in well-understood scenarios. However, for more complex,\nindustrial-scale production lines, RL still faces significant challenges,\nhighlighting the need for further research in areas such as reward shaping,\ncurriculum learning, and hierarchical control.", "published": "2025-05-10 19:36:18", "link": "http://arxiv.org/abs/2505.06744v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Beyond $\\tilde{O}(\\sqrt{T})$ Constraint Violation for Online Convex Optimization with Adversarial Constraints", "abstract": "We revisit the Online Convex Optimization problem with adversarial\nconstraints (COCO) where, in each round, a learner is presented with a convex\ncost function and a convex constraint function, both of which may be chosen\nadversarially. The learner selects actions from a convex decision set in an\nonline fashion, with the goal of minimizing both regret and the cumulative\nconstraint violation (CCV) over a horizon of $T$ rounds. The best-known policy\nfor this problem achieves $O(\\sqrt{T})$ regret and $\\tilde{O}(\\sqrt{T})$ CCV.\nIn this paper, we present a surprising improvement that achieves a\nsignificantly smaller CCV by trading it off with regret. Specifically, for any\nbounded convex cost and constraint functions, we propose an online policy that\nachieves $\\tilde{O}(\\sqrt{dT}+ T^\\beta)$ regret and $\\tilde{O}(dT^{1-\\beta})$\nCCV, where $d$ is the dimension of the decision set and $\\beta \\in [0,1]$ is a\ntunable parameter. We achieve this result by first considering the special case\nof $\\textsf{Constrained Expert}$ problem where the decision set is a\nprobability simplex and the cost and constraint functions are linear.\nLeveraging a new adaptive small-loss regret bound, we propose an efficient\npolicy for the $\\textsf{Constrained Expert}$ problem, that attains\n$O(\\sqrt{T\\ln N}+T^{\\beta})$ regret and $\\tilde{O}(T^{1-\\beta} \\ln N)$ CCV,\nwhere $N$ is the number of experts. The original problem is then reduced to the\n$\\textsf{Constrained Expert}$ problem via a covering argument. Finally, with an\nadditional smoothness assumption, we propose an efficient gradient-based policy\nattaining $O(T^{\\max(\\frac{1}{2},\\beta)})$ regret and $\\tilde{O}(T^{1-\\beta})$\nCCV.", "published": "2025-05-10 17:23:10", "link": "http://arxiv.org/abs/2505.06709v1", "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws", "abstract": "This paper formalizes an emerging learning paradigm that uses a trained model\nas a reference to guide and enhance the training of a target model through\nstrategic data selection or weighting, named $\\textbf{model steering}$. While\nad-hoc methods have been used in various contexts, including the training of\nlarge foundation models, its underlying principles remain insufficiently\nunderstood, leading to sub-optimal performance. In this work, we propose a\ntheory-driven framework for model steering called $\\textbf{DRRho risk\nminimization}$, which is rooted in Distributionally Robust Optimization (DRO).\nThrough a generalization analysis, we provide theoretical insights into why\nthis approach improves generalization and data efficiency compared to training\nwithout a reference model. To the best of our knowledge, this is the first time\nsuch theoretical insights are provided for the new learning paradigm, which\nsignificantly enhance our understanding and practice of model steering.\nBuilding on these insights and the connection between contrastive learning and\nDRO, we introduce a novel method for Contrastive Language-Image Pretraining\n(CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments\nvalidate the theoretical insights, reveal a superior scaling law compared to\nCLIP without a reference model, and demonstrate its strength over existing\nheuristic approaches.", "published": "2025-05-10 16:55:03", "link": "http://arxiv.org/abs/2505.06699v1", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Learning Guarantee of Reward Modeling Using Deep Neural Networks", "abstract": "In this work, we study the learning theory of reward modeling with pairwise\ncomparison data using deep neural networks. We establish a novel non-asymptotic\nregret bound for deep reward estimators in a non-parametric setting, which\ndepends explicitly on the network architecture. Furthermore, to underscore the\ncritical importance of clear human beliefs, we introduce a margin-type\ncondition that assumes the conditional winning probability of the optimal\naction in pairwise comparisons is significantly distanced from 1/2. This\ncondition enables a sharper regret bound, which substantiates the empirical\nefficiency of Reinforcement Learning from Human Feedback and highlights clear\nhuman beliefs in its success. Notably, this improvement stems from high-quality\npairwise comparison data implied by the margin-type condition, is independent\nof the specific estimators used, and thus applies to various learning\nalgorithms and models.", "published": "2025-05-10 11:21:29", "link": "http://arxiv.org/abs/2505.06601v1", "categories": ["stat.ML", "cs.LG"], "primary_category": "stat.ML"}
{"title": "Feature Representation Transferring to Lightweight Models via Perception Coherence", "abstract": "In this paper, we propose a method for transferring feature representation to\nlightweight student models from larger teacher models. We mathematically define\na new notion called \\textit{perception coherence}. Based on this notion, we\npropose a loss function, which takes into account the dissimilarities between\ndata points in feature space through their ranking. At a high level, by\nminimizing this loss function, the student model learns to mimic how the\nteacher model \\textit{perceives} inputs. More precisely, our method is\nmotivated by the fact that the representational capacity of the student model\nis weaker than the teacher model. Hence, we aim to develop a new method\nallowing for a better relaxation. This means that, the student model does not\nneed to preserve the absolute geometry of the teacher one, while preserving\nglobal coherence through dissimilarity ranking. Our theoretical insights\nprovide a probabilistic perspective on the process of feature representation\ntransfer. Our experiments results show that our method outperforms or achieves\non-par performance compared to strong baseline methods for representation\ntransferring.", "published": "2025-05-10 10:55:06", "link": "http://arxiv.org/abs/2505.06595v1", "categories": ["stat.ML", "cs.AI", "cs.CV", "cs.LG", "math.PR"], "primary_category": "stat.ML"}
{"title": "Optimal Transport for Machine Learners", "abstract": "Optimal Transport is a foundational mathematical theory that connects\noptimization, partial differential equations, and probability. It offers a\npowerful framework for comparing probability distributions and has recently\nbecome an important tool in machine learning, especially for designing and\nevaluating generative models. These course notes cover the fundamental\nmathematical aspects of OT, including the Monge and Kantorovich formulations,\nBrenier's theorem, the dual and dynamic formulations, the Bures metric on\nGaussian distributions, and gradient flows. It also introduces numerical\nmethods such as linear programming, semi-discrete solvers, and entropic\nregularization. Applications in machine learning include topics like training\nneural networks via gradient flows, token dynamics in transformers, and the\nstructure of GANs and diffusion models. These notes focus primarily on\nmathematical content rather than deep learning techniques.", "published": "2025-05-10 10:35:03", "link": "http://arxiv.org/abs/2505.06589v1", "categories": ["stat.ML", "cs.AI", "math.OC"], "primary_category": "stat.ML"}
{"title": "TAROT: Towards Essentially Domain-Invariant Robustness with Theoretical Justification", "abstract": "Robust domain adaptation against adversarial attacks is a critical research\narea that aims to develop models capable of maintaining consistent performance\nacross diverse and challenging domains. In this paper, we derive a new\ngeneralization bound for robust risk on the target domain using a novel\ndivergence measure specifically designed for robust domain adaptation. Building\nupon this, we propose a new algorithm named TAROT, which is designed to enhance\nboth domain adaptability and robustness. Through extensive experiments, TAROT\nnot only surpasses state-of-the-art methods in accuracy and robustness but also\nsignificantly enhances domain generalization and scalability by effectively\nlearning domain-invariant features. In particular, TAROT achieves superior\nperformance on the challenging DomainNet dataset, demonstrating its ability to\nlearn domain-invariant representations that generalize well across different\ndomains, including unseen ones. These results highlight the broader\napplicability of our approach in real-world domain adaptation scenarios.", "published": "2025-05-10 09:43:04", "link": "http://arxiv.org/abs/2505.06580v1", "categories": ["cs.AI", "stat.ML"], "primary_category": "cs.AI"}
{"title": "Good Things Come in Pairs: Paired Autoencoders for Inverse Problems", "abstract": "In this book chapter, we discuss recent advances in data-driven approaches\nfor inverse problems. In particular, we focus on the \\emph{paired autoencoder}\nframework, which has proven to be a powerful tool for solving inverse problems\nin scientific computing. The paired autoencoder framework is a novel approach\nthat leverages the strengths of both data-driven and model-based methods by\nprojecting both the data and the quantity of interest into a latent space and\nmapping these latent spaces to provide surrogate forward and inverse mappings.\nWe illustrate the advantages of this approach through numerical experiments,\nincluding seismic imaging and classical inpainting: nonlinear and linear\ninverse problems, respectively. Although the paired autoencoder framework is\nlikelihood-free, it generates multiple data- and model-based reconstruction\nmetrics that help assess whether examples are in or out of distribution. In\naddition to direct model estimates from data, the paired autoencoder enables\nlatent-space refinement to fit the observed data accurately. Numerical\nexperiments show that this procedure, combined with the latent-space initial\nguess, is essential for high-quality estimates, even when data noise exceeds\nthe training regime. We also introduce two novel variants that combine\nvariational and paired autoencoder ideas, maintaining the original benefits\nwhile enabling sampling for uncertainty analysis.", "published": "2025-05-10 07:31:09", "link": "http://arxiv.org/abs/2505.06549v1", "categories": ["cs.LG", "stat.ML", "68T99"], "primary_category": "cs.LG"}
{"title": "dcFCI: Robust Causal Discovery Under Latent Confounding, Unfaithfulness, and Mixed Data", "abstract": "Causal discovery is central to inferring causal relationships from\nobservational data. In the presence of latent confounding, algorithms such as\nFast Causal Inference (FCI) learn a Partial Ancestral Graph (PAG) representing\nthe true model's Markov Equivalence Class. However, their correctness\ncritically depends on empirical faithfulness, the assumption that observed\n(in)dependencies perfectly reflect those of the underlying causal model, which\noften fails in practice due to limited sample sizes. To address this, we\nintroduce the first nonparametric score to assess a PAG's compatibility with\nobserved data, even with mixed variable types. This score is both necessary and\nsufficient to characterize structural uncertainty and distinguish between\ndistinct PAGs. We then propose data-compatible FCI (dcFCI), the first hybrid\ncausal discovery algorithm to jointly address latent confounding, empirical\nunfaithfulness, and mixed data types. dcFCI integrates our score into an\n(Anytime)FCI-guided search that systematically explores, ranks, and validates\ncandidate PAGs. Experiments on synthetic and real-world scenarios demonstrate\nthat dcFCI significantly outperforms state-of-the-art methods, often recovering\nthe true PAG even in small and heterogeneous datasets. Examining top-ranked\nPAGs further provides valuable insights into structural uncertainty, supporting\nmore robust and informed causal reasoning and decision-making.", "published": "2025-05-10 07:05:19", "link": "http://arxiv.org/abs/2505.06542v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Online Feedback Efficient Active Target Discovery in Partially Observable Environments", "abstract": "In various scientific and engineering domains, where data acquisition is\ncostly, such as in medical imaging, environmental monitoring, or remote\nsensing, strategic sampling from unobserved regions, guided by prior\nobservations, is essential to maximize target discovery within a limited\nsampling budget. In this work, we introduce Diffusion-guided Active Target\nDiscovery (DiffATD), a novel method that leverages diffusion dynamics for\nactive target discovery. DiffATD maintains a belief distribution over each\nunobserved state in the environment, using this distribution to dynamically\nbalance exploration-exploitation. Exploration reduces uncertainty by sampling\nregions with the highest expected entropy, while exploitation targets areas\nwith the highest likelihood of discovering the target, indicated by the belief\ndistribution and an incrementally trained reward model designed to learn the\ncharacteristics of the target. DiffATD enables efficient target discovery in a\npartially observable environment within a fixed sampling budget, all without\nrelying on any prior supervised training. Furthermore, DiffATD offers\ninterpretability, unlike existing black-box policies that require extensive\nsupervised training. Through extensive experiments and ablation studies across\ndiverse domains, including medical imaging and remote sensing, we show that\nDiffATD performs significantly better than baselines and competitively with\nsupervised methods that operate under full environmental observability.", "published": "2025-05-10 06:50:01", "link": "http://arxiv.org/abs/2505.06535v1", "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "cs.AI"}
{"title": "High-Dimensional Importance-Weighted Information Criteria: Theory and Optimality", "abstract": "Imori and Ing (2025) proposed the importance-weighted orthogonal greedy\nalgorithm (IWOGA) for model selection in high-dimensional misspecified\nregression models under covariate shift. To determine the number of IWOGA\niterations, they introduced the high-dimensional importance-weighted\ninformation criterion (HDIWIC). They argued that the combined use of IWOGA and\nHDIWIC, IWOGA + HDIWIC, achieves an optimal trade-off between variance and\nsquared bias, leading to optimal convergence rates in terms of conditional mean\nsquared prediction error. In this article, we provide a theoretical\njustification for this claim by establishing the optimality of IWOGA + HDIWIC\nunder a set of reasonable assumptions.", "published": "2025-05-10 06:26:12", "link": "http://arxiv.org/abs/2505.06531v1", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "stat.ML"}
{"title": "Beyond Identity: A Generalizable Approach for Deepfake Audio Detection", "abstract": "Deepfake audio presents a growing threat to digital security, due to its\npotential for social engineering, fraud, and identity misuse. However, existing\ndetection models suffer from poor generalization across datasets, due to\nimplicit identity leakage, where models inadvertently learn speaker-specific\nfeatures instead of manipulation artifacts. To the best of our knowledge, this\nis the first study to explicitly analyze and address identity leakage in the\naudio deepfake detection domain. This work proposes an identity-independent\naudio deepfake detection framework that mitigates identity leakage by\nencouraging the model to focus on forgery-specific artifacts instead of\noverfitting to speaker traits. Our approach leverages Artifact Detection\nModules (ADMs) to isolate synthetic artifacts in both time and frequency\ndomains, enhancing cross-dataset generalization. We introduce novel dynamic\nartifact generation techniques, including frequency domain swaps, time domain\nmanipulations, and background noise augmentation, to enforce learning of\ndataset-invariant features. Extensive experiments conducted on ASVspoof2019,\nADD 2022, FoR, and In-The-Wild datasets demonstrate that the proposed\nADM-enhanced models achieve F1 scores of 0.230 (ADD 2022), 0.604 (FoR), and\n0.813 (In-The-Wild), consistently outperforming the baseline. Dynamic Frequency\nSwap proves to be the most effective strategy across diverse conditions. These\nfindings emphasize the value of artifact-based learning in mitigating implicit\nidentity leakage for more generalizable audio deepfake detection.", "published": "2025-05-10 22:03:07", "link": "http://arxiv.org/abs/2505.06766v1", "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "cs.SD"}
{"title": "RADE: A Neural Codec for Transmitting Speech over HF Radio Channels", "abstract": "Speech compression is commonly used to send voice over radio channels in\napplications such as mobile telephony and two-way push-to-talk (PTT) radio. In\nclassical systems, the speech codec is combined with forward error correction,\nmodulation and radio hardware. In this paper we describe an autoencoder that\nreplaces many of the traditional signal processing elements with a neural\nnetwork. The encoder takes a vocoder feature set (short term spectrum, pitch,\nvoicing), and produces discrete time, but continuously valued quadrature\namplitude modulation (QAM) symbols. We use orthogonal frequency domain\nmultiplexing (OFDM) to send and receive these symbols over high frequency (HF)\nradio channels. The decoder converts received QAM symbols to vocoder features\nsuitable for synthesis. The autoencoder has been trained to be robust to\nadditive Gaussian noise and multipath channel impairments while simultaneously\nmaintaining a Peak To Average Power Ratio (PAPR) of less than 1~dB. Over\nsimulated and real world HF radio channels we have achieved output speech\nintelligibility that clearly surpasses existing analog and digital radio\nsystems over a range of SNRs.", "published": "2025-05-10 15:16:05", "link": "http://arxiv.org/abs/2505.06671v1", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Short Overview of Multi-Modal Wi-Fi Sensing", "abstract": "Wi-Fi sensing has emerged as a significant technology in wireless sensing and\nIntegrated Sensing and Communication (ISAC), offering benefits such as low\ncost, high penetration, and enhanced privacy. Currently, it is widely utilized\nin various applications, including action recognition, human localization, and\ncrowd counting. However, Wi-Fi sensing also faces challenges, such as low\nrobustness and difficulties in data collection. Recently, there has been an\nincreasing focus on multi-modal Wi-Fi sensing, where other modalities can act\nas teachers, providing ground truth or robust features for Wi-Fi sensing models\nto learn from, or can be directly fused with Wi-Fi for enhanced sensing\ncapabilities. Although these methods have demonstrated promising results and\nsubstantial value in practical applications, there is a lack of comprehensive\nsurveys reviewing them. To address this gap, this paper reviews the multi-modal\nWi-Fi sensing literature \\textbf{from the past 24 months} and highlights the\ncurrent limitations, challenges and future directions in this field.", "published": "2025-05-10 16:12:56", "link": "http://arxiv.org/abs/2505.06682v1", "categories": ["eess.SP", "cs.AI"], "primary_category": "eess.SP"}
{"title": "Distributionally Robust Contract Theory for Edge AIGC Services in Teleoperation", "abstract": "Advanced AI-Generated Content (AIGC) technologies have injected new impetus\ninto teleoperation, further enhancing its security and efficiency. Edge AIGC\nnetworks have been introduced to meet the stringent low-latency requirements of\nteleoperation. However, the inherent uncertainty of AIGC service quality and\nthe need to incentivize AIGC service providers (ASPs) make the design of a\nrobust incentive mechanism essential. This design is particularly challenging\ndue to both uncertainty and information asymmetry, as teleoperators have\nlimited knowledge of the remaining resource capacities of ASPs. To this end, we\npropose a distributionally robust optimization (DRO)-based contract theory to\ndesign robust reward schemes for AIGC task offloading. Notably, our work\nextends the contract theory by integrating DRO, addressing the fundamental\nchallenge of contract design under uncertainty. In this paper, contract theory\nis employed to model the information asymmetry, while DRO is utilized to\ncapture the uncertainty in AIGC service quality. Given the inherent complexity\nof the original DRO-based contract theory problem, we reformulate it into an\nequivalent, tractable bi-level optimization problem. To efficiently solve this\nproblem, we develop a Block Coordinate Descent (BCD)-based algorithm to derive\nrobust reward schemes. Simulation results on our unity-based teleoperation\nplatform demonstrate that the proposed method improves teleoperator utility by\n2.7\\% to 10.74\\% under varying degrees of AIGC service quality shifts and\nincreases ASP utility by 60.02\\% compared to the SOTA method, i.e., Deep\nReinforcement Learning (DRL)-based contract theory. The code and data are\npublicly available at https://github.com/Zijun0819/DRO-Contract-Theory.", "published": "2025-05-10 15:53:05", "link": "http://arxiv.org/abs/2505.06678v1", "categories": ["cs.NI", "eess.SP"], "primary_category": "cs.NI"}
{"title": "Event-based Neural Spike Detection Using Spiking Neural Networks for Neuromorphic iBMI Systems", "abstract": "Implantable brain-machine interfaces (iBMIs) are evolving to record from\nthousands of neurons wirelessly but face challenges in data bandwidth, power\nconsumption, and implant size. We propose a novel Spiking Neural Network Spike\nDetector (SNN-SPD) that processes event-based neural data generated via delta\nmodulation and pulse count modulation, converting signals into sparse events.\nBy leveraging the temporal dynamics and inherent sparsity of spiking neural\nnetworks, our method improves spike detection performance while maintaining low\ncomputational overhead suitable for implantable devices. Our experimental\nresults demonstrate that the proposed SNN-SPD achieves an accuracy of 95.72% at\nhigh noise levels (standard deviation 0.2), which is about 2% higher than the\nexisting Artificial Neural Network Spike Detector (ANN-SPD). Moreover, SNN-SPD\nrequires only 0.41% of the computation and about 26.62% of the weight\nparameters compared to ANN-SPD, with zero multiplications. This approach\nbalances efficiency and performance, enabling effective data compression and\npower savings for next-generation iBMIs.", "published": "2025-05-10 07:07:00", "link": "http://arxiv.org/abs/2505.06544v1", "categories": ["eess.SP", "cs.NE"], "primary_category": "eess.SP"}
{"title": "Monopulse Parameter Estimation based on MIMO-STCA Radar in the Presence of Multiple Mainlobe Jammings", "abstract": "The monopulse technique is characterized by its high accuracy in angle\nestimation and simplicity in engineering implementation. However, in the\ncomplex electromagnetic environment, the presence of the mainlobe jamming (MLJ)\ngreatly degrades the accuracy of angle estimation. Conventional methods of\njamming suppression often lead to significant deviations in monopulse ratio\nwhile suppressing MLJ. Additionally, the monopulse technique based on\ntraditional radar cannot jointly estimate the target's range. In this paper,\nthe four-channel adaptive beamforming (ABF) algorithm is proposed, which adds a\ndelta-delta channel based on conventional sum-difference-difference\nthree-channel to suppress a single MLJ. Moreover, considering the suppression\nof multiple MLJs and sidelobe jammings (SLJs), the row-column ABF algorithm is\nproposed. This algorithm utilizes more spatial degrees of freedom (DOFs) to\nsuppress multiple jammings by the row-column adaptive beamforming at the\nsubarray level. The key ideal of both algorithms is to suppress MLJ with null\nalong one spatial direction while keeping the sum and difference beampatterns\nundistorted along another spatial direction. Therefore, the monopulse ratio\nremains undistorted while suppressing the MLJ, ensuring the accuracy of\nmonopulse parameter estimation. Furthermore, by utilizing the additional\ndegrees of freedom (DOFs) in the range domain provided by the multiple-input\nmultiple-output space-time coding array (MIMO-STCA) radar, joint angle-range\nestimation can be achieved through the monopulse technique. Simulation results\nhighlight the effectiveness of the proposed methods in suppressing multiple\nMLJs and enhancing the accuracy of monopulse parameter estimation, as verified\nby the low root mean square error (RMSE) in the parameter estimation results.", "published": "2025-05-10 02:45:47", "link": "http://arxiv.org/abs/2505.06495v1", "categories": ["eess.SP"], "primary_category": "eess.SP"}
{"title": "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws", "abstract": "This paper formalizes an emerging learning paradigm that uses a trained model\nas a reference to guide and enhance the training of a target model through\nstrategic data selection or weighting, named $\\textbf{model steering}$. While\nad-hoc methods have been used in various contexts, including the training of\nlarge foundation models, its underlying principles remain insufficiently\nunderstood, leading to sub-optimal performance. In this work, we propose a\ntheory-driven framework for model steering called $\\textbf{DRRho risk\nminimization}$, which is rooted in Distributionally Robust Optimization (DRO).\nThrough a generalization analysis, we provide theoretical insights into why\nthis approach improves generalization and data efficiency compared to training\nwithout a reference model. To the best of our knowledge, this is the first time\nsuch theoretical insights are provided for the new learning paradigm, which\nsignificantly enhance our understanding and practice of model steering.\nBuilding on these insights and the connection between contrastive learning and\nDRO, we introduce a novel method for Contrastive Language-Image Pretraining\n(CLIP) with a reference model, termed DRRho-CLIP. Extensive experiments\nvalidate the theoretical insights, reveal a superior scaling law compared to\nCLIP without a reference model, and demonstrate its strength over existing\nheuristic approaches.", "published": "2025-05-10 16:55:03", "link": "http://arxiv.org/abs/2505.06699v2", "categories": ["cs.LG", "stat.ML"], "primary_category": "cs.LG"}
{"title": "Development of a WAZOBIA-Named Entity Recognition System", "abstract": "Named Entity Recognition NER is very crucial for various natural language\nprocessing applications, including information extraction, machine translation,\nand sentiment analysis. Despite the ever-increasing interest in African\nlanguages within computational linguistics, existing NER systems focus mainly\non English, European, and a few other global languages, leaving a significant\ngap for under-resourced languages. This research presents the development of a\nWAZOBIA-NER system tailored for the three most prominent Nigerian languages:\nHausa, Yoruba, and Igbo. This research begins with a comprehensive compilation\nof annotated datasets for each language, addressing data scarcity and\nlinguistic diversity challenges. Exploring the state-of-the-art machine\nlearning technique, Conditional Random Fields (CRF) and deep learning models\nsuch as Bidirectional Long Short-Term Memory (BiLSTM), Bidirectional Encoder\nRepresentation from Transformers (Bert) and fine-tune with a Recurrent Neural\nNetwork (RNN), the study evaluates the effectiveness of these approaches in\nrecognizing three entities: persons, organizations, and locations. The system\nutilizes optical character recognition (OCR) technology to convert textual\nimages into machine-readable text, thereby enabling the Wazobia system to\naccept both input text and textual images for extraction purposes. The system\nachieved a performance of 0.9511 in precision, 0.9400 in recall, 0.9564 in\nF1-score, and 0.9301 in accuracy. The model's evaluation was conducted across\nthree languages, with precision, recall, F1-score, and accuracy as key\nassessment metrics. The Wazobia-NER system demonstrates that it is feasible to\nbuild robust NER tools for under-resourced African languages using current NLP\nframeworks and transfer learning.", "published": "2025-05-10 22:59:24", "link": "http://arxiv.org/abs/2505.07884v1", "categories": ["cs.CL", "cs.HC", "cs.IR", "cs.LG"], "primary_category": "cs.CL"}
{"title": "OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval", "abstract": "Vision-language retrieval-augmented generation (RAG) has become an effective\napproach for tackling Knowledge-Based Visual Question Answering (KB-VQA), which\nrequires external knowledge beyond the visual content presented in images. The\neffectiveness of Vision-language RAG systems hinges on multimodal retrieval,\nwhich is inherently challenging due to the diverse modalities and knowledge\ngranularities in both queries and knowledge bases. Existing methods have not\nfully tapped into the potential interplay between these elements. We propose a\nmultimodal RAG system featuring a coarse-to-fine, multi-step retrieval that\nharmonizes multiple granularities and modalities to enhance efficacy. Our\nsystem begins with a broad initial search aligning knowledge granularity for\ncross-modal retrieval, followed by a multimodal fusion reranking to capture the\nnuanced multimodal information for top entity selection. A text reranker then\nfilters out the most relevant fine-grained section for augmented generation.\nExtensive experiments on the InfoSeek and Encyclopedic-VQA benchmarks show our\nmethod achieves state-of-the-art retrieval performance and highly competitive\nanswering results, underscoring its effectiveness in advancing KB-VQA systems.", "published": "2025-05-10 14:24:41", "link": "http://arxiv.org/abs/2505.07879v1", "categories": ["cs.IR", "cs.AI", "cs.CV"], "primary_category": "cs.IR"}
