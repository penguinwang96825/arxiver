{"title": "Persona Extraction Through Semantic Similarity for Emotional Support\n  Conversation Generation", "abstract": "Providing emotional support through dialogue systems is becoming increasingly\nimportant in today's world, as it can support both mental health and social\ninteractions in many conversation scenarios. Previous works have shown that\nusing persona is effective for generating empathetic and supportive responses.\nThey have often relied on pre-provided persona rather than inferring them\nduring conversations. However, it is not always possible to obtain a user\npersona before the conversation begins. To address this challenge, we propose\nPESS (Persona Extraction through Semantic Similarity), a novel framework that\ncan automatically infer informative and consistent persona from dialogues. We\ndevise completeness loss and consistency loss based on semantic similarity\nscores. The completeness loss encourages the model to generate missing persona\ninformation, and the consistency loss guides the model to distinguish between\nconsistent and inconsistent persona. Our experimental results demonstrate that\nhigh-quality persona information inferred by PESS is effective in generating\nemotionally supportive responses.", "published": "2024-03-07 04:33:11", "link": "http://arxiv.org/abs/2403.04212v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Self-Evaluation of Large Language Model based on Glass-box Features", "abstract": "The proliferation of open-source Large Language Models (LLMs) underscores the\npressing need for evaluation methods. Existing works primarily rely on external\nevaluators, focusing on training and prompting strategies. However, a crucial\naspect, model-aware glass-box features, is overlooked. In this study, we\nexplore the utility of glass-box features under the scenario of\nself-evaluation, namely applying an LLM to evaluate its own output. We\ninvestigate various glass-box feature groups and discovered that the softmax\ndistribution serves as a reliable quality indicator for self-evaluation.\nExperimental results on public benchmarks validate the feasibility of\nself-evaluation of LLMs using glass-box features.", "published": "2024-03-07 04:50:38", "link": "http://arxiv.org/abs/2403.04222v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "UltraWiki: Ultra-fine-grained Entity Set Expansion with Negative Seed\n  Entities", "abstract": "Entity Set Expansion (ESE) aims to identify new entities belonging to the\nsame semantic class as a given set of seed entities. Traditional methods\nprimarily relied on positive seed entities to represent a target semantic\nclass, which poses challenge for the representation of ultra-fine-grained\nsemantic classes. Ultra-fine-grained semantic classes are defined based on\nfine-grained semantic classes with more specific attribute constraints.\nDescribing it with positive seed entities alone cause two issues: (i) Ambiguity\namong ultra-fine-grained semantic classes. (ii) Inability to define \"unwanted\"\nsemantic. Due to these inherent shortcomings, previous methods struggle to\naddress the ultra-fine-grained ESE (Ultra-ESE). To solve this issue, we first\nintroduce negative seed entities in the inputs, which belong to the same\nfine-grained semantic class as the positive seed entities but differ in certain\nattributes. Negative seed entities eliminate the semantic ambiguity by contrast\nbetween positive and negative attributes. Meanwhile, it provide a\nstraightforward way to express \"unwanted\". To assess model performance in\nUltra-ESE, we constructed UltraWiki, the first large-scale dataset tailored for\nUltra-ESE. UltraWiki encompasses 236 ultra-fine-grained semantic classes, where\neach query of them is represented with 3-5 positive and negative seed entities.\nA retrieval-based framework RetExpan and a generation-based framework GenExpan\nare proposed to comprehensively assess the efficacy of large language models\nfrom two different paradigms in Ultra-ESE. Moreover, we devised three\nstrategies to enhance models' comprehension of ultra-fine-grained entities\nsemantics: contrastive learning, retrieval augmentation, and chain-of-thought\nreasoning. Extensive experiments confirm the effectiveness of our proposed\nstrategies and also reveal that there remains a large space for improvement in\nUltra-ESE.", "published": "2024-03-07 06:10:02", "link": "http://arxiv.org/abs/2403.04247v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild", "abstract": "Hallucinations pose a significant challenge to the reliability of large\nlanguage models (LLMs) in critical domains. Recent benchmarks designed to\nassess LLM hallucinations within conventional NLP tasks, such as\nknowledge-intensive question answering (QA) and summarization, are insufficient\nfor capturing the complexities of user-LLM interactions in dynamic, real-world\nsettings. To address this gap, we introduce HaluEval-Wild, the first benchmark\nspecifically designed to evaluate LLM hallucinations in the wild. We\nmeticulously collect challenging (adversarially filtered by Alpaca) user\nqueries from ShareGPT, an existing real-world user-LLM interaction datasets, to\nevaluate the hallucination rates of various LLMs. Upon analyzing the collected\nqueries, we categorize them into five distinct types, which enables a\nfine-grained analysis of the types of hallucinations LLMs exhibit, and\nsynthesize the reference answers with the powerful GPT-4 model and\nretrieval-augmented generation (RAG). Our benchmark offers a novel approach\ntowards enhancing our comprehension of and improving LLM reliability in\nscenarios reflective of real-world interactions. Our benchmark is available at\nhttps://github.com/HaluEval-Wild/HaluEval-Wild.", "published": "2024-03-07 08:25:46", "link": "http://arxiv.org/abs/2403.04307v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Can Your Model Tell a Negation from an Implicature? Unravelling\n  Challenges With Intent Encoders", "abstract": "Conversational systems often rely on embedding models for intent\nclassification and intent clustering tasks. The advent of Large Language Models\n(LLMs), which enable instructional embeddings allowing one to adjust semantics\nover the embedding space using prompts, are being viewed as a panacea for these\ndownstream conversational tasks. However, traditional evaluation benchmarks\nrely solely on task metrics that don't particularly measure gaps related to\nsemantic understanding. Thus, we propose an intent semantic toolkit that gives\na more holistic view of intent embedding models by considering three tasks --\n(1) intent classification, (2) intent clustering, and (3) a novel triplet task.\nThe triplet task gauges the model's understanding of two semantic concepts\nparamount in real-world conversational systems -- negation and implicature. We\nobserve that current embedding models fare poorly in semantic understanding of\nthese concepts. To address this, we propose a pre-training approach to improve\nthe embedding model by leveraging augmentation with data generated by an\nauto-regressive model and a contrastive loss term. Our approach improves the\nsemantic understanding of the intent embedding model on the aforementioned\nlinguistic dimensions while slightly effecting their performance on downstream\ntask metrics.", "published": "2024-03-07 08:32:17", "link": "http://arxiv.org/abs/2403.04314v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Computational Modelling of Plurality and Definiteness in Chinese Noun\n  Phrases", "abstract": "Theoretical linguists have suggested that some languages (e.g., Chinese and\nJapanese) are \"cooler\" than other languages based on the observation that the\nintended meaning of phrases in these languages depends more on their contexts.\nAs a result, many expressions in these languages are shortened, and their\nmeaning is inferred from the context. In this paper, we focus on the omission\nof the plurality and definiteness markers in Chinese noun phrases (NPs) to\ninvestigate the predictability of their intended meaning given the contexts. To\nthis end, we built a corpus of Chinese NPs, each of which is accompanied by its\ncorresponding context, and by labels indicating its singularity/plurality and\ndefiniteness/indefiniteness. We carried out corpus assessments and analyses.\nThe results suggest that Chinese speakers indeed drop plurality and\ndefiniteness markers very frequently. Building on the corpus, we train a bank\nof computational models using both classic machine learning models and\nstate-of-the-art pre-trained language models to predict the plurality and\ndefiniteness of each NP. We report on the performance of these models and\nanalyse their behaviours.", "published": "2024-03-07 10:06:54", "link": "http://arxiv.org/abs/2403.04376v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Exploring Continual Learning of Compositional Generalization in NLI", "abstract": "Compositional Natural Language Inference has been explored to assess the true\nabilities of neural models to perform NLI. Yet, current evaluations assume\nmodels to have full access to all primitive inferences in advance, in contrast\nto humans that continuously acquire inference knowledge. In this paper, we\nintroduce the Continual Compositional Generalization in Inference (C2Gen NLI)\nchallenge, where a model continuously acquires knowledge of constituting\nprimitive inference tasks as a basis for compositional inferences. We explore\nhow continual learning affects compositional generalization in NLI, by\ndesigning a continual learning setup for compositional NLI inference tasks. Our\nexperiments demonstrate that models fail to compositionally generalize in a\ncontinual scenario. To address this problem, we first benchmark various\ncontinual learning algorithms and verify their efficacy. We then further\nanalyze C2Gen, focusing on how to order primitives and compositional inference\ntypes and examining correlations between subtasks. Our analyses show that by\nlearning subtasks continuously while observing their dependencies and\nincreasing degrees of difficulty, continual learning can enhance composition\ngeneralization ability.", "published": "2024-03-07 10:54:27", "link": "http://arxiv.org/abs/2403.04400v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Classist Tools: Social Class Correlates with Performance in NLP", "abstract": "Since the foundational work of William Labov on the social stratification of\nlanguage (Labov, 1964), linguistics has made concentrated efforts to explore\nthe links between sociodemographic characteristics and language production and\nperception. But while there is strong evidence for socio-demographic\ncharacteristics in language, they are infrequently used in Natural Language\nProcessing (NLP). Age and gender are somewhat well represented, but Labov's\noriginal target, socioeconomic status, is noticeably absent. And yet it\nmatters. We show empirically that NLP disadvantages less-privileged\nsocioeconomic groups. We annotate a corpus of 95K utterances from movies with\nsocial class, ethnicity and geographical language variety and measure the\nperformance of NLP systems on three tasks: language modelling, automatic speech\nrecognition, and grammar error correction. We find significant performance\ndisparities that can be attributed to socioeconomic status as well as ethnicity\nand geographical differences. With NLP technologies becoming ever more\nubiquitous and quotidian, they must accommodate all language varieties to avoid\ndisadvantaging already marginalised groups. We argue for the inclusion of\nsocioeconomic class in future language technologies.", "published": "2024-03-07 12:27:08", "link": "http://arxiv.org/abs/2403.04445v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Pearl: A Review-driven Persona-Knowledge Grounded Conversational\n  Recommendation Dataset", "abstract": "Conversational recommender system is an emerging area that has garnered an\nincreasing interest in the community, especially with the advancements in large\nlanguage models (LLMs) that enable diverse reasoning over conversational input.\nDespite the progress, the field has many aspects left to explore. The currently\navailable public datasets for conversational recommendation lack specific user\npreferences and explanations for recommendations, hindering high-quality\nrecommendations. To address such challenges, we present a novel conversational\nrecommendation dataset named PEARL, synthesized with persona- and\nknowledge-augmented LLM simulators. We obtain detailed persona and knowledge\nfrom real-world reviews and construct a large-scale dataset with over 57k\ndialogues. Our experimental results demonstrate that utterances in PEARL\ninclude more specific user preferences, show expertise in the target domain,\nand provide recommendations more relevant to the dialogue context than those in\nprior datasets.", "published": "2024-03-07 12:57:16", "link": "http://arxiv.org/abs/2403.04460v4", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "NLPre: a revised approach towards language-centric benchmarking of\n  Natural Language Preprocessing systems", "abstract": "With the advancements of transformer-based architectures, we observe the rise\nof natural language preprocessing (NLPre) tools capable of solving preliminary\nNLP tasks (e.g. tokenisation, part-of-speech tagging, dependency parsing, or\nmorphological analysis) without any external linguistic guidance. It is arduous\nto compare novel solutions to well-entrenched preprocessing toolkits, relying\non rule-based morphological analysers or dictionaries. Aware of the\nshortcomings of existing NLPre evaluation approaches, we investigate a novel\nmethod of reliable and fair evaluation and performance reporting. Inspired by\nthe GLUE benchmark, the proposed language-centric benchmarking system enables\ncomprehensive ongoing evaluation of multiple NLPre tools, while credibly\ntracking their performance. The prototype application is configured for Polish\nand integrated with the thoroughly assembled NLPre-PL benchmark. Based on this\nbenchmark, we conduct an extensive evaluation of a variety of Polish NLPre\nsystems. To facilitate the construction of benchmarking environments for other\nlanguages, e.g. NLPre-GA for Irish or NLPre-ZH for Chinese, we ensure full\ncustomization of the publicly released source code of the benchmarking system.\nThe links to all the resources (deployed platforms, source code, trained\nmodels, datasets etc.) can be found on the project website:\nhttps://sites.google.com/view/nlpre-benchmark.", "published": "2024-03-07 14:07:00", "link": "http://arxiv.org/abs/2403.04507v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Uncertainty-Aware Relational Graph Neural Network for Few-Shot Knowledge\n  Graph Completion", "abstract": "Few-shot knowledge graph completion (FKGC) aims to query the unseen facts of\na relation given its few-shot reference entity pairs. The side effect of noises\ndue to the uncertainty of entities and triples may limit the few-shot learning,\nbut existing FKGC works neglect such uncertainty, which leads them more\nsusceptible to limited reference samples with noises. In this paper, we propose\na novel uncertainty-aware few-shot KG completion framework (UFKGC) to model\nuncertainty for a better understanding of the limited data by learning\nrepresentations under Gaussian distribution. Uncertainty representation is\nfirst designed for estimating the uncertainty scope of the entity pairs after\ntransferring feature representations into a Gaussian distribution. Further, to\nbetter integrate the neighbors with uncertainty characteristics for entity\nfeatures, we design an uncertainty-aware relational graph neural network\n(UR-GNN) to conduct convolution operations between the Gaussian distributions.\nThen, multiple random samplings are conducted for reference triples within the\nGaussian distribution to generate smooth reference representations during the\noptimization. The final completion score for each query instance is measured by\nthe designed uncertainty optimization to make our approach more robust to the\nnoises in few-shot scenarios. Experimental results show that our approach\nachieves excellent performance on two benchmark datasets compared to its\ncompetitors.", "published": "2024-03-07 14:23:25", "link": "http://arxiv.org/abs/2403.04521v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "MaCmS: Magahi Code-mixed Dataset for Sentiment Analysis", "abstract": "The present paper introduces new sentiment data, MaCMS, for\nMagahi-Hindi-English (MHE) code-mixed language, where Magahi is a\nless-resourced minority language. This dataset is the first\nMagahi-Hindi-English code-mixed dataset for sentiment analysis tasks. Further,\nwe also provide a linguistics analysis of the dataset to understand the\nstructure of code-mixing and a statistical study to understand the language\npreferences of speakers with different polarities. With these analyses, we also\ntrain baseline models to evaluate the dataset's quality.", "published": "2024-03-07 16:29:19", "link": "http://arxiv.org/abs/2403.04639v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "QAQ: Quality Adaptive Quantization for LLM KV Cache", "abstract": "The emergence of LLMs has ignited a fresh surge of breakthroughs in NLP\napplications, particularly in domains such as question-answering systems and\ntext generation. As the need for longer context grows, a significant bottleneck\nin model deployment emerges due to the linear expansion of the Key-Value (KV)\ncache with the context length. Existing methods primarily rely on various\nhypotheses, such as sorting the KV cache based on attention scores for\nreplacement or eviction, to compress the KV cache and improve model throughput.\nHowever, heuristics used by these strategies may wrongly evict essential KV\ncache, which can significantly degrade model performance. In this paper, we\npropose QAQ, a Quality Adaptive Quantization scheme for the KV cache. We\ntheoretically demonstrate that key cache and value cache exhibit distinct\nsensitivities to quantization, leading to the formulation of separate\nquantization strategies for their non-uniform quantization. Through the\nintegration of dedicated outlier handling, as well as an improved\nattention-aware approach, QAQ achieves up to 10x the compression ratio of the\nKV cache size with a neglectable impact on model performance. QAQ significantly\nreduces the practical hurdles of deploying LLMs, opening up new possibilities\nfor longer-context applications. The code is available at\ngithub.com/ClubieDong/KVCacheQuantization.", "published": "2024-03-07 16:42:37", "link": "http://arxiv.org/abs/2403.04643v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chain of Thought Explanation for Dialogue State Tracking", "abstract": "Dialogue state tracking (DST) aims to record user queries and goals during a\nconversational interaction achieved by maintaining a predefined set of slots\nand their corresponding values. Current approaches decide slot values opaquely,\nwhile humans usually adopt a more deliberate approach by collecting information\nfrom relevant dialogue turns and then reasoning the appropriate values. In this\nwork, we focus on the steps needed to figure out slot values by proposing a\nmodel named Chain-of-Thought-Explanation (CoTE) for the DST task. CoTE, which\nis built on the generative DST framework, is designed to create detailed\nexplanations step by step after determining the slot values. This process leads\nto more accurate and reliable slot values. More-over, to improve the reasoning\nability of the CoTE, we further construct more fluent and high-quality\nexplanations with automatic paraphrasing, leading the method CoTE-refined.\nExperimental results on three widely recognized DST benchmarks-MultiWOZ 2.2,\nWoZ 2.0, and M2M-demonstrate the remarkable effectiveness of the CoTE.\nFurthermore, through a meticulous fine-grained analysis, we observe significant\nbenefits of our CoTE on samples characterized by longer dialogue turns, user\nresponses, and reasoning steps.", "published": "2024-03-07 16:59:55", "link": "http://arxiv.org/abs/2403.04656v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Greater than the sum of its parts: The role of minority and majority\n  status in collaborative problem-solving communication", "abstract": "Collaborative problem-solving (CPS) is a vital skill used both in the\nworkplace and in educational environments. CPS is useful in tackling\nincreasingly complex global, economic, and political issues and is considered a\ncentral 21st century skill. The increasingly connected global community\npresents a fruitful opportunity for creative and collaborative problem-solving\ninteractions and solutions that involve diverse perspectives. Unfortunately,\nwomen and underrepresented minorities (URMs) often face obstacles during\ncollaborative interactions that hinder their key participation in these\nproblem-solving conversations. Here, we explored the communication patterns of\nminority and non-minority individuals working together in a CPS task. Group\nCommunication Analysis (GCA), a temporally-sensitive computational linguistic\ntool, was used to examine how URM status impacts individuals' sociocognitive\nlinguistic patterns. Results show differences across racial/ethnic groups in\nkey sociocognitive features that indicate fruitful collaborative interactions.\nWe also investigated how the groups' racial/ethnic composition impacts both\nindividual and group communication patterns. In general, individuals in more\ndemographically diverse groups displayed more productive communication\nbehaviors than individuals who were in majority-dominated groups. We discuss\nthe implications of individual and group diversity on communication patterns\nthat emerge during CPS and how these patterns can impact collaborative\noutcomes.", "published": "2024-03-07 17:17:20", "link": "http://arxiv.org/abs/2403.04671v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Evaluating Biases in Context-Dependent Health Questions", "abstract": "Chat-based large language models have the opportunity to empower individuals\nlacking high-quality healthcare access to receive personalized information\nacross a variety of topics. However, users may ask underspecified questions\nthat require additional context for a model to correctly answer. We study how\nlarge language model biases are exhibited through these contextual questions in\nthe healthcare domain. To accomplish this, we curate a dataset of sexual and\nreproductive healthcare questions that are dependent on age, sex, and location\nattributes. We compare models' outputs with and without demographic context to\ndetermine group alignment among our contextual questions. Our experiments\nreveal biases in each of these attributes, where young adult female users are\nfavored.", "published": "2024-03-07 19:15:40", "link": "http://arxiv.org/abs/2403.04858v1", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Code-Mixed Probes Show How Pre-Trained Models Generalise On\n  Code-Switched Text", "abstract": "Code-switching is a prevalent linguistic phenomenon in which multilingual\nindividuals seamlessly alternate between languages. Despite its widespread use\nonline and recent research trends in this area, research in code-switching\npresents unique challenges, primarily stemming from the scarcity of labelled\ndata and available resources. In this study we investigate how pre-trained\nLanguage Models handle code-switched text in three dimensions: a) the ability\nof PLMs to detect code-switched text, b) variations in the structural\ninformation that PLMs utilise to capture code-switched text, and c) the\nconsistency of semantic information representation in code-switched text. To\nconduct a systematic and controlled evaluation of the language models in\nquestion, we create a novel dataset of well-formed naturalistic code-switched\ntext along with parallel translations into the source languages. Our findings\nreveal that pre-trained language models are effective in generalising to\ncode-switched text, shedding light on the abilities of these models to\ngeneralise representations to CS corpora. We release all our code and data\nincluding the novel corpus at https://github.com/francesita/code-mixed-probes.", "published": "2024-03-07 19:46:03", "link": "http://arxiv.org/abs/2403.04872v2", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Few shot chain-of-thought driven reasoning to prompt LLMs for open ended\n  medical question answering", "abstract": "In this paper, we propose a modified version of the MedQA-USMLE dataset,\nnamed MEDQA-OPEN, which contains open-ended medical questions without options\nto mimic clinical scenarios, along with clinician-approved reasoned answers.\nAdditionally, we implement a prompt driven by Chain of Thought (CoT) reasoning,\nCLINICR, to mirror the prospective process of incremental reasoning, reaching a\ncorrect response to medical questions. We empirically demonstrate how CLINICR\noutperforms the state-of-the-art 5-shot CoT-based prompt (Li\\'evin et al.,\n2022). We also present an approach that mirrors real-life clinical practice by\nfirst exploring multiple differential diagnoses through MCQ-CLINICR and\nsubsequently narrowing down to a final diagnosis using MCQ-ELIMINATIVE.\nFinally, emphasizing the importance of response verification in medical\nsettings, we utilize a reward model mechanism, replacing the elimination\nprocess performed by MCQ-ELIMINATIVE.", "published": "2024-03-07 20:48:40", "link": "http://arxiv.org/abs/2403.04890v3", "categories": ["cs.CL"], "primary_category": "cs.CL"}
{"title": "Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference", "abstract": "Large Language Models (LLMs) have unlocked new capabilities and applications;\nhowever, evaluating the alignment with human preferences still poses\nsignificant challenges. To address this issue, we introduce Chatbot Arena, an\nopen platform for evaluating LLMs based on human preferences. Our methodology\nemploys a pairwise comparison approach and leverages input from a diverse user\nbase through crowdsourcing. The platform has been operational for several\nmonths, amassing over 240K votes. This paper describes the platform, analyzes\nthe data we have collected so far, and explains the tried-and-true statistical\nmethods we are using for efficient and accurate evaluation and ranking of\nmodels. We confirm that the crowdsourced questions are sufficiently diverse and\ndiscriminating and that the crowdsourced human votes are in good agreement with\nthose of expert raters. These analyses collectively establish a robust\nfoundation for the credibility of Chatbot Arena. Because of its unique value\nand openness, Chatbot Arena has emerged as one of the most referenced LLM\nleaderboards, widely cited by leading LLM developers and companies. Our demo is\npublicly available at \\url{https://chat.lmsys.org}.", "published": "2024-03-07 01:22:38", "link": "http://arxiv.org/abs/2403.04132v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "DA-Net: A Disentangled and Adaptive Network for Multi-Source\n  Cross-Lingual Transfer Learning", "abstract": "Multi-Source cross-lingual transfer learning deals with the transfer of task\nknowledge from multiple labelled source languages to an unlabeled target\nlanguage under the language shift. Existing methods typically focus on\nweighting the predictions produced by language-specific classifiers of\ndifferent sources that follow a shared encoder. However, all source languages\nshare the same encoder, which is updated by all these languages. The extracted\nrepresentations inevitably contain different source languages' information,\nwhich may disturb the learning of the language-specific classifiers.\nAdditionally, due to the language gap, language-specific classifiers trained\nwith source labels are unable to make accurate predictions for the target\nlanguage. Both facts impair the model's performance. To address these\nchallenges, we propose a Disentangled and Adaptive Network (DA-Net). Firstly,\nwe devise a feedback-guided collaborative disentanglement method that seeks to\npurify input representations of classifiers, thereby mitigating mutual\ninterference from multiple sources. Secondly, we propose a class-aware parallel\nadaptation method that aligns class-level distributions for each source-target\nlanguage pair, thereby alleviating the language pairs' language gap.\nExperimental results on three different tasks involving 38 languages validate\nthe effectiveness of our approach.", "published": "2024-03-07 02:30:46", "link": "http://arxiv.org/abs/2403.04158v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Regression-aware Inference with LLMs", "abstract": "Large language models (LLMs) have shown strong results on a range of\napplications, including regression and scoring tasks. Typically, one obtains\noutputs from an LLM via autoregressive sampling from the model's output\ndistribution. We show that this inference strategy can be sub-optimal for\ncommon regression and scoring evaluation metrics. As a remedy, we build on\nprior work on Minimum Bayes Risk decoding, and propose alternate inference\nstrategies that estimate the Bayes-optimal solution for regression and scoring\nmetrics in closed-form from sampled responses. We show that our proposal\nsignificantly improves over baselines across datasets and models.", "published": "2024-03-07 03:24:34", "link": "http://arxiv.org/abs/2403.04182v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Large Language Models are In-Context Molecule Learners", "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance in\nbiochemical tasks, especially the molecule caption translation task, which aims\nto bridge the gap between molecules and natural language texts. However,\nprevious methods in adapting LLMs to the molecule-caption translation task\nrequired extra domain-specific pre-training stages, suffered weak alignment\nbetween molecular and textual spaces, or imposed stringent demands on the scale\nof LLMs. To resolve the challenges, we propose In-Context Molecule Adaptation\n(ICMA), as a new paradigm allowing LLMs to learn the molecule-text alignment\nfrom context examples via In-Context Molecule Tuning. Specifically, ICMA\nincorporates the following three stages: Hybrid Context Retrieval,\nPost-retrieval Re-ranking, and In-context Molecule Tuning. Initially, Hybrid\nContext Retrieval utilizes BM25 Caption Retrieval and Molecule Graph Retrieval\nto retrieve similar informative context examples. Additionally, Post-retrieval\nRe-ranking is composed of Sequence Reversal and Random Walk selection to\nfurther improve the quality of retrieval results. Finally, In-Context Molecule\nTuning unlocks the in-context learning and reasoning capability of LLMs with\nthe retrieved examples and adapts the parameters of LLMs for better alignment\nbetween molecules and texts. Experimental results demonstrate that ICMA can\nempower LLMs to achieve state-of-the-art or comparable performance without\nextra training corpora and intricate structures, showing that LLMs are\ninherently in-context molecule learners.", "published": "2024-03-07 03:58:28", "link": "http://arxiv.org/abs/2403.04197v4", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "On the Essence and Prospect: An Investigation of Alignment Approaches\n  for Big Models", "abstract": "Big models have achieved revolutionary breakthroughs in the field of AI, but\nthey might also pose potential concerns. Addressing such concerns, alignment\ntechnologies were introduced to make these models conform to human preferences\nand values. Despite considerable advancements in the past year, various\nchallenges lie in establishing the optimal alignment strategy, such as data\ncost and scalable oversight, and how to align remains an open question. In this\nsurvey paper, we comprehensively investigate value alignment approaches. We\nfirst unpack the historical context of alignment tracing back to the 1920s\n(where it comes from), then delve into the mathematical essence of alignment\n(what it is), shedding light on the inherent challenges. Following this\nfoundation, we provide a detailed examination of existing alignment methods,\nwhich fall into three categories: Reinforcement Learning, Supervised\nFine-Tuning, and In-context Learning, and demonstrate their intrinsic\nconnections, strengths, and limitations, helping readers better understand this\nresearch area. In addition, two emerging topics, personal alignment, and\nmultimodal alignment, are also discussed as novel frontiers in this field.\nLooking forward, we discuss potential alignment paradigms and how they could\nhandle remaining challenges, prospecting where future alignment will go.", "published": "2024-03-07 04:19:13", "link": "http://arxiv.org/abs/2403.04204v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "TEGEE: Task dEfinition Guided Expert Ensembling for Generalizable and\n  Few-shot Learning", "abstract": "Large Language Models (LLMs) exhibit the ability to perform in-context\nlearning (ICL), where they acquire new tasks directly from examples provided in\ndemonstrations. This process is thought to operate through an implicit task\nselection mechanism that involves extracting and processing task definitions\nfrom these demonstrations. However, critical questions remain: Which is more\nessential -- task extraction or definition? And how can these capabilities be\nfurther improved? To address these questions, we propose \\textbf{TEGEE} (Task\nDefinition Guided Expert Ensembling), a method that explicitly extracts task\ndefinitions and generates responses based on specific tasks. Our framework\nemploys a dual 3B model approach, with each model assigned a distinct role: one\nfocuses on task definition extraction, while the other handles learning from\ndemonstrations. This modular approach supports the hypothesis that extracting\ntask definitions is more vital than processing the task itself. Empirical\nevaluations show that TEGEE performs comparably to the larger LLaMA2-13B model.\nBy leveraging a modular design, our approach extends traditional ICL from\nfew-shot to many-shot learning, supporting an unlimited number of\ndemonstrations and enhancing continual learning capabilities.", "published": "2024-03-07 05:26:41", "link": "http://arxiv.org/abs/2403.04233v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "A New Benchmark for Evaluating Automatic Speech Recognition in the\n  Arabic Call Domain", "abstract": "This work is an attempt to introduce a comprehensive benchmark for Arabic\nspeech recognition, specifically tailored to address the challenges of\ntelephone conversations in Arabic language. Arabic, characterized by its rich\ndialectal diversity and phonetic complexity, presents a number of unique\nchallenges for automatic speech recognition (ASR) systems. These challenges are\nfurther amplified in the domain of telephone calls, where audio quality,\nbackground noise, and conversational speech styles negatively affect\nrecognition accuracy. Our work aims to establish a robust benchmark that not\nonly encompasses the broad spectrum of Arabic dialects but also emulates the\nreal-world conditions of call-based communications. By incorporating diverse\ndialectical expressions and accounting for the variable quality of call\nrecordings, this benchmark seeks to provide a rigorous testing ground for the\ndevelopment and evaluation of ASR systems capable of navigating the\ncomplexities of Arabic speech in telephonic contexts. This work also attempts\nto establish a baseline performance evaluation using state-of-the-art ASR\ntechnologies.", "published": "2024-03-07 07:24:32", "link": "http://arxiv.org/abs/2403.04280v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Online Adaptation of Language Models with a Memory of Amortized Contexts", "abstract": "Due to the rapid generation and dissemination of information, large language\nmodels (LLMs) quickly run out of date despite enormous development costs. To\naddress the crucial need to keep models updated, online learning has emerged as\na critical tool when utilizing LLMs for real-world applications. However, given\nthe ever-expanding corpus of unseen documents and the large parameter space of\nmodern LLMs, efficient adaptation is essential. To address these challenges, we\npropose Memory of Amortized Contexts (MAC), an efficient and effective online\nadaptation framework for LLMs with strong knowledge retention. We propose a\nfeature extraction and memory-augmentation approach to compress and extract\ninformation from new documents into compact modulations stored in a memory\nbank. When answering questions, our model attends to and extracts relevant\nknowledge from this memory bank. To learn informative modulations in an\nefficient manner, we utilize amortization-based meta-learning, which\nsubstitutes an otherwise required optimization process with a single forward\npass of the encoder. Subsequently, we learn to choose from and aggregate\nselected documents into a single modulation by conditioning on the question,\nallowing us to adapt a frozen language model during test time without requiring\nfurther gradient updates. Our experiment demonstrates the superiority of MAC in\nmultiple aspects, including online adaptation performance, time, and memory\nefficiency. In addition, we show how MAC can be combined with and improve the\nperformance of popular alternatives such as retrieval augmented generations\n(RAGs). Code is available at: https://github.com/jihoontack/MAC.", "published": "2024-03-07 08:34:57", "link": "http://arxiv.org/abs/2403.04317v2", "categories": ["cs.LG", "cs.CL"], "primary_category": "cs.LG"}
{"title": "Measuring Meaning Composition in the Human Brain with Composition Scores\n  from Large Language Models", "abstract": "The process of meaning composition, wherein smaller units like morphemes or\nwords combine to form the meaning of phrases and sentences, is essential for\nhuman sentence comprehension. Despite extensive neurolinguistic research into\nthe brain regions involved in meaning composition, a computational metric to\nquantify the extent of composition is still lacking. Drawing on the key-value\nmemory interpretation of transformer feed-forward network blocks, we introduce\nthe Composition Score, a novel model-based metric designed to quantify the\ndegree of meaning composition during sentence comprehension. Experimental\nfindings show that this metric correlates with brain clusters associated with\nword frequency, structural processing, and general sensitivity to words,\nsuggesting the multifaceted nature of meaning composition during human sentence\ncomprehension.", "published": "2024-03-07 08:44:42", "link": "http://arxiv.org/abs/2403.04325v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ProMoAI: Process Modeling with Generative AI", "abstract": "ProMoAI is a novel tool that leverages Large Language Models (LLMs) to\nautomatically generate process models from textual descriptions, incorporating\nadvanced prompt engineering, error handling, and code generation techniques.\nBeyond automating the generation of complex process models, ProMoAI also\nsupports process model optimization. Users can interact with the tool by\nproviding feedback on the generated model, which is then used for refining the\nprocess model. ProMoAI utilizes the capabilities LLMs to offer a novel,\nAI-driven approach to process modeling, significantly reducing the barrier to\nentry for users without deep technical knowledge in process modeling.", "published": "2024-03-07 08:48:04", "link": "http://arxiv.org/abs/2403.04327v2", "categories": ["cs.DB", "cs.CL"], "primary_category": "cs.DB"}
{"title": "From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge\n  Prediction", "abstract": "Confusing charge prediction is a challenging task in legal AI, which involves\npredicting confusing charges based on fact descriptions. While existing charge\nprediction methods have shown impressive performance, they face significant\nchallenges when dealing with confusing charges, such as Snatch and Robbery. In\nthe legal domain, constituent elements play a pivotal role in distinguishing\nconfusing charges. Constituent elements are fundamental behaviors underlying\ncriminal punishment and have subtle distinctions among charges. In this paper,\nwe introduce a novel From Graph to Word Bag (FWGB) approach, which introduces\ndomain knowledge regarding constituent elements to guide the model in making\njudgments on confusing charges, much like a judge's reasoning process.\nSpecifically, we first construct a legal knowledge graph containing constituent\nelements to help select keywords for each charge, forming a word bag.\nSubsequently, to guide the model's attention towards the differentiating\ninformation for each charge within the context, we expand the attention\nmechanism and introduce a new loss function with attention supervision through\nwords in the word bag. We construct the confusing charges dataset from\nreal-world judicial documents. Experiments demonstrate the effectiveness of our\nmethod, especially in maintaining exceptional performance in imbalanced label\ndistributions.", "published": "2024-03-07 09:57:42", "link": "http://arxiv.org/abs/2403.04369v3", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Acceleron: A Tool to Accelerate Research Ideation", "abstract": "Several tools have recently been proposed for assisting researchers during\nvarious stages of the research life-cycle. However, these primarily concentrate\non tasks such as retrieving and recommending relevant literature, reviewing and\ncritiquing the draft, and writing of research manuscripts. Our investigation\nreveals a significant gap in availability of tools specifically designed to\nassist researchers during the challenging ideation phase of the research\nlife-cycle. To aid with research ideation, we propose `Acceleron', a research\naccelerator for different phases of the research life cycle, and which is\nspecially designed to aid the ideation process. Acceleron guides researchers\nthrough the formulation of a comprehensive research proposal, encompassing a\nnovel research problem. The proposals motivation is validated for novelty by\nidentifying gaps in the existing literature and suggesting a plausible list of\ntechniques to solve the proposed problem. We leverage the reasoning and\ndomain-specific skills of Large Language Models (LLMs) to create an agent-based\narchitecture incorporating colleague and mentor personas for LLMs. The LLM\nagents emulate the ideation process undertaken by researchers, engaging\nresearchers in an interactive fashion to aid in the development of the research\nproposal. Notably, our tool addresses challenges inherent in LLMs, such as\nhallucinations, implements a two-stage aspect-based retrieval to manage\nprecision-recall trade-offs, and tackles issues of unanswerability. As\nevaluation, we illustrate the execution of our motivation validation and method\nsynthesis workflows on proposals from the ML and NLP domain, given by 3\ndistinct researchers. Our observations and evaluations provided by the\nresearchers illustrate the efficacy of the tool in terms of assisting\nresearchers with appropriate inputs at distinct stages and thus leading to\nimproved time efficiency.", "published": "2024-03-07 10:20:06", "link": "http://arxiv.org/abs/2403.04382v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "SGNet: Folding Symmetrical Protein Complex with Deep Learning", "abstract": "Deep learning has made significant progress in protein structure prediction,\nadvancing the development of computational biology. However, despite the high\naccuracy achieved in predicting single-chain structures, a significant number\nof large homo-oligomeric assemblies exhibit internal symmetry, posing a major\nchallenge in structure determination. The performances of existing deep\nlearning methods are limited since the symmetrical protein assembly usually has\na long sequence, making structural computation infeasible. In addition,\nmultiple identical subunits in symmetrical protein complex cause the issue of\nsupervision ambiguity in label assignment, requiring a consistent structure\nmodeling for the training. To tackle these problems, we propose a protein\nfolding framework called SGNet to model protein-protein interactions in\nsymmetrical assemblies. SGNet conducts feature extraction on a single subunit\nand generates the whole assembly using our proposed symmetry module, which\nlargely mitigates computational problems caused by sequence length. Thanks to\nthe elaborate design of modeling symmetry consistently, we can model all global\nsymmetry types in quaternary protein structure prediction. Extensive\nexperimental results on a benchmark of symmetrical protein complexes further\ndemonstrate the effectiveness of our method.", "published": "2024-03-07 10:39:48", "link": "http://arxiv.org/abs/2403.04395v1", "categories": ["q-bio.BM", "cs.CL"], "primary_category": "q-bio.BM"}
{"title": "Low-Resource Court Judgment Summarization for Common Law Systems", "abstract": "Common law courts need to refer to similar precedents' judgments to inform\ntheir current decisions. Generating high-quality summaries of court judgment\ndocuments can facilitate legal practitioners to efficiently review previous\ncases and assist the general public in accessing how the courts operate and how\nthe law is applied. Previous court judgment summarization research focuses on\ncivil law or a particular jurisdiction's judgments. However, judges can refer\nto the judgments from all common law jurisdictions. Current summarization\ndatasets are insufficient to satisfy the demands of summarizing precedents\nacross multiple jurisdictions, especially when labeled data are scarce for many\njurisdictions. To address the lack of datasets, we present CLSum, the first\ndataset for summarizing multi-jurisdictional common law court judgment\ndocuments. Besides, this is the first court judgment summarization work\nadopting large language models (LLMs) in data augmentation, summary generation,\nand evaluation. Specifically, we design an LLM-based data augmentation method\nincorporating legal knowledge. We also propose a legal knowledge enhanced\nevaluation metric based on LLM to assess the quality of generated judgment\nsummaries. Our experimental results verify that the LLM-based summarization\nmethods can perform well in the few-shot and zero-shot settings. Our LLM-based\ndata augmentation method can mitigate the impact of low data resources.\nFurthermore, we carry out comprehensive comparative experiments to find\nessential model components and settings that are capable of enhancing\nsummarization performance.", "published": "2024-03-07 12:47:42", "link": "http://arxiv.org/abs/2403.04454v1", "categories": ["cs.CL", "cs.AI", "I.2.7; I.7"], "primary_category": "cs.CL"}
{"title": "Do Large Language Model Understand Multi-Intent Spoken Language ?", "abstract": "This research signifies a considerable breakthrough in leveraging Large\nLanguage Models (LLMs) for multi-intent spoken language understanding (SLU).\nOur approach re-imagines the use of entity slots in multi-intent SLU\napplications, making the most of the generative potential of LLMs within the\nSLU landscape, leading to the development of the EN-LLM series. Furthermore, we\nintroduce the concept of Sub-Intent Instruction (SII) to amplify the analysis\nand interpretation of complex, multi-intent communications, which further\nsupports the creation of the ENSI-LLM models series. Our novel datasets,\nidentified as LM-MixATIS and LM-MixSNIPS, are synthesized from existing\nbenchmarks. The study evidences that LLMs may match or even surpass the\nperformance of the current best multi-intent SLU models. We also scrutinize the\nperformance of LLMs across a spectrum of intent configurations and dataset\ndistributions. On top of this, we present two revolutionary metrics - Entity\nSlot Accuracy (ESA) and Combined Semantic Accuracy (CSA) - to facilitate a\ndetailed assessment of LLM competence in this multifaceted field.\" Our code and\ndatasets are available at \\url{https://github.com/SJY8460/SLM}.", "published": "2024-03-07 13:30:52", "link": "http://arxiv.org/abs/2403.04481v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "GraphInstruct: Empowering Large Language Models with Graph Understanding\n  and Reasoning Capability", "abstract": "Evaluating and enhancing the general capabilities of large language models\n(LLMs) has been an important research topic. Graph is a common data structure\nin the real world, and understanding graph data is a crucial part for advancing\ngeneral intelligence. To evaluate and enhance the graph understanding abilities\nof LLMs, in this paper, we propose a benchmark named GraphInstruct, which\ncomprehensively includes 21 classical graph reasoning tasks, providing diverse\ngraph generation pipelines and detailed reasoning steps. Based on\nGraphInstruct, we further construct GraphLM through efficient\ninstruction-tuning, which shows prominent graph understanding capability. In\norder to enhance the LLM with graph reasoning capability as well, we propose a\nstep mask training strategy, and construct a model named GraphLM+. As one of\nthe pioneering efforts to enhance the graph understanding and reasoning\nabilities of LLMs, extensive experiments have demonstrated the superiority of\nGraphLM and GraphLM+ over other LLMs. We look forward to more researchers\nexploring the potential of LLMs in the graph data mining domain through\nGraphInstruct. Our code for generating GraphInstruct is released publicly at:\nhttps://github.com/CGCL-codes/GraphInstruct.", "published": "2024-03-07 13:36:08", "link": "http://arxiv.org/abs/2403.04483v2", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Where does In-context Translation Happen in Large Language Models", "abstract": "Self-supervised large language models have demonstrated the ability to\nperform Machine Translation (MT) via in-context learning, but little is known\nabout where the model performs the task with respect to prompt instructions and\ndemonstration examples. In this work, we attempt to characterize the region\nwhere large language models transition from in-context learners to translation\nmodels. Through a series of layer-wise context-masking experiments on\n\\textsc{GPTNeo2.7B}, \\textsc{Bloom3B}, \\textsc{Llama7b} and\n\\textsc{Llama7b-chat}, we demonstrate evidence of a \"task recognition\" point\nwhere the translation task is encoded into the input representations and\nattention to context is no longer necessary. We further observe correspondence\nbetween the low performance when masking out entire layers, and the task\nrecognition layers. Taking advantage of this redundancy results in 45\\%\ncomputational savings when prompting with 5 examples, and task recognition\nachieved at layer 14 / 32. Our layer-wise fine-tuning experiments indicate that\nthe most effective layers for MT fine-tuning are the layers critical to task\nrecognition.", "published": "2024-03-07 14:12:41", "link": "http://arxiv.org/abs/2403.04510v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Wiki-TabNER:Advancing Table Interpretation Through Named Entity\n  Recognition", "abstract": "Web tables contain a large amount of valuable knowledge and have inspired\ntabular language models aimed at tackling table interpretation (TI) tasks. In\nthis paper, we analyse a widely used benchmark dataset for evaluation of TI\ntasks, particularly focusing on the entity linking task. Our analysis reveals\nthat this dataset is overly simplified, potentially reducing its effectiveness\nfor thorough evaluation and failing to accurately represent tables as they\nappear in the real-world. To overcome this drawback, we construct and annotate\na new more challenging dataset. In addition to introducing the new dataset, we\nalso introduce a novel problem aimed at addressing the entity linking task:\nnamed entity recognition within cells. Finally, we propose a prompting\nframework for evaluating the newly developed large language models (LLMs) on\nthis novel TI task. We conduct experiments on prompting LLMs under various\nsettings, where we use both random and similarity-based selection to choose the\nexamples presented to the models. Our ablation study helps us gain insights\ninto the impact of the few-shot examples. Additionally, we perform qualitative\nanalysis to gain insights into the challenges encountered by the models and to\nunderstand the limitations of the proposed dataset.", "published": "2024-03-07 15:22:07", "link": "http://arxiv.org/abs/2403.04577v1", "categories": ["cs.AI", "cs.CL"], "primary_category": "cs.AI"}
{"title": "Strong Priority and Determinacy in Timed CCS", "abstract": "Building on the standard theory of process algebra with priorities, we\nidentify a new scheduling mechanism, called \"constructive reduction\" which is\ndesigned to capture the essence of synchronous programming. The distinctive\nproperty of this evaluation strategy is to achieve determinacy-by-construction\nfor multi-cast concurrent communication with shared memory. In the technical\nsetting of CCS extended by clocks and priorities, we prove for a large class of\n\"coherent\" processes a confluence property for constructive reductions. We show\nthat under some restrictions, called \"pivotability\", coherence is preserved by\nthe operators of prefix, summation, parallel composition, restriction and\nhiding. Since this permits memory and sharing, we are able to cover a strictly\nlarger class of processes compared to those in Milner's classical confluence\ntheory for CCS without priorities.", "published": "2024-03-07 16:02:31", "link": "http://arxiv.org/abs/2403.04618v3", "categories": ["cs.PL", "cs.CL"], "primary_category": "cs.PL"}
{"title": "Yi: Open Foundation Models by 01.AI", "abstract": "We introduce the Yi model family, a series of language and multimodal models\nthat demonstrate strong multi-dimensional capabilities. The Yi model family is\nbased on 6B and 34B pretrained language models, then we extend them to chat\nmodels, 200K long context models, depth-upscaled models, and vision-language\nmodels. Our base models achieve strong performance on a wide range of\nbenchmarks like MMLU, and our finetuned chat models deliver strong human\npreference rate on major evaluation platforms like AlpacaEval and Chatbot\nArena. Building upon our scalable super-computing infrastructure and the\nclassical transformer architecture, we attribute the performance of Yi models\nprimarily to its data quality resulting from our data-engineering efforts. For\npretraining, we construct 3.1 trillion tokens of English and Chinese corpora\nusing a cascaded data deduplication and quality filtering pipeline. For\nfinetuning, we polish a small scale (less than 10K) instruction dataset over\nmultiple iterations such that every single instance has been verified directly\nby our machine learning engineers. For vision-language, we combine the chat\nlanguage model with a vision transformer encoder and train the model to align\nvisual representations to the semantic space of the language model. We further\nextend the context length to 200K through lightweight continual pretraining and\ndemonstrate strong needle-in-a-haystack retrieval performance. We show that\nextending the depth of the pretrained checkpoint through continual pretraining\nfurther improves performance. We believe that given our current results,\ncontinuing to scale up model parameters using thoroughly optimized data will\nlead to even stronger frontier models.", "published": "2024-03-07 16:52:49", "link": "http://arxiv.org/abs/2403.04652v3", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Telecom Language Models: Must They Be Large?", "abstract": "The increasing interest in Large Language Models (LLMs) within the\ntelecommunications sector underscores their potential to revolutionize\noperational efficiency. However, the deployment of these sophisticated models\nis often hampered by their substantial size and computational demands, raising\nconcerns about their viability in resource-constrained environments. Addressing\nthis challenge, recent advancements have seen the emergence of small language\nmodels that surprisingly exhibit performance comparable to their larger\ncounterparts in many tasks, such as coding and common-sense reasoning. Phi-2, a\ncompact yet powerful model, exemplifies this new wave of efficient small\nlanguage models. This paper conducts a comprehensive evaluation of Phi-2's\nintrinsic understanding of the telecommunications domain. Recognizing the\nscale-related limitations, we enhance Phi-2's capabilities through a\nRetrieval-Augmented Generation approach, meticulously integrating an extensive\nknowledge base specifically curated with telecom standard specifications. The\nenhanced Phi-2 model demonstrates a profound improvement in accuracy, answering\nquestions about telecom standards with a precision that closely rivals the more\nresource-intensive GPT-3.5. The paper further explores the refined capabilities\nof Phi-2 in addressing problem-solving scenarios within the telecom sector,\nhighlighting its potential and limitations.", "published": "2024-03-07 17:13:12", "link": "http://arxiv.org/abs/2403.04666v2", "categories": ["cs.CL", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Common 7B Language Models Already Possess Strong Math Capabilities", "abstract": "Mathematical capabilities were previously believed to emerge in common\nlanguage models only at a very large scale or require extensive math-related\npre-training. This paper shows that the LLaMA-2 7B model with common\npre-training already exhibits strong mathematical abilities, as evidenced by\nits impressive accuracy of 97.7% and 72.0% on the GSM8K and MATH benchmarks,\nrespectively, when selecting the best response from 256 random generations. The\nprimary issue with the current base model is the difficulty in consistently\neliciting its inherent mathematical capabilities. Notably, the accuracy for the\nfirst answer drops to 49.5% and 7.9% on the GSM8K and MATH benchmarks,\nrespectively. We find that simply scaling up the SFT data can significantly\nenhance the reliability of generating correct answers. However, the potential\nfor extensive scaling is constrained by the scarcity of publicly available math\nquestions. To overcome this limitation, we employ synthetic data, which proves\nto be nearly as effective as real data and shows no clear saturation when\nscaled up to approximately one million samples. This straightforward approach\nachieves an accuracy of 82.6% on GSM8K and 40.6% on MATH using LLaMA-2 7B\nmodels, surpassing previous models by 14.2% and 20.8%, respectively. We also\nprovide insights into scaling behaviors across different reasoning complexities\nand error types.", "published": "2024-03-07 18:00:40", "link": "http://arxiv.org/abs/2403.04706v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "ConstitutionalExperts: Training a Mixture of Principle-based Prompts", "abstract": "Large language models (LLMs) are highly capable at a variety of tasks given\nthe right prompt, but writing one is still a difficult and tedious process. In\nthis work, we introduce ConstitutionalExperts, a method for learning a prompt\nconsisting of constitutional principles (i.e. rules), given a training dataset.\nUnlike prior methods that optimize the prompt as a single entity, our method\nincrementally improves the prompt by surgically editing individual principles.\nWe also show that we can improve overall performance by learning unique prompts\nfor different semantic regions of the training data and using a\nmixture-of-experts (MoE) architecture to route inputs at inference time. We\ncompare our method to other state of the art prompt-optimization techniques\nacross six benchmark datasets. We also investigate whether MoE improves these\nother techniques. Our results suggest that ConstitutionalExperts outperforms\nother prompt optimization techniques by 10.9% (F1) and that mixture-of-experts\nimproves all techniques, suggesting its broad applicability.", "published": "2024-03-07 20:58:04", "link": "http://arxiv.org/abs/2403.04894v1", "categories": ["cs.CL", "cs.AI"], "primary_category": "cs.CL"}
{"title": "Presenting Terrorizer: an algorithm for consolidating company names in\n  patent assignees", "abstract": "The problem of disambiguation of company names poses a significant challenge\nin extracting useful information from patents. This issue biases research\noutcomes as it mostly underestimates the number of patents attributed to\ncompanies, particularly multinational corporations which file patents under a\nplethora of names, including alternate spellings of the same entity and,\neventually, companies' subsidiaries. To date, addressing these challenges has\nrelied on labor-intensive dictionary based or string matching approaches,\nleaving the problem of patents' assignee harmonization on large datasets mostly\nunresolved. To bridge this gap, this paper describes the Terrorizer algorithm,\na text-based algorithm that leverages natural language processing (NLP),\nnetwork theory, and rule-based techniques to harmonize the variants of company\nnames recorded as patent assignees. In particular, the algorithm follows the\ntripartite structure of its antecedents, namely parsing, matching and filtering\nstage, adding an original \"knowledge augmentation\" phase which is used to\nenrich the information available on each assignee name. We use Terrorizer on a\nset of 325'917 companies' names who are assignees of patents granted by the\nUSPTO from 2005 to 2022. The performance of Terrorizer is evaluated on four\ngold standard datasets. This validation step shows us two main things: the\nfirst is that the performance of Terrorizer is similar over different kind of\ndatasets, proving that our algorithm generalizes well. Second, when comparing\nits performance with the one of the algorithm currently used in PatentsView for\nthe same task (Monath et al., 2021), it achieves a higher F1 score. Finally, we\nuse the Tree-structured Parzen Estimator (TPE) optimization algorithm for the\nhyperparameters' tuning. Our final result is a reduction in the initial set of\nnames of over 42%.", "published": "2024-03-07 09:59:15", "link": "http://arxiv.org/abs/2403.12083v1", "categories": ["cs.IR", "cs.CL", "I.2; J.4"], "primary_category": "cs.IR"}
{"title": "Can Large Language Models Reason and Plan?", "abstract": "While humans sometimes do show the capability of correcting their own\nerroneous guesses with self-critiquing, there seems to be no basis for that\nassumption in the case of LLMs.", "published": "2024-03-07 00:36:32", "link": "http://arxiv.org/abs/2403.04121v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Exploring LLM-based Agents for Root Cause Analysis", "abstract": "The growing complexity of cloud based software systems has resulted in\nincident management becoming an integral part of the software development\nlifecycle. Root cause analysis (RCA), a critical part of the incident\nmanagement process, is a demanding task for on-call engineers, requiring deep\ndomain knowledge and extensive experience with a team's specific services.\nAutomation of RCA can result in significant savings of time, and ease the\nburden of incident management on on-call engineers. Recently, researchers have\nutilized Large Language Models (LLMs) to perform RCA, and have demonstrated\npromising results. However, these approaches are not able to dynamically\ncollect additional diagnostic information such as incident related logs,\nmetrics or databases, severely restricting their ability to diagnose root\ncauses. In this work, we explore the use of LLM based agents for RCA to address\nthis limitation. We present a thorough empirical evaluation of a ReAct agent\nequipped with retrieval tools, on an out-of-distribution dataset of production\nincidents collected at Microsoft. Results show that ReAct performs\ncompetitively with strong retrieval and reasoning baselines, but with highly\nincreased factual accuracy. We then extend this evaluation by incorporating\ndiscussions associated with incident reports as additional inputs for the\nmodels, which surprisingly does not yield significant performance improvements.\nLastly, we conduct a case study with a team at Microsoft to equip the ReAct\nagent with tools that give it access to external diagnostic services that are\nused by the team for manual RCA. Our results show how agents can overcome the\nlimitations of prior work, and practical considerations for implementing such a\nsystem in practice.", "published": "2024-03-07 00:44:01", "link": "http://arxiv.org/abs/2403.04123v1", "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "cs.SE"}
{"title": "Attempt Towards Stress Transfer in Speech-to-Speech Machine Translation", "abstract": "The language diversity in India's education sector poses a significant\nchallenge, hindering inclusivity. Despite the democratization of knowledge\nthrough online educational content, the dominance of English, as the internet's\nlingua franca, limits accessibility, emphasizing the crucial need for\ntranslation into Indian languages. Despite existing Speech-to-Speech Machine\nTranslation (SSMT) technologies, the lack of intonation in these systems gives\nmonotonous translations, leading to a loss of audience interest and\ndisengagement from the content. To address this, our paper introduces a dataset\nwith stress annotations in Indian English and also a Text-to-Speech (TTS)\narchitecture capable of incorporating stress into synthesized speech. This\ndataset is used for training a stress detection model, which is then used in\nthe SSMT system for detecting stress in the source speech and transferring it\ninto the target language speech. The TTS architecture is based on FastPitch and\ncan modify the variances based on stressed words given. We present an Indian\nEnglish-to-Hindi SSMT system that can transfer stress and aim to enhance the\noverall quality and engagement of educational content.", "published": "2024-03-07 03:21:19", "link": "http://arxiv.org/abs/2403.04178v1", "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "cs.CL"}
{"title": "Generative AI for Synthetic Data Generation: Methods, Challenges and the\n  Future", "abstract": "The recent surge in research focused on generating synthetic data from large\nlanguage models (LLMs), especially for scenarios with limited data\navailability, marks a notable shift in Generative Artificial Intelligence (AI).\nTheir ability to perform comparably to real-world data positions this approach\nas a compelling solution to low-resource challenges. This paper delves into\nadvanced technologies that leverage these gigantic LLMs for the generation of\ntask-specific training data. We outline methodologies, evaluation techniques,\nand practical applications, discuss the current limitations, and suggest\npotential pathways for future research.", "published": "2024-03-07 03:38:44", "link": "http://arxiv.org/abs/2403.04190v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.0"], "primary_category": "cs.LG"}
{"title": "Aligners: Decoupling LLMs and Alignment", "abstract": "Large Language Models (LLMs) need to be aligned with human expectations to\nensure their safety and utility in most applications. Alignment is challenging,\ncostly, and needs to be repeated for every LLM and alignment criterion. We\npropose to decouple LLMs and alignment by training aligner models that can be\nused to align any LLM for a given criteria on an as-needed basis, thus also\nreducing the potential negative impacts of alignment on performance. Our recipe\nfor training the aligner models solely relies on synthetic data generated with\na (prompted) LLM and can be easily adjusted for a variety of alignment\ncriteria. We use the same synthetic data to train inspectors, binary\nmiss-alignment classification models to guide a \"squad\" of multiple aligners.\nOur empirical results demonstrate consistent improvements when applying aligner\nsquad to various LLMs, including chat-aligned models, across several\ninstruction-following and red-teaming datasets.", "published": "2024-03-07 04:54:56", "link": "http://arxiv.org/abs/2403.04224v4", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Can Small Language Models be Good Reasoners for Sequential\n  Recommendation?", "abstract": "Large language models (LLMs) open up new horizons for sequential\nrecommendations, owing to their remarkable language comprehension and\ngeneration capabilities. However, there are still numerous challenges that\nshould be addressed to successfully implement sequential recommendations\nempowered by LLMs. Firstly, user behavior patterns are often complex, and\nrelying solely on one-step reasoning from LLMs may lead to incorrect or\ntask-irrelevant responses. Secondly, the prohibitively resource requirements of\nLLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real\nsequential recommender systems. In this paper, we propose a novel Step-by-step\nknowLedge dIstillation fraMework for recommendation (SLIM), paving a promising\npath for sequential recommenders to enjoy the exceptional reasoning\ncapabilities of LLMs in a \"slim\" (i.e., resource-efficient) manner. We\nintroduce CoT prompting based on user behavior sequences for the larger teacher\nmodel. The rationales generated by the teacher model are then utilized as\nlabels to distill the downstream smaller student model (e.g., LLaMA2-7B). In\nthis way, the student model acquires the step-by-step reasoning capabilities in\nrecommendation tasks. We encode the generated rationales from the student model\ninto a dense vector, which empowers recommendation in both ID-based and\nID-agnostic scenarios. Extensive experiments demonstrate the effectiveness of\nSLIM over state-of-the-art baselines, and further analysis showcasing its\nability to generate meaningful recommendation reasoning at affordable costs.", "published": "2024-03-07 06:49:37", "link": "http://arxiv.org/abs/2403.04260v2", "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "cs.IR"}
{"title": "Advancing Chinese biomedical text mining with community challenges", "abstract": "Objective: This study aims to review the recent advances in community\nchallenges for biomedical text mining in China. Methods: We collected\ninformation of evaluation tasks released in community challenges of biomedical\ntext mining, including task description, dataset description, data source, task\ntype and related links. A systematic summary and comparative analysis were\nconducted on various biomedical natural language processing tasks, such as\nnamed entity recognition, entity normalization, attribute extraction, relation\nextraction, event extraction, text classification, text similarity, knowledge\ngraph construction, question answering, text generation, and large language\nmodel evaluation. Results: We identified 39 evaluation tasks from 6 community\nchallenges that spanned from 2017 to 2023. Our analysis revealed the diverse\nrange of evaluation task types and data sources in biomedical text mining. We\nexplored the potential clinical applications of these community challenge tasks\nfrom a translational biomedical informatics perspective. We compared with their\nEnglish counterparts, and discussed the contributions, limitations, lessons and\nguidelines of these community challenges, while highlighting future directions\nin the era of large language models. Conclusion: Community challenge evaluation\ncompetitions have played a crucial role in promoting technology innovation and\nfostering interdisciplinary collaboration in the field of biomedical text\nmining. These challenges provide valuable platforms for researchers to develop\nstate-of-the-art solutions.", "published": "2024-03-07 06:52:51", "link": "http://arxiv.org/abs/2403.04261v2", "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "cs.AI"}
{"title": "Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model\n  with Proxy", "abstract": "Reinforcement Learning from Human Feedback (RLHF) is the prevailing approach\nto ensure Large Language Models (LLMs) align with human values. However,\nexisting RLHF methods require a high computational cost, one main reason being\nthat RLHF assigns both the generation and alignment tasks to the LLM\nsimultaneously. In this paper, we introduce Proxy-RLHF, which decouples the\ngeneration and alignment processes of LLMs, achieving alignment with human\nvalues at a much lower computational cost. We start with a novel Markov\nDecision Process (MDP) designed for the alignment process and employ\nReinforcement Learning (RL) to train a streamlined proxy model that oversees\nthe token generation of the LLM, without altering the LLM itself. Experiments\nshow that our method achieves a comparable level of alignment with only 1\\% of\nthe training parameters of other methods.", "published": "2024-03-07 07:31:00", "link": "http://arxiv.org/abs/2403.04283v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "ALTO: An Efficient Network Orchestrator for Compound AI Systems", "abstract": "We present ALTO, a network orchestrator for efficiently serving compound AI\nsystems such as pipelines of language models. ALTO achieves high throughput and\nlow latency by taking advantage of an optimization opportunity specific to\ngenerative language models: streaming intermediate outputs. As language models\nproduce outputs token by token, ALTO exposes opportunities to stream\nintermediate outputs between stages when possible. We highlight two new\nchallenges of correctness and load balancing which emerge when streaming\nintermediate data across distributed pipeline stage instances. We also motivate\nthe need for an aggregation-aware routing interface and distributed\nprompt-aware scheduling to address these challenges. We demonstrate the impact\nof ALTO's partial output streaming on a complex chatbot verification pipeline,\nincreasing throughput by up to 3x for a fixed latency target of 4 seconds /\nrequest while also reducing tail latency by 1.8x compared to a baseline serving\napproach.", "published": "2024-03-07 08:30:26", "link": "http://arxiv.org/abs/2403.04311v1", "categories": ["cs.AI", "cs.CL", "cs.DC", "cs.IR"], "primary_category": "cs.AI"}
{"title": "Discriminative Probing and Tuning for Text-to-Image Generation", "abstract": "Despite advancements in text-to-image generation (T2I), prior methods often\nface text-image misalignment problems such as relation confusion in generated\nimages. Existing solutions involve cross-attention manipulation for better\ncompositional understanding or integrating large language models for improved\nlayout planning. However, the inherent alignment capabilities of T2I models are\nstill inadequate. By reviewing the link between generative and discriminative\nmodeling, we posit that T2I models' discriminative abilities may reflect their\ntext-image alignment proficiency during generation. In this light, we advocate\nbolstering the discriminative abilities of T2I models to achieve more precise\ntext-to-image alignment for generation. We present a discriminative adapter\nbuilt on T2I models to probe their discriminative abilities on two\nrepresentative tasks and leverage discriminative fine-tuning to improve their\ntext-image alignment. As a bonus of the discriminative adapter, a\nself-correction mechanism can leverage discriminative gradients to better align\ngenerated images to text prompts during inference. Comprehensive evaluations\nacross three benchmark datasets, including both in-distribution and\nout-of-distribution scenarios, demonstrate our method's superior generation\nperformance. Meanwhile, it achieves state-of-the-art discriminative performance\non the two discriminative tasks compared to other generative models.", "published": "2024-03-07 08:37:33", "link": "http://arxiv.org/abs/2403.04321v2", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "primary_category": "cs.CV"}
{"title": "Membership Inference Attacks and Privacy in Topic Modeling", "abstract": "Recent research shows that large language models are susceptible to privacy\nattacks that infer aspects of the training data. However, it is unclear if\nsimpler generative models, like topic models, share similar vulnerabilities. In\nthis work, we propose an attack against topic models that can confidently\nidentify members of the training data in Latent Dirichlet Allocation. Our\nresults suggest that the privacy risks associated with generative modeling are\nnot restricted to large neural models. Additionally, to mitigate these\nvulnerabilities, we explore differentially private (DP) topic modeling. We\npropose a framework for private topic modeling that incorporates DP vocabulary\nselection as a pre-processing step, and show that it improves privacy while\nhaving limited effects on practical utility.", "published": "2024-03-07 12:43:42", "link": "http://arxiv.org/abs/2403.04451v2", "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "cs.CR"}
{"title": "MedFLIP: Medical Vision-and-Language Self-supervised Fast Pre-Training\n  with Masked Autoencoder", "abstract": "Within the domain of medical analysis, extensive research has explored the\npotential of mutual learning between Masked Autoencoders(MAEs) and multimodal\ndata. However, the impact of MAEs on intermodality remains a key challenge. We\nintroduce MedFLIP, a Fast Language-Image Pre-training method for Medical\nanalysis. We explore MAEs for zero-shot learning with crossed domains, which\nenhances the model's ability to learn from limited data, a common scenario in\nmedical diagnostics. We verify that masking an image does not affect\ninter-modal learning. Furthermore, we propose the SVD loss to enhance the\nrepresentation learning for characteristics of medical images, aiming to\nimprove classification accuracy by leveraging the structural intricacies of\nsuch data. Our theory posits that masking encourages semantic preservation,\nrobust feature extraction, regularization, domain adaptation, and invariance\nlearning. Lastly, we validate using language will improve the zero-shot\nperformance for the medical image analysis. MedFLIP's scaling of the masking\nprocess marks an advancement in the field, offering a pathway to rapid and\nprecise medical image analysis without the traditional computational\nbottlenecks. Through experiments and validation, MedFLIP demonstrates efficient\nperformance improvements, helps for future research and application in medical\ndiagnostics.", "published": "2024-03-07 16:11:43", "link": "http://arxiv.org/abs/2403.04626v2", "categories": ["eess.IV", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "eess.IV"}
{"title": "Fact-Checking the Output of Large Language Models via Token-Level\n  Uncertainty Quantification", "abstract": "Large language models (LLMs) are notorious for hallucinating, i.e., producing\nerroneous claims in their output. Such hallucinations can be dangerous, as\noccasional factual inaccuracies in the generated text might be obscured by the\nrest of the output being generally factually correct, making it extremely hard\nfor the users to spot them. Current services that leverage LLMs usually do not\nprovide any means for detecting unreliable generations. Here, we aim to bridge\nthis gap. In particular, we propose a novel fact-checking and hallucination\ndetection pipeline based on token-level uncertainty quantification. Uncertainty\nscores leverage information encapsulated in the output of a neural network or\nits layers to detect unreliable predictions, and we show that they can be used\nto fact-check the atomic claims in the LLM output. Moreover, we present a novel\ntoken-level uncertainty quantification method that removes the impact of\nuncertainty about what claim to generate on the current step and what surface\nform to use. Our method Claim Conditioned Probability (CCP) measures only the\nuncertainty of a particular claim value expressed by the model. Experiments on\nthe task of biography generation demonstrate strong improvements for CCP\ncompared to the baselines for seven LLMs and four languages. Human evaluation\nreveals that the fact-checking pipeline based on uncertainty quantification is\ncompetitive with a fact-checking tool that leverages external knowledge.", "published": "2024-03-07 17:44:17", "link": "http://arxiv.org/abs/2403.04696v2", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "How Far Are We from Intelligent Visual Deductive Reasoning?", "abstract": "Vision-Language Models (VLMs) have recently demonstrated incredible strides\non diverse vision language tasks. We dig into vision-based deductive reasoning,\na more sophisticated but less explored realm, and find previously unexposed\nblindspots in the current SOTA VLMs. Specifically, we leverage Raven's\nProgressive Matrices (RPMs), to assess VLMs' abilities to perform multi-hop\nrelational and deductive reasoning relying solely on visual clues. We perform\ncomprehensive evaluations of several popular VLMs employing standard strategies\nsuch as in-context learning, self-consistency, and Chain-of-thoughts (CoT) on\nthree diverse datasets, including the Mensa IQ test, IntelligenceTest, and\nRAVEN. The results reveal that despite the impressive capabilities of LLMs in\ntext-based reasoning, we are still far from achieving comparable proficiency in\nvisual deductive reasoning. We found that certain standard strategies that are\neffective when applied to LLMs do not seamlessly translate to the challenges\npresented by visual reasoning tasks. A detailed analysis reveals that VLMs\nstruggle to solve these tasks mainly because they are unable to perceive and\ncomprehend multiple, confounding abstract patterns in RPM examples.", "published": "2024-03-07 18:35:54", "link": "http://arxiv.org/abs/2403.04732v3", "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "cs.AI"}
{"title": "LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error", "abstract": "Tools are essential for large language models (LLMs) to acquire up-to-date\ninformation and take consequential actions in external environments. Existing\nwork on tool-augmented LLMs primarily focuses on the broad coverage of tools\nand the flexibility of adding new tools. However, a critical aspect that has\nsurprisingly been understudied is simply how accurately an LLM uses tools for\nwhich it has been trained. We find that existing LLMs, including GPT-4 and\nopen-source LLMs specifically fine-tuned for tool use, only reach a correctness\nrate in the range of 30% to 60%, far from reliable use in practice. We propose\na biologically inspired method for tool-augmented LLMs, simulated trial and\nerror (STE), that orchestrates three key mechanisms for successful tool use\nbehaviors in the biological system: trial and error, imagination, and memory.\nSpecifically, STE leverages an LLM's 'imagination' to simulate plausible\nscenarios for using a tool, after which the LLM interacts with the tool to\nlearn from its execution feedback. Both short-term and long-term memory are\nemployed to improve the depth and breadth of the exploration, respectively.\nComprehensive experiments on ToolBench show that STE substantially improves\ntool learning for LLMs under both in-context learning and fine-tuning settings,\nbringing a boost of 46.7% to Mistral-Instruct-7B and enabling it to outperform\nGPT-4. We also show effective continual learning of tools via a simple\nexperience replay strategy.", "published": "2024-03-07 18:50:51", "link": "http://arxiv.org/abs/2403.04746v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "cs.CL"}
{"title": "Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks", "abstract": "We introduce Syntax-Aware Fill-In-the-Middle (SAFIM), a new benchmark for\nevaluating Large Language Models (LLMs) on the code Fill-in-the-Middle (FIM)\ntask. This benchmark focuses on syntax-aware completions of program structures\nsuch as code blocks and conditional expressions, and includes 17,720 examples\nfrom multiple programming languages, sourced from recent code submissions after\nApril 2022 to minimize data contamination. SAFIM provides a robust framework\nwith various prompt designs and novel syntax-aware post-processing techniques,\nfacilitating accurate and fair comparisons across LLMs. Our comprehensive\nevaluation of 15 LLMs shows that FIM pretraining not only enhances FIM\nproficiency but also improves Left-to-Right (L2R) inference using LLMs. Our\nfindings challenge conventional beliefs and suggest that pretraining methods\nand data quality have more impact than model size. SAFIM thus serves as a\nfoundational platform for future research in effective pretraining strategies\nfor code LLMs. The evaluation toolkit and dataset are available at\nhttps://github.com/gonglinyuan/safim, and the leaderboard is available at\nhttps://safimbenchmark.com.", "published": "2024-03-07 05:05:56", "link": "http://arxiv.org/abs/2403.04814v3", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "primary_category": "cs.CL"}
{"title": "Automating the Information Extraction from Semi-Structured Interview\n  Transcripts", "abstract": "This paper explores the development and application of an automated system\ndesigned to extract information from semi-structured interview transcripts.\nGiven the labor-intensive nature of traditional qualitative analysis methods,\nsuch as coding, there exists a significant demand for tools that can facilitate\nthe analysis process. Our research investigates various topic modeling\ntechniques and concludes that the best model for analyzing interview texts is a\ncombination of BERT embeddings and HDBSCAN clustering. We present a\nuser-friendly software prototype that enables researchers, including those\nwithout programming skills, to efficiently process and visualize the thematic\nstructure of interview data. This tool not only facilitates the initial stages\nof qualitative analysis but also offers insights into the interconnectedness of\ntopics revealed, thereby enhancing the depth of qualitative analysis.", "published": "2024-03-07 13:53:03", "link": "http://arxiv.org/abs/2403.04819v1", "categories": ["cs.CL", "cs.CY", "cs.IR", "cs.SI"], "primary_category": "cs.CL"}
{"title": "A Survey on Human-AI Teaming with Large Pre-Trained Models", "abstract": "In the rapidly evolving landscape of artificial intelligence (AI), the\ncollaboration between human intelligence and AI systems, known as Human-AI\n(HAI) Teaming, has emerged as a cornerstone for advancing problem-solving and\ndecision-making processes. The advent of Large Pre-trained Models (LPtM) has\nsignificantly transformed this landscape, offering unprecedented capabilities\nby leveraging vast amounts of data to understand and predict complex patterns.\nThis paper surveys the pivotal integration of LPtMs with HAI, emphasizing how\nthese models enhance collaborative intelligence beyond traditional approaches.\nIt examines the potential of LPtMs in augmenting human capabilities, discussing\nthis collaboration for AI model improvements, effective teaming, ethical\nconsiderations, and their broad applied implications in various sectors.\nThrough this exploration, the study sheds light on the transformative impact of\nLPtM-enhanced HAI Teaming, providing insights for future research, policy\ndevelopment, and strategic implementations aimed at harnessing the full\npotential of this collaboration for research and societal benefit.", "published": "2024-03-07 22:37:49", "link": "http://arxiv.org/abs/2403.04931v2", "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "cs.AI"}
{"title": "MEIT: Multi-Modal Electrocardiogram Instruction Tuning on Large Language\n  Models for Report Generation", "abstract": "Electrocardiogram (ECG) is the primary non-invasive diagnostic tool for\nmonitoring cardiac conditions and is crucial in assisting clinicians. Recent\nstudies have concentrated on classifying cardiac conditions using ECG data but\nhave overlooked ECG report generation, which is time-consuming and requires\nclinical expertise. To automate ECG report generation and ensure its\nversatility, we propose the Multimodal ECG Instruction Tuning (MEIT) framework,\nthe first attempt to tackle ECG report generation with LLMs and multimodal\ninstructions. To facilitate future research, we establish a benchmark to\nevaluate MEIT with various LLMs backbones across two large-scale ECG datasets.\nOur approach uniquely aligns the representations of the ECG signal and the\nreport, and we conduct extensive experiments to benchmark MEIT with nine\nopen-source LLMs using more than 800,000 ECG reports. MEIT's results underscore\nthe superior performance of instruction-tuned LLMs, showcasing their\nproficiency in quality report generation, zero-shot capabilities, and\nresilience to signal perturbation. These findings emphasize the efficacy of our\nMEIT framework and its potential for real-world clinical application.", "published": "2024-03-07 23:20:56", "link": "http://arxiv.org/abs/2403.04945v3", "categories": ["cs.CL", "cs.LG", "eess.SP"], "primary_category": "cs.CL"}
{"title": "Bridging Text and Molecule: A Survey on Multimodal Frameworks for\n  Molecule", "abstract": "Artificial intelligence has demonstrated immense potential in scientific\nresearch. Within molecular science, it is revolutionizing the traditional\ncomputer-aided paradigm, ushering in a new era of deep learning. With recent\nprogress in multimodal learning and natural language processing, an emerging\ntrend has targeted at building multimodal frameworks to jointly model molecules\nwith textual domain knowledge. In this paper, we present the first systematic\nsurvey on multimodal frameworks for molecules research. Specifically,we begin\nwith the development of molecular deep learning and point out the necessity to\ninvolve textual modality. Next, we focus on recent advances in text-molecule\nalignment methods, categorizing current models into two groups based on their\narchitectures and listing relevant pre-training tasks. Furthermore, we delves\ninto the utilization of large language models and prompting techniques for\nmolecular tasks and present significant applications in drug discovery.\nFinally, we discuss the limitations in this field and highlight several\npromising directions for future research.", "published": "2024-03-07 03:03:13", "link": "http://arxiv.org/abs/2403.13830v1", "categories": ["q-bio.BM", "cs.CL", "cs.LG"], "primary_category": "q-bio.BM"}
{"title": "Promising and worth-to-try future directions for advancing\n  state-of-the-art surrogates methods of agent-based models in social and\n  health computational sciences", "abstract": "The execution and runtime performance of model-based analysis tools for\nrealistic large-scale ABMs (Agent-Based Models) can be excessively long. This\ndue to the computational demand exponentially proportional to the model size\n(e.g. Population size) and the number of model parameters. Even the runtime of\na single simulation of a realistic ABM may demand huge computational resources\nwhen attempting to employ realistic population size. The main aim of this\nad-hoc brief report is to highlight some of surrogate models that were adequate\nand computationally less demanding for nonlinear dynamical models in various\nmodeling application areas.To the author knowledge, these methods have been\nnot, at least extensively, employed for ABMs within the field of (SHCS) Social\nHealth Computational Sciences, yet. Thus, they might be, but not necessarily,\nuseful in progressing state of the art for establishing surrogate models for\nABMs in the field of SHCS.", "published": "2024-03-07 11:30:56", "link": "http://arxiv.org/abs/2403.04417v1", "categories": ["cs.CL", "cs.AI", "cs.SY", "eess.SY", "math.DS"], "primary_category": "cs.CL"}
{"title": "Speech Emotion Recognition Via CNN-Transformer and Multidimensional\n  Attention Mechanism", "abstract": "Speech Emotion Recognition (SER) is crucial in human-machine interactions.\nMainstream approaches utilize Convolutional Neural Networks or Recurrent Neural\nNetworks to learn local energy feature representations of speech segments from\nspeech information, but struggle with capturing global information such as the\nduration of energy in speech. Some use Transformers to capture global\ninformation, but there is room for improvement in terms of parameter count and\nperformance. Furthermore, existing attention mechanisms focus on spatial or\nchannel dimensions, hindering learning of important temporal information in\nspeech. In this paper, to model local and global information at different\nlevels of granularity in speech and capture temporal, spatial and channel\ndependencies in speech signals, we propose a Speech Emotion Recognition network\nbased on CNN-Transformer and multi-dimensional attention mechanisms.\nSpecifically, a stack of CNN blocks is dedicated to capturing local information\nin speech from a time-frequency perspective. In addition, a time-channel-space\nattention mechanism is used to enhance features across three dimensions.\nMoreover, we model local and global dependencies of feature sequences using\nlarge convolutional kernels with depthwise separable convolutions and\nlightweight Transformer modules. We evaluate the proposed method on IEMOCAP and\nEmo-DB datasets and show our approach significantly improves the performance\nover the state-of-the-art methods.", "published": "2024-03-07 18:49:29", "link": "http://arxiv.org/abs/2403.04743v2", "categories": ["eess.AS"], "primary_category": "eess.AS"}
{"title": "The best autoregressive approach to audio inpainting is gap-wise Janssen", "abstract": "A novel variant of the Janssen method for audio inpainting is presented. The\nnew method is compared with a number of other popular audio inpainting methods\nbased on autoregressive modeling. Main differences between the particular\napproaches are pointed out. In the experimental part, the importance of the\nchoice of the AR model estimator is confirmed by objective metrics, and the\neffect of the chosen AR model order and window size is explored. The results of\nsmall-scale and mid-scale computational experiments are in agreement. The\nresults show the superiority of the proposed gap-wise Janssen approach, which\nis confirmed by a listening test.", "published": "2024-03-07 12:06:19", "link": "http://arxiv.org/abs/2403.04433v3", "categories": ["eess.AS", "cs.SD"], "primary_category": "eess.AS"}
{"title": "A Detailed Audio-Text Data Simulation Pipeline using Single-Event Sounds", "abstract": "Recently, there has been an increasing focus on audio-text cross-modal\nlearning. However, most of the existing audio-text datasets contain only simple\ndescriptions of sound events. Compared with classification labels, the\nadvantages of such descriptions are significantly limited. In this paper, we\nfirst analyze the detailed information that human descriptions of audio may\ncontain beyond sound event labels. Based on the analysis, we propose an\nautomatic pipeline for curating audio-text pairs with rich details. Leveraging\nthe property that sounds can be mixed and concatenated in the time domain, we\ncontrol details in four aspects: temporal relationship, loudness, speaker\nidentity, and occurrence number, in simulating audio mixtures. Corresponding\ndetails are transformed into captions by large language models. Audio-text\npairs with rich details in text descriptions are thereby obtained. We validate\nthe effectiveness of our pipeline with a small amount of simulated data,\ndemonstrating that the simulated data enables models to learn detailed audio\ncaptioning.", "published": "2024-03-07 15:40:01", "link": "http://arxiv.org/abs/2403.04594v1", "categories": ["cs.SD", "eess.AS"], "primary_category": "cs.SD"}
{"title": "Audio-Visual Person Verification based on Recursive Fusion of Joint\n  Cross-Attention", "abstract": "Person or identity verification has been recently gaining a lot of attention\nusing audio-visual fusion as faces and voices share close associations with\neach other. Conventional approaches based on audio-visual fusion rely on\nscore-level or early feature-level fusion techniques. Though existing\napproaches showed improvement over unimodal systems, the potential of\naudio-visual fusion for person verification is not fully exploited. In this\npaper, we have investigated the prospect of effectively capturing both the\nintra- and inter-modal relationships across audio and visual modalities, which\ncan play a crucial role in significantly improving the fusion performance over\nunimodal systems. In particular, we introduce a recursive fusion of a joint\ncross-attentional model, where a joint audio-visual feature representation is\nemployed in the cross-attention framework in a recursive fashion to\nprogressively refine the feature representations that can efficiently capture\nthe intra-and inter-modal relationships. To further enhance the audio-visual\nfeature representations, we have also explored BLSTMs to improve the temporal\nmodeling of audio-visual feature representations. Extensive experiments are\nconducted on the Voxceleb1 dataset to evaluate the proposed model. Results\nindicate that the proposed model shows promising improvement in fusion\nperformance by adeptly capturing the intra-and inter-modal relationships across\naudio and visual modalities.", "published": "2024-03-07 16:57:45", "link": "http://arxiv.org/abs/2403.04654v3", "categories": ["cs.CV", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "Dynamic Cross Attention for Audio-Visual Person Verification", "abstract": "Although person or identity verification has been predominantly explored\nusing individual modalities such as face and voice, audio-visual fusion has\nrecently shown immense potential to outperform unimodal approaches. Audio and\nvisual modalities are often expected to pose strong complementary\nrelationships, which plays a crucial role in effective audio-visual fusion.\nHowever, they may not always strongly complement each other, they may also\nexhibit weak complementary relationships, resulting in poor audio-visual\nfeature representations. In this paper, we propose a Dynamic Cross-Attention\n(DCA) model that can dynamically select the cross-attended or unattended\nfeatures on the fly based on the strong or weak complementary relationships,\nrespectively, across audio and visual modalities. In particular, a conditional\ngating layer is designed to evaluate the contribution of the cross-attention\nmechanism and choose cross-attended features only when they exhibit strong\ncomplementary relationships, otherwise unattended features. Extensive\nexperiments are conducted on the Voxceleb1 dataset to demonstrate the\nrobustness of the proposed model. Results indicate that the proposed model\nconsistently improves the performance on multiple variants of cross-attention\nwhile outperforming the state-of-the-art methods.", "published": "2024-03-07 17:07:51", "link": "http://arxiv.org/abs/2403.04661v3", "categories": ["cs.CV", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "cs.CV"}
{"title": "A Study of Dropout-Induced Modality Bias on Robustness to Missing Video\n  Frames for Audio-Visual Speech Recognition", "abstract": "Advanced Audio-Visual Speech Recognition (AVSR) systems have been observed to\nbe sensitive to missing video frames, performing even worse than\nsingle-modality models. While applying the dropout technique to the video\nmodality enhances robustness to missing frames, it simultaneously results in a\nperformance loss when dealing with complete data input. In this paper, we\ninvestigate this contrasting phenomenon from the perspective of modality bias\nand reveal that an excessive modality bias on the audio caused by dropout is\nthe underlying reason. Moreover, we present the Modality Bias Hypothesis (MBH)\nto systematically describe the relationship between modality bias and\nrobustness against missing modality in multimodal systems. Building on these\nfindings, we propose a novel Multimodal Distribution Approximation with\nKnowledge Distillation (MDA-KD) framework to reduce over-reliance on the audio\nmodality and to maintain performance and robustness simultaneously. Finally, to\naddress an entirely missing modality, we adopt adapters to dynamically switch\ndecision strategies. The effectiveness of our proposed approach is evaluated\nand validated through a series of comprehensive experiments using the MISP2021\nand MISP2022 datasets. Our code is available at\nhttps://github.com/dalision/ModalBiasAVSR", "published": "2024-03-07 06:06:55", "link": "http://arxiv.org/abs/2403.04245v1", "categories": ["cs.SD", "cs.CV", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "cs.SD"}
